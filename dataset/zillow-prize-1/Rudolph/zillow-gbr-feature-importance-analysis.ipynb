{"nbformat_minor":1,"metadata":{"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"_uuid":"a2b7cb2e62a998c69be07fa46f3ad13abe5b57b6","_cell_guid":"fa4d4816-f425-4035-aa66-44f3cab68541"},"cell_type":"markdown","source":"This is version 2 where I used the GradientBoostingRegressor (gbr) with default parameters  and I added a few new features in addition to Day, Month and Season (from the previous version) such as the tax per square foot etc. I removed some of the features with large number of missing values and changed the dtypes to keep the properties frame under 0.7GB and the number of features at 64. On its own this gave LB 0.06445 but when combined (simply averaged) with some of the other public kernels that have similar score on their own the result was 0.06426 (top 5%).  Suprisingly both lgbm and xgb gave worse score with the extra features.  The rest of the notebook compares the feature importances between gbr  and lgbm and xgb and looks at the impact of each feature. The test set score seems to converge at about 30 features but keeping all 64 gave a better LB score.\n"},{"metadata":{"_uuid":"7c5670caa7a3faf992fcda8a7064d682eb90b3b7","_cell_guid":"ac9bfcc6-529e-424e-afd5-4ac80e9c3850"},"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import  GradientBoostingRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import MiniBatchKMeans\nimport lightgbm as lgb\nimport xgboost as xgb\nimport datetime as dt\nimport gc\n\nprint('loading files...')\nprop = pd.read_csv('../input/properties_2016.csv',low_memory=False)\nprop.rename(columns={'parcelid': 'ParcelId'}, inplace=True)   # make it the same as sample_submission\ntrain = pd.read_csv('../input/train_2016_v2.csv')\ntrain.rename(columns={'parcelid': 'ParcelId'},inplace=True)\nsample = pd.read_csv('../input/sample_submission.csv')\nprint(train.shape, prop.shape, sample.shape)","cell_type":"code","outputs":[],"execution_count":1},{"metadata":{"_uuid":"c348da19d950905ef4c02a2147be7e7221d6e48e","_cell_guid":"a7d9a3a5-0024-4f63-9f78-a384cef8e0b2"},"source":"print('preprocessing, fillna, outliters, dtypes ...')\n\nprop['longitude']=prop['longitude'].fillna(prop['longitude'].median()) / 1e6   #  convert to float32 later\nprop['latitude'].fillna(prop['latitude'].median()) / 1e6\nprop['censustractandblock'].fillna(prop['censustractandblock'].median()) / 1e12\ntrain = train[train['logerror'] <  train['logerror'].quantile(0.9975)]  # exclude 0.5% of outliers\ntrain = train[train['logerror'] >  train['logerror'].quantile(0.0025)]\n\nprint('qualitative ...')\nqualitative = [f for f in prop.columns if prop.dtypes[f] == object]\nprop[qualitative] = prop[qualitative].fillna('Missing')\nfor c in qualitative:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(int)\n\nprint('smallval ...')\nsmallval = [f for f in prop.columns if np.abs(prop[f].max())<100]\nprop[smallval] = prop[smallval].fillna('Missing')\nfor c in smallval:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(np.int8)\n\nprint('other ...')\nother=['regionidcounty','fips','propertycountylandusecode','propertyzoningdesc','propertylandusetypeid']\nprop[other] = prop[other].fillna('Missing')\nfor c in other:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(int)\n\nrandomyears=pd.Series(np.random.choice(prop['yearbuilt'].dropna().values,len(prop)))\nprop['yearbuilt']=prop['yearbuilt'].fillna(randomyears).astype(int)\nmed_yr=prop['yearbuilt'].quantile(0.5)\nprop['New']=prop['yearbuilt'].apply(lambda x: 1 if x > med_yr else 0).astype(np.int8)  # adding a new feature\n\nrandomyears=pd.Series(np.random.choice(prop['assessmentyear'].dropna().values,len(prop)))\nprop['assessmentyear']=prop['assessmentyear'].fillna(randomyears).astype(int)\n\nprop['unitcnt'] = prop['unitcnt'].fillna(1).astype(int)    \n    \nfeat_to_drop=[ 'finishedsquarefeet50', 'finishedfloor1squarefeet', 'finishedsquarefeet15', 'finishedsquarefeet13']\nprop.drop(feat_to_drop,axis=1,inplace=True)   # drop because too many missing values\nprop['lotsizesquarefeet'].fillna(prop['lotsizesquarefeet'].quantile(0.001),inplace=True)\nprop['finishedsquarefeet12'].fillna(prop['finishedsquarefeet12'].quantile(0.001),inplace=True)\nprop['calculatedfinishedsquarefeet'].fillna(prop['finishedsquarefeet12'],inplace=True)\nprop['taxamount'].fillna(prop['taxamount'].quantile(0.001),inplace=True)\nprop['landtaxvaluedollarcnt'].fillna(prop['landtaxvaluedollarcnt'].quantile(0.001),inplace=True)\nprop.fillna(0,inplace=True)\n    \nprint('quantitative ...')   \nquantitative = [f for f in prop.columns if prop.dtypes[f] == np.float64]\nprop[quantitative] = prop[quantitative].astype(np.float32) \n\ncfeatures = list(prop.select_dtypes(include = ['int64', 'int32', 'uint8', 'int8']).columns)\nfor c in qualitative:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values))\n\n# some quantitative features have a limited number of values (eg ZIP code)    \nfor c in ['rawcensustractandblock',  'regionidcity',  'regionidneighborhood',  'regionidzip',  'censustractandblock'] :\n    prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values))\n\n# other quantitative features were probably transformed when Zillow first calculate prices because of the skew\nfor c in ['calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'lotsizesquarefeet', \n    'structuretaxvaluedollarcnt',  'taxvaluedollarcnt',  'landtaxvaluedollarcnt',  'taxamount'] :\n    prop[c] = np.log1p(prop[c].values)\n    \ngc.collect()","cell_type":"code","outputs":[],"execution_count":2},{"metadata":{"_uuid":"2d262aef018faedcb7af3387a63d60849085222f","_cell_guid":"3c64ec3b-1021-4399-b3a7-5930c47dd06f"},"source":"print('create new features and the final dataframes frames ...')\n\n#replace latitudes and longitudes with 500 clusters  (similar to ZIP codes)\ncoords = np.vstack(prop[['latitude', 'longitude']].values)\nsample_ind = np.random.permutation(len(coords))[:1000000]\nkmeans = MiniBatchKMeans(n_clusters=500, batch_size=100000).fit(coords[sample_ind])\nprop['Cluster'] = kmeans.predict(prop[['latitude', 'longitude']])\n\nprop['Living_area_prop'] = prop['calculatedfinishedsquarefeet'] / prop['lotsizesquarefeet']\nprop['Value_ratio'] = prop['taxvaluedollarcnt'] / prop['taxamount']\nprop['Value_prop'] = prop['structuretaxvaluedollarcnt'] / prop['landtaxvaluedollarcnt']\nprop['Taxpersqrtfoot']=prop['finishedsquarefeet12']/prop['taxamount']\n\ntrain['transactiondate'] = pd.to_datetime(train.transactiondate)\ntrain['Month'] = train['transactiondate'].dt.month.astype(np.int8)\ntrain['Day'] = train['transactiondate'].dt.day.astype(np.int8)\ntrain['Season'] = train['Month'].apply(lambda x: 1 if x in [1,2,9,10,11,12] else 0).astype(np.int8)\n\nmonth_err=(train.groupby('Month').aggregate({'logerror': lambda x: np.mean(x)})- train['logerror'].mean()).values\ntrain['Meanerror']=train['Month'].apply(lambda x: month_err[x-1]).astype(np.float)\n\ntrain['abserror']=train['logerror'].abs()\nmonth_abs_err=(train.groupby('Month').aggregate({'abserror': lambda x: np.mean(x)})- train['abserror'].mean()).values\ntrain['Meanabserror']=train['Month'].apply(lambda x: month_abs_err[x-1]).astype(np.float)\ntrain.drop(['abserror'], axis=1,inplace=True)\n\nX = train.merge(prop, how='left', on='ParcelId')\ny = X['logerror']\nX.drop(['ParcelId', 'logerror', 'transactiondate'], axis=1,inplace=True)\nfeatures=list(X.columns)\n\nprint(X.shape, y.shape)\ngc.collect()","cell_type":"code","outputs":[],"execution_count":3},{"metadata":{"_uuid":"eba33b0faa3bfa65f6d0516e92e6614434d601c5","_cell_guid":"81268377-8fc4-4f4e-a417-922c55d98086"},"source":"print(' Training GB ...')\nX_train=X\ny_train=y\nn_estimators=800\nclf = GradientBoostingRegressor(loss='lad',   n_estimators=n_estimators,  verbose=1)\nclf.fit(X_train, y_train)\nprint('MAE train  {:.4f}'.format(np.mean(np.abs(y_train-clf.predict(X_train)) )))\ngc.collect()\n\nsubmit=False     # change to create the submission file\nfeatures=X_train.columns\nif submit:\n    print('predict and submit ...')\n    X_test = (sample.merge(prop, on='ParcelId', how='left')).loc[:,features]\n    \n    if 'Season' in features: X_test['Season']=np.int8(1)\n    if 'Day' in features: X_test['Day']=np.int8(15)\n\n    for month in [10, 11, 12]:\n        print('month ',month)\n        if 'Month' in features: X_test['Month']=np.int8(month) \n        if 'Meanerror' in features: X_test['Meanerror']=np.float(month_err[month-1])\n        if 'Meanabserror' in features: X_test['Meanabserror']=np.float(month_abs_err[month-1])\n        sample['2016' + str(month)] = clf.predict(X_test)\n        print(' MAE {}  {:.4f}'.format(month,np.mean(np.abs(sample['2016' + str(month)]-0) )))\n\n    sample.to_csv('submission_GBR6445.csv', index = False, float_format = '%.5f')\n\nFeatImp=pd.DataFrame(clf.feature_importances_, index=X_train.columns, columns=['Importance'])\nFeatImp=FeatImp.sort_values('Importance')\nFeatImp.plot(kind='barh', figsize=(8,14))\nplt.show()\n","cell_type":"code","outputs":[],"execution_count":4},{"metadata":{"_uuid":"7586979b49d350f9276bc9ca28243c0c6af056f6","_cell_guid":"2ef18d6f-e354-4d5a-9f79-cc08407187d4"},"source":"# Plot training deviance - 600 iteration seems enough\nplt.plot(np.arange(n_estimators)+1, clf.train_score_)\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nplt.show()","cell_type":"code","outputs":[],"execution_count":8},{"metadata":{"_uuid":"4bcd0282e646b64f104f649fcd996364c34b6778","_cell_guid":"45119564-5430-4fe0-a9b7-8b38ce5c6c0e"},"source":"# starting with 10 most important features I gradually add more features to see their impact\n# there are 64 features but after the first 30 the gain is quite small\nprint('feature impact ...')\n\nX_train, X_eval, y_train, y_eval = train_test_split(X,y, test_size=0.5, random_state=1)\nclf = GradientBoostingRegressor(loss='lad',   n_estimators=600,  verbose=0)\nclf.fit(X_train, y_train)\nFeatImp=pd.DataFrame(clf.feature_importances_, index=X_train.columns, columns=['Importance'])\nFeatImp=FeatImp.sort_values('Importance', ascending = False)\nprint( FeatImp.iloc[0:10].index.values )\nErrors_train = []\nErrors_eval = []\n\nistart=10\niend=len(FeatImp)+1\niend = 30  # remove if time is no constraint and let run to the end (ie 64)\nfor i in range(istart,iend):\n    X_train_temp = X_train[FeatImp.iloc[0:i].index.values]\n    X_eval_temp = X_eval[FeatImp.iloc[0:i].index.values]\n    clf.fit(X_train_temp, y_train)\n    Err_eval = np.mean(np.abs(y_eval-clf.predict(X_eval_temp) ) )\n    Err_train=np.mean(np.abs(y_train-clf.predict(X_train_temp) ) )\n    print('{:<30} train {:.3f} eval {:.3f} '.format(FeatImp.index[i-1],1000*Err_train, 1000*Err_eval))\n    Errors_train = Errors_train+[Err_train]\n    Errors_eval = Errors_eval+[Err_eval]\n\nplt.figure(figsize=(20,10))\nplt.plot(range(istart,iend),Errors_train,label='train')\nplt.plot(range(istart,iend),Errors_eval,label='eval')\nplt.xticks(range(istart,iend), features[10:],rotation=90)\nplt.ylabel('Errors')\nplt.legend()\nplt.show()   ","cell_type":"code","outputs":[],"execution_count":10},{"metadata":{"_uuid":"64f087bcfabc6af44472ee3780ab575054fccc47","_cell_guid":"811a632c-ef64-4c60-9ca6-f1e52c35175a"},"source":"print('Training lgbm ...')\nfeatures=list(X.columns)\ncfeatures = list(X.select_dtypes(include = ['int64', 'int32', 'uint8', 'int8']).columns)\n\nparams = {'metric': 'mae', 'learning_rate' : 0.005, 'max_depth':10, 'max_bin':10,\n         'feature_fraction': 0.95,'bagging_fraction':0.95,'bagging_freq':10,'min_data': 500}\n\n# using eval or not (set CV to True or False)\nCV=False\nif CV:\n    \n    X_train, X_eval, y_train, y_eval = train_test_split(X,y, test_size=0.5, random_state=5)\n    lgb_train = lgb.Dataset(X_train.values, y_train.values)\n    lgb_eval = lgb.Dataset(X_eval.values, y_eval.values, reference = lgb_train)\n    lgb_model = lgb.train(params, lgb_train, num_boost_round = 3000, valid_sets = lgb_eval, \n             feature_name=features, early_stopping_rounds=100, verbose_eval = 100)\n    pred1 = lgb_model.predict(X_train.values, num_iteration = lgb_model.best_iteration)\n    pred2 = lgb_model.predict(X_eval.values, num_iteration = lgb_model.best_iteration)\n    print(' MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\n    print(' MAE eval   {:.4f}'.format(np.mean(np.abs(y_eval.values-pred2) )))\n    del lgb_train,pred1,lgb_eval, pred2\n    \nelse:\n\n    X_train=X\n    y_train=y\n    lgb_train = lgb.Dataset(X_train.values, y_train.values)\n    lgb_model = lgb.train(params, lgb_train, num_boost_round = 3000, feature_name=features)\n    pred1 = lgb_model.predict(X_train.values, num_iteration = lgb_model.best_iteration)\n    print(' MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\n    del lgb_train, pred1\n    \n    \nlgb_model.save_model('model.txt')\n#bst = lgb.Booster(model_file='model.txt')    \ngc.collect()","cell_type":"code","outputs":[],"execution_count":15},{"metadata":{"_uuid":"18a7859408be0cfbf6602eb920b1e33adf472bb9","_cell_guid":"8e2cca88-a916-4b2d-adc9-12578616ff46"},"source":"#check feature importance\nlgb.plot_importance(lgb_model,  figsize=(10,20))\nplt.show()\ngc.collect()","cell_type":"code","outputs":[],"execution_count":32},{"metadata":{"_uuid":"194bb5846bae18c98f4b4f28f42cd6c1aa2c04b0","_cell_guid":"56d88ee9-7d60-4335-90b6-8c1df31e7442"},"source":"# I do not know if there is a more pythonic way to get the lgbm feature importances but the best I \n# could do is by parsing the model file\nind=[]\ndata=[]\nwith open('model.txt') as f: FI = list(f)[-100:-2]\nFI=FI[FI.index('feature importances:\\n') +1:]    \nfor i in range(len(FI)): \n    FI[i]=FI[i][:-1]\n    ind=ind+[FI[i].split('=')[0]]\n    data=data+[int(FI[i].split('=')[1])]\nFeatImp=pd.DataFrame(data, index=ind, columns=['Importance'])\ndel f,ind,data\nFeatImp.head()","cell_type":"code","outputs":[],"execution_count":17},{"metadata":{"_uuid":"aad019cfee7c3bd65da4e995cc9c2348198cdd2a","_cell_guid":"43d2d029-7bf7-4324-84f4-fc81d59c3ddf"},"cell_type":"markdown","source":"Obviously the feature importances depend on the choice of the parameters but still the first attempt to compare gbr and lgbm leads to quite large differences and so it makes sense to combine the different methods. Finally, let us compare with xgb. "},{"metadata":{"_uuid":"414cc2037ba248b554233296cbc951e8cb3e6960","_cell_guid":"aaf9fd2b-e0ad-45d4-9c10-c121eced7793"},"source":"print('training xgboost ...')\nX_train=X\ny_train=y\ny_mean = np.mean(y_train)\nxgb_params = {'eta': 0.037, 'max_depth': 5, 'subsample': 0.80,  'eval_metric': 'mae', \n              'lambda': 0.8,   'alpha': 0.4, 'base_score': y_mean, 'silent': 1 }\ndtrain = xgb.DMatrix(X_train, y_train)\nmodel = xgb.train(xgb_params, dtrain, num_boost_round=250)\npred1 = model.predict(dtrain)\nprint(' xgb MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\ndel dtrain, pred1\ngc.collect()","cell_type":"code","outputs":[],"execution_count":25},{"metadata":{"_uuid":"ec70cc56e00cff55b6ec4a4493bac424cba5eb6c","_cell_guid":"90157eff-6a9d-4f2f-a7b4-075dc997d908"},"source":"fig, ax = plt.subplots(figsize=(20, 20))\nxgb.plot_importance(model, ax=ax)\nplt.show()\ngc.collect()","cell_type":"code","outputs":[],"execution_count":29},{"metadata":{"_uuid":"5a83ec74ae8fa22832f922fc4858aaab6e66a974","_cell_guid":"4554da72-4a75-47ab-bc92-d88506dc56c9"},"cell_type":"markdown","source":"Work in progress ...\n"},{"metadata":{"_uuid":"6891fc6a265e40ef161fd43d24b65d3fd6f6b6b7","_cell_guid":"078f83d4-5247-429f-9a64-b2d80349d8d9"},"cell_type":"markdown","source":""}],"nbformat":4}