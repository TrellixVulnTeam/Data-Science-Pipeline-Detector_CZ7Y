{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"700e3e8f-2972-5c83-9e55-b48f7a927274"},"source":"# first neural network test-split the data\n# obtain the results to ann\n# the code must be improved"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc99ba69-0c52-3434-ba07-21968eac9dc9"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPRegressor\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"789ed47c-c8ab-7058-4839-ddc1c0b74bc0"},"outputs":[],"source":"prop_df = pd.read_csv(\"../input/properties_2016.csv\")\ntrain_df = pd.read_csv(\"../input/train_2016.csv\")\ndata= pd.merge(left=train_df,right=prop_df, left_on='parcelid', right_on='parcelid') # merge target and train"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5a9b3b3-8f4e-29a7-b54a-5dc4d283e327"},"outputs":[],"source":"# split the dataset (train and test)\ntrain=data.sample(frac=0.4,random_state=200)\ntest=data.drop(train.index)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45030457-2a58-c5c6-8412-a3220459fd61"},"outputs":[],"source":"# geting the name of variables\nstrings = list(data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db0e3f9e-b1b3-f39f-dd6e-41bca13dd939"},"outputs":[],"source":"# dataset: features to be excluded \ninvalid = ['parecelid', 'logerror', 'transactiondate','propertycountylandusecode','propertyzoningdesc','taxdelinquencyflag',\n               'hashottuborspa','fireplaceflag','latitude','longitude']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75ab11c1-df04-e792-b264-c7f9743f0e10"},"outputs":[],"source":"# exlucluding features\nNomes = list(filter(lambda x: not any(s in x.lower() for s in invalid),strings))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75d09e85-7fc2-a2e8-39f1-cef6f5a9bcd3"},"outputs":[],"source":"#s plit the dataset in train and target and replace NaNs by zero\ntrain_x=train[Nomes]\ntrain_x[np.isnan(train_x)] = 0\ntrain_y=train[['logerror']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23bcfac4-dd5a-7a0e-94a2-472220573b60"},"outputs":[],"source":"# normatization of dataset\ntrain_y=(train_y-train_y.min())/(train_y.max()-train_y.min())\ntrain_x=(train_x-train_x.min())/(train_x.max()-train_x.min())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d420211a-5001-770f-f280-d01aaabd5ad4"},"outputs":[],"source":"#create neural net regressor\n# activation : {'identity', 'logistic', 'tanh', 'relu'},\nreg = MLPRegressor(hidden_layer_sizes=(100,),activation='logistic',solver=\"lbfgs\",max_iter=10000)\nreg.fit(train_x,train_y)\n \n#test prediction\ntest_x=train_x\npredict=reg.predict(test_x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"905742bc-c80d-aad0-8363-c729c9433946"},"outputs":[],"source":"%matplotlib inline\nplt.figure(figsize=(8,6))\nplt.scatter(train_y,predict)\nplt.xlabel(\"y_train\")\nplt.ylabel(\"y_calc\")\nplt.xlim((0,1))\nplt.ylim((0,1))\nplt.title(\"my first ANN approx\")\n\nplt.show()\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}