{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport missingno as msno\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom scipy.stats import ttest_ind\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.feature_selection import SelectFromModel\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\n\n#sets up pandas table display\npd.set_option('display.width', 800)\npd.set_option('display.max_columns', 100)\npd.set_option('display.notebook_repr_html', True)\n#stop scientific notation\npd.options.display.float_format = '{:.2f}'.format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a list of missing value types\nmissing_values = [\"n/a\", \"na\", \"--\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the 2016 properties data and target variable\nhouse_2016_df = pd.read_csv('../input/zillow-prize-1/properties_2016.csv', na_values = missing_values, low_memory=False)\nhouse_2017_df = pd.read_csv('../input/zillow-prize-1/properties_2017.csv', na_values = missing_values, low_memory=False)\nhouse_log_2016 = pd.read_csv('../input/zillow-prize-1/train_2016_v2.csv', low_memory=False)\nhouse_log_2017 = pd.read_csv('../input/zillow-prize-1/train_2017.csv', low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(house_2016_df.shape)\nprint(house_2017_df.shape)\nprint(house_log_2016.shape)\nprint(house_log_2017.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge the trasaction dataset fro 2016-2017\n#I drop the overlapped parcelid id \nhouse_log_full = pd.concat([house_log_2016,house_log_2017],ignore_index=True)\nhouse_log_full2= house_log_full.drop_duplicates(subset= 'parcelid' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check if 2016 and 2017 is overlap \nlen(set(house_2016_df['parcelid']).intersection(house_2017_df['parcelid']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#so why use both year to join in 2017 house? \n#there are overlaps of parcelid id, 167888-165210= 2678\n\nhouse_2017_full = house_2017_df.merge(house_log_full2, on = 'parcelid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house_2017_full.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#house_2017_full has all th data that has log, so we need to find the test set \n#house_2017_full_2 = house_2017_df.merge(house_log_full, on = 'parcelid', how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#two method: 1 use the house_2017_full as the predict set, 2 use the unused as the predict set. \n#house_2017_full.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#house_2017_full_2[house_2017_full_2['logerror'].isnull()].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission= pd.read_csv(\"../input/zillow-prize-1/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#house_2017_full[house_2017_full['parcelid']==13850164]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So there is a process of impute the boolean variables, but we didn't do that for the house_2017_full \n#impute boolean variables \nhouse_2017_full['fireplaceflag'].replace(True, 1, inplace=True)\nhouse_2017_full['fireplaceflag'].fillna(0, inplace = True)\nhouse_2017_full['hashottuborspa'].replace(True, 1, inplace=True)\nhouse_2017_full['hashottuborspa'].fillna(0, inplace = True) \nhouse_2017_full['pooltypeid10'].fillna(0, inplace = True) \nhouse_2017_full['pooltypeid2'].fillna(0, inplace = True)\nhouse_2017_full['pooltypeid7'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot distribution of target variable log error\n#1.9% outliner. \nfrom scipy.stats import zscore\nhouse_2017_full[\"logerror_zscore\"] = zscore(house_2017_full[\"logerror\"])\nhouse_2017_full[\"is_outlier\"] = house_2017_full[\"logerror_zscore\"].apply(\n  lambda x: x <= -2.5 or x >= 2.5\n)\n\nplt.figure(figsize=(12,8))\nsb.distplot(house_2017_full[~house_2017_full['is_outlier']].logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.title('logerror distribution')\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#explore the missing value\nmissing_df = house_2017_full.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, missing_df.missing_count.values, color='lightblue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h2o.init()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house_2017_temp = house_2017_full[~house_2017_full['is_outlier']]\nhouse_2017_tree = house_2017_temp.drop(['logerror_zscore','is_outlier','parcelid'], axis =1)\nhouse_2017_full_hf = h2o.H2OFrame(house_2017_tree)\nhouse_2017_tree.head(5)\n\n#house_2017_tree dropped the outlier, the parcelid id and logerror_zscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defind the model\nh2o_tree = H2ORandomForestEstimator(ntrees = 50, max_depth = 20, nfolds =10)\n#train the model,if x not specify,model will use all x except the y column\nh2o_tree.train(y = 'logerror', training_frame = house_2017_full_hf)\n#print variable importance\nh2o_tree_df = h2o_tree._model_json['output']['variable_importances'].as_data_frame()\n#visualize the importance\n\nplt.rcdefaults()\nfig, ax = plt.subplots(figsize = (10, 10))\nvariables = h2o_tree._model_json['output']['variable_importances']['variable']\ny_pos = np.arange(len(variables))\nscaled_importance = h2o_tree._model_json['output']['variable_importances']['scaled_importance']\nax.barh(y_pos, scaled_importance, align='center', color='green', ecolor='black')\nax.set_yticks(y_pos)\nax.set_yticklabels(variables)\nax.invert_yaxis()\nax.set_xlabel('Scaled Importance')\nax.set_title('Variable Importance')\nplt.show()\n\n#choose features have importance score >0.2\nfeature_score = 0.1\nselected_features = h2o_tree_df[h2o_tree_df.scaled_importance>=feature_score]['variable']\nselected_features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_features = ['regionidneighborhood','taxamount','calculatedfinishedsquarefeet'\n                     ,'yearbuilt','lotsizesquarefeet','propertyzoningdesc','garagetotalsqft','bedroomcnt','buildingqualitytypeid'\n                     ,'calculatedbathnbr','yardbuildingsqft17']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_cols = (pd.Series(selected_features)).append(pd.Series(['logerror']))\n#split data to training and test data set\nX_train,X_test= train_test_split(house_2017_tree[selected_cols], test_size=0.33, random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pred= house_2017_df[selected_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pred.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_h2o = h2o.H2OFrame(X_train)\nX_test_h2o = h2o.H2OFrame(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pred_h2o = h2o.H2OFrame(X_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from h2o.estimators import H2OXGBoostEstimator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_h2o.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nparam = {\n      \"ntrees\" : 100\n    , \"learn_rate\" : 0.02\n    , \"max_depth\" : 10\n    , \"sample_rate\" : 0.7\n    , \"col_sample_rate_per_tree\" : 0.9\n    , \"min_rows\" : 5\n    , \"seed\": 4241\n    , \"score_tree_interval\": 100\n    ,  'nfolds': 10\n    , \"stopping_metric\" : \"MSE\"\n}\nfrom h2o.estimators import H2OXGBoostEstimator\nmodel = H2OXGBoostEstimator(**param)\nmodel.train(y = 'logerror', training_frame = X_train_h2o)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model.summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nhyper_params = {'max_depth' : [4,6,8,12,16,20]\n               ,\"learn_rate\" : [0.1, 0.01, 0.0001] \n               }\nparam_grid = {\n      \"ntrees\" : 50\n    , \"sample_rate\" : 0.7\n    , \"col_sample_rate_per_tree\" : 0.9\n    , \"min_rows\" : 5\n    , \"seed\": 4241\n    , \"score_tree_interval\": 100\n    ,  'nfolds': 10\n    , \"stopping_metric\" : \"MSE\"\n}\nmodel_grid = H2OXGBoostEstimator(**param_grid)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#grid = H2OGridSearch(model_grid,hyper_params,\n                         grid_id = 'depth_grid',\n                         search_criteria = {'strategy': \"Cartesian\"})\n\n\n#Train grid search\n#grid.train(y='logerror',\n       #    training_frame = X_train_h2o)\n       \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xgb_gridperf = grid.get_grid(sort_by='mse', decreasing=True)\n#xgb_gridperf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_param = {\n      \"ntrees\" : 100\n    , \"learn_rate\" : 0.1\n    , \"max_depth\" : 6\n    , \"sample_rate\" : 0.7\n    , \"col_sample_rate_per_tree\" : 0.9\n    , \"min_rows\" : 5\n    , \"seed\": 4241\n    , \"score_tree_interval\": 100\n    ,  'nfolds': 10\n    , \"stopping_metric\" : \"MSE\"\n}\n\nbest_model = H2OXGBoostEstimator(**best_param)\nbest_model.train(y = 'logerror', training_frame = X_train_h2o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the test set metrics for the best model\nbest_metrics = best_model.model_performance(test_data=X_test_h2o) \nbest_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=best_model.predict(X_test_pred_h2o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#h2o.h2o.download_csv(result, \"Predcited.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_list = h2o.h2o.as_list(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(result_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house_2017_df[\"logerror\"]=result_list\nSubmit = house_2017_df[[\"parcelid\",\"logerror\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submit[\"201610\"]=result_list\nSubmit[\"201611\"]=result_list\nSubmit[\"201612\"]=result_list\nSubmit[\"201710\"]=result_list\nSubmit[\"201711\"]=result_list\nSubmit[\"201712\"]=result_list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submit = Submit.drop(\"logerror\",axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submit.columns = [\"ParcelId\", \"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submit.to_csv(\"Submission.csv\", index = False )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}