{"nbformat":4,"cells":[{"cell_type":"code","outputs":[],"metadata":{"_uuid":"2c03b457b91a30c42847dd9885104a1aadccc088","collapsed":true,"_cell_guid":"5bd5f440-4450-40d7-97cf-3d24b474a3ea"},"execution_count":null,"source":"import pandas as pd\nimport numpy as np\nimport datetime as datetime\n\n#mdf = 'c:/Users/John/Documents/Kaggle/zillow/data/'\nmdf = '../input/'\n\ntrain = pd.read_csv(mdf + 'properties_2016.csv')\ntrain_label = pd.read_csv(mdf + 'train_2016_v2.csv', parse_dates = ['transactiondate'])\n\ntrain.shape"},{"cell_type":"markdown","metadata":{"_uuid":"e602044bd42ee28f47114d6e8d5b50bec7c90e4b","_cell_guid":"910e1253-9b3c-49f4-82cc-b560c136404c"},"source":"This script uses a simple Bayesian Network model for logerror. Discussion [is here.](http://https://www.kaggle.com/c/zillow-prize-1/discussion/39811#223545)\n\n![1](http://elmtreegarden.com/wp-content/uploads/2017/03/Variable-sensitivity-1.jpg)"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"42729b6992f07f4bb75de4988a70d27530fc17d7","collapsed":true,"_cell_guid":"3495868a-4e5f-445a-baa5-1d2ec6a6900c"},"execution_count":null,"source":"# Build features for model. Based on early BN of clusters\ntrain.loc[:,'No_Structure'] = train.structuretaxvaluedollarcnt.isnull()\ntrain.loc[:,'M_Age'] = 2017 - train['yearbuilt']\ncommon = train.merge(train_label,on=['parcelid'])\n\nmodel = pd.DataFrame()\nmodel.loc[:,'logerror'] = common.logerror\nmodel.loc[:,'Tax_Value'] = common.taxvaluedollarcnt\nmodel.loc[:,'Structure_Age'] = common.M_Age\n\n# the other variables are in buckets that maximize mutual information w logerror\nbins1 = [0,184421,850293,1360000,500000000]\ncat1 = ['<185k','<850k','<1360k','>=1360k']\nmodel.loc[:,'Tax_Value_b'] = pd.cut(model.Tax_Value, bins1, labels = cat1)\nbins2 = [0, 23, 41, 57, 80, 300]\ncat2 = ['<23', '<41', '<57', '<80', '>=80']\nmodel.loc[:,'Age_b'] = pd.cut(model.Structure_Age, bins2, labels = cat2)\n\n\n# calculate the probability distribution p(e |Age,Tax)\n# \n# the expected value of e is the weighted average for each state of logerror\np = pd.DataFrame()\np = model.groupby(['Tax_Value_b','Age_b'])['logerror'].agg([('exp_logerror','mean')])\npd.set_option('display.float_format', lambda x: '%.3f' % x)\np.reset_index(inplace = True)\n\n# calculate p (e|Tax) when Age is nan.\nps = pd.DataFrame()\nps = model[model.Age_b.isnull() == True].groupby(['Tax_Value_b'])['logerror'].agg([('exp_logerror','mean')])\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nps.reset_index(inplace = True)\n\n# calculate p (e|Age) when there is no Tax_Value\npss = pd.DataFrame()\npss = model[model.Tax_Value.isnull() == True].\\\n        groupby(['Age_b'])['logerror'].agg([('exp_logerror','mean')])\n\np.head(10)"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"e1e8945541c68d8bb7be02510a9541f1342a6ab1","collapsed":true,"_cell_guid":"fe2c0669-aa71-4736-828a-09e7ecf9db5c"},"execution_count":null,"source":"#Use the above tables to look up the expected logerror for each property in train\ndf = pd.DataFrame()\ndf.loc[:,'parcelid'] = train.parcelid\ndf.loc[:,'Tax_Value'] = train.taxvaluedollarcnt\ndf.loc[:,'Age'] = 2017 - train.yearbuilt\ndf.loc[:,'Tax_Value_b'] = pd.cut(df.Tax_Value, bins1, labels = cat1)\ndf.loc[:,'Age_b'] = pd.cut(df.Age, bins2, labels = cat2)\ndf = df.drop('Tax_Value', 1)\ndf = df.drop('Age', 1)\n\ndf.head(5)"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"3b9c8425e843cc8a6232aad87b681b453cca1b0b","collapsed":true,"_cell_guid":"fcaff2ed-753c-40db-94bd-9c5534380979"},"execution_count":null,"source":"s0 = pd.DataFrame()\ns1 = pd.DataFrame()\ndf0 = pd.DataFrame()\ndf1 = pd.DataFrame()\ndf2 = pd.DataFrame()\ndf3 = pd.DataFrame()\n\ndf0 = df[(df['Tax_Value_b'].isnull() == False) & (df['Age_b'].isnull() == False)]\ns0 = pd.merge(df0, p, on = ['Tax_Value_b', 'Age_b'], how = 'left')\n\ndf1 = df[(df['Tax_Value_b'].isnull() == False) & (df['Age_b'].isnull() == True)]\ns1 = pd.merge(df1, ps, on = 'Tax_Value_b', how = 'left')\n\ndf2 = df[(df['Tax_Value_b'].isnull() == True) & (df['Age_b'].isnull() == True)]\ndf2['exp_logerror'] = 0.004\n\ndf3 = df[(df['Tax_Value_b'].isnull() == True) & (df['Age_b'].isnull() == False)]\ndf3['exp_logerror'] = -0.010\n\nframes = [s0, s1, df2, df3]\ndf = pd.concat(frames)\n\ndf.shape"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"b312d2716142fc5bb1f19bda36da8168fa96dda9","collapsed":true,"_cell_guid":"be7cd966-2d57-49d0-a767-044778076a91"},"execution_count":null,"source":"\ndf = df.drop('Tax_Value_b', 1)\ndf = df.drop('Age_b', 1)\n\ndf['201610'] = df.exp_logerror\ndf['201611'] = df.exp_logerror\ndf['201612'] = df.exp_logerror\ndf['201710'] = df.exp_logerror\ndf['201711'] = df.exp_logerror\ndf['201712'] = df.exp_logerror\ndf = df.drop('exp_logerror', 1)\ndf = df.rename(columns={'parcelid': 'ParcelId'})\n\ndf.sort_values('ParcelId')\n\ndf.to_csv('mean_logerror6.csv', index = False)\ndf.shape"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"af44cecfb46d492b671edcd2a3e81cddf8ff3ca1","collapsed":true,"_cell_guid":"5681ad26-e33f-412a-bcbc-0a486eec40ab"},"execution_count":null,"source":""}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","version":"3.6.1","name":"python","nbconvert_exporter":"python","mimetype":"text/x-python"}},"nbformat_minor":1}