{"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","version":"3.6.0","name":"python"}},"nbformat_minor":1,"cells":[{"source":"import numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom sklearn.metrics import mean_absolute_error\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.regression.quantile_regression import QuantReg","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"from statsmodels.sandbox.tools import cross_val","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"train2017 = pd.read_csv('../input/train_2017.csv')\ntrain2016 = pd.read_csv('../input/train_2016_v2.csv')\nprop = pd.read_csv('../input/properties_2016.csv', low_memory = False)\nprop17 = pd.read_csv('../input/properties_2017.csv', low_memory = False)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"zip_count = prop['regionidzip'].value_counts().to_dict()\ncity_count = prop['regionidcity'].value_counts().to_dict()\nmedyear = prop.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\nmeanarea = prop.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\nmedlat = prop.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\nmedlong = prop.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()\n\nzip_count17 = prop17['regionidzip'].value_counts().to_dict()\ncity_count17 = prop17['regionidcity'].value_counts().to_dict()\nmedyear17 = prop17.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\nmeanarea17 = prop17.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\nmedlat17 = prop17.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\nmedlong17 = prop17.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"train2016 = train2016.merge(prop, how='left', on=['parcelid'])\ntrain2017 = train2017.merge(prop17, how='left', on=['parcelid'])","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"def calculate_features(df):\n    df['N-zip_count'] = df['regionidzip'].map(zip_count)\n    df['N-city_count'] = df['regionidcity'].map(city_count)\n    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n                         (df['pooltypeid10']>0) & \\\n                         (df['airconditioningtypeid']!=5))*1 \n    df['mean_area'] = df['regionidneighborhood'].map(meanarea)\n    df['med_year'] = df['regionidneighborhood'].map(medyear)\n    df['med_lat'] = df['regionidneighborhood'].map(medlat)\n    df['med_long'] = df['regionidneighborhood'].map(medlong)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"def calculate_features17(df):\n    df['N-zip_count'] = df['regionidzip'].map(zip_count17)\n    df['N-city_count'] = df['regionidcity'].map(city_count17)\n    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n                         (df['pooltypeid10']>0) & \\\n                         (df['airconditioningtypeid']!=5))*1 \n    df['mean_area'] = df['regionidneighborhood'].map(meanarea17)\n    df['med_year'] = df['regionidneighborhood'].map(medyear17)\n    df['med_lat'] = df['regionidneighborhood'].map(medlat17)\n    df['med_long'] = df['regionidneighborhood'].map(medlong17)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"calculate_features(train2016)\ncalculate_features17(train2017)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"train = pd.concat([train2016, train2017], axis = 0)","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"train['month'] = pd.to_datetime(train['transactiondate']).dt.month\ntrain['year'] = pd.to_datetime(train['transactiondate']).dt.year\ntrain['yearmonth'] = 100*train.year+train.month\nselect_2016 = train['year']==2016\nbasedate = pd.to_datetime('2015-11-17').toordinal()\nordinal = pd.to_datetime(train.transactiondate).apply(lambda x: x.toordinal()-basedate)\ntrain['cos_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.cos)\ntrain['sin_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.sin)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"train.columns","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"def impute_nas(train_df, test_df, feat):\n    meds = train_df.median()\n    for f in feat:\n        imputed = meds[f]\n        train_df[f] = train_df[f].replace(np.nan, meds[f])\n        test_df[f] = test_df[f].replace(np.nan, meds[f])","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# dropped:\n\n#   calculatedbathnbr\n#   lotsizesquarefeet\n#   unitcnt\n#   finishedsquarefeet50\n#   numberofstories\n#   fireplacecnt\n#   fullbathcnt\n#   threequarterbathnbr\n#   finishedsquarefeet13\n#   poolsizesum\n#   yardbuildingsqft26\n\n#   N-city_count\n#   med_year\n#   med_lat\n#   med_long\n#   N-GarPoolAC","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"static_features = ['taxamount','structuretaxvaluedollarcnt',\n            'landtaxvaluedollarcnt', 'taxvaluedollarcnt', 'yearbuilt', \n             'finishedsquarefeet12', 'bedroomcnt', \n             'bathroomcnt', 'finishedsquarefeet15',\n             'finishedfloor1squarefeet', 'finishedsquarefeet6', 'garagetotalsqft',\n             'yardbuildingsqft17', 'garagecarcnt', \n             'N-zip_count', 'mean_area' ]\nfeatures = static_features + ['cos_t', 'sin_t']","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"data = train[select_2016]\nn = np.sum(select_2016)\nk = 5\n\nX = data[features]\ny = data.logerror\nkf = cross_val.KFold(n, k=k)\navgmae = 0\nfor train_index, test_index in kf:\n    X_train_, X_test_, y_train, y_test = cross_val.split(train_index, test_index, X, y)\n    X_train = pd.DataFrame(X_train_.copy(), columns=features)\n    X_test = pd.DataFrame(X_test_.copy(), columns=features)\n    impute_nas(X_train, X_test, features)\n    reg = QuantReg(y_train, sm.add_constant(X_train)).fit(q=.5)\n    ypred = reg.predict(sm.add_constant(X_test,has_constant='add'))\n    mae = mean_absolute_error(y_test, ypred)\n    print( \"Fold MAE: \", mae )\n    avgmae += mae\navgmae /= k\nprint(\"\\nFeatures:\\n\", features, \"\\n\\nAverage MAE: \", avgmae)","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"# Test model on 2017 data\n\ndata = train[select_2016]\nn = np.sum(select_2016)\ntest = train[~select_2016]\n\nX = data[features].copy()\ny = data.logerror\nX_test = test[features].copy()\ny_test = test.logerror\n\nimpute_nas(X, X_test, features)\n\nreg = QuantReg(y, sm.add_constant(X)).fit(q=.5)\nypred = reg.predict(sm.add_constant(X_test,has_constant='add'))\n\nprint( \"Baseline MAE: \", mean_absolute_error(y_test, 0*ypred) )\nprint( \"Model MAE:    \", mean_absolute_error(y_test, ypred) )","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"sample_submission = pd.read_csv('../input/sample_submission.csv', low_memory = False)\n\ntest_df = pd.merge( sample_submission[['ParcelId']], \n                    prop.rename(columns = {'parcelid': 'ParcelId'}), \n                    how = 'left', on = 'ParcelId' )","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"calculate_features(test_df)\nimpute_nas(train[select_2016].copy(), test_df, static_features)","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"y_preds = []\nfor tdate in ['2016-10-15', '2016-11-15', '2016-12-15']:\n    test_df['transactiondate'] = tdate\n    ordinal = pd.to_datetime(test_df.transactiondate).apply(lambda x: x.toordinal()-basedate)\n    test_df['cos_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.cos)\n    test_df['sin_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.sin)\n    X_test = sm.add_constant(test_df[features],has_constant='add')\n    pred = reg.predict(X_test)\n    y_pred=[]\n    for i,predict in enumerate(pred):\n       y_pred.append(str(round(predict,5)))\n    y_preds.append(np.array(y_pred))","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"output = pd.DataFrame({'ParcelId': sample_submission['ParcelId'].astype(np.int32),\n       '201610': y_preds[0], '201611': y_preds[1], '201612': y_preds[2],\n       '201710': y_preds[0], '201711': y_preds[1], '201712': y_preds[2]})\n\ncols = output.columns.tolist()\ncols","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"cols = cols[-1:] + cols[:-1]\noutput = output[cols]\noutput.head()","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"output.to_csv('lad2016.csv', index=False)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"features","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"}]}