{"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"outputs":[],"source":"from datetime import datetime\nimport numpy as np\nimport numpy as numpy\nimport pandas as pd\nimport pylab\nimport calendar\nfrom scipy import stats\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nfrom scipy.stats import kendalltau\nimport warnings\nimport matplotlib.pyplot as plt\nimport pandas\n## Keras comes here\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, BatchNormalization\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\n","metadata":{"_uuid":"c66da892109b957ff23487adba8e83123665587b","_cell_guid":"72cd0880-63f6-43a4-b6c4-baaffd2bf52f"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Load train, Prop and sample\nprint('Loading train, prop and sample data')\ntrain = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\nprop = pd.read_csv('../input/properties_2016.csv')\nsample = pd.read_csv('../input/sample_submission.csv')\n \nprint('Fitting Label Encoder on properties')\nfor c in prop.columns:\n    prop[c]=prop[c].fillna(-1)\n    if prop[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(prop[c].values))\n        prop[c] = lbl.transform(list(prop[c].values))\n        \n#Create df_train and x_train y_train from that\nprint('Creating training set:')\ndf_train = train.merge(prop, how='left', on='parcelid')\n\n###########################################################\ndf_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\ndf_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\ndf_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\ndf_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day\n\nselect_qtr4 = df_train[\"transactiondate_quarter\"] == 4\n\n\n###########################################\n\nprint('Fill  NA/NaN values using suitable method' )\n#df_train.fillna(df_train.mean(),inplace = True)\ndf_train.fillna(-1.0)\n\n#df_train =df_train[ df_train.logerror > -0.4005 ]\n#df_train=df_train[ df_train.logerror < 0.412 ]\n\nprint('Create x_train and y_train from df_train' )\nx_train_all = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\ny_train_all = df_train[\"logerror\"]\ny_train = y_train_all[~select_qtr4]\nx_train = x_train_all[~select_qtr4]\nx_valid = x_train_all[select_qtr4]\ny_valid = y_train_all[select_qtr4]\n\n\n#print(\"Bind x_train to float32:\")\n#x_train = x_train.values.astype(np.float32, copy=False)\n\n\ny_mean = np.mean(y_train)\nprint(x_train.shape, y_train.shape)\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c] == True)\n# Create df_test and test set\nprint('Creating df_test  :')\nsample['parcelid'] = sample['ParcelId']\n\nprint(\"Merge Sample with property data :\")\ndf_test = sample.merge(prop, on='parcelid', how='left')\n\n\n########################\ndf_test[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\ndf_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\ndf_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\ndf_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n\n#################################\n\n\nx_test = df_test[train_columns]\n\nprint('Shape of x_test:', x_test.shape)\nprint(\"Preparing x_test:\")\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\n  ","metadata":{"_uuid":"155964558e863579ab314d9207f46e507aba7b3d","_cell_guid":"eae6136b-acc7-4645-860b-2458287806b9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.preprocessing import Imputer\nimputer= Imputer()\nimputer.fit(x_train.iloc[:, :])\nx_train = imputer.transform(x_train.iloc[:, :])\nimputer.fit(x_valid.iloc[:, :])\nx_valid = imputer.transform(x_valid.iloc[:, :])\nimputer.fit(x_test.iloc[:, :])\nx_test = imputer.transform(x_test.iloc[:, :])\n\n#########################Standard Scalar##############\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\nx_valid = sc.fit_transform(x_valid)\nx_val = np.array(x_valid)\ny_val = np.array(y_valid)\n","metadata":{"_uuid":"db838b2003328313675a8ce75133c93d1144d7c6","collapsed":true,"_cell_guid":"c0a8f4f5-a346-4ab0-9841-a5ed3884685a"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"len_x=int(x_train.shape[1])\nprint(\"len_x is:\",len_x)\n#########################################################################\n####################ANN Starts here#\n\nnn = Sequential()\nnn.add(Dense(units = 400 , kernel_initializer = 'normal', activation = 'relu', input_dim = len_x))\nnn.add(Dropout(.36))\nnn.add(Dense(units = 160 , kernel_initializer = 'normal', activation = 'relu'))\nnn.add(BatchNormalization())\nnn.add(Dropout(.6))\nnn.add(Dense(units = 64 , kernel_initializer = 'normal', activation = 'relu'))\nnn.add(BatchNormalization())\nnn.add(Dropout(.48))\nnn.add(Dense(units = 28, kernel_initializer = 'normal', activation = 'relu'))\nnn.add(BatchNormalization())\nnn.add(Dropout(.48))\nnn.add(Dense(1, kernel_initializer='normal'))","metadata":{"_uuid":"6e547dce8674af8b45843e5b518a046d0701550f","_cell_guid":"53c09aea-ec0d-42df-9dc5-ee343f198b41"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"nn.compile(loss='mae', optimizer=Adam(lr=1e-3))","metadata":{"_uuid":"f82520693ae62b0b89963a29f7d35e613d3fb613","collapsed":true,"_cell_guid":"c13d0413-91d5-4987-821b-6e17b2dc046b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"nn.fit(np.array(x_train), np.array(y_train), batch_size = 32, epochs = 100, verbose=2, \n       validation_data=(x_val,y_val))","metadata":{"_uuid":"d6d5b09e8e22b442a77056694e02ee7e420f3b46","_cell_guid":"9f1c596d-17e8-42b5-961c-a4c8f5df822f"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print(\"x_test.shape:\",x_test.shape)\ny_pred_ann = nn.predict(x_test)\n\n#######################################################################################\n\nprint( \"\\nPreparing results for write :\" )","metadata":{"_uuid":"f83622df04f2829c5d1b9190ac804e76f7e584ad","collapsed":true,"_cell_guid":"5a4d34fd-9ace-44af-903d-fb3dc10d879e"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"y_pred = y_pred_ann.flatten()\n\noutput = pd.DataFrame({'ParcelId': prop['parcelid'].astype(np.int32),\n        '201610': y_pred, '201611': y_pred, '201612': y_pred,\n        '201710': y_pred, '201711': y_pred, '201712': y_pred})\n# set col 'ParceID' to first col\ncols = output.columns.tolist()\ncols = cols[-1:] + cols[:-1]\noutput = output[cols]\n\nprint( \"\\nWriting results to disk:\" )\noutput.to_csv('Only_ANN_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n\nprint( \"\\nFinished!\" )\n","metadata":{"_uuid":"126bade51bc1e9813d2dfc4167bd0fd40728d1fe","collapsed":true,"_cell_guid":"0b8896d1-c5f6-49bd-b92d-d1622b8bffbe"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"name":"python","version":"3.6.1","mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":1}