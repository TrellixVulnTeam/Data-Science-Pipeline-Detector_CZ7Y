{"cells":[{"source":"import numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom sklearn.metrics import mean_absolute_error\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.regression.quantile_regression import QuantReg","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"from statsmodels.sandbox.tools import cross_val","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"train2017 = pd.read_csv('../input/train_2017.csv')\ntrain2016 = pd.read_csv('../input/train_2016_v2.csv')\nprop = pd.read_csv('../input/properties_2016.csv', low_memory = False)\nprop17 = pd.read_csv('../input/properties_2017.csv', low_memory = False)","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"zip_count = prop['regionidzip'].value_counts().to_dict()\ncity_count = prop['regionidcity'].value_counts().to_dict()\nmedyear = prop.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\nmeanarea = prop.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\nmedlat = prop.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\nmedlong = prop.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()\n\nzip_count17 = prop17['regionidzip'].value_counts().to_dict()\ncity_count17 = prop17['regionidcity'].value_counts().to_dict()\nmedyear17 = prop17.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\nmeanarea17 = prop17.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\nmedlat17 = prop17.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\nmedlong17 = prop17.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"train2016 = train2016.merge(prop, how='left', on=['parcelid'])\ntrain2017 = train2017.merge(prop17, how='left', on=['parcelid'])","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"def calculate_features(df):\n    df['N-zip_count'] = df['regionidzip'].map(zip_count)\n    df['N-city_count'] = df['regionidcity'].map(city_count)\n    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n                         (df['pooltypeid10']>0) & \\\n                         (df['airconditioningtypeid']!=5))*1 \n    df['mean_area'] = df['regionidneighborhood'].map(meanarea)\n    df['med_year'] = df['regionidneighborhood'].map(medyear)\n    df['med_lat'] = df['regionidneighborhood'].map(medlat)\n    df['med_long'] = df['regionidneighborhood'].map(medlong)\n    df['taxrate'] = df['taxamount']/df['taxvaluedollarcnt']\n    df['taxXcars'] = df['taxrate']*df['garagecarcnt']\n\n","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"def calculate_features17(df):\n    df['N-zip_count'] = df['regionidzip'].map(zip_count17)\n    df['N-city_count'] = df['regionidcity'].map(city_count17)\n    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n                         (df['pooltypeid10']>0) & \\\n                         (df['airconditioningtypeid']!=5))*1 \n    df['mean_area'] = df['regionidneighborhood'].map(meanarea17)\n    df['med_year'] = df['regionidneighborhood'].map(medyear17)\n    df['med_lat'] = df['regionidneighborhood'].map(medlat17)\n    df['med_long'] = df['regionidneighborhood'].map(medlong17)\n    df['taxrate'] = df['taxamount']/df['taxvaluedollarcnt']\n    df['taxXcars'] = df['taxrate']*df['garagecarcnt']","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"calculate_features(train2016)\ncalculate_features17(train2017)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"train = pd.concat([train2016, train2017], axis = 0)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"train['month'] = pd.to_datetime(train['transactiondate']).dt.month\ntrain['year'] = pd.to_datetime(train['transactiondate']).dt.year\ntrain['yearmonth'] = 100*train.year+train.month\nselect_2016 = train['year']==2016\nbasedate = pd.to_datetime('2015-11-17').toordinal()\nordinal = pd.to_datetime(train.transactiondate).apply(lambda x: x.toordinal()-basedate)\ntrain['cos_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.cos)\ntrain['sin_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.sin)","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"train.columns","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"def impute_nas(train_df, test_df, feat):\n    meds = train_df.median()\n    for f in feat:\n        imputed = meds[f]\n        train_df[f] = train_df[f].replace(np.nan, meds[f])\n        test_df[f] = test_df[f].replace(np.nan, meds[f])","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"static_features = [\n    'finishedsquarefeet12',  # 678821\n    'taxrate',               # 678811\n    'garagetotalsqft',\n    'garagecarcnt', \n    'N-zip_count', \n    'taxXcars'\n]\nfeatures = static_features + ['cos_t', \n                              'sin_t']","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"data = train[select_2016]\nn = np.sum(select_2016)\nk = 5\n\nX = data[features]\ny = data.logerror\nkf = cross_val.KFold(n, k=k)\navgmae = 0\nfor train_index, test_index in kf:\n    X_train_, X_test_, y_train, y_test = cross_val.split(train_index, test_index, X, y)\n    X_train = pd.DataFrame(X_train_.copy(), columns=features)\n    X_test = pd.DataFrame(X_test_.copy(), columns=features)\n    impute_nas(X_train, X_test, features)\n    reg = QuantReg(y_train, sm.add_constant(X_train)).fit(q=.5) #,max_iter=2500)\n    ypred = reg.predict(sm.add_constant(X_test,has_constant='add'))\n    mae = mean_absolute_error(y_test, ypred)\n    print( \"Fold MAE: \", mae )\n    avgmae += mae\navgmae /= k\nprint(\"\\nFeatures:\\n\", features, \"\\n\\nAverage MAE: \", avgmae)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"# Test model on 2017 data\n\ndata = train[select_2016]\nn = np.sum(select_2016)\ntest = train[~select_2016]\n\nX = data[features].copy()\ny = data.logerror\nX_test = test[features].copy()\ny_test = test.logerror\n\nimpute_nas(X, X_test, features)\n\nreg = QuantReg(y, sm.add_constant(X)).fit(q=.5)\nreg.summary()","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"ypred = reg.predict(sm.add_constant(X_test,has_constant='add'))\n\nprint( \"Baseline MAE: \", mean_absolute_error(y_test, 0*ypred) )\nprint( \"Model MAE:    \", mean_absolute_error(y_test, ypred) )","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"ypred.shape","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"test.parcelid.shape","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"simpLADpreds = pd.DataFrame({\"ParcelId\":test.parcelid, \"pred\":ypred})","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"simpLADpreds.to_csv('simpLADpreds17.csv',index=False)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"sample_submission = pd.read_csv('../input/sample_submission.csv', low_memory = False)\n\ntest_df = pd.merge( sample_submission[['ParcelId']], \n                    prop17.rename(columns = {'parcelid': 'ParcelId'}), \n                    how = 'left', on = 'ParcelId' )","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"# Train on full data set\n\ndata = train.copy()\n\ncalculate_features17(test_df)\nimpute_nas(data, test_df, static_features)\n\nX = data[features]\ny = data.logerror\n\nreg = QuantReg(y, sm.add_constant(X)).fit(q=.5)\nreg.summary()","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"y_preds = []\nfor tdate in ['2016-10-15', '2016-11-15', '2016-12-15']:\n    test_df['transactiondate'] = tdate\n    ordinal = pd.to_datetime(test_df.transactiondate).apply(lambda x: x.toordinal()-basedate)\n    test_df['cos_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.cos)\n    test_df['sin_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.sin)\n    X_test = sm.add_constant(test_df[features],has_constant='add')\n    pred = reg.predict(X_test)\n    y_pred=[]\n    for i,predict in enumerate(pred):\n       y_pred.append(str(round(predict,5)))\n    y_preds.append(np.array(y_pred))","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"output = pd.DataFrame({'ParcelId': sample_submission['ParcelId'].astype(np.int32),\n       '201610': y_preds[0], '201611': y_preds[1], '201612': y_preds[2],\n       '201710': y_preds[0], '201711': y_preds[1], '201712': y_preds[2]})\n\ncols = output.columns.tolist()\ncols","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"cols = cols[-1:] + cols[:-1]\noutput = output[cols]\noutput.head()","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"output.to_csv('simplad2017.csv', index=False)","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"features","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"}],"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","pygments_lexer":"ipython3","version":"3.6.0","file_extension":".py"}},"nbformat":4}