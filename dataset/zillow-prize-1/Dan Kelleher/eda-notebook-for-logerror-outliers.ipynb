{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3a1d3bf4-defd-4466-482d-e7d3c0dee62b"},"source":"SRK's notebook \"[Simple Exploration Notebook](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize)\" has a nice set of visualizations for the general data.  This will attempt to explore the outliers instead.  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ec11eff-6d3d-49db-2d04-20536224ce9c"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\npd.options.display.max_rows = 200"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37141b71-658b-e0a5-ac8d-3bd170e6305a"},"outputs":[],"source":"train_df = pd.read_csv('../input/train_2016.csv', parse_dates=[\"transactiondate\"])\nprop_df = pd.read_csv('../input/properties_2016.csv')\nsample_df = pd.read_csv('../input/sample_submission.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"0451b8c3-0adb-5d7a-9ca8-e6d3705b8e50"},"source":"First let's reproduce the log error graph so we have another look at the outliers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"742e28c7-72bc-0695-1e7e-9c5b15941fab"},"outputs":[],"source":"plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('logerror', fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"10b75eff-675b-cd43-1a22-2cb21a96aedd"},"source":"### Isolate the outliers:\n\nNow we can remove the middle values to isolate the outliers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe056e0c-e7e2-7410-b75d-848f2140c036"},"outputs":[],"source":"ulimit = np.percentile(train_df.logerror.values, 99)\nllimit = np.percentile(train_df.logerror.values, 1)\nprint(\"Upper limit: {}\".format(ulimit))\nprint(\"Lower limit: {}\".format(llimit))\noutlier_df = train_df[(train_df.logerror.values > ulimit) | (train_df.logerror.values < llimit)]\nprint(\"Outlier shape: {}\".format(outlier_df.shape))\n\nplt.figure(figsize=(12,8))\nsns.distplot(outlier_df.logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cd53fe53-2f6e-588c-30b8-611331e6afc9"},"source":"So we get the same normal distribution with the center cut out.  Exactly what we expected.  We can reproduce many on the same graphs as in SRK's notebook.\n\n### Transaction Date:\n\nNow we can reproduce the date field graph."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f85e75b-ddbb-ce70-5dc7-1d7888e005e0"},"outputs":[],"source":"outlier_df['transaction_month'] = outlier_df['transactiondate'].dt.month\n\ncnt_srs = outlier_df['transaction_month'].value_counts()\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[3])\nplt.xticks(rotation='vertical')\nplt.xlabel('Month of transaction', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4f07540d-9242-d28a-8806-530676276f15"},"source":"Basically the same as the SRK version except scaled down."},{"cell_type":"markdown","metadata":{"_cell_guid":"672c6737-6544-5f2d-f310-82c1b1c8e4da"},"source":"### Properties 2016:\n\nNow lets merge the data and start looking at the outliers."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19e3fcc1-040b-d827-2069-cd2c93da0fc8"},"outputs":[],"source":"outlier_df = pd.merge(outlier_df, prop_df, on='parcelid', how='left')\noutlier_df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4f425819-000c-ae2a-48ac-4a8a0e2a6852"},"source":"Now lets look at the role of NaN values in the outliers."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6824cf12-aa7c-0664-3176-29794f8b69ab"},"outputs":[],"source":"missing_df = outlier_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df[missing_df['missing_count']>0]\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, missing_df.missing_count.values, color='blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel('Count of missing values')\nax.set_title('Number of missing values in each column')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc905d9e-4bb8-20e1-e2a2-1441748d2446"},"source":"Let us explore the latitude and longitude variable."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"001916ff-bc23-f705-7e46-8d923bf46bf0"},"outputs":[],"source":"plt.figure(figsize=(12,12))\nsns.jointplot(x=outlier_df.latitude.values, y=outlier_df.longitude.values, size=10)\nplt.ylabel('Longitude', fontsize=12)\nplt.xlabel('Latitude', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1ba00c4-2d64-73b5-0237-b87e607bd8c1"},"outputs":[],"source":"dtype_df = outlier_df.dtypes.reset_index()\ndtype_df.columns = ['Count', 'Column Type']\ndtype_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52d4ed13-0e45-06ee-1b16-e90b025ba08a"},"outputs":[],"source":"missing_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19e1816a-5244-3cf9-cefd-eedc0104771e"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}