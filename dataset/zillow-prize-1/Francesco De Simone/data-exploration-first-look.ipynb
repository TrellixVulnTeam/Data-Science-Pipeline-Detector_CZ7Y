{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2a8536ea-bef4-f033-b8fd-2753aa528d3e"},"source":"**Imports Library**\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b159915e-0b31-2805-b458-b6fb0e4701dc"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nfrom ggplot import *\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3e433fd-9eca-55ff-3d82-4217c501f16b"},"outputs":[],"source":"# Load Train data\n\ntrain_df = pd.read_csv(\"../input/train_2016.csv\", parse_dates=[\"transactiondate\"])\ntrain_df.head()\n\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"db6f3cfd-4001-c118-3978-510c766bf30c"},"source":"**Considering all data make a plot of distribution of error**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1dc83f63-f965-391c-55dc-56cd61ed6815"},"outputs":[],"source":"\nplt.figure(figsize=(12,8))\nsns.distplot(train_df.logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f33636d6-4f42-6d2e-87be-2293d24e4433"},"outputs":[],"source":"train_df['transaction_month'] = train_df['transactiondate'].dt.month\n\ncnt_srs = train_df['transaction_month'].value_counts()\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[1])\nplt.xticks(rotation='vertical')\nplt.xlabel('Month of transaction', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"61d21ced-5945-a099-ceff-497f4ad8c0f0"},"outputs":[],"source":"train_df['transaction_day'] = train_df['transactiondate'].dt.day\n\ncnt_srs = train_df['transaction_day'].value_counts()\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[5])\nplt.xticks(rotation='vertical')\nplt.xlabel('Day of transaction', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89d26047-af04-b62a-e7e8-1492834e7b3f"},"outputs":[],"source":"#load properties data frame\nprop_df = pd.read_csv(\"../input/properties_2016.csv\")\nprop_df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"92628aa8-93a0-b1e3-3226-0f681fb9e001"},"source":"How many NaN there are in this dataset ?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b43e341-5374-35c2-6b18-c5ebbb56dea9"},"outputs":[],"source":"missing_df = prop_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.ix[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.4\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, missing_df.missing_count.values, color='red')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of NaN\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69d3bb9c-4254-feed-bfd8-d41ebcaec873"},"outputs":[],"source":"plt.figure(figsize=(12,12))\nsns.jointplot(x=prop_df.latitude.values, y=prop_df.longitude.values, size=10)\nplt.ylabel('Longitude', fontsize=12)\nplt.xlabel('Latitude', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5850687e-5cf4-8120-10f5-d633056b5ea3"},"outputs":[],"source":"#merge data on key \ntrain_df_merged = pd.merge(train_df, prop_df, on='parcelid', how='left')\ntrain_df_merged.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c95d0be9-6e72-df42-6d4a-8cfd4b2f850d"},"outputs":[],"source":"#aggregate this\nnan_df = train_df_merged.isnull().sum(axis=0).reset_index()\nnan_df.columns = ['column_name', 'missing_count']\nnan_df['missing_ratio'] = nan_df['missing_count'] / train_df_merged.shape[0]\nnan_df.ix[nan_df['missing_ratio']>0.999]\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb5a7c19-12e7-e15b-2201-e903019054b7"},"outputs":[],"source":"# Let us just impute the missing values with mean values to compute correlation coefficients #\nmean_values = train_df_merged.mean(axis=0)\ntrain_df_new = train_df_merged.fillna(mean_values, inplace=True)\n\n# Now let us look at the correlation coefficient of each of these variables #\nx_cols = [col for col in train_df_new.columns if col not in ['logerror'] if train_df_new[col].dtype=='float64']\n\nlabels = []\nvalues = []\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(train_df_new[col].values, train_df_new.logerror.values)[0,1])\ncorr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n    \nind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,40))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='y')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\n#autolabel(rects)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89027db7-7e50-7aef-42f3-ca2726f3424a"},"outputs":[],"source":"corr_df_sel = corr_df.ix[(corr_df['corr_values']>0.02) | (corr_df['corr_values'] < -0.01)]\n#corr_df_sel\n\ncols_to_use = corr_df_sel.col_labels.tolist()\n\ntemp_df = train_df_merged[cols_to_use]\ncorrmat = temp_df.corr(method='spearman')\nf, ax = plt.subplots(figsize=(10, 10))\n\n# Draw the heatmap using seaborn\nsns.heatmap(corrmat, vmax=1., square=True)\nplt.title(\"Correlation HeatMap\", fontsize=15)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"bcd099b0-af61-3ca2-7233-063b43b990d8"},"source":"**Bathroom count**\n\n***There is an interesting 2.279 value in the bathroom count this is a mean value***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b39167b-8dca-4e49-e5ea-8fe6ef9bdb7a"},"outputs":[],"source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"bathroomcnt\", data=train_df_merged)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bathroom', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bathroom count\", fontsize=15)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"3479353a-2bca-8607-c96f-82f1ecf48604"},"source":"**Dimension distribution**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eec43bbd-5660-8b61-95c9-d58f43a6126b"},"outputs":[],"source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"bedroomcnt\", data=train_df_merged)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Beedroom count frequency\", fontsize=15)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f099eea3-eba1-1b33-61d9-d4d45ba45aed"},"outputs":[],"source":"train_df_merged['bedroomcnt'].ix[train_df_merged['bedroomcnt']>7] = 7\nplt.figure(figsize=(10,8))\nsns.violinplot(x='bedroomcnt', y='logerror', data=train_df_merged)\nplt.xlabel('Bedroom count', fontsize=12)\nplt.ylabel('Log Error', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4594c1e-4473-1444-e649-46b37cf306e9"},"outputs":[],"source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"yearbuilt\", data=train_df_merged)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Beedroom count frequency\", fontsize=15)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c839f14-759a-544b-9215-b259e32e8212"},"outputs":[],"source":"\nggplot(aes(x='latitude', y='longitude', color='logerror'), data=train_df_merged) + \\\n    geom_point() + \\\n    scale_color_gradient(low = 'red', high = 'blue')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79ff157e-3f5c-a8bd-f2a6-063a2fe76962"},"outputs":[],"source":"ggplot(aes(x='finishedsquarefeet12', y='taxamount', color='logerror'), data=train_df_merged) + \\\n    geom_now_its_art()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31e72927-6695-38ea-c9f6-d44a3fd56d1f"},"outputs":[],"source":"#reload all data \ntrain_raw_data = pd.read_csv(\"../input/train_2016.csv\", parse_dates=[\"transactiondate\"])\n\n#merge data on key \ntrain_df = pd.merge(train_raw_data, prop_df, on='parcelid', how='left')\n\ntrain_y = train_raw_data['logerror'].values\ncat_cols = [\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\ntrain_df = train_df.drop(['parcelid', 'logerror', 'transactiondate']+cat_cols, axis=1)\n#clean all data NaN\ntrain_df = train_df.fillna(0)\nfeat_names = train_df.columns.values\n\ntrain_df.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ebc982d1-b445-59f4-4273-6ee387c46e75"},"outputs":[],"source":"from sklearn import ensemble\nmodel = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30, max_features=0.3, n_jobs=-1, random_state=0)\nmodel.fit(train_df, train_y)\n## plot the importances ##\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='90')\nplt.xlim([-1, len(indices)])\nplt.gca().invert_yaxis()\nplt.show()\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}