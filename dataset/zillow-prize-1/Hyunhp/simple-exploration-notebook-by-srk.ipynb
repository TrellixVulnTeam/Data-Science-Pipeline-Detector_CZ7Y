{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### This kernel used dataset from the Zillow Prize: Zillow’s Home Value Prediction and copied from the 'Simple Exploration Notebook - Zillow Prize' written by SRK.\n##### Introduction to 'Simple Exploration Notebook - Zillow Prize' : [URL](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize)\n##### Thanks for sharing kernel, SRK","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-03T03:09:12.023317Z","iopub.execute_input":"2021-10-03T03:09:12.02364Z","iopub.status.idle":"2021-10-03T03:09:12.027955Z","shell.execute_reply.started":"2021-10-03T03:09:12.023606Z","shell.execute_reply":"2021-10-03T03:09:12.02683Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None # same function as warnings.filterwarnings('ignore')\npd.options.display.max_columns = 999 # show the omitted columns \n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:20.468745Z","iopub.execute_input":"2021-10-10T04:47:20.469056Z","iopub.status.idle":"2021-10-10T04:47:20.4806Z","shell.execute_reply.started":"2021-10-10T04:47:20.469027Z","shell.execute_reply":"2021-10-10T04:47:20.479915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/zillow-prize-1/train_2016_v2.csv', parse_dates=[\"transactiondate\"])\n# 'parse_dates' read date, time data as datetime format\n# if not, just read data, time data as object format","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:20.481964Z","iopub.execute_input":"2021-10-10T04:47:20.482571Z","iopub.status.idle":"2021-10-10T04:47:20.546431Z","shell.execute_reply.started":"2021-10-10T04:47:20.482539Z","shell.execute_reply":"2021-10-10T04:47:20.545765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Logerror:\n\nTarget variable for this competition is \"logerror\" field. So let us do some analysis on this field first.","metadata":{"execution":{"iopub.status.busy":"2021-10-03T03:27:25.255489Z","iopub.execute_input":"2021-10-03T03:27:25.25576Z","iopub.status.idle":"2021-10-03T03:27:25.262331Z","shell.execute_reply.started":"2021-10-03T03:27:25.255727Z","shell.execute_reply":"2021-10-03T03:27:25.260337Z"}}},{"cell_type":"code","source":"plt.figure(figsize = (8, 6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index', fontsize = 12)\nplt.ylabel('logerror', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:20.547599Z","iopub.execute_input":"2021-10-10T04:47:20.548193Z","iopub.status.idle":"2021-10-10T04:47:20.88058Z","shell.execute_reply.started":"2021-10-10T04:47:20.548155Z","shell.execute_reply":"2021-10-10T04:47:20.879925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This looks nice with some outliers at both the ends.!\n\nLet us remove the outliers and then do a histogram plot on the same.","metadata":{}},{"cell_type":"code","source":"# np.percentile = 오름차순 정렬했을 때 0을 최소값, 100을 최대값으로 백분율로 나타낸 특정 위치\nulimit = np.percentile(train_df.logerror.values, 99)\nllimit = np.percentile(train_df.logerror.values, 1)\n\ntrain_df['logerror'].loc[train_df['logerror'] > ulimit] = ulimit\ntrain_df['logerror'].loc[train_df['logerror'] < llimit] = llimit\n\nplt.figure(figsize = (12, 8))\nsns.distplot(train_df.logerror.values, bins = 50, kde = True)\nplt.xlabel('logerror', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:20.88275Z","iopub.execute_input":"2021-10-10T04:47:20.883007Z","iopub.status.idle":"2021-10-10T04:47:21.717762Z","shell.execute_reply.started":"2021-10-10T04:47:20.882975Z","shell.execute_reply":"2021-10-10T04:47:21.716953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Transaction Date:\nNow let us explore the date field. Let us first check the number of transactions in each month","metadata":{"execution":{"iopub.status.busy":"2021-10-03T03:09:46.94054Z","iopub.execute_input":"2021-10-03T03:09:46.940817Z","iopub.status.idle":"2021-10-03T03:09:46.946244Z","shell.execute_reply.started":"2021-10-03T03:09:46.94079Z","shell.execute_reply":"2021-10-03T03:09:46.945229Z"}}},{"cell_type":"code","source":"train_df['transaction_month'] = train_df['transactiondate'].dt.month\n\ncnt_srs = train_df['transaction_month'].value_counts()\nplt.figure(figsize = (12, 6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[3])\nplt.xticks(rotation = 'vertical')\nplt.xlabel('Month of transaction', fontsize = 12)\nplt.ylabel('Number of Occurences', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:21.719302Z","iopub.execute_input":"2021-10-10T04:47:21.71957Z","iopub.status.idle":"2021-10-10T04:47:22.100908Z","shell.execute_reply.started":"2021-10-10T04:47:21.719536Z","shell.execute_reply":"2021-10-10T04:47:22.092588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Parcel ID:","metadata":{"execution":{"iopub.status.busy":"2021-10-10T03:55:46.941682Z","iopub.execute_input":"2021-10-10T03:55:46.942453Z","iopub.status.idle":"2021-10-10T03:55:46.948716Z","shell.execute_reply.started":"2021-10-10T03:55:46.942407Z","shell.execute_reply":"2021-10-10T03:55:46.947434Z"}}},{"cell_type":"code","source":"(train_df['parcelid'].value_counts().reset_index())['parcelid'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:22.103018Z","iopub.execute_input":"2021-10-10T04:47:22.103276Z","iopub.status.idle":"2021-10-10T04:47:22.120067Z","shell.execute_reply.started":"2021-10-10T04:47:22.103243Z","shell.execute_reply":"2021-10-10T04:47:22.119233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So most of the parcel ids are appearing only once in the dataset.","metadata":{}},{"cell_type":"markdown","source":"#### Properties 2016:\n\nNow let us explore the properties_2016 file.","metadata":{}},{"cell_type":"code","source":"prop_df =pd.read_csv('../input/zillow-prize-1/properties_2016.csv')\nprint(prop_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:22.121507Z","iopub.execute_input":"2021-10-10T04:47:22.121777Z","iopub.status.idle":"2021-10-10T04:47:34.797405Z","shell.execute_reply.started":"2021-10-10T04:47:22.121745Z","shell.execute_reply":"2021-10-10T04:47:34.796602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prop_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:34.798545Z","iopub.execute_input":"2021-10-10T04:47:34.799357Z","iopub.status.idle":"2021-10-10T04:47:34.856606Z","shell.execute_reply.started":"2021-10-10T04:47:34.799318Z","shell.execute_reply":"2021-10-10T04:47:34.855792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing NaN values\nmissing_df = prop_df.isnull().sum(axis = 0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count'] > 0]\nmissing_df = missing_df.sort_values(by = 'missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize = (12, 18))\nrects = ax.barh(ind, missing_df.missing_count.values, color='blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation = 'horizontal')\nax.set_xlabel('count of missing values')\nax.set_title('number of missing values in each columns')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:34.859196Z","iopub.execute_input":"2021-10-10T04:47:34.85941Z","iopub.status.idle":"2021-10-10T04:47:36.917624Z","shell.execute_reply.started":"2021-10-10T04:47:34.859387Z","shell.execute_reply":"2021-10-10T04:47:36.916797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 12))\nsns.jointplot(x=prop_df.latitude.values, y=prop_df.longitude.values,\n              size = 10)\nplt.ylabel('longtitude', fontsize = 12)\nplt.xlabel('latitude', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:36.920755Z","iopub.execute_input":"2021-10-10T04:47:36.921105Z","iopub.status.idle":"2021-10-10T04:47:44.270871Z","shell.execute_reply.started":"2021-10-10T04:47:36.921067Z","shell.execute_reply":"2021-10-10T04:47:44.270202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the data page, we are provided with a full list of real estate properties in three counties (Los Angeles, Orange and Ventura, California) data in 2016.\n\nWe have about 90,811 rows in train but we have about 2,985,217 rows in properties file. So let us merge the two files and then carry out our analysis.","metadata":{}},{"cell_type":"code","source":"train_df = pd.merge(train_df, prop_df, on='parcelid', how = 'left')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:44.271995Z","iopub.execute_input":"2021-10-10T04:47:44.272323Z","iopub.status.idle":"2021-10-10T04:47:46.752707Z","shell.execute_reply.started":"2021-10-10T04:47:44.272278Z","shell.execute_reply":"2021-10-10T04:47:46.751973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let us check the dtypes of different types of variable.","metadata":{"execution":{"iopub.status.busy":"2021-10-03T03:10:22.570112Z","iopub.execute_input":"2021-10-03T03:10:22.570394Z","iopub.status.idle":"2021-10-03T03:10:22.576482Z","shell.execute_reply.started":"2021-10-03T03:10:22.570367Z","shell.execute_reply":"2021-10-03T03:10:22.575386Z"}}},{"cell_type":"code","source":"pd.options.display.max_rows = 65\n\ndtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = ['Count', 'Column Type']\ndtype_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:46.753987Z","iopub.execute_input":"2021-10-10T04:47:46.754221Z","iopub.status.idle":"2021-10-10T04:47:46.766356Z","shell.execute_reply.started":"2021-10-10T04:47:46.75419Z","shell.execute_reply":"2021-10-10T04:47:46.765567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Almost all are float variables with few object (categorical) variables. Let us get the count.","metadata":{}},{"cell_type":"code","source":"dtype_df['Column Type'].value_counts().reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:46.767786Z","iopub.execute_input":"2021-10-10T04:47:46.768656Z","iopub.status.idle":"2021-10-10T04:47:46.781235Z","shell.execute_reply.started":"2021-10-10T04:47:46.768617Z","shell.execute_reply":"2021-10-10T04:47:46.780524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let us check the number of Nulls in this new merged dataset.","metadata":{}},{"cell_type":"code","source":"missing_df = train_df.isnull().sum(axis = 0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df['missing_ratio'] = missing_df['missing_count'] / train_df.shape[0]\nmissing_df.loc[missing_df['missing_ratio'] > 0.999]","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:46.782656Z","iopub.execute_input":"2021-10-10T04:47:46.783103Z","iopub.status.idle":"2021-10-10T04:47:46.837859Z","shell.execute_reply.started":"2021-10-10T04:47:46.783066Z","shell.execute_reply":"2021-10-10T04:47:46.837056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Four columns have missing values 99.9% of the times.!","metadata":{}},{"cell_type":"markdown","source":"#### Univariate Analysis:\n\nSince there are so many variables, let us first take the 'float' variables alone and then get the correlation with the target variable to see how they are related.","metadata":{}},{"cell_type":"code","source":"# let us just impute the missing values with mean values to compute correlation coefficients\nmean_values = train_df.mean(axis = 0)\ntrain_df.fillna(mean_values, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:46.83908Z","iopub.execute_input":"2021-10-10T04:47:46.83934Z","iopub.status.idle":"2021-10-10T04:47:47.422854Z","shell.execute_reply.started":"2021-10-10T04:47:46.839299Z","shell.execute_reply":"2021-10-10T04:47:47.422097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now let us look at the correlation coefficient of each of these variables\nx_cols = [col for col in train_df.columns if col not in ['logerror'] if train_df[col].dtype == 'float64']\n\nlabels = []\nvalues = []\n\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(train_df[col].values, train_df.logerror.values)[0, 1])\ncorr_df = pd.DataFrame({'col_labels':labels,\n                        'corr_values':values})\ncorr_df = corr_df.sort_values(by = 'corr_values')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:47.424255Z","iopub.execute_input":"2021-10-10T04:47:47.424539Z","iopub.status.idle":"2021-10-10T04:47:47.472573Z","shell.execute_reply.started":"2021-10-10T04:47:47.424505Z","shell.execute_reply":"2021-10-10T04:47:47.471938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize = (12, 40))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color = 'y')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation = 'horizontal')\nax.set_xlabel('correlation coefficient')\nax.set_title('correlation coefficient of the variables')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:47.473821Z","iopub.execute_input":"2021-10-10T04:47:47.474071Z","iopub.status.idle":"2021-10-10T04:47:48.431296Z","shell.execute_reply.started":"2021-10-10T04:47:47.474039Z","shell.execute_reply":"2021-10-10T04:47:48.430633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The correlation of the target variable with the given set of variables are low overall.\n\nThere are few variables at the top of this graph without any correlation values. I guess they have only one unique value and hence no correlation value. Let us confirm the same.","metadata":{}},{"cell_type":"code","source":"corr_zero_cols = ['assessmentyear', 'storytypeid', 'pooltypeid2', 'pooltypeid7', 'pooltypeid10', 'poolcnt', 'decktypeid', 'buildingclasstypeid']\nfor col in corr_zero_cols:\n    print(col, len(train_df[col].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:48.432634Z","iopub.execute_input":"2021-10-10T04:47:48.432901Z","iopub.status.idle":"2021-10-10T04:47:48.448736Z","shell.execute_reply.started":"2021-10-10T04:47:48.432867Z","shell.execute_reply":"2021-10-10T04:47:48.447872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us take the variables with high correlation values and then do some analysis on them.","metadata":{}},{"cell_type":"code","source":"corr_df_sel = corr_df.loc[(corr_df['corr_values']>0.02) | (corr_df['corr_values'] < -0.01)]\ncorr_df_sel.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:48.450111Z","iopub.execute_input":"2021-10-10T04:47:48.450355Z","iopub.status.idle":"2021-10-10T04:47:48.461384Z","shell.execute_reply.started":"2021-10-10T04:47:48.450324Z","shell.execute_reply":"2021-10-10T04:47:48.460515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_use = corr_df_sel.col_labels.tolist()\n\ntemp_df = train_df[cols_to_use] # make dataframe through list\ncorrmat = temp_df.corr(method='spearman')\nf, ax = plt.subplots(figsize = (8, 8))\n\n# draw the heatmap using seaborn\nsns.heatmap(corrmat, vmax = 1, square = True)\nplt.title('important variables correlation map', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:48.462969Z","iopub.execute_input":"2021-10-10T04:47:48.463241Z","iopub.status.idle":"2021-10-10T04:47:48.898144Z","shell.execute_reply.started":"2021-10-10T04:47:48.463208Z","shell.execute_reply":"2021-10-10T04:47:48.897502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The important variables themselves are very highly correlated.! Let us now look at each of them.\n\n#### Finished SquareFeet 12:\n\nLet us see how the finished square feet 12 varies with the log error.","metadata":{}},{"cell_type":"code","source":"col = \"finishedsquarefeet12\"\nulimit = np.percentile(train_df[col].values, 99.5)\nllimit = np.percentile(train_df[col].values, 0.5)\ntrain_df[col].loc[train_df[col] > ulimit] = ulimit\ntrain_df[col].loc[train_df[col] < llimit] = llimit","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:48.899431Z","iopub.execute_input":"2021-10-10T04:47:48.899699Z","iopub.status.idle":"2021-10-10T04:47:48.910613Z","shell.execute_reply.started":"2021-10-10T04:47:48.899665Z","shell.execute_reply":"2021-10-10T04:47:48.909845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 12))\nsns.jointplot(x=train_df.finishedsquarefeet12.values,\n              y=train_df.logerror.values,\n              size = 10, color = color[4])\nplt.ylabel('log error', fontsize = 12)\nplt.xlabel('finished square feet 12', fontsize = 12)\nplt.title('finished square feet 12 vs log error', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:48.91178Z","iopub.execute_input":"2021-10-10T04:47:48.912484Z","iopub.status.idle":"2021-10-10T04:47:50.28313Z","shell.execute_reply.started":"2021-10-10T04:47:48.912435Z","shell.execute_reply":"2021-10-10T04:47:50.28243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems the range of logerror narrows down with increase in finished square feet 12 variable. Probably larger houses are easy to predict?\n\n#### Calculated finished square feet:","metadata":{}},{"cell_type":"code","source":"col = \"calculatedfinishedsquarefeet\"\nulimit = np.percentile(train_df[col].values, 99.5)\nllimit = np.percentile(train_df[col].values, 0.5)\ntrain_df[col].loc[train_df[col] > ulimit] = ulimit\ntrain_df[col].loc[train_df[col] < llimit] = llimit\n\nplt.figure(figsize = (12, 12))\nsns.jointplot(x = train_df[col].values,\n              y = train_df['logerror'].values, \n              size = 10, color = color[5])\nplt.ylabel('log error', fontsize = 12)\nplt.xlabel('calculated finished square feet', fontsize = 12)\nplt.title('calculated finished square feet vs log error', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:50.284611Z","iopub.execute_input":"2021-10-10T04:47:50.284908Z","iopub.status.idle":"2021-10-10T04:47:51.992456Z","shell.execute_reply.started":"2021-10-10T04:47:50.284869Z","shell.execute_reply":"2021-10-10T04:47:51.991855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here as well the distribution is very similar to the previous one. No wonder the correlation between the two variables are also high.\n\n#### Bathroom Count:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"bathroomcnt\", data=train_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bathroom', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bathroom count\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:51.9939Z","iopub.execute_input":"2021-10-10T04:47:51.994372Z","iopub.status.idle":"2021-10-10T04:47:52.304307Z","shell.execute_reply.started":"2021-10-10T04:47:51.994336Z","shell.execute_reply":"2021-10-10T04:47:52.303661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is an interesting 2.279 value in the bathroom count.\n\nNow let us check how the log error changes based on this.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nsns.boxplot(x = 'bathroomcnt', y = 'logerror', data = train_df)\nplt.ylabel('log error', fontsize = 12)\nplt.xlabel('Bathroom Count', fontsize = 12)\nplt.xticks(rotation = 'vertical')\nplt.title('how log error changes with bathroom count?', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:52.305458Z","iopub.execute_input":"2021-10-10T04:47:52.305717Z","iopub.status.idle":"2021-10-10T04:47:52.857911Z","shell.execute_reply.started":"2021-10-10T04:47:52.305684Z","shell.execute_reply":"2021-10-10T04:47:52.85724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bedroom count:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nsns.countplot(x='bedroomcnt', data = train_df)\nplt.ylabel('Frequency', fontsize = 12)\nplt.xlabel('Bedroom count', fontsize = 12)\nplt.xticks(rotation = 'vertical')\nplt.title('Frequency of Bedroom count', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:52.859228Z","iopub.execute_input":"2021-10-10T04:47:52.85949Z","iopub.status.idle":"2021-10-10T04:47:53.135825Z","shell.execute_reply.started":"2021-10-10T04:47:52.859443Z","shell.execute_reply":"2021-10-10T04:47:53.135165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['bedroomcnt'].loc[train_df['bedroomcnt'] > 7] = 7\nplt.figure(figsize = (12, 8))\nsns.violinplot(x='bedroomcnt', y='logerror', data = train_df)\nplt.xlabel('Bedroom count', fontsize = 12)\nplt.ylabel('Log error', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:53.136868Z","iopub.execute_input":"2021-10-10T04:47:53.137106Z","iopub.status.idle":"2021-10-10T04:47:53.842687Z","shell.execute_reply.started":"2021-10-10T04:47:53.137073Z","shell.execute_reply":"2021-10-10T04:47:53.841843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'taxamount'\nulimit = np.percentile(train_df[col].values, 99.5)\nllimit = np.percentile(train_df[col].values, 0.5)\ntrain_df[col].loc[train_df[col] > ulimit] = ulimit\ntrain_df[col].loc[train_df[col] < llimit] = llimit\n\nplt.figure(figsize = (12, 12))\nsns.jointplot(x=train_df['taxamount'].values, \n              y=train_df['logerror'].values, size = 10, color ='g')\nplt.ylabel('Log error', fontsize = 12)\nplt.xlabel('Tax amount', fontsize = 12)\nplt.title('Tax amount VS log error', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:53.846267Z","iopub.execute_input":"2021-10-10T04:47:53.846465Z","iopub.status.idle":"2021-10-10T04:47:55.564136Z","shell.execute_reply.started":"2021-10-10T04:47:53.846442Z","shell.execute_reply":"2021-10-10T04:47:55.563369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### YearBuilt:\nLet us explore how the error varies with the yearbulit variable.","metadata":{}},{"cell_type":"code","source":"from ggplot import *\nggplot(aes(x='yearbuilt', y='logerror'), data = train_df) + \\\n    geom_point(color = 'steelblue', size = 1) + \\\n    stat_smooth()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:47:55.565266Z","iopub.execute_input":"2021-10-10T04:47:55.56562Z","iopub.status.idle":"2021-10-10T04:48:02.129966Z","shell.execute_reply.started":"2021-10-10T04:47:55.565576Z","shell.execute_reply":"2021-10-10T04:48:02.129329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a minor incremental trend seen with respect to built year.\n\nNow let us see how the logerror varies with respect to latitude and longitude.","metadata":{}},{"cell_type":"code","source":"ggplot(aes(x = 'latitude', y = 'longitude', color = 'logerror'), data = train_df) + \\\n    geom_point() + \\\n    scale_color_gradient(low = 'red', high = 'blue')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:48:02.131397Z","iopub.execute_input":"2021-10-10T04:48:02.131886Z","iopub.status.idle":"2021-10-10T04:48:03.180956Z","shell.execute_reply.started":"2021-10-10T04:48:02.13185Z","shell.execute_reply":"2021-10-10T04:48:03.1802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no visible pockets as such with respect to latitude or longitude atleast with the naked eye.\n\nLet us take the variables with highest positive correlation and highest negative correlation to see if we can see some visible patterns.","metadata":{}},{"cell_type":"code","source":"ggplot(aes(x='finishedsquarefeet12', y='taxamount', color = 'logerror'), data = train_df) + \\\n    geom_point(alpha = 0.7) + \\\n    scale_color_gradient(low = 'pink', high = 'blue')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:48:03.182273Z","iopub.execute_input":"2021-10-10T04:48:03.182661Z","iopub.status.idle":"2021-10-10T04:48:03.911563Z","shell.execute_reply.started":"2021-10-10T04:48:03.182623Z","shell.execute_reply":"2021-10-10T04:48:03.910768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no visible patterns here as well.","metadata":{}},{"cell_type":"code","source":"train_y = train_df['logerror'].values\ncat_cols = [\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\ntrain_df = train_df.drop(['parcelid', 'logerror', 'transactiondate', 'transaction_month']+cat_cols, axis=1)\nfeat_names = train_df.columns.values\n\nfrom sklearn import ensemble\nmodel = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30,\n                                     max_features=0.3, n_jobs=-1, random_state=0)\nmodel.fit(train_df, train_y)\n\n## plot the importances ##\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis =0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12, 12))\nplt.title('Feature importances')\nplt.bar(range(len(indices)), importances[indices], color='r',\n        yerr = std[indices], align = 'center')\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:48:03.913166Z","iopub.execute_input":"2021-10-10T04:48:03.913431Z","iopub.status.idle":"2021-10-10T04:48:08.717758Z","shell.execute_reply.started":"2021-10-10T04:48:03.913396Z","shell.execute_reply":"2021-10-10T04:48:08.716978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems \"tax amount\" is the most importanct variable followed by \"structure tax value dollar count\" and \"land tax value dollor count\"","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'silent': 1,\n    'seed' : 0\n}\n\ndtrain = xgb.DMatrix(train_df, train_y, feature_names = train_df.columns.values)\nmodel = xgb.train(dict(xgb_params, silent = 0), dtrain, num_boost_round=50)\n\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12, 18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:50:42.655668Z","iopub.execute_input":"2021-10-10T04:50:42.65631Z","iopub.status.idle":"2021-10-10T04:50:55.829748Z","shell.execute_reply.started":"2021-10-10T04:50:42.656275Z","shell.execute_reply":"2021-10-10T04:50:55.829078Z"},"trusted":true},"execution_count":null,"outputs":[]}]}