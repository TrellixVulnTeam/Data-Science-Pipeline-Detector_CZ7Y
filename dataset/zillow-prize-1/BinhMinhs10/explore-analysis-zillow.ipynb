{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Understand the problem"},{"metadata":{},"cell_type":"markdown","source":"Train data bao tất cả các transaction trước ngày 15/10, 2016, và thêm một số transaction sau 15/10, 2016\n\nTest data trong public leaderboard phần còn lại transactions 15/10 đến 31/12, 2016. Còn test data trong private leaderboard sử dụng data 17/10 đến 15/12, 2017.\n\nYêu cầu predict 6 time points: October 2016 (201610), November 2016 (201611), December 2016 (201612), October 2017 (201710), November 2017 (201711) và December 2017 (201712). \nIf a property was not sold in a certain time period, that particular row will be ignored when calculating your score.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nfrom sklearn.model_selection import train_test_split\nimport gc\n\nimport lightgbm as lgb\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\ncolor = sns.color_palette()\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Data"},{"metadata":{},"cell_type":"markdown","source":"## File transaction train 2016 and 2017\n* Có 90275 giao dịch trước tháng 10 trong năm 2016"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train2016_df = pd.read_csv(\"/kaggle/input/zillow-prize-1/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\ntrain2017_df = pd.read_csv(\"/kaggle/input/zillow-prize-1/train_2017.csv\", parse_dates=[\"transactiondate\"])\nprint ('train 2016 data has {0} rows and {1} columns'.format(train2016_df.shape[0],train2016_df.shape[1]))\nprint ('----------------------------')\nprint ('train 2017 data has {0} rows and {1} columns'.format(train2017_df.shape[0],train2017_df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target varibale là logerror "},{"metadata":{"trusted":true},"cell_type":"code","source":"train2016_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train2016_df['parcelid'].value_counts().reset_index())['parcelid'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at the distribution of the target variable (log-error)\nprint(train2016_df['logerror'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution of the target variable logerror**\n* skew: thước đo sự bất đối xứng của phân phối xác suất của biến ngẫu nhiên có giá trị thực về giá trị trung bình của nó"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Skewness is', train2016_df['logerror'].skew())\ntarget = train2016_df.loc[abs(train2016_df['logerror']) < 0.4, 'logerror']\nprint('Skewness after tranforms is', target.skew())\nprint('train data has rows', target.shape)\ntarget.hist(bins=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# biểu diễn tháng sales bằng bar plot\ntrain2016_df['transaction_month'] = train2016_df['transactiondate'].dt.month\ncnt_srs = train2016_df['transaction_month'].value_counts()\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[3])\nplt.xticks(rotation='vertical')\nplt.xlabel('Month of transaction', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()\ntrain2016_df.drop(['transaction_month'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the distribution of the target variable logerror 2017\nprint('Skewness is', train2017_df['logerror'].skew())\ntarget = train2017_df.loc[abs(train2017_df['logerror']) < 0.4, 'logerror']\nprint('Skewness after tranforms is', target.skew())\nprint('train data has rows', target.shape)\nsns.distplot(target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore file properties 2016 and 2017\n* Có 58 đặc trưng khác nhau miêu tả cho mỗi ngôi nhà trong gần 3 triệu ngôi nhà"},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2016_df = pd.read_csv(\"/kaggle/input/zillow-prize-1/properties_2016.csv\")\nprop2016_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)\nprop2016_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2017_df = pd.read_csv(\"/kaggle/input/zillow-prize-1/properties_2017.csv\")\nprop2017_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge 2 file\ntrain_2016 = train2016_df.merge(prop2016_df, how='left', on='parcelid')\ntrain_2017 = train2017_df.merge(prop2017_df, how='left', on='parcelid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## zillow data dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"dicts = pd.read_excel('/kaggle/input/zillow-prize-1/zillow_data_dictionary.xlsx')\ndicts.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration\n### Corralation matrix plot\n* dataset có nhiều cột thì cách nhanh dể xác định mqh giữa các cột là dùng heatmaps (biểu đồ nhiệt)\n* Cho phép nhận diện mối quan hệ giữa 2 cột\n    * màu càng đỏ thể hiện mối quan hệ positive mạnh\n    * màu càng xanh thể hiện mối quan hệ negative mạnh \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"catvars = ['airconditioningtypeid','architecturalstyletypeid','buildingqualitytypeid','buildingclasstypeid',\n           'decktypeid','fips','hashottuborspa', 'fireplaceflag','heatingorsystemtypeid',\n           'propertycountylandusecode','propertylandusetypeid','propertyzoningdesc','regionidcity',\n           'regionidcounty','regionidneighborhood','regionidzip','storytypeid','typeconstructiontypeid','yearbuilt',\n           'taxdelinquencyflag', 'latitude', 'longitude', 'parcelid', 'assessmentyear']\n\nnumvars = [i for i in prop2016_df.columns if i not in catvars]\nprint (\"Có {} numeric và {} categorical columns\".format(len(numvars),len(catvars)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = prop2016_df[numvars].corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(19, 19))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\ncmap ='coolwarm'\n\n# Draw the heatmap with the mask and correct aspect ratio\nax = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0, annot=True,\n            square=True, linewidths=.3, cbar_kws={\"shrink\": .5})\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Từ correlation plot thấy một số nhóm biến có sự tương quan mạnh. \n* taxes: taxvaluedollarcnt, landtaxvaluedollarcnt và taxamount. \n* square footage: finishedfloor1squarefeet, finishedsquarefeet12, finishedsquarefeet13, finishedsquarefeet15, finishedsquarefeet50, finishedsquarefeet6, and calculatedfinishedsquarefeet.\n* bathrooms: fullbathcnt, calculatedbathnbr, and bathroomcnt."},{"metadata":{"trusted":true},"cell_type":"code","source":"del corr, target, ax, dicts\ngc.collect()\nprint('Memory usage reduction…')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### plot histograms numeric \n*  categorical variables thì tạo boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create numeric plots\nsns.set(style=\"whitegrid\", color_codes=True)\nnd = pd.melt(train_2016, value_vars = numvars)\nn1 = sns.FacetGrid(nd, col='variable', col_wrap=6, sharex=False, sharey = False)\nn1 = n1.map(sns.distplot, 'value')\nn1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del nd, n1\ngc.collect()\nprint('Memory usage reduction…')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pre-Processing\n* Dữ liệu mâu thuẫn có thể đưa ra kết quả phân tích không chính xác\n* xử lý không đầy đủ, có rất nhiều cột có giá trị NaN\n* xử lý nhiễu\n* Dữ liệu bị trùng lặp bị loại bỏ\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing value trong từng cột\nmissing_df = prop2016_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, missing_df.missing_count.values, color='blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trước khi quyết định loại bỏ một số feature (hầu hết bị thiếu),cần đảm bảo rằng một ô có chữ \"NaN\" thực sự mang ý nghĩa là \"Không\". \n* Ví dụ: nếu một ngôi nhà có một hồ bơi, \"hashottuborspa\"  nếu một ngôi nhà không có một hồ bơi \"NaN\" được nhập vào"},{"metadata":{"trusted":true},"cell_type":"code","source":"# miss > 99%\nmissing_df = prop2016_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df['missing_ratio'] = missing_df['missing_count'] / prop2016_df.shape[0]\nmissing_df.loc[missing_df['missing_ratio']>0.99]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pools & Hot tubs\n* \"poolcnt\" - Số hồ bơi. \"NaN\" nghĩa là \"0 hồ bơi\", nên có thể update giá trị \"0\" thay vì \"NaN\".\n* \"hashottuborspa\" - nhà có bồn tắm nước nóng hay spa không. \n    * \"NaN\" nghĩa là \"0\", nên có thể update giá trị \"0\" thay vì \"NaN\".\n    * Thay \"true\" thành \"1\"\n* \"poolsizesum\" - Tổng diện tích bể bơi. \n    * \"NaN\" nghĩa là diện tích \"0 feet vuông\" nên có thể update giá trị \"0\".\n    * Với nhà có bể bơi (poolcnt=1) nhưng bị missing diện tich thì sẽ thay bằng giá trị diện tích trung bình\n* \"pooltypeid2\" & \"pooltypeid7\" & \"pooltypeid10\" - Kiểu loại hồ hoặc bồn tắm nước nóng, những category này chỉ cung cấp thông tin với những giá trị khác null nên ta có thể update giá trị \"Nan\" bằng \"0\". \"pooltypeid10\" cung cấp thông tin giống \"hashottuborspa\" nên có thể loại khỏi tập dữ liệu"},{"metadata":{"trusted":true},"cell_type":"code","source":"def poolhottubor_process(property_data):\n    # 0 pools\n    property_data.poolcnt.fillna(0,inplace = True)\n    # 0 hot tubs or spas\n    property_data.hashottuborspa.fillna(0,inplace = True)\n    # Convert \"True\" to 1\n    property_data.hashottuborspa.replace(to_replace = True, value = 1,inplace = True)\n\n    # Set properties that have a pool but no info on poolsize equal to the median poolsize value.\n    property_data.loc[property_data.poolcnt==1, 'poolsizesum'] = property_data.loc[property_data.poolcnt==1, 'poolsizesum'].fillna(property_data[property_data.poolcnt==1].poolsizesum.median())\n    # \"0 pools\" = \"0 sq ft of pools\"\n    property_data.loc[property_data.poolcnt==0, 'poolsizesum']=0\n\n    # \"0 pools with a spa/hot tub\"\n    property_data.pooltypeid2.fillna(0,inplace = True)\n    # \"0 pools without a hot tub\"\n    property_data.pooltypeid7.fillna(0,inplace = True)\n\n    # Drop redundant feature\n    property_data.drop('pooltypeid10', axis=1, inplace=True)\n    \n    return property_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fireplace\n* fireplaceflag - Ngôi nhà có lò sưởi. Giá trị \"True\" hoặc \"NaN\"\n    * Thể thay \"True\" bằng \"1\" và \"NaN\" bằng \"0\".\n    * với nhà có số lò sưởi > 1 thay thế fireplaceflag bằng 1\n* fireplacecnt - Số lò sưởi. update giá trị \"NaN\" bằng \"0\"\n    * với nhà có fireplaceflag bằng True thay thế bằng giá trị trung bình số lò sưởi là 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# số lò sưởi trung bình \nprint(prop2016_df['fireplacecnt'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fireplace_process(property_data):\n    # fireplaceflag là True và fireplacecnt NaN, ta sẽ thay thế bằng trung bình các fireplace.\n    property_data.loc[(property_data['fireplaceflag'] == True) & (property_data['fireplacecnt'].isnull()), ['fireplacecnt']] = 1\n    # If \"fireplacecnt\" is 1 or larger \"fireplaceflag\" is \"NaN\", we will set \"fireplaceflag\" to \"True\".\n    property_data.loc[(property_data['fireplacecnt'] >= 1.0) & (property_data['fireplaceflag'].isnull()), ['fireplaceflag']] = True\n    \n    # Convert \"NaN\" thành 0\n    property_data.fireplaceflag.fillna(0,inplace = True)\n    # Convert \"True\" thành 1\n    property_data.fireplaceflag.replace(to_replace = True, value = 1,inplace = True)\n    \n    # If 'fireplacecnt' is \"NaN\", replace with \"0\"\n    property_data.fireplacecnt.fillna(0,inplace = True)\n    \n    return property_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Garage\n* \"garagecarcnt\" - Có bao nhiêu gara trong ngôi nhà, update giá trị \"NaN\" bằng \"0\"\n* \"garagetotalsqft\" - diện tích gara, nếu ngồi nhà không có gara ta có thể thay thế \"NaN\" bằng \"0\" "},{"metadata":{"trusted":true},"cell_type":"code","source":"def garage_process(property_data):\n    property_data.garagecarcnt.fillna(0,inplace = True)\n    property_data.garagetotalsqft.fillna(0,inplace = True)\n    return property_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Taxs value\n* \"taxdelinquencyflag\" - Tax Delinquency (nợ thuế) thuế tài sản quá hạn từ năm 2015, giá trị là 'NaN' hoặc 'Y'\n* \"landtaxvaluedollarcnt\" - Giá trị đánh giá của diện tích đất của thửa đất\n    * Thay \"NaN\" bằng 0\n* \"structuretaxvaluedollarcnt\" - Giá trị đánh giá của cấu trúc xây dựng trên lô đất\n    * Thay \"NaN\" bằng 0\n* \"taxvaluedollarcnt\" -  Tổng giá trị thuế đánh giá trên lô đất\n    * Thay \"NaN\" bằng giá trị trung bình \n* \"taxamount\" - Tổng thuế tài sản trong năm đánh giá đó\n    * phần thông tin thừa phần feature engineering sẽ loại bỏ\n* \"regionidcity\" - Mã thành phố tại vị trí đất\n    * Thông tin thừa nên loại bỏ\n* \"yearbuilt\" - Năm nhà được xây dựng\n    * Thay \"NaN\" bằng giá trị phổ biến"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tax_process(property_data):\n    # Replace \"NaN\" with \"0\"\n    property_data.taxdelinquencyflag.fillna(0,inplace = True)\n    # Change \"Y\" to \"1\"\n    property_data.taxdelinquencyflag.replace(to_replace = 'Y', value = 1,inplace = True)\n    \n    \n    property_data.landtaxvaluedollarcnt.fillna(0,inplace = True)\n    property_data.structuretaxvaluedollarcnt.fillna(0,inplace = True)\n\n    property_data['taxvaluedollarcnt'].fillna((property_data['taxvaluedollarcnt'].mean()), inplace=True)\n    \n    # Drop \"regionidcity\"\n    property_data.drop('regionidcity', axis=1, inplace=True)\n    # Fill in \"NaN\" \"yearbuilt\" with most common\n    yearbuilt = property_data['yearbuilt'].value_counts().idxmax()\n    property_data['yearbuilt'] = property_data['yearbuilt'].fillna(yearbuilt)\n    \n    return property_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Diện tích\n* \"finishedsquarefeet6\" - Khu vực dang dở\n    * drop do ít xuất hiện và nếu có cũng bằng calculatedfinishedsquarefeet\n* \"finishedsquarefeet12\" - Khu vực sinh hoạt đã hoàn thành\n    * drop do missing nhiều\n* \"finishedsquarefeet15\" - Tổng diện tích\n    * xuất hiện 6.4% ít và đa số đều bằng calculatedfinishedsquarefeet nên fill \"NaN\" bằng giá trị calculatedfinishedsquarefeet  \n* \"finishedsquarefeet50\" - Kích thước khu vực sinh hoạt đã hoàn thành tại tầng 1 (lối vào)\n    * Nếu numberofstories=1 thay \"NaN\" bằng giá trị calculatedfinishedsquarefeet\n    * Thay \"NaN\" còn lại bằng giá trị trung bình\n* \"finishedfloor1squarefeet\" - Kích thước khu vực sinh hoạt đã hoàn thành tại tầng 1 (lối vào)\n    * drop do lặp thông tin với finishedsquarefeet50\n* \"calculatedfinishedsquarefeet\" - Tổng khu vực sinh hoạt đã hoàn thành (đơn vị feet vuông)\n    * thay \"NaN\" bằng giá trị trung bình\n* \"numberofstories\" - số tầng\n    * thay \"NaN\" bằng giá trị phổ biến là 1 tầng"},{"metadata":{"trusted":true},"cell_type":"code","source":"squarefeet = prop2016_df[ prop2016_df['finishedsquarefeet15'].notnull() & prop2016_df['finishedsquarefeet50'].notnull() & prop2016_df['lotsizesquarefeet'].notnull()]\nsquarefeet[['calculatedfinishedsquarefeet','finishedsquarefeet6','finishedsquarefeet12','finishedsquarefeet15','finishedsquarefeet50','numberofstories','lotsizesquarefeet']].sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def squarefeet_process(property_data):\n    \n    # Drop \"finishedsquarefeet6\"\n    property_data.drop('finishedsquarefeet6', axis=1, inplace=True)\n    # Drop \"finishedsquarefeet12\"\n    property_data.drop('finishedsquarefeet12', axis=1, inplace=True)\n    # Drop \"finishedfloor1squarefeet\"\n    property_data.drop('finishedfloor1squarefeet', axis=1, inplace=True)\n\n    # Replace \"NaN\" \"calculatedfinishedsquarefeet\" values with mean.\n    property_data['calculatedfinishedsquarefeet'].fillna((property_data['calculatedfinishedsquarefeet'].mean()), inplace=True)\n\n    # If \"numberofstories\" is equal to \"1\", then we can replace the \"NaN\"s with the \"calculatedfinishedsquarefeet\" value. Fill in the rest with the average values.\n    property_data.loc[property_data['numberofstories'] == 1.0,'finishedsquarefeet50'] = property_data['calculatedfinishedsquarefeet']\n    property_data['finishedsquarefeet50'].fillna((property_data['finishedsquarefeet50'].mean()), inplace=True)\n\n    # Replace \"NaN\" \"finishedsquarefeet15\" values with calculatedfinishedsquarefeet.\n    property_data.loc[property_data['finishedsquarefeet15'].isnull(),'finishedsquarefeet15'] = property_data['calculatedfinishedsquarefeet']\n    # Replace rest valule \"NaN\" \"finishedsquarefeet15\" values with mean.\n    property_data['finishedsquarefeet15'].fillna((property_data['finishedsquarefeet15'].mean()), inplace=True)\n    # change numberofstories with common value \n    property_data.numberofstories.fillna(1,inplace = True)\n    \n    return property_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## bathroom features\n* threequarterbathnbr - Số phòng tắm trong nhà có 3/4 (vòi sen + bồn rửa + nhà vệ sinh)\n* fullbathcnt - Số lượng phòng tắm đầy đủ (sink, shower + bathtub và  toilet) trong nhà\n* calculatedbathnbr - Số phòng tắm (bao gồm cả fractional bathroom)\n---------------\n**relation**\n* calculatedbathnbr bao gồm cả threequarterbathnbr và fullbathcnt\n    * drop threequarterbathnbr và fullbathcnt và thay thế missing value bằng số lượng phòng tắm phổ biến"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,4))\nsns.countplot(x=\"calculatedbathnbr\", data=prop2016_df)\nplt.ylabel('Count', fontsize=8)\nplt.xlabel('Bathroom', fontsize=12)\nplt.title('Frequency of bathroom count', fontsize=15)\nplt.show()\n\n# look at some data example \nbathrooms = prop2016_df[prop2016_df['fullbathcnt'].notnull() & prop2016_df['threequarterbathnbr'].notnull() & prop2016_df['calculatedbathnbr'].notnull()]\nbathrooms[['fullbathcnt','threequarterbathnbr','calculatedbathnbr']].sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bathroom_process(property_data):\n    # Drop \"threequarterbathnbr\"\n    property_data.drop('threequarterbathnbr', axis=1, inplace=True)\n    # Drop \"fullbathcnt\"\n    property_data.drop('fullbathcnt', axis=1, inplace=True)\n\n    # Fill in \"NaN\" \"calculatedbathnbr\" with most common\n    bathroommode = property_data['calculatedbathnbr'].value_counts().idxmax()\n    property_data['calculatedbathnbr'] = property_data['calculatedbathnbr'].fillna(bathroommode)\n    return property_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # identify levels of missingness\n# missing = prop2016_df.isnull().sum().sort_values(ascending = False)\n# vartypes = prop2016_df.dtypes\n# missingpercent = (prop2016_df.isnull().sum()/prop2016_df.shape[0]).sort_values(ascending=False)\n# pd.concat([vartypes, missing, missingpercent], axis = 1,\n#           keys =['var type', 'missing n', 'percent']\n#         ).sort_values(by = 'missing n', ascending = False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Phần còn lại\n* => Các thuộc tính category missing 99% nên loại bỏ thuộc tính\n* \"taxdelinquencyyear\" - Năm mà chưa nộp thuế\n* \"basementsqft\" - Khu vực sinh hoạt đã hoàn thành hoặc một phần ở tầng hầm\n* \"storytypeid\" - Mã mô tả tất cả loại nhà như ngôi nhà nhiều tầng\n* \"architecturalstyletypeid\" - Phong cách kiến trúc của ngôi nhà\n* \"typeconstructiontypeid\" - Loại vật liệu được sử dụng để xây nhà\n* \"finishedsquarefeet13\" - Chu vi khu vực sinh hoạt đã hoàn thành. Hầu như missing nên drop category\n* \"buildingclasstypeid\" - Id loại khung của tòa nhà. Không mang lại nhiều thông tin và missing nhiều nên drop\n------\n* \"yardbuildingsqft17\" - Diện tích sân bên trong, thay thế NaN bằng \"0\"\n* \"yardbuildingsqft26\" - Diện tích nhà kho/sân sau, thay thế NaN bằng \"0\"\n* \"decktypeid\" - Loại sàn chỉ có 2 giá trị \"66.0\" hoặc \"NaN\", nên sẽ thay 66 bằng 1 và NaN bằng 0\n* \"airconditioningtypeid\" - loại hệ thống làm mát. trong dic None gán là 5, nên thay \"NaN\" bằng 5\n* \"heatingorsystemtypeid\" - Loại hệ thống sưởi trong nhà. thay \"Nan\" bằng 13 cho \"None\"\n* \"buildingqualitytypeid\" - đánh giá chung về tình trạng của tòa nhà, từ tốt (giá trị nhỏ) đến cao (giá trị to)\n    * Thay bằng giá trị common\n* \"unitcnt\" - Số khối xây dựng được tích hợp vào thành nhà. \n    * Thay \"NaN\" gia trị phổ biến\n* \"lotsizesquarefeet\" - Diện tích lô đất tính bằng feet vuông\n    * Thay \"NaN\" bằng giá trị trung bình\n* \"regionidneighborhood\" - id hàng xóm. cần map để xác định hàng xóm và alongitude & latitude về cơ bản cung cấp thông tin này\n    * drop cột này\n* \"regionidcounty\" - id quận của lô đất\n    * drop cột này\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"def rest_process(property_data):\n    # Drop \"taxdelinquencyyear\"\n    property_data.drop('taxdelinquencyyear', axis=1, inplace=True)\n    # Drop 'basementsqft'\n    property_data.drop('basementsqft', axis=1, inplace = True)\n    # Drop \"storytypeid\"\n    property_data.drop('storytypeid', axis=1, inplace=True)\n    # Drop \"architecturalstyletypeid\"\n    property_data.drop('architecturalstyletypeid', axis=1, inplace=True)\n    # Drop \"typeconstructiontypeid\" and \"finishedsquarefeet13\"\n    property_data.drop('typeconstructiontypeid', axis=1, inplace=True)\n    property_data.drop('finishedsquarefeet13', axis=1, inplace=True)\n    # Drop \"buildingclasstypeid\"\n    property_data.drop('buildingclasstypeid', axis=1, inplace=True)\n    ##------------------------------------------------------------\n    # Replace 'yardbuildingsqft17' \"NaN\"s with \"0\".\n    property_data.yardbuildingsqft17.fillna(0,inplace = True)\n    # Replace 'yardbuildingsqft26' \"NaN\"s with \"0\".\n    property_data.yardbuildingsqft26.fillna(0,inplace = True)\n    # Change \"decktypeid\" \"Nan\"s to \"0\"\n    property_data.decktypeid.fillna(0,inplace = True)\n    # Convert \"decktypeid\" \"66.0\" to \"1\"\n    property_data.decktypeid.replace(to_replace = 66.0, value = 1,inplace = True)\n    # change \"airconditioningtypeid\" NaN to \"5\"\n    property_data.airconditioningtypeid.fillna(5,inplace = True)\n    # change \"heatingorsystemtypeid\" NaN to \"13\"\n    property_data.heatingorsystemtypeid.fillna(13,inplace = True)\n\n    # Fill in \"NaN\" \"buildingqualitytypeid\" bằng giá trị phổ biến\n    buildingqual = property_data['buildingqualitytypeid'].value_counts().idxmax()\n    property_data['buildingqualitytypeid'] = property_data['buildingqualitytypeid'].fillna(buildingqual)\n    # Fill in \"NaN\" \"unitcnt\" bằng giá trị phổ biến\n    unitcommon = property_data['unitcnt'].value_counts().idxmax()\n    property_data['unitcnt'] = property_data['unitcnt'].fillna(unitcommon)\n    \n\n    property_data['lotsizesquarefeet'].fillna((property_data['lotsizesquarefeet'].mean()), inplace=True)\n\n    # Drop \"regionidneighborhood\"\n    property_data.drop('regionidneighborhood', axis=1, inplace=True)\n    # Drop 'regionidcounty'\n    property_data.drop('regionidcounty', axis=1, inplace=True)\n    \n    return property_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## rawcensustractandblock & censustractandblock\n* \"rawcensustractandblock = censustractandblock\" - Kết hợp điều tra dân số và ID khối - cũng như phân công nhóm theo phần mở rộng\n    * trùng lặp nên sẽ loại bỏ feature censustractandblock\n-------\n## Fill rest NaN with most common value\n* regionidzip, fips, propertylandusetypeid, latitude, longitude, rawcensustractandblock, assessmentyear, bedroomcnt, bathroom, roomcnt, propertycountylandusecode, propertyzoningdesc (mô tả được phép sử dụng đất cho tài sản đó) bằng giá trị phổ biến"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillcommonvalue(property_data):    \n    # Drop \"censustractandblock\"\n    property_data.drop('censustractandblock', axis=1, inplace=True)\n    ##-------------------------------------------------------------\n    # Fill in \"regionidzip\" bằng giá trị phổ biến\n    regionidzip = property_data['regionidzip'].value_counts().idxmax()\n    property_data['regionidzip'] = property_data['regionidzip'].fillna(regionidzip)\n\n    # Fill in \"fips\" bằng giá trị phổ biến\n    fips = property_data['fips'].value_counts().idxmax()\n    property_data['fips'] = property_data['fips'].fillna(fips)\n\n    # Fill in \"propertylandusetypeid\" bằng giá trị phổ biến\n    propertylandusetypeid = property_data['propertylandusetypeid'].value_counts().idxmax()\n    property_data['propertylandusetypeid'] = property_data['propertylandusetypeid'].fillna(propertylandusetypeid)\n\n    # Fill in \"latitude\"  bằng giá trị phổ biến\n    latitude = property_data['latitude'].value_counts().idxmax()\n    property_data['latitude'] = property_data['latitude'].fillna(latitude)\n\n    # Fill in \"longitude\" bằng giá trị phổ biến\n    longitude = property_data['longitude'].value_counts().idxmax()\n    property_data['longitude'] = property_data['longitude'].fillna(longitude)\n    \n    # Normal value\n    property_data[['latitude', 'longitude']] /= 1e6\n    property_data['rawcensustractandblock'] /= 1e6\n\n    # Fill in \"rawcensustractandblock\" bằng giá trị phổ biến\n    rawcensustractandblock = property_data['rawcensustractandblock'].value_counts().idxmax()\n    property_data['rawcensustractandblock'] = property_data['rawcensustractandblock'].fillna(rawcensustractandblock)\n\n    # Fill in \"assessmentyear\" bằng giá trị phổ biến\n    assessmentyear = property_data['assessmentyear'].value_counts().idxmax()\n    property_data['assessmentyear'] = property_data['assessmentyear'].fillna(assessmentyear)\n\n    # Fill in \"bedroomcnt\" bằng giá trị phổ biến\n    bedroomcnt = property_data['bedroomcnt'].value_counts().idxmax()\n    property_data['bedroomcnt'] = property_data['bedroomcnt'].fillna(bedroomcnt)\n\n    # Fill in \"bathroomcnt\" bằng giá trị phổ biến\n    bathroomcnt = property_data['bathroomcnt'].value_counts().idxmax()\n    property_data['bathroomcnt'] = property_data['bathroomcnt'].fillna(bathroomcnt)\n\n    # Fill in \"roomcnt\" bằng giá trị phổ biến\n    roomcnt = property_data['roomcnt'].value_counts().idxmax()\n    property_data['roomcnt'] = property_data['roomcnt'].fillna(roomcnt)\n    \n    # Fill in \"propertycountylandusecode\" bằng giá trị phổ biến\n    propertycountylandusecode = property_data['propertycountylandusecode'].value_counts().idxmax()\n    property_data['propertycountylandusecode'] = property_data['propertycountylandusecode'].fillna(propertycountylandusecode)\n    \n    # Fill in \"NaN\" \"propertyzoningdesc\" with most common\n    propertyzoningdesc = property_data['propertyzoningdesc'].value_counts().idxmax()\n    property_data['propertyzoningdesc'] = property_data['propertyzoningdesc'].fillna(propertyzoningdesc)\n    \n    return property_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce 58 to 42 columns \nprop2016_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_transactiondate(train_with_months):\n    train_with_months['sale_month'] = train_with_months['transactiondate'].apply(lambda x: (x.to_pydatetime()).month)\n    train_with_months['sale_day'] = train_with_months['transactiondate'].apply(lambda x: (x.to_pydatetime()).day)\n    train_with_months['sale_year'] = train_with_months['transactiondate'].apply(lambda x: (x.to_pydatetime()).year)\n    train_with_months.drop(['transactiondate'],axis=1,inplace=True)\n    return train_with_months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(property_data):\n    property_data = poolhottubor_process(property_data)\n    property_data = fireplace_process(property_data)\n    property_data = garage_process(property_data)\n    property_data = tax_process(property_data)\n    property_data = squarefeet_process(property_data)\n    property_data = bathroom_process(property_data)\n    \n    property_data = rest_process(property_data)\n    property_data = fillcommonvalue(property_data)\n    return property_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2016 = preprocess_data(prop2016_df)\nprop2017 = preprocess_data(prop2017_df)\n\nprint ('prop 2016 data has {0} rows and {1} columns'.format(prop2016.shape[0],prop2016.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# identify levels of missingness\nmissing = prop2016.isnull().sum().sort_values(ascending = False)\nvartypes = prop2016.dtypes\nmissingpercent = (prop2016.isnull().sum()/prop2016.shape[0]).sort_values(ascending=False)\npd.concat([vartypes, missing, missingpercent], axis = 1,\n          keys =['var type', 'missing n', 'percent']\n        ).sort_values(by = 'missing n', ascending = False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in prop2016.columns:\n    if prop2016[c].dtype == 'object':\n        print(c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Chuyển dữ liệu từ chữ thành số"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncountylandusecode = LabelEncoder()\nprop2016[\"propertycountylandusecode\"] = countylandusecode.fit_transform(prop2016[\"propertycountylandusecode\"])\nprop2017[\"propertycountylandusecode\"] = countylandusecode.fit_transform(prop2017[\"propertycountylandusecode\"])\n\nzoningdesc = LabelEncoder()\nprop2016[\"propertyzoningdesc\"] = zoningdesc.fit_transform(prop2016[\"propertyzoningdesc\"])\nprop2017[\"propertyzoningdesc\"] = zoningdesc.fit_transform(prop2017[\"propertyzoningdesc\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(prop2016_df['propertyzoningdesc'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2016_df['parcelid']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chuẩn hóa dữ liệu\nChuẩn hoá sẽ giúp cân bằng mức độ ảnh hưởng đến nhãn của các đặc trưng\n\n\nCông thức đơn giản: z = (x - u) / s\n\ntrong đó u is trung bình các đặc trưng and s độ lệch chuẩn.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nprop2016 = scaler.fit_transform(prop2016.loc[:, 'airconditioningtypeid':])\nprop2016 = pd.DataFrame(prop2016, columns=prop2016_df.loc[:, 'airconditioningtypeid':].columns)\nprop2016['parcelid'] = prop2016_df['parcelid']\nprop2017 = scaler.fit_transform(prop2017.loc[:, 'airconditioningtypeid':])\nprop2017 = pd.DataFrame(prop2017, columns=prop2017_df.loc[:, 'airconditioningtypeid':].columns)\nprop2017['parcelid'] = prop2017_df['parcelid']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2016.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n\n* Bổ sung \"taxpercentage\" - taxamount/taxvaluedollarcnt thay cho taxamount"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(property_data):\n    property_data['avg_garage_size'] = property_data['garagetotalsqft'] / property_data['garagecarcnt']\n    property_data['avg_garage_size'].fillna(0, inplace=True)\n    \n    # Rotated Coordinates\n    property_data['location_1'] = property_data['latitude'] + property_data['longitude']\n    property_data['location_2'] = property_data['latitude'] - property_data['longitude']\n    property_data['location_3'] = property_data['latitude'] + 0.5 * property_data['longitude']\n    property_data['location_4'] = property_data['latitude'] - 0.5 * property_data['longitude']\n\n    property_data['taxpercentage'] = property_data['taxamount'] / property_data['taxvaluedollarcnt']\n    property_data['taxpercentage'].fillna((property_data['taxpercentage'].mean()), inplace=True)\n    # Drop \"taxamount\"\n    property_data.drop('taxamount', axis=1, inplace=True)\n\n    # Thêm derived room_cnt feature bằng cách cộng bathroom_cnt và bedroom_cnt\n    property_data['derived_room_cnt'] = property_data['bedroomcnt'] + property_data['bathroomcnt']\n    \n    return property_data\n\nprop2016 = feature_engineering(prop2016)\nprop2017 = feature_engineering(prop2017)\nprint ('prop 2016 data has {0} rows and {1} columns'.format(prop2016.shape[0],prop2016.shape[1]))\nprint ('prop 2017 data has {0} rows and {1} columns'.format(prop2017.shape[0],prop2017.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import featuretools as ft\n# # creating and entity set 'es'\n# es = ft.EntitySet(id = 'zillow')\n\n# # adding a dataframe \n# es.entity_from_dataframe(entity_id = 'properties', dataframe = prop2016, index = 'parcelid')\n# # create entity\n#es.normalize_entity(base_entity_id = 'properties', new_entity_id='land_zone', index = 'propertyzoningdesc', additional_variables = ['propertycountylandusecode', 'propertylandusetypeid'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_matrix, feature_names = ft.dfs(entityset=es, \n#                                       target_entity = 'properties', \n#                                       max_depth = 2, \n#                                       verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_2016 = convert_transactiondate(train2016_df.copy()).merge(prop2016, how='left', on='parcelid')\ntrain_2017 = convert_transactiondate(train2017_df.copy()).merge(prop2017, how='left', on='parcelid')\ntrain = pd.concat([train_2016, train_2017], axis=0, ignore_index=True)\n\nprint ('prop 2016 data has {0} rows and {1} columns'.format(prop2016.shape[0],prop2016.shape[1]))\nprint ('train 2016 data has {0} rows and {1} columns'.format(train_2016.shape[0],train_2016.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kiểm tra kiểu dữ liệu "},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype_df = prop2016.dtypes.reset_index()\ndtype_df.columns = ['Count', 'Column type']\ndtype_df.groupby('Column type').aggregate('count').reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# export prop after data processing\nprop2016.to_csv(\"properties_2016_proc.csv.gz\", index=False, compression='gzip')\nprop2017.to_csv(\"properties_2017_proc.csv.gz\", index=False, compression='gzip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Univariate analysis**\n* vì có nhiều biến nên có thể có mối quan hệ giữa các biến thuộc tính và 'logerror' mục tiêu \n    * không có tương quan mạnh nào của các biến và logerror"},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{},"cell_type":"markdown","source":"## Implement CatBoot\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in train.columns:\n    if train[c].dtype != 'object' and c in catvars:\n        print(\"{0} have type: {1}\".format(c,train[c].dtype ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to change use .astype() \n# CatBoost requires all the categorical variables to be in the string format\ndef float2string(train):\n    train['airconditioningtypeid'] = train.airconditioningtypeid.astype(str)\n    train['buildingqualitytypeid'] = train.buildingqualitytypeid.astype(str)\n    train['decktypeid'] = train.decktypeid.astype(str)\n    train['fips'] = train.fips.astype(str)\n    train['hashottuborspa'] = train.fips.astype(str)\n    train['heatingorsystemtypeid'] = train.heatingorsystemtypeid.astype(str)\n    train['latitude'] = train.latitude.astype(str)\n    train['longitude'] = train.longitude.astype(str)\n    train['propertycountylandusecode'] = train.fips.astype(str)\n    train['propertylandusetypeid'] = train.fips.astype(str)\n    train['propertyzoningdesc'] = train.fips.astype(str)\n    train['regionidzip'] = train.regionidzip.astype(str)\n    train['yearbuilt'] = train.yearbuilt.astype(str)\n    train['fireplaceflag'] = train.fips.astype(str)\n    train['assessmentyear'] = train.assessmentyear.astype(str)\n    train['taxdelinquencyflag'] = train.fips.astype(str)\n    \n    return train\ntrain_cat = float2string(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2016 = float2string(prop2016)\nprop2017 = float2string(prop2017)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboot_features = train_cat.drop(['parcelid', 'logerror', 'sale_month', 'sale_day', 'sale_year'], axis=1)\n\nprint(\"Number of features for CastBoot: {}\".format(len(catboot_features.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare training and cross-validation data\ncatboot_label = train_cat.logerror.astype(np.float32)\nprint(catboot_label.head())\n\n# Transform to Numpy matrices\ncatboot_X = catboot_features.values\ncatboot_y = catboot_label.values\n\n# Perform shuffled train/test split\nnp.random.seed(42)\nrandom.seed(10)\nX_train, X_val, y_train, y_val = train_test_split(catboot_X, catboot_y, test_size=0.2)\n\n# Remove outlier examples from X_train and y_train; Keep them in X_val and y_val for proper cross-validation\noutlier_threshold = 0.4\nmask = (abs(y_train) <= outlier_threshold)\nX_train = X_train[mask, :]\ny_train = y_train[mask]\n\nprint(\"X_train shape: {}\".format(X_train.shape))\nprint(\"y_train shape: {}\".format(y_train.shape))\nprint(\"X_val shape: {}\".format(X_val.shape))\nprint(\"y_val shape: {}\".format(y_val.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del prop2016_df, prop2017_df, catboot_X, catboot_y\ngc.collect()\nprint('Memory usage reduction...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = [s for s in catboot_features.columns]\n\ncategorical_indices = []\nfor i, n in enumerate(catboot_features.columns):\n    if n in catvars:\n        categorical_indices.append(i)\nprint(categorical_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CatBoost parameters after tuned hyperparameter\nparams = {}\nparams['loss_function'] = 'MAE'\nparams['eval_metric'] = 'MAE'\nparams['nan_mode'] = 'Min'  # Method to handle NaN (set NaN to either Min or Max)\nparams['random_seed'] = 0\n\nparams['iterations'] = 1000  # default 1000, use early stopping during training\nparams['learning_rate'] = 0.03  # default 0.03\nparams['max_depth'] = 10  # default 6 (must be <= 16, 6 to 10 is recommended)\nparams['l2_leaf_reg'] = 9  # default 3 (used for leaf value calculation, try different values)\n\nparams['border_count'] = 254  # default 254 (alias max_bin, suggested to keep at default for best quality)\nparams['bagging_temperature'] = 1  # default 1 (higher value -> more aggressive bagging, try different values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom catboost import CatBoostRegressor, Pool\n# Train CatBoost Regressor with cross-validated early-stopping\nval_pool = Pool(X_val, y_val, cat_features=categorical_indices)\n\nnp.random.seed(42)\nrandom.seed(36)\nmodel = CatBoostRegressor(**params)\nmodel.fit(X_train, y_train,\n          cat_features=categorical_indices,\n          use_best_model=True, eval_set=val_pool, early_stopping_rounds=30,\n          logging_level='Silent', plot=True)\n\n# Evaluate model performance\nprint(\"Train score: {}\".format(abs(model.predict(X_train) - y_train).mean() * 100))\nprint(\"Val score: {}\".format(abs(model.predict(X_val) - y_val).mean() * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_and_export(models, features_2016, features_2017, file_name):\n    # Construct DataFrame for prediction results\n    submission_2016 = pd.DataFrame()\n    submission_2017 = pd.DataFrame()\n    submission_2016['ParcelId'] = features_2016.parcelid\n    submission_2017['ParcelId'] = features_2017.parcelid\n    \n    test_features_2016 = features_2016.drop(['parcelid'], axis=1)\n    test_features_2017 = features_2017.drop(['parcelid'], axis=1)\n    \n    pred_2016, pred_2017 = [], []\n    for i, model in enumerate(models):\n        print(\"Start model {} (2016)\".format(i))\n        pred_2016.append(model.predict(test_features_2016))\n        print(\"Start model {} (2017)\".format(i))\n        pred_2017.append(model.predict(test_features_2017))\n    \n    # Take average across all models\n    mean_pred_2016 = np.mean(pred_2016, axis=0)\n    mean_pred_2017 = np.mean(pred_2017, axis=0)\n    \n    submission_2016['201610'] = [float(format(x, '.4f')) for x in mean_pred_2016]\n    submission_2016['201611'] = submission_2016['201610']\n    submission_2016['201612'] = submission_2016['201610']\n\n    submission_2017['201710'] = [float(format(x, '.4f')) for x in mean_pred_2017]\n    submission_2017['201711'] = submission_2017['201710']\n    submission_2017['201712'] = submission_2017['201710']\n    \n    submission = submission_2016.merge(how='inner', right=submission_2017, on='ParcelId')\n    \n    print(\"Length of submission DataFrame: {}\".format(len(submission)))\n    print(\"Submission header:\")\n    print(submission.head())\n    \n    submission.to_csv(file_name, index=False, compression='gzip')\n    return submission, pred_2016, pred_2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop2016.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfile_name = 'v23_EDA_catboost_single.csv.gz'\nsubmission, pred_2016, pred_2017 = predict_and_export([model], prop2016, prop2017, file_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model, submission, pred_2016, pred_2017\ngc.collect()\nprint('Memory usage reduction…')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble Training & Prediction catboot"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nbags = 3\nmodels = []\nfor i in range(bags):\n    print(\"Start training model {}\".format(i))\n    params['random_seed'] = i\n    np.random.seed(42)\n    random.seed(36)\n    model = CatBoostRegressor(**params)\n    model.fit(X_train, y_train, cat_features=categorical_indices, verbose=False)\n    models.append(model)\n    \n# Sanity check (make sure scores on a small portion of the dataset are reasonable)\nfor i, model in enumerate(models):\n    print(\"model {}: {}\".format(i, abs(model.predict(X_val) - y_val).mean() * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_name = 'v23_EDA_catboost_ensemble_x3.csv.gz'\nsubmission, pred_2016, pred_2017 = predict_and_export(models, prop2016, prop2017, file_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implement XGBoot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# train_y = train['logerror'].values\n# cat_cols = [\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\n# train_df = train.drop(['parcelid', 'logerror']+cat_cols, axis=1)\n# feat_names = train_df.columns.values\n\n# from sklearn import ensemble\n# train_df_new=train_df.fillna(train_df.mean())\n# model = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30, max_features=0.3, n_jobs=-1, random_state=0)\n# model.fit(train_df_new, train_y)\n\n# ## plot the importance\n# importances = model.feature_importances_\n# std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n# indices = np.argsort(importances)[::-1][:20]\n\n# plt.figure(figsize=(12,12))\n# plt.title(\"Feature importances\")\n# plt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n# plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\n# plt.xlim([-1, len(indices)])\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import xgboost as xgb\n# xgb_params = {\n#     'eta': 0.05,\n#     'max_depth': 8,\n#     'subsample': 0.7,\n#     'colsample_bytree': 0.7,\n#     'objective': 'reg:linear',\n#     'silent': 1,\n#     'seed' : 0\n# }\n# dtrain = xgb.DMatrix(train_df, train_y, feature_names=train_df.columns.values)\n# model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)\n\n# # plot the important features #\n# fig, ax = plt.subplots(figsize=(12,18))\n# xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n# plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}