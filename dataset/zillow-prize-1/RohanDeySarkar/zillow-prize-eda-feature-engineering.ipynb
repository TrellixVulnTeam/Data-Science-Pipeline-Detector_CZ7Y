{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"../input/zillow-prize-1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/zillow-prize-1/train_2017.csv', parse_dates=[\"transactiondate\"])\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.logerror.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index')\nplt.ylabel('logerror')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identify and replace the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_limit = np.percentile(train_df.logerror.values, 99)\nlower_limit = np.percentile(train_df.logerror.values, 1)\nupper_limit, lower_limit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace the outlier vals with upper and lower limit vals"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['logerror'] > upper_limit, 'logerror'] = upper_limit\ntrain_df.loc[train_df['logerror'] < lower_limit, 'logerror'] = lower_limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index')\nplt.ylabel('logerror')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.distplot(train_df.logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normal distribution obtained."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['transaction_month'] = train_df['transactiondate'].dt.month\n\nindex_of_months = train_df['transaction_month'].value_counts().index\nunique_months_vals = train_df['transaction_month'].value_counts().values\n\nplt.figure(figsize=(12, 6))\nsns.barplot(index_of_months, unique_months_vals, alpha=0.8, color=color[2])\nplt.xlabel('Months of transaction')\nplt.ylabel('Number of Transactions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = train_df['parcelid'].value_counts().reset_index()\ntemp_df['parcelid'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After counting appearance of each parcel id.\nIt is seen that most parcelid appear only once in the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"prop_df = pd.read_csv(\"../input/zillow-prize-1/properties_2017.csv\")\nprop_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop_df.isnull().sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df = prop_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\n\nmissing_df = missing_df.ix[missing_df['missing_count'] > 0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nfig, ax = plt.subplots(figsize=(12, 18))\nrects = ax.barh(ind, missing_df.missing_count.values)\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nsns.jointplot(x = prop_df.latitude.values, y = prop_df.longitude.values, size=10)\nplt.ylabel('Longitude', fontsize=12)\nplt.xlabel('Latitude', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(train_df, prop_df, on='parcelid', how='left')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 65\n\ndtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all are float variables with few object (categorical) variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype_df.groupby(\"Column Type\").count().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.fillna(0)\n\nx_cols = [col for col in train_df.columns if col not in ['logerror'] if train_df[col].dtype == 'float64']\n\nlabels = []\nvalues = []\n\n# check corr of each col wrt 'logerror' col\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(train_df[col].values, train_df.logerror.values)[0,1])\n\ncorr_df = pd.DataFrame({'col_labels': labels, 'corr_values': values})\ncorr_df = corr_df.sort_values(by='corr_values')\n\nind = np.arange(len(labels))\nfig, ax = plt.subplots(figsize=(12,40))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='r')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are few variables at the top of this graph without any correlation values."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_zero_cols = ['assessmentyear', 'storytypeid', 'pooltypeid2', 'pooltypeid7', 'pooltypeid10', 'poolcnt', 'decktypeid', 'buildingclasstypeid']\n\nfor col in corr_zero_cols:\n    print(col, train_df[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us take the variables with high correlation values "},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df.loc[(corr_df['corr_values'] > 0.02) | (corr_df['corr_values'] < -0.01), ('col_labels', 'corr_values')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df_sel = corr_df.ix[(corr_df['corr_values']>0.02) | (corr_df['corr_values'] < -0.01)]\ncorr_df_sel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now to find corr among cols which are highly correlated to 'logerror' col"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_use = corr_df_sel.col_labels.tolist()\n\ntemp_df = train_df[cols_to_use]\ncorrmat = temp_df.corr(method='spearman')\n\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(corrmat, vmax=1., square=True)\nplt.title(\"Important variables correlation map\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The important variables themselves are very highly correlated."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_use","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now visualizing each cols against 'logerror' col"},{"metadata":{"trusted":true},"cell_type":"code","source":"col = 'finishedsquarefeet12'\n\nupper_limit = np.percentile(train_df[col].values, 99.5)\nlower_limit = np.percentile(train_df[col].values, 0.5)\n\ntrain_df.loc[train_df[col] > upper_limit, col] = upper_limit\ntrain_df.loc[train_df[col] < lower_limit, col] = lower_limit\n\n# train_df[col].ix[train_df[col] > upper_limit] = upper_limit\n# train_df[col].ix[train_df[col] < lower_limit] = lower_limit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(col, 'logerror', data = train_df, size=10, color=color[2])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Finished Square Feet 12', fontsize=12)\nplt.title(\"Finished square feet 12 Vs Log error\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems the range of logerror narrows down with increase in finished square feet 12 variable. Probably larger houses are easy to predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"calculatedfinishedsquarefeet\"\n\nupper_limit = np.percentile(train_df[col].values, 99.5)\nlower_limit = np.percentile(train_df[col].values, 0.5)\n\ntrain_df.loc[train_df[col] > upper_limit, col] = upper_limit\ntrain_df.loc[train_df[col] < lower_limit, col] = lower_limit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(col, 'logerror', data = train_df, size=10, color=color[4])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Calculated finished square feet', fontsize=12)\nplt.title(\"Calculated finished square feet Vs Log error\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here as well the distribution is very similar to the previous one. No wonder the correlation between the two variables are also high."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['bathroomcnt'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"bathroomcnt\"\n\nplt.figure(figsize=(12,8))\nsns.countplot(x = col, data=train_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bathroom', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bathroom count\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.boxplot(x = col, y='logerror', data=train_df)\nplt.ylabel('Log error', fontsize=12)\nplt.xlabel('Bathroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"How log error changes with bathroom count?\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"bedroomcnt\"\n\nplt.figure(figsize=(12,8))\nsns.countplot(col, data = train_df)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bedroom count\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['bedroomcnt'] > 7, 'bedroomcnt'] = 7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"bedroomcnt\"\n\nplt.figure(figsize=(12,8))\nsns.countplot(col, data = train_df)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bedroom count\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.violinplot(x='bedroomcnt', y='logerror', data=train_df)\nplt.xlabel('Bedroom count', fontsize=12)\nplt.ylabel('Log Error', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"taxamount\"\n\nupper_limit = np.percentile(train_df[col].values, 99.5)\nlower_limit = np.percentile(train_df[col].values, 0.5)\n\ntrain_df.loc[train_df[col] > upper_limit, col] = upper_limit\ntrain_df.loc[train_df[col] < lower_limit, col] = lower_limit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(col, 'logerror', data = train_df, size=10, color=color[6])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Tax Amt', fontsize=12)\nplt.title(\"Tax Amount Vs Log error\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train_df['logerror'].values\ncat_cols = [\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\n\ntrain_df = train_df.drop(['parcelid', 'logerror', 'transactiondate', 'transaction_month'] + cat_cols, axis=1)\n\nfeat_names = train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\n\nmodel = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30, max_features=0.3, n_jobs=-1, random_state=0)\nmodel.fit(train_df, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.estimators_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'silent': 1,\n    'seed' : 0\n}\n\ndtrain = xgb.DMatrix(train_df, train_y, feature_names=train_df.columns.values)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}