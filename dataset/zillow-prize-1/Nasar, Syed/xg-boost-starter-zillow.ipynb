{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"cca10b72-7885-486a-0227-726cc277e243"},"source":"This notebook is to have an end to end process right from training the model to testing and predicting. Finally preparing a submission."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2890f1c-da65-6377-8d46-c7da27dfc2a0"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport gc\n\nprint('Loading data ...')\n\ntrain = pd.read_csv('../input/train_2016.csv')\nprop = pd.read_csv('../input/properties_2016.csv')\nsample = pd.read_csv('../input/sample_submission.csv')\n\nprint('Binding to float32')\n\nfor c, dtype in zip(prop.columns, prop.dtypes):\n\tif dtype == np.float64:\n\t\tprop[c] = prop[c].astype(np.float32)\n\nprint('Creating training set ...')\n\ndf_train = train.merge(prop, how='left', on='parcelid')\n\nx_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\ny_train = df_train['logerror'].values\nprint(x_train.shape, y_train.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a72bc1dd-cdd1-c571-820f-cf85e47eeb65"},"outputs":[],"source":"\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c] == True)\n\ndel df_train; gc.collect()\n\nsplit = 80000\nx_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n\nprint('Building DMatrix...')\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\n\ndel x_train, x_valid; gc.collect()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86a16e86-b63c-da74-12ee-b2e869288c59"},"outputs":[],"source":"\nprint('Training ...')\n\nparams = {}\nparams['eta'] = 0.02\nparams['objective'] = 'reg:linear'\nparams['eval_metric'] = 'mae'\nparams['max_depth'] = 4\nparams['silent'] = 1\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nclf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n\ndel d_train, d_valid"},{"cell_type":"markdown","metadata":{"_cell_guid":"1aa7999c-aa11-6415-4057-accfbb3b1d87"},"source":"A notebook showcasing the model development, training and testing it."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db105003-9d1f-5b32-1459-413a63c7d442"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32e88686-b43a-9664-eaf7-b214c9307904"},"outputs":[],"source":"print('Building test set ...')\n\nsample['parcelid'] = sample['ParcelId']\ndf_test = sample.merge(prop, on='parcelid', how='left')\n\ndel prop; gc.collect()\n\nx_test = df_test[train_columns]\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\n\ndel df_test, sample; gc.collect()\n\nd_test = xgb.DMatrix(x_test)\n\ndel x_test; gc.collect()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8012709f-85c0-6fa5-6092-90e6e280b000"},"outputs":[],"source":"print('Predicting on test ...')\n\np_test = clf.predict(d_test)\n\ndel d_test; gc.collect()\n\nsub = pd.read_csv('../input/sample_submission.csv')\nfor c in sub.columns[sub.columns != 'ParcelId']:\n    sub[c] = p_test\n\nprint('Writing csv ...')\nsub.to_csv('xgb_starter.csv', index=False, float_format='%.4f') # Thanks to @inversion"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb42eccd-abe2-69e4-e29f-6e05d8b63b5a"},"outputs":[],"source":"sub.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6398072-37e3-bef4-9a5d-21a83ab92c0b"},"outputs":[],"source":"!ls"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6763c85f-28fb-38aa-cfb3-972144598082"},"outputs":[],"source":"sub.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"775b5116-57c3-0514-cf6f-fa8e1daa1302"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}