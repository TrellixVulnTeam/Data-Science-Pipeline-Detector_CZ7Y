{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"출처 : https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"**Zillow:**\n\nZillow is an online real estate databse company founded in 2006\n\n**Zestimate:**\n\nZestimates are estimated home values based on 7.5 million statistical and machine learning models that analyze hunderes of data  points on each property. And, by continually imporoving the median margin of error\n\n**Objective**:\nBuilding a model to imporve the Zestimate residual error.\n\n보통 부동산 집값 예측이라고 하면, 집과 관련된 여러변수들로 모델을 구축하여 집값을 예측하는 것 같지만,\n이번 대회의 주제는 잔차 오차를 개선하기 위한 모델을 구축하는 것이 목표다.\n\n여기서 잔차는 에러 즉, **실제 부동산값 - 예측 부동산 값**을 의미\n\n ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(action='ignore')\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:02.544824Z","iopub.execute_input":"2021-08-14T01:40:02.545353Z","iopub.status.idle":"2021-08-14T01:40:03.583047Z","shell.execute_reply.started":"2021-08-14T01:40:02.545269Z","shell.execute_reply":"2021-08-14T01:40:03.582029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터 리스트 확인\nfrom subprocess import check_output\nprint(check_output(['ls', '../input/zillow-prize-1']).decode('utf8'))","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:03.584346Z","iopub.execute_input":"2021-08-14T01:40:03.584583Z","iopub.status.idle":"2021-08-14T01:40:03.602576Z","shell.execute_reply.started":"2021-08-14T01:40:03.584561Z","shell.execute_reply":"2021-08-14T01:40:03.601266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Train Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/zillow-prize-1/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:03.605108Z","iopub.execute_input":"2021-08-14T01:40:03.605389Z","iopub.status.idle":"2021-08-14T01:40:03.724758Z","shell.execute_reply.started":"2021-08-14T01:40:03.605361Z","shell.execute_reply":"2021-08-14T01:40:03.723782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:03.726148Z","iopub.execute_input":"2021-08-14T01:40:03.726413Z","iopub.status.idle":"2021-08-14T01:40:03.74577Z","shell.execute_reply.started":"2021-08-14T01:40:03.726386Z","shell.execute_reply":"2021-08-14T01:40:03.744701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-1. Logerror","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('logerror', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:03.746766Z","iopub.execute_input":"2021-08-14T01:40:03.747018Z","iopub.status.idle":"2021-08-14T01:40:04.158448Z","shell.execute_reply.started":"2021-08-14T01:40:03.746992Z","shell.execute_reply":"2021-08-14T01:40:04.157488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"양 끝에 이상치 발견 > remove and histogram 그리기\n\npercentile로 양 끝 백분위수 구한 뒤, 값을 대신 채워넣는 형식","metadata":{}},{"cell_type":"code","source":"ulimit = np.percentile(train_df.logerror.values, 99)\nllimit = np.percentile(train_df.logerror.values, 1)\ntrain_df['logerror'].loc[train_df['logerror']>ulimit] = ulimit\ntrain_df['logerror'].loc[train_df['logerror']<llimit] = llimit\n\nplt.figure(figsize=(12,8))\nsns.distplot(train_df.logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.show()\n\n# .ix > .loc","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:04.159604Z","iopub.execute_input":"2021-08-14T01:40:04.159894Z","iopub.status.idle":"2021-08-14T01:40:04.44402Z","shell.execute_reply.started":"2021-08-14T01:40:04.159866Z","shell.execute_reply":"2021-08-14T01:40:04.442893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-2. transaction \n\nNow let us explore the date field. Let us first check the number of transactions in each month.","metadata":{"execution":{"iopub.status.busy":"2021-08-10T05:39:56.111524Z","iopub.execute_input":"2021-08-10T05:39:56.111885Z","iopub.status.idle":"2021-08-10T05:39:56.118794Z","shell.execute_reply.started":"2021-08-10T05:39:56.111855Z","shell.execute_reply":"2021-08-10T05:39:56.117748Z"}}},{"cell_type":"code","source":"train_df['transaction_month'] = train_df['transactiondate'].dt.month\n\ncnt_srs = train_df['transaction_month'].value_counts()\nplt.figure(figsize=(12,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[3])\nplt.xticks(rotation='vertical')\nplt.xlabel('Month of transaction', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:04.445196Z","iopub.execute_input":"2021-08-14T01:40:04.445525Z","iopub.status.idle":"2021-08-14T01:40:04.671679Z","shell.execute_reply.started":"2021-08-14T01:40:04.445496Z","shell.execute_reply":"2021-08-14T01:40:04.670632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we could see from the data page as well The train data has all the transactions before October 15, 2016, plus some of the transactions after October 15, 2016.\n\nSo we have shorter bars in the last three months.\n\n**Parcel ID:**","metadata":{}},{"cell_type":"code","source":"(train_df['parcelid'].value_counts().reset_index())['parcelid'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:04.676452Z","iopub.execute_input":"2021-08-14T01:40:04.676746Z","iopub.status.idle":"2021-08-14T01:40:04.693744Z","shell.execute_reply.started":"2021-08-14T01:40:04.676719Z","shell.execute_reply":"2021-08-14T01:40:04.692887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So most of the parcel ids are appearing only once in the dataset.\n- 대부분 한번씩만 존재\n\n# 2. Properties Data\n\nNow let us explore the properties_2016 file.\n\n2016년의 특징","metadata":{}},{"cell_type":"code","source":"prop_df = pd.read_csv(\"../input/zillow-prize-1/properties_2016.csv\")\nprop_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:04.695085Z","iopub.execute_input":"2021-08-14T01:40:04.695297Z","iopub.status.idle":"2021-08-14T01:40:24.466608Z","shell.execute_reply.started":"2021-08-14T01:40:04.695271Z","shell.execute_reply":"2021-08-14T01:40:24.465514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prop_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:24.467549Z","iopub.execute_input":"2021-08-14T01:40:24.467759Z","iopub.status.idle":"2021-08-14T01:40:24.516929Z","shell.execute_reply.started":"2021-08-14T01:40:24.467739Z","shell.execute_reply":"2021-08-14T01:40:24.516458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are so many NaN values in the dataset. So let us first do some exploration on that one.\n\n## 2-1. missing values\n- 후에 유의미 확인\n","metadata":{}},{"cell_type":"code","source":"missing_df = prop_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, missing_df.missing_count.values, color = 'blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:24.517756Z","iopub.execute_input":"2021-08-14T01:40:24.518075Z","iopub.status.idle":"2021-08-14T01:40:25.944525Z","shell.execute_reply.started":"2021-08-14T01:40:24.518041Z","shell.execute_reply":"2021-08-14T01:40:25.943796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-2. latitude and longitude","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.jointplot(x=prop_df.latitude.values, y=prop_df.longitude.values, size=10)\nplt.ylabel('Longitude', fontsize=12)\nplt.xlabel('Latitude', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:25.946467Z","iopub.execute_input":"2021-08-14T01:40:25.946793Z","iopub.status.idle":"2021-08-14T01:40:34.994447Z","shell.execute_reply.started":"2021-08-14T01:40:25.946763Z","shell.execute_reply":"2021-08-14T01:40:34.993419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"위의 지도를 보면, 2016년 3개의 counties(Los angeles, Orange and Ventura, California)의 부동산 전체 목록을 제공한다.\n\ntrain 에는 90,811개의 행이 있지만, property 파일에는 2,985,217개의 행이 있으므로 두 개의 파일을 병합 후 분석 수행\n\n# 3. all data","metadata":{}},{"cell_type":"code","source":"train_df = pd.merge(train_df, prop_df, on='parcelid', how='left')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:34.996014Z","iopub.execute_input":"2021-08-14T01:40:34.996354Z","iopub.status.idle":"2021-08-14T01:40:37.037096Z","shell.execute_reply.started":"2021-08-14T01:40:34.99632Z","shell.execute_reply":"2021-08-14T01:40:37.036159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let us check the dtypes of different types of variable.","metadata":{}},{"cell_type":"code","source":"pd.options.display.max_rows = 65\n\ndtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:37.038851Z","iopub.execute_input":"2021-08-14T01:40:37.039245Z","iopub.status.idle":"2021-08-14T01:40:37.063428Z","shell.execute_reply.started":"2021-08-14T01:40:37.039205Z","shell.execute_reply":"2021-08-14T01:40:37.062117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtype_df.groupby(\"Column Type\").count().reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:37.064572Z","iopub.execute_input":"2021-08-14T01:40:37.064802Z","iopub.status.idle":"2021-08-14T01:40:37.078322Z","shell.execute_reply.started":"2021-08-14T01:40:37.064781Z","shell.execute_reply":"2021-08-14T01:40:37.077047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-1. missing values","metadata":{}},{"cell_type":"code","source":"# 결측값 check\nmissing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df['missing_ratio'] = missing_df['missing_count'] / train_df.shape[0]\nmissing_df.loc[missing_df['missing_ratio']>0.999]","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:37.081773Z","iopub.execute_input":"2021-08-14T01:40:37.082147Z","iopub.status.idle":"2021-08-14T01:40:37.15707Z","shell.execute_reply.started":"2021-08-14T01:40:37.082115Z","shell.execute_reply":"2021-08-14T01:40:37.155799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-2. Univariate Analysis\n\n변수가 많으므로, float변수만 target과의 관계 파악\n\n","metadata":{}},{"cell_type":"code","source":"mean_values = train_df.mean(axis=0)\ntrain_df.fillna(mean_values, inplace=True)\ntrain_df_new = train_df\nx_cols = [col for col in train_df_new.columns \n          if col not in ['logerror'] if train_df_new[col].dtype=='float64']\n\nlabels = []\nvalues = []\n\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(train_df_new[col].values, \n                             train_df.logerror.values)[0,1])\ncorr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n\nind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,40))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='y')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation= 'horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficeint of the variables\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:37.158578Z","iopub.execute_input":"2021-08-14T01:40:37.158864Z","iopub.status.idle":"2021-08-14T01:40:38.69113Z","shell.execute_reply.started":"2021-08-14T01:40:37.158835Z","shell.execute_reply":"2021-08-14T01:40:38.690527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"target과의 상관관계가 전반적으로 낮다.\n\n상관값이 없는 변수가 거의없다.\n\n변수들이 하나의 고유값만 가지고 있어서 상관관계가 없는 것 처럼 보인다.\n\n","metadata":{}},{"cell_type":"code","source":"corr_zero_cols = ['assessmentyear', 'storytypeid', 'pooltypeid2', 'pooltypeid7', 'pooltypeid10', 'poolcnt', 'decktypeid', 'buildingclasstypeid']\nfor col in corr_zero_cols:\n    print(col, len(train_df_new[col].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:38.692072Z","iopub.execute_input":"2021-08-14T01:40:38.692397Z","iopub.status.idle":"2021-08-14T01:40:38.705868Z","shell.execute_reply.started":"2021-08-14T01:40:38.69237Z","shell.execute_reply":"2021-08-14T01:40:38.705201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"상관관계가 높은 변수 파악하기","metadata":{"execution":{"iopub.status.busy":"2021-08-10T10:54:18.97144Z","iopub.execute_input":"2021-08-10T10:54:18.971956Z","iopub.status.idle":"2021-08-10T10:54:18.98009Z","shell.execute_reply.started":"2021-08-10T10:54:18.971917Z","shell.execute_reply":"2021-08-10T10:54:18.978314Z"}}},{"cell_type":"code","source":"corr_df_sel = corr_df.loc[(corr_df['corr_values']>0.02) | (corr_df['corr_values'] < -0.01)]\ncorr_df_sel","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:38.706702Z","iopub.execute_input":"2021-08-14T01:40:38.70701Z","iopub.status.idle":"2021-08-14T01:40:38.718029Z","shell.execute_reply.started":"2021-08-14T01:40:38.706986Z","shell.execute_reply":"2021-08-14T01:40:38.716783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_use = corr_df_sel.col_labels.tolist()\n\ntemp_df = train_df[cols_to_use]\ncorrmat = temp_df.corr(method='spearman')\nf, ax = plt.subplots(figsize=(8, 8))\n\n# Draw the heatmap using seaborn\nsns.heatmap(corrmat, vmax=1., square=True)\nplt.title(\"Important variables correlation map\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:38.71905Z","iopub.execute_input":"2021-08-14T01:40:38.719271Z","iopub.status.idle":"2021-08-14T01:40:39.185436Z","shell.execute_reply.started":"2021-08-14T01:40:38.719248Z","shell.execute_reply":"2021-08-14T01:40:39.184628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The important variables themselves are very highly correlated.! Let us now look at each of them.\n\n**Finished SquareFeet 12:**\n\nLet us seee how the finished square feet 12 varies with the log error.","metadata":{}},{"cell_type":"code","source":"col = \"finishedsquarefeet12\"\nulimit = np.percentile(train_df[col].values, 99.5)\nllimit = np.percentile(train_df[col].values, 0.5)\ntrain_df[col].loc[train_df[col]>ulimit] = ulimit\ntrain_df[col].loc[train_df[col]<llimit] = llimit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(x=train_df.finishedsquarefeet12.values, y=train_df.logerror.values, size=10, color=color[4])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Finished Square Feet 12', fontsize=12)\nplt.title(\"Finished square feet 12 Vs Log error\", fontsize=15)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:39.186578Z","iopub.execute_input":"2021-08-14T01:40:39.186866Z","iopub.status.idle":"2021-08-14T01:40:40.75782Z","shell.execute_reply.started":"2021-08-14T01:40:39.186838Z","shell.execute_reply":"2021-08-14T01:40:40.757001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"logerror는 finishedsquarefeet12가 증가함에 따라 error가 감소되는 형태를 보임\n\n아마도 더 큰 집(평방피트가 큰)은 오류가 적으므로 예측하기 쉬운 것으로 보인다.\n\n**calculatedfinishedsquarefeet:**","metadata":{}},{"cell_type":"code","source":"col = \"calculatedfinishedsquarefeet\"\nulimit = np.percentile(train_df[col].values, 99.5)\nllimit = np.percentile(train_df[col].values, 0.5)\ntrain_df[col].loc[train_df[col]>ulimit] = ulimit\ntrain_df[col].loc[train_df[col]<llimit] = llimit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(x=train_df.calculatedfinishedsquarefeet.values, y=train_df.logerror.values, size=10, color=color[5])\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Calculated finished square feet', fontsize=12)\nplt.title(\"Calculated finished square feet Vs Log error\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:40.75894Z","iopub.execute_input":"2021-08-14T01:40:40.759166Z","iopub.status.idle":"2021-08-14T01:40:41.998521Z","shell.execute_reply.started":"2021-08-14T01:40:40.759141Z","shell.execute_reply":"2021-08-14T01:40:41.997612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"분포 유사. 위 두 변수 간 상관관계 높다고 추정가능","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"bathroomcnt\", data=train_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Bathroom', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bathroom count\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:42.001672Z","iopub.execute_input":"2021-08-14T01:40:42.002008Z","iopub.status.idle":"2021-08-14T01:40:42.236344Z","shell.execute_reply.started":"2021-08-14T01:40:42.001979Z","shell.execute_reply":"2021-08-14T01:40:42.235186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,9))\nsns.boxplot(x='bathroomcnt', y = 'logerror', data = train_df)\nplt.ylabel('Log error', fontsize=12)\nplt.xlabel('Bathroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"How log error changes with bathroom count?\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:42.237785Z","iopub.execute_input":"2021-08-14T01:40:42.238003Z","iopub.status.idle":"2021-08-14T01:40:42.836263Z","shell.execute_reply.started":"2021-08-14T01:40:42.23798Z","shell.execute_reply":"2021-08-14T01:40:42.83513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"bathroom 수가 늘어날수록 4분위 범위가 커진다.\n\nbathroom 크기가 작을 수록 이상치 값이 많이 분포되어 있다. \n\n즉, log error가 다양하게 분포되어 있다는 것을 의미한다.","metadata":{}},{"cell_type":"markdown","source":"**Bedroom count**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"bedroomcnt\", data=train_df)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Bedroom Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Bedroom count\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:42.837421Z","iopub.execute_input":"2021-08-14T01:40:42.837649Z","iopub.status.idle":"2021-08-14T01:40:43.040199Z","shell.execute_reply.started":"2021-08-14T01:40:42.837605Z","shell.execute_reply":"2021-08-14T01:40:43.039446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['bedroomcnt'].loc[train_df['bedroomcnt']>7] = 7\nplt.figure(figsize=(12,8))\nsns.violinplot(x='bedroomcnt', y='logerror', data=train_df)\nplt.xlabel('Bedroom count', fontsize=12)\nplt.ylabel('Log Error', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:43.041713Z","iopub.execute_input":"2021-08-14T01:40:43.042Z","iopub.status.idle":"2021-08-14T01:40:43.952186Z","shell.execute_reply.started":"2021-08-14T01:40:43.041976Z","shell.execute_reply":"2021-08-14T01:40:43.951525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"logerror 값이 0을 기준으로 -0.2 ~ 0.2 범위 안에 분포","metadata":{}},{"cell_type":"code","source":"col = \"taxamount\"\nulimit = np.percentile(train_df[col].values, 99.5)\nllimit = np.percentile(train_df[col].values, 0.5)\ntrain_df[col].loc[train_df[col]>ulimit] = ulimit\ntrain_df[col].loc[train_df[col]<llimit] = llimit\n\nplt.figure(figsize=(12,12))\nsns.jointplot(x=train_df['taxamount'].values, y=train_df['logerror'].values, size=10, color='g')\nplt.ylabel('Log Error', fontsize=12)\nplt.xlabel('Tax Amount', fontsize=12)\nplt.title(\"Tax Amount Vs Log error\", fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:43.953456Z","iopub.execute_input":"2021-08-14T01:40:43.953973Z","iopub.status.idle":"2021-08-14T01:40:45.57767Z","shell.execute_reply.started":"2021-08-14T01:40:43.953934Z","shell.execute_reply":"2021-08-14T01:40:45.577037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**YearBuilt:**\n\nLet us explore how the error varies with the yearbuilt variable.\n","metadata":{}},{"cell_type":"code","source":"from ggplot import *\nggplot(aes(x='yearbuilt', y='logerror'), data = train_df) + \\\n    geom_point(color='steelblue', size=1) + \\\n    stat_smooth()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:45.578605Z","iopub.execute_input":"2021-08-14T01:40:45.578973Z","iopub.status.idle":"2021-08-14T01:40:54.338094Z","shell.execute_reply.started":"2021-08-14T01:40:45.578946Z","shell.execute_reply":"2021-08-14T01:40:54.337269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"built year에 따라 사소한 증가 추세를 보임\n\nlogerror와 경도, 위도","metadata":{}},{"cell_type":"code","source":"ggplot(aes(x='latitude', y='longitude', color='logerror'), data=train_df) + \\\n    geom_point() + \\\n    scale_color_gradient(low = 'red', high = 'blue')","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:54.339439Z","iopub.execute_input":"2021-08-14T01:40:54.339951Z","iopub.status.idle":"2021-08-14T01:40:55.138483Z","shell.execute_reply.started":"2021-08-14T01:40:54.339912Z","shell.execute_reply":"2021-08-14T01:40:55.13733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"no visible pockets\n\n양 음 상관관계가 가장 높은 변수를 이용해 visible pattern 확인","metadata":{}},{"cell_type":"code","source":"ggplot(aes(x='finishedsquarefeet12', y='taxamount', color='logerror'), data=train_df) + \\\n    geom_point(alpha=0.7) + \\\n    scale_color_gradient(low = 'pink', high = 'blue')","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:55.1398Z","iopub.execute_input":"2021-08-14T01:40:55.140069Z","iopub.status.idle":"2021-08-14T01:40:55.769857Z","shell.execute_reply.started":"2021-08-14T01:40:55.140042Z","shell.execute_reply":"2021-08-14T01:40:55.769244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"no visible pattern too","metadata":{"execution":{"iopub.status.busy":"2021-08-10T11:14:28.567327Z","iopub.execute_input":"2021-08-10T11:14:28.567874Z","iopub.status.idle":"2021-08-10T11:14:28.575253Z","shell.execute_reply.started":"2021-08-10T11:14:28.567831Z","shell.execute_reply":"2021-08-10T11:14:28.573683Z"}}},{"cell_type":"code","source":"ggplot(aes(x='finishedsquarefeet12', y='taxamount', color='logerror'), data=train_df) + \\\n    geom_now_its_art()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:55.770801Z","iopub.execute_input":"2021-08-14T01:40:55.771142Z","iopub.status.idle":"2021-08-14T01:40:56.136661Z","shell.execute_reply.started":"2021-08-14T01:40:55.771114Z","shell.execute_reply":"2021-08-14T01:40:56.135711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hurray.! Finally we got some nice pattern in the data :P\n\nWe had an understanding of important variables from the univariate analysis. But this is on a stand alone basis and also we have linearity assumption. Now let us build a non-linear model to get the important variables by building Extra Trees model.\n\n- 일변량 분석을 통해 중요 변수 이해함\n- 독립형기준 + 선형성 가정이라 비선형 모델 구축 > tree model의 중요 변수 얻기","metadata":{}},{"cell_type":"markdown","source":"## 비선형 모델 구축","metadata":{}},{"cell_type":"code","source":"train_y = train_df['logerror'].values\ncat_cols = [\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\ntrain_df = train_df.drop(['parcelid', 'logerror', 'transactiondate', 'transaction_month']+cat_cols, axis=1)\nfeat_names = train_df.columns.values\n# 트리 모델 분석시 수치형 변수를 제외한 target 컬럼 범주형 변수, 날짜형 변수등과 같이 필요 없는 컬럼은 삭제 하고, \n# 분석하고 싶은 수치형 변수만 남긴다.한다.\n# axis=1 컬럼을 삭제 (cf : axis=0 은 행을 삭제)\n\n\nfrom sklearn import ensemble\nmodel = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30, max_features=0.3, n_jobs=-1, random_state=0)\nmodel.fit(train_df, train_y)\n\n## plot the importances ##\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:56.139556Z","iopub.execute_input":"2021-08-14T01:40:56.139835Z","iopub.status.idle":"2021-08-14T01:40:59.476882Z","shell.execute_reply.started":"2021-08-14T01:40:56.13981Z","shell.execute_reply":"2021-08-14T01:40:59.476055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'silent': 1,\n    'seed' : 0\n}\ndtrain = xgb.DMatrix(train_df, train_y, feature_names=train_df.columns.values)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)\n\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:40:59.477986Z","iopub.execute_input":"2021-08-14T01:40:59.478253Z","iopub.status.idle":"2021-08-14T01:41:06.761399Z","shell.execute_reply.started":"2021-08-14T01:40:59.478225Z","shell.execute_reply":"2021-08-14T01:41:06.760808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport gc\n\nprint('Loading data ...')\n\ntrain = pd.read_csv('../input/zillow-prize-1/train_2016_v2.csv')\nprop = pd.read_csv('../input/zillow-prize-1/properties_2016.csv')\nsample = pd.read_csv('../input/zillow-prize-1/sample_submission.csv')\n\nprint('Binding to float32')\n\nfor c, dtype in zip(prop.columns, prop.dtypes):\n\tif dtype == np.float64:\n\t\tprop[c] = prop[c].astype(np.float32)\n\nprint('Creating training set ...')\n\ndf_train = train.merge(prop, how='left', on='parcelid')\n\nx_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\ny_train = df_train['logerror'].values\nprint(x_train.shape, y_train.shape)\n\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c] == True)\n\ndel df_train; gc.collect()\n\nsplit = 80000\nx_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n\nprint('Building DMatrix...')\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\n\ndel x_train, x_valid; gc.collect()\n\nprint('Training ...')\n\nparams = {}\nparams['eta'] = 0.02\nparams['objective'] = 'reg:linear'\nparams['eval_metric'] = 'mae'\nparams['max_depth'] = 4\nparams['silent'] = 1\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nclf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n\ndel d_train, d_valid\n\nprint('Building test set ...')\n\nsample['parcelid'] = sample['ParcelId']\ndf_test = sample.merge(prop, on='parcelid', how='left')\n\ndel prop; gc.collect()\n\nx_test = df_test[train_columns]\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\n\ndel df_test, sample; gc.collect()\n\nd_test = xgb.DMatrix(x_test)\n\ndel x_test; gc.collect()\n\nprint('Predicting on test ...')\n\np_test = clf.predict(d_test)\n\ndel d_test; gc.collect()\n\nsub = pd.read_csv('../input/zillow-prize-1/sample_submission.csv')\nfor c in sub.columns[sub.columns != 'ParcelId']:\n    sub[c] = p_test\n\nprint('Writing csv ...')\nsub.to_csv('xgb_starter.csv', index=False, float_format='%.4f') # Thanks to @inversion","metadata":{"execution":{"iopub.status.busy":"2021-08-14T01:41:06.762378Z","iopub.execute_input":"2021-08-14T01:41:06.762754Z","iopub.status.idle":"2021-08-14T01:43:18.492458Z","shell.execute_reply.started":"2021-08-14T01:41:06.762727Z","shell.execute_reply":"2021-08-14T01:43:18.491049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}