{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# !git clone https://github.com/motefly/DeepGBM.git","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc, collections, os\nimport numpy as np\nimport pandas as pd\nimport category_encoders as ce\nfrom tqdm import tqdm\nfrom pathlib import Path\n\ndataset_path = Path(\"../input/zillow-prize-1/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_path = Path(\"./out\")\noutput_tr_path = output_path / \"train\"\noutput_te_path = output_path / \"test\"\n\nif not output_tr_path.exists():\n    output_tr_path.mkdir(parents=True)\n\nif not output_te_path.exists():\n    output_te_path.mkdir(parents=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls ../input/zillow-prize-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference: https://www.kaggle.com/aharless/xgboost-lightgbm-and-ols\nprop = pd.read_csv(dataset_path / 'properties_2016.csv')\ntrain = pd.read_csv(dataset_path / \"train_2016_v2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"\\nProcessing data for LightGBM ...\" )\nfor c, dtype in zip(prop.columns, prop.dtypes):\t\n    if dtype == np.float64:\t\t\n        prop[c] = prop[c].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = train.merge(prop, how='left', on='parcelid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nume_col = ['bathroomcnt','bedroomcnt','calculatedbathnbr','threequarterbathnbr','finishedfloor1squarefeet','calculatedfinishedsquarefeet','finishedsquarefeet6','finishedsquarefeet12','finishedsquarefeet13','finishedsquarefeet15','finishedsquarefeet50','fireplacecnt','fullbathcnt','garagecarcnt','garagetotalsqft','latitude','longitude','lotsizesquarefeet','numberofstories','poolcnt','poolsizesum','roomcnt','unitcnt','yardbuildingsqft17','yardbuildingsqft17','taxvaluedollarcnt','structuretaxvaluedollarcnt','landtaxvaluedollarcnt','taxamount','taxdelinquencyyear','yearbuilt']\ncate_col = ['architecturalstyletypeid', 'yearbuilt_cate', 'buildingqualitytypeid', 'propertyzoningdesc', 'regionidneighborhood', 'yardbuildingsqft26', 'fireplaceflag', 'propertycountylandusecode', 'hashottuborspa', 'basementsqft', 'fips', 'buildingclasstypeid', 'pooltypeid2', 'pooltypeid10', 'regionidcounty', 'heatingorsystemtypeid', 'rawcensustractandblock', 'censustractandblock', 'taxdelinquencyflag', 'airconditioningtypeid', 'pooltypeid7', 'regionidcity', 'regionidzip', 'decktypeid', 'typeconstructiontypeid', 'propertylandusetypeid', 'storytypeid']\nlabel_col = 'logerror'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ref: https://github.com/motefly/DeepGBM/issues/8\ndf_train[\"yearbuilt_cate\"] = df_train[\"yearbuilt\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_csv(\"train.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unpackbits(x,num_bits):\n    xshape = list(x.shape)\n    x = x.reshape([-1,1])\n    to_and = 2**np.arange(num_bits).reshape([1,num_bits])\n    return (x & to_and).astype(bool).astype(int).reshape(xshape + [num_bits])\n\nclass NumEncoder(object):\n    def __init__(self, cate_col, nume_col, threshold, thresrate, label):\n        self.label_name = label\n        # cate_col = list(df.select_dtypes(include=['object']))\n        self.cate_col = cate_col\n        # nume_col = list(set(list(df)) - set(cate_col))\n        self.dtype_dict = {}\n        for item in cate_col:\n            self.dtype_dict[item] = 'str'\n        for item in nume_col:\n            self.dtype_dict[item] = 'float'\n        self.nume_col = nume_col\n        self.tgt_nume_col = []\n        self.encoder = ce.ordinal.OrdinalEncoder(cols=cate_col)\n        self.threshold = threshold\n        self.thresrate = thresrate\n        # for online update, to do\n        self.save_cate_avgs = {}\n        self.save_value_filter = {}\n        self.save_num_embs = {}\n        self.Max_len = {}\n        self.samples = 0\n\n    def fit_transform(self, inPath, outPath):\n        print('----------------------------------------------------------------------')\n        print('Fitting and Transforming %s .'%inPath)\n        print('----------------------------------------------------------------------')\n        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n        self.samples = df.shape[0]\n        print('Filtering and fillna features')\n        for item in tqdm(self.cate_col):\n            value_counts = df[item].value_counts()\n            num = value_counts.shape[0]\n            self.save_value_filter[item] = list(value_counts[:int(num*self.thresrate)][value_counts>self.threshold].index)\n            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n            df[item] = df[item].fillna('<UNK>')\n            del value_counts\n            gc.collect()\n\n        for item in tqdm(self.nume_col):\n            df[item] = df[item].fillna(df[item].mean())\n            self.save_num_embs[item] = {'sum':df[item].sum(), 'cnt':df[item].shape[0]}\n\n        print('Ordinal encoding cate features')\n        # ordinal_encoding\n        df = self.encoder.fit_transform(df)\n\n        print('Target encoding cate features')\n        # dynamic_targeting_encoding\n        for item in tqdm(self.cate_col):\n            feats = df[item].values\n            labels = df[self.label_name].values\n            feat_encoding = {'mean':[], 'count':[]}\n            feat_temp_result = collections.defaultdict(lambda : [0, 0])\n            self.save_cate_avgs[item] = collections.defaultdict(lambda : [0, 0])\n            for idx in range(self.samples):\n                cur_feat = feats[idx]\n                # smoothing optional\n                if cur_feat in self.save_cate_avgs[item]:\n                    # feat_temp_result[cur_feat][0] = 0.9*feat_temp_result[cur_feat][0] + 0.1*self.save_cate_avgs[item][cur_feat][0]/self.save_cate_avgs[item][cur_feat][1]\n                    # feat_temp_result[cur_feat][1] = 0.9*feat_temp_result[cur_feat][1] + 0.1*self.save_cate_avgs[item][cur_feat][1]/idx\n                    feat_encoding['mean'].append(self.save_cate_avgs[item][cur_feat][0]/self.save_cate_avgs[item][cur_feat][1])\n                    feat_encoding['count'].append(self.save_cate_avgs[item][cur_feat][1]/idx)\n                else:\n                    feat_encoding['mean'].append(0)\n                    feat_encoding['count'].append(0)\n                self.save_cate_avgs[item][cur_feat][0] += labels[idx]\n                self.save_cate_avgs[item][cur_feat][1] += 1\n            df[item+'_t_mean'] = feat_encoding['mean']\n            df[item+'_t_count'] = feat_encoding['count']\n            self.tgt_nume_col.append(item+'_t_mean')\n            self.tgt_nume_col.append(item+'_t_count')\n        \n        print('Start manual binary encode')\n        rows = None\n        for item in tqdm(self.nume_col+self.tgt_nume_col):\n            feats = df[item].values\n            if rows is None:\n                rows = feats.reshape((-1,1))\n            else:\n                rows = np.concatenate([rows,feats.reshape((-1,1))],axis=1)\n            del feats\n            gc.collect()\n        for item in tqdm(self.cate_col):\n            feats = df[item].values\n            Max = df[item].max()\n            bit_len = len(bin(Max)) - 2\n            samples = self.samples\n            self.Max_len[item] = bit_len\n            res = unpackbits(feats, bit_len).reshape((samples,-1))\n            rows = np.concatenate([rows,res],axis=1)\n            del feats\n            gc.collect()\n        trn_y = np.array(df[self.label_name].values).reshape((-1,1))\n        del df\n        gc.collect()\n        trn_x = np.array(rows)\n        np.save(outPath+'_features.npy', trn_x)\n        np.save(outPath+'_labels.npy', trn_y)\n\n    # for test dataset\n    def transform(self, inPath, outPath):\n        print('----------------------------------------------------------------------')\n        print('Transforming %s .'%inPath)\n        print('----------------------------------------------------------------------')\n        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n        samples = df.shape[0]\n        print('Filtering and fillna features')\n        for item in tqdm(self.cate_col):\n            value_counts = df[item].value_counts()\n            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n            df[item] = df[item].fillna('<UNK>')\n\n        for item in tqdm(self.nume_col):\n            mean = self.save_num_embs[item]['sum'] / self.save_num_embs[item]['cnt']\n            df[item] = df[item].fillna(mean)\n\n        print('Ordinal encoding cate features')\n        # ordinal_encoding\n        df = self.encoder.transform(df)\n\n        print('Target encoding cate features')\n        # dynamic_targeting_encoding\n        for item in tqdm(self.cate_col):\n            avgs = self.save_cate_avgs[item]\n            df[item+'_t_mean'] = df[item].map(lambda x: avgs[x][0]/avgs[x][1] if x in avgs else 0)\n            df[item+'_t_count'] = df[item].map(lambda x: avgs[x][1]/self.samples if x in avgs else 0)\n        \n        print('Start manual binary encode')\n        rows = None\n        for item in tqdm(self.nume_col+self.tgt_nume_col):\n            feats = df[item].values\n            if rows is None:\n                rows = feats.reshape((-1,1))\n            else:\n                rows = np.concatenate([rows,feats.reshape((-1,1))],axis=1)\n            del feats\n            gc.collect()\n        for item in tqdm(self.cate_col):\n            feats = df[item].values\n            bit_len = self.Max_len[item]\n            res = unpackbits(feats, bit_len).reshape((samples,-1))\n            rows = np.concatenate([rows,res],axis=1)\n            del feats\n            gc.collect()\n        vld_y = np.array(df[self.label_name].values).reshape((-1,1))\n        del df\n        gc.collect()\n        vld_x = np.array(rows)\n        np.save(outPath+'_features.npy', vld_x)\n        np.save(outPath+'_labels.npy', vld_y)\n    \n    # for update online dataset\n    def refit_transform(self, inPath, outPath):\n        print('----------------------------------------------------------------------')\n        print('Refitting and Transforming %s .'%inPath)\n        print('----------------------------------------------------------------------')\n        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n        samples = df.shape[0]\n        print('Filtering and fillna features')\n        for item in tqdm(self.cate_col):\n            value_counts = df[item].value_counts()\n            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n            df[item] = df[item].fillna('<UNK>')\n\n        for item in tqdm(self.nume_col):\n            self.save_num_embs[item]['sum'] += df[item].sum()\n            self.save_num_embs[item]['cnt'] += df[item].shape[0]\n            mean = self.save_num_embs[item]['sum'] / self.save_num_embs[item]['cnt']\n            df[item] = df[item].fillna(mean)\n\n        print('Ordinal encoding cate features')\n        # ordinal_encoding\n        df = self.encoder.transform(df)\n\n        print('Target encoding cate features')\n        # dynamic_targeting_encoding\n        for item in tqdm(self.cate_col):\n            feats = df[item].values\n            labels = df[self.label_name].values\n            feat_encoding = {'mean':[], 'count':[]}\n            for idx in range(samples):\n                cur_feat = feats[idx]\n                if self.save_cate_avgs[item][cur_feat][1] == 0:\n                    pdb.set_trace()\n                feat_encoding['mean'].append(self.save_cate_avgs[item][cur_feat][0]/self.save_cate_avgs[item][cur_feat][1])\n                feat_encoding['count'].append(self.save_cate_avgs[item][cur_feat][1]/(self.samples+idx))\n                self.save_cate_avgs[item][cur_feat][0] += labels[idx]\n                self.save_cate_avgs[item][cur_feat][1] += 1\n            df[item+'_t_mean'] = feat_encoding['mean']\n            df[item+'_t_count'] = feat_encoding['count']\n\n        self.samples += samples\n            \n        print('Start manual binary encode')\n        rows = None\n        for item in tqdm(self.nume_col+self.tgt_nume_col):\n            feats = df[item].values\n            if rows is None:\n                rows = feats.reshape((-1,1))\n            else:\n                rows = np.concatenate([rows,feats.reshape((-1,1))],axis=1)\n            del feats\n            gc.collect()\n        for item in tqdm(self.cate_col):\n            feats = df[item].values\n            bit_len = self.Max_len[item]\n            res = unpackbits(feats, bit_len).reshape((samples,-1))\n            rows = np.concatenate([rows,res],axis=1)\n            del feats\n            gc.collect()\n        vld_y = np.array(df[self.label_name].values).reshape((-1,1))\n        del df\n        gc.collect()\n        vld_x = np.array(rows)\n        np.save(outPath+'_features.npy', vld_x)\n        np.save(outPath+'_labels.npy', vld_y)\n        # to do\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CateEncoder(object):\n    def __init__(self, cate_col, nume_col, threshold, thresrate, bins, label):\n        self.label_name = label\n        # cate_col = list(df.select_dtypes(include=['object']))\n        self.cate_col = cate_col \n        # nume_col = list(set(list(df)) - set(cate_col))\n        self.dtype_dict = {}\n        for item in cate_col:\n            self.dtype_dict[item] = 'str'\n        for item in nume_col:\n            self.dtype_dict[item] = 'float'\n        self.nume_col = nume_col\n        self.encoder = ce.ordinal.OrdinalEncoder(cols=cate_col+nume_col)\n        self.threshold = threshold\n        self.thresrate = thresrate\n        self.bins = bins\n        # for online update, to do\n        self.save_value_filter = {}\n        self.save_num_bins = {}\n        self.samples = 0\n\n    def save2npy(self, df, out_dir):\n        if not os.path.isdir(out_dir):\n            os.mkdir(out_dir)\n        result = {'label':[], 'index':[],'feature_sizes':[]}\n        result['label'] = df[self.label_name].values\n        result['index'] = df[self.cate_col+self.nume_col].values\n        for item in self.cate_col+self.nume_col:\n            result['feature_sizes'].append(df[item].max()+1)\n        for item in result:\n            result[item] = np.array(result[item])\n            np.save(out_dir + '_' + item +'.npy', result[item])\n\n    def fit_transform(self, inPath, outPath):\n        print('----------------------------------------------------------------------')\n        print('Fitting and Transforming %s .'%inPath)\n        print('----------------------------------------------------------------------')\n        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n        print('Filtering and fillna features')\n        for item in tqdm(self.cate_col):\n            value_counts = df[item].value_counts()\n            num = value_counts.shape[0]\n            self.save_value_filter[item] = list(value_counts[:int(num*self.thresrate)][value_counts>self.threshold].index)\n            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n            df[item] = df[item].fillna('<UNK>')\n\n        print('Fillna and Bucketize numeric features')\n        for item in tqdm(self.nume_col):\n            q_res = pd.qcut(df[item], self.bins, labels=False, retbins=True, duplicates='drop')\n            df[item] = q_res[0].fillna(-1).astype('int')\n            self.save_num_bins[item] = q_res[1]\n\n        print('Ordinal encoding cate features')\n        # ordinal_encoding\n        df = self.encoder.fit_transform(df)\n        self.save2npy(df, outPath)\n        # df.to_csv(outPath, index=False)\n\n    # for test dataset\n    def transform(self, inPath, outPath):\n        print('----------------------------------------------------------------------')\n        print('Transforming %s .'%inPath)\n        print('----------------------------------------------------------------------')\n        df = pd.read_csv(inPath, dtype=self.dtype_dict)\n        print('Filtering and fillna features')\n        for item in tqdm(self.cate_col):\n            value_counts = df[item].value_counts()\n            rm_values = set(value_counts.index)-set(self.save_value_filter[item])\n            df[item] = df[item].map(lambda x: '<LESS>' if x in rm_values else x)\n            df[item] = df[item].fillna('<UNK>')\n\n        for item in tqdm(self.nume_col):\n            df[item] = pd.cut(df[item], self.save_num_bins[item], labels=False, include_lowest=True).fillna(-1).astype('int')\n\n        print('Ordinal encoding cate features')\n        # ordinal_encoding\n        df = self.encoder.transform(df)\n        self.save2npy(df, outPath)\n        # df.to_csv(outPath, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set default value\nthreshold = 10\nthresrate = 0.99\nnum_bins = 32\n\nec = NumEncoder(cate_col, nume_col, threshold, thresrate, label_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ec.fit_transform(\"train.csv\", str(output_tr_path))\n# ec.transform(args['test_csv_path'], args['out_dir']+'/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ce = CateEncoder(cate_col, nume_col, threshold, thresrate, num_bins, label_col)\nce.fit_transform(\"train.csv\", str(output_tr_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls out/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}