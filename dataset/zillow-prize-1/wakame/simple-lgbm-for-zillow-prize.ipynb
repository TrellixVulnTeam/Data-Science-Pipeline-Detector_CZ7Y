{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install optuna==0.18.1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import optuna \noptuna.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls ../input/zillow-prize-1/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nimport gc\nimport datetime as dt\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = Path(\"../input/zillow-prize-1/\")\nproperties_2016_path = input_path / \"properties_2016.csv\"\ntrain_2016_v2_path = input_path / \"train_2016_v2.csv\"\ntrain_2017_path = input_path / \"train_2017.csv\"\nproperties_2017_path = input_path / \"properties_2017.csv\"\nsample_submission_path = input_path / \"sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loading data...')\nproperties = pd.read_csv(properties_2016_path, low_memory = False)\ntrain = pd.read_csv(train_2016_v2_path)\nsample_submission = pd.read_csv(sample_submission_path, low_memory = False)\ntrain = pd.merge(train, properties, how = 'left', on = 'parcelid')\ntest = pd.merge(sample_submission[['ParcelId']], properties.rename(columns = {'parcelid': 'ParcelId'}), \n                how = 'left', on = 'ParcelId')\ndel properties\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Memory usage reduction...')\ntrain[['latitude', 'longitude']] /= 1e6\ntest[['latitude', 'longitude']] /= 1e6\n\ntrain['censustractandblock'] /= 1e12\ntest['censustractandblock'] /= 1e12\n\nfor column in test.columns:\n    if test[column].dtype == int:\n        test[column] = test[column].astype(np.int32)\n    if test[column].dtype == float:\n        test[column] = test[column].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Feature engineering...')\ntrain['month'] = pd.to_datetime(train['transactiondate']).dt.month\ntrain = train.drop('transactiondate', axis = 1)\nfrom sklearn.preprocessing import LabelEncoder\nnon_number_columns = train.dtypes[train.dtypes == object].index.values\n\nfor column in non_number_columns:\n    train_test = pd.concat([train[column], test[column]], axis = 0)\n    encoder = LabelEncoder().fit(train_test.astype(str))\n    train[column] = encoder.transform(train[column].astype(str)).astype(np.int32)\n    test[column] = encoder.transform(test[column].astype(str)).astype(np.int32)\n    \nfeature_names = train.columns[2:]\nfeature_names = [feature for feature in feature_names if feature != 'month']\n\nmonth_avgs = train.groupby('month').agg(['mean'])['logerror', 'mean'].values - train['logerror'].mean()\n\nfrom sklearn.linear_model import LinearRegression\nmonth_model = LinearRegression().fit(np.arange(4, 13, 1).reshape(-1, 1), \n                                     month_avgs[3:].reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Preparing arrays and throwing out outliers...')\nX_train = train[feature_names].values\ny_train = train.iloc[:, 1].values\nX_test = test[feature_names].values\n\ndel test\ngc.collect();\n\nmonth_values = train['month'].values\nX_train = np.hstack([X_train, month_model.predict(month_values.reshape(-1, 1))])\n\nX_train = X_train[np.abs(y_train) < 0.4, :]\ny_train = y_train[np.abs(y_train) < 0.4]\n\n\nprint('Training LGBM model...')\nltrain = lgb.Dataset(X_train, label = y_train)\n\nparams = {}\nparams['metric'] = 'mae'\nparams['max_depth'] = 100\nparams['num_leaves'] = 32\nparams['feature_fraction'] = .85\nparams['bagging_fraction'] = .95\nparams['bagging_freq'] = 8\nparams['learning_rate'] = 0.0025\nparams['verbosity'] = 0\n\nlgb_model = lgb.train(params, ltrain, verbose_eval=0, num_boost_round=2930)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Making predictions and praying for good results...')\nX_test = np.hstack([X_test, np.zeros((X_test.shape[0], 1))])\nfolds = 20\nn = int(X_test.shape[0] / folds)\n\nfor j in range(folds):\n    results = pd.DataFrame()\n    \n    if j < folds - 1:\n            X_test_ = X_test[j*n: (j+1)*n, :]\n            results['ParcelId'] = sample_submission['ParcelId'].iloc[j*n: (j+1)*n]\n    else:\n            X_test_ = X_test[j*n: , :]\n            results['ParcelId'] = sample_submission['ParcelId'].iloc[j*n: ]\n            \n    for month in [10, 11, 12]:\n        X_test_[:, -1] = month_avgs[month - 1]\n        assert X_test_.shape[1] == X_test.shape[1]\n        y_pred = lgb_model.predict(X_test_)\n        results['2016' + str(month)] = y_pred\n        results['2017' + str(month)] = y_pred\n        \n    if j == 0:\n        results_ = results.copy()\n    else:\n        results_ = pd.concat([results_, results], axis = 0)\n    print('{}% completed'.format(round(100*(j+1)/folds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Saving predictions...')\nresults = results_[sample_submission.columns]\nassert results.shape == sample_submission.shape\nresults.to_csv('submission.csv', index = False, float_format = '%.6f')\nprint('Done!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}