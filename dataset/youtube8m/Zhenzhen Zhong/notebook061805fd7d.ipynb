{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"437d4cbd-0aa7-e742-7462-9384ed893e2b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9a7771f-5eed-23bb-5c00-04e463615e7a"},"outputs":[],"source":"print(check_output([\"ls\", \"../input/video_level\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"445a7d53-f0ed-cfb5-1bb2-91277c7c7f61"},"outputs":[],"source":"print(check_output([\"ls\", \"../input/frame_level\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd04055b-98c9-bd6c-8db1-38fe956d6d90"},"outputs":[],"source":"labels_df = pd.read_csv('../input/label_names.csv')\nlabels_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0274be94-639a-3c1a-ce54-98e7874c105e"},"outputs":[],"source":"labels_df.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"712d9cb4-ddc6-8cd7-78dd-49f557d46d14"},"outputs":[],"source":"labels_df.iloc[45]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e83a2ff-a111-930c-f345-73b2ab35f6f8"},"outputs":[],"source":"submit_df = pd.read_csv('../input/sample_submission.csv')\nsubmit_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82eabf03-5990-cdcb-293c-befca987a715"},"outputs":[],"source":"import tensorflow as tf\nlabels = []\ntextual_labels = []\ntextual_labels_nested = []\nfilenames = [\"../input/video_level/train-{}.tfrecord\".format(i) for i in range(10)]\ntotal_sample_counter = 0\n\nlabel_counts = []\n\nfor filename in filenames:\n    for example in tf.python_io.tf_record_iterator(filename):\n        total_sample_counter += 1\n        tf_example = tf.train.Example.FromString(example)\n\n        label_example = list(tf_example.features.feature['labels'].int64_list.value)\n        label_counts.append(len(label_example))\n        labels = labels + label_example\n        label_example_textual = list(labels_df[labels_df['label_id'].isin(label_example)]['label_name'])\n        textual_labels_nested.append(set(label_example_textual))\n        textual_labels = textual_labels + label_example_textual\n        if len(label_example_textual) != len(label_example):\n            print('label names lookup failed: {} vs {}'.format(label_example, label_example_textual))\n\nprint('label ids missing from label_names.csv: {}'.format(sorted(set(labels) - set(labels_df['label_id']))))\nprint('Found {} samples in all of the 10 available tfrecords'.format(total_sample_counter))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd95b964-7777-2b4b-a6cd-7d60224a9b75"},"outputs":[],"source":"tf.python_io.tf_record_iterator(\"../input/video_level/train-0.tfrecord\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce3b6b3f-4a9b-cf02-7293-dd4bc5177e14"},"outputs":[],"source":"import tensorflow as tf\nfor example in tf.python_io.tf_record_iterator(\"../input/video_level/train-0.tfrecord\"):\n#    total_sample_counter += 1\n    tf_example1 = tf.train.Example.FromString(example)\ntf_example1\n#print (example)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fda09bb-3bc3-b302-5ffe-c691c84ccb03"},"outputs":[],"source":"tf_example1 = tf.train.Example.FromString('../input/video_level/train-0.tfrecord[0]')\ntf_example1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3316b70-115c-08a3-5837-6396f8bdb7a5"},"outputs":[],"source":"shape = tf.unstack(tf.shape(example))\nshape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f735201-3951-4c26-0e3b-ee1bae513bfc"},"outputs":[],"source":"def prepare_serialized_examples(self, serialized_example,\n      max_quantized_value=2, min_quantized_value=-2):\n\n    contexts, features = tf.parse_single_sequence_example(\n        serialized_example,\n        context_features={\"video_id\": tf.FixedLenFeature(\n            [], tf.string),\n                          \"labels\": tf.VarLenFeature(tf.int64)},\n        sequence_features={\n            feature_name : tf.FixedLenSequenceFeature([], dtype=tf.string)\n            for feature_name in self.feature_names\n        })\n\n    # read ground truth labels\n    labels = (tf.cast(\n        tf.sparse_to_dense(contexts[\"labels\"].values, (self.num_classes,), 1,\n            validate_indices=False),\n        tf.bool))\n\n    # loads (potentially) different types of features and concatenates them\n    num_features = len(self.feature_names)\n    assert num_features > 0, \"No feature selected: feature_names is empty!\"\n\n    assert len(self.feature_names) == len(self.feature_sizes), \\\n    \"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\n    len(self.feature_names), len(self.feature_sizes))\n\n    num_frames = -1  # the number of frames in the video\n    feature_matrices = [None] * num_features  # an array of different features\n    for feature_index in range(num_features):\n      feature_matrix, num_frames_in_this_feature = self.get_video_matrix(\n          features[self.feature_names[feature_index]],\n          self.feature_sizes[feature_index],\n          self.max_frames,\n          max_quantized_value,\n          min_quantized_value)\n      if num_frames == -1:\n        num_frames = num_frames_in_this_feature\n      else:\n        tf.assert_equal(num_frames, num_frames_in_this_feature)\n\n      feature_matrices[feature_index] = feature_matrix\n\n    # cap the number of frames at self.max_frames\n    num_frames = tf.minimum(num_frames, self.max_frames)\n\n    # concatenate different features\n    video_matrix = tf.concat(feature_matrices, 1)\n\n    # convert to batch format.\n    # TODO: Do proper batch reads to remove the IO bottleneck.\n    batch_video_ids = tf.expand_dims(contexts[\"video_id\"], 0)\n    batch_video_matrix = tf.expand_dims(video_matrix, 0)\n    batch_labels = tf.expand_dims(labels, 0)\n    batch_frames = tf.expand_dims(num_frames, 0)\n\n    return batch_video_ids, batch_video_matrix, batch_labels, batch_frames"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a17d6a70-c092-ce25-134e-e19de0dea87e"},"outputs":[],"source":"prepare_serialized_examples(self, serialized_example,max_quantized_value=2, min_quantized_value=-2)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d4e1871-e66b-d164-d92e-41d4c59b659b"},"outputs":[],"source":"list_mean_audio=list(tf_example.features.feature['mean_audio'].float_list.value)\nlist_mean_audio\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c04d133e-88ce-f91c-b4ca-ce533deea3f6"},"outputs":[],"source":"len(list_mean_audio)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3159839b-6f1c-fe48-0751-d7603660b1c8"},"outputs":[],"source":"list_mean_rgb=list(tf_example.features.feature['mean_rgb'].float_list.value)\nlist_mean_rgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06571324-2ee9-fe95-2ad5-db42ba4db127"},"outputs":[],"source":"len(list_mean_rgb)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36544c0f-9306-0a66-cbd5-8f72ad47274c"},"outputs":[],"source":"for example in tf.python_io.tf_record_iterator(\"../input/video_level/train-1.tfrecord\"):\n    total_sample_counter += 1\n    tf_example2 = tf.train.Example.FromString(example)\ntf_example2"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eefbcb8-87d8-14a7-2e1d-994dac60ffe8"},"outputs":[],"source":"for example in tf.python_io.tf_record_iterator(\"../input/video_level/train-2.tfrecord\"):\n    total_sample_counter += 1\n    tf_example3 = tf.train.Example.FromString(example)\ntf_example3"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a32425ce-1c54-7f26-e65f-944b8704becb"},"outputs":[],"source":"for example in tf.python_io.tf_record_iterator(\"../input/video_level/train-7.tfrecord\"):\n    total_sample_counter += 1\n    tf_example8 = tf.train.Example.FromString(example)\ntf_example8"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b92323d-77f8-e311-1f8f-0156763cd1c2"},"outputs":[],"source":"label_example = list(tf_example1.features.feature['labels'].int64_list.value)\nlabel_example"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e7e66dd-4be7-35ee-4e78-658299cc83f0"},"outputs":[],"source":"len(label_example)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92d29706-1827-cc29-cf8d-215b23de0358"},"outputs":[],"source":"label_counts.append(len(label_example))\nlabels = labels + label_example\nlabel_example_textual = list(labels_df[labels_df['label_id'].isin(label_example)]['label_name'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b1ef208-304a-aa1e-5077-afdc29b7d2a2"},"outputs":[],"source":"label_counts"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ad26738-23e5-4791-cf28-30a8ef18a900"},"outputs":[],"source":"labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7c3bce6-1abf-cdd6-3426-0609d8538557"},"outputs":[],"source":"labels_df['label_name']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bcbd8f2-f0ce-399e-5ac1-bbaf58b0df5b"},"outputs":[],"source":"label_example_textual "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2769a4f4-0b17-58f2-0856-b3757a6abfe7"},"outputs":[],"source":"set(label_example_textual)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d5b5645-4c7f-6e6b-4e21-9596b30491aa"},"outputs":[],"source":"textual_labels_nested"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59e94de4-0397-f827-d02b-9b2a9e06e0c3"},"outputs":[],"source":"textual_labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3190a11e-3919-2906-c8bb-891d4ce3e172"},"outputs":[],"source":"pd.DataFrame({'label': textual_labels}).groupby('label').size()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05e8afb1-ea91-34fe-c3a5-1283876230ea"},"outputs":[],"source":"def grouped_data_for(l):\n    # wrap the grouped data into dataframe, since the inner is pd.Series, not what we need\n    l_with_c = pd.DataFrame(\n        pd.DataFrame({'label': l}).groupby('label').size().rename('n')\n    ).sort_values('n', ascending=False).reset_index()\n    return l_with_c"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"035a8745-d4b5-aff4-e1cd-c72c4a977939"},"outputs":[],"source":"N = 20\n\ntextual_labels_with_counts_all = grouped_data_for(textual_labels)\ntextual_labels_with_counts_all"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18320eef-ec8a-3832-b856-7946962f565e"},"outputs":[],"source":"type(textual_labels_with_counts_all['label'][0:50].values)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a446edbe-887a-8d0c-9e29-d38dcae1de84"},"outputs":[],"source":"top_50_labels = list(textual_labels_with_counts_all['label'][0:50].values)\ntop_50_labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cefb50d-90b4-6a0d-1543-e7dc779fc00a"},"outputs":[],"source":"easy_install youtubevideo"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cee05ac5-5d2e-535d-bc91-ee3d226a9eaf"},"outputs":[],"source":"\ndef play_one_vid(record_name, video_index):\n    return vid_ids[video_index]\n    \n# this worked on my local jupyter notebook, but doesn't show on kaggle kernels:\nYouTubeVideo(play_one_vid(example, 7))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"082f7a2e-7b12-e291-244f-b8ef8ffccf4c"},"outputs":[],"source":"import tensorflow as tf\nimport numpy as np\nfrom IPython.display import YouTubeVideo\n\n\nvideo_lvl_record = \"../input/video_level/train-1.tfrecord\"\nframe_lvl_record = \"../input/frame_level/train-1.tfrecord\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d324c71-acc7-c16f-3168-a6c84cca26e2"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32812214-011e-bbcc-1063-e674fe79e050"},"outputs":[],"source":"vid_ids = []\nlabels = []\nmean_rgb = []\nmean_audio = []\n\nfor example in tf.python_io.tf_record_iterator(video_lvl_record):\n    tf_example = tf.train.Example.FromString(example)\n\n    vid_ids.append(tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8'))\n    labels.append(tf_example.features.feature['labels'].int64_list.value)\n    mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n    mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05df3785-70ed-ab7a-2566-a1c374a4ad5b"},"outputs":[],"source":"for example in tf.python_io.tf_record_iterator(video_lvl_record):\n    tf_example = tf.train.Example.FromString(example)\ntf_example"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab6178e2-b3fb-b7ac-dc54-9b86769552bf"},"outputs":[],"source":"n=10\nfrom collections import Counter\nlabel_mapping = pd.Series.from_csv('../input/label_names.csv',header=0).to_dict()\n\ntop_n = Counter([item for sublist in labels for item in sublist]).most_common(n)\ntop_n_labels = [int(i[0]) for i in top_n]\ntop_n_label_names = [label_mapping[x] for x in top_n_labels]\ntop_n_label_names"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84c057c7-9711-61f0-d9ae-74248373ec2c"},"outputs":[],"source":"type(top_n_label_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eebcd879-813e-f35a-b7a7-9d31bf25dbe1"},"outputs":[],"source":"list(labels)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12b486da-3b35-9452-ed2c-e0181be84d9b"},"outputs":[],"source":"\nimport networkx as nx\nfrom itertools import combinations\n\nG=nx.Graph()\n\nG.clear()\nfor list_of_nodes in labels:\n    filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels))  \n    for node1,node2 in list(combinations(filtered_nodes,2)): \n        node1_name = label_mapping[node1]\n        node2_name = label_mapping[node2]\n        G.add_node(node1_name)\n        G.add_node(node2_name)\n        G.add_edge(node1_name, node2_name)\n\nnx.draw_networkx(G)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe822305-6f53-6fcd-1a52-33cc40fcc9fe"},"outputs":[],"source":"filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels)) \nfiltered_nodes\nset(list_of_nodes)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07ba206f-6371-89ba-f701-924be4a1acf3"},"outputs":[],"source":"count=0\nnum=0\nfor list_of_nodes in labels:\n    filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels))  \n    print (len(list(combinations(filtered_nodes,3))))\n    print ('abc', num)\n    num+=1\n    for node1 in list(combinations(filtered_nodes,3)): \n        print('nodes', node1, node2)\n        count+=1\nprint (count)        \n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92a45e73-b619-945d-a044-53aea83e6ab1"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom IPython.display import YouTubeVideo\nfrom subprocess import check_output\n\nlabels = pd.read_csv('../input/label_names.csv') #4716 labels\n\ncols_rgb = [\"rgb_{}\".format(i) for i in range(1024)]\ncols_aud = [\"aud_{}\".format(i) for i in range(128)]\ncols_y   = [\"y_{}\".format(i) for i in range(4716 + 1)]\n\nusevidlvl = True\nusefralvl = False"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86664ece-0990-e682-3f7e-6933fbbbf1a7"},"outputs":[],"source":"#PREPROCESSING\n\n#homemade \"dataframfy\" method\ndef dffy(filenames):\n    index = []\n    rgb = []\n    aud = []\n    y = []\n    if len(filenames)>0:\n        isVideo = filenames[0].find(\"video\")!=-1\n\n    for filename in filenames:\n        for example in tf.python_io.tf_record_iterator(filename):\n            tf_example = tf.train.Example.FromString(example)\n            index.append(tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8'))\n            if isVideo:\n                rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n                aud.append(tf_example.features.feature['mean_audio'].float_list.value)\n            else:\n                rgb.append(tf_example.features.feature['rgb'].float_list.value)\n                aud.append(tf_example.features.feature['audio'].float_list.value)\n            y.append(np.array(tf_example.features.feature['labels'].int64_list.value))\n            \n    index = pd.DataFrame(np.array(index),columns=[\"id\"])\n    rgb = pd.DataFrame(np.array(rgb),columns=cols_rgb)\n    aud = pd.DataFrame(np.array(aud),columns=cols_aud)\n    y2 = pd.DataFrame(np.zeros((len(index),len(labels) + 1)))\n    for i in range(len(y)):\n        y2.loc[i,y[i].clip(0,len(labels))] = 1\n    y2.columns=cols_y\n    y = []\n    \n    return [index,rgb,aud,y2]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3dbb4b6f-482a-eda3-771a-53055cdc1a93"},"outputs":[],"source":"if usevidlvl:\n    vidfilenames = [\"../input/video_level/train-{}.tfrecord\".format(i) for i in range(10)]\n    [vid_id,vid_rgb,vid_aud,vid_y] = dffy(vidfilenames)\n\nif usefralvl:\n    frafilenames = [\"../input/frame_level/train-{}.tfrecord\".format(i) for i in range(10)]\n    [fra_id,fra_rgb,fra_aud,fra_y] = dffy(frafilenames)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43738e77-deb3-e766-085b-1bf157db8959"},"outputs":[],"source":"[vid_id,vid_rgb,vid_aud,vid_y]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80334df4-116e-bf4e-a6b4-ce7eba24f8f7"},"outputs":[],"source":"vid_rgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"405d4d66-d05c-e3b6-cf41-ccdf0325bb8a"},"outputs":[],"source":"vid_aud"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2bb926fe-75cb-6dec-2a12-e75a0e68811a"},"outputs":[],"source":"vid_aud.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1382133-d189-8d63-76b7-aa15851a4b41"},"outputs":[],"source":"vid_y"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1fbe4bd-8bef-bcca-46da-90218f6020b8"},"outputs":[],"source":"usefralvl = True\nif usefralvl:\n    frafilenames = [\"../input/frame_level/train-{}.tfrecord\".format(i) for i in range(10)]\n    [fra_id,fra_y] = dffy(frafilenames)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8032a96c-9a61-9c75-41da-4fb9ccc42607"},"outputs":[],"source":"fra_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea98129e-b42a-df50-85a3-008a9a2c57b2"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}