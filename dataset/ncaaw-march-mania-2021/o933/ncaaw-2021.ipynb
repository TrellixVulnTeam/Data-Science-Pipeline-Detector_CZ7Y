{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import itertools, gc\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport xgboost\nimport lightgbm\nimport catboost\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nINPUT_PATH = '../input/ncaaw-march-mania-2021/WDataFiles_Stage2'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_key(seed, col):\n    return seed['Season'].astype(str) + '_' + seed[col].astype(str)\n\ndef make_slot():\n    slot = pd.read_csv('{}/WNCAATourneySlots.csv'.format(INPUT_PATH))\n    slot['Round'] = slot['Slot'].str[1].astype(int)\n    rounds = slot[slot['Round'] == 1].copy()\n    rounds.rename(columns={'Slot': 1}, inplace=True)\n    rounds.drop('Round', axis=1, inplace=True)\n\n    slot_uppers = slot[slot['Round'] > 1]\n    strong_map = slot_uppers.set_index('StrongSeed')['Slot']\n    weak_map = slot_uppers.set_index('WeakSeed')['Slot']\n\n    for i in range(2, 7):\n        before_slot = rounds[i - 1]\n\n        after_col = i\n        rounds[after_col] = before_slot.map(strong_map)\n        rounds.loc[rounds[after_col].isnull(), after_col] = before_slot.map(weak_map)\n\n    rounds.set_index(list(range(1, 7)), inplace=True)\n    rounds = pd.concat([rounds['StrongSeed'].rename('Seed'), rounds['WeakSeed'].rename('Seed')]).to_frame()\n    rounds.reset_index(inplace=True)\n    rounds.sort_values('Seed', inplace=True)\n    rounds.set_index('Seed', inplace=True)\n    \n    stack = rounds.stack().to_frame()\n    stack.reset_index(inplace=True)\n    stack.columns = ['Seed', 'Round', 'Slot']\n    \n    unique = stack['Seed'].unique()\n    product = pd.DataFrame(list(itertools.product(unique, unique)), columns=['T_Seed', 'O_Seed'])\n    product = product[product['T_Seed'] != product['O_Seed']]\n\n    t = pd.merge(product, stack.rename(columns={'Seed': 'T_Seed'}), on='T_Seed', how='left')\n    t.drop('Round', axis=1, inplace=True)\n    t = pd.merge(t, stack.rename(columns={'Seed': 'O_Seed'}), on=['O_Seed', 'Slot'], how='left')\n    t.dropna(inplace=True)\n    t['Round'] = t['Round'].astype(int)\n    return t.groupby(['T_Seed', 'O_Seed'], as_index=False).min()\n\nseason = pd.read_csv('{}/WSeasons.csv'.format(INPUT_PATH), parse_dates=['DayZero'])\nseason.set_index('Season', inplace=True)\nprint('season:', season.shape)\ndisplay(season.head())\n\nseed = pd.read_csv('{}/WNCAATourneySeeds.csv'.format(INPUT_PATH))\nseed['Key'] = make_key(seed, 'TeamID')\nseed['SeedNo'] = seed['Seed'].str[1:].astype(int)\nseed.set_index('Key', inplace=True)\nprint('seed:', seed.shape)\ndisplay(seed.head())\n\nslot = make_slot()\nprint('slot:', slot.shape)\ndisplay(slot.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_compact(f):\n    f.sort_values(['Season', 'DayNum'], inplace=True)\n\n    f['LLoc'] = 'N'\n    f.loc[f['WLoc'] == 'H', 'LLoc'] = 'A'\n    f.loc[f['WLoc'] == 'A', 'LLoc'] = 'H'\n    \n    sides = []\n    for v1, v2 in [('W', 'L'), ('L', 'W')]:\n        f['{}ScoreDiff'.format(v1)] = f['{}Score'.format(v1)] - f['{}Score'.format(v2)]\n        \n        cols = ['{}TeamID'.format(v1), '{}TeamID'.format(v2), '{}Score'.format(v1), '{}ScoreDiff'.format(v1), '{}Loc'.format(v1)]\n        side = f[cols].copy()\n        side.columns = ['TeamID', 'OpponentID', 'Score', 'ScoreDiff', 'Loc']\n        side['Judge'] = 1 if v1 == 'W' else 0\n        sides.append(side)\n    \n    cols = ['Season', 'DayNum', 'NumOT']\n    for side in sides:\n        side[cols] = f[cols]\n\n    new_f = pd.concat(sides)\n\n    new_f['Loc'] = new_f['Loc'].map({'H': 1, 'N': 0, 'A': -1})\n\n    new_keys = ['Season', 'DayNum', 'TeamID', 'OpponentID']\n    new_f.set_index(new_keys, inplace=True)\n    new_f.sort_index(inplace=True)\n    new_f.reset_index(inplace=True)\n\n    return new_f\n\ndef convert_detail(f):\n    f.sort_values(['Season', 'DayNum'], inplace=True)\n    f.drop(['WScore', 'LScore', 'WLoc', 'NumOT'], axis=1, inplace=True)\n\n    sides = []\n    for v1, v2 in [('W', 'L'), ('L', 'W')]:\n        from_cols = ['{}TeamID'.format(v1), '{}TeamID'.format(v2)]\n        to_cols = ['TeamID', 'OpponentID']\n        bases = ['FGM', 'FTM', 'FTA', 'OR', 'DR', 'Ast', 'Blk']\n        for base in bases:\n            for v, i in [(v1, 'T')]:\n                from_cols.append('{}{}'.format(v1, base))\n                to_cols.append(base)\n\n        side = f[from_cols].copy()\n        side.columns = to_cols\n        sides.append(side)\n    \n    for side in sides:\n        side[['Season', 'DayNum']] = f[['Season', 'DayNum']]\n\n    new_f = pd.concat(sides)\n    new_keys = ['Season', 'DayNum', 'TeamID', 'OpponentID']\n    new_f.set_index(new_keys, inplace=True)\n    new_f.sort_index(inplace=True)\n    new_f.reset_index(inplace=True)\n    \n    return new_f\n\ndef add_match_features(f, seed, slot):\n    t_key = make_key(f, 'TeamID')\n    o_key = make_key(f, 'OpponentID')\n\n    f['T_Seed'] = t_key.map(seed['Seed']).fillna('A17')\n    f['O_Seed'] = o_key.map(seed['Seed']).fillna('A17')\n    f['T_SeedNo'] = t_key.map(seed['SeedNo']).fillna(17).astype(int)\n    f['O_SeedNo'] = o_key.map(seed['SeedNo']).fillna(17).astype(int)\n    f['M_SeedNoDiff'] = f['O_SeedNo'] - f['T_SeedNo']\n\n    f = pd.merge(f, slot[['T_Seed', 'O_Seed', 'Round']], on=['T_Seed', 'O_Seed'], how='left')\n    f['Round'] = f['Round'].fillna(0).astype(int)\n\n    return f\n\ndef make_strong(f, period, size, target_round):\n    strongs = []\n    for season in range(f['Season'].min() + period - 1, f['Season'].max() + 1):\n        begin, end = season - period, season - 1\n        target = f[f['Season'].between(begin, end)]\n    \n        s =  target[target['Round'] >= target_round]\n        s = s[['TeamID', 'Judge']].groupby('TeamID').agg({'Judge': ('mean', 'count')})\n        s.columns = ['Mean', 'Count']\n        s = s[(s['Mean'] > 0.0)]\n\n        s = target[target['TeamID'].isin(s.index.values)].copy()\n        s['StrongPoint'] = s['Judge'] * s['Round']\n        s = s[['TeamID', 'StrongPoint']].groupby('TeamID', as_index=False).mean()\n        s.sort_values('StrongPoint', ascending=False, inplace=True)\n        s = s[:size]\n        s['Season'] = season\n        s['Strong'] = np.flipud(range(1, size + 1))\n\n        strongs.append(s)\n\n    strong = pd.concat(strongs)\n    strong['Key'] = make_key(strong, 'TeamID')\n    strong.set_index('Key', inplace=True)\n    \n    return strong\n\ndef load_and_convert(key, seed, slot):\n    c = pd.read_csv('{}/W{}CompactResults.csv'.format(INPUT_PATH, key))\n    c = convert_compact(c)\n    c = add_match_features(c, seed, slot)\n    \n    d = pd.read_csv('{}/W{}DetailedResults.csv'.format(INPUT_PATH, key))\n    d = convert_detail(d)\n    \n    return pd.merge(c, d, on=['Season', 'DayNum', 'TeamID', 'OpponentID'], how='left')\n\ntourney = load_and_convert('NCAATourney', seed, slot)\nprint('tourney:', tourney.shape)\ndisplay(tourney.head())\n\nregular = load_and_convert('RegularSeason', seed, slot)\nregular['Round'] = 0\nprint('regular:', regular.shape)\ndisplay(regular.head())\n\nstrong = make_strong(tourney, 8, 5, 4)\nprint('strong:', strong.shape)\ndisplay(strong.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_team_features(m, strong):\n    t_key = make_key(m, 'TeamID')\n    o_key = make_key(m, 'OpponentID')\n\n    m['T_Strong'] = t_key.map(strong['Strong']).fillna(0)\n    m['O_Strong'] = o_key.map(strong['Strong']).fillna(0)\n\n    return m\n\ndef make_match(f, seed, slot, strong, tt):\n    m = pd.DataFrame()\n    \n    keys = ['Season', 'TeamID', 'OpponentID']\n    m[keys] = f[keys]\n\n    m = add_match_features(m, seed, slot)\n    m = add_team_features(m, strong)\n\n    if tt == 'train':\n        m['Judge'] = f['Judge']\n\n    return m\n\ntourney_match = make_match(tourney, seed, slot, strong, 'train')\nprint('tourney_match:', tourney_match.shape)\ndisplay(tourney_match.head())\n\nregular_match = make_match(regular, seed, slot, strong, 'train')\nregular_match = regular_match[(regular_match['T_SeedNo'] <= 4) & (regular_match['O_SeedNo'] <= 4)]\nprint('regular_match:', regular_match.shape)\ndisplay(regular_match.head())\n\nsubmission = pd.read_csv('{}/WSampleSubmissionStage2.csv'.format(INPUT_PATH))\nsub_key = submission['ID'].str.split('_', expand=True).astype(int)\nsub_key.columns = ['Season', 'TeamID', 'OpponentID']\nsub_feature = make_match(sub_key, seed, slot, strong, 'predict')\nprint('sub_feature:', sub_feature.shape)\ndisplay(sub_feature.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_data(f, tt, scaler=None):\n    x = f.set_index(['Season', 'TeamID', 'OpponentID'])\n    x.drop(['Round', 'T_Seed', 'O_Seed'], axis=1, inplace=True)\n \n    if tt != 'predict':\n        y = x['Judge']\n        x.drop('Judge', axis=1, inplace=True)\n    \n    if scaler is None:\n        scaler = StandardScaler()\n        scaler.fit(x)\n    x = scaler.transform(x)\n    \n    if tt == 'predict':\n        return x, None, scaler\n\n    y = y.values\n    \n    return x, y, scaler\n\ndef learns(params, data, models):\n    train_x, train_y, scaler = make_data(data['train'], 'train')\n    test_x, test_y, scaler = make_data(data['test'], 'test', scaler)\n    pred_x, _, _ = make_data(data['pred'], 'predict', scaler)\n    \n    result = {'train': {}, 'test': {}, 'pred': {}}\n    for tt in ['train', 'test', 'pred']:\n        result[tt]['pred'] = pd.DataFrame()\n        result[tt]['score'] = []\n\n    print('  ', train_x.shape, train_y.shape)    \n        \n    for name, model in models:\n        state = params[name]['random_state']\n\n        x = pd.DataFrame(train_x).sample(frac=1.0, random_state=state).values\n        y = pd.DataFrame(train_y.reshape(-1, 1)).sample(frac=1.0, random_state=state).values[:, 0]            \n        \n        if name in ['xgb', 'lgbm', 'catboost']:\n            x = np.concatenate([x, pd.DataFrame(x).sample(frac=0.01, random_state=state).values])\n            y = np.concatenate([y, pd.DataFrame(y.reshape(-1, 1)).sample(frac=0.01, random_state=state).values[:, 0]])\n            model.fit(x, y, eval_set=[(test_x, test_y)], verbose=0)\n        else:\n            model.fit(x, y)\n\n        result['train']['pred'][name] = model.predict_proba(train_x)[:, 1]\n        result['train']['score'].append((name, log_loss(train_y, result['train']['pred'][name].values)))\n\n        result['test']['pred'][name] = model.predict_proba(test_x)[:, 1]\n        result['test']['score'].append((name, log_loss(test_y, result['test']['pred'][name].values)))\n        \n        result['pred']['pred'][name] = model.predict_proba(pred_x)[:, 1]\n\n        print('    ', result['train']['score'][-1], result['test']['score'][-1])\n\n    result['train']['score'] = pd.DataFrame(result['train']['score'], columns=['model_name', 'score'])\n    result['test']['score'] = pd.DataFrame(result['test']['score'], columns=['model_name', 'score'])\n    \n    return result\n\ndef make_models(names, params):\n    models = []\n    for name in names:\n        if name == 'extra_trees':\n            models.append(('extra_trees', ExtraTreesClassifier(**params['extra_trees'])))\n        elif name == 'random_forest':\n            models.append(('random_forest', RandomForestClassifier(**params['random_forest'])))\n        elif name == 'xgb':\n            models.append(('xgb', xgboost.XGBClassifier(**params['xgb'])))\n        elif name == 'lgbm':\n            models.append(('lgbm', lightgbm.LGBMClassifier(**params['lgbm'])))\n        elif name == 'catboost':\n            models.append(('catboost', catboost.CatBoostClassifier(verbose=0, **params['catboost'])))\n\n    return models\n\ndef learn_seasons(models, params, test_seasons, target_seasons, tourney_seasons, regular_seasons, ignores, mix_size=0):\n    data = {}\n    train = pd.concat([\n        tourney_match[tourney_match['Season'].isin(tourney_seasons)],\n        regular_match[regular_match['Season'].isin(regular_seasons)]\n    ])\n\n    for season, rounds in ignores:\n        for r in rounds:\n            \n            condition = (train['Season'] == season) & (train['Round'] == r)\n            train = train[~condition]\n\n    data['train'] = train\n    data['test'] = tourney_match[tourney_match['Season'].isin(test_seasons)].copy()\n    data['pred'] = sub_feature[sub_feature['Season'].isin(target_seasons)].copy()\n\n    for tt in ['train', 'test', 'pred']:\n        data[tt].reset_index(drop=True, inplace=True)\n\n    result = learns(params, data, models)\n\n    rank = result['test']['score'].groupby('model_name').mean().sort_values('score')\n\n    for tt in ['train', 'test', 'pred']:\n        result[tt]['pred'].reset_index(drop=True, inplace=True)\n        \n        if mix_size <= 0:\n            mix_size = rank.shape[0]\n\n        data[tt]['Pred'] = result[tt]['pred'][rank.index[0:mix_size]].mean(axis=1)\n\n        data[tt].loc[data[tt]['M_SeedNoDiff'] >= 10, 'Pred'] = 1.0\n        data[tt].loc[data[tt]['M_SeedNoDiff'] <= -10, 'Pred'] = 0.0\n        data[tt].loc[(data[tt]['Round'] == 2) & (data[tt]['T_SeedNo'] == 1), 'Pred'] = 1.0\n        data[tt].loc[(data[tt]['Round'] == 2) & (data[tt]['O_SeedNo'] == 1), 'Pred'] = 0.0\n\n        data[tt].sort_values(['Season', 'TeamID', 'OpponentID'], inplace=True)\n        data[tt].reset_index(drop=True, inplace=True)\n\n        if tt == 'test':\n            result[tt]['last_score'] = log_loss(data[tt]['Judge'].astype(np.float64), data[tt]['Pred'].astype(np.float64))\n            print('mean:', result[tt]['last_score'])\n\n    return data, result\n\ndef learn_states(file_name, random_states, mix_size, sub):\n    last = {\n        'test': [],\n        'pred': [],\n        'score': [],\n        'mix_size': mix_size,\n    }\n\n    for state in random_states:\n        model_names = ['extra_trees', 'random_forest', 'xgb', 'lgbm', 'catboost']\n\n        for name in model_names:\n            params[name].update({'random_state': state})\n\n        models = make_models(model_names, params)\n\n        data, result = learn_seasons(models, params, test_seasons, target_seasons, tourney_seasons, regular_seasons, ignores, mix_size)\n\n        last['test'].append(data['test']['Pred'])\n        last['pred'].append(data['pred']['Pred'])\n        last['score'].append(result['test']['last_score'])\n\n        del data, result\n        gc.collect()\n\n    last_pred = pd.DataFrame()\n    for i, p in enumerate(last['pred']):\n        last_pred[i] = p\n\n    sub['Pred'] = last_pred.mean(axis=1)\n    \n    print('last score:', np.mean(last['score']))\n    \n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = { \n    'extra_trees': {\n        'n_estimators': 1400,\n        'max_depth': 22,\n        'max_features': 2,\n        'min_samples_leaf': 1,\n        'min_samples_split': 2,\n        'min_impurity_split': 0.21,\n        'criterion': 'entropy',\n    },\n    'random_forest': {\n        'n_estimators': 1200,\n        'max_depth': 21,\n        'max_features': 2,\n        'min_samples_leaf': 1,\n        'min_samples_split': 2,\n        'criterion': 'gini',\n    },\n    'xgb': {\n        'n_estimators': 20000,\n        'early_stopping_rounds': 512,\n        'learning_rate': 0.045,\n        'max_depth': 3,\n        'max_delta_step': 0.7,\n    },\n    'lgbm': {\n        'n_estimators': 20000,\n        'early_stopping_rounds': 512,\n        'learning_rate': 0.034,\n        'feature_fraction': 0.8,\n    },\n    'catboost': {\n        'n_estimators': 20000,\n        'early_stopping_rounds': 512,\n        'learning_rate': 0.03,\n        'max_depth': 6,\n        'l2_leaf_reg': 3,\n        'subsample': 0.85,\n        'use_best_model': True,\n    },\n#     'extra_trees': {\n#         'max_depth': 12,\n#     },\n#     'random_forest': {\n#     },\n#     'xgb': {\n#     },\n#     'lgbm': {\n#     },\n#     'catboost': {\n#     },\n}\n\n\n\nsubs = []\nfor move_seasons in [[2016, 2017], [2018, 2019], [2016, 2018], [2017, 2019]]:\n    target_seasons = [2021]\n    test_seasons = [2016, 2017, 2018, 2019]\n    tourney_seasons = [1998, 1999, 2000, 2001, 2002, 2003, 2004, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n    regular_seasons = [1998, 1999, 2000, 2001, 2004, 2006, 2008, 2010, 2013, 2014, 2015]\n\n    ignores = [\n        (1998, [2, 3, 6]), (1999, [2, 3, 5]), (2001, [3]), (2003, [1, 4]), (2007, [1, 3, 4]), (2009, [2, 3, 5]),\n        (2010, [1, 3]), (2011, [2, 4]), (2012, [1, 4])\n    ]\n\n    random_states = range(48, 64)\n\n    for move_season in move_seasons:\n        test_seasons.remove(move_season)\n        tourney_seasons.append(move_season)\n        regular_seasons.append(move_season)\n    \n    print('====', test_seasons, '====')\n\n    sub = learn_states('subs_state8_mix1.csv', random_states, 1, submission.copy())\n    subs.append(sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_mixs = pd.concat(subs)\nsub_mixs = sub_mixs.groupby('ID').mean()\nsub_mixs.to_csv('submission.csv')\nsub_mixs.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}