{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 2nd place solution of the 2021 NCAAW Competition\n\nSolution write-up is available here : https://www.kaggle.com/c/ncaaw-march-mania-2021/discussion/230705"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport sklearn\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\nfrom sklearn.metrics import *\nfrom sklearn.linear_model import *\nfrom sklearn.model_selection import *\n\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/ncaaw-march-mania-2021/WDataFiles_Stage2/'\n\nfor filename in os.listdir(DATA_PATH):\n    print(filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preparation"},{"metadata":{},"cell_type":"markdown","source":"## Seeds\n> This file identifies the seeds for all teams in each NCAA® tournament, for all seasons of historical data. Thus, there are between 64-68 rows for each year, depending on whether there were any play-in games and how many there were. In recent years the structure has settled at 68 total teams, with four \"play-in\" games leading to the final field of 64 teams entering Round 1 on Thursday of the first week (by definition, that is DayNum=136 each season). We will not know the seeds of the respective tournament teams, or even exactly which 68 teams it will be, until Selection Sunday on March 15, 2020 (DayNum=132).\n\n> The seed is a 3/4-character :\n- First character : Region (W, X, Y, or Z)\n- Next two digits : Seed within the region (01 to 16)\n- Last character (optional): Distinguishes teams between play-ins ( a or b)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_seeds = pd.read_csv(DATA_PATH + \"WNCAATourneySeeds.csv\")\ndf_seeds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Season results\n> This file identifies the game-by-game results for many seasons of historical data, starting with the 1985 season (the first year the NCAA® had a 64-team tournament). For each season, the file includes all games played from DayNum 0 through 132. It is important to realize that the \"Regular Season\" games are simply defined to be all games played on DayNum=132 or earlier (DayNum=132 is Selection Sunday, and there are always a few conference tournament finals actually played early in the day on Selection Sunday itself). Thus a game played on or before Selection Sunday will show up here whether it was a pre-season tournament, a non-conference game, a regular conference game, a conference tournament game, or whatever."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_season_results = pd.read_csv(DATA_PATH + \"WRegularSeasonCompactResults.csv\")\ndf_season_results.drop(['NumOT', 'WLoc'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_season_results['ScoreGap'] = df_season_results['WScore'] - df_season_results['LScore']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_season_results.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features \nFor each team at each season, I compute : \n- Number of wins\n- Number of losses\n- Average score gap of wins\n- Average score gap of losses\n\nAnd use the following features : \n- Win Ratio\n- Average score gap"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_win = df_season_results.groupby(['Season', 'WTeamID']).count()\nnum_win = num_win.reset_index()[['Season', 'WTeamID', 'DayNum']].rename(columns={\"DayNum\": \"NumWins\", \"WTeamID\": \"TeamID\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_loss = df_season_results.groupby(['Season', 'LTeamID']).count()\nnum_loss = num_loss.reset_index()[['Season', 'LTeamID', 'DayNum']].rename(columns={\"DayNum\": \"NumLosses\", \"LTeamID\": \"TeamID\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_win = df_season_results.groupby(['Season', 'WTeamID']).mean().reset_index()\ngap_win = gap_win[['Season', 'WTeamID', 'ScoreGap']].rename(columns={\"ScoreGap\": \"GapWins\", \"WTeamID\": \"TeamID\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_loss = df_season_results.groupby(['Season', 'LTeamID']).mean().reset_index()\ngap_loss = gap_loss[['Season', 'LTeamID', 'ScoreGap']].rename(columns={\"ScoreGap\": \"GapLosses\", \"LTeamID\": \"TeamID\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_season_w = df_season_results.groupby(['Season', 'WTeamID']).count().reset_index()[['Season', 'WTeamID']].rename(columns={\"WTeamID\": \"TeamID\"})\ndf_features_season_l = df_season_results.groupby(['Season', 'LTeamID']).count().reset_index()[['Season', 'LTeamID']].rename(columns={\"LTeamID\": \"TeamID\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_season = pd.concat([df_features_season_w, df_features_season_l], 0).drop_duplicates().sort_values(['Season', 'TeamID']).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_season = df_features_season.merge(num_win, on=['Season', 'TeamID'], how='left')\ndf_features_season = df_features_season.merge(num_loss, on=['Season', 'TeamID'], how='left')\ndf_features_season = df_features_season.merge(gap_win, on=['Season', 'TeamID'], how='left')\ndf_features_season = df_features_season.merge(gap_loss, on=['Season', 'TeamID'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_season.fillna(0, inplace=True)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compute features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_season['WinRatio'] = df_features_season['NumWins'] / (df_features_season['NumWins'] + df_features_season['NumLosses'])\ndf_features_season['GapAvg'] = (\n    (df_features_season['NumWins'] * df_features_season['GapWins'] - \n    df_features_season['NumLosses'] * df_features_season['GapLosses'])\n    / (df_features_season['NumWins'] + df_features_season['NumLosses'])\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_season.drop(['NumWins', 'NumLosses', 'GapWins', 'GapLosses'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tourney results\n\n> This file identifies the game-by-game NCAA® tournament results for all seasons of historical data. The data is formatted exactly like the MRegularSeasonCompactResults data. All games will show up as neutral site (so WLoc is always N). Note that this tournament game data also includes the play-in games (which always occurred on day 134/135) for those years that had play-in games. Thus each season you will see between 63 and 67 games listed, depending on how many play-in games there were."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tourney_results = pd.read_csv(DATA_PATH + \"WNCAATourneyCompactResults.csv\")\ndf_tourney_results.drop(['NumOT', 'WLoc'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FiveThirtyEight Ratings\n> Thanks to Raddar ! https://www.kaggle.com/raddar/ncaa-women-538-team-ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_538 = pd.read_csv(\"../input/ncaa-women-538-team-ratings/538ratingsWomen.csv\")\ndf_538.drop('TeamName', axis=1, inplace=True)\n\ndf_538.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_tourney_results.copy()\ndf = df[df['Season'] >= 2016].reset_index(drop=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seeds\n- `SeedW` is the seed of the winning team\n- `SeedL` is the seed of the losing team"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(\n    df, \n    df_seeds, \n    how='left', \n    left_on=['Season', 'WTeamID'], \n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'Seed': 'SeedW'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(\n    df, \n    df_seeds, \n    how='left', \n    left_on=['Season', 'LTeamID'], \n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'Seed': 'SeedL'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def treat_seed(seed):\n    return int(re.sub(\"[^0-9]\", \"\", seed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SeedW'] = df['SeedW'].apply(treat_seed)\ndf['SeedL'] = df['SeedL'].apply(treat_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Season Stats\n- `WinRatioW` is the win ratio of the winning team during the season\n- `WinRatioL` is the win ratio of the losing team during the season"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(\n    df,\n    df_features_season,\n    how='left',\n    left_on=['Season', 'WTeamID'],\n    right_on=['Season', 'TeamID']\n).rename(columns={\n    'NumWins': 'NumWinsW',\n    'NumLosses': 'NumLossesW',\n    'GapWins': 'GapWinsW',\n    'GapLosses': 'GapLossesW',\n    'WinRatio': 'WinRatioW',\n    'GapAvg': 'GapAvgW',\n}).drop(columns='TeamID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(\n    df,\n    df_features_season,\n    how='left',\n    left_on=['Season', 'LTeamID'],\n    right_on=['Season', 'TeamID']\n).rename(columns={\n    'NumWins': 'NumWinsL',\n    'NumLosses': 'NumLossesL',\n    'GapWins': 'GapWinsL',\n    'GapLosses': 'GapLossesL',\n    'WinRatio': 'WinRatioL',\n    'GapAvg': 'GapAvgL',\n}).drop(columns='TeamID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FiveThirtyEight Ratings\n- `538ratingW` is the rating of the winning team during the season\n- `538ratingL` is the rating of the losing team during the season"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(\n    df,\n    df_538,\n    how='left',\n    left_on=['Season', 'WTeamID'],\n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'538rating': '538ratingW'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(\n    df, \n    df_538, \n    how='left', \n    left_on=['Season', 'LTeamID'], \n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'538rating': '538ratingL'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add symetrical\n- Right now our data only consists of won matches\n- We duplicate our data, get rid of the winner loser "},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_loosing_matches(df):\n    win_rename = {\n        \"WTeamID\": \"TeamIdA\", \n        \"WScore\" : \"ScoreA\", \n        \"LTeamID\" : \"TeamIdB\",\n        \"LScore\": \"ScoreB\",\n     }\n    win_rename.update({c : c[:-1] + \"A\" for c in df.columns if c.endswith('W')})\n    win_rename.update({c : c[:-1] + \"B\" for c in df.columns if c.endswith('L')})\n    \n    lose_rename = {\n        \"WTeamID\": \"TeamIdB\", \n        \"WScore\" : \"ScoreB\", \n        \"LTeamID\" : \"TeamIdA\",\n        \"LScore\": \"ScoreA\",\n    }\n    lose_rename.update({c : c[:-1] + \"B\" for c in df.columns if c.endswith('W')})\n    lose_rename.update({c : c[:-1] + \"A\" for c in df.columns if c.endswith('L')})\n    \n    win_df = df.copy()\n    lose_df = df.copy()\n    \n    win_df = win_df.rename(columns=win_rename)\n    lose_df = lose_df.rename(columns=lose_rename)\n    \n    return pd.concat([win_df, lose_df], 0, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = add_loosing_matches(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Differences\n- We compute the difference between the team for each feature.\n- This helps further assessing how better (or worse) team A is from team B"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_diff = [\n    'Seed', 'WinRatio', 'GapAvg', '538rating'\n]\n\nfor col in cols_to_diff:\n    df[col + 'Diff'] = df[col + 'A'] - df[col + 'B']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Data"},{"metadata":{},"cell_type":"markdown","source":"### Preparing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(DATA_PATH + \"WSampleSubmissionStage2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Season'] = df_test['ID'].apply(lambda x: int(x.split('_')[0]))\ndf_test['TeamIdA'] = df_test['ID'].apply(lambda x: int(x.split('_')[1]))\ndf_test['TeamIdB'] = df_test['ID'].apply(lambda x: int(x.split('_')[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seeds"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.merge(\n    df_test,\n    df_seeds,\n    how='left',\n    left_on=['Season', 'TeamIdA'],\n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'Seed': 'SeedA'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.merge(\n    df_test, \n    df_seeds, \n    how='left', \n    left_on=['Season', 'TeamIdB'], \n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'Seed': 'SeedB'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['SeedA'] = df_test['SeedA'].apply(treat_seed)\ndf_test['SeedB'] = df_test['SeedB'].apply(treat_seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Season Stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.merge(\n    df_test,\n    df_features_season,\n    how='left',\n    left_on=['Season', 'TeamIdA'],\n    right_on=['Season', 'TeamID']\n).rename(columns={\n    'NumWins': 'NumWinsA',\n    'NumLosses': 'NumLossesA',\n    'GapWins': 'GapWinsA',\n    'GapLosses': 'GapLossesA',\n    'WinRatio': 'WinRatioA',\n    'GapAvg': 'GapAvgA',\n}).drop(columns='TeamID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.merge(\n    df_test,\n    df_features_season,\n    how='left',\n    left_on=['Season', 'TeamIdB'],\n    right_on=['Season', 'TeamID']\n).rename(columns={\n    'NumWins': 'NumWinsB',\n    'NumLosses': 'NumLossesB',\n    'GapWins': 'GapWinsB',\n    'GapLosses': 'GapLossesB',\n    'WinRatio': 'WinRatioB',\n    'GapAvg': 'GapAvgB',\n}).drop(columns='TeamID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.merge(\n    df_test,\n    df_538,\n    how='left',\n    left_on=['Season', 'TeamIdA'],\n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'538rating': '538ratingA'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.merge(\n    df_test,\n    df_538,\n    how='left',\n    left_on=['Season', 'TeamIdB'],\n    right_on=['Season', 'TeamID']\n).drop('TeamID', axis=1).rename(columns={'538rating': '538ratingB'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Differences"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cols_to_diff:\n    df_test[col + 'Diff'] = df_test[col + 'A'] - df_test[col + 'B']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ScoreDiff'] = df['ScoreA'] - df['ScoreB']\ndf['WinA'] = (df['ScoreDiff'] > 0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    'SeedDiff',\n    '538ratingDiff',\n    'WinRatioDiff', \n    'GapAvgDiff', \n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rescale(features, df_train, df_val, df_test=None):\n    min_ = df_train[features].min()\n    max_ = df_train[features].max()\n    \n    df_train[features] = (df_train[features] - min_) / (max_ - min_)\n    df_val[features] = (df_val[features] - min_) / (max_ - min_)\n    \n    if df_test is not None:\n        df_test[features] = (df_test[features] - min_) / (max_ - min_)\n        \n    return df_train, df_val, df_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross Validation\n- Validate on season `n`, for `n` in the 3 last seasons. \n- Train on earlier seasons. First available season is 2016 because of the FiveThirtyEight ratings.\n- Pipeline support classification (predict the team that wins) and regression (predict the score gap), but classification worked better on CV."},{"metadata":{"trusted":true},"cell_type":"code","source":"def kfold(df, df_test_=None, plot=False, verbose=0, mode=\"reg\"):\n    seasons = df['Season'].unique()\n    cvs = []\n    pred_tests = []\n    target = \"ScoreDiff\" if mode == \"reg\" else \"WinA\"\n    \n    for season in seasons[1:]:\n        if verbose:\n            print(f'\\nValidating on season {season}')\n        \n        df_train = df[df['Season'] < season].reset_index(drop=True).copy()\n        df_val = df[df['Season'] == season].reset_index(drop=True).copy()\n        df_test = df_test_.copy()\n        \n        df_train, df_val, df_test = rescale(features, df_train, df_val, df_test)\n        \n        if mode == \"reg\":\n            model = ElasticNet(alpha=1, l1_ratio=0.5)\n        else:\n            model = LogisticRegression(C=100)\n\n        model.fit(df_train[features], df_train[target])\n        \n        if mode == \"reg\":\n            pred = model.predict(df_val[features])\n            pred = (pred - pred.min()) / (pred.max() - pred.min())\n        else:\n            pred = model.predict_proba(df_val[features])[:, 1]\n        \n        if df_test is not None:\n            if mode == \"reg\":\n                pred_test = model.predict(df_test[features])\n                pred_test = (pred_test - pred_test.min()) / (pred_test.max() - pred_test.min())\n            else:\n                pred_test = model.predict_proba(df_test[features])[:, 1]\n                \n            pred_tests.append(pred_test)\n            \n        if plot:\n            plt.figure(figsize=(15, 6))\n            plt.subplot(1, 2, 1)\n            plt.scatter(pred, df_val['ScoreDiff'].values, s=5)\n            plt.grid(True)\n            plt.subplot(1, 2, 2)\n            sns.histplot(pred)\n            plt.show()\n        \n        loss = log_loss(df_val['WinA'].values, pred)\n        cvs.append(loss)\n\n        if verbose:\n            print(f'\\t -> Scored {loss:.3f}')\n        \n    print(f'\\n Local CV is {np.mean(cvs):.3f}')\n    \n    return pred_tests","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tests = kfold(df, df_test, plot=False, verbose=1, mode=\"cls\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = np.mean(pred_tests, 0)\n\n_ = sns.displot(pred_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Overriding predictions"},{"metadata":{},"cell_type":"markdown","source":"## Prepare"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = df_test[['ID', 'Pred', 'TeamIdA', 'TeamIdB', 'SeedA', 'SeedB']].copy()\nsub['Pred'] = pred_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_teams = pd.read_csv(DATA_PATH + \"WTeams.csv\")\nsub = sub.merge(df_teams, left_on=\"TeamIdA\", right_on=\"TeamID\").drop('TeamID', axis=1).rename(columns={\"TeamName\": \"TeamA\"})\nsub = sub.merge(df_teams, left_on=\"TeamIdB\", right_on=\"TeamID\").drop('TeamID', axis=1).rename(columns={\"TeamName\": \"TeamB\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'Season' in df_seeds.keys():\n    df_seeds = df_seeds[df_seeds['Season'] == 2021].drop(\"Season\", axis=1)\ndf_seeds['Seed'] = df_seeds['Seed'].apply(lambda x:x[0])\n\nsub = sub.merge(df_seeds, left_on=\"TeamIdA\", right_on=\"TeamID\").drop('TeamID', axis=1).rename(columns={\"Seed\": \"RegionA\"})\nsub = sub.merge(df_seeds, left_on=\"TeamIdB\", right_on=\"TeamID\").drop('TeamID', axis=1).rename(columns={\"Seed\": \"RegionB\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Strategies\n\n#### Risky strategy\n\n- Picked 11 teams that would win their first match\n- Stanford and Baylor beat every team seeded 3 or higher\n- Connecticut and South Carolina  beat every team seeded 4 or higher\n- Maryland wins beats every team seeded 7 or higher\n- use p=0.99999 for overriding\n\n#### Safe strategy\n\n- Picked 7 teams that would win their first match\n- Stanford, Connecticut and South Carolina beat every team seeded 6 or higher\n- Baylor wins beats every team seeded 7 or higher\n- use p=0.99 for overriding"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_teams = ['Stanford', 'South Carolina', 'Connecticut', 'Baylor', 'Maryland']  # considered for buff\n\nstrong_teams_safe = best_teams + ['NC State', 'Louisville']  # win 1st round\nstrong_teams_risky = strong_teams_safe + ['Texas A&M', 'Arizona', 'Georgia', 'UCLA']  # win 1st round","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def overwrite_pred_risky(sub, eps=1e-5):\n\n    new_sub = []\n    \n    for i, row in sub.iterrows():\n        \n        # Buff Stanford\n        if row['TeamA'] == 'Stanford' and row['SeedB'] >= 3:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Stanford' and row['SeedA'] >= 3:\n            row['Pred'] = eps\n    \n        # Buff South Carolina\n        if row['TeamA'] == 'South Carolina' and row['SeedB'] >= 4:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'South Carolina' and row['SeedA'] >= 4:\n            row['Pred'] = eps\n            \n        # Buff Connecticut\n        if row['TeamA'] == 'Connecticut' and row['SeedB'] >= 4:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Connecticut' and row['SeedA'] >= 4:\n            row['Pred'] = eps\n            \n        # Buff Baylor\n        if row['TeamA'] == 'Baylor' and row['SeedB'] >= 3:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Baylor' and row['SeedA'] >= 3:\n            row['Pred'] = eps\n            \n        # Buff Maryland\n        if row['TeamA'] == 'Maryland' and row['SeedB'] >= 7:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Maryland' and row['SeedA'] >= 7:\n            row['Pred'] = eps\n        \n        # Strong teams (risky) win their first round\n        if row['TeamA'] in strong_teams_risky and row['SeedB'] >= 13:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] in strong_teams_risky and row['SeedA'] >= 13:\n            row['Pred'] = eps\n\n        new_sub.append(row)\n        \n    return pd.DataFrame(np.array(new_sub), columns=sub.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def overwrite_pred_safe(sub, eps=1e-2):    \n    new_sub = []\n    \n    for i, row in sub.iterrows():\n        row['Pred'] = np.clip(row['Pred'], 0.1, 0.9) # clip for safety\n        \n        # Buff Stanford\n        if row['TeamA'] == 'Stanford' and row['SeedB'] >= 6:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Stanford' and row['SeedA'] >= 6:\n            row['Pred'] = eps\n    \n        # Buff South Carolina\n        if row['TeamA'] == 'South Carolina' and row['SeedB'] >= 6:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'South Carolina' and row['SeedA'] >= 6:\n            row['Pred'] = eps\n            \n        # Buff Connecticut\n        if row['TeamA'] == 'Connecticut' and row['SeedB'] >= 6:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Connecticut' and row['SeedA'] >= 6:\n            row['Pred'] = eps\n\n        # Buff Baylor\n        if row['TeamA'] == 'Baylor' and row['SeedB'] >= 7:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] == 'Baylor' and row['SeedA'] >= 7:\n            row['Pred'] = eps\n        \n        # Strong teams (safe) win their first rounds\n        if row['TeamA'] in strong_teams_safe and row['SeedB'] >= 13:\n            row['Pred'] = 1 - eps\n        elif row['TeamB'] in strong_teams_safe and row['SeedA'] >= 13:\n            row['Pred'] = eps\n\n        new_sub.append(row)\n        \n    return pd.DataFrame(np.array(new_sub), columns=sub.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub_pp = overwrite_pred_safe(sub)\nsub_pp = overwrite_pred_risky(sub)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sub = sub_pp[['ID', 'Pred']].copy()\nfinal_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}