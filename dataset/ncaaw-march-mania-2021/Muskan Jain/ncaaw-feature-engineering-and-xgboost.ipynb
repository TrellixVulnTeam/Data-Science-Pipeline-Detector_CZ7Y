{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LOAD THE DATA AND IMPORT THE LIBRARIES","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom scipy.interpolate import UnivariateSpline\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport collections","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:31.447976Z","iopub.execute_input":"2021-05-31T16:34:31.448491Z","iopub.status.idle":"2021-05-31T16:34:33.508669Z","shell.execute_reply.started":"2021-05-31T16:34:31.448412Z","shell.execute_reply":"2021-05-31T16:34:33.507806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\n@dataclass\nclass Config: \n    stage_2 = True # True for Stage 2 submission\n    debug = True # True for fast debug run\n\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:33.510501Z","iopub.execute_input":"2021-05-31T16:34:33.510838Z","iopub.status.idle":"2021-05-31T16:34:33.515604Z","shell.execute_reply.started":"2021-05-31T16:34:33.510803Z","shell.execute_reply":"2021-05-31T16:34:33.514531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp = '../input/ncaaw-march-mania-2021/WDataFiles_Stage2/'\nregular_results = pd.read_csv(inp+'WRegularSeasonDetailedResults.csv')\ntourney_results = pd.read_csv(inp+'WNCAATourneyDetailedResults.csv')\nseeds=pd.read_csv(inp+'WNCAATourneySeeds.csv')\n#seeds.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:33.517091Z","iopub.execute_input":"2021-05-31T16:34:33.51748Z","iopub.status.idle":"2021-05-31T16:34:33.737045Z","shell.execute_reply.started":"2021-05-31T16:34:33.517446Z","shell.execute_reply":"2021-05-31T16:34:33.7363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA PREPARATION","metadata":{}},{"cell_type":"code","source":"### double the data by swapping team positions\ndef prepare_data(df):\n    dfswap = df[['Season', 'DayNum', 'LTeamID', 'LScore', 'WTeamID', 'WScore', 'WLoc', 'NumOT', \n    'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', \n    'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]\n\n    dfswap.loc[df['WLoc'] == 'H', 'WLoc'] = 'A'\n    dfswap.loc[df['WLoc'] == 'A', 'WLoc'] = 'H'\n    df.columns.values[6] = 'location'\n    dfswap.columns.values[6] = 'location'    \n      \n    df.columns = [x.replace('W','T1_').replace('L','T2_') for x in list(df.columns)]\n    dfswap.columns = [x.replace('L','T1_').replace('W','T2_') for x in list(dfswap.columns)]\n\n    output = pd.concat([df, dfswap]).reset_index(drop=True)\n    output.loc[output.location=='N','location'] = '0'\n    output.loc[output.location=='H','location'] = '1'\n    output.loc[output.location=='A','location'] = '-1'\n    output.location = output.location.astype(int)\n    \n    output['PointDiff'] = output['T1_Score'] - output['T2_Score']\n    \n    return output","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:33.738039Z","iopub.execute_input":"2021-05-31T16:34:33.738485Z","iopub.status.idle":"2021-05-31T16:34:33.747703Z","shell.execute_reply.started":"2021-05-31T16:34:33.738456Z","shell.execute_reply":"2021-05-31T16:34:33.747038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#apply it on both regular and tournament data \nregular_data = prepare_data(regular_results)\ntourney_data = prepare_data(tourney_results)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:33.750655Z","iopub.execute_input":"2021-05-31T16:34:33.751103Z","iopub.status.idle":"2021-05-31T16:34:33.930398Z","shell.execute_reply.started":"2021-05-31T16:34:33.75106Z","shell.execute_reply":"2021-05-31T16:34:33.929702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"boxscore_cols = ['T1_Score', 'T2_Score', \n        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_FTM', 'T1_FTA', 'T1_OR', 'T1_DR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_Blk', 'T1_PF', \n        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_FTM', 'T2_FTA', 'T2_OR', 'T2_DR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk', 'T2_PF', \n        'PointDiff']\n\nboxscore_cols = [\n        'T1_FGM', 'T1_FGA', 'T1_FGM3', 'T1_FGA3', 'T1_OR', 'T1_Ast', 'T1_TO', 'T1_Stl', 'T1_PF', \n        'T2_FGM', 'T2_FGA', 'T2_FGM3', 'T2_FGA3', 'T2_OR', 'T2_Ast', 'T2_TO', 'T2_Stl', 'T2_Blk',  \n        'PointDiff']\n\nfuncs = [np.mean]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:33.933088Z","iopub.execute_input":"2021-05-31T16:34:33.933659Z","iopub.status.idle":"2021-05-31T16:34:33.939995Z","shell.execute_reply.started":"2021-05-31T16:34:33.9336Z","shell.execute_reply":"2021-05-31T16:34:33.939305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Regular season statistics\nseason_statistics = regular_data.groupby([\"Season\", 'T1_TeamID'])[boxscore_cols].agg(funcs).reset_index()\nseason_statistics.columns = [''.join(col).strip() for col in season_statistics.columns.values]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:33.941002Z","iopub.execute_input":"2021-05-31T16:34:33.941392Z","iopub.status.idle":"2021-05-31T16:34:34.07403Z","shell.execute_reply.started":"2021-05-31T16:34:33.941358Z","shell.execute_reply":"2021-05-31T16:34:34.073224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"season_statistics_T1 = season_statistics.copy()\nseason_statistics_T2 = season_statistics.copy()\n\nseason_statistics_T1.columns = [\"T1_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(season_statistics_T1.columns)]\nseason_statistics_T2.columns = [\"T2_\" + x.replace(\"T1_\",\"\").replace(\"T2_\",\"opponent_\") for x in list(season_statistics_T2.columns)]\nseason_statistics_T1.columns.values[0] = \"Season\"\nseason_statistics_T2.columns.values[0] = \"Season\"\nseason_statistics_T1.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:34.075142Z","iopub.execute_input":"2021-05-31T16:34:34.075502Z","iopub.status.idle":"2021-05-31T16:34:34.115796Z","shell.execute_reply.started":"2021-05-31T16:34:34.075471Z","shell.execute_reply":"2021-05-31T16:34:34.114768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Combine all features into a data frame\ntourney_data = tourney_data[['Season', 'DayNum', 'T1_TeamID', 'T1_Score', 'T2_TeamID' ,'T2_Score']]\ntourney_data = pd.merge(tourney_data, season_statistics_T1, on = ['Season', 'T1_TeamID'], how = 'left')\ntourney_data = pd.merge(tourney_data, season_statistics_T2, on = ['Season', 'T2_TeamID'], how = 'left')\ntourney_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:34.117161Z","iopub.execute_input":"2021-05-31T16:34:34.117489Z","iopub.status.idle":"2021-05-31T16:34:34.157927Z","shell.execute_reply.started":"2021-05-31T16:34:34.117459Z","shell.execute_reply":"2021-05-31T16:34:34.156954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Combine all features into a data frame\nregular_season_effects = regular_data[['Season','T1_TeamID','T2_TeamID','PointDiff']].copy()\nregular_season_effects['T1_TeamID'] = regular_season_effects['T1_TeamID'].astype(str)\nregular_season_effects['T2_TeamID'] = regular_season_effects['T2_TeamID'].astype(str)\nregular_season_effects['win'] = np.where(regular_season_effects['PointDiff']>0,1,0)\nmarch_madness = pd.merge(seeds[['Season','TeamID']],seeds[['Season','TeamID']],on='Season')\nmarch_madness.columns = ['Season', 'T1_TeamID', 'T2_TeamID']\nmarch_madness.T1_TeamID = march_madness.T1_TeamID.astype(str)\nmarch_madness.T2_TeamID = march_madness.T2_TeamID.astype(str)\nregular_season_effects = pd.merge(regular_season_effects, march_madness, on = ['Season','T1_TeamID','T2_TeamID'])\nregular_season_effects.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:34.159131Z","iopub.execute_input":"2021-05-31T16:34:34.159433Z","iopub.status.idle":"2021-05-31T16:34:34.807852Z","shell.execute_reply.started":"2021-05-31T16:34:34.159405Z","shell.execute_reply":"2021-05-31T16:34:34.80704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def team_quality(season):\n    formula = 'win~-1+T1_TeamID+T2_TeamID'\n    glm = sm.GLM.from_formula(formula=formula, \n                              data=regular_season_effects.loc[regular_season_effects.Season==season,:], \n                              family=sm.families.Binomial()).fit()\n    \n    quality = pd.DataFrame(glm.params).reset_index()\n    quality.columns = ['TeamID','quality']\n    quality['Season'] = season\n    quality['quality'] = np.exp(quality['quality'])\n    quality = quality.loc[quality.TeamID.str.contains('T1_')].reset_index(drop=True)\n    quality['TeamID'] = quality['TeamID'].apply(lambda x: x[10:14]).astype(int)\n    return quality","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:34.809154Z","iopub.execute_input":"2021-05-31T16:34:34.809512Z","iopub.status.idle":"2021-05-31T16:34:34.816673Z","shell.execute_reply.started":"2021-05-31T16:34:34.809483Z","shell.execute_reply":"2021-05-31T16:34:34.815687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glm_quality = pd.concat([team_quality(2016),\n                         team_quality(2017),\n                         team_quality(2018), \n                        team_quality(2019)]).reset_index(drop=True)\nif not config.debug: \n    glm_quality = [team_quality(2010),\n                 team_quality(2011),\n                 team_quality(2012),\n                 team_quality(2013),\n                 team_quality(2014),\n                 team_quality(2015)] + glm_quality\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:34.818094Z","iopub.execute_input":"2021-05-31T16:34:34.818469Z","iopub.status.idle":"2021-05-31T16:34:39.974711Z","shell.execute_reply.started":"2021-05-31T16:34:34.818432Z","shell.execute_reply":"2021-05-31T16:34:39.973699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glm_quality_T1 = glm_quality.copy()\nglm_quality_T2 = glm_quality.copy()\nglm_quality_T1.columns = ['T1_TeamID','T1_quality','Season']\nglm_quality_T2.columns = ['T2_TeamID','T2_quality','Season']\ntourney_data = pd.merge(tourney_data, glm_quality_T1, on = ['Season', 'T1_TeamID'], how = 'left')\ntourney_data = pd.merge(tourney_data, glm_quality_T2, on = ['Season', 'T2_TeamID'], how = 'left')\ntourney_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:39.976114Z","iopub.execute_input":"2021-05-31T16:34:39.976549Z","iopub.status.idle":"2021-05-31T16:34:40.017115Z","shell.execute_reply.started":"2021-05-31T16:34:39.976508Z","shell.execute_reply":"2021-05-31T16:34:40.016076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seeds['seed'] = seeds['Seed'].apply(lambda x: int(x[1:3]))\nseeds_T1 = seeds[['Season','TeamID','seed']].copy()\nseeds_T2 = seeds[['Season','TeamID','seed']].copy()\nseeds_T1.columns = ['Season','T1_TeamID','T1_seed']\nseeds_T2.columns = ['Season','T2_TeamID','T2_seed']\ntourney_data = pd.merge(tourney_data, seeds_T1, on = ['Season', 'T1_TeamID'], how = 'left')\ntourney_data = pd.merge(tourney_data, seeds_T2, on = ['Season', 'T2_TeamID'], how = 'left')\ntourney_data[\"Seed_diff\"] = tourney_data[\"T1_seed\"] - tourney_data[\"T2_seed\"]\nseeds.head() ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.018358Z","iopub.execute_input":"2021-05-31T16:34:40.018631Z","iopub.status.idle":"2021-05-31T16:34:40.049068Z","shell.execute_reply.started":"2021-05-31T16:34:40.018604Z","shell.execute_reply":"2021-05-31T16:34:40.048081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tourney_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.050233Z","iopub.execute_input":"2021-05-31T16:34:40.050505Z","iopub.status.idle":"2021-05-31T16:34:40.077785Z","shell.execute_reply.started":"2021-05-31T16:34:40.05048Z","shell.execute_reply":"2021-05-31T16:34:40.076877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL BUILDING","metadata":{}},{"cell_type":"code","source":"y = tourney_data['T1_Score'] - tourney_data['T2_Score']\ny.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.079158Z","iopub.execute_input":"2021-05-31T16:34:40.079459Z","iopub.status.idle":"2021-05-31T16:34:40.090495Z","shell.execute_reply.started":"2021-05-31T16:34:40.079433Z","shell.execute_reply":"2021-05-31T16:34:40.089797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = list(season_statistics_T1.columns[2:999]) + \\\n    list(season_statistics_T2.columns[2:999]) + \\\n    list(seeds_T1.columns[2:999]) + \\\n    list(seeds_T2.columns[2:999]) + \\\n    [\"Seed_diff\"] + [\"T1_quality\",\"T2_quality\"]\nX = tourney_data[features].values\ndtrain = xgb.DMatrix(X, label = y)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.091551Z","iopub.execute_input":"2021-05-31T16:34:40.091796Z","iopub.status.idle":"2021-05-31T16:34:40.11022Z","shell.execute_reply.started":"2021-05-31T16:34:40.091774Z","shell.execute_reply":"2021-05-31T16:34:40.109456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Prepare xgboost\ndef cauchyobj(preds, dtrain):\n    labels = dtrain.get_label()\n    c = 5000 \n    x =  preds-labels    \n    grad = x / (x**2/c**2+1)\n    hess = -c**2*(x**2-c**2)/(x**2+c**2)**2\n    return grad, hess","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.113943Z","iopub.execute_input":"2021-05-31T16:34:40.11578Z","iopub.status.idle":"2021-05-31T16:34:40.122602Z","shell.execute_reply.started":"2021-05-31T16:34:40.115743Z","shell.execute_reply":"2021-05-31T16:34:40.121605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = {} \n#param['objective'] = 'reg:linear'\nparam['eval_metric'] =  'mae'\nparam['booster'] = 'gbtree'\nparam['eta'] = 0.02 #change to ~0.02 for final run\nparam['subsample'] = 0.7\nparam['colsample_bytree'] = 0.8\nparam['num_parallel_tree'] = 10 #recommend 10\nparam['min_child_weight'] = 40\nparam['gamma'] = 10\nparam['max_depth'] =  4\nparam['silent'] = 1\n\nprint(param)\nif config.debug: \n    param['num_parallel_tree'] = 5","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.124852Z","iopub.execute_input":"2021-05-31T16:34:40.125108Z","iopub.status.idle":"2021-05-31T16:34:40.133347Z","shell.execute_reply.started":"2021-05-31T16:34:40.125084Z","shell.execute_reply":"2021-05-31T16:34:40.132651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv = []\nrepeat_cv = 20\nn_splits = 5\nif config.debug: \n    repeat_cv = 2\n    n_splits = 3\n\nfor i in range(repeat_cv): \n    print(f\"Fold repeater {i}\")\n    xgb_cv.append(\n        xgb.cv(\n          params = param,\n          dtrain = dtrain,\n          obj = cauchyobj,\n          num_boost_round = 3000,\n          folds = KFold(n_splits = n_splits, shuffle = True, random_state = i),\n          early_stopping_rounds = 25,\n          verbose_eval = 50\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:40.134268Z","iopub.execute_input":"2021-05-31T16:34:40.134643Z","iopub.status.idle":"2021-05-31T16:34:52.212384Z","shell.execute_reply.started":"2021-05-31T16:34:40.134618Z","shell.execute_reply":"2021-05-31T16:34:52.211563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iteration_counts = [np.argmin(x['test-mae-mean'].values) for x in xgb_cv]\nval_mae = [np.min(x['test-mae-mean'].values) for x in xgb_cv]\niteration_counts, val_mae","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:52.213798Z","iopub.execute_input":"2021-05-31T16:34:52.214326Z","iopub.status.idle":"2021-05-31T16:34:52.222058Z","shell.execute_reply.started":"2021-05-31T16:34:52.214292Z","shell.execute_reply":"2021-05-31T16:34:52.221393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Build cross-validation model, repeated 5-times\noof_preds = []\nfor i in range(repeat_cv):\n    print(f\"Fold repeater {i}\")\n    preds = y.copy()\n    kfold = KFold(n_splits = 5, shuffle = True, random_state = i)    \n    for train_index, val_index in kfold.split(X,y):\n        dtrain_i = xgb.DMatrix(X[train_index], label = y[train_index])\n        dval_i = xgb.DMatrix(X[val_index], label = y[val_index])  \n        model = xgb.train(\n              params = param,\n              dtrain = dtrain_i,\n              num_boost_round = iteration_counts[i],\n              verbose_eval = 50\n        )\n        preds[val_index] = model.predict(dval_i)\n    oof_preds.append(np.clip(preds,-30,30))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:34:52.223333Z","iopub.execute_input":"2021-05-31T16:34:52.223719Z","iopub.status.idle":"2021-05-31T16:35:09.210966Z","shell.execute_reply.started":"2021-05-31T16:34:52.22368Z","shell.execute_reply":"2021-05-31T16:35:09.21018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_df = pd.DataFrame({\"pred\":oof_preds[0], \"label\":np.where(y>0,1,0)})\nplot_df[\"pred_int\"] = plot_df[\"pred\"].astype(int)\nplot_df = plot_df.groupby('pred_int')['label'].mean().reset_index(name='average_win_pct')\n\nplt.figure()\nplt.plot(plot_df.pred_int,plot_df.average_win_pct)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.212077Z","iopub.execute_input":"2021-05-31T16:35:09.212544Z","iopub.status.idle":"2021-05-31T16:35:09.391659Z","shell.execute_reply.started":"2021-05-31T16:35:09.212507Z","shell.execute_reply":"2021-05-31T16:35:09.390711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ### Fit a smoothed model on predicted result point differential to get probabilities\nspline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n        \n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    \n    print(f\"logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.392731Z","iopub.execute_input":"2021-05-31T16:35:09.393006Z","iopub.status.idle":"2021-05-31T16:35:09.411742Z","shell.execute_reply.started":"2021-05-31T16:35:09.392982Z","shell.execute_reply":"2021-05-31T16:35:09.41055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_df = pd.DataFrame({\"pred\":oof_preds[0], \"label\":np.where(y>0,1,0), \"spline\":spline_model[0](oof_preds[0])})\nplot_df[\"pred_int\"] = (plot_df[\"pred\"]).astype(int)\nplot_df = plot_df.groupby('pred_int')['spline','label'].mean().reset_index()\n\nplt.figure()\nplt.plot(plot_df.pred_int,plot_df.spline)\nplt.plot(plot_df.pred_int,plot_df.label)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.413293Z","iopub.execute_input":"2021-05-31T16:35:09.413801Z","iopub.status.idle":"2021-05-31T16:35:09.565517Z","shell.execute_reply.started":"2021-05-31T16:35:09.41375Z","shell.execute_reply":"2021-05-31T16:35:09.564813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a model\nspline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    spline_fit = np.clip(spline_fit,0.025,0.975)\n    \n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.566447Z","iopub.execute_input":"2021-05-31T16:35:09.566796Z","iopub.status.idle":"2021-05-31T16:35:09.581934Z","shell.execute_reply.started":"2021-05-31T16:35:09.566771Z","shell.execute_reply":"2021-05-31T16:35:09.581048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building models and inlcuding the upsets\nspline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    spline_fit = np.clip(spline_fit,0.025,0.975)\n    spline_fit[(tourney_data.T1_seed==1) & (tourney_data.T2_seed==16)] = 1.0\n    spline_fit[(tourney_data.T1_seed==2) & (tourney_data.T2_seed==15)] = 1.0\n    spline_fit[(tourney_data.T1_seed==3) & (tourney_data.T2_seed==14)] = 1.0\n    spline_fit[(tourney_data.T1_seed==4) & (tourney_data.T2_seed==13)] = 1.0\n    spline_fit[(tourney_data.T1_seed==16) & (tourney_data.T2_seed==1)] = 0.0\n    spline_fit[(tourney_data.T1_seed==15) & (tourney_data.T2_seed==2)] = 0.0\n    spline_fit[(tourney_data.T1_seed==14) & (tourney_data.T2_seed==3)] = 0.0\n    spline_fit[(tourney_data.T1_seed==13) & (tourney_data.T2_seed==4)] = 0.0\n    \n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.582812Z","iopub.execute_input":"2021-05-31T16:35:09.583075Z","iopub.status.idle":"2021-05-31T16:35:09.617242Z","shell.execute_reply.started":"2021-05-31T16:35:09.583052Z","shell.execute_reply":"2021-05-31T16:35:09.616359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##upsets\npd.concat(\n    [tourney_data[(tourney_data.T1_seed==1) & (tourney_data.T2_seed==16) & (tourney_data.T1_Score < tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==2) & (tourney_data.T2_seed==15) & (tourney_data.T1_Score < tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==3) & (tourney_data.T2_seed==14) & (tourney_data.T1_Score < tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==4) & (tourney_data.T2_seed==13) & (tourney_data.T1_Score < tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==16) & (tourney_data.T2_seed==1) & (tourney_data.T1_Score > tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==15) & (tourney_data.T2_seed==2) & (tourney_data.T1_Score > tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==14) & (tourney_data.T2_seed==3) & (tourney_data.T1_Score > tourney_data.T2_Score)],\n     tourney_data[(tourney_data.T1_seed==13) & (tourney_data.T2_seed==4) & (tourney_data.T1_Score > tourney_data.T2_Score)]]\n)   ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.618563Z","iopub.execute_input":"2021-05-31T16:35:09.618873Z","iopub.status.idle":"2021-05-31T16:35:09.66407Z","shell.execute_reply.started":"2021-05-31T16:35:09.618845Z","shell.execute_reply":"2021-05-31T16:35:09.663187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    spline_fit = np.clip(spline_fit,0.025,0.975)\n    spline_fit[(tourney_data.T1_seed==1) & (tourney_data.T2_seed==16) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==2) & (tourney_data.T2_seed==15) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==3) & (tourney_data.T2_seed==14) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==4) & (tourney_data.T2_seed==13) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==16) & (tourney_data.T2_seed==1) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    spline_fit[(tourney_data.T1_seed==15) & (tourney_data.T2_seed==2) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    spline_fit[(tourney_data.T1_seed==14) & (tourney_data.T2_seed==3) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    spline_fit[(tourney_data.T1_seed==13) & (tourney_data.T2_seed==4) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    \n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.665464Z","iopub.execute_input":"2021-05-31T16:35:09.665758Z","iopub.status.idle":"2021-05-31T16:35:09.707714Z","shell.execute_reply.started":"2021-05-31T16:35:09.665735Z","shell.execute_reply":"2021-05-31T16:35:09.706692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cross-validation \nval_cv = []\nspline_model = []\n\nfor i in range(repeat_cv):\n    dat = list(zip(oof_preds[i],np.where(y>0,1,0)))\n    dat = sorted(dat, key = lambda x: x[0])\n    datdict = {}\n    for k in range(len(dat)):\n        datdict[dat[k][0]]= dat[k][1]\n    spline_model.append(UnivariateSpline(list(datdict.keys()), list(datdict.values())))\n    spline_fit = spline_model[i](oof_preds[i])\n    spline_fit = np.clip(spline_fit,0.025,0.975)\n    spline_fit[(tourney_data.T1_seed==1) & (tourney_data.T2_seed==16) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==2) & (tourney_data.T2_seed==15) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==3) & (tourney_data.T2_seed==14) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==4) & (tourney_data.T2_seed==13) & (tourney_data.T1_Score > tourney_data.T2_Score)] = 1.0\n    spline_fit[(tourney_data.T1_seed==16) & (tourney_data.T2_seed==1) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    spline_fit[(tourney_data.T1_seed==15) & (tourney_data.T2_seed==2) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    spline_fit[(tourney_data.T1_seed==14) & (tourney_data.T2_seed==3) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    spline_fit[(tourney_data.T1_seed==13) & (tourney_data.T2_seed==4) & (tourney_data.T1_Score < tourney_data.T2_Score)] = 0.0\n    \n    val_cv.append(pd.DataFrame({\"y\":np.where(y>0,1,0), \"pred\":spline_fit, \"season\":tourney_data.Season}))\n    print(f\"adjusted logloss of cvsplit {i}: {log_loss(np.where(y>0,1,0),spline_fit)}\") \n    \nval_cv = pd.concat(val_cv)\nval_cv.groupby('season').apply(lambda x: log_loss(x.y, x.pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.709678Z","iopub.execute_input":"2021-05-31T16:35:09.710114Z","iopub.status.idle":"2021-05-31T16:35:09.780839Z","shell.execute_reply.started":"2021-05-31T16:35:09.710072Z","shell.execute_reply":"2021-05-31T16:35:09.779657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREDICTIONS AND SUBMISSION","metadata":{}},{"cell_type":"code","source":"#making predictions and submission\nif config.stage_2: \n    sub=pd.read_csv(inp+'WSampleSubmissionStage2.csv')\n    sub['Season'] = sub['ID'].map(lambda x: int(x.split('_')[0]))\n    sub['T1_TeamID'] = sub['ID'].map(lambda x: int(x.split('_')[1]))\n    sub['T2_TeamID'] = sub['ID'].map(lambda x: int(x.split('_')[2]))\n    sub = pd.merge(sub, season_statistics_T1, on = ['Season', 'T1_TeamID'],how=\"left\")\n    sub = pd.merge(sub, season_statistics_T2, on = ['Season', 'T2_TeamID'],how=\"left\")\n    sub = pd.merge(sub, glm_quality_T1, on = ['Season', 'T1_TeamID'],how=\"left\")\n    sub = pd.merge(sub, glm_quality_T2, on = ['Season', 'T2_TeamID'],how=\"left\")\n    sub = pd.merge(sub, seeds_T1, on = ['Season', 'T1_TeamID'],how=\"left\")\n    sub = pd.merge(sub, seeds_T2, on = ['Season', 'T2_TeamID'],how=\"left\")\n    sub[\"Seed_diff\"] = sub[\"T1_seed\"] - sub[\"T2_seed\"]\n    Xsub = sub[features].values\n    dtest = xgb.DMatrix(Xsub)\n    sub_models = []\n    for i in range(repeat_cv):\n        print(f\"Fold repeater {i}\")\n        sub_models.append(\n        xgb.train(\n          params = param,\n          dtrain = dtrain,\n          num_boost_round = int(iteration_counts[i] * 1.05),\n          verbose_eval = 50\n        )\n    )\n    sub_preds = []\n    for i in range(repeat_cv):\n        sub_preds.append(np.clip(spline_model[i](np.clip(sub_models[i].predict(dtest),-30,30)),0.025,0.975))\n    sub[\"Pred\"] = pd.DataFrame(sub_preds).mean(axis=0)\n\n \n    sub.loc[(sub.T1_seed==1) & (sub.T2_seed==16), 'Pred'] = 1.0\n    sub.loc[(sub.T1_seed==2) & (sub.T2_seed==15), 'Pred'] = 1.0\n    sub.loc[(sub.T1_seed==3) & (sub.T2_seed==14), 'Pred'] = 1.0\n    sub.loc[(sub.T1_seed==4) & (sub.T2_seed==13), 'Pred'] = 1.0\n    sub.loc[(sub.T1_seed==16) & (sub.T2_seed==1), 'Pred'] = 0.0\n    sub.loc[(sub.T1_seed==15) & (sub.T2_seed==2), 'Pred'] = 0.0\n    sub.loc[(sub.T1_seed==14) & (sub.T2_seed==3), 'Pred'] = 0.0\n    sub.loc[(sub.T1_seed==13) & (sub.T2_seed==4), 'Pred'] = 0.0\n    sub[['ID','Pred']].to_csv(\"submission_stage2_2.csv\", index = None)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:09.782491Z","iopub.execute_input":"2021-05-31T16:35:09.78293Z","iopub.status.idle":"2021-05-31T16:35:14.473817Z","shell.execute_reply.started":"2021-05-31T16:35:09.782887Z","shell.execute_reply":"2021-05-31T16:35:14.473074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:35:14.476667Z","iopub.execute_input":"2021-05-31T16:35:14.477058Z","iopub.status.idle":"2021-05-31T16:35:14.482038Z","shell.execute_reply.started":"2021-05-31T16:35:14.477021Z","shell.execute_reply":"2021-05-31T16:35:14.480962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References:-\nhttps://www.kaggle.com/raddar/paris-madness","metadata":{}}]}