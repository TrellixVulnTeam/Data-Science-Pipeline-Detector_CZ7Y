{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.animation as animation\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom tqdm import tqdm\n\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_colwidth', 1000)\npd.set_option('display.max_rows', 1000)\nplt.rcParams[\"animation.html\"] = \"jshtml\"\nplt.rcParams['figure.dpi'] = 150  \nplt.ioff()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that I download the plays_with_both.csv not plays.csv. This file is same as the standard plays.csv except it has the full names of the covers and the targets."},{"metadata":{"trusted":true},"cell_type":"code","source":"plays = pd.read_csv(\"/kaggle/input/mybigdatabowl2021/plays_with_both.csv\").drop(['Unnamed: 0'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What are the most successful/ unsuccessful target-cover pair?\nGiven that we know who the target and the cover are for each play, we want to know if there is a most successful or most unsuccessful pairings. Success will be determined by whether the pass was complete or incomplete."},{"metadata":{"trusted":true},"cell_type":"code","source":"nan = np.nan\nplaysWithPair = plays.query(\"target!='-'\")\nplaysWithPair = playsWithPair[~playsWithPair.coverOne.isna()]\nplaysWithPair = playsWithPair.reset_index(drop=True)\nprint(str(round(100.0*len(playsWithPair)/len(plays), 1))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We lost about 20% of the plays. I think that's expected. All the plays that resulted in sacks and some other miscellaneous cases. Now, I need to create tabluate pairs and results. To do that, I need to formulate a way to count the countTwo as an equal share holder in the passResult. Let's create this DataFrame:"},{"metadata":{"trusted":true},"cell_type":"code","source":"playsWithPair.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coverTwoExists = playsWithPair[~playsWithPair.coverTwo.isna()]\ntarget = pd.concat([playsWithPair.target, coverTwoExists.target])\ncover = pd.concat([playsWithPair.coverOne, coverTwoExists.coverTwo])\npassResult = pd.concat([playsWithPair.passResult, coverTwoExists.passResult])\npairResult = pd.DataFrame()\npairResult = pairResult.assign(target=target, cover=cover, passResult=passResult)\npairResult = pairResult.reset_index(drop=True)\npairResult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairResult.query(\"passResult=='C'\").groupby(['target', 'cover']).count().sort_values(\"passResult\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obviously, this does not mean that Xavier Rhodes is the worst cover in the league. Especially, given that Davante Adams is the leagues best WR in general. What I need to look is percentage out of all plays."},{"metadata":{"trusted":true},"cell_type":"code","source":"pairCompletion= pairResult.query(\"passResult=='C'\").groupby(['target', 'cover']).count().sort_values(\"passResult\", ascending=False)\npairTotal = pairResult.groupby(['target', 'cover']).count().sort_values(\"passResult\", ascending=False)\npairTotal = pairTotal.assign(completionRate=pairCompletion.passResult.divide(pairTotal.passResult, fill_value=0.0))\npairTotal.query(\"passResult > 7\").sort_values(['passResult','completionRate'], ascending=[False, True])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that most pairs are above 50% except for Odell-James Bradberry pair. I think this is very impressive for James Bradberry.\n\nHowever, in general, it looks like it's hard to be conclusive when grouped by pairs. The number of samples is too little. I think this makes sense because if the teams identify this pairing is a great matchup (or poor depended on which team you are rooting for), they would most likely switch around to gain favoritism."},{"metadata":{},"cell_type":"markdown","source":"# Who are the most succssful covers?\nInstead of looking at pairs, I think more useful information might be to look at, which cover forced the the lowest completionRate. Note that from here on out, we look at INcompletion rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"pairIncompletion = pairResult.query(\"passResult!='C'\").groupby('cover').count().sort_values(\"passResult\", ascending=False)\npairTotal = pairResult.groupby('cover').count().sort_values(\"passResult\", ascending=False)\npairTotal = pairTotal.assign(incompletionRate=pairIncompletion.passResult.divide(pairTotal.passResult, fill_value=0.0)).drop('target', axis=1)\npairTotal = pairTotal.rename(columns={'passResult':'coverCount'})[[\"incompletionRate\", \"coverCount\"]]\npairTotal = pairTotal.sort_values(['coverCount', 'incompletionRate'], ascending=[False, True])\npairTotal.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, looks like the 50% incompletion rate is insanely good when you look at this result. What is the baseline here? What is the average incompletionRate in the league?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean Incompletion Rate:\\t\" + str(round(pairTotal.incompletionRate.mean(),3)))\nprint(\"Mean Cover Count:\\t\" + str(round(pairTotal.coverCount.mean(), 1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's just plot this. It's difficult to see all the numbers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.close('all')\nax = pairTotal.plot.scatter(x='coverCount', y='incompletionRate', figsize=(10,5))\nplt.plot([-10,130], [pairTotal.incompletionRate.mean(), pairTotal.incompletionRate.mean()], c='C1')\n\n# Finding the players on the edges\ntempX = np.arange(0,110,1)\ntempY = np.exp(-0.03 * (tempX+10))+0.6\n#plt.plot(tempX, tempY, c='C2')\n\ntempDistToLine = []\nfor i in range(len(pairTotal)):\n    p = pairTotal.iloc[i]\n    minDist = 100000000\n    for j in range(len(tempX)):\n        tempdist = math.sqrt((p.coverCount-j)**2+(p.incompletionRate-tempY[j])**2)\n        minDist = min(minDist, tempdist)\n    tempDistToLine.append(minDist)\ntemp = pairTotal.assign(dist=tempDistToLine)\nedge_points = temp.sort_values('dist', ascending=True)[:7]\nedge_points.plot.scatter(x='coverCount', y='incompletionRate',c='C3', ax=ax)\nfor i in range(len(edge_points)):\n    p = edge_points.iloc[i]\n    name = edge_points.index[i]\n    if 'Darius Slay' in name:\n        plt.text(x=p.coverCount, y=p.incompletionRate+0.03, s=name)\n    else:   \n        plt.text(x=p.coverCount, y=p.incompletionRate, s=name)\nprint(edge_points.index)\n\n\nplt.xlim([0, 110])\nplt.ylim([-.05, 1.05])\nplt.title(\"Forced Incompletion Rate per Defensive Tries\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the above 7 players are exceptional when it comes to forcing imcompletions."},{"metadata":{"trusted":true},"cell_type":"code","source":"edge_points.drop('dist', axis=1).sort_values('coverCount', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}