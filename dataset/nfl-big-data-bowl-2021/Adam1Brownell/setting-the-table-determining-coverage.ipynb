{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport time \nimport pandas as pd\nimport numpy as np\nimport os\nimport math\nimport datetime\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"offense_pos = ['QB','WR','RB','TE','FB','HB','P','LS','K']\n\ncoverage_pd = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021-bonus/coverages_week1.csv\",\n                    header = 0)\ndisplay(coverage_pd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Play Position Dictionary\n\nwk1_pd = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/week1.csv',header=0)\nplay_data = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/plays.csv',header=0)\ngame_data = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/games.csv', header=0)\n\n\npositions = wk1_pd.position.unique()\nlabel_encode_dict = dict()\nfor i in range(len(positions)):\n    label_encode_dict[positions[i]] = i\n    \nlabel_encode_dict['P'] = 19\nlabel_encode_dict['LS'] = 20\nlabel_encode_dict['K'] = 21\nlabel_encode_dict['DT'] = 22","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert times from strings (lame) to datetimes\nwk1_pd['time'] = wk1_pd.time.astype('datetime64[ns]')\n\n# See the shortest play\nx = wk1_pd.copy()\nx = x.groupby(['gameId','playId'])['frameId'].max().values\nplt.hist(x)\nplt.gca().axvline(min(x),linestyle='--',color='gray',label='Min Frame ({})'.format(min(x)))\nplt.gca().axvline(np.mean(x),linestyle='--',color='green',label='Avg Frame ({})'.format(int(np.mean(x))))\nplt.legend(frameon=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(1,7):\n#     cntr = 0\n#     for j in dif_secs:\n#         if j>=i:\n#             cntr += 1\n#     print('At least',i,'seconds: {:.2f}% of plays'.format(100*cntr/len(dif_secs)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Play-Level Man/Zone Predictions\n\nUsing a GBM trained on player position for the first several seconds of the play with provided labels to determine if play is a Man or Zone play"},{"metadata":{},"cell_type":"markdown","source":"### Step 1: Preprocessing 1 Week"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NEW PLAYER POSITION DATASET\nplyr_pd = wk1_pd.copy()\n\n# Convert times from strings (lame) to datetimes\nplyr_pd['time'] = plyr_pd.time.astype('datetime64[ns]')\n\n# Pos at Ball Snap\nd_schema_pd = plyr_pd[plyr_pd.event == 'ball_snap'][['gameId','playId','x','y','displayName','position']]\nd_schema_pd.columns = ['gameId','playId','x0','y0','displayName','position']\n\n# Time at Ball Snap\ntime_data = plyr_pd[plyr_pd.event == 'ball_snap'][['gameId','playId','time']].drop_duplicates()\ntime_data.columns = ['gameId','playId','snap_time']\n\n# time file\nplyr_time = plyr_pd.merge(time_data, on=['gameId','playId'])\n\n\n## Remove plays that run longer than 3 seconds\n# plyr_time = plyr_time.merge(plyr_time.groupby(['gameId','playId'])['time'].max(), on=['gameId','playId']) \\\n#                      .merge(plyr_time.groupby(['gameId','playId'])['time'].min(), on=['gameId','playId'])\n# plyr_time['diff'] = (plyr_time.time_y - plyr_time.time)/ np.timedelta64(1, 's')\n# plyr_time = plyr_time[plyr_time['diff'] > 3]\n# plyr_time = plyr_pd.merge(time_data, on=['gameId','playId'])\n\n# Pos at 1-3 Seconds\nfor i in range(1,4):\n    sec_loc = plyr_time[plyr_time.time <= plyr_time.snap_time + datetime.timedelta(seconds=i)]\n    sec_loc = sec_loc.groupby(['gameId','playId'])['frameId'].max()\n\n    sec_loc = plyr_time.merge(sec_loc, on=['gameId','playId'])\n    sec_loc = sec_loc[sec_loc.frameId_x == sec_loc.frameId_y][['gameId','playId','x','y','displayName']]\n    sec_loc.columns = ['gameId','playId','x{}'.format(i),'y{}'.format(i),'displayName']\n\n    d_schema_pd = d_schema_pd.merge(sec_loc, on=['gameId','playId','displayName'], how='inner')\n\n\n# Add Offense Column\nd_schema_pd['offense'] = [i in offense_pos for i in d_schema_pd.position]\n\n# Get Football Position\nfootball_pos = wk1_pd[wk1_pd.team == 'football'][wk1_pd.frameId == 1][['gameId','playId','x']]\nfootball_pos.columns = ['gameId','playId','fball_x']\n\nd_schema_pd = d_schema_pd.merge(football_pos, on=['gameId','playId']) \n\n# If I just want to use Defense\nd_schema_pd = d_schema_pd[~d_schema_pd.offense]\n\n# Found out max players on a play\nx = d_schema_pd.copy()\nx['cntr'] = 1\n\nplay_group = x.groupby(['gameId','playId'])['cntr'].sum().values\nprint(max(play_group))\n\n# Make all coordinates relative to Football axis\nfor i in range(4):\n    col = 'x{}'.format(i)\n    d_schema_pd[col] = d_schema_pd[col] - d_schema_pd['fball_x']\n    d_schema_pd.loc[(d_schema_pd.offense) & (d_schema_pd[col] > 0), col] *= -1\n    d_schema_pd.loc[(~d_schema_pd.offense) & (d_schema_pd[col] < 0), col] *= -1\n    \n\nd_schema_pd = d_schema_pd[d_schema_pd.displayName != 'Football']\nd_schema_pd['position'] = [label_encode_dict[i] for i in d_schema_pd.position]\n\nd_schema_pd = d_schema_pd.drop(['fball_x','offense','displayName'],axis=1) \\\n                         .groupby(['gameId','playId']).agg(lambda x: list(x))\n\np = play_data[['gameId','playId','quarter','down','yardsToGo','yardlineNumber','defendersInTheBox','numberOfPassRushers']] \\\n               .set_index(['gameId','playId'])\n\nd_schema_pd2 = d_schema_pd.join(p).fillna(-1) \\\n                         .join(coverage_pd.set_index(['gameId','playId'])).dropna()\n\n# d_schema_pd3 = d_schema_pd.join(p).dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def row_maker3(row):\n    x0 = row['x0']\n    y0 = row['y0']\n    x1 = row['x1']\n    y1 = row['y1']\n    x2 = row['x2']\n    y2 = row['y2']\n    x3 = row['x3']\n    y3 = row['y3']\n    pos =  row['position']\n    \n    l = sorted(zip(x0, pos, y0, x1, y1, x2, y2, x3,y3))\n    x0, pos, y0, x1, y1, x2, y2, x3, y3 = zip(*l)\n        \n    row_dict ={\n        'position':pos,\n        'x0':x0,\n        'y0':y0,\n        'x1':x1,\n        'y1': y1,\n        'x2':x2,\n        'y2':y2,\n        'x3':x3,\n        'y3':y3\n    }\n            \n    for i in range(18):\n        if len(x0)-1 < i:\n            for j in range(4):\n                for k in ['x','y']:\n                    row[k+str(j)+'_'+str(i)] = 99\n            row['pos_'+str(i)] = 99\n        else:\n            for j in range(4):\n                for k in ['x','y']:\n                    row[k+str(j)+'_'+str(i)] = row_dict[k+str(j)][i]\n            row['pos_'+str(i)] = row_dict['position'][i]\n         \n    row['coverage_label'] = 'Man' in row['coverage']\n    \n    for i in row_dict.keys():\n        row = row.drop([i])\n    return(row)\n \nt = time.time()\nbs_list_bin = d_schema_pd2.apply(row_maker3, axis=1)\nprint(int(time.time()-t),'seconds to run')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = bs_list_bin.drop(['coverage','coverage_label'],axis=1).values\ny = bs_list_bin.coverage_label.values\n\nCounter(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 2: Building Model & Producing Accuracy Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = bs_list_bin.drop(['coverage','coverage_label'],axis=1).values\ny = bs_list_bin.coverage_label.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\ndtree_model = DecisionTreeClassifier(max_depth = 150).fit(X_train, y_train) \n# dtree_model = GradientBoostingClassifier(max_depth = 150).fit(X_train, y_train) \ndtree_predictions = dtree_model.predict(X_test) \n\ndisp = plot_confusion_matrix(dtree_model, X_test, y_test,\n                                 cmap=plt.cm.Blues,\n                                 normalize='true')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = sum(dtree_predictions == y_test)/len(y_test)\nf1 = f1_score(y_test,dtree_predictions)\n\nplot_roc_curve(dtree_model, X_test, y_test)\nplt.plot([0,1],[0,1],linestyle='--',color='red')\nplt.ylim([0,1])\nplt.xlim([0,1])\nplt.title('ACC: {}% || F1: {:.2f}'.format(int(acc*100),f1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3: Collecting Predictions for all 17 Weeks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Collect all results for all weeks\n# week1 = pd.read_csv('../input/nfl-big-data-bowl-2021/week1.csv')\n# week2 = pd.read_csv('../input/nfl-big-data-bowl-2021/week2.csv')\n# week3 = pd.read_csv('../input/nfl-big-data-bowl-2021/week3.csv')\n# week4 = pd.read_csv('../input/nfl-big-data-bowl-2021/week4.csv')\n# week5 = pd.read_csv('../input/nfl-big-data-bowl-2021/week5.csv')\n# week6 = pd.read_csv('../input/nfl-big-data-bowl-2021/week6.csv')\n# week7 = pd.read_csv('../input/nfl-big-data-bowl-2021/week7.csv')\n# week8 = pd.read_csv('../input/nfl-big-data-bowl-2021/week8.csv')\n# week9 = pd.read_csv('../input/nfl-big-data-bowl-2021/week9.csv')\n# week10 = pd.read_csv('../input/nfl-big-data-bowl-2021/week10.csv')\n# week11 = pd.read_csv('../input/nfl-big-data-bowl-2021/week11.csv')\n# week12 = pd.read_csv('../input/nfl-big-data-bowl-2021/week12.csv')\n# week13 = pd.read_csv('../input/nfl-big-data-bowl-2021/week13.csv')\n# week14 = pd.read_csv('../input/nfl-big-data-bowl-2021/week14.csv')\n# week15 = pd.read_csv('../input/nfl-big-data-bowl-2021/week15.csv')\n# week16 = pd.read_csv('../input/nfl-big-data-bowl-2021/week16.csv')\n# week17 = pd.read_csv('../input/nfl-big-data-bowl-2021/week7.csv')\n\n# week = pd.concat([week1,week2], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def row_maker4(row):\n    x0 = row['x0']\n    y0 = row['y0']\n    x1 = row['x1']\n    y1 = row['y1']\n    x2 = row['x2']\n    y2 = row['y2']\n    x3 = row['x3']\n    y3 = row['y3']\n    pos =  row['position']\n    \n    l = sorted(zip(x0, pos, y0, x1, y1, x2, y2, x3,y3))\n    x0, pos, y0, x1, y1, x2, y2, x3, y3 = zip(*l)\n        \n    row_dict ={\n        'position':pos,\n        'x0':x0,\n        'y0':y0,\n        'x1':x1,\n        'y1': y1,\n        'x2':x2,\n        'y2':y2,\n        'x3':x3,\n        'y3':y3\n    }\n            \n    for i in range(18):\n        if len(x0)-1 < i:\n            for j in range(4):\n                for k in ['x','y']:\n                    row[k+str(j)+'_'+str(i)] = 99\n            row['pos_'+str(i)] = 99\n        else:\n            for j in range(4):\n                for k in ['x','y']:\n                    row[k+str(j)+'_'+str(i)] = row_dict[k+str(j)][i]\n            row['pos_'+str(i)] = row_dict['position'][i]\n         \n#     row['coverage_label'] = 'Man' in row['coverage']\n    \n    for i in row_dict.keys():\n        row = row.drop([i])\n    return(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"play_pred_pd = pd.DataFrame(columns=['gameId','playId','isManPlay'])\n\nfor week_num in range(1,18):\n    print('Starting wk', week_num)\n    t = time.time()\n    week = pd.read_csv('../input/nfl-big-data-bowl-2021/week{}.csv'.format(week_num))\n    \n    # Prepro from above\n    # NEW PLAYER POSITION DATASET\n    plyr_pd = week.copy()\n\n    # Convert times from strings (lame) to datetimes\n    plyr_pd['time'] = plyr_pd.time.astype('datetime64[ns]')\n\n    # Pos at Ball Snap\n    d_schema_pd = plyr_pd[plyr_pd.event == 'ball_snap'][['gameId','playId','x','y','displayName','position']]\n    d_schema_pd.columns = ['gameId','playId','x0','y0','displayName','position']\n\n    # Time at Ball Snap\n    time_data = plyr_pd[plyr_pd.event == 'ball_snap'][['gameId','playId','time']].drop_duplicates()\n    time_data.columns = ['gameId','playId','snap_time']\n\n    # time file\n    plyr_time = plyr_pd.merge(time_data, on=['gameId','playId'])\n\n\n    ## Remove plays that run longer than 3 seconds\n#     plyr_time = plyr_time.merge(plyr_time.groupby(['gameId','playId'])['time'].max(), on=['gameId','playId']) \\\n#                          .merge(plyr_time.groupby(['gameId','playId'])['time'].min(), on=['gameId','playId'])\n#     plyr_time['diff'] = (plyr_time.time_y - plyr_time.time)/ np.timedelta64(1, 's')\n#     plyr_time = plyr_time[plyr_time['diff'] > 3]\n#     plyr_time = plyr_pd.merge(time_data, on=['gameId','playId'])\n\n    # Pos at 1-3 Seconds\n    for i in range(1,4):\n        sec_loc = plyr_time[plyr_time.time <= plyr_time.snap_time + datetime.timedelta(seconds=i)]\n        sec_loc = sec_loc.groupby(['gameId','playId'])['frameId'].max()\n\n        sec_loc = plyr_time.merge(sec_loc, on=['gameId','playId'])\n        sec_loc = sec_loc[sec_loc.frameId_x == sec_loc.frameId_y][['gameId','playId','x','y','displayName']]\n        sec_loc.columns = ['gameId','playId','x{}'.format(i),'y{}'.format(i),'displayName']\n\n        d_schema_pd = d_schema_pd.merge(sec_loc, on=['gameId','playId','displayName'], how='inner')\n\n\n    # Add Offense Column\n    d_schema_pd['offense'] = [i in offense_pos for i in d_schema_pd.position]\n\n    # Get Football Position\n    football_pos = week[week.team == 'football'][week.frameId == 1][['gameId','playId','x']]\n    football_pos.columns = ['gameId','playId','fball_x']\n\n    d_schema_pd = d_schema_pd.merge(football_pos, on=['gameId','playId']) \n\n    # If I just want to use Defense\n    d_schema_pd = d_schema_pd[~d_schema_pd.offense]\n\n    # Make all coordinates relative to Football axis\n    for i in range(4):\n        col = 'x{}'.format(i)\n        d_schema_pd[col] = d_schema_pd[col] - d_schema_pd['fball_x']\n        d_schema_pd.loc[(d_schema_pd.offense) & (d_schema_pd[col] > 0), col] *= -1\n        d_schema_pd.loc[(~d_schema_pd.offense) & (d_schema_pd[col] < 0), col] *= -1\n\n\n    d_schema_pd = d_schema_pd[d_schema_pd.displayName != 'Football']\n    d_schema_pd['position'] = [label_encode_dict[i] for i in d_schema_pd.position]\n\n    d_schema_pd = d_schema_pd.drop(['fball_x','offense','displayName'],axis=1) \\\n                             .groupby(['gameId','playId']).agg(lambda x: list(x))\n\n    p = play_data[['gameId','playId','quarter','down','yardsToGo','yardlineNumber','defendersInTheBox','numberOfPassRushers']] \\\n                   .set_index(['gameId','playId']).fillna(-1)\n\n    d_schema_pd2 = d_schema_pd.join(p)\n    \n    # Apply Function from above \n    bs_list_bin = d_schema_pd2.apply(row_maker4, axis=1)\n    print(int(time.time()-t),'seconds to process week',week_num,'...')\n    \n    # Predict\n    bs_list_bin['isManPlay'] = dtree_model.predict_proba(bs_list_bin.values)[:,0]\n    week_preds = bs_list_bin[['isManPlay']].reset_index()\n    \n    play_pred_pd = play_pred_pd.append(week_preds)\n    \n    print('Number of Total Plays Score: {:,}'.format(len(play_pred_pd)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"play_pred_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"100*len(play_pred_pd[play_pred_pd.isManPlay == 1.0])/19227","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# play_pred_pd.to_csv('play_pred.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Player-level Man-Zone Predictions\n\nUsing an unsupervised method described here and implemented here, determine likelihood that a player is in man coverage"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build dataset\n# Build player-level labels\n    # Based on coverage type\n# unsupervised, check groupings ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_pd = wk1_pd[~wk1_pd.position.isin(offense_pos)][['gameId','playId','position','displayName']].drop_duplicates().copy()\nx_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_num_pd = x_pd.copy()\n\n# Count the number of safeties\nsafety_pos = ['SS','FS','S']\npos_num_pd['isSafety'] = 0\npos_num_pd['isSS'] = 0\npos_num_pd.loc[pos_num_pd.position.isin(safety_pos), 'isSafety'] = 1\n\n# Count the number of DBs\ndb_pos = ['CB','DB']\npos_num_pd['isDB'] = 0\npos_num_pd.loc[pos_num_pd.position.isin(db_pos), 'isDB'] = 1\n\n\npos_num_pd = pos_num_pd.groupby(['gameId','playId']).agg({'isSafety':['sum'],'isDB':['sum']}) \\\n                      .reset_index()\npos_num_pd.columns = ['gameId','playId','numS','numDB']\n\nx_pd2 = x_pd.merge(coverage_pd, on=['gameId','playId']) \\\n            .merge(pos_num_pd, on=['gameId','playId']) \n\nx_pd2['playerCoverage'] = np.nan\n\nfor i in range(6):\n    if i == 0:\n        x_pd2.loc[(x_pd2.coverage=='Cover 0 Man'), 'playingMan'] = True\n        x_pd2.loc[(x_pd2.coverage=='Prevent Zone' ), 'playingMan'] = False\n        continue\n        \n    # If Cover X Man == i, we can check if we know coverages\n    x_pd2.loc[(x_pd2.coverage=='Cover {} Man'.format(i))&\n              (x_pd2.numS <= i)&\n              (x_pd2.position.isin(safety_pos)), 'playingMan'] = False\n\n    x_pd2.loc[(x_pd2.coverage=='Cover {} Man'.format(i))&\n              (x_pd2.numS >= i)&\n              (x_pd2.position.isin(db_pos)), 'playingMan'] = True\n    \nx_pd2.loc[x_pd2.coverage.str.contains('Zone')&((x_pd2.position.isin(safety_pos))|(x_pd2.position.isin(db_pos))),'playingMan'] = False\n        \nlen(x_pd2[~x_pd2.playingMan.isna()]),100*len(x_pd2[~x_pd2.playingMan.isna()])/len(x_pd2)         \n# x_pd2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_pd2.groupby('playingMan').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate Dataset\n\ndef process_player_data(week):\n    weekArray = np.array(week)\n    previousEvent = 'ball_snap'\n    for i, instance in enumerate(weekArray):\n        event = instance[8]\n        frameId = instance[13]\n        if (previousEvent == 'ball_snap' and event != 'ball_snap') or frameId == 1:\n            weekArray[i][8] = 'ball_snap'\n            previousEvent = 'ball_snap'\n        elif (event == 'ball_snap'):\n            previousEvent = 'between_snap'\n        elif (previousEvent == 'between_snap' and event != 'pass_forward'):\n            weekArray[i][8] = 'between_snap'\n            previousEvent = 'between_snap'\n        elif (event == 'pass_forward'):\n            weekArray[i][8] = 'after_thrown'\n            previousEvent = 'after_thrown'\n        elif (previousEvent == 'after_thrown' and frameId != 1):\n            weekArray[i][8] = 'after_thrown'\n            previousEvent = 'after_thrown'\n\n    weekMod = pd.DataFrame(weekArray, columns=week.columns)\n    week['event'] = weekMod['event']\n    weekMod = week\n\n    varX = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['x'].agg(['var']).reset_index().rename(columns={\"var\": \"varX\"})\n    varY = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['y'].agg(['var']).reset_index().rename(columns={\"var\": \"varY\"})\n    varS = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['s'].agg(['var']).reset_index().rename(columns={\"var\": \"varS\"})\n\n    groupedWeek = weekMod.groupby(['gameId', 'playId', 'frameId'])\n    playerXY = {}\n    for name, group in groupedWeek:\n        playerXY[name] = []\n        for row in group.iterrows():\n            data = [row[1]['nflId'], row[1]['team'], row[1]['x'], row[1]['y'], row[1]['dir']]\n            playerXY[name].append(data)\n\n    features = list(weekMod.columns)\n    weekArray = np.array(weekMod)\n    minOppDist = []\n    for player in weekArray:\n        try:\n            if player[features.index('team')] != 'football':\n                opponentPositions = playerXY[(player[features.index('gameId')], player[features.index('playId')], player[features.index('frameId')])]\n                distances = []\n                directions = []\n                opponents = []\n                xs = []\n                ys = []\n                for oppPos in opponentPositions: \n                    if player[features.index('team')] != oppPos[1] and player[features.index('team')] != 'football' and oppPos[1] != 'football':\n                        dx = (player[features.index('x')] - oppPos[2])**2\n                        dy = (player[features.index('y')] - oppPos[3])**2\n                        dist = np.sqrt(dx+dy)\n                        distances.append(dist)\n                        directions.append(oppPos[4])\n                        opponents.append(oppPos[0])\n                        xs.append(oppPos[2])\n                        ys.append(oppPos[3])\n                minDist = min(distances)\n                closestOpponent = opponents[np.argmin(distances)]\n                opponentDir = directions[np.argmin(distances)]\n                opponentX = xs[np.argmin(distances)]\n                opponentY = ys[np.argmin(distances)]\n                summary = [player[features.index('gameId')], player[features.index('playId')], player[features.index('frameId')], player[features.index('nflId')], minDist, closestOpponent, opponentDir, opponentX, opponentY]\n                minOppDist.append(summary)\n        except:\n            continue\n\n    minOppDist = pd.DataFrame(minOppDist, columns=['gameId', 'playId', 'frameId', 'nflId', 'oppMinDist', 'closestOpp(nflId)', 'oppDir', 'oppX', 'oppY'])\n    weekMod = pd.merge(weekMod, minOppDist, how='left', on=['gameId', 'frameId', 'playId', 'nflId'])\n    oppVar = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['oppMinDist'].agg(['var']).reset_index().rename(columns={\"var\": \"oppVar\"})\n    oppMean = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['oppMinDist'].agg(['mean']).reset_index().rename(columns={\"mean\": \"oppMean\"})\n\n    features = list(weekMod.columns)\n    weekArray = np.array(weekMod)\n    minMateDist = []\n    for player in weekArray:\n        if player[features.index('team')] != 'football':\n            matePositions = playerXY[(player[features.index('gameId')], player[features.index('playId')], player[features.index('frameId')])]\n            distances = []\n            mates = []\n            xs = []\n            ys = []\n            for matePos in matePositions: \n                if player[features.index('team')] == matePos[1] and player[features.index('nflId')] != matePos[0] and player[features.index('team')] != 'football' and matePos[1] != 'football':\n                    dx = (player[features.index('x')] - matePos[2])**2\n                    dy = (player[features.index('y')] - matePos[3])**2\n                    dist = np.sqrt(dx+dy)\n                    distances.append(dist)\n                    mates.append(matePos[0])\n                    xs.append(oppPos[2])\n                    ys.append(oppPos[3])\n            minDist = min(distances)\n            closestMate = mates[np.argmin(distances)]\n            mateX = xs[np.argmin(distances)]\n            mateY = ys[np.argmin(distances)]\n            summary = [player[features.index('gameId')], player[features.index('playId')], player[features.index('frameId')], player[features.index('nflId')], minDist, closestMate, mateX, mateY]\n            minMateDist.append(summary)\n\n    minMateDist = pd.DataFrame(minMateDist, columns=['gameId', 'playId', 'frameId', 'nflId', 'mateMinDist', 'closestMate(nflId)', 'mateX', 'mateY'])\n    weekMod = pd.merge(weekMod, minMateDist, how='left', on=['gameId', 'frameId', 'playId', 'nflId'])\n    mateVar = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['mateMinDist'].agg(['var']).reset_index().rename(columns={\"var\": \"mateVar\"})\n    mateMean = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['mateMinDist'].agg(['mean']).reset_index().rename(columns={\"mean\": \"mateMean\"})\n\n    diffDir = np.absolute(weekMod['dir'] - weekMod['oppDir'])\n    weekMod['diffDir'] = diffDir\n    oppDirVar = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['diffDir'].agg(['var']).reset_index().rename(columns={\"var\": \"oppDirVar\"})\n    oppDirMean = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['diffDir'].agg(['mean']).reset_index().rename(columns={\"mean\": \"oppDirMean\"})\n\n    ratio = weekMod['oppMinDist'] / np.sqrt((weekMod['oppX'] - weekMod['mateX'])**2 + (weekMod['oppY'] - weekMod['mateY'])**2)\n    weekMod['oppMateDistRatio'] = ratio\n    oppMateDistRatioMean = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['oppMateDistRatio'].agg(['mean']).reset_index().rename(columns={\"mean\": \"meanOppMateDistRatio\"})\n    oppMateDistRatioVar = weekMod.groupby(['gameId', 'playId', 'event', 'nflId'])['oppMateDistRatio'].agg(['var']).reset_index().rename(columns={\"var\": \"varOppMateDistRatio\"})\n\n    features = [varX, varY, varS, oppVar, oppMean, mateVar, mateMean, oppDirVar, oppDirMean, oppMateDistRatioMean, oppMateDistRatioVar]\n    for feature in features:\n        weekMod = pd.merge(weekMod, feature, how='left', on=['gameId', 'event', 'playId', 'nflId'])\n       \n    weekMod = weekMod.dropna(subset=['nflId']).fillna(0)\n\n    return(weekMod)\n\nstart = time.time()\nweekMod = process_player_data(wk1_pd)\nprint(' {:.2f} minutes to process'.format((time.time()-start)/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\n\nsamples = x_pd2[~x_pd2.playingMan.isna()][['gameId','playId','displayName','playingMan']]\n\nsamples['playingMan'] = samples['playingMan'].astype(int)\n\nWeekMod = samples \\\n                .merge(weekMod, on=['gameId','playId','displayName']) \\\n                .drop(['time','event','jerseyNumber','route','team','playDirection'],axis=1)\n\nWeekMod = WeekMod[~WeekMod.position.isin(offense_pos)]\n\nWeekMod['position'] = [label_encode_dict[i] for i in WeekMod.position]\n\nmsk = np.random.rand(len(samples)) < 0.8\n\ntrain_samples = samples[msk].drop(['playingMan'],axis=1)\ntest_samples = samples[~msk].drop(['playingMan'],axis=1)\n\nX_test = WeekMod.merge(test_samples, on=['gameId','playId','displayName']).dropna(subset=['nflId'])\ny_test = X_test.playingMan.values\ny_labels = X_test[['gameId','playId','displayName','playingMan']]\nX_test = X_test.drop(['playingMan','gameId','playId','displayName','nflId'],axis=1)\n\nX_train = WeekMod.merge(train_samples, on=['gameId','playId','displayName']).dropna(subset=['nflId'])\ny_train =  X_train.playingMan.values\nX_train = X_train.drop(['playingMan','gameId','playId','displayName','nflId'],axis=1)\n\ndtree_model = GradientBoostingClassifier(max_depth = 150).fit(X_train, y_train) \ndtree_predictions = dtree_model.predict(X_test) \n\nprint(' {:.2f} minutes to process & train'.format((time.time()-start)/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=[16,10])\n# plt.plot(threshold,acc_list, linestyle='--', label='Acc')\n# plt.plot(threshold,f1_list,  linestyle='--', label='F1')\n# plt.legend()\n# plt.title('Best: {:.2f} ({:.2f})'.format(best_idx/100,best_val))\n# plt.ylim([0,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validate\n\ny_labels['isManPred'] = dtree_predictions\n\ny = y_labels.groupby(['gameId','playId','displayName'])[['isManPred']].mean() \\\n            .merge(\n                    y_labels[['gameId','playId','displayName','playingMan']].drop_duplicates(),\n                    on=['gameId','playId','displayName']\n                  )\nacc_list = []\nf1_list = []\nthreshold = [i for i in range(1,100)]\nbest_idx = 1\nbest_val = 0\nfor i in threshold:\n    p = (y.isManPred >= (i/100)).astype(int)\n    \n    acc = sum(p == y.playingMan)/len(p)\n    f1 = f1_score(p,y.playingMan)\n    \n    acc_list.append(acc)\n    f1_list.append(f1)\n    if f1 > best_val:\n        print(i,f1)\n        best_val = f1\n        best_idx = i\n    \nplt.title('Best: {:.2f} ({:.2f})'.format(best_idx/100,best_val))\n\ncm = confusion_matrix((y.isManPred >= (best_idx/100)).astype(int), y.playingMan)\n\ndf_cm = pd.DataFrame(cm)\n# plt.figure(figsize=(10,7))\nsn.set(font_scale=1.4) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n\nplt.title('{:.0f}% Acc || {:.2f} F1'.format(100*(cm[0][0]+cm[1][1])/len(y), f1_score((y.isManPred >= (best_idx/100)).astype(int),y.playingMan)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thresholding is super low so there are very few False Positives\n# If the model predicts Zone, it absolutely is a Zone player\n# If the model predicts Man, check if the play-level expects man as well","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict\nplayer_pd = pd.DataFrame()\nstart = time.time()\nfor week_num in range(1,18):\n    print('Starting wk', week_num)\n    t = time.time()\n    week = pd.read_csv('../input/nfl-big-data-bowl-2021/week{}.csv'.format(week_num))\n    \n    week = process_player_data(week).dropna(subset=['nflId'])\n    \n    week = week[~week.position.isin(offense_pos)]\n    \n    context = week[['playId','gameId','displayName']]\n    \n    week = week.drop(['time','gameId','playId','event','jerseyNumber','route',\n                      'nflId','displayName','team','playDirection'],axis=1) \n    \n    \n    week['position'] = [label_encode_dict[i] for i in week.position]\n    \n    dtree_predictions = dtree_model.predict(week) \n    \n    context['isManCoverage'] = dtree_predictions\n    \n    context = context.groupby(['gameId','playId','displayName'])[['isManCoverage']].mean()\n    \n    context['isManCoverage'] = (context.isManCoverage >= (best_idx/100)).astype(int)\n    \n    player_pd = player_pd.append(context)\n    \n    print('Processing & Scoring took {:.2f} minutes ({:.2f}min, {:,} players total)'.format((time.time()-t)/60,\n                                                                                            (time.time()-start)/60,\n                                                                                             len(player_pd)))\n# player_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"player_pd.to_csv('player_level_man_pred.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./player_level_man_pred.csv\"> Download File </a>"},{"metadata":{},"cell_type":"markdown","source":"# Find Targetted Receivers"},{"metadata":{"trusted":true},"cell_type":"code","source":"shortHandDict = dict()\noffense_pos = ['QB','WR','RB','TE','FB','HB']\n\nfor week_num in range(1,18):\n    print('Starting wk', week_num)\n    week = pd.read_csv('../input/nfl-big-data-bowl-2021/week{}.csv'.format(week_num))\n    \n    off_data = week[week.position.isin(offense_pos)]\n    for name in off_data.displayName.unique():\n\n        shorthand = name[0]+'.'+name.split()[1]\n\n        \n        # If there is a name duplication, mark it for later cleaning\n        # Else, add it to dictionary\n        if shorthand in shortHandDict:\n            if shortHandDict[shorthand] != name:\n                shortHandDict[shorthand] = shorthand+'*'\n        else:\n            shortHandDict[shorthand] = name\n  \ntrouble_makers = ['Ty.Williams','Dam. Williams','D.Cruikshank','De.Thomas','M.Crosby',\n                  'R.Kelly','J.Hardee','B.Sowell','S.Shields','D.Dawkins','J.Lewis',\n                  'S.Pulley','A.Villanueva','T.Decker','Dar.Williams','J.Staley','G.Fant',\n                  'S.Hubbard','K.Williams']\n\nfor name in trouble_makers:\n    shortHandDict[name] = name+'*'\n    \nshortHandDict['E.St'] = 'Equanimeous St. Brown'\n# shortHandDict['O.Beckham'] = 'Odell Beckham Jr.'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_plays = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/plays.csv',header=0)\nnew_plays['target_receiver'] = new_plays.playDescription.str.extract(r'[o|t][r|o]\\s([A-Z][a-z]*\\.\\s?\\S+[a-z])[\\s\\.]')\nnew_plays = new_plays.replace({\"target_receiver\": shortHandDict}).fillna('None')\n   \nnew_plays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm\nstart = time.time()\n\ndup_plays = new_plays[new_plays.target_receiver.str.contains('\\*')]\nfor week_num in range(1,18):\n    week = pd.read_csv('../input/nfl-big-data-bowl-2021/week{}.csv'.format(week_num))\n    print('Checking wk {}'.format(week_num))\n    \n    for i in range(len(dup_plays)):\n        bad_play = dup_plays.iloc[i]\n        g = bad_play.gameId\n        p = bad_play.playId\n        abbrev_name = bad_play.target_receiver.split('.')\n        first_name = abbrev_name[0]\n        last_name = abbrev_name[1][:-1].strip()\n\n        play = week.query('gameId == @g and playId == @p')\n        \n        if len(play) > 1:\n\n            # This misses a few plays because of Defense playing Offense,\n            # But lowers runtime + avoids labelling an offensive player as defense\n            players = play[play.position.isin(offense_pos)].displayName.unique()\n\n            name_options = 0\n            for name in players:\n                if (name[:len(first_name)] == first_name) and (name.split()[-1] == last_name):\n                    new_plays.loc[(new_plays['gameId'] == g) & (new_plays['playId'] == p), 'target_receiver'] = name\n                    name_options+=1\n            if name_options > 1:\n                print(\"Yikes, Play ({}, {}, Week {}) has {} name options\".format(g,p,wk,name_options))\n            if name_options == 0:\n                # The missing names that trigger this are not labelled in play_level data... so it is fine\n                # to label a \"None\"\n                print(\"Yikes, Could not find replacement for {} ({}, {}, Week {})\".format(abbrev_name,g,p, week_num))\n                new_plays.loc[(new_plays['gameId'] == g) & (new_plays['playId'] == p), 'target_receiver'] = \"None\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation\nactual = pd.read_csv('../input/nfl-big-data-bowl-2021-bonus/targetedReceiver.csv',header=0)\nconversion_pd = pd.read_csv('../input/nfl-big-data-bowl-2021/players.csv', header=0)\n\nnew_plays.loc[new_plays.target_receiver.str.contains('DJ Moore'), 'target_receiver'] = 'D.J. Moore'\n\nactual_pd = conversion_pd[['nflId','displayName']].merge(actual, left_on='nflId',right_on='targetNflId')\nactual_pd.loc[actual_pd.displayName.str.contains('Odell Beckham'), 'displayName'] = 'Odell Beckham'\nactual_pd.loc[actual_pd.displayName.str.contains('DJ Moore'), 'displayName'] = 'D.J. Moore'\ntestr_pd = actual_pd.merge(new_plays[['gameId','playId','target_receiver']], on=['gameId','playId'])\n\nright = testr_pd[(testr_pd.target_receiver != 'None')&(testr_pd.displayName == testr_pd.target_receiver)]\n100*len(right)/len(testr_pd[testr_pd.target_receiver != 'None'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding Defenders for Targetted Receiver"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the Coverage Player for every Receiver\nimport time\nstart = time.time()\n\nmatch_pd = pd.DataFrame()\nid_to_name = pd.DataFrame() \npress = pd.DataFrame() \n\n# Check if coverage is < 5yrds from scrimmage \"press\"\ncoverage_pos = ['DB','CB','S','SS','FS','ILB','OLB']\n\nfor week_num in range(1,18):\n    print('Starting wk', week_num)\n    week = pd.read_csv('../input/nfl-big-data-bowl-2021/week{}.csv'.format(week_num))\n\n    fball_pos = week[(week.displayName == 'Football')&(week.event=='ball_snap')][['gameId','playId','x']].drop_duplicates() \\\n                 .rename(columns={\"x\": \"los\"})\n\n    week = week.merge(fball_pos, on=['gameId','playId'])\n\n    week['press'] = False\n    week.loc[(week.event == 'ball_snap') & (week.position.isin(coverage_pos)) & (abs(week.x-week.los) <=2), 'press'] = True\n\n    week['chuck'] = False\n    week.loc[(week.event == 'ball_snap') & (week.position.isin(coverage_pos)) & (abs(week.x-week.los) <=5), 'chuck'] = True\n\n    _press = week[(week.event == 'ball_snap')][['gameId','playId','nflId','press','chuck']].drop_duplicates()\n\n    press = press.append(_press)\n\n    start_frame_pd = week.query(\"event == 'ball_snap'\") \\\n                            [['gameId','playId','frameId']].drop_duplicates() \\\n                            .rename(columns={\"frameId\": \"startFrame\"})\n\n    end_frame_pd = week.query(\"event == 'pass_forward'\") \\\n                            [['gameId','playId','frameId']].drop_duplicates() \\\n                            .rename(columns={\"frameId\": \"endFrame\"})\n\n    week = week.merge(start_frame_pd, on=['gameId','playId']) \\\n                     .merge(end_frame_pd, on=['gameId','playId']) \\\n                     .query(\"frameId >= startFrame and frameId <= endFrame and team != 'football'\")\n\n\n    # Find coverage for every receiver\n    id_to_name = id_to_name.append(week[['nflId','displayName']]).drop_duplicates()\n\n    wrs = week[week.position=='WR']['nflId'].unique()\n\n    for wr in wrs:\n        target_pd = week[week.nflId == wr][['gameId','playId','frameId','x','y']] \\\n               .rename(columns={\"x\": \"target_x\", 'y':'target_y'})\n\n        wr_play = week.merge(target_pd, on=['gameId','playId','frameId'])\n\n        wr_play['dist'] = np.sqrt((wr_play.x-wr_play.target_x)**2+(wr_play.y-wr_play.target_y)**2)\n\n        wr_play.loc[wr_play.position.isin(offense_pos), 'dist'] = 100\n\n        tot_dists = wr_play.groupby(['gameId','playId','nflId'])[['dist']].sum()\n\n        closest_pd = tot_dists.groupby(['gameId','playId']).min() \n\n        cov_pd = tot_dists.reset_index().merge(closest_pd, on=['gameId','playId','dist']) \\\n                         [['gameId','playId','nflId']] \\\n                         .rename(columns={'nflId':'cov_nflId'})\n\n        cov_pd['nflId'] = wr\n\n        cov_pd = cov_pd.merge(id_to_name, on='nflId',how='left') \\\n                       .drop('nflId',axis=1) \\\n                       .rename(columns={'displayName':'covering','cov_nflId':'nflId'})\n\n        match_pd = match_pd.append(cov_pd)\n\n    print(int(time.time()-start),'total seconds...')\n    \nx = match_pd.merge(new_plays[['gameId','playId','passResult','playResult','epa','target_receiver']],\n              on=['gameId','playId'],how='left') \\\n        .dropna() \\\n        .merge(press,on=['gameId','playId','nflId'],how='left') \\\n        .merge(id_to_name.drop_duplicates(),on='nflId') \\\n        .rename(columns={'displayName':'defender'}) \nx['targetted'] = x.target_receiver == x.covering\nx = x.drop(['target_receiver','nflId'], axis=1)\nx = x[['gameId','playId','defender','covering','press','chuck','targetted','passResult','playResult','epa']]\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.to_csv('coverage_pairings.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_pd = new_plays[['gameId','playId','target_receiver']].copy()\n\nnew_plays2 = new_plays.copy()\n\noffense_pos = ['QB','WR','RB','TE','FB','HB']\nmerge_pd = new_plays[['gameId','playId','target_receiver']].copy()\n\nwk_cntr = 1\ntarg_plays = pd.DataFrame()\nfor week_num in range(1,18):\n    print('Starting wk', week_num)\n    week = pd.read_csv('../input/nfl-big-data-bowl-2021/week{}.csv'.format(week_num))\n    \n    print('Processing Week {}...'.format(week_num))\n    \n    week = week.merge(merge_pd, on=['gameId','playId'], how='left')\n    week['is_target'] = week.displayName == week.target_receiver\n    \n    start_frame_pd = week.query(\"event == 'ball_snap'\") \\\n                        [['gameId','playId','frameId']].drop_duplicates() \\\n                        .rename(columns={\"frameId\": \"startFrame\"})\n\n    end_frame_pd = week.query(\"event == 'pass_forward' or event == 'pass_shovel'\") \\\n                            [['gameId','playId','frameId']].drop_duplicates() \\\n                            .rename(columns={\"frameId\": \"endFrame\"})\n\n    week = week.merge(start_frame_pd, on=['gameId','playId']) \\\n               .merge(end_frame_pd, on=['gameId','playId']) \\\n               .query(\"frameId >= startFrame and frameId <= endFrame and team != 'football'\")\n\n    \n    target_pd = week[week.is_target][['gameId','playId','frameId','x','y']] \\\n                       .rename(columns={\"x\": \"target_x\", 'y':'target_y'})\n\n\n    week = week.merge(target_pd, on=['gameId','playId','frameId'])\n\n\n    week['dist'] = np.sqrt((week.x-week.target_x)**2+(week.y-week.target_y)**2)\n\n    week.loc[week.position.isin(offense_pos), 'dist'] = 100\n\n    tot_dists = week.groupby(['gameId','playId','nflId'])[['dist']].sum()\n\n    closest_pd = tot_dists.groupby(['gameId','playId']).min() \n    closest_pd['is_coverage'] = True\n\n    tot_dists['nflId'] = [i[2] for i in tot_dists.index]\n\n    week = tot_dists.merge(closest_pd, on=['gameId','playId','dist'],how='left') \\\n                 .fillna(False) \\\n                 .merge(week, on=['gameId','playId','nflId']) \\\n                 .drop(['dist_x','dist_y'], axis=1) \n    \n    c_pd = week[week.is_coverage][['gameId','playId',\n                                 'displayName','jerseyNumber']] \\\n      .drop_duplicates() \\\n      .rename(columns={\"displayName\": \"coverage_player\", \n                       'jerseyNumber':'coverage_jersey'})\n\n    t_pd = week[week.is_target][['gameId','playId',\n                                       'displayName','jerseyNumber']] \\\n          .drop_duplicates() \\\n          .rename(columns={\"displayName\": \"target_player\", \n                           'jerseyNumber':'target_jersey'})\n\n    new_targs = c_pd.merge(t_pd, on=['gameId', 'playId']) \n        \n    targ_plays = targ_plays.append(new_targs)\n\n\nnew_plays2 = new_plays2.merge(targ_plays, on=['gameId','playId'],how='left') \n\nnew_plays2.loc[new_plays2.target_receiver == 'None', 'target_player'] = 'None'\n\nnew_plays2 = new_plays2.drop(['target_receiver'], axis=1)\n\nnew_plays2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_plays2.to_csv('enriched_plays.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"context['isManPred2'] = (context.isManPred >= (1/100)).astype(int)\ncontext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\n\ny_labels['isManPred'] = dtree_predictions\n\ny = y_labels.groupby(['gameId','playId','displayName'])[['isManPred']].mean() \\\n            .merge(\n                    y_labels[['gameId','playId','displayName','playingMan']].drop_duplicates(),\n                    on=['gameId','playId','displayName']\n                  )\ncm = confusion_matrix(y.isManPred, y.playingMan)\n\ndf_cm = pd.DataFrame(cm)\n# plt.figure(figsize=(10,7))\nsn.set(font_scale=1.4) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n\nplt.title('{:.0f}% Acc'.format(100*(cm[0][0]+cm[1][1])/len(y)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = sum(y.isManPred.values == y.playingMan.values)/len(y)\nf1 = f1_score(y_test,dtree_predictions)\n\nplot_roc_curve(dtree_model, X_test, y_test)\nplt.plot([0,1],[0,1],linestyle='--',color='red')\nplt.ylim([0,1])\nplt.xlim([0,1])\nplt.title('ACC: {}% || F1: {:.2f}'.format(int(acc*100),f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tmp), len(test_samples), len(X_test), len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"298960+58949","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_labels['preds'] = dtree_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x = x.drop(['time','event','jerseyNumber','route','team','playDirection'],axis=1).dropna()\n\nfor col in x.columns:\n    if col in ['gameId','playId','displayName']:\n        continue\n    x[col] = np.float32(x[col])\n\ntest_samples = x_pd2[~x_pd2.playingMan.isna()][['gameId','playId','displayName']].sample(frac=0.2)\n\nX_test = x.merge(test_samples, on=['gameId','playId','displayName']).dropna()\ny_test = X_test.playingMan.values\ny_labels = X_test[['gameId','playId','displayName','playingMan']]\nX_test = X_test.drop(['playingMan','displayName','gameId','playId'],axis=1)\n\nX_train = x.merge(test_samples, on=['gameId','playId','displayName'],how='outer').dropna()\ny_train = X_train.playingMan.values\nX_train = X_train.drop(['playingMan','displayName','gameId','playId'],axis=1)\n\n# dtree_model = DecisionTreeClassifier(max_depth = 10).fit(X_train, y_train) \ndtree_model = GradientBoostingClassifier(max_depth = 150).fit(X_train, y_train) \ndtree_predictions = dtree_model.predict(X_test) \n\ndisp = plot_confusion_matrix(dtree_model, X_test, y_test,\n                                 cmap=plt.cm.Blues,\n                                 normalize='true')\n\n# x_pd2.merge(test_samples,on=['gameId','playId','displayName'],how='outer')\n\n# X = bs_list_bin.drop(['coverage','coverage_label'],axis=1).values\n# y = bs_list_bin.coverage_label.values\n\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train), len(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add the Player-level labels generated above\nx_pd2\n# Train an additional classifier, splitting on the player-level \n\n# Get Acc metrics\n    # Sum up predictions and that is prob of man coverage\n# Loop through and score every player","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Can I take the ML model and use ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_pd2['num_cover'] = x_pd2.coverage.str.extract('([0-9])')\nx_pd2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_pd2.coverage.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekArray = np.array(week)\npreviousEvent = 'ball_snap'\nfor i, instance in enumerate(weekArray):\n    event = instance[8]\n    frameId = instance[13]\n    if (previousEvent == 'ball_snap' and event != 'ball_snap') or frameId == 1:\n        weekArray[i][8] = 'ball_snap'\n        previousEvent = 'ball_snap'\n    elif (event == 'ball_snap'):\n        previousEvent = 'between_snap'\n    elif (previousEvent == 'between_snap' and event != 'pass_forward'):\n        weekArray[i][8] = 'between_snap'\n        previousEvent = 'between_snap'\n    elif (event == 'pass_forward'):\n        weekArray[i][8] = 'after_thrown'\n        previousEvent = 'after_thrown'\n    elif (previousEvent == 'after_thrown' and frameId != 1):\n        weekArray[i][8] = 'after_thrown'\n        previousEvent = 'after_thrown'\n        \nweekMod = pd.DataFrame(weekArray, columns=week.columns)\nweek['event'] = weekMod['event']\nweekMod = week","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect\nbs_list_bin.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}