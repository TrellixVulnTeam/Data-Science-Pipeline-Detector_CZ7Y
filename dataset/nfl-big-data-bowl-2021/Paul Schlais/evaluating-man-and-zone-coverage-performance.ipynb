{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Introduction\n\nSome elite pass defense performances show up in NFL box scores like the audio guy at a concert: they are doing their job correctly if you don’t notice them. For example, Nnamdi Asomugha was awarded First-Team All-Pro for elite cornerback play in 2010 [with only six pass deflections and zero interceptions on the season](https://www.nfl.com/players/nnamdi-asomugha/stats/career). His great play passed the \"eye test\", but two of the most visible statistics associated with individual pass defense did not fully reflect his performance.\n\nThis report develops a methodology to identify top pass defenders through a non-traditional metric and briefly investigates receiver-defender height disparity as a potential predictor of pass play success. The following two questions are posed:\n\n* **When targeted, which players excel at defending the pass in man and zone coverage schemes?**\n* **Does the height difference between a receiver and defender influence defensive performance?**\n\nTo begin answering these questions, each play during the 2018 season needs to have:\n\n1.\tA man or zone coverage scheme label, and \n2.\tA value for pass attempt difficulty, to ultimately provide a baseline for comparison between players.\n"},{"metadata":{},"cell_type":"markdown","source":"# Predicting Man/Zone Coverage\n\n\nThe 2021 NFL Big Data Bowl competition provided labeled coverages for each play during Week 1.  The man/zone classifier developed in this report attempts to maintain generality from week-to-week and team-to-team by only looking at player tracking data within the play without considering game situation, teams, or unique players.\n\nVarious aspects of the play are quantified at the snap, a “freeze frame” after 1.5 seconds, and cumulative until a pass/fumble/sack event or a maximum of 4 seconds to remove any influence of extended play improvisation. The “freeze frame” allows time for the true scheme to develop out of the potentially deceptive pre-snap look and also determine which players in the tracking data are rushing the passer instead of covering. The 4-second max threshold was determined from an accuracy optimization exercise when developing the final classifier.\n\nOver 40 different features were generated as potential predictors encompassing many different aspects of the play, averaged into a single value for the play:\n\n* Features for distance between players, speed, and various ratios as proposed in [this publication](https://arxiv.org/abs/1906.11373) \n* Percentage of time a defender is facing the line of scrimmage/QB\n* Number of defenders in coverage\n* Number of defenders deep at the snap and freeze frame (10+ yards past line of scrimmage)\n* Outer receiver-defender pairs: ratio of the length of the receiver route to the final distance between the pair\n* Outermost defenders inside/outside leverage: at the snap and average throughout the play\n* Depth of CBs at the snap and freeze frame\n\nAn iterative study was done to select the classification algorithm, downselect features, and confirm no overfitting based on 5-fold cross validation during training. A 20% holdout set was used to evaluate expected model performance. The following 7 features are used in the final linear SVC model (pictorial representation shown in the figure below), in order of importance:  \n\n* **rec_space_play_mean:** Average distance from each offensive receiver beyond the line of scrimmage to the nearest coverage defender\n* **depth_play_mean:** Average depth past the line of scrimmage of all coverage defenders\n* **cb_depth_snap_min:** Depth of the cornerback closest to the line of scrimmage at the snap\n* **dist_cover_play_mean:** Average distance from each coverage defender to the closest offensive receiver\n* **dist_shadow_out_play_mean:** Average inside/outside leverage of outer defenders to outer receivers (players paired at the snap)\n* **n_deep_frz:** Number of defenders 10+ yards past the line of scrimmage at the freeze frame\n* **speed_play_var:** Average variance of the speed of each coverage defender\n\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import Image\nImage('../input/bdb-2021-figures/model_features.png', width=800)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model's confusion matrix for the holdout set Week 1 plays is shown below.\n\n|             | **Predicted Man** | **Predicted Zone** | Recall |\n|-------------|:-------------:|:--------------:|:------:|\n| **Actual Man**  | 45            | 23             | 66%    |\n| **Actual Zone** | 13            | 125            | 91%    |\n| Precision   | 78%           | 84%            | **Accuracy: 83%** (206 total) |"},{"metadata":{},"cell_type":"markdown","source":"The model accuracy for the holdout set is on-par with the 85% and 84% average accuracies for the cross-validation training and test sets, respectively. The model is less accurate classifying actual man coverage plays than zone, but the precision is balanced. For an aggregate and comparative analysis over the course of a season, this is acceptable, while taking note that any results for man coverage have an artificially deflated sample size.\n\n## Model Validation\n\nA comparison of the model’s predictions for Week 1 plays vs. down, distance, location on field, quarter, and time-to-release confirms that misclassifications do not follow a pattern with respect to game situation (not shown).\n\nPredictions were generated for all valid plays of Weeks 2-17. The percentage of plays each team played in man coverage over the entire season is shown below."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image(\"../input/bdb-2021-figures/team_man_coverage_pct.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparing these results to 2018 coverage data provided by Sports Info Solutions (SIS) via [this tweet](https://twitter.com/keeganabdoo/status/1078722411338522624?lang=en) shows that in general, this model captures some real season-level trends:\n\n* The model predicts New England played the most man coverage of all teams, aligning with the SIS data. Detroit, Kansas City, and Baltimore are also high-man teams. \n* Indianapolis, Los Angeles Chargers, Carolina, and Arizona are low-man (high-zone) teams.\n\nHowever, the model misses on a few teams in terms of man-coverage percentage relative ranking: Dallas is far too high, Chicago and Houston are far too low. There are variations within the broad labels of man and zone coverage that this model is not capturing. \n\nOverall, because many season-level trends are captured with this model, the model’s man/zone predictions for each play of Weeks 2-17 supports a relative ranking analysis at a season-level."},{"metadata":{},"cell_type":"markdown","source":"# Normalizing for Pass Difficulty\n\nTo find individuals or specific height difference over- and under-performance, pass difficulty should be normalized so that defenders are compared against their expected performance before being compared against each other.\n\nOne outcome-based measure of pass difficulty is completion percentage. Actual completion percentage has a strong relationship with the downfield distance of the target, as shown in the figure below. To turn this relationship into a continuous function that can be evaluated for individual plays for “expected performance,” the relationship is modeled as a generalized logistic function to follow a qualitative explanation of the relationship:\n\n* Passes behind the line of scrimmage tend to be “safe” throws (natural completion rate, asymptote)\n* Increasing the distance downfield increases the difficulty (negative slope)\n* As the pass attempts approach deep downfield, the difference in difficulty is small for each incremental yard (asymptote)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image('../input/bdb-2021-figures/cmp_pct_vs_depth.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This simple model provides a reasonable approximation for expected completion percentage, with residuals on the order of a few completion percentage points. This level of accuracy is sufficient to answer the driving comparison questions.\n\n## Completion Percentage Below Expected (CPBE)\n\nThe targeted defender on any given play is identified as the closest defender to the target at the time the ball arrives. Once aggregated, comparing a defender’s completion percentage against their expected completion percentage gives a normalized measure of over- or under-performance. This report defines a “Completion Percentage Below Expected” (CPBE) metric as the expected completion percentage (mean) minus the actual completion percentage:\n\n$CPBE = \\frac{\\sum_{i=1}^{N_{plays}} CP_{expected,i}}{N_{plays}} -CP_{actual}$\n\nwhere:\n\n$CP_{expected,i}$ = Expected completion percentage for the $i$th play where the defender is targeted\n\n$N_{plays}$ = Number of plays the defender is targeted\n\n$CP_{actual}$ = Actual completion percentage (completions/targets)\n\nPositive CPBE values mean the defender allowed a lower completion percentage than expected, which is good for the defensive team.\n"},{"metadata":{},"cell_type":"markdown","source":"# Question 1: When targeted, which players excel at defending the pass in man and zone coverage?\n\nAll plays during the 2018 season are grouped by targeted defender and defensive man or zone coverage scheme. CPBE is calculated in each subset (with a minimum of 20 targets in man/zone each) and plotted for CB- and DB-listed players in the figure below. The above-average players are in the top right quadrant of the plot."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image('../input/bdb-2021-figures/cb_cpbe_compare.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Larger markers represent more targets which implies less uncertainty of the CPBE values. Deeper blue means a higher percentage of targets when the defense plays man, while deeper red means a higher percentage of targets when the defense plays zone. The top 10 over-performing players in terms of standardized distance from the average man/zone CPBE origin are labeled. A few interesting insights from the plot:\n\n* **Marlon Humphrey** ranked highest in terms of standardized distance from the origin and shows well above average performance in both man and zone, with a balanced coverage type ratio. This result implying elite performance is consistent with traditional metrics like pass deflections and interceptions because his 2018 stats  are nearly identical to his All-Pro 2019 season ([15/2 and 14/3, respectively](https://www.nfl.com/players/marlon-humphrey/stats/)) \n* **Denzel Ward** and **Stephon Gilmore** rank high in man coverage CPBE while being targeted mostly in man, which adds more certainty to their ranking.\n* **Tramon Williams**, **Tramaine Brock**, and **Terrance Mitchell** are all in the upper quadrant but have small sample sizes. Their high performance has more uncertainty than the others mentioned earlier due to their lack of targets.\n\nFiltering the players in the top-performing quadrant for negative average EPA in both man and zone coverage, only four CB/DB remain:\n\n* **Marlon Humphrey**\n* **Jalen Ramsey**\n* **Stephon Gilmore**\n* **Mackensie Alexander**\n\nThis type of analysis is useful for identifying strengths and weaknesses of individual players and could be used to refine game plans and inform roster decisions. The short analysis above uses the CB and DB positions as an example, but it is easily extensible to safeties and linebackers. The analysis could also be further refined to look at defending against specific offensive positions (RB, TE, WR, etc.)."},{"metadata":{},"cell_type":"markdown","source":"# Question 2: Does the height difference between a receiver and defender influence defensive performance?\n\nInstead of grouping by player, the player measurement data is merged with the target/defender per play data to group by height disparity. The average EPA for each height disparity and man/zone coverage is shown in the figure below. The distribution of height disparity (not shown) is normal-like with a mode of 2 inches, so values for larger disparities contain more uncertainty."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image('../input/bdb-2021-figures/hgt_adv_epa.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general, the mean EPA increases as the receiver increases in height relative to the defender, however this may be influenced by the distribution of passes present in each grouping; the average pass is further downfield as the receiver height advantage increases.\n\nThe comparison of CPBE vs. height difference is shown below."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image('../input/bdb-2021-figures/hgt_adv_cpbe.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There does not appear to be a meaningful trend for CPBE vs. height disparity. This comparison was also computed for different defense positions, offense positions, and defender-receiver position combinations with the same end conclusion (not shown). Based on the data, it appears that **height difference alone is not a significant indicator of pass defense performance.**\n"},{"metadata":{},"cell_type":"markdown","source":"# Conclusions\n\n* **Answer to Question 1:** Completion Percentage Below Expected (CPBE) provides a simple but useful comparative metric of individual defender performance and can be extended to different position groups as well. When looking at CPBE and EPA in both man and zone coverage schemes, there were 4 CB/DB in 2018 that are above average in CPBE and negative EPA in both man and zone coverage (shown below): \n\n    * Marlon Humphrey\n    * Jalen Ramsey\n    * Stephon Gilmore\n    * Mackensie Alexander\n    \n* **Answer to Question 2:** On its own, the receiver-defender height disparity has no noticeable correlation with defensive performance for the 2018 season data. This conclusion does not change when stratifying by man and zone coverage schemes or looking at different defender-receiver position combinations.\n\n**Other Conclusions:**\n\n* With 7 features and a simple linear SVC model, defensive man and zone coverage schemes can be predicted with reasonable accuracy for labeling within an aggregate analysis (84%).\n* The downfield distance of a pass has a strong relationship with the observed completion percentage.\n\n## Future Work\n\n* Building a stronger predictive model for Expected Completion Percentage will make the CPBE values useful as a standalone performance metric beyond the comparative analysis in this report.\n* Building stronger and more granular classifier for specific coverage schemes (Cover 1 Man, Cover 3 Zone, etc.) could be used to identify strengths and weaknesses at an individual and team level.\n* Discovering the holy grail of defending Aaron Rodgers, because the past decade has shown that no amount of scheming, manpower, or analytics puts a dent in his passing performance. (*GO PACK GO!*)\n"},{"metadata":{},"cell_type":"markdown","source":"# Appendix (Code)"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"### ======== NFL Analysis utility functions and constants ==================== ###\nimport pandas as pd\nimport numpy as np\n\ndef _rgb(r, g, b):\n    # Converts RGB range from 0-255 to 0-1 for matplotlib.\n    # Returns np.array of length 3.\n    return np.array([r, g, b]) / 255.0\n\n# --------- CONSTANTS --------------------------- ####\n\nFIELD_SIZE_X = 120.0  # yards, field goal to field goal (back of endzones)\nFIELD_SIZE_Y = 53.3  # yards, sideline to sideline\nTEAM_COLORS = {'ARI': {'main': _rgb(155, 35, 63), 'secondary': _rgb(255, 255, 255)},\n               'ATL': {'main': _rgb(0, 0, 0), 'secondary': _rgb(255, 255, 255)},\n               'BAL': {'main': _rgb(26, 25, 95), 'secondary': _rgb(255, 255, 255)},\n               'BUF': {'main': _rgb(0, 51, 141), 'secondary': _rgb(198, 12, 48)},\n               'CAR': {'main': _rgb(0, 133, 202), 'secondary': _rgb(16, 24, 32)},\n               'CHI': {'main': _rgb(11, 22, 42), 'secondary': _rgb(200, 56, 3)},\n               'CIN': {'main': _rgb(251, 79, 20), 'secondary': _rgb(255, 255, 255)},\n               'CLE': {'main': _rgb(255, 60, 0), 'secondary': _rgb(49, 29, 0)},\n               'DAL': {'main': _rgb(0, 34, 68), 'secondary': _rgb(134, 147, 151)},\n               'DEN': {'main': _rgb(0, 34, 68), 'secondary': _rgb(251, 79, 20)},\n               'DET': {'main': _rgb(0, 118, 182), 'secondary': _rgb(176, 183, 188)},\n               'GB': {'main': _rgb(24, 48, 40), 'secondary': _rgb(255, 184, 28)},\n               'HOU': {'main': _rgb(3, 32, 47), 'secondary': _rgb(167, 25, 48)},\n               'IND': {'main': _rgb(0, 44, 95), 'secondary': _rgb(162, 170, 173)},\n               'JAX': {'main': _rgb(0, 103, 120), 'secondary': _rgb(16, 24, 32)},\n               'KC': {'main': _rgb(227, 24, 55), 'secondary': _rgb(255, 255, 255)},\n               'LA': {'main': _rgb(0, 53, 148), 'secondary': _rgb(255, 209, 0)},\n               'LAC': {'main': _rgb(0, 42, 94), 'secondary': _rgb(255, 194, 14)},\n               'MIA': {'main': _rgb(0, 142, 151), 'secondary': _rgb(252, 76, 2)},\n               'MIN': {'main': _rgb(79, 38, 131), 'secondary': _rgb(255, 255, 255)},\n               'NE': {'main': _rgb(0, 34, 68), 'secondary': _rgb(176, 183, 188)},\n               'NO': {'main': _rgb(211, 188, 141), 'secondary': _rgb(16, 24, 31)},\n               'NYG': {'main': _rgb(1, 35, 82), 'secondary': _rgb(163, 13, 45)},\n               'NYJ': {'main': _rgb(18, 87, 64), 'secondary': _rgb(255, 255, 255)},\n               'OAK': {'main': _rgb(0, 0, 0), 'secondary': _rgb(165, 172, 175)},\n               'PHI': {'main': _rgb(0, 76, 84), 'secondary': _rgb(165, 172, 175)},\n               'PIT': {'main': _rgb(16, 24, 32), 'secondary': _rgb(255, 182, 18)},\n               'SEA': {'main': _rgb(0, 34, 68), 'secondary': _rgb(105, 190, 40)},\n               'SF': {'main': _rgb(170, 0, 0), 'secondary': _rgb(173, 153, 93)},\n               'TB': {'main': _rgb(213, 10, 10), 'secondary': _rgb(10, 10, 8)},\n               'TEN': {'main': _rgb(12, 35, 64), 'secondary': _rgb(75, 146, 219)},\n               'WAS': {'main': _rgb(63, 16, 16), 'secondary': _rgb(255, 182, 18)}}\n\n\n# -------------- FUNCTIONS -------------------------------------------\n\ndef transform_tracking_data(track_df, inplace=False):\n    \"\"\"\n    Standardizes the tracking data so that all offensive plays have the same reference frame (Madden camera)\n\n    Transforms all positional attributes: x, y, o, dir. Returns a copy of the dataframe. Increasing x is downfield for\n    the offense, increasing y is towards the left sideline\n    :param track_df: [DataFrame] tracking data\n    :param inplace: [boolean] determine if transformation should be made in place or on a copy of the DataFrame\n    :return: DataFrame if inplace=False, otherwise None\n    \"\"\"\n    if inplace:\n        out_df = track_df  # work on actual DataFrame\n    else:\n        out_df = track_df.copy()  # only apply changes to a copy of the DataFrame\n\n    # get indexing for plays moving to the left (right is the standard)\n    i_left = (out_df.playDirection == 'left')\n\n    # transform X, Y\n    out_df.loc[i_left, 'x'] = FIELD_SIZE_X - out_df.loc[i_left, 'x']\n    out_df.loc[i_left, 'y'] = FIELD_SIZE_Y - out_df.loc[i_left, 'y']\n\n    # convert the orientations so that 0 points to left sideline\n    # - see figure here for more info (https://www.kaggle.com/c/nfl-big-data-bowl-2021/data)\n    out_df.loc[i_left, 'o'] = (out_df.loc[i_left, 'o'] + 180) % 360\n    out_df.loc[i_left, 'dir'] = (out_df.loc[i_left, 'dir'] + 180) % 360\n\n    if inplace:\n        return None  # modified inplace\n    else:\n        return out_df\n\n\n### ==== Feature generation, model training/evaluation, model validation ================= ###\n\n# standard imports\nimport pandas as pd\nimport numpy as np\nimport os.path\n\n# model training imports\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n\n\n# --- FEATURE GENERATION FUNCTIONS ----------------------------------------------\n\ndef create_play_features(play_track_df, game_df, play_df, t_defender_thresh=1.5, t_scheme_develop=4, t_reaction_time=0):\n    ### THE INPUT TRACKING DATA MUST BE NORMALIZED FOR DIRECTION BEFORE INPUT INTO THIS FUNCTION\n    # inputs:\n    #     - play_track_df: DataFrame of the raw player tracking data for an individual play.\n    #                      MUST ONLY BE FOR A SINGLE PLAY, CANNOT HANDLE MULTIPLE PLAYS.\n    #     - game_df: DataFrame for the game data (games.csv)\n    #     - play_df: DataFrame for the play data (play.csv)\n    #     - t_defender_thresh: time in seconds after the snap to determine which players are in coverage\n    #     - t_scheme_develop: time in seconds after the snap to set as a max time threshold\n    #                         (i.e. before the play breaks down, after which the movement\n    #                          is not always indicative of the coverage scheme)\n    #     - t_reaction_time: time in seconds after the ball thrown to continue taking statistics (paths\n    #                        won't change until players realize the ball has been thrown)\n\n    # local constants\n    DEF_DEEP_THRESH = 10  # yards behind the line of scrimmage considered \"deep\" coverage\n\n    # work on a copy of the data rather than the actual data (for temporary features), drop duplicate rows\n    play_track_df = play_track_df.copy().drop_duplicates()\n\n    # get the current play gameId and playId\n    game_id = play_track_df.gameId.iloc[0]\n    play_id = play_track_df.playId.iloc[0]\n\n    # determine who has the ball (team code)\n    home_abbr = game_df[game_df.gameId == game_id].iloc[0]['homeTeamAbbr']\n\n    abbr_possess = play_df[(play_df.gameId == game_id) & (play_df.playId == play_id)].iloc[0]['possessionTeam']\n\n    if abbr_possess == home_abbr:\n        team_poss = 'home'\n        team_def = 'away'\n    else:\n        team_poss = 'away'\n        team_def = 'home'\n\n    # ------------- FEATURE GENERATION SETUP/INTERMEDIATE CALCULATIONS ----------------------\n\n    # get play information\n    x_los = play_track_df.x[(play_track_df.team == 'football') & (play_track_df.frameId == 1)].iloc[0]\n\n    # save the distance downfield of all observations relative to the line of scrimmage\n    play_track_df['depth'] = play_track_df['x'] - x_los\n\n    # get frameId for specific points in the play (exclude handoff: not a material pivot part of the play,\n    # also sometimes occurs prior to the snap)\n    pivot_events = ['pass_forward', 'qb_sack', 'fumble', 'qb_strip_sack', 'pass_shovel']\n\n    frame_max = play_track_df.frameId.max()\n    frame_snap = play_track_df[play_track_df.event == 'ball_snap']['frameId'].iloc[0]\n    if np.any(play_track_df.event.isin(pivot_events)):\n        # find the frameId of the earliest of the pivot events\n        # - account for errors on individual players: group by event, find the median frame for each event, then\n        #   take the minimum of the medians to get the first event (essentially voting then min)\n        frame_pivot = (play_track_df.loc[play_track_df.event.isin(pivot_events), ['event', 'frameId']]\n                       .groupby('event').median().min().iloc[0]\n                       + int(round(10 * t_reaction_time)))\n    else:\n        frame_pivot = frame_max\n\n    # save important frameId's in the play:\n    frame_start = frame_snap\n    frame_cover_freeze = min(frame_max, frame_pivot, int(round(frame_snap + 10 * t_defender_thresh)))\n    frame_scheme_develop = int(frame_snap + round(10 * t_scheme_develop))\n    frame_end = min(frame_pivot, frame_scheme_develop, frame_max)\n\n    # filter out data from frames outside of the range (frame_start <= F <= frame_end)\n    play_track_df = play_track_df[(play_track_df.frameId >= frame_start) & (play_track_df.frameId <= frame_end)]\n\n    # ----- SAVE SLICES OF DATAFRAME FOR DEFENDERS AND COVERAGE AND ELIGIBLE RECEIVERS ----\n\n    ### get defensive player tracks that are in coverage (i.e. not blitzing/rushing the passer)\n    cover_players = play_track_df.nflId[(play_track_df.frameId == frame_cover_freeze) &\n                                        (play_track_df.team == team_def) &\n                                        (play_track_df.depth > 0)]\n    def_track = play_track_df[play_track_df.nflId.isin(cover_players)].pivot(\n        index='frameId', columns='nflId', values=['x', 'depth', 'y', 's', 'a', 'dir', 'o'])\n\n    ### get offensive player tracks of eligible receivers (minus QB)\n    # all players\n    off_track = play_track_df[(play_track_df.team == team_poss) & (play_track_df.position != 'QB')].pivot(\n        index='frameId', columns='nflId', values=['x', 'depth', 'y', 's', 'a', 'dir', 'o'])\n\n    # players downfield (depth > 0)\n    downfield_players = play_track_df.nflId[(play_track_df.frameId == frame_cover_freeze) &\n                                            (play_track_df.team == team_poss) &\n                                            (play_track_df.depth > 0)]\n    # edge case where there are no downfield receivers at the time of throw: quick screen,\n    # goal-line, etc. --> classify all offensive players as \"downfield\"\n    if len(downfield_players) == 0:\n        downfield_players = play_track_df.nflId[(play_track_df.frameId == frame_cover_freeze) &\n                                                (play_track_df.team == team_poss) &\n                                                (play_track_df.position != 'QB')]\n\n    downfield_track = play_track_df[play_track_df.nflId.isin(downfield_players)].pivot(\n        index='frameId', columns='nflId', values=['x', 'depth', 'y', 's', 'a', 'dir', 'o'])\n\n    # ----- OUTERMOST OFF-DEF MATCHUP FEATURES --------------------------------------------------------\n\n    # get attributes for the outermost receivers and defenders at the snap to identify\n    # coverage as inside or outside technique\n\n    # identify outermost defenders at snap (get corresponding array column index)\n    min_def_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n                                      (play_track_df.team == team_def), 'y'].idxmin()\n    max_def_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n                                      (play_track_df.team == team_def), 'y'].idxmax()\n    right_def_nfl_id = play_track_df.nflId.loc[min_def_y_idx]\n    left_def_nfl_id = play_track_df.nflId.loc[max_def_y_idx]\n\n    # get outermost defender at snap Y-coordinates during the play\n    outer_def_y = np.hstack([play_track_df.y[play_track_df.nflId == left_def_nfl_id].to_numpy().reshape(-1, 1),\n                             play_track_df.y[play_track_df.nflId == right_def_nfl_id].to_numpy().reshape(-1, 1)])\n\n    # identify outermost receivers at snap (get corresponding array column index)\n    min_off_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n                                      (play_track_df.team == team_poss), 'y'].idxmin()\n    max_off_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n                                      (play_track_df.team == team_poss), 'y'].idxmax()\n    right_off_nfl_id = play_track_df.nflId.loc[min_off_y_idx]\n    left_off_nfl_id = play_track_df.nflId.loc[max_off_y_idx]\n\n    # get outermost receiver at snap Y-coordinates during the play\n    outer_off_y = np.hstack([play_track_df.y[play_track_df.nflId == left_off_nfl_id].to_numpy().reshape(-1, 1),\n                             play_track_df.y[play_track_df.nflId == right_off_nfl_id].to_numpy().reshape(-1, 1)])\n\n    # -- Determine if the defender shadows outside or inside of the outer receiver:\n    # -- inner likely man, outer likely zone. look at snap and aggregate until throw\n\n    # distance from the middle of the field\n    dist_def_mid = np.abs(53.3 / 2 - outer_def_y)\n    dist_off_mid = np.abs(53.3 / 2 - outer_off_y)\n    # def - off: positive if defender is outside, negative if defender is inside\n    dist_shadow_out = dist_def_mid - dist_off_mid\n\n    # aggregate over play (mean offset inside or outside)\n    dist_shadow_out_play = np.nanmean(dist_shadow_out, axis=0)\n\n    # ------ PLAY CHARACTERISTICS AT SPECIFIC FRAMES/POINTS IN TIME -----------------------\n\n    # find characteristics of scheme at the snap (line of scrimmage naturally divides offense + defense)\n    cb_id = play_track_df[play_track_df.position == 'CB']['nflId'].unique()\n    n_cb = len(cb_id)\n\n    if n_cb > 0:\n        # depth at snap\n        cb_depth_at_snap = play_track_df.loc[(play_track_df.frameId == frame_start)\n                                             & (play_track_df.nflId.isin(cb_id)), 'depth']\n\n    # find characteristics of players in coverage at the \"cover freeze time\"\n    n_deep_freeze = np.sum((play_track_df.nflId.isin(cover_players)) &\n                           (play_track_df.depth >= DEF_DEEP_THRESH) &\n                           (play_track_df.frameId == frame_cover_freeze))\n\n    # ------GENERATE FEATURES FOR EACH COVERAGE PLAYER AT EACH FRAME ---------------------\n\n    feature_data = {'depth_play_mean': [],\n                    'speed_play_var': [],\n                    'dist_cover_play_mean': [],\n                    }\n\n    # data that is not dependent on the specific player\n    x_off = off_track['x'].to_numpy()  # (n_frame, n_off) array\n    y_off = off_track['y'].to_numpy()  # (n_frame, n_off) array\n    x_def_full = def_track['x'].to_numpy()  # (n_frame, n_def) array\n    y_def_full = def_track['y'].to_numpy()  # (n_frame, n_def) array\n\n    ### --- loop over each cover player (defense) ---------------------------------------\n    for i, player in enumerate(cover_players):\n        x_player = def_track['x'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n        depth_player = def_track['depth'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n        y_player = def_track['y'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n        s_player = def_track['s'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n\n        # calculate distance to each player at each time\n        dist_off = np.sqrt((x_player - x_off) ** 2 + (y_player - y_off) ** 2)  # (n_frame, n_off) array\n        dist_off_min = np.nanmin(dist_off, axis=1)  # (n_frame,) array\n\n        # save average distance\n        feature_data['depth_play_mean'].append(np.nanmean(depth_player))\n        feature_data['speed_play_var'].append(np.nanvar(s_player))\n        feature_data['dist_cover_play_mean'].append(np.nanmean(dist_off_min))\n\n    # put results into a dataframe\n    def_df = pd.DataFrame(feature_data, index=cover_players)\n\n    ### -- loop over each downfield offensive player  (offense) ----------------------\n    downfield_data = {\n        'rec_space_play_mean': [],\n    }\n\n    for i, player in enumerate(downfield_players):\n        # extract location of player and put as column vector\n        x_player = downfield_track['x'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n        y_player = downfield_track['y'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n\n        # calculate distance to each defensive at each time\n        dist_to_defender = np.sqrt(\n            (x_player - x_def_full) ** 2 + (y_player - y_def_full) ** 2)  # (n_frame, n_def) array\n        # get distance to closest defender\n        dist_to_defender_min = np.nanmin(dist_to_defender, axis=1)  # (n_frame,) array\n\n        # save average of distance to closest defender\n        downfield_data['rec_space_play_mean'].append(np.nanmean(dist_to_defender_min))\n\n    # put results into a dataframe\n    downfield_df = pd.DataFrame(downfield_data, index=downfield_players)\n\n    # ----------- COLLECT ALL FEATURES INTO OUTPUT SERIES -------------------------\n\n    # return averages of features generated from applicable players, for play-level feature\n    out_data = pd.concat([def_df.mean(), downfield_df.mean()])\n\n    # add in number of deep defenders at the \"freeze frame\"\n    out_data['n_deep_frz'] = n_deep_freeze\n\n    # add in inside-outside technique feature\n    out_data['dist_shadow_out_play_mean'] = np.mean(dist_shadow_out_play)\n\n    # add in CB-specific feature (depth at snap of all cornerbacks)\n    if n_cb > 0:\n        out_data['cb_depth_snap_min'] = np.nanmin(cb_depth_at_snap)\n    else:\n        out_data['cb_depth_snap_min'] = 0\n\n    return out_data\n\n\ndef create_feature_dataframe(track_df, coverage_df, game_df, play_df, t_scheme_develop=4, t_reaction_time=0):\n    # Transform the raw tracking data so that all offensive plays face the same direction,\n    # group the tracking data for each play together\n    test_df_group = transform_tracking_data(track_df).groupby(['gameId', 'playId'])\n\n    # ------ Create the features for each play ---------------------\n    feature_df = pd.DataFrame()\n\n    col_names = []\n    values = []\n\n    # loop over each play\n    for (loop_game_id, loop_play_id), loop_track_df in test_df_group:\n\n        # error block for easier debugging if a particular play runs into an error\n        try:\n            features = create_play_features(loop_track_df,\n                                            game_df,\n                                            play_df,\n                                            t_scheme_develop=t_scheme_develop,\n                                            t_reaction_time=t_reaction_time)\n        except Exception as err:\n            print(f'error in gameId {loop_game_id}, playId {loop_play_id}')\n            raise err\n\n        # first loop: save the output dataframe column names (gameId, playId, all feature names)\n        if not col_names:  # empty\n            col_names.extend(['gameId', 'playId'])\n            col_names.extend(features.index.tolist())\n\n        # save the gameId, playId, and all feature values into a list\n        loop_values = [loop_game_id, loop_play_id]\n        loop_values.extend(features.values.tolist())\n        values.append(loop_values)\n\n    # convert the features into a dataframe (1 row per play), inner join on plays with labeled coverages\n    feature_df = pd.DataFrame(values, columns=col_names)\n    labeled_play_df = pd.merge(feature_df, coverage_df.dropna(), on=['gameId', 'playId'])\n\n    # split coverage into \"Cover X\" and Zone labels\n\n    # Zone\n    labeled_play_df['zone'] = 0\n    labeled_play_df.loc[labeled_play_df.coverage.str.contains('Zone'), 'zone'] = 1\n\n    # Cover X (Prevent will be listed as np.nan)\n    labeled_play_df['cover'] = np.nan\n    labeled_play_df.loc[labeled_play_df.coverage.str.contains('Cover'), 'cover'] = (\n        labeled_play_df.loc[labeled_play_df.coverage.str.contains('Cover'), 'coverage'].apply(\n            lambda x: int(x.split()[1]))\n    )\n\n    # return the feature dataframe\n    return labeled_play_df\n\n\n### SCRIPT TO GENERATE FEATURES AND TRAIN MODEL --------------------------------------------\n\n### --- load data --------\nbdb_base_path = '/kaggle/input/nfl-big-data-bowl-2021/'\nbdb_bonus_path = '/kaggle/input/nfl-big-data-bowl-2021-bonus'\ntrack_df = pd.read_csv(os.path.join(bdb_base_path, 'week1.csv'))\nplay_df = pd.read_csv(os.path.join(bdb_base_path, 'plays.csv'))\ngame_df = pd.read_csv(os.path.join(bdb_base_path, 'games.csv'))\ncoverage_df = pd.read_csv(os.path.join(bdb_bonus_path, 'coverages_week1.csv'))\n\n# create features\nlabeled_play_df = create_feature_dataframe(track_df, coverage_df, game_df, play_df)\n\n# drop the Prevent Zone play (for training only, final model correctly predicts Prevent as zone)\nzone_df = labeled_play_df[labeled_play_df.coverage != 'Prevent Zone'].copy()\n\n# train test split\ny = zone_df.zone\nX = zone_df.drop(columns=['gameId', 'playId', 'coverage', 'zone', 'cover'])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=123456)\n\n### TRAIN MODEL\n### -- After many side studies, SVC always performed the best at avoiding overfitting without sacrificing accuracy.\n###    Other algorithms investigated were Random Forest, AdaBoost, Naive Bayes, and KNN. PCA was also investigated\n###    as a feature down-selection method, but did not have a meaningful impact on results.\n\n# build pipeline\nestimators_svc = [('normalize', StandardScaler()),\n              ('clf', SVC())]\npipe_svc = Pipeline(estimators_svc)\n\n# build grid search\nparam_grid_svc = [\n    {\n        'clf': [LinearSVC(random_state=123456)],\n        'clf__class_weight': [None, 'balanced']\n    },\n    {\n        'clf': [SVC(random_state=123456)],\n        'clf__kernel': ['poly', 'rbf', 'sigmoid'],\n        'clf__gamma': ['scale', 'auto'],\n        'clf__class_weight': [None, 'balanced']\n}]\n\n# train model\nclf_zone = GridSearchCV(pipe_svc, param_grid=param_grid_svc, return_train_score=True)\nclf_zone.fit(X_train, y_train)\nprint(f'Best model and parameters: {clf_zone.best_params_}')\nprint(f'Train accuracy: {clf_zone.cv_results_[\"mean_train_score\"][clf_zone.best_index_]:.3f}')\nprint(f'CV test accuracy: {clf_zone.cv_results_[\"mean_test_score\"][clf_zone.best_index_]:.3f}')\n\n# evaluate on holdout set\ny_pred = clf_zone.predict(X_test)\nprint(f'Test accuracy: {accuracy_score(y_test, y_pred):.3f}')\nprint(f'Test f1: {f1_score(y_test, y_pred):.3f}')\nprint()\nprint('Classification Report:')\nprint(classification_report(y_test, y_pred))\nprint()\nprint('Confusion Matrix: ')\nprint(pd.DataFrame(confusion_matrix(y_test, y_pred),\n                   index=['Actual Man', 'Actual Zone'],\n                   columns=['Pred. Man', 'Pred. Zone']))\nprint()\n\n### - END SCRIPT ---------------------------------------------------------------------------\n\n## === Analysis ============================================================================\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.optimize as optim\n\n\n# --- Functions --------------------------------------------------------------------------------------------------\ndef closest_defender(track_df, game_df, play_df, target_df):\n    # returns the nflId of the defensive player closest to the targeted player at the resolution of the pass attempt\n    #\n    # inputs:\n    #     - track_df: DataFrame of the raw player tracking data for an individual play.\n    #                      MUST ONLY BE FOR A SINGLE PLAY, CANNOT HANDLE MULTIPLE PLAYS.\n    #     - game_df: DataFrame for the game data (games.csv)\n    #     - play_df: DataFrame for the play data (play.csv)\n\n    # initialize output series\n    cd_series = pd.Series([np.nan, np.nan], index=['nflId_def', 'dist_def'])\n\n    # add target as a column of the tracking DataFrame\n    play_track_df = pd.merge(track_df, target_df, how='left', on=['gameId', 'playId'])\n\n    # get the current play gameId and playId\n    game_id = play_track_df.gameId.iloc[0]\n    play_id = play_track_df.playId.iloc[0]\n\n    # determine who has the ball (team code)\n    home_abbr = game_df[game_df.gameId == game_id].iloc[0]['homeTeamAbbr']\n\n    abbr_possess = play_df[(play_df.gameId == game_id) & (play_df.playId == play_id)].iloc[0]['possessionTeam']\n\n    if abbr_possess == home_abbr:\n        team_def = 'away'\n    else:\n        team_def = 'home'\n\n    if np.any(play_track_df.targetNflId.isna()):\n        # no targeted receiver data for this play, return NaN\n        return cd_series\n\n    # constants\n    PASS_END_EVENTS = ['pass_arrived',\n                       'pass_outcome_interception',\n                       'pass_outcome_incomplete',\n                       'pass_outcome_caught']\n    # find the frameId of the earliest of the pass end events\n    # - account for errors on individual players: group by event, find the median frame for each event, then\n    #   take the minimum of the medians to get the first event (essentially voting then min)\n    frame_id = (play_track_df.loc[play_track_df.event.isin(PASS_END_EVENTS), ['event', 'frameId']]\n        .groupby('event').median().min().iloc[0])\n    if np.isnan(frame_id):\n        return cd_series  # no frame to choose closest defender, return nan\n\n    # get the data of the applicable frame\n    frame_df = play_track_df[play_track_df.frameId == frame_id]\n\n    # get the location of the targeted receiver\n    if not np.any(frame_df.nflId == frame_df.targetNflId):\n        # no target data for the play, discard\n        return cd_series\n\n    # QB throwaways consider the target the QB. If this is the case, do not consider closest defender.\n    tgt_position = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'position'].iloc[0]\n    if tgt_position == 'QB':\n        return cd_series\n\n    x_tgt = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'x'].iloc[0]\n    y_tgt = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'y'].iloc[0]\n\n    # get the location of defenders\n    if not np.any(frame_df.team == team_def):\n        # no defender data - return nan\n        return cd_series\n\n    nfl_id_def = frame_df.loc[frame_df.team == team_def, 'nflId'].to_numpy()\n    x_def = frame_df.loc[frame_df.team == team_def, 'x'].to_numpy()\n    y_def = frame_df.loc[frame_df.team == team_def, 'y'].to_numpy()\n\n    # calculate the distance between the defenders and the targeted receiver\n    dist_def = np.sqrt((x_def - x_tgt) ** 2 + (y_def - y_tgt) ** 2)\n\n    # determine the closest defender to the ball\n    idx_min = np.argmin(dist_def)\n\n    # return ID and distance for closest defender\n    cd_series['nflId_def'] = nfl_id_def[idx_min]\n    cd_series['dist_def'] = dist_def[idx_min]\n    return cd_series\n\n\ndef depth_of_pass(track_df, target_df):\n    # Calculates the depth of the pass attempt target past the line of scrimmage.\n    #\n    # inputs:\n    #     - track_df: DataFrame of the raw player tracking data for an individual play.\n    #                      MUST ONLY BE FOR A SINGLE PLAY, CANNOT HANDLE MULTIPLE PLAYS.\n    #     - target_df: DataFrame of the pass attempt targets per play (targetedReceiver.csv)\n\n    # transform the directionality of the data, add targeted receiver as a column\n    play_track_df = pd.merge(transform_tracking_data(track_df), target_df,\n                             how='left', on=['gameId', 'playId'])\n\n    if np.any(play_track_df.targetNflId.isna()):\n        # no targeted receiver data for this play, return NaN\n        return np.nan\n\n    # constants\n    PASS_END_EVENTS = ['pass_arrived',\n                       'pass_outcome_interception',\n                       'pass_outcome_incomplete',\n                       'pass_outcome_caught']\n    # find the frameId of the earliest of the pass end events\n    # - account for errors on individual players: group by event, find the median frame for each event, then\n    #   take the minimum of the medians to get the first event (essentially voting then min)\n    frame_id = (play_track_df.loc[play_track_df.event.isin(PASS_END_EVENTS), ['event', 'frameId']]\n        .groupby('event')\n        .median().min().iloc[0])\n\n    if np.isnan(frame_id):\n        return np.nan  # no frame to choose closest defender, return nan\n\n    # get the data of the applicable frame\n    frame_df = play_track_df[play_track_df.frameId == frame_id].copy()\n\n    # get the location of the targeted receiver\n    if not np.any(frame_df.nflId == frame_df.targetNflId):\n        # no target data for the play, discard\n        return np.nan\n\n    # QB throwaways consider the target the QB. If this is the case, do not consider closest defender.\n    tgt_position = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'position'].iloc[0]\n    if tgt_position == 'QB':\n        return np.nan\n\n    # get x-coordinate of the line of scrimmage (in normalized direction)\n    x_los = play_track_df.x[(play_track_df.team == 'football') & (play_track_df.frameId == 1)].iloc[0]\n\n    # save the distance downfield of all observations relative to the line of scrimmage\n    frame_df['depth'] = frame_df['x'] - x_los\n\n    depth_tgt = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'depth'].iloc[0]\n\n    # return the depth of the target\n    return depth_tgt\n\n\ndef create_zone_predict_dataframe(clf_zone, track_df, game_df, play_df,\n                                  t_scheme_develop=4, t_reaction_time=0,\n                                  coverage_df=None, bad_plays=None):\n    # Creates the dataframe of features and zone predictions\n    #\n    # inputs:\n    #   - clf_zone: scikit-learn model for predicting man/zone\n    #   - track_df: DataFrame of tracking data (full week of data, week{i}.csv)\n    #   - game_df: DataFrame of game data (games.csv)\n    #   - play_df: DataFrame of play data (plays.csv)\n    #   - t_scheme_develop: time in seconds after the snap to set as a max time threshold\n    #                         (i.e. before the play breaks down, after which the movement\n    #                          is not always indicative of the coverage scheme)\n    #   - t_reaction_time: time in seconds after the ball thrown to continue taking statistics (paths\n    #                        won't change until players realize the ball has been thrown)\n    #   - coverage_df: DataFrame of actual coverages, None if not available (only for week 1, coverages_week1.csv)\n    #   - bad_plays: list of (gameId, playId) tuples to ignore in analysis\n\n    # remove bad plays (if provided)\n    if bad_plays is not None and len(bad_plays) > 0:\n        track_df = track_df[~track_df[['gameId', 'playId']].apply(tuple, 1).isin(bad_plays)]\n\n    # filter out any plays that are missing an entire team (does occur in the dataset where the defense is missing:\n    # 3 is for 'home', 'away', and 'football')\n    track_df = track_df.groupby(['gameId', 'playId']).filter(lambda df: len(df.team.unique()) == 3)\n\n    # filter out spike plays\n    track_df = track_df.groupby(['gameId', 'playId']).filter(lambda df: np.all(df.event != 'qb_spike'))\n\n    # Transform the raw tracking data so that all offensive plays face the same direction,\n    # group the tracking data for each play together\n    test_df_group = transform_tracking_data(track_df).groupby(['gameId', 'playId'])\n\n    # ------ Create the features for each play ---------------------\n    feature_df = pd.DataFrame()\n\n    col_names = []\n    values = []\n\n    # loop over each play\n    for (loop_game_id, loop_play_id), loop_track_df in test_df_group:\n\n        # error block for easier debugging if a particular play runs into an error\n        try:\n            features = create_play_features(loop_track_df,\n                                            game_df,\n                                            play_df,\n                                            t_scheme_develop=t_scheme_develop,\n                                            t_reaction_time=t_reaction_time)\n        except Exception as err:\n            print(f'error in gameId {loop_game_id}, playId {loop_play_id}')\n            raise err\n\n        # first loop: save the output dataframe column names (gameId, playId, all feature names)\n        if not col_names:  # empty\n            col_names.extend(['gameId', 'playId'])\n            col_names.extend(features.index.tolist())\n\n        # save the gameId, playId, and all feature values into a list\n        loop_values = [loop_game_id, loop_play_id]\n        loop_values.extend(features.values.tolist())\n        values.append(loop_values)\n\n    # convert the features into a dataframe (1 row per play), inner join on plays with labeled coverages\n    feature_df = pd.DataFrame(values, columns=col_names)\n\n    # create zone-labeled plays\n    labeled_play_df = feature_df.copy()\n\n    # make predictions\n    labeled_play_df['zone'] = clf_zone.predict(feature_df.drop(columns=['gameId', 'playId']))\n\n    # if the actual labels are known, set the plays to those values\n    if coverage_df is not None:\n        # classify the actual coverage as man or zone\n        temp_df = coverage_df.copy()\n        temp_df['zone'] = np.nan  # initialize all as nan\n        temp_df.loc[temp_df.coverage.str.contains('Zone'), 'zone'] = 1\n        temp_df.loc[temp_df.coverage.str.contains('Man'), 'zone'] = 0\n\n        if np.sum(temp_df.zone.isna()) > 0:\n            raise ValueError(\n                'coverage_df contains a value in the \"coverage\" field that does not contain \"Man\" or \"Zone\"')\n\n        # overwrite particular plays with known values\n        known_coverage_idx = pd.MultiIndex.from_frame(temp_df[['gameId', 'playId']])\n        labeled_play_df.set_index(['gameId', 'playId'], inplace=True)\n        labeled_play_df.loc[known_coverage_idx, 'zone'] = temp_df['zone'].to_numpy()\n        # set index back to original\n        labeled_play_df.reset_index(inplace=True)\n\n    # return the feature dataframe\n    return labeled_play_df\n\n\ndef ftin_to_in(ftin):\n    # converts ft-in notation to inches (i.e. 6-2 to 74)\n    [f, i] = ftin.split('-')\n    return 12 * int(f) + int(i)\n\n\n### --- BELOW THIS LINE: SCRIPT CODE TO GENERATE FEATURES, MANIPULATE DATA, AND CREATE PLOTS ----------\n# load data\nbdb_base_path = '/kaggle/input/nfl-big-data-bowl-2021/'\nbdb_bonus_path = '/kaggle/input/nfl-big-data-bowl-2021-bonus'\ntrack_df = pd.read_csv(os.path.join(bdb_base_path, 'week1.csv'))\nplay_df = pd.read_csv(os.path.join(bdb_base_path, 'plays.csv'))\ngame_df = pd.read_csv(os.path.join(bdb_base_path, 'games.csv'))\nplayer_df = pd.read_csv(os.path.join(bdb_base_path, 'players.csv'))\ncoverage_df = pd.read_csv(os.path.join(bdb_bonus_path, 'coverages_week1.csv'))\ntarget_df = pd.read_csv(os.path.join(bdb_bonus_path, 'targetedReceiver.csv'))\n\n# remove bad plays from the analysis\n# 1. gameId = 2018102101, playId = 3078: Offense positions are clearly wrong at start and during play\n# 2. gameId = 2018092301, playId = 477: SS Jefferson position jumps around and is intermittent during play\n# 3. gameId = 2018092301, playId = 949: Same as play 477\nbad_plays = [(2018102101, 3078),\n             (2018092301, 477),\n             (2018092301, 949)]\n\n# --- Generate zone predictions, depth of pass, and targeted defender data for all weeks ------------------\nprocessed_weeks = []  # list of DataFrames containing processed data\nzone_predict = []  # list of DataFrames containing zone prediction data\nmax_week = 17\n\nfor week in range(1, max_week + 1):  # weeks 1-17\n    print(f'Analyzing tracking data for week {week}...')\n    # load tracking data\n    temp_track_df = pd.read_csv(os.path.join(bdb_base_path, f'week{week}.csv'))\n    # calculate closest defender\n    closest_def = temp_track_df.groupby(['gameId', 'playId']).apply(closest_defender,\n                                                                    game_df, play_df, target_df).reset_index()\n    # calculate depth of pass\n    dop_df = temp_track_df.groupby(['gameId', 'playId']).apply(depth_of_pass, target_df).reset_index()\n    dop_df.rename(columns={0: 'pass_depth'}, inplace=True)\n    # combine into single dataframe\n    processed_weeks.append(pd.merge(closest_def, dop_df, on=['gameId', 'playId']))\n\n    # predict man/zone coverage\n    if week == 1:\n        # use actual known labels since they are available\n        zone_df = create_zone_predict_dataframe(clf_zone, temp_track_df, game_df, play_df, coverage_df=coverage_df,\n                                                bad_plays=bad_plays)\n    else:\n        # no known coverage, predict the coverage based on the model\n        zone_df = create_zone_predict_dataframe(clf_zone, temp_track_df, game_df, play_df,\n                                                bad_plays=bad_plays)\n    # save the data for the week\n    zone_predict.append(zone_df)\n\nprint('Loop complete.')\n\n# concatenate into a full matrix\nclosest_def_df = pd.concat(processed_weeks, ignore_index=True)\n\n# remove \"special\"/non-traditional passing plays (fake punts, fake field goals, spikes, etc.)\nclosest_def_df.set_index(['gameId', 'playId'], inplace=True)\nvalid_plays_mi = pd.MultiIndex.from_frame(play_df.loc[play_df.typeDropback != 'UNKNOWN', ['gameId', 'playId']])\nclosest_def_df = closest_def_df.loc[valid_plays_mi]\nclosest_def_df.reset_index(inplace=True)\n\n# concatenate zone dataframes\nzone_def_df = pd.concat(zone_predict, ignore_index=True)\n\n# ----- Build dataframe for pass play analysis ----------------------------------------------------\n\n# create base dataframe for pass play characteristics\npass_df = pd.merge(closest_def_df, zone_def_df,\n                          how='left',\n                          on=['gameId','playId'])\n\n# add targeted receiver data to the DataFrame\npass_df = pd.merge(pass_df, target_df.rename(columns={'targetNflId': 'nflId_target'}),\n        how='left',\n        on=['gameId','playId'])\n\n# - Over 99.5% of the cases are below 15 yards to the closest defender. This is a reasonable cutoff for downstream\n# - analysis so that prevent or soft zone (coverages designed to give up yards but not points) does not count against\n# - an individual's performance, since filtering the mean defensive team depth of over 15 yards during the play has a\n# - closest defender distance of under 15 yards 90% of the time as well (signifying soft coverage but not prevent).\n# - Therefore removing all cases above 15 yards to the closest defender effectively filters out the vast majority of\n# - prevent defense plays where there is no real attempt to force an incompletion.\n\n# flag scenarios where the closest individual is not really attempting to cause an incompletion\ndist_def_cutoff = 15\npass_df['covered'] = (pass_df.dist_def < dist_def_cutoff).astype(int)\n\n# get the height of each player\nind_ftin = player_df.height.str.contains('-')\nplayer_df.loc[ind_ftin, 'height'] = player_df.height[ind_ftin].apply(ftin_to_in)\nplayer_df.loc[:, 'height'] = player_df.height.astype('int')\n\n# add the targeted defender height\npass_df = pd.merge(pass_df, player_df[['nflId', 'height']].rename(columns={'nflId': 'nflId_def',\n                                                                           'height': 'def_height'}),\n                   how='left',\n                   on='nflId_def'\n                  )\n\n# add the targeted receiver height\npass_df = pd.merge(pass_df, player_df[['nflId', 'height']].rename(columns={'nflId': 'nflId_target',\n                                                                           'height': 'tgt_height'}),\n                   how='left',\n                   on='nflId_target'\n                  )\n\n# add the height difference between the receiver and defender\n# 'tgt_height_adv' = target height advantage (target - defender)\npass_df['tgt_height_adv'] = pass_df.tgt_height - pass_df.def_height\n\n# Grouping together the height advantage values <= -7 and >= 8 will group the extremes to roughly 200 pass plays\nmin_bin_bound = -7\nmax_bin_bound = 8\npass_df['tgt_height_adv_bin'] = pass_df.tgt_height_adv\npass_df.loc[pass_df.tgt_height_adv <= min_bin_bound, 'tgt_height_adv_bin'] = min_bin_bound\npass_df.loc[pass_df.tgt_height_adv >= max_bin_bound, 'tgt_height_adv_bin'] = max_bin_bound\n\n# add in EPA and pass result information\npass_df = pd.merge(pass_df, play_df[['gameId','playId','epa', 'passResult']],\n                  on=['gameId', 'playId'],\n                  how='left')\n\n# ----- Man/Zone model verification analysis by team man percentage over 2018 season ---------------------------\n# get the teams involved in each play\ndefend_team_df = pd.merge(play_df[['gameId','playId','possessionTeam']],\n                game_df[['gameId','homeTeamAbbr','visitorTeamAbbr','week']],\n                on='gameId')\n# get the defending team\ndefend_team_df['defendTeam'] = defend_team_df.apply(\n    lambda x: x.homeTeamAbbr if (x.visitorTeamAbbr == x.possessionTeam) else x.visitorTeamAbbr,\n    axis=1)\n\n# only keep the gameId, playId, week, and defendTeam\ndefend_team_df = defend_team_df[['gameId','playId','week','defendTeam']].copy()\n\n# add the zone label to the dataframe\ndefend_team_df = pd.merge(defend_team_df, pass_df[['gameId','playId','zone']], on=['gameId','playId'])\n\n# add reciprocal label of 'zone' ('man')\ndefend_team_df['man'] = (defend_team_df.zone == 0).astype(int)\n\n# calculate the man coverage percentage and sort for plotting\nteam_man_agg = (defend_team_df[['defendTeam','man']]\n                .groupby('defendTeam')\n                .mean()\n                .reset_index().sort_values('man', ascending=False))\nteam_man_agg['man_pct'] = team_man_agg.man * 100\n\n# get team colors into a list format\nteam_color_dict = {team: colordict['main'] for team, colordict in TEAM_COLORS.items()}\nteam_color_list = [team_color_dict[team].tolist() for team in team_man_agg.defendTeam.tolist()]\n\n# plot man percentages for each team\nf = plt.figure(figsize=(14, 6))\nax = f.gca()\nplt.grid('on')\nsns.barplot(data=team_man_agg, x='defendTeam', y='man_pct',\n            palette=team_color_list, ci=None)\nplt.ylim([0, 70])\nvals = ax.get_yticks()\nax.set_yticklabels([f'{int(i)}%' for i in vals])\n\nplt.xlabel('')\nplt.ylabel('Man Coverage Percentage')\nplt.title('2018 Season Man Coverage Play Percentage by Team')\n\nplt.show()\n\n\n# ------ Normalizing for Pass Difficulty -------------------------------------------\n\n# get base DataFrame with gameId, playId, pass_depth, and passResult\ncomp_depth_df = pd.merge(pass_df[['gameId','playId','pass_depth']],\n                         play_df[['gameId','playId','passResult']])\ncomp_depth_df.dropna(inplace=True)\n\n# add flag for complete vs not complete\ncomp_depth_df['comp'] = (comp_depth_df.passResult=='C').astype(int)\n\n# bin the pass depths to get aggregate completion percentages for the 2018 season\nmin_depth = -6  # all below this value will be binned together\nmax_depth = 36 # all above this value will be binned together\nbin_width = 3  # yards\n\ndepth_bins = np.concatenate([np.array([-100]), np.arange(min_depth, max_depth + 0.01, bin_width), np.array([100])])\n# define the depth to use for regression (middle of the bin, except for the ends which will use a cutoff)\ndepth_points_mid = (depth_bins[1:-2] + depth_bins[2:-1]) / 2\n# first and last points are temporary\ndepth_points = np.concatenate([np.array([-100]), depth_points_mid, np.array([100])])\n# set first and last points to the mean value for the extreme bins\ndepth_points[0] = comp_depth_df.loc[comp_depth_df.pass_depth <= min_depth, 'pass_depth'].mean()\ndepth_points[-1] = comp_depth_df.loc[comp_depth_df.pass_depth > max_depth, 'pass_depth'].mean()\n\n# add bins to the dataframe\ncomp_depth_df['pass_depth_bin'] = pd.cut(comp_depth_df['pass_depth'], depth_bins)\n\n# aggregate plays by bin\ncomp_depth_agg = comp_depth_df.groupby('pass_depth_bin').agg(\n    comp_pct=pd.NamedAgg(column='comp', aggfunc='mean')\n)\n\n# save the midpoint of the bin (or mean for first and last bins) for plotting and curve fit\ncomp_depth_agg['depth_point'] = depth_points\n\n# -- Curve fit the data with a logistic function --\ndef logistic_fcn(depth, a, b, k, q, v):\n    # generic logistic function equation\n    return a + (k - a) / ((1 + q * np.exp(-b * depth)) ** (1/v))\n\n# initialize parameters and bounds for logistic curve fit (a,b,k,q,v)\np0 = np.array([.85, .05, .25, .25, 1])\nlog_bounds = ([0, 0, 0, 0, .00000000001], [1, 3, 1, 1000, 10])\n\nx_depth = comp_depth_agg.depth_point.to_numpy()  # independent variable\ny_comp_pct = comp_depth_agg.comp_pct.to_numpy()  # dependent variable\n# fit data to the logistic curve\ncmp_model_params, _ = optim.curve_fit(logistic_fcn, x_depth, y_comp_pct, bounds=log_bounds, p0=p0)\n\n# create a handle to the completion percentage model\ncmp_pct_model = lambda depth: logistic_fcn(depth, *cmp_model_params)\n\n# generate the curve fit\nx_curve = np.linspace(-10, 60, 500)\ncmp_curve = cmp_pct_model(x_curve)\n\n# plot the data\nf = plt.figure(figsize=(10, 5))\nax = f.gca()\nplt.plot(x_depth, y_comp_pct, marker='o', linestyle='')\nplt.plot(x_curve, cmp_curve, linestyle='-', marker=None, color='k', label='Expected Completion Percent Model')\nplt.xlabel('Pass Attempt Depth (yds)')\nplt.ylabel('Completion Percentage')\nplt.ylim([.2, .9])\n# add percentage y-labels\nvals = ax.get_yticks()\nax.set_yticklabels([f'{int(i * 100)}%' for i in vals])\nplt.title(f'2018 Aggregate Completion Percentage by Pass Attempt Depth, Relative to LOS ({bin_width}-yd Bins)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n# ------- Analysis for Question 1 (best defenders in man/zone, CBs/DBs) ------------------------------\n\n# base dataframe\ncpbe_df = pass_df[['gameId', 'playId', 'nflId_def', 'pass_depth', 'zone', 'covered', 'passResult', 'epa']].copy().dropna()\n\n# calculate the expected completion percentage\ncpbe_df['cp_expect'] = cmp_pct_model(cpbe_df.pass_depth)\n\n# remove the plays where there wasn't really coverage (very soft zone)\ncpbe_df = cpbe_df[cpbe_df.covered == 1]\n\n# aggregate by targeted defender: total plays, zone plays, man plays, average EPA, comp. pct., expected comp. pct.\ncpbe_agg = cpbe_df.groupby('nflId_def').agg(\n    plays_total = pd.NamedAgg(column='passResult', aggfunc=len),\n    plays_zone = pd.NamedAgg(column='zone', aggfunc=lambda x: np.sum(x==1)),\n    plays_man = pd.NamedAgg(column='zone', aggfunc=lambda x: np.sum(x==0)),\n    epa_avg_tot = pd.NamedAgg(column='epa', aggfunc='mean'),\n    cp_tot = pd.NamedAgg(column='passResult', aggfunc=lambda x: np.mean(x=='C')),\n    cp_expect_tot = pd.NamedAgg(column='cp_expect', aggfunc='mean'),\n).reset_index()\n\n# calculate percentage of plays targeted in zone\ncpbe_agg['pct_zone'] = cpbe_agg.plays_zone / cpbe_agg.plays_total\n\n# make play count columns integers\ncpbe_agg['plays_zone'] = cpbe_agg.plays_zone.astype(int)\ncpbe_agg['plays_man'] = cpbe_agg.plays_man.astype(int)\n\n# calculate CPBE\ncpbe_agg['cpbe'] = cpbe_agg.cp_expect_tot - cpbe_agg.cp_tot\n\ncpbe_agg = pd.merge(cpbe_agg, player_df[['nflId', 'displayName', 'position']],\n                    left_on='nflId_def', right_on='nflId', how='left').drop(columns='nflId')\n\n# get the average EPA, CP, and expected CP for zone vs. man coverage\nman_zone_agg = cpbe_df.groupby(['nflId_def', 'zone']).agg(\n    epa_avg = pd.NamedAgg(column='epa', aggfunc='mean'),\n    cp_avg = pd.NamedAgg(column='passResult', aggfunc=lambda x: np.mean(x=='C')),\n    cp_expect_avg = pd.NamedAgg(column='cp_expect', aggfunc='mean')\n).unstack()\nman_zone_agg.columns = ['epa_avg_man', 'epa_avg_zone', 'cp_man', 'cp_zone', 'cp_expect_man', 'cp_expect_zone']\nman_zone_agg.reset_index(inplace=True)\n\n# calculate CPBE\nman_zone_agg['cpbe_man'] = man_zone_agg.cp_expect_man - man_zone_agg.cp_man\nman_zone_agg['cpbe_zone'] = man_zone_agg.cp_expect_zone - man_zone_agg.cp_zone\n\n# add man/zone breakdown into main CB/DB analysis dataframe\ncpbe_agg = pd.merge(cpbe_agg, man_zone_agg, on='nflId_def')\n\n# reduced dataframe to CB/DB and 20+ man, 20+ zone targets\ncb_agg = cpbe_agg[cpbe_agg.position.isin(['CB', 'DB'])].copy()\ncb_mz = cb_agg[(cb_agg.plays_zone >= 20) & (cb_agg.plays_man >= 20)]\n\n# --- Question 1 plot for CB/DB CPBE man and zone -------------------------------------\n\n# figure\nf = plt.figure(figsize=(12, 8))\nax = f.gca()\nplt.axhline(cb_mz.cpbe_man.mean(), ls='--', c='gray')\nplt.axvline(cb_mz.cpbe_zone.mean(), ls='--', c='gray')\nscatter = plt.scatter(cb_mz.cpbe_zone, cb_mz.cpbe_man,\n                      c=cb_mz.pct_zone * 100,\n                      s=cb_mz.plays_total,\n                      marker='o',\n                      edgecolors='gray',\n                      cmap='bwr')\nplt.grid(True)\n\n# colorbar\nplt.colorbar(label='% Targets in Zone Coverage', orientation='vertical')\nplt.clim([0, 100])\n\n# legend\nsizes = [40, 80, 120]\nscatter_legend = plt.scatter([None] * len(sizes), [None] * len(sizes), s=sizes, c='k')\nmean_legend = plt.plot([], [], ls='--', c='gray', label='Mean CPBE')[0]\nlegend_elements = scatter_legend.legend_elements(prop='sizes')\nlegend_elements[0].append(mean_legend)\nlegend_elements[1].append(\"Mean CB/DB CPBE\")\nplt.legend(*legend_elements, title='Targeted Plays', loc='lower right')\n\n# limits\nax.set_ylim([-.15, .30])\n\n### annotations\n# arrows\nax.text(cb_mz.cpbe_zone.mean(), cb_mz.cpbe_man.max(),\n        \"Increasing Zone Performance\", ha=\"center\", va=\"center\", rotation=0, size=12,\n        bbox=dict(boxstyle=\"rarrow,pad=0.3\", fc=\"white\", ec=[.05, .05, .05], lw=0.5))\n\nax.text(cb_mz.cpbe_zone.min(), cb_mz.cpbe_man.mean(),\n        \"Increasing Man Performance\", ha=\"center\", va=\"center\", rotation=90, size=12,\n        bbox=dict(boxstyle=\"rarrow,pad=0.3\", fc=\"white\", ec=[.05, .05, .05], lw=0.5))\n\n# players\ntemp_df = cb_mz.copy()\ntemp_df['cpbe_dist'] = np.sqrt(((cb_mz.cpbe_zone - cb_mz.cpbe_zone.mean()) / cb_mz.cpbe_zone.std()) ** 2\n                               + ((cb_mz.cpbe_man - cb_mz.cpbe_man.mean()) / cb_mz.cpbe_man.std()) ** 2)\ntemp_df['shortName'] = temp_df.displayName.str.split().apply(lambda x: x[0][0] + '. ' + x[1])\n\n# get top 10 performers\ntemp_df = temp_df[(temp_df.cpbe_zone > temp_df.cpbe_zone.mean())\n                  & (temp_df.cpbe_man > temp_df.cpbe_man.mean())].sort_values('cpbe_dist', ascending=False).head(\n    10).set_index('displayName')\nannot_df = pd.DataFrame({'x_offset': 0, 'y_offset': 0, 'arrowstyle': None}, index=temp_df.index)\nannot_df.loc['Denzel Ward', :] = [-0.04, 0, None]\nannot_df.loc['Mackensie Alexander', :] = [0.005, -0.01, None]\nannot_df.loc['Tramon Williams', :] = [0.005, 0, None]\nannot_df.loc['James Bradberry', :] = [0.007, 0, None]\nannot_df.loc['Stephon Gilmore', :] = [-0.03, -0.035, '->']\nannot_df.loc['Marlon Humphrey', :] = [0.006, 0, None]\nannot_df.loc[\"Tre'Davious White\", :] = [0.005, 0, None]\nannot_df.loc['Tramaine Brock', :] = [0.013, 0, '->']\nannot_df.loc['Kyle Fuller', :] = [-0.03, 0.02, '->']\nannot_df.loc['Terrance Mitchell', :] = [0.01, -0.02, '->']\n\n# add arrows to specific names\nfor name, row in temp_df.iterrows():\n    if annot_df.loc[name].arrowstyle is not None:\n        annot_kwarg = {'arrowprops': {'arrowstyle': annot_df.loc[name].arrowstyle}}\n    else:\n        annot_kwarg = {}\n\n    ax.annotate(row.shortName, (row.cpbe_zone, row.cpbe_man),\n                xytext=(row.cpbe_zone + annot_df.loc[name].x_offset, row.cpbe_man + annot_df.loc[name].y_offset),\n                **annot_kwarg)\n\n# make axis labels percentages\nx_vals = ax.get_xticks()\nax.set_xticklabels([f'{int(round(i*100))}%' for i in x_vals])\ny_vals = ax.get_yticks()\nax.set_yticklabels([f'{int(round(i*100))}%' for i in y_vals])\n    \n# labels and title\nplt.xlabel('Zone CPBE')\nplt.ylabel('Man CPBE')\nplt.title('2018 Season: CB/DB Man and Zone CPBE, Minimum 20 Targets (Each)')\n\nplt.show()\n\n\n# ------- Analysis for Question 2 (height advantage impact on passing performance) -------------------\n\n# base dataframe: merge height difference to CPBE base dataframe\nheight_df = pd.merge(cpbe_df.drop(columns='covered'),\n                     pass_df[['gameId','playId','tgt_height_adv','tgt_height_adv_bin']],\n                     how='left', on=['gameId','playId'])\n\n# attach defender position\nheight_df = pd.merge(height_df, player_df[['nflId','displayName','position']].copy().rename(\n                                                columns={'displayName': 'defenderName', 'position': 'defenderPos'}),\n                   left_on='nflId_def', right_on='nflId', how='left').drop(columns='nflId')\n\n# attach receiver nflId as targetNflId\nheight_df = pd.merge(height_df, target_df, on=['gameId','playId'], how='left')\n\n# attach receiver position and name\nheight_df = pd.merge(height_df, player_df[['nflId','displayName','position']].copy().rename(\n                                                columns={'displayName': 'receiverName', 'position': 'receiverPos'}),\n                   left_on='targetNflId', right_on='nflId', how='left').drop(columns='nflId')\n\n# add cpbe for each play (for seaborn)\nheight_df['cpbe'] = height_df.cp_expect - (height_df.passResult=='C').astype(int)\n\n# add label to make it easier for seaborn stratification and legend\nheight_df['zone_label'] = 'Man'\nheight_df.loc[height_df.zone==1, 'zone_label'] = 'Zone'\n\n# ------- Function to plot the Question 2 height advantage passing performance data -------\ndef plot_height_adv_coverage_split(height_df, target, figsize=(12, 6), rec_positions=None, def_positions=None,\n                                   show_pass_depth=False):\n    # create label based on target\n    if target == 'epa':\n        ylabel = 'Average EPA'\n    elif target == 'cpbe':\n        ylabel = 'CPBE'\n    else:\n        ylabel = target\n\n    # filter down based on input positions\n    plot_df = height_df.copy()\n    if rec_positions:\n        if type(rec_positions) is str:\n            rp = [rec_positions]  # make it a list\n        elif type(rec_positions) is list:\n            rp = rec_positions\n    else:  # use all positions\n        rp = plot_df.receiverPos.unique().tolist()\n\n    if def_positions:\n        if type(def_positions) is str:\n            dp = [def_positions]  # make it a list\n        elif type(def_positions) is list:\n            dp = def_positions\n    else:  # use all positions\n        dp = plot_df.defenderPos.unique().tolist()\n\n    plot_df = plot_df[plot_df.receiverPos.isin(rp) & plot_df.defenderPos.isin(dp)]\n\n    # create custom title based on if positions are input\n    title = '2018 Season: ' + ylabel + ', Split by Receiver Height Advantage and Coverage Type'\n    if rec_positions or def_positions:\n        # starting parentheses\n        title += ' ('\n    if rec_positions:\n        title += ('Receivers: ' + '/'.join(rp))\n        if def_positions:\n            # add separating comma\n            title += ', '\n    if def_positions:\n        title += ('Defenders: ' + '/'.join(dp))\n    if rec_positions or def_positions:\n        # ending parentheses\n        title += ')'\n\n    # create plot\n    f = plt.figure(figsize=figsize)\n    ax1 = f.gca()\n    sns.barplot(x=plot_df.tgt_height_adv_bin.astype(int),\n                y=plot_df[target],\n                hue=plot_df.zone_label,\n                hue_order=['Man', 'Zone'],\n                ci=None,\n                ax=ax1)\n    # labels\n    plt.xlabel('Receiver Height Advantage (inches, Receiver - Defender)')\n    plt.ylabel(ylabel)\n    ax1.grid(True, axis='y')\n\n    handles, labels = ax1.get_legend_handles_labels()\n\n    # if EPA, add mean line\n    if target == 'epa':\n        sns.lineplot(x=np.arange(len(plot_df.tgt_height_adv_bin.unique())),\n                     y=plot_df.groupby('tgt_height_adv_bin')['epa'].mean().to_numpy(),\n                     marker='o', linestyle='--', ci=None, color='gray', ax=ax1)\n        # add mean EPA line to legend\n        line_epa, = ax1.plot([], [], c='gray', marker='o', linestyle='--', label='Mean EPA')\n        handles.append(line_epa)\n        labels.append(line_epa.get_label())\n\n    # add second y-axis for mean pass depth, if desired\n    if show_pass_depth:\n        ax2 = ax1.twinx()\n        sns.lineplot(x=np.arange(len(plot_df.tgt_height_adv_bin.unique())),\n                     y=plot_df.groupby('tgt_height_adv_bin')['pass_depth'].mean().to_numpy(),\n                     marker='o', ci=None, color='blue', ax=ax2)\n        ax2.set_ylabel('Mean Pass Depth (yds)')\n        ax2.tick_params(axis='y', labelcolor='blue')\n\n        # add mean pass depth line to legend\n        line_mean_depth, = ax1.plot([], [], c='blue', marker='o', label='Mean Pass Depth')\n        handles.append(line_mean_depth)\n        labels.append(line_mean_depth.get_label())\n\n    # add legend and title\n    ax1.legend(handles, labels, title='Coverage Type')\n    plt.title(title)\n\n\n# Target Height Advantage, EPA and Mean Pass Depth\nplot_height_adv_coverage_split(height_df, 'epa', show_pass_depth=True)\nplt.show()\n\n# Target Height Advantage, CPBE\nplot_height_adv_coverage_split(height_df, 'cpbe')\n# set y-label to percentage\nax = plt.gcf().gca()\ny_vals = ax.get_yticks()\nax.set_yticklabels([f'{int(round(i*100))}%' for i in y_vals])\n\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}