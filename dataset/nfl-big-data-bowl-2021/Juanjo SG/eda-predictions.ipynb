{"cells":[{"metadata":{},"cell_type":"markdown","source":"---\n\n**Author:** *Juan José Serrano Gutiérrez* (*juanjoguti* at *correo.ugr.es* or *juanjo.jjserra* at *gmail.com*)\n\n---\n\n# NFL Big Data Bowl 2021\n\n## Overview\n\nIn American football, there are a plethora of defensive strategies and outcomes. The National Football League (NFL) has used previous Kaggle competitions to focus on offensive plays, but as the old proverb goes, \"defense wins championships\". Though metrics for analyzing quarterbacks, running backs, and wide receivers are consistently a part of public discourse, techniques for analyzing the defensive part of the game trail and lag behind. Identifying player, team, or strategic advantages on the defensive side of the ball would be a significant breakthrough for the game.\n\nThis competition uses NFL's Next Gen Stats data, which includes the position and speed of every player on the field during each play. You'll employ player tracking data for all drop-back pass plays from the 2018 regular season. The goal of submissions is to identify unique and impactful approaches to measure defensive performance on these plays. There are several different directions for participants to 'tackle' (ha)—which may require levels of football savvy, data aptitude, and creativity.\n\n## Exploratory Data Analysis\n\nThe 2021 Big Data Bowl data contains player tracking, play, game, and player level information for all possible passing plays during the 2018 regular season. For purposes of this event, passing plays are considered to be ones on a pass was thrown, the quarterback was sacked, or any one of five different penalties was called (defensive pass interference, offensive pass interference, defensive holding, illegal contact, or roughing the passer). On each play, linemen (both offensive and defensive) data are not provided. The focus of this year's contest is on pass coverage.\n\nTo be able to start with the EDA, we should upload the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\n\npath = Path('../input/nfl-big-data-bowl-2021')\ndf_games = pd.read_csv(path/'games.csv')\ndf_players = pd.read_csv(path/'players.csv')\ndf_plays = pd.read_csv(path/'plays.csv')\ndf_weeks = pd.read_csv(path/'week1.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have lot of data frames so we are going to analyze them one by one.\n\n### Game data\n\nFirst of all, we could have a look at how our data looks like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_games","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `games.csv` contains the teams playing each game. The key variable is `gameId`.\n- `gameId`: Game identifier, unique (numeric)\n- `gameDate`: Game Date (time, mm/dd/yyyy)\n- `gameTimeEastern`: Start time of game (time, HH:MM:SS, EST)\n- `homeTeamAbbr`: Home team three-letter code (text)\n- `visitorTeamAbbr`: Visiting team three-letter code (text)\n- `week`: Week of game (numeric)\n\nOnce we have seen our data, we should check if we have missing values as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_games.isnull().sum().sort_values(ascending = False)/len(df_games)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we know we don't have missing values, we could start analyzing the data.\n\nSome interesting information we could find out here is the number of games played by each date:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ngames_by_date = df_games['gameDate'].value_counts().reset_index()\ngames_by_date.columns = [ 'date', 'games' ]\ngames_by_date = games_by_date.sort_values('games')\n\nfig = px.bar(\n    games_by_date, \n    y = 'date', \n    x = 'games', \n    orientation = 'h', \n    title = 'Number of games by date',\n    labels = {'date': 'Game date', 'games': 'Games played'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the same way, we could obtain the number of games by game time:"},{"metadata":{"trusted":true},"cell_type":"code","source":"games_by_time = df_games['gameTimeEastern'].value_counts().reset_index()\ngames_by_time.columns = [ 'time', 'games' ]\ngames_by_time = games_by_time.sort_values('games')\n\nfig = px.bar(\n    games_by_time, \n    y = 'time', \n    x = 'games', \n    orientation = 'h', \n    title = 'Number of games by date',\n    labels = {'time': 'Game time', 'games': 'Games played'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Other relevant information we could get is the games played at home and away:"},{"metadata":{"trusted":true},"cell_type":"code","source":"home_games = df_games['homeTeamAbbr'].value_counts().reset_index()\nhome_games.columns = [ 'team', 'games' ]\nhome_games = home_games.sort_values('games')\n\nfig = px.bar(\n    home_games, \n    y = 'team', \n    x = 'games',\n    orientation = 'h', \n    title = 'Number of games at home',\n    labels = {'team': 'Home team', 'games': 'Games played'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"away_games = df_games['visitorTeamAbbr'].value_counts().reset_index()\naway_games.columns = [ 'team', 'games' ]\naway_games = home_games.sort_values('games')\n\nfig = px.bar(\n    away_games, \n    y = 'team', \n    x = 'games',\n    orientation = 'h', \n    title = 'Number of games away',\n    labels = {'team': 'Away team', 'games': 'Games played'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In a similar way, we could get the number of games per week:"},{"metadata":{"trusted":true},"cell_type":"code","source":"games_per_week = df_games['week'].value_counts().reset_index()\ngames_per_week.columns = [ 'week', 'games' ]\ngames_per_week = games_per_week.sort_values('games')\n\nfig = px.bar(\n    games_per_week, \n    y = 'week', \n    x = 'games',\n    orientation = 'h', \n    title = 'Number of games per week',\n    labels = {'week': 'Week', 'games': 'Games played'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Player data\n\nAgain, we start looking at the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_players","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Player data: The `players.csv` file contains player-level information from players that participated in any of the tracking data files. The key variable is `nflId`.\n- `nflId`: Player identification number, unique across players (numeric)\n- `height`: Player height (text)\n- `weight`: Player weight (numeric)\n- `birthDate`: Date of birth (YYYY-MM-DD)\n- `collegeName`: Player college (text)\n- `position`: Player position (text)\n- `displayName`: Player name (text)\n\nThe first thing we must do is check the missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_players.isnull().sum().sort_values(ascending = False)/len(df_players)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After that, we should convert all heights to feet:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nplayers_height = df_players['height'].str.split('-',expand=True)\nplayers_height.columns = [ 'first', 'second' ]\n\nplayers_height.loc[(players_height['second'].notnull()), 'first'] \\\n= players_height[players_height['second'].notnull()]['first'].astype(np.int16) * 12 \\\n+ players_height[players_height['second'].notnull()]['second'].astype(np.int16)\n\ndf_players['height'] = players_height['first']\ndf_players['height'] = df_players['height'].astype(np.float32)\ndf_players['height'] /= 12\ndf_players","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we should be able to check the heights and weights distributions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_players,\n    x = \"height\", \n    nbins = 20,\n    title = 'Height distribution',\n    labels = {'height': 'Height'}\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_players,\n    x = \"weight\", \n    nbins = 20,\n    title = 'Weight distribution',\n    labels = {'weight': 'Weight'}\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the information we have here we could also get the top 50 colleges by the number of players they produce:"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_50_colleges = df_players['collegeName'].value_counts().reset_index()\ntop_50_colleges.columns = [ 'college', 'players' ]\ntop_50_colleges = top_50_colleges.sort_values('players').tail(50)\n\nfig = px.bar(\n    top_50_colleges, \n    y = 'college', \n    x = 'players', \n    orientation = 'h', \n    title = 'Top 50 colleges by number of players produced',\n    labels = {'college': 'College', 'players': 'Players produced'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Furthermore, we could get the most common positions according to the number of players for each one:"},{"metadata":{"trusted":true},"cell_type":"code","source":"positions = df_players['position'].value_counts().reset_index()\npositions.columns = [ 'position', 'players' ]\npositions = positions.sort_values('players')\n\nfig = px.bar(\n    positions, \n    y = 'position', \n    x = 'players', \n    orientation = 'h', \n    title = 'Most common positions by number of players',\n    labels = {'position': 'Position abbr.', 'players': 'Players'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For those interesing, here you have the players positions abbreviation meaning:\n- WR: Wide Receiver\n- CB: Cornerback\n- RB: Running Back\n- TE: Tight End\n- QLB: Outside Linebreaker\n- QB: Quarterback\n- FS: Free Safety\n- LB: Linebacker\n- SS: Strong Safety\n- ILB: Inside Linebreaker\n- DE: Defensive End\n- DB: Defensive Back\n- MLB: Middle Linebacker\n- DT: Defensive Tackle\n- FB: Fullback\n- P: Punter\n- LS: Long Snapper\n- S: Safety\n- K: Kicker\n- HB: Running Back\n- NT: Nose Tackle\n\n### Play data\n\nOnce again, we look the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This time, we have too many columns to be displayed so we could check their names as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Play data: The `plays.csv` file contains play-level information from each game. The key variables are gameId and `playId`.\n- `gameId`: Game identifier, unique (numeric)\n- `playId`: Play identifier, not unique across games (numeric)\n- `playDescription`: Description of play (text)\n- `quarter`: Game quarter (numeric)\n- `down`: Down (numeric)\n- `yardsToGo`: Distance needed for a first down (numeric)\n- `possessionTeam`: Team on offense (text)\n- `playType`: Outcome of dropback: sack or pass (text)\n- `yardlineSide`: 3-letter team code corresponding to line-of-scrimmage (text)\n- `yardlineNumber`: Yard line at line-of-scrimmage (numeric)\n- `offenseFormation`: Formation used by possession team (text)\n- `personnelO`: Personnel used by offensive team (text)\n- `defendersInTheBox`: Number of defenders in close proximity to line-of-scrimmage (numeric)\n- `numberOfPassRushers`: Number of pass rushers (numeric)\n- `personnelD`: Personnel used by defensive team (text)\n- `typeDropback`: Dropback categorization of quarterback (text)\n- `preSnapHomeScore`: Home score prior to the play (numeric)\n- `preSnapVisitorScore`: Visiting team score prior to the play (numeric)\n- `gameClock`: Time on clock of play (MM:SS)\n- `absoluteYardlineNumber`: Distance from end zone for possession team (numeric)\n- `penaltyCodes`: NFL categorization of the penalties that ocurred on the play. For purposes of this contest, the most important penalties are Defensive Pass Interference (DPI), Offensive Pass Interference (OPI), Illegal Contact (ICT), and Defensive Holding (DH). Multiple penalties on a play are separated by a ; (text)\n- `penaltyJerseyNumber`: Jersey number and team code of the player commiting each penalty. Multiple penalties on a play are separated by a ; (text)\n- `passResult`: Outcome of the passing play (C: Complete pass, I: Incomplete pass, S: Quarterback sack, IN: Intercepted pass, text)\n- `offensePlayResult`: Yards gained by the offense, excluding penalty yardage (numeric)\n- `playResult`: Net yards gained by the offense, including penalty yardage (numeric)\n- `epa`: Expected points added on the play, relative to the offensive team. Expected points is a metric that estimates the average of every next scoring outcome given the play's down, distance, yardline, and time remaining (numeric)\n- `isDefensivePI`: An indicator variable for whether or not a DPI penalty ocurred on a given play (TRUE/FALSE)\n\nOnce again, we check for missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays.isnull().sum().sort_values(ascending = False)/len(df_plays)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, this time we have some missing values. In fact, the percentage of missing values for columns *penaltyJerseyNumbers* and *penaltyCodes* is too big, around 93-94%. Since those columns aren't giving us any useful information, we could removed it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays = df_plays.drop(columns = ['penaltyJerseyNumbers', 'penaltyCodes'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are still some columns with a low percentage of missing values we have to deal with. For those cases, we have two different approach:\n- Drop all the rows with missing values.\n- Fill the missing values using any technique such us linear interpolation.\n\nAs the percentages are lower than 1%, we could drop all the rows without losing too many information:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays = df_plays.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, we could start analyzing the data by ploting the number of plays per team:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_team = df_plays['possessionTeam'].value_counts().reset_index()\nplays_per_team.columns = [ 'team', 'plays' ]\nplays_per_team = plays_per_team.sort_values('plays')\n\nfig = px.bar(\n    plays_per_team, \n    y = 'team',\n    x = 'plays',\n    orientation = 'h',\n    title = 'Number of plays per team',\n    labels = {'team': 'Team', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could also check the plays by type:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_by_type = df_plays['playType'].value_counts().reset_index()\nplays_by_type.columns = [ 'type', 'plays' ]\nplays_by_type = plays_by_type.sort_values('plays')\n\nfig = px.pie(\n    plays_by_type, \n    names = 'type', \n    values = 'plays',  \n    title = 'Number of plays of every type'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have the information to plot the number of plays for each down:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_down = df_plays['down'].value_counts().reset_index()\nplays_per_down.columns = [ 'down', 'plays' ]\nplays_per_down = plays_per_down.sort_values('plays')\n\nfig = px.pie(\n    plays_per_down, \n    names = 'down', \n    values = 'plays',  \n    title = 'Number of plays of every down',\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could plot the number of plays per quarter too:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_quarter = df_plays['quarter'].value_counts().reset_index()\nplays_per_quarter.columns = [ 'quarter', 'plays' ]\nplays_per_quarter = plays_per_quarter.sort_values('plays')\n\nfig = px.pie(\n    plays_per_quarter, \n    names = 'quarter', \n    values = 'plays',  \n    title = 'Number of plays per quarter'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could also check the plays by \"yards to go\" category:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_by_yardsToGo = df_plays['yardsToGo'].value_counts().reset_index()\nplays_by_yardsToGo.columns = [ 'yardsToGo', 'plays' ]\nplays_by_yardsToGo = plays_by_yardsToGo.sort_values('plays')\n\nfig = px.bar(\n    plays_by_yardsToGo, \n    y = 'yardsToGo', \n    x = \"plays\", \n    orientation = 'h', \n    title = 'Number of plays by yards to go',\n    labels = {'yardsToGo': 'Yards to go', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Furthermore, we could have a look at the plays for every team yard side or for every yardline:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_by_yardlineSide = df_plays['yardlineSide'].value_counts().reset_index()\nplays_by_yardlineSide.columns = [ 'yardlineSide', 'plays' ]\nplays_by_yardlineSide = plays_by_yardlineSide.sort_values('plays')\n\nfig = px.bar(\n    plays_by_yardlineSide, \n    y = 'yardlineSide', \n    x = 'plays', \n    orientation = 'h', \n    title = 'Number of plays by team yardline side',\n    labels = {'yardlineSide': 'Team yardline side', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_yardlineNumber = df_plays['yardlineNumber'].value_counts().reset_index()\nplays_per_yardlineNumber.columns = [ 'yardlineNumber', 'plays' ]\nplays_per_yardlineNumber = plays_per_yardlineNumber.sort_values('plays')\n\nfig = px.bar(\n    plays_per_yardlineNumber, \n    y = 'yardlineNumber', \n    x = 'plays', \n    orientation = 'h', \n    title = 'Number of plays by team yardline number',\n    labels = {'yardlineNumber': 'Team yardline number', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_plays, \n    x = 'absoluteYardlineNumber',\n    nbins = 50,\n    title = 'Absolute Yardline Number distribution',\n    labels = {'absoluteYardlineNumber': 'Absolute yardline number'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In addition, we could do a couple of plots to show the relation between the plays and the offensive formations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_offensiveFormation = df_plays['offenseFormation'].value_counts().reset_index()\nplays_per_offensiveFormation.columns = [ 'offenseFormation', 'plays' ]\nplays_per_offensiveFormation = plays_per_offensiveFormation.sort_values('plays')\n\nfig = px.pie(\n    plays_per_offensiveFormation, \n    names = 'offenseFormation', \n    values = 'plays',\n    title = 'Number of plays for every offense formation type'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_personnelO = df_plays['personnelO'].value_counts().reset_index()\nplays_per_personnelO.columns = [ 'personnelO', 'plays' ]\nplays_per_personnelO = plays_per_personnelO.sort_values('plays')\n\nfig = px.bar(\n    plays_per_personnelO, \n    y = 'personnelO', \n    x = 'plays', \n    orientation = 'h', \n    title = 'Number of plays by personnel O.',\n    labels = {'personnelO': 'Personnel O.', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could do exactly the same with the defensive data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_by_defendersInBox = df_plays['defendersInTheBox'].value_counts().reset_index()\nplays_by_defendersInBox.columns = [ 'defendersInTheBox', 'plays' ]\nplays_by_defendersInBox = plays_by_defendersInBox.sort_values('plays')\n\nfig = px.bar(\n    plays_by_defendersInBox, \n    x = 'defendersInTheBox', \n    y = 'plays',  \n    title = 'Number of plays by number of defenders in the box',\n   labels = {'defendersInTheBox': 'Number of defenders in the box', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_numberOfPassRushers = df_plays['numberOfPassRushers'].value_counts().reset_index()\nplays_per_numberOfPassRushers.columns = [ 'numberOfPassRushers', 'plays' ]\nplays_per_numberOfPassRushers = plays_per_numberOfPassRushers.sort_values('plays')\n\nfig = px.bar(\n    plays_per_numberOfPassRushers, \n    x = 'numberOfPassRushers', \n    y = 'plays',  \n    title = 'Number of plays per number of pass rushers',\n    labels = {'numberOfPassRushers': 'Number of pass rushers', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Moreover, we could have a look at the number of plays for every dropback type or pass result:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_per_typeDropback = df_plays['typeDropback'].value_counts().reset_index()\nplays_per_typeDropback.columns = [ 'typeDropback', 'plays' ]\nplays_per_typeDropback = plays_per_typeDropback.sort_values('plays')\n\nfig = px.pie(\n    plays_per_typeDropback, \n    names = 'typeDropback', \n    values = 'plays',  \n    title = 'Number of plays per type of Dropback',\n    labels = {'typeDropback': 'Type of Dropback', 'plays': 'Number of plays'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_by_passResult = df_plays['passResult'].value_counts().reset_index()\nplays_by_passResult.columns = [ 'passResult', 'plays' ]\nplays_by_passResult = plays_by_passResult.sort_values('plays')\n\nfig = px.pie(\n    plays_by_passResult, \n    names = 'passResult', \n    values = 'plays',\n    title = 'Number of plays for every pass result'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Additionally, we could study the distribution for the plays result:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_plays, \n    x = 'playResult',\n    nbins = 50,\n    title = 'Play result distribution',\n    labels = {'playResult': 'Play result'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_plays,\n    x = 'offensePlayResult',\n    nbins = 50,\n    title = 'Offense play result distribution',\n    labels = {'offensePlayResult': 'Offense play result'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It would be also interesting to understand how the score was prior to the play:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_plays, \n    x = 'preSnapHomeScore',\n    nbins = 50,\n    title = 'Pre-snap home score distribution',\n    labels = {'preSnapHomeScore': 'Pre-snap home score'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_plays, \n    x = 'preSnapVisitorScore',\n    nbins = 50,\n    title = 'Pre-snap visitor score distribution',\n    labels = {'preSnapVisitorScore': 'Pre-snap visitor score'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tracking data\n\nOne more time, we start by visualize the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weeks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tracking data: Files `week[week].csv` contain player tracking data from all games in week `[week]`. The key variables are `gameId`, `playId`, and `nflId`. There are 17 weeks to a typical NFL Regular Season, and thus 17 data frames with player tracking data are provided.\n\nEach of the 17 `week[week].csv` files contain player tracking data from all passing plays during Week `[week]` of the 2018 regular season. Nearly all plays from each `[gameId]` are included; certain plays or games with insufficient data are dropped. Each team and player plays no more than 1 game in a given week.\n- `time`: Time stamp of play (time, yyyy-mm-dd, hh:mm:ss)\n- `x`: Player position along the long axis of the field, 0 - 120 yards. See Figure 1 below. (numeric)\n- `y`: Player position along the short axis of the field, 0 - 53.3 yards. See Figure 1 below. (numeric)\n- `s`: Speed in yards/second (numeric)\n- `a`: Acceleration in yards/second^2 (numeric)\n- `dis`: Distance traveled from prior time point, in yards (numeric)\n- `o`: Player orientation (deg), 0 - 360 degrees (numeric)\n- `dir`: Angle of player motion (deg), 0 - 360 degrees (numeric)\n- `event`: Tagged play details, including moment of ball snap, pass release, pass catch, tackle, etc (text)\n- `nflId`: Player identification number, unique across players (numeric)\n- `displayName`: Player name (text)\n- `jerseyNumber`: Jersey number of player (numeric)\n- `position`: Player position group (text)\n- `team`: Team (away or home) of corresponding player (text)\n- `frameId`: Frame identifier for each play, starting at 1 (numeric)\n- `gameId`: Game identifier, unique (numeric)\n- `playId`: Play identifier, not unique across games (numeric)\n- `playDirection`: Direction that the offense is moving (text, left or right)\n- `route`: Route ran by offensive player (text)\n\nNow, we should check if we have missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weeks.isnull().sum().sort_values(ascending = False)/len(df_weeks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the percentage of missing values for column *route* is big, around 72%. This column contains the ran by offensive player which could be interesting to know. \n\nHowever, with less than a 30% of information we're not going to be able to learn anything interesting so we could remove the column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weeks = df_weeks.drop(columns = ['route'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns *o*, *dir*, *position*, *jerseyNumber* and *nflId* also contains some missing values but even so, it's less than a 1% of the total. Then, we could remove those rows containing missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weeks = df_weeks.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now our data is prepared we could start checking the variable distribution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 'x',\n    nbins = 50,\n    title = 'X coordinate distribution'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 'y',\n    nbins = 50,\n    title = 'Y coordinate distribution'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 's',\n    nbins = 50,\n    title = 'Speed distribution',\n    labels = {'s': 'Speed (yards/second)'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 'a',\n    nbins = 50,\n    title = 'Acceleration distribution',\n    labels = {'a': 'Acceleration (yards/second^2)'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 'dis',\n    nbins = 50,\n    title = 'Distance distribution',\n    labels = {'dis': 'Distance (yards)'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 'o',\n    nbins = 50,\n    title = 'Player orientation distribution',\n    labels = {'o': 'Player orientation (degrees)'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    df_weeks, \n    x = 'dir',\n    nbins = 50,\n    title = 'Angle of player motion distribution',\n    labels = {'dir': 'Angle of player motion (degrees)'}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also have some interesting information related to events:"},{"metadata":{"trusted":true},"cell_type":"code","source":"events_per_game = df_weeks['gameId'].value_counts().reset_index()\nevents_per_game.columns = [ 'gameId', 'events' ]\nevents_per_game['gameId'] = events_per_game['gameId'].astype(np.int64).astype(str) + '-'\nevents_per_game = events_per_game.sort_values('events')\n\nfig = px.bar(\n    events_per_game, \n    y = 'gameId', \n    x = 'events', \n    orientation = 'h', \n    title = 'Number of events per game',\n    labels = {'events': 'Number of events'},\n    height = 1000\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_none_events = df_weeks[df_weeks['event'] != 'None']['event'].value_counts().reset_index()\nnot_none_events.columns = [ 'event', 'actions' ]\nnot_none_events = not_none_events.sort_values('actions')\n\nfig = px.bar(\n    not_none_events, \n    y = 'event', \n    x = 'actions', \n    orientation = 'h', \n    title = 'Not none events',\n    labels = {'event': 'Events', 'actions': 'Number of actions'},\n    height = 1000\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Additionally, we have some information related to jerseys popularity:"},{"metadata":{"trusted":true},"cell_type":"code","source":"jerseys_popularity = df_weeks['jerseyNumber'].value_counts().reset_index()\njerseys_popularity.columns = [ 'jerseyNumber', 'items' ]\njerseys_popularity['jerseyNumber'] = jerseys_popularity['jerseyNumber'].astype(np.int16).astype(str) + '-'\njerseys_popularity = jerseys_popularity.sort_values('items')\n\nfig = px.bar(\n    jerseys_popularity, \n    y = 'jerseyNumber', \n    x = 'items', \n    orientation = 'h', \n    title = 'Most popular jerseys',\n    labels = {'jerseyNumber': 'Jersey number', 'items': 'Number of jerseys'},\n    height = 1000\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model: evaluation of plays\n\n"},{"metadata":{},"cell_type":"markdown","source":"With the data we have, we could be interested in predict the *play result*. In order to do this, we should determine with predictors are relevant. For sure, the model don't need the time or the jersey number so we can start removing it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_weeks.drop(columns = ['time', 'jerseyNumber'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The team is important so we could replace the *home* and *away* labels for the specific team abbr.:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(data, df_games[['gameId', 'homeTeamAbbr', 'visitorTeamAbbr']], how = 'inner', on = 'gameId')\ndata.team = data.apply(lambda x: x.homeTeamAbbr if x.team == 'home' else x.visitorTeamAbbr, axis = 1)\ndata = data.drop(columns = ['homeTeamAbbr', 'visitorTeamAbbr'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have specific measures for speed or acceleration, so we could replace this values with their averages:"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg = data[['nflId', 's', 'a', 'dis']].groupby('nflId').mean()\ndata = data.drop(columns = ['s', 'a', 'dis'])\ndata = pd.merge(data, avg, how = 'inner', on = 'nflId')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to remove the *play direction*, we could make all the *x* components go in the same direction using the *absolute yardline number*:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def xmod(row):\n    if row.playDirection == 'left': return row.absoluteYardlineNumber - row.x\n    if row.playDirection == 'right': return row.x - row.absoluteYardlineNumber\n\ndata = pd.merge(data, df_plays[['gameId', 'playId', 'absoluteYardlineNumber']], how = 'inner', on = ['gameId', 'playId'])\ndata['x'] = data.apply(xmod, axis = 1)\ndata = data.drop(columns = ['playDirection', 'absoluteYardlineNumber'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It could be also interesting to know the *height* and the *weight* of the players because it could influence in their *speed* or *acceleration*:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(data, df_players[['nflId', 'height', 'weight']], how = 'inner', on = 'nflId')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing the plays, we have some measures related with the intesity: some players plays more focus when the game score is tight or when they have the obligation of go up.\n\nTo simplify the model, we could make one simple assumption: players always play at his best level. Then, we could remove the following list of variables from our list of predictors:\n- *quarter*\n- *down*\n- *preSnapVisitorScore*\n- *preSnapHomeScore*\n- *gameClock*\n\nWe already include information about the yardline when we made all the *x* components go in the same direction so we could avoid to include the *yardlineSide* and the *yardlineNumber*. We could also remove the *play description* since its content will be difficult to process:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plays_info = df_plays[['gameId', 'playId', 'possessionTeam', 'yardsToGo', 'playType', 'offenseFormation', \n                       'personnelO', 'defendersInTheBox', 'numberOfPassRushers', 'personnelD', 'typeDropback', \n                       'passResult', 'offensePlayResult', 'playResult', 'epa', 'isDefensivePI']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can merge our processed data with the relevant play information we have chosen:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['gameId', 'playId', 'x', 'y', 'team', 'displayName', 'position', \n             'height', 'weight', 's', 'a', 'dis', 'o', 'dir', 'event']]\ndata = pd.merge(data, plays_info, how = 'inner', on = ['gameId', 'playId'])\ndata = data.drop(columns = ['gameId', 'playId'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be able to apply most of the ML algorithms, we should encode some of our variables. Let's check our types:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We should recode the bools and also the objects. We could start with the boolean ones:"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_type_bool = data.dtypes[data.dtypes == bool]\ncols_to_transform = list(columns_type_bool.index)\ncols_to_transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[cols_to_transform] = data[cols_to_transform].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we do the same for the objects:"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_type_object = data.dtypes[data.dtypes == object]\ncols_to_transform = list(columns_type_object.index)\ncols_to_transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndata[cols_to_transform] = data[cols_to_transform].apply(lambda col: le.fit_transform(col), axis = 0, result_type = 'expand')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we should be able to obtain our model. In order to know how good our model is we should apply *K-fold Cross Validation*. Then, for $k = 10$, we prepare our folds as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nY = data['playResult']\nX = data.drop(columns = 'playResult')\n\ncv = KFold(n_splits = 10, random_state = 1, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, we just need to choose the model and one metric to measure how good are the results obtained:\n\n## Linear model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nscores = cross_val_score(model, X, Y, scoring = 'r2', cv = cv, n_jobs = -1)\nprint('R^2 (coefficient of determination): %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nscores = cross_val_score(model, X, Y, scoring = 'f1_micro', cv = cv, n_jobs = -1)\nprint('F1-Score (micro): %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both results are good in their respective metrics: almost 90% for the Regression Linear Model and 100% for the Random Forest Classifier.\n\nHowever, due to memory issues, we're not using all the data available. If we use all the `weeks[weeks].csv`, the results will be worse. In order to avoid it, we could simplify the model by simplify the *play results* using just three \"labels\":\n- 1 if the team wins points,\n- -1 if the team loses points and\n- 0 in other case"},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_play_result(value):\n    if value == 0: return 0\n    if value > 0: return 1\n    if value < 0: return -1\n    \ndata['playResult'] = data['playResult'].apply(lambda value: process_play_result(value))\nY = data['playResult']\nX = data.drop(columns = 'playResult')\n\nscores = cross_val_score(model, X, Y, scoring = 'r2', cv = cv, n_jobs = -1)\nprint('R^2 (coefficient of determination) for Linear Regression Model: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nscores = cross_val_score(model, X, Y, scoring = 'f1_micro', cv = cv, n_jobs = -1)\nprint('F1-Score (micro) for Random Forest Model: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In one hand, we lose information about the exact play result so it will be more difficult to get the exact result of the game. In the other hand, we get a more accuracy model so it will be easy to determine which team will win each play."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}