{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Summary\nThis report represents my analysis for the NFL Big Data Bowl 2021 Competition. My work was mainly inspired by the brilliant and highly successful work of the [OpenAI Five](https://en.wikipedia.org/wiki/OpenAI_Five) project in which machine learning was used in teaching the team of the game bots for Dota 2 video game. Finally this bots were able to defeat professional esport teams.\nI was very interested in trying this approach for the real game and am very grateful for provided opportunity.\n\nThe results are as follows:\n* It is possible to use Reinforcement Learning (RL) approach in analysis of football plays.\n* The one of the core concepts of RL - *state-value function* - modelled by the neural network do can predict outcome of the play.\n* The accuracy of the prediction is better than random guessing even when using rather simple neural networks.\n* Even without finishing RL task - teaching intelligent agent - having the model that can predict outcome of the play can be useful.\n* At the end I present couple of results that have no relation to RL: how tracks clusterization might look and some revealed correlations.\n\nMy work has rather qualitative results than quantative. It is more about the instrument that can assist in getting answers rather than about direct getting answers.\n\nOne might ask: Why reinforcement learning? Why so difficult?\nHere are my reasonings:\n* *There is no best defense for all situations.* The best defense is always relative to offense actions. Simple mental experiment as example. What would be if defense choose some would-be-best symmetric formation while offense choose asymetric formation with the most players on one side? Well, from my point of view most probably offence would break through the flank and get touchdown.\n* *Football data are very complex.* How many combinations of players on the field offensive team can use? How many formations and locations they can use? What is down? How much time left? And so on and so forth. Number of all possible variants is astronomical. On the other hand capacity of human [working memory](https://en.wikipedia.org/wiki/Working_memory) is limited. So the help of AI could be of much use.\n* *Reinforcement learning is very powerful technique.* It seems to me it can be of use in many situations (in increasing order of time scale, amount of compute and pretentiousness): in player training to make good decisions on the field, in preparing defense for a given play, in choosing players for a game."},{"metadata":{},"cell_type":"markdown","source":"# 2. Reinforcement Learning (RL)\nThe ultimate goal of the RL is to teach an ***agent*** to take ***actions*** in an ***environment*** to maximize some ***reward***. One way of doing this is to use the ***state-value function*** that describes value of the state in terms of the expected reward. Once getting this state-value function it is possible to use *greedy-search* (over all possible actions) to choose the best action to perform transition to the next state with the maximum expected reward.\n\nIn low-dimensional discrete tasks the tables can be used for storing the state-value function. For high-dimensional and continuous tasks like in football some approximation should be used. The neural networks is a good choice for this.\n\n# 3. Reward for training RL model\nThe goal of the game is to win and do not loose. However in this competition we are concentrating on plays. We want to use such reward per play that lead to the goal.\n\nThe most obvious choice for reward from given play data is ***offencePlayResult***. The other candidate is ***epa*** (\"expected points added on the play, relative to the offensive team\"). Actually these variables have significant correlation and experiments showed that both variables can be used as reward with similar results.\n\nBoth ***offencePlayResult*** and ***epa*** relate to offensive team. But that should not be confusing because the goal of defense team is to prevent offence team to win. And maximization problem simply becomes minimization problem. From mathematical point of view there is no difference."},{"metadata":{},"cell_type":"markdown","source":"# 4. Model architecture\nThe diagram below shows the model and input variables used for making predictions. Some remarks:\n* This is simple model. As a consequence it is not of high accuracy of prediction. It was done intentionally for being able to make many fast experiments in a limited time for getting qualitative result of approach.\n* The model makes prediction for every moment of the play on the basis of the data at this given moment.\n* Model has no specific order of players. Every defense player data can be at every appropriate input of the model. The same for offence. As a result we should require prediction invariance for such permutation of players.\n* Before training all variables were normalized to be in [0; 1] range (except of sin, cos and outputs which were normalized to be in [-1; 1]).\n* Neural network contains no recurrent connections or convolution layers.\n\n<p align=\"center\">\n    <img src=\"http://artemefimov.ru/nfl/network_diagram.png\" width=\"700\">\n</p>\n\n# 5. Data used for making predictions\n \nSome remarks about information ***used*** in the model :\n* *Information about only 7 defense players and 6 offence players.* These numbers are most frequent in given tracking data. And such model can still be used for plays with more tracked players. You should simply choose arbitrarily 7 defense and 6 offence players. Or more complex calculate average value of predictions from all possible combinations of 7+6 players from given tracked players. It is easier than model with more players that should be trained with partially missed data.\n* *Speed characteristics of players \"s75\" and \"s99\".* The idea was that the first one represents speed of the run and the second one represents ability of afterburner. Actually these are per-player speed statistics from all given tracking data - 0.75-quantile and 0.99-quantile of the speed. It turned out they are very important for making predictions.\n\nWhat information ***is not used*** in the model:\n* *Football rules in any explicit forms.*\n* *Information about down.* Actually this information is of very importance. But experiments showed that including down information turns out to very vast overfitting (without regularizing) in relation to weights of connections from corresponding inputs. Instead of that it is more practical to train 3 different models for the down 1, 2 and 3 (the 4th down turned out to be very different).\n* *Players' positions.* Such decision seems to have more benefits than drawbacks. The pros are: no difficulties about coding positions, less-dimensional input, simpler model, faster training, less tendency to overfitting. The con is: rejecting some information that could be useful.\n* *Possible players actions except of moving.* Model do not know what player will do when he will close to player of opposite team. This is up to player discretion.\n"},{"metadata":{},"cell_type":"markdown","source":"# 6. Training of the model\n### 6.1 Training approach ###\nThe training can be described as stochastic batch gradient descent. The trick is that batch data consist of all data choosed for training, but this data should be shuffled before each iteration by means of players permutation. This trick provides us with 7! * 6! &asymp; 3.6 million more data for training. And such shuffling guarantee irrelevance of the trained model to players order.\n\n### 6.2 Data splitting ###\nAll available data was splitted in 3 parts:\n* *Test data* - data from games of weeks 14-17. This data was used only after finishing of training to confirm that trained model actually *learned something about the game* and has prediction accuracy better than random guessing.\n* *Validation data* - data from games of weeks 3, 6, 11 (were randomly choosed). This data was used to monitor the training, to early stop and prevent overfitting.\n* *Training data* - data from games of the rest of weeks. This data was actually used for gradient calculation and updating network weights.\n\n### 6.3 Training history ###\nTypical plot of training history is shown in figure below. There is noticeable difference between train and validation errors because of that train and validation data sets are from completely different games. Nevertheless they both are decreasing during the training without signs of overfitting that testify about generalization ability of the model.\n<img src=\"http://artemefimov.ru/nfl/training_curve.png\">"},{"metadata":{},"cell_type":"markdown","source":"# 7. Analysis of trained model\nAfter getting the trained model of *state-value function* we obviously want to check it for correctness. The traditional RL approach is to realize *policy* of action selection for *agent*, to put the agent in *environment* and to observe the result is it become better or not. Obviously this is not the option in this work.\n\nThe other option is to analyze what trained model can say us and to check is it consistent with common sense. Bearing in mind that this given model is simple, has limitations and is not of high accuracy.\n\n### 7.1 Prediction error depending on time from start of play ###\nThis dependence is shown in figure below. Maximum of uncertainty corresponds to the moment around 40% of total play time. It seems to be average moment before quarterback make pass. After that uncertainty decreases as the situation becomes clearer. The increasing of uncertainty after around 80% of total play time seems to be due to possible inaccuracy of the pass since it is unknown is it complete pass or not until ball reach pass receiver. So in the whole this figure looks like the truth.\n<img src=\"http://artemefimov.ru/nfl/prediction_error_per_play_time.png\">\n\n### 7.2 Prediction during play ###\nIt is of interest to analyze how prediction changes during the play. Obviously this can be done only for specific play.\n\nThe video below shows progress of prediction during the play between LA Rams and NO Saints that ended with touchdown.\n<p alig=\"left\">\n<video src=\"http://artemefimov.ru/nfl/3460out.mp4\" width=\"859\" hegith=\"508\" autoplay controls preload />\n</p>\n\nWhat is very interesting to observe:\n* The prediction begins to increase &asymp;0.5 sec ***before*** the pass was actually thrown.\n* At the moment when pass is received prediction is already 9.01 yards while pass receiver is actually only 5 yards from line of scrimmage.\n* After receiving the pass the prediction continues to fast increase until the very end of play.\n\nBarplots on the right side of the video illustrates additional opportunities provided by using neural networks as models. Namely the possibility of determining influence of every input variables on prediction. Actually these influences are defined by the partial derivatives of model output with respect to model inputs. They seems of no much meaning in this particular play. Just illustration of possible visualization."},{"metadata":{},"cell_type":"markdown","source":"# 8. Words of warning\nDealing with historical data one should be careful in interpreting the results. No matter what models and approaches are used. Any conclusions should be verified in practice. Experiment is criterion of truth in scientific method.\n\nIn the language of statistics it sounds like: [\"Correlation does not imply causation\"](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation). Every correlation might have multiple explanations.\n\nIn the RL it develops in that state-value function changes when agent changes his policy of taking actions. In the limit, it converges to some optimal state-value function. Until then state-value function has limited predictive capabilities."},{"metadata":{},"cell_type":"markdown","source":"# 9. Bonus. Tracks clusterization\nAt beginning of work I was thinking about the question \"What schemes defense employs?\". To answer this question I have developed algorithm that clusterize tracks of players.\n\nThe video below shows progress of tracks clusterization. Linebackers' tracks are used as an example. Relative to initial ball position at (0;0). Only first 5 seconds of tracks are used. Because very often pass happens  after 5 seconds of play. And it seems there should be big difference between tracks before and after pass.\n\nThe conclusion is that even when dealing with linebackers' tracks only the number of clusters remains big. If we will multiply this number by about the same numbers of clusters of other positions we will get unreal number of variants to deal with. Decreasing number of clusters will result in a significant loss of information which is unacceptable.\n<p align=\"left\">\n    <video src=\"http://artemefimov.ru/nfl/LB.mp4\" width=\"800\" autoplay controls preload />\n</p>\n"},{"metadata":{},"cell_type":"markdown","source":"# 10. Bonus 2. Play results vs Defense personnel\nAt the very beginning of work I have checked some correlations and have had interesting findings (even without using tracking data). They are shown in figure below.\n\n<img src=\"http://artemefimov.ru/nfl/confidence_intervals.png\">"},{"metadata":{},"cell_type":"markdown","source":"# 11. How AI assistance might look like\nAt the end I would like to share my vision how AI assistance in football might look like.\n\nI was inspired to this sketch by the very first game of 2018 regular season.\n\n<img src=\"http://artemefimov.ru/nfl/AI_assistance.png\">"},{"metadata":{},"cell_type":"markdown","source":"## p.s.\nAll media from this submission are available also at [this dataset](https://www.kaggle.com/arteme/media-of-my-submission-for-nfl-big-data-bowl-2021)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}