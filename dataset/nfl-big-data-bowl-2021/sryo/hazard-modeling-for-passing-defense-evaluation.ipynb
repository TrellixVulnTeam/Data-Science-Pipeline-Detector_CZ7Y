{"cells":[{"metadata":{},"cell_type":"markdown","source":"> # Hazard modeling for passing plays"},{"metadata":{},"cell_type":"markdown","source":"The yardage gained on the passing play in American football distributes to one-dimenstional distribution, which depends on defensive and offensive formations. This notebook adopts **Cox proportional hazard model** to express this distribution and shows the advantage of hazard modeling approach to infer players' contributions in each play."},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"Hazard modeling mainly focus on explaining the duration of time until some events happen. In hazard modeling, we estimate the hazard function instead of probability density function. \n\nLet $y$ be obtained yardage. Since the obtained yardage takes a discrete value, our aim is to estimate the discrete hazard function\n\n$$\n\\begin{aligned}\nh(y) = \\mathrm{Pr}(y \\leq Y < y + 1 \\mid Y \\geq y),\n\\end{aligned}\n$$\n\nwhich explains the probability of a player with a ball being stopped at $y$.\n\nIn a passing play, defensive players try to intercept pass or stop the player who catch the ball as soon as possible. In terms of the hazard function, defensive players try to increase $h(r)$ whereas offensive players decrease $h(r)$. \n\nThe aim of this notebook is to estimate how each player affects on this hazard. It is not sufficient to evaluate players contribution of passing play by simple stats like obtained yards, touchdowns and tuckles. Even one wide reciever gains long yards, it is unclear how other offensive players contribute to this gain.\nOn the other hand, using hazard values enables us to compare players' contributions between diferrent positions. "},{"metadata":{},"cell_type":"markdown","source":"# Model definition"},{"metadata":{},"cell_type":"markdown","source":"We adopt **Cox proportional model** to express the hazard function. Cox proportional model divides this hazard function into two parts as\n\n$$\n\\begin{aligned}\n    h(y) = h_0(y) \\cdot \\exp(\\phi(x, y)), \\, \\text{$x$ : covariates.}\n\\end{aligned}\n$$\n\n\nThe former part indicates how the hazard function depends on time and the latter part indicates how it depends on the covariate information.  Estimating the former part in empirical manner enables us to express the complex distribution easily.\n\nWe define $\\phi(x, y)$ as the summation of player's contribution.\n$$\n\\begin{aligned}\n    \\phi(x, y) =  \\phi_\\mathrm{P}(x_\\mathrm{P}, y \\mid x) + \\sum_{i=1}^{10} \\phi_\\mathrm{O}(x^{(i)}_\\mathrm{O}, y \\mid x) + \\sum_{j=1}^{11} \\phi_\\mathrm{D}(x^{(j)}_\\mathrm{D}, y \\mid x).\n\\end{aligned}\n$$\nHere, $x_\\mathrm{P}, \\{x^{(i)}_\\mathrm{O}\\}_{i=1, \\cdots, 10} \\,\\, ,  \\{x^{(j)}_\\mathrm{D}\\}_{j=1, \\cdots, 11} \\, \\, $ are player's information for a quaterback, offensive players and defensive players. $\\phi_\\mathrm{P}(\\cdot), \\phi_\\mathrm{O}(\\cdot), \\phi_\\mathrm{D}(\\cdot)$ are estimand functions. Specifically, we use players' locations and velocities when the quaterback throws the ball as $x$.\n\nEach player's contribution to the hazard is also affected by nearby players. We express these interactions as graph expression. \nFirst, we calculate Delaunay diagram from players location those who directly involve passing play (e.g. QB, WL, LB, DB). Then, we omit some edges which may not influence on this passing play, and construct a graph indicates the pairs of offensive players and defensive players.\nUnder this graph, we adopt **Gated Graph Neural Network** for expressing $\\phi_\\mathrm{P}(\\cdot), \\phi_\\mathrm{O}(\\cdot), \\phi_\\mathrm{D}(\\cdot)$. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/gatedgnn/GGNN.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Application example"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport networkx as nx\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom scipy.spatial import Delaunay","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def split_dispaly_name(display_name):\n    display_name_splited = display_name.split(' ')\n    if len(display_name_splited) == 2:\n        return display_name_splited[0][0] + '.' + display_name_splited[1]\n    else:\n        return display_name\n\n\ndef find_passer_and_carrier(game, play, play_detail):\n\n    homeTeam, awayTeam = game.homeTeamAbbr.values[0], game.visitorTeamAbbr.values[0]\n    possessionTeam = play.possessionTeam.values[0]\n    play_description = play.playDescription.values[0].replace('(', '').replace(').', '').replace(' .', '')\n\n    player_in_description =  [word for word in play_description.split(' ') if '.' in word]\n    player_in_description_converted = []\n\n    for player in player_in_description:\n\n        player_splited = player.split('.')\n        player_in_description_converted.append(player_splited[0][0] + '.' + player_splited[1])\n\n    display_names = np.array(list(map(split_dispaly_name, play_detail.displayName.values)))\n    play_detail_in_descritpion = play_detail[np.array(list(map(lambda display_name: display_name in player_in_description_converted, display_names)))]\n\n    play_detail_passer = play_detail_in_descritpion[play_detail_in_descritpion.position.values == 'QB']\n\n    if homeTeam == possessionTeam:\n        play_detail_carrier = play_detail_in_descritpion[(play_detail_in_descritpion.position.values != 'QB') * (play_detail_in_descritpion.team.values == 'home')]\n    else:\n        play_detail_carrier = play_detail_in_descritpion[(play_detail_in_descritpion.position.values != 'QB') * (play_detail_in_descritpion.team.values == 'away')]\n\n    return play_detail_passer, play_detail_carrier\n\n\ndef extract_feature(game, play, play_detail):\n\n    homeTeam, awayTeam = game.homeTeamAbbr.values[0], game.visitorTeamAbbr.values[0]\n    possessionTeam = play.possessionTeam.values[0]\n\n    vel = pd.concat([np.cos((- play_detail.dir.values + 90) / 360 * 2 * np.pi) * play_detail['s'], np.sin((- play_detail.dir.values + 90) / 360 * 2 * np.pi) * play_detail['s']], axis=1)\n    vel.columns = ['vel_x', 'vel_y']\n    play_detail = pd.concat([play_detail, vel], axis=1)\n\n    play_detail_passer, play_detail_carrier = find_passer_and_carrier(game, play, play_detail)\n\n    if homeTeam == possessionTeam:\n        play_detail_offense, play_detail_defense = play_detail[play_detail.team.values == \"home\"], play_detail[play_detail.team.values == \"away\"]\n    else:\n        play_detail_offense, play_detail_defense = play_detail[play_detail.team.values == \"away\"], play_detail[play_detail.team.values == \"home\"]\n\n    direction = 2 * np.float('right' == play_detail.playDirection.values[0]) - 1\n    scrimmageLine = play.absoluteYardlineNumber.values[0]\n    if np.isnan(scrimmageLine):\n        scrimmageLine = play_detail['x'].values.mean(0)\n\n    name_passer = play_detail_passer.displayName.values\n    name_carrier = play_detail_carrier.displayName.values\n    name_offense = play_detail_offense.displayName.values\n    name_defense = play_detail_defense.displayName.values\n\n    is_not_passer_carrier = np.logical_not(np.any(name_offense == name_passer[:, np.newaxis], 0)) * np.logical_not(np.any(name_offense == name_carrier[:, np.newaxis], 0))\n\n    name = np.hstack([name_passer, name_carrier, np.pad(name_offense[is_not_passer_carrier], [0, 11 - name_offense.shape[0]]), np.pad(name_defense, [0, 11 - name_defense.shape[0]])])\n    name_replaced = np.array(['Other' if na == 0 else na for na in name])\n\n    position_passer = play_detail_passer.position.values\n    position_carrier = play_detail_carrier.position.values\n    position_offense = play_detail_offense.position.values\n    position_defense = play_detail_defense.position.values\n\n    position = np.hstack([position_passer, position_carrier, np.pad(position_offense[is_not_passer_carrier], [0, 11 - position_offense.shape[0]]), np.pad(position_defense, [0, 11 - position_defense.shape[0]])])\n    position_replaced = []\n\n    for pos in position:\n\n        if pos in ['QB']:\n            position_replaced.append('QB')\n        elif pos in  ['RB', 'HB', 'FB', 'TE', 'WR']:\n            position_replaced.append('WR')\n        elif pos in ['LB', 'ILB', 'OLB', 'MLB']:\n            position_replaced.append('LB')\n        elif pos in ['DB', 'CB', 'FS', 'SS', 'S', 'SAF']:\n            position_replaced.append('DB')\n        else:\n            position_replaced.append('Other')\n\n    position_replaced = np.array(position_replaced)\n\n    loc_passer = (play_detail_passer[['x', 'y']].values - np.array([scrimmageLine, 53.3 / 2])) * direction\n    loc_carrier = (play_detail_carrier[['x', 'y']].values - np.array([scrimmageLine, 53.3 / 2])) * direction\n    loc_offense = (play_detail_offense[['x', 'y']].values - np.array([scrimmageLine, 53.3 / 2])) * direction\n    loc_defense = (play_detail_defense[['x', 'y']].values - np.array([scrimmageLine, 53.3 / 2])) * direction\n\n    vel_passer = play_detail_passer[['vel_x', 'vel_y']].values * direction\n    vel_carrier = play_detail_carrier[['vel_x', 'vel_y']].values * direction\n    vel_offense = play_detail_offense[['vel_x', 'vel_y']].values * direction\n    vel_defense = play_detail_defense[['vel_x', 'vel_y']].values * direction\n\n    if possessionTeam == homeTeam:\n        offense_team, defense_team = homeTeam, awayTeam\n    else:\n        defense_team, offense_team = homeTeam, awayTeam\n\n    loc = np.vstack([loc_passer, loc_carrier, np.pad(loc_offense[is_not_passer_carrier], ([0, 11 - loc_offense.shape[0]], [0, 0])), np.pad(loc_defense, ([0, 11 - loc_defense.shape[0]], [0, 0]))])\n    vel = np.vstack([vel_passer, vel_carrier, np.pad(vel_offense[is_not_passer_carrier], ([0, 11 - loc_offense.shape[0]], [0, 0])), np.pad(vel_defense, ([0, 11 - loc_defense.shape[0]], [0, 0]))])\n    m = np.hstack([np.pad(np.ones(loc_offense.shape[0]), ([0, 11 - loc_offense.shape[0]])), np.pad(np.ones(loc_defense.shape[0]), ([0, 11 - loc_defense.shape[0]]))]).astype(np.bool)\n\n    x = np.hstack([loc, vel])\n\n    delau = Delaunay(loc[m])\n    adj = np.zeros((22, 22))\n    ind = np.arange(22)[m]\n\n    for i in range(delau.simplices.shape[0]):\n        for j in delau.simplices[i]:\n            adj[ind[j], ind[delau.simplices[i]]] = 1\n\n    adj *= 1 - np.eye(22)\n    adj[1:11, 1:11] = 0.\n    adj[11:, 11:] = 0.\n\n    y = play.offensePlayResult.values[0]\n    c = 'touchdown' not in play.playDescription.values[0]\n\n    return x, m, adj, y, c, position_replaced, name_replaced, offense_team, defense_team\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"games = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/games.csv')\nplays = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/plays.csv')\nplayers = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/players.csv')\n\nweeks = []\nfor i in range(1, 18):\n    week = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2021/week%s.csv' %i)\n    week = week.query('event == \"pass_forward\" or event == \"pass_shovel\" or event == \"pass_lateral\"')\n    week = week.drop_duplicates()\n    weeks.append(week)\n\nxs, ms, adjs, ys, cs = [], [], [], [], []\n\npositions, names = [], []\noffense_teams, defense_teams = [], []\n\nfor week in weeks:\n\n    for gameId in list(set(week.gameId.values)):\n\n        for playId in list(set(plays.query('gameId == %s' % gameId).playId.values)):\n\n            game = games.query('gameId == %s' % gameId)\n            play = plays.query('gameId == %s and playId == %s' % (gameId, playId))\n            play_detail = week.query('gameId == %s and playId == %s' % (gameId, playId))\n\n            if (play.passResult.values[0] == 'C' or play.passResult.values[0] == 'I') and play.penaltyCodes.values[0] is np.nan and 'FUMBLES' not in play.playDescription.values[0] and 'Direct snap' not in play.playDescription.values[0] and 'Punt' not in play.playDescription.values[0] and 'spike' not in play.playDescription.values[0]:\n\n                try:\n                    x, m, adj, y, c, position, name, offense_team, defense_team = extract_feature(game, play, play_detail)\n\n                    xs.append(x)\n                    ms.append(m)\n                    adjs.append(adj)\n                    ys.append(y)\n                    cs.append(c)\n\n                    positions.append(position)\n                    names.append(name)\n                    offense_teams.append(offense_team)\n                    defense_teams.append(defense_team)\n\n                except:\n                    \n                    pass\n\nxs, adjs, ys, cs = np.stack(xs), np.stack(adjs), np.hstack(ys), np.array(cs).astype(np.int)\nms = np.stack(ms)\n\nnames, positions, offense_teams, defense_teams = np.vstack(names),  np.vstack(positions), np.hstack(offense_teams), np.hstack(defense_teams)\n\nind = np.logical_not(np.any(np.isnan(xs), axis=(1, 2))) * (ms[:, :11].sum(1) != 0) * (ms[:, 11:].sum(1) != 0)\nxs, adjs, ys, cs, ms = xs[ind], adjs[ind], ys[ind], cs[ind], ms[ind]\nnames, positions, offense_teams, defense_teams = names[ind], positions[ind], offense_teams[ind], defense_teams[ind]\n\nX_eval, A_eval, M_eval = tf.constant(xs, dtype=tf.float32), tf.constant(adjs, dtype=tf.float32), tf.constant(ms, dtype=tf.float32)\n\nxs, adjs, ys, cs, ms = np.vstack([xs, xs * np.array([1, -1, 1, -1])]), np.vstack([adjs, adjs]), np.hstack([ys, ys]), np.hstack([cs, cs]), np.vstack([ms, ms])\nxs, adjs, ys, cs, ms = xs[np.argsort(ys)], adjs[np.argsort(ys)], ys[np.argsort(ys)], cs[np.argsort(ys)], ms[np.argsort(ys)]\n\nX, A, M = tf.constant(xs, dtype=tf.float32), tf.constant(adjs, dtype=tf.float32), tf.constant(ms, dtype=tf.float32)\n\nn = xs.shape[0]\nys_unique, ys_index, ys_inverse, ys_count = np.unique(ys, return_index=True, return_inverse=True, return_counts=True)\nys_mask = tf.constant(np.arange(ys_unique[0], ys_unique[-1] + 1)[:, np.newaxis] == ys_unique, dtype=tf.float32)\n\ncs_count = []\nfor j in ys_unique:\n    cs_count.append(cs[ys == j].sum())\n\ncs_count = np.array(cs_count)\n\ncs_mask = np.zeros((n, ys_unique.shape[0]))\nfor j, index, count in zip(range(ys_unique.shape[0]), ys_index, ys_count):\n    cs_mask[index:index+count, j] = 1.\ncs_mask = tf.constant(cs_mask, dtype=tf.float32)\n\nmask = tf.constant(ys_index <= np.arange(n)[:, np.newaxis], dtype=tf.float32)\ninf_array = - tf.ones_like(mask, dtype=tf.float32) * np.inf\n\nzero_index = tf.cast(ys_unique == 0, tf.float32)[tf.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class GGNN(tf.keras.Model):\n\n    \n    def __init__(self):\n\n        super(GGNN, self).__init__()\n\n        self.gru_L = 5\n\n        self.denseGRU_P, self.denseGRU_O, self.denseGRU_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh)\n\n        self.update_P, self.update_O, self.update_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid, use_bias=False), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid, use_bias=False), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid, use_bias=False)\n        self.reset_P, self.reset_O, self.reset_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid, use_bias=False), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid, use_bias=False), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid, use_bias=False)\n        self.modify_P, self.modify_O, self.modify_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh, use_bias=True), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh, use_bias=True), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh, use_bias=True)\n\n        self.dropoutGRU_P, self.dropoutGRU_O, self.dropoutGRU_D = tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate)\n        self.dropoutGRU_neighbor_P, self.dropoutGRU_neighbor_O, self.dropoutGRU_neighbor_D = tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate)\n\n        self.dense1_P, self.dense1_O, self.dense1_D = tf.keras.layers.Dense(n_layer1, activation=tf.nn.tanh), tf.keras.layers.Dense(n_layer1, activation=tf.nn.tanh), tf.keras.layers.Dense(n_layer1, activation=tf.nn.tanh)\n        self.dropout1_P, self.dropout1_O, self.dropout1_D = tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate)\n\n        self.dense2_P, self.dense2_O, self.dense2_D = tf.keras.layers.Dense(1, use_bias=False), tf.keras.layers.Dense(1, use_bias=False), tf.keras.layers.Dense(1, use_bias=False)\n        self.weight_P, self.weight_O, self.weight_D = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid), tf.keras.layers.Dense(1, activation=tf.nn.sigmoid), tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n\n\n    @tf.function\n    def call(self, X, A, M, is_training=False):\n\n        X_P = tf.slice(X, [0, 0, 0], [-1, 1, -1])\n        X_O = tf.concat([tf.tile(X_P, (1, 10, 1)), tf.slice(X, [0, 1, 0], [-1, 10, -1])], axis=2)\n        X_D = tf.concat([tf.tile(X_P, (1, 11, 1)), tf.slice(X, [0, 11, 0], [-1, 11, -1])], axis=2)\n\n        M_P, M_O, M_D = tf.slice(M, [0, 0], [-1, 1]), tf.slice(M, [0, 1], [-1, 10]), tf.slice(M, [0, 11], [-1, 11])\n\n        layerGRU_P, layerGRU_O, layerGRU_D = self.denseGRU_P(X_P), self.denseGRU_O(X_O), self.denseGRU_D(X_D)\n\n        maskGRU_update_P, maskGRU_update_O, maskGRU_update_D = self.dropoutGRU_P(tf.ones_like(layerGRU_P), is_training), self.dropoutGRU_O(tf.ones_like(layerGRU_O), is_training), self.dropoutGRU_D(tf.ones_like(layerGRU_D), is_training)\n        maskGRU_reset_P, maskGRU_reset_O, maskGRU_reset_D = self.dropoutGRU_P(tf.ones_like(layerGRU_P), is_training), self.dropoutGRU_O(tf.ones_like(layerGRU_O), is_training), self.dropoutGRU_D(tf.ones_like(layerGRU_D), is_training)\n        maskGRU_modify_P, maskGRU_modify_O, maskGRU_modify_D = self.dropoutGRU_P(tf.ones_like(layerGRU_P), is_training), self.dropoutGRU_O(tf.ones_like(layerGRU_O), is_training), self.dropoutGRU_D(tf.ones_like(layerGRU_D), is_training)\n\n        maskGRU_update_neighbor_P, maskGRU_update_neighbor_O, maskGRU_update_neighbor_D = self.dropoutGRU_neighbor_P(tf.ones(tf.shape(layerGRU_P) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_O(tf.ones(tf.shape(layerGRU_O) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_D(tf.ones(tf.shape(layerGRU_D) * (1, 1, 2)), is_training)\n        maskGRU_reset_neighbor_P, maskGRU_reset_neighbor_O, maskGRU_reset_neighbor_D = self.dropoutGRU_neighbor_P(tf.ones(tf.shape(layerGRU_P) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_O(tf.ones(tf.shape(layerGRU_O) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_D(tf.ones(tf.shape(layerGRU_D) * (1, 1, 2)), is_training)\n        maskGRU_modify_neighbor_P, maskGRU_modify_neighbor_O, maskGRU_modify_neighbor_D = self.dropoutGRU_neighbor_P(tf.ones(tf.shape(layerGRU_P) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_O(tf.ones(tf.shape(layerGRU_O) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_D(tf.ones(tf.shape(layerGRU_D) * (1, 1, 2)), is_training)\n\n        for l in range(self.gru_L):\n\n            layerGRU_neighbor_P = tf.concat([tf.matmul(A[:, :1, 1:11], layerGRU_O), tf.matmul(A[:, :1, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_O = tf.concat([tf.matmul(A[:, 1:11, :1], layerGRU_P), tf.matmul(A[:, 1:11, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_D = tf.concat([tf.matmul(A[:, 11:, :1], layerGRU_P), tf.matmul(A[:, 11:, 1:11], layerGRU_O)], axis=-1)\n\n            z_P = self.update_P(tf.concat([layerGRU_P * maskGRU_update_P, layerGRU_neighbor_P * maskGRU_update_neighbor_P], 2))\n            r_P = self.reset_P(tf.concat([layerGRU_P * maskGRU_reset_P, layerGRU_neighbor_P * maskGRU_reset_neighbor_P], 2))\n            layerGRU_modified_P = self.modify_P(tf.concat([layerGRU_P * r_P * maskGRU_modify_P, layerGRU_neighbor_P * maskGRU_modify_neighbor_P], 2))\n\n            z_O = self.update_O(tf.concat([layerGRU_O * maskGRU_update_O, layerGRU_neighbor_O * maskGRU_update_neighbor_O], 2))\n            r_O = self.reset_O(tf.concat([layerGRU_O * maskGRU_reset_O, layerGRU_neighbor_O * maskGRU_reset_neighbor_O], 2))\n            layerGRU_modified_O = self.modify_O(tf.concat([layerGRU_O * r_O * maskGRU_modify_O, layerGRU_neighbor_O * maskGRU_modify_neighbor_O], 2))\n\n            z_D = self.update_D(tf.concat([layerGRU_D * maskGRU_update_D, layerGRU_neighbor_D * maskGRU_update_neighbor_D], 2))\n            r_D = self.reset_D(tf.concat([layerGRU_D * maskGRU_reset_D, layerGRU_neighbor_D * maskGRU_reset_neighbor_D], 2))\n            layerGRU_modified_D = self.modify_D(tf.concat([layerGRU_D * r_D * maskGRU_modify_D, layerGRU_neighbor_D * maskGRU_modify_neighbor_D], 2))\n\n            layerGRU_P = (1. - z_P) * layerGRU_P + z_P * layerGRU_modified_P\n            layerGRU_O = (1. - z_O) * layerGRU_O + z_O * layerGRU_modified_O\n            layerGRU_D = (1. - z_D) * layerGRU_D + z_D * layerGRU_modified_D\n\n        layer1_P, layer1_O, layer1_D = self.dense1_P(layerGRU_P), self.dense1_O(layerGRU_O), self.dense1_D(layerGRU_D)\n        layer1_P, layer1_O, layer1_D = self.dropout1_P(layer1_P), self.dropout1_O(layer1_O), self.dropout1_D(layer1_D)\n        layer2_P, layer2_O, layer2_D = self.dense2_P(layer1_P), self.dense2_O(layer1_O), self.dense2_D(layer1_D)\n        weight_P, weight_O, weight_D = self.weight_P(layer1_P), self.weight_O(layer1_O), self.weight_D(layer1_D)\n\n        layer2_P = layer2_P * (weight_P * zero_index + (1. - weight_P))\n        layer2_O = layer2_O * (weight_O * zero_index + (1. - weight_O))\n        layer2_D = layer2_D * (weight_D * zero_index + (1. - weight_D))\n\n        out = tf.squeeze(M_P[:, :, tf.newaxis] * layer2_P, 1) + tf.reduce_sum(M_O[:, :, tf.newaxis] * layer2_O, 1) + tf.reduce_sum(M_D[:, :, tf.newaxis] * layer2_D, 1)\n\n        return out\n\n    def call_players(self, X, A, M):\n\n        X_P = tf.slice(X, [0, 0, 0], [-1, 1, -1])\n        X_O = tf.concat([tf.tile(X_P, (1, 10, 1)), tf.slice(X, [0, 1, 0], [-1, 10, -1])], axis=2)\n        X_D = tf.concat([tf.tile(X_P, (1, 11, 1)), tf.slice(X, [0, 11, 0], [-1, 11, -1])], axis=2)\n\n        M_P, M_O, M_D = tf.slice(M, [0, 0], [-1, 1]), tf.slice(M, [0, 1], [-1, 10]), tf.slice(M, [0, 11], [-1, 11])\n\n        layerGRU_P, layerGRU_O, layerGRU_D = self.denseGRU_P(X_P), self.denseGRU_O(X_O), self.denseGRU_D(X_D)\n\n        for l in range(self.gru_L):\n\n            layerGRU_neighbor_P = tf.concat([tf.matmul(A[:, :1, 1:11], layerGRU_O), tf.matmul(A[:, :1, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_O = tf.concat([tf.matmul(A[:, 1:11, :1], layerGRU_P), tf.matmul(A[:, 1:11, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_D = tf.concat([tf.matmul(A[:, 11:, :1], layerGRU_P), tf.matmul(A[:, 11:, 1:11], layerGRU_O)], axis=-1)\n\n            z_P = self.update_P(tf.concat([layerGRU_P, layerGRU_neighbor_P], 2))\n            r_P = self.reset_P(tf.concat([layerGRU_P, layerGRU_neighbor_P], 2))\n            layerGRU_modified_P = self.modify_P(tf.concat([layerGRU_P * r_P, layerGRU_neighbor_P], 2))\n\n            z_O = self.update_O(tf.concat([layerGRU_O, layerGRU_neighbor_O], 2))\n            r_O = self.reset_O(tf.concat([layerGRU_O, layerGRU_neighbor_O], 2))\n            layerGRU_modified_O = self.modify_O(tf.concat([layerGRU_O * r_O, layerGRU_neighbor_O], 2))\n\n            z_D = self.update_D(tf.concat([layerGRU_D, layerGRU_neighbor_D], 2))\n            r_D = self.reset_D(tf.concat([layerGRU_D, layerGRU_neighbor_D], 2))\n            layerGRU_modified_D = self.modify_D(tf.concat([layerGRU_D * r_D, layerGRU_neighbor_D], 2))\n\n            layerGRU_P = (1. - z_P) * layerGRU_P + z_P * layerGRU_modified_P\n            layerGRU_O = (1. - z_O) * layerGRU_O + z_O * layerGRU_modified_O\n            layerGRU_D = (1. - z_D) * layerGRU_D + z_D * layerGRU_modified_D\n\n        layer1_P, layer1_O, layer1_D = self.dense1_P(layerGRU_P), self.dense1_O(layerGRU_O), self.dense1_D(layerGRU_D)\n        layer2_P, layer2_O, layer2_D = self.dense2_P(layer1_P), self.dense2_O(layer1_O), self.dense2_D(layer1_D)\n        weight_P, weight_O, weight_D = self.weight_P(layer1_P), self.weight_O(layer1_O), self.weight_D(layer1_D)\n\n        layer2_P = layer2_P * (weight_P * zero_index + (1. - weight_P))\n        layer2_O = layer2_O * (weight_O * zero_index + (1. - weight_O))\n        layer2_D = layer2_D * (weight_D * zero_index + (1. - weight_D))\n\n        return tf.concat([M_P[:, :, tf.newaxis] * layer2_P, M_O[:, :, tf.newaxis] * layer2_O, M_D[:, :, tf.newaxis] * layer2_D], axis=1)\n\n    \ndef compute_cost(model, X, A, M):\n\n    out = model.call(X, A, M, True)\n\n    out_max = tf.reduce_max(tf.where(tf.cast(mask, tf.bool), out, inf_array), 0)\n    exp_sum = tf.reduce_sum(tf.exp(out - out_max) * mask, 0)\n    den = (out_max + tf.math.log(exp_sum)) * cs_count\n\n    cost = - tf.reduce_sum(tf.reduce_sum(out * cs_mask, 1) * cs) + tf.reduce_sum(den)\n\n    return cost\n\n\n@tf.function\ndef compute_gradients(model, X, A, M):\n\n    with tf.GradientTape() as tape:\n        cost = compute_cost(model, X, A, M)\n\n    return tape.gradient(cost, model.trainable_variables), cost\n\n\n@tf.function\ndef apply_gradients(optimizer, gradients, variables):\n\n    optimizer.apply_gradients(zip(gradients, variables))\n\n\ndef compute_baseline_hazard(model, X, A, M):\n\n    out = model.call(X, A, M, False)\n\n    out_max = tf.reduce_max(tf.where(tf.cast(mask, tf.bool), out, inf_array), 0)\n    exp_sum = tf.reduce_sum(tf.exp(out - out_max) * mask, 0)\n    den = (out_max + tf.math.log(exp_sum)) * cs_count\n\n    baseline_hazard = np.sum(ys_mask * tf.exp(- out_max) * exp_sum.numpy() ** -1 * cs_count, axis=1)\n\n    return baseline_hazard\n\n\ndef compute_hazard_ratio(model, X, A, M):\n\n    out = model.call(X, A, M, False)\n    hazard_ratio = np.dot(tf.exp(out).numpy(), tf.transpose(ys_mask))\n\n    return hazard_ratio","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Training ...')\n\nlearning_rate = 0.01\ndropout_rate = 0.1\nn_layerGRU = 32\nn_layer1 = 16\nn_player_info = 4\nn_ties = ys_unique.shape[0]\n\nmodel = GGNN()\noptimizer = tf.keras.optimizers.Adam(learning_rate)\n\ntraning_epochs = 1000\n\nfor epoch in range(traning_epochs):\n\n    gradients, cost_epoch = compute_gradients(model, X, A, M)\n    apply_gradients(optimizer, gradients, model.variables)\n\n    if (epoch + 1) % 100 == 0:\n\n        print('epoch ' + str(epoch + 1) + ': ' + str(cost_epoch.numpy()))\n        \nout_players = model.call_players(X_eval, A_eval, M_eval)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def draw_play(game, play, play_detail, is_pass=True):\n\n    x, m, adj, y, c, position, name, offense_team, defense_team = extract_feature(game, play, play_detail)\n    out = model.call_players(tf.constant(x[np.newaxis], dtype=tf.float32), tf.constant(adj[np.newaxis], dtype=tf.float32), tf.constant(m[np.newaxis], dtype=tf.float32))\n\n    loc, vel = x[m, :2], x[m, 2:]\n    position = position[m]\n\n    if is_pass:\n        score = np.sum(out.numpy()[0, m] * zero_index, -1)\n    else:\n        score = np.sum(out.numpy()[0, m] * (1. - zero_index), -1) / np.sum(1. - zero_index)\n\n    n_offense, n_defense = m[:11].sum(), m[11:].sum()\n    n = n_offense + n_defense\n\n    G = nx.Graph()\n\n    G.add_nodes_from(np.arange(n_offense), bipartite=0)\n    G.add_nodes_from(np.arange(n_offense, n_offense + n_defense), bipartite=1)\n    node_color = ['r']\n    node_color.extend(['b' for i in range(n_offense - 1)])\n    node_color.extend(['g' for i in range(n_defense)])\n\n    row, col = np.where(adj[m, :][:, m] != 0)\n    G.add_edges_from(zip(row, col))\n\n    plt.figure(figsize=(12, 12))\n\n    nx.draw_networkx_nodes(G, loc, node_color=node_color, node_size=1000, alpha=1.)\n    nx.draw_networkx_edges(G, loc, alpha=0.5, style='dashed', edge_color='k')\n    nx.draw_networkx_labels(G, loc, {i: position[i] for i in range(len(position))}, font_weight='bold', font_color='white')\n\n    for i in range(n):\n        plt.arrow(loc[i, 0], loc[i, 1], vel[i, 0] / 2. + 0.01, vel[i, 1] / 2. + 0.01, width=0.01, head_width=0.3,head_length=0.3,length_includes_head=True, color='k', alpha=0.4)\n        plt.text(loc[i, 0]+0.5, loc[i, 1]+0.5, np.around(np.exp(score[i]), 2))\n\n    xmin, ymin = loc.min(0)\n    xmax, ymax = loc.max(0)\n    \n    plt.vlines(0, ymin-1, ymax+1, linestyle='solid', alpha=0.2)\n    plt.vlines(play.yardsToGo.values[0], ymin-1, ymax+1, color='goldenrod', linestyle='solid', alpha=0.5)\n    plt.ylim(xmin-1, xmax+1)\n    plt.ylim(ymin-1, ymax+1)\n    \n    print(\"OFFENSE: \" + str(np.around(np.exp(np.sum(score[:11])), 2)))\n    print(\"DEFENSE: \" + str(np.around(np.exp(np.sum(score[11:])), 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following figure shows the assigned hazard values for players in one passing play. \nEach value indicates hazard ratio at 0 yard. \nFor example, if a defensive player have 1.5, then the hazard at 0 yard on this play is 1.5 times larger due to this player."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"i = 39\ngameId, playId = week.gameId.values[i], week.playId.values[i]\n\ngame = games.query('gameId == %s' % gameId)\nplay = plays.query('gameId == %s and playId == %s' % (gameId, playId))\nplay_detail = week.query('gameId == %s and playId == %s' % (gameId, playId))\n\ndraw_play(game, play, play_detail, False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following tables show that the mean hazard values for players and teams in 2018 season. These results differ from the passing stats in 2018 season. This is because our model only considers offensive and defensive formations and ignores the players' performances and skills."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"offense_players = np.unique(names[positions == 'WR'])\n\nscore_offense_players = pd.Series([np.exp(tf.reduce_mean(tf.reduce_sum(out_players[:, 1:11][names[:, 1:11] == player] * zero_index, 1) / tf.reduce_sum(zero_index))) for player in offense_players if np.sum(names == player) > 100], index= [player for player in offense_players if np.sum(names == player) > 100])\nscore_offense_players = score_offense_players.sort_values()\n\ndefense_players = np.unique(names[positions == 'LB'])\n\nscore_defense_players = pd.Series([np.exp(tf.reduce_mean(tf.reduce_sum(out_players[:, 11:][names[:, 11:] == player] * zero_index, 1) / tf.reduce_sum(zero_index))) for player in defense_players if np.sum(names == player) > 100], index= [player for player in defense_players if np.sum(names == player) > 100])\nscore_defense_players = score_defense_players.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Top 10 Offense players (WR)')\nprint(score_offense_players.head(10))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Top 10 Defense players (DB)')\nprint(score_defense_players.head(10))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"teams = np.unique(offense_teams)\n\nscore_offense_teams = pd.Series([np.exp(tf.reduce_mean(tf.reduce_sum(out_players[offense_teams == team][:, :11] * (1 - zero_index), (1, 2))) / np.sum(1 - zero_index)) for team in teams], index=teams)\nscore_offense_teams = score_offense_teams.sort_values()\n\nscore_defense_teams = pd.Series([np.exp(tf.reduce_mean(tf.reduce_sum(out_players[defense_teams == team][:, 11:] * (1 - zero_index), (1, 2))) / np.sum(1 - zero_index)) for team in teams], index=teams)\nscore_defense_teams = score_defense_teams.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Top 10 Offense teams')\nprint(score_offense_teams.head(10))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Top 10 Defense teams')\nprint(score_defense_teams.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, we have demonstrated how to incorpolate hazard modeling to evaluate passing play performance. \nThe main advantage of our model is that it can decompose defensive (or offensive) performance into the sum of players' contributions in terms of hazard rate.\n\nOur model can be extended to more complicated model. One possible challenge is to incorporate each player's skill into our model. Such extension may provide more reliable information about player's performance along one season and suggest appropriate defensive (or offensive) formations for each NFL team."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}