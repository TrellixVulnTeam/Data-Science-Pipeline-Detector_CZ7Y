{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/springleaf-marketing-response/train.csv.zip')\ndf_test = pd.read_csv('/kaggle/input/springleaf-marketing-response/test.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data[missing_data[\"Total\"] > 1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf_test = df_test.drop((missing_data[missing_data['Total'] > 1]).index,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"target\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df_train.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.select_dtypes(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"VAR_0001\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['0001H'] = df_train['VAR_0001'].map({'H': 1, 'R': 0, 'Q': 0})\ndf_train['0001R'] = df_train['VAR_0001'].map({'H': 0, 'R': 1, 'Q': 0})\ndf_train['0001Q'] = df_train['VAR_0001'].map({'H': 0, 'R': 0, 'Q': 1})\ndf_train.pop(\"VAR_0001\")\n\ndf_test['0001H'] = df_test['VAR_0001'].map({'H': 1, 'R': 0, 'Q': 0})\ndf_test['0001R'] = df_test['VAR_0001'].map({'H': 0, 'R': 1, 'Q': 0})\ndf_test['0001Q'] = df_test['VAR_0001'].map({'H': 0, 'R': 0, 'Q': 1})\ndf_test.pop(\"VAR_0001\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"VAR_0005\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['0005C'] = df_train['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_train['0005B'] = df_train['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_train['0005N'] = df_train['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_train['0005S'] = df_train['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_train.pop(\"VAR_0005\")\n\ndf_test['0005C'] = df_test['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_test['0005B'] = df_test['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_test['0005N'] = df_test['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_test['0005S'] = df_test['VAR_0005'].map({'C': 1, 'B': 0, 'N': 0, 'S': 0})\ndf_test.pop(\"VAR_0005\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"VAR_1934\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['1934_IAPS'] = df_train['VAR_1934'].map({'IAPS': 1, 'RCC': 0, 'BRANCH': 0, 'MOBILE': 0, 'CSC': 0})\ndf_train['1934_RCC'] = df_train['VAR_1934'].map({'IAPS': 0, 'RCC': 1, 'BRANCH': 0, 'MOBILE': 0, 'CSC': 0})\ndf_train['1934_BRANCH'] = df_train['VAR_1934'].map({'IAPS': 0, 'RCC': 0, 'BRANCH': 1, 'MOBILE': 0, 'CSC': 0})\ndf_train['1934_MOBILE'] = df_train['VAR_1934'].map({'IAPS': 0, 'RCC': 0, 'BRANCH': 0, 'MOBILE': 1, 'CSC': 0})\ndf_train['1934_CSC'] = df_train['VAR_1934'].map({'IAPS': 0, 'RCC': 0, 'BRANCH': 0, 'MOBILE': 0, 'CSC': 1})\ndf_train.pop(\"VAR_1934\")\n\ndf_test['1934_IAPS'] = df_test['VAR_1934'].map({'IAPS': 1, 'RCC': 0, 'BRANCH': 0, 'MOBILE': 0, 'CSC': 0})\ndf_test['1934_RCC'] = df_test['VAR_1934'].map({'IAPS': 0, 'RCC': 1, 'BRANCH': 0, 'MOBILE': 0, 'CSC': 0})\ndf_test['1934_BRANCH'] = df_test['VAR_1934'].map({'IAPS': 0, 'RCC': 0, 'BRANCH': 1, 'MOBILE': 0, 'CSC': 0})\ndf_test['1934_MOBILE'] = df_test['VAR_1934'].map({'IAPS': 0, 'RCC': 0, 'BRANCH': 0, 'MOBILE': 1, 'CSC': 0})\ndf_test['1934_CSC'] = df_test['VAR_1934'].map({'IAPS': 0, 'RCC': 0, 'BRANCH': 0, 'MOBILE': 0, 'CSC': 1})\ndf_test.pop(\"VAR_1934\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(df_train.select_dtypes(include=['O']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.fillna(-1)\ndf_test = df_test.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['target1'] = df_train[\"target\"]\ndf_train.pop('target')\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_train.drop('target1', 1), df_train['target1'], test_size = .2, random_state=10) \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nbest = 0 \naverage = 0\ntotal_for_average = 0\nmodel1 = xgb.XGBClassifier(max_depth=2, n_estimators=200, learning_rate=0.2)\nmodel1.fit(df_train.drop('target1', 1), df_train['target1'])\ny_pred = model1.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\ntotal_for_average += 1\naverage += accuracy_score(y_test, y_pred)\nif (accuracy_score(y_test, y_pred) > best): \n    best = accuracy_score(y_test, y_pred)\nprint(\"\\nThe Best is\", best)\nprint(\"The Average is\", average/total_for_average)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''y_pred_l = model1.predict(df_test)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndb=pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ndb['Survived'] = y_pred_l\ndb.to_csv(\"BJladikaSumbmission6.csv\", index = False)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureNames = df_train.columns[1:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"sampling train to get around 8GB memory limitations\\n\")\ndf_train = df_train.sample(n=20000)\n\n\nprint(\"training a XGBoost classifier\\n\")\ndtrain = xgb.DMatrix(df_train[featureNames].values, label=df_train['target1'].values)\n\nparam = {'max_depth':2, \n         'eta':1, \n         'objective':'binary:logistic', \n         'eval_metric': 'auc'}\nclf = xgb.train(param, dtrain, 20)\n\n\nprint(\"making predictions in batches due to 8GB memory limitation\\n\")\nsubmission = df_test[['ID']]\nsubmission['target1'] = np.nan\nstep = len(submission)/10000\nfor rows in range(0, len(submission), int(step)):\n    submission.loc[rows:rows+step, \"target\"] = clf.predict(xgb.DMatrix(df_test.loc[rows:rows+step, featureNames].values))\n\n\nprint(\"saving the submission file\\n\")\nsubmission.to_csv(\"xgboost_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}