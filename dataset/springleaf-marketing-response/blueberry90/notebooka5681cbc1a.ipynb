{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Librerías"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import export_graphviz\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recolectar data"},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv('D:/Cursos Data Science/Kaggle/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test  = pd.read_csv(\"D:/Cursos Data Science/Kaggle/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Limpieza y descripción de la data"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.dtypes.to_csv('D:/Cursos Data Science/Kaggle/variables_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"variables_mixtas = (8,9,10,11,12,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,38,39,40,41,42,43,44,58,59,60,61,62,63,66,67,68,69,70,71,72,73,75,76,77,\n78,79,80,83,84,114,156,157,158,159,166,167,168,169,176,177,178,179,188,189,190,191,196,202,204,207,213,214,216,217,222,225,228,229,231,235,238,239,\n244,266,283,305,404,427,428,454,466,467,493,840)\nprint(len(variables_mixtas))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Recolección de variables mixtas\ncols = []\nvariables_mixtas_cols = []\nfor i in range(1,1935):\n    if i not in variables_mixtas:\n        cols.append(i)\n    else:\n        variables_mixtas_cols.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lista de variables mixtas\ncols.sort()\nvariables_mixtas_cols.sort()\ncols = [str(n).zfill(4) for n in cols]\ncols = ['VAR_' + n for n in cols] \ncols.append('target')\ncols.insert(0,'ID')\n\nvariables_mixtas_cols = [str(n).zfill(4) for n in variables_mixtas_cols]\nvariables_mixtas_cols = ['VAR_' + n for n in variables_mixtas_cols] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Eliminar variables mixtas en la data train\ntrain.drop(variables_mixtas_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Eliminar variables mixtas en la data test\ntest.drop(variables_mixtas_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Verificar el porcentaje de nulos por variable\ncolumnas_nulas = train.isnull().sum()/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"columnas_nulas.to_csv('D:/Cursos Data Science/Kaggle/null_values.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Elimino los que tienen el valor de nulo superior al 50% del total de datos para la data train\ntrain.drop(['VAR_0074','VAR_0205','VAR_0206','VAR_0208','VAR_0209','VAR_0210','VAR_0211','VAR_0226', 'VAR_0230', 'VAR_0232', 'VAR_0236'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Elimino los que tienen el valor de nulo superior al 50% del total de datos para la data test\ntest.drop(['VAR_0074','VAR_0205','VAR_0206','VAR_0208','VAR_0209','VAR_0210','VAR_0211','VAR_0226', 'VAR_0230', 'VAR_0232', 'VAR_0236'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Variables que tengo para modelar\nfeatures = list(train.columns)\ntrain_copia = train\n# features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#características numéricas\nfeatures_num = list(train.describe())\n# features_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#características categóricas\nfeatures_cat = list(train_copia[features].drop(features_num, axis=1).columns)\nfeatures_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Ploteamos el comportamiento de las variables categóricas para ver qué aportan\n#     var = train.groupby(feature)[feature].count().sort_values(ascending = False)\n#     fig = plt.figure()\n#     ax1 = fig.add_subplot(1,1,1)\n#     ax1.set_xlabel(feature)\n#     ax1.set_ylabel('Cantidad')\n#     ax1.set_title(feature)\n#     var.plot(kind='bar')\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Definimos una función para convertir un dataframe de valores categóricos a números\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ndef conversion(dataframe):\n    for col in dataframe:\n        nans = dataframe[col].isnull().sum()\n        \n        if not np.isreal(dataframe[col][0]):\n            if nans > 0:\n                dataframe[col] = dataframe[col].fillna('Void')            \n            dataframe[col] = dataframe[col].astype(str)    \n            le.fit(dataframe[col])\n            dataframe[col] = le.transform(dataframe[col])\n        else:\n            if nans > 0:\n                dataframe[col] = dataframe[col].fillna(0)\n    \n    return dataframe    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = conversion(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test = conversion(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Vemos la cantidad de ceros como target\nno = train[train['target'] == 0]\nno.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Vemos la cantidad de unos como target\nsi = train[train['target'] == 1]\nsi.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(len(no))\nprint(len(si))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Nos damos cuenta que la proporción es de 3.3 a 1\nprint(round(len(no)/len(train),4))\nprint(round(len(si)/len(train),4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# En lugar de usar el undersampling que más abajo detallo, utilizo solo una muestra de 38000 por temas de costo computacional\nno_sub_muestra = no.sample(n=38000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(len(no_sub_muestra))\nprint(len(si))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Creo un dataframe nuevo que es la unión de la muestra de 38k ceros y todos los unos con los que contaba\ntrain_2 = pd.concat([no_sub_muestra, si], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(train_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"select = [x for x in train_2.columns if x != 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = train_2.loc[:, select]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = train_2['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Verifico que ambos cuenten con la misma cantidad de datos\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data train y test"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lo óptimo es usar un modelo con cross validation, pero por un tema de costo computacional no lo he usado. De igual forma lo detallo en cada modelo utilizado.\nfrom sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.70, random_state=999)\nprint(len(X_train), len(y_train), len(X_test), len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = X\ny_train = y\nlen(X), len(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Undersampling"},{"metadata":{},"cell_type":"markdown","source":"#### Atención: Comento el undersampling porque mi pc se cuelga por la cantidad de variables y filas que tiene la data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# import random\n# def UnderSampling(X, y, target_percentage, seed):\n#     # Assuming minority class is the positive\n#     n_samples = y.shape[0]\n#     n_samples_0 = (y == 0).sum()\n#     n_samples_1 = (y == 1).sum()\n\n#     n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n#     n_samples_0_new_per = n_samples_0_new / n_samples_0\n\n#     filter_ = y == 0\n\n#     np.random.seed(seed)\n#     rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n    \n#     filter_ = filter_ & rand_1\n#     filter_ = filter_ | (y == 1)\n#     filter_ = filter_.astype(bool)\n    \n#     return X[filter_], y[filter_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from time import time\n# time_star = time()\n\n# X_u, y_u = UnderSampling(X_train, y_train, 0.45, 103)\n\n# time_end = time()\n# print (\"Time: \", np.round((time_end-time_star)/60,2), \" minutes\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# X_u.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# y_u.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomForestClassifier"},{"metadata":{},"cell_type":"markdown","source":"#### Atención: El objetivo determinar las variables más importantes para el modelo. Con esto podemos reducir el número de variables a enfrentar"},{"metadata":{"trusted":false},"cell_type":"code","source":"seeds = np.arange(0,501,50)\nseeds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from time import time\ntime_star = time()\n\ntemp = pd.DataFrame({'atributo':list(X.columns)})\nfrom sklearn.ensemble import RandomForestClassifier\nfor seed in seeds:\n    clf = RandomForestClassifier(random_state=seed)\n    clf = clf.fit(X, y)\n    semilla = 'semilla_' + str(seed)\n    temp[semilla]=clf.feature_importances_\ntemp['importancia'] = temp.iloc[:,1:].apply(np.mean, axis=1)\n\ntime_end = time()\nprint (\"Time: \", np.round((time_end-time_star)/60,2), \" minutes\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ranking_features = temp[['atributo','importancia']].sort_values('importancia', ascending = False).reset_index(drop = True)\nranking_features.head(250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"variables_elegidas = ranking_features.iloc[:, 0].head(250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X[variables_elegidas].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Construcción del modelo"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = X[variables_elegidas]\nX_test = X_test[variables_elegidas]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regresión Logística"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mean_accuracy_scores = []\nclf = logreg.fit(X_train, y_train)\nscores = cross_val_score(clf, X_train, y_train, cv=10)\nmean_accuracy_scores.append(np.mean(scores))\nprint (mean_accuracy_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = logreg.predict(X_test)\ncm = metrics.confusion_matrix(y_test, y_pred)\naccuracy = metrics.accuracy_score(y_test, y_pred)\nroc_auc = metrics.roc_auc_score(y_test, y_pred)\nprint(cm)\nprint(\"accuracy = \" + str(accuracy))\nprint(\"roc_auc = \" + str(roc_auc))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":false},"cell_type":"code","source":"from numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# # Entrenar la data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\nprint(model)\n\n# Atención: comento el método con cross validation porque el costo computacional es muy alto.\n\n# model = XGBClassifier()\n# kfold = KFold(n_splits=10, random_state=7)\n# results = cross_val_score(model, X_train, y_train, cv=kfold)\n# print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predicciones sobre la data de test\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Evaluamos la predicción\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def metricas(objetivo, prediccion):\n    matriz_conf = confusion_matrix(objetivo, prediccion)\n    score = accuracy_score(objetivo, prediccion)\n    reporte = classification_report(objetivo, prediccion)\n    metricas = [matriz_conf, score, reporte]\n    return(metricas)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"metricas = metricas(y_test, predictions)\n[print(i) for i in metricas]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nimport sklearn.metrics\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n\n# Predicción del conjunto de prueba\ny_pred = classifier.predict(X_test)\n\n# Matriz de confusion\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\naccuracy = metrics.accuracy_score(y_test, y_pred)\nroc_auc = metrics.roc_auc_score(y_test, y_pred)\nprint(cm)\nprint(\"accuracy = \" + str(accuracy))\nprint(\"roc_auc = \" + str(roc_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM with cross-validation"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Como demora demasiado el SVM con cross-validation, he comentado el modelo con validación cruzada y he dejado este simple.\nfrom sklearn.svm import SVC\nclf = SVC(kernel='linear').fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint (\"Accuracy on testing set:\")\nprint (clf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Modelo SVM con cross-validation que demora mucho por el coste máquina\n\n# from sklearn.svm import SVC\n# mean_accuracy_scores = []\n# clf = SVC(kernel='linear').fit(X_train, y_train)\n# scores = cross_val_score(clf, X_train, y_train, cv=10)\n# mean_accuracy_scores.append(np.mean(scores))\n# print (mean_accuracy_scores)\n# y_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicción"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_2 = test.sample(n=38000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(test_2.shape)\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test_real = test_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(X_test_real.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = model.predict(X_test_real)\npredictions = [round(value) for value in y_pred]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"resultados = X_test_real","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"resultados['predictions'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"resultados.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"resultados.to_csv('D:/Cursos Data Science/Kaggle/resultado_data_test.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}