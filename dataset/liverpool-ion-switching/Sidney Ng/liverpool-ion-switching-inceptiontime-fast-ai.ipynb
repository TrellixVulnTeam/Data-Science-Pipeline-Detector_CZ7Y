{"cells":[{"metadata":{},"cell_type":"markdown","source":"# InceptionTime model based on paper --> https://arxiv.org/abs/1909.04939\n\n# implement model using fast.ai\n"},{"metadata":{"id":"UNEOjO9xlV2y"},"cell_type":"markdown","source":"# Build 3 models for 3ch, 5ch & 10ch\n\n# add OverSampling due to Class imbalance"},{"metadata":{"id":"wIz06osDvHeo","outputId":"fe7e7927-80a7-4c7a-d6ca-c689e7272d23","trusted":true},"cell_type":"code","source":"! pip install pyunpack PyWavelets pyts fire nvidia-ml-py3","execution_count":null,"outputs":[]},{"metadata":{"id":"bcaX5IVpynhS","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# fast.ai implementation of InceptionTime"},{"metadata":{"id":"hDemNSejO60x","outputId":"32c3bef1-11e2-4aa0-d20e-5426e48163b0","trusted":true},"cell_type":"code","source":"! git clone https://github.com/timeseriesAI/timeseriesAI1  ","execution_count":null,"outputs":[]},{"metadata":{"id":"E3B-MGpRO_D3","trusted":true},"cell_type":"code","source":"! ln -s timeseriesAI1/fastai_timeseries .\n! ln -s timeseriesAI1/torchtimeseries .","execution_count":null,"outputs":[]},{"metadata":{"id":"zDe0zLh7yscp","outputId":"2dbce7c9-5a8b-490b-8e03-425ba915e33a","trusted":true},"cell_type":"code","source":"import fastai, os\nfrom fastai_timeseries import *\nfrom torchtimeseries.models import *\nfrom fastai.callbacks import *\nimport random\n\npath = Path('/kaggle/input/data-without-drift')\n\nprint('fastai :', fastai.__version__)\nprint('torch  :', torch.__version__)\nprint('device :', device)","execution_count":null,"outputs":[]},{"metadata":{"id":"mmaWray65sRR","trusted":true},"cell_type":"code","source":"#plotting fn from https://www.kaggle.com/miklgr500/ghost-drift-and-outliers\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use('dark_background')","execution_count":null,"outputs":[]},{"metadata":{"id":"GbzZb-YU58T4","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/miklgr500/ghost-drift-and-outliers\n\ndef plot_open_channels_signal(df: pd.DataFrame, vline=[]):\n    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n    \n    ax.plot(df.signal, df.open_channels, '.', color='fuchsia', alpha=0.25)\n    for x in vline:\n        ax.axvline(x, alpha=0.75, color='tomato')\n    ax.set_xlabel('Signal')\n    ax.set_ylabel('Open Channels')\n    plt.show()\n    \n    \ndef plot_data(df: pd.DataFrame):\n    if 'open_channels' in df.columns:\n        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 16))\n    \n        ax2.plot(df.time, df.open_channels, color='royalblue', alpha=0.75)\n        ax2.set_xlabel('time')\n        ax2.set_ylabel('Open Channels')\n    else:\n        fig, ax1 = plt.subplots(1, 1, figsize=(24, 8))\n    \n    ax1.plot(df.time, df.signal, color='royalblue', alpha=0.75)\n    ax1.set_xlabel('time')\n    ax1.set_ylabel('Signal')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa7b6857-a125-4f44-9670-f0a45d472102","_uuid":"fef6f081e475b8c0943257ce834991f40de19152","id":"7_HYgauzHUUQ","trusted":true},"cell_type":"code","source":"file_tr = 'train_clean.csv'\nfile_tst = 'test_clean.csv'\n\ndf_train_all=pd.read_csv(path/file_tr,  ) \ndf_test_all=pd.read_csv(path/file_tst,  )\n#df_valid=pd.read_csv(path/file_val,  )","execution_count":null,"outputs":[]},{"metadata":{"id":"2wKsE1RaqPL6","trusted":true},"cell_type":"code","source":"def remove_bad_signal(data):\n    # https://www.kaggle.com/hirayukis/lightgbm-keras-and-4-kfold?scriptVersionId=32154310\n    # read data\n    #data = pd.read_csv('../input/data-without-drift/train_clean.csv')\n    data.iloc[478587:478588, [1]] = -2  #reset spike siugnals x2\n    data.iloc[478609:478610, [1]] = -2\n    data_ = data[3500000:3642922].append(data[3822754:4000000])  # cut off error signal from DF\n    data = data[:3500000].append(data[4000000:]).reset_index().append(data_, ignore_index=True)\n    return data\n    #data.head()\n    #data[[\"signal\", \"open_channels\"]].plot(figsize=(19,5), alpha=0.7)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"k7UBhIRO6nR3","outputId":"235f6b1f-122a-48e1-f8cd-15cd5cc5d175","trusted":true},"cell_type":"code","source":"plot_data(df_train_all)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZkCsUpqK6oMO","outputId":"affec19a-8edf-4cdb-c63a-dcd9dfefa52f","trusted":true},"cell_type":"code","source":"plot_data(df_test_all)","execution_count":null,"outputs":[]},{"metadata":{"id":"PTtCeWzDu7cG","trusted":true},"cell_type":"code","source":"#500k samples per group\ngp_size = 500_000\n\nfor df in [df_train_all, df_test_all]:\n  batches = df.shape[0] // gp_size\n  df['batch'] = 0\n  for i in range(batches):\n        idx = np.arange(i*gp_size, (i+1)*gp_size)\n        df.loc[idx, 'batch'] = i ","execution_count":null,"outputs":[]},{"metadata":{"id":"misiW49BEYy-","trusted":true},"cell_type":"code","source":"df_train_all = remove_bad_signal(df_train_all)  #remove bad signals from set 0 & 7","execution_count":null,"outputs":[]},{"metadata":{"id":"8FLCpG_NEZ70","outputId":"f69d74cc-b9cb-4b39-8950-b72904007477","trusted":true},"cell_type":"code","source":"plot_data(df_train_all)","execution_count":null,"outputs":[]},{"metadata":{"id":"m0wViq0h6Yae"},"cell_type":"markdown","source":"# Create DataBunch : select batches to train, validate"},{"metadata":{"id":"RZCPKB2d3mUq","trusted":true},"cell_type":"code","source":"def get_db(train_list, valid_list, test_list,  scale_type, bs=1024):\n\n  # selecting rows based on condition \n  df_train = df_train_all.loc[df_train_all['batch'].isin(train_list)] \n  df_valid = df_train_all.loc[df_train_all['batch'].isin(valid_list)] \n\n  df_test = df_test_all.loc[df_test_all['batch'].isin(test_list)]\n\n  # split_by_df\n  df_train['is_valid']=False\n  df_valid['is_valid']=True\n  df_combine = pd.concat([df_train, df_valid], axis=0, sort=False)\n\n  offset = random.randint(0, 20000)\n  train_size=df_train.shape[0]\n  valid_size=df_valid.shape[0]\n  test_size=df_test.shape[0]\n  train_idx = 0  #offset + train_size\n  valid_idx = 0  #valid_size + train_idx\n  test_idx = 0  #test_size + valid_idx\n  print ('training set= ',train_size, 'train index=', train_idx)\n  print ('valid set= ',valid_size, 'valid index=', valid_idx)\n  print('test set =', test_size, 'test index=', test_idx)\n  print ('total length', test_size+train_size+valid_size)\n  print ('Dataset= ', df_train.shape[0] )\n\n  bs = bs                           # ✳️ orig 1024\n  #seed = 8888                        # ✳️\n  scale_type = scale_type          # ✳️ \n  scale_by_channel = True            # ✳️ \n  scale_by_sample  = False           # ✳️ \n  scale_range = (-1, 1)              # ✳️ \n\n  db = (TimeSeriesList.from_df(df_combine, '.', cols=[\"signal\"],)  # feat='feat')\n      #.split_by_idx(list(range(train_size, train_size+valid_size)) )\n      .split_from_df(col='is_valid')\n      .label_from_df(cols='open_channels', label_cls=CategoryList)\n      .add_test(TimeSeriesList.from_df(df_test, '.', cols=[\"signal\"]) )\n      .databunch(bs=bs,  val_bs=bs,  num_workers=cpus,  device=device)\n      .scale(scale_type=scale_type, scale_by_channel=scale_by_channel, \n             scale_by_sample=scale_by_sample,scale_range=scale_range)\n     )\n  return db, df_test","execution_count":null,"outputs":[]},{"metadata":{"id":"fc35wpGcMbrS"},"cell_type":"markdown","source":"# Main function"},{"metadata":{"id":"b4noGQlsYhz6","trusted":true},"cell_type":"code","source":"def main(\n        epochs: 10,\n        bs:    1024,\n        runs:  1, \n        train_list: [],\n        valid_list: [],\n        test_list: [],\n        scale_type: 'normalize', \n        ):\n\n\n    global df_result, learn\n\n    bs = bs                           # ✳️ orig 1024\n    scale_type = scale_type          # ✳️ \n\n    \n    # ResCNN, FCN, InceptionTime, ResNet\n    arch = InceptionTime                     # ✳️   \n    arch_kwargs = dict()           # \n   \n    \n    db, df_result = get_db(train_list, valid_list, test_list, scale_type, bs)\n    print('# class= ', db.c, 'features= ', db.features)\n\n    epochs = epochs         # ✳️ orig 100\n    max_lr = 1e-2        # ✳️ orig 1e-2\n    warmup = True       # ✳️ orig False\n    pct_start = .7       # ✳️\n    metrics = [accuracy] # ✳️\n    wd = 1e-2\n\n    \n    for run in range(runs):\n        print(f'Run: {run}')\n        model = arch(db.features, db.c, **arch_kwargs).to(device)\n        learn = Learner(db, model, opt_func=Ranger)\n\n        learn.metrics = metrics\n        learn.fit_fc(epochs, max_lr,  callbacks=[OverSamplingCallback(learn), SaveModelCallback(learn, monitor='accuracy')] ) \n\n        preds, tgt = learn.get_preds(ds_type=DatasetType.Test) # ds_type=DatasetType.Valid\n        test_preds = preds.argmax(-1).view(-1).numpy()\n        df_result[f'Run_{run}'] = test_preds\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"KnyqPUwRbqTn","outputId":"e6435af3-0f27-46d0-bac3-2b29c4b01ae6","trusted":true},"cell_type":"code","source":"#trg set 0 & 7 have spikes\n# 10 channel model\nruns = 1\nepochs = 3\n\nkwargs = ( {'epochs': epochs, 'bs': 1024, 'runs': runs, 'train_list': [4], 'valid_list': [9], 'test_list': [1], 'scale_type': 'normalize' })  # 10 chan\nmain(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"id":"uELwWXovBrrM","outputId":"212a24ca-ffac-4aa1-9655-ae9bcb524b8b","trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(10,10), dpi=60)","execution_count":null,"outputs":[]},{"metadata":{"id":"sIoO4pjdPTLL","trusted":true},"cell_type":"code","source":"df_mod1 = df_result.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"ftxNWx-fy2ol","outputId":"31b3a306-f4bc-4d25-8622-066dffb24663","trusted":true},"cell_type":"code","source":"#trg set 0 & 7 have spikes\n#5 channel model\n\nkwargs = ( {'epochs': epochs, 'bs': 1024, 'runs': runs, 'train_list': [5], 'valid_list': [8], 'test_list': [0], 'scale_type': 'normalize' })  #up to 5 chan\nmain(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"id":"v8mmlLFvBo-Y","outputId":"55b06b5c-e9a9-404d-da6d-cbb34ac1a05d","trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(10,10), dpi=60)","execution_count":null,"outputs":[]},{"metadata":{"id":"ALOrzMGip16K","trusted":true},"cell_type":"code","source":"df_mod2 = df_result.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"HYXQnQV2CnZc","outputId":"7655ac4b-2373-4f5f-d098-f43acff50ba7","trusted":true},"cell_type":"code","source":"#trg set 0 & 7 have spikes\n#3 channel model\n\nkwargs = ( {'epochs': epochs, 'bs': 1024, 'runs': runs, 'train_list': [3], 'valid_list': [7], 'test_list': [2,3], 'scale_type': 'normalize' })  \nmain(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"id":"uSJcs31-Cr2z","outputId":"414f008e-e5d7-4b3c-a7d6-83fc25f5a1c2","trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(10,10), dpi=60)","execution_count":null,"outputs":[]},{"metadata":{"id":"YGlFzgfPDAWC","trusted":true},"cell_type":"code","source":"df_mod3 = df_result.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"bmc54oMJqGrY","trusted":true},"cell_type":"code","source":"df_model = pd.concat([df_mod1, df_mod2, df_mod3], axis=0).sort_values(['time'])","execution_count":null,"outputs":[]},{"metadata":{"id":"8mbyJ3i6Go-Y","trusted":true},"cell_type":"code","source":"if runs == 1 :\n  df_vote = df_model[['Run_0']]\nelif runs == 3 :\n  df_vote = df_model[['Run_0', 'Run_1', 'Run_2']]\nelif runs == 5 :  \n  df_vote = df_model[['Run_0', 'Run_1', 'Run_2', 'Run_3', 'Run_4']]\nelse :\n  print (\"Error ! runs INCORRECT ! \", runs)\n  ","execution_count":null,"outputs":[]},{"metadata":{"id":"9fibZOKLGsyw","trusted":true},"cell_type":"code","source":"#use numba to run mode 4x faster !!\nimport numba\nfrom numba import jit\nfrom scipy import stats\n\n# numba likes loop, np array & broadcasting\n\n@jit\ndef mode_numba(df):  \n    x = df.to_numpy()\n    a = np.zeros(shape=x.shape[0])\n    for i in range(x.shape[0]):\n      a[i] = np.asscalar(stats.mode(x[i, :])[0] ) # index 0 gives class, index 1 gives freq\n    \n    return a.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"id":"gts9hLbOHHCQ","trusted":true},"cell_type":"code","source":"if runs == 1:\n  df_model['vote'] = df_model['Run_0']\nelse :\n  df_model['vote'] = mode_numba(df_vote) ","execution_count":null,"outputs":[]},{"metadata":{"id":"FzGXfS0X_ycu","outputId":"2d9cdbe3-2f80-4311-b772-a42d852fafb8","trusted":true},"cell_type":"code","source":"df_model[df_model['batch']==1]","execution_count":null,"outputs":[]},{"metadata":{"id":"9lvPUYFtOaw2","trusted":true},"cell_type":"code","source":"path2 = Path('/kaggle/input/liverpool-ion-switching')\ndf_subm = pd.read_csv(path2/\"sample_submission.csv\")\ndf_subm['open_channels'] = df_model.vote.values\ndf_subm.to_csv(\"submissions.csv\", float_format='%.4f', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"sF7SUUMpPrKm","outputId":"747289e2-14e9-4f9f-c94a-930b00d8a63a","trusted":true},"cell_type":"code","source":"df_model.vote.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_subm","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"K_liverpool_ion_channel_Main-3_models.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}