{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Intro"},{"metadata":{},"cell_type":"markdown","source":"When I first time saw public notebooks I reaslized that there are two main options: use feature engineering and than train boosting or train 1D CNN. \n\nAnd even now there is no \"new hacks\". \nBut I thought: \"Hmm, interesting, what if I train pure MLP without FE, how low would be the final score?\"\n\nSo welcome to this kernel with MLP on pytorch, without feature encoding, solving \"classification task\"!"},{"metadata":{},"cell_type":"markdown","source":"# All necessary imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn import functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score\nimport tqdm\nimport sys\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nfrom IPython.display import clear_output\nimport itertools\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set reproducibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(3246)\nnp.random.seed(3246)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"submisson = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv')\ntest_df = pd.read_csv('/kaggle/input/liverpool-ion-switching/test.csv')\ndf = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')\n\n#df = df.head(1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standartize train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['time'] = (df['time'] - df['time'].mean()) / (df['time'].max() - df['time'].min())\ndf['signal'] = (df['signal'] - df['signal'].mean()) / (df['signal'].max() - df['signal'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standartize test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['time'] = (test_df['time'] - test_df['time'].mean()) / (test_df['time'].max() - test_df['time'].min())\ntest_df['signal'] = (test_df['signal'] - test_df['signal'].mean()) / (test_df['signal'].max() - test_df['signal'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look on imported data"},{"metadata":{"trusted":true},"cell_type":"code","source":"submisson.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one_hot = pd.get_dummies(df['open_channels'])\n#df = df.drop('open_channels',axis = 1)\n#df = df.join(one_hot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FE"},{"metadata":{},"cell_type":"markdown","source":"# EDA (in progress)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ROW_PER_BATCH = 500000\ndf_for_eda = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_for_eda['batch'] = 0\n\nfor i in range(0, df_for_eda.shape[0]//ROW_PER_BATCH):\n    df_for_eda.iloc[i * ROW_PER_BATCH: (i+1) * ROW_PER_BATCH,3] = i","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"class oversampTrainData(Dataset):\n    def __init__(self, data):\n            self.data = torch.FloatTensor(data.values.astype('float'))\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n            target = self.data[index][-1:]\n            data_val = self.data[index][:-1]\n            #list_target = list(0 for i in range(11)) \n            #list_target[int(target.item())] = 1\n            #print(data_val)\n            #print(target)\n            return data_val, target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class oversampTestData(Dataset):\n    def __init__(self, data):\n            self.data = torch.FloatTensor(data.values.astype('float'))\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n            data_val = self.data[index]\n            return data_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_Batch_Size = 128\nTest_Batch_Size = 128\n\ntrain_dataset = oversampTrainData(df)\ntest_dataset = oversampTestData(test_df)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nkwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\ntrain_loader = DataLoader(train_dataset, batch_size=Train_Batch_Size, shuffle=True, **kwargs)\ntest_loader = DataLoader(test_dataset, batch_size=Test_Batch_Size, shuffle=False, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LinearModel(nn.Module):\n    def __init__(self):\n        super(LinearModel, self).__init__()\n        self.fc1 = nn.Linear(2, 1000)\n        self.fc2 = nn.Linear(1000, 1000)\n        self.fc3 = nn.Linear(1000, 1000)\n        self.fc4 = nn.Linear(1000, 1000)\n        self.fc5 = nn.Linear(1000, 1000)\n        self.fc6 = nn.Linear(1000, 1000)\n        self.fc7 = nn.Linear(1000, 1000)\n        self.fc8 = nn.Linear(1000, 500)\n        self.fc9 = nn.Linear(500, 500)\n        self.fc10 = nn.Linear(500, 100)\n        self.fc11 = nn.Linear(100, 11)\n        \n        \n    def forward(self,x):\n        out = self.fc1(x)\n        out = F.relu(out)\n        \n        out = self.fc2(out)\n        out = F.relu(out)\n        \n        out = self.fc3(out)\n        out = F.relu(out)\n        \n        out = self.fc4(out)\n        out = F.relu(out)\n        \n        out = self.fc5(out)\n        out = F.relu(out)\n        \n        out = self.fc6(out)\n        out = F.relu(out)\n        \n        out = self.fc7(out)\n        out = F.relu(out)\n        \n        out = self.fc8(out)\n        out = F.relu(out)\n        \n        out = self.fc9(out)\n        out = F.relu(out)\n        \n        out = self.fc10(out)\n        out = F.relu(out)\n        \n        out = self.fc11(out)\n        #out = torch.softmax(out, dim=0)\n        \n\n        return out\n    \nmodel = LinearModel()\n\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n\tmodel = model.cuda()\n\tprint ('USE GPU')\nelse:\n\tprint ('USE CPU')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\nscheduler = ReduceLROnPlateau(optimizer, 'max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMBER_OF_EPOCHS = 5\nf1_score_history = []\nloss_history = []\n\nfor epoch in range(NUMBER_OF_EPOCHS): \n    epoch_loss = 0\n    f1_score_val = -1\n    \n    \n    model.train()\n    \n    for i in tqdm.tqdm(train_loader, position=0):\n        data, target = i\n        data, target = data.to(device), target.to(device)\n        \n        target_pred = model(data)\n        \n        target = target.squeeze()\n        target = target.type(torch.LongTensor).to(device)\n        \n        loss = criterion(target_pred, target)\n        epoch_loss += loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    model.eval()\n    \n    pure_target_for_f1_score = []\n    pred_target_for_f1_score = []\n    \n    for i in tqdm.tqdm(train_loader, position=0):\n        data, target = i\n        data, target = data.to(device), target.to(device)\n        \n        target_pred = model(data)\n        \n        target = target.squeeze()\n        target = target.type(torch.LongTensor).to(device)\n        \n        #print('target', target.cpu().data.numpy().astype(int))\n        #print('preds', np.argmax(target_pred.cpu().data.numpy(), axis=1))\n        \n        pure_target_for_f1_score += list(target.cpu().data.numpy().astype(int))\n        pred_target_for_f1_score += list(np.argmax(target_pred.cpu().data.numpy(), axis=1))\n    \n    \n    clear_output(wait=True)\n    \n    f1_score_val = f1_score(pure_target_for_f1_score, pred_target_for_f1_score, zero_division=1, average='macro')\n    scheduler.step(f1_score_val)\n    \n    f1_score_history.append(f1_score_val)\n    loss_history.append(epoch_loss/len(train_loader))\n    \n    plt.plot(loss_history)\n    plt.plot(f1_score_history)\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(loss_history, 'ko-')\n    plt.xlabel('epoch')\n    plt.ylabel('LOSS')\n    \n\n    plt.subplot(1, 2, 2)\n    plt.plot(f1_score_history, 'r.-')\n    plt.xlabel('epoch')\n    plt.ylabel('F1')\n    \n    plt.tight_layout()\n    plt.pause(0.1)\n        \n    print('epoch: ', epoch,' loss: ', epoch_loss/len(train_loader), ' F1 score: ', f1_score_val, ' learning rate: ', get_lr(optimizer))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_for_subm = []\nfor data in tqdm.tqdm(test_loader, position=0):\n        data = data.to(device)\n        target_pred = model(data)\n        \n        preds_for_subm += list(np.argmax(target_pred.cpu().data.numpy(), axis=1))\n        #print('preds', list(itertools.chain(*target_pred.cpu().data.numpy().astype(int))))\n        \n#print(preds_for_subm[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submisson['open_channels'] = preds_for_subm\nsubmisson['time'] = submisson['time'].astype(float)\nsubmisson.to_csv('our_submission1.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}