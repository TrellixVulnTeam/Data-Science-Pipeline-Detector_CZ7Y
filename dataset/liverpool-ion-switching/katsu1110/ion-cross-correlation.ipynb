{"cells":[{"metadata":{},"cell_type":"markdown","source":"Although the signal data are separated by a batch whose size is 500,000, we cannot be sure if the signal is similar within the batch and distinctively different across the batch. One naive way to see this is **auto- correlation**, which is helpful finding a repeated pattern.\n\nThe data are from [Data Without Drift with Kalman filter](https://www.kaggle.com/michaln/data-without-drift-with-kalman-filter)."},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom matplotlib_venn import venn2\nimport seaborn as sns\nsns.set_context(\"talk\")\n# sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nstyle.use('fivethirtyeight')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/data-without-drift-with-kalman-filter/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/data-without-drift-with-kalman-filter/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_signal = train[\"signal\"].values.reshape(-1,500000)\ntest_signal = test[\"signal\"].values.reshape(-1,500000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Autocorrelation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize=(15, 18), sharey=\"all\")\nax = ax.flatten()\nfor i, a in enumerate(ax):\n    a.acorr(train_signal[i,::1000], usevlines=False, normed=True, maxlags=50, lw=.5, alpha=0.2, color=\"k\");\n    a.set_xlabel(\"lag ($x10^{3}$)\")\n    a.set_title(f\"train batch {i}\")\n    if i % 2 == 0:\n        a.set_ylabel(\"cross correlation\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 2, figsize=(15, 8), sharey=\"all\")\nax = ax.flatten()\nfor i, a in enumerate(ax):\n    a.acorr(test_signal[i,::1000], usevlines=False, normed=True, maxlags=50, lw=.5, alpha=0.2, color=\"k\");\n    a.set_xlabel(\"lag ($x10^{3}$)\")\n    a.set_title(f\"test batch {i}\")\n    if i % 2 == 0:\n        a.set_ylabel(\"cross correlation\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Interesting, the auto-correlation structure is very different across the \"batches\"! We might want to think about how to deal with them rather than just fitting a single model across the \"batches\"."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}