{"cells":[{"metadata":{},"cell_type":"markdown","source":"thanks to https://www.kaggle.com/nxrprime/wavenet-with-shifted-rfc-proba-and-cbr\nthanks to https://www.kaggle.com/keitarokonishi/lgbm-version-wavenet-with-shifted-rfc-proba-and-cb","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# !pip install tensorflow_addons\n# import tensorflow as tf\n# from tensorflow.keras.layers import *\nimport pandas as pd\nimport numpy as np\nimport random\n# from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n# from tensorflow.keras.losses import categorical_crossentropy\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras import backend as K\n# from tensorflow.keras import losses, models, optimizers\n# import tensorflow_addons as tfa\nimport gc\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import f1_score\n\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# configurations and main hyperparammeters\nEPOCHS = 180\nNNBATCHSIZE = 16\nGROUP_BATCH_SIZE = 4000\nSEED = 321\nLR = 0.0015\nSPLITS = 6\n\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndef read_data():\n    train = pd.read_csv('/kaggle/input/data-without-drift/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n    test  = pd.read_csv('/kaggle/input/data-without-drift/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\n    sub  = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv', dtype={'time': np.float32})\n    \n    Y_train_proba = np.load(\"/kaggle/input/ion-shifted-rfc-proba/Y_train_proba.npy\")\n    Y_test_proba = np.load(\"/kaggle/input/ion-shifted-rfc-proba/Y_test_proba.npy\")\n    \n    for i in range(11):\n        train[f\"proba_{i}\"] = Y_train_proba[:, i]\n        test[f\"proba_{i}\"] = Y_test_proba[:, i]\n\n    return train, test, sub\n\n# create batches of 4000 observations\ndef batching(df, batch_size):\n    df['group'] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n    df['group'] = df['group'].astype(np.uint16)\n    return df\n\n# normalize the data (standard scaler). We can also try other scalers for a better score!\ndef normalize(train, test):\n    train_input_mean = train.signal.mean()\n    train_input_sigma = train.signal.std()\n    train['signal'] = (train.signal - train_input_mean) / train_input_sigma\n    test['signal'] = (test.signal - train_input_mean) / train_input_sigma\n    return train, test\n\n# get lead and lags features\ndef lag_with_pct_change(df, windows):\n    for window in windows:    \n        df['signal_shift_pos_' + str(window)] = df.groupby('group')['signal'].shift(window).fillna(0)\n        df['signal_shift_neg_' + str(window)] = df.groupby('group')['signal'].shift(-1 * window).fillna(0)\n    return df\n\n# main module to run feature engineering. Here you may want to try and add other features and check if your score imporves :).\ndef run_feat_engineering(df, batch_size):\n    # create batches\n    df = batching(df, batch_size = batch_size)\n    # create leads and lags (1, 2, 3 making them 6 features)\n    df = lag_with_pct_change(df, [1, 2, 3])\n    # create signal ** 2 (this is the new feature)\n    df['signal_2'] = df['signal'] ** 2\n    return df\n\n# fillna with the mean and select features for training\ndef feature_selection(train, test):\n    features = [col for col in train.columns if col not in ['index', 'group', 'open_channels', 'time']]\n    train = train.replace([np.inf, -np.inf], np.nan)\n    test = test.replace([np.inf, -np.inf], np.nan)\n    for feature in features:\n        feature_mean = pd.concat([train[feature], test[feature]], axis = 0).mean()\n        train[feature] = train[feature].fillna(feature_mean)\n        test[feature] = test[feature].fillna(feature_mean)\n    return train, test, features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test, sample_submission = read_data()\ntrain, test = normalize(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = run_feat_engineering(train, batch_size = GROUP_BATCH_SIZE)\ntest = run_feat_engineering(test, batch_size = GROUP_BATCH_SIZE)\ntrain, test, features = feature_selection(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['signal_rolling_mean_1h'] = train['signal'].rolling(window = 100).mean().fillna(0)\ntest['signal_rolling_mean_1h'] = test['signal'].rolling(window = 100).mean().fillna(0)\n\ntrain['signal_rolling_std_1h'] = train['signal'].rolling(window = 100).std().fillna(0)\ntest['signal_rolling_std_1h'] = test['signal'].rolling(window = 100).std().fillna(0)\n\ntrain['signal_rolling_mean_1t'] = train['signal'].rolling(window = 1000).mean().fillna(0)\ntest['signal_rolling_mean_1t'] = test['signal'].rolling(window = 1000).mean().fillna(0)\n\ntrain['signal_rolling_std_1t'] = train['signal'].rolling(window = 1000).std().fillna(0)\ntest['signal_rolling_std_1t'] = test['signal'].rolling(window = 1000).std().fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## check data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.head()\n# test.head()\n# features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## optuna","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n# import lightgbm as lgb\nimport optuna.integration.lightgbm as lgb\nimport optuna, os, uuid, pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['time', 'open_channels'], axis = 1)\ny = train['open_channels']\nX_test = test.drop(['time'], axis = 1)\nX_train, X_val, y_train, y_val = train_test_split(X, y)\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"num_class\": 11,\n    \"metric\": \"multi_logloss\",\n    \"verbosity\": -1,\n    \"boosting_type\": \"gbdt\",\n#     \"boosting_type\": \"dart\",\n#     \"boosting_type\": \"goss\",\n    'num_boost_round': 3,\n}\n\nbest_params, tuning_history = dict(), list()\nmodel = lgb.train(\n    params,\n    lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n#     verbose_eval=1,\n    verbose_eval=100,\n    early_stopping_rounds=100,\n#     early_stopping_rounds=1,\n    best_params=best_params,\n    tuning_history=tuning_history,\n)\n\nprint(\"Best Params:\", best_params)\nprint(\"Tuning history:\", tuning_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = model.params\nbest_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(best_params, lgb_train, valid_sets=lgb_eval, num_boost_round=3)\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\ny_pred_max = np.argmax(y_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['open_channels'] = y_pred_max\n# sample_submission['open_channels'].value_counts()\n\nsample_submission.to_csv('submission_wavenet_lgbm.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}