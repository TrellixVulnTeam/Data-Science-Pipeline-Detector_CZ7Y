{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"# Import","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import gc\nimport os\nimport random\n\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random seed initialize","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def random_seed_initialize(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"random_seed_initialize()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reduce memory Function","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read CSV data\n<https://www.kaggle.com/cdeotte/data-without-drift>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data = pd.read_csv('../input/data-without-drift/train_clean.csv')\ntest_data  = pd.read_csv('../input/data-without-drift/test_clean.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add Feature","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_index(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_batch_index(df, batch_size1=50_000, batch_size2=5_000):\n    df['batch'] = df.index // batch_size1\n    df['batch_index'] = df.index - (df.batch * batch_size1)\n    df['batch_slices'] = df['batch_index'] // batch_size2\n    df['batch_slices2'] = df.apply(lambda r: '_'.join(\n        [str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_features_batch50000(df):\n    df['signal_batch_min'] = df.groupby('batch')['signal'].transform('min')  # 最小値\n    df['signal_batch_max'] = df.groupby('batch')['signal'].transform('max')  # 最大値\n    df['signal_batch_std'] = df.groupby('batch')['signal'].transform('std')  # 標準偏差\n    df['signal_batch_mean'] = df.groupby('batch')['signal'].transform('mean')  # 平均\n    df['mean_abs_chg_batch'] = df.groupby(['batch'])['signal'].transform(lambda x: np.mean(np.abs(np.diff(x))))  # 前回との差分の平均\n    df['abs_max_batch'] = df.groupby(['batch'])['signal'].transform(lambda x: np.max(np.abs(x)))  # 絶対値の最大値\n    df['abs_min_batch'] =df.groupby(['batch'])['signal'].transform(lambda x: np.min(np.abs(x)))  # 絶対値の最小値\n\n    df['range_batch'] = df['signal_batch_max'] - df['signal_batch_min']  # 最大値と最小値のギャップ\n    df['maxtomin_batch'] = df['signal_batch_max'] / df['signal_batch_min']  # 最大値÷最小値\n    df['abs_avg_batch'] = (df['abs_min_batch'] + df['abs_max_batch']) / 2  # 最大値（絶対値）と最小値（絶対値）の平均\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_features_batch5000(df):\n    df['signal_batch_5k_min'] = df.groupby('batch_slices2')['signal'].transform('min')\n    df['signal_batch_5k_max'] = df.groupby('batch_slices2')['signal'].transform('max')\n    df['signal_batch_5k_std'] = df.groupby('batch_slices2')['signal'].transform('std')\n    df['signal_batch_5k_mean'] = df.groupby('batch_slices2')['signal'].transform('mean')\n    df['mean_abs_chg_batch_5k'] = df.groupby(['batch_slices2'])['signal'].transform(lambda x: np.mean(np.abs(np.diff(x))))\n    df['abs_max_batch_5k'] = df.groupby(['batch_slices2'])['signal'].transform(lambda x: np.max(np.abs(x)))\n    df['abs_min_batch_5k'] = df.groupby(['batch_slices2'])['signal'].transform(lambda x: np.min(np.abs(x)))\n\n    df['range_batch_5k'] = df['signal_batch_5k_max'] - df['signal_batch_5k_min']\n    df['maxtomin_batch_5k'] = df['signal_batch_5k_max'] / df['signal_batch_5k_min']\n    df['abs_avg_batch_5k'] = (df['abs_min_batch_5k'] + df['abs_max_batch_5k']) / 2\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_shift_features(df):\n    df['signal_shift+1'] = df.groupby(['batch']).shift(1)['signal']\n    df['signal_shift-1'] = df.groupby(['batch']).shift(-1)['signal']\n    df['signal_shift+2'] = df.groupby(['batch']).shift(2)['signal']\n    df['signal_shift-2'] = df.groupby(['batch']).shift(-2)['signal']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_difference_features(df, ignore=['open_channels', 'time', 'batch', 'batch_index', 'batch_slices', 'batch_slices2',]):\n    for c in list(set(df.columns) ^ set(ignore)):\n        df[f'{c}_msignal'] = df[c] - df['signal']  \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_gradients_features(df, n_grads=4):\n    for i in range(n_grads):\n        if i == 0:\n            df['grad_' + str(i+1)] = df.groupby(['batch'])['signal'].transform(lambda x: np.gradient(x))\n        else:\n            df['grad_' + str(i+1)] = df.groupby(['batch'])['grad_' + str(i)].transform(lambda x: np.gradient(x))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def set_features(df, is_test=False, memory_reduce=True):\n    print('set_index()')\n    df = set_index(df)\n    print('set_batch_index()')\n    df = set_batch_index(df)\n    print('set_features_batch50000()')\n    df = set_features_batch50000(df)\n    print('set_features_batch5000()')\n    df = set_features_batch5000(df)\n    print('set_lag_features()')\n    df = set_shift_features(df)\n    print('set_gradients_features()')\n    df = set_gradients_features(df)\n    \n    print('set_difference_features()')\n    if not is_test:\n        df = set_difference_features(df, ignore=['open_channels', 'time', 'batch', 'batch_index', 'batch_slices', 'batch_slices2'])\n    else:\n        df = set_difference_features(df, ignore=['time', 'batch', 'batch_index', 'batch_slices', 'batch_slices2'])\n    \n    df = df.fillna(0)\n    \n    if memory_reduce:\n        print('reduce_mem_usage()')\n        df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data = set_features(train_data)\n\npd.set_option('display.max_columns', 200)\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sampling","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"frac = 1.0\ntrain_data = train_data.sample(frac=frac, random_state=42).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PyCaret Setup","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install pycaret","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"IGNORE_FEATURES  = [\n                    'time',\n                    'batch',\n                    'batch_index',\n                    'batch_slices',\n                    'batch_slices2',\n                    'abs_max_batch',\n                    'abs_min_batch',\n                    'abs_avg_batch',\n                    'signal_batch_min_msignal',\n                    'signal_batch_mean_msignal',\n                    'range_batch_5k_msignal'\n                   ]\n\nprint('TARGET FEATURE LIST : ', end=\"\")\nprint([f for f in list(set(IGNORE_FEATURES) ^ set(train_data.columns))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from pycaret.regression import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"exp = setup(data = train_data, \n            target = 'open_channels',\n            silent=True,\n            sampling = False,\n            ignore_features = IGNORE_FEATURES,\n            session_id=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create LGBM model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm_model = create_model('lightgbm', fold=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm_model = finalize_model(lgbm_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"test_data = set_features(test_data, is_test=True)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions = predict_model(lgbm_model, data=test_data)\npredictions['open_channels'] = predictions['Label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub = pd.read_csv(\"../input/liverpool-ion-switching/sample_submission.csv\")\n\nsubmission = pd.DataFrame()\nsubmission['time']  = sub['time']\nsubmission['open_channels'] = predictions['open_channels']\nsubmission['open_channels'] = submission['open_channels'].round(decimals=0)\nsubmission['open_channels'] = submission['open_channels'].astype(int)\nsubmission.to_csv('submission.csv', float_format='%0.4f', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}