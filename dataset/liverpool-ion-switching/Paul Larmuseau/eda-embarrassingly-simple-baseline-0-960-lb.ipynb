{"cells":[{"metadata":{},"cell_type":"markdown","source":"# at first sight an impressive LB\n\nwhat does this mean ?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport math","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/liverpool-ion-switching/test.csv\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_groups = 40\ndf[\"group\"] = 0\nfor i in range(n_groups):\n    ids = np.arange(i*50000, (i+1)*50000)\n    df.loc[ids,\"group\"] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(n_groups):\n    sub = df[df.group == i]\n    signals = sub.signal.values\n    imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n    signals = (signals - np.min(signals))/(np.max(signals) - np.min(signals))\n    signals = signals*(imax-imin) \n    df.loc[sub.index,\"open_channels\"] = [0,] + list(np.array(signals[:-1],np.int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n#distr=df.groupby('open_channels').count() \n\nplt.scatter(df['signal'],df['open_channels'] ,c=df.group)\nplt.show()\nfrom scipy.stats import boxcox\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# not the most convincing solution h√©\n\nthere is simply a remarkable low 'error' mesurement"},{"metadata":{"trusted":true},"cell_type":"code","source":"trdf = pd.read_csv(\"../input/liverpool-ion-switching/train.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_groups = 100\ntrdf[\"group\"] = 0\nfor i in range(n_groups):\n    ids = np.arange(i*50000, (i+1)*50000)\n    trdf.loc[ids,\"group\"] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(n_groups):\n    sub = trdf[trdf.group == i]\n    signals = sub.signal.values\n    imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n    signals = (signals - np.min(signals))/(np.max(signals) - np.min(signals))\n    signals = signals*(imax-imin) \n    trdf.loc[sub.index,\"open_channel2\"] = [0,] + list(np.array(signals[:-1],np.int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(trdf[-500000:]['open_channel2'],trdf[-500000:]['open_channels'] ,c=trdf[-500000:]['group'])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Want to see the relationship ?\n\nindeed: at first sight we simply need to find the bottom/min, find the max and disperse the solution\nand then there seems to me that the true problem is how do you forecast that variability ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(trdf[-500000:]['signal'],trdf[-500000:]['open_channels'] ,c=trdf[-500000:]['group'])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lengte=50000\ntr=trdf[:lengte]\ntr['date']=pd.to_datetime((tr.time*1000000-1.469100e+06)*100, unit='ms')\n\nts = pd.Series(tr.signal.values, index=pd.DatetimeIndex(tr.date).to_period('ms'))\nts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n#Checking trend and autocorrelation\ndef initial_plots(time_series, num_lag):\n\n    #Original timeseries plot\n    plt.figure(1)\n    plt.plot(time_series)\n    plt.title('Original data across time')\n    plt.figure(2)\n    plot_acf(time_series, lags = num_lag)\n    plt.title('Autocorrelation plot')\n    plot_pacf(time_series, lags = num_lag)\n    plt.title('Partial autocorrelation plot')\n    \n    plt.show()\n\n    \n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\n#print('p-value: {}'.format(adfuller('date')[1]))\n\n#plotting\ninitial_plots(ts, 45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining RMSE\ndef rmse(x,y):\n    return sqrt(mean_squared_error(x,y))\n\n#fitting ARIMA model on dataset\ndef SARIMAX_call(time_series,p_list,d_list,q_list,P_list,D_list,Q_list,s_list,test_period):    \n    \n    #Splitting into training and testing\n    training_ts = time_series[:-test_period]\n    \n    testing_ts = time_series[len(time_series)-test_period:]\n    \n    error_table = pd.DataFrame(columns = ['p','d','q','P','D','Q','s','AIC','BIC','RMSE'],\\\n                                                           index = range(len(ns_ar)*len(ns_diff)*len(ns_ma)*len(s_ar)\\\n                                                                         *len(s_diff)*len(s_ma)*len(s_list)))\n    count = 0\n    \n    for p in p_list:\n        for d in d_list:\n            for q in q_list:\n                for P in P_list:\n                    for D in D_list:\n                        for Q in Q_list:\n                            for s in s_list:\n                                #fitting the model\n                                SARIMAX_model = SARIMAX(training_ts.astype(float),\\\n                                                        order=(p,d,q),\\\n                                                        seasonal_order=(P,D,Q,s),\\\n                                                        enforce_invertibility=False)\n                                SARIMAX_model_fit = SARIMAX_model.fit(disp=0)\n                                AIC = np.round(SARIMAX_model_fit.aic,2)\n                                BIC = np.round(SARIMAX_model_fit.bic,2)\n                                predictions = SARIMAX_model_fit.forecast(steps=test_period,typ='levels')\n                                RMSE = rmse(testing_ts.values,predictions.values)                                \n                                print(p,d,q,P,D,Q,AIC,BIC,RMSE)\n                                #populating error table\n                                error_table['p'][count] = p\n                                error_table['d'][count] = d\n                                error_table['q'][count] = q\n                                error_table['P'][count] = P\n                                error_table['D'][count] = D\n                                error_table['Q'][count] = Q\n                                error_table['s'][count] = s\n                                error_table['AIC'][count] = AIC\n                                error_table['BIC'][count] = BIC\n                                error_table['RMSE'][count] = RMSE\n                                \n                                count+=1 #incrementing count        \n    \n    #returning the fitted model and values\n    return error_table\n\nns_ar = [0,1,2]\nns_diff = [1]\nns_ma = [0,1]#,2]\ns_ar = [0,1]\ns_diff = [0,1] \ns_ma = [1,2]\ns_list = [4]\n\nerror_table = SARIMAX_call(ts,ns_ar,ns_diff,ns_ma,s_ar,s_diff,s_ma,s_list,30)\nerror_table.sort_values(by='RMSE').head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nmod = sm.tsa.SARIMAX(ts,order = (0,1,1), seasonal_order=(0,0,1,4)).fit()\nmod.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.plot_diagnostics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv(\"../input/liverpool-ion-switching/sample_submission.csv\", dtype={'time':str})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.open_channels = np.array(df.open_channels, np.int)\nsample_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}