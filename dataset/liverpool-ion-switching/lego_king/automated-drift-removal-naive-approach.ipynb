{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is attempted to remove the drift from the signal\n\n1) First sampling index is generated\n2) The samples are then processed for drift removal from the sampling index\n\n\n#vary relax_rate to get different results(relax_rate=5) is optimal value \nThe points where the drift occurs are noted down and those points are the sampling index.\n\n\n\nPlease do upvote the kernel if you enjoy the approach!!!","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/liverpool-ion-switching/test.csv')\ntrain = pd.read_csv('../input/liverpool-ion-switching/train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_offset(a,b):\n  if (a)>0 and b<0:\n    if b<0-a:\n      offset=b\n    else:\n      offset=0-a\n  elif a>0 and b>0:\n    if b>a:\n      offset=0-b\n    else:\n      offset=0-a\n  elif a<0 and b>0:\n    if b<0-a:\n      offset=b\n    else:\n      offset=0-a\n  elif a<0 and b<0:\n    offset=a+b\n  return offset\n\n\n\ndef get_samples(input_batch,single_batch_size,roll_period):\n  test_drift=input_batch;roll_period=np.int(roll_period)\n  result = seasonal_decompose(input_batch, model='additive',freq=1)\n  trend_rolling=result.trend.rolling(roll_period).mean()\n  trend_rolling=trend_rolling.fillna(trend_rolling.min())\n  c=trend_rolling.values\n  data_without_drift=pd.Series(c-np.array(input_batch))\n  c=pd.Series(c)\n  xx=data_without_drift.rolling(roll_period).mean().min()\n  a=xx-c.min();b=input_batch.mean()\n  return a,b,c,data_without_drift\n\n##################\ndef remove_redundant(sub_index,batch_index,relax_rate=5):\n    sub2=[];\n    #print(\"sub_index:\",sub_index)\n    #print(\"sub2 :\",sub2)\n    for i in range(0,len(sub_index)-1):\n        if sub_index[i+1]-sub_index[i]>relax_rate*num_record_per_sec:\n            sub2.append(sub_index[i])\n    sub_index=sub2;sub2=[]\n    for i in range(0,len(sub_index)):\n        c=0\n        for j in range(len(batch_index)):\n            if abs(sub_index[i]-batch_index[j])<relax_rate*num_record_per_sec:\n                c+=1\n        if c==0:\n            sub2.append(sub_index[i])\n    sub2.extend(batch_index)\n    sub2 = list(dict.fromkeys(sub2))\n    sub2=np.sort(sub2)\n    return list(sub2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_subindex2sample(df,istrain,batch_index,batch_index1,order=2,relax_rate=5):\n  sub_index=[];count=0;\n  while(order!=0):\n    #print(order)\n    for i in range(len(batch_index)-1):\n      train_series=pd.Series(df.iloc[batch_index[i]:batch_index[i+1]].signal);idx=[]\n      a,b,c,data_without_drift_init=get_samples(train_series,batch_index[i+1]-batch_index[i],np.round((num_record_per_sec/single_batch_size)*(batch_index[i+1]-batch_index[i])))\n      offset=get_offset(a,b)\n\n      data_without_drift_init=offset-data_without_drift_init\n      f=data_without_drift_init.rolling(num_record_per_sec).mean()\n      f=f.fillna(f.mean())\n      g=np.array(c)\n      idx = np.argwhere(np.diff(np.sign(f - g))).flatten()\n      if count==0:\n        idx=np.insert(idx,len(idx),single_batch_size);idx=np.insert(idx,0,0)\n      idx=[val+batch_index[i] for val in idx]\n      sub_index.extend(idx)\n    sub_index=remove_redundant(sub_index,batch_index1,relax_rate)\n    #sub_index=np.sort(sub_index)\n    batch_index=sub_index\n    order-=1;count+=1\n  if sub_index[-1]!=df.shape[0]:\n    sub_index[-1]=df.shape[0] \n  if sub_index[0]!=0:\n    sub_index[0]=0 \n  return sub_index\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vary relax_rate to get better results\nsingle_batch_size=500000;num_record_per_sec=10000;relax_rate=5\n\nfor df in [train,test]:\n  num_of_batch=np.int(df.shape[0]/single_batch_size)\n  count=pd.Series()\n  batch_index=[val*single_batch_size for val in range(num_of_batch+1)]\n  sampling_idx= get_subindex2sample(df,True,batch_index,batch_index,order=2,relax_rate=relax_rate)\n  print(sampling_idx[0])\n  sampling_idx=np.sort(sampling_idx)\n  for i in range(len(sampling_idx)-1):\n    train_series=pd.Series(df.iloc[sampling_idx[i]:sampling_idx[i+1]].signal)\n    a,b,c,data_without_drift_init=get_samples(train_series,sampling_idx[i+1]-sampling_idx[i],np.round((num_record_per_sec/single_batch_size)*(sampling_idx[i+1]-sampling_idx[i])))\n    offset=get_offset(a,b)\n    data_without_drift_init=offset-data_without_drift_init\n    count=count.append(data_without_drift_init)\n  count=list(count)\n  print(len(count))\n  df['new_sig']=count\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,8))\n\ntrain.signal.plot(color='r')\ntrain.new_sig.plot()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,8))\n\ntest.signal.plot(color='r')\ntest.new_sig.plot()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.signal>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test.signal<0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}