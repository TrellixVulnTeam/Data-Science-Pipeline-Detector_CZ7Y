{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading the data.. **"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')\nsubmission = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv')\ntest = pd.read_csv('/kaggle/input/liverpool-ion-switching/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitng the data by batches..\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = [train.iloc[500000*i:500000*(i+1), :].reset_index(drop = True) for i in range(10)]\ntest = [test.iloc[500000*i:500000*(i+1), :].reset_index(drop = True) for i in range(4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dr = pd.concat([train[i][['signal']] for i in range(10)]+[test[i][['signal']] for i in range(4)], axis = 1)\n\ndr.columns = ['train_b1', 'train_b2', 'train_b3', 'train_b4', 'train_b5', 'train_b6', 'train_b7', 'train_b8',\n             'train_b9', 'train_b10', 'test_b1', 'test_b2', 'test_b3', 'test_b4']\n\ncorr = dr.corr()\n\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let style it !**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ncmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\ndef magnify():\n    return [dict(selector=\"th\",\n                 props=[(\"font-size\", \"7pt\")]),\n            dict(selector=\"td\",\n                 props=[('padding', \"0em 0em\")]),\n            dict(selector=\"th:hover\",\n                 props=[(\"font-size\", \"12pt\")]),\n            dict(selector=\"tr:hover td:hover\",\n                 props=[('max-width', '200px'),\n                        ('font-size', '12pt')])\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr.style.background_gradient(cmap, axis=1).set_properties(**{'max-width': '100px', 'font-size': '10pt'})\\\n        .set_caption(\"Signal Correlation\").set_precision(2).set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A clear cluster can be seen within train batch 7 to 10\n\n* The first batch of test is midly correlated with train batch 7 to 10.\n* The second batch of test is slightly correlated with train batch 7 to 10.\n* The third batch of test is highly correlated with train batch 7 to 10.\n* The fourth batch of test has no correlation with train batch 7 to 10.\n\n\nOne can use it in modelling. You can provide more weight to train batch 7 to 10 while predicting for test batch 3 and so on."},{"metadata":{},"cell_type":"markdown","source":"**What happens if we see moving average?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_roll = 6\ndef movingaverage(df):\n    df['cummax'] = df['signal'].cummax()\n    df['cummin'] = df['signal'].cummin()\n    \n    for i in range(2,MAX_roll):\n        df['MA_{}'.format(i)] = df['signal'].rolling(window=i).mean()\n    df.fillna(-999, inplace = True)\n    df.reset_index(drop = True, inplace = True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = [movingaverage(x) for x in train]\ntest = [movingaverage(x) for x in test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[2].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let see correlation between Moving Averages:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dr = pd.concat([train[i][['MA_2']] for i in range(10)]+[test[i][['MA_2']] for i in range(4)], axis = 1)\n\ndr.columns = ['train_b1', 'train_b2', 'train_b3', 'train_b4', 'train_b5', 'train_b6', 'train_b7', 'train_b8',\n             'train_b9', 'train_b10', 'test_b1', 'test_b2', 'test_b3', 'test_b4']\n\ncorr = dr.corr()\ncorr.style.background_gradient(cmap, axis=1).set_properties(**{'max-width': '100px', 'font-size': '10pt'})\\\n        .set_caption(\"Signal Moving Average 2 Correlation\").set_precision(2).set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* A Cluster among train batch 1 to 4.\n\n* This group correlates with test batch 4 which was not correlated with any train batch on signals."},{"metadata":{},"cell_type":"markdown","source":"**Moving Average 3 Correlation**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dr = pd.concat([train[i][['MA_3']] for i in range(10)]+[test[i][['MA_3']] for i in range(4)], axis = 1)\n\ndr.columns = ['train_b1', 'train_b2', 'train_b3', 'train_b4', 'train_b5', 'train_b6', 'train_b7', 'train_b8',\n             'train_b9', 'train_b10', 'test_b1', 'test_b2', 'test_b3', 'test_b4']\n\ncorr = dr.corr()\ncorr.style.background_gradient(cmap, axis=1).set_properties(**{'max-width': '100px', 'font-size': '10pt'})\\\n        .set_caption(\"Signal Moving Average 3 Correlation\").set_precision(2).set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dr = pd.concat([train[i][['MA_4']] for i in range(10)]+[test[i][['MA_4']] for i in range(4)], axis = 1)\n\ndr.columns = ['train_b1', 'train_b2', 'train_b3', 'train_b4', 'train_b5', 'train_b6', 'train_b7', 'train_b8',\n             'train_b9', 'train_b10', 'test_b1', 'test_b2', 'test_b3', 'test_b4']\n\ncorr = dr.corr()\ncorr.style.background_gradient(cmap, axis=1).set_properties(**{'max-width': '100px', 'font-size': '10pt'})\\\n        .set_caption(\"Signal Moving Average 4 Correlation\").set_precision(2).set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dr = pd.concat([train[i][['MA_5']] for i in range(10)]+[test[i][['MA_5']] for i in range(4)], axis = 1)\n\ndr.columns = ['train_b1', 'train_b2', 'train_b3', 'train_b4', 'train_b5', 'train_b6', 'train_b7', 'train_b8',\n             'train_b9', 'train_b10', 'test_b1', 'test_b2', 'test_b3', 'test_b4']\n\ncorr = dr.corr()\ncorr.style.background_gradient(cmap, axis=1).set_properties(**{'max-width': '100px', 'font-size': '10pt'})\\\n        .set_caption(\"Signal Moving Average 5 Correlation\").set_precision(2).set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference: These correlation can be used for advance feature engineering and may be seperate modelling excerise for each test batches using different combination of train batches.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}