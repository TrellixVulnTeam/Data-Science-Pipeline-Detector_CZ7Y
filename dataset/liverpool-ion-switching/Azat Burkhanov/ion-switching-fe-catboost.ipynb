{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# IMPORT LIBRARIES \n\nimport pandas as pd\nimport numpy as np\nimport os\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.model_selection import train_test_split\nfrom catboost.utils import eval_metric\nfrom catboost import CatBoostRegressor, Pool\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# LOAD TRAIN AND TEST DATA\n\ndf_train = pd.read_csv(r'/kaggle/input/liverpool-ion-switching/train.csv')\ndf_test = pd.read_csv(r'/kaggle/input/liverpool-ion-switching/test.csv')\ndf_train = reduce_mem_usage(df_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.head(3))\ndf_train.time.min(), df_train.time.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_test.head(3))\ndf_test.time.min(), df_test.time.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAIN AND TEST SIGNAL VISUALIZATION\n\ndf1 = df_train.copy()\ndf2 = df_test.copy()\ndf1['type'] = 'train'\ndf2['type'] = 'test'\ndf = df1\ndf = df.append(df2)\n\ndel df1\ndel df2\n\n\nfig = px.line(df.iloc[::20], x=\"time\", y=\"signal\", color='type')\nfig.show()\ndel df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAIN AND TEST DATA SIGNAL & NUMBER OF OPEN CHANNELS VISUALIZATION\n\n\nsplit_val = 50\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df_train.iloc[::split_val]['time'], y=df_train.iloc[::split_val]['signal'],\n                    mode='lines',\n                    name='train'))\nfig.add_trace(go.Scatter(x=df_test.iloc[::split_val]['time'], y=df_test.iloc[::split_val]['signal'],\n                    mode='lines',\n                    name='test'))\n\nfig.add_trace(go.Scatter(x=df_train.iloc[::split_val]['time'], y=df_train.iloc[::split_val]['open_channels'],\n                    mode='lines',\n                    name='open_channels'))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experimenting with feature engineering "},{"metadata":{},"cell_type":"markdown","source":"thanks for Kernels:<br>\nhttps://www.kaggle.com/vbmokin/ion-switching-advanced-fe-lgb-xgb-confmatrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nwindow_sizes = [10, 50, 100, 250, 500, 1000, 2000, 5000, 10000]\n\n\n\ndef feature_engineering(df_train):\n    for window in window_sizes:\n        df_train['signal_' + \"rolling_mean_\" + str(window)] = df_train['signal'].rolling(window=window).mean()\n        df_train['signal_' + \"rolling_std_\" + str(window)] = df_train['signal'].rolling(window=window).std()\n        df_train['signal_' + \"rolling_var_\" + str(window)] = df_train['signal'].rolling(window=window).var()\n        df_train['signal_' + \"rolling_min_\" + str(window)] = df_train['signal'].rolling(window=window).min()\n        df_train['signal_' + \"rolling_max_\" + str(window)] = df_train['signal'].rolling(window=window).max()\n        df_train['signal_' + \"rolling_median_\" + str(window)] = df_train['signal'].rolling(window=window).median()\n        df_train['signal_' + \"rolling_range_\" + str(window)] = abs(df_train['signal_' + \"rolling_max_\" + str(window)] - df_train['signal_' + \"rolling_min_\" + str(window)])\n        # adding covariance\n        df_train['signal_' + \"rolling_cov_\" + str(window)] = df_train['signal'].rolling(window=window).cov()\n        # adding skewnes - not working\n#         df_train['signal_' + \"rolling_skew_\" + str(window)] = df_train['signal'].rolling(window=window).skew()\n        # adding kurtosis - not working\n#         df_train['signal_' + \"rolling_kurt_\" + str(window)] = df_train['signal'].rolling(window=window).kurt()\n\n        # exponentially weighted parameters\n        df_train['signal_' + \"rolling_EW_mean_\" + str(window)] = df_train['signal'].ewm(span=window).mean()\n        df_train['signal_' + \"rolling_EW_var_\" + str(window)] = df_train['signal'].ewm(span=window).var()\n        df_train['signal_' + \"rolling_EW_std_\" + str(window)] = df_train['signal'].ewm(span=window).std()\n        df_train['signal_' + \"rolling_EW_cov_\" + str(window)] = df_train['signal'].ewm(span=window).cov()    \n        \n        # max2min\n        df_train['signal_' + \"rolling_max2min_\" + str(window)] = abs(df_train['signal_' + \"rolling_max_\" + str(window)] / df_train['signal_' + \"rolling_min_\" + str(window)])\n        # average max_min\n        df_train['signal_' + \"rolling_abs_avg_\" + str(window)] = abs((df_train['signal_' + \"rolling_max_\" + str(window)] + df_train['signal_' + \"rolling_min_\" + str(window)])) / 2\n        \n    # lets add some lag for statistics\n    signal_cols = [x for x in df_train.columns.tolist() if 'signal' in x]\n    \n    # add lags for data\n    df_train['signal' + '_lagged_1minus'] = df_train['signal'].shift(-1)\n    df_train['signal' + '_lagged_1plus'] = df_train['signal'].shift(1)\n    df_train['signal' + '_lagged_2minus'] = df_train['signal'].shift(-2)\n    df_train['signal' + '_lagged_2plus'] = df_train['signal'].shift(2)\n    \n        \n    df_train = df_train.replace([np.inf, -np.inf], np.nan)    \n    \n    return df_train\n\ndf_train = feature_engineering(df_train)\ndf_train = reduce_mem_usage(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(df_train.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets get only required column which will participate in training and testing \ncol = df_train.columns.tolist()\nunwanted_num = {'time', 'open_channels'}\ncol = [ele for ele in col if ele not in unwanted_num] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1, x2, y1, y2 = train_test_split(df_train[col], df_train['open_channels'], test_size=0.3, random_state=7)\ndel df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(random_seed=42, logging_level='Silent', iterations=700)\n\nmodel.fit(\n    x1, y1,\n    eval_set=(x2, y2),\n#     logging_level='Verbose',  # you can uncomment this for text output\n    plot=True, use_best_model=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_feature_importance()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x1\ndel x2\ndel y1\ndel y2\n\ndf_test = feature_engineering(df_test)\n\npreds = model.predict(df_test[col])\n\ndf_test['open_channels'] = np.round(np.clip(preds, 0, 10)).astype(int)\ndf_test[['time','open_channels']].to_csv('submission.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}