{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/stochastic/stochastic-0.4.0-py2.py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import KFold\n\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nN_SPLITS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_memory_usage(df):\n    numerics = [\"int16\", \"int32\", \"int64\", \"float64\"]\n    for col, col_type in df.dtypes.iteritems():\n        best_type = None\n        if col_type == \"object\":\n            df[col] = df[col].astype(\"category\")\n            best_type = \"category\"\n        elif col_type in numerics:\n            downcast = \"integer\" if \"int\" in str(col_type) else \"float\"\n            df[col] = pd.to_numeric(df[col], downcast=downcast)\n            best_type = df[col].dtype.name\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def macro_f1_score(preds, train_data):\n    labels = train_data.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = f1_score(labels, preds, average=\"macro\")\n    return \"f1\", score, True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features(df):\n    df = df.sort_values(by=[\"time\"]).reset_index(drop=True)\n    df.index = df.time * 10000 - 1\n    df[\"batch\"] = df.index // 25000\n    df[\"batch_index\"] = df.index - df.batch * 25000\n    df[\"batch_slices\"] = df[\"batch_index\"] // 2500\n    df[\"batch_slices_2\"] = df[\"batch\"].astype(str) + \"_\" + df[\"batch_slices\"].astype(str)\n\n    for c in [\"batch\", \"batch_slices_2\"]:\n        d = {}\n\n        d[\"mean_\" + c] = df.groupby([c])[\"signal\"].mean()\n        d[\"std_\" + c] = df.groupby([c])[\"signal\"].std()\n        d[\"median_\" + c] = df.groupby([c])[\"signal\"].median()\n        d[\"min_\" + c] = df.groupby([c])[\"signal\"].min()\n        d[\"max_\" + c] = df.groupby([c])[\"signal\"].max()\n        d[\"mean_abs_change_\" + c] = df.groupby([c])[\"signal\"].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d[\"abs_max_\" + c] = df.groupby([c])[\"signal\"].apply(lambda x: np.max(np.abs(x)))\n        d[\"abs_min_\" + c] = df.groupby([c])[\"signal\"].apply(lambda x: np.min(np.abs(x)))\n        d[\"range_\" + c] = d[\"max_\" + c] - d[\"min_\" + c]\n        d[\"abs_range_\" + c] = np.abs(d[\"max_\" + c] - d[\"min_\" + c])\n        d[\"max_to_min_\" + c] = d[\"max_\" + c] / d[\"min_\" + c]\n        d[\"abs_avg_\" + c] = (d[\"abs_min_\" + c] + d[\"abs_max_\" + c]) / 2\n\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n\n    df[\"signal_shift_+1\"] = [0] + list(df[\"signal\"].values[:-1])\n    df[\"signal_shift_-1\"] = list(df[\"signal\"].values[1:]) + [0]\n    for i in df[df[\"batch_index\"] == 0].index:\n        df[\"signal_shift_+1\"][i] = np.nan\n    for i in df[df[\"batch_index\"] == 49999].index:\n        df[\"signal_shift_-1\"][i] = np.nan\n\n    for c in [x for x in df.columns if x not in [\"time\", \"signal\", \"open_channels\", \"batch\", \"batch_index\", \"batch_slices\", \"batch_slices_2\"]]:\n        df[c + \"_minus_signal\"] = df[c] - df[\"signal\"]\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/liverpool-ion-switching/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/liverpool-ion-switching/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"signal\"] = np.exp(train[\"signal\"])\ntest[\"signal\"] = np.exp(test[\"signal\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = features(train)\ntest = features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = reduce_memory_usage(train)\ntest = reduce_memory_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in train.columns if x not in [\"time\", \"open_channels\", \"batch\", \"batch_index\", \"batch_slices\", \"batch_slices_2\"]]\ntarget = \"open_channels\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train[features], train[target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    \"learning_rate\": 0.1,\n    \"max_depth\": -1,\n    \"num_leaves\": 2**7 + 1,\n    \"metric\": \"l2\",\n    \"random_state\": SEED,\n    \"n_jobs\": -1,\n    \"sample_fraction\": 0.33\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\npreds = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = pd.DataFrame()\nfeature_importance[\"Feature\"] = X.columns\nfeature_importance[\"Value\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold, (train_idx, test_idx) in enumerate(folds.split(X)):\n    print(\"Fold\", fold)\n\n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n\n    model = lgb.train(params, train_set=lgb.Dataset(X_train, y_train), num_boost_round=2000, valid_sets=lgb.Dataset(X_test, y_test), feval=macro_f1_score, early_stopping_rounds=100, verbose_eval=100)\n    preds += model.predict(test[features], num_iteration=model.best_iteration)\n\n    current_importance = pd.DataFrame(zip(X.columns, model.feature_importance()), columns=[\"Feature\", \"Value\"])\n    feature_importance = pd.concat((feature_importance, current_importance)).groupby(\"Feature\", as_index=False).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds / N_SPLITS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"open_channels\"] = np.round(np.clip(preds, 0, 10)).astype(int)\ntest[[\"time\", \"open_channels\"]].to_csv(\"submission.csv\", index=False, float_format=\"%.4f\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 40))\nfig.patch.set_facecolor(\"white\")\nsns.set(style=\"whitegrid\")\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_importance.sort_values(by=\"Value\", ascending=False))\nplt.title(\"LightGBM feature importance\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.savefig(\"feature_importance.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance.sort_values(\"Value\", ascending=False).to_csv(\"feature_importance.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}