{"cells":[{"metadata":{},"cell_type":"markdown","source":"The code below to remove drift is forked from https://www.kaggle.com/friedchips/clean-removal-of-data-drift"},{"metadata":{},"cell_type":"markdown","source":"This notebook shows how to remove the drift from the training and test data as cleanly as possible. A clean signal is extremely important, since predictions from any ML models depend strongly on the precise value of each data point. The drift is removed by computing the histograms of small signal batches and matching them to an ideal (non-shifted) histogram. The resulting shifts are already much better than those from e.g. a rolling mean. The shifts are then further smoothed by approximating them with 4th degree polynomials. \nThe resulting clean signal retains the original offset.\nFor the pupose of this competition, the \"signal groups\" (see below) are determined by hand. This could also be done in an automated way (e.g. through analysis of the histograms) in the case of real-world data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport lightgbm as lgb\n\nfrom sklearn import model_selection, metrics\n\nfrom tsfresh import extract_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/liverpool-ion-switching/train.csv\")\ndf_test  = pd.read_csv(\"../input/liverpool-ion-switching/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_axes_grid(numplots_x, numplots_y, plotsize_x=6, plotsize_y=3):\n    fig, axes = plt.subplots(numplots_y, numplots_x)\n    fig.set_size_inches(plotsize_x * numplots_x, plotsize_y * numplots_y)\n    return fig, axes\n    \ndef set_axes(axes, use_grid=True, x_val = [0,100,10,5], y_val = [-50,50,10,5]):\n    axes.grid(use_grid)\n    axes.tick_params(which='both', direction='inout', top=True, right=True, labelbottom=True, labelleft=True)\n    axes.set_xlim(x_val[0], x_val[1])\n    axes.set_ylim(y_val[0], y_val[1])\n    axes.set_xticks(np.linspace(x_val[0], x_val[1], np.around((x_val[1] - x_val[0]) / x_val[2] + 1).astype(int)))\n    axes.set_xticks(np.linspace(x_val[0], x_val[1], np.around((x_val[1] - x_val[0]) / x_val[3] + 1).astype(int)), minor=True)\n    axes.set_yticks(np.linspace(y_val[0], y_val[1], np.around((y_val[1] - y_val[0]) / y_val[2] + 1).astype(int)))\n    axes.set_yticks(np.linspace(y_val[0], y_val[1], np.around((y_val[1] - y_val[0]) / y_val[3] + 1).astype(int)), minor=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data consists of different segments which can be sorted into one of 5 \"signal groups\":"},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,2,30,5)\nset_axes(axes[0], x_val=[0,5000000,500000,100000], y_val=[-5,15,5,1])\naxes[0].plot(df_train['signal'], color='darkblue', linewidth=.1);\naxes[0].set_title('training')\nset_axes(axes[1], x_val=[0,2000000,100000,10000], y_val=[-5,15,5,1])\naxes[1].set_title('test')\naxes[1].plot(df_test['signal'], color='darkgreen', linewidth=.1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visual identification can easily determine a) the signal group and b) whether there is a drift:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_segm_separators = np.concatenate([[0,500000,600000], np.arange(1000000,5000000+1,500000)])\ntrain_segm_signal_groups = [0,0,0,1,2,4,3,1,2,3,4] # from visual identification\ntrain_segm_is_shifted = [False, True, False, False, False, False, False, True, True, True, True] # from visual identification\ntrain_signal = np.split(df_train['signal'].values, train_segm_separators[1:-1])\ntrain_opench = np.split(df_train['open_channels'].values, train_segm_separators[1:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_segm_separators = np.concatenate([np.arange(0,1000000+1,100000), [1500000,2000000]])\ntest_segm_signal_groups = [0,2,3,0,1,4,3,4,0,2,0,0] # from visual id\ntest_segm_is_shifted = [True, True, False, False, True, False, True, True, True, False, True, False] # from visual id\ntest_signal = np.split(df_test['signal'].values, test_segm_separators[1:-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training data segments 0,3,4,6,5 are the \"model segments\" for the signal groups 0-5, respectively (clean & no shift):"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create clean signal histograms\nfig, axes = create_axes_grid(1,1,30,4)\nset_axes(axes, x_val=[-4,8,1,.1], y_val=[0,0.05,0.01,0.01])\n\nclean_hist = []\nhist_bins = np.linspace(-4,10,500)\n\n# iterate through the clean signal groups 0, 3, 4, 6, 5\nfor j,i in enumerate([0,3,4,6,5]):\n    clean_hist.append(np.histogram(train_signal[i], bins=hist_bins)[0])\n    clean_hist[-1] = clean_hist[-1] / 500000 # normalize histogram\n    axes.plot(hist_bins[1:], clean_hist[-1], label='Segment '+str(i)+', signal group '+str(j));\naxes.legend();\naxes.set_title(\"Clean reference histograms for all 5 signal groups\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the linear shift in segment 1 and compare the histogram of 4 slices of width 1000 (at 0,25000,50000 and 75000) to the clean histogram of segment 0:"},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 1000\n\nfig, axes = create_axes_grid(1,1,30,4)\nset_axes(axes, x_val=[-4,2,1,.1], y_val=[0,0.05,0.01,0.01])\n\naxes.plot(hist_bins[1:], clean_hist[0]);\nfor i in [0,25000,50000,75000]:\n    window_hist = np.histogram(train_signal[1][i:i+window_size], bins=hist_bins)[0] / window_size\n    axes.plot(hist_bins[1:], window_hist);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's visually clear that the shift can be determined by matching the window histograms to the clean histogram. Now we need to do this automatically for all shifted data segments:"},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 1000\nbin_width = np.diff(hist_bins)[0]\ns_window = 10 # maximum absolute change in shift from window to window+1\ntrain_signal_shift = []\n\nfor clean_id in range(len(train_segm_signal_groups)):\n    \n    group_id = train_segm_signal_groups[clean_id]\n    window_shift = []\n    prev_s = 0 # all signal groups start with shift=0\n    window_data = train_signal[clean_id].reshape(-1,window_size)\n    \n    for w in window_data:\n        window_hist = np.histogram(w, bins=hist_bins)[0] / window_size\n        window_corr = np.array([ np.sum(clean_hist[group_id] * np.roll(window_hist, -s)) for s in range(prev_s-s_window, prev_s+s_window+1) ])\n        prev_s = prev_s + np.argmax(window_corr) - s_window\n        window_shift.append(-prev_s * bin_width)\n\n    window_shift = np.array(window_shift)\n    train_signal_shift.append(window_shift)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This results in an already quite clean shift signal:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,1,30,4)\nset_axes(axes, x_val=[0,5000,500,100], y_val=[-5,1,1,.1])\naxes.plot(np.concatenate(train_signal_shift));\naxes.set_title(\"Shift value as determined by histogram matching:\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, approximation by a 4th order polynomial:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_signal_shift_clean = []\ntrain_signal_detrend = []\n\nfor data, use_fit, signal in zip(train_signal_shift, train_segm_is_shifted, train_signal):\n    if use_fit:\n        data_x = np.arange(len(data), dtype=float) * window_size + window_size/2\n        fit = np.flip(np.polyfit(data_x, data, 4))\n        data_x = np.arange(len(data) * window_size, dtype=float)\n        data_2 = np.sum([ c * data_x ** i for i, c in enumerate(fit) ], axis=0)\n    else:\n        data_2 = np.zeros(len(data) * window_size, dtype=float)\n        \n    train_signal_shift_clean.append(data_2)\n    train_signal_detrend.append(signal + data_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final shift and the cleaned signal:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,1,30,4)\nset_axes(axes, x_val=[0,5000000,500000,100000], y_val=[-6,1,1,.1])\naxes.plot(np.concatenate(train_signal_shift_clean));\naxes.set_title(\"Final shift value after polynomial fit\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,1,30,5)\nset_axes(axes, x_val=[0,5000000,500000,100000], y_val=[-5,15,5,1])\naxes.plot(np.concatenate(train_signal_detrend), linewidth=.1);\naxes.set_title(\"Training data without shift\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And the same procedure for the test data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 1000\nbin_width = np.diff(hist_bins)[0]\ns_window = 10\ntest_signal_detrend = []\ntest_signal_shift = []\n\nfor clean_id in range(len(test_segm_signal_groups)):\n    \n    group_id = test_segm_signal_groups[clean_id]\n    window_shift = []\n    prev_s = 0\n    window_data = test_signal[clean_id].reshape(-1,window_size)\n    \n    for w in window_data:\n        window_hist = np.histogram(w, bins=hist_bins)[0] / window_size\n        window_corr = np.array([ np.sum(clean_hist[group_id] * np.roll(window_hist, -s)) for s in range(prev_s-s_window, prev_s+s_window+1) ])\n        prev_s = prev_s + np.argmax(window_corr) - s_window\n        window_shift.append(-prev_s * bin_width)\n\n    window_shift = np.array(window_shift)\n    test_signal_shift.append(window_shift)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,1,30,4)\nset_axes(axes, x_val=[0,2000,100,10], y_val=[-6,1,1,.1])\naxes.plot(np.concatenate(test_signal_shift));\naxes.set_title(\"Shift value as determined by histogram matching:\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_signal_shift_clean = []\ntest_signal_detrend = []\ntest_remove_shift = [True, True, False, False, True, False, True, True, True, False, True, False]\n\nfor data, use_fit, signal in zip(test_signal_shift, test_segm_is_shifted, test_signal):\n    if use_fit:\n        data_x = np.arange(len(data), dtype=float) * window_size + window_size/2\n        fit = np.flip(np.polyfit(data_x, data, 4))\n        data_x = np.arange(len(data) * window_size, dtype=float)\n        data_2 = np.sum([ c * data_x ** i for i, c in enumerate(fit) ], axis=0)\n    else:\n        data_2 = np.zeros(len(data) * window_size, dtype=float)\n        \n    test_signal_shift_clean.append(data_2)\n    test_signal_detrend.append(signal + data_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,1,30,4)\nset_axes(axes, x_val=[0,2000000,100000,10000], y_val=[-6,1,1,.1])\naxes.plot(np.concatenate(test_signal_shift_clean));\naxes.set_title(\"Final shift value after polynomial fit\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = create_axes_grid(1,1,30,5)\nset_axes(axes, x_val=[0,2000000,200000,10000], y_val=[-5,12,5,1])\naxes.plot(np.concatenate(test_signal_detrend), linewidth=.1);\naxes.set_title(\"Test data without shift\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now add the undrifted signals back to our dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.savez_compressed(\"train_detrend.npz\", train_signal=train_signal_detrend, train_opench=train_opench, train_groups=train_segm_signal_groups)\ntrain = df_train.copy()\ntrain['signal_normalized'] = np.concatenate(train_signal_detrend).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.savez_compressed(\"test_detrend.npz\", test_signal=test_signal_detrend, test_groups=test_segm_signal_groups)\ntest = df_test.copy()\ntest['signal_normalized'] = np.concatenate(test_signal_detrend).ravel()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the data description we know that data is a discrete batch for every 500,000 rows, so lets label these accordingly."},{"metadata":{"trusted":true},"cell_type":"code","source":"rows_per_sample = 500000\ntrain['sample'] = train.groupby(train.index // rows_per_sample).ngroup()\ntest['sample'] = test.groupby(test.index // rows_per_sample).ngroup()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a bunch of standard time series features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature creation taken from https://www.kaggle.com/vbmokin/ion-switching-advanced-fe-lgb-confmatrix\ndef create_features(df, window_sizes, group='sample', column='signal_normalized'):\n    for window in window_sizes:\n        df[f\"rolling_mean_{window}\"] = df.groupby(group)[column].rolling(window=window).mean().values\n        df[f\"rolling_std_{window}\"] = df.groupby(group)[column].rolling(window=window).std().values\n        df[f\"rolling_var_{window}\"] = df.groupby(group)[column].rolling(window=window).var().values\n        df[f\"rolling_min_{window}\"] = df.groupby(group)[column].rolling(window=window).min().values\n        df[f\"rolling_max_{window}\"] = df.groupby(group)[column].rolling(window=window).max().values\n        df[f\"rolling_min_max_ratio_{window}\"] = df[f\"rolling_min_{window}\"] / df[f\"rolling_max_{window}\"]\n        df[f\"rolling_min_max_diff_{window}\"] = df[f\"rolling_max_{window}\"] - df[f\"rolling_min_{window}\"]\n        \n        df[f'lag_diff_{window}'] = df.groupby(group)[column].diff(window)\n\n        a = (df[column] - df[f'rolling_min_{window}']) / (df[f'rolling_max_{window}'] - df[f'rolling_min_{window}'])\n        df[f\"norm_{window}\"] = a * (np.floor(df[f'rolling_max_{window}']) - np.ceil(df[f'rolling_min_{window}']))\n\n    return df.replace([np.inf, -np.inf], np.nan).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arbitrary assign a bunch of windows\nwindows = [2, 3, 5, 10, 20, 30, 50]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the features and clean up the dataframe to prepare for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = create_features(train, windows)\ntrain = train.drop(['time', 'signal', 'sample'], axis='columns').rename(columns={'signal_normalized': 'signal'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.filter(regex='norm*|rolling*').iloc[10000:11000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = create_features(test, windows)\ntest = test.drop(['time', 'signal', 'sample'], axis='columns').rename(columns={'signal_normalized': 'signal'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train.drop(['open_channels'], axis='columns'), train['open_channels']\nX_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gbdt(X_train, y_train, X_valid, y_valid, early_stopping_rounds=10, num_boost_round=150):\n    # these are taken from various notebooks\n    params = {\n        'learning_rate': 0.1,\n        'max_depth': 2 ** 7 + 1,\n        'num_leaves': 200,\n        'metric': 'logloss',\n        'random_state': 7,\n        'n_jobs': -1,\n        'sample_fraction': 0.33,\n    }\n    \n    def f1_metric(preds, train_df):\n        labels = train_df.get_label()\n        preds = np.round(np.clip(preds, 0, 10)).astype(int)\n        score = metrics.f1_score(labels, preds, average = 'macro')\n        return ('f1_metric', score, True)\n    \n    clf = lgb.train(params, lgb.Dataset(X_train, y_train), valid_sets=lgb.Dataset(X_valid, y_valid), early_stopping_rounds=early_stopping_rounds, num_boost_round=num_boost_round, feval=f1_metric)\n    y_valid_pred = np.rint(clf.predict(X_valid,  num_iteration=clf.best_iteration))\n    \n    return clf, y_valid_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf, y_valid_pred = gbdt(X_train, y_train, X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.f1_score(y_valid, y_valid_pred, average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(clf, figsize=(50,50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = np.rint(clf.predict(test, num_iteration=clf.best_iteration))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df_test[['time']].copy()\nsubmission['open_channels'] = y_test.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(f\"results_{time.strftime('%Y%m%d%H%M%S')}.csv\", index=False, float_format='%.4f')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}