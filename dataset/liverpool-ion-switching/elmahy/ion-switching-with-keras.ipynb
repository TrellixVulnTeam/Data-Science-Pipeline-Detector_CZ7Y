{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import f1_score\nimport graphviz\nfrom sklearn import tree\nimport random\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/liverpool-ion-switching/test.csv')\ntrain = pd.read_csv('../input/liverpool-ion-switching/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(train['open_channels'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_val_signal = np.array(train['signal'])\ntrain_val_y = np.array(train['open_channels'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split to train and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_signal = train_val_signal[:4800000]\ntrain_y = train_val_y[:4800000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_signal = train_val_signal[4800000:]\nval_y = train_val_y[4800000:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scale the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import scale\ntrain_signal = scale(train_signal, axis=0, with_mean=True, with_std=True, copy=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_signal = scale(val_signal, axis=0, with_mean=True, with_std=True, copy=True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a data generator\nThis is important to load the data in patches otherwise, loading data will take long time\n\nHere, I am using 50 signals before and 50 signals after the point we want to predict its channels. That's why I am using signal size to be 101\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_generator(data_signal, data_y, batch_size, signal_size):\n    def g():\n        \n        start_index = random.randint(0,len(data_signal) - (signal_size + 1))\n         \n        x = data_signal[start_index:(start_index+signal_size)]\n        y = data_y[start_index + (signal_size // 2)]\n \n        return x,y\n            \n    while True:\n        x_batch = np.zeros(shape = (batch_size,signal_size))\n        y_batch = np.zeros(shape = (batch_size,1))\n        for k in range(batch_size):\n            x_batch[k],y_batch[k] = g()\n            \n        yield x_batch,y_batch\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = data_generator(train_signal, train_y, batch_size = 200, signal_size = 101)\nval_gen = data_generator(val_signal, val_y, batch_size = 200, signal_size = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in val_gen:\n    print(y.shape)\n    break;\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.layers import Input, Dense, Dropout,BatchNormalization\n\ninputs = Input(shape=(101,))\nxx = Dense(101, activation= 'softmax')(inputs)\nxx = BatchNormalization()(xx)\nxx = Dense(101, activation= 'softmax')(xx)\nxx = BatchNormalization()(xx)\nxx = Dense(101, activation= 'softmax')(xx)\n\n\noutputs = Dense(11, activation= 'softmax')(xx)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.compile(optimizer='adam',\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n             metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_gen,\n            steps_per_epoch=1000,\n            epochs=10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = []\ny_true = []\n\n\nfor x,y in train_gen:\n    y_true = y_true +  list(y)\n    y_hat = y_hat + list(np.argmax(model.predict(x), -1))\n\n    break;\n        \nprint(confusion_matrix(y_hat,y_true))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reshape test in batches\nThe new test should have the following shape\n\n(10000, 200, 101)\n\nwhere 10000 prediction are going to happend\nEach batch contains 200 lists for each we have 101 signals, output y will be a list of shape 200\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_signal = test['signal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = []\nbatch_size = 200\ninput_size = 101\nstart = 0\ntest_signal_list = list(test_signal)+ [0] * input_size\nwhile (start+101) < len(test_signal_list):\n    batch = []\n    for x in range(batch_size):\n        batch.append(test_signal_list[start:(start + 101)])\n        #batch.append([0]*101)\n        start = start + 1\n    new_test.append(batch)\n    if len(new_test) % 1000 == 0:\n        print(len(new_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arrp = []\nfor k in range(len(new_test)):\n    arrp.append(np.argmax(model.predict(np.array(new_test[k])), -1))\n    if k % 200 == 0:\n        print(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = [i for sublist in arrp for i in sublist]\nh = [0]* 50 + h\nprint(len(h))\nfor x in range((101 // 2) ):\n    h.pop()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(h)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submition"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/liverpool-ion-switching/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['open_channels'] = h","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False,float_format='%.4f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The current score is .55 but this means the method works to some extent"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}