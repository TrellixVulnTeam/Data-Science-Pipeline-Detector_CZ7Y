{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Training by Segmenting","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"in this notebook, I will try to show the pattern of the data, then we will train it partially. If you have tried to solve this problem. You must have realized that there is a pattern on the training data. **if an interval has high variances then there will be more categorical output for that interval**. therefore, I will train a model on an interval, then use it to predict the interval in the test dataset that have the similar characteristic.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In summary :\n1. Split the train and test by using the same variances of the data\n2. Train using simple MLP (3 hidden layers)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\n# Deep Learning\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load in data\ndata = pd.read_csv(\"../input/liverpool-ion-switching/train.csv\")\ntest = pd.read_csv(\"../input/liverpool-ion-switching/test.csv\")\nsample_sub = pd.read_csv(\"../input/liverpool-ion-switching/sample_submission.csv\" ,dtype={'time': 'str'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look at the plot, I differ each categoric by color.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,8))\nplt.plot(data[data['open_channels']==0]['signal'], color = 'c')\nplt.plot(data[data['open_channels']==1]['signal'], color = 'b')\nplt.plot(data[data['open_channels']==2]['signal'], color = 'r')\nplt.plot(data[data['open_channels']==3]['signal'], color = 'k')\nplt.plot(data[data['open_channels']==4]['signal'], color = 'g')\nplt.plot(data[data['open_channels']==5]['signal'], color = 'y')\nplt.plot(data[data['open_channels']==6]['signal'], color = 'c')\nplt.plot(data[data['open_channels']==7]['signal'], color = 'm')\nplt.plot(data[data['open_channels']==8]['signal'], color = 'b')\nplt.plot(data[data['open_channels']==9]['signal'], color = 'r')\nplt.plot(data[data['open_channels']==10]['signal'], color = 'g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The interval with high variances has more color. noted. To make it simple to be seen, we can transform each interval to be \"bar\" not curvy by using **polyfit to interpolate then substract them**. I use 10 seconds interval. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = pd.concat([data,test])\ncombined = combined.reset_index()\nmodified = []\nfor i in range(70):\n    a = i*10 \n    b = i*10 + 10\n    temp = combined[(combined['time']>a)&(combined['time']<=b)]\n    par = np.polyfit(temp['time'],temp['signal'],2)\n    modified += (temp['signal'] - (par[0]*temp['time']**2 + par[1]*temp['time']**1 + par[2])).tolist()\ncombined['modi'] = modified","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,8))\nplt.plot(combined[combined['open_channels']==0]['modi'], color = 'c')\nplt.plot(combined[combined['open_channels']==1]['modi'], color = 'b')\nplt.plot(combined[combined['open_channels']==2]['modi'], color = 'r')\nplt.plot(combined[combined['open_channels']==3]['modi'], color = 'k')\nplt.plot(combined[combined['open_channels']==4]['modi'], color = 'g')\nplt.plot(combined[combined['open_channels']==5]['modi'], color = 'y')\nplt.plot(combined[combined['open_channels']==6]['modi'], color = 'c')\nplt.plot(combined[combined['open_channels']==7]['modi'], color = 'm')\nplt.plot(combined[combined['open_channels']==8]['modi'], color = 'b')\nplt.plot(combined[combined['open_channels']==9]['modi'], color = 'r')\nplt.plot(combined[combined['open_channels']==10]['modi'], color = 'g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,8))\nplt.plot(combined['modi'], color = 'c')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the plot above, we can split the train and test by it's variances. Because a particular variances have a number amount of unique output. Here is the split I have done","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#split\nsplit1 = [combined[(combined['time']>0)&(combined['time']<=100)], \n          pd.concat([combined[(combined['time']>500)&(combined['time']<=510)],\n                     combined[(combined['time']>530)&(combined['time']<=540)],\n                     combined[(combined['time']>580)&(combined['time']<=590)],\n                     combined[(combined['time']>600)&(combined['time']<=700)]])]\n\nsplit2 = [pd.concat([combined[(combined['time']>100)&(combined['time']<=150)],\n                     combined[(combined['time']>300)&(combined['time']<=350)]]),\n          combined[(combined['time']>540)&(combined['time']<=550)]]\n    \nsplit3 = [combined[(combined['time']>150)&(combined['time']<=200)],\n          pd.concat([combined[(combined['time']>510)&(combined['time']<=520)],\n                     combined[(combined['time']>590)&(combined['time']<=600)]])]\n\nsplit4 = [pd.concat([combined[(combined['time']>200)&(combined['time']<=250)],\n                     combined[(combined['time']>450)&(combined['time']<=500)]]),\n          pd.concat([combined[(combined['time']>550)&(combined['time']<=560)],\n                     combined[(combined['time']>570)&(combined['time']<=580)]])]  \n                     \nsplit5 = [pd.concat([combined[(combined['time']>250)&(combined['time']<=300)],\n                     combined[(combined['time']>400)&(combined['time']<=450)]]),\n          pd.concat([combined[(combined['time']>520)&(combined['time']<=530)],\n                     combined[(combined['time']>560)&(combined['time']<=570)]])]        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now everything is ready to be trained on model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get('accuracy')>0.999):\n            print('\\n yuhu, accuracy already reach 99.9%')\n            self.model.stop_training = True ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(n):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(30, input_shape = [1,], activation='relu'))\n    model.add(tf.keras.layers.Dense(30, activation='relu'))\n    model.add(tf.keras.layers.Dense(30, activation='relu'))\n    model.add(tf.keras.layers.Dense(n,activation='softmax'))\n\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for i in [split1,split2,split3,split4,split5]:\n    split = i\n    skf = StratifiedKFold(n_splits=4)\n    callback = myCallback()\n    record = []\n    for train_index, test_index in skf.split(split[0]['modi'], split[0]['open_channels']):\n        print('\\n Cross validation Segment \\n')\n        X_train, X_test = split[0]['modi'].values[train_index], split[0]['modi'].values[test_index]\n        y_train, y_test = pd.get_dummies(split[0]['open_channels']).values[train_index], pd.get_dummies(split[0]['open_channels']).values[test_index]\n        model = get_model(y_train.shape[1])\n        scaler = StandardScaler()\n        scaler.fit(X_train.reshape(-1, 1))\n        nn_history = model.fit(scaler.transform(X_train.reshape(-1, 1)), y_train, epochs = 10, \n                               validation_data = (scaler.transform(X_test.reshape(-1, 1)),y_test),callbacks = [callback],batch_size = 4000)\n        record.append(nn_history.history['val_accuracy'][-1])\n    print('\\n mean validation accuracy is {}'.format(np.array(record).mean()))\n    \n    #predict\n    split[1].loc[split[1].index,'open_channels'] = np.argmax(model.predict(scaler.transform(np.array(split[1]['modi']).reshape(-1, 1))), axis=-1)\n    \noutput = pd.concat([split1[1],split2[1],split3[1],split4[1],split5[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = output.sort_values('time')\nreal_output = output[['time','open_channels']].reset_index()\nreal_output = real_output.drop('index', axis = 1)\nreal_output['time'] =  sample_sub['time']\nreal_output.to_csv('ion.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}