{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/liverpool-ion-switching/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/liverpool-ion-switching/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shift time in test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['time'] = (test['time'] - 500).round(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create 'batch' feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_batch(data, batch_size):\n    c = 'batch_' + str(batch_size)\n    data[c] = 0\n    ci = data.columns.get_loc(c)\n    n = int(data.shape[0] / batch_size)\n    print('Batch size:', batch_size, 'Column name:', c, 'Number of batches:', n)\n    for i in range(0, n):\n        data.iloc[i * batch_size: batch_size * (i + 1), ci] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for batch_size in [500000, 50000, 5000]:\n    add_batch(train, batch_size)\n    add_batch(test, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_batch_column = 'batch_500000'\n\nbatch_columns = [c for c in train.columns if c.startswith('batch')]\nbatch_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_6 = train[train[original_batch_column] == 6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(15, 5))\nplt.plot(batch_6['signal'], color='blue')\nplt.plot(batch_6['open_channels'], color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Free memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"# From https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n#        else:\n#            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_stats(data, batch_column, column):\n    \n    # mean,std: one value per batch\n    stats = {}\n    group = data.groupby(batch_column)[column]\n    stats['mean']   = group.mean()\n    stats['median'] = group.median()\n    stats['max']    = group.max()\n    stats['min']    = group.min()\n    stats['std']    = group.std()\n    \n    c = column + '_' + batch_column\n    \n    # apply it to batches\n    for key in stats:\n        data[c + '_' + key] = data[batch_column].map(stats[key].to_dict())\n    \n    # range\n    data[c + '_range'] = data[c + '_max'] - data[c + '_min']\n    data[c + '_max_to_min_ratio'] = data[c + '_max'] / data[c + '_min']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for batch_column in batch_columns:\n    if batch_column == original_batch_column:\n        continue\n    \n    add_stats(train, batch_column, 'signal')\n    # add_stats(train, batch_column, 'open_channels')\n    \n    add_stats(test, batch_column, 'signal')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add copies of the signal with time shift"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_shifted_signal(data, shift):\n    for batch in data[original_batch_column].unique():\n        m = data[original_batch_column] == batch\n        new_feature = 'shifted_signal_'\n        if shift > 0:\n            shifted_signal = np.concatenate((np.zeros(shift), data.loc[m, 'signal'].values[:-shift]))\n            new_feature += str(shift)\n        else:\n            t = -shift\n            shifted_signal = np.concatenate((data.loc[m, 'signal'].values[t:], np.zeros(t)))\n            new_feature += 'minus_' + str(t)\n        data.loc[m, new_feature] = shifted_signal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_shifted_signal(train, -1)\nadd_shifted_signal(test, -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_shifted_signal(train, 1)\nadd_shifted_signal(test, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add signal minus other features"},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude_columns = ['time', 'signal', 'open_channels'] + batch_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_signal_minus(data, exclude_columns):\n    for column in [c for c in data.columns if c not in exclude_columns]:\n        data['signal_minus_' + column] = data['signal'] - data[column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_signal_minus(train, exclude_columns)\nadd_signal_minus(test, exclude_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# groups = train['batch'].copy()\n\ny_train = train['open_channels'].copy()\nx_train = train.drop(['time', 'open_channels'] + batch_columns, axis=1)\n\nx_test = test.drop(['time'] + batch_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(x_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train\ndel test\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(x_train.columns) ^ set(x_test.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standard scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n\n# scaler = StandardScaler()\n# x_train = scaler.fit_transform(x_train)\n# x_test = scaler.transform(x_test)\n\nx_train = x_train.values\nx_test = x_test.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_train, x_train_valid, y_train_train, y_train_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective': 'multiclass',\n    'num_class': len(np.unique(y_train)),\n    'metric': 'multi_logloss',\n    'learning_rate': 0.05,\n    'max_depth': -1,\n    'num_leaves': 200,\n    'num_threads': 4,\n    'random_state': 42\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(data=x_train_train.astype('float32'), label=y_train_train.astype('float32'))\nlgb_valid = lgb.Dataset(data=x_train_valid.astype('float32'), label=y_train_valid.astype('float32'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = lgb.train(params, lgb_train, 100, valid_sets=lgb_valid,\n                      early_stopping_rounds=100, verbose_eval=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(y_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(y_pred)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/liverpool-ion-switching/sample_submission.csv')\nsubmission['open_channels'] = y_pred\nsubmission.to_csv('submission.csv', index=False, float_format='%.4f')\n\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}