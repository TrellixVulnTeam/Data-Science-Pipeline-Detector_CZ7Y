{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nimport gc\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/data-without-drift/train_clean.csv')\ntest_df  = pd.read_csv('../input/data-without-drift/test_clean.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def apply_group():\n    for i in range(20):\n        train_df.loc[((train_df.time) > i * 50) & (train_df.time <= (i+1) * 50), 'batch'] = i + 1\n        test_df.loc[i*100_000:(i+1)*100_000, 'batch'] = i\n    \n    batch_group = [(1,0), (2,0), (3,1), (4,2), (5,4), (6,3), (7,1), (8,2), (9,3), (10,4),\n                   (11,4),(12,3),(13,2),(14,1),(15,3),(16,4),(17,2),(18,1),(19,0),(20,0)]\n    for batch_i, group_i in batch_group:\n        train_df.loc[train_df.batch == batch_i, 'group'] = group_i\n    \n    batch_group = [(1,0), (2,2), (3,3), (4,0), (5,1), (6,4), (7,3), (8,4), (9,0), (10,2),\n                         (21,0),(22,0),(23,0),(24,0),(25,0),(26,0),(27,0),(28,0),(29,0),(30,0),\n                         (31,2),(32,0),(33,4),(34,3),(35,4),(36,1),(37,0),(38,3),(39,2),(40,0)]\n    batch_group.extend([(i, 0) for i in range(11,21)])\n    for batch_i, group_i in batch_group:\n        test_df.loc[test_df.batch == batch_i, 'group'] = group_i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"apply_group()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Group Assignments","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nfor _ in train_df.group.unique():\n    plt.plot(train_df[train_df.group == _].set_index('time').signal[::1000], '.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nfor _ in train_df.group.unique():\n    plt.plot(test_df[test_df.group == _].set_index('time').signal[::200], '.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit Linear Models by Group (without CV) and Visualize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = {}; alpha = {}; beta = {}\nfor _ in train_df.group.unique():\n    temp = train_df[train_df.group == _]\n    beta[_] = np.cov(temp.signal, temp.open_channels)[0,1] / np.var(temp.signal.astype(np.float64))\n    alpha[_] = np.mean(temp.open_channels) - (beta[_] * np.mean(temp.signal.astype(np.float64)))\n    diff[_] = temp.open_channels - (beta[_] * temp.signal + alpha[_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha, beta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ls(group_i, start, stop):\n    train_df[train_df.group == group_i].sample(1000).plot.scatter(x='signal', y='open_channels', figsize=(18,6))\n    \n    ols = lambda x, i: beta[i] * x + alpha[i]\n    plt.plot(np.linspace(start, stop), np.linspace(ols(start, group_i), ols(stop, group_i)), label='ols')\n    \n    lr = LogisticRegression(multi_class='multinomial')\n    lr.fit(\n        train_df[train_df.group == group_i].signal.values.reshape(-1,1),\n        y=train_df[train_df.group == group_i].open_channels.values.reshape(-1,1)\n    )\n    plt.plot(np.linspace(start, stop), lr.predict(np.linspace(start, stop).reshape(-1,1)), label='multinomial')\n    \n    lr = LogisticRegression(multi_class='ovr')\n    lr.fit(\n        train_df[train_df.group == group_i].signal.values.reshape(-1,1),\n        y=train_df[train_df.group == group_i].open_channels.values.reshape(-1,1)\n    )\n    plt.plot(np.linspace(start, stop), lr.predict(np.linspace(start, stop).reshape(-1,1)), label='ovr')\n\n    plt.legend(loc='upper left', fontsize=10)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls(0, -3.5, -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls(1, -4, -0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls(2, -4, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls(3, -4, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls(4, -4, 8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=10, shuffle=True, random_state=8982)\n\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ls_cv(model, cv, group_i, feature_cols):\n    \n    # Drop noise\n    if group_i == 2:\n        temp = train_df.drop(train_df.loc[3642932:3822753].index)[train_df.group == group_i]\n    else:\n        temp = train_df[train_df.group == group_i]\n    train_df_idx = temp.index\n        \n    # Define empty oof / Fill missing values with mean if present\n    oof = np.zeros(temp.shape[0])\n    temp = temp.fillna(temp.astype(np.float32).mean())\n    \n    # Cross-validate\n    models = []\n    for train_idx, valid_idx in cv.split(temp, temp.open_channels):\n        \n        if issubclass(model, LinearRegression):\n            lr = model()\n        elif issubclass(model, LogisticRegression):\n            lr = model(multi_class='multinomial')\n        \n        lr.fit(temp[feature_cols].iloc[train_idx].values,\n               temp.open_channels.iloc[train_idx].values.reshape(-1,1))\n        oof[valid_idx] = lr.predict(temp[feature_cols].iloc[valid_idx].values).flatten()\n        models.append(lr)\n    \n    # Predict OOF\n    try:\n        valid_f1 = metrics.f1_score(temp.open_channels, oof, average='macro')\n    except ValueError:\n        oof = np.round(np.clip(oof, 0, 10)).astype(np.int8)\n        valid_f1 = metrics.f1_score(temp.open_channels, oof, average='macro')\n    \n    print(f'valid_f1 of group {int(group_i)}: {valid_f1}')\n    \n    # Predict on test set\n    temp = test_df[test_df.group == group_i]\n    temp = temp.fillna(temp.astype(np.float64).mean())\n    test_df_idx = temp.index\n    \n    y_test = np.zeros(temp.shape[0])\n    for lr in models:\n        y_test += lr.predict(temp[feature_cols].values).flatten()\n    y_test /= len(models)\n    \n    del temp, models\n    gc.collect()\n    \n    return y_test, oof, train_df_idx, test_df_idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_linear = {}\nfor i in train_df.group.unique():\n    _ = ls_cv(LinearRegression, kf, i, ['signal'])\n    test_df.loc[_[3], 'linear'] = _[0]\n    train_df.loc[_[2], 'linear'] = _[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_logistic = {}\nfor i in train_df.group.unique():\n    _ = ls_cv(LogisticRegression, kf, i, ['signal'])\n    test_df.loc[_[3], 'logistic'] = _[0]\n    train_df.loc[_[2], 'logistic'] = _[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def blend_thresholder(oofs, y_tests, col_1, col_2, blend_name):\n    \n    best = {i: 0 for i in range(5)}\n    threshold = {}\n    start = 0.0\n    end = 1.0\n    \n    def _print(improved: bool):\n        if improved:\n            if _ == end:\n                print('!')\n            else:\n                print('!', end='')\n        else:\n            if _ == end:\n                print('.')\n            else:\n                print('.', end='')\n    \n    for i in range(5):\n        print(f'[Thresholder] ({i})', end=' ')\n        \n        for _ in np.linspace(start, end, 50):\n            temp = _ * oofs[col_1] + (1 - _) * oofs[col_2]\n            mask = oofs.group == i\n            one = oofs.open_channels.drop(oofs.open_channels.loc[3642932:3822753].index)[mask]\n            two = temp.drop(oofs.loc[3642932:3822753].index)[mask]\n            score = metrics.f1_score(one,\n                                     np.round(np.clip(two, 0, 10)).astype(np.int8),\n                                     average='macro')\n            if score > best[i]:\n                _print(True)\n                best[i] = score\n                threshold[i] = _\n            else:\n                _print(False)\n                \n        oofs.loc[mask, blend_name] = threshold[i] * oofs[mask][col_1] + (1 - threshold[i]) * oofs[mask][col_2]\n        one = oofs.open_channels.drop(oofs.loc[3642932:3822753].index)[mask]\n        two = oofs[blend_name].drop(oofs.loc[3642932:3822753].index)[mask]\n        \n        temp = metrics.f1_score(one, np.round(np.clip(two, 0, 10)), average='macro')\n        assert best[i] == temp\n        \n        mask = oofs.group == i\n        temp = threshold[i] * y_tests[mask][col_1] + (1 - threshold[i]) * y_tests[mask][col_2]\n        y_tests.loc[mask, blend_name] = temp\n    \n    del one, two, temp; gc.collect()\n    print()\n    print('best_threshold -', threshold)\n    print('overall_score -', metrics.f1_score(oofs.open_channels.drop(train_df.loc[3642932:3822753].index),\n                                              np.round(np.clip(oofs[blend_name].drop(train_df.loc[3642932:3822753].index), 0, 10)), average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blend_thresholder(train_df, test_df, 'linear', 'logistic', 'ls')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.ls[::2000].plot(figsize=(20,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.ls[::900].plot(figsize=(20,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/liverpool-ion-switching/sample_submission.csv', dtype={'time':str})\nsample_submission['open_channels'] = test_df.ls.astype(np.int8)\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}