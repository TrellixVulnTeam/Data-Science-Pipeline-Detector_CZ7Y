{"cells":[{"metadata":{"id":"huixWaL42uZi"},"cell_type":"markdown","source":"The validation scheme is based on [seq2seq-rnn-with-gru](https://www.kaggle.com/brandenkmurray/seq2seq-rnn-with-gru/output), and cleaned data is from [data-without-drift](https://www.kaggle.com/cdeotte/data-without-drift) and Kalman filter is from [https://www.kaggle.com/teejmahal20/single-model-lgbm-kalman-filter](single-model-lgbm-kalman-filter) and the added feature is from [wavenet-with-1-more-feature](wavenet-with-1-more-feature). I also used ragnar's data in this version [clean-kalman](https://www.kaggle.com/ragnar123/clean-kalman). The Wavenet is based on [https://github.com/philipperemy/keras-tcn](https://github.com/philipperemy/keras-tcn), [https://github.com/peustr/wavenet](https://github.com/peustr/wavenet) and [https://github.com/basveeling/wavenet](https://github.com/basveeling/wavenet) and also [https://www.kaggle.com/wimwim/wavenet-lstm](https://www.kaggle.com/wimwim/wavenet-lstm). If any refrence is not mentioned it was not intentional, please add them in comments.\n\nPrevious versions were mainly based on [https://www.kaggle.com/wimwim/wavenet-lstm](https://www.kaggle.com/wimwim/wavenet-lstm)  "},{"metadata":{"_kg_hide-input":true,"id":"LqmWjeYJ2uZn","trusted":true},"cell_type":"code","source":"!pip install --no-warn-conflicts -q tensorflow-addons","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"y1qOuodBfSxN","trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import (TimeDistributed, Dropout, BatchNormalization, Flatten, Convolution1D, Activation, Input, Dense, LSTM, Lambda, Bidirectional,\n                                     Add, AveragePooling1D, Multiply, GRU, GRUCell, LSTMCell, SimpleRNNCell, SimpleRNN, TimeDistributed, RNN,\n                                     RepeatVector, Conv1D, MaxPooling1D, Concatenate, GlobalAveragePooling1D, UpSampling1D)\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, ReduceLROnPlateau, LearningRateScheduler\nfrom tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, QuantileTransformer,  StandardScaler, MaxAbsScaler\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom tensorflow.keras.utils import Sequence, to_categorical\nfrom tensorflow.keras import losses, models, optimizers\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.metrics import f1_score, cohen_kappa_score, mean_squared_error\nfrom logging import getLogger, Formatter, StreamHandler, FileHandler, INFO\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom tqdm import tqdm_notebook as tqdm\nfrom contextlib import contextmanager\nfrom joblib import Parallel, delayed\nfrom IPython.display import display\nfrom sklearn import preprocessing\nfrom scipy.special import erfinv\nimport tensorflow_addons as tfa\nimport scipy.stats as stats\nimport random as rn\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport itertools\nimport warnings\nimport time\nimport pywt\nimport os\nimport gc\n\n\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"UafJMtyefSxU","trusted":true},"cell_type":"code","source":"EPOCHS=125\nNNBATCHSIZE=16\nBATCHSIZE = 4000\nSERIESIZE = 500000\nSEED = 321\nSELECT = True\nSPLITS = 5\nLR = 0.001\nfe_config = [\n    (True, 4000),\n]","execution_count":null,"outputs":[]},{"metadata":{"id":"EE4v8h1tfSxb","trusted":true},"cell_type":"code","source":"\ndef init_logger():\n    handler = StreamHandler()\n    handler.setLevel(INFO)\n    handler.setFormatter(Formatter(LOGFORMAT))\n    fh_handler = FileHandler('{}.log'.format(MODELNAME))\n    fh_handler.setFormatter(Formatter(LOGFORMAT))\n    logger.setLevel(INFO)\n    logger.addHandler(handler)\n    logger.addHandler(fh_handler)\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"7nxcdN_5fSxo","trusted":true},"cell_type":"code","source":"\n@contextmanager\ndef timer(name : Text):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\nCOMPETITION = 'ION-Switching'\nlogger = getLogger(COMPETITION)\nLOGFORMAT = '%(asctime)s %(levelname)s %(message)s'\nMODELNAME = 'WaveNet'\n","execution_count":null,"outputs":[]},{"metadata":{"id":"OC5DOcDifSxx","trusted":true},"cell_type":"code","source":"\ndef seed_everything(seed : int) -> NoReturn :\n    \n    rn.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"adUHGQUTfSyA","trusted":true},"cell_type":"code","source":"\ndef read_data(base : os.path.abspath) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n    \n    train = pd.read_csv('/kaggle/input/detrendedwithkalman/train_kalman.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n    test  = pd.read_csv('/kaggle/input/detrendedwithkalman/test_kalman.csv', dtype={'time': np.float32, 'signal': np.float32})\n    sub  = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv', dtype={'time': np.float32})\n    \n    return train, test, sub\n","execution_count":null,"outputs":[]},{"metadata":{"id":"HpDaJQ5yfSyI","trusted":true},"cell_type":"code","source":"\ndef batching(df : pd.DataFrame,\n             batch_size : int,\n             colname: Text) -> pd.DataFrame :\n    \n    df[colname] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n    df[colname] = df[colname].astype(np.uint16)\n        \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"id":"iQxOYF3tfSyj","trusted":true},"cell_type":"code","source":"\ndef reduce_mem_usage(df: pd.DataFrame,\n                     verbose: bool = True) -> pd.DataFrame:\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n\n                if (c_min > np.iinfo(np.int32).min\n                      and c_max < np.iinfo(np.int32).max):\n                    df[col] = df[col].astype(np.int32)\n                elif (c_min > np.iinfo(np.int64).min\n                      and c_max < np.iinfo(np.int64).max):\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (c_min > np.finfo(np.float16).min\n                        and c_max < np.finfo(np.float16).max):\n                    df[col] = df[col].astype(np.float16)\n                elif (c_min > np.finfo(np.float32).min\n                      and c_max < np.finfo(np.float32).max):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    reduction = (start_mem - end_mem) / start_mem\n\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n    if verbose:\n        print(msg)\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"id":"dytmNmL_fSzj","trusted":true},"cell_type":"code","source":"\ndef lag_with_pct_change(df : pd.DataFrame,\n                        shift_sizes : Optional[List]=[1, 2],\n                        add_pct_change : Optional[bool]=False,\n                        add_pct_change_lag : Optional[bool]=False) -> pd.DataFrame:\n    \n    for shift_size in shift_sizes:    \n        df['signal_shift_pos_'+str(shift_size)] = df.groupby('group')['signal'].shift(shift_size).fillna(0)\n        df['signal_shift_neg_'+str(shift_size)] = df.groupby('group')['signal'].shift(-1*shift_size).fillna(0)\n\n    if add_pct_change:\n        df['pct_change'] = df['signal'].pct_change()\n        if add_pct_change_lag:\n            for shift_size in shift_sizes:    \n                df['pct_change_shift_pos_'+str(shift_size)] = df.groupby('group')['pct_change'].shift(shift_size).fillna(0)\n                df['pct_change_shift_neg_'+str(shift_size)] = df.groupby('group')['pct_change'].shift(-1*shift_size).fillna(0)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"id":"m-ULWLF_fS0B","trusted":true},"cell_type":"code","source":"\ndef run_feat_enginnering(df : pd.DataFrame,\n                         create_all_data_feats : bool,\n                         batch_size : int) -> pd.DataFrame:\n    \n    df = batching(df, batch_size=batch_size, colname='group')\n\n    if create_all_data_feats:\n        df = lag_with_pct_change(df, [1, 2, 3],  add_pct_change=False, add_pct_change_lag=False)\n    df['signal_2'] = df['signal'] ** 2\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6E87jcu2fS0O","trusted":true},"cell_type":"code","source":"def feature_selection(df : pd.DataFrame,\n                      df_test : pd.DataFrame) -> Tuple[pd.DataFrame , pd.DataFrame, List]:\n    use_cols = [col for col in df.columns if col not in ['index','group', 'open_channels', 'time', 'batch']]\n    df = df.replace([np.inf, -np.inf], np.nan)\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    for col in use_cols:\n        col_mean = pd.concat([df[col], df_test[col]], axis=0).mean()\n        df[col] = df[col].fillna(col_mean)\n        df_test[col] = df_test[col].fillna(col_mean)\n   \n    gc.collect()\n    return df, df_test, use_cols\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef augment(X: np.array, y:np.array) -> Tuple[np.array, np.array]:\n    \n    X = np.vstack((X, np.flip(X, axis=1)))\n    y = np.vstack((y, np.flip(y, axis=1)))\n    \n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"id":"e4QulGxHfS0n","trusted":true},"cell_type":"code","source":"\ndef run_cv_model_by_batch(train : pd.DataFrame,\n                          test : pd.DataFrame,\n                          splits : int,\n                          batch_col : Text,\n                          feats : List,\n                          sample_submission: pd.DataFrame,\n                          nn_epochs : int,\n                          nn_batch_size : int) -> NoReturn:\n    seed_everything(SEED)\n    K.clear_session()\n    config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n    tf.compat.v1.keras.backend.set_session(sess)\n\n    oof_ = np.zeros((len(train), 11))\n    preds_ = np.zeros((len(test), 11))\n    target = ['open_channels']\n    group = train['group']\n    kf = GroupKFold(n_splits=5)\n    splits = [x for x in kf.split(train, train[target], group)]\n\n    new_splits = []\n    for sp in splits:\n        new_split = []\n        new_split.append(np.unique(group[sp[0]]))\n        new_split.append(np.unique(group[sp[1]]))\n        new_split.append(sp[1])    \n        new_splits.append(new_split)\n        \n    tr = pd.concat([pd.get_dummies(train.open_channels), train[['group']]], axis=1)\n\n    tr.columns = ['target_'+str(i) for i in range(11)] + ['group']\n    target_cols = ['target_'+str(i) for i in range(11)]\n    train_tr = np.array(list(tr.groupby('group').apply(lambda x: x[target_cols].values))).astype(np.float32)\n    train = np.array(list(train.groupby('group').apply(lambda x: x[feats].values)))\n    test = np.array(list(test.groupby('group').apply(lambda x: x[feats].values)))\n\n    for n_fold, (tr_idx, val_idx, val_orig_idx) in enumerate(new_splits[0:], start=0):\n        train_x, train_y = train[tr_idx], train_tr[tr_idx]\n        valid_x, valid_y = train[val_idx], train_tr[val_idx]\n        train_x, train_y = augment(train_x, train_y)\n        \n        gc.collect()\n        shape_ = (None, train_x.shape[2])\n        model = Classifier(shape_)\n        cb_lr_schedule = LearningRateScheduler(lr_schedule)\n        cb_prg = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False,leave_overall_progress=False, show_epoch_progress=False,show_overall_progress=True)\n        model.fit(train_x,train_y,\n                  epochs=nn_epochs,\n                  callbacks=[cb_prg, cb_lr_schedule, MacroF1(model, valid_x,valid_y)],\n                  batch_size=nn_batch_size,verbose=0,\n                  validation_data=(valid_x,valid_y))\n        preds_f = model.predict(valid_x)\n        f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  np.argmax(preds_f, axis=2).reshape(-1), average = 'macro')\n        logger.info(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n        preds_f = preds_f.reshape(-1, preds_f.shape[-1])\n        oof_[val_orig_idx,:] += preds_f\n        te_preds = model.predict(test)\n        te_preds = te_preds.reshape(-1, te_preds.shape[-1])           \n        preds_ += te_preds / SPLITS\n    f1_score_ =f1_score(np.argmax(train_tr, axis=2).reshape(-1),  np.argmax(oof_, axis=1), average = 'macro')\n    logger.info(f'Training completed. oof macro f1 score : {f1_score_:1.5f}')\n    sample_submission['open_channels'] = np.argmax(preds_, axis=1).astype(int)\n    sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')\n    display(sample_submission.head())\n    np.save('oof.npy', oof_)\n    np.save('preds.npy', preds_)\n\n    return \n","execution_count":null,"outputs":[]},{"metadata":{"id":"dqt0VJAS2ucB","trusted":true},"cell_type":"code","source":"def lr_schedule(epoch):\n    if epoch < 40:\n        lr = LR\n    elif epoch < 50:\n        lr = LR / 3\n    elif epoch < 60:\n        lr = LR / 6\n    elif epoch < 75:\n        lr = LR / 9\n    elif epoch < 85:\n        lr = LR / 12\n    elif epoch < 100:\n        lr = LR / 15\n    elif epoch < 110:    \n        lr = LR / 25       \n    else:\n        lr = LR / 50\n    return lr","execution_count":null,"outputs":[]},{"metadata":{"id":"SjbrEQSa2ucN","trusted":true},"cell_type":"code","source":"class Mish(tf.keras.layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(Mish, self).__init__(**kwargs)\n        self.supports_masking = True\n\n    def call(self, inputs):\n        return inputs * K.tanh(K.softplus(inputs))\n\n    def get_config(self):\n        base_config = super(Mish, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\ndef mish(x):\n\treturn tf.keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)\n \nfrom tensorflow.keras.utils import get_custom_objects\nfrom tensorflow.keras.layers import Activation\nget_custom_objects().update({'mish': Activation(mish)})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_focal_loss(gamma=2.0, alpha=0.25):\n    \"\"\"\n    Implementation of Focal Loss from the paper in multiclass classification\n    Formula:\n        loss = -alpha*((1-p)^gamma)*log(p)\n    Parameters:\n        alpha -- the same as wighting factor in balanced cross entropy\n        gamma -- focusing parameter for modulating factor (1-p)\n    Default value:\n        gamma -- 2.0 as mentioned in the paper\n        alpha -- 0.25 as mentioned in the paper\n    \"\"\"\n    def focal_loss(y_true, y_pred):\n        # Define epsilon so that the backpropagation will not result in NaN\n        # for 0 divisor case\n        epsilon = K.epsilon()\n        # Add the epsilon to prediction value\n        #y_pred = y_pred + epsilon\n        # Clip the prediction value\n        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n        # Calculate cross entropy\n        cross_entropy = -y_true*K.log(y_pred)\n        # Calculate weight that consists of  modulating factor and weighting factor\n        weight = alpha * y_true * K.pow((1-y_pred), gamma)\n        # Calculate focal loss\n        loss = weight * cross_entropy\n        # Sum the losses in mini_batch\n        loss = K.sum(loss, axis=1)\n        return loss\n    \n    return focal_loss","execution_count":null,"outputs":[]},{"metadata":{"id":"YSESlpaNwkkx","trusted":true},"cell_type":"code","source":"def WaveNetResidualConv1D(num_filters, kernel_size, stacked_layer):\n\n    def build_residual_block(l_input):\n        resid_input = l_input\n        for dilation_rate in [2**i for i in range(stacked_layer)]:\n            l_sigmoid_conv1d = Conv1D(\n              num_filters, kernel_size, dilation_rate=dilation_rate,\n              padding='same', activation='sigmoid')(l_input)\n            l_tanh_conv1d = Conv1D(\n             num_filters, kernel_size, dilation_rate=dilation_rate,\n             padding='same', activation='mish')(l_input)\n            l_input = Multiply()([l_sigmoid_conv1d, l_tanh_conv1d])\n            l_input = Conv1D(num_filters, 1, padding='same')(l_input)\n            resid_input = Add()([resid_input ,l_input])\n        return resid_input\n    return build_residual_block\n\n\ndef Classifier(shape_):\n    num_filters_ = 16\n    kernel_size_ = 4\n    stacked_layers_ = [12, 8, 4, 1]\n    l_input = Input(shape=(shape_))\n    x = Conv1D(num_filters_, 1, padding='same')(l_input)\n    x = WaveNetResidualConv1D(num_filters_, kernel_size_, stacked_layers_[0])(x)\n    x = Conv1D(num_filters_*2, 1, padding='same')(x)\n    x = WaveNetResidualConv1D(num_filters_*2, kernel_size_, stacked_layers_[1])(x)\n    x = Conv1D(num_filters_*4, 1, padding='same')(x)\n    x = WaveNetResidualConv1D(num_filters_*4, kernel_size_, stacked_layers_[2])(x)\n    x = Conv1D(num_filters_*8, 1, padding='same')(x)\n    x = WaveNetResidualConv1D(num_filters_*8, kernel_size_, stacked_layers_[3])(x)\n    l_output = Dense(11, activation='softmax')(x)\n    model = models.Model(inputs=[l_input], outputs=[l_output])\n    opt = Adam(lr=LR)\n    opt = tfa.optimizers.SWA(opt)\n    model.compile(loss=categorical_focal_loss(gamma=3.0, alpha=0.25), optimizer=opt, metrics=['categorical_accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"1yfpldH_2ucw","trusted":true},"cell_type":"code","source":"class MacroF1(Callback):\n    def __init__(self, model, inputs, targets):\n        self.model = model\n        self.inputs = inputs\n        self.targets = np.argmax(targets, axis=2).reshape(-1)\n\n    def on_epoch_end(self, epoch, logs):\n        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n        score = f1_score(self.targets, pred, average=\"macro\")\n        print(f' F1Macro: {score:.5f}')    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GaussRankScaler():\n\n    def __init__( self ):\n        self.epsilon = 0.001\n        self.lower = -1 + self.epsilon\n        self.upper =  1 - self.epsilon\n        self.range = self.upper - self.lower\n\n    def fit_transform( self, X ):\n\t\n        i = np.argsort( X, axis = 0 )\n        j = np.argsort( i, axis = 0 )\n\n        assert ( j.min() == 0 ).all()\n        assert ( j.max() == len( j ) - 1 ).all()\n\n        j_range = len( j ) - 1\n        self.divider = j_range / self.range\n\n        transformed = j / self.divider\n        transformed = transformed - self.upper\n        transformed = erfinv( transformed )\n        return transformed\n","execution_count":null,"outputs":[]},{"metadata":{"id":"skru4lPt2uc6","trusted":true},"cell_type":"code","source":"def rankgaus_transform(train, test):\n    \n  shape_ = train.shape[0]\n  data = pd.concat([train[['signal']], test[['signal']]]).values\n  rgsc = GaussRankScaler()\n  data = rgsc.fit_transform(data)\n  train['signal'] = data[:shape_]\n  test['signal'] = data[shape_:]\n    \n  return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale(train, test):\n    \n    sc = StandardScaler()\n    train['signal'] = sc.fit_transform(train.signal.values.reshape(-1, 1))\n    test['signal'] = sc.transform(test.signal.values.reshape(-1, 1))\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"id":"02TDJtejfS0_","trusted":true},"cell_type":"code","source":"\ndef run_everything(fe_config : List) -> NoReturn:\n    not_feats_cols = ['time']\n    target_col = ['open_channels']\n    init_logger()\n    with timer(f'Reading Data'):\n        logger.info('Reading Data Started ...')\n        base = os.path.abspath('/kaggle/input/liverpool-ion-switching/')\n        train, test, sample_submission = read_data(base)\n        train = batching(train, batch_size=SERIESIZE, colname='batch')\n        selection = [0,2,3,4,5]\n        train = train.loc[train['batch'].isin(selection)]\n        train = train.reset_index(drop=True)\n        train = train.drop('batch', axis=1)\n        train, test = scale(train, test)    \n        logger.info('Reading and Normalizing Data Completed ...')\n    with timer(f'Creating Features'):\n        logger.info('Feature Enginnering Started ...')\n        for config in fe_config:\n            train = run_feat_enginnering(train, create_all_data_feats=config[0], batch_size=config[1])\n            test  = run_feat_enginnering(test,  create_all_data_feats=config[0], batch_size=config[1])\n        train, test, feats = feature_selection(train, test)\n        logger.info('Feature Enginnering Completed ...')\n\n    with timer(f'Running Wavenet model'):\n        logger.info(f'Training Wavenet model with {SPLITS} folds of GroupKFold Started ...')\n        run_cv_model_by_batch(train, test, splits=SPLITS, batch_col='group', feats=feats, sample_submission=sample_submission, nn_epochs=EPOCHS, nn_batch_size=NNBATCHSIZE)\n        logger.info(f'Training completed ...')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"_w4_OJJtfS1K","outputId":"7ea711e0-3974-419e-85fc-af53090561df","trusted":true},"cell_type":"code","source":"run_everything(fe_config)","execution_count":null,"outputs":[]},{"metadata":{"id":"m43NcOnF7Jl8","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"WaveNet_Keras_(4) (1).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"1bffc1de906f4d52af208a1a81dcd1b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a57774c733a846158189adea362ddc9f","placeholder":"​","style":"IPY_MODEL_20ad09e52ee24cb192de983a08da3a8a","value":" 120/120 ETA: 00:00s,  16.07s/epochs"}},"2051121a881d4619a9044b5ae66488b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Training: 100%","description_tooltip":null,"layout":"IPY_MODEL_84e7e7f749664b9ca46072111341c792","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_856b5c34256e41649bba9e896c85bd8f","value":120}},"20ad09e52ee24cb192de983a08da3a8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"228d13dcf4454115ad62a0cd8c286ffa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"2a7df7391ef041688dd9888bff262b65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"327ffe509d5d43eb8c02b8296d2e20cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341cb647b093472cb71af2a7afee4c9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"3813b4ceb82843bc9f6add2bb3b3f692":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cbe1c9da8bf47af82cb7e40ebee876a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Training: 100%","description_tooltip":null,"layout":"IPY_MODEL_8d3b2522b9874bde85fc998ced237cc6","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50a5a603c2ed4f5aadcfe8200e8bb0be","value":120}},"4f29ddd2dfe64abc859b7a53eb8ff62b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fab1c24f9d449e78b33f0e9e0695ac4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cbe1c9da8bf47af82cb7e40ebee876a","IPY_MODEL_1bffc1de906f4d52af208a1a81dcd1b4"],"layout":"IPY_MODEL_5a2213e401594aa5969f527b3415986e"}},"50a5a603c2ed4f5aadcfe8200e8bb0be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"54e561b6b6cc45e39c1c769f1c6c1591":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Training: 100%","description_tooltip":null,"layout":"IPY_MODEL_c81fa17ae5384158b825788b07073a58","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5febd96d3335429abba1f4713f53a620","value":120}},"5a2213e401594aa5969f527b3415986e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"5febd96d3335429abba1f4713f53a620":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"6ef474ca4b054ca6bbfd366ff3d8e383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac20a6c0d18a4018a337f3f6d6aa39a1","placeholder":"​","style":"IPY_MODEL_cff36729bbde4160853553861497745d","value":" 120/120 ETA: 00:00s,   8.83s/epochs"}},"748fc12e896847f89673c54f4b1f469e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3772fad60e64f6d953d5a62c0e4eb4b","IPY_MODEL_6ef474ca4b054ca6bbfd366ff3d8e383"],"layout":"IPY_MODEL_b9d1e6c47dd4488d9727bca6c349dda8"}},"84e7e7f749664b9ca46072111341c792":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"856b5c34256e41649bba9e896c85bd8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"8d3b2522b9874bde85fc998ced237cc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d61b33a5f064952afef1e8a850dfdd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dfa59b69e804e07a2d7cf41811a6c72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8f579158249e4ac093f002196c0ac19e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f29ddd2dfe64abc859b7a53eb8ff62b","placeholder":"​","style":"IPY_MODEL_9f503ff8c5224979ba713832f6a67983","value":" 120/120 ETA: 00:00s,  16.17s/epochs"}},"9a3679a883274596837b88345fa435cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c74e4dfd00c44753a69e38e9afc43a8e","IPY_MODEL_a9d7f4151f8f41a7af8872de5879d6f3"],"layout":"IPY_MODEL_8dfa59b69e804e07a2d7cf41811a6c72"}},"9f503ff8c5224979ba713832f6a67983":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1f3c776fa9149e6ab311cb5cfc89d37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a57774c733a846158189adea362ddc9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9d7f4151f8f41a7af8872de5879d6f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab03c73e9fc445ef99e95dfbd990a9b7","placeholder":"​","style":"IPY_MODEL_ef74b1b13bb747afb64cdf5b588f9aa4","value":" 120/120 ETA: 00:00s,   8.86s/epochs"}},"ab03c73e9fc445ef99e95dfbd990a9b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac20a6c0d18a4018a337f3f6d6aa39a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7bc1c0b7e134b31a58d516e9cfb05d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2051121a881d4619a9044b5ae66488b8","IPY_MODEL_8f579158249e4ac093f002196c0ac19e"],"layout":"IPY_MODEL_2a7df7391ef041688dd9888bff262b65"}},"b9d1e6c47dd4488d9727bca6c349dda8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"c20af5b38dd64c25af3bd43e22e2c82e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54e561b6b6cc45e39c1c769f1c6c1591","IPY_MODEL_f8075f1f41654f6f847320116e3e43d5"],"layout":"IPY_MODEL_a1f3c776fa9149e6ab311cb5cfc89d37"}},"c74e4dfd00c44753a69e38e9afc43a8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Training: 100%","description_tooltip":null,"layout":"IPY_MODEL_8d61b33a5f064952afef1e8a850dfdd2","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_341cb647b093472cb71af2a7afee4c9e","value":120}},"c81fa17ae5384158b825788b07073a58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cff36729bbde4160853553861497745d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1c23e90153046f58f3fd39d7459f11c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef74b1b13bb747afb64cdf5b588f9aa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3772fad60e64f6d953d5a62c0e4eb4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Training: 100%","description_tooltip":null,"layout":"IPY_MODEL_327ffe509d5d43eb8c02b8296d2e20cb","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_228d13dcf4454115ad62a0cd8c286ffa","value":120}},"f8075f1f41654f6f847320116e3e43d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c23e90153046f58f3fd39d7459f11c","placeholder":"​","style":"IPY_MODEL_3813b4ceb82843bc9f6add2bb3b3f692","value":" 120/120 ETA: 00:00s,   8.86s/epochs"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}