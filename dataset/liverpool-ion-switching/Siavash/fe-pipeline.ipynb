{"cells":[{"metadata":{},"cell_type":"markdown","source":"Part of the Feature Engineering is from the following notebooks:\n\n[1-geomean-nn-and-6featlgbm-2-259-private-lb](https://www.kaggle.com/dkaraflos/1-geomean-nn-and-6featlgbm-2-259-private-lb) \n\n[physically-possible](https://www.kaggle.com/jazivxt/physically-possible)\n\n[permutation-importance-for-feature-selection-part1](https://www.kaggle.com/corochann/permutation-importance-for-feature-selection-part1)\n\nand the data is from:\n\n[data-without-drift](https://www.kaggle.com/cdeotte/data-without-drift)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.metrics import f1_score, cohen_kappa_score, mean_squared_error\nfrom logging import getLogger, Formatter, StreamHandler, FileHandler, INFO\nfrom scipy.signal import butter, lfilter,filtfilt,savgol_filter\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom tsfresh.feature_extraction import feature_calculators\nfrom scipy.stats import pearsonr, spearmanr, kendalltau\nfrom sklearn.linear_model import LinearRegression\nfrom pandas_profiling import ProfileReport\nfrom tqdm import tqdm_notebook as tqdm\nfrom contextlib import contextmanager\nfrom joblib import Parallel, delayed\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy import signal\nimport lightgbm as lgb\nimport xgboost as xgb\nimport seaborn as sns\nimport random as rn\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport itertools\nimport warnings\nimport librosa\nimport time\nimport pywt\nimport os\nimport gc\n\n\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nBATCHSIZE = 50000\nSEED = 529\nSELECT = True\nSPLITS = 5\nfe_config =[\n    (True, [5000, 10000, 50000], True, True, False),\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef init_logger():\n    handler = StreamHandler()\n    handler.setLevel(INFO)\n    handler.setFormatter(Formatter(LOGFORMAT))\n    fh_handler = FileHandler('{}.log'.format(MODELNAME))\n    fh_handler.setFormatter(Formatter(LOGFORMAT))\n    logger.setLevel(INFO)\n    logger.addHandler(handler)\n    logger.addHandler(fh_handler)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n@contextmanager\ndef timer(name : Text):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\nCOMPETITION = 'ION-Switching'\nlogger = getLogger(COMPETITION)\nLOGFORMAT = '%(asctime)s %(levelname)s %(message)s'\nMODELNAME = 'Baseline'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef seed_everything(seed : int) -> NoReturn :\n    \n    rn.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef read_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n\n    train = pd.read_csv('../input/data-without-drift/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int8})\n    test  = pd.read_csv('../input/data-without-drift/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\n    sub  = pd.read_csv('../input/liverpool-ion-switching/sample_submission.csv', dtype={'time': np.float32})\n    return train, test, sub\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_visual_idx = [0, 500000, 600000, 1000000, 1500000, 2000000, 2500000, 3000000, 3500000, 4000000, 4500000, 5000000]\nte_visual_idx = [0, 100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000, 1500000, 2000000]\ntr_data_type = [0,0,0,1,2,4,3,1,2,3,4]\nte_data_type = [0,2,3,0,1,4,3,4,0,2,0,0]\n\ndef add_visual_batching(df: pd.DataFrame, train: bool = True):\n    idx = tr_visual_idx if train else te_visual_idx\n    type_ = tr_data_type if train else te_data_type\n    s = idx; t = type_\n    visual_batch = np.zeros((s[-1],), dtype=np.int64)\n    visual_type = np.zeros((s[-1],), dtype=np.int64)\n    df['visual_batch'] = 0\n    df['visual_type'] = 0\n    \n    for i, j in zip(range(len(s) - 1), t):\n        df.loc[s[i]:s[i+1],'visual_batch'] = i\n        df.loc[s[i]:s[i+1],'visual_type'] = j\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef reduce_mem_usage(df: pd.DataFrame,\n                     verbose: bool = True) -> pd.DataFrame:\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if (c_min > np.iinfo(np.int8).min\n                        and c_max < np.iinfo(np.int8).max):\n                    df[col] = df[col].astype(np.int8)\n                elif (c_min > np.iinfo(np.int16).min\n                      and c_max < np.iinfo(np.int16).max):\n                    df[col] = df[col].astype(np.int16)\n                elif (c_min > np.iinfo(np.int32).min\n                      and c_max < np.iinfo(np.int32).max):\n                    df[col] = df[col].astype(np.int32)\n                elif (c_min > np.iinfo(np.int64).min\n                      and c_max < np.iinfo(np.int64).max):\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (c_min > np.finfo(np.float16).min\n                        and c_max < np.finfo(np.float16).max):\n                    df[col] = df[col].astype(np.float16)\n                elif (c_min > np.finfo(np.float32).min\n                      and c_max < np.finfo(np.float32).max):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    reduction = (start_mem - end_mem) / start_mem\n\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n    if verbose:\n        print(msg)\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_wave(x, cutoff=(-1, -1), N=4, filtering='lfilter'):\n\n    assert x.ndim == 1\n    output = 'sos' if filtering == 'sos' else 'ba'\n    if cutoff[0] <= 0 and cutoff[1] <= 0:\n        # Do not apply filter\n        return x\n    elif cutoff[0] <= 0 and cutoff[1] > 0:\n        # Apply low pass filter\n        output = signal.butter(N, Wn=cutoff[1]/len(x), btype='lowpass', output=output)\n    elif cutoff[0] > 0 and cutoff[1] <= 0:\n        # Apply high pass filter\n        output = signal.butter(N, Wn=cutoff[0]/len(x), btype='highpass', output=output)\n    else:\n        # Apply band pass filter\n        output = signal.butter(N, Wn=(cutoff[0]/len(x), cutoff[1]/len(x)), btype='bandpass', output=output)\n\n    if filtering == 'lfilter':\n        b, a = output\n        return signal.lfilter(b, a, x)\n    elif filtering == 'filtfilt':\n        b, a = output\n        return signal.filtfilt(b, a, x)\n    elif filtering == 'sos':\n        sos = output\n        return signal.sosfilt(sos, x)\n    else:\n        raise ValueError(\"[ERROR] Unexpected value filtering={}\".format(filtering))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef lag_with_pct_change(df : pd.DataFrame,\n                        shift_sizes : Optional[List]=[1, 2, 3],\n                        add_pct_change : Optional[bool]=False,\n                        add_pct_change_lag : Optional[bool]=False) -> pd.DataFrame:\n    df['batch'] = df.index // 500000\n    df['batch_idx'] = df.index - (df.batch * 500000)\n    smooth_sig = lambda x: filter_wave(x, cutoff=(0, 100), filtering='filtfilt')\n    df['baseline'] = np.concatenate(df.groupby(['visual_batch'])['signal'].apply(smooth_sig))\n        \n    for shift_size in shift_sizes:    \n        df['signal_shift_pos_'+str(shift_size)] = df.groupby(['batch']).shift(shift_size, fill_value=0.)['signal']\n        df['signal_shift_neg_'+str(shift_size)] = df.groupby(['batch']).shift(-1*shift_size, fill_value=0.)['signal']\n\n    if add_pct_change:\n        df['pct_change'] = df['signal'].pct_change()\n        if add_pct_change_lag:\n            for shift_size in shift_sizes:    \n                df['pct_change_shift_pos_'+str(shift_size)] = df.groupby(['batch']).shift(shift_size, fill_value=0.)['pct_change']\n                df['pct_change_shift_neg_'+str(shift_size)] = df.groupby(['batch']).shift(-1*shift_size, fill_value=0.)['pct_change']\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef feature_enginering_by_batch(z : Union[pd.Series, np.array],\n                                window_size : Optional[List]=[50000]) -> pd.DataFrame:\n    \n    temp = pd.DataFrame(index=[0], dtype=np.float16)\n    if window_size is not None:\n        for window in window_size:\n            roll = pd.Series(z).rolling(window=window, min_periods=1, center=True)\n            temp[f'roll_mean_{window}'] = roll.mean()\n            temp[f'roll_max_{window}'] = roll.max()\n            temp[f'roll_min_{window}'] = roll.min()\n            temp[f'roll_std_{window}'] = roll.std()\n            temp[f'roll_mean_abs_chg_{window}'] = roll.apply(lambda x: np.mean(np.abs(np.diff(x))), raw=True)\n            temp[f'roll_abs_max_{window}'] = roll.apply(lambda x: np.max(np.abs(x)), raw=True)\n            temp[f'roll_abs_min_{window}'] = roll.apply(lambda x: np.min(np.abs(x)), raw=True)\n            temp[f'roll_range_{window}'] = temp[f'roll_max_{window}'] - temp[f'roll_min_{window}']\n            temp[f'roll_max_to_min_{window}'] = temp[f'roll_max_{window}'] / temp[f'roll_min_{window}']\n            temp[f'roll_abs_avg_{window}'] = (temp[f'roll_abs_max_{window}'] + temp[f'roll_abs_min_{window}']) / 2\n    \n    for i in range(4, 5): \n        temp[f'kstat_{i}'] = stats.kstat(z, i)\n\n    for i in range(4, 5):\n        temp[f'moment_{i}'] = stats.moment(z, i)    \n           \n    return temp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef parse_sample(sample : pd.DataFrame,\n                 batch_no : int,\n                 window_size : List) -> pd.DataFrame:\n    \n    temp = feature_enginering_by_batch(sample['signal'].values, window_size)\n    temp['visual_batch'] = int(batch_no)\n    \n    return temp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \ndef sample_gen(df : pd.DataFrame,\n               window_size : List,\n               batches : List=[0], ) -> pd.DataFrame:\n    \n    result = Parallel(n_jobs=1, temp_folder='/tmp', max_nbytes=None, backend='multiprocessing')(delayed(parse_sample)\n                                              (df[df['visual_batch']==i], int(i), window_size)\n                                                                                              for i in tqdm(batches))\n    data = [r.values for r in result]\n    data = np.vstack(data)\n    cols = result[0].columns\n    X = pd.DataFrame(data, columns=cols)\n    X = reduce_mem_usage(X, False)\n    X = X.sort_values('visual_batch')\n    \n    return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_feat_enginnering(df : pd.DataFrame,\n                         create_all_data_feats : bool,\n                         window_size : List,\n                         add_visual_batch : bool,\n                         is_train: Optional[bool]=None) -> pd.DataFrame:\n    \n    if add_visual_batching:\n        df = add_visual_batching(df, is_train)\n    if create_all_data_feats:\n        df = lag_with_pct_change(df, [1, 2, 3],  add_pct_change=True, add_pct_change_lag=True)\n    batches = df['visual_batch'].unique().tolist()\n    batch_feats=sample_gen(df, window_size=window_size, batches=batches)\n    df = pd.merge(df, batch_feats, on='visual_batch', how='left')\n    df = reduce_mem_usage(df, False)\n    \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_selection(df : pd.DataFrame,\n                      df_test : pd.DataFrame,\n                      subtract_only : Optional[bool]=True,\n                      idx_cols : List=['time'],\n                      target_col : List=['open_channels']) -> Tuple[pd.DataFrame , pd.DataFrame]:\n    \n    drops = df.columns[df.isna().sum()>25000]\n    df = df.drop(drops, axis=1)\n    df_test = df_test.drop(drops, axis=1)\n  \n    gc.collect()\n    if subtract_only == False:\n        corrcoef_cols = [col for col in df.columns.tolist() if col not in (idx_cols+target_col)]\n        first=dict(); second=dict(); third=dict()\n        for col in corrcoef_cols:\n            ss = np.corrcoef(df[col], df['open_channels'])[0, 1]\n            first[col] = ss\n            ss = np.corrcoef(df[col]-df['signal'], df['open_channels'])[0, 1]\n            second[col] = ss\n            ss = np.corrcoef(df[col]*df['signal'], df['open_channels'])[0, 1]\n            third[col] = ss\n        corr_df = pd.DataFrame.from_dict(\n            {\n            'Base':first, \n            'Signal-Subtracted': second,\n            'Signal-Multiplied': third\n            }\n        ).fillna(0).apply(np.abs).sort_values('Base', ascending=False)\n\n        base_cols = corr_df.sort_values('Base', ascending=False).head(100).index.tolist()\n        multiply_cols = corr_df.sort_values('Signal-Multiplied', ascending=False).head(10).index.tolist()\n        subtract_cols = corr_df.sort_values('Signal-Subtracted', ascending=False).head(25).index.tolist()\n        display(corr_df.sort_values('Base', ascending=False).tail(50))\n        all_cols = list(set(base_cols + multiply_cols + subtract_cols + idx_cols + target_col))\n        all_cols_test = list(set(base_cols + multiply_cols + subtract_cols + idx_cols))   \n        drops = list(set(multiply_cols + subtract_cols)-set(base_cols))\n        df = df[all_cols]\n        df_test = df_test[all_cols_test]\n    \n        for col in multiply_cols:\n            df[col+'_m'] = df[col] * df['signal']\n            df_test[col+'_m'] = df_test[col] * df_test['signal']        \n        for col in subtract_cols:\n            df[col+'_s'] = df[col] - df['signal']\n            df_test[col+'_s'] = df_test[col] - df_test['signal']\n        df = df.drop(drops, axis=1)\n    else:\n        not_imp = ['kstat_4', 'moment_4','signal','baseline']\n        subtract_cols = list(set(df.columns.tolist())-set(idx_cols + target_col + not_imp))\n        for col in subtract_cols:\n            df[col+'_s'] = df[col] - df['signal']\n            df_test[col+'_s'] = df_test[col] - df_test['signal']\n            df[col+'_b'] = df[col] - df['baseline']\n            df_test[col+'_b'] = df_test[col] - df_test['baseline']\n    \n    df = df.replace([np.inf, -np.inf], np.nan)\n    df = df.fillna(-1)\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    df_test = df_test.fillna(-1) \n    df = reduce_mem_usage(df, False)\n    df_test = reduce_mem_usage(df_test, False)\n    gc.collect()\n    return df, df_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MacroF1Metric(preds : np.array, dtrain : lgb.Dataset) -> Tuple[Text, np.array, bool] :\n    \n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = f1_score(labels, preds, average = 'macro')\n    \n    return ('MacroF1Metric', score, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_params(seed : int) -> Dict :\n    params = dict()\n    params['learning_rate']=0.1;\n    params['max_depth']=-1;\n    params['num_leaves']=128;\n    params['metric']='l1';\n    params['random_state']=seed;\n    params['n_jobs']=-1;\n    params['feature_fraction']=1 ;\n    params['boosting']='gbdt';\n    params['bagging_seed']=seed;\n    params['bagging_freq']=5;\n    params['bagging_fraction']=0.8;\n    params['reg_alpha']=0.1;\n    params['reg_lambda']=0.3\n    return params\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_cv_model_by_batch(train : pd.DataFrame,\n                          test : pd.DataFrame,\n                          splits : int,\n                          shuffle : bool,\n                          seed : int,\n                          params : Dict,\n                          feats : List,\n                          sample_submission: pd.DataFrame) -> pd.DataFrame:\n    \n    oof_ = np.zeros(len(train))\n    preds_ = np.zeros(len(test))\n    target = ['open_channels']\n    imp_df = pd.DataFrame(index=feats)\n    groups = np.tile(np.arange(splits).repeat(500000 // splits), 10)\n    kf = GroupKFold(n_splits=splits)\n    for n_fold, (tr_idx, val_idx) in enumerate(kf.split(train, train[target], groups=groups)):\n        trn_data = lgb.Dataset(train[feats].iloc[tr_idx], label=train[target].iloc[tr_idx])\n        val_data = lgb.Dataset(train[feats].iloc[val_idx], label=train[target].iloc[val_idx])\n        \n        model = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=0 , early_stopping_rounds = 50)\n        oof_[val_idx] += model.predict(train[feats].iloc[val_idx], num_iteration=model.best_iteration)\n        preds_ += model.predict(test[feats], num_iteration=model.best_iteration) / SPLITS\n        f1_score_ = f1_score(train[target].iloc[val_idx], np.round(np.clip(oof_[val_idx], 0, 10)).astype(int), average = 'macro')\n        rmse_score_ = np.sqrt(mean_squared_error(train[target].iloc[val_idx], oof_[val_idx]))\n        logger.info(f'Fold {n_fold + 1} macro f1 score : {f1_score_ :1.5f} rmse score : {rmse_score_:1.5f}')\n        imp_df[f'feat_importance_{n_fold + 1}'] = model.feature_importance(importance_type='gain')\n    f1_score_ = f1_score(train[target], np.round(np.clip(oof_, 0, 10)).astype(int), average = 'macro')\n    rmse_score_ = np.sqrt(mean_squared_error(train[target], oof_))\n    logger.info(f'OOF macro f1 score : {f1_score_:1.5f} oof rmse score : {rmse_score_:1.5f}')\n    sample_submission['open_channels'] = np.round(np.clip(preds_, 0, 10)).astype(int)\n    sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')\n    display(sample_submission.head())\n    np.save('oof.npy', oof_)\n    np.save('preds.npy', preds_)\n\n    return imp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_everything(fe_config : List) -> NoReturn:\n    idx_cols = ['time','batch','batch_idx','visual_batch']\n    target_col = ['open_channels']\n    type_col = ['visual_type']\n    init_logger()\n    with timer(f'Reading Data'):\n        logger.info('Reading Data Started ...')\n        train, test, sample_submission = read_data()\n        logger.info('Reading and Cleaning Data Completed ...')\n        \n    with timer(f'Creating Features'):\n        logger.info('Feature Enginnering Started ...')\n        for config in fe_config:\n            train = run_feat_enginnering(train, create_all_data_feats=config[0], window_size=config[1], add_visual_batch=config[2], is_train=config[3])\n            test  = run_feat_enginnering(test,  create_all_data_feats=config[0], window_size=config[1], add_visual_batch=config[2], is_train=config[4])\n        if SELECT:\n            train, test = feature_selection(train, test, subtract_only=True, idx_cols=idx_cols+type_col, target_col=target_col)\n        logger.info('Feature Enginnering Completed ...')\n\n    with timer(f'Running LGB model'):\n        logger.info(f'Training LGB model with {SPLITS} folds Started ...')\n        params = get_params(SEED)\n        feats = [c for c in train.columns if c not in (idx_cols+target_col)]\n        imp = run_cv_model_by_batch(train, test, splits=SPLITS, shuffle=True, seed=SEED ,params=params, feats=feats, sample_submission=sample_submission)\n        logger.info(f'Training completed ...')\n    \n    return imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp = run_everything(fe_config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"04f79e2e2ab1459aa571b1487b00d494":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb134753d684aa090836dc6ee1888f5","placeholder":"​","style":"IPY_MODEL_c6c8efedc2c84ba2b25eba51122f3f0f","value":" 40/40 [00:06&lt;00:00,  6.30it/s]"}},"0bafeb618242429ca809c0818c052191":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8661f2b5b52c4657a785a514e147c05f","placeholder":"​","style":"IPY_MODEL_e6e437580d9c435ca4b7d2e246603665","value":" 100/100 [00:21&lt;00:00,  4.57it/s]"}},"0fcc50d19bcd4c769e356f60a823638c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95ede86745a64a009c45a4016f6713ec","IPY_MODEL_b5c45f4701f7423dbe3807be35a5c7e8"],"layout":"IPY_MODEL_76f92a18e77b4fbcabfeb7cad5da77a1"}},"14964cdad2974cc989f20df553a70460":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cb134753d684aa090836dc6ee1888f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f9ea5c9ea004252bca38f83ed1421bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d78cf9e8d5344a893f8240651e48c1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_9adc5bdc8a1d4ad6b3420beeda100389","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf16200a001d49f5a0734b7f3b559ad5","value":40}},"3ea07a54302b4bc68f9112fb031f53a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a1e3338784a4b45b8f644653caea054":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77d2a44b4d2a4071ac5c2ef65ba18825","IPY_MODEL_8bf7b7096da444bfb08cf497a9b6458b"],"layout":"IPY_MODEL_99389ddc64764d4c90070d694453a441"}},"67887f1b3af54f1c98378ec216ec285b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"7491faee1cf742bcb60d651602cda0bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"76f92a18e77b4fbcabfeb7cad5da77a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7750454fad0c4a3abe42abcbf1a8ff7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d78cf9e8d5344a893f8240651e48c1e","IPY_MODEL_04f79e2e2ab1459aa571b1487b00d494"],"layout":"IPY_MODEL_2f9ea5c9ea004252bca38f83ed1421bd"}},"77d2a44b4d2a4071ac5c2ef65ba18825":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_f477232073a9446daeffc3db5c0c29b7","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7491faee1cf742bcb60d651602cda0bb","value":1000}},"7b92c09a61fd4d039a286bf199a2d52a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8661f2b5b52c4657a785a514e147c05f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89f584d2b5a645049700394348d51701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e38665e28f1c4465b367f0407e128e30","IPY_MODEL_0bafeb618242429ca809c0818c052191"],"layout":"IPY_MODEL_9032157081124667b6dfe610612f43d5"}},"8bf7b7096da444bfb08cf497a9b6458b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b92c09a61fd4d039a286bf199a2d52a","placeholder":"​","style":"IPY_MODEL_14964cdad2974cc989f20df553a70460","value":" 1000/1000 [01:09&lt;00:00, 14.31it/s]"}},"9032157081124667b6dfe610612f43d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"925de34801004b30906038d186791fe0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"95ede86745a64a009c45a4016f6713ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_9766f1e0d89948659e6a7b9ef8d188ef","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_925de34801004b30906038d186791fe0","value":400}},"9766f1e0d89948659e6a7b9ef8d188ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99389ddc64764d4c90070d694453a441":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9adc5bdc8a1d4ad6b3420beeda100389":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c45f4701f7423dbe3807be35a5c7e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7048d826931422d9ed4794ea5464014","placeholder":"​","style":"IPY_MODEL_3ea07a54302b4bc68f9112fb031f53a5","value":" 400/400 [00:32&lt;00:00, 12.13it/s]"}},"bdd4ba7e206a4601a294a901850018b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6c8efedc2c84ba2b25eba51122f3f0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf16200a001d49f5a0734b7f3b559ad5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"e38665e28f1c4465b367f0407e128e30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_bdd4ba7e206a4601a294a901850018b7","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67887f1b3af54f1c98378ec216ec285b","value":100}},"e6e437580d9c435ca4b7d2e246603665":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f477232073a9446daeffc3db5c0c29b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7048d826931422d9ed4794ea5464014":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}