{"cells":[{"metadata":{},"cell_type":"markdown","source":"The validation scheme is based on [ion-switching-5kfold-lgbm-tracking](https://www.kaggle.com/robikscube/ion-switching-5kfold-lgbm-tracking), the selected features are based on [physically-possible](https://www.kaggle.com/jazivxt/physically-possible) and some parts are borrowed from [1-geomean-nn-and-6featlgbm-2-259-private-lb](https://www.kaggle.com/dkaraflos/1-geomean-nn-and-6featlgbm-2-259-private-lb) and cleaned data is from [data-without-drift](https://www.kaggle.com/cdeotte/data-without-drift)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{},"colab_type":"code","id":"y1qOuodBfSxN","trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import (BatchNormalization, Flatten, Convolution1D, Activation, Input, Dense, LSTM, Lambda, Bidirectional, GRU)\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, ReduceLROnPlateau, LearningRateScheduler\nfrom tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom tensorflow.keras.utils import Sequence, to_categorical\nfrom tensorflow.keras import losses, models, optimizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import losses\nimport tensorflow as tf\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.metrics import f1_score, cohen_kappa_score, mean_squared_error\nfrom logging import getLogger, Formatter, StreamHandler, FileHandler, INFO\nfrom scipy.signal import butter, lfilter, filtfilt, savgol_filter, detrend\nfrom sklearn.model_selection import KFold, train_test_split\nfrom scipy.stats import pearsonr, spearmanr, kendalltau\nfrom sklearn.linear_model import LinearRegression\nfrom tqdm import tqdm_notebook as tqdm\nfrom contextlib import contextmanager\nfrom joblib import Parallel, delayed\nfrom IPython.display import display\nfrom sklearn import preprocessing\nimport scipy.stats as stats\nimport random as rn\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport itertools\nimport warnings\nimport time\nimport pywt\nimport os\nimport gc\n\n\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"UafJMtyefSxU","trusted":true},"cell_type":"code","source":"EPOCHS=30\nNNBATCHSIZE=2000\nBATCHSIZE = 50000\nSEED = 529\nSELECT = True\nSPLITS = 5\nLR = 0.01\nfe_config = [\n    (True, True, 50000, None),\n    (False, False, 5000, None),\n]","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"EE4v8h1tfSxb","trusted":true},"cell_type":"code","source":"\ndef init_logger():\n    handler = StreamHandler()\n    handler.setLevel(INFO)\n    handler.setFormatter(Formatter(LOGFORMAT))\n    fh_handler = FileHandler('{}.log'.format(MODELNAME))\n    fh_handler.setFormatter(Formatter(LOGFORMAT))\n    logger.setLevel(INFO)\n    logger.addHandler(handler)\n    logger.addHandler(fh_handler)\n    ","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"7nxcdN_5fSxo","trusted":true},"cell_type":"code","source":"\n@contextmanager\ndef timer(name : Text):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\nCOMPETITION = 'ION-Switching'\nlogger = getLogger(COMPETITION)\nLOGFORMAT = '%(asctime)s %(levelname)s %(message)s'\nMODELNAME = 'Baseline'\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"OC5DOcDifSxx","trusted":true},"cell_type":"code","source":"\ndef seed_everything(seed : int) -> NoReturn :\n    \n    rn.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"adUHGQUTfSyA","trusted":true},"cell_type":"code","source":"\ndef read_data(base : os.path.abspath) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n    \n    train = pd.read_csv('../input/data-without-drift/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int8})\n    test  = pd.read_csv('../input/data-without-drift/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\n    sub  = pd.read_csv(os.path.join(base + '/sample_submission.csv'), dtype={'time': np.float32})\n    \n    return train, test, sub\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"HpDaJQ5yfSyI","trusted":true},"cell_type":"code","source":"\ndef batching(df : pd.DataFrame,\n             batch_size : int,\n             add_index : Optional[bool]=True) -> pd.DataFrame :\n    \n    df['batch_'+ str(batch_size)] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values + 1\n    df['batch_'+ str(batch_size)] = df['batch_'+ str(batch_size)].astype(np.uint16)\n    if add_index:\n        df['batch_' + str(batch_size) +'_idx'] = df.index  - (df['batch_'+ str(batch_size)] * batch_size)\n        df['batch_' + str(batch_size) +'_idx'] = df['batch_' + str(batch_size) +'_idx'].astype(np.uint16)\n        \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"Bny_y6aPfSyU","trusted":true},"cell_type":"code","source":"def normalize(X_train, X_valid, X_test, normalize_opt, excluded_feat):\n    feats = [f for f in X_train.columns if f not in excluded_feat]\n    if normalize_opt != None:\n        if normalize_opt == 'min_max':\n            scaler = preprocessing.MinMaxScaler()\n        elif normalize_opt == 'robust':\n            scaler = preprocessing.RobustScaler()\n        elif normalize_opt == 'standard':\n            scaler = preprocessing.StandardScaler()\n        elif normalize_opt == 'max_abs':\n            scaler = preprocessing.MaxAbsScaler()\n        scaler = scaler.fit(X_train[feats])\n        X_train[feats] = scaler.transform(X_train[feats])\n        X_valid[feats] = scaler.transform(X_valid[feats])\n        X_test[feats] = scaler.transform(X_test[feats])\n    return X_train, X_valid, X_test","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"iQxOYF3tfSyj","trusted":true},"cell_type":"code","source":"\ndef reduce_mem_usage(df: pd.DataFrame,\n                     verbose: bool = True) -> pd.DataFrame:\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if (c_min > np.iinfo(np.int8).min\n                        and c_max < np.iinfo(np.int8).max):\n                    df[col] = df[col].astype(np.int8)\n                elif (c_min > np.iinfo(np.int16).min\n                      and c_max < np.iinfo(np.int16).max):\n                    df[col] = df[col].astype(np.int16)\n                elif (c_min > np.iinfo(np.int32).min\n                      and c_max < np.iinfo(np.int32).max):\n                    df[col] = df[col].astype(np.int32)\n                elif (c_min > np.iinfo(np.int64).min\n                      and c_max < np.iinfo(np.int64).max):\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (c_min > np.finfo(np.float16).min\n                        and c_max < np.finfo(np.float16).max):\n                    df[col] = df[col].astype(np.float16)\n                elif (c_min > np.finfo(np.float32).min\n                      and c_max < np.finfo(np.float32).max):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    reduction = (start_mem - end_mem) / start_mem\n\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n    if verbose:\n        print(msg)\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"dytmNmL_fSzj","trusted":true},"cell_type":"code","source":"\ndef lag_with_pct_change(df : pd.DataFrame,\n                        batch_size : int,\n                        shift_sizes : Optional[List]=[1, 2, 3, 4],\n                        add_pct_change : Optional[bool]=False,\n                        add_pct_change_lag : Optional[bool]=False) -> pd.DataFrame:\n    \n    assert 'batch_' + str(batch_size) +'_idx' in df.columns\n    for shift_size in shift_sizes:    \n        df['signal_shift_pos_'+str(shift_size)] = df['signal'].shift(shift_size).fillna(0)\n        df['signal_shift_neg_'+str(shift_size)] = df['signal'].shift(-1*shift_size).fillna(0)\n        for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(shift_size))].index:\n            df['signal_shift_pos_'+str(shift_size)][i] = np.nan\n        for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(batch_size - shift_size, batch_size))].index:\n            df['signal_shift_neg_'+str(shift_size)][i] = np.nan\n    if add_pct_change:\n        df['pct_change'] = df['signal'].pct_change()\n        if add_pct_change_lag:\n            df['pct_change_shift_pos_'+str(shift_size)] = df['pct_change'].shift(shift_size).fillna(0)\n            df['pct_change_shift_neg_'+str(shift_size)] = df['pct_change'].shift(-1*shift_size).fillna(0)\n            for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(shift_size))].index:\n                df['pct_change_shift_pos_'+str(shift_size)][i] = np.nan\n            for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(batch_size - shift_size, batch_size))].index:\n                df['pct_change_shift_neg_'+str(shift_size)][i] = np.nan \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"HSi0xhuKfSzp","trusted":true},"cell_type":"code","source":"\ndef feature_enginering_by_batch(z : Union[pd.Series, np.array],\n                                batch_size : int,\n                                window_size : Optional[List]=None) -> pd.DataFrame:\n    \n    temp = pd.DataFrame(index=[0], dtype=np.float16)\n    \n    temp['mean'] = z.mean()\n    temp['max'] = z.max()\n    temp['min'] = z.min()\n    temp['std'] = z.std()  \n    temp['mean_abs_chg'] = np.mean(np.abs(np.diff(z)))\n    temp['abs_max'] = np.max(np.abs(z))\n    temp['abs_min'] = np.min(np.abs(z))\n    temp['range'] = temp['max'] - temp['min']\n    temp['max_to_min'] = temp['max'] / temp['min']\n    temp['abs_avg'] = (temp['abs_max'] + temp['abs_min']) / 2\n    \n    for i in range(2, 5):\n        temp[f'moment_{i}'] = stats.moment(z, i)\n\n    for i in [1, 2]:\n        temp[f'kstatvar_{i}'] = stats.kstatvar(z, i)\n               \n    return temp\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"3aWvQjzpfSzw","trusted":true},"cell_type":"code","source":"\ndef parse_sample(sample : pd.DataFrame,\n                 batch_no : int,\n                 batch_size : int,\n                 window_size : List) -> pd.DataFrame:\n    \n    temp = feature_enginering_by_batch(sample['signal'].values, batch_size, window_size)\n    temp['batch_'+ str(batch_size)] = int(batch_no)\n    \n    return temp\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"9CVpMQqAfSz4","trusted":true},"cell_type":"code","source":"    \ndef sample_gen(df : pd.DataFrame,\n               batch_size : int,\n               window_size : List,\n               batches : List=[0], ) -> pd.DataFrame:\n    \n        result = Parallel(n_jobs=1, temp_folder='/tmp', max_nbytes=None, backend='multiprocessing')(delayed(parse_sample)\n                                              (df[df['batch_'+ str(batch_size)]==i], int(i), batch_size, window_size)\n                                                                                              for i in tqdm(batches))\n        data = [r.values for r in result]\n        data = np.vstack(data)\n        cols = result[0].columns\n        cols = [name+'_'+str(batch_size) if name!='batch_'+ str(batch_size) else 'batch_'+ str(batch_size) for name in cols ]\n        X = pd.DataFrame(data, columns=cols)\n        X = reduce_mem_usage(X, False)\n        X = X.sort_values('batch_'+ str(batch_size))\n    \n        return X\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"m-ULWLF_fS0B","trusted":true},"cell_type":"code","source":"\ndef run_feat_enginnering(df : pd.DataFrame,\n                         create_all_data_feats : bool,\n                         add_index : bool,\n                         batch_size : int,\n                         window_size : List) -> pd.DataFrame:\n    \n    df = batching(df, batch_size=batch_size, add_index=add_index)\n    if create_all_data_feats:\n        df = lag_with_pct_change(df, batch_size, [1, 2, 3, 4],  add_pct_change=True, add_pct_change_lag=True)\n    batches = df['batch_'+ str(batch_size)].unique().tolist()\n    batch_feats=sample_gen(df, batch_size=batch_size, window_size=window_size, batches=batches)\n    df = pd.merge(df, batch_feats, on='batch_'+ str(batch_size), how='left')\n    df = reduce_mem_usage(df, False)\n    \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"6E87jcu2fS0O","trusted":true},"cell_type":"code","source":"def feature_selection(df : pd.DataFrame,\n                      df_test : pd.DataFrame,\n                      subtract_only : Optional[bool]=True,\n                      idx_cols : List=['time'],\n                      target_col : List=['open_channels']) -> Tuple[pd.DataFrame , pd.DataFrame]:\n    \n    drops = df.columns[df.isna().sum()>25000]\n    df = df.drop(drops, axis=1)\n    df = df.replace([np.inf, -np.inf], np.nan)\n    df = df.fillna(0)\n    df_test = df_test.drop(drops, axis=1)\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    df_test = df_test.fillna(0)\n    gc.collect()\n    df = reduce_mem_usage(df, False)\n    df_test = reduce_mem_usage(df_test, False)\n\n    gc.collect()\n    return df, df_test\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"e4QulGxHfS0n","trusted":true},"cell_type":"code","source":"\ndef run_cv_model_by_batch(train : pd.DataFrame,\n                          test : pd.DataFrame,\n                          splits : int,\n                          shuffle : bool,\n                          seed : int,\n                          batch_col : Text,\n                          feats : List,\n                          sample_submission: pd.DataFrame,\n                          nn_epochs : int,\n                          nn_batch_size : int) -> NoReturn:\n    \n    oof_ = np.zeros(len(train))\n    preds_ = np.zeros(len(test))\n    target = 'open_channels'\n    kf = KFold(splits, shuffle, seed)\n    for n_fold, (tr_idx, val_idx) in enumerate(kf.split(train, train[target], groups=train[batch_col])):\n        train_x, train_y = train[feats].iloc[tr_idx], train[target].iloc[tr_idx].values\n        valid_x, valid_y = train[feats].iloc[val_idx], train[target].iloc[val_idx].values\n        train_x,valid_x,test_scaled=normalize(train_x.copy(), valid_x.copy(), test[feats].copy(), 'min_max', [])\n        train_x=train_x.values.reshape(train_x.shape[0],1,train_x.shape[1])\n        valid_x=valid_x.values.reshape(valid_x.shape[0],1,valid_x.shape[1])\n        test_scaled=test_scaled.values.reshape(test_scaled.shape[0],1,test_scaled.shape[1])\n        gc.collect()\n        K.clear_session()\n        shape_ = train[feats].shape[1]\n        model = Regressor(shape_)\n        cb_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n        cb_Early_Stop=EarlyStopping(monitor='val_loss',patience=3)\n        model.fit(train_x,train_y,\n                  epochs=nn_epochs,\n                  callbacks=[cb_schedule, cb_Early_Stop, MacroF1(model, valid_x,valid_y)],\n                  batch_size=nn_batch_size,verbose=0,\n                  validation_data=(valid_x,valid_y))\n        preds_f = model.predict(valid_x).ravel()\n        oof_[val_idx] += preds_f\n        preds_ += model.predict(test_scaled).ravel() / SPLITS\n        f1_score_ = f1_score(valid_y,  np.round(np.clip(preds_f, 0, 10)).astype(int), average = 'macro')\n        rmse_score_ = np.sqrt(mean_squared_error(valid_y, preds_f))\n        logger.info(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f} rmse score : {rmse_score_:1.5f}')\n    f1_score_ = f1_score(train[target], np.round(np.clip(oof_, 0, 10)).astype(int), average = 'macro')\n    rmse_score_ = np.sqrt(mean_squared_error(train[target], oof_))\n    logger.info(f'Training completed. oof macro f1 score : {f1_score_:1.5f} oof rmse score : {rmse_score_:1.5f}')\n    sample_submission['open_channels'] = np.round(np.clip(preds_, 0, 10)).astype(int)\n    sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')\n    display(sample_submission.head())\n    np.save('oof.npy', oof_)\n    np.save('preds.npy', preds_)\n\n    return \n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"YjRTgJjufS0t","trusted":true},"cell_type":"code","source":"def Regressor(shape_):\n\n    inp = Input(shape=(1,shape_))\n    x = BatchNormalization()(inp)\n    x = Bidirectional(GRU(128,return_sequences=True))(x)\n    x = Bidirectional(GRU(128,return_sequences=False))(x)\n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)  \n    x = Dense(64,  activation='relu')(x)\n    x = Dense(64,  activation='relu')(x)   \n\n    out = Dense(1, name='out')(x)\n    \n    model = models.Model(inputs=inp, outputs=out)    \n    opt = Adam(lr=LR)\n    model.compile(loss=losses.mean_squared_error, optimizer=opt, metrics=['mse'])\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MacroF1(Callback):\n    def __init__(self, model, X_val, y_val):\n        super().__init__()\n        self.model = model\n        self.X = X_val\n        self.y = y_val.reshape(-1)\n    def on_epoch_end(self, epoch, logs=None):\n        pred = np.round(np.clip((self.model.predict(self.X, batch_size=64).ravel()), 0, 10)).astype(int)\n        score = f1_score(self.y, pred, average='macro')       \n        print(f' F1Macro: {score:.5f}')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"02TDJtejfS0_","trusted":true},"cell_type":"code","source":"\ndef run_everything(fe_config : List) -> NoReturn:\n    not_feats_cols = ['time']\n    target_col = ['open_channels']\n    init_logger()\n    with timer(f'Reading Data'):\n        logger.info('Reading Data Started ...')\n        base = os.path.abspath('/kaggle/input/liverpool-ion-switching/')\n        train, test, sample_submission = read_data(base)\n        logger.info('Reading Data Completed ...')\n        \n    with timer(f'Creating Features'):\n        logger.info('Feature Enginnering Started ...')\n        for config in fe_config:\n            train = run_feat_enginnering(train, create_all_data_feats=config[0], add_index=config[1], batch_size=config[2], window_size=config[3])\n            test  = run_feat_enginnering(test,  create_all_data_feats=config[0], add_index=config[1], batch_size=config[2], window_size=config[3])\n            not_feats_cols.append('batch_'+str(config[2]))\n            if config[1]:\n                not_feats_cols.append('batch_'+str(config[2])+'_idx')\n        if SELECT:\n            train, test = feature_selection(train, test, subtract_only=True, idx_cols=not_feats_cols, target_col=target_col)\n        logger.info('Feature Enginnering Completed ...')\n\n    with timer(f'Running NN model'):\n        logger.info(f'Training NN model with {SPLITS} folds Started ...')\n        feats = [c for c in train.columns if c not in (not_feats_cols+target_col)]\n        run_cv_model_by_batch(train, test, splits=SPLITS, shuffle=True, seed=SEED, batch_col='batch_50000', feats=feats, sample_submission=sample_submission, nn_epochs=EPOCHS, nn_batch_size=NNBATCHSIZE)\n        logger.info(f'Training completed ...')\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417,"referenced_widgets":["383530742df04345b8c40a24da72f2cc","3c4c9afd1e444390a0a8493405e79e60","be68378ad1d3445dababfddfab8db8bf","ef6c30034951411988864f0109d067f7","a80e1d28016e4d88bf97d4c0cb99b6cd","c427e3e973c84382ad5824cd3e6c10b8","f16859eeb47b45fdb50bb6e84c237048","986accfcfe16463489b194ae56e49e42","0f3595fdb94c4b8694e707f19947c4db","0b002fd7517645ffae15afd6e10124f2","b4b8fde85a5b4d4fb5e3e991417cf372","6160917278284f858c8eeec79a608be7","13766cb9b3264dcc966ce9aac18f3cc7","048c17934e0d4eae8eb7b0fbb1cfd4f7","97a8d8dc930445a08e97e0a1c55a8a70","11c74280e80d41c48858c2b6db9566be","bb9eac4fe34d4ff5a2b8871044d5254a","3a2cab8fbead41e3859a7768cadb8b72","d7f5da65fa2f40e7a58336f41ed9a4ca","8621a0e99a7c4827900524e37332c310","45312895e2ab4583a546dbf1bc74e57c","a2327055cc1440bcbed7cb0428c5fc86","49d9a1acb6eb4edfbeb2323d360d8560","be7c55d0c5bd462bab584d409e7cdf8d","50b82af4203247bcbd079ee9a54d54de","5caa4a1b4b824321a659a9d8e4ca060b","eff84033b739410ab8382cbf0b6aba5b","45cfe8409dbf4e279ec71cf47575e3df","b784f711f8584d16b9428d02eaf7c9c3","6e5abe7bad4b4c2d85bb129ed827e1ff","968fb288eda24bcaa91a695944be7c19","407faaa9f11c41a784fe75c9781459bf"]},"colab_type":"code","id":"_w4_OJJtfS1K","outputId":"b9dfce2c-c355-431e-e28f-943a4c840d6c","trusted":true},"cell_type":"code","source":"run_everything(fe_config)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"KURo6D4nfS1R","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"SRrBeBk5fS1a","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"kernelea82b0c7b9.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"04fec6fd1a97476d831768783e040ba4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86d27992627743588e2a25b9adc2cdcd","placeholder":"​","style":"IPY_MODEL_77b27c841cfd4e55abc7417975eec75f","value":" 40/40 [00:06&lt;00:00,  6.60it/s]"}},"0ce4e768d47a4cbdb5ca7d3edde102d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"117242a80eed488eade96073056df15e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"137624ebf66f4e3bb9fb38467f2d3f38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1e5afa37e794a1db17cd162b82718d2","IPY_MODEL_8a3079996ebf4e45834d087c90897ad6"],"layout":"IPY_MODEL_cd3fcb8c7f474fb2814270a6e92d3491"}},"1820796d84cd46518996c32600760919":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3a90a9f4004e0191cb2374775c33e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_5b1e6a8fc25a4df6833a77cd4cf98061","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1dfa19c5aca4c31b3498356da170326","value":100}},"4d00877e39f5411b866e00194aa4a460":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5334765dc1d94474801f89f6006e0d41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1820796d84cd46518996c32600760919","placeholder":"​","style":"IPY_MODEL_d25ed28393db4f8eb730ececa1f1d802","value":" 400/400 [00:39&lt;00:00, 10.20it/s]"}},"5b1e6a8fc25a4df6833a77cd4cf98061":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6063f48aa9d940e2a6d394dcbf8bde72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa2a321d3dc7455b8fc3756bc472cd93","IPY_MODEL_5334765dc1d94474801f89f6006e0d41"],"layout":"IPY_MODEL_6805271430a04cc48041a1370d4ae4f0"}},"60a16e11a16945248e2c9cf67854a578":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9f1d7cf116b47ba8bc81cdf275b2f78","IPY_MODEL_04fec6fd1a97476d831768783e040ba4"],"layout":"IPY_MODEL_82066967864041c69ea07b8280221c5a"}},"6136f2ba3deb404caca14d3afbb031f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"6495cc79eaf94519aff78126e2926dee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"6805271430a04cc48041a1370d4ae4f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77b27c841cfd4e55abc7417975eec75f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82066967864041c69ea07b8280221c5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d27992627743588e2a25b9adc2cdcd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a3079996ebf4e45834d087c90897ad6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9134b40986644f32980a748cc3588bbb","placeholder":"​","style":"IPY_MODEL_f0fac547e0af4174a7c772039011bc7c","value":" 1000/1000 [01:14&lt;00:00, 13.35it/s]"}},"9001a31a6e8040ddbc71a6c2e542d0d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9134b40986644f32980a748cc3588bbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1dfa19c5aca4c31b3498356da170326":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"c418940097b44a4f84678cb28b09939f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8279014877744459111c4658a44e561":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"cd3fcb8c7f474fb2814270a6e92d3491":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d25ed28393db4f8eb730ececa1f1d802":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9f1d7cf116b47ba8bc81cdf275b2f78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_c418940097b44a4f84678cb28b09939f","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6136f2ba3deb404caca14d3afbb031f7","value":40}},"e1e5afa37e794a1db17cd162b82718d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_9001a31a6e8040ddbc71a6c2e542d0d4","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8279014877744459111c4658a44e561","value":1000}},"e8a1c7804447463fb295ffa527e22681":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd9189e54c0947649d811d02fdd3f99f","placeholder":"​","style":"IPY_MODEL_0ce4e768d47a4cbdb5ca7d3edde102d5","value":" 100/100 [00:24&lt;00:00,  4.04it/s]"}},"eb6be85827714a52a38e60047e1d1931":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e3a90a9f4004e0191cb2374775c33e0","IPY_MODEL_e8a1c7804447463fb295ffa527e22681"],"layout":"IPY_MODEL_4d00877e39f5411b866e00194aa4a460"}},"f0fac547e0af4174a7c772039011bc7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa2a321d3dc7455b8fc3756bc472cd93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_117242a80eed488eade96073056df15e","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6495cc79eaf94519aff78126e2926dee","value":400}},"fd9189e54c0947649d811d02fdd3f99f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}