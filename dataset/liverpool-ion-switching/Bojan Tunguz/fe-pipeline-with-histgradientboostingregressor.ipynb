{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a direct copy of the followign kernel, with LGBM replaced with HistGradientBoosting\n\nhttps://www.kaggle.com/siavrez/fe-pipeline"},{"metadata":{},"cell_type":"markdown","source":"Part of the Feature Engineering is from the following notebooks:\n\n[1-geomean-nn-and-6featlgbm-2-259-private-lb](https://www.kaggle.com/dkaraflos/1-geomean-nn-and-6featlgbm-2-259-private-lb) \n\n[physically-possible](https://www.kaggle.com/jazivxt/physically-possible)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\n\nfrom sklearn.metrics import f1_score, cohen_kappa_score, mean_squared_error\nfrom logging import getLogger, Formatter, StreamHandler, FileHandler, INFO\nfrom scipy.signal import butter, lfilter,filtfilt,savgol_filter\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tsfresh.feature_extraction import feature_calculators\n\nfrom scipy.stats import pearsonr, spearmanr, kendalltau\nfrom sklearn.linear_model import LinearRegression\nfrom pandas_profiling import ProfileReport\nfrom tqdm import tqdm_notebook as tqdm\nfrom contextlib import contextmanager\nfrom joblib import Parallel, delayed\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport lightgbm as lgb\nimport xgboost as xgb\nimport seaborn as sns\nimport random as rn\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport itertools\nimport warnings\nimport librosa\nimport time\nimport pywt\nimport os\nimport gc\n\n\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCHSIZE = 50000\nSEED = 529\nSELECT = True\nSPLITS = 5\nfe_config = [\n    (True, True, 50000, None),\n    (False, False, 5000, None),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef init_logger():\n    handler = StreamHandler()\n    handler.setLevel(INFO)\n    handler.setFormatter(Formatter(LOGFORMAT))\n    fh_handler = FileHandler('{}.log'.format(MODELNAME))\n    fh_handler.setFormatter(Formatter(LOGFORMAT))\n    logger.setLevel(INFO)\n    logger.addHandler(handler)\n    logger.addHandler(fh_handler)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n@contextmanager\ndef timer(name : Text):\n    t0 = time.time()\n    yield\n    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n\nCOMPETITION = 'ION-Switching'\nlogger = getLogger(COMPETITION)\nLOGFORMAT = '%(asctime)s %(levelname)s %(message)s'\nMODELNAME = 'Baseline'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef seed_everything(seed : int) -> NoReturn :\n    \n    rn.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef read_data(base : os.path.abspath) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n    \n    train = pd.read_csv(os.path.join(base + '/train.csv'), dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int8})\n    test  = pd.read_csv(os.path.join(base + '/test.csv'), dtype={'time': np.float32, 'signal': np.float32})\n    sub  = pd.read_csv(os.path.join(base + '/sample_submission.csv'), dtype={'time': np.float32})\n    \n    return train, test, sub\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef batching(df : pd.DataFrame,\n             batch_size : int,\n             add_index : Optional[bool]=True) -> pd.DataFrame :\n    \n    df['batch_'+ str(batch_size)] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values + 1\n    df['batch_'+ str(batch_size)] = df['batch_'+ str(batch_size)].astype(np.uint16)\n    if add_index:\n        df['batch_' + str(batch_size) +'_idx'] = df.index  - (df['batch_'+ str(batch_size)] * batch_size)\n        df['batch_' + str(batch_size) +'_idx'] = df['batch_' + str(batch_size) +'_idx'].astype(np.uint16)\n        \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef reduce_mem_usage(df: pd.DataFrame,\n                     verbose: bool = True) -> pd.DataFrame:\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if (c_min > np.iinfo(np.int8).min\n                        and c_max < np.iinfo(np.int8).max):\n                    df[col] = df[col].astype(np.int8)\n                elif (c_min > np.iinfo(np.int16).min\n                      and c_max < np.iinfo(np.int16).max):\n                    df[col] = df[col].astype(np.int16)\n                elif (c_min > np.iinfo(np.int32).min\n                      and c_max < np.iinfo(np.int32).max):\n                    df[col] = df[col].astype(np.int32)\n                elif (c_min > np.iinfo(np.int64).min\n                      and c_max < np.iinfo(np.int64).max):\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (c_min > np.finfo(np.float16).min\n                        and c_max < np.finfo(np.float16).max):\n                    df[col] = df[col].astype(np.float16)\n                elif (c_min > np.finfo(np.float32).min\n                      and c_max < np.finfo(np.float32).max):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    reduction = (start_mem - end_mem) / start_mem\n\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n    if verbose:\n        print(msg)\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef maddest(d : Union[np.array, pd.Series, List], axis : Optional[int]=None) -> np.array:  \n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef denoise_signal(x : Union[np.array, pd.Series],\n                   wavelet : Optional[Text]='db4',\n                   level : Optional[int]=1) -> np.array:\n    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    return pywt.waverec(coeff, wavelet, mode='per')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef denoise_signal_simple(x : Union[np.array, pd.Series],\n                          wavelet : Optional[Text]='db4',\n                          level : Optional[int]=1) -> np.array:\n    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    uthresh = 10\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    \n    return pywt.waverec(coeff, wavelet, mode='per')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef trend(df : Union[pd.Series, np.array],\n          abs_values: Optional[bool]=False) -> float:\n    \n    idx = np.array(range(len(df)))\n    if abs_values:\n        df = np.abs(df)\n    lr = LinearRegression()\n    lr.fit(idx.reshape(-1, 1), df)\n    \n    return lr.coef_[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef change_rate(df : Union[pd.Series, np.array]) -> float:\n    \n    change = (np.diff(df) / df[:-1])\n    change = change[np.nonzero(change)[0]]\n    change = change[~np.isnan(change)]\n    change = change[change != -np.inf]\n    change = change[change != np.inf]\n    \n    return np.mean(change)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef lag_with_pct_change(df : pd.DataFrame,\n                        batch_size : int,\n                        shift_sizes : Optional[List]=[1, 2],\n                        add_pct_change : Optional[bool]=False,\n                        add_pct_change_lag : Optional[bool]=False) -> pd.DataFrame:\n    \n    assert 'batch_' + str(batch_size) +'_idx' in df.columns\n    for shift_size in shift_sizes:    \n        df['signal_shift_pos_'+str(shift_size)] = df['signal'].shift(shift_size).fillna(0)\n        df['signal_shift_neg_'+str(shift_size)] = df['signal'].shift(-1*shift_size).fillna(0)\n        for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(shift_size))].index:\n            df['signal_shift_pos_'+str(shift_size)][i] = np.nan\n        for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(batch_size - shift_size, batch_size))].index:\n            df['signal_shift_neg_'+str(shift_size)][i] = np.nan\n    if add_pct_change:\n        df['pct_change'] = df['signal'].pct_change()\n        if add_pct_change_lag:\n            df['pct_change_shift_pos_'+str(shift_size)] = df['pct_change'].shift(shift_size).fillna(0)\n            df['pct_change_shift_neg_'+str(shift_size)] = df['pct_change'].shift(-1*shift_size).fillna(0)\n            for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(shift_size))].index:\n                df['pct_change_shift_pos_'+str(shift_size)][i] = np.nan\n            for i in df[df['batch_' + str(batch_size) +'_idx'].isin(range(batch_size - shift_size, batch_size))].index:\n                df['pct_change_shift_neg_'+str(shift_size)][i] = np.nan \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef feature_enginering_by_batch(z : Union[pd.Series, np.array],\n                                batch_size : int,\n                                window_size : Optional[List]=None) -> pd.DataFrame:\n    \n    temp = pd.DataFrame(index=[0], dtype=np.float16)\n    \n    temp['mean'] = z.mean()\n    temp['max'] = z.max()\n    temp['min'] = z.min()\n    temp['std'] = z.std()  \n    temp['mean_abs_chg'] = np.mean(np.abs(np.diff(z)))\n    temp['abs_max'] = np.max(np.abs(z))\n    temp['abs_min'] = np.min(np.abs(z))\n    temp['range'] = temp['max'] - temp['min']\n    temp['max_to_min'] = temp['max'] / temp['min']\n    temp['abs_avg'] = (temp['abs_max'] + temp['abs_min']) / 2\n    \n    for i in range(1, 5): \n        temp[f'kstat_{i}'] = stats.kstat(z, i)\n\n    for i in range(2, 5):\n        temp[f'moment_{i}'] = stats.moment(z, i)\n\n    for i in [1, 2]:\n        temp[f'kstatvar_{i}'] = stats.kstatvar(z, i)\n    \n    if window_size is not None:\n        for window in window_size:\n            temp['percentile_roll_'+str(window)+'_std_25'] = np.percentile(pd.Series(z).rolling(window).std().dropna().values, 25)\n            temp['percentile_roll_'+str(window)+'_std_75'] = np.percentile(pd.Series(z).rolling(window).std().dropna().values, 75)\n            temp['percentile_roll_'+str(window)+'_std_05'] = np.percentile(pd.Series(z).rolling(window).std().dropna().values,  5)\n            temp['percentile_roll_'+str(window)+'_std_95'] = np.percentile(pd.Series(z).rolling(window).std().dropna().values, 95)\n            temp['percentile_roll_'+str(window)+'_mean_25'] = np.percentile(pd.Series(z).rolling(window).mean().dropna().values, 25)\n            temp['percentile_roll_'+str(window)+'_mean_75'] = np.percentile(pd.Series(z).rolling(window).mean().dropna().values, 75)\n            temp['percentile_roll_'+str(window)+'_mean_05'] = np.percentile(pd.Series(z).rolling(window).mean().dropna().values,  5)\n            temp['percentile_roll_'+str(window)+'_mean_95'] = np.percentile(pd.Series(z).rolling(window).mean().dropna().values, 95)            \n    return temp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef parse_sample(sample : pd.DataFrame,\n                 batch_no : int,\n                 batch_size : int,\n                 window_size : List) -> pd.DataFrame:\n    \n    temp = feature_enginering_by_batch(sample['signal'].values, batch_size, window_size)\n    temp['batch_'+ str(batch_size)] = int(batch_no)\n    \n    return temp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \ndef sample_gen(df : pd.DataFrame,\n               batch_size : int,\n               window_size : List,\n               batches : List=[0], ) -> pd.DataFrame:\n    \n    result = Parallel(n_jobs=1, temp_folder='/tmp', max_nbytes=None, backend='multiprocessing')(delayed(parse_sample)\n                                              (df[df['batch_'+ str(batch_size)]==i], int(i), batch_size, window_size)\n                                                                                              for i in tqdm(batches))\n    data = [r.values for r in result]\n    data = np.vstack(data)\n    cols = result[0].columns\n    cols = [name+'_'+str(batch_size) if name!='batch_'+ str(batch_size) else 'batch_'+ str(batch_size) for name in cols ]\n    X = pd.DataFrame(data, columns=cols)\n    X = reduce_mem_usage(X, False)\n    X = X.sort_values('batch_'+ str(batch_size))\n    \n    return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_feat_enginnering(df : pd.DataFrame,\n                         create_all_data_feats : bool,\n                         add_index : bool,\n                         batch_size : int,\n                         window_size : List) -> pd.DataFrame:\n    \n    df = batching(df, batch_size=batch_size, add_index=add_index)\n    if create_all_data_feats:\n        df = lag_with_pct_change(df, batch_size, [1, 2, 4],  add_pct_change=True, add_pct_change_lag=True)\n    batches = df['batch_'+ str(batch_size)].unique().tolist()\n    batch_feats=sample_gen(df, batch_size=batch_size, window_size=window_size, batches=batches)\n    df = pd.merge(df, batch_feats, on='batch_'+ str(batch_size), how='left')\n    df = reduce_mem_usage(df, False)\n    \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_selection(df : pd.DataFrame,\n                      df_test : pd.DataFrame,\n                      subtract_only : Optional[bool]=True,\n                      idx_cols : List=['time'],\n                      target_col : List=['open_channels']) -> Tuple[pd.DataFrame , pd.DataFrame]:\n    \n    drops = df.columns[df.isna().sum()>25000]\n    df = df.drop(drops, axis=1)\n    df = df.replace([np.inf, -np.inf], np.nan)\n    df = df.fillna(0)\n    gc.collect()\n    if subtract_only == False:\n        corrcoef_cols = [col for col in df.columns.tolist() if col not in (idx_cols+target_col)]\n        first=dict(); second=dict(); third=dict()\n        for col in corrcoef_cols:\n            ss = np.corrcoef(df[col], df['open_channels'])[0, 1]\n            first[col] = ss\n            ss = np.corrcoef(df[col]-df['signal'], df['open_channels'])[0, 1]\n            second[col] = ss\n            ss = np.corrcoef(df[col]*df['signal'], df['open_channels'])[0, 1]\n            third[col] = ss\n        corr_df = pd.DataFrame.from_dict(\n            {\n            'Base':first, \n            'Signal-Subtracted': second,\n            'Signal-Multiplied': third\n            }\n        ).fillna(0).apply(np.abs).sort_values('Base', ascending=False)\n\n        base_cols = corr_df.sort_values('Base', ascending=False).head(100).index.tolist()\n        multiply_cols = corr_df.sort_values('Signal-Multiplied', ascending=False).head(10).index.tolist()\n        subtract_cols = corr_df.sort_values('Signal-Subtracted', ascending=False).head(25).index.tolist()\n        display(corr_df.sort_values('Base', ascending=False).tail(50))\n        all_cols = list(set(base_cols + multiply_cols + subtract_cols + idx_cols + target_col))\n        all_cols_test = list(set(base_cols + multiply_cols + subtract_cols + idx_cols))   \n        drops = list(set(multiply_cols + subtract_cols)-set(base_cols))\n        df = df[all_cols]\n        df_test = df_test[all_cols_test]\n    \n        for col in multiply_cols:\n            df[col+'_m'] = df[col] * df['signal']\n            df_test[col+'_m'] = df_test[col] * df_test['signal']        \n        for col in subtract_cols:\n            df[col+'_s'] = df[col] - df['signal']\n            df_test[col+'_s'] = df_test[col] - df_test['signal']\n        df = df.drop(drops, axis=1)\n    else:\n        not_imp = ['kstat_1_5000', 'kstat_2_5000', 'kstat_3_5000', 'kstat_4_5000', 'moment_2_5000',\n                   'moment_3_5000','moment_4_5000', 'kstatvar_1_5000', 'kstatvar_2_5000','kstat_1_50000',\n                   'kstat_2_50000', 'kstat_3_50000', 'kstat_4_50000', 'moment_2_50000', 'moment_3_50000',\n                   'moment_4_50000', 'kstatvar_1_50000', 'kstatvar_2_50000']\n        subtract_cols = list(set(df.columns.tolist())-set(idx_cols + target_col + not_imp))\n        for col in subtract_cols:\n            df[col+'_s'] = df[col] - df['signal']\n            df_test[col+'_s'] = df_test[col] - df_test['signal']\n    df = reduce_mem_usage(df, False)\n    df_test = reduce_mem_usage(df_test, False)\n\n    gc.collect()\n    return df, df_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef MacroF1Metric(preds : np.array, dtrain : lgb.Dataset) -> Tuple[Text, np.array, bool] :\n    \n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = f1_score(labels, preds, average = 'macro')\n    \n    return ('MacroF1Metric', score, True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_cv_model_by_batch(train : pd.DataFrame,\n                          test : pd.DataFrame,\n                          splits : int,\n                          shuffle : bool,\n                          seed : int,\n                          batch_col : Text,\n                          params : Dict,\n                          feats : List,\n                          sample_submission: pd.DataFrame) -> pd.DataFrame:\n    \n    oof_ = np.zeros(len(train))\n    preds_ = np.zeros(len(test))\n    target = ['open_channels']\n    imp_df = pd.DataFrame(index=feats)\n    kf = KFold(splits, shuffle, seed)\n    for n_fold, (tr_idx, val_idx) in enumerate(kf.split(train, train[target], groups=train[batch_col])):\n        tr_x = train[feats].iloc[tr_idx]\n        vl_x = train[feats].iloc[val_idx]\n        tr_y = train[target].iloc[tr_idx].values\n        vl_y = train[target].iloc[val_idx].values\n        model = HistGradientBoostingRegressor(learning_rate = 0.1, max_iter=800, random_state = 404, validation_fraction=None, verbose = 0, max_depth=12, min_samples_leaf=25, l2_regularization=0.05)\n        model.fit(tr_x, tr_y)\n        oof_[val_idx] += model.predict(train[feats].iloc[val_idx])\n        preds_ += model.predict(test[feats]) / SPLITS\n        f1_score_ = f1_score(train[target].iloc[val_idx], np.round(np.clip(oof_[val_idx], 0, 10)).astype(int), average = 'macro')\n        rmse_score_ = np.sqrt(mean_squared_error(train[target].iloc[val_idx], oof_[val_idx]))\n        logger.info(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f} rmse score : {rmse_score_:1.5f}')\n        #imp_df[f'feat_importance_{n_fold + 1}'] = model.feature_importance(importance_type='gain')\n    f1_score_ = f1_score(train[target], np.round(np.clip(oof_, 0, 10)).astype(int), average = 'macro')\n    rmse_score_ = np.sqrt(mean_squared_error(train[target], oof_))\n    logger.info(f'Training completed. oof macro f1 score : {f1_score_:1.5f} oof rmse score : {rmse_score_:1.5f}')\n    sample_submission['open_channels'] = np.round(np.clip(preds_, 0, 10)).astype(int)\n    sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')\n    display(sample_submission.head())\n    np.save('oof.npy', oof_)\n    np.save('preds.npy', preds_)\n\n    return imp_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_params(seed : int) -> Dict :\n    params = dict()\n    params['learning_rate']=0.009;\n    params['max_depth']=-1;\n    params['num_leaves']=257;\n    params['metric']='rmse';\n    params['random_state']=seed;\n    params['n_jobs']=-1;\n    params['feature_fraction']=1 ;\n    params['boosting']='goss';\n    params['boost_from_average']=True;\n    params['bagging_seed']=seed;\n    params['bagging_freq']=0;\n    params['bagging_fraction']=1;\n    params['reg_alpha']=0;\n    params['reg_lambda']=0\n    params['force_row_wise']=True\n    return params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_everything(fe_config : List) -> NoReturn:\n    not_feats_cols = ['time']\n    target_col = ['open_channels']\n    init_logger()\n    with timer(f'Reading Data'):\n        logger.info('Reading Data Started ...')\n        base = os.path.abspath('/kaggle/input/liverpool-ion-switching/')\n        train, test, sample_submission = read_data(base)\n        logger.info('Reading Data Completed ...')\n        \n    with timer(f'Creating Features'):\n        logger.info('Feature Enginnering Started ...')\n        for config in fe_config:\n            train = run_feat_enginnering(train, create_all_data_feats=config[0], add_index=config[1], batch_size=config[2], window_size=config[3])\n            test  = run_feat_enginnering(test,  create_all_data_feats=config[0], add_index=config[1], batch_size=config[2], window_size=config[3])\n            not_feats_cols.append('batch_'+str(config[2]))\n            if config[1]:\n                not_feats_cols.append('batch_'+str(config[2])+'_idx')\n        if SELECT:\n            train, test = feature_selection(train, test, subtract_only=True, idx_cols=not_feats_cols, target_col=target_col)\n        logger.info('Feature Enginnering Completed ...')\n\n    with timer(f'Running HistGradientBoosting model'):\n        logger.info(f'Training HistGradientBoosting model with {SPLITS} folds Started ...')\n        params = get_params(SEED)\n        feats = [c for c in train.columns if c not in (not_feats_cols+target_col)]\n        importances = run_cv_model_by_batch(train, test, splits=SPLITS, shuffle=True, seed=SEED, batch_col='batch_50000',params=params, feats=feats, sample_submission=sample_submission)\n        importances.to_csv('importances.csv')\n        logger.info(f'Training completed ...')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_everything(fe_config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0283fd66d7e1425898a85af6f86b44f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"069c008ac5d34ac1b7e256bce432ef95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_074b60c4691242a0a4977b4fcf0e823c","IPY_MODEL_2aa7687fdee5422db7566c0ef2017610"],"layout":"IPY_MODEL_728ec511ce654fca97b43181fa80b79a"}},"074b60c4691242a0a4977b4fcf0e823c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_c2ab19f3bb584cdc9c57a0bf296d5e69","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec0b69d47295474fbe1aff1f6b163d31","value":400}},"0d99e156c9db49a9a875a5acc3da636c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_756e6ca0739d4138a6039dfca3634f2b","placeholder":"​","style":"IPY_MODEL_4e543dabc6a341faa6f9416709756393","value":" 40/40 [00:06&lt;00:00,  6.25it/s]"}},"21d41b089a7648f895252e4a8ee9a5d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24e4b165ec8a4f06b41479017a7d4ae3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e4ec073fbed4fefa7864ec6fb998686","placeholder":"​","style":"IPY_MODEL_74f5cacf2d5a4129aa3a692bfba9f89d","value":" 1000/1000 [01:07&lt;00:00, 14.91it/s]"}},"2aa7687fdee5422db7566c0ef2017610":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cf7c81cf32a4bfdabac0c895051c352","placeholder":"​","style":"IPY_MODEL_21d41b089a7648f895252e4a8ee9a5d2","value":" 400/400 [00:31&lt;00:00, 12.55it/s]"}},"3de29e57e7774a6cb989831eaf666239":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6406157a8d6141938caebedf75a5efec","IPY_MODEL_a86bb364c06441c38b78aed401c12cbf"],"layout":"IPY_MODEL_555907575e2f4127908391538df222b5"}},"4cf7c81cf32a4bfdabac0c895051c352":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e543dabc6a341faa6f9416709756393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50c28780d202428c94919cf57507a93c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"555907575e2f4127908391538df222b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e4ec073fbed4fefa7864ec6fb998686":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc9547d721d4586a9601973df7b2327":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"6406157a8d6141938caebedf75a5efec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_d209ef4baa7c433e9ed464da922683c4","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50c28780d202428c94919cf57507a93c","value":100}},"6d0903c13afd4db892fec0cc7a5b8fb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dba9981dbdd14b72b8e35af57f0fcfc0","IPY_MODEL_0d99e156c9db49a9a875a5acc3da636c"],"layout":"IPY_MODEL_7e3a6001660d4a8aac429b6ba5cb8592"}},"728ec511ce654fca97b43181fa80b79a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"744da4c50f54411dbd555cced9e163d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_943359e6cb38409d876bc201e7f516e7","IPY_MODEL_24e4b165ec8a4f06b41479017a7d4ae3"],"layout":"IPY_MODEL_c58aa2ed6a184b33a3c9865c444387c7"}},"74f5cacf2d5a4129aa3a692bfba9f89d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"756e6ca0739d4138a6039dfca3634f2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e3a6001660d4a8aac429b6ba5cb8592":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"943359e6cb38409d876bc201e7f516e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_c359040efbcb46d38cf0a15333a6d13f","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fc9547d721d4586a9601973df7b2327","value":1000}},"9c5363ad0f6749328c34226c87d5af42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"a86bb364c06441c38b78aed401c12cbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6e965c4074948ada557915d2e181234","placeholder":"​","style":"IPY_MODEL_b93513f3c3184d988923a6035e4df393","value":" 100/100 [00:21&lt;00:00,  4.71it/s]"}},"b93513f3c3184d988923a6035e4df393":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2ab19f3bb584cdc9c57a0bf296d5e69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c359040efbcb46d38cf0a15333a6d13f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c58aa2ed6a184b33a3c9865c444387c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6e965c4074948ada557915d2e181234":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d209ef4baa7c433e9ed464da922683c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba9981dbdd14b72b8e35af57f0fcfc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_0283fd66d7e1425898a85af6f86b44f3","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c5363ad0f6749328c34226c87d5af42","value":40}},"ec0b69d47295474fbe1aff1f6b163d31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}