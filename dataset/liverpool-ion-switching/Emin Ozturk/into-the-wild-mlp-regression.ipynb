{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from collections import Counter\nfrom contextlib import contextmanager\nimport gc\nimport os\nimport psutil\nimport time\nimport warnings\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n#from sklearn.preprocessing import StandardScaler\n#from tsfresh.feature_extraction import feature_calculators\nfrom tqdm import tqdm_notebook as tqdm\nfrom joblib import Parallel, delayed\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as rn\nimport scipy as sp\nimport itertools\nimport warnings\n# import librosa\nimport pywt\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom scipy import signal\nfrom keras.models import Model\nimport keras.layers as L\nfrom sklearn import preprocessing\ndef normalize(X_train, X_test, normalize_opt, feats):\n    if normalize_opt != None:\n        if normalize_opt == 'min_max':\n            scaler = preprocessing.MinMaxScaler()\n        elif normalize_opt == 'robust':\n            scaler = preprocessing.RobustScaler()\n        elif normalize_opt == 'standard':\n            scaler = preprocessing.StandardScaler()\n        elif normalize_opt == 'max_abs':\n            scaler = preprocessing.MaxAbsScaler()\n        scaler = scaler.fit(X_train[feats])\n        X_train[feats] = scaler.transform(X_train[feats])\n        X_test[feats] = scaler.transform(X_test[feats])\n    return X_train, X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df,verbose=True):\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if (c_min > np.iinfo(np.int8).min\n                        and c_max < np.iinfo(np.int8).max):\n                    df[col] = df[col].astype(np.int8)\n                elif (c_min > np.iinfo(np.int16).min\n                      and c_max < np.iinfo(np.int16).max):\n                    df[col] = df[col].astype(np.int16)\n                elif (c_min > np.iinfo(np.int32).min\n                      and c_max < np.iinfo(np.int32).max):\n                    df[col] = df[col].astype(np.int32)\n                elif (c_min > np.iinfo(np.int64).min\n                      and c_max < np.iinfo(np.int64).max):\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (c_min > np.finfo(np.float16).min\n                        and c_max < np.finfo(np.float16).max):\n                    df[col] = df[col].astype(np.float16)\n                elif (c_min > np.finfo(np.float32).min\n                      and c_max < np.finfo(np.float32).max):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    reduction = (start_mem - end_mem) / start_mem\n\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\n    if verbose:\n        print(msg)\n\n    return df\n\n\n\n@contextmanager\ndef timer(title, new_line=True):\n    \"\"\"\n    USAGE:\n    with timer(\"Process bureau and bureau_balance\"):\n        bureau = bureau_and_balance(num_rows)\n        print(\"Bureau df shape:\", bureau.shape)\n        df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n        del bureau\n        gc.collect()\n    \"\"\"\n    t0 = time.time()\n    yield\n    print(f\"{title} - done in {time.time() - t0:.0f}s\")\n    if new_line:\n        print()\n        \n        \ndef report_process_mem_usage():\n    \"\"\"\n    Print memory usage (in GB) of main process\n    \"\"\"\n    print(f\"Main process memory usage: \"\n          f\"{psutil.Process(os.getpid()).memory_info().rss/1024**3:.2f} GB\")\n \n\n\n   \ndef evaluate_macroF1(data_vali, preds):  \n    labels = data_vali.astype(int)\n    preds = np.array(preds)\n    preds = np.argmax(preds,axis=1)\n    score_vali = f1_score(y_true=labels,y_pred=preds,average='macro')\n    return  score_vali\n\ndef get_class_weight(classes, exp=1):\n    '''\n    Weight of the class is inversely proportional to the population of the class.\n    There is an exponent for adding more weight.\n    '''\n    hist, _ = np.histogram(classes, bins=np.arange(12)-0.5)\n    class_weight = hist.sum()/np.power(hist, exp)\n    \n    return class_weight\n    \n\n    \ndef create_mpl(shape):\n    '''\n    Returns a keras model\n    '''\n    \n    X_input = L.Input(shape)\n    \n    X = L.Dense(150, activation='relu')(X_input)\n    X = L.Dense(150, activation='relu')(X)\n    X = L.Dense(125, activation='relu')(X)\n    X = L.Dense(75, activation='relu')(X)\n    X = L.Dense(50, activation='relu')(X)\n    X = L.Dense(25, activation='relu')(X)\n    X = L.Dense(1)(X)\n    \n    model = Model(inputs=X_input, outputs=X)\n    \n    return model\n\n\n\n\n\ndef calc_gradients(s, n_grads=4):\n    '''\n    Calculate gradients for a pandas series. Returns the same number of samples\n    '''\n    grads = pd.DataFrame()\n    \n    g = s.values\n    for i in range(n_grads):\n        g = np.gradient(g)\n        grads['grad_' + str(i+1)] = g\n        \n    return grads\n\n\ndef calc_low_pass(s, n_filts=10):\n    '''\n    Applies low pass filters to the signal. Left delayed and no delayed\n    '''\n    wns = np.logspace(-2, -0.3, n_filts)\n    \n    low_pass = pd.DataFrame()\n    x = s.values\n    for wn in wns:\n        b, a = signal.butter(1, Wn=wn, btype='low')\n        zi = signal.lfilter_zi(b, a)\n        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n        \n    return low_pass\n\n\ndef calc_high_pass(s, n_filts=10):\n    '''\n    Applies high pass filters to the signal. Left delayed and no delayed\n    '''\n    wns = np.logspace(-2, -0.1, n_filts)\n    \n    high_pass = pd.DataFrame()\n    x = s.values\n    for wn in wns:\n        b, a = signal.butter(1, Wn=wn, btype='high')\n        zi = signal.lfilter_zi(b, a)\n        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n        \n    return high_pass\n\n\ndef calc_roll_stats(s, windows=[10, 50, 100, 500, 1000]):\n    '''\n    Calculates rolling stats like mean, std, min, max...\n    '''\n    roll_stats = pd.DataFrame()\n    for w in windows:\n        roll_stats['roll_mean_' + str(w)] = s.rolling(window=w, min_periods=1).mean()\n        roll_stats['roll_std_' + str(w)] = s.rolling(window=w, min_periods=1).std()\n        roll_stats['roll_min_' + str(w)] = s.rolling(window=w, min_periods=1).min()\n        roll_stats['roll_max_' + str(w)] = s.rolling(window=w, min_periods=1).max()\n        roll_stats['roll_range_' + str(w)] = roll_stats['roll_max_' + str(w)] - roll_stats['roll_min_' + str(w)]\n        roll_stats['roll_q10_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.10)\n        roll_stats['roll_q25_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.25)\n        roll_stats['roll_q50_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.50)\n        roll_stats['roll_q75_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.75)\n        roll_stats['roll_q90_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.90)\n    \n    # add zeros when na values (std)\n    roll_stats = roll_stats.fillna(value=0)\n             \n    return roll_stats\n\ndef calc_ewm(s, windows=[10, 50, 100, 500, 1000]):\n    '''\n    Calculates exponential weighted functions\n    '''\n    ewm = pd.DataFrame()\n    for w in windows:\n        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n        \n    # add zeros when na values (std)\n    ewm = ewm.fillna(value=0)\n        \n    return ewm\n\n\ndef add_features(s):\n    '''\n    All calculations together\n    '''\n    \n    # gradients = calc_gradients(s)\n    # low_pass = calc_low_pass(s)\n    high_pass = calc_high_pass(s)\n    roll_stats = calc_roll_stats(s)\n    ewm = calc_ewm(s)\n    temp=pd.concat([s, high_pass, roll_stats, ewm], axis=1)\n    return temp\n\n\ndef divide_and_add_features(s, signal_size=100000):\n    '''\n    Divide the signal in bags of \"signal_size\".\n    Normalize the data dividing it by 15.0\n    '''\n    # normalize\n    # s = s/15.0\n    \n    ls = []\n    for i in tqdm(range(int(s.shape[0]/signal_size))):\n        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n        sig_featured = add_features(sig)\n        ls.append(sig_featured)\n\n    return pd.concat(ls, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport tensorflow as tf\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \nSEED = 321\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer(\"Load saved features from disk\"):\n    submission  = pd.read_csv('/kaggle/input/liverpool-ion-switching/sample_submission.csv') \n    train = pd.read_csv(\"/kaggle/input/remove-trends-giba/train_clean_giba.csv\", usecols=[\"signal\",\"open_channels\"], dtype={'signal': np.float32, 'open_channels':np.int32})\n    test  = pd.read_csv(\"/kaggle/input/remove-trends-giba/test_clean_giba.csv\", usecols=[\"signal\"], dtype={'signal': np.float32})\n\n    # 5+8 Augmentation to Create new batch with 10 channels\n    train['group'] = np.arange(train.shape[0])//500_000\n    aug_df = train[train[\"group\"] == 5].copy()\n    aug_df[\"group\"] = 10\n\n    for col in [\"signal\", \"open_channels\"]:\n        aug_df[col] += train[train[\"group\"] == 8][col].values\n\n    train = train.append(aug_df, sort=False).reset_index(drop=True)\n    del aug_df\n\n    y=train['open_channels']\n    del train['open_channels']\n    gc.collect()\n\n    report_process_mem_usage()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in ['signal']:\n    if item in train.columns:\n        print(item)\n        train_input_mean = train[item].mean()\n        train_input_sigma = train[item].std()\n        train[item]= (train[item] - train_input_mean) / train_input_sigma\n        test[item] = (test[item] - train_input_mean) / train_input_sigma","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer(\"public features\"): \n    train= divide_and_add_features(train['signal'],signal_size=100_000)\n    test= divide_and_add_features(test['signal'],signal_size=100_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_splits=5    \nremove_fea=['time','batch','batch_index','batch_slices','batch_slices2','group']\nfeatures=[i for i in train.columns if i not in remove_fea]\n\nwith timer(\"train lgb model:\"):\n    cv_result = []\n    cv_pred = []\n    oof_preds = np.zeros(train.shape[0])\n    y_preds = np.zeros(test.shape[0]) \n\n    target = \"open_channels\"\n    train['group'] = np.arange(train.shape[0])//4000\n    group = train['group']\n    kf = GroupKFold(n_splits=5)\n    splits = [x for x in kf.split(train, y, group)]\n\n    for fold, (tr_ind, val_ind) in enumerate(splits):\n        x_train, x_val = train[features].iloc[tr_ind].values, train[features].iloc[val_ind].values\n        y_train, y_val = y[tr_ind].values, y[val_ind].values\n        print(f'Fold {fold + 1}, {x_train.shape}, {x_val.shape}')\n        class_weight = get_class_weight(y_train)\n        print(x_train[0].shape)\n        #weight=class_weight[y_train]\n        mlp = create_mpl(x_train[0].shape)\n        mlp.compile(optimizer='adam', loss='mean_squared_error')\n        mlp.fit(x=x_train, y=y_train, epochs=50, batch_size=256, class_weight=class_weight, verbose = 1)  \n        del x_train,y_train\n        gc.collect()\n        oof_preds[val_ind] = mlp.predict(x_val).reshape(x_val.shape[0],)\n        del x_val\n        gc.collect()\n        result = f1_score(y_val,np.round(np.clip(oof_preds[val_ind], 0, 10)).astype(int),average='macro')\n        print('f1 score : ',result)\n        cv_result.append(round(result,5))\n        y_preds += mlp.predict(test[features]).reshape(test.shape[0],)/n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y,np.round(np.clip(oof_preds, 0, 10)).astype(int),average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y[:5000_000],np.round(np.clip(oof_preds[:5000_000], 0, 10)).astype(int),average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.savez_compressed('mlp_reg.npz',valid=oof_preds, test=y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# report OOF RMSE and QWK\nprint(cv_result)\nf1_mean,f1_std = np.mean(cv_result),np.std(cv_result)\nprint(f\"[CV] F1 Mean: {f1_mean}\")\nprint(f\"[CV] F1 Std: {f1_std}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make test predictions with optimized coefficients\nsub_preds = np.round(np.clip(y_preds, 0, 10)).astype(int)\nsubmission['open_channels'] = sub_preds\nprint(submission['open_channels'].value_counts()) \nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}