{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom catboost import CatBoostRegressor, CatBoostClassifier, Pool, cv\n\nimport os\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_features(dataset, window_size, rev=False, per_batch=True):\n    if per_batch:\n        rolling_signal = dataset.groupby([\"batch_group\"]).signal.rolling(window_size)\n    else:\n        rolling_signal = dataset.signal.rolling(window_size)\n        \n    dataset[\"rolling_sum_\" + str(window_size)] = rolling_signal.sum().reset_index(drop=True)\n    dataset[\"rolling_mean_\" + str(window_size)] = rolling_signal.mean().reset_index(drop=True)\n    dataset[\"rolling_min_\" + str(window_size)] = rolling_signal.min().reset_index(drop=True)\n    dataset[\"rolling_max_\" + str(window_size)] = rolling_signal.max().reset_index(drop=True)\n    dataset[\"rolling_std_\" + str(window_size)] = rolling_signal.std().reset_index(drop=True)\n    dataset[\"rolling_var_\" + str(window_size)] = rolling_signal.var().reset_index(drop=True)\n    dataset[\"rolling_skew_\" + str(window_size)] = rolling_signal.skew().reset_index(drop=True)\n    dataset[\"rolling_kurt_\" + str(window_size)] = rolling_signal.kurt().reset_index(drop=True)\n    if rev:\n        dataset[\"rev_rolling_sum_\" + str(window_size)] = rolling_signal.sum().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_mean_\" + str(window_size)] = rolling_signal.mean().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_min_\" + str(window_size)] = rolling_signal.min().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_max_\" + str(window_size)] = rolling_signal.max().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_std_\" + str(window_size)] = rolling_signal.std().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_var_\" + str(window_size)] = rolling_signal.var().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_skew_\" + str(window_size)] = rolling_signal.skew().shift(-window_size).reset_index(drop=True)\n        dataset[\"rev_rolling_kurt_\" + str(window_size)] = rolling_signal.kurt().shift(-window_size).reset_index(drop=True)\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_lagged_signals(dataset, windows):\n    for window in windows:\n        dataset[\"lagged_\" + str(window)] = dataset.groupby([\"batch_group\"]).signal.shift(window)\n        \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_batch_group(df, size):\n    num_list = np.empty([10, size])\n    num_list.fill(0)\n    for i in range(10):\n        num_list[i,:].fill(i)\n    num_list = num_list.reshape(-1,1)\n    batch_group = pd.DataFrame(num_list).rename(columns={0: \"batch_group\"})\n    return pd.concat([df.reset_index(drop=True), batch_group.reset_index(drop=True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset_with_features(window_sizes, lagged_windows, return_transform=True, rev=False, fn=None):\n    df_train = pd.read_csv(\"../input/liverpool-ion-switching/train.csv\")\n\n    discrete_batch = 500000\n    train_size = int(0.70 * discrete_batch)\n    valid_size = int(discrete_batch - train_size)\n    train_set = pd.DataFrame()\n    valid_set = pd.DataFrame()\n\n    print(\"Training size:\", train_size*10)\n    print(\"Validation size:\", valid_size*10)\n    \n    for i in range(0, len(df_train)+1, discrete_batch)[1:]:\n        train_set = pd.concat([train_set, df_train[i-discrete_batch:i].head(train_size)], axis=0)\n        valid_set = pd.concat([valid_set, df_train[i-discrete_batch:i].tail(valid_size)], axis=0)\n    \n    train_set = create_batch_group(train_set, train_size)\n    valid_set = create_batch_group(valid_set, valid_size)\n        \n    del df_train\n    gc.collect()\n\n    if fn:\n        train_set = fn(train_set)\n        valid_set = fn(valid_set)\n    else:\n        train_set = add_lagged_signals(train_set, lagged_windows)\n        valid_set = add_lagged_signals(valid_set, lagged_windows)\n        \n        for window in window_sizes:\n            train_set = add_features(train_set, window, rev)\n            valid_set = add_features(valid_set, window, rev)\n            gc.collect()\n    \n    train_set = train_set.drop(columns=[\"batch_group\"])\n    valid_set = valid_set.drop(columns=[\"batch_group\"])\n    \n    train_set[\"signal_2\"] = train_set[\"signal\"]**2\n    train_set[\"signal_3\"] = train_set[\"signal\"]**3\n    valid_set[\"signal_2\"] = valid_set[\"signal\"]**2\n    valid_set[\"signal_3\"] = valid_set[\"signal\"]**3\n    \n    if return_transform:\n        y_train = train_set.open_channels\n        y_valid = valid_set.open_channels\n\n        scaler = MinMaxScaler()\n        train_set = train_set.drop(columns=[\"time\", \"open_channels\"])\n        X_train = scaler.fit_transform(train_set)\n        X_valid = scaler.transform(valid_set.drop(columns=[\"time\", \"open_channels\"]))\n\n        X_train = np.nan_to_num(X_train, nan=0)\n        X_valid = np.nan_to_num(X_valid, nan=0)\n        return X_train, X_valid, y_train, y_valid, train_set.columns\n    else:\n        return train_set, valid_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid, X_cols = load_dataset_with_features([5000, 6000, 7000, 8000], [1000,2000,3000,4000],\n                                                                        return_transform=True, rev=True)\n# catboost = CatBoostRegressor(loss_function=\"RMSE\", random_seed=1, eval_metric=\"RMSE\")\n# catboost.fit(X_train, y_train, eval_set=Pool(X_valid, y_valid), early_stopping_rounds=100, plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cboost = CatBoostRegressor(loss_function=\"RMSE\", random_seed=1, eval_metric=\"RMSE\")\ncboost.fit(X_train, y_train, eval_set=Pool(X_valid, y_valid), early_stopping_rounds=100, plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance_list = list(zip(X_cols, cboost.feature_importances_))\nsorted(importance_list, key = lambda x: x[1], reverse = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nc_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\nc_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cboost2 = CatBoostClassifier(loss_function=\"MultiClass\", random_seed=1, eval_metric=\"MultiClass\", class_weights=c_weights, task_type=\"GPU\")\ncboost2.fit(X_train, y_train, eval_set=Pool(X_valid, y_valid), early_stopping_rounds=100, plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance_list2 = list(zip(X_cols, cboost2.feature_importances_))\nsorted(importance_list2, key = lambda x: x[1], reverse = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nfrom sklearn.metrics import f1_score\nimport scipy as sp\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize F1 (Macro) score\n    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _f1_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n        return -f1_score(y, X_p, average = 'macro')\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._f1_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n\n    def coefficients(self):\n        \"\"\"\n        Return the optimized coefficients\n        \"\"\"\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cboost2.best_iteration_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cboost2.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cboost2.best_iteration_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cboost2.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(cboost.predict(X_train).reshape(-1,), y_train)\ncoefficients = optR.coefficients()\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def round_preds(model, X_valid, y_valid, classification=False):\n    y_preds = model.predict(X_valid)\n        \n    if y_valid is not None:\n        X_round = pd.DataFrame(np.concatenate([y_preds.reshape(-1, 1), y_valid.to_numpy().reshape(-1, 1)], axis=1))\n    else:\n        X_round = pd.DataFrame(y_preds.reshape(-1, 1))\n        \n    if classification: \n        return X_round.rename(columns={0: \"open_channels\"})\n\n    # [0.50865957 1.5679399  2.52020058 3.50749837 4.44309614 5.47364305\n    #  6.51207558 7.54953974 8.43190615 9.36119176]\n    coefficients1 = [0.50865957, 1.5679399, 2.52020058, 3.50749837, 4.44309614, 5.47364305, 6.51207558, 7.54953974, 8.43190615, 9.36119176] # 0.4173822\n    coefficients2 = [0.51868838, 1.51346738, 2.48039854, 3.52332079, 4.4799399,  5.4619901, 6.49833485, 7.50395204, 8.4661238,  9.44524934]  # 0.3757953\n    coefficients3 = [0.51713402, 1.50215723, 2.50622843, 3.50676172, 4.49122719, 5.43780087, 6.53170168, 7.52116961, 8.48203458, 9.44349437]   # 0.3461139853866367\n    coefficients4 = [0.51627947, 1.50882392, 2.47761787, 3.51451859, 4.48488742, 5.485062, 6.51204066, 7.49428795, 8.49180723, 9.45132125]  #  0.3459922\n    optR = OptimizedRounder()\n\n#     ceil_10 = 11.259509127623923\n    ceil_10 = 11.234590256740304  #  0.3459922\n\n    X_round[\"open_channels\"] = 0\n    X_round.loc[X_round[0] < 0, \"open_channels\"] = 0\n    X_round.loc[(X_round[0] > 10) & (X_round[0] <= ceil_10), \"open_channels\"] = 10\n    X_round.loc[X_round[0] > ceil_10, \"open_channels\"] = np.round(X_round.loc[X_round[0] > ceil_10, 0])\n\n    within_class_range = (X_round[0] > 0) & (X_round[0] < 10)\n    X_round.loc[within_class_range, \"open_channels\"] = optR.predict(X_round.loc[within_class_range, 0], coefficients4)\n    X_round[\"open_channels\"] = X_round[\"open_channels\"].astype(\"int64\")\n\n#     print(X_round.head())\n    return X_round","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n# X_round = round_preds(cboost, X_valid, y_valid)\n# print(classification_report(y_valid, X_round[[\"open_channels\"]]))\nX_round = round_preds(cboost2, X_valid, y_valid, classification=True)\nprint(classification_report(y_valid, X_round[\"open_channels\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_round = round_preds(cboost2, X_valid, y_valid, classification=True)\nprint(classification_report(y_valid, X_round[\"open_channels\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train, X_valid, y_train, y_valid, X_cols\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_entire_dataset(iterations, gpu=False, classification=False):\n    X_train = pd.read_csv(\"../input/liverpool-ion-switching/train.csv\")\n    X_train = create_batch_group(X_train, 500000)\n    \n    X_train = add_lagged_signals(X_train, lagged_window)\n    for window in window_sizes:\n        X_train = add_features(X_train, window, rev=True)\n        \n    X_train = X_train.drop(columns=[\"batch_group\"])\n    \n    scaler = MinMaxScaler()\n    y_train = X_train.open_channels\n    X_train = X_train.drop(columns=[\"time\", \"open_channels\"])\n    X_train = scaler.fit_transform(X_train)\n    X_train = np.nan_to_num(X_train, nan=0)\n    \n    task_type = \"GPU\" if gpu else \"CPU\"\n    print(\"Model will be trained on\", task_type)\n    \n    if classification:\n        catboost = CatBoostClassifier(loss_function=\"MultiClass\", random_seed=1, eval_metric=\"MultiClass\", iterations=iterations, class_weights=c_weights, task_type=task_type)\n        catboost.fit(X_train, y_train, plot=True)\n    else:\n        catboost = CatBoostRegressor(loss_function=\"RMSE\", random_seed=1, eval_metric=\"RMSE\", iterations=iterations, task_type=task_type)\n        catboost.fit(X_train, y_train, plot=True)\n    \n    return catboost, scaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_test_dataset(model, scaler, classification=False):\n    X_test = pd.read_csv(\"../input/liverpool-ion-switching/test.csv\")\n    X_test = create_batch_group(X_test, 500000)\n    \n    X_test = add_lagged_signals(X_test, lagged_window)\n    for window in window_sizes:\n        X_test = add_features(X_test, window, rev=True, per_batch=True)\n        \n    X_test = X_test.drop(columns=[\"batch_group\"])  \n    \n    X_time = X_test[\"time\"]\n    X_test = X_test.drop(columns=[\"time\"])\n    X_test = scaler.transform(X_test)\n    X_test = np.nan_to_num(X_test, nan=0)\n    \n    y_preds = round_preds(model, X_test, None, classification=classification)\n    X_test = pd.concat([X_time, y_preds[\"open_channels\"]], axis=1)\n    \n    return X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterations = 144\n# iterations = 237\n# iterations = 550  # 0.3459922\n# iterations = 531  # classification 0.31083008985387717\niterations = cboost2.best_iteration_  #745\nlagged_window = [1000, 2000]\nwindow_sizes = [5000, 6000, 7000, 8000]\nmodel, scaler = train_entire_dataset(iterations, gpu=True, classification=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = predict_test_dataset(model, scaler, classification=True)\nsubmission.iloc[:2000000][\"open_channels\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.iloc[:2000000].to_csv('submission.csv', float_format='%0.4f', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}