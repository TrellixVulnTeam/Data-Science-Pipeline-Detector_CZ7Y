{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport pandas as pd\nimport numpy as np\n\nimport lightgbm as lgb\nimport time\nimport datetime\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\n\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/liverpool-ion-switching/train.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/liverpool-ion-switching/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['time'].diff().max(),   train['time'].diff().min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['open_channels'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.iloc[0:500000]['open_channels'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Signal"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['signal'].min(),train['signal'].max(),train['signal'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure(data=[\n    go.Scatter(x=train.iloc[100000:]['time'], y=train.iloc[100000:]['signal'], name='Signal'),])\n\nfig.update_layout(title='Signal (part of batch #0)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Scatter(x=train.iloc[100000:125000]['time'], y=train.iloc[100000:125000]['signal'], name='Signal'),])\n\nfig.update_layout(title='Signal (part of batch #0)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(x=list(range(11)), y=train['open_channels'].value_counts(sort=False).values)\n])\n\nfig.update_layout(title='Target (open_channels) distribution')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\n\nfig = make_subplots(rows=3, cols=4,  subplot_titles=[\"Batch #{}\".format(i) for i in range(10)])\ni = 0\nfor row in range(1, 4):\n    for col in range(1, 5):\n        data = train.iloc[(i * 500000):((i+1) * 500000 + 1)]['open_channels'].value_counts(sort=False).values\n        fig.add_trace(go.Bar(x=list(range(11)), y=data), row=row, col=col)\n        \n        i += 1\n\n\nfig.update_layout(title_text=\"Target distribution in different batches\", showlegend=False)\nfig.show()\n\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rolling featuresÂ¶\n\nimport matplotlib.pyplot as plt\n\nwindow_sizes = [10, 50, 100, 1000]\n\nfor window in window_sizes:\n    train[\"rolling_mean_\" + str(window)] = train['signal'].rolling(window=window).mean()\n    train[\"rolling_std_\" + str(window)] = train['signal'].rolling(window=window).std()\n\nfig, ax = plt.subplots(len(window_sizes),1,figsize=(20, 6 * len(window_sizes)))\n\nn = 0\nfor col in train.columns.values:\n    if \"rolling_\" in col:\n        if \"mean\" in col:\n            mean_df = train.iloc[2200000:2210000][col]\n            ax[n].plot(mean_df, label=col, color=\"mediumseagreen\")\n        if \"std\" in col:\n            std = train.iloc[2200000:2210000][col].values\n            ax[n].fill_between(mean_df.index.values,\n                               mean_df.values-std, mean_df.values+std,\n                               facecolor='lightgreen',\n                               alpha = 0.5, label=col)\n            ax[n].legend()\n            n+=1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = '/kaggle/input/liverpool-ion-switching'\n\ntrain_df = pd.read_csv(DIR_INPUT + '/train.csv')\ntrain_df.shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nwindow_sizes = [10, 25, 50, 100, 500, 1000, 5000, 10000, 25000]\n\nfor window in window_sizes:\n    train_df[\"rolling_mean_\" + str(window)] = train_df['signal'].rolling(window=window).mean()\n    train_df[\"rolling_std_\" + str(window)] = train_df['signal'].rolling(window=window).std()\n    train_df[\"rolling_var_\" + str(window)] = train_df['signal'].rolling(window=window).var()\n    train_df[\"rolling_min_\" + str(window)] = train_df['signal'].rolling(window=window).min()\n    train_df[\"rolling_max_\" + str(window)] = train_df['signal'].rolling(window=window).max()\n    \n    train_df[\"rolling_min_max_ratio_\" + str(window)] = train_df[\"rolling_min_\" + str(window)] / train_df[\"rolling_max_\" + str(window)]\n    train_df[\"rolling_min_max_diff_\" + str(window)] = train_df[\"rolling_max_\" + str(window)] - train_df[\"rolling_min_\" + str(window)]\n    \n    a = (train_df['signal'] - train_df['rolling_min_' + str(window)]) / (train_df['rolling_max_' + str(window)] - train_df['rolling_min_' + str(window)])\n    train_df[\"norm_\" + str(window)] = a * (np.floor(train_df['rolling_max_' + str(window)]) - np.ceil(train_df['rolling_min_' + str(window)]))\n    \ntrain_df = train_df.replace([np.inf, -np.inf], np.nan)\ntrain_df.fillna(0, inplace=True)\n\ntrain_y = train_df['open_channels']\ntrain_x = train_df.drop(columns=['time', 'open_channels'])\n\ndel train_df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(train_x)\ntrain_x_scaled = pd.DataFrame(scaler.transform(train_x), columns=train_x.columns)\n\ndel train_x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(DIR_INPUT + '/test.csv')\ntest.drop(columns=['time'], inplace=True)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for window in window_sizes:\n    test[\"rolling_mean_\" + str(window)] = test['signal'].rolling(window=window).mean()\n    test[\"rolling_std_\" + str(window)] = test['signal'].rolling(window=window).std()\n    test[\"rolling_var_\" + str(window)] = test['signal'].rolling(window=window).var()\n    test[\"rolling_min_\" + str(window)] = test['signal'].rolling(window=window).min()\n    test[\"rolling_max_\" + str(window)] = test['signal'].rolling(window=window).max()\n    \n    test[\"rolling_min_max_ratio_\" + str(window)] = test[\"rolling_min_\" + str(window)] / test[\"rolling_max_\" + str(window)]\n    test[\"rolling_min_max_diff_\" + str(window)] = test[\"rolling_max_\" + str(window)] - test[\"rolling_min_\" + str(window)]\n\n    \n    a = (test['signal'] - test['rolling_min_' + str(window)]) / (test['rolling_max_' + str(window)] - test['rolling_min_' + str(window)])\n    test[\"norm_\" + str(window)] = a * (np.floor(test['rolling_max_' + str(window)]) - np.ceil(test['rolling_min_' + str(window)]))\n\ntest = test.replace([np.inf, -np.inf], np.nan)\ntest.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns)\ndel test\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nn_fold = 5\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n\nparams = {'num_leaves': 128,\n          'min_data_in_leaf': 64,\n          'objective': 'huber',\n          'max_depth': -1,\n          'learning_rate': 0.005,\n          \"boosting\": \"gbdt\",\n          \"bagging_freq\": 5,\n          \"bagging_fraction\": 0.8,\n          \"bagging_seed\": 11,\n          \"metric\": 'mae',\n          \"verbosity\": -1,\n          'reg_alpha': 0.1,\n          'reg_lambda': 0.3\n         }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\noof = np.zeros(len(train_x_scaled))\nprediction = np.zeros(len(test_x_scaled))\nscores = []\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train_x_scaled)):\n    print('Fold', fold_n, 'started at', time.ctime())\n    X_train, X_valid = train_x_scaled.iloc[train_index], train_x_scaled.iloc[valid_index]\n    y_train, y_valid = train_y.iloc[train_index], train_y.iloc[valid_index]\n    \n    model = lgb.LGBMRegressor(**params, n_estimators = 5000, n_jobs = -1)\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n            verbose=500, early_stopping_rounds=200)\n\n    y_pred_valid = model.predict(X_valid)\n    y_pred = model.predict(test_x_scaled, num_iteration=model.best_iteration_)\n\n    oof[valid_index] = y_pred_valid.reshape(-1,)\n    scores.append(mean_absolute_error(y_valid, y_pred_valid))\n\n    prediction += y_pred\n\nprediction /= n_fold\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nsample_df = pd.read_csv(DIR_INPUT + \"/sample_submission.csv\", dtype={'time':str})\n\nsample_df['open_channels'] = np.round(prediction).astype(np.int)\nsample_df.to_csv(\"submission.csv\", index=False, float_format='%.4f')\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}