{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn import *\nimport lightgbm as lgb\npd.set_option('display.max_rows', 1000)  # or 1000\n\ntrain = pd.read_csv('/kaggle/input/ionswitchingkl/datasets/trainK.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 1000)  # or 1000\npd.set_option('display.max_rows', 1000)  # or 1000\npd.set_option('display.max_colwidth', 199)  # or 199\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index // 25_000\n    df['batch_index'] = df.index  - (df.batch * 25_000)\n    df['batch_slices'] = df['batch_index']  // 2500\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n\n    print('Pre-Processing stat features....')\n    \n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal'].mean()\n        d['var'+c] = df.groupby([c])['signal'].var()\n        d['max'+c] = df.groupby([c])['signal'].max()\n        d['min'+c] = df.groupby([c])['signal'].min()\n        d['std'+c] = df.groupby([c])['signal'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n        df['range'+c] = df['max'+c] - df['min'+c]\n        df['maxtomin'+c] = df['max'+c] / df['min'+c]\n        df['abs_avg'+c] = (df['abs_min'+c] + df['abs_max'+c]) / 2\n    \n    print('Pre-Processing shifting features....')\n    \n    df['shift+1_'] = df['signal'].shift(1)\n    df['shift-1_'] = df['signal'].shift(-1)\n    df['shift+2_'] = df['signal'].shift(2)\n    df['shift-2_'] = df['signal'].shift(-2)\n    df['shift+3_'] = df['signal'].shift(3)\n    df['shift-3_'] = df['signal'].shift(-3)\n    df['shift+4_'] = df['signal'].shift(4)\n    df['shift-4_'] = df['signal'].shift(-4)\n    df['shift+5_'] = df['signal'].shift(5)\n    df['shift-5_'] = df['signal'].shift(-5)\n        \n    \n    for c in [20,50,100,500]:\n        print('Pre-Processing rolling window '+str(c)+'.....')\n        df['rolling_mean'+str(c)] = df['signal'].rolling(c).mean().tolist()\n        df['rolling_std'+str(c)] = df['signal'].rolling(c).std().tolist()\n        df['rolling_var'+str(c)] = df['signal'].rolling(c).var().tolist()\n        \n    df = df.fillna(method='bfill').fillna(method='ffill')\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    return df\n\ntraining = features(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_columns = training.columns\ncol = [c for c in training_columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\nY = training['open_channels'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = training[col].values\ndel training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=7)\ndel X\ndel Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MacroF1Metric(preds, dtrain):\n    from sklearn.metrics import f1_score\n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = f1_score(labels, preds, average = 'macro')\n    return ('MacroF1Metric', score, True)\n\nparams = {}\nparams['application']='root_mean_squared_error'\nparams['num_boost_round'] = 3000\nparams['learning_rate'] = 0.01\nparams['boosting_type'] = 'gbdt'\nparams['metric'] = 'rmse'\nparams['sub_feature'] = 0.833\nparams['num_leaves'] = 207\nparams['min_split_gain'] = 0.05\nparams['min_child_weight'] = 27\nparams['max_depth'] = -1\nparams['num_threads'] = 20\nparams['max_bin'] = 50\nparams['lambda_l2'] = 0.10\nparams['lambda_l1'] = 0.30\nparams['feature_fraction']= 0.833\nparams['bagging_fraction']= 0.979\nparams['seed']=1729\nparams['device_type'] = 'gpu'\nmodel = lgb.train(params, lgb.Dataset(X_train, Y_train), 2000, lgb.Dataset(X_test, Y_test),verbose_eval=100, early_stopping_rounds=200, feval=MacroF1Metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train\ndel X_test\ndel Y_train\ndel Y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/ionswitchingkl/datasets/testK.csv')\ntest = features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(test[col], num_iteration=model.best_iteration)\ntest['open_channels'] = np.round(np.clip(preds, 0, 10)).astype(int)\ntest[['time','open_channels']].to_csv('submission.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(model,ax = axes,height = 0.5)\nplt.show();plt.close()\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}