{"cells":[{"metadata":{},"cell_type":"markdown","source":"# For Japanese, One Feature Model.\n\nこのノートブックでは、Kaggle Ion Compデータを探索し、1つの特徴量モデルを探します。データドリフトを手動で削除していることに注目してください。ドリフトを取り除くには機械学習を使用する方がよいです。ただし、手動で行うと、その性質を理解し、後でより適切なモデルを構築できます。\n\nドリフトとは何かを知るには、[ここ] [2]を確認してください。\n\n[2]: https://www.kaggle.com/c/liverpool-ion-switching/discussion/133874"},{"metadata":{},"cell_type":"markdown","source":"# ライブラリとデータの読み込み"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import f1_score\nimport graphviz\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/liverpool-ion-switching/test.csv')\ntrain = pd.read_csv('../input/liverpool-ion-switching/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# データの説明\nトレインデータは時間内の記録です。 10,000秒ごとに、シグナルの強度が記録され、開いているイオンチャネルの数が記録されました。 各タイムステップでシグナルから開いているチャネルの数を予測するモデルを構築するのが私たちの仕事です。 さらに、データは50秒のバッチで記録されたと伝えられています。 したがって、各500,000行は1つのバッチです。 トレーニングデータには10バッチが含まれ、テストデータには4バッチが含まれます。 各トレーニングバッチについて、開いているチャネルの数とシグナル強度を一緒に表示してみましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5)); res = 1000\nplt.plot(range(0,train.shape[0],res),train.signal[0::res])\nfor i in range(11): plt.plot([i*500000,i*500000],[-5,12.5],'r')\nfor j in range(10): plt.text(j*500000+200000,10,str(j+1),size=20)\nplt.xlabel('Row',size=16); plt.ylabel('Signal',size=16); \nplt.title('Training Data Signal - 10 batches',size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5)); res = 1000\nplt.plot(range(0,train.shape[0],res),train.open_channels[0::res])\nfor i in range(11): plt.plot([i*500000,i*500000],[-5,12.5],'r')\nfor j in range(10): plt.text(j*500000+200000,10,str(j+1),size=20)\nplt.xlabel('Row',size=16); plt.ylabel('Channels Open',size=16); \nplt.title('Training Data Open Channels - 10 batches',size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 考察\n\n上記のグラフから、5つの異なる合成モデルを使用しているように見えます。 1つのモデルは、低い確率で最大1チャネルのオープンを生成しました（バッチ1および2）。 1つのモデルは、高い確率で最大1チャネルのオープンを生成しました（バッチ3および7）。1つのモデルで最大3チャネルのオープンが生成されました（バッチ4および8）。1つのモデルは最大5チャネルのオープン（バッチ6および9）を生成し、1つのモデルは最大10チャネルのオープン（バッチ7および10）を生成しました。さらに、ドリフトがバッチ7、8、9、10に追加されました。また、バッチ2の始まりです。論文[ここ] [1]に従って、データが合成されます。また、「電気生理学的」ノイズとドリフトが追加されました。ドリフトはシグナルバイアスであり、シグナルは上記のバッチ2、7、8、9、10のような水平線ではなくなります。\n\n>データの説明とデータセットの構築。イオンチャネルの滞留時間は、公開されている単一チャネルモデルからGillespie 43の方法を使用してシミュレーションされました。チャネルは、確率的マルコフ過程に従い、各状態に対して計算された寿命確率分布からランダムにサンプリングすることにより、ある状態から次の状態に遷移すると想定されています。シグナルをパッチクランプアンプに通し、Axon電子「モデルセル」を介してCEDのSignalソフトウェアでファイルに記録して戻すことにより、これらのイベントに本物の「電気生理学的」ノイズが追加されました。一部のデータセットでは、Matlabを使用して最終データに追加のドリフトが適用されました。 2つの異なる確率的ゲーティングモデル（M1およびM2と呼ばれる）を使用して、半合成イオンチャネルデータを生成しました。 M1は、参考文献の低オープン確率モデルです。 41（図3a、b）では、通常、同時に開くイオンチャネルは1つだけです。モデルM2は参照からのものです。 42,44であり、オープンの確率がはるかに高い（図3c、d）。その結果、最大5つのチャネルが同時にオープンし、ゼロチャネルがオープンするインスタンスはほとんどありません。\n\n[1]: https://www.nature.com/articles/s42003-019-0729-3\n"},{"metadata":{},"cell_type":"markdown","source":"# シグナルとオープンチャネル間の相関\nシグナルとオープンチャネルのランダムな間隔を詳しく見て、それらがどのように関連しているかを観察します。 それらは高度に相関しており、一緒に上下に移動します。 したがって、シグナルからオープンチャネルを確率的に予測できます。 唯一の問題は、追加された合成ドリフトです。 したがって、それを削除します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(10):\n    a = int( np.random.uniform(0,train.shape[0]-50000) )\n    b=a+5000; res=10\n    print('#'*25)\n    print('### Random %i to %i'%(a,b))\n    print('#'*25)\n    plt.figure(figsize=(20,5))\n    plt.plot(range(a,b,res),train.signal[a:b][0::res])\n    plt.plot(range(a,b,res),train.open_channels[a:b][0::res])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# テストデータ\nテストデータシグナルを表示してみましょう"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nres = 1000; let = ['A','B','C','D','E','F','G','H','I','J']\nplt.plot(range(0,test.shape[0],res),test.signal[0::res])\nfor i in range(5): plt.plot([i*500000,i*500000],[-5,12.5],'r')\nfor j in range(21): plt.plot([j*100000,j*100000],[-5,12.5],'r:')\nfor k in range(4): plt.text(k*500000+200000,10,str(k+1),size=20)\nfor k in range(10): plt.text(k*100000+40000,7,let[k],size=16)\nplt.xlabel('Row',size=16); plt.ylabel('Channels Open',size=16); \nplt.title('Test Data Signal - 4 batches - 10 subsamples',size=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 考察\nこのグラフから、動作中の5つのモデルを特定できます。 そして、追加されたドリフトを認識できます。 バッチ1は5つのサブサンプルのように見え、A、B、C、D、Eはそれぞれモデル1s、3、5、1s、1fによって作成されました。 モデル1sは、最大1チャネルが開いており、確率が低いモデルです。 モデル1fは、高確率で最大1チャネルが開いているモデルです。 また、モデル3、5、10はそれぞれ最大3、5、10チャネルのモデルです。 サブサンプルA、B、E、G、H、Iの傾斜ドリフトを観察します。バッチ3で放物線ドラフトを観察します。"},{"metadata":{},"cell_type":"markdown","source":"# トレインデータのドリフトの削除\nこれは、バッチ2の傾斜ドリフトの削除を示すデモです。  以下では、バッチ1、3、4、5、6のモデルのみをトレインします。ただし、トレインドリフトを削除した後、必要に応じてバッチ2、7、8、9、10のデータをトレインデータに含めることができます。\n\n新しいシグナルは古いシグナルからf（time）= 3 （time-50）/ 10を引いたものであることに注意してください。これは線形方程式、つまりy（x）=（3/10）（x-50）です。 y（x）=（3/10） x-15.これは傾斜ドリフトの方程式です。（この方程式は手計算により決定しました。）ドリフトは、そのラインを信号に追加した編集者によって作成されました。 そのため、その行を引くことで削除します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = train.copy()\n\na=500000; b=600000 # CLEAN TRAIN BATCH 2\ntrain2.loc[train.index[a:b],'signal'] = train2.signal[a:b].values - 3*(train2.time.values[a:b] - 50)/10.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch=2; a=500000*(batch-1); b=500000*batch; res=50\nplt.figure(figsize=(20,5))\nplt.plot(range(a,b,res),train.signal[a:b][0::res])\nplt.title('Training Batch 2 with Slant Drift',size=16)\nplt.figure(figsize=(20,5))\nplt.plot(range(a,b,res),train2.signal[a:b][0::res])\nplt.title('Training Batch 2 without Slant Drift',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"次は、バッチ7、8、9、10の放物線ドリフトを削除するデモです。\n\n新しいシグナルは古いシグナルから((-low+high)/625) (x-mid)^2 を引いたものであることに注意してください。放射線の軸からの変位の2乗に係数を掛けたものを引くことで、放射線ドリフトを削除します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"def f(x,low,high,mid): return -((-low+high)/625)*(x-mid)**2+high -low\n\n# CLEAN TRAIN BATCH 7\nbatch = 7; a = 500000*(batch-1); b = 500000*batch\ntrain2.loc[train2.index[a:b],'signal'] = train.signal.values[a:b] - f(train.time[a:b].values,-1.817,3.186,325)\n# CLEAN TRAIN BATCH 8\nbatch = 8; a = 500000*(batch-1); b = 500000*batch\ntrain2.loc[train2.index[a:b],'signal'] = train.signal.values[a:b] - f(train.time[a:b].values,-0.094,4.936,375)\n# CLEAN TRAIN BATCH 9\nbatch = 9; a = 500000*(batch-1); b = 500000*batch\ntrain2.loc[train2.index[a:b],'signal'] = train.signal.values[a:b] - f(train.time[a:b].values,1.715,6.689,425)\n# CLEAN TRAIN BATCH 10\nbatch = 10; a = 500000*(batch-1); b = 500000*batch\ntrain2.loc[train2.index[a:b],'signal'] = train.signal.values[a:b] - f(train.time[a:b].values,3.361,8.45,475)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.plot(train.time[::1000],train.signal[::1000])\nplt.title('Training Batches 7-10 with Parabolic Drift',size=16)\nplt.figure(figsize=(20,5))\nplt.plot(train2.time[::1000],train2.signal[::1000])\nplt.title('Training Batches 7-10 without Parabolic Drift',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5つのモデルの作成\n上で観察したシグナルの異なるタイプごとに決定木の分類器モデルを作成します。"},{"metadata":{},"cell_type":"markdown","source":"## 1s: 最大1の低確率オープンチャンネル"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 1; a = 500000*(batch-1); b = 500000*batch\nbatch = 2; c = 500000*(batch-1); d = 500000*batch\nX_train = np.concatenate([train2.signal.values[a:b],train2.signal.values[c:d]]).reshape((-1,1))\ny_train = np.concatenate([train2.open_channels.values[a:b],train2.open_channels.values[c:d]]).reshape((-1,1))\n\nclf1s = tree.DecisionTreeClassifier(max_depth=1)\nclf1s = clf1s.fit(X_train,y_train)\nprint('Training model 1s channel')\npreds = clf1s.predict(X_train)\nprint('has f1 validation score =',f1_score(y_train,preds,average='macro'))\n\ntree_graph = tree.export_graphviz(clf1s, out_file=None, max_depth = 10,\n    impurity = False, feature_names = ['signal'], class_names = ['0', '1'],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1f: 最大1の高確率オープンチャネル"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 3; a = 500000*(batch-1); b = 500000*batch\nbatch = 7; c = 500000*(batch-1); d = 500000*batch\nX_train = np.concatenate([train2.signal.values[a:b],train2.signal.values[c:d]]).reshape((-1,1))\ny_train = np.concatenate([train2.open_channels.values[a:b],train2.open_channels.values[c:d]]).reshape((-1,1))\n\nclf1f = tree.DecisionTreeClassifier(max_depth=1)\nclf1f = clf1f.fit(X_train, y_train)\nprint('Training model 1f channel')\npreds = clf1f.predict(X_train)\nprint('has f1 validation score =',f1_score(y_train,preds,average='macro'))\n\ntree_graph = tree.export_graphviz(clf1f, out_file=None, max_depth = 10,\n    impurity = False, feature_names = ['signal'], class_names = ['0', '1'],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3: 最大3のオープンチャネル"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 4; a = 500000*(batch-1); b = 500000*batch\nbatch = 8; c = 500000*(batch-1); d = 500000*batch\nX_train = np.concatenate([train2.signal.values[a:b],train2.signal.values[c:d]]).reshape((-1,1))\ny_train = np.concatenate([train2.open_channels.values[a:b],train2.open_channels.values[c:d]]).reshape((-1,1))\n\nclf3 = tree.DecisionTreeClassifier(max_leaf_nodes=4)\nclf3 = clf3.fit(X_train,y_train)\nprint('Training model 3 channel')\npreds = clf3.predict(X_train)\nprint('has f1 validation score =',f1_score(y_train,preds,average='macro'))\n\ntree_graph = tree.export_graphviz(clf3, out_file=None, max_depth = 10,\n    impurity = False, feature_names = ['signal'], class_names = ['0', '1','2','3'],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5: 最大5のオープンチャネル"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 6; a = 500000*(batch-1); b = 500000*batch\nbatch = 9; c = 500000*(batch-1); d = 500000*batch\nX_train = np.concatenate([train2.signal.values[a:b],train2.signal.values[c:d]]).reshape((-1,1))\ny_train = np.concatenate([train2.open_channels.values[a:b],train2.open_channels.values[c:d]]).reshape((-1,1))\n\nclf5 = tree.DecisionTreeClassifier(max_leaf_nodes=6)\nclf5 = clf5.fit(X_train, y_train)\nprint('Trained model 5 channel')\npreds = clf5.predict(X_train)\nprint('has f1 validation score =',f1_score(y_train,preds,average='macro'))\n\ntree_graph = tree.export_graphviz(clf5, out_file=None, max_depth = 10,\n    impurity = False, feature_names = ['signal'], class_names = ['0', '1','2','3','4','5'],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 10: 最大10のオープンチャネル"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 5; a = 500000*(batch-1); b = 500000*batch\nbatch = 10; c = 500000*(batch-1); d = 500000*batch\nX_train = np.concatenate([train2.signal.values[a:b],train2.signal.values[c:d]]).reshape((-1,1))\ny_train = np.concatenate([train2.open_channels.values[a:b],train2.open_channels.values[c:d]]).reshape((-1,1))\n\nclf10 = tree.DecisionTreeClassifier(max_leaf_nodes=8)\nclf10 = clf10.fit(X_train, y_train)\nprint('Trained model 10 channel')\npreds = clf10.predict(X_train)\nprint('has f1 validation score =',f1_score(y_train,preds,average='macro'))\n\ntree_graph = tree.export_graphviz(clf10, out_file=None, max_depth = 10,\n    impurity = False, feature_names = ['signal'], class_names = [str(x) for x in range(11)],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# テストデータのドリフトを分析する\nトレーニングデータとテストデータのドリフトをプロットしましょう"},{"metadata":{},"cell_type":"markdown","source":"## トレーニングデータのドリフト\n次のプロットが水平線ではない場合は、ドリフトを観察します。 バッチ2、7、8、9、10にドリフトが見られます。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ORIGINAL TRAIN DATA\nplt.figure(figsize=(20,5))\nr = train.signal.rolling(30000).mean()\nplt.plot(train.time.values,r)\nfor i in range(11): plt.plot([i*50,i*50],[-3,8],'r:')\nfor j in range(10): plt.text(j*50+20,6,str(j+1),size=20)\nplt.title('Training Signal Rolling Mean. Has Drift wherever plot is not horizontal line',size=16)\nplt.show()\n\n# TRAIN DATA WITHOUT DRIFT\nplt.figure(figsize=(20,5))\nr = train2.signal.rolling(30000).mean()\nplt.plot(train2.time.values,r)\nfor i in range(11): plt.plot([i*50,i*50],[-3,8],'r:')\nfor j in range(10): plt.text(j*50+20,6,str(j+1),size=20)\nplt.title('Training Signal Rolling Mean without Drift',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## テストデータのドリフト\nテストサブサンプルA、B、E、G、H、Iとテストバッチ3のドリフトを観察します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nlet = ['A','B','C','D','E','F','G','H','I','J']\nr = test.signal.rolling(30000).mean()\nplt.plot(test.time.values,r)\nfor i in range(21): plt.plot([500+i*10,500+i*10],[-3,6],'r:')\nfor i in range(5): plt.plot([500+i*50,500+i*50],[-3,6],'r')\nfor k in range(4): plt.text(525+k*50,5.5,str(k+1),size=20)\nfor k in range(10): plt.text(505+k*10,4,let[k],size=16)\nplt.title('Test Signal Rolling Mean. Has Drift wherever plot is not horizontal line',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# テストデータのドリフトの削除\n\nトレインデータと同様にドリフトを削除します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# REMOVE BATCH 1 DRIFT\nstart=500\na = 0; b = 100000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - 3*(test2.time.values[a:b]-start)/10.\nstart=510\na = 100000; b = 200000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - 3*(test2.time.values[a:b]-start)/10.\nstart=540\na = 400000; b = 500000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - 3*(test2.time.values[a:b]-start)/10.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# REMOVE BATCH 2 DRIFT\nstart=560\na = 600000; b = 700000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - 3*(test2.time.values[a:b]-start)/10.\nstart=570\na = 700000; b = 800000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - 3*(test2.time.values[a:b]-start)/10.\nstart=580\na = 800000; b = 900000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - 3*(test2.time.values[a:b]-start)/10.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# REMOVE BATCH 3 DRIFT\ndef f(x):\n    return -(0.00788)*(x-625)**2+2.345 +2.58\na = 1000000; b = 1500000\ntest2.loc[test2.index[a:b],'signal'] = test2.signal.values[a:b] - f(test2.time[a:b].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nres = 1000\nplt.plot(range(0,test2.shape[0],res),test2.signal[0::res])\nfor i in range(5): plt.plot([i*500000,i*500000],[-5,12.5],'r')\nfor i in range(21): plt.plot([i*100000,i*100000],[-5,12.5],'r:')\nfor k in range(4): plt.text(k*500000+250000,10,str(k+1),size=20)\nfor k in range(10): plt.text(k*100000+40000,7.5,let[k],size=16)\nplt.title('Test Signal without Drift',size=16)\nplt.show()\n\nplt.figure(figsize=(20,5))\nr = test2.signal.rolling(30000).mean()\nplt.plot(test2.time.values,r)\nfor i in range(21): plt.plot([500+i*10,500+i*10],[-2,6],'r:')\nfor i in range(5): plt.plot([500+i*50,500+i*50],[-2,6],'r')\nfor k in range(4): plt.text(525+k*50,5.5,str(k+1),size=20)\nfor k in range(10): plt.text(505+k*10,4,let[k],size=16)\nplt.title('Test Signal Rolling Mean without Drift',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# テストの予測\nシグナルとオープンチャネルの相関性を元に、グラフから各区間が５つのどのモデルと適合しているかを推測し、そのモデルを用いてオープンチャネルを予測します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/liverpool-ion-switching/sample_submission.csv')\n\na = 0 # SUBSAMPLE A, Model 1s\nsub.iloc[100000*a:100000*(a+1),1] = clf1s.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 1 # SUBSAMPLE B, Model 3\nsub.iloc[100000*a:100000*(a+1),1] = clf3.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 2 # SUBSAMPLE C, Model 5\nsub.iloc[100000*a:100000*(a+1),1] = clf5.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 3 # SUBSAMPLE D, Model 1s\nsub.iloc[100000*a:100000*(a+1),1] = clf1s.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 4 # SUBSAMPLE E, Model 1f\nsub.iloc[100000*a:100000*(a+1),1] = clf1f.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 5 # SUBSAMPLE F, Model 10\nsub.iloc[100000*a:100000*(a+1),1] = clf10.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 6 # SUBSAMPLE G, Model 5\nsub.iloc[100000*a:100000*(a+1),1] = clf5.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 7 # SUBSAMPLE H, Model 10\nsub.iloc[100000*a:100000*(a+1),1] = clf10.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 8 # SUBSAMPLE I, Model 1s\nsub.iloc[100000*a:100000*(a+1),1] = clf1s.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\na = 9 # SUBSAMPLE J, Model 3\nsub.iloc[100000*a:100000*(a+1),1] = clf3.predict(test2.signal.values[100000*a:100000*(a+1)].reshape((-1,1)))\n\n # BATCHES 3 AND 4, Model 1s\nsub.iloc[1000000:2000000,1] = clf1s.predict(test2.signal.values[1000000:2000000].reshape((-1,1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# テスト予測の表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nres = 1000\nplt.plot(range(0,test.shape[0],res),sub.open_channels[0::res])\nfor i in range(5): plt.plot([i*500000,i*500000],[-5,12.5],'r')\nfor i in range(21): plt.plot([i*100000,i*100000],[-5,12.5],'r:')\nfor k in range(4): plt.text(k*500000+250000,10,str(k+1),size=20)\nfor k in range(10): plt.text(k*100000+40000,7.5,let[k],size=16)\nplt.title('Test Data Predictions',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False,float_format='%.4f')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}