{"cells":[{"metadata":{},"cell_type":"markdown","source":"Credit to [AlexFocus](https://www.kaggle.com/alexfocus) and [jazivxt](https://www.kaggle.com/jazivxt) for original kernels"},{"metadata":{},"cell_type":"markdown","source":"\n![liverpol](https://storage.googleapis.com/kaggle-competitions/kaggle/18045/logos/thumb76_76.png?t=2020-02-21-18-37-27)\n\nIf you like this notebook please let here your upvote!\n\n### Install libraries and load the Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn import *\nimport lightgbm as lgb\n\ntrain = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')\ntest = pd.read_csv('/kaggle/input/liverpool-ion-switching/test.csv')\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nimport scipy as sp\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize F1 (Macro) score\n    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _f1_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n        return -metrics.f1_score(y, X_p, average = 'macro')\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._f1_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n\n    def coefficients(self):\n        \"\"\"\n        Return the optimized coefficients\n        \"\"\"\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize_prediction(prediction, coefficients):\n    prediction[prediction <= coefficients[0]] = 0\n    prediction[np.where(np.logical_and(prediction > coefficients[0], prediction <= coefficients[1]))] = 1\n    prediction[np.where(np.logical_and(prediction > coefficients[1], prediction <= coefficients[2]))] = 2\n    prediction[np.where(np.logical_and(prediction > coefficients[2], prediction <= coefficients[3]))] = 3\n    prediction[np.where(np.logical_and(prediction > coefficients[3], prediction <= coefficients[4]))] = 4\n    prediction[np.where(np.logical_and(prediction > coefficients[4], prediction <= coefficients[5]))] = 5\n    prediction[np.where(np.logical_and(prediction > coefficients[5], prediction <= coefficients[6]))] = 6\n    prediction[np.where(np.logical_and(prediction > coefficients[6], prediction <= coefficients[7]))] = 7\n    prediction[np.where(np.logical_and(prediction > coefficients[7], prediction <= coefficients[8]))] = 8\n    prediction[np.where(np.logical_and(prediction > coefficients[8], prediction <= coefficients[9]))] = 9\n    prediction[prediction > coefficients[9]] = 10\n    \n    return prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create features for train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"def features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index // 50_000\n    df['batch_index'] = df.index  - (df.batch * 50_000)\n    df['batch_slices'] = df['batch_index']  // 5_000\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    \n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal'].mean()\n        d['median'+c] = df.groupby([c])['signal'].median()\n        d['max'+c] = df.groupby([c])['signal'].max()\n        d['min'+c] = df.groupby([c])['signal'].min()\n        d['std'+c] = df.groupby([c])['signal'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n        df['range'+c] = df['max'+c] - df['min'+c]\n        df['maxtomin'+c] = df['max'+c] / df['min'+c]\n        df['abs_avg'+c] = (df['abs_min'+c] + df['abs_max'+c]) / 2\n    \n    #add shifts\n    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+1'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-1'][i] = np.nan\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    return df\n\ntrain = features(train)\ntest = features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = [c for c in train.columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\nx1, x2, y1, y2 = model_selection.train_test_split(train[col], train['open_channels'], test_size=0.3, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Light GBM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgb_Metric(preds, dtrain):\n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = metrics.f1_score(labels, preds, average='macro')\n    return ('F1 Macro', score, True)\n \nparams = {'learning_rate': 0.8, 'max_depth': 7, 'num_leaves':2**7+1, 'metric': 'rmse', 'random_state': 7, 'n_jobs':-1} \nmodel = lgb.train(params, lgb.Dataset(x1, y1), 2000,  lgb.Dataset(x2, y2), verbose_eval=50, early_stopping_rounds=100, feval=lgb_Metric)\ntrain_preds_lgb = model.predict(train[col], num_iteration=model.best_iteration)\npreds_lgb = model.predict(test[col], num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Optimize Rounder Coefficients on LGB training predictions and training dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"optR_lgb = OptimizedRounder()\noptR_lgb.fit(train_preds_lgb.reshape(-1,), train['open_channels'])\ncoefficients_lgb = optR_lgb.coefficients()\nprint(coefficients_lgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['open_channels'] = optimize_prediction(preds_lgb,coefficients_lgb).astype(int)\ntest[['time','open_channels']].to_csv('submission_lgb.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CatBoost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import Pool,CatBoostRegressor\n\n# Initialize CatBoostRegressor\nmodel = CatBoostRegressor(task_type = \"CPU\",\n                          iterations=1000,\n                          learning_rate=0.1,\n                          random_seed = 42,\n                          depth=2,\n                         )\n# Fit model\nmodel.fit(x1, y1)\n# Get predictions\ntrain_preds_cat = model.predict(train[col])\npreds_catb = model.predict(test[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Optimize Rounder Coefficients on Catboost training predictions and training dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"optR_cat = OptimizedRounder()\noptR_cat.fit(train_preds_cat.reshape(-1,), train['open_channels'])\ncoefficients_cat = optR_cat.coefficients()\nprint(coefficients_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['open_channels'] = optimize_prediction(preds_catb, coefficients_cat).astype(int)\ntest[['time','open_channels']].to_csv('submission_cat.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ensemble predictions"},{"metadata":{},"cell_type":"markdown","source":"#### Optimize Rounder Coefficients on Ensembled training predictions and training dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preds_comb = 0.75 * train_preds_lgb + 0.25 * train_preds_cat\noptR = OptimizedRounder()\noptR.fit(train_preds_comb.reshape(-1,), train['open_channels'])\ncoefficients = optR.coefficients()\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_comb = 0.75 * preds_lgb + 0.25 * preds_catb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest['open_channels'] = optimize_prediction(preds_comb, coefficients).astype(int)\ntest[['time','open_channels']].to_csv('submission.csv', index=False, float_format='%.4f')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}