{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"trusted":false},"cell_type":"code","source":"\nimport numpy as np # linear algebra \nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport multiprocessing\nfrom multiprocessing import Pool\nimport requests\nimport json, requests, shutil\nfrom pandas.io.json import json_normalize\nimport os\nimport urllib3\n\n\"\"\"\nHow to use this code\nFile structure\n---------------\n/data\n/input\ndata.py\n\n\n\nFile description\n-----------------\n/data is originally empty. It will stored the data in test, train and validation folders.\n/input contains all the required data input which include test.json, train.json, and validation.json\n\n\"\"\"\n\n\n\ndef download(data_type, data):\n\n    #create a directory if it is absent\n    directory = 'data/'+data_type+'_images/'\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n\n\n    for i in range(len( data)):\n        #response = requests.get(data.loc[i]['url'], timeout = 5, stream = True)\n\n\n        try:\n            response = requests.get(data.loc[i]['url'], timeout = 50000, stream = True)\n\n            with open( directory+ str(data.loc[i]['imageId'])+ '.jpeg', 'wb') as out_file:\n                shutil.copyfileobj(response.raw, out_file)\n        except ( requests.exceptions.ConnectionError, urllib3.exceptions.ProtocolError ):\n            print \"Connection refused\"\n\n    return 1\n\n\ndef convertToParallelSolution (ind, data_type, data, numOfProcesses):\n    totalnumberOfSamples = len( data )\n\n    numOfBins = round ( totalnumberOfSamples / numOfProcesses ) + 1\n    start =  int (ind * numOfBins )\n    end = int (start + numOfBins )\n\n    result = 0\n    \n    if end >= totalnumberOfSamples:\n        end = totalnumberOfSamples\n\n    if end <= start:\n        return result \n\n    if end > start:\n        result = download (data_type, data[start : end].reset_index( ) )\n\n    print \"Batch {} of {} is done so far!!!!! {}.json (in progress)\".format (ind, numOfProcesses, data_type)\n    #return result\n    return 1\n\n\ndef parallel_solution (data_type, data, numOfProcesses=20 ):\n\n    pool = Pool(processes=numOfProcesses)              # start 20 worker processes\n\n    # launching multiple evaluations asynchronously *may* use more processes\n    multiple_results = [pool.apply_async(convertToParallelSolution, args=(ind, data_type, data, numOfProcesses, )) for ind in range(numOfProcesses)]\n\n    resultContainer =  [res.get() for res in multiple_results]\n\nif __name__ == \"__main__\":\n\n    dataTypeLst = [\"test\", \"train\", \"validation\" ]\n    for data_type in dataTypeLst:\n        data = json.load(open('input/' + data_type + '.json'))\n        data = json_normalize(data[\"images\"])\n        print \"{}.json is fully loaded\".format (data_type)\n        parallel_solution  (data_type, data )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}