{"cells":[{"metadata":{"colab_type":"text","id":"HdMyi2D4-6YC","_uuid":"5e7877505b1d76c85f5d2844c59525ac4d95cf15"},"cell_type":"markdown","source":"# **This notebook is for linking, authenticating and downloading the Image data sets from json files directly into your Google Drive**"},{"metadata":{"colab_type":"text","id":"IzJv9UUti_og","_uuid":"7cd5fde1c908bda4bf54375c6987a4360892e8cd"},"cell_type":"markdown","source":"\n###Features:\n1.   Smaller version of images can be found by replacing \"-large\" with \"-small\" at the end of url. In this code, the small picture (around 5 kb on average) are downloaded.\n2.   This script has been built for Colab users. As the instance gets destroyed every 12 hours, one can't download datasets everytime.\n3.   Also, if you have a locally available GPU and want to download images to your drive (and then to your computer on one click), you can use this script. \n4.   This notebook can be used to download data to drive for any competition that gives urls in JSON files (ofcourse with little modifications).\n\n"},{"metadata":{"colab_type":"text","id":"F_r1e_f2nCKK","_uuid":"0fbfce5ca49b5029a79b0ebbf88a4e4ba451f731"},"cell_type":"markdown","source":"###Instructions:\n\n\n1.   Carefully read the comments mentioned. They are there for a reason!\n2.   You can also add your code and modify it!\n3.   Feedback is valuable guys. Lemme know what you thinking. \n\n"},{"metadata":{"colab_type":"text","id":"RNuqhVm2oLAw","_uuid":"676a06dfb801338bae415a3f6f2f522ca4ba715c"},"cell_type":"markdown","source":"Well, lets get started..."},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"GKHwTTZg5eJa","trusted":true,"_uuid":"8edbbb6eb49d41ad509c90639016810be5aad172"},"cell_type":"code","source":"#Linking drive to colab to store datasets\n!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n!apt-get update -qq 2>&1 > /dev/null\n!apt-get -y install -qq google-drive-ocamlfuse fuse","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"WcT_t6L1L6CQ","trusted":true,"_uuid":"d969bba192922d89002528fa7ee1c2fc099eecf4"},"cell_type":"code","source":"# Generate auth tokens for Colab\nfrom google.colab import auth\nauth.authenticate_user()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"r8NO1DnqL8ZW","trusted":true,"_uuid":"91c45b81256bcd7498daac4d3efcc628a4ad7db9"},"cell_type":"code","source":"# Generate creds for the Drive FUSE library. Though the link asks you to verify twice, you don't have to!\nfrom oauth2client.client import GoogleCredentials\ncreds = GoogleCredentials.get_application_default()\nimport getpass\n!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\nvcode = getpass.getpass()\n!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"KTRy3vPxL-NC","trusted":true,"_uuid":"7a775165088631cd5545735bf2afe5e5fe5e48fe"},"cell_type":"code","source":"# Create a directory and mount Google Drive using that directory.\n!mkdir -p drive\n!google-drive-ocamlfuse drive\n\nprint 'Files in Drive:'\n!ls drive/","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"8LcRSRL2FTXI","trusted":true,"_uuid":"a7ae107fdbed850c622774b6f5c8d76ec5e5dd7a"},"cell_type":"code","source":"# Create a file in a new directory called \"Kaggle\" in your Google Drive. This will be your operation base :P\n!echo \"This newly created file will appear in your Drive file list. If you are reading this, that means the attempt to integrate was successful\" > drive/kaggle/created.txt","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"ISxFR2GdjX_-","_uuid":"c506095a5a09b6fd6110f111889110cd54f5ec9e"},"cell_type":"markdown","source":"*Tried integrating kaggle-api into colab's instance. But it's throwing error:401 (Unauthorized). So, you have to manually upload the json files to \"kaggle\" folder in your drive!\n*"},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"3DvUTP0UDjwQ","trusted":true,"_uuid":"9b06dfe047d9ec6929221f8a4824be40897bf223"},"cell_type":"code","source":"#The uploaded files are in .zip format. The following code will unzip them into nice json files. This has to be done only the first time!\n!unzip \"drive/kaggle/*.zip\" -d drive/kaggle\n\n#Now, remove those archives\n!rm -f drive/kaggle/*.zip\n\n#Make directories for the data\n!mkdir drive/kaggle/train drive/kaggle/validation drive/kaggle/test","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"MPm3yuVEkuV6","trusted":true,"_uuid":"1335612f021a39ac2d2a0dd45c47a51af9b97b37"},"cell_type":"code","source":"#Now, to download the train set into your drive from the urls in the JSON files, execute the below.  Also, a file is generated with the ImageURL, imageName, imageId and \n#their labelIds.\n\n\nimport json\nimport time\n\ntrain_data = json.load(open('drive/kaggle/train.json'))\n!echo ImageURL, ImgName, ImgId, LabelId >> drive/kaggle/train/train.txt\n\nfor i in range(len(train_data['images'])):\n  img_url = train_data['images'][i]['url']\n  img_id = train_data['images'][i]['imageId']\n  label_id = train_data['annotations'][i]['labelId']\n  img_name=img_url.split(\"/\")[-1]\n  #print img_name\n  img_name_actual = img_name.split(\"-\")[0]\n  img_name_small = img_name_actual + \"-small\"+\".jpg\"\n  #print img_name_actual\n  img_url_small = img_url.split(\"-\")[-2]\n  img_url_small = img_url_small + \"-small\"\n  print img_url_small\n  !curl $img_url_small > drive/kaggle/train/$img_name_small\n  time.sleep(0.05) \n  !echo $img_url_small,$img_name_small,$img_id,$label_id >> drive/kaggle/train/train.txt \n  #time.sleep(0.5)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"LHtp2PhSteDE","trusted":true,"_uuid":"1cccb24ecf8682c51de8dc01e47f0c5939ecd70d"},"cell_type":"code","source":"#To download validation data on to your drive...\n\nimport json\nimport time\n\nval_data = json.load(open('drive/kaggle/validation.json'))\n!echo ImageURL, ImgName, ImgId, LabelId >> drive/kaggle/validation/validation.txt \n\nfor i in range(len(val_data['images'])):\n  img_url = val_data['images'][i]['url']\n  #print img_url\n  img_id = val_data['images'][i]['imageId']\n  #print img_id\n  label_id = val_data['annotations'][i]['labelId']\n  #print label_id\n  img_name=img_url.split(\"/\")[-1]\n  #print img_name\n  img_name_actual = img_name.split(\"-\")[0]\n  img_name_small = img_name_actual + \"-small\"+\".jpg\"\n  #print img_name_actual\n  img_url_small = img_url.split(\"-\")[-2]\n  img_url_small = img_url_small + \"-small\"\n  print img_url_small\n  !curl $img_url_small > drive/kaggle/validation/$img_name_small\n  time.sleep(0.05)\n  !echo $img_name_actual,$img_id,$label_id >> drive/kaggle/validation/validation.txt \n  #time.sleep(0.05)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"iuPd7QQFKHM2","trusted":true,"_uuid":"82e32343ef7609922e3fcadaef8a6973485beeb4"},"cell_type":"code","source":"#And this is for downloading test data into your drive\n\nimport json\nimport time\n\ntest_data = json.load(open('drive/kaggle/test.json'))\n#print len(test_data['images'])\n\nfor i in range(len(test_data['images'])):\n  img_url = test_data['images'][i]['url']\n  #print img_url\n  img_id = test_data['images'][i]['imageId']\n  #print img_id\n  img_name=img_url.split(\"/\")[-1]\n  #print img_name\n  img_name_actual = img_name.split(\"-\")[0]\n  img_name_small = img_name_actual + \"-small\"+\".jpg\"\n  #print img_name_actual\n  img_url_small = img_url.split(\"-\")[-2]\n  img_url_small = img_url_small + \"-small\"\n  print img_url_small\n  !curl $img_url_small > drive/kaggle/test/$img_name_small\n  time.sleep(0.05)\n  ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"PcHBDoTRpChw","_uuid":"d6796e3ec743d533dfab0ff4cba5982d0271a928"},"cell_type":"markdown","source":"###Note\n\n1.   This is it for now. Later, I shall include EDA and hopefully the actual CV architecture part! But boy, those data sets are too hot to handle :P\n\n2.   And yes, too large too! Anyway, it seems really fun to play with this dataset! Good luck to everyone!!\n\n**Upvote this kernel if you find it useful so that others can find it easily.**"}],"metadata":{"colab":{"collapsed_sections":[],"default_view":{},"name":"iMaterialist Challenge (Fashion) at FGVC5.ipynb","provenance":[],"version":"0.3.2","views":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}