{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:44.289522Z","iopub.status.busy":"2021-01-22T17:17:44.288842Z","iopub.status.idle":"2021-01-22T17:17:44.304034Z","shell.execute_reply":"2021-01-22T17:17:44.304428Z"},"papermill":{"duration":0.041308,"end_time":"2021-01-22T17:17:44.304555","exception":false,"start_time":"2021-01-22T17:17:44.263247","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:44.354226Z","iopub.status.busy":"2021-01-22T17:17:44.353493Z","iopub.status.idle":"2021-01-22T17:17:46.229569Z","shell.execute_reply":"2021-01-22T17:17:46.230064Z"},"papermill":{"duration":1.905821,"end_time":"2021-01-22T17:17:46.230216","exception":false,"start_time":"2021-01-22T17:17:44.324395","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import gc\nimport random\nfrom   tqdm import tqdm\nfrom   sklearn.model_selection import train_test_split\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport psutil\nimport datatable as dt\nfrom   collections import namedtuple\nfrom   sklearn.pipeline import Pipeline\nfrom   sklearn.impute import SimpleImputer\nfrom   sklearn.preprocessing import StandardScaler\nfrom   sklearn.pipeline import Pipeline\nimport lightgbm as lgb\nfrom   sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport pickle\nfrom   mlxtend.classifier import StackingClassifier, StackingCVClassifier\nfrom   sklearn.calibration import CalibratedClassifierCV\nimport os\nimport seaborn as sns\nfrom   sklearn.utils import shuffle\nimport datetime\nimport time\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import balanced_accuracy_score, recall_score, precision_score, confusion_matrix, make_scorer, f1_score, accuracy_score, precision_recall_fscore_support, matthews_corrcoef, roc_auc_score\n\nfrom scipy.sparse import csr_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport xgboost as xgb\nfrom sklearn.svm import LinearSVC\nfrom copy import deepcopy\n\nimport torch\n\nimport warnings\nwarnings.filterwarnings (\"ignore\")\nVERSION = ''","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.274887Z","iopub.status.busy":"2021-01-22T17:17:46.274271Z","iopub.status.idle":"2021-01-22T17:17:46.277244Z","shell.execute_reply":"2021-01-22T17:17:46.277733Z"},"papermill":{"duration":0.026557,"end_time":"2021-01-22T17:17:46.277837","exception":false,"start_time":"2021-01-22T17:17:46.25128","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Global Params\nSEED         = 420\nN_ESTIMATORS = 250\nDEVICE       = torch.device (\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.020628,"end_time":"2021-01-22T17:17:46.319614","exception":false,"start_time":"2021-01-22T17:17:46.298986","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Helpers"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.363696Z","iopub.status.busy":"2021-01-22T17:17:46.363199Z","iopub.status.idle":"2021-01-22T17:17:46.367043Z","shell.execute_reply":"2021-01-22T17:17:46.367518Z"},"papermill":{"duration":0.027158,"end_time":"2021-01-22T17:17:46.367617","exception":false,"start_time":"2021-01-22T17:17:46.340459","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"CV_SCORERS = {\n    'precision_score':         make_scorer (precision_score),\n    'recall_score':            make_scorer (recall_score),\n    'f1_score':                make_scorer (f1_score),\n    'balanced_accuracy_score': make_scorer (balanced_accuracy_score)\n}","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.411168Z","iopub.status.busy":"2021-01-22T17:17:46.410648Z","iopub.status.idle":"2021-01-22T17:17:46.418686Z","shell.execute_reply":"2021-01-22T17:17:46.419153Z"},"papermill":{"duration":0.031027,"end_time":"2021-01-22T17:17:46.41925","exception":false,"start_time":"2021-01-22T17:17:46.388223","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def pickleSave (obj, file):\n\n    if VERSION != '':\n\n        file, ext = os.path.splitext (file)\n        file += \"_v\" + str (VERSION) + ext\n    dirs = os.path.dirname (file) \n    if dirs:\n        os.makedirs (dirs, exist_ok=True)\n    with open (file, 'wb') as f:\n        pickle.dump (obj, f)\n    return\n\ndef unpickle (file):\n\n    if VERSION != '':\n\n        file, ext = os.path.splitext(file)\n        file += \"_v\" + str(VERSION) + ext\n    return pickle.load (open (file, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.463013Z","iopub.status.busy":"2021-01-22T17:17:46.462368Z","iopub.status.idle":"2021-01-22T17:17:46.509167Z","shell.execute_reply":"2021-01-22T17:17:46.509541Z"},"papermill":{"duration":0.069987,"end_time":"2021-01-22T17:17:46.509643","exception":false,"start_time":"2021-01-22T17:17:46.439656","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Best_clf_cv_transformer (BaseEstimator, TransformerMixin): \n    \n    def __init__(self, myparams={'name':'LSvc', 'C':1}, **other_params):\n        \n        self.myparams = myparams\n        self.myinit (**other_params)\n        return\n    \n    def myinit (self, **other_params):\n        \n        self.cv    =  5\n        if 'cv' in self.myparams:\n            self.cv= self.myparams['cv']\n        clf        =  None\n        name       =  self.myparams['name']\n        if name   == 'Logit':\n            clf    =  LogisticRegression (random_state=0)\n        elif name == 'DT':\n            clf    =  DecisionTreeClassifier (random_state=0)\n        elif name == 'RidgClf':\n            clf    =  RidgeClassifier (random_state=0)\n        elif name == 'Prcpt':\n            clf    =  Perceptron (random_state=0)\n        elif name == 'PssAggClf':\n            clf    =  PassiveAggressiveClassifier (random_state=0)\n        elif name == 'Knn':\n            clf    =  KNeighborsClassifier (random_state=0)\n        elif name == 'RF':\n            clf    =  RandomForestClassifier (random_state=0)\n        elif name == 'NearCent':\n            clf    =  NearestCentroid (random_state=0)\n        elif name == 'MultNB':\n            clf    =  MultinomialNB (random_state=0)\n        elif name == 'BernNB':\n            clf    =  BernoulliNB (random_state=0)    \n        elif name == 'Svc':\n            clf    =  SVC (probability=True, random_state=0)\n        elif name == 'LSvc':\n            clf    =  LinearSVC (random_state=0)\n        elif name == 'Xgb':\n            clf    =  xgb.XGBClassifier (random_state=0) # XGBRFClassifier()\n        elif name == 'Catb' :                            # issues with CV\n            clf    =  CatBoostClassifier (verbose=False, random_state=0)\n        elif name == 'FCNN':\n            clf    =  None    # init at  fit ()\n        else:\n            print('ERROR Best_clf_cv_transformer: invalid @param name \\n')\n            clf    = None\n        self.isCV = True\n        if 'isCV' in self.myparams:\n            \n            self.isCV = self.myparams['isCV']\n        self.n_estimators = 1\n        if 'n_estimators' in self.myparams:\n            \n            self.n_estimators = self.myparams['n_estimators']\n        if 'params' in self.myparams:\n            \n            clf.set_params (**self.myparams['params'])\n        if other_params:\n            \n            clf.set_params (**other_params)\n        self.param_grid = None\n        if 'param_grid' in self.myparams:\n            \n            self.param_grid = self.myparams['param_grid']\n        self.clf = clf\n        self.cv_score = 0\n        self.name = name\n        self._estimator_type='classifier'\n        return    \n    \n    def fit (self, X, Y, **FIT_PARAMS):\n        \n        train_len = len (Y[pd.isnull(Y)==False])\n        X, Y = X[:train_len], Y[:train_len]\n        print ('training', self.name, 'for X.shape =', X.shape)\n        n_jobs = -1    \n        if self.name == 'FCNN':\n            \n            lrScheduler = LRScheduler (\n                \n                CyclicLR,\n                base_lr=0.0001,\n                max_lr=0.05,\n                step_every='batch'\n            )\n            self.clf = NeuralNetClassifier (\n                \n                    module=MyModule,\n                    module__inputCount=X.shape[1], \n                    module__outputCount=2, \n                    module__hiddenLayerCounts=[15],\n                    max_epochs=1000,\n                    # lr=0.01,\n                    verbose=0,\n                    # Shuffle training data on each epoch\n                    iterator_train__shuffle=True,\n                    callbacks=[('LRScheduler', lrScheduler), ('EarlyStopping', EarlyStopping (patience=20))]\n            )\n            X = X.astype (np.float32)\n            Y = Y.astype (np.int64)\n            n_jobs = None\n        if self.isCV:\n            if self.param_grid:\n\n                gridSearchCV = GridSearchCV (\n                    self.clf, self.param_grid, iid=False, cv=self.cv, scoring=CV_SCORERS, \n                    refit='f1_score', n_jobs=n_jobs\n                )\n                gridSearchCV.fit (X, Y)  \n                print (self.name, \": Best_clf_cv_transformer: Best parameter (CV score=%0.3f):\" % gridSearchCV.best_score_)\n                print (gridSearchCV.best_params_)\n                self.clf = gridSearchCV.best_estimator_\n                self.cv_score = gridSearchCV.best_score_\n                if self.name == 'LSvc':\n                    \n                    self.clf = CalibratedClassifierCV (self.clf)\n                    # self.clf.fit (X, Y)\n                # global RESULTS\n                # RESULTS.append(benchmark(self.clf))\n                # TODO: Plot scores for each split, and get its' variance\n            else:\n\n                if self.name == 'LSvc':\n                    \n                    self.clf = CalibratedClassifierCV (self.clf)\n                print (self.name, ': Best_clf_cv_transformer: starting CV =', self.cv)\n                if self.name not in {'fss'}:  # {'RF', 'Catb', 'FCNN'}:\n                    \n                    cv_results = cross_validate (self.clf, X, Y, cv=int(self.cv))\n                else:\n                    \n                    voting_clf = VotingClassifier (estimators=[(self.name, self.clf)])\n                    cv_results = cross_validate (voting_clf, X, Y, cv=self.cv)\n                self.cv_score = np.mean (cv_results['test_score'])\n                # self.clf.fit (X, Y)\n                print (self.name, \": cv_score:   %0.3f\" % self.cv_score)\n        else:\n            if self.name == 'LSvc':\n                self.clf = CalibratedClassifierCV (self.clf)\n            # self.clf.fit (X, Y)\n        if self.n_estimators > 1:\n            self.clf = BaggingClassifier (base_estimator=self.clf, n_estimators=self.n_estimators)\n        self.clf.fit (X, Y)\n        print (\"Done Fitting\", self.name)\n        return self\n    \n    def get_cv_score (self):\n        return self.cv_score\n    \n    def transform (self, X, Y=None, **FIT_PARAMS):        \n        if self.name == 'FCNN':\n            X = X.astype (np.float32)\n            if not Y is None:\n                Y = Y.astype (np.int64)        \n        return self.clf.transform(X, Y)\n    \n    def predict (self, X, **FIT_PARAMS):        \n        if self.name == 'FCNN':\n            X = X.astype (np.float32)      \n        return self.clf.predict(X)\n    \n    def predict_proba (self, X):        \n        if self.name == 'FCNN':\n            X = X.astype (np.float32)      \n        return self.clf.predict_proba (X)\n    \n    def predict_log_proba (self, X):        \n        if self.name == 'FCNN':\n            X = X.astype (np.float32)\n        return self.clf.predict_log_proba (X)\n    \n    def score (self, X, Y, **FIT_PARAMS):        \n        if self.name == 'FCNN':\n            X = X.astype (np.float32)\n        return self.clf.score (X, Y, **FIT_PARAMS)\n    \n    def decision_function (self, X, **FIT_PARAMS):        \n        if self.name == 'FCNN':\n            X = X.astype (np.float32)\n        return self.clf.decision_function (X)\n    \n    def set_params (self, **params):        \n        self.myparams = params['myparams']\n        params.pop ('myparams')\n        self.myinit (**params)\n        return self\n    \n    def get_params (self, deep=True):\n        params = {'myparams': self.myparams}\n        return params\n    \n    def apply (self, X):\n        return self.clf.apply(X)\n    \n    def decision_path (self, X):\n        return self.clf.decision_path (X)\n    \n    def staged_decision_function (self, X):\n        return self.clf.staged_decision_function (X)\n    \n    def staged_predict (self, X):\n        return self.clf.staged_predict (X)\n    \n    def staged_predict_proba (self, X):\n        return self.clf.staged_predict_proba (X)\n    \n    def staged_score (self, X):\n        return self.clf.staged_score (X)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.553423Z","iopub.status.busy":"2021-01-22T17:17:46.552925Z","iopub.status.idle":"2021-01-22T17:17:46.556696Z","shell.execute_reply":"2021-01-22T17:17:46.55714Z"},"papermill":{"duration":0.026995,"end_time":"2021-01-22T17:17:46.557237","exception":false,"start_time":"2021-01-22T17:17:46.530242","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def seed_all ():\n    \n    random.seed (SEED)\n    np.random.seed (SEED)\n    random.seed (SEED)\n    \nseed_all ()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.020817,"end_time":"2021-01-22T17:17:46.599157","exception":false,"start_time":"2021-01-22T17:17:46.57834","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Read and preprocess the Data"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.685864Z","iopub.status.busy":"2021-01-22T17:17:46.685325Z","iopub.status.idle":"2021-01-22T17:17:46.69733Z","shell.execute_reply":"2021-01-22T17:17:46.697697Z"},"papermill":{"duration":0.035503,"end_time":"2021-01-22T17:17:46.697816","exception":false,"start_time":"2021-01-22T17:17:46.662313","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def load_preprocess_data (filename='../input/jane-street-market-prediction/train.csv', isTrainData=True):\n    \n    dtype = None\n    if isTrainData:\n        \n        dtype = {\n            'date'      : 'int64', \n            'weight'    : 'float64',\n            'resp'      : 'float64',\n            'ts_id'     : 'int64',  \n            'feature_0' : 'float64'\n        }\n    else:\n        \n        dtype = {\n            'date'      : 'int64', \n            'weight'    : 'float64',\n            'feature_0' : 'float64'\n        }\n    for i in range (1, 130):\n        k = 'feature_' + str (i)\n        dtype[k] = 'float32'\n    \n    X = pd.read_csv (filename, dtype=dtype)\n    \n    resp_cols   = ['resp_1', 'resp_2', 'resp_3','resp_4', 'resp']    \n    X           = X.query ('date > 85')\n    X           = X[X['weight'] != 0].reset_index (drop = True)\n    y           = np.stack ([(X[c] > 0).astype ('int') for c in resp_cols]).T\n    f_columns   = [c for c in X.columns if \"feature\" in c]    \n    Weights     = X['weight'].values.reshape ((-1,1))\n    \n    if isTrainData:\n        X.drop (columns=['date', 'weight', 'resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'ts_id'], inplace=True)\n    else:\n        X.drop (columns=['date', 'weight'], inplace=True)\n          \n    preprocess_pipe =  Pipeline ([\n        (\"imputer\", SimpleImputer (missing_values=np.nan, strategy='mean')),\n        # (\"stand\",   StandardScaler (with_mean=False))\n    ])\n    X = preprocess_pipe.fit_transform (X)\n    \n    X = np.hstack ((X, Weights))\n    \n    X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.05)\n    del X, y\n    gc.collect ()\n    \n    W_train = X_train[:, -1]\n    X_train = X_train[:, :-1]\n    W_test  = X_test[:, -1]\n    X_test  = X_test[:, :-1]\n    return X_train, X_test, y_train, y_test, W_train, W_test, preprocess_pipe","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:17:46.741829Z","iopub.status.busy":"2021-01-22T17:17:46.741237Z","iopub.status.idle":"2021-01-22T17:20:11.769898Z","shell.execute_reply":"2021-01-22T17:20:11.770324Z"},"papermill":{"duration":145.051961,"end_time":"2021-01-22T17:20:11.770454","exception":false,"start_time":"2021-01-22T17:17:46.718493","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_TRAIN, X_TEST, Y_TRAIN, Y_TEST, W_train, W_test, preprocess_pipe = load_preprocess_data ()\ngc.collect ()\nX_TRAIN.shape,  Y_TRAIN.shape","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:11.815737Z","iopub.status.busy":"2021-01-22T17:20:11.815207Z","iopub.status.idle":"2021-01-22T17:20:11.818054Z","shell.execute_reply":"2021-01-22T17:20:11.817558Z"},"papermill":{"duration":0.026722,"end_time":"2021-01-22T17:20:11.818142","exception":false,"start_time":"2021-01-22T17:20:11.79142","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# TODO: comment this\n# X_TRAIN = X_TRAIN[:50000]\n# Y_TRAIN = Y_TRAIN[:50000]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:11.864339Z","iopub.status.busy":"2021-01-22T17:20:11.863804Z","iopub.status.idle":"2021-01-22T17:20:11.865859Z","shell.execute_reply":"2021-01-22T17:20:11.86625Z"},"papermill":{"duration":0.027338,"end_time":"2021-01-22T17:20:11.866351","exception":false,"start_time":"2021-01-22T17:20:11.839013","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def learning_rate_010_decay_power_09 (current_iter):\n    \n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power (.995, current_iter)\n    return lr if lr > 1e-2 else 1e-2\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:11.913698Z","iopub.status.busy":"2021-01-22T17:20:11.913164Z","iopub.status.idle":"2021-01-22T17:20:11.916021Z","shell.execute_reply":"2021-01-22T17:20:11.915497Z"},"papermill":{"duration":0.028803,"end_time":"2021-01-22T17:20:11.916102","exception":false,"start_time":"2021-01-22T17:20:11.887299","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# n_estimators is set to a \"large value\" say 5000. The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n# or\n# train till a small say 600 rounds only and select the best esimator, then trail this estimator to 10,000 rounds with early stopping\n\n# Global Var\nFIT_PARAMS= {\n    \"early_stopping_rounds\":30, \n    \"eval_metric\" : 'auc', \n    \"eval_set\" : [(X_TEST, Y_TEST[:,-1])],\n    'eval_names': ['valid'],\n    'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_09)],\n    'verbose': 50,\n    'categorical_feature': 'auto'\n}","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021245,"end_time":"2021-01-22T17:20:11.958565","exception":false,"start_time":"2021-01-22T17:20:11.93732","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021122,"end_time":"2021-01-22T17:20:12.001112","exception":false,"start_time":"2021-01-22T17:20:11.97999","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Search for the best model under constraints"},{"metadata":{"papermill":{"duration":0.021689,"end_time":"2021-01-22T17:20:12.044096","exception":false,"start_time":"2021-01-22T17:20:12.022407","status":"completed"},"tags":[]},"cell_type":"markdown","source":"param_test = {\n     'num_leaves': sp_randint(6, 50), \n     'min_child_samples': sp_randint(100, 500), \n     'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n     'subsample': sp_uniform (loc=0.2, scale=0.8), \n     'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n     'reg_alpha' : [0, 1e-1, 1, 5,  10],\n     'reg_lambda': [0, 1e-1, 1, 10, 20]\n}\n\n#This parameter defines the number of HP points to be tested\nn_HP_points_to_test = 4\n\n# do a random search\nlgb_clf = lgb.LGBMClassifier (max_depth=-1, random_state=SEED, silent=True, metric='None', n_jobs=8, n_estimators=N_ESTIMATORS)\n\ngs = RandomizedSearchCV (\n    estimator=lgb_clf, \n    param_distributions=param_test, \n    n_iter=n_HP_points_to_test,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=314,\n    verbose=False\n)"},{"metadata":{"papermill":{"duration":0.021268,"end_time":"2021-01-22T17:20:12.086646","exception":false,"start_time":"2021-01-22T17:20:12.065378","status":"completed"},"scrolled":true,"tags":[]},"cell_type":"markdown","source":"# uncomment this to train from scratch\n\ngs.fit (X_TRAIN, Y_TRAIN, **FIT_PARAMS)\nprint ('Best score reached: {} with params: {} '.format (gs.best_score_, gs.best_params_))"},{"metadata":{"papermill":{"duration":0.021803,"end_time":"2021-01-22T17:20:12.13034","exception":false,"start_time":"2021-01-22T17:20:12.108537","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Opt Params"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:12.175909Z","iopub.status.busy":"2021-01-22T17:20:12.175127Z","iopub.status.idle":"2021-01-22T17:20:12.178195Z","shell.execute_reply":"2021-01-22T17:20:12.178702Z"},"papermill":{"duration":0.02701,"end_time":"2021-01-22T17:20:12.178812","exception":false,"start_time":"2021-01-22T17:20:12.151802","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# [600]\tvalid's auc: 0.601937\n# Best score reached: 0.598930845392645 with params: {'colsample_bytree': 0.6681799297021748, 'min_child_samples': 191, 'min_child_weight': 1, 'num_leaves': 46, 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.8720649952803985}","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:12.224599Z","iopub.status.busy":"2021-01-22T17:20:12.223849Z","iopub.status.idle":"2021-01-22T17:20:12.228896Z","shell.execute_reply":"2021-01-22T17:20:12.229344Z"},"papermill":{"duration":0.029283,"end_time":"2021-01-22T17:20:12.229447","exception":false,"start_time":"2021-01-22T17:20:12.200164","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Global Var\nOPT_PARAMS_1 = {'n_estimators': N_ESTIMATORS, 'colsample_bytree': 0.668, 'min_child_samples': 150, 'min_child_weight': 1, 'num_leaves': 80, 'reg_alpha': 0, 'reg_lambda': 0.002, 'subsample': 0.87}\nOPT_PARAMS_2 = {'n_estimators': N_ESTIMATORS, 'colsample_bytree': 0.668, 'min_child_samples': 190, 'min_child_weight': 1, 'num_leaves': 90, 'reg_alpha': 0, 'reg_lambda': 0.002, 'subsample': 0.87}","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021344,"end_time":"2021-01-22T17:20:12.272552","exception":false,"start_time":"2021-01-22T17:20:12.251208","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Create clf from the best params"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:12.319081Z","iopub.status.busy":"2021-01-22T17:20:12.318268Z","iopub.status.idle":"2021-01-22T17:20:12.32543Z","shell.execute_reply":"2021-01-22T17:20:12.325907Z"},"papermill":{"duration":0.031722,"end_time":"2021-01-22T17:20:12.326003","exception":false,"start_time":"2021-01-22T17:20:12.294281","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def create_train_lgbm (X_train, y_train, component):\n    \n    if component == 1:\n        opt_params = deepcopy (OPT_PARAMS_1)\n    else:\n        opt_params = deepcopy (OPT_PARAMS_2)\n        \n    # find #best-iterations\n    lgb_clf_1 = lgb.LGBMClassifier (**opt_params)   #;print ('X_train.shape =', X_train.shape),  ;print ('y_train.shape =', y_train.shape)\n    lgb_clf_1.fit (X_train, y_train, **FIT_PARAMS)\n\n    # refit on the #best-iterations\n    if lgb_clf_1.best_iteration_ != N_ESTIMATORS:\n        opt_params['n_estimators'] = lgb_clf_1.best_iteration_\n        lgb_clf_1  = lgb.LGBMClassifier (**opt_params)\n        lgb_clf_1.fit (X_train, y_train, **FIT_PARAMS)\n        \n    # save\n    # pickleSave (lgb_clf_1, str (model_id)+'_'+str (component)+'_lgbm.bin')\n\n    # sanity test\n    X_temp = X_train[10].reshape ((1, -1))\n    np.round (lgb_clf_1.predict (X_temp)).astype (int)\n    return lgb_clf_1","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:12.372174Z","iopub.status.busy":"2021-01-22T17:20:12.371382Z","iopub.status.idle":"2021-01-22T17:20:12.376794Z","shell.execute_reply":"2021-01-22T17:20:12.377233Z"},"papermill":{"duration":0.029797,"end_time":"2021-01-22T17:20:12.377324","exception":false,"start_time":"2021-01-22T17:20:12.347527","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def getLgbs ():\n    \n    LGBS    = []\n    for model_id in range (5):\n        \n        y_train = Y_TRAIN[:, model_id]        #;print ('X_TRAIN.shape =', X_TRAIN.shape),  ;print ('y_train.shape =', y_train.shape)\n        lgbm_1  = create_train_lgbm (X_TRAIN, y_train, 1)\n        lgbm_2  = create_train_lgbm (X_TRAIN, y_train, 2)\n        LGBS.append ((lgbm_1, lgbm_2))\n\n    # save\n    pickleSave (LGBS, 'lgbs.bin')\n    return LGBS","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021763,"end_time":"2021-01-22T17:20:12.420778","exception":false,"start_time":"2021-01-22T17:20:12.399015","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Stacking clf"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:12.467016Z","iopub.status.busy":"2021-01-22T17:20:12.466204Z","iopub.status.idle":"2021-01-22T17:20:12.474558Z","shell.execute_reply":"2021-01-22T17:20:12.474166Z"},"papermill":{"duration":0.032211,"end_time":"2021-01-22T17:20:12.474637","exception":false,"start_time":"2021-01-22T17:20:12.442426","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def getSclfs ():\n    \n    SCLFS = []\n    for model_id in range (5):\n\n        sclf = StackingClassifier (classifiers=LGBS[model_id], fit_base_estimators=False, \n                                   use_probas=True, average_probas=False, \n                                   meta_classifier=Best_clf_cv_transformer ({ 'name': 'LSvc',  'params': {'penalty': 'l2', 'class_weight': 'balanced'}, 'param_grid': {'C' : [0.01, 0.05, 0.1, 1]} }) )\n        sclf.name = 'sclf_' + str (model_id)\n        y_train   = Y_TRAIN[:, model_id]\n        sclf.fit (X_TRAIN, y_train)\n        SCLFS.append (sclf)\n\n    # save\n    pickleSave (SCLFS, 'sclfs.bin')\n\n    # sanity test\n    X_temp = X_TRAIN[10].reshape ((1, -1))\n    np.round (SCLFS[0].predict (X_temp)).astype (int)\n    return SCLFS","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:20:12.522399Z","iopub.status.busy":"2021-01-22T17:20:12.521902Z","iopub.status.idle":"2021-01-22T17:31:25.64277Z","shell.execute_reply":"2021-01-22T17:31:25.643871Z"},"papermill":{"duration":673.147237,"end_time":"2021-01-22T17:31:25.644308","exception":false,"start_time":"2021-01-22T17:20:12.497071","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Global Vars, Calling training\n# LGBS  = getLgbs ()\n# SCLFS = getSclfs ()\n\n# OR\n\n# use pre trained models\nLGBS  = unpickle ('../input/jane-lgbm-stackedlsvc/lgbs.bin')\nSCLFS = unpickle ('../input/jane-lgbm-stackedlsvc/sclfs.bin')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033168,"end_time":"2021-01-22T17:31:25.870297","exception":false,"start_time":"2021-01-22T17:31:25.837129","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Predict for X_test"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"THRESH = 0.50"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print ('Finding the optimal probability threshold..')\n\nY_TRAIN = np.median (Y_TRAIN, axis=1)\n\n# Random init threshold for gradient descent\nTH = torch.tensor (0.50, device=DEVICE, dtype=float, requires_grad=True)\n\n# Loss (W*Actual, W * Ceil (pr-TH))\nW_train = torch.tensor (W_train).float ()                   #;print ('W_train.shape =', W_train.size ())\nY_TRAIN = torch.tensor (Y_TRAIN).float ()\nX_TRAIN = torch.tensor (X_TRAIN).float ()\n\nA  = torch.tensor (W_train * Y_TRAIN)                       #;print ('A.shape =', A.size ())\n\n# create batches to fit in memory\nepochs  = 10\nlr      = 0.1\nbatches = 2\n\nfor e in range (epochs):\n    \n    lr *= 0.9\n    lr  = 0.01 if lr < 0.01 else lr\n    for b in range (batches):\n\n        batch_siz = X_TRAIN.size(0)//10\n        b_A       = A[b*batch_siz : (b+1)*batch_siz]\n        b_W_train = W_train[b*batch_siz : (b+1)*batch_siz]\n        b_X_train = X_TRAIN[b*batch_siz : (b+1)*batch_siz]\n        b_pr      = torch.tensor (predict (b_X_train.numpy ()))        #;print ('pr.shape =', b_pr.size ())\n\n        b_P       = b_W_train * torch.ceil (b_pr - TH) \n        # print ('b_W_train =', b_W_train, 'b_pr =', b_pr, 'torch.ceil(b_pr - TH) =', torch.ceil(b_pr - TH), 'b_P =', b_P)\n        # print ('(b_pr - TH).shape =', (b_pr - TH).size (), 'b_W_train.shape =', b_W_train.shape, 'b_P.shape =', b_P.shape)\n        b_loss    = (b_A - b_P).pow (2).mean ()\n        b_loss.backward ()    \n        with torch.no_grad ():\n            TH -= lr * TH.grad\n        TH.grad = None    \n\n        if b % batches == batches-1:\n            print('loss =', b_loss.item ())\n\nTHRESH = TH.detach ().numpy ()\nprint ('THRESH =', THRESH)\nTHRESH"},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:31:26.034815Z","iopub.status.busy":"2021-01-22T17:31:26.033953Z","iopub.status.idle":"2021-01-22T17:31:26.86479Z","shell.execute_reply":"2021-01-22T17:31:26.864247Z"},"papermill":{"duration":0.885243,"end_time":"2021-01-22T17:31:26.8649","exception":false,"start_time":"2021-01-22T17:31:25.979657","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def predict (test_df, isRetProb=False):\n    \n    test_df.drop (columns=['weight', 'date'], inplace=True)\n    test_df.reset_index (drop=True, inplace=True)\n    X_test = preprocess_pipe.transform (test_df).reshape ((-1, 130))\n    \n    y_probs = []\n    for sclf in SCLFS:\n        y_p = sclf.predict_proba (X_test).reshape ((-1, 2))[:, 1].reshape ((-1, 1))\n        y_probs.append (y_p)\n        \n    y_probs = np.hstack (y_probs)                 #;print ('y_probs.shape =', y_probs.shape, 'X_test.shape =', X_test.shape)\n    pred_pr = np.median (y_probs, axis=1)         #;print ('pred_pr.shape =', pred_pr.shape, 'pred_pr =', pred_pr) \n    y_pred  = (pred_pr >= 0.5).astype (int)\n    if isRetProb:\n        return y_pred, pred_pr\n    else:\n        return y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Pred"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"filename='../input/jane-street-market-prediction/train.csv'\n# eval the prediction\ndtype = {\n    'date'      : 'int64', \n    'weight'    : 'float64',\n    'resp'      : 'float64',\n    'ts_id'     : 'int64',  \n    'feature_0' : 'float64'\n}\nfor i in range (1, 130):\n    k = 'feature_' + str (i)\n    dtype[k] = 'float32'\n\ntest_df   = pd.read_csv (filename, dtype=dtype)\nresp_cols = ['resp_1', 'resp_2', 'resp_3','resp_4', 'resp']   \nY_test_df = np.stack ([(test_df[c] > 0).astype ('int') for c in resp_cols]).T\ntest_df.drop (columns=resp_cols+['ts_id'], inplace=True) \nY_test_df = np.mean (Y_test_df, axis=1)\npred_pr   = predict (test_df, True)[1]\npred_pr.shape"},{"metadata":{"papermill":{"duration":0.032966,"end_time":"2021-01-22T17:31:26.931136","exception":false,"start_time":"2021-01-22T17:31:26.89817","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Submission"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:31:27.002159Z","iopub.status.busy":"2021-01-22T17:31:27.00153Z","iopub.status.idle":"2021-01-22T17:31:27.022402Z","shell.execute_reply":"2021-01-22T17:31:27.022925Z"},"papermill":{"duration":0.0586,"end_time":"2021-01-22T17:31:27.023043","exception":false,"start_time":"2021-01-22T17:31:26.964443","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import janestreet\nenv      = janestreet.make_env () # initialize the environment\nenv_iter = env.iter_test ()       # an iterator which loops over the test set","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.035087,"end_time":"2021-01-22T17:31:27.091327","exception":false,"start_time":"2021-01-22T17:31:27.05624","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# For direct submission, without using the Trainer class"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:31:27.160524Z","iopub.status.busy":"2021-01-22T17:31:27.159772Z","iopub.status.idle":"2021-01-22T17:36:44.962072Z","shell.execute_reply":"2021-01-22T17:36:44.960851Z"},"papermill":{"duration":317.837702,"end_time":"2021-01-22T17:36:44.962194","exception":false,"start_time":"2021-01-22T17:31:27.124492","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"for test_df, pred_df in env_iter:\n    if test_df[\"weight\"].item () > 0:\n        \n        predictions    = predict (test_df)\n        pred_df.action = predictions\n    else:\n        pred_df.action = 0\n        \n    # print (pred_df)\n    # print (\"--------------\")\n    env.predict (pred_df)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-22T17:36:45.044988Z","iopub.status.busy":"2021-01-22T17:36:45.044392Z","iopub.status.idle":"2021-01-22T17:36:45.047803Z","shell.execute_reply":"2021-01-22T17:36:45.047296Z"},"papermill":{"duration":0.047695,"end_time":"2021-01-22T17:36:45.047901","exception":false,"start_time":"2021-01-22T17:36:45.000206","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print ('Done !')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.03364,"end_time":"2021-01-22T17:36:45.114887","exception":false,"start_time":"2021-01-22T17:36:45.081247","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}