{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\n\nimport pandas as pd\nimport numpy as np\nimport plotnine as pn\nimport matplotlib.pyplot as plt \nimport dask.dataframe as dd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read subset of training data to make EDA simpler to handle"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/jane-street-market-prediction/train.csv\", nrows=20000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = (train.weight * train.resp > 0).astype(int)\ntrain.loc[:, 'target'] = target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Directly, we notice `feature_0` as different from the others. 1 and -1 seems weird to be stock market prices at least"},{"metadata":{},"cell_type":"markdown","source":"For each `date` $i$ we have\n\n$$p_i = \\sum_j(weight_{ij} * resp_{ij} * action_{ij}),$$\n\nwhich we input to \n\n$$t = \\frac{\\sum p_i }{\\sqrt{\\sum p_i^2}} * \\sqrt{\\frac{250}{|i|}}.$$\n\nwhere $|i|$ is the number of unique days in the sample. The utility score is finally\n\n$$u = \\min(\\max(t,0), 6)  \\sum p_i.$$\n\nFor comparison, the Sharpe ratio is defined as \n\n$$\\text{Sharpe Ratio} = \\frac{R_p - R_f}{\\sigma_p}$$\n\nwhere $R_p$ is the return of the portolfio, $R_f$ is the risk-free return, and $\\sigma_p$ is the volatility of the portfolio excess return."},{"metadata":{},"cell_type":"markdown","source":"Say that we would predict action 1 and 0 at random"},{"metadata":{"trusted":true},"cell_type":"code","source":"action = np.random.randint(2, size=len(train.index))\ny_pred = pd.DataFrame(dict(action=action), index=train.date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The utility score using our mock predictions for date 0 is"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_utility(df: pd.DataFrame, y_pred: pd.Series) -> int:\n    unique_dates = train.date.unique()\n    ps = np.array([0] * unique_dates)\n    for i in unique_dates:\n        t0 = train.loc[train.date == i]\n        y0 = y_pred.loc[y_pred.index == i]\n        p = sum(np.multiply(t0.weight, np.multiply(np.array(t0.resp), np.array(y0.action))))\n        ps[i] = p\n    t = sum(ps) / np.sqrt(sum(ps ** 2)) * np.sqrt(250 / len(unique_dates))\n    u = min(max(t, 0), 6) * sum(ps)\n    return u","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simulate for $N$ rounds"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nseed = 42\nnp.random.seed(seed)\nN = 1000\nus = []\nfor i in tqdm(range(N)):\n    action = np.random.randint(2, size=len(train.index))\n    y_pred = pd.DataFrame(dict(action=action), index=train.date)\n    us.append(calculate_utility(train, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\npd.Series(us).hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we're able to predict all trades with positive return?"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = train[[\"date\", \"target\"]]\ny_pred = y_pred.set_index(\"date\")\ny_pred.columns = [\"action\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculate_utility(train, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore the features"},{"metadata":{"trusted":true},"cell_type":"code","source":"b = train.columns.str.contains(\"feature\")\nfeatures = train[train.columns[b]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.describe().iloc[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plt = features.iloc[:500, 1:3].reset_index()\nm = pd.melt(df_plt, value_vars=[\"feature_1\", \"feature_2\"], id_vars=\"index\")\n(pn.ggplot(m, pn.aes(x=\"index\", y=\"value\", color=\"variable\")) \n + pn.geom_line()\n + pn.xlab(\"Time\")\n + pn.ylab(\"Return\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Return seem to be capped for some assets"},{"metadata":{},"cell_type":"markdown","source":"### Correlation analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"b = train.columns.str.contains(\"feature\")\nfeatures = train[train.columns[b]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmat = features.corr()\nplt.figure(figsize=(12, 10))\nsns.heatmap(cmat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two obvious areas that need further exploration: Features around the sixties, and the large negative correlations around 30."},{"metadata":{"trusted":true},"cell_type":"code","source":"c = cmat.abs().unstack().sort_values(ascending=False)[len(features.columns):len(features.columns) + 10]\nc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assets 60-69 seem to be coming from the same asset class, or classes that are strongly correlated in some sense."},{"metadata":{"trusted":true},"cell_type":"code","source":"sixties = [\"feature_\" + str(i) for i in range(60, 70)]\nf = features.columns.isin(sixties)\nsdf = features[features.columns[f]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plt(df_plt: pd.DataFrame, value_vars: list):\n    m = pd.melt(df_plt.reset_index(), value_vars=value_vars, id_vars=\"index\")\n    return (\n        pn.ggplot(m, pn.aes(x=\"index\", y=\"value\", color=\"variable\")) \n        + pn.geom_line()\n        + pn.xlab(\"Time\")\n    )\ndf_plt = sdf.iloc[:1000, :]\nplt(df_plt, sixties)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf = sdf.filter(regex=\"[0-5]\")\nlower_sixties = list(ldf.columns)\nplt(ldf.iloc[1000:2000, :], lower_sixties)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are those monotonically increasing  feature 64? Trend?"},{"metadata":{"trusted":true},"cell_type":"code","source":"f64 = features[[\"feature_64\"]]\nplt(f64.iloc[:, :], [\"feature_64\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature summary:\n\n* Features 60-65\n\n    * Feature 64 seem to be a piecewise, with monotonically(almost, see around time 15000) incerasing functions\n    * Features 61-63 and 65 seem to be capped from above, and only have \"negative return\". Is that shorting behaviour, and should we analyse the absolute values?\n    "},{"metadata":{},"cell_type":"markdown","source":"## Missingness Handling"},{"metadata":{"trusted":true},"cell_type":"code","source":"(features.isnull().sum() / len(features.index)).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How are missing values distributed over time?"},{"metadata":{"trusted":true},"cell_type":"code","source":"features.isnull().sum(axis=1).plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values seem to be clustered, with regular spikes and hill-looking values."},{"metadata":{},"cell_type":"markdown","source":"## Full dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = dd.read_csv(\"../input/jane-street-market-prediction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ncols = train.shape[1]\nnrows = train.shape[0].compute()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Columns: {ncols}\\nRows: {nrows}\".format(ncols=ncols, nrows=nrows))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}