{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\nimport pandas as pd\nimport numpy as np\nimport cupy as cp\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\nimport datatable\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loading...')\ntrain = datatable.fread('/kaggle/input/jane-street-market-prediction/train.csv').to_pandas()\nfeatures = [c for c in train.columns if 'feature' in c]\n\nprint('Filling...')\nf_mean = train[features[1:]].mean()\ntrain = train.query('weight > 0').reset_index(drop = True)\ntrain[features[1:]] = train[features[1:]].fillna(f_mean)\ntrain['action'] = (train['resp'] > 0).astype('int')\n\nprint('Converting...')\nf_mean = np.array(f_mean)\nnp.save('f_mean.npy', f_mean)\n\nprint('Finish.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 4096\nhidden_units = [384, 896, 896, 394]\ndropout_rates = [0.10143786981358652, 0.19720339053599725, 0.2703017847244654, 0.23148340929571917, 0.2357768967777311]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\noof = np.zeros(len(train['action']))\ngkf = GroupKFold(n_splits = 5)\nfor fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n    X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n    y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n\n    ckp_path = f'JSModel_{fold}.hdf5'\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n                         min_delta = 1e-4, mode = 'max')\n    ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n                       save_best_only = True, save_weights_only = True, mode = 'max')\n    es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                    baseline = None, restore_best_weights = True, verbose = 0)\n    model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 1000, \n           batch_size = batch_size, callbacks = [rlr, ckp, es], verbose = 0)\n    oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n    score = roc_auc_score(y_val, oof[te])\n    print(f'Fold {fold} ROC AUC:\\t', score)\n    # Finetune 3 epochs on validation set with small learning rate\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate / 100)\n    model.load_weights(ckp_path)\n    model.fit(X_val, y_val, epochs = 3, batch_size = batch_size, verbose = 0)\n    model.save_weights(ckp_path)\n    K.clear_session()\n    del model\n    rubbish = gc.collect()\n        \n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_oof = roc_auc_score(train['action'].values, oof)\nprint(score_oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}