{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jane Street Market Prediction"},{"metadata":{},"cell_type":"markdown","source":"## Scikit-learn 0.24 install\n\nRequired for TimeSeriesSplit with the gap parameter. For more details on getting the install file, check [this notebook](https://www.kaggle.com/heylav/time-series-split-with-gap-using-just-sklearn)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# install from file; ignore the message regarding autogloun-core since that is not used \n!pip install ../input/scikitlearn024/scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# success check (should say 0.24)\n!pip freeze | grep scikit-learn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading\n\nRead the training data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_data = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/train.csv\", index_col='ts_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data filtering\n\n* Operations with non-positive weight are irrelevant for scoring, so ignored.\n\n* For RAM saving, numeric (int or float) data is made to use 32 bits instead of 64. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ntrain_data = train_data[train_data[\"weight\"] > 0]\ntrain_data.reset_index(drop=True, inplace=True)\ntrain_data.set_index('ts_id')\n\ntrain_data = train_data.astype({col: np.float32 for col in train_data.select_dtypes('float64').columns})\ntrain_data = train_data.astype({col: np.int32 for col in train_data.select_dtypes('int64').columns})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features and target definition\n\nSet which are the predictors (x) and the variable to predict (y)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# the target variable is the action (1 to make the trading operation and 0 to skip it);\n# in training, the operation is considered positive if it has positive return (the future time horizons are not used in evaluation metric)\ntrain_data['action'] = (train_data['resp'] > 0.0001).astype('int')\n\n# the only target variable is the action: this is a binary classification problem\nfull_y_train = train_data['action']\n\n# the predictor variables are the feature columns\nx_cols = ['feature_' + str(i) for i in range(0, 130)]\nfull_x_train = train_data[x_cols]\n\n# date series to be used in splitting\ndate_series = train_data['date']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time Series Splitting\n\nThe data in the competition is a time series, so to avoid potential information leakage a splitting technique where validation data is always temporarily later than training data."},{"metadata":{},"cell_type":"markdown","source":"Find the date range: dates will be the splitting unit, to avoid having operations of the same day in multiple splits (which could happen if we splitted at operation level instead)."},{"metadata":{"trusted":true},"cell_type":"code","source":"min_date = date_series.min()\nmax_date = date_series.max()\n\ndates = list(range(min_date, max_date + 1))\nprint(dates)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perform the date-level splitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\n\nsplit_num = 5\ndate_gap_num = 1\n\nsplitter = TimeSeriesSplit(n_splits=split_num, gap=date_gap_num)\ndate_splits = list(splitter.split(dates))\nfor i, (train_dates, valid_dates) in enumerate(date_splits):\n    print(\"Date split #{}\\n train: {}\\nvalid: {}\\n\\n\".format(i, train_dates, valid_dates))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the data frame indices associated to each split, based on dates. Note: if instead of the index you want whole data frame or series splits, see the Version 1 of this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_indices_from_dates(dates):\n    return [ i - 1 for i in date_series[date_series.isin(dates)].index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_indices = list()\nfor train_dates, valid_dates in date_splits:\n    train_indices = get_indices_from_dates(train_dates)\n    valid_indices = get_indices_from_dates(valid_dates)\n    split_indices.append((train_indices, valid_indices))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cross validation\n\nUse the splits to run cross validation using a classification model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Replace with your model here, this is just a non-optimized example, with few estimators for fast run-time\nmodel = XGBClassifier(tree_method='gpu_hist', n_estimators=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncv_scores = cross_val_score(model, full_x_train.values, full_y_train, cv=split_indices, scoring='f1')\nprint(\"Scores:\", cv_scores, \"\\tmean score:\", np.mean(cv_scores))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}