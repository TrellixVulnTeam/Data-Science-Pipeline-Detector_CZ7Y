{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'><a> Imports </a></font>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cudf\nimport torch\nimport joblib\nimport janestreet\nimport numpy as np\nimport cupy as cp\nfrom time import time\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom contextlib import contextmanager\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import QuantileTransformer\nfrom cupyx.scipy.special import erfinv as cupy_erfinv\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\nLEARNING_RATE = 1e-3\nWEIGHT_DECAY = 1e-5\nEARLY = 4\nDEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'><a> Read Data </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"@contextmanager\ndef timer(name):\n    t0 = time()\n    yield\n    print(f'[{name}] done in {time() - t0:.2f} s')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer('cuDF'):\n    train = cudf.read_csv('../input/jane-street-market-prediction/train.csv',nrows=1e4)\n    test = cudf.read_csv(\"../input/jane-street-market-prediction/example_test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = list(np.setdiff1d(train.columns,test.columns)) + ['ts_id','date']\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'><a> Dataset </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class janeDataset(Dataset):\n    \n    def __init__(self,df,target,mode=\"train\"):\n        \n        self.df = df.values\n        self.mode = mode\n        if self.mode == 'train':\n            self.target = target.values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        \n        if self.mode==\"train\":\n            \n            return {'x':torch.FloatTensor(self.df[idx,:]),\n                    'y':torch.FloatTensor(self.target[idx])}\n        else:\n            \n            return {'x':torch.FloatTensor(self.df[idx,:])}\n            \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'><a> Model </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class JaneModel(nn.Module):\n    \n    def __init__(self):\n        super(JaneModel,self).__init__()\n        \n        self.hidden = [131,64,16]\n        self.batch1 = nn.BatchNorm1d(self.hidden[0])\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(self.hidden[0],self.hidden[1]))\n        \n        self.batch2 = nn.BatchNorm1d(self.hidden[1])\n        self.dropout2 = nn.Dropout(0.15)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(self.hidden[1],self.hidden[2]))\n        \n        \n        self.batch3 = nn.BatchNorm1d(self.hidden[2])\n        self.dense3 = nn.utils.weight_norm(nn.Linear(self.hidden[2],1))\n        \n        \n    def forward(self,x):\n        \n        x = self.batch1(x)\n        x = self.dropout1(x)\n        x = F.leaky_relu(self.dense1(x))\n        \n        x = self.batch2(x)\n        x = self.dropout2(x)\n        x = F.leaky_relu(self.dense2(x))\n    \n        x = self.batch3(x)\n        x = torch.sigmoid(self.dense3(x))\n        \n        return x\n        \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font size='4' ><a> Preprocess </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train[train['weight']!=0]\ntarget = (train['resp']>0)*1\nprint(train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef do_preprocess(train,mode=1):\n    \n    features = [f'feature_{i}' for i in range(1,130)]+['weight']\n    \n    def to_labels(x):\n        if x==1:\n            return 0\n        else:\n            return 1\n    \n    \n    for col in features :\n        \n        train[col].fillna(train[col].mean(),inplace=True)\n        \n    if mode:\n\n            transformer = StandardScaler()\n            matrix = train[features].as_matrix()\n            scaled_data = transformer.fit_transform(matrix)\n            scaled_data  = cudf.DataFrame(scaled_data)\n            scaled_data.columns = features\n            joblib.dump(transformer,f'{col}.pkl')\n        \n    else:\n            transformer = joblib.load(f'{col}.pkl')\n            matrix = train[features].as_matrix()\n            scaled_data = transformer.transform(matrix)\n            scaled_data = cudf.DataFrame(scaled_data)\n            scaled_data.columns = features\n\n            \n\n   \n    train['feature_0'].fillna(-1,inplace=True)\n    scaled_data['feature_0']=train['feature_0'].applymap(to_labels).values\n    \n    \n\n        \n        \n    return train\n\n\n\ntrain = do_preprocess(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n    model.train()\n    final_loss = 0\n    final_auc = 0\n    \n    for data in dataloader:\n        optimizer.zero_grad()\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n        outputs = model(inputs).squeeze()\n        loss = loss_fn(outputs, targets)\n        auc = roc_auc_score(targets.detach().cpu().numpy(),outputs.detach().cpu().numpy())\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        final_loss += loss.item()\n        final_auc += auc\n        \n    final_loss /= len(dataloader)\n    final_auc /= len(dataloader)\n    \n    return final_loss,final_auc\n\ndef valid_fn(model, loss_fn, dataloader, device):\n    model.eval()\n    final_loss = 0\n    final_auc = 0\n    valid_preds = []\n    \n    for data in dataloader:\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n        outputs = model(inputs).squeeze()\n        loss = loss_fn(outputs, targets)\n        auc = roc_auc_score(targets.detach().cpu().numpy(),outputs.detach().cpu().numpy())\n        \n        final_loss += loss.item()\n        final_auc += auc\n        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    final_loss /= len(dataloader)\n    final_auc /= len(dataloader)\n    valid_preds = np.concatenate(valid_preds)\n    \n    return final_loss,final_auc,valid_preds\n\ndef inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n    \n    for data in dataloader:\n        inputs = data['x'].to(device)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n        \n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    preds = np.concatenate(preds)\n    \n    return preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'><a> Training </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(train,target):\n    \n    train.fillna(-1,inplace=True)\n    X_train,X_valid,y_train,y_valid  = train_test_split(train.drop(drop_cols,axis=1),target,test_size=0.15)\n    \n    train_data = janeDataset(X_train,y_train)\n    valid_data = janeDataset(X_valid,y_valid)\n    \n    train_data = DataLoader(train_data,batch_size=2**10,shuffle=True)\n    valid_data = DataLoader(valid_data,batch_size=2**10,shuffle=True)\n    \n    model = JaneModel()\n    model.to(DEVICE)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(train_data))\n    loss_fn = nn.BCEWithLogitsLoss()\n    best_loss = np.inf\n    \n    for epoch in range(EPOCHS):\n            \n            train_loss,train_auc = train_fn(model, optimizer, scheduler, loss_fn, train_data, DEVICE)\n            final_loss,valid_auc,valid_pred = valid_fn(model, loss_fn, valid_data, DEVICE)\n            print(f\" Epoch {epoch} train loss {train_loss : .5f} valid loss {final_loss : .5f} train_auc {train_auc: .4f} valid_auc {valid_auc : .4f}\")\n            \n            if final_loss<best_loss:\n                \n                best_loss = final_loss\n                torch.save(model.state_dict(),f'jane_model.pth')\n                early_stop=0\n            if EARLY:\n                early_stop+=1\n                if early_stop>EARLY:\n                    break\n        \n        \n\ntrain_model(train,target)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'><a> Inference </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = JaneModel()\nmodel.load_state_dict(torch.load(\"jane_model.pth\"))\nmodel.to(DEVICE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env() \niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nfor (test,sample_pred) in tqdm(iter_test):\n    \n    test = cudf.from_pandas(test)\n    test = test[train.drop(drop_cols,axis=1).columns]\n    test = do_preprocess(test,mode=0)\n    test_ = janeDataset(test,None,mode='test')\n    test_ = DataLoader(test_,batch_size=2**12,shuffle=False)\n    predictions = inference_fn(model,test_,DEVICE)\n    sample_pred.action = np.round(predictions).reshape(1,-1)\n    env.predict(sample_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='green'><a> WORK IN PROGRESS !!! DO AN UPVOTE IF YOU LIKED IT </a></font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}