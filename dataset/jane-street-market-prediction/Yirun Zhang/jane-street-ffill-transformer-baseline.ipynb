{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jane Street: ðŸ”¥TransformerðŸ”¥ Baseline\n\nTransformer is very popular among time-series competitions. This notebook provides the training and inference pipelines for transformer encoder implementation. Due to the long training time, I only test a small model with small window size for inference (e.g., window size equals to 5). You may get better results by tuning the structure and hyperparameters as well as the window size.\n\nIn the latest version, I use numpy sliding-window function to create training samples instead of TensorFlow Dataset. It makes training faster but more memory consuming.\n\n![Transformer.png](attachment:Transformer.png)","attachments":{"Transformer.png":{"image/png":"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"}}},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\ndevice = 'GPU' if 'GPU' in tf.test.gpu_device_name() else 'CPU/TPU'\nprint('Device:', device)\n\nimport os, gc, random, datetime\nif device == 'GPU':\n    import cudf\n    import cupy as cp\nimport pandas as pd\nimport numpy as np\nimport janestreet\nimport xgboost as xgb\nimport datatable as dtable\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\nfrom time import time\nfrom numba import njit\n\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIXED_PRECISION = False\nXLA_ACCELERATE = True\n\nif MIXED_PRECISION:\n    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    mixed_precision.set_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"%%time\n\nprint('Loading...')\ntrain = dtable.fread('../input/jane-street-market-prediction/train.csv').to_pandas()\nfeatures = [c for c in train.columns if 'feature' in c]\n\nprint('Filling...')\ntrain = train.query('weight > 0').reset_index(drop = True)\ntrain[features] = train[features].fillna(method = 'ffill').fillna(0)\ntrain['action'] = (train['resp'] > 0).astype('int')\n\nprint('Finish.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{},"cell_type":"markdown","source":"Base Transformer structure from https://www.tensorflow.org/tutorials/text/transformer, modified with Swish activation function."},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def scaled_dot_product_attention(q, k, v, mask):\n    \"\"\"Calculate the attention weights.\n    q, k, v must have matching leading dimensions.\n    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n    The mask has different shapes depending on its type(padding or look ahead) \n    but it must be broadcastable for addition.\n\n    Args:\n    q: query shape == (..., seq_len_q, depth)\n    k: key shape == (..., seq_len_k, depth)\n    v: value shape == (..., seq_len_v, depth_v)\n    mask: Float tensor with shape broadcastable \n          to (..., seq_len_q, seq_len_k). Defaults to None.\n\n    Returns:\n    output, attention_weights\n    \"\"\"\n\n    matmul_qk = tf.matmul(q, k, transpose_b = True)  # (..., seq_len_q, seq_len_k)\n\n    # scale matmul_qk\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    # add the mask to the scaled tensor.\n    if mask is not None:\n        \n        scaled_attention_logits += (mask * -1e9)  \n\n    # softmax is normalized on the last axis (seq_len_k) so that the scores\n    # add up to 1.\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)  # (..., seq_len_q, seq_len_k)\n\n    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n\n    return output, attention_weights\n\nclass MultiHeadAttention(tf.keras.layers.Layer):\n    \n    def __init__(self, d_model, num_heads):\n        \n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n\n        assert d_model % self.num_heads == 0\n\n        self.depth = d_model // self.num_heads\n\n        self.wq = tf.keras.layers.Dense(d_model)\n        self.wk = tf.keras.layers.Dense(d_model)\n        self.wv = tf.keras.layers.Dense(d_model)\n\n        self.dense = tf.keras.layers.Dense(d_model)\n        \n    def split_heads(self, x, batch_size):\n        \"\"\"Split the last dimension into (num_heads, depth).\n        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n        \"\"\"\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm = [0, 2, 1, 3])\n    \n    def call(self, v, k, q, mask):\n        \n        batch_size = tf.shape(q)[0]\n\n        q = self.wq(q)  # (batch_size, seq_len, d_model)\n        k = self.wk(k)  # (batch_size, seq_len, d_model)\n        v = self.wv(v)  # (batch_size, seq_len, d_model)\n\n        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n\n        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n        scaled_attention, attention_weights = scaled_dot_product_attention(\n            q, k, v, mask)\n\n        scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n\n        concat_attention = tf.reshape(scaled_attention, \n                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n\n        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n        \n        return output, attention_weights\n\ndef point_wise_feed_forward_network(d_model, dff):\n    \n    return tf.keras.Sequential([\n      tf.keras.layers.Dense(dff, activation = 'swish'),  # (batch_size, seq_len, dff)\n      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n    ])\n\nclass EncoderLayer(tf.keras.layers.Layer):\n    \n    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n        \n        super(EncoderLayer, self).__init__()\n\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n\n    def call(self, x, training, mask):\n\n        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n        attn_output = self.dropout1(attn_output, training = training)\n        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n\n        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n        ffn_output = self.dropout2(ffn_output, training = training)\n        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n\n        return out2\n\nclass TransformerEncoder(tf.keras.layers.Layer):\n    \n    def __init__(self, num_layers, d_model, num_heads, dff, \n                 maximum_position_encoding, rate = 0.1):\n        \n        super(TransformerEncoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.dff = dff\n        self.maximum_position_encoding = maximum_position_encoding\n        self.rate = rate\n\n#         self.pos_encoding = positional_encoding(self.maximum_position_encoding, \n#                                                 self.d_model)\n#         self.embedding = tf.keras.layers.Dense(self.d_model)\n        self.pos_emb = tf.keras.layers.Embedding(input_dim = self.maximum_position_encoding, \n                                                 output_dim = self.d_model)\n\n        self.enc_layers = [EncoderLayer(self.d_model, self.num_heads, self.dff, self.rate) \n                           for _ in range(self.num_layers)]\n\n        self.dropout = tf.keras.layers.Dropout(self.rate)\n        \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'num_layers': self.num_layers,\n            'd_model': self.d_model,\n            'num_heads': self.num_heads,\n            'dff': self.dff,\n            'maximum_position_encoding': self.maximum_position_encoding,\n            'dropout': self.dropout,\n        })\n        return config\n\n    def call(self, x, training, mask = None):\n\n        seq_len = tf.shape(x)[1]\n\n        # adding embedding and position encoding.\n#         x += self.pos_encoding[:, :seq_len, :]\n#         x = self.embedding(x)\n        positions = tf.range(start = 0, limit = seq_len, delta = 1)\n        x += self.pos_emb(positions)\n\n        x = self.dropout(x, training = training)\n\n        for i in range(self.num_layers):\n\n            x = self.enc_layers[i](x, training, mask)\n\n        return x  # (batch_size, input_seq_len, d_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_transformer_model(num_columns, num_labels, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (window_size, num_columns))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dense(d_model)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    x = tf.keras.layers.SpatialDropout1D(dropout_rate)(x)\n    x = TransformerEncoder(num_layers, d_model, num_heads, dff, window_size, dropout_rate)(x)\n    out = tf.keras.layers.Dense(num_labels, activation = 'sigmoid')(x[:, -1, :])\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay = weight_decay, learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are some configurations. I use a small model for inference test."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096 * strategy.num_replicas_in_sync\nnum_layers = 1\nd_model = 96\nnum_heads = 1\ndff = 64\nwindow_size = 3\ndropout_rate = 0.15\nweight_decay = 0\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3 * strategy.num_replicas_in_sync\nverbose = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate)\nmodel.summary()\n\nK.clear_session()\ndel model\nrubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Tensorflow Dataset\ndef prepare_dataset(X, y, window_size, batch_size, mode = 'training'):\n    x_ds = tf.data.Dataset.from_tensor_slices(X) \n    y_ds = tf.data.Dataset.from_tensor_slices(y[window_size - 1:])\n    x_ds = x_ds.window(window_size, shift = 1, drop_remainder = True)\n    x_ds = x_ds.flat_map(lambda window: window.batch(window_size))\n    dataset = tf.data.Dataset.zip((x_ds, y_ds))\n    if mode == 'training':\n        buffer_size = batch_size * 8\n        dataset = dataset.repeat()\n        dataset = dataset.shuffle(buffer_size, reshuffle_each_iteration = True)\n        dataset = dataset.batch(batch_size)#, drop_remainder = True\n    elif mode == 'validation':\n        dataset = dataset.batch(batch_size)\n        dataset = dataset.cache() \n    elif mode == 'testing':\n        dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# Use Numpy [may cause Out-of-Memory (OOM) error]\ndef rolling_window(a, shape):  # rolling window for 2D array\n    s = (a.shape[0] - shape[0] + 1,) + (a.shape[1] - shape[1] + 1,) + shape\n    strides = a.strides + a.strides\n    return np.squeeze(np.lib.stride_tricks.as_strided(a, shape = s, strides = strides), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Test-Split Training\n\nSplit the train set into three folds, i.e., training-1, training-2 and validation sets. First, train the more on training-1 set and validate it on the validation set. Then use the training-2 set to find the best number of finetuning epochs. Finally, finetune on both training-2 and validation sets and submit."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr = train.loc[train['date'] < 303, features].values\ny_tr = train.loc[train['date'] < 303, 'action'].values\n\nX_tr2 = train.loc[(train['date'] >= 303) & (train['date'] <= 367), features].values\ny_tr2 = train.loc[(train['date'] >= 303) & (train['date'] <= 367), 'action'].values\n\nX_val = train.loc[train['date'] > 367, features].values\ny_val = train.loc[train['date'] > 367, 'action'].values\n\nrubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr = rolling_window(X_tr, (window_size, len(features)))\nX_val = rolling_window(X_val, (window_size, len(features)))\ny_tr = y_tr[window_size - 1:]\ny_val = y_val[window_size - 1:]\nX_tr2 = rolling_window(X_tr2, (window_size, len(features)))\ny_tr2 = y_tr2[window_size - 1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train on the training-1 set and validate on the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time_fold = time()\n\nckp_path = 'JSTransformer.hdf5'\nwith strategy.scope():\n    model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate)\nrlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = verbose, \n                        min_delta = 1e-4, mode = 'max')\nckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n                      save_best_only = True, save_weights_only = True, mode = 'max')\nes = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                   baseline = None, restore_best_weights = True, verbose = 0)\nhistory = model.fit(X_tr, y_tr, validation_data = (X_val, y_val), batch_size = batch_size,\n                    epochs = 1000, callbacks = [rlr, ckp, es], verbose = verbose)\nhist = pd.DataFrame(history.history)\nprint(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] ROC AUC:\\t', hist['val_AUC'].max())\n\nK.clear_session()\ndel model, X_tr, y_tr\nrubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the best number of epochs for finetuning."},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time_fold = time()\n\nwith strategy.scope():\n    model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, \n                                     window_size, dropout_rate, weight_decay, label_smoothing, \n                                     learning_rate / 100)\nmodel.load_weights(ckp_path)\nes = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                   baseline = None, restore_best_weights = True, verbose = 0)\nhistory2 = model.fit(X_tr2, y_tr2, validation_data = (X_val, y_val), batch_size = batch_size,\n                    epochs = 1000, callbacks = [es], verbose = verbose)\nhist2 = pd.DataFrame(history2.history)\nprint(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] ROC AUC:\\t', hist2['val_AUC'].max())\nfinetune_epochs = hist2['val_AUC'].argmax() + 1\n\nK.clear_session()\ndel model\nrubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train on both training-2 and validation sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, \n                                     window_size, dropout_rate, weight_decay, label_smoothing, \n                                     learning_rate / 100)\nmodel.load_weights(ckp_path)\nmodel.fit(np.concatenate((X_tr2, X_val)), np.concatenate((y_tr2, y_val)), \n          batch_size = batch_size,epochs = finetune_epochs, verbose = verbose)\nmodel.save_weights(ckp_path)\n\nK.clear_session()\ndel model, X_tr2, y_tr2, X_val, y_val\nrubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GroupCV Training"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# gkf = GroupKFold(n_splits = 5)\n# for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n#     start_time_fold = time()\n#     X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n#     y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n    \n#     train_steps = int((X_tr.shape[0] // batch_size) + 1)\n#     val_steps = int((X_val.shape[0] // batch_size) + 1)\n    \n#     dataset_tr = prepare_dataset(X_tr, y_tr, window_size, batch_size, 'training')\n#     dataset_val = prepare_dataset(X_val, y_val, window_size, batch_size, 'validation')\n    \n#     ckp_path = f'JSModel_{fold}.hdf5'\n#     with strategy.scope():\n#         model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate)\n#     rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = verbose, \n#                             min_delta = 1e-4, mode = 'max')\n#     ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n#                           save_best_only = True, save_weights_only = True, mode = 'max')\n#     es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n#                        baseline = None, restore_best_weights = True, verbose = 0)\n#     history = model.fit(dataset_tr, steps_per_epoch = train_steps, \n#                         validation_data = dataset_val, validation_steps = val_steps, \n#                         epochs = 1000, callbacks = [rlr, ckp, es], verbose = verbose)\n#     hist = pd.DataFrame(history.history)\n    \n#     K.clear_session()\n#     del model\n#     rubbish = gc.collect()\n    \n#     # Finetune 3 epochs on validation set with small learning rate\n#     with strategy.scope():\n#         model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate / 100)\n#     model.load_weights(ckp_path)\n#     dataset_val = prepare_dataset(X_val, y_val, window_size, batch_size, 'training')\n#     model.fit(dataset_val, steps_per_epoch = val_steps, epochs = 3, verbose = 0)\n#     model.save_weights(ckp_path)\n    \n#     print(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] Fold {fold} ROC AUC:\\t', hist['val_AUC'].max())\n    \n#     K.clear_session()\n#     del model, X_tr, X_val, y_tr, y_val, dataset_tr, dataset_val\n#     rubbish = gc.collect()\n#     break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = create_transformer_model(len(features), 1, num_layers, d_model, num_heads, dff, window_size, dropout_rate, weight_decay, label_smoothing, learning_rate)\nmodel.load_weights('./JSTransformer.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/gogo827jz/optimise-speed-of-filling-nan-function\n@njit\ndef fast_fillna(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\n\n# The first run of numba decorated function requires compiling, which takes longer time than the later runs. So, we compile it before submission.\ntrain.loc[0, features[1:]] = fast_fillna(train.loc[0, features[1:]].values, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"opt_th = 0.505\ntmp = np.zeros((1, window_size, len(features)))\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        x_tt[0] = fast_fillna(x_tt[0], tmp[0, -1])\n        tmp[0] = np.concatenate((tmp[0, 1:], x_tt))\n        pred = model(tmp, training = False).numpy().item()\n        pred_df.action = np.where(pred >= opt_th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}