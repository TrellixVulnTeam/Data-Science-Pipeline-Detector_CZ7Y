{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries and Loading data ."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import janestreet \nfrom tqdm.notebook import tqdm \nimport time\nimport numpy as np\nimport os ,gc\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport datatable as dt \n\nimport tensorflow as tf \nfrom tensorflow import keras \nimport tensorflow_addons as tfa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting random seed for reproducibility: \ndef set_seed(seed=7):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(seed=7)\n\n#setting plt.style\n\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the files \n%time\ntrain_df=dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas().query('weight > 0 and date >85').reset_index(drop=True)\ntest_df=dt.fread('../input/jane-street-market-prediction/example_test.csv').to_pandas().reset_index(drop=True)\nsample_submission=pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\n# features=pd.read_csv('../input/jane-street-market-prediction/features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training set shape {} \\n Test set  shape {} '.format(train_df.shape,test_df.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets visualize the returns columns **"},{"metadata":{"trusted":true},"cell_type":"code","source":"resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\n\ndef plot_returns(df,cols):\n    plt.figure(figsize=(20,80))\n    for i,col in enumerate(cols):\n        plt.subplot(5,1,i+1)\n        plt.plot(df['date'],df[col],linewidth=.3,color='b')\n        plt.title(col)\n        plt.legend()\n    plt.show()\n\nplot_returns(train_df,resp_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing the data ."},{"metadata":{},"cell_type":"markdown","source":"**Imputing the data with interpolation and bfill**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding % of data that is null and imputing it :\n\nnull_val_ratio= train_df.isnull().sum().sum()/np.product(train_df.shape)\nprint(f'% of null values in train set is {null_val_ratio *100} ')\n\n\n#imputing data using ffill() ( i.e forward fill) and bfill() (i.e backward fill)\n# train_df=train_df.ffill().bfill()\n\n#trying interpolate to fill null values:\ntrain_df=train_df.interpolate(limit_direction='forward',axis=0)\ntrain_df=train_df.bfill()\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building and Training the model: no CrossValidation.\n\nI've tried three models with a little changes in thier architecture,with diffrent Learning rates and diffrent batch sizes.  "},{"metadata":{},"cell_type":"markdown","source":"Mainly used this notebook for this approach . Credits to the author.[https://www.kaggle.com/code1110/jane-street-with-keras-nn-overfit]"},{"metadata":{"trusted":true},"cell_type":"code","source":"#features to use in training model :\nfeatures = train_df.columns[train_df.columns.str.contains('feature')]\n\n#converting the 'resp' values into binary, i.e 1 if >0 else 0 if 0>resp value.\n#resp refers to return values, so action = buy if return is +ve else no action if return is -ve.\ntrain_df['action']=(train_df['resp']>0).astype('int')\n\n#target variable and training set :\nX_train=train_df[features]\ny_train=np.stack([(train_df[c] > 0).astype('int') for c in resp_cols]).T\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see the class balance :\ndef plot_countplot(df,col):\n    plt.figure(figsize=(10,6))\n    sns.countplot(df[col])\n    plt.xlabel('Action')\n    plt.ylabel('Count')\n    plt.show()\nplot_countplot(train_df,'action')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build model:\ndef Build_model( num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n        \n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n    \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parameters for model1 \n# epochs = 200\n# batch_size = 8192\n# hidden_units = [256,256,256,128]\n# dropout_rates = [0.1,0.15, 0.15, 0.2, 0.15]\n# label_smoothing = 1e-2\n# learning_rate = 1e-3\n\n# tf.keras.backend.clear_session()\n\n\n# #model1:\n# model1 = Build_model(len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)\n\n# #callbacks:\n# #reduce lr\n# reduce_lr = keras.callbacks.ReduceLROnPlateau(\n#     monitor = 'AUC', factor = 0.75, patience = 3, verbose = 0, min_delta = 1e-3, mode = 'max')\n\n# model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,callbacks=[reduce_lr])\n\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2nd model\nepochs = 200\nbatch_size = 8192\nhidden_units = [256,128,128,64]\ndropout_rates = [0.2,0.25, 0.25, 0.2, 0.15]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-2\n\ntf.keras.backend.clear_session()\n\nmodel2 = Build_model(len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)\n\n#callbacks:\n\n\n#reduce learning rate \nreduce_lr = keras.callbacks.ReduceLROnPlateau(\n    monitor = 'AUC', factor = 0.75, patience = 3, verbose = 0, min_delta = 1e-3, mode = 'max',min_lr=1e-8)\n\n\n#early stopping\nearly_stopping=keras.callbacks.EarlyStopping(patience=15,min_delta=1e-2,monitor='loss',restore_best_weights=True)\n\n#training\nmodel2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,callbacks=[reduce_lr,early_stopping])\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3rd model:\nepochs = 200\nbatch_size = 8192\nhidden_units = [256,128,64]\ndropout_rates = [0.2,0.25, 0.20, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-1\n\ntf.keras.backend.clear_session()\n\nmodel3= Build_model(len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)\n\n#callbacks:\n#reduce lr\nreduce_lr = keras.callbacks.ReduceLROnPlateau(\n    monitor = 'AUC', factor = 0.50, patience = 3, verbose = 0, min_delta = 1e-3, mode = 'max',min_lr=1e-8)\n\n#early stopping\nearly_stopping=keras.callbacks.EarlyStopping(patience=15,min_delta=1e-3,monitor='loss',restore_best_weights=True)\n\n#training\nmodel3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,callbacks=[reduce_lr,early_stopping])\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[model2,model3]\n#inference:\nth = 0.491\nf = np.median\nenv = janestreet.make_env()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    test_df=test_df.interpolate(limit_direction='forward',axis=0)\n    test_df=test_df.bfill()\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n        pred=f(pred)\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}