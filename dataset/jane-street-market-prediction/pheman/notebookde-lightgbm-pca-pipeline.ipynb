{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport datatable as dt\nfrom sklearn.model_selection import GroupKFold\n\nfrom tqdm import tqdm\nfrom random import choices\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING = True\nUSE_FINETUNE = False     \nFOLDS = 5\nSEED = 42\naction_type = 1\ny_type = 0\nENCODER = False\nNANFILL = -9999\n\ntrain_data_datatable = dt.fread('/kaggle/input/jane-street-market-prediction/train.csv')\ntrain = train_data_datatable.to_pandas()\n\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\nfillnaDict = train.mean()\n\n#train.fillna(fillnaDict,inplace=True)\ntrain = train.fillna(NANFILL)\n\ntrain = train.query('weight > 0').reset_index(drop = True)\n\n\n\n\n\nif action_type == 0:\n    train['action'] = (train['resp'] > 0).astype('int')\nelif action_type == 1:\n    train['action'] =  (  (train['resp_1'] > 0.00001 ) & (train['resp_2'] > 0.00001 ) & (train['resp_3'] > 0.00001 ) & (train['resp_4'] > 0.00001 ) &  (train['resp'] > 0.00001 )   ).astype('int')\nelse:\n    train['action'] = (train['resp'] > 0).astype('int')\n    \ndatalength = len(train)\ntrainlength = int(datalength * 0.9)\n\ntrain, valid = train.loc[:trainlength,:],train.loc[trainlength:,:]\nSAMPLE_WEIGHTS = (train['resp'] * train['weight']).abs() + 1\n\nfeatures = [c for c in train.columns if 'feature' in c]\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX = train[features].values\nXvalid = valid[features].values\n\nif y_type == 0:\n    y      = np.stack([(train[c] > 0.000001).astype('int') for c in resp_cols]).T #Multitarget\n    yvalid = np.stack([(valid[c] > 0.000001).astype('int') for c in resp_cols]).T #Multitarget\nelif y_type == 1:\n    y      = np.stack([ train['action'].values for c in resp_cols]).T #Multitarget\n    yvalid = np.stack([ valid['action'].values for c in resp_cols]).T #Multitarget\nelse:\n    y      = np.stack([(train[c] > 0.000001).astype('int') for c in resp_cols]).T #Multitarget\n    yvalid = np.stack([(valid[c] > 0.000001).astype('int') for c in resp_cols]).T #Multitarget\n\nf_mean = np.mean(train[features[1:]].values,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nimport random\nfrom sklearn import metrics\n\ndef create_clf():\n    clf = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=500, max_depth=11, max_bin=63,\n                         learning_rate=0.05, n_estimators=500,  \n                         objective='binary', class_weight='balanced', min_split_gain=0.05, min_child_weight=0.01, \n                         min_child_samples=100, subsample=0.9, subsample_freq=3, colsample_bytree=0.7, \n                         reg_alpha=100, reg_lambda=1.5, random_state=None, n_jobs=-1, \n                         silent=True, importance_type='split',device=\"cpu\")\n    '''\n    clf =  xgb.XGBClassifier(   n_estimators=50,use_label_encoder=False,eval_metric='logloss',\n                                max_depth=6,\n                                learning_rate=0.05,\n                                subsample=0.9,\n                                colsample_bytree=0.7,\n                                missing=-999,\n                                random_state=random.randint(5000,6000)\n                            )\n    clf =  LogisticRegression(  C=0.1\n                            )\n    '''\n    return clf\n\nFOLDS = 5\nSEED = 42\n#gkf = PurgedGroupTimeSeriesSplit(n_splits = FOLDS, group_gap=20)\n#splits = list(gkf.split(y, groups=train['date'].values))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {}\nrespTrainList = [0,1,2,3,4]\nfor resp_type in respTrainList:\n    clf = create_clf()\n    clf.fit(X, y[:,resp_type], sample_weight=SAMPLE_WEIGHTS)\n    y_train_prob = clf.predict_proba(X)[:,1]\n    auctrain = metrics.roc_auc_score(y[:,resp_type], y_train_prob)\n\n    y_valid_prob = clf.predict_proba(Xvalid)[:,1]\n    aucvalid = metrics.roc_auc_score(yvalid[:,resp_type], y_valid_prob)\n\n    print('resp = ',resp_cols[resp_type],auctrain,aucvalid)\n\n    models[f'{resp_cols[resp_type]}'] = clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_predict_slow(X,models):\n    y_multi_pre = concat_respx_pred(X,models)\n    y = models['lr'].predict(y_multi_pre)\n    #y = y > np.mean(y)\n    #print(np.mean(y))\n    return y.astype(int)\n\ndef model_predict_fast(X,models):\n    \n    y = models['resp'].predict(X)\n    #y = y > np.mean(y)\n    #print(np.mean(y))\n    return y.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_respx_pred(X,models):\n    y_multi_pre = np.stack([ models[f'{respx}'].predict_proba(X)[:,1] for respx in models if respx != 'lr']).T\n    return y_multi_pre\nlr = LogisticRegression(C=1.0, solver='sag', class_weight={0:0.3,1:0.7})\n\ny_multi_pre = concat_respx_pred(X, models)\nyvalid_multi_pre = concat_respx_pred(Xvalid, models)\n\nlr.fit(y_multi_pre, train['action'].values)\nmodels['lr'] = lr\n\nnp.mean(y_multi_pre,axis=0),np.mean(lr.predict_proba(y_multi_pre)[:,1]),np.mean(lr.predict(y_multi_pre)),np.mean(train['action'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_proba = lr.predict_proba(y_multi_pre)[:,1]\ntrain_pred = model_predict_slow(X,models)\naction_auc_train = metrics.roc_auc_score(train['action'], train_proba)\naction_mse_train = metrics.accuracy_score(train['action'], train_pred)\nprint(action_auc_train,action_mse_train)\n\nvalid_proba = lr.predict_proba(yvalid_multi_pre)[:,1]\nvalid_pred = model_predict_slow(Xvalid,models)\naction_auc_valid = metrics.roc_auc_score(valid['action'], valid_proba)\naction_mse_valid = metrics.accuracy_score(valid['action'], valid_pred)\nprint(action_auc_valid,action_mse_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import janestreet\nfrom tqdm import tqdm\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n#fillnaDict = train.mean()\nmodel_predict = model_predict_slow\nfeatures = [f'feature_{x}' for x in range(130)]\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    if test_df['weight'].values[0] < 0.001:\n        y_preds = 0\n    else:\n        X_test = test_df.loc[:, features].fillna(0.0).values\n        y_preds = model_predict(X_test,models)\n    sample_prediction_df.action = y_preds\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('submission.csv')\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/models","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}