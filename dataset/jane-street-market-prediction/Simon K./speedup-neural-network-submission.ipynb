{"cells":[{"metadata":{},"cell_type":"markdown","source":"# how to speedup the Submission Process for Neural Networks written in Tensorflow/Keras"},{"metadata":{},"cell_type":"markdown","source":"To not get a Timeout at Submission Time you need around 50 it/sec in the submission loop. Manny Complex Models have problems with this Time constraint since the API only lets us predict in single mode instead of in Batch Mode. At least for Tensorflow/Keras I have found a weird behaviour, which takes up a lot of time and so causes the Submission to fail due to a timeout."},{"metadata":{},"cell_type":"markdown","source":"For demonstration I will just build a simple Keras model and use it imediately for predictions. Since the Model doesn't get trained at all the Predictions are going to be way off, but this is for demonstration Purpouses only!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow.keras as keras\nimport janestreet\nfrom tqdm import tqdm\nimport time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def build_model(input_dim):\n    i = keras.Input(input_dim)\n    \n    x = keras.layers.Dense(64, activation=\"relu\")(i)\n    x = keras.layers.BatchNormalization()(x)\n    \n    x = keras.layers.Dense(32, activation=\"relu\")(x)\n    x = keras.layers.BatchNormalization()(x)\n    \n    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    \n    model = keras.Model(i, x)\n    model.compile(optimizer=\"Adam\", loss=\"MSE\")\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(130)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['feature_0',\n 'feature_1',\n 'feature_2',\n 'feature_3',\n 'feature_4',\n 'feature_5',\n 'feature_6',\n 'feature_7',\n 'feature_8',\n 'feature_9',\n 'feature_10',\n 'feature_11',\n 'feature_12',\n 'feature_13',\n 'feature_14',\n 'feature_15',\n 'feature_16',\n 'feature_17',\n 'feature_18',\n 'feature_19',\n 'feature_20',\n 'feature_21',\n 'feature_22',\n 'feature_23',\n 'feature_24',\n 'feature_25',\n 'feature_26',\n 'feature_27',\n 'feature_28',\n 'feature_29',\n 'feature_30',\n 'feature_31',\n 'feature_32',\n 'feature_33',\n 'feature_34',\n 'feature_35',\n 'feature_36',\n 'feature_37',\n 'feature_38',\n 'feature_39',\n 'feature_40',\n 'feature_41',\n 'feature_42',\n 'feature_43',\n 'feature_44',\n 'feature_45',\n 'feature_46',\n 'feature_47',\n 'feature_48',\n 'feature_49',\n 'feature_50',\n 'feature_51',\n 'feature_52',\n 'feature_53',\n 'feature_54',\n 'feature_55',\n 'feature_56',\n 'feature_57',\n 'feature_58',\n 'feature_59',\n 'feature_60',\n 'feature_61',\n 'feature_62',\n 'feature_63',\n 'feature_64',\n 'feature_65',\n 'feature_66',\n 'feature_67',\n 'feature_68',\n 'feature_69',\n 'feature_70',\n 'feature_71',\n 'feature_72',\n 'feature_73',\n 'feature_74',\n 'feature_75',\n 'feature_76',\n 'feature_77',\n 'feature_78',\n 'feature_79',\n 'feature_80',\n 'feature_81',\n 'feature_82',\n 'feature_83',\n 'feature_84',\n 'feature_85',\n 'feature_86',\n 'feature_87',\n 'feature_88',\n 'feature_89',\n 'feature_90',\n 'feature_91',\n 'feature_92',\n 'feature_93',\n 'feature_94',\n 'feature_95',\n 'feature_96',\n 'feature_97',\n 'feature_98',\n 'feature_99',\n 'feature_100',\n 'feature_101',\n 'feature_102',\n 'feature_103',\n 'feature_104',\n 'feature_105',\n 'feature_106',\n 'feature_107',\n 'feature_108',\n 'feature_109',\n 'feature_110',\n 'feature_111',\n 'feature_112',\n 'feature_113',\n 'feature_114',\n 'feature_115',\n 'feature_116',\n 'feature_117',\n 'feature_118',\n 'feature_119',\n 'feature_120',\n 'feature_121',\n 'feature_122',\n 'feature_123',\n 'feature_124',\n 'feature_125',\n 'feature_126',\n 'feature_127',\n 'feature_128',\n 'feature_129']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple prediction Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"janestreet.competition.make_env.__called__ = False\nenv = janestreet.make_env()\n\nstart_time = time.time()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    x_tt = test_df.loc[:, features].values\n    if np.isnan(x_tt[:, 1:].sum()):  # simply ignoring missing values and imediately predicting 0\n        pred_df.action = 0\n    else:\n        pred = model.predict(x_tt)\n        pred_df.action = np.where(pred > 0.5, 1, 0).astype(int)\n    env.predict(pred_df)\nprint(f\"took: {time.time() - start_time} seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see this simple Neural Network is to slow for submitting. This Code would result in an Timeout on Submission. I also analyzed the Code and found out that as expectet most of the time went into producing the Neural Network Predictions. As you can see we used the ***model.predict*** Function to get our Predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"janestreet.competition.make_env.__called__ = False\nenv = janestreet.make_env()\n\nstart_time = time.time()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    x_tt = test_df.loc[:, features].values\n    if np.isnan(x_tt[:, 1:].sum()):  # simply ignoring missing values and imediately predicting 0\n        pred_df.action = 0\n    else:\n        pred = model(x_tt, training=False)\n        pred_df.action = np.where(pred > 0.5, 1, 0).astype(int)\n    env.predict(pred_df)\nprint(f\"took: {time.time() - start_time} seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" this time we changed the ***model.predict()*** function to simply calling the model itselv with the ***model()*** function. As you can see the Prediction Loop is now way faster! For me this is quite a weird behaviour since both methods results in exactly the same predictions but the direct ***model()*** function just is way faster. I also tried this in other real Notebooks and the direct ***model()*** function made the difference for all these Notebooks, before I used the ***model.predict()*** function and even the most simple models got an timeout on submission. Now I'm able to train quite large and complex Models wihout beeing in troubble for an timeout on Prediction."},{"metadata":{},"cell_type":"markdown","source":"### In one Line: use ***model()*** instead of ***model.predict()*** !!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}