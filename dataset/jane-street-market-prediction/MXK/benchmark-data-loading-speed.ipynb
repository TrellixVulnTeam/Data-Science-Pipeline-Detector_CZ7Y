{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Benchmark Laoding Speed using](https://i.imgur.com/8BBQdvc.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Benchmark Loading Speed \n\nThis notebook have most of data loading techniques, some of them will timeout before finishing the job, others are \n\ninadequate for loading a specific data types and structures, and some are very fast and we'll try to benchmark them.\n\nFeel free to share with us your thoughts in the comment section =)\n\n\n\n##### 0- Libs\n\n##### 1- Parser \n##### 2- Numpy\n##### 3- Numba\n##### 4- Pandas \n##### 5- Datatable\n\n##### 6- cuDF\n##### 7- cuPY\n\n##### 8- Pickle\n##### 9- Joblib\n\n##### 10- feather\n##### 11- parquet\n##### 12- jay\n##### 13- hdf5\n\n##### 14- Benchmark\n##### 15- Kuods"},{"metadata":{},"cell_type":"markdown","source":"# 0- Libs"},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nimport numpy as np\nfrom numpy import genfromtxt\nfrom numba import njit\nimport cudf\nimport cupy\nimport pandas as pd\nimport datatable as dt\nimport pickle\nimport joblib\nimport feather\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '/kaggle/input/jane-street-market-prediction/train.csv'\n# saved_data_path = '../input/name of the netebook/name of the data file' if you import the data from another notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#################################### 1- Pythonâ€™s Built-in CSV parser ####################################\n#with open('/kaggle/input/jane-street-market-prediction/train.csv') as csv_file:\n#    csv_reader = csv.reader(csv_file, delimiter=',')\n#    data = list(csv_reader) \n# Result : Your notebook tried to allocate more memory than is available. It has restarted.\n\n\n#################################### 2- Numpy ####################################\n#my_data = genfromtxt('/kaggle/input/jane-street-market-prediction/train.csv', delimiter=',')\n# Result : Your notebook tried to allocate more memory than is available. It has restarted.\n\n# Step 1\nnp.save('./data.npy', pd.read_csv(data_path))\n\n# Step 2\nspeed_np = %timeit -o np.load('./data.npy')\n\n\n#################################### 3- Numba ####################################\n#@njit\n#def numba_data():\n#    data = genfromtxt('/kaggle/input/jane-street-market-prediction/train.csv', delimiter=',')\n#    return data\n# Result : Untyped global name 'genfromtxt': cannot determine Numba type of <class 'function'>\n\n\n#################################### 4- Pandas ####################################\nspeed_pd =  %timeit -o  pd.read_csv(data_path)\n\n\n#################################### 5- Datatable ####################################\nspeed_dt =  %timeit -o  dt.fread(data_path)\n\n\n#################################### 6- cuDF ####################################\nspeed_cu =  %timeit -o  data_cudf = cudf.read_csv(data_path)\n\n\n#################################### 7- cuPY ####################################\n#data = cupy.load('/kaggle/input/jane-street-market-prediction/train.csv', allow_pickle=False) # if the loaded file is pickled then allow_pickle=True\n# Result : Only load pickled files\n\n\n#################################### 8- Pickle + Datatable ####################################\n# Step 1 (save the data)\npickle.dump(dt.fread(data_path), open(r'data_dt.pickle', 'wb'))\n\n# Step 2 (load the data)\nspeed_pickle =  %timeit -o  pickle.load(open('./data_dt.pickle', 'rb'))\n\n\n#################################### 9- Joblib + Datatable ####################################\n# Step 1 (save the data)\njoblib.dump(dt.fread(data_path), 'data_dt.joblib')\n\n# Step 2 (load the data)\nspeed_joblib =  %timeit -o  joblib.load('./data_dt.joblib')\n\n\n#################################### 10- Feather + Pandas ####################################\n# Step 1 (save the data)\npd.read_csv(data_path).to_feather(\"data_pd.feather\")\n\n# Step 2 (load the data)\nspeed_feather =  %timeit -o  pd.read_feather('./data_pd.feather')\n\n\n#################################### 11- Parquet + Pandas ####################################\n# Step 1 (save the data)\npd.read_csv(data_path).to_parquet(\"data.parquet\")\n\n# Step 2 (load the data)\nspeed_parquet =  %timeit -o  pd.read_parquet('./data.parquet')\n\n\n#################################### 12- Jay + Datatable ####################################\n# Step 1 (save the data)\ndt.Frame(data_path).to_jay(\"data_dt.jay\")\n\n# Step 2 (load the data)\nspeed_jay =  %timeit -o  dt.fread('./data_dt.jay')\n\n\n#################################### 13- hdf5 + Pandas ####################################\n# Step 1 (save the data)\npd.read_csv(data_path).to_hdf(\"data.h5\", \"data\")\n\n# Step 2 (load the data)\nspeed_hdf5 =  %timeit -o pd.read_hdf('./data.h5', \"data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 14- Benchmark"},{"metadata":{"trusted":true},"cell_type":"code","source":"speed = [\"{:.2f}\".format(speed_np.average) ,\"{:.2f}\".format(speed_pd.average), \"{:.2f}\".format(speed_dt.average), \"{:.2f}\".format(speed_cu.average), \"{:.2f}\".format(speed_pickle.average), \"{:.2f}\".format(speed_joblib.average), \"{:.2f}\".format(speed_feather.average), \"{:.2f}\".format(speed_parquet.average), \"{:.4f}\".format(speed_jay.average), \"{:.2f}\".format(speed_hdf5.average)]\nspeed_name = ['Numpy', 'Pandas', 'Datatable', 'cuDF', 'Pickle', 'Joblib', 'Feather', 'Parquet', 'Jay', 'hdf5']\n\nfor row in range(len(speed)):\n    print(speed_name[row] + ' = ', speed[row], 's')\n    \nspeedy = pd.DataFrame()\nspeedy[\"name\"] = speed_name\nspeedy[\"speed\"] = list(map(float, speed))\nspeedy.sort_values(by=['speed'], ascending=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(speedy, y='speed', x='name', text='speed', title='Benchmarking Data loading speed in seconds')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are other very fast ways to load data, and can very useful during data processing that i'll try to add as soon as i finish testing them. \n\nFinally feel free to put in the comment section the code that use for fast data processing =)"},{"metadata":{},"cell_type":"markdown","source":"# 15- Kudos\n\n##### https://www.kaggle.com/quillio/pickling\n##### https://www.kaggle.com/pedrocouto39/fast-reading-w-pickle-feather-parquet-jay"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}