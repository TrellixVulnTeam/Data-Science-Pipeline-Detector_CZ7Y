{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle: Jane Streem Market Prediction\nhttps://www.kaggle.com/c/jane-street-market-prediction/\n\n# Keras autoencoder + CatBoost v05_1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install optuna","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import gc\nimport numpy as np \nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport joblib\npd.set_option('display.max_columns', 200)\n\nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.layers import Lambda, Concatenate, Input, GaussianNoise\nfrom tensorflow.keras import utils, initializers, optimizers, regularizers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.regularizers import L1L2\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\n\nfrom catboost import CatBoostClassifier\n#from lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss\n#from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n\n#import optuna\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport catboost\n#import lightgbm\nimport sklearn\n\nprint('Scikit-learn ver:', sklearn.__version__)\nprint('Keras ver:', tf.keras.__version__)\nprint('CatBoost ver:', catboost.__version__)\n#print('LightGBM ver:', lightgbm.__version__)\n#print('Optuna ver:', optuna.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Constant\nLOCAL_MODE = False # load data from file train.parquet, else kaggle datastore\nIS_TRAIN_ENCODER = False\nIS_GRID = False # Serching best parameters in boosters\nIS_TRAIN = False # load model and only predict, else train, predict\nIS_SUBMIT = True # commit or not\nIS_ADD_FEATURES = False # add new features\nTEST_SIZE = 0.1 # data test size \nSIZE_TRAIN = None #400_000 # if None all rows in train\nCOL_FEATURES = [f'feature_{x}' for x in range(130)]\nCOL_TARGET = ['target']\nCOL_SCORE = ['date', 'weight', 'resp']\nNAN_VALUE = 'mean' # if None dropna else fillna, if 'mean' mean of col\nPATH = '../input/jsm-v05-1/' # path for non local\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntry:\n    import cudf\n    train_cudf  = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\n    train = train_cudf.to_pandas()\n    del train_cudf\n    gc.collect()\nexcept:\n    if LOCAL_MODE: # for local notebook\n        train = pd.read_parquet('kaggle/input/jane-street-market-prediction/train.parquet') \n    else:\n        train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\nif SIZE_TRAIN:\n    train = train[-SIZE_TRAIN:]\n# drop day<86, in forum say JSM changed the strategy after 86 days\ntrain = train.query('date > 85').reset_index(drop=True)\ngc.collect()\ntrain['target'] = (train.loc[:,'resp']>0).astype('int8') # set target field\ntrain.loc[train['weight']<=0, 'weight'] = np.nan # only weight>0\ntrain = train.astype({x: np.float32 for x in train.select_dtypes(include='float64').columns})\ntrain = train.astype({x: np.int32 for x in train.select_dtypes(include='int64').columns}) \ntrain = train[COL_FEATURES + COL_TARGET + COL_SCORE] # trim the extra columns\nif NAN_VALUE: # fillna value or fillna mean values of features\n    if NAN_VALUE == 'mean':\n        F_MEAN = train[COL_FEATURES].mean()\n        for col in F_MEAN.index:\n            val_mean = F_MEAN.loc[col]\n            train[col] = train[col].fillna(val_mean)\n    else:\n        train[COL_TARGET] = train[COL_FEATURES].fillna(NAN_VALUE)\ntrain.dropna(inplace=True)\ngc.collect()\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_ADD_FEATURES:\n    tags = pd.read_csv('../input/jane-street-market-prediction/features.csv')\n    tag_f = tag_f = {x: list(tags['feature'][tags[x]]) for x in tags.columns[1:]}\n    for col in tags.columns[1:]:\n        train[col] = train[tag_f[col]].sum(axis=1).astype('float32')\n    COL_FEATURES += list(tags.columns[1:])\n    #COL_FEATURES = list(tags.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Split train, test\ncol_score = ['date', 'weight', 'resp']\npos_test = int(len(train)*TEST_SIZE)\ntrain = train.sample(frac=1).copy() # shuffle train, access - eval(x_tr)...\ngc.collect() # optimize RAM\nx_tr = \"train[COL_FEATURES].iloc[:-pos_test]\"\ny_tr = \"train[COL_TARGET].iloc[:-pos_test]\"\nx_te = \"train[COL_FEATURES].iloc[-pos_test:]\"\ny_te = \"train[COL_TARGET].iloc[-pos_test:]\"\nprint('Start training: train:', eval(x_tr).shape, eval(y_tr).shape, \n      'test:', eval(x_te).shape, eval(y_te).shape)\n#print('Distribution of target:')\n#print(eval(y_te).value_counts(sort=False, normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numba import njit\n# Score for Jane Street Market\n@njit(fastmath=True)\ndef jsm_score(date, weight, resp, action):\n    Pi = np.bincount(date, weight * resp * action)\n    count_i = len(Pi)\n    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n    u = min(max(t, 0), 6) * np.sum(Pi)\n    return u","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_score_test = jsm_score(\n    train['date'].loc[eval(y_te).index].values,\n    train['weight'].loc[eval(y_te).index].values,\n    train['resp'].loc[eval(y_te).index].values,\n    train['target'].loc[eval(y_te).index].values,\n    #((train[COL_TARGET]>0.000001).loc[eval(y_te).index].sum(axis=1) == 5).astype(int).values\n    #y_test['target'].values,\n)\nmax_score_train = jsm_score(\n    train['date'].loc[eval(y_tr).index].values,\n    train['weight'].loc[eval(y_tr).index].values,\n    train['resp'].loc[eval(y_tr).index].values,\n    train['target'].loc[eval(y_tr).index].values,\n    #((train[COL_TARGET]>0.000001).loc[eval(y_tr).index].sum(axis=1) == 5).astype(int).values\n)\nprint('Max score in train: {:_.0f}'.format(max_score_train))\nprint('Max score in test: {:_.0f}'.format(max_score_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras autoencoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_models_ae(input_shape, latent_dim=16, lambda_l1=0, noise=0.05):\n    input_dim = np.prod(input_shape) # if input is multidim\n    #print(input_dim)\n    activation = 'swish'\n    encoder_in = Input(input_shape)\n    #x = Flatten()(encoder_in) # dense for multidim\n    #x = BatchNormalization()(encoder_in)\n    x = GaussianNoise(noise)(encoder_in)\n    x = Dense(128, activation = activation)(x)\n    #x = Dropout(0.2)(x)\n    x = Dense(128, activation = activation)(x)\n    #x = Dropout(0.2)(x)\n    z = Dense(latent_dim, activation='sigmoid', \n             activity_regularizer=L1L2(lambda_l1, 0))(x) # dense of PCA\n    encoder = Model(encoder_in, z, name='encoder')\n    #encoder.summary()\n    decoder_in = Input((latent_dim,))\n    x = Dense(128, activation = activation)(decoder_in)\n    #x = Dropout(0.2)(x)\n    x = Dense(128, activation = activation)(x)\n    output = Dense(input_dim, activation='linear')(x)\n    decoder = Model(decoder_in, output, name='decoder')\n    #decoder.summary()\n    ae_output = decoder(encoder(encoder_in))\n    autoencoder = Model(encoder_in, ae_output, name='autoencoder')\n    autoencoder.compile(optimizer='adam', loss='mse')\n    return encoder, decoder, autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder, decoder, autoencoder = create_models_ae(eval(x_tr).shape[1:], latent_dim=64, lambda_l1=1e-4, noise=0.1)\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\nif IS_TRAIN_ENCODER:\n    autoencoder.fit(eval(x_tr), eval(x_tr),\n                    epochs=1010,\n                    batch_size = 16384,\n                    validation_data = (eval(x_te), eval(x_te)),\n                    callbacks=[EarlyStopping('val_loss', patience=10, restore_best_weights=True),\n                               ReduceLROnPlateau(monitor='loss', factor=0.7, patience=3, min_lr=0.000001, verbose=1)\n                              ]\n                   )\n    encoder.save_weights('v05_encoder.hdf5')\nelse:\n    if LOCAL_MODE:\n        encoder.load_weights('v05_encoder.hdf5')\n    else:\n        encoder.load_weights(PATH+'v05_encoder.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Epoch 154/1010\n73/73 [==============================] - 2s 30ms/step - loss: 0.1507 - val_loss: 0.1830  \nEpoch 427/1010\n87/87 [==============================] - 2s 23ms/step - loss: 0.1133 - val_loss: 0.1174  \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\nnp.mean(encoder(eval(x_te).iloc[0:1].values))\n#0.42087412","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict after encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshuffle train, test\ntrain = train.sample(frac=1).copy() # shuffle train, access - eval(x_tr)...\ngc.collect() # optimize RAM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\ndef get_best_th(y_test, y_proba_test):\n    best_score = 0\n    best_th = 0\n    th_list = [0.5] + [0.4 + x/1000 for x in range(200)]\n    for my_th in tqdm(th_list, desc='Find best threshold'):\n        acc_test = accuracy_score(eval(y_te), (y_proba_test>my_th).astype(int).argmax(axis=1))*100\n        try:\n            score_test = jsm_score(\n                train['date'].loc[eval(y_te).index].values,\n                train['weight'].loc[eval(y_te).index].values,\n                train['resp'].loc[eval(y_te).index].values,\n                (y_proba_test>my_th).astype(int).argmax(axis=1).reshape(-1)\n            )        \n        except:\n            continue\n        if (score_test >= best_score):\n            best_score = score_test\n            best_th = my_th\n            print('Best score with TH: {:.3f}: acc_test: {:.2f}%, score_test: {:_.0f}'.format(\n                my_th,                                                                                           \n                acc_test, score_test))\n    gc.collect()\n    return best_th ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_report(y_test, y_proba_test):\n    my_th = 0.5\n    score_test = jsm_score(\n        train['date'].loc[y_test.index].values,\n        train['weight'].loc[y_test.index].values,\n        train['resp'].loc[y_test.index].values,\n        (y_proba_test>my_th).astype(int).argmax(axis=1).reshape(-1)\n    )\n    acc_test = accuracy_score(y_test, (y_proba_test>my_th).astype(int).argmax(axis=1))*100\n    print('Report with TH: {:.3f}, acc_test: {:.2f}%, score_test: {:_.0f}'.format(\n            my_th,                                                                                           \n            acc_test, score_test))\n    print(classification_report(y_test, (y_proba_test>my_th).astype(int).argmax(axis=1)))\n    cm = confusion_matrix(y_test, (y_proba_test>my_th).astype(int).argmax(axis=1))\n    conf_matrix = pd.DataFrame(data=cm, index=[0,1], columns=[0,1])\n    plt.figure(figsize = (6, 6))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\", cbar=False)\n    plt.title('Confusion matrix')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CatBoostClassifier()"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Search the best options\ngc.collect()\nif IS_GRID: \n    clf = CatBoostClassifier(\n        iterations=100,\n        learning_rate=0.05, \n        custom_loss = ['Accuracy'],\n        loss_function='Logloss', #'Logloss', 'CrossEntropy',        \n        eval_metric='AUC',\n        random_seed=2020,\n        task_type=\"GPU\",\n        # ---- param gridsearch\n        #depth=6,\n        l2_leaf_reg=5, # 1 - the best\n        border_count=20,\n        leaf_estimation_iterations=7,\n    )\n    grid = {\n        'depth': [x for x in range(4,13)],\n        #'learning_rate': [0.5, 0.2, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0001],\n        #'l2_leaf_reg': [x for x in range(1,256)],\n        #'border_count': [x for x in range(1,256)],\n        #'leaf_estimation_iterations': [x for x in range(1,256)],        \n        }\n    grid_search_result = clf.grid_search(grid,\n    #grid_search_result = clf.randomized_search(grid, n_iter=20,\n        X=encoder.predict(train[COL_FEATURES]), y=train[COL_TARGET],\n        plot=True, verbose=False,\n        cv=3, partition_random_seed=3, stratified=True,\n        #sample_weight=sample_weights[-200_000:],\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if IS_GRID:\n    print('The best params')\n    print(grid_search_result['params'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\nif IS_TRAIN:\n    sample_weight = ((train['resp'].loc[eval(x_tr).index] * train['weight'].loc[eval(x_tr).index]))\n    clf_cb = CatBoostClassifier(\n        iterations=10_000, # 10_000\n        loss_function='Logloss', #MultiClassOneVsAll, logloss\n        task_type=\"GPU\",\n        #learning_rate=0.05,\n        depth=10, l2_leaf_reg=5, border_count=254, leaf_estimation_iterations=7,\n        use_best_model=True, random_seed=2020,\n        #rsm=0.98,\n        verbose=0,\n    )#, save_snapshot=True, snapshot_file='snapshot_ml_v1.cbs')\n    clf_cb.fit(encoder.predict(eval(x_tr)), eval(y_tr), \n            eval_set=(encoder.predict(eval(x_te)), eval(y_te)),\n            sample_weight = np.abs(sample_weight),\n            #plot=False, \n            plot=True,\n            verbose=0, #100\n           );\n    clf_cb.save_model('v05_model_catboost.cbm')\nelse:\n    clf_cb = CatBoostClassifier()\n    if LOCAL_MODE:\n        clf_cb.load_model('v05_model_catboost.cbm')\n    else:\n        clf_cb.load_model(PATH+'v05_model_catboost.cbm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Select TH**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Max score in test: {:_.0f}'.format(max_score_test))\ny_proba_test = clf_cb.predict_proba(encoder.predict(eval(x_te)))\nget_model_report(eval(y_te), y_proba_test)\nBEST_TH_CB = get_best_th(eval(y_te), y_proba_test)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best score with TH: 0.507: acc_test: 51.79%, score_test: 563  \nBest score with TH: 0.502: acc_test: 54.45%, score_test: 2_639  \nBest score with TH: 0.500: acc_test: 53.57%, score_test: 3_148 (depth=8, iter=10_000)  \nBest score with TH: 0.504: acc_test: 53.77%, score_test: 3_142 (depth=11, iter=2_000)  \nBest score with TH: 0.529: acc_test: 53.96%, score_test: 3_419 (depth=10, iter=10_000)  \n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"BEST_TH_CB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Submit prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif IS_SUBMIT:\n    model_th = BEST_TH_CB\n    if NAN_VALUE:\n        if NAN_VALUE == 'mean':\n            f_mean = F_MEAN.values.reshape(1,-1)\n    import janestreet\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test() # an iterator which loops over the test set\n    count = 0\n    for (val_df, sample_prediction_df) in tqdm(iter_test):\n        if val_df['weight'].iloc[0] > 0:\n            x_val = val_df[COL_FEATURES].values\n            if NAN_VALUE:\n                if NAN_VALUE == 'mean':\n                    x_val[:, :] = np.nan_to_num(x_val[:, :]) + np.isnan(x_val[:, :]) * f_mean\n                else:    \n                    x_val = np.nan_to_num(x_val, nan=NAN_VALUE, posinf=NAN_VALUE, neginf=NAN_VALUE)\n                y_pred = clf_cb.predict_proba(encoder(x_val[:,:], training=False).numpy()).reshape(-1)\n                sample_prediction_df.action = np.where(y_pred[1] > model_th, 1, 0).astype(int)\n            else:\n                if np.isnan(x_val[:, :].sum()):\n                    sample_prediction_df.action = 0\n                else:\n                    y_pred = clf_cb.predict_proba(encoder(x_val[:,:], training=False).numpy()).reshape(-1)\n                    sample_prediction_df.action = np.where(y_pred[1] > model_th, 1, 0).astype(int)\n        else:\n            sample_prediction_df.action = 0\n        env.predict(sample_prediction_df)\n        count += 1\n    print('Submit done ({})'.format(count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#env.predict(sample_prediction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}