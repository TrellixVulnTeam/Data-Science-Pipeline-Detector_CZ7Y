{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport cudf\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nimport pandas as pd\npd.set_option('display.max_columns', 500)\n\nimport xgboost as xgb\nprint(\"XGBoost version:\", xgb.__version__)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# create the environment\nimport janestreet\nprint('Creating competition environment...', end='')\nenv = janestreet.make_env()\nprint('Finished.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Reading datasets...', end='')\n\n#train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ntrain_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ntrain = train_cudf.to_pandas()\ndel train_cudf\n\n#features_meta = pd.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\nfeatures_meta_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\nfeatures_meta = features_meta_cudf.to_pandas()\ndel features_meta_cudf\n\n#example_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\n#sample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nprint('Finished.')\n\nprint(f'train shape: {format(train.shape)}')\nprint(f'features_meta shape: {format(features_meta.shape)}')\n#print(f'example_test shape: {format(example_test.shape)}')\n#print(f'sample_prediction_df shape:{format(sample_prediction_df.shape)}')\n\n# display the first rows of the training data\n# print(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Preprocessing data...', end='')\n\nfeatures = [col for col in list(train.columns) if 'feature' in col]\n\n# # adjust features to use top half based on importance\n# features = ['feature_43', 'feature_42', 'feature_45', 'feature_41', 'feature_44', 'feature_63', 'feature_61', 'feature_69', 'feature_6', 'feature_64', 'feature_5', 'feature_62', 'feature_7', 'feature_11', 'feature_20', 'feature_39', 'feature_60', 'feature_83', 'feature_3', 'feature_37', 'feature_1', 'feature_40', 'feature_4', 'feature_38', 'feature_27', 'feature_77', 'feature_119', 'feature_28', 'feature_120', 'feature_68', 'feature_95', 'feature_90', 'feature_66', 'feature_55', 'feature_121', 'feature_89', 'feature_84', 'feature_107', 'feature_114', 'feature_113', 'feature_71', 'feature_8', 'feature_124', 'feature_49', 'feature_101', 'feature_125', 'feature_102', 'feature_78', 'feature_57', 'feature_67', 'feature_65', 'feature_108', 'feature_70', 'feature_31', 'feature_48', 'feature_126', 'feature_18', 'feature_26', 'feature_96', 'feature_86', 'feature_116', 'feature_127', 'feature_22', 'feature_92', 'feature_51', 'feature_58', 'feature_12', 'feature_33', 'feature_53', 'feature_17', 'feature_104', 'feature_24', 'feature_110', 'feature_72', 'feature_36', 'feature_21', 'feature_35', 'feature_32', 'feature_25', 'feature_59', 'feature_34', 'feature_2', 'feature_93', 'feature_10', 'feature_117', 'feature_87', 'feature_47', 'feature_128', 'feature_98', 'feature_80', 'feature_50', 'feature_54', 'feature_79', 'feature_129', 'feature_9', 'feature_23', 'feature_19', 'feature_111', 'feature_115', 'feature_56', 'feature_30', 'feature_73', 'feature_122', 'feature_105', 'weight', 'feature_74', 'feature_14', 'feature_123', 'feature_29', 'feature_109', 'feature_82', 'feature_112', 'feature_76', 'feature_16', 'feature_99', 'feature_88', 'feature_85', 'feature_106', 'feature_118', 'feature_91', 'feature_46', 'feature_81', 'feature_75', 'feature_94', 'feature_52', 'feature_13', 'feature_103', 'feature_15', 'feature_100', 'feature_97', 'feature_0']\n# features = features[:65]\n\n# only train on rows with positive weights\ntrain = train[train['weight'] != 0]\n\n# binarize the target\ntrain['action'] = (train['resp'].values > 0).astype(int)\n\n#train = train.fillna(-99999)\nf_mean = train.mean()\ntrain.fillna(f_mean)\n\n# split data for training and free data space usage to prevent exceeding maximum allowed\nX_train = train.loc[:, features]\ny_train = train.loc[:, 'action']\ndel train\n\nprint('Finished.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#   X G B o o s t\n#\n# create, configure and train the classifier using GPU\n# TODO: other tree_methods ?\n\nprint('Creating classifier...', end='')\nclf = xgb.XGBClassifier(\n    n_estimators=5000,\n            max_depth=12,\n            learning_rate=0.02,\n            subsample=0.8,\n            colsample_bytree=0.4,\n            missing=-1,\n            eval_metric='auc',\n            # USE CPU\n            #nthread=4,\n            #tree_method='hist'\n            # USE GPU\n            tree_method='gpu_hist' \n#     n_estimators=400,\n#     max_depth=7,\n#     eta=0.5, # learning_rate\n#     missing=None,\n#     random_state=42,\n#     tree_method='gpu_hist',\n#     subsample=0.8,\n#     colsample_bytree=1,\n#     #sampling_method='gradient_based',\n#     #eval_metric='logloss',\n#     verbosity=2   # info\n    \n)\nprint('Finished.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport eli5\n\nimport lightgbm as lgbm\nimport xgboost as xgb\n\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain, Xval, Ztrain, Zval = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\ntrain_set = lgbm.Dataset(Xtrain, Ztrain, silent=False)\nvalid_set = lgbm.Dataset(Xval, Zval, silent=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,        \n    }\n\nmodelL = lgbm.train(params, train_set = train_set, num_boost_round=1000,\n                   early_stopping_rounds=50, verbose_eval=10, valid_sets=valid_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgbm.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_score = pd.DataFrame(features, columns = ['feature']) \nfeature_score['score_lgb'] = modelL.feature_importance()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform test and create submissions file\nprint('Creating submissions file...', end='')\nrcount = 0\nfor (test_df, prediction_df) in env.iter_test():\n    X_test = test_df.loc[:, features]\n    y_preds = modelL.predict(X_test)\n    prediction_df.action = y_preds\n    env.predict(prediction_df)\n    rcount += len(test_df.index)\nprint(f'Finished processing {rcount} rows.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(modelx,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\n# train\nprint('Training classifier...', end='')\n%time clf.fit(X_train, y_train)\nprint('Finished.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_df = prediction_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform test and create submissions file\nprint('Creating submissions file...', end='')\nrcount = 0\nfor (test_df, xg_df) in env.iter_test():\n    X_test = test_df.loc[:, features]\n    y_preds = modelL.predict(X_test)\n    prediction_df.action = y_preds\n    env.predict(prediction_df)\n    rcount += len(test_df.index)\nprint(f'Finished processing {rcount} rows.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #   E X P E R I M E N T S\n\n# # adjust parameters to test fit\n\n# # eval_metric = ['logloss', 'error', 'error@0.6']\n# # sampling_method=['uniform', 'gradient_based']\n# # param_grid = dict(eval_metric=eval_metric, sampling_method=sampling_method)\n\n# #kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n# grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_log_loss\", n_jobs=1, cv=10, verbose=3, refit=False)\n# grid_result = grid_search.fit(X_train, y_train)\n\n# # summarize results\n# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n# for mean, stdev, param in zip(means, stds, params):\n# \tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n# # # plot results\n# # scores = np.array(means).reshape(len(eval_metric), len(sampling_method))\n# # for i, value in enumerate(sampling_method):\n# #     plt.plot(eval_metric, scores[i], label='sampling_method: ' + str(value))\n# # plt.legend()\n# # plt.xlabel('sampling_method')\n# # plt.ylabel('Log Loss')\n# # plt.savefig('best_params.png')m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # available importance_types = [‘weight’, ‘gain’, ‘cover’, ‘total_gain’, ‘total_cover’]\n# f = 'gain'\n# top = len(features)  # or set constant to view only the most important\n# fdata = clf.get_booster().get_score(importance_type= f)\n# fsorted = dict(sorted(fdata.items(), key=lambda item: item[1], reverse=True))\n# plt.figure(figsize=(10,top * 0.25))\n# plt.barh(range(top), list(fsorted.values())[:top], align='center')\n# plt.yticks(range(top), list(fsorted.keys())[:top])\n# plt.show()\n# #print(list(fsorted.keys()))\n# #print(fsorted)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}