{"cells":[{"metadata":{},"cell_type":"markdown","source":"In my previous notebook [JS Adversarial Validation: Time Consistency](http://www.kaggle.com/gerwynng/js-adversarial-validation-time-consistency), i have explored a one-fit-size-all approach to test for time consistency. \n\nIn this notebook, i extended the analysis to look at **the individual features to see how they 'shift' across time.** Again, i will mimic the private leaderboard by creating a 6-month gap (~125 days) to see how consistent the features are across time. That is, we split the train data into two subsets:\n 1. first 188 days\n 2. last 188 days\n \n \nDoing so will give us more ideas on how each individual feature shift across time.\n\n\n[Reference kernel](https://www.kaggle.com/nroman/eda-for-cis-fraud-detection)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport gc\nimport datatable as dt\nimport math\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()\nprint(df.shape)\n\nfeatures = [c for c in df.columns if 'feature' in c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[df['date'] <= 188]\ntest = df[df['date'] >= (500-188)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'num_leaves': 50,\n         'min_data_in_leaf': 30, \n         'objective':'binary',\n         'max_depth': 5,\n         'learning_rate': 0.2,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 44,\n         \"metric\": 'auc',\n         \"verbosity\": -1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def covariate_shift(feature):\n    df_train = pd.DataFrame(data = {feature: train[feature], 'isTest':0})\n    df_test = pd.DataFrame(data = {feature: test[feature], 'isTest': 1})\n    \n    # Creating a single dataframe\n    df_merge = pd.concat([df_train, df_test], ignore_index=True)\n    \n    # Splitting it to a training and testing set\n    X_train, X_test, y_train, y_test = train_test_split(df_merge[feature], df_merge['isTest'].values, test_size=0.33,\n                                                        random_state=47, stratify=df_merge['isTest'].values)\n    # prepare data for lgb\n    train_ = lgb.Dataset(np.expand_dims(X_train,axis=-1), label=y_train)\n    \n    clf = lgb.train(param, train_, 50)\n    roc_auc =  roc_auc_score(y_test, clf.predict(np.expand_dims(X_test,axis=-1)))\n\n    del X_train, y_train, X_test, y_test\n    gc.collect();\n    \n    return roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\nfor f in features:\n    score = covariate_shift(f)\n    scores.append(score)\n    print('{feature} : {score}'.format(feature = f, score = score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROC AUC score close to 0.5 --> the feature does not have any shift across the 6-month gap as the auxiliary model cannot distinguish the features values between first 188 and last 188 dates."},{"metadata":{},"cell_type":"markdown","source":"We will normalise the ROC AUC scores across the features and create a plot for visualise inspection."},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalise scores by looking at absolute difference from 0.5\nnorm_scores = [abs(x-0.5) for x in scores]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.plot([*range(0,130)], norm_scores)\nplt.ylabel('Norm Scores')\nplt.xlabel('Feature');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look at the top five features with highest norm scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features = sorted(range(len(norm_scores)), key=lambda i: norm_scores[i], reverse=True)[:5]\nprint('Top Five Features with Highest Covariate Shifts:')\nfor x in top_features:\n    print('feature_{x} : {norm_score}'.format(x = x, norm_score = norm_scores[x]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}