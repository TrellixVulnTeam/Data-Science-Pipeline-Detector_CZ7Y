{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle Competition : Jane Street Market Prediction"},{"metadata":{},"cell_type":"markdown","source":" $\\rule{20cm}{0.1pt}$"},{"metadata":{},"cell_type":"markdown","source":"## Notebook details\n\ncf. https://www.kaggle.com/lunatik62/pytorch-tagmodels-stacking-1-2"},{"metadata":{},"cell_type":"markdown","source":"**Load Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport json\nimport time\nimport random\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom scipy.special import expit\n\nimport torch\nimport torch.nn as nn\n\nprint(f\"Pytorch version : {torch.__version__}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU : {torch.cuda.get_device_name()} available\")\nelse:\n    print(\"Error : GPU not available\")\n    sys.exit(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Functions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    return None\n\ndef utility(dates, weights, true_resp, actions, use_mult=False):\n    \"\"\"Jane Street evaluation metric\"\"\"\n    Pi = weights * true_resp * actions\n    if use_mult:\n        mult = np.sqrt(250 / np.bincount(dates).shape[0])\n    else:\n        mult = 1\n    sum_Pi = Pi.sum() \n    sum_pi_squared = np.sqrt((Pi ** 2).sum())\n    t = (sum_Pi / sum_pi_squared) * mult\n    u = min(max(t, 0), 6) * sum_Pi\n    return u\n\ndef compute_utility_many(predictions, dates, weights, true_resp, interval=np.linspace(0, 1, 101)):\n    \"\"\"given predictions probability compute utility for many threshold\"\"\"\n    lst_ut = []\n    for v in interval:\n        actions =  (predictions > v).astype(int)\n        ut = utility(dates=dates, weights=weights, true_resp=true_resp, actions=actions)\n        lst_ut.append((v, ut))\n    return lst_ut\n\ndef build_dic_records(datasets=[], records=[]):\n    \"\"\"save training data into python dict\"\"\"\n    dic = {}\n    for dataset in datasets:\n        dic[dataset] = {}\n        for record in records:\n            dic[dataset][record] = []\n    return dic","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Settings**"},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 2021\nDATE_NOW = datetime.now().__format__(\"%Y-%m-%d_%H:%M:%S\")\nDATE_TRAINING_TAGMODEL = \"2021-02-16_154406\"\nDEVICE = torch.device(\"cuda\")\n\nPATH_ROOT = \"/kaggle/input/jane-street-market-prediction\"\nPATH_WEIGHT_TAGMODEL = \"../input/weights-tagmodels/\"\nPATH_WEIGHT_STACKMODEL = \"../input/weightsstackedmodel/StackedModel_2021-02-17_135144.pt\"\n\nPATH_DATA = os.path.join(PATH_ROOT, \"train.csv\")\nPATH_FEATURES =  os.path.join(PATH_ROOT, \"features.csv\")\n\nLST_FEATURES = [\"feature_\"+str(n_feat) for n_feat in range(0, 130, 1)]\nLST_TARGETS = [\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]\n\nTRAIN_PREVIOUS_LAYERS = False\nTHRESHOLD = .5\nSIZE_TRAIN = .85\nTRAINING = False\nSAVE_DICT = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nseed_everything(seed=SEED)\n\ndata = dt.fread(PATH_DATA).to_pandas()  # fast loading\ndata = data[data.date > 85]  # delete date < 85\ndata = data.sample(frac=1)  # shuffle\ndata.reset_index(drop=True, inplace=True)\nprint(f\"shape : {data.shape}\")\n\ndf_tags = pd.read_csv(PATH_FEATURES, index_col=\"feature\")\ndic_tags = {}\nfor n, tag in enumerate(df_tags.columns):\n    lst_features = df_tags[tag][df_tags[tag] == True].index.tolist()\n    lst_num_features = [int(e.strip(\"feature_\")) for e in lst_features]\n    dic_tags[str(n)] = lst_num_features\n\n# add feature_0 in all tags\nfor e in dic_tags.keys():\n    dic_tags[e].append(0)\n    \nf_mean = data[LST_FEATURES[1:]].mean()\nf_mean[\"feature_0\"] = 1\nf_mean.sort_index()\ndata = data.loc[data.weight > 0].reset_index(drop = True)  # delete 0 weight data\ndata[LST_FEATURES[1:]] = data[LST_FEATURES[1:]].fillna(f_mean)  # filling NaN by mean of each feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pytorch utils**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class EarlyStopping:\n    \n    def __init__(self, patience=7, mode=\"max\", delta=0.0, verbose=False, trace_func=print, path=\"checkpoint.pt\"):\n        \n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        self.verbose = verbose\n        self.trace_func = trace_func\n        self.path = path\n        \n        if self.mode == \"min\":\n            self.val_score = np.Inf\n            \n        else:\n            self.val_score = -np.Inf\n\n    def __call__(self, epoch_score, model):\n\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n            \n        elif self.mode == \"max\":\n            score = np.copy(epoch_score)\n        \n        # first epoch\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model)\n        \n        # best score NOT modified\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n                \n        # best score modified        \n        else:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model)\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model):\n        \"\"\"\n        Save model when validation loss decrease.\n        \"\"\"\n        if self.verbose:\n            self.trace_func(f'Validation metric moving : ({self.val_score:.6f} --> {epoch_score:.6f}).  Saving model ...')\n            \n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            torch.save(model.state_dict(), self.path)\n            \n        self.val_score = epoch_score\n\nclass BuildDataset:\n    \n    def __init__(self, df, col_x, target):\n        self.col_x = col_x.copy()\n        self.target = target.copy()\n        self.X = df[self.col_x].values\n        self.y = (df[self.target] > 0).astype('int').values\n        self.weights = df.weight.values\n        self.resps = df.resp.values\n        self.actions = (df.resp > 0 ).astype('int').values\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            'features': torch.tensor(self.X[idx], dtype=torch.float),\n            'label': torch.tensor(self.y[idx], dtype=torch.float),\n            'weights': torch.tensor(self.weights[idx], dtype=torch.float),\n            'resps': torch.tensor(self.resps[idx], dtype=torch.float),\n            'actions': torch.tensor(self.actions[idx], dtype=torch.float)\n        }\n    \nclass P1UtilityLoss(torch.nn.Module):\n    \"\"\"\n    customized loss based on first part of utility evaluation metric\n    \"\"\"\n\n    def __init__(self, threshold=.5):\n        super(P1UtilityLoss, self).__init__()\n        self.threshold = torch.tensor(threshold)\n        \n    def forward(self, true_actions, pred, weights, resps):\n        w_r = torch.mul(weights, resps)\n        pi_true = torch.mul(w_r, true_actions)\n        pi_pred = torch.mul(w_r, pred)\n        pi_true_sum = torch.sum(pi_true)\n        pi_pred_sum = torch.sum(pi_pred)\n        res = torch.sub(torch.tensor(1), torch.div(pi_pred_sum, pi_true_sum))\n        return res\n\nclass TagModel(torch.nn.Module):\n    \"\"\"\n    MLP : batchnorm0 > dropout > dense0 > relu > batchnorm1 > dropout > dense1 > sigmoid\n    \"\"\"\n    \n    def __init__(self, dic_tags, tag_number, input_size, output_size, threshold=.5, rate_dropout=.1):\n        \n        super(TagModel, self).__init__()\n        self.dic_tags = dic_tags\n        self.tag_number = str(tag_number)\n        self.input_size = input_size\n        self.output_size = output_size\n        self.rate_dropout = rate_dropout\n        \n        self.sigmoid = torch.nn.Sigmoid()\n        self.dropout = nn.Dropout(self.rate_dropout)\n        self.batch_norm0 = nn.BatchNorm1d(len(self.dic_tags[self.tag_number]))\n        self.batch_norm1 = nn.BatchNorm1d(2 * len(self.dic_tags[self.tag_number]))\n        self.dense0 = torch.nn.Linear(\n            len(self.dic_tags[self.tag_number]),\n            2 * len(self.dic_tags[self.tag_number])\n        )\n        self.dense1 = torch.nn.Linear(\n            2 * len(self.dic_tags[self.tag_number]),\n            self.output_size\n        )\n        self.relu = torch.nn.ReLU()\n        \n    def forward(self, x):\n        \n        x = self.batch_norm0(x[:, self.dic_tags[self.tag_number]])\n        x = self.dropout(x)\n        x = self.dense0(x)\n        \n        x = self.relu(x)\n        \n        x = self.batch_norm1(x)\n        x = self.dropout(x)\n        x = self.dense1(x)\n        \n        x = self.sigmoid(x)\n        return x\n    \nclass StackedModel(torch.nn.Module):\n    \n    def __init__(self, dic_tags, path_weights, date_training_tag, rate_dropout=.1, train_previous_layers=False, device=DEVICE):\n        super(StackedModel, self).__init__()\n\n        self.dic_tags = dic_tags\n        self.path_weights = path_weights\n        self.rate_dropout = rate_dropout\n        self.date_training_tag = date_training_tag\n        self.train_previous_layers = train_previous_layers\n        self.device = DEVICE\n        \n        # load 29 TagModels\n        self.model0 = TagModel(dic_tags=self.dic_tags, tag_number=0, input_size=130, output_size=1).to(self.device)\n        self.model1 = TagModel(dic_tags=self.dic_tags, tag_number=1, input_size=130, output_size=1).to(self.device)\n        self.model2 = TagModel(dic_tags=self.dic_tags, tag_number=2, input_size=130, output_size=1).to(self.device)\n        self.model3 = TagModel(dic_tags=self.dic_tags, tag_number=3, input_size=130, output_size=1).to(self.device)\n        self.model4 = TagModel(dic_tags=self.dic_tags, tag_number=4, input_size=130, output_size=1).to(self.device)\n        self.model5 = TagModel(dic_tags=self.dic_tags, tag_number=5, input_size=130, output_size=1).to(self.device)\n        self.model6 = TagModel(dic_tags=self.dic_tags, tag_number=6, input_size=130, output_size=1).to(self.device)\n        self.model7 = TagModel(dic_tags=self.dic_tags, tag_number=7, input_size=130, output_size=1).to(self.device)\n        self.model8 = TagModel(dic_tags=self.dic_tags, tag_number=8, input_size=130, output_size=1).to(self.device)\n        self.model9 = TagModel(dic_tags=self.dic_tags, tag_number=9, input_size=130, output_size=1).to(self.device)\n        self.model10 = TagModel(dic_tags=self.dic_tags, tag_number=10, input_size=130, output_size=1).to(self.device)\n        self.model11 = TagModel(dic_tags=self.dic_tags, tag_number=11, input_size=130, output_size=1).to(self.device)\n        self.model12 = TagModel(dic_tags=self.dic_tags, tag_number=12, input_size=130, output_size=1).to(self.device)\n        self.model13 = TagModel(dic_tags=self.dic_tags, tag_number=13, input_size=130, output_size=1).to(self.device)\n        self.model14 = TagModel(dic_tags=self.dic_tags, tag_number=14, input_size=130, output_size=1).to(self.device)\n        self.model15 = TagModel(dic_tags=self.dic_tags, tag_number=15, input_size=130, output_size=1).to(self.device)\n        self.model16 = TagModel(dic_tags=self.dic_tags, tag_number=16, input_size=130, output_size=1).to(self.device)\n        self.model17 = TagModel(dic_tags=self.dic_tags, tag_number=17, input_size=130, output_size=1).to(self.device)\n        self.model18 = TagModel(dic_tags=self.dic_tags, tag_number=18, input_size=130, output_size=1).to(self.device)\n        self.model19 = TagModel(dic_tags=self.dic_tags, tag_number=19, input_size=130, output_size=1).to(self.device)\n        self.model20 = TagModel(dic_tags=self.dic_tags, tag_number=20, input_size=130, output_size=1).to(self.device)\n        self.model21 = TagModel(dic_tags=self.dic_tags, tag_number=21, input_size=130, output_size=1).to(self.device)\n        self.model22 = TagModel(dic_tags=self.dic_tags, tag_number=22, input_size=130, output_size=1).to(self.device)\n        self.model23 = TagModel(dic_tags=self.dic_tags, tag_number=23, input_size=130, output_size=1).to(self.device)\n        self.model24 = TagModel(dic_tags=self.dic_tags, tag_number=24, input_size=130, output_size=1).to(self.device)\n        self.model25 = TagModel(dic_tags=self.dic_tags, tag_number=25, input_size=130, output_size=1).to(self.device)\n        self.model26 = TagModel(dic_tags=self.dic_tags, tag_number=26, input_size=130, output_size=1).to(self.device)\n        self.model27 = TagModel(dic_tags=self.dic_tags, tag_number=27, input_size=130, output_size=1).to(self.device)\n        self.model28 = TagModel(dic_tags=self.dic_tags, tag_number=28, input_size=130, output_size=1).to(self.device)\n        \n        # load their weights\n        self.model0.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel0_{self.date_training_tag}.pt\")))\n        self.model1.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel1_{self.date_training_tag}.pt\")))\n        self.model2.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel2_{self.date_training_tag}.pt\")))\n        self.model3.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel3_{self.date_training_tag}.pt\")))\n        self.model4.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel4_{self.date_training_tag}.pt\")))\n        self.model5.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel5_{self.date_training_tag}.pt\")))\n        self.model6.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel6_{self.date_training_tag}.pt\")))\n        self.model7.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel7_{self.date_training_tag}.pt\")))\n        self.model8.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel8_{self.date_training_tag}.pt\")))\n        self.model9.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel9_{self.date_training_tag}.pt\")))\n        self.model10.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel10_{self.date_training_tag}.pt\")))\n        self.model11.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel11_{self.date_training_tag}.pt\")))\n        self.model12.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel12_{self.date_training_tag}.pt\")))\n        self.model13.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel13_{self.date_training_tag}.pt\")))\n        self.model14.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel14_{self.date_training_tag}.pt\")))\n        self.model15.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel15_{self.date_training_tag}.pt\")))\n        self.model16.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel16_{self.date_training_tag}.pt\")))\n        self.model17.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel17_{self.date_training_tag}.pt\")))\n        self.model18.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel18_{self.date_training_tag}.pt\")))\n        self.model19.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel19_{self.date_training_tag}.pt\")))\n        self.model20.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel20_{self.date_training_tag}.pt\")))\n        self.model21.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel21_{self.date_training_tag}.pt\")))\n        self.model22.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel22_{self.date_training_tag}.pt\")))\n        self.model23.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel23_{self.date_training_tag}.pt\")))\n        self.model24.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel24_{self.date_training_tag}.pt\")))\n        self.model25.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel25_{self.date_training_tag}.pt\")))\n        self.model26.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel26_{self.date_training_tag}.pt\")))\n        self.model27.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel27_{self.date_training_tag}.pt\")))\n        self.model28.load_state_dict(torch.load(os.path.join(self.path_weights, f\"TagModel28_{self.date_training_tag}.pt\")))\n        \n        # fix weights of TagModels only\n        if not self.train_previous_layers:\n            self.model0.eval()\n            self.model1.eval()\n            self.model2.eval()\n            self.model3.eval()\n            self.model4.eval()\n            self.model5.eval()\n            self.model6.eval()\n            self.model7.eval()\n            self.model8.eval()\n            self.model9.eval()\n            self.model10.eval()\n            self.model11.eval()\n            self.model12.eval()\n            self.model13.eval()\n            self.model14.eval()\n            self.model15.eval()\n            self.model16.eval()\n            self.model17.eval()\n            self.model18.eval()\n            self.model19.eval()\n            self.model20.eval()\n            self.model21.eval()\n            self.model22.eval()\n            self.model23.eval()\n            self.model24.eval()\n            self.model25.eval()\n            self.model26.eval()\n            self.model27.eval()\n            self.model28.eval()\n                \n        self.relu = torch.nn.ReLU()\n        self.sigmoid = torch.nn.Sigmoid()\n        self.dropout = nn.Dropout(self.rate_dropout)\n        self.batch_norm0 = nn.BatchNorm1d(60)\n        self.batch_norm1 = nn.BatchNorm1d(5)\n        \n        self.dense0 = torch.nn.Linear(30, 60)\n        self.dense1 = torch.nn.Linear(60, 5)\n        self.dense2 = torch.nn.Linear(5, 1)\n\n        \n    def forward(self, x):\n        feature_0 = torch.reshape(x[:, 0], (-1, 1))\n        \n        # xi is output of TagModeli\n        x0 = self.model0(x)\n        x1 = self.model1(x)\n        x2 = self.model2(x)\n        x3 = self.model3(x)\n        x4 = self.model4(x)\n        x5 = self.model5(x)\n        x6 = self.model6(x)\n        x7 = self.model7(x)\n        x8 = self.model8(x)\n        x9 = self.model9(x)\n        x10 = self.model10(x)\n        x11 = self.model11(x)\n        x12 = self.model12(x)\n        x13 = self.model13(x)\n        x14 = self.model14(x)\n        x15 = self.model15(x)\n        x16 = self.model16(x)\n        x17 = self.model17(x)\n        x18 = self.model18(x)\n        x19 = self.model19(x)\n        x20 = self.model20(x)\n        x21 = self.model21(x)\n        x22 = self.model22(x)\n        x23 = self.model23(x)\n        x24 = self.model24(x)\n        x25 = self.model25(x)\n        x26 = self.model26(x)\n        x27 = self.model27(x)\n        x28 = self.model28(x)\n        \n        x = torch.cat(\n            (\n                feature_0,\n                x0, x1, x2, x3, x4, x5, x6, x7, x8, x9,\n                x10, x11, x12, x13, x14, x15, x16, x17, x18, x19,\n                x20, x21, x22, x23, x24, x25, x26, x27, x28\n            ), 1\n        )\n        \n        x = self.dense0(x)\n        x = self.relu(x)\n        \n        x = self.batch_norm0(x)\n        x = self.dropout(x)\n        x = self.dense1(x)\n        \n        x = self.batch_norm1(x)\n        x = self.dropout(x)\n        x = self.dense2(x)\n        \n        x = self.sigmoid(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training all TagModel**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model : architecture\nbatch_size = 16384\ninput_size = 130\noutput_size = 1\n\n# Model : training\nnum_epochs = 100\nlearning_rate = 0.001\nthreshold =.5\nes_mode = \"min\"\npatience = 3\n\ndic_records = build_dic_records(\n            datasets=[\"train\", \"val\"],\n            records=[\"lst_loss_epoch\", \"lst_loss_batch\", \"lst_utility\", \"lst_accuracy\", \"lst_precision\", \"lst_recall\"]\n)\n\nif TRAINING:\n\n    # sample data\n    data = data.sample(frac=1)\n    data.reset_index(drop=True, inplace=True)\n\n    train_index = [e for e in range(0, int(data.shape[0] * SIZE_TRAIN), 1)]\n    val_index = [e for e in range(max(train_index), data.shape[0], 1)]\n\n    # build sets for training\n    train = data.loc[train_index]\n    val = data.loc[val_index]\n    train_set = BuildDataset(df=train.loc[train_index], col_x=LST_FEATURES, target=LST_TARGETS)\n    val_set = BuildDataset(df=val.loc[val_index], col_x=LST_FEATURES, target=LST_TARGETS)\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size)\n\n    # compute and save perfect utility for each set\n    perfect_train_utility = utility(dates=train.date.values, weights=train.weight.values, true_resp=train.resp.values, actions=(train.resp > 0).astype(int))\n    perfect_val_utility = utility(dates=val.date.values, weights=val.weight.values, true_resp=val.resp.values, actions=(val.resp > 0).astype(int))\n    dic_records[\"train\"][\"perfect_utility\"] = perfect_train_utility\n    dic_records[\"val\"][\"perfect_utility\"] = perfect_val_utility\n    dic_records[\"train\"][\"lst_index\"] = train_index\n    dic_records[\"val\"][\"lst_index\"] = val_index\n\n    # define utils for model\n    torch.cuda.empty_cache()\n    model = StackedModel(\n        dic_tags=dic_tags, path_weights=PATH_WEIGHT_TAGMODEL, date_training_tag=DATE_TRAINING_TAGMODEL,train_previous_layers=TRAIN_PREVIOUS_LAYERS, device=DEVICE\n    ).to(DEVICE)\n    p1_utility_loss = P1UtilityLoss(threshold)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    path_model = f\"./StackedModel_{DATE_NOW}.pt\"\n    early_stopping = EarlyStopping(mode=es_mode, patience=patience, verbose=True, path=path_model)\n\n    pbar_epoch = tqdm(total=num_epochs, position=1)\n\n    for epoch in range(num_epochs):\n\n        dic_records[\"train\"][\"lst_loss_batch\"] = []\n        dic_records[\"val\"][\"lst_loss_batch\"] = []\n        train_outputs = np.empty(shape=(len(train)))\n        val_outputs = np.empty(shape=(len(val)))\n\n        pbar_batch = tqdm(total=len(train_loader), position=2)\n\n        for i, train_batch in enumerate(train_loader):\n\n            # Allow training <=> moving weights\n            model.train()\n\n            # Remember index on train data\n            start_ind = i * batch_size\n            end_ind = start_ind + batch_size\n\n            # Send to GPU\n            X = train_batch[\"features\"].to(DEVICE)\n            y = train_batch[\"label\"].to(DEVICE)\n            w = train_batch[\"weights\"].to(DEVICE)\n            r = train_batch[\"resps\"].to(DEVICE)\n            a = train_batch[\"actions\"].to(DEVICE)\n\n            # Forward pass\n            outputs = model(X.float())\n            loss = p1_utility_loss(a.to(DEVICE), outputs[:,0].to(DEVICE), w.to(DEVICE), r.to(DEVICE))\n            # Backward and optimize\n            optimizer.zero_grad() \n            loss.backward()\n            optimizer.step()\n\n            # Save \n            dic_records[\"train\"][\"lst_loss_batch\"].append(loss.item())\n            train_outputs[start_ind:end_ind] = outputs[:,0].cpu().detach().numpy()\n            pbar_batch.update(1)\n\n        # compute loss on validation\n        model.eval()\n        with torch.no_grad():\n            for i_, val_batch in enumerate(val_loader):\n\n                # Remember index on validation data\n                start_ind_ = i_ * batch_size\n                end_ind_ = start_ind_ + batch_size\n\n                # Send to GPU\n                X_ = val_batch[\"features\"].to(DEVICE)\n                y_ = val_batch[\"label\"].to(DEVICE)\n                w_ = val_batch[\"weights\"].to(DEVICE)\n                r_ = val_batch[\"resps\"].to(DEVICE)\n                a_ = val_batch[\"actions\"].to(DEVICE)\n\n                # Compute\n                outputs_ = model(X_.float())\n                loss_ = p1_utility_loss(a_.to(DEVICE), outputs_[:,0].to(DEVICE), w_.to(DEVICE), r_.to(DEVICE))\n                # Save\n                dic_records[\"val\"][\"lst_loss_batch\"].append(loss_.item())\n                val_outputs[start_ind_:end_ind_] = outputs_[:,0].cpu().detach().numpy()\n        dic_records[\"train\"][\"lst_loss_epoch\"].append(np.mean(dic_records[\"train\"][\"lst_loss_batch\"]))\n        dic_records[\"val\"][\"lst_loss_epoch\"].append(np.mean(dic_records[\"val\"][\"lst_loss_batch\"]))\n\n        # Early Stopping on loss function\n        train_actions = (train_outputs > threshold).astype(int)\n        train_utility = utility(dates=train.date.values, weights=train.weight.values, true_resp=train.resp.values, actions=train_actions)\n        train_accuracy = accuracy_score((train.resp > 0).astype(int), train_actions)\n        train_precision = precision_score((train.resp > 0).astype(int), train_actions)\n        train_recall = recall_score((train.resp > 0).astype(int), train_actions)\n        dic_records[\"train\"][\"lst_utility\"].append(train_utility)\n        dic_records[\"train\"][\"lst_accuracy\"].append(train_accuracy)\n        dic_records[\"train\"][\"lst_precision\"].append(train_precision)\n        dic_records[\"train\"][\"lst_recall\"].append(train_recall)\n            \n        val_actions = (val_outputs > threshold).astype(int)\n        val_utility = utility(dates=val.date.values, weights=val.weight.values, true_resp=val.resp.values, actions=val_actions)\n        val_accuracy = accuracy_score((val.resp > 0).astype(int), val_actions)\n        val_precision = precision_score((val.resp > 0).astype(int), val_actions)\n        val_recall = recall_score((val.resp > 0).astype(int), val_actions)\n        dic_records[\"val\"][\"lst_utility\"].append(val_utility)\n        dic_records[\"val\"][\"lst_accuracy\"].append(val_accuracy)\n        dic_records[\"val\"][\"lst_precision\"].append(val_precision)\n        dic_records[\"val\"][\"lst_recall\"].append(val_recall)\n            \n        msg1 = '~~~ Epoch [{}/{}], Loss train: {:.4f}, Loss val {:.4f}'.format(\n                    epoch + 1,\n                    num_epochs,\n                    dic_records[\"train\"][\"lst_loss_epoch\"][-1],\n                    dic_records[\"val\"][\"lst_loss_epoch\"][-1]\n        )\n        msg2 = '~~~ train utility: {:.4f}, val utility {:.4f}'.format(\n                    dic_records[\"train\"][\"lst_utility\"][-1],\n                    dic_records[\"val\"][\"lst_utility\"][-1]\n        )\n        pbar_epoch.update(1)\n        pbar_epoch.write(msg1)\n        pbar_epoch.write(msg2)\n\n        early_stopping(dic_records[\"val\"][\"lst_loss_epoch\"][-1], model)\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Save dict**"},{"metadata":{"trusted":true},"cell_type":"code","source":"if SAVE_DICT:\n    with open(\"./dic_records_training_StackedModel.json\", \"w\") as out:  \n        json.dump(dic_records, out) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load StackedModel**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load model\ntorch.cuda.empty_cache()\nmodel = StackedModel(\n        dic_tags=dic_tags, path_weights=PATH_WEIGHT_TAGMODEL, date_training_tag=DATE_TRAINING_TAGMODEL,train_previous_layers=TRAIN_PREVIOUS_LAYERS, device=DEVICE\n    ).to(DEVICE)\nmodel.load_state_dict(torch.load(PATH_WEIGHT_STACKMODEL))\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env()\nenv_iter = env.iter_test()\n\nfor (test_df, pred_df) in tqdm(env_iter):\n    \n    if test_df['weight'].values[0] > 0:\n        x_tt = test_df.loc[:, LST_FEATURES].values\n        \n        if np.isnan(x_tt.sum()):\n            x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean.values.reshape(1, -1)\n        \n        pred = model(torch.tensor(x_tt, dtype=torch.float).to(DEVICE)).detach().cpu().numpy()\n        int_pred = int(pred >= THRESHOLD)\n        \n        pred_df[\"action\"].values[0] = int_pred\n    \n    else:\n        pred_df[\"action\"].values[0] = 0\n    \n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}