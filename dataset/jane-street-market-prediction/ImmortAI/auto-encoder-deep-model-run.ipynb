{"cells":[{"metadata":{"_uuid":"178f1f58-81ff-4701-ad0c-b8c8c5636ffe","_cell_guid":"3a11ff5d-1242-4712-b6a1-f6c442919bdd","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy import stats\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport datatable as dt\nimport glob\nimport os\nfrom tensorflow.python.keras.callbacks import Callback\nimport keras.backend as K\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nsns.set_style('darkgrid')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fc33d3e-640f-43ed-aefe-60f15dc7d988","_cell_guid":"cde143f0-be93-43a3-9113-d20494bf1a09","trusted":true},"cell_type":"code","source":"TRAIN_MODEL = False\nseed = 1021\n\n\ntf.random.set_seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9305ce3f-fe79-444a-991f-dfaef5d5da7e","_cell_guid":"3fbc64e8-c5cd-4f13-a42b-08f0486961c2","trusted":true},"cell_type":"code","source":"df = dt.fread('../input/jane-street-market-prediction/train.csv')\ndf = df.to_pandas()\ndf = df.astype({c: np.float32 for c in df.select_dtypes(include='float64').columns}) #limit memory use","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"098610a4-5396-4195-aa80-6d2619c46608","_cell_guid":"00f1f65b-9f18-49bc-9c9f-635ad8065322","trusted":true},"cell_type":"code","source":"log_top_nan_f = ['feature_84', 'feature_90', 'feature_96','feature_102', 'feature_108', 'feature_114']\nnolog_top_nan_f = ['feature_7', 'feature_8', 'feature_17', 'feature_18', 'feature_27', 'feature_28', 'feature_72', 'feature_78']\n\ntop_nan_features = log_top_nan_f + nolog_top_nan_f","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"515a77f2-8634-49ed-8ba7-d09991d1f4f4","_cell_guid":"0974d13b-b7f5-4b83-8a09-568446c114a4","trusted":true},"cell_type":"code","source":"Q1_nolog_top_nan_f = df[nolog_top_nan_f].quantile(0.005)\nQ3_nolog_top_nan_f = df[nolog_top_nan_f].quantile(0.995)\ndf[nolog_top_nan_f] = df[nolog_top_nan_f].clip(lower=Q1_nolog_top_nan_f,upper=Q3_nolog_top_nan_f,axis=1)\nbias_nolog_top_nan_f = 1 - df[nolog_top_nan_f].min()\ndf[nolog_top_nan_f] = df[nolog_top_nan_f] + bias_nolog_top_nan_f\ndf[nolog_top_nan_f].hist(bins=100,figsize=(20,30),layout=(6,3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ae199b4-e854-4558-8194-0cf54cbd4a7a","_cell_guid":"9a056276-54b0-475f-9414-ec56b5eebc93","trusted":true},"cell_type":"code","source":"bias_log_top_nan_f = np.exp(1) - df[log_top_nan_f].min()\ndf[log_top_nan_f] = df[log_top_nan_f] + bias_log_top_nan_f\ndf[log_top_nan_f] = np.log(df[log_top_nan_f])\ndf[log_top_nan_f].hist(bins=100,figsize=(20,30),layout=(6,3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67bca23c-8c57-407a-b491-aa949854bcc8","_cell_guid":"60ba075a-0ef8-4fad-8cf4-270220222899","trusted":true},"cell_type":"code","source":"df[top_nan_features] = df[top_nan_features].fillna(0)\n# df[top_nan_features] = df[top_nan_features].fillna(df[top_nan_features].mean())\nprint(df.shape)\ndf = df.dropna()\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf870602-257e-4181-9bfc-05c7ba4ec32a","_cell_guid":"24e902ad-9eaf-48ea-b5f8-cfebed4c9b3c","trusted":true},"cell_type":"code","source":"features_to_drop_quantiles = ['feature_46','feature_48','feature_49', 'feature_50','feature_51','feature_54','feature_55','feature_56','feature_57','feature_58','feature_59']\nfor f in features_to_drop_quantiles:\n    df = df.loc[df[f] < df[f].quantile(0.999)].reset_index(drop=True)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e32d4e9-3d05-4fbf-8365-ba8e72b3dc7b","_cell_guid":"783b9479-4448-4eb5-9115-a39c38fb5cda","trusted":true},"cell_type":"code","source":"features = [c for c in df.columns if 'feature' in c]\nresp_cols = ['resp','resp_1','resp_2','resp_3','resp_4']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13cf9b81-6819-4c38-9268-3e1e15d7c77c","_cell_guid":"8bb86fc0-6325-4b31-81f7-9afc7cb8246e","trusted":true},"cell_type":"code","source":"val = df.query('400 <= date').reset_index(drop = True)\ntrain = df.query('85 < date < 400').reset_index(drop = True)\n\nrb_scalar = RobustScaler()\nrb_scalar.fit(train[features].values)\n\ntrain = train.query('weight > 0').reset_index(drop = True)\nval = val.query('weight > 0').reset_index(drop = True)\n\nX = train[features].values\nX_val = val[features].values\n\nX = rb_scalar.transform(X)\nX_val = rb_scalar.transform(X_val)\n\nY = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\nY_val = np.stack([(val[c] > 0).astype('int') for c in resp_cols]).T\n\nf_mean = np.mean(train[features].values,axis=0)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fdc3c6c-4806-489c-a448-f85ba6d01718","_cell_guid":"2797d4c1-3f78-4461-b17c-fdf36ebf7dd0","trusted":true},"cell_type":"code","source":"def create_autoencoder(input_dim, noise=0.1):\n    inp = Input(input_dim)\n    encoded = GaussianNoise(noise)(inp)\n    \n    encoded = Dense(128)(encoded)\n    encoded = BatchNormalization()(encoded)\n    encoded = Activation('relu')(encoded)\n#     encoded = Dropout(0.2)(encoded)\n    \n    encoded = Dense(64)(encoded)\n    encoded = BatchNormalization()(encoded)\n    encoded = Activation('relu')(encoded)\n#     encoded = Dropout(0.2)(encoded)\n    \n    encoded = Dense(32)(encoded)\n    encoded = BatchNormalization()(encoded)\n    \n    decoded = Dense(64,activation='relu')(encoded)\n    decoded = BatchNormalization()(decoded)\n#     decoded = Dropout(0.2)(decoded)\n\n    decoded = Dense(128,activation='relu')(decoded)\n    \n    decoded = Dense(input_dim, name='encoder')(decoded)\n    \n    encoder = Model(inputs=inp,outputs=encoded)\n    autoencoder = Model(inputs=inp,outputs=decoded)\n    \n    autoencoder.compile(optimizer=Adam(0.001),loss='mae')\n    return autoencoder,encoder\n\nautoencoder,encoder = create_autoencoder(X.shape[-1])\nautoencoder.summary()\nautoencoder.load_weights('../input/auto-encoder/autoencoder.hdf5')\nencoder.load_weights('../input/auto-encoder/encoder.hdf5')\nencoder.trainable = False\nautoencoder.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac2bed49-08c6-4e36-9288-82c97e36b24b","_cell_guid":"c5ed3c5d-a266-4cd2-afe5-f4bba1a696e0","trusted":true},"cell_type":"code","source":"X_pred = autoencoder(X_val)\nfrom matplotlib import pyplot as plt\nfig = plt.figure()\nplt.plot(X_val[-100:,1])\nplt.plot(X_pred[-100:,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcd84325-a3d8-409c-b4dd-5b67cc523ff6","_cell_guid":"915583ec-1401-45af-8376-85d1310a25a8","trusted":true},"cell_type":"code","source":"# def utility_score(date, weight, resp, action):\n#     Pi = np.bincount(date, weight * resp * action)\n#     t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n#     u = min(max(t, 0), 6) * np.sum(Pi)\n#     return u, np.sum(weight * resp * action)\n\n\ndef utility_score(date, weight, resp, action):\n    count_i = len(np.unique(date))\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n    u = np.clip(t, 0, 6) * np.sum(Pi)\n    return u\n\nclass UtilityScoreCallback(tf.keras.callbacks.Callback):\n    def __init__(self, X, date, weight, resp, stage = 'train'):\n        super(Callback, self).__init__()\n        self.X = X\n        self.date = date\n        self.weight = weight\n        self.resp = resp\n        self.stage = stage\n\n    def on_epoch_end(self, epoch, logs = {}):\n        y_preds = self.model(self.X)\n        y_preds = np.median(y_preds, axis = 1) # this is for multi-target\n#         y_preds = np.squeeze(y_preds)\n        action = np.where(y_preds >= 0.5, 1, 0)\n        uscore = utility_score(self.date, self.weight, self.resp, action)\n        print(\"Uscores {} : {:.2f} Percent Action 1: {:.2f}\".format(self.stage, uscore, np.sum(action)/len(action)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efb00773-92c9-4085-a5db-b0dae998c405","_cell_guid":"f805c251-9a99-4a32-99bf-6b62a914dfe4","trusted":true},"cell_type":"code","source":"# print('scores before training')\n# Y_hat = model.predict(X)\n# Y_hat = np.median(Y_hat,axis=1)\n# # Y_hat = np.squeeze(Y_hat)\n# Y_hat[Y_hat>0.5] = 1\n# Y_hat[Y_hat<=0.5] = 0\n\n# print(Y_hat.shape)\n\n# print(utility_score(train['date'], train['weight'], train['resp'], Y_hat))\n\n# Y_hat_val = model.predict(X_val)\n# Y_hat_val = np.median(Y_hat_val,axis=1)\n# # Y_hat_val = np.squeeze(Y_hat_val)\n# Y_hat_val[Y_hat_val>0.5] = 1\n# Y_hat_val[Y_hat_val<=0.5] = 0\n\n# print(Y_hat_val.shape)\n# print(utility_score(val['date'], val['weight'], val['resp'], Y_hat_val))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b787668-7223-46eb-9327-aee09f8a8684","_cell_guid":"ae7d78e5-f6ef-4906-987d-fe67ced8700f","trusted":true},"cell_type":"code","source":"def create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n#     x = autoencoder(inp)\n    x = encoder(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n#     x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n\n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n#         optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n#         optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model\n\nbatch_size = 5000\nhidden_units = [64, 64, 64, 64]\ndropout_rates = [0, 0.1, 0.1, 0.1, 0]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-4","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0625abc1-f27f-4db7-b91b-70b646384685","_cell_guid":"b841c00c-7c4a-4825-a7b0-662d470547b9","trusted":true},"cell_type":"code","source":"all_models = []\n\nfor i_model in range(5):\n    model = create_mlp(X.shape[-1], Y.shape[-1], hidden_units, dropout_rates, label_smoothing, learning_rate)\n    model.summary()\n\n    print(X.shape)\n    print(Y.shape)\n    if TRAIN_MODEL:\n        model.fit(X,Y,\n                  epochs=500,\n                  batch_size=4096,\n                  validation_data = (X_val,Y_val),\n    #               sample_weight = sample_weight,\n                  callbacks = [EarlyStopping('val_loss', patience=50, restore_best_weights=True),\n    #                            UtilityScoreCallback(X, train['date'].values, train['weight'].values, train['resp'].values, stage = 'train'),\n    #                            UtilityScoreCallback(X_val, val['date'].values, val['weight'].values, val['resp'].values, stage = 'val')\n                              ]\n    #               callbacks = UtilityScoreCallback(X_val, val['date'].values, val['weight'].values, val['resp'].values, stage = 'val')\n                       )\n        model.save_weights('./model_' + str(i_model) + '.hdf5')\n    else:\n        model.load_weights('../input/auto-encoder-deep-model/model_' + str(i_model) + '.hdf5')\n    all_models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e06a0e49-ece5-4def-800a-cff3e75fa305","_cell_guid":"c945c47e-6c23-4f81-89aa-74caec0a2198","trusted":true},"cell_type":"code","source":"all_Y_hat_val = []\nfor model in all_models:\n    Y_hat_val = model.predict(X_val)\n    Y_hat_val = np.median(Y_hat_val,axis=1)\n    Y_hat_val = np.squeeze(Y_hat_val)\n    all_Y_hat_val.append(Y_hat_val)\nall_Y_hat_val = np.array(all_Y_hat_val)\n\nY_hat_val = np.mean(all_Y_hat_val,axis=0)\n\nbest_util = 0\nbest_thr = None\nfor i in range(4500, 5500):\n    thr = float(i) / 10000\n    Y_hat_val_ = Y_hat_val.copy()\n    Y_hat_val_[Y_hat_val_>thr] = 1\n    Y_hat_val_[Y_hat_val_<=thr] = 0\n    ul = utility_score(val['date'], val['weight'], val['resp'], Y_hat_val_)\n#     print(str(thr) + ' ' + str(ul)))\n    if ul > best_util:\n        best_util = ul\n        best_thr = thr\n    if i == 5000:\n        print(ul)\n        print(thr)\n\nprint(best_util)\nprint(best_thr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53349e30-45b0-42fb-9285-a572c82bb5df","_cell_guid":"a0d9fe93-1dc0-4985-a927-c228bbc6e4a9","trusted":true},"cell_type":"code","source":"no_log_top_nan_f_ind = [int(f.split('_')[1]) for f in nolog_top_nan_f]\nlog_top_nan_f_ind = [int(f.split('_')[1]) for f in log_top_nan_f]\ntop_nan_features_ind = [int(f.split('_')[1]) for f in top_nan_features]\nfor model in all_models:\n    model.call = tf.function(model.call, experimental_relax_shapes=True)\nencoder.call = tf.function(encoder.call, experimental_relax_shapes=True)\ncount = 0\n\n\nimport janestreet\nenv = janestreet.make_env()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        x_ = test_df.loc[:, features].values\n        \n        x_ = np.squeeze(x_)\n        x_temp = x_[no_log_top_nan_f_ind]\n        x_temp = np.clip(x_temp, Q1_nolog_top_nan_f.values, Q3_nolog_top_nan_f.values)\n        x_temp = x_temp + bias_nolog_top_nan_f.values\n        x_[no_log_top_nan_f_ind] = x_temp\n        \n        x_[log_top_nan_f_ind] = x_[log_top_nan_f_ind] + bias_log_top_nan_f.values\n        x_[log_top_nan_f_ind] = np.log(x_[log_top_nan_f_ind])\n        \n        x_temp = x_[top_nan_features_ind]\n        x_temp[np.isnan(x_temp)] = 0\n        x_[top_nan_features_ind] = x_temp\n        \n        x = x_[np.newaxis, :]\n\n\n        if np.isnan(x.sum()):\n            x = np.nan_to_num(x) + np.isnan(x) * f_mean\n\n        x = rb_scalar.transform(x)\n        \n        y = np.zeros(len(all_models))\n        ii = 0\n        for model in all_models:\n            y_hat = model(x, training = False).numpy()\n            y_hat = np.median(y_hat)\n            y[ii] = y_hat\n            ii = ii + 1\n\n        y = np.mean(y)\n        if y > 0.5:\n            pred_df.action = 1\n            count = count + 1\n        else:\n            pred_df.action = 0\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8605c82-eafa-43d7-bff2-7abddf7e072d","_cell_guid":"34435f09-c706-411c-8a35-ce9bb74446c6","trusted":true},"cell_type":"code","source":"# janestreet.competition.make_env.__called__ = False","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}