{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Clustering of feature values"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport datatable as dt\nfrom sklearn.metrics import silhouette_score\n\n\nimport gc\npd.set_option('display.max_rows', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Install and import FAISS"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"!pip install ../input/faiss-163/faiss_cpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import faiss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train_data_datatable = dt.fread('../input/jane-street-market-prediction/train.csv')\ndf = train_data_datatable.to_pandas()\n\n# Thanks to this notebook to gain memory usage : https://www.kaggle.com/jorijnsmit/one-liner-to-halve-your-memory-usage\nfloat64_cols = df.select_dtypes(include='float64').columns\nmapper = {col_name: np.float32 for col_name in float64_cols}\ndf = df.astype(mapper)\n\ndel train_data_datatable    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train a clustering with k=5 clusters"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"class FaissKMeans:\n    def __init__(self, n_clusters=8, n_init=10, max_iter=300):\n        self.n_clusters = n_clusters\n        self.n_init = n_init\n        self.max_iter = max_iter\n        self.kmeans = None\n        self.cluster_centers_ = None\n        self.inertia_ = None\n\n    def fit(self, X):\n        self.kmeans = faiss.Kmeans(d=X.shape[1],\n                                   k=self.n_clusters,\n                                   niter=self.max_iter,\n                                   nredo=self.n_init)\n        self.kmeans.train(X.astype(np.float32))\n        self.cluster_centers_ = self.kmeans.centroids\n        self.inertia_ = self.kmeans.obj[-1]\n\n    def predict(self, X):\n        return self.kmeans.index.search(X.astype(np.float32), 1)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing = [col for col in df.columns if df[col].isnull().any()]\nfor col in cols_with_missing:\n    df[col].fillna(-999, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB_CLUSTERS = 5\nFEATURES_LIST = ['feature_'+str(i) for i in range(130)] + ['weight']\n\nclusterer = FaissKMeans(n_clusters=NB_CLUSTERS, n_init=10, max_iter=3000)\n\ndf = df.astype({'feature_0': np.float32})\ndf_feats = np.copy(df[FEATURES_LIST].to_numpy(), order='C')\nclusterer.fit(df_feats)\ny_clusters = clusterer.predict(df_feats)\n#silhouette_score(df_feats, y_clusters.ravel()) # Too slow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full = pd.concat([df[FEATURES_LIST+['date', 'resp']], pd.DataFrame(y_clusters, columns=['cluster'], index=df.index)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some visualizations "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#fig = plt.figure(figsize = (15, 10))\nfig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Date', fontsize=18)\nax.set_ylabel('Number of instances in cluster', fontsize=18)\nax.set_title('Repartition of clusters along time', fontsize=18)\n\ncolors = ['red', 'blue', 'orange', 'brown', 'black']\n\nfor cluster_indice in range(NB_CLUSTERS):\n    df_cluster = df_full[df_full.cluster == cluster_indice].groupby(by='date')['date'].count()\n    df_cluster.rename(f'Cluster {cluster_indice}', inplace=True)\n    #ax = fig.add_subplot(111)\n\n    df_cluster.groupby(pd.cut(df_cluster.index, np.arange(-1,500,100))).sum().plot(kind='bar', position=cluster_indice, label=f'{cluster_indice}', color=colors[cluster_indice], width=0.1)\n    \nplt.legend(loc=\"upper right\");","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#df_full['resp_bins'] = pd.cut(df_full['resp'], bins=[-0.25, -0.2, -0.15, -0.1, -0.0505, -0.000569, 0.0493, 0.0992, 0.149])\ndf_full['resp_bins'] = pd.cut(df_full['resp'], bins=50)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#fig = plt.figure(figsize = (15, 10))\nfig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Date', fontsize=18)\nax.set_ylabel('Number of instances in cluster', fontsize=18)\nax.set_title('Repartition of clusters along resp interval', fontsize=18)\n\ncolors = ['red', 'blue', 'orange', 'brown', 'black']\n\nfor cluster_indice in range(NB_CLUSTERS):\n    df_cluster = df_full[df_full.cluster == cluster_indice].groupby(by='resp_bins')['resp_bins'].count()\n    df_cluster.rename(f'Cluster {cluster_indice}', inplace=True)\n    #ax = fig.add_subplot(111)\n\n    df_cluster.plot(kind='bar', position=cluster_indice, label=f'{cluster_indice}', color=colors[cluster_indice], width=0.1)\n    \nplt.legend(loc=\"upper right\");","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Cluster', fontsize=18)\nax.set_ylabel('Number of values in cluster', fontsize=18)\nax.set_title('Number of values by cluster', fontsize=18)\n\ndf_full.groupby(by='cluster')['resp'].count().plot.bar(figsize=(15,5), ax=ax, color=colors);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\n#ax = axes.ravel()\n#fig.tight_layout(pad=10.0)\n\nax.set_xlabel('Cluster', fontsize=18)\nax.set_ylabel('Mean value of resp in cluster', fontsize=18)\nax.set_title('resp mean by cluster', fontsize=18)\n\ndf_full.groupby(by='cluster')['resp'].mean().plot.bar(figsize=(15,5), ax=ax, color=colors);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}