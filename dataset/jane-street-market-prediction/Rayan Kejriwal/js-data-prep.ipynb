{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T06:44:28.002813Z","iopub.execute_input":"2021-08-21T06:44:28.003177Z","iopub.status.idle":"2021-08-21T06:44:28.021516Z","shell.execute_reply.started":"2021-08-21T06:44:28.003147Z","shell.execute_reply":"2021-08-21T06:44:28.020438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall --y typing\n!pip install nvtx dask_cuda\n!pip install git+https://github.com/NVIDIA/NVTabular.git@4c92dffac4354d816178264bcfcdec722db2ec1c","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:46:04.771607Z","iopub.execute_input":"2021-08-20T08:46:04.772022Z","iopub.status.idle":"2021-08-20T08:46:50.675724Z","shell.execute_reply.started":"2021-08-20T08:46:04.771988Z","shell.execute_reply":"2021-08-20T08:46:50.674764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom time import time\nimport re\nimport glob\nimport warnings\n# import cudf\nimport gc\n\n# tools for data preproc/loading\nimport torch\n# import rmm\n# import nvtabular as nvt\n# from nvtabular.ops import Normalize,  Categorify,  LogOp, FillMissing, Clip, get_embedding_sizes\n# from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n# from nvtabular.utils import device_mem_size, get_rmm_size\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# tools for training\nfrom fastai.basics import Learner\n\nfrom fastai.tabular.all import *\nfrom fastai.tabular.model import TabularModel\nfrom fastai.tabular.data import TabularDataLoaders\nfrom fastai.metrics import accuracy\nfrom fastai.callback.progress import ProgressCallback\nfrom collections import defaultdict\nfrom numba import njit\nfrom scipy import stats\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom kmodes import kmodes\nfrom sklearn.impute import KNNImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.linear_model import LinearRegression\n\n# import dask\n# import dask.dataframe as dd\nimport pandas as pd\nimport numpy as np\ngc.collect()\n\n  ################################################################################################################\n\n# class CFG:\n#     TRAIN_SIZE = 0.2\n#     MIN_WEIGHT = 0\n#     NROWS = None\n#     FILL_NA = -999\n    \n# # -75% of time space took by train.csv so we can train faster models\n# # and avoid RAM errors\n\n# features_columns = [\"feature_%d\" % i for i in range(130)]\n# columns_dtypes = {}\n# for column in features_columns:\n#     columns_dtypes[column] = \"float16\"\n# columns_dtypes[\"resp_1\"] = \"float16\"\n# columns_dtypes[\"resp_2\"] = \"float16\"\n# columns_dtypes[\"resp_3\"] = \"float16\"\n# columns_dtypes[\"resp_4\"] = \"float16\"\n# columns_dtypes[\"resp\"] = \"float16\"\n\n# print(\"Loading dataset...\")\n# dataset = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/train.csv\", delimiter=\",\", nrows=CFG.NROWS, dtype=columns_dtypes)\n# dataset = dataset[dataset.weight > CFG.MIN_WEIGHT]\n# print(\"Done!\")\n\n# print(\"Splitting train/test dataset...\")\n# train_number_items = int(dataset.shape[0] * CFG.TRAIN_SIZE)\n# train = dataset[:train_number_items]\n# test = dataset[train_number_items + 1:]\n# print(\"Done!\")\n\n# print(\"Filling NaN values...\")\n# train = train.fillna(CFG.FILL_NA)\n# test = test.fillna(CFG.FILL_NA)\n# print(\"Done.\")\n\n# print(\"Preparing X and y...\")\n# X_train = train[features_columns].to_numpy()\n# X_test = test[features_columns].to_numpy()\n# y_train = np.where(train[\"resp\"] > 0, 1, 0)\n# y_test = np.where(test[\"resp\"] > 0, 1, 0)\n# d_train = train[\"date\"].to_numpy()\n# d_test = test[\"date\"].to_numpy()\n# w_train = train[\"weight\"].to_numpy()\n# w_test = test[\"weight\"].to_numpy()\n# r_train = train[\"resp\"].to_numpy()\n# r_test = test[\"resp\"].to_numpy()\n# resp_train = train[[\"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]].to_numpy()\n# resp_test = test[[\"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]].to_numpy()\n\n# resp_label_train = np.where(resp_train > 0, 1, 0)\n# resp_label_test = np.where(resp_test > 0, 1, 0)\n\n# print(\"Done!\")\n\n# print(\"Deleting unused variables...\")\n# del dataset\n# del train\n# del test\n# print(\"Done!\")\n\n# print(\"Train/test sizes: %d/%d\" % (len(X_train), len(X_test)))","metadata":{"execution":{"iopub.status.busy":"2021-08-21T07:23:05.442165Z","iopub.execute_input":"2021-08-21T07:23:05.442751Z","iopub.status.idle":"2021-08-21T07:23:09.187204Z","shell.execute_reply.started":"2021-08-21T07:23:05.442715Z","shell.execute_reply":"2021-08-21T07:23:09.185988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js=pd.read_csv(\"../input/jane-street-market-prediction/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-21T07:23:12.523736Z","iopub.execute_input":"2021-08-21T07:23:12.524276Z","iopub.status.idle":"2021-08-21T07:25:21.791508Z","shell.execute_reply.started":"2021-08-21T07:23:12.524241Z","shell.execute_reply":"2021-08-21T07:25:21.790566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-21T07:26:49.385882Z","iopub.execute_input":"2021-08-21T07:26:49.386441Z","iopub.status.idle":"2021-08-21T07:26:49.394097Z","shell.execute_reply.started":"2021-08-21T07:26:49.386397Z","shell.execute_reply":"2021-08-21T07:26:49.392972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4','ts_id']","metadata":{"execution":{"iopub.status.busy":"2021-08-21T07:47:42.628034Z","iopub.execute_input":"2021-08-21T07:47:42.628708Z","iopub.status.idle":"2021-08-21T07:47:42.634715Z","shell.execute_reply.started":"2021-08-21T07:47:42.628663Z","shell.execute_reply":"2021-08-21T07:47:42.633543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js=js[js.weight>0]\njs=js[js.date>85]\njs['action'] = (  (js['resp_1'] > 0 ) & (js['resp_2'] > 0 ) & (js['resp_3'] > 0 ) & (js['resp_4'] > 0 ) &  (js['resp'] > 0 )   ).astype('int')\njs.drop(drop_cols, inplace=True, axis=1)\njs.reset_index(inplace=True)\njs.to_feather('js')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T07:47:43.549275Z","iopub.execute_input":"2021-08-21T07:47:43.549846Z","iopub.status.idle":"2021-08-21T07:47:53.151784Z","shell.execute_reply.started":"2021-08-21T07:47:43.549799Z","shell.execute_reply":"2021-08-21T07:47:53.149734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js.drop(['index'], inplace=True, axis=1)\njs.to_feather('js')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T07:49:32.353729Z","iopub.execute_input":"2021-08-21T07:49:32.354052Z","iopub.status.idle":"2021-08-21T07:49:36.935992Z","shell.execute_reply.started":"2021-08-21T07:49:32.354024Z","shell.execute_reply":"2021-08-21T07:49:36.934902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\npath = pathlib.Path(\"/kaggle/input/jane-street-market-prediction\")","metadata":{"execution":{"iopub.status.busy":"2021-08-20T09:14:37.269901Z","iopub.execute_input":"2021-08-20T09:14:37.270359Z","iopub.status.idle":"2021-08-20T09:14:37.277264Z","shell.execute_reply.started":"2021-08-20T09:14:37.270322Z","shell.execute_reply":"2021-08-20T09:14:37.275614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T09:14:37.279867Z","iopub.execute_input":"2021-08-20T09:14:37.280431Z","iopub.status.idle":"2021-08-20T09:14:37.324497Z","shell.execute_reply.started":"2021-08-20T09:14:37.280378Z","shell.execute_reply":"2021-08-20T09:14:37.322494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic1 = dic.set_index('Unnamed: 0').to_dict()\ndic.drop(dic.index,inplace=True)\ndic1=dic1['0']\ntrain = pd.read_csv(path/\"train.csv\",dtype=dic1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DATA_DIR='/kaggle/working/' ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths = ['../input/train-and-valid/train']\nvalid_paths = ['../input/train-and-valid/valid']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_parquet('../input/train-and-valid/train')\nvalid = pd.read_parquet('../input/train-and-valid/valid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\nfeats=[f'feature_{i}' for i in range(130)]\ncon_names = ['weight'] + resp_cols + feats \ncat_names = [x for x in train.columns if '_na' in x]\ncat_names= ['date'] + cat_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=train[train.weight>0]\ntrain=train[train.date>85]\nvalid=valid[valid.weight>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.concat([train,valid])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('index',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-20T09:14:37.326285Z","iopub.execute_input":"2021-08-20T09:14:37.326754Z","iopub.status.idle":"2021-08-20T09:14:37.340965Z","shell.execute_reply.started":"2021-08-20T09:14:37.326716Z","shell.execute_reply":"2021-08-20T09:14:37.339582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"js.to_feather('js') ","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:57:35.532377Z","iopub.execute_input":"2021-08-20T08:57:35.532776Z","iopub.status.idle":"2021-08-20T08:57:39.092556Z","shell.execute_reply.started":"2021-08-20T08:57:35.532743Z","shell.execute_reply":"2021-08-20T08:57:39.091234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,4):\n    print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tnacol = train.columns[train.isnull().any()]\ntna = train[tnacol].isnull()\nnat={}\nfor c in tnacol:\n    nat[c]= c+\"_na\"\ntna.rename(mapper=nat,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vnacol = valid.columns[valid.isnull().any()]\nvna = valid[vnacol].isnull()\nnav={}\nfor c in vnacol:\n    nav[c]= c+\"_na\"\nvna.rename(mapper=nav,inplace=True)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fn to reduce memory usage significantly\ndef reduce_memory_usage(df):\n    \n    start_memory = df.memory_usage().sum() / 1024**2\n    print(f\"Memory usage of dataframe is {start_memory} MB\")\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    pass\n        else:\n            df[col] = df[col].astype('category')\n    \n    end_memory = df.memory_usage().sum() / 1024**2\n    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# valid = valid.astype({c: np.float32 for c in valid.select_dtypes(include='float64').columns}) #limit memory use\n# valid['action'] =  (  (valid['resp_1'] > 0 ) & (valid['resp_2'] > 0 ) & (valid['resp_3'] > 0 ) & (valid['resp_4'] > 0 ) &  (valid['resp'] > 0 )   ) & (valid['weight'] > 0).astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n# train['action'] =  (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   )& (train['weight'] > 0).astype('int')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_metric(dataset):\n    p = []\n    for d in dataset.date.unique():\n        p.append(np.sum(dataset[dataset.date==d].weight*dataset[dataset.date==d].resp*dataset[dataset.date==d].action))\n    t = (np.sum(p)*np.sqrt(250))/(np.sqrt(np.sum(p**2))*len(dataset.date.unique()))\n    u = min(max(t,0),6)*np.sum(p)\n    return u\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef fillna_npwhere_njit(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t=t.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = [i for i in range(130)]\nl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"di","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"di = {}\nfor i in range(130):\n    di[i]=f'feature_{i}'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.rename(columns = di, inplace = True)\n# valid.rename(columns = di, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.feature_77","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef KNNimp(dataset):\n    imputer = KNNImputer()\n    dataset = imputer.fit_transform(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fillm(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n#Fill Na using numpy numba : fillna_npwhere_njit\n@njit(parallel=True, fastmath=True)\ndef cluster_missing(dataset):\n    array = dataset.to_numpy()\n#     dataset.interpolate(method ='quadratic', axis=0, inplace=True)\n    d=dataset.isna().sum().sort_values(ascending=False).to_dict()\n    g=defaultdict(list)\n    for k in d.keys():\n        if (d[k]!=0):\n            g[d[k]].append(k)\n            p=d[k]\n        else:\n            break;\n    return g\n#     for k in g.keys():\n#         imp = IterativeImputer(sample_posterior=True)\n#         dataset[g[k]]=imp.fit_transform(dataset[g[k]])\n#         gc.collect()\n#         gc.collect()\n#     print(dataset.isnull().sum().sum())\n# def cluster_tags(dataset):\n    \n\ndef spearman(df):\n    m = df.corr()\n    return m;\n#     sx,sy=np.where(s>0.5)\n#     for  i in range(len(sx)):\n#         if(sx[i]>sy[i]):\n\n# Using kmeans to cluster the features based on their correlation\ncorr_feat_mtx = spearman(t).to_numpy()\nkmeans = KMeans(n_clusters = 20, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ncorr_feat_labels = kmeans.fit_predict(corr_feat_mtx)\n\n# Preparing a dataframe to collect some cluster stats\n# corr_feat_clust_df = pd.DataFrame(np.c_[feat_names, corr_feat_labels])\n# corr_feat_clust_df.columns = [\"feature\", \"cluster\"]\n# corr_feat_clust_df['feat_list'] = corr_feat_clust_df.groupby([\"cluster\"]).transform(lambda x: ', '.join(x))\n# corr_feat_clust_df = corr_feat_clust_df.groupby([\"cluster\", \"feat_list\"]).size().reset_index(name = 'feat_count')\n# corr_feat_clust_df\n    \n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag1.isna().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag1=tag1.astype('float')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x2=corr_feat_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install missingno","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrclus = defaultdict(list)\nfor i in range(130):\n    f='feature_{}'.format(i)\n    corrclus[corr_feat_labels[i]].append(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrclus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clustering Using Tags, Missing, Distribution, Pearson Correlation \ng = defaultdict(list)\ng['a'] = [1,2,9,10,15,16,42,43,45,46,48,49]\ng['b'] = [3,4,5,6,7,8,11,12,14]\ng['c'] = [17,18,19,20,21,22,23,24,25,26]\ng['d'] = [27,28,29,30,31,32,33,34,35,36,37,39,40]\ng['e'] = [41,44,51,52,53,55,56,57,58,59,60,61]\ng['f'] = [42,43,45]\ng['g'] = [46,48,49,50,86,87,88]\ng['h'] = [62,63,65,66]\ng['i'] = [64,67,68]\ng['j'] = [65,66]\ng['k'] = [69,70,71]\ng['l'] = [72,78,84,90,93,96,99,102,105,108,114]\ng['m'] = [73,74,75,76,78,79,80,81,82]\ng['n'] = [120,122,124,126,128]\ng['o'] = [121,123,125,127,129]\ng['p'] = [89,92,98,101,104,109,113,116]\ng['q'] = [95,107,119]\ng['r'] = [108,110,111,112,115,117,118]\ng['s'] = [92,93,94,99,100,105]\ng['t'] = [85,91,97,100,103,106]\noutf = [13,38,47,54,77,83]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(outf,axis=1,inplace=True)\nvalid.drop(outf,axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = [None]*130\nfor x in g.keys():\n    for i in g[x]:\n        lm[i]=x\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --no-cache-dir --upgrade autoimpute","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install autoimpute","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from autoimpute.analysis import MiLinearRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @njit(parallel=True, fastmath=True)\ndef wt(dataset):\n    return dataset.corr().to_numpy()\ndef fillm(dataset):\n    for k in g.keys():\n        lr = LinearRegression()\n        imp = IterativeImputer(estimator=lr, verbose=2, max_iter=50, tol=1e-10, imputation_order='ascending')\n        if (dataset=='valid') : imp.initial_startegy=train[g[k]].mean()\n        dataset[g[k]]=imp.fit_transform(dataset[g[k]])\n        gc.collect()\n        gc.collect()\n    print(dataset.isnull().sum().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fillm(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[g['a']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GMM Clustering\ndef gm(t):\n    from sklearn.mixture import GaussianMixture\n    gmm = GaussianMixture(n_components=4)\n    gmm.fit(t)\n\n    #predictions from gmm\n    labels = gmm.predict(t)\n    frame = pd.DataFrame(t)\n    frame['cluster'] = labels\n    frame.columns = ['Weight', 'Height', 'cluster']\n\n    color=['blue','green','cyan', 'black']\n    for k in range(0,4):\n        t = frame[frame[\"cluster\"]==k]\n        plt.scatter(t[\"Weight\"],t[\"Height\"],c=color[k])\n    plt.show()\n\n\n            \n    \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_w0 = train[train.weight==0]\ntrain = train[train.weight>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fillm(train)\nreduce_memory_usage(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_w0 = valid[valid.weight==0]\nvalid = valid[valid.weight>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fillm(valid)\nreduce_memory_usage(valid)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fillm(train)\nfillm(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"procs = [Categorify, FillMissing, Normalize]\ny_names = 'salary'\ny_block = CategoryBlock()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=con_names,\n                   y_names=y_names, y_block=y_block, splits=splits)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.date==360]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = train[1683632:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=train[:1683632]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlen(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.interpolate(method ='quadratic', axis=0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"av","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g479=['feature_28','feature_27','feature_18','feature_17']\ng476=['feature_102','feature_7','feature_78','feature_72','feature_84','feature_108','feature_96','feature_90','feature_114','feature_8'] \ng99=['feature_121','feature_120','feature_55']\ng74=['feature_21','feature_32','feature_31','feature_22']\ng72=['feature_92','feature_104','feature_80','feature_98','feature_116','feature_86','feature_74','feature_110','feature_11','feature_12']\ng71=['feature_121','feature_120']\ng48 = ['feature_55']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing GMM","metadata":{}},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   ).astype('int')\nvalid_y =  (  (valid['resp_1'] > 0 ) & (valid['resp_2'] > 0 ) & (valid['resp_3'] > 0 ) & (valid['resp_4'] > 0 ) &  (valid['resp'] > 0 )   ).astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmm = GaussianMixture(n_components=2,max_iter=200).fit(train)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm_preds=gmm.predict(valid)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(gm_preds[gm_preds==valid_y])/len(gm_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr = [1]*len(gm_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm_preds = abs(gm_preds - arr) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gm_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf = pd.concat([train,valid])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(traindf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid.interpolate(method ='quadratic', axis=0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"av=valid.isna().sum().sort_values(ascending=False).to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"av","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features = cat_names >> Categorify()\ncon_features = con_names >> Normalize()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = cat_features+con_features+['action']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[con_names]=train[con_names].astype('float32')\nvalid[con_names]=valid[con_names].astype('float32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"workflow = nvt.Workflow(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = nvt.Dataset(train)\nvalid_dataset = nvt.Dataset(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nworkflow.fit(train_dataset)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DATA_DIR='./'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_train_dir = os.path.join(OUTPUT_DATA_DIR, 'train/')\noutput_valid_dir = os.path.join(OUTPUT_DATA_DIR, 'valid/')\n! mkdir -p $output_train_dir\n! mkdir -p $output_valid_dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nworkflow.transform(train_dataset).to_parquet(output_path=output_train_dir,\n                                             shuffle=nvt.io.Shuffle.PER_PARTITION, \n                                             out_files_per_proc=5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nworkflow.transform(valid_dataset).to_parquet(output_path=output_valid_dir, out_files_per_proc=5)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)+len(valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = int(os.environ.get('BATCH_SIZE', 1024*16))           # Batch-size for training neural networks\nPARTS_PER_CHUNK = int(os.environ.get('PARTS_PER_CHUNK', 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_itrs = TorchAsyncItr(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    cats=cat_names,\n    conts=con_names,\n    labels=['action'],\n    parts_per_chunk=PARTS_PER_CHUNK\n)\nvalid_data_itrs = TorchAsyncItr(\n    valid_dataset,\n    batch_size=BATCH_SIZE,\n    cats=cat_names,\n    conts=con_names,\n    labels=['action'],\n    parts_per_chunk=PARTS_PER_CHUNK\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_col(batch):\n    return (batch[0], batch[1], batch[2].long())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DLDataLoader(train_data_itrs, collate_fn=gen_col, batch_size=None, pin_memory=False, num_workers=0)\nvalid_dataloader = DLDataLoader(valid_data_itrs, collate_fn=gen_col, batch_size=None, pin_memory=False, num_workers=0)\ndatabunch = TabularDataLoaders(train_dataloader, valid_dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = list(get_embedding_sizes(workflow).values())\nembeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TabularModel(emb_szs=embeddings, n_cont=len(con_names), out_sz=2, layers=[512, 256]).cuda()\nlearn =  Learner(databunch, model, loss_func = torch.nn.CrossEntropyLoss(), metrics=[accuracy], cbs=ProgressCallback())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.callback.schedule import fit_one_cycle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.tabular.all import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.lr_find()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1.32e-2\nepochs = 5\nlearn.fit(epochs, learning_rate)\nfit_one_cycle(learn, n_epoch=epochs, lr_max=learning_rate)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.lr_find()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_mat = train[features].corr('spearman')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select_f = corr_mat[abs(corr_mat)>=0.5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"miss_X = train[miss_idx]\nmiss_mat = miss_X.corr()\nmiss_f = miss_mat[abs(miss_mat)>=0.5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"miss_f = pd.read_csv(\"../input/janestreet/miss_f.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\n\n\ndic.to_csv('dic.csv')\n\ndef create_download_link(title = \"Download CSV file\", filename = \"dic.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='dic.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Below we define a neural net with 2 hidden layers to predict missing values","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = KNNImputer(weights=wt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[features].isna().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class missnet():\n    def __init__(self,x,y):\n        self.y = y\n        self.x = x\n        self.data = x.merge(y,left_index=True,right_index=True)\n        \n        \n    def forward(self):\n        knn_imputer = impute.KNNImputer()\n        knn_imputer.fit_transform(self.x)\n        train_y = self.y[self.y!=np.nan]\n        predict_y = self.\n        \n        \n        \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(train.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.ts_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.set_index(train.ts_id,inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/jane-street-market-prediction/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:47:34.814861Z","iopub.execute_input":"2021-08-19T16:47:34.815264Z","iopub.status.idle":"2021-08-19T16:49:56.436883Z","shell.execute_reply.started":"2021-08-19T16:47:34.815225Z","shell.execute_reply":"2021-08-19T16:49:56.435824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_hdf(path_or_buf=\"./data_hdf5_format\",key=\"data_hdf5_format\")","metadata":{"execution":{"iopub.status.busy":"2021-08-19T17:01:23.479211Z","iopub.execute_input":"2021-08-19T17:01:23.481509Z","iopub.status.idle":"2021-08-19T17:01:34.332675Z","shell.execute_reply.started":"2021-08-19T17:01:23.481467Z","shell.execute_reply":"2021-08-19T17:01:34.331608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=train.isna().sum().sort_values(ascending=False).to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.feature_12[:72]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for y in miss_X:\n    \"X_{}\".format(y) = miss_f[y]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"procs = [Categorify, FillMissing, Normalize]\nsplits = (L(np.arange(1000000), use_list=True),\n          L(np.arange(1000000, 1981287), use_list=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to = TabularPandas(train, procs, cat_col, cont_col, y_names=\"action\", splits=splits)\ndls = to.dataloaders(bs=16384)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}