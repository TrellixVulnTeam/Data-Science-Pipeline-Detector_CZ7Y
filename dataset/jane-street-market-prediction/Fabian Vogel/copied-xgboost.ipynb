{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 500)\n\n\n# Standard plotly imports\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\nimport os\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost version:\", xgb.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# functions from: https://www.kaggle.com/kabure/baseline-fraud-detection-eda-interactive-views\n\ndef resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary\n\ndef plot_distribution(df, var_select=None, title=None, bins=1.0): \n    # Calculate the correlation coefficient between the new variable and the target\n    tmp_fraud = df[df['isFraud'] == 1]\n    tmp_no_fraud = df[df['isFraud'] == 0]    \n    corr = df['isFraud'].corr(df[var_select])\n    corr = np.round(corr,3)\n    tmp1 = tmp_fraud[var_select].dropna()\n    tmp2 = tmp_no_fraud[var_select].dropna()\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['Fraud', 'No Fraud']\n    colors = ['seagreen','indianred', ]\n\n    fig = ff.create_distplot(hist_data,\n                             group_labels,\n                             colors = colors, \n                             show_hist = True,\n                             curve_type='kde', \n                             bin_size = bins\n                            )\n    \n    fig['layout'].update(title = title+' '+'(corr target ='+ str(corr)+')')\n\n    iplot(fig, filename = 'Density plot')\n    \ndef plot_dist_churn(df, col, binary=None):\n    tmp_churn = df[df[binary] == 1]\n    tmp_no_churn = df[df[binary] == 0]\n    tmp_attr = round(tmp_churn[col].value_counts().sort_index() / df[col].value_counts().sort_index(),2)*100\n    print(f'Distribution of {col}: ')\n    trace1 = go.Bar(\n        x=tmp_churn[col].value_counts().sort_index().index,\n        y=tmp_churn[col].value_counts().sort_index().values, \n        name='Fraud',opacity = 0.8, marker=dict(\n            color='seagreen',\n            line=dict(color='#000000',width=1)))\n\n    trace2 = go.Bar(\n        x=tmp_no_churn[col].value_counts().sort_index().index,\n        y=tmp_no_churn[col].value_counts().sort_index().values,\n        name='No Fraud', opacity = 0.8, \n        marker=dict(\n            color='indianred',\n            line=dict(color='#000000',\n                      width=1)\n        )\n    )\n\n    trace3 =  go.Scatter(   \n        x=tmp_attr.sort_index().index,\n        y=tmp_attr.sort_index().values,\n        yaxis = 'y2', \n        name='% Fraud', opacity = 0.6, \n        marker=dict(\n            color='black',\n            line=dict(color='#000000',\n                      width=2 )\n        )\n    )\n    \n    layout = dict(title =  f'Distribution of {str(col)} feature by %Fraud',\n              xaxis=dict(type='category'), \n              yaxis=dict(title= 'Count'), \n              yaxis2=dict(range= [0, 15], \n                          overlaying= 'y', \n                          anchor= 'x', \n                          side= 'right',\n                          zeroline=False,\n                          showgrid= False, \n                          title= 'Percentual Fraud Transactions'\n                         ))\n\n    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n    iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('# File sizes')\ntotal_size = 0\nstart_path = '../input/jane-street-market-prediction'  # To get size of current directory\nfor path, dirs, files in os.walk(start_path):\n    for f in files:\n        fp = os.path.join(path, f)\n        total_size += os.path.getsize(fp)\nprint(\"Directory size: \" + str(round(total_size/ 1000000, 2)) + 'MB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\nfeatures = pd.read_csv('../input/jane-street-market-prediction/features.csv')\nexample_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nprint (\"Data is loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing/total_cells) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Is the data balanced or not?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I have taked this cell from https://www.kaggle.com/jazivxt/the-market-is-reactive\n# And https://www.kaggle.com/drcapa/jane-street-market-prediction-starter-xgb\n\ntrain = train[train['weight'] != 0]\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\ny_train = train.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train['action'].value_counts().index\ny = train['action'].value_counts().values\n\ntrace2 = go.Bar(\n     x=x ,\n     y=y,\n     marker=dict(\n         color=y,\n         colorscale = 'Viridis',\n         reversescale = True\n     ),\n     name=\"Imbalance\",    \n )\nlayout = dict(\n     title=\"Data imbalance - action\",\n     #width = 900, height = 500,\n     xaxis=go.layout.XAxis(\n     automargin=True),\n     yaxis=dict(\n         showgrid=False,\n         showline=False,\n         showticklabels=True,\n #         domain=[0, 0.85],\n     ), \n)\nfig1 = go.Figure(data=[trace2], layout=layout)\niplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, x, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training\n##### To activate GPU usage, simply use tree_method='gpu_hist' (took me an hour to figure out, I wish XGBoost documentation was clearer about that)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# The training part taked from here https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s\n\nclf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=8,\n    learning_rate=0.01,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n    X_test.fillna(-999)\n    y_preds = clf.predict(X_test)\n    sample_prediction_df.action = y_preds\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}