{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jane Street - EDA focused on “features”\n\nGiven dataset contains an anonymized set of features, feature_{0...129}, representing real stock market data.\n\nBecause of the large number of variables, we might look at selecting variable or compressing them with PCA and so on. In order to do that, I got be curious to see what kind of relationship there is between the variables, so we did the analysis."},{"metadata":{},"cell_type":"markdown","source":"## Contents\n\n1. [Loading and overviewing dataset](#1)\n1. [Analysis with similarity matrix](#2)\n1. [Analysis with clustering method](#3)\n1. [Compressing](#4)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# <div class=\"alert alert-block alert-success\">Loading and overviewing dataset</div>"},{"metadata":{},"cell_type":"markdown","source":"### Load library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.decomposition import PCA\nimport umap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls ../input/jane-street-market-prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/jane-street-market-prediction/train.csv\")\nfeature = pd.read_csv(\"../input/jane-street-market-prediction/features.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train.csv contains historical data and returns."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"feature.csv includes metadata pertaining to the anonymized features."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocess\n\nTo analysis, I'll try some preprocess for dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_col = feature[\"feature\"]\ntag_col = [col for col in feature.columns if col not in [\"feature\"]]\nfeature = feature.rename(index=feature[\"feature\"])[tag_col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Analysis with similarity matrix</div>\n\nI create two similarity matrix and visualized as heatmap.\n\n- cosine similarity matrix for feature.csv\n\n- correlation matrix for train.csv"},{"metadata":{},"cell_type":"markdown","source":"## Cosine similarity matrix for feature.csv\n\nFirst, I'll check features' similarity by feature.csv."},{"metadata":{},"cell_type":"markdown","source":"### Calculate cosine similarity matrix\n\nI regarded the dataframe as a vector representation of the features by tag_{0. .28}. So I create cosine similarity matrix for each feature pairs."},{"metadata":{"trusted":true},"cell_type":"code","source":"cos_matrix = cosine_similarity(feature, feature)\ncos_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize heatmap\n\nNext, I'll visualize the matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 15))\ng = sns.heatmap(data=cos_matrix)\ng.set_title(\"Cosine similarity matrix of features' metadata\", fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you look at the heat map, you can see that there are highly similar features each other and not ones. For example, features{0..40} are more similar to each other than to features{0..40} and features{41..54}."},{"metadata":{},"cell_type":"markdown","source":"## Euqlid distance matrix for feature.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"distance_matrix = pairwise_distances(feature, feature, metric='euclidean')\ndistance_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 15))\ng = sns.heatmap(data=distance_matrix)\ng.set_title(\"Euclid distance matrix of features' metadata\", fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation matrix for train.csv\n\nI'll also check features' similarity by train.csv."},{"metadata":{},"cell_type":"markdown","source":"### Calculate correlation matrix\n\nBy train.csv's data, we can calculate correlation matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature = train[feature_col]\ntrain_feature_corr = train_feature.corr()\ntrain_feature_corr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize heatmap\n\nAs in the previous example, we can visualize the matrix with heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 15))\ng = sns.heatmap(data=train_feature_corr)\ng.set_title(\"Correlation matrix of features\", fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The brighter the color, the higher the correlation is. As you can see, there are some correlated features. It's hard to see, but you can see some highly correlated blocks.  For example, features{84..120} are more similar to each other than to features{84..120} and features{18..26}."},{"metadata":{},"cell_type":"markdown","source":"## Comparison of heatmaps \n\nLet's compare the previous two heat maps."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15,6), gridspec_kw=dict(wspace=0.1, hspace=0.6))\nfig.suptitle(\"Comparison of the heatmaps\", fontsize=15)\n\ng_1 = sns.heatmap(data=cos_matrix, ax=axes[0])\ng_1.set_title(\"Cosine similarity matrix of features' metadata\")\n\ng_2 = sns.heatmap(data=distance_matrix, ax=axes[1])\ng_2.set_title(\"Euqlid distance matrix of features\")\n\ng_3 = sns.heatmap(data=train_feature_corr, ax=axes[2])\ng_3.set_title(\"Correlation matrix of features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is interesting that we can see that there are highly similar blocks floating on the diagonal elements on two heatmaps and the pattern is similar. Thus, it can be said that fetures with high similarity in terms of metadata tend to have also high correlation coefficients as well."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Analysis with clustering method</div>\n\nI also check that there are some similar groups of features by clustering method. I assumed that features are spatially similar, and estimated their labels by kmeans. And I droped features into two dimensions with Umap, and I checked that the feature of the same label is gathered. For data, I use feature.csv."},{"metadata":{},"cell_type":"markdown","source":"I estimate labels for each feature by kmeans. Note that I specified the n_clusters=3 because I visualized the data with Umap beforehand and I knew that it is divided into three clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=3, random_state=0).fit(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll visualize the data with Umap"},{"metadata":{"trusted":true},"cell_type":"code","source":"reducer = umap.UMAP()\nembedding = reducer.fit_transform(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=go.Scatter(x=embedding[:, 0],\n                                y=embedding[:, 1],\n                                mode='markers',\n                                marker_color=kmeans.labels_))\nfig.update_layout(title='features with kmeans labels')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I could roughly divide features into three groups. So we can say that there are three similar groups of features."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature[\"kmeans_label\"] = kmeans.labels_\nfeature[[\"kmeans_label\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Compressing</div>\n\nI'll try PCA and see how well the trainset can be represented by the variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA().fit(train[feature_col].dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/kushal1506/deciding-n-components-in-pca\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 131, step=1)\ny = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 130, step=10)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found that with roughly 30 variables, 95% can be represented."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}