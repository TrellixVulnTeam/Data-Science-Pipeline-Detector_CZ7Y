{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1 - MLP\nbatch_size = 4096\nhidden_units = [384, 896, 896, 394]\ndropout_rates = [0.10143786981358652, 0.19720339053599725, 0.2703017847244654, 0.23148340929571917, 0.2357768967777311]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3 \n\ndef create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    init = tf.constant_initializer(array)\n    l1 = tf.keras.layers.Dense(units=len(features),kernel_initializer=init)(inp)\n    x = tf.keras.layers.BatchNormalization()(l1)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LSTM parameters\n# LSTM parameters\nlookback = 10\nbatch_size = 4096\nhead_hidden_units = [256]\nlstm_units = [64]\ntail_hidden_units = [512, 394]\ndropout_rates = [0.20143786981358652, 0.19720339053599725, 0.2123435323 ,0.23148340929571917, 0.2457768967777311]\n\n\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3 \n#Model2 - LSTM\ndef create_lstm(lookback, num_columns, num_labels, head_hidden_units,lstm_units,tail_hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    assert (len(dropout_rates)==1 + len(head_hidden_units) + len(lstm_units)+ len(tail_hidden_units)), \"number of dropout_rates is not equal to number of layers!\"  \n    \n    inp = tf.keras.layers.Input(shape = (lookback,num_columns,))\n    init = tf.constant_initializer(array)\n    l1 = tf.keras.layers.Dense(units=len(features),kernel_initializer=init)(inp)\n    x = tf.keras.layers.BatchNormalization()(l1)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    \n    # implement hidden_layers before LSTMs\n    for i in range(len(head_hidden_units)): \n        x = tf.keras.layers.Dense(head_hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)\n    # implement LSTMs\n    for i in range(len(lstm_units)):\n        x = tf.compat.v1.keras.layers.CuDNNLSTM(lstm_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1+len(head_hidden_units)])(x) \n        \n    # implement hidden_layers after LSTMs\n    for i in range(len(tail_hidden_units)): \n        x = tf.keras.layers.Dense(tail_hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1+len(head_hidden_units)+len(lstm_units)])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_model_clf = xgb.XGBClassifier(\n    n_estimators=400,\n    max_depth=7,\n    eta=0.5, # learning_rate\n    missing=None,\n    random_state=42,\n    #tree_method='gpu_hist',\n    subsample=0.8,\n    colsample_bytree=1,\n    #sampling_method='gradient_based',\n    #eval_metric='logloss',\n    verbosity=2   # info\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nmeta_model_clf = pickle.load(open(\"/kaggle/input/xgboost-models/pima.pickle.dat\", \"rb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = np.zeros((113,113))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mlp = create_mlp(len(features), 1, hidden_units,dropout_rates, label_smoothing, learning_rate)\nmodel_mlp.load_weights(\"/kaggle/input/testing/JSModelCV_MLP_4.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodel_lstm = create_lstm(1, len(features), 1, head_hidden_units,lstm_units,tail_hidden_units, dropout_rates, label_smoothing, learning_rate) \nmodel_lstm.load_weights(f'/kaggle/input/testing/JSModelCV_LSTM_4.hdf5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = pd.read_csv('/kaggle/input/tabnet-we/Tabnet_weights.csv')\nfeatures = list(weights['Feature'])\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = np.array([ 0.4424  ,  0.4636  , -0.0113  , -0.01884 , -0.0229  , -0.0372  ,\n        0.0384  ,  0.01365 ,  0.2854  ,  0.231   ,  0.0883  ,  0.0631  ,\n        0.1599  ,  0.1171  ,  0.2352  ,  0.2106  ,  0.1144  ,  0.1047  ,\n        0.2717  ,  0.2429  ,  0.18    ,  0.1708  ,  0.2369  ,  0.2208  ,\n        0.2686  ,  0.2443  ,  0.1317  ,  0.1632  ,  0.2964  ,  0.3137  ,\n        0.2184  ,  0.2585  ,  0.298   ,  0.3333  ,  0.3105  ,  0.3418  ,\n        0.01668 ,  0.00395 ,  0.03458 ,  0.04456 ,  0.3408  ,  0.4534  ,\n        0.2683  ,  0.296   ,  0.1874  ,  0.3767  ,  0.4094  ,  0.4922  ,\n        0.514   ,  0.338   ,  0.4001  , -0.012085,  0.3958  ,  0.288   ,\n        0.299   ,  0.3835  ,  0.317   ,  0.316   ,  0.3276  ,  0.546   ,\n        0.5483  ,  0.5146  ,  0.5137  ,  0.3953  ,  0.585   ,  0.5903  ,\n        0.579   ,  0.5806  ,  0.4424  ,  0.276   ,  0.4316  ,  0.01331 ,\n       -0.03613 ,  0.00651 , -0.01566 , -0.03305 , -0.06946 ,  0.01355 ,\n       -0.03162 ,  0.01108 , -0.002892, -0.02783 , -0.03934 ,  0.428   ,\n        0.552   ,  0.4338  ,  0.466   ,  0.5103  ,  0.4521  ,  0.2145  ,\n        0.3757  ,  0.2544  ,  0.2627  ,  0.304   ,  0.2122  ,  0.4304  ,\n        0.5586  ,  0.435   ,  0.4573  ,  0.503   ,  0.4568  ,  0.1692  ,\n        0.371   ,  0.2654  ,  0.267   ,  0.2893  ,  0.2065  ,  0.4268  ,\n        0.49    ,  0.4373  ,  0.4448  ,  0.4778  ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th = 0.5 # 0.502\nf = np.median\n\n\n\nfrom tqdm import tqdm\nimport janestreet\njanestreet.make_env.__called__ = False\nenv = janestreet.make_env()\n\npred_df_list = [] \n\n# speed up___\ntest_df_columns = ['weight'] + features + ['date']\nindex_features = [n for n, col in enumerate(test_df_columns) if col in features]\n\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    \n  \n    if test_df['weight'].values[0] > 0:\n        #test_df = test_df.fillna(0)\n        test_df = test_df.loc[:,test_df_columns]\n    \n        x_tt = test_df[features].fillna(0).values.reshape(1,-1)\n            \n        pred_mlp = model_mlp(x_tt, training=False).numpy()[0][0] \n        pred_lstm = model_mlp(x_tt, training=False).numpy()[0][0] \n        \n        x_tt = np.append(np.append(x_tt, pred_mlp),pred_lstm) \n        pred_xgb = meta_model_clf.predict(x_tt.reshape(1,-1)) \n    \n    else:\n    \n        pred_df['action'].values[0] = 0\n        \n    env.predict(pred_df)\n    pred_df_list.append(list(pred_df['action'])[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsubmission = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['action'] = pred_df_list\nsubmission['action'] = submission['action'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(pred_df_list)):\n    if submission['action'][i] !=0 and submission['action'][i] != 1:\n        print(submission['action'][i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv' , index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}