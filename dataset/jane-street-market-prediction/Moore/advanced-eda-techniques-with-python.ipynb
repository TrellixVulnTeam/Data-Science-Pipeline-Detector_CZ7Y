{"cells":[{"metadata":{"_cell_guid":"e3bc4854-2787-eae1-950d-2742ad3d7db2","_uuid":"d507f816cc74a88c9afefd02cf225d1a7dd6461f"},"cell_type":"markdown","source":"# Advanced EDA techniques WITH PYTHON\n"},{"metadata":{"_cell_guid":"8ca352d7-08aa-36b4-fb2d-3c9854a8d86a","_uuid":"014f5c099a26d9232f9d0d6ca85d5c02b812c98a"},"cell_type":"markdown","source":"What we are doing in this kernel is something like:\n\n1. <b>Understand the problem</b>. We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n2. <b>Univariable study</b>. We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.\n3. <b>Multivariate study</b>. We'll try to understand how the dependent variable and independent variables relate.\n4. <b>Basic cleaning</b>. We'll clean the dataset and handle the missing data, outliers and categorical variables.\n5. <b>Test assumptions</b>. We'll check if our data meets the assumptions required by most multivariate techniques.\n\nNow, it's time to have fun!"},{"metadata":{"_cell_guid":"2df621e0-e03c-7aaa-6e08-40ed1d7dfecc","_execution_state":"idle","_uuid":"d581f6797b9fde1580271358d484df67bf6b14a1","trusted":true},"cell_type":"code","source":"#invite people for the Kaggle party\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d56d5e71-4277-7a74-5306-7d5af4c7f263","_execution_state":"idle","_uuid":"827a72128cd211cf6af16b003e7c09951e3f2b1e","trusted":true},"cell_type":"code","source":"#bring in the six packs\ndf_train = pd.read_csv('../input/jane-street-market-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7a3e43cc-5b75-0b49-1ad2-426d10d7fb42","_uuid":"c984e32d4d10b1e6766c1b79ed8ade9a57529ffb"},"cell_type":"markdown","source":"*'Amazing! If my love calculator is correct, our success probability is 97.834657%. I think we should meet again! Please, keep my number and give me a call if you're free next Friday. See you in a while, crocodile!'*"},{"metadata":{"_cell_guid":"2ea2f896-48a6-db39-0684-6a029d8fda60","_uuid":"d67e5bf6f2c4b6acb617c4cdcee0dc5c3f79d9b8"},"cell_type":"markdown","source":"Until now we just followed our intuition and analysed the variables we thought were important. In spite of our efforts to give an objective character to our analysis, we must say that our starting point was subjective. \n\nAs an engineer, I don't feel comfortable with this approach. All my education was about developing a disciplined mind, able to withstand the winds of subjectivity. There's a reason for that. Try to be subjective in structural engineering and you will see physics making things fall down. It can hurt.\n\nSo, let's overcome inertia and do a more objective analysis."},{"metadata":{"_cell_guid":"06f8d02c-d779-f8fd-7f48-ba3c5166eda8","_uuid":"bf469f1030a8768f73a18e5ad59db43c4241c603"},"cell_type":"markdown","source":"#### Correlation matrix (heatmap style)"},{"metadata":{"_cell_guid":"4eb7a6ef-adf5-6abf-947d-c95afdc477b8","_execution_state":"idle","_uuid":"5dfee22210f5a126ea34ca6475bb4f365d41317b","trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(30, 30))\nsns.heatmap(corrmat, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9ce00498-d5e6-9e35-debc-8d507002d461","_uuid":"726efbb348d1022cabb171f622d7b4e01fe8c778"},"cell_type":"markdown","source":"# Missing data\n\nImportant questions when thinking about missing data:\n\n* How prevalent is the missing data?\n* Is missing data random or does it have a pattern?\n\nThe answer to these questions is important for practical reasons because missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis. Moreover, from a substantive perspective, we need to ensure that the missing data process is not biased and hidding an inconvenient truth."},{"metadata":{"_cell_guid":"ca2f89e7-1c16-c3ae-6fe0-ab4eaf7e52a1","_execution_state":"idle","_uuid":"664e03dc1434fa2c4eb730ea36ab60e37f13cd3f","trusted":true},"cell_type":"code","source":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\npercent.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"49a133fb-b713-45bd-ca42-c1ca0eb4d3f6","_execution_state":"idle","_uuid":"09b3bc296d01936b3b6df7f3ea670499e926720e","trusted":true},"cell_type":"code","source":"#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(df_train['resp'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We know that logged charts are very important in Stock market. Here is a simple way to do so.**"},{"metadata":{"_cell_guid":"cced5b14-c39d-c847-6dc9-93af3f4b6e6d","_execution_state":"idle","_uuid":"f578838e98e9996b09abbec058200cb18aa38869","trusted":true},"cell_type":"code","source":"#applying log transformation\ndf_train['resplog'] = np.log(df_train['resp'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e17fba2-3ff2-d6f1-841d-bc2a9746bcc2","_execution_state":"idle","_uuid":"de8366b3ad71c7cb398644766a412bee1d05642f","trusted":true},"cell_type":"code","source":"#transformed histogram and normal probability plot\nsns.distplot(df_train['resplog'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['resplog'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"92018f8f-4782-5a0c-9fee-f657b6331ffd","_uuid":"38631001da379277b3ae8cbc78504546a23a810d"},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"_cell_guid":"95c93455-85f4-e0a4-3d3a-8365bcf750e0","_uuid":"c05bfefad3b6084b9a7314ab87e5d9ae54af5ba1"},"cell_type":"markdown","source":"That's it! We reached the end of our exercise.\n\nThroughout this kernel we put in practice many of the strategies proposed by [Hair et al. (2013)](https://amzn.to/2uC3j9p). We philosophied about the variables, we analysed 'resp' alone and with the most correlated variables, we dealt with missing data and outliers, we tested some of the fundamental statistical assumptions and we even transformed categorial variables into dummy variables. That's a lot of work that Python helped us make easier.\n\nBut the quest is not over. Remember that our story stopped in the Facebook research. Now it's time to give a call to 'SalePrice' and invite her to dinner. Try to predict her behaviour. Do you think she's a girl that enjoys regularized linear regression approaches? Or do you think she prefers ensemble methods? Or maybe something else?\n\nIt's up to you to find out."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}