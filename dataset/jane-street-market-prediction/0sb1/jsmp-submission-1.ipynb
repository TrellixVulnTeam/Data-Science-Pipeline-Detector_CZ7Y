{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas\nimport os\nimport numpy\nimport math\nimport matplotlib.pyplot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_csv = pandas.read_pickle('/kaggle/input/jsmp-preprocess-1/train_csv.pickle.gz')\nfeatures_csv = pandas.read_pickle('/kaggle/input/jsmp-preprocess-1/features_csv.pickle.gz')\n\nfeature_columns = [f'feature_{i}' for i in range(130)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm\nimport sklearn.model_selection\nimport sklearn.metrics\n\ndef calc_utility_score(actions, df):\n    result = pandas.DataFrame({\n        'date': df.loc[:, 'date'],\n        'resp': df.loc[:, 'resp'],\n        'weight': df.loc[:, 'weight'],\n        'action': actions,\n    })\n    \n    days = result['date'].nunique()\n\n    result['p'] = result['weight'] * result['resp'] * result['action']\n\n    p = result.groupby('date').sum()['p']\n    t = p.sum() / math.sqrt((p ** 2).sum()) * math.sqrt(250 / days)\n    u = min(max(t, 0), 6) * p.sum()\n    \n    normalized_u = u / days\n    \n    return normalized_u\n\ntrain_rates = numpy.linspace(0.05, 0.95, 10)\ntrain_scores = []\ntest_scores = []\n\nfor train_rate in train_rates:\n    train_n_rows = int(len(train_csv) * train_rate)\n    train_df = train_csv.iloc[:train_n_rows, :]\n    test_df = train_csv.iloc[train_n_rows:, :]\n    \n    train_features = train_df.loc[:, feature_columns].to_numpy()\n    train_resps = train_df.loc[:, 'resp']\n\n    test_features = test_df.loc[:, feature_columns].to_numpy()\n    test_resps = test_df.loc[:, 'resp']\n\n    train = lightgbm.Dataset(train_features, train_resps)\n    test = lightgbm.Dataset(test_features, test_resps, reference=train)\n\n    params = {}\n    model = lightgbm.train(params=params, train_set=train, valid_sets=test)\n    \n    train_score = calc_utility_score(model.predict(train_features) > 0, train_df)\n    test_score = calc_utility_score(model.predict(test_features) > 0, test_df)\n    \n    train_scores.append(train_score)\n    test_scores.append(test_score)\n\n    print(f'Train score : {train_score}')\n    print(f'Test score : {test_score}')\n    \nmatplotlib.pyplot.plot(train_rates, train_scores, label='Train scores')\nmatplotlib.pyplot.plot(train_rates, test_scores, label='Test scores')\nmatplotlib.pyplot.xlabel('Train data rate')\nmatplotlib.pyplot.ylabel('Utility score')\nmatplotlib.pyplot.legend()\nmatplotlib.pyplot.tight_layout()\nmatplotlib.pyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = lightgbm.Dataset(train_csv.loc[:, feature_columns].to_numpy(), train_csv.loc[:, 'resp'].to_numpy())\nparams = {}\nmodel = lightgbm.train(params=params, train_set=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env()\niter_test = env.iter_test()\n\nfor (test_df, sample_prediction_df) in iter_test:\n    action = model.predict(test_df.loc[:, feature_columns].to_numpy()) > 0\n    \n    sample_prediction_df.action = action.astype(numpy.int8)\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}