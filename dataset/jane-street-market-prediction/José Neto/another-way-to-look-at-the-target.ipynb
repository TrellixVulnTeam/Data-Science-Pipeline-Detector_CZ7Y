{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regression instead of Classification  \nI start thinking about this problem mainly as a regression instead of classification. If we change the primary target to pursue a return? One should pay attention to the fact that, as an arbitrageur on high frequency trading, the most important thing is not the action of trade or not itself, but the return impact of each trade. \n\nBased on that predicted return per trade, it can be much easier to guide a decision about action. In this notebook my aim is to give a **brief** description of another way to look at the same problem. If you enjoy, upvote and comment below!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #plotting\nimport seaborn as sns #plotting \nimport warnings\n\nfrom sklearn.model_selection import train_test_split #split training set\nfrom sklearn import metrics as ms  # MSE and accuracy\nfrom sklearn.preprocessing import StandardScaler #standardizing features\nfrom lightgbm import LGBMRegressor #Light Gradient Boost Regressor\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline\npd.set_option('display.max_columns', 200)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A very brief EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/jane-street-market-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let´s see the number of null values for each feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"nulls = pd.DataFrame(df.iloc[:, 8:].isnull().sum(), columns = ['missing_values'])\nnulls.sort_values(by='missing_values', ascending=False).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With a total of 2,4 million samples, I think that imputing the features with more than 10% missing values with median or something like will not improve that much our analysis. So, I decided to drop some of these features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['feature_28', 'feature_17', 'feature_27', 'feature_18', 'feature_7',\n              'feature_8', 'feature_108', 'feature_114', 'feature_90', 'feature_96',\n              'feature_102', 'feature_78', 'feature_72', 'feature_84'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, the complete train set is full of weight-zero rows. They do not change our return target, so, let´s get rid of them filtering df and after that, I´ll create a trade_return column that equals $response * weight$"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.weight != 0] # filtering our df\ndf['trade_return'] = df.weight * df.resp # trade_return column\ndf['action'] = df.resp.apply(lambda x: x > 0).astype(int) # this will be my \"second\" target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I´ll drop ts_id column also, since I think that it´s useless for a first study\ndf.drop('ts_id', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape # now wep´ve 1,9m samples and 125 features. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It´s a good idea to have a look at the correlations between features."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(df.drop(['action', 'date'], axis = 1).corr(), cmap='inferno');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Any of the features alone cannot give good correlations with trade_return. That´s previously expected, as if arbitrage could be succesfully done with only one feature, everyone would succeed on investing."},{"metadata":{},"cell_type":"markdown","source":"# Splitting the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, 8:-2] # Select only feature columns\ny = df.iloc[:, -2:] # return per trade and action column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Action is based on resp, and resp*weight gives return. I´ll work with return target instead of action as said before\nXtrain, Xval, ytrain, yval = train_test_split(X, y.trade_return, test_size = .2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I made a first data preprocessing when dropped some of the features above. But I did not impute any missing values yet. Now, I´ll do it using median, as I think that the remaining features won´t be impacted by imputing median"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain = Xtrain.fillna(value = Xtrain.median()) # Median is quite better than avg for this case\nXval = Xval.fillna(value = Xval.median()) # I´m avoiding information leakage here (from train to val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let´s get a visual clue about the features on the training set. Remember that we should do our EDA on train set and use validation set only after dealing with the training one."},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a distplot for each of the variables \nplt.figure(figsize=(30, 70))\nfor i in range(1, len(Xtrain.columns)+1):\n\n  plt.subplot(58, 2, i)\n  sns.distplot(Xtrain.iloc[:5000, i-1], bins = 70, kde=True) # using only first 5000 rows\n\nplt.subplots_adjust(hspace=1.25, wspace=.2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all of the features seems to have a mean close to zero. But not all of them. Otherwise, some features have different range of values, and that may be a problem when doing regressions without standardizing them. Let´s do it after creating a baseline model"},{"metadata":{},"cell_type":"markdown","source":"# Constructing a baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline = np.zeros_like(yval) # np.array with the same dimensions as yval\nbaseline += ytrain.mean() # broadcasting it with all elements equallying ytrain mean\n\n# Any model worst than RMSE baseline should be ignored\nprint ('Baseline RMSE:', np.sqrt(ms.mean_squared_error(yval, baseline))*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Standardizing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(Xtrain)\n\nXtrain_std = scaler.transform(Xtrain)\nXval_std = scaler.transform(Xval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM Regressor  \nI think that a good start is LGBM, as it´s pretty fast and robust"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb = LGBMRegressor(num_leaves=30, n_estimators=400, max_depth=10) # Without any hyperparameter opt.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.fit(Xtrain_std, ytrain)\npredlgb = lgb.predict(Xval_std)\nprint ('Light GBM RMSE:', np.sqrt(ms.mean_squared_error(yval, predlgb))*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now, classification  \nAs we´ve already done predictions of returns, we can try to classify action target based on trade_return criteria. If it´s greater than zero, action = 1, else, action = 0. "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pd.DataFrame() # blank dataframe\npredictions['pred_lgb'] = predlgb # creating a column that contain return predictions made before\n\ndf1 = pd.DataFrame(yval)\ndf1['action'] = [1 if p > 0 else 0 for p in df1.trade_return] # as resp defines action, whenever resp>0, action > 0.\ndf1.reset_index(inplace=True)\ndf1.drop('index', axis = 1, inplace = True)\n\npredictions = pd.concat([df1, predictions], axis = 1) # concatenating both dataframes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let´s create action predictions based on LGB return predictions and compare it to the baseline "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions['lgb_action'] = [1 if p > 0 else 0 for p in predictions.pred_lgb]\npredictions['pred_baseline'] = 1 # cause the average return from ytrain is > 0\n\npredictions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, let´s evaluate the accuracy of them. Remember that you can also try using different regression models, hyperparameter optimization on LGB, XGBoost or another, and even try to run many models and create a final ensemble of them, using stacking, average voting or mode voting!"},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Baseline Accuracy:', ms.accuracy_score(predictions.action, predictions.pred_baseline)*100,'%')\nprint ('-'*50)\nprint ('Light Gradient Boosting Accuracy:', ms.accuracy_score(predictions.action, predictions.lgb_action)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the LGM model performed very good if considered that few EDA were done before and the hyperparameters weren´t optimized. Be creative, try another ways to deal with this problem!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}