{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi all, as you may know, 2020 brought the first (that I know) deep learning architecture for tabular data ([here](https://arxiv.org/pdf/1908.07442.pdf) the paper for those interested). Since it proved to be high-performing for many datasets, including in some of the latest kaggle [competitions](https://www.kaggle.com/c/lish-moa/notebooks?competitionId=19988&sortBy=scoreAscending&searchQuery=tabnet), why not give a try here? \n\n\n### Props to: \n\n- [pytorch-tabnet](https://github.com/dreamquark-ai/tabnet) I think this library should get a round of applause, fitting a neural network is as easy as a scikit-learn estimator;\n\n- [binary-classification-example](https://github.com/dreamquark-ai/tabnet/blob/develop/census_example.ipynb) a notebook with an example tailored for our use case;\n\n- https://www.kaggle.com/wilddave/xgb-starter I want this to be a complementary to his notebook. \n\n\nI don't have much time (and knowledge) to add a proper torch customization or to use the pretrainer, but I may do it in the next weeks. \n\n**Please let me know what you think about it!**\n\n<img src=\"https://www.europol.europa.eu/sites/default/files/images/finance_budget.jpg\">\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Install pytorch-tabnet, read data, downcast Training, make env"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"!pip install pytorch-tabnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport datatable as dt\n\nimport torch\nfrom pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\nfrom sklearn.model_selection import StratifiedKFold\n\nDEVICE = 'gpu' if torch.cuda.is_available() else 'cpu'\n\ninput_path = '/kaggle/input/'\nroot_path = os.path.join(input_path, 'jane-street-market-prediction')\n\n#reading files\ntrain = dt.fread(os.path.join(root_path, \"train.csv\")).to_pandas()\nfloat64_cols = train.select_dtypes('float64').columns\ntrain[float64_cols] = train[float64_cols].astype('float32')\nresp_cols = [i for i in train.columns if 'resp' in i]\nmeta_features = dt.fread(os.path.join(root_path, \"features.csv\")).to_pandas()\n\n\nfeatures_names = list(set(train.columns) - set(resp_cols) - set(['weight', 'ts_id', 'date']))\nfeatures_index = list(map(lambda x: int(re.sub(\"feature_\", \"\", x)), features_names))\nfeatures_tuples = sorted(list(zip(features_names, features_index)), key = lambda x: x[1])\njust_features = [i[0] for i in features_tuples]\n\nimport janestreet\nenv = janestreet.make_env()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill Na, define features and target for model"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = train.loc[train['weight'] != 0]\n# binarize the target\ntrain['action'] = (train['resp'].values > 0).astype(int)\n#train = train.fillna(-99999)\nf_mean = train.mean()\ntrain = train.fillna(f_mean)\n\n# split data for training and free data space usage to prevent exceeding maximum allowed\nX_features = train.loc[:, just_features]\ny_target = train.loc[:, 'action']\ndel train\n\nprint('Finished.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit and Predict"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameters and use GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_EPOCHS = 200\nBATCH_SIZE = 1024\nVIRTUAL_BATCH_SIZE = 128\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nprint(\"Using {}\".format(DEVICE))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TabNetClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = TabNetClassifier(n_d=64, n_a=64, n_steps=5,\n                       gamma=1.5, n_independent=2, n_shared=2,\n                       cat_emb_dim=1, lambda_sparse=1e-4, \n                       momentum=0.3, clip_value=2., optimizer_fn=torch.optim.Adam,\n                       optimizer_params=dict(lr=2e-2), scheduler_params = {\"gamma\": 0.95,\n                         \"step_size\": 20},\n                       scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15,\n                       device_name = DEVICE\n)\n\nclf.fit(X_train=X_features.values, y_train=y_target.values,\n    max_epochs=MAX_EPOCHS , patience=20,\n    batch_size=BATCH_SIZE, virtual_batch_size=VIRTUAL_BATCH_SIZE,\n    num_workers=0,\n    weights=1,\n    drop_last=False\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit\n\nBy default I don't, be sure to switch *I_WANT_TO_SUBMIT* to *True*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform test and create submissions file\nprint('Creating submissions file...', end='')\nrcount = 0\nI_WANT_TO_SUBMIT = True\nif I_WANT_TO_SUBMIT: \n    for (test_df, prediction_df) in env.iter_test():\n        X_test = test_df.loc[:, just_features].fillna(f_mean)\n        y_preds = clf.predict(X_test.values)\n        prediction_df.action = y_preds.item()\n        env.predict(prediction_df)\n        rcount += len(test_df.index)\n    print(f'Finished processing {rcount} rows.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Take\n\nI find it as easy to use as other gradient boosting alternatives. Please tell me what you think in the comments. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}