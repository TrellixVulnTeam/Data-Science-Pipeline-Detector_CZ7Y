{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Jane Strret Market Prediction](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Jane_Street_Capital_Logo.svg/1200px-Jane_Street_Capital_Logo.svg.png)"},{"metadata":{},"cell_type":"markdown","source":"**So, In this competition we need to build a trading Model to find out the Maximum return from the stock Exchange. In the train data, each row is corrosponding to a trade opportuninty or action value. If the action value is 1 the it will be taken and if 0 it will pass on.**\n\n* If this notebbok really helps to get some little bit more insights of teh features and data please UPVOTE my work. I will update more on feature Selection."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing Necessary Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the Necesssary Datas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting the paths to variables to access when required\n#Taking  a subset of the data to analyze\ntrain = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/train.csv\")\nsample_test = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/features.csv\")\n\n#Shape of teh Datasets\ntrain.shape, sample_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Understanding teh Column Types and Missing Values Imputation Techniques"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---------------------"},{"metadata":{},"cell_type":"markdown","source":"## Handling Missing Values\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_val = pd.DataFrame(train.isna().sum().sort_values(ascending=False)*100/train.shape[0],columns=['missing %'])[:50]\nmissing_val.style.background_gradient(cmap='Oranges_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a total 14 features having Missing Values >10%/ let's found out what are the best stratigies to fill up the missing Values."},{"metadata":{},"cell_type":"markdown","source":"**Approach 1: Fill in Missing Values with -999 or -9999**\n\nIn this particular scenario the missing values are in random as the data is a real-time trading data. So this approch is appropiate for this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(-999,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Approach 2: Fill in Missing Values with mean replacement of each column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining a mappper function to replace missing values with withs mean.\nfor i in list(train.columns):\n    x = train[i].mean()\n    print(i,\"    : \",x)\n    #mapp[i] = x\n    #train[i]=train[i].fillna(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Define the action in the data\n\n#We are using pi value 1 to take only the Weight!=0. Weight = 0 is only for data completeness. \ntrain=train[train['weight']!=0]\ntrain['action']=(train['resp']>0)*1\n\ntrain.action.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target Label is Balanced or Not?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train.action)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot it is visible that the target feature is balanced so we need not to worry  about the unbalances in the data. "},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Different Time Horizons and Action "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20, 6))\nsns.distplot(train['action'], ax=axs[0])\nsns.distplot(train['resp'], ax=axs[1])\nsns.distplot(train['weight'], ax=axs[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"weight is completely left skewed whreas resp has a normal distribution. Let's find out the different time horizons distributions and their differences"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 4, figsize=(20, 6))\nsns.distplot(train['resp_1'], ax=axs[0])\nsns.distplot(train['resp_2'], ax=axs[1])\nsns.distplot(train['resp_3'], ax=axs[2])\nsns.distplot(train['resp_4'], ax=axs[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's found out the cummulative returns of 4 different Time Horizons"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\n\nreturns = pd.Series(train['resp']).cumsum()\n\nresp_1= pd.Series(train['resp_1']).cumsum()\nresp_2= pd.Series(train['resp_2']).cumsum()\nresp_3= pd.Series(train['resp_3']).cumsum()\nresp_4= pd.Series(train['resp_4']).cumsum()\n\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_title (\"Cummulative Return of 4 diffrerent Time Regions\", fontsize=20)\nreturns.plot()\nresp_1.plot()\nresp_2.plot()\nresp_3.plot()\nresp_4.plot()\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation of Different Time Horizons and Action"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train[['resp_1','resp_2','resp_3','resp_4','resp','action']].corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nfig = plt.figure(figsize = (15, 8))\n\n# plot the data using seaborn\nax = sns.heatmap(corr, \n                 mask = mask, \n                 annot=True,\n                 vmax = 0.3, \n                 square = True,  \n                 cmap = \"viridis\")\n# set the title for the figure\nax.set_title(\"Correlation Actions Vs resp, resp_{1,2,3,4}\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing the Noisy Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_set = train.loc[:,train.columns.str.contains('feature')].columns\n\n#For analyzing part I am using only 20 features distribution. \nfor i in feature_set[:20]:\n    fig, ax = plt.subplots(figsize=(10, 4))\n    feature_ = pd.Series(train[str(i)]).cumsum()\n    ax.set_xlabel (\"Trade\", fontsize=18)\n    ax.set_ylabel (f\"feature_{i} (cumulative)\", fontsize=15);\n    feature_.plot(lw=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks @Carl for poiniting out this insight.\n[https://www.kaggle.com/carlmcbrideellis/jane-street-eda-of-day-0-and-feature-importance](http://)\n\nFrom the above plots we can observe the trends of the features whether it is linear in nature or noisy pattern.\n*  Considering teh whole data,OneImportant thing to be noticed here, that feature 3,4,5,6,73,75,76,77,79,82 the trade is decreasing where as for others there is a increasing trends(Curvilinear and Linear Patterns).\n\n* We can sort out the Noisy features as a different subset to the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_feats = train[[\"feature_3\",\"feature_4\",\"feature_5\",\"feature_6\",\"feature_73\",\"feature_75\",\"feature_76\",\"feature_77\",\"feature_79\",\"feature_82\",\"resp\",\"action\"]]\nbad_feats.corr().style.background_gradient(cmap='viridis', low=1, high=0, axis=None).set_precision(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Insights\n\n1. One thing that is very Noticable that with our action(Traget feature) there is really very correlation with these feature swhich has a negative slope with trade."},{"metadata":{},"cell_type":"markdown","source":"## Outlier Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_skewed_boundaries(df, variable, distance):\n\n    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n\n    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n\n    return upper_boundary, lower_boundary\n\nupper_resp,lower_resp = find_skewed_boundaries(train,'resp',1.5)\n\n\nprint('Capping are',lower_resp,upper_resp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it is a Trading Dataset These extreme values may be a important factor to consider. So we will keep it."},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Only Extracting the int64 type features\nnum_features = []\nfor i,j in zip(train.columns,train.dtypes.tolist()):\n    if(j==\"object\" or j == \"datetime64[ns]\"):\n        pass\n    else:\n        num_features.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom xgboost import XGBClassifier\n\n\n\nmodel = XGBClassifier(\n        n_estimators = 500,\n        max_depth=11,\n        learning_rate=0.06,\n        subsample=0.85,\n        colsample_bytree=0.6,\n        random_state=0,\n        tree_method='gpu_hist'\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you uncomment the below code It will take a lot of time. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting Top 50 features\n#selector = RFE(model,n_features_to_select=50,step=2)\n#selector.fit(X_train[num_features],y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = ['feature_2',\n 'feature_9',\n 'feature_12',\n 'feature_16',\n 'feature_19',\n 'feature_24',\n 'feature_30',\n 'feature_32',\n 'feature_35',\n 'feature_37',\n 'feature_39',\n 'feature_42',\n 'feature_45',\n 'feature_57',\n 'feature_61',\n 'feature_62',\n 'feature_63',\n 'feature_67',\n 'feature_69',\n 'feature_76',\n 'feature_81',\n 'feature_82',\n 'feature_83',\n 'feature_88',\n 'feature_105',\n 'feature_120',\n 'feature_121',\n 'feature_122',\n 'feature_124',\n 'feature_129']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's Analyze the Top 50 features distribution over the span of Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feats in feats:\n    fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n    sns.distplot(train[feats], ax=axs[0])\n    sns.distplot(train[train.weight !=0][feats], ax=axs[1])\n    sns.boxplot(train[train.weight !=0][feats], ax=axs[2])\n    fig.suptitle(feats, fontsize=15, y=1.1)\n    \n    axs[0].set_title('Distribution of feats')\n    axs[1].set_title('weight ! 0')\n    axs[2].set_title('Box Plot Distribution')\n    \n    \n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* One thing here to be noticed that Most of the features, (weight !=0) the distribution is very skewed."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\ndef permutation_feature_selection(model,xtrain,ytrain,n_repeats=2):\n\n    '''\n    model : Empty model constructor of any ML algorithm.(e.g RandomForestRegressor(random_state=2020))\n    xtrain : Training dataset\n    ytrain : Output label of training dataset\n    n_repeats : The number of times the feature will be shuffled\n\n    '''\n\n\n    model.fit(xtrain,ytrain)\n    train_cols = []\n    val_cols = []\n\n    # Feature Selection on just Training data\n\n    r_train = permutation_importance(model,xtrain,ytrain,n_repeats=n_repeats,random_state=0)\n    for i in r_train.importances_mean.argsort()[::-1]:\n        train_cols.append(xtrain.columns[i])\n\n\n\n# Calling Code\nmodel = XGBClassifier(\n        n_estimators = 500,\n        max_depth=11,\n        learning_rate=0.06,\n        subsample=0.85,\n        colsample_bytree=0.6,\n        random_state=0,\n        tree_method='gpu_hist'\n)\n\n#Takes a lot of time\n#t_cols= permutation_feature_selection(model,train[num_features],train['action'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 50 features based on Permutation feature Importance.\n#t_cols[:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}