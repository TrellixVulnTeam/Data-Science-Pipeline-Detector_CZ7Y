{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport xgboost as xgb\nimport sklearn\nimport tqdm\nimport random\nimport janestreet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED= 9899\nrandom.seed(SEED)\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/train.csv\")\nexample_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eda(data):\n    print(\"----------Top-5- Record----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types-----------\")\n    print(data.dtypes)\n    print(\"----------Missing value-----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n\ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n    \ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset,keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    print('After drop shape:', data.shape)\n    after = data.shape[0]\n    print('Total Duplicate:', before-after)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph_insight(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['resp_1'] = (((train['resp_1'].values)*train['weight']) > 0).astype(int)\ntrain['resp_2'] = (((train['resp_2'].values)*train['weight']) > 0).astype(int)\ntrain['resp_3'] = (((train['resp_3'].values)*train['weight']) > 0).astype(int)\ntrain['resp_4'] = (((train['resp_4'].values)*train['weight']) > 0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['weight'] != 0]\n\ntrain = train.query('date > 85').reset_index(drop = True) \n\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\ntrain.fillna(train.mean(),inplace=True)\n\nfeatures = [c for c in train.columns if 'feature' in c]\n\ndf_train = train.sample(frac=0.8, random_state=0)\ndf_valid = train.drop(df_train.index)\n\n\nX_train = df_train.loc[:, df_train.columns.str.contains('feature')]\nX_valid = df_valid.loc[:, df_valid.columns.str.contains('feature')]\ny_train = df_train['action']\ny_valid = df_valid['action']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature = 'feature_11'\nsns.lmplot(\n    x=feature, y=\"action\", hue=\"feature_0\", col=\"feature_0\",\n    data=df_train, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = X_train.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(X_train[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n#corrmat.to_csv('correlation.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"feature_0 does not  seem to have any impact on the results as being the only categorical variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nprint(\"XGBoost version:\", xgb.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the below features are selected after removing the correlared features from the ones with top feature importance scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_features = [\n'feature_0','feature_1','feature_3','feature_6','feature_20','feature_27','feature_31','feature_37','feature_39','feature_41','feature_42','feature_43','feature_44','feature_45','feature_60','feature_62','feature_83','feature_107']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=9,\n    learning_rate=0.01,\n    gamma = 0.3,\n    min_child_weight=5,\n    random_state=SEED,\n    subsample=0.8, \n    colsample_bytree= 0.8,\n    eval_metric = \"error\",\n    use_label_encoder=False,\n    scale_pos_weight=1,\n    nthread=4,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)\n%time clf.fit(X_train[selected_features], y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The feature selection by finding threshold for the feature importance and then removing the correlated features helps to increase the score from 0.5635 to 0.5695."},{"metadata":{},"cell_type":"markdown","source":"There are many rounds of optimizing the XGBoost parameters and the ones in baseline and clf have the optimized parameters only."},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING = True\n\nstart_time = time.time()\n\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\n# count = 0\nfor (test_df, sample_prediction_df) in iter_test:\n    if test_df['weight'].item() > 0:\n        X_test = test_df.loc[:, features]\n        X_test.fillna(X_test.mean(),inplace=True)\n        select_X_test = X_test[selected_features]\n        y_preds = clf.predict(select_X_test)\n        sample_prediction_df.action = y_preds.astype(int)\n    else:\n        sample_prediction_df.action = 0\n    env.predict(sample_prediction_df)\n        \nprint(f\"took: {time.time() - start_time} seconds\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}