{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.data.experimental import cardinality","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ngc.collect()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add in a feature tracking time since current day started\nperday = train['date'].value_counts().sort_index()\ntime_since_start = [list(range(i)) for i in perday]\ntime_since_start = sum(time_since_start, [])\ntrain['time_since_start'] = time_since_start","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the features and target\nfeats = [i for i in train.columns if i.startswith('feature')] + ['time_since_start']\nX = train[feats].fillna(0)\ny = train['resp']\ndel train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize features\nfrom sklearn import preprocessing\n\nsc = preprocessing.StandardScaler()\n\nX_train_sc = sc.fit_transform(X)\n\nprint(X_train_sc.shape)\npd.DataFrame(X_train_sc[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set hyperparameter values\nbatch_size = 7\nlstm_size = 32\ndense_size = 16\nbeta = 0.1\nlstm_dropout = 0.2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'chunk' the data into chunks of size batch_size for training the LSTM\n# note that we're using separate chunks rather than a sliding window here\n# i.e. [1,2,3,4,5,6] would become [[1,2,3],[4,5,6]] with a batch size of 3\n\ndataset_train = tf.data.Dataset.from_tensor_slices((X_train_sc, y))\ndataset_train = dataset_train.batch(batch_size)\ndel X, y, X_train_sc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_train = cardinality(dataset_train).numpy() - 1\n\nX_train = np.array([i[0].numpy() for i in dataset_train.take(l_train)])\n\ny_train = np.array([i[1].numpy() for i in dataset_train.take(l_train)])\n\ndel dataset_train\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss function attempting to penalize high variance of trade responses\n# note it differs from the real utility score, where the penalization of high variance is \n# on the level of days; here it's on the level of individual trades\n\ndef my_loss(action, response):\n    x = tf.multiply(action, response)\n    xsq = tf.square(x)\n    return - tf.reduce_sum(x) + beta * tf.reduce_sum(xsq)\n\n# accuracy function, looking for cases where a trade is 'successful'\n# i.e. either resp<0 and no trade, or resp>0 and a trade\n\ndef my_accuracy(y_true, y_pred):\n    return (y_true>=0) == (y_pred>=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf\n\nmodel = keras.Sequential()\nmodel.add(layers.LSTM(lstm_size, \n                      input_shape=(batch_size,131), \n                      return_sequences=True, \n                      dropout=lstm_dropout))\nmodel.add(layers.Dense(dense_size))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',\n              loss=my_loss, \n              metrics=[my_accuracy])\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission\nimport janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_submission():\n    \n    row_history = []\n    current_day = 0\n    time_of_day = 0\n    n_rows = batch_size\n    subs = []\n\n    for (test_df, sample_prediction_df) in iter_test:\n        if test_df['date'].iloc[0] == current_day:\n            time_of_day = time_of_day + 1\n        else:\n            current_day = test_df['date'].iloc[0]\n            time_of_day = 0\n            print(current_day, time_of_day) \n\n        test_df = test_df.fillna(0)\n        test_df['time_since_start'] = time_of_day\n        r = sc.transform(test_df[feats])\n        if len(row_history) < n_rows:\n            sample_prediction_df.action = 0 # no trades for first 40\n            row_history.append(r)\n        elif len(row_history)==n_rows:\n            row_history = row_history[1:]\n            row_history.append(r)\n            X = np.array(row_history).reshape(1,n_rows,len(feats))\n            a = model(X, training=False)\n            sample_prediction_df.action = int(a[0][-1][0] > 0.5)\n        else:\n            print(\"ERROR: Row history is > n_rows\")\n\n        subs.append(sample_prediction_df['action'])\n        env.predict(sample_prediction_df)\n        \n    return subs\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs = make_submission()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}