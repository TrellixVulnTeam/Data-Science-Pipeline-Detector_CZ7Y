{"cells":[{"metadata":{},"cell_type":"markdown","source":"![logo](https://www.usu.edu/degrees/images/large/mathematics2.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Jane Street Data Preprocessing\nThe steps taken here are:\n1. Read in data\n2. Filter out data to use\n3. Calculate mean, median, skew etc for each feature\n4. Create mean vector for use during imputation\n5. Impute NaNs \n6. Apply standardscaler\n7. Pickle training data and other parameters needed for training and inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import skew, normaltest\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read data and filter\nMany notebooks filter out data prior to date = 85 because those data show different properties then after. Maybe best to try training a model with all data as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all = pd.read_csv('../input/jane-street-market-prediction/train.csv')\ntrain_all = train_all[train_all.date > 85].reset_index(drop = True) \ntrain_all = train_all[train_all['weight'] != 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate mean, median, skew etc for each feature\nHere we drop all NaNs and compute a few statistical properties for each column."},{"metadata":{"trusted":true},"cell_type":"code","source":"par = []\nfor i in range(130):\n    df = train_all['feature_'+str(i)].dropna()\n    par.append([i, np.mean(df), np.median(df), df.mode()[0], np.abs(skew(df)), normaltest(df)[1]])\ndfp = pd.DataFrame(par, columns=['feature', 'mean', 'median', 'mode', 'skew', 'normaltest'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfp.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The skew tells us if the values have a symmetric distribution (skew close to zero), or skewed distribution. If the distribution is symmetric, it makes sense to use the mean value during imputation (filling in the NaNs). Otherwise it might be better to use the median value, or the mode value (most common value).\nBTW: The normaltest shows that none of the features are normal distributed, which is as expected."},{"metadata":{},"cell_type":"markdown","source":"## Create mean vector\nWe can use the mean values only, or a combination of mean, median and mode values based on skew. Here we define two thresholds that allow us to make use of one, two or all of the mean, meadian and mode values based on the skew value. Strictly speaking, we should only calculate mean values from the training set after the train/test split, to avoid data leakage from the test/validation set into the mean vector."},{"metadata":{"trusted":true},"cell_type":"code","source":"MEAN_TH = 1.25\nMODE_TH = 100. # must be >= MEAN_TH\n\ndef get_mmm(dfm):\n    fmean = np.zeros(130)\n    for i in range(130):\n        if dfm['skew'][i] <= MEAN_TH:\n            fmean[i] = dfm['mean'][i]  # use mean value\n        elif dfm['skew'][i] > MODE_TH:\n            fmean[i] = dfm['mode'][i] # use mode value\n        else:\n            fmean[i] = dfm['median'][i] # use median value\n    return fmean\n\nf_mean = get_mmm(dfp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impute\nOnce the mean vector has been created, we use it to impute all the missing numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"f_pad = np.concatenate(([0.,0.,0.,0.,0.,0.,0.], f_mean, [0.]))\npad = pd.Series(f_pad, index = train_all.columns)\ntrain_all.fillna(pad, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scale\nWhen feeding a DNN it is benefical to scale the features to mean = 0 and std.dev. = 1.0. While training a random forest and similar standard scaling has no impact (but it does not hurt either).  \nFeature_0 is only 1 or -1, so we will leave that one alone."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in train_all.columns if \"feature\" in c]\nfeatures = features[1:] # leave feature_0 untouched\nX_train = train_all[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before scaling:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_t = scaler.transform(X_train)\ndel X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all[features] = X_t","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After scaling:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature 1 and upwards all have std = 1 now, and the other variables are unchanged. Finally we pickle the training data for use in training notebooks."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all.to_pickle('train_data.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Save parameters\nLast thing to do is to save the scaler model and the mean vector, both are required during inference."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\npickle.dump(scaler, open('./scaler.pkl','wb'))\nnp.save('feat_mmm.npy', f_mean) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}