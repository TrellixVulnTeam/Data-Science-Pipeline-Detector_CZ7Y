{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit, train_test_split, KFold\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport gc\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '/kaggle/input/jane-street-market-prediction'\ntrain = pd.read_csv(os.path.join(data_path, 'train.csv'))\nfeatures = pd.read_csv(os.path.join(data_path, 'features.csv'))\ntest = pd.read_csv(os.path.join(data_path, 'example_test.csv'))\nsubmission = pd.read_csv(os.path.join(data_path, 'example_sample_submission.csv'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nstart = time.time()\nx_ = train.fillna(0, inplace = False)\nstop = time.time()\nprint('Pandas fillna:', stop - start)\n\nstart = time.time()\nx_ = np.nan_to_num(train)\nstop = time.time()\nprint('nan_to_num fillna:', stop - start)\n\nstart = time.time()\nx_ = np.where(np.isnan(train), 0, train)\nstop = time.time()\nprint('np.where fillna:', stop - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# downcast dataset to save memory\ngc.collect()\n\ndef downcast_type(df):\n    # downcast value: float64 -> float32, int64 -> int32\n    float_cols = [col for col in df.columns if df[col].dtype == 'float64']\n    int_cols = [col for col in df.columns if df[col].dtype == 'int64']\n    \n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int32)\n    \n    return df\n\ntrain = downcast_type(train)\nfeatures = downcast_type(features)\ntest = downcast_type(test)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(features.shape)\nprint(test.shape)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.date.value_counts().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train.date, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Raw model: withou explicit feature engineering and domain knowledge, get a baseline prediction\ngc.collect()\n\ntrain['action_num'] = train['resp_1'] + train['resp_2'] + train['resp_3'] + train['resp_4']\n\ngc.collect()\ntrain['action'] = train['weight']*train['resp']\n\nthreshold = 0\n\n\n# binarize action: greater than thershold, action = 1. less than threshold, action = 0\ntrain[train['action'] > threshold] = 1\ntrain[train['action'] <= threshold] = 0\ntrain[train['action_num'] > threshold] = 1\ntrain[train['action_num'] <= threshold] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine the tag_x influence for each features in each row:\n# 1. convert impact of tag_x to binary\n# 2. calculate product of each tag_x for each feature_x in each row\n# 3. combine the tag_x impact of each feature_x in each row together\nfeatures_bin = features.copy()\nfeatures_bin.iloc[:, 1:] = features.iloc[:, 1:].astype(int)\ngc.collect()\nprint(features_bin.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_col = [col for col in train.columns if 'feature' in col]\ntags = [col for col in features.columns if 'tag' in col]\n\nproduct = np.dot(train[feature_col], features_bin[tags])\n\ngc.collect()\ntrain[tags] = product\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature processing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit, train_test_split\n\ntrain.fillna(0, inplace = True)\n\n\n# Generate X & y dataframe\ndrop_feature = ['action', 'action_num', 'resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'ts_id']\ntarget = train['action']\ntrain.drop(drop_feature, axis = 1, inplace = True)\ngc.collect()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\nlr = LogisticRegression()\n\ntarget = target.values.reshape(-1, 1)\nlr.fit(train, target)\n\npredict = lr.predict(train)\n\nscore = roc_auc_score(target, predict)\n\nprint('LR score:', score)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install numba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fillna function\nfrom numba import njit\n\n@njit\ndef fillna_arr(df):\n    \n    if (np.isnan(df).sum()):\n        df = np.where(np.isnan(df), 0, df)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make submission\n\nimport janestreet\n\njanestreet.competition.make_env.__called__ = False\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    a = test_df\n    stop\n    test_df = downcast_type(test_df)\n    gc.collect()\n    test_df[tags] = np.dot(test_df[feature_col], features_bin[tags])\n    gc.collect()\n    \n    # Save time for submission\n    # For zero weight, prediction.action = 0\n    X_test = test_df.values\n    X_test = fillna_arr(X_test)\n    \n    sample_prediction_df.action = lr.predict(X_test) #make your 0/1 prediction here\n        \n    env.predict(sample_prediction_df)\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.loc[:, a.columns.str.contains('feature')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}