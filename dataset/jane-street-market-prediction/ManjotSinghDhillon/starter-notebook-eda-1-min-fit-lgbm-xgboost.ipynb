{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DO UPVOTE THE KERNEL IF YOU LIKE IT.\n# CHECK OUT MY OTHER WORK TOO."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf = pd.read_csv(\"../input/jane-street-market-prediction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df= pd.read_csv(\"../input/jane-street-market-prediction/example_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_prediction_df= pd.read_csv(\"../input/jane-street-market-prediction/example_sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv(\"../input/jane-street-market-prediction/features.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nCOLS = df.iloc[:,7:10].columns\nfor f in COLS:\n    fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n    sns.distplot(df[f], ax=axs[0])\n    sns.distplot(df.query('weight > 0')[f], ax=axs[1])\n    try:\n        sns.distplot(df.query('weight > 0 and resp > 0')[f].dropna().apply(np.log1p), ax=axs[2])\n        sns.distplot(df.query('weight > 0 and resp < 0')[f].dropna().apply(np.log1p), ax=axs[2])\n    except:\n        pass\n    df.sample(5000).plot(kind='scatter', x=f, y='resp', ax=axs[3])\n    fig.suptitle(f, fontsize=15, y=1.1)\n    \n    axs[0].set_title('feature distribution')\n    axs[1].set_title('only weight > 0')\n    axs[2].set_title('log transform')\n    axs[3].set_title('feature vs. response')\n    \n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBCLASSIFIER"},{"metadata":{"trusted":true},"cell_type":"code","source":"# #UPVOTE\n# #HOW TO RUN THIS BLOCK \n# #PRESS CTRL + A\n# #PRESS CTRL + ? \n# # SHIFT + ENTER.\n# ####################################\n# # IMPORTING LIBRARIES\n# from sklearn import preprocessing\n# import xgboost as xgb\n# ####################################\n# # HANDLING DATA\n# ############################################################################\n# df = df[df['weight'] != 0]\n# df['action'] = ((df['weight'].values * df['resp'].values) > 0).astype('int')\n# X_train = df.loc[:, df.columns.str.contains('feature')]\n# y_train = df.loc[:, 'action']\n# X_train = X_train.fillna(-999)\n# ############################################################################\n# #PARAMETERS\n# #########################\n# clf = xgb.XGBClassifier(\n#     n_estimators=480,\n#     max_depth=10,\n#     learning_rate=0.05,\n#     subsample=0.9,\n#     colsample_bytree=0.7,\n#     missing=-999,\n#     random_state=2020,\n#     tree_method='gpu_hist'\n# )\n# #########################\n# # FIT UNDER 1 MIN\n# #########################\n# clf.fit(X_train, y_train)\n# #########################\n# # SUBMISSION\n# ####################################################################\n# for (test_df, sample_prediction_df) in iter_test:\n#     X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n#     X_test.fillna(-999)\n#     y_preds = clf.predict(X_test)\n#     sample_prediction_df.action = y_preds\n#     env.predict(sample_prediction_df)\n# ####################################################################","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LIGHTGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# #UPVOTE\n# #HOW TO RUN THIS BLOCK \n# #PRESS CTRL + A\n# #PRESS CTRL + ? \n# # SHIFT + ENTER.\n# ##############################\n# # IMPORTING LIBRARY\n# import numpy as np\n# import pandas as pd\n# from sklearn import preprocessing\n# import xgboost as xgb\n# import lightgbm as lgb\n# from sklearn import *\n# #################################\n# # MAKING ENVIRONMENT\n# ###########################\n# import janestreet\n# env = janestreet.make_env()\n# iter_test = env.iter_test()\n# ############################\n# # READING DATA\n# #######################################################################################\n# train = pd.read_csv('../input/jane-street-market-prediction/train.csv')\n# features = pd.read_csv('../input/jane-street-market-prediction/features.csv')\n# test= pd.read_csv(\"../input/jane-street-market-prediction/example_test.csv\")\n# sub= pd.read_csv(\"../input/jane-street-market-prediction/example_sample_submission.csv\")\n# #######################################################################################\n# # HANDLING DATA\n# ###################################################################################################################################\n# col = [c for c in train.columns if c not in ['resp_1', 'resp_2', 'resp_3', 'weight', 'resp_4', 'resp', 'ts_id', 'date', 'action']]\n# train['action'] = (train['resp'].values > 0).astype('int')\n# train = train.fillna(-999)\n# ####################################################################################################################################\n# #PARAMETERS\n# ############################################\n# params = { \n#             'nthread':4,\n#             'n_estimators':1,\n#             'device' : 'gpu',\n#             'learning_rate': 0.05,\n#             'num_leaves': 34,\n#             'colsample_bytree':0.9497036,\n#             'subsample': 0.8715623,\n#             'max_depth':8,\n#             'min_child_weight':39.3259775\n#  }\n# ############################################\n# # FIT UNDER 1 MIN\n# ################################################################################################################\n# x1, x2, y1, y2 = model_selection.train_test_split(train[col], train['action'], test_size=0.2, random_state=20)\n# model = lgb.train(params, lgb.Dataset(x1, y1), 250,  lgb.Dataset(x2, y2), verbose_eval=100)\n# ################################################################################################################\n# #SUBMITTING FILE\n# #######################################################################\n# for (test, sub) in iter_test:\n#     X_test = test.loc[:, test.columns.str.contains('feature')]\n#     X_test.fillna(X_test.mean())\n#     y_preds = model.predict(X_test, num_iteration=model.best_iteration)\n#     sub.action = y_preds\n#     sub.action = (sub.action.values > 0.5).astype('int')\n#     env.predict(sub)\n# #######################################################################","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DASK DATAFRAME"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport dask.dataframe as dd\nimport pyarrow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dask.distributed import Client, progress\nclient = Client(n_workers=4, memory_limit='4GB')\nclient","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_parquet('output.parquet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndata = dd.read_parquet('./output.parquet', engine='pyarrow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION"},{"metadata":{},"cell_type":"markdown","source":"**This concludes your starter analysis! To go forward from here, click the blue \"Fork Notebook\" button at the top of this kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling!**"},{"metadata":{},"cell_type":"markdown","source":"# HAPPY CODING"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}