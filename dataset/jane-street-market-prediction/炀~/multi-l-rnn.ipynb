{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datatable as dt \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/input/jane-street-market-prediction/train.csv\"\ndf_train = dt.fread(path ,fill = True)\ndf_train = df_train.to_pandas()\ndf_train = df_train.query('date > 85').reset_index(drop = True) \ndf_train = df_train[df_train['weight'] != 0]\ndf_train.fillna(df_train.mean(),inplace=True)\ndf_train['action'] = (df_train.resp > 0).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_mask = ['feature_'+str(i) for i in range(0,130)]\nfeatures_mask.append('weight')\nret_mask = ['resp_4','resp_3','resp_2','resp_1','resp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train[features_mask]\ny = df_train['resp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 2000\ntime_step = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 2000\ntime_step = 4\nX_sub = X[:sample_size]\ny_sub = y[time_step:+sample_size+time_step]\nn_features = 131\nX_sub = X_sub.to_numpy()\n\ndef transfer(time_step,X_sub):\n    X_p = []\n    sample_size = len(X_sub)\n    for i in range(sample_size-time_step+1):\n        l = []\n        for j in range(time_step):\n            l.append(X_sub[i+j])\n        X_p.append(l)\n    X_p = np.array(X_p)\n    return X_p\n\nX_train = transfer(time_step, X_sub)[:int(sample_size*0.75)]\ny_train = y_sub[:int(sample_size*0.75)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras import *\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tf.config.run_functions_eagerly(True)\n\n#model = Sequential()\n#model.add(LSTM(140, input_shape=(time_step, n_features),return_sequences=True, activation = tf.keras.activations.relu))\n#model.add(BatchNormalization())\n#model.add(Dropout(0.2))    \n#model.add(LSTM(40,activation = tf.keras.activations.swish))\n#model.add(Dense(1, activation = sigmoid))\n\n#model.compile(optimizer='adam', loss='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length = 4\ninp= Input(shape=(length,131))\nx = LSTM(160,return_sequences=True)(inp)\nx = tf.keras.layers.Dense(1)(x)\n\nx = LSTM(160,return_sequences=True)(inp)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\nx = tf.keras.layers.Dropout(0.3)(x)\n\nx = LSTM(40,)(inp)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\nx = tf.keras.layers.Dropout(0.3)(x)\n\nx = tf.keras.layers.Dense(1)(x)\nout = tf.keras.layers.Activation(\"sigmoid\")(x)\n\nmodel = tf.keras.models.Model(inputs=inp, outputs=out)\nmodel.compile(optimizer='adam', loss='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train,epochs=10, verbose=0,batch_size=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\ni = 0\nlst = []\n\nfor (test_df, sample_prediction_df) in iter_test:\n    if i < 4:\n        lst.append(test_df[features_mask].to_numpy())\n        sample_prediction_df.action = 0\n        i = i+1\n\n    else:    \n        lst = lst[1:]\n        lst.append(test_df[features_mask].to_numpy())\n        input_ = np.array(lst).reshape(1,4,131)\n        if model.predict(input_,verbose = 0) > 0.025:\n            sample_prediction_df.action = 1\n        else:\n             sample_prediction_df.action = 0\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}