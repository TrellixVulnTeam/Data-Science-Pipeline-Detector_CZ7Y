{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# Jane Street Market Prediction: A Commplete EDA\n\nThis is a simple exploratory data analysis (EDA) of the files provided for the [Jane Street Market Prediction](https://www.kaggle.com/c/jane-street-market-prediction) time series competition."},{"metadata":{},"cell_type":"markdown","source":"## Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dabl\n!pip install datatable","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\ncolorMap = sns.light_palette(\"blue\", as_cmap=True)\n\n\nimport dabl\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncolorMap = sns.light_palette(\"blue\", as_cmap=True)\n\nimport missingno as msno","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!wc -l ../input/jane-street-market-prediction/train.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_data = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save memory !!! ðŸš€ðŸš€ðŸš€ Compure faster ðŸš€ðŸš€ðŸš€"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = reduce_mem_usage(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" Total days avaiallbe in dataset:- \",len(train_data['date'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA starts "},{"metadata":{"trusted":true},"cell_type":"code","source":"days_txn = train_data.groupby(['date']).agg({'ts_id':'count'}).reset_index()\ndays_txn.rename(columns={'ts_id':'txn_count'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(25, 10))\nsns.lineplot(days_txn['date'],days_txn['txn_count'])\nax.set_xlabel (\"Days\", fontsize=18)\nax.set_ylabel (\"Transaction count\", fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sum of Weights accross dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"days_txn_wght = train_data.groupby(['date']).agg({'weight':'sum'}).reset_index()\nfig, ax = plt.subplots(figsize=(25, 10))\nsns.lineplot(days_txn_wght['date'],days_txn_wght['weight'])\nax.set_xlabel (\"Days\", fontsize=18)\nax.set_ylabel (\"Sum of weight\", fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean of Weights accross dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"days_txn_wght = train_data.groupby(['date']).agg({'weight':'mean'}).reset_index()\nfig, ax = plt.subplots(figsize=(25, 10))\nsns.lineplot(days_txn_wght['date'],days_txn_wght['weight'])\nax.set_xlabel (\"Days\", fontsize=18)\nax.set_ylabel (\"Mean of weight\", fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is Huge trend and seasonality in the trade data "},{"metadata":{"trusted":true},"cell_type":"code","source":"percent_zeros = (100/train_data.shape[0])*((train_data.weight.values == 0).sum())\nprint('Percentage of zero weights is: %i' % percent_zeros +\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weight\n\n> *Each trade has an associated `weight` and `resp`, which together represents a return on the trade.\nTrades with `weight = 0` were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation. So we ignore 17% data while doing modeling*"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_weight = train_data['weight'].max()\nprint('The maximum weight was: %.2f' % max_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data['weight']==(max_weight)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tade of maximum weightage happends in Day-446 "},{"metadata":{},"cell_type":"markdown","source":"## Features\n> \"*This dataset contains an anonymized set of features, `feature_{0...129}`, representing real stock market data.*\"\n\nHowever, `feature_0` seems to me to be a little unusual, as it is composed solely of the integers `+1` or `-1`:"},{"metadata":{},"cell_type":"markdown","source":"## Curious nature of feature 1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['feature_0'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 3))\nfeature_0 = pd.Series(train_data['feature_0']).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_ylabel (\"feature_0 (cumulative)\", fontsize=18);\nfeature_0.plot(lw=3);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trade Action\n\n`action`: 1 to make the trade and 0 to pass on it.In view of this let us add a new 'binary' column to our test dataset called `action` such that if `resp` is positive then `action=1` else `action=0`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['action'] = ((train_data['resp'])>0)*1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets see how the trade transactions in Day 5 "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_txn_day_cumsum(day):\n    fig, ax = plt.subplots(figsize=(25, 10))\n    balance= pd.Series(day['resp']).cumsum()\n    resp_1= pd.Series(day['resp_1']).cumsum()\n    resp_2= pd.Series(day['resp_2']).cumsum()\n    resp_3= pd.Series(day['resp_3']).cumsum()\n    resp_4= pd.Series(day['resp_4']).cumsum()\n    ax.set_xlabel (\"Trade\", fontsize=18)\n    ax.set_title (\"Cumulative return for resp and time horizons 1, 2, 3, and 4\", fontsize=18)\n    balance.plot(lw=3)\n    resp_1.plot(lw=3)\n    resp_2.plot(lw=3)\n    resp_3.plot(lw=3)\n    resp_4.plot(lw=3)\n    plt.legend(loc=\"upper left\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trade Day - 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trade Day - 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trade Day - 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 499])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Its has been oberved that Cummulative sum of trade response varies over days"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(train_data.loc[train_data['date'] == 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(train_data.loc[train_data['date'] == 100])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation :- \n\n Bunch of fields have missing elements , Panoramically missing value pattern looks even accross trading days"},{"metadata":{},"cell_type":"markdown","source":"# Pearson Correlation between features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(train_data.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation :- \n\n* Features 80-117 have high correlation with each other \n* Feature 17-25 & Feature 29-33 have high correlation\n"},{"metadata":{},"cell_type":"markdown","source":"# Let see How distribution looks like "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taken from this notebook: https://www.kaggle.com/blurredmachine/jane-street-market-eda-viz-prediction\n\ndate = 0\nn_features = 130\n\ncols = [f'feature_{i}' for i in range(1, n_features)]\nhist = px.histogram(\n    train_data[train_data[\"date\"] == date], \n    x=cols, \n    animation_frame='variable', \n    range_y=[0, 600], \n    range_x=[-7, 7]\n)\n\nhist.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Automatic Data Vizualisation with Dabl "},{"metadata":{"trusted":true},"cell_type":"code","source":"dabl.plot(train_data.loc[train_data['date'] == 5], target_col=\"resp\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Day - 5 Trade Txn Scatter Plot "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_1 = px.scatter(train_data.loc[train_data['date'] == 5], x=train_data.loc[train_data['date'] == 5]['ts_id'], y=train_data.loc[train_data['date'] == 5]['resp'], \n                   trendline=\"ols\", marginal_y=\"violin\",\n                   title=(\"Scatter plot of resp with respect to ts_id for day 5\"))\nfig_1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_1 = px.scatter(train_data.loc[train_data['date'] == 446], x=train_data.loc[train_data['date'] == 446]['ts_id'], y=train_data.loc[train_data['date'] == 446]['resp'], \n                   trendline=\"ols\", marginal_y=\"violin\",\n                   title=(\"Scatter plot of resp with respect to ts_id for day 446\"))\nfig_1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Observation - Trade reponse is above zero for Day-446 compared to Day 0 "},{"metadata":{},"cell_type":"markdown","source":"## Subset data preperation for Feature importance and model explainability"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_data.loc[train_data['date'] == 5].loc[:, train_data.columns.str.contains('feature')]\nX_train = X_train.fillna(X_train.mean())\n# our target is the action\ny_train = train_data.loc[train_data['date'] == 5]['resp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = RandomForestRegressor(max_features='auto')\nregressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance by PermutationImportance"},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm_import = PermutationImportance(regressor, random_state=1).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### visualize the results - Show top 20 features"},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(perm_import, top=20, feature_names = X_train.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation :- For Day 5 important features for Feature 43,6,35,45,64 etc"},{"metadata":{},"cell_type":"markdown","source":"<font color=\"red\" size=5>Please upvote this kernel if you like it. It motivates me to create kernal with great content  :) </font>"},{"metadata":{},"cell_type":"markdown","source":"## Model Explainability with SHAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap \n\n# load JS visualization code to notebook\nshap.initjs()\n\nexplainer = shap.TreeExplainer(regressor)\nshap_values = explainer.shap_values(X_train)\n\n#use matplotlib=True\n\n\n# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\nshap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature interation with model output "},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort the features indexes by their importance in the model\n# (sum of SHAP value magnitudes over the train dataset)\n\n\nexplainer = shap.TreeExplainer(regressor)\nshap_values = explainer.shap_values(X_train)\n\n\ntop_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n\n# make SHAP plots of the three most important features\nfor i in range(len(top_inds)):\n    shap.dependence_plot(top_inds[i], shap_values, X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclustion :- \n\nThis notebook covers detail trend analysis of response and weights at day level , Interaction of target variable with independent variables****"},{"metadata":{},"cell_type":"markdown","source":"# Future work\n\n1. Feature Analysis \n2. Dimentionality reduction\n3. Data Imputation"},{"metadata":{},"cell_type":"markdown","source":"For Model explainability you can visit another kernel for more details \n\nhttps://www.kaggle.com/praveengovi/jane-street-model-interpretability-shap\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}