{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation, GaussianDropout\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy, Huber\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom random import choices\nfrom tensorflow.keras.constraints import max_norm, min_max_norm\nfrom keras.callbacks import ReduceLROnPlateau\n\nSEED = 1111\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\ntrain = pd.read_csv('../input/jane-street-market-prediction/train.csv')\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]\n\ntrain.fillna(train.mean(),inplace=True)\n\ntrain['action'] = ((train['resp'].values) > 0).astype(int)\n\n\nfeatures = [c for c in train.columns if \"feature\" in c]\n\nf_mean = np.mean(train[features[1:]].values,axis=0)\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\n#y_train = (train.loc[:, 'action'])\n\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n\n# Add the GELU function to Keras\n#https://mlfromscratch.com/activation-functions-explained/#/\n    \ndef gelu(x):\n    return 0.5 * x * (1 + tf.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n    #https://github.com/hendrycks/GELUs\n    #exact version is better not sure if below if exact and above is approximation\n    \n# not sure if below is considered exact\n#    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\nget_custom_objects().update({'gelu': Activation(gelu)})\n\n# Add leaky-relu so we can use it as a string\nget_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})\n\nact_func = ['sigmoid', 'relu', 'elu', 'leaky-relu', 'selu', 'gelu']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    x = tf.keras.layers.GaussianDropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n#        x = tf.keras.layers.Dense(hidden_units[i], kernel_constraint=min_max_norm(min_value=-0.5, max_value=0.5, rate=1.0, axis=0))(x)\n#        x = tf.keras.layers.Dense(hidden_units[i],kernel_initializer=tf.keras.initializers.TruncatedNormal(seed=1111))(x)\n#        x = tf.keras.layers.Dense(hidden_units[i],kernel_initializer=tf.keras.initializers.Orthogonal(seed=1111))(x)\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n#        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Activation('gelu')(x)\n# introduce randomness e.g. flip a coin and choose different dropouts\n#        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n        x = tf.keras.layers.GaussianDropout(dropout_rates[i + 1])(x)\n\n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n#        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n#        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n# introduce randomness e.g. flip a coin and choose difference losses\n# i don' tthink you can use huber on sigmoid acivation, you would need to activate after the fact then, \n# as huber probably won't work for this 1 vs 0 loss....\n#        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        loss=tf.keras.losses.Huber(),\n#        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n        metrics=[tf.keras.metrics.AUC(name=\"AUC\"),\n                 tf.keras.metrics.TrueNegatives(name=\"TN\"),\n                 tf.keras.metrics.TruePositives(name=\"TP\")]\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 5000\n#hidden_units = [130, 130, 130]\nhidden_units = [130, 130, 130, 130, 130, 130]\n#hidden_units = [260, 260, 260, 260, 260, 260]\n#dropout_rates = [0.2, 0.2, 0.2, 0.2]\ndropout_rates = [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n#dropout_rates = [0.2, 0.2, 0.2, 0.2, 0.5, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n# REDUCED LEARNING RATE\n#learning_rate = 1e-2\n\nclf = create_mlp(\n    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\n\nclf.fit(X_train, y_train, epochs=50, batch_size=5000)\n#clf.fit(X_train, y_train, epochs=200, batch_size=5000)\n#clf.fit(X_train, y_train, epochs=800, batch_size=5000)\n#clf.fit(X_train, y_train, epochs=1000, batch_size=5000)\n# time out, need to optimize if want to meet this\n#clf.fit(X_train, y_train, epochs=2000, batch_size=5000)\n\n\nmodels = []\n\nmodels.append(clf)\n\nth = 0.5000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission = True\nsubmission = False\n\nif(submission==False):\n    janestreet.make_env.__called__ = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nf = np.median\nmodels = models[-3:]\nimport janestreet\nenv = janestreet.make_env()\nif(submission==False):\n    store_data_1 = []\n    store_data_2 = []\n    store_data_3 = []\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n        pred = f(pred)\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n        pred=0\n    env.predict(pred_df)\n    if(submission==False):\n        store_data_1.append(pred_df)\n        store_data_2.append(test_df)\n        store_data_3.append(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if(submission==False):\n    df_data_1 = pd.concat(store_data_1)\n    df_data_2 = pd.concat(store_data_2)\n    df_data_2['action'] = df_data_1['action']\n    df_data_2['resp'] = store_data_3 #careful as some values are just repeat of last value sicne skipped, but we are filterin gthese out\n    train = df_data_2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"if(submission==False):\n    features = [c for c in train.columns if 'feature' in c]\n    print('Forward-Filling...')\n    train = train.query('weight > 0').reset_index(drop = True)\n    train[features] = train[features].fillna(method = 'ffill').fillna(0)\n\n    date = train['date'].values #* 1.0\n    weight = train['weight'].values #* 1.0\n    resp = train['resp'].values #* 1.0 # just doing this for now to debug... not sure if my 1 and 0 will also cause issues\n    action = train['action'].values #* 1.0\n\n\n    date = date.astype(np.int64)\n    weight = weight.astype(np.float64)\n    resp = resp.astype(np.float64)\n    action = action.astype(np.int64)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if(submission==False):\n    def utility_score_pd(date, weight, resp, action):\n        count_i = len(pd.unique(date))\n        Pi = np.bincount(date, weight * resp * action)\n        t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n        u = np.clip(t, 0, 6) * np.sum(Pi)\n        return u\n\n    def utility_score_max(date, weight, resp, action):\n        count_i = date.max() + 1\n        Pi = np.bincount(date, weight * resp * action)\n        t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n        u = np.clip(t, 0, 6) * np.sum(Pi)\n        return u\n\n    def utility_score_last(date, weight, resp, action):\n        count_i = date[-1] + 1\n        Pi = np.bincount(date, weight * resp * action)\n        t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n        u = np.clip(t, 0, 6) * np.sum(Pi)\n        return u\n\n    from numba import njit\n\n    @njit(fastmath = True)\n    def utility_score_numba(date, weight, resp, action):\n    #    import pdb;pdb.set_trace()\n        Pi = np.bincount(date, weight * resp * action)\n        t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n        u = min(max(t, 0), 6) * np.sum(Pi)\n        return u","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if(submission==False):\n    #utility_score_pd(date, weight, resp, action)\n    #utility_score_max(date, weight, resp, action)\n    #utility_score_last(date, weight, resp, action)\n    somevalue = utility_score_numba(date, weight, resp, action)\n    print(somevalue)\n    assumed_number = 400\n    print(somevalue/assumed_number) # there is some difference in this calculation and actual, so here is what we think we would get with this notebook\n    \n# 200,000 equates to about 4,000 or 5,000 on PB Leaderboard\n#200000/4000","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}