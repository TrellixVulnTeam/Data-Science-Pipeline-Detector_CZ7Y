{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport time\nimport matplotlib.pylab as plt\nfrom tqdm import tqdm\nimport pickle\n\nfrom shutil import copyfile\ncopyfile(src = \"../input/jane-multiclass-models/Models.py\", dst = \"../working/Models.py\")\n\nfrom Models import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n#DEVICE = 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(model, x):\n    x = torch.tensor(x, dtype=torch.float)\n    pred = model(x.to(DEVICE))\n    return np.mean(pred.sigmoid().detach().cpu().numpy(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\nuseless_cols = ['date', 'weight', 'ts_id']\ntarget = 'action'\nNFOLDS = 1\nModel_Root = '../input/jane-multiclass-models/'\n\n#train = pd.read_csv('../input/jane-street-market-prediction/train.csv', nrows=10000)\n#feature_cols = list(train.drop(useless_cols + target_cols, axis=1))\nwith open(Model_Root + 'feature_cols.pkl', 'rb') as handle:\n    feature_cols = pickle.load(handle)\n\nf_mean = np.load(Model_Root + 'fmean.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\n\nmodel = torch.load(Model_Root + 'FOLD_1_10.pth')\nmodels.append(model)\nfor ep in [50, 100, 150, 200]:\n    model = torch.load(Model_Root + f'FOLD_1_10_{ep}.pth')\n    models.append(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\n\ndef create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n    \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden_units = [160, 160, 160]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\nSEED=101\ntf.keras.backend.clear_session()\ntf.random.set_seed(SEED)\nclf = create_mlp(\n    len(feature_cols), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\n\nclf = load_model('../input/keras-overfitted-model/model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env()\n\n\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n\n    if test_df['weight'].item() > 0:\n        \n        x_tst = test_df.loc[:, feature_cols].values\n        \n        if np.isnan(x_tst[:, :].sum()):\n            x_tst[:, 1:] = np.nan_to_num(x_tst[:, 1:]) + np.isnan(x_tst[:, 1:]) * f_mean\n        \n        pred = np.zeros((1, len(target_cols)))\n        for model in models:\n            outs = model(torch.tensor(x_tst, dtype=torch.float).to(DEVICE))\n            label = []\n            for i in range(len(pred[0])):\n                label.append(torch.max(outs[0][i], 1)[1].unsqueeze(1))\n            label = torch.cat(label, dim=1)\n            pred += label.detach().cpu().numpy()/len(models)\n        \n        pred = np.median(pred, axis=1)\n        pred_df.action = np.where(pred > 2, 1, 0).astype(int)\n\n    else:\n\n        pred_df.action = 0\n\n    env.predict(pred_df)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}