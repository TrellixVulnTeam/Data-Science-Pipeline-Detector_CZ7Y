{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jane Street: Neural Network Starter\n\nI try implementing a simple Tensorflow Keras neural network here."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\nimport cudf\nimport pandas as pd\nimport cupy as cp\nfrom cupyx.scipy.special import erfinv\nimport numpy as np\nimport cupy as cp\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\n\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print('Loading...')\ntrain = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\nfeatures = [c for c in train.columns if 'feature' in c]\n\nprint('Filling...')\nf_mean = train[features[1:]].mean()\ntrain = train.query('weight > 0').reset_index(drop = True)\ntrain[features[1:]] = train[features[1:]].fillna(f_mean)\ntrain['action'] = (train['resp'] > 0).astype('int')\n\nprint('Converting...')\ntrain = train.to_pandas()\nf_mean = f_mean.values.get()\nnp.save('f_mean.npy', f_mean)\n\nprint('Finish.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gauss_rank_scaler(X):\n    epsilon = 1e-15\n    X = cp.asarray(X)\n    X = X.argsort().argsort()\n    X = (X / X.max() - 0.5) * 2 # Scale to (-1, 1)\n    X = cp.clip(X, -1 + epsilon, 1 - epsilon)\n    X = erfinv(X)\n    return cp.asnumpy(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in features[1:]:\n    train[col] = gauss_rank_scaler(train[col].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096\nhidden_units = [384, 896, 896, 394]\ndropout_rates = [0.10143786981358652, 0.19720339053599725, 0.2703017847244654, 0.23148340929571917, 0.2357768967777311]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\noof = np.zeros(len(train['action']))\ngkf = GroupKFold(n_splits = 5)\nfor fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n    X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n    y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n    \n    ckp_path = f'JSModel_{fold}.hdf5'\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n                            min_delta = 1e-4, mode = 'max')\n    ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n                          save_best_only = True, save_weights_only = True, mode = 'max')\n    es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                       baseline = None, restore_best_weights = True, verbose = 0)\n    model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 1000, \n              batch_size = batch_size, callbacks = [rlr, ckp, es], verbose = 2)\n                \n    oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n    score = roc_auc_score(y_val, oof[te])\n    print(f'Fold {fold} ROC AUC:\\t', score)\n    \n    # Finetune 3 epochs on validation set with small learning rate\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate / 100)\n    model.load_weights(ckp_path)\n    model.fit(X_val, y_val, epochs = 3, batch_size = batch_size, verbose = 2)\n    model.save_weights(ckp_path)\n    \n    K.clear_session()\n    del model\n    rubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_oof = roc_auc_score(train['action'].values, oof)\nprint(score_oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Models\n\nJust use three models to reduce running time."},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nfor i in range(3):\n    clf = create_mlp(len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n#     clf.load_weights(f'../input/js-nn-models/JSModel_{i}.hdf5')\n    clf.load_weights(f'./JSModel_{i}.hdf5')\n    models.append(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = np.load('./f_mean.npy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"opt_th = 0.501756827861\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        for i, clf in enumerate(models):\n            if i == 0:\n                pred = clf(x_tt, training = False).numpy().item() / len(models)\n            else:\n                pred += clf(x_tt, training = False).numpy().item() / len(models)\n#         pred = models[0](x_tt, training = False).numpy().item()\n        pred_df.action = np.where(pred >= opt_th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}