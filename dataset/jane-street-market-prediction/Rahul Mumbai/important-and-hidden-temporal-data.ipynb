{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Temporal feature inspection (Features 60-69)\n\n- Please give credit to @nanomathias for starting discussion on these features and writing code to display relationships in his notebook here: https://www.kaggle.com/nanomathias/feature-0-beyond-feature-0 \n\nFeatures 60-69 represent intraday temporal features. This notebook will give you actionable insights on these features, allowing for your own feature engineering. "},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install seaborn --upgrade --quiet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from typing import List\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"\n# Get the first 10k rows, which have not be\nordered_subset = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv', nrows=50000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature 64, and how we can use it with other features\n\nFeature 64 represents the time of day at a trade. This is a guess based on discussion from the community, information from the competition organizers, and a simple sanity check. The rows in our training data set are monotonically increasing, with every new row representing the next timestep. Feature 64 shares this... feature, only ever decreasing when a new day begins."},{"metadata":{"trusted":true},"cell_type":"code","source":"decr_64_ts_id = ordered_subset[ordered_subset['feature_64'].diff()<0]['ts_id']\n# print(decr_64_ts_id)\ndecr_64_date = []\ndate_ts_subset = pd.concat((ordered_subset['ts_id'], ordered_subset['date']),axis=1)\nfor ts_id in decr_64_ts_id:\n    dates = (date_ts_subset.loc[ts_id-1,'date'], date_ts_subset.loc[ts_id,'date'], date_ts_subset.loc[ts_id+1,'date'])\n    print(f'Date BEFORE DECREASE in 64: {dates[0]}, date AT DECREASE in 64: {dates[1]}, date AFTER DECREASE in 64: {dates[2]}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ordered_subset['ts_id'], ordered_subset['feature_64'])\nfor ts_id in decr_64_ts_id:\n    plt.axvline(ordered_subset.loc[ts_id, 'ts_id'], color='m')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Timeskip in feature 64\n\nWe also see a peculiar skip in time, with a lack of data matching the conditions: 'feature_64' > .7 and 'feature_64' < 1.3. We'll continue our visual investigation on day 0, and shift our data in regards to this skip."},{"metadata":{},"cell_type":"markdown","source":"### Features 60-68\n\nThese features all share tag 22, and show interesting dynamics. For each feature in this range, we fit and plot a Kernel Density Estimate, with accompanying scatter plots.  We do the same for each feature adjusted by feature 64. The KDEs are separated by feature 0, which significantly affects the distributions in features.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotFeatureSplits(df: pd.DataFrame, feature_list: List[int]) -> None:\n    for i in feature_list:\n        if i != 64:\n\n            # Create a plot with original timeseries, and split by feature 0\n            _, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n            # Original timeseries\n            \n            axes[0].scatter(df['ts_id'], df[f'feature_{i}'], s=.2)\n            axes[0].set_title(f'Feature {i}')\n            axes[0].set_ylabel(f'Feature {i}')\n            axes[0].set_xlabel(f'Trade ID')\n\n            # Plot by feature 0 split\n            axes[1].scatter(df['ts_id'],df['feature_64']-df[f'feature_{i}'], s=0.5,alpha=0.8)\n            axes[1].set_title(f'Feature {i}, adj by feature 64')\n            axes[1].set_ylabel(f'Feature {i}')\n            axes[1].set_xlabel(f'Trade ID')\n\n            # Show figure with legend\n            plt.legend()    \n            plt.show()\n            \n            \n\n            \n            sns.displot( data=df,x=\"ts_id\",y=f'feature_{i}', kind='kde', hue='feature_0')\n            df[f'feature _64-feature_{i}'] = df['feature_64']-df[f'feature_{i}']\n            sns.displot( data=df,x=\"ts_id\",y=f'feature _64-feature_{i}', kind='kde', hue='feature_0')\n            \n            plt.show()\n\n# Show features 60-68 and their relationship\nordered_subset['action'] = (ordered_subset['resp']>0).astype('int')\nnew = ordered_subset.copy()\nnew.loc[new['ts_id']>3255,'ts_id']+=500\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features 60-64\nThe unadjusted plot of feature 60 seems to show discrete values of feature 60, suggesting feature 60 is binned, much like an open-high-low-close (OHLC) data set may be binned. This behavior is repeated for features 61, 62, and 63. We also begin to see patterns emerging. The block of time that is not included in our dataset and that we adjusted our plots for seems to propogate, creating a streak with no points. The KDE plots show the result of this when the data, creating 3 groups: trades before the removed block, trades after the removed block and above some threshold, and trades after the removed block and below some threshold. "},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"plotFeatureSplits(new[:5587], np.arange(60, 65))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features 65-68\n\nFeature 65 doesn't have the same binned look as features 60-64. Instead, points seem to gravitate towards where feature 64 may be during the day. This may indicate tick data. We see changes in the KDE distributions as well when accounting for feature 0. The same missing data propogation phenonemon occurs, but in a slightly different manner. While I don't have much evidence for this, the different manner may indicate we have logarithmic data rather than tick data present. There are other possibilities, but we may be able to garner new insights without prodding the anonymous tags too much. The same 3 groupings are present as from features 60-64. All of these points are also varyingly applicable to features 66, 67, 68."},{"metadata":{"trusted":true},"cell_type":"code","source":"plotFeatureSplits(new[:5587], np.arange(65, 69))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n\nWe may be able to increase our model's predictive ability by incorporating the hidden information in features 60-68. Creating new features from symbolic representations between these features may provide valuable information to our neural nets, boosted trees, and simple regressors."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}