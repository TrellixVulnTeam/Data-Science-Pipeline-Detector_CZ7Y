{"cells":[{"metadata":{},"cell_type":"markdown","source":"The purpose is to perform neural network on the data provided for the Jane Street Market Prediction"},{"metadata":{},"cell_type":"markdown","source":"### Import the relevant packages an librairies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport time\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DataSets Loading "},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/jane-street-market-prediction/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv(folder_path +'train.csv' , nrows=1800000)\nfeatures_df = pd.read_csv(folder_path + 'features.csv')\nsample_df = pd.read_csv(folder_path + 'example_sample_submission.csv')\ntest_data_df = pd.read_csv(folder_path + 'example_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in train_df.columns if 'feature' in c]\nresps = [c for c in train_df.columns if 'resp' in c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df['weight'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['action'] = train_df['resp'].apply(lambda x:x>0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_median = train_df[features].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df[features].fillna(train_df_median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df['action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before we perform PCA, we need to normalise the features so that they have zero mean and unit variance\nscaler = StandardScaler()\nscaler.fit(X)\nx_norm = scaler.transform(X)\n\npca = PCA()\ncomp = pca.fit(x_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We plot a graph to show how the explained variation in the 129 features varies with the number of principal components\nplt.plot(np.cumsum(comp.explained_variance_ratio_))\nplt.grid()\nplt.xlabel('Number of Principal Components')\nplt.ylabel('Explained Variance')\nsns.despine();\n\n# The first 15 principal components explains about 80% of the variation\n# The first 40 principal components explains about 95% of the variation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=50).fit(x_norm)\nx_transform = pca.transform(x_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make the x for train and test (also called validat ion data)\nxtrain,xval, ytrain, yval = train_test_split(x_transform, y,train_size=0.5,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain[:100000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(xtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LSTM expects 3D input (examples, timestep, features)\nprint(xtrain.shape, xval.shape)\nX_train = xtrain.reshape((xtrain.shape[0], 1, xtrain.shape[1]))\nX_val = xval.reshape((xval.shape[0], 1, xval.shape[1]))\n#print(X_train.shape, X_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, xval.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### # define the keras model\nmodel = Sequential()\n#model.add(Dense(50, input_dim=50, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(42, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(36, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(24, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(16, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(8, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\nmodel = Sequential([\n    LSTM(64, input_shape=(1,50), return_sequences=True ),\n    Dropout(0.25),\n    LSTM(32, return_sequences=True),\n    Dropout(0.25),\n    LSTM(16, return_sequences=True),\n    Dropout(0.25),\n    LSTM(8, return_sequences=True),\n    Dropout(0.25),\n    Dense(1, activation='sigmoid')\n])\n# model.compile(optimizer='adam', loss='mse')\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.add(LSTM(64, batch_size=256, return_sequences = True, input_shape=(1,50)))\n#model.add(Dropout(0.2))\n\n#model.add(LSTM(32, return_sequences = True))\n#model.add(Dropout(0.2))\n\n#model.add(LSTM(16, return_sequences = True))\n#model.add(Dropout(0.2))\n\n#model.add(LSTM(8, return_sequences = True))\n#model.add(Dropout(0.2))\n#model.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntrain = tf.data.Dataset.from_tensor_slices((X_train, ytrain))\nval = tf.data.Dataset.from_tensor_slices((X_val, yval)).batch(batch_size)\ntrain = train.cache().batch(batch_size).repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile the keras model\n#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit the keras model on the dataset\n#model.fit(xtrain, ytrain,validation_data=(xval, yval), epochs=10, batch_size=batch_size)\n#model.fit(X_train, ytrain,validation_data=(X_val, yval), epochs=10, batch_size=batch_size)\nmodel.fit(train, epochs=20, steps_per_epoch=200, validation_data=val, validation_steps=50)\n# evaluate the keras model\n_, accuracy = model.evaluate(X_val, yval)\nprint('Accuracy: %.2f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Data Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillna_npwhere(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\njanestreet.competition.make_env.__called__ = False\nenv = janestreet.make_env()\n\nfrom tqdm import tqdm #\n\nstart_time = time.time()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    #x_tt = test_df.loc[:, features].values\n    #if np.isnan(x_tt[:, 1:].sum()):  # simply ignoring missing values and imediately predicting 0\n     #   pred_df.action = 0\n    wt = test_df.iloc[0].weight\n    if(wt == 0):\n        pred_df.action = 0 \n    else:\n        #pred = model(x_tt, training=False)\n        xpred = pca.transform(scaler.transform(fillna_npwhere(test_df[features].values,train_df_median[features].values)))\n        X_pred = xpred.reshape((xpred.shape[0], 1, xpred.shape[1]))\n        action = model(X_pred)\n        a = 1 if action[0][0].numpy()[0]>0.5 else 0\n        pred_df.action = np.int64(a)\n        # print(tf.make_ndarray(pred))\n        # print(xpred)\n        # pred_df.action = np.where(pred > 0.5, 1, 0).astype(int)\n    env.predict(pred_df)\nprint(f\"took: {time.time() - start_time} seconds\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}