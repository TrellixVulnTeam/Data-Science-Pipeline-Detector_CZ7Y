{"cells":[{"metadata":{},"cell_type":"markdown","source":"The purpose is to perform neural network on the data provided for the Jane Street Market Prediction"},{"metadata":{},"cell_type":"markdown","source":"### Import the relevant packages an librairies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport time\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, BatchNormalization, Dropout, Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n# !pip install tensorflow_addons\nimport tensorflow_addons as tfa\nfrom matplotlib import pyplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DataSets Loading "},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/jane-street-market-prediction/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv(folder_path +'train.csv' , nrows=1800000)\nfeatures_df = pd.read_csv(folder_path + 'features.csv')\nsample_df = pd.read_csv(folder_path + 'example_sample_submission.csv')\ntest_data_df = pd.read_csv(folder_path + 'example_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in train_df.columns if 'feature' in c]\nresps = [c for c in train_df.columns if 'resp' in c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df['weight'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['action'] = train_df['resp'].apply(lambda x:x>0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_median = train_df[features].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df[features].fillna(train_df_median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df['action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before we perform PCA, we need to normalise the features so that they have zero mean and unit variance\nscaler = StandardScaler()\nscaler.fit(X)\nx_norm = scaler.transform(X)\n\npca = PCA()\ncomp = pca.fit(x_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We plot a graph to show how the explained variation in the 129 features varies with the number of principal components\nplt.plot(np.cumsum(comp.explained_variance_ratio_))\nplt.grid()\nplt.xlabel('Number of Principal Components')\nplt.ylabel('Explained Variance')\nsns.despine();\n\n# The first 15 principal components explains about 80% of the variation\n# The first 40 principal components explains about 95% of the variation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=50).fit(x_norm)\nx_transform = pca.transform(x_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units,\n               dropout_rates, label_smoothing, learning_rate):\n  \n  inp = Input(shape=(num_columns,))\n  x = BatchNormalization()(inp)\n  x = Dropout(dropout_rates[0])(x)\n\n  for i in range(len(hidden_units)):\n    x = Dense(hidden_units[i])(x)\n    x = BatchNormalization()(x)\n    x = Activation(tf.keras.activations.swish)(x)\n    x = Dropout(dropout_rates[i+1])(x)\n\n  x = Dense(num_labels)(x)\n  out = Activation('sigmoid')(x)\n\n  model = tf.keras.models.Model(inputs=inp, outputs=out)\n  model.compile(\n      optimizer = tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n      loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n      metrics = tf.keras.metrics.AUC(name='AUC')\n  )\n\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make the x for train and test (also called validat ion data)\nxtrain,xval, ytrain, yval = train_test_split(x_transform, y,train_size=0.8,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = [400, 40] # PGTSCV folds all stopped bf. 40\nbatch_size = [4096, 8192]\nhidden_units = [160, 160, 160]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_mlp(50, 1, hidden_units,\n                      dropout_rates, label_smoothing, learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"er = EarlyStopping(patience = 8, \n                    restore_best_weights = True, \n                    monitor = 'val_loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(xtrain, ytrain,\n              validation_data = (xval, yval),\n              epochs = epochs[0],\n              batch_size = batch_size[1], callbacks = [er, mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the keras model\n_, train_accuracy = model.evaluate(xtrain, ytrain)\nprint(' Validation Accuracy: %.2f' % (train_accuracy*100))\n_, val_accuracy = model.evaluate(xval, yval)\nprint(' Validation Accuracy: %.2f' % (val_accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot training history\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Data Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillna_npwhere(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\njanestreet.competition.make_env.__called__ = False\nenv = janestreet.make_env()\n\nfrom tqdm import tqdm #\n\nstart_time = time.time()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    #x_tt = test_df.loc[:, features].values\n    #if np.isnan(x_tt[:, 1:].sum()):  # simply ignoring missing values and imediately predicting 0\n     #   pred_df.action = 0\n    wt = test_df.iloc[0].weight\n    if(wt == 0):\n        pred_df.action = 0 \n    else:\n        #pred = model(x_tt, training=False)\n        action = model(pca.transform(scaler.transform(fillna_npwhere(test_df[features].values,train_df_median[features].values))))\n        a = 1 if action[0].numpy()[0]>0.5 else 0\n        pred_df.action = np.int64(a)    \n        #pred_df.action = np.where(pred > 0.5, 1, 0).astype(int)\n    env.predict(pred_df)\nprint(f\"took: {time.time() - start_time} seconds\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}