{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\n\nimport time\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nfrom sklearn.metrics import log_loss, roc_auc_score, f1_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/jane-street-market-prediction/'\n\nBATCH_SIZE = 8192\nEPOCHS = 200\nLR = 1e-4\nWEIGHT_DECAY = 1e-5\n#EARLYSTOP_NUM = 3\nnFOLDS = 5\n\ntraining = True\nprint('Reading input data...')\ntrain = pd.read_csv(f'{DATA_PATH}train.csv',nrows=5000)\ntrain = train.query('date > 85').reset_index(drop=True)\nprint('Optimizing memory usage...')\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns})\nprint('Complete')\n\nfeat_cols = [f'feature_{i}' for i in range(130)]\ntarget_cols = ['action', 'action_1', 'action_2', 'action_3', 'action_4']\n\nall_feat_cols = [col for col in feat_cols]\nall_feat_cols.extend(['cross_41_42_43', 'cross_1_2'])\n\nf_mean = np.load('../input/f-mean/f_mean.npy')\nf_mean = np.insert(f_mean,0,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.batch_norm0 = nn.BatchNorm1d(132)\n        self.dropout0 = nn.Dropout(0.2)\n\n        dropout_rate = 0.2\n        hidden_size = 256\n        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n\n        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n\n        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n\n        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n\n        self.Relu = nn.ReLU(inplace=True)\n        self.PReLU = nn.PReLU()\n        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        # self.GeLU = nn.GELU()\n        self.RReLU = nn.RReLU()\n\n    def forward(self, x):\n        x = self.batch_norm0(x)\n        x = self.dropout0(x)\n\n        x1 = self.dense1(x)\n        x1 = self.batch_norm1(x1)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x1 = self.LeakyReLU(x1)\n        x1 = self.dropout1(x1)\n\n        x = torch.cat([x, x1], 1)\n\n        x2 = self.dense2(x)\n        x2 = self.batch_norm2(x2)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x2 = self.LeakyReLU(x2)\n        x2 = self.dropout2(x2)\n\n        x = torch.cat([x1, x2], 1)\n\n        x3 = self.dense3(x)\n        x3 = self.batch_norm3(x3)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x3 = self.LeakyReLU(x3)\n        x3 = self.dropout3(x3)\n\n        x = torch.cat([x2, x3], 1)\n\n        x4 = self.dense4(x)\n        x4 = self.batch_norm4(x4)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x4 = self.LeakyReLU(x4)\n        x4 = self.dropout4(x4)\n\n        x = torch.cat([x3, x4], 1)\n\n        x = self.dense5(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\")\nmodel_list = {}\nweights = {'M_1':0.5,'M_3':0.5}\n\nfor _fold in range(nFOLDS):\n    if _fold == 1 or _fold == 3:\n        model_name = f\"M_{_fold}\"\n        torch.cuda.empty_cache()\n        model = Model().to(device)\n        model.load_state_dict(torch.load(\"../input/resnetoverfit/online_model_v3_{}.pkl\".format(_fold)))\n        model.eval()\n        model_list[model_name] = {\"model\":model,\"weight\":weights[model_name]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df,pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        \n\n        x_tt = test_df.loc[:, feat_cols].values\n        if np.isnan(x_tt.sum()):\n             x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n\n        cross_41_42_43 = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n        cross_1_2 = x_tt[:, 1] / (x_tt[:, 2] + 1e-5)\n        feature_inp = np.concatenate((\n            x_tt,\n            np.array(cross_41_42_43).reshape(x_tt.shape[0], 1),\n            np.array(cross_1_2).reshape(x_tt.shape[0], 1),\n        ), axis=1)\n            \n        pred = np.zeros((1, len(target_cols)))\n        for model in model_list:\n            pred+=model_list[model]['model'](torch.tensor(feature_inp,dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy() * model_list[model]['weight']\n        #pred = neutralize(test_df,pred,features)    \n        pred = np.median(pred)\n        pred_df.action = np.where(pred >= 0.503,1,0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}