{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nfrom sklearn.metrics import log_loss, roc_auc_score, f1_score, accuracy_score\nimport sklearn.metrics as sk_metrics\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nimport xgboost as xgb\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN = False\nprint('Reading input data...')\ntrain = pd.read_csv('../input/jane-street-market-prediction/train.csv',nrows=100)\ntrain = train.query('date > 85').reset_index(drop=True)\nprint('Optimizing memory usage...')\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns})\nprint('Complete')\nfeatures = [c for c in train.columns if 'feature' in c]\nf_mean = np.load('../input/onlinefmean/f_mean_online.npy')\ntrain[features] = train[features].fillna(method='ffill').fillna(0)\ntrain = train.query('weight > 0').reset_index(drop=True)\ntrain['action'] = (train['resp'] > 0).astype('int')\ntrain['action_1'] = (train['resp_1'] > 0).astype('int')\ntrain['action_2'] = (train['resp_2'] > 0).astype('int')\ntrain['action_3'] = (train['resp_3'] > 0).astype('int')\ntrain['action_4'] = (train['resp_4'] > 0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = [col for col in features]\ntarget_cols = [target for target in train.columns if 'action' in target]\nfeat_cols= [col for col in features]\n    \ntrain['cross_41_42_43'] = train['feature_41'] + train['feature_42'] + train['feature_43']\n    \ntrain['cross_1_2'] = train['feature_1'] / (train['feature_2'] + 1e-5)\n   \nfeat_cols.extend(['cross_41_42_43','cross_1_2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.batch_norm0 = nn.BatchNorm1d(len(feat_cols))\n        self.dropout0 = nn.Dropout(0.2)\n\n        dropout_rate = 0.2\n        hidden_size = 256\n        self.dense1 = nn.Linear(len(feat_cols), hidden_size)\n        nn.init.kaiming_normal_(self.dense1.weight,mode='fan_out')\n        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n\n        self.dense2 = nn.Linear(hidden_size+len(feat_cols), hidden_size)\n        nn.init.kaiming_normal_(self.dense2.weight,mode='fan_out')\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        nn.init.kaiming_normal_(self.dense3.weight,mode='fan_out')\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n\n        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        nn.init.kaiming_normal_(self.dense4.weight,mode='fan_out')\n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n\n        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n        nn.init.kaiming_normal_(self.dense5.weight,mode='fan_out')\n\n        self.Relu = nn.ReLU(inplace=True)\n        self.PReLU = nn.PReLU()\n        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        # self.GeLU = nn.GELU()\n        self.RReLU = nn.RReLU()\n\n    def forward(self, x):\n        x = self.batch_norm0(x)\n        x = self.dropout0(x)\n\n        x1 = self.dense1(x)\n        x1 = self.batch_norm1(x1)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x1 = self.LeakyReLU(x1)\n        x1 = self.dropout1(x1)\n\n        x = torch.cat([x, x1], 1)\n\n        x2 = self.dense2(x)\n        x2 = self.batch_norm2(x2)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x2 = self.LeakyReLU(x2)\n        x2 = self.dropout2(x2)\n\n        x = torch.cat([x1, x2], 1)\n\n        x3 = self.dense3(x)\n        x3 = self.batch_norm3(x3)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x3 = self.LeakyReLU(x3)\n        x3 = self.dropout3(x3)\n\n        x = torch.cat([x2, x3], 1)\n\n        x4 = self.dense4(x)\n        x4 = self.batch_norm4(x4)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x4 = self.LeakyReLU(x4)\n        x4 = self.dropout4(x4)\n\n        x = torch.cat([x3, x4], 1)\n\n        x = self.dense5(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')\nmodel_list = []\nfor model in range(5):\n    resnet = Model().to(device)\n    resnet_weights = f'../input/resnet-v7/model_v7_{model}.pkl'\n    resnet.load_state_dict(torch.load(resnet_weights))\n    resnet.eval()\n    model_list.append(resnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_dist = {\n    'objective':'binary:logistic',\n    'n_estimators':300,\n    'tree_method':'gpu_hist',\n    'colsample_bytree':.1162\n}\n\nclf = xgb.XGBClassifier(**param_dist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.load_model('../input/metaxgbv4/XGB_Meta_Classifier_v4.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env()\nenv_iter = env.iter_test()\n\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, feats].values\n        if np.isnan(x_tt.sum()):\n            x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n\n        cross_41_42_43 = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n        cross_1_2 = x_tt[:, 1] / (x_tt[:, 2] + 1e-5)\n        feature_inp = np.concatenate((\n            x_tt,\n            np.array(cross_41_42_43).reshape(x_tt.shape[0], 1),\n            np.array(cross_1_2).reshape(x_tt.shape[0], 1),\n        ), axis=1)\n\n        pred = np.zeros((1, len(target_cols)))\n        for model in model_list:\n            pred += model(torch.tensor(feature_inp, dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy() / len(model_list)\n        pred = np.median(pred)\n        prediction_int = np.where(pred >= 0.5, 1, 0).astype(int).reshape((-1,1))\n        new_features = np.concatenate((prediction_int,feature_inp),axis=1)\n        meta_predictions = clf.predict(new_features)\n        pred_df.action = (meta_predictions&prediction_int.flatten())\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}