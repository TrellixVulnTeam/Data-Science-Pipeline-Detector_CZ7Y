{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import datatable as dt\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.optim.lr_scheduler import _LRScheduler\nimport janestreet\nfrom tqdm import tqdm\nimport pandas as pd\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dt.fread('/kaggle/input/jane-street-market-prediction/train.csv')\ndata = data.to_pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ignore_columns = ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp','ts_id','date']\nfeatures = [col for col in data.columns if col not in ignore_columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"data = data.fillna(method='ffill').fillna(method='bfill')\ndata['action'] = (data['resp'] > 0).astype('int')\ndata = data.drop(columns=ignore_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Timeseries_Dataset(Dataset):\n    \"\"\"\n    Custom Dataset subclass.\n    Serves as input to DataLoader to transform X\n      into sequence data using rolling window.\n    DataLoader using this dataset will output batches\n      of `(batch_size, seq_len, n_features)` shape.\n    Suitable as an input to RNNs.\n    \"\"\"\n\n    def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 32):\n        self.X = torch.tensor(X).float()\n        self.y = torch.tensor(y).float()\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return self.X.__len__() - (self.seq_len - 1)\n\n    def __getitem__(self, index):\n        return {'x': torch.tensor(self.X[index:index + self.seq_len], dtype=torch.float),\n                'y': torch.tensor(self.y[index + self.seq_len - 1], dtype=torch.long)}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n    \n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        h0, c0 = self.init_hidden(x)\n        out, (hn, cn) = self.rnn(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out\n    \n    def init_hidden(self, x):\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n        return [t.to(device) for t in (h0, c0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096\nlr = 0.0005\ninput_dim = 131\nhidden_dim = 256\nlayer_dim = 5\noutput_dim = 2\nseq_dim = 32\ntarget_column = 'action'\n\nfeature_columns = data.columns[~data.columns.isin([target_column])]\ntrain, validation = data[:int(len(data) * 0.8)], data[int(len(data) * 0.2):]\ntrain_features, train_target = train[feature_columns], train[[target_column]]\nvalidation_features, validation_target = validation[feature_columns], validation[[target_column]]\ntrain_dataset = Timeseries_Dataset(X=train_features.values, y=train_target.values, seq_len=seq_dim)\nvalidation_dataset = Timeseries_Dataset(X=validation_features.values, y=validation_target.values, seq_len=seq_dim)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\nvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight = '/kaggle/input/weight-lstm/best_30.pth'\n\nphase_training = True\nif os.path.exists(weight):\n    phase_training = False\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\nmodel = model.to(device)\nif phase_training:\n    iterations_per_epoch = len(train_loader)\n    num_epochs = 30\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n    print('Start model training ...')\n    best_acc = 0.0\n    patience, trials = 100, 0\n    for epoch in range(1, num_epochs + 1):\n        for i, train_batch in enumerate(validation_loader):\n            model.train()\n            features = train_batch['x'].to(device)\n            targets = train_batch['y'].to(device)\n            targets = torch.squeeze(targets)\n            preds = model(features)\n            loss = criterion(preds, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        print(f'Epoch {epoch} best model saved with loss: {loss:2.2}')\n\n        model.eval()\n        correct, total = 0, 0\n        for valid_batch in validation_loader:\n            features = valid_batch['x'].to(device)\n            targets = valid_batch['y'].to(device)\n            targets = torch.squeeze(targets)\n            preds = model(features)\n            preds = F.log_softmax(preds, dim=1).argmax(dim=1)\n            total += targets.size(0)\n            correct += (preds == targets).sum().item()\n\n        acc = correct / total\n\n        if epoch % 5 == 0:\n            print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n\n        if acc > best_acc:\n            trials = 0\n            best_acc = acc\n            torch.save(model.state_dict(), 'best.pth')\n            print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n        else:\n            trials += 1\n            if trials >= patience:\n                print(f'Early stopping on epoch {epoch}')\n                break\n    print('Training Complete !!!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if phase_training:\n    model.load_state_dict(torch.load('best.pth'))\nelse:\n    model.load_state_dict(torch.load(weight))\n    \nmodel.eval()\nX_test = None\nenv = janestreet.make_env()\nenv_iter = env.iter_test()\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        test_df = pd.DataFrame(test_df, columns=feature_columns)\n        test_df = test_df.fillna(method='ffill').fillna(method='bfill')\n        if X_test is None:\n            X_test = np.concatenate([test_df for _ in range(seq_dim)],axis=0)\n        X_test = np.concatenate([X_test[1:], test_df] ,axis=0)\n        preds = model(torch.tensor(X_test[np.newaxis,:], dtype=torch.float).to(device))\n        preds = preds.cpu().detach().numpy()\n        action = ((test_df['weight'].values * preds[:, 1]) > 0).astype('int')\n        pred_df.action = action\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}