{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How to validate a model on chronologically ordered data which also contains groups?\nSince it takes quite some time to get a utility (leaderboard) score back for our model, it would be nice to be able to 'locally' calculate an indication of a model's performance; independent of the (time expensive and limited) submission API. This would allow for much better tuning of hyper-parameters or other aspects of the model's training process.\n\nIn this notebook I want to lay out a couple of techniques that can be used to do this. For every step we will see that there is a problem with using it for this particular competition. Fortunately the last chapter provides a solution! If you are not interested in an introduction in test and validation techniques, then skip to the bottom. First up: train and test subsets."},{"metadata":{},"cell_type":"markdown","source":"i use this notebook for reference https://www.kaggle.com/gogo827jz/jane-street-neural-network-starter"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Import Libraries 📚**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\n# import cudf\nimport pandas as pd\nimport numpy as np\n# import cupy as cp\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\nimport seaborn as sns\n\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing Data ✍**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\nfeatures = [c for c in train.columns if 'feature' in c]\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Understanding Data Features 📈**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Features Correlation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = train.corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(16, 16))\nsns.heatmap(correlations)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Missing Values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Missing Values\nprint('Train Nan Valued colas: %d' %train.isna().any().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = 40\nnan_val = train.isna().sum()[train.isna().sum() > 0].sort_values(ascending=False)\nprint(nan_val)\n\n\nfig, axs = plt.subplots(figsize=(10, 10))\n\nsns.barplot(y = nan_val.index[0:n_features], \n            x = nan_val.values[0:n_features], \n            alpha = 0.8\n           )\n\nplt.title(f'NaN values of train dataset (Top {n_features})')\nplt.xlabel('NaN values')\nfig.savefig(f'nan_values_top_{n_features}_features.png')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exploratory Data Analysis 📊**"},{"metadata":{},"cell_type":"markdown","source":"**Weight and Resp Distribution Plots**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(16, 6))\nsns.distplot(train['resp'], ax=axs[0])\nsns.distplot(train['weight'], ax=axs[1])\nfig.savefig('resp_weight_distplot.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16, 8))\n\nresp = train['resp'].cumsum()\nresp_1 = train['resp_1'].cumsum()\nresp_2 = train['resp_2'].cumsum()\nresp_3 = train['resp_3'].cumsum()\nresp_4 = train['resp_4'].cumsum()\n\nresp.plot(linewidth=2)\nresp_1.plot(linewidth=2)\nresp_2.plot(linewidth=2)\nresp_3.plot(linewidth=2)\nresp_4.plot(linewidth=2)\n\nax.set_xlabel (\"Trade\", fontsize=12)\nax.set_title (\"Cumulative Trade returns\", fontsize=18)\n\nplt.legend(loc=\"upper left\");\nplt.savefig('cummulative_trade_growth.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Resp Violin Plots**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16, 12))\nsns.violinplot(data=train[[\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]], \n               inner=\"points\", \n               linewidth=1, \n               palette=\"Set3\", \n               ax=ax)    \nfig.savefig('resp_violinplot.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Understanding Data Spread**"},{"metadata":{},"cell_type":"markdown","source":"***preprocessing***"},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = train[features[1:]].mean()\ntrain = train.query('weight > 0').reset_index(drop = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[features[1:]] = train[features[1:]].fillna(f_mean)\ntrain['action'] = (train['resp'] > 0).astype('int')\nnp.save('f_mean.npy', f_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **validation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096\nhidden_units = [384, 896, 896, 394]\ndropout_rates = [\n    0.10143786981358652,\n    0.19720339053599725,\n    0.2703017847244654,\n    0.23148340929571917,\n    0.2357768967777311,\n]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-7\n\noof = np.zeros(len(train['action']))\ngkf = GroupKFold(n_splits = 5)\nfor fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n    X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n    y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n    \n    ckp_path = f'JSModel_{fold}.hdf5'\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n                            min_delta = 1e-4, mode = 'max')\n    ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n                          save_best_only = True, save_weights_only = True, mode = 'max')\n    es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                       baseline = None, restore_best_weights = True, verbose = 0)\n    model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 1000, \n              batch_size = batch_size, callbacks = [rlr, ckp, es], verbose = 0)\n                \n    oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n    score = roc_auc_score(y_val, oof[te])\n    print(f'Fold {fold} ROC AUC:\\t', score)\n    \n    # Finetune 3 epochs on validation set with small learning rate\n    model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate / 100)\n    model.load_weights(ckp_path)\n    model.fit(X_val, y_val, epochs = 4, batch_size = batch_size, verbose = 0)\n    model.save_weights(ckp_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_oof = roc_auc_score(train['action'].values, oof)\nprint(score_oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Load model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_models = 2\n\nmodels = []\nfor i in range(num_models):\n    clf = create_mlp(len(features), 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    clf.load_weights(f'./JSModel_{i}.hdf5')\n    models.append(clf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = np.load('./f_mean.npy')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Submitting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt_th =  0.502\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = 0.\n        for clf in models:\n            pred += clf(x_tt, training = False).numpy().item() / num_models\n        pred_df.action = np.where(pred >= opt_th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}