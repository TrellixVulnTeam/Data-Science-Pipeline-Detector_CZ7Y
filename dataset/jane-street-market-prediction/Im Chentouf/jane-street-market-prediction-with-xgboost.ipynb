{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import The Libraries Needed"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#import datatable as dt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import The data\n**Load the data**"},{"metadata":{},"cell_type":"markdown","source":"If we try to read with pandas it will take a long time, The opperation is faster on Datatable , we can try with Datatable but it will bring us in a memory problem .The notebook will try to allocate more memory than is available."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndata_train = pd.read_csv(\"../input/jane-street-market-prediction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In Pandas it will take approximately 1min 40s"},{"metadata":{},"cell_type":"markdown","source":"Method: Datatable\n\n![](https://i.ibb.co/V9S7jRH/0-w7dsj-AY9-CKNY7ow-L.png)\n\nDatatable (heavily inspired by R's data.table) can read large datasets fairly quickly and is often faster than pandas. It is specifically meant for data processing of tabular datasets with emphasis on speed and support for large sized data.\n\nDocumentation: https://datatable.readthedocs.io/en/latest/index.html"},{"metadata":{},"cell_type":"markdown","source":"install datatable"},{"metadata":{},"cell_type":"markdown","source":"**Read The Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n\n#data = dt.fread(\"../input/jane-street-market-prediction/train.csv\")\n\n#print(\"Train size:\", data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" It contains 2390491 datapoints in 138 unique columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#column names\ndata_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The types of columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# column types\ndata_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the missing data "},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_count = data_train.isnull().sum()\nmissing_values_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cells_data = np.product(data_train.shape)\ntotal_missing_data = missing_values_count.sum()\nprint (\"The percentage of missing data = \",(total_missing_data/total_cells_data) * 100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Why replacing with -999**  >  [Reference](https://stats.stackexchange.com/questions/225175/why-do-some-people-use-999-or-9999-to-replace-missing-values/225179)\n\nAnd since our data is distributed far from -999 we can replace it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data_train.fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data_train[data_train['weight'] != 0]\ndata_train['action'] = ((data_train['weight'].values * data_train['resp'].values) > 0).astype('int')\ndata_train['action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# splitting The Train data"},{"metadata":{},"cell_type":"markdown","source":"This dataset contains an anonymized set of features, feature_{0...129}, representing real stock market data. Each row in the dataset represents a trading opportunity, for which you will be predicting an action value: 1 to make the trade and 0 to pass on it. Each trade has an associated weight and resp, which together represents a return on the trade. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_train.loc[:, data_train.columns.str.contains('feature')]\ny_train = data_train.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Predictions with XGBoost Model"},{"metadata":{},"cell_type":"markdown","source":"**What is XGBoost**?\n\nXGBoost stands for eXtreme Gradient Boosting.\n\nThe name xgboost, though, actually refers to the engineering goal to push the limit of computations resources for boosted tree algorithms. Which is the reason why many people use xgboost.\n\n\nIt is an implementation of gradient boosting machines created by Tianqi Chen, now with contributions from many developers. It belongs to a broader collection of tools under the umbrella of the Distributed Machine Learning Community or DMLC who are also the creators of the popular mxnet deep learning library.\n\nTianqi Chen provides a brief and interesting back story on the creation of XGBoost in the post Story and Lessons Behind the Evolution of XGBoost.\n\nXGBoost is a software library that you can download and install on your machine, then access from a variety of interfaces. Specifically, XGBoost supports the following main interfaces:\n\n* Command Line Interface (CLI).\n* C++ (the language in which the library is written).\n* Python interface as well as a model in scikit-learn.\n* R interface as well as a model in the caret package.\n* Julia.\n* Java and JVM languages like Scala and platforms like Hadoop.\n\n**XGBoost Features**:\n\nThe library is laser focused on computational speed and model performance, as such there are few frills. Nevertheless, it does offer a number of advanced features.\n\n[Reference: To get More](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model no training data\nmodel = xgb.XGBClassifier(\n    n_estimators=480,\n    max_depth=10,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the XGBoost Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%time \nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_prediction_df  = pd.read_csv(\"../input/jane-street-market-prediction/example_sample_submission.csv\")\ndata_test= pd.read_csv(\"../input/jane-street-market-prediction/example_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make The environement"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\n# initiation of the environment\nenv = janestreet.make_env()\n# an iterator to loops over the test set\niter_test = env.iter_test() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**iter_test** function is:\n\nGenerator which loops through each rushing play in the test set and provides the observations at TimeHandoff just like the training set. Once you call predict to make your yardage prediction, you can continue on to the next play."},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    #We will specify the X_test from our test data (features)\n    X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n    #Replace the missing value with -999\n    X_test.fillna(-999)\n    #Predict using our X_test\n    y_preds = model.predict(X_test)\n    #Make / store our prediction results in sample_pred_df\n    sample_prediction_df.action = y_preds\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}