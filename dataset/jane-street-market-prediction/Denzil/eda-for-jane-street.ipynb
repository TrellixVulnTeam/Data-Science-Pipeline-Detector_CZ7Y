{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.plotting.backend = \"plotly\"\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"input_folder='/kaggle/input/jane-street-market-prediction/'\ntraining_path = input_folder+'train.csv'\nfeatures_path = input_folder+'features.csv'\ntesting_path = input_folder+'example_test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install datatable\nimport datatable as dt\nimport matplotlib.pyplot as plt\nimport seaborn as sns  \nimport plotly.offline as py\n\nimport plotly.express as px\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.subplots import make_subplots\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_df_full = dt.fread(training_path).to_pandas()\n\n# test_df = dt.fread(testing_path).to_pandas()\n# features_df = dt.fread(features_path).to_pandas()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the shapes of the respectives dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"save = 'Testing'\nif save == 'Testing':\n    train_df = train_df_full.head(10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training dataframe')\nprint(f'Number of Columns : {len(train_df.columns)}')\nprint(f'Number of Rows: {len(train_df.index)}\\n')\n\n# print('Features dataframe shape')\n# print(f'Number of Columns : {len(features_df/.columns)}')\n# print(f'Number of Rows: {len(features_df.index)}\\n')\n\n# print('Testing dataframe')\n# print(f'Number of Columns : {len(test_df.columns)}')\n# print(f'Number of Rows: {len(test_df.index)}\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define Action for the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"actn = ((train_df['weight'].values * train_df['resp'].values) > 0).astype('int')\ntrain_df = train_df.assign(action = actn)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at the training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_missing_values(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return tt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_missing  = count_missing_values(train_df)\ntrain_missing = train_missing[train_missing.Total !=0]\n\nbars=go.Bar(x=train_missing.index.values,y=train_missing.Total,name = 'Total')\nline = go.Scatter(x=train_missing.index.values,y=train_missing.Percent,name = 'Percent')\nfig = make_subplots(specs=[[{\"secondary_y\": True}]], print_grid=True)\nfig.add_trace(bars, 1, 1, secondary_y=False)\nfig.add_trace(line, 1, 1, secondary_y=True)\nfig.update_layout(\n    title=\"Missing Values\",\n    xaxis_title=\"Column Names\",\n    yaxis_title=\"Number of Missing Values\",\n    legend_title=\"Legend\",\n    \n)\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns with more than 25% missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_missing = []\nfor idx,i in train_missing['Percent'].iteritems():\n \n    if i > 5:\n        columns_missing.append([idx, i])\n        \nprint(*columns_missing,sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resp = []\nsubset = train_df[train_df.columns[0:7]]\n\nfor col in subset.columns[2:]:\n#     resp.append(go.Scatter(\n#         x=pd.Series(train_df[col].cumsum()), name = col\n#         ))\n    resp.append(go.Scatter(y=pd.Series(subset[col].cumsum()),\n        name = col\n    ))\nlayout = go.Layout(dict(title = \"Cummulative sum of responses\",\n                  yaxis = dict(title = 'Response'),\n                  ),legend=dict(\n                orientation=\"h\"))\n        \npy.iplot(dict(data=resp, layout=layout), filename='basic-line')   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HeatMap\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_to_heatmap(df):\n    \n    return {       'y': df.columns.values,\n            'x': df.columns.values,\n           'z':df.corr().values}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_test = train_df.head(10)\n\nfigure = go.Figure(go.Heatmap(df_to_heatmap(train_df_test)))\nfigure.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig  = px.bar(train_df['action'].value_counts(),x='action', color='action')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Violin and Histograms of all the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfig = make_subplots(rows=len(train_df.columns), cols=2,vertical_spacing = 0.5/len(train_df.columns))\n\ncolor1 = '#9467bd'\ncolor2 = '#F08B00'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx,col in enumerate(train_df.columns):\n#     print(idx,col)\n    fig.add_trace( go.Scatter(\n        y = train_df[col],\n        name=col,\n        mode = 'markers',\n        line = dict(\n            color = color1\n        )),row = idx+1, col =1)\n    fig.add_trace( go.Violin(y=train_df[col],name=col),row=idx+1,col=2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig['layout'].update(height=100000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.loc[:, train_df.columns.str.contains('feature')]\nX = X_train.fillna(X_train.mean())\n# our target is the action\ny = train_df['action']\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(max_features='auto')\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npreds = classifier.predict(X_valid)\nprint('Score: {}'.format(accuracy_score(preds, y_valid)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}