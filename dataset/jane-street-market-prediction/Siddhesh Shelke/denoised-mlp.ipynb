{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, gc\nimport pandas as pd\nimport numpy as np\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\nimport tensorflow as tf\nimport kerastuner as kt\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tqdm import tqdm\nfrom random import choices","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAINING = False\nUSE_FINETUNE = False     \nFOLDS = 4\nSEED = 42\n\ntrain = pd.read_csv('../input/jane-street-market-prediction/train.csv')\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\ntrain.fillna(train.mean(),inplace=True)\ntrain = train.query('weight > 0').reset_index(drop = True)\n#train['action'] = (train['resp'] > 0).astype('int')\ntrain['action'] =  (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   ).astype('int')\nfeatures = [c for c in train.columns if 'feature' in c]\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX = train[features].values\ny = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n\nf_mean = np.mean(train[features[1:]].values,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_autoencoder(input_dim,output_dim,noise=0.05):\n    i = Input(input_dim)\n    encoded = BatchNormalization()(i)\n    encoded = GaussianNoise(noise)(encoded)\n    encoded = Dense(64,activation='relu')(encoded)\n    decoded = Dropout(0.2)(encoded)\n    decoded = Dense(input_dim,name='decoded')(decoded)\n    x = Dense(32,activation='relu')(decoded)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    x = Dense(32,activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)    \n    x = Dense(output_dim,activation='sigmoid',name='label_output')(x)\n    \n    encoder = Model(inputs=i,outputs=encoded)\n    autoencoder = Model(inputs=i,outputs=[decoded,x])\n    \n    autoencoder.compile(optimizer=Adam(0.005),loss={'decoded':'mse','label_output':'binary_crossentropy'})\n    return autoencoder, encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_dim,output_dim,encoder):\n    inputs = Input(input_dim)\n    \n    x = encoder(inputs)\n    x = Concatenate()([x,inputs])\n    x = BatchNormalization()(x)\n    x = Dropout(0.13)(x)\n    \n    hidden_units = [384, 896, 896, 394]\n    for idx, hidden_unit in enumerate(hidden_units):\n        x = Dense(hidden_unit)(x)\n        x = BatchNormalization()(x)\n        x = Lambda(tf.keras.activations.relu)(x)\n        x = Dropout(0.25)(x)\n    x = Dense(output_dim,activation='sigmoid')(x)\n    model = Model(inputs=inputs,outputs=x)\n    model.compile(optimizer=Adam(0.0005),loss=BinaryCrossentropy(label_smoothing=0.05),metrics=[tf.keras.metrics.AUC(name = 'auc')])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder, encoder = create_autoencoder(X.shape[-1],y.shape[-1],noise=0.1)\nif TRAINING:\n    autoencoder.fit(X,(X,y),\n                    epochs=1000,\n                    batch_size=4096, \n                    validation_split=0.1,\n                    callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n    encoder.save_weights('./encoder.hdf5')\nelse:\n    encoder.load_weights('../input/janestreetmodels/encoder.hdf5')\nencoder.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLDS = 4\nSEED = 42\n\nif TRAINING:\n    gkf = PurgedGroupTimeSeriesSplit(n_splits = FOLDS, group_gap=20)\n    splits = list(gkf.split(y, groups=train['date'].values))\n\n    for fold, (train_indices, test_indices) in enumerate(splits):\n        model = create_model(130, 5, encoder)\n        X_train, X_test = X[train_indices], X[test_indices]\n        y_train, y_test = y[train_indices], y[test_indices]\n        model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=4096,callbacks=[EarlyStopping('val_auc',mode='max',patience=10,restore_best_weights=True)])\n        model.save_weights(f'./model_{SEED}_{fold}.hdf5')\n        model.compile(Adam(0.00001),loss='binary_crossentropy')\n        model.fit(X_test,y_test,epochs=3,batch_size=4096)\n        model.save_weights(f'./model_{SEED}_{fold}_finetune.hdf5')\nelse:\n    models = []\n    for f in range(FOLDS):\n        model = create_model(130, 5, encoder)\n        if USE_FINETUNE:\n            model.load_weights(f'../input/janestreetmodels/model_{SEED}_{f}_finetune.hdf5')\n        else:\n            model.load_weights(f'../input/janestreetmodels/model_{SEED}_{f}.hdf5')\n        models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not TRAINING:\n    f = np.median\n    models = models[-2:]\n    import janestreet\n    env = janestreet.make_env()\n    th = 0.502\n    for (test_df, pred_df) in tqdm(env.iter_test()):\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, features].values\n            if np.isnan(x_tt[:, 1:].sum()):\n                x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n            pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n            pred = f(pred)\n            pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}