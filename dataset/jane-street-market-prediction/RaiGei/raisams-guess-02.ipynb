{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:47:47.137246Z","iopub.status.busy":"2021-01-24T20:47:47.136428Z","iopub.status.idle":"2021-01-24T20:47:49.62469Z","shell.execute_reply":"2021-01-24T20:47:49.62539Z"},"papermill":{"duration":2.515915,"end_time":"2021-01-24T20:47:49.625583","exception":false,"start_time":"2021-01-24T20:47:47.109668","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport missingno as msn\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport datatable as dt\nimport seaborn as sns\nfrom numba import njit","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:47:49.673811Z","iopub.status.busy":"2021-01-24T20:47:49.672932Z","iopub.status.idle":"2021-01-24T20:47:49.681147Z","shell.execute_reply":"2021-01-24T20:47:49.680386Z"},"papermill":{"duration":0.033074,"end_time":"2021-01-24T20:47:49.681294","exception":false,"start_time":"2021-01-24T20:47:49.64822","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# notebook created by R. Geiges 200119\n# implementing a simple serial NN with feature engineering and normaization\n# highly correlated features are combined\nccut = 0.975\ndropout = 0.2\ndateCut = 'date > 85'\nnepochs = 140\nprint(\"Running prediction with correlation cutoff: \", ccut)\nprint('Layer dropouts set to: ', dropout)\nrunjane = True","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:47:49.716608Z","iopub.status.busy":"2021-01-24T20:47:49.71568Z","iopub.status.idle":"2021-01-24T20:47:49.732079Z","shell.execute_reply":"2021-01-24T20:47:49.732681Z"},"papermill":{"duration":0.03556,"end_time":"2021-01-24T20:47:49.732835","exception":false,"start_time":"2021-01-24T20:47:49.697275","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"if runjane :\n    print('# File sizes')\n    total_size = 0\n    start_path = '../input/jane-street-market-prediction'  # To get size of current directory\n    for path, dirs, files in os.walk(start_path):\n        for f in files:\n            fp = os.path.join(path, f)\n            total_size += os.path.getsize(fp)\n    print(\"Directory size: \" + str(round(total_size/ 1000000, 2)) + 'MB')\n    # load training data\n    train_raw = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\n#featureData = pd.read_csv('../input/jane-street-market-prediction/features.csv')\n# example_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\n# sample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nelse :\n    train_raw = pd.read_csv('train85_100k.csv')\n\nprint (\"Data is loaded\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:50:34.816773Z","iopub.status.busy":"2021-01-24T20:50:34.815888Z","iopub.status.idle":"2021-01-24T20:50:36.286294Z","shell.execute_reply":"2021-01-24T20:50:36.284941Z"},"papermill":{"duration":1.488938,"end_time":"2021-01-24T20:50:36.286404","exception":false,"start_time":"2021-01-24T20:50:34.797466","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# eliminate first 85 days\nprint(\"Reading in data with cutoff: \", dateCut)\ntrain_raw=train_raw.query( dateCut ).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:50:36.633362Z","iopub.status.busy":"2021-01-24T20:50:36.34102Z","iopub.status.idle":"2021-01-24T20:50:45.881908Z","shell.execute_reply":"2021-01-24T20:50:45.881037Z"},"papermill":{"duration":9.578806,"end_time":"2021-01-24T20:50:45.882039","exception":false,"start_time":"2021-01-24T20:50:36.303233","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# build list of feature columns\nfeatures = [c for c in train_raw.columns if 'feature' in c]\n# ignore feature_0\nfeatures.remove('feature_0')\nfeatures.remove('feature_41')\nfeatures.remove('feature_42')\nfeatures.remove('feature_43')\ntrain_raw.describe()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:50:45.946572Z","iopub.status.busy":"2021-01-24T20:50:45.945928Z","iopub.status.idle":"2021-01-24T20:50:45.95123Z","shell.execute_reply":"2021-01-24T20:50:45.952781Z"},"papermill":{"duration":0.04427,"end_time":"2021-01-24T20:50:45.952969","exception":false,"start_time":"2021-01-24T20:50:45.908699","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%time\n#Function to reduce memory usage. from Kaggle -> maxwienandts\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df \n\n\n\n#train_raw = reduce_mem_usage(train_raw)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.017894,"end_time":"2021-01-24T20:50:45.990126","exception":false,"start_time":"2021-01-24T20:50:45.972232","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# create correlated feature tree\n# print(features)\ncorrel= train_raw[features].corr().abs()\ncorrel[correl == 1] = 0\n# drop lower triangle of matrix\nfor i in range(len(correl)) :\n    for j in range(i) :\n        correl.iat[j,i] = 0\n# print(correl.head())        \ncflist = correl.unstack().sort_values(ascending=False).drop_duplicates()\n# combine features with correlation bigger than ccut\ncflcut = cflist[cflist > ccut]\ncflcutis = cflcut.index\nprint(\"List of correlated features with absolute value > \", ccut)\nfeat2drop = []\nprint(\"Building list of features to drop\")\nfor i in range(len(cflcutis)) :\n    print(\"Index: %s , value: %f \" % (cflcutis[i] , cflcut[i]))\n    if not(cflcutis[i][1] in feat2drop) :\n        feat2drop.append(cflcutis[i][1])\n                \nprint(\"Features to drop: \", len(feat2drop))\nprint(feat2drop)\n# remove feature from feature index list\nfor feat in feat2drop:\n    features.remove(feat)\nprint(\"Number of remaining features is: \", len(features))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:50:46.072802Z","iopub.status.busy":"2021-01-24T20:50:46.072164Z","iopub.status.idle":"2021-01-24T20:50:51.569697Z","shell.execute_reply":"2021-01-24T20:50:51.570414Z"},"papermill":{"duration":5.524448,"end_time":"2021-01-24T20:50:51.570559","exception":false,"start_time":"2021-01-24T20:50:46.046111","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(\"Building model and stetting up training now!\")\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:50:51.612779Z","iopub.status.busy":"2021-01-24T20:50:51.611908Z","iopub.status.idle":"2021-01-24T20:51:16.649677Z","shell.execute_reply":"2021-01-24T20:51:16.650563Z"},"papermill":{"duration":25.060797,"end_time":"2021-01-24T20:51:16.650782","exception":false,"start_time":"2021-01-24T20:50:51.589985","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# do feature engineering\ntrain = train_raw.fillna(train_raw.mean())\n#train = train_raw.fillna(0)\nprint(train.head())\nprint(\"Null values found in train: \", train.isnull().sum().sum()) \ntrain = reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:51:16.714546Z","iopub.status.busy":"2021-01-24T20:51:16.713276Z","iopub.status.idle":"2021-01-24T20:51:18.86447Z","shell.execute_reply":"2021-01-24T20:51:18.863714Z"},"papermill":{"duration":2.183692,"end_time":"2021-01-24T20:51:18.864598","exception":false,"start_time":"2021-01-24T20:51:16.680906","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# prepare train and test datasets\n\ntrain = train[train['weight'] != 0]\n\nif 'resp' in train.columns :\n    train['action'] = np.where(train['resp'] > 0,1,0)\n#    train['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\nelse:\n    train['action'] = np.where(train['weight'] > 0,1,0)    \n#    train['action'] = (train['weight'].values > 0).astype('int')\n\nX = train.loc[:, features]\ny = train.loc[:, 'action']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n# X_test.head\n# y_test.head","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:51:18.930176Z","iopub.status.busy":"2021-01-24T20:51:18.92938Z","iopub.status.idle":"2021-01-24T20:51:18.942326Z","shell.execute_reply":"2021-01-24T20:51:18.941607Z"},"papermill":{"duration":0.048233,"end_time":"2021-01-24T20:51:18.942441","exception":false,"start_time":"2021-01-24T20:51:18.894208","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# create numpy datasets for normalization\nX_nptrain = X_train[:200000].to_numpy()\ny_nptrain = y_train[:200000].to_numpy()\n# define shapes of model layers\nprint(\"Shape X_train: \", X_train.shape[1])\ndim_lay1 = X_train.shape[1]\ndim_lay2 = dim_lay1 / 1.5\ndim_lay3 = dim_lay2 / 2\n#dim_lay2 = 150\n#dim_lay3 = 150\ndim_lay4 = min(10,dim_lay3/2)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:51:19.007192Z","iopub.status.busy":"2021-01-24T20:51:19.006386Z","iopub.status.idle":"2021-01-24T20:51:19.562214Z","shell.execute_reply":"2021-01-24T20:51:19.561498Z"},"papermill":{"duration":0.590221,"end_time":"2021-01-24T20:51:19.562318","exception":false,"start_time":"2021-01-24T20:51:18.972097","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# implement normalization of input features\nnormalizer = preprocessing.Normalization()\nnormalizer.adapt(X_nptrain)\ninput_shape = X_train.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:51:19.613396Z","iopub.status.busy":"2021-01-24T20:51:19.61199Z","iopub.status.idle":"2021-01-24T20:51:19.70717Z","shell.execute_reply":"2021-01-24T20:51:19.706571Z"},"papermill":{"duration":0.123683,"end_time":"2021-01-24T20:51:19.70728","exception":false,"start_time":"2021-01-24T20:51:19.583597","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"inputs = keras.Input(shape=input_shape)\nx = tf.keras.layers.BatchNormalization()(inputs)\n#x = normalizer(inputs)\nx = layers.Dense(dim_lay1, activation=\"tanh\")(x)\nx = layers.Dropout(dropout)(x)\n# x = layers.Dense(dim_lay1, activation=\"tanh\")(x)\nx = layers.Dense(dim_lay2, activation=\"tanh\")(x)\nx = layers.Dropout(dropout)(x)\nx = layers.Dense(dim_lay3, activation=\"tanh\")(x)\nx = layers.Dropout(dropout)(x)\nx = layers.Dense(dim_lay4, activation=\"tanh\")(x)\nx = layers.Dropout(dropout)(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = keras.Model(inputs, outputs)\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:51:19.82903Z","iopub.status.busy":"2021-01-24T20:51:19.828407Z","iopub.status.idle":"2021-01-24T20:53:32.05265Z","shell.execute_reply":"2021-01-24T20:53:32.053464Z"},"papermill":{"duration":132.251829,"end_time":"2021-01-24T20:53:32.053632","exception":false,"start_time":"2021-01-24T20:51:19.801803","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# now train model\n%time history = model.fit(X_train, y_train, epochs=nepochs, batch_size = 4096, validation_split=0.05, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Show trainint statistics...')\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:53:34.606076Z","iopub.status.busy":"2021-01-24T20:53:34.603072Z","iopub.status.idle":"2021-01-24T20:53:44.400038Z","shell.execute_reply":"2021-01-24T20:53:44.401059Z"},"papermill":{"duration":11.065676,"end_time":"2021-01-24T20:53:44.401214","exception":false,"start_time":"2021-01-24T20:53:33.335538","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test)\nprint(\"Accuracy Score on X_test:  \"+str(round(score[1],4)))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:53:47.122088Z","iopub.status.busy":"2021-01-24T20:53:47.121237Z","iopub.status.idle":"2021-01-24T20:53:47.153101Z","shell.execute_reply":"2021-01-24T20:53:47.153757Z"},"papermill":{"duration":1.395039,"end_time":"2021-01-24T20:53:47.153918","exception":false,"start_time":"2021-01-24T20:53:45.758879","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"if runjane :\n# specials for janestreet submission\n    import janestreet\n    janestreet.make_env.__called__ = False\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test() # an iterator which loops over the test set","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-24T20:53:51.719061Z","iopub.status.busy":"2021-01-24T20:53:51.718339Z","iopub.status.idle":"2021-01-24T20:57:39.716056Z","shell.execute_reply":"2021-01-24T20:57:39.71658Z"},"papermill":{"duration":229.071376,"end_time":"2021-01-24T20:57:39.716715","exception":false,"start_time":"2021-01-24T20:53:50.645339","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%time\nif runjane :\n    for (test_df, sample_prediction_df) in iter_test:\n    # predict only trades that generate results\n        if test_df['weight'].item() > 0:\n            X_test = test_df.loc[: , features].values\n            X_test = np.nan_to_num(X_test[:,:])\n            y_preds = model(X_test)\n            sample_prediction_df.action = np.where(y_preds >= 0.5, 1, 0).astype(int)\n        else:\n            sample_prediction_df.action = 0\n        \n        submission=env.predict(sample_prediction_df)\n\n    print(\"test_df prediction completed!\")\n    print(sample_prediction_df)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}