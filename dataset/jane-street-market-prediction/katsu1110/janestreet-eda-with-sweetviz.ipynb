{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><h2>Jane Street Market Prediction | EDA with SweetViz | katsu1110 </h2></center><hr>\n\nEDA seems to be vital in this competition, as provided features are anonymous. Given the number of features, let's use [sweetviz](https://pypi.org/project/sweetviz/) to cover all the columns.\nThis module gives us very nice overview of the provided data."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sweetviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nimport numpy as np\nimport pandas as pd\n\nimport os, sys\nimport gc\nimport math\nimport random\nimport pathlib\nfrom tqdm import tqdm\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model\nimport operator\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook as tqdm\nimport sweetviz as sv\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\npd.options.display.max_columns = None\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n### Make prettier the prints ###\nfrom colorama import Fore\nc_ = Fore.CYAN\nm_ = Fore.MAGENTA\nr_ = Fore.RED\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\ng_ = Fore.GREEN","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config\nSome configuration setups."},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 20201225 # Merry Christmas!\n# INPUT_DIR = '../input/jane-street-market-prediction/'\nINPUT_DIR = '../input/janestreet-save-as-feather/'\nTRADING_THRESHOLD = 0.5 # 0 ~ 1: The smaller, the more aggressive\nDATE_BEGIN = 200 # 0 ~ 499: set 0 for model training using the complete data \nUSE_SAMPLE_WEIGHT = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data\nI have already saved the training data in the feather-format in [my another notebook](https://www.kaggle.com/code1110/janestreet-save-as-feather?scriptVersionId=47635784). Loading csv takes time but loading feather is really light:)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%time\n\n# load data blitz fast!\ndef load_data(input_dir=INPUT_DIR):\n    train = pd.read_feather(pathlib.Path(input_dir + 'train.feather'))\n    features = pd.read_feather(pathlib.Path(input_dir + 'features.feather'))\n    example_test = pd.read_feather(pathlib.Path(input_dir + 'example_test.feather'))\n    ss = pd.read_feather(pathlib.Path(input_dir + 'example_sample_submission.feather'))\n    return train, features, example_test, ss\n\ntrain, features, example_test, ss = load_data(INPUT_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature \n'feature.csv' is very sparse...I don't know what it means. Let's visualize it for now. We have 29 'tag's (whatever it means) for each 139-feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = features * 1\nprint(features.shape)\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(5, 12))\nsns.heatmap(features[[f for f in features.columns.values.tolist() if 'tag' in f]], ax=ax);\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\nax.set_yticks(range(features.shape[0]))\nax.set_yticklabels(features['feature'].values)\nax.set_title('features.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It would be great if some of you could decode this data:D"},{"metadata":{},"cell_type":"markdown","source":"# EDA with SweetViz\nThe training data is huge, so I sample the data based on 'date'."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmy_report = sv.analyze(train.groupby('date').apply(lambda x: x.sample(frac=0.1, random_state=SEED)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_report.show_notebook() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Takeaways\n\n- 'date' is slightly negatively correlated with some features (such as 'feature_45'), suggesting that some features are decaying overtime.\n- 'weight' has median of 1 and has clear positive (e.g. feature_51) and negative (e.g. feature_126) correlations with some features.\n- 'resp' has strong positive correlations with other resps (1-4), but 'resp' is not well correlated with features (bad news!).\n- 'feature_0' is binary, and highly correlated with some features (e.g. 'feature_40').\n- Many 'feature' are highly correlated with one another, suggesting redundancy.\n- 'feature_64 ~ 68' are perfectly correlated with another (pearson r = 1)!\n- 'ts_id' has negative correlation with some features (same as 'date'), again suggesting that some features decay overtime.\n\nHope you like this kearnel and learn some!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}