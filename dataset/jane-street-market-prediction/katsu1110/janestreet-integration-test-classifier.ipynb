{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><h2>Jane Street Market Prediction | Numerai Baseline | katsu1110 </h2></center><hr>\n\nHere I use an example model (XGBoost) used for the [Numerai tournament](https://numer.ai/tournament). This model [performs well](https://numer.ai/integration_test) in Numerai, but how about this competition?\n\nThis notebook loads feathered-data from [my another notebook](https://www.kaggle.com/code1110/janestreet-save-as-feather?scriptVersionId=47635784) such that we don't have to spend our time on waiting long for loading csv files.\n\nIn this notebook we treat the task as a binary classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nimport numpy as np\nimport pandas as pd\n\nimport os, sys\nimport gc\nimport math\nimport random\nimport pathlib\nfrom tqdm import tqdm\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model\nimport operator\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook as tqdm\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\npd.options.display.max_columns = None\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config\nSome configuration setups."},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 20201225 # Merry Christmas!\n# INPUT_DIR = '../input/jane-street-market-prediction/'\nINPUT_DIR = '../input/janestreet-save-as-feather/'\nTRADING_THRESHOLD = 0.502 # 0 ~ 1: The smaller, the more aggressive\nDATE_BEGIN = 86 # 0 ~ 499: set 0 for model training using the complete data ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data\nI have already saved the training data in the feather-format in [my another notebook](https://www.kaggle.com/code1110/janestreet-save-as-feather?scriptVersionId=47635784). Loading csv takes time but loading feather is really light:)"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(INPUT_DIR)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%time\n\n# load data blitz fast!\ndef load_data(input_dir=INPUT_DIR):\n    train = pd.read_feather(pathlib.Path(input_dir + 'train.feather'))\n    features = pd.read_feather(pathlib.Path(input_dir + 'features.feather'))\n    example_test = pd.read_feather(pathlib.Path(input_dir + 'example_test.feather'))\n    ss = pd.read_feather(pathlib.Path(input_dir + 'example_sample_submission.feather'))\n    return train, features, example_test, ss\n\ntrain, features, example_test, ss = load_data(INPUT_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA (Exploratory Data Analysis)\nLet's briefly look at data."},{"metadata":{},"cell_type":"markdown","source":"## Train\n>train.csv - the training set, contains historical data and returns"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Date range from {} to {}.'.format(train['date'].min(), train['date'].max()))\nprint('ts_id range from {} to {}.'.format(train['ts_id'].min(), train['ts_id'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histograms for non-features\nfor f in ['weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']:\n    train[f].plot.hist(bins=100, title=f)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">In the training set, train.csv, you are provided a resp value, as well as several other resp_{1,2,3,4} values that represent returns over different time horizons.\n\nLet's look at 'resp': how they are correlated with one another."},{"metadata":{"trusted":true},"cell_type":"code","source":"# resp...correlated with one another?\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nsns.heatmap(train[['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']].corr(), \n            annot=True, square=True, ax=ax);\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right');\nax.set_title('resp correlations');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Each trade has an associated weight and resp, which together represents a return on the trade. The date column is an integer which represents the day of the trade\n\nOK, how does the return look like?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(20, 5))\nfor f in ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']:\n    train.iloc[-10000:].plot(x='ts_id', y=f, alpha=0.4, label=f, ax=ax) # last 10000\nax.legend(frameon=False)\nax.set_ylabel('return')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not always winning but overall many chances of winning?:D"},{"metadata":{"trusted":true},"cell_type":"code","source":"# target\ntrain['action'] = train['resp'] * train['weight']\ntrain['action'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target 'action' has its median of 0, meaning that we can take this task as a binary classification without label unbalance. \n\nAlternatively we can also take it as a regression problem. "},{"metadata":{},"cell_type":"markdown","source":"## features\n>features.csv - metadata pertaining to the anonymized features\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(features.shape)\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(16, 10))\nsns.heatmap(features[[f for f in features.columns.values.tolist() if f.startswith('tag')]], \n            ax=ax);\nax.set_yticklabels(features['feature'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right');\nax.set_title('features.csv');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks beautiful but what does this indicate???"},{"metadata":{},"cell_type":"markdown","source":"## Test, submission\nNote that this is a code competition...which means, the actual test file is hidden (the example_test is just an example!) ...your score is calculated on the hidden dataset only when you submit."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(example_test.shape)\nexample_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ss.shape)\nss.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete irrelevant files to save memory\ndel features, example_test, ss\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model fitting\nFor now, let's use a simple XGBoost which is also used as an example in the Numerai Tournament.\n\nThere are several columns of returns (resp 1-4 and resp). Let's predict all as our targets and ensemble the results for our final prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove weight = 0 for saving memory \noriginal_size = train.shape[0]\ntrain = train.query('weight > 0').reset_index(drop=True)\n\n# use data later than DATE_BEGIN\ntrain = train.query(f'date >= {DATE_BEGIN}')\n\nprint('Train size reduced from {:,} to {:,}.'.format(original_size, train.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['action'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['action'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features to use\nfeats = [f for f in train.columns.values.tolist() if f.startswith('feature')]\nprint('There are {:,} features.'.format(len(feats)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# same hyperparameters from an numerai example (https://github.com/numerai/example-scripts/blob/master/example_model.py)\nparams = {\n    'colsample_bytree': 0.1,                 \n    'learning_rate': 0.01,\n    'max_depth': 5,\n    'seed': SEED,\n    'n_jobs': -1,\n    'n_estimators': 2000,\n#     'tree_method': 'gpu_hist' # Let's use GPU for a faster experiment\n}\n\n# params[\"objective\"] = 'reg:squarederror'\n# params[\"eval_metric\"] = 'rmse'\n# model = xgb.XGBRegressor(**params)\n\nparams[\"objective\"] = 'binary:logistic'\nparams[\"eval_metric\"] = 'logloss'\n    \nmodel = xgb.XGBClassifier(**params)\nmodel.fit(train[feats], train['action'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature importance\nLet's see feature importance given by the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(model.feature_importances_, index=feats, columns=['importance']).sort_values(by='importance', ascending=False).style.background_gradient(cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\ntest = env.iter_test()\n        \nweight_sum = np.sum(np.array(AVERAGE_WEIGHTS))\n\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        pred_df.action = (model.predict_proba(test_df[feats])[:, 1] > TRADING_THRESHOLD).astype('int')\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}