{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv', nrows=100000)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import csv\nfrom csv import DictReader\n\n\ndef train_data(path):\n    t = 0\n    with open(path, 'r') as f:\n        buffer = csv.reader(f)\n        for ID, line in enumerate(buffer):\n            if ID == 0:\n                date_idx = line.index('date')\n                weight_idx = line.index('weight')\n                resp_idx = line.index('resp')\n                cols = [i for (i, field) in enumerate(line) if 'feature' in field]\n                yield len(cols)  # dimension\n                continue\n            # preprocess\n            if line[weight_idx] == '0':\n                continue\n            else:\n                y = int((float(line[weight_idx]) * float(line[resp_idx])) > 0)\n                x = np.array([float(line[i]) if line[i] else 0 for i in cols])\n                yield ID - 1, x, y, t, line[date_idx]\n                t += 1\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numba\n\nDATE = 'date'\nWEIGHT = 'weight'\nTARGET = 'resp'\n\n@numba.njit(fastmath = True)\ndef utility_score_numba(date, weight, resp, action):\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n    u = min(max(t, 0), 6) * np.sum(Pi)\n    return u\n\ndef utility(data, action):\n    return utility_score_numba(data[DATE].values, data[WEIGHT].values, data[TARGET].values, action)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.date.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import exp\n\n\ndef projection(x, V):\n    \"\"\"\n    projection of vector x on ball of radius V\n    \"\"\"\n    x_norm = np.linalg.norm(x)\n    if x_norm > V:\n        return x / x_norm * V\n    return x\n\n\nclass ogd(object):\n    \"\"\"\n    Standard Gradient Descent algorithm for linear prediction problems,\n    with Euclidean regularization.\n    \"\"\"\n\n    def __init__(self, d, beta=1, rand_init=False, project=False):\n        \"\"\"\n        d - dimension\n        beta - diameter of the set V considered (we do not operate projection)\n        \"\"\"\n        self.d = d                  # dimension\n        self.beta = beta            # diameter for projection\n        self.rand_init = rand_init  # random initialization\n        self.project = project      # whether to project on a bounded (L2) ball\n        self.w = None\n        self.reset()\n\n    def reset(self):\n        if self.w is None:\n            if self.rand_init:\n                self.w = np.random.rand(self.d)\n            else:\n                self.w = np.zeros(self.d)\n        self.eta = 1\n        self.G_t = 0\n        \n    def get_model(self):\n        return self.w\n            \n    def predict(self, x):\n        \"\"\"\n        Prediction according OGD weights.\n        \"\"\"\n        return 1. / (1. + np.exp(-np.maximum(np.minimum(x.dot(self.w), 35.), -35.)))\n    \n    def update(self, x, p, y):\n        \"\"\"\n        Update model.\n        \"\"\"\n        \n        # gradient of log loss\n        g_t = (p - y) * x\n\n        # params\n        self.G_t += np.linalg.norm(g_t)**2\n        self.eta = self.beta / np.sqrt(1 + self.G_t)\n        self.w -= self.eta * g_t\n        if self.project:\n            self.w = projection(self.w, self.beta)\n            \n    def __repr__(self):\n        return \"OGD\"\n\n        \ndef logloss(p, y):\n    ''' FUNCTION: Bounded logloss\n\n        INPUT:\n            p: our prediction\n            y: real answer\n\n        OUTPUT:\n            logarithmic loss of p given y\n    '''\n\n    p = max(min(p, 1. - 10e-15), 10e-15)\n    return -np.log(p) if y == 1. else -np.log(1. - p)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ftrl(ogd):\n    \"\"\"\n    FTRL algorithm for linear prediction problems,\n    with Euclidean regularization.\n    \"\"\"\n\n    def __init__(self, d, beta=1, rand_init=False, project=False):\n        \"\"\"\n        d - dimension\n        beta - diameter of the set V considered (we do not operate projection)\n        \"\"\"\n        ogd.__init__(self, d, beta=1, rand_init=rand_init, project=project)\n        self.grad_sum = np.zeros(d)\n    \n    def update(self, x, p, y):\n        \"\"\"\n        Update model.\n        \"\"\"\n        \n        # gradient of log loss\n        g_t = (p - y) * x\n\n        # params\n        self.grad_sum += g_t\n        self.G_t += np.linalg.norm(g_t)**2\n        self.eta = self.beta / np.sqrt(1 + self.G_t)\n        self.w = -self.eta * self.grad_sum\n        if self.project:\n            self.w = projection(self.w, self.beta)\n            \n    def __repr__(self):\n        return \"FTRL\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\n\ndef training(learner, path, epoch=1, verbose=True):\n    # start training\n    start = datetime.now()\n    \n    for e in range(epoch):\n        count = 0\n        valid_loss = 0.\n        train_loss = 0.\n        prev_date = '0'\n        \n        it = train_data(path)\n        dim = next(it)  # first iteration returns the dimension\n        \n        for ID, x, y, t, date in it:  # data is a generator\n            # ID  : index of the line in the file \n            # x   : features\n            # y   : label\n            # t   : just a instance counter\n            # date: date!\n\n            # step 1, get prediction from learner\n            p = learner.predict(x)\n            train_loss += logloss(p, y)\n\n            if t % 1000 == 0:\n                # step 2-1, calculate validation loss\n                #           we do not train with the validation data so that our\n                #           validation loss is an accurate estimation\n                valid_loss += logloss(p, y)\n                count += 1\n            else:\n                # step 2-2, update learner with label information\n                learner.update(x, p, y)\n                yield ID, p\n            \n            if date != prev_date:\n                pi = 0\n            \n            if t % 20000 == 0:\n                if t == 0:\n                    pass\n                else:\n                    avg_train = train_loss / t\n                    if verbose:\n                        print(f\"Processed: {t} datapoints\", datetime.now())\n                        print(f\"\\tAVG Cum Train Loss: {avg_train:.3f}\")\n                        print(f\"\\tAVG Cum Valid Loss: {valid_loss / count:.3f}\")\n                \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport pickle\n\n\n##############################################################################\n# parameters #################################################################\n##############################################################################\n\n\n# A, paths\ntrain_path = '/kaggle/input/jane-street-market-prediction/train.csv'    # path to training file\nepoch = 1                                                               # learn training data for N passes\n\n\n##############################################################################\n# start training #############################################################\n##############################################################################\n\ndim = next(train_data(train_path))\n# initialize a learner\n# learners = [ogd(dim, project=True), ftrl(dim)]\nlearners = [ftrl(dim)]\n\nfor learner in learners:\n    print(f\"----- {str(learner)} -----\\n\")\n    ids = []\n    pred = []\n    for t, value in enumerate(training(learner, '/kaggle/input/jane-street-market-prediction/train.csv', epoch)):\n        ID, p = value\n        ids.append(ID)\n        pred.append(p)\n    print()\n    # utility function\n    pred_train = np.array(pred)\n    try:\n        print(f\"Train Score = {utility(train.iloc[ids], pred_train > 0.5):.4f}\\n\")\n    except IndexError:\n        print(\"Maybe next time!\")\n        train_pickle_file = '/kaggle/input/pickling/train.csv.pandas.pickle'\n        train = pickle.load(open(train_pickle_file, 'rb'))\n    \n\ntry:\n    pickle.dump(learner.get_model(), open(os.path.join('../working', 'model.pkl'), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\nexcept TypeError:\n    learner.get_model().save(open(os.path.join('../working', 'model.h5')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillna_npwhere_njit(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\n\n\ndef test_data(df_object, cols):\n    ''' GENERATOR.\n\n        INPUT:\n            path: path to testing file\n\n        YIELDS:\n            ID: id of the instance, mainly useless\n            x: feature vector\n            y: action, either 0 or 1\n    '''\n    # test dataset is given as pandas dataframe\n    arr = pd.DataFrame(df_object, columns=cols).to_numpy()\n    return fillna_npwhere_njit(arr, 0)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_train = train.iloc[:100000]\ncols = ['feature_' + str(i) for i in range(130)]\ny = learner.predict(test_data(small_train, cols))\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##############################################################################\n# start testing, and build Kaggle's submission file ##########################\n##############################################################################\n\nimport janestreet\n\nenv = janestreet.make_env()\n\ntest_path = '/kaggle/input/jane-street-market-prediction/example_test.csv'\niter_test = env.iter_test()\ncols = ['feature_' + str(i) for i in range(130)]\n# test_all_data = []\n\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    sample_prediction_df.action = int(learner.predict(test_data(test_df, cols)) > .5)\n    env.predict(sample_prediction_df)\n    # test_all_data.append(test_df)\n    \n\"\"\"\n# sanity check\nzeros = []\nones = []\n\nfor idx, x in enumerate(test_all_data):\n    y_pred = int(learner.predict(test_data(x, cols)) > .5)\n    if y_pred == 1:\n        ones.append(idx)\n    else:\n        zeros.append(idx)\n\nprint(len(ones))\nprint(len(zeros))\n\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}