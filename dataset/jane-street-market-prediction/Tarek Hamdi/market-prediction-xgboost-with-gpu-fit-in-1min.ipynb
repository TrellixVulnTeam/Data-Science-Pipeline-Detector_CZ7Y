{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Market Prediction: XGBoost with GPU (Fit in 1min)\n\n# Check my kernel [ðŸ”¥ðŸ”¥ Market Prediction: CatBoost Classifier ðŸ”¥ðŸ”¥](https://www.kaggle.com/hamditarek/market-prediction-catboost-classifier) ==> Public Score: 5242.189 (version 18)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cudf\npd.set_option('display.max_columns', 500)\n\n\nimport time\nfrom tqdm.notebook import tqdm\n\n# Standard plotly imports\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\nimport os\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_cudf  = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ntrain = train_cudf.to_pandas()\ndel train_cudf\nfeatures = pd.read_csv('../input/jane-street-market-prediction/features.csv')\nexample_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nprint (\"Data is loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing/total_cells) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Is the data balanced or not?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['weight'] != 0]\n\ntrain = train.query('date > 85').reset_index(drop = True) \n\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\ntrain.fillna(train.mean(),inplace=True)\n\ncols = [c for c in train.columns if 'feature' in c]\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\ny_train = train.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train['action'].value_counts().index\ny = train['action'].value_counts().values\n\ntrace2 = go.Bar(\n     x=x ,\n     y=y,\n     marker=dict(\n         color=y,\n         colorscale = 'Viridis',\n         reversescale = True\n     ),\n     name=\"Imbalance\",    \n )\nlayout = dict(\n     title=\"Data imbalance - action\",\n     #width = 900, height = 500,\n     xaxis=go.layout.XAxis(\n     automargin=True),\n     yaxis=dict(\n         showgrid=False,\n         showline=False,\n         showticklabels=True,\n #         domain=[0, 0.85],\n     ), \n)\nfig1 = go.Figure(data=[trace2], layout=layout)\niplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x, y, train, features, example_test, sample_prediction_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training\n##### To activate GPU usage, simply use tree_method='gpu_hist' (took me an hour to figure out, I wish XGBoost documentation was clearer about that)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nprint(\"XGBoost version:\", xgb.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=11,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING = True\n\nstart_time = time.time()\n\nif TRAINING:\n    import janestreet\n    env = janestreet.make_env()\n    th = 0.5\n    for (test_df, pred_df) in tqdm(env.iter_test()):\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, test_df.columns.str.contains('feature')].values\n            if np.isnan(x_tt[:, 1:].sum()):\n                x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:])\n            pred = clf.predict(x_tt)\n            pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)\n        \nprint(f\"took: {time.time() - start_time} seconds\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}