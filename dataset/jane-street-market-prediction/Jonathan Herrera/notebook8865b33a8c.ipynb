{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport janestreet\nimport cupy as cp\nimport gc\n\nfrom time import time\nfrom sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer, MaxAbsScaler, Normalizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import optimizers\nfrom multiprocessing.pool import ThreadPool\nfrom tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getDf():\n    df = pd.read_csv('../input/jane-street-market-prediction/train.csv')\n    df = df.dropna()\n    df = df.drop(columns=['resp_1','resp_2','resp_3','resp_4','ts_id'])\n    \n    return df\n            \ndef getTVT_split(split,mn):\n    global df\n    y = np.where(df['resp'] > mn,1,0).reshape(len(df),1)\n    resp = df['resp'].values.reshape(-1,1)\n    x = df.drop(columns=['resp']).values\n    date = x[:,:1]\n    weight = x[:,1:2]\n    x = x[:,2:]\n    \n    x_train, x_test = train_test_split(x,train_size=split,random_state=5)\n\n    y_train, y_test = train_test_split(y,train_size=split,random_state=5)\n    \n    gc.collect()\n    \n    return x_train, x_test, y_train, y_test\n    \ndef scaling(i):\n    global x_train, x_test, scalers\n    if(scalers[i]!=\"no\"):\n        x_train[:,i+0:i+1] = scalers[i].fit_transform(x_train[:,i+0:i+1])\n        x_test[:,i+0:i+1] = scalers[i].transform(x_test[:,i+0:i+1])\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = getDf()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split = 0.57165\nmn = 0\nhid_layers = 5\nact_in = 'elu'\nnn_in = 95\nact_out = 'linear'\nnn_hid = [72,54,60,6,83]\nact_hid = ['softplus','tanh','softsign','relu','selu']\nscalers = [MinMaxScaler(), MaxAbsScaler(), StandardScaler(), 'no', StandardScaler(with_std=False),\n           StandardScaler(with_mean=False, with_std=False), StandardScaler(with_mean=False),\n           RobustScaler(), RobustScaler(with_centering=False), RobustScaler(), 'no', \n           StandardScaler(with_mean=False, with_std=False), 'no', QuantileTransformer(random_state=5),\n           MaxAbsScaler(), RobustScaler(with_centering=False), PowerTransformer(standardize=False),\n           StandardScaler(with_std=False), StandardScaler(with_std=False), 'no', MinMaxScaler(),\n           RobustScaler(with_scaling=False), PowerTransformer(),\n           StandardScaler(with_mean=False, with_std=False), RobustScaler(with_scaling=False), 'no',\n           QuantileTransformer(random_state=5), 'no', StandardScaler(with_mean=False),\n           RobustScaler(with_centering=False), StandardScaler(with_std=False),\n           StandardScaler(with_mean=False, with_std=False), StandardScaler(with_std=False),\n           StandardScaler(), QuantileTransformer(random_state=5), StandardScaler(),\n           QuantileTransformer(random_state=5), StandardScaler(with_mean=False, with_std=False),\n           RobustScaler(with_centering=False), MinMaxScaler(feature_range=(-1, 1)), PowerTransformer(),\n           PowerTransformer(standardize=False), QuantileTransformer(random_state=5),\n           RobustScaler(with_centering=False),\n           QuantileTransformer(output_distribution='normal', random_state=5),\n           MinMaxScaler(feature_range=(-1, 1)), StandardScaler(with_mean=False, with_std=False),\n           StandardScaler(), RobustScaler(), 'no', RobustScaler(with_scaling=False),\n           StandardScaler(with_std=False), RobustScaler(with_centering=False, with_scaling=False),\n           StandardScaler(with_mean=False, with_std=False),\n           RobustScaler(with_centering=False, with_scaling=False), MaxAbsScaler(), StandardScaler(),\n           MaxAbsScaler(), QuantileTransformer(random_state=5), MaxAbsScaler(),\n           QuantileTransformer(random_state=5), StandardScaler(with_mean=False),\n           StandardScaler(with_mean=False), RobustScaler(with_centering=False),\n           StandardScaler(with_mean=False), PowerTransformer(), RobustScaler(with_centering=False),\n           MinMaxScaler(feature_range=(-1, 1)),\n           QuantileTransformer(output_distribution='normal', random_state=5),\n           RobustScaler(with_centering=False), PowerTransformer(), MinMaxScaler(), RobustScaler(),\n           PowerTransformer()]\nn_features = len(scalers)\nls = 'mean_squared_error'\nopt = 'adam'\n\nx_train, x_test, y_train, y_test = getTVT_split(split,mn)\ngc.collect()\n\nf_used = [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n          1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n          1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n          0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, \n          1, 0]\nx_train = x_train[:,np.nonzero(f_used)][:,0]\nx_test = x_test[:,np.nonzero(f_used)][:,0]\n\np = ThreadPool()\np.map(scaling, range(n_features))\np.close()\np.join()\ngc.collect()\neps = 144\nbatch = 7208\nfeatures_used = np.array(np.nonzero(f_used))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(95,input_dim=(74),activation='elu'))\nmodel.add(Dense(72,activation='softplus'))\nmodel.add(Dense(54,activation='tanh'))\nmodel.add(Dense(60,activation='softsign'))\nmodel.add(Dense(6,activation='relu'))\nmodel.add(Dense(83,activation='selu'))\nmodel.add(Dense(y_train.shape[1],activation='linear'))\n\nmodel.compile(loss=ls,optimizer=opt)\n\nmodel.fit(x_train,y_train,epochs=eps,batch_size=batch,verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train size: {}\\n\\nLower limit for earning: {}\\n\\nNumber of hiden layers: {}\\n\\nActivation on input layer: {}\\n\\nNumber of neurons on input layer: {}\\n\\nActivation on output layer: {}\\n\\nNumber of neurons on hidden layers: {}\\n\\nActivation on hidden layers: {}\\n\\nFeatures used: {}\\n\\nScalers of the features: {}\\n\\nLoss of the model: {}\\n\\nOptimizer of the model: {}\\n\\nEpochs of training: {}\\n\\nBatch size: {}\".format(split,\nmn,hid_layers,act_in,nn_in,act_out,nn_hid,act_hid,features_used,scalers,ls,opt,eps,batch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\niter_test = env.iter_test()\ntest_df = 0\np = ThreadPool()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scaler(i):\n    global test_df, scalers\n    if(scalers[i]!=\"no\"):\n        test_df[:,i+0:i+1] = scalers[i].transform(test_df[:,i+0:i+1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.drop(columns=['date','weight','feature_0','feature_3','feature_9','feature_10',\n                                        'feature_11','feature_12','feature_14','feature_15','feature_16',\n                                        'feature_20','feature_21','feature_24','feature_28','feature_30',\n                                        'feature_31','feature_33','feature_36','feature_39','feature_42',\n                                        'feature_45','feature_46','feature_47','feature_48','feature_49',\n                                        'feature_51','feature_53','feature_55','feature_56','feature_59',\n                                        'feature_60','feature_65','feature_66','feature_67','feature_71',\n                                        'feature_72','feature_74','feature_76','feature_78','feature_80',\n                                        'feature_83','feature_85','feature_86','feature_89','feature_90',\n                                        'feature_95','feature_96','feature_98','feature_103','feature_109',\n                                        'feature_110','feature_112','feature_113','feature_119','feature_121',\n                                        'feature_125','feature_129']).values\n    if(np.isnan(test_df).any()):\n        sample_prediction_df.action = 0\n        env.predict(sample_prediction_df)\n    else:\n        p.map(scaler,range(74))\n        sample_prediction_df.action = int(model(test_df,training=False).numpy()[0,0] > 0.5)\n        env.predict(sample_prediction_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}