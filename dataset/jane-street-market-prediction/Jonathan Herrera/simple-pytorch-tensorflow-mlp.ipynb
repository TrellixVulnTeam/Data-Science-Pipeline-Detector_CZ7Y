{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport pickle\nimport random\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CACHE_PATH = '../input/mlp012003weights'\n\ndef save_pickle(dic, save_path):\n    with open(save_path, 'wb') as f:\n        pickle.dump(dic, f)\n\ndef load_pickle(load_path):\n    with open(load_path, 'rb') as f:\n        message_dict = pickle.load(f)\n    return message_dict\n\nf_mean = np.load(f'{CACHE_PATH}/f_mean_online.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of the features\nfeat_cols = [f'feature_{i}' for i in range(130)]\n\n# list of all the features\nall_feat_cols = [col for col in feat_cols]\n\n# add two more features to the feature list\nall_feat_cols.extend(['cross_41_42_43', 'cross_1_2'])\n\n# resp 1,2,3,4\ntarget_cols = ['action', 'action_1', 'action_2', 'action_3', 'action_4']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Model(nn.Module):\n    \n    def __init__(self):\n        \n        super(Model, self).__init__()\n        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n        \n        self.dropout0 = nn.Dropout(0.8) # 0.2\n\n        dropout_rate = 0.5 # 0.2\n        hidden_size = 256\n        \n        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n\n        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n\n        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n\n        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n\n        self.Relu = nn.ReLU(inplace=True)\n        self.PReLU = nn.PReLU()\n        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n\n        self.RReLU = nn.RReLU()\n\n    def forward(self, x):\n        \n        x = self.batch_norm0(x)\n        x = self.dropout0(x)\n\n        x1 = self.dense1(x)\n        x1 = self.batch_norm1(x1)\n\n        x1 = self.LeakyReLU(x1)\n        x1 = self.dropout1(x1)\n\n        x = torch.cat([x, x1], 1)\n\n        x2 = self.dense2(x)\n        x2 = self.batch_norm2(x2)\n\n        x2 = self.LeakyReLU(x2)\n        x2 = self.dropout2(x2)\n\n        x = torch.cat([x1, x2], 1)\n\n        x3 = self.dense3(x)\n        x3 = self.batch_norm3(x3)\n\n        x3 = self.LeakyReLU(x3)\n        x3 = self.dropout3(x3)\n\n        x = torch.cat([x2, x3], 1)\n\n        x4 = self.dense4(x)\n        x4 = self.batch_norm4(x4)\n\n        x4 = self.LeakyReLU(x4)\n        x4 = self.dropout4(x4)\n\n        x = torch.cat([x3, x4], 1)\n\n        x = self.dense5(x)\n\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print('using device: cuda')\n    torch.device(\"cuda:0\")\nelse:\n    print('using device: cpu')\n    device = torch.device('cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFOLDS = 5\n\nmodel_list = []\ntmp = np.zeros(len(feat_cols))\nfor _fold in range(NFOLDS):\n    torch.cuda.empty_cache()\n    model = Model()\n    model.to(device)\n    model_weights = f\"{CACHE_PATH}/online_model{_fold}.pth\"\n    model.load_state_dict(torch.load(model_weights, map_location=device))\n    model.eval()\n    model_list.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport tensorflow_addons as tfa","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 1111\n\nnp.random.seed(SEED)\n\ndef create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n    \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model\n\nepochs = 300\nbatch_size = 4096\nhidden_units = [160, 160, 160]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\ntf.keras.backend.clear_session()\ntf.random.set_seed(SEED)\nclf = create_mlp(len(feat_cols), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model and save it with \n#clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n#clf.save(f'model.h5')\n\n# Load the Fitted model\n# !ls ../input/jane-street-with-keras-nn-overfit/\nclf.load_weights('../input/jane-street-with-keras-nn-overfit/model.h5')\n\n# If you have several models, the you can store into a list\n#tf_models = [clf]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"th = 0.5\nimport janestreet\njanestreet.competition.make_env.__called__ = False\n\nenv = janestreet.make_env()\nenv_iter = env.iter_test()\n\nfor (test_df, pred_df) in tqdm(env_iter):\n\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, feat_cols].values\n        \n        if np.isnan(x_tt.sum()):\n            \n            x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n\n    \n        cross_41_42_43 = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n        cross_1_2 = x_tt[:, 1] / (x_tt[:, 2] + 1e-5)\n        feature_inp = np.concatenate((x_tt, np.array(cross_41_42_43).reshape(x_tt.shape[0], 1), np.array(cross_1_2).reshape(x_tt.shape[0], 1),), axis=1)\n\n        \n        torch_pred = np.zeros((1, len(target_cols)))\n        for model in model_list:\n            torch_pred += model(torch.tensor(feature_inp, dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy() / NFOLDS\n        torch_pred = np.median(torch_pred)\n\n        tf_pred = np.median(clf(x_tt))\n\n        \n        # PyTorch and TensorFlow Average prediction\n        pred = torch_pred * 0.4 + tf_pred * 0.6\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n        \n    else:\n        pred_df.action = 0\n        \n    env.predict(pred_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}