{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Intro\nWelcome to the [Jane Street Market Prediction](https://www.kaggle.com/c/jane-street-market-prediction/data) competition.\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/23304/logos/header.png)\n\nThis is a starter notebook and will help you to begin with the competition.\n\nWe pass a simple feature engineering to handle missing values and start with a simple XGB Classifier.\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. </span>"},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Path"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/jane-street-market-prediction/'\nos.listdir(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_timeseries(data, feature):\n    fig = plt.figure(figsize=(10, 6))\n    x = range(len(data))\n    y = data[feature]\n    plt.plot(x, y)\n    plt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use a memory reduction function based on this [notebook](https://www.kaggle.com/unrool/starter-notebook-with-mem-reducing)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def memory_reduction(df):\n    \"\"\" Iterate through all the columns of the dataframe df \n        and modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(path+'train.csv')\n#test_data = pd.read_csv(path+'example_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('number of train samples:', len(train_data))\n#print('number of features:', len(feature_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[['weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_timeseries(train_data, 'feature_4')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handle Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing_train = [col for col in train_data.columns if train_data[col].isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train columns with missing data:', cols_with_missing_train[0:4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features are numericals. There are several techniques to fill the missing data, i.e. set them to zero oder the mean value."},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = train_data[cols_with_missing_train].mean()\n#train_data[cols_with_missing_train] = train_data[cols_with_missing_train].fillna(0, inplace=False)\ntrain_data[cols_with_missing_train] = train_data[cols_with_missing_train].fillna(mean, inplace=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reduce Memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data = memory_reduction(train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Prepare Data\nWe focus on the samples with weight grather than zero. And define the binar target based on the feature resp."},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data['resp_mean'] = train_data[['resp_4', 'resp']].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_temp = train_data[train_data['weight'] != 0]\ntrain_temp['action'] = (train_temp['resp'] > 0) * 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_temp.loc[:, train_temp.columns.str.contains('feature')]\ny_train = train_temp.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scale data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['feature_'+str(i) for i in range(130)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = X_train[features].mean(axis=0)\nX_train[features] = X_train[features].astype('float32')\nX_train[features] -= X_train[features].mean(axis=0)\nstd = X_train[features].std(axis=0)\nX_train[features] /= X_train[features].std(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Train And Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('number of train samples', len(X_train))\nprint('number of val samples', len(X_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\nWe use a simple XGB classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_grid = {'objective': ['binary:logistic'],\n#               'learning_rate': [1/(10**i) for i in range(1, 2)],\n#               'max_depth': [i for i in range(9, 11)],\n#               'n_estimators': [i*100 for i in range(8, 10)],\n#               'random_state': [2020],\n#              'tree_method': ['gpu_hist']}\n# grid = GridSearchCV(XGBClassifier(), param_grid=param_grid, cv=6)\n# grid.fit(X_train, y_train)\n# best_params = grid.best_params_\n# print('Best score of cross validation: {:.2f}'.format(grid.best_score_))\n# print('Best parameters:', best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_XGB = XGBClassifier(objective='binary:logistic',\n                          n_estimators=900,\n                          learning_rate=0.1,\n                          random_state=2020,\n                          max_depth=9,\n                          tree_method = 'gpu_hist')\nmodel_XGB.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_val = model_XGB.predict(X_val)\naccuracy_score(y_val, preds_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance\nWe want to know useful are the features for predicting a target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"importance = model_XGB.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 30))\nx = X_train.columns.values\nplt.barh(x, 100*importance, orientation='horizontal')\nplt.title('Feature Importance', loc='left')\nplt.xlabel('Percentage')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n    \n    #Predict Target\n    y_preds = model_XGB.predict(X_test)\n    sample_prediction_df.action = y_preds\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}