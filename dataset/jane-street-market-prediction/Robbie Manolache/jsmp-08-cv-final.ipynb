{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\nfrom datetime import datetime\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datatable as dt\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom sklearn.model_selection import KFold\nnow = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nprint(now)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = dt.fread(\"../input/jane-street-market-prediction/train.csv\")\ndf = df.to_pandas()\ndf = df.query('weight > 0').drop(columns=[\"resp_\"+str(r) for r in range(1,5)])\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def __profit_maximizer__(y_true, y_pred):\n    \"\"\"\n    \"\"\"\n    L = - K.sum(y_true * y_pred)\n    return L  \n\ndef __create_NN_model__(NN_params, input_shape):\n    \"\"\"\n    \"\"\"\n    n_layer = len(NN_params[\"layers\"])\n    model = keras.Sequential()\n    for l in range(n_layer):\n        if l == 0:\n            if NN_params[\"pre_drop\"] is None:\n                pass\n            else:\n                model.add(keras.layers.Dropout(NN_params[\"pre_drop\"]))\n            model.add(keras.layers.Dense(\n                NN_params[\"layers\"][l],\n                input_shape=[input_shape],\n                activation=NN_params[\"actifun\"][l],\n                kernel_regularizer=keras.regularizers.l2(NN_params[\"L2\"][l])))\n        else:\n            model.add(keras.layers.Dense(\n                NN_params[\"layers\"][l],\n                activation=NN_params[\"actifun\"][l],\n                kernel_regularizer=keras.regularizers.l2(NN_params[\"L2\"][l])))\n        model.add(keras.layers.Dropout(NN_params[\"dropout\"][l]))\n    model.add(keras.layers.Dense(1, activation='sigmoid'))\n    return model\n\nNN_params = {\n    \"lr\": 0.0055,\n    \"n_epoch\": 49,\n    \"n_batch\": 2,\n    \"pre_drop\": None,\n    \"layers\": [60, 80, 120],\n    \"actifun\": ['relu', 'relu', 'relu'],\n    \"dropout\": [0.01, 0.03, 0.05],\n    \"L2\": [0.001, 0.003, 0.005]\n}\n\noth_params = {\n    \"weight_pwr\": 0.6,\n    \"seed\": 42,\n    \"n_fold\": 5,\n    \"thresholds\": [0.5, 0.75, 0.9, 0.95]\n}\n\nall_params = {\"NN_params\": NN_params, \"oth_params\": oth_params}\nwith open(\"D%s_train_config.json\"%now, 'w') as tcf:\n    json.dump(all_params, tcf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:, \"target\"] = df['resp'] * (df['weight'] ** oth_params[\"weight_pwr\"])\nX_col = [f for f in df.columns if f.startswith(\"feature\")]\n\ndates = np.array(range(500))\nkf = KFold(n_splits=oth_params[\"n_fold\"], random_state=oth_params[\"seed\"], shuffle=True)\nresults = {}\n\nfor i, (train_index, test_index) in enumerate(kf.split(dates)):\n    \n    # Train/test split\n    x_train = np.nan_to_num(df.loc[df['date'].isin(train_index), X_col].values)\n    y_train = df.loc[df['date'].isin(train_index), \"target\"].values\n    \n    x_test = np.nan_to_num(df.loc[df['date'].isin(test_index), X_col].values)\n    pred_df = df.loc[df['date'].isin(test_index), ['date', 'resp', 'weight']]\n    stats = {'resp_mean': pred_df['resp'].mean(),\n             'resp_median': pred_df['resp'].median(),\n             'resp_std': pred_df['resp'].std(),\n             'wgt_median': pred_df['weight'].median()}\n    \n    # Model training\n    model = __create_NN_model__(NN_params, input_shape=x_train.shape[1])\n    model.compile(loss=__profit_maximizer__, \n                  optimizer=keras.optimizers.Adam(learning_rate=NN_params[\"lr\"]))\n    model.fit(x_train, y_train, \n              epochs=NN_params[\"n_epoch\"], \n              batch_size=np.ceil(x_train.shape[0]/\n                                 NN_params[\"n_batch\"]).astype(int),\n              verbose=0)\n    \n    # Predictions and utility\n    preds = model.predict(x_test)\n    utility = {}\n    for th in oth_params[\"thresholds\"]:\n        pred_df.loc[:, \"action\"] = (preds > th).astype(int)\n        pred_df.loc[:, 'profit'] = pred_df['weight'] * pred_df['resp'] * pred_df['action'] \n        daily_profit = pred_df.groupby('date')['profit'].sum()\n\n        # compute utility and its components \n        p = np.sum(daily_profit)\n        v = np.sqrt(np.sum(daily_profit ** 2)*len(daily_profit)/250)\n        t = p / v\n        u = min(max(0, t), 6) * p\n        print(\"Utility in fold %d with %d%% threshold: %.2f\"%(i+1, int(th*100), u))\n        utility[\"T_\"+str(int(th*100))] = {'profit': p, 'volatility': v, 'ratio': t, 'utility': u}\n        \n    results[\"K\"+str(i+1)] = {'utility': utility, 'stats': stats}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_list = []\nfor k, v in results.items():\n    for t, u in v['utility'].items():\n        x = u.copy()\n        x['threshold'] = t\n        x['kfold'] = k\n        for stat, val in v['stats'].items():\n            x[stat] = val\n        d_list.append(x)\n        \nu_df = pd.DataFrame(d_list).sort_values(['threshold', 'kfold'])\nu_df.to_csv(\"D%s_Kfold_stats.csv\"%now, index=False)\ndisplay(u_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train/test split\nx_train = np.nan_to_num(df[X_col].values)\ny_train = df[\"target\"].values\n\n# Model training\nmodel = __create_NN_model__(NN_params, input_shape=x_train.shape[1])\nmodel.compile(loss=__profit_maximizer__, \n              optimizer=keras.optimizers.Adam(learning_rate=NN_params[\"lr\"]))\nmodel.fit(x_train, y_train, \n          epochs=NN_params[\"n_epoch\"], \n          batch_size=np.ceil(x_train.shape[0]/\n                             NN_params[\"n_batch\"]).astype(int),\n          verbose=1)\n\n# Save model\nn_layer = len(NN_params[\"layers\"]) + 1\nnames = [s + str(i) for i in range(n_layer) for s in [\"w\", \"b\"]]\nweights = {}\nfor i, a in enumerate(model.get_weights()):\n    weights[names[i]] = a.tolist()\nwith open(\"D%s_model_weights.json\"%now, \"w\") as mwf:\n    json.dump(weights, mwf)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}