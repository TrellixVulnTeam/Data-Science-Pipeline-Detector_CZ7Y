{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Decoding](http://www.daskeyboard.com/blog/decode-our-das-keyboard-holiday-message-and-win/decryptthemessage-2/)"},{"metadata":{},"cell_type":"markdown","source":"Inspired by the excellent notebooks [\"De-anonymization: Time Aggregation Tags\"](https://www.kaggle.com/gregorycalvez/de-anonymization-time-aggregation-tags/notebook#De-anonymization:-Time-Aggregation-Tags) and [\"De-anonymization: Price, Quantity, Stocks\"](https://www.kaggle.com/gregorycalvez/de-anonymization-price-quantity-stocks). (I am wondering how I can @author of notebook, sorry about that.) Here a notebook sharing my insights about the features and the meaning of tags. Comments and ideas are welcome!"},{"metadata":{},"cell_type":"markdown","source":"**TL; DR**\n\n* Feature 0: the side of the trade\n* Feature 64: the time in a date\n* Tag 0-4: time window, (length see below, based on feature 64)\n* Feature 41-43: identify a stock in a date\n\n|tag|window|\n|:----|:--------|\n|tag_0|    0.000000|  \n|tag_1|    0.006602|\n|tag_2|    0.020753|\n|tag_3|    0.058880|\n|tag_4|    0.236351|\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datatable as dt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\npd.options.display.max_rows = 999\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\n\ntrain_df = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()\nfeature_tag = pd.read_csv('../input/jane-street-market-prediction/features.csv', index_col=0)\nprint(train_df.shape)\nprint(train_df.columns)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='content'></a>\n# Table of Contents\n\n\n* [Explore & Visualization](#section-1)\n* [Feature 0](#section-2)\n<!--     - [Subsection 1](#subsection-one) -->\n<!--     - [Subsection 2](#anything-you-like) -->\n* [Feature 64 & Tag 22](#section-3)\n* [Tag 0-4](#section-4)\n* [Feature 41-43 & Tag 14](#section-5)\n\n* [TODO](#section-100)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper functions\ndef display_query(query, show = True):\n    query_raw = feature_tag.query(query)\n    query_compact = query_raw.loc[:, query_raw.any()]\n    if show:\n        display((query_compact*1).style.background_gradient(cmap='Oranges', vmin=0, vmax=1))\n        \n    return query_compact\n\n\ndef check_unique(df, sub_cols):\n    return df.drop_duplicates().equals(df.drop_duplicates(subset=sub_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-1\"></a>\n# Explore & Visualization\n[Back to content](#content)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many tags for each feature?\ntag_counts = feature_tag.sum(axis=1)\nfig = px.bar(tag_counts, title = 'Tag counts')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many times each tag occurs in features:\ntag_counts = feature_tag.sum(axis=0)\nfig = px.bar(tag_counts, title = 'Feature counts')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overall visualization:\ndisplay((feature_tag*1).style.background_gradient(cmap='Oranges', vmin=0, vmax=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can play around with different query\n# display_query('tag_6') \n# display_query('tag_6 & tag_9')\n# display_query('tag_20 | tag_28')\nfeatures = display_query('(tag_0 | tag_1 | tag_2 | tag_3 | tag_4)&(tag_23)')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=section-2></a>\n# Feature 0: Side of trade\n\nA binary feature with value 1 and -1, with roughly same number of rows.\n\nEducated guess: side of the trade, i.e. buy/sell the stock\n\n[Back to content](#content)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['feature_0'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean resp, ratio of pos vs neg resp for each side:\ndf = pd.DataFrame()\ndf['Mean resp'] = train_df.groupby('feature_0')['resp'].mean()\ndf['Pos resp ratio'] = train_df.groupby('feature_0')['resp'].apply(lambda s: sum(s>0)/len(s))\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualze the distribution of both side:\nrow_index = train_df['feature_0']>0\n\nfig, ax = plt.subplots()\nax.hist(train_df.loc[row_index, 'resp'], label = 'Buy Order', bins=100, alpha = 0.3, density=True)\nax.hist(train_df.loc[~row_index, 'resp'], label = 'Sell Order', bins=100, alpha = 0.3, density=True)\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Over long term, the return a holding is slightly positive skew.  \n\nTherefore, the guess here is that \"-1\" indidates a **sell** order on the market, which means we are **buying** if the trade is executed.   \nSimilarly, the \"1\" indicates a **buy** order and we take short position if executed."},{"metadata":{},"cell_type":"markdown","source":"<a id=section-3></a>\n# Feature_64 & Tag 22: Intraday time\n\n[Back to content](#content)"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = display_query('tag_22')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at a random sample date:\ndate = 42\nfeature = 'feature_64'\n\nsample_df = train_df.query(f'date == {date}')\nprint(f'Range in date {date}: {min(sample_df[feature]):.4f} - {max(sample_df[feature]):.4f}')\nsample_df[feature].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Range of feature 64 in all dates:\nf_range_df = pd.DataFrame()\nf_range_df['MAX'] = train_df.groupby('date')[feature].max()\nf_range_df['MIN'] = train_df.groupby('date')[feature].min()\nf_range_df = f_range_df.reset_index()\n\npx.line(f_range_df, x='date', y=['MAX', 'MIN'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spot outlier dates from graphs:\noutlier_dates = [2, 14, 87, 294] # 2 & 294 is abnormally short\n\nprint(f'Average trades in a date: {train_df[\"date\"].value_counts().mean():.2f}')\nprint(train_df.loc[train_df.date.isin(outlier_dates), 'date'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Consistency check of clock feature:\nreverse_clock = train_df[feature] < train_df[feature].shift(1)\nnew_date = train_df['date'] > train_df['date'].shift(1)\n\nall(reverse_clock == new_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the lunch gap:\nsub_df = train_df[['date',feature]].copy()\nsub_df[f'{feature}_pre'] = sub_df[feature].shift(1)\ngap_df = sub_df.loc[(sub_df[feature].diff() > 0.5) & (sub_df[feature]>0) & (sub_df[feature]<4), :]\nlunch_start = gap_df[feature+\"_pre\"].mean()\nlunch_end = gap_df[feature].mean()\n\nprint(f'The lunch gap is from {lunch_start:.4f} to {lunch_end:.4f}')\npx.line(gap_df, x='date', y = [feature, feature+'_pre'])\n# any(gap_df.date.duplicated())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of number of trades during a trading date:\nfig, ax = plt.subplots()\nfor i in range(10, 18):\n    sample_ser = train_df.loc[train_df.date==i, feature]\n    ax.scatter(x=sample_ser, y = list(range(len(sample_ser))), label = f'Date {i}', alpha=0.2, s=1)\n\nax.legend(markerscale = 10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{},"cell_type":"markdown","source":"<a id = \"section-4\"></a>\n# Tag 0-4: Time windows\n\n[Back to content](#content)"},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_query = '(tag_0|tag_1|tag_2|tag_3|tag_4)'\nadd_query = '&(tag_6|tag_23)'\nfeatures = display_query(basic_query+add_query)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date = 12\nx_col = 'feature_64'\nsample_df = train_df.query(f'date == {date}')\ndf = pd.DataFrame()\ndf['time'] = sample_df[x_col]\nlunch_end = 1.3769\n\ncols = []\nfor i in range(5):\n    y_col = features.index[features[f'tag_{i}']]\n    count_col = f'NA_counts_tag_{i}'\n    cols.append(count_col)\n    df[count_col] = sample_df[y_col].isnull().sum(axis=1)\n    \n    missing_time = df.loc[df[count_col]>0, 'time']\n    if len(missing_time)>0:\n        window = max(missing_time) - lunch_end\n        print(f'Estimated window len of tag_{i}: {window:.4f}')\n    else:\n        print(f'Fail at date {date}')\n\npx.line(df, x='time', y=cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def estimate_window_len(date, tag):\n    x_col = 'feature_64'\n    sample_df = train_df.query(f'date == {date}')\n    features = display_query(f'(tag_23|tag_6) & {tag}', show=False)\n    y_cols = features.index\n    \n    df = pd.DataFrame()\n    df['time'] = sample_df[x_col]\n    df['NA_counts'] = sample_df[y_cols].isnull().sum(axis=1)\n    missing_time = df.loc[df['NA_counts']>0, 'time']\n    if len(missing_time)>0:\n        window = max(missing_time) - lunch_end\n        if window > 0:\n            return window\n        else:\n            return 0\n    else:\n        return np.nan\n\n# estimate_window_len(12, 'tag_2')\n\nestimate_df = pd.DataFrame()\noutlier_dates = [2, 14, 87, 294]\nfor i in range(0, 5):\n    for date in range(50):\n        if date in outlier_dates:\n            continue\n        estimate_df.loc[date, f'tag_{i}'] = estimate_window_len(date, f'tag_{i}')\n\nprint('Estimate windows: (first 50 dates)')\nprint(estimate_df.median())\n\n\nestimate_df = pd.DataFrame()\noutlier_dates = [2, 14, 87, 294]\nfor i in range(0, 5):\n    for date in range(450, 500):\n        if date in outlier_dates:\n            continue\n        estimate_df.loc[date, f'tag_{i}'] = estimate_window_len(date, f'tag_{i}')\n\nprint('Estimate windows: (last 50 dates)')\nprint(estimate_df.median())\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"section-5\"></a>\n# Feature 41-43 & Tag 14: Stock in Date\n\nUsing feature 41-45 (or just only feature 45) provide the same identity.\n\n[Back to content](#content)"},{"metadata":{"trusted":true},"cell_type":"code","source":"date = 12\nid_cols = ['feature_41', 'feature_42', 'feature_43']\n\nsample_df = train_df.query(f'date == {date}').copy()\nsample_df['stock_id'] = sample_df['feature_41'].astype(str) +\"_\"+sample_df['feature_42'].astype(str) +\"_\"+ sample_df['feature_43'].astype(str)\nsample_df[id_cols+['stock_id']]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df['stock_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = display_query('tag_5')\nfeature_name = features.index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relation of tag 5 features support the identification:\nfor i in range(features.shape[0]//2):\n    col_x = feature_name[2*i]\n    col_y = feature_name[2*i+1]\n    fig = px.scatter(sample_df, x=col_x, y=col_y, color = 'stock_id')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_dates = [2, 14, 87, 294]\n\ndf = pd.DataFrame()\ndf['date'] = list(range(500))\ndf['trade'] = train_df['date'].value_counts()\ndf['stock'] = train_df.groupby('date').apply(lambda df: len(df[id_cols].value_counts()) )\ndf = df.loc[~df.date.isin(outlier_dates), :]\ndf['ratio'] = df['trade']/df['stock']\n\ndf.set_index('date').plot(subplots=True)\n\nprint(f'Trades: {df.trade.mean():.2f} with std ({df.trade.std():.2f})')\nprint(f'Stocks: {df.stock.mean():.2f} with std ({df.stock.std():.2f})')\nprint(f'Ratio: {df.ratio.mean():.4f} with std {df.ratio.std():.4f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"section-100\"></a>\n# TODO:\n\n* use time and stock identification to have better understand of other features and tags.\n* better NA filling methods than mean/median or naive backward/forward filling\n* feature engineer is possible after better understanding meanings of tags.\n\n[Back to content](#content)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}