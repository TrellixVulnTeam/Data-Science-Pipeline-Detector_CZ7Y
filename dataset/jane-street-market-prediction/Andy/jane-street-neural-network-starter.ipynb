{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jane Street: Neural Network Starter\n\nI try implementing a simple Tensorflow Keras neural network here. Train in Version 17.\n\n**Caution:** The GroupCV method applied in this notebook may cause time leakage problem. Please use [Purged Time-Series CV][1] instead.\n\n[1]: https://www.kaggle.com/marketneutral/purged-time-series-cv-xgboost-optuna"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\n# import cudf\nimport pandas as pd\nimport numpy as np\n# import cupy as cp\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\n\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# print('Loading...')\n# train = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/jane-street-market-prediction/example_test.csv', nrows = 3)\nfeatures = [c for c in test_df.columns if 'feature' in c]\n\n# print('Filling...')\n# f_mean = train[features[1:]].mean()\n# train = train.query('weight > 0').reset_index(drop = True)\n# train[features[1:]] = train[features[1:]].fillna(f_mean)\n# train['action'] = (train['resp'] > 0).astype('int')\n\n# print('Converting...')\n# train = train.to_pandas()\n# f_mean = f_mean.values.get()\n# np.save('f_mean.npy', f_mean)\n\n# print('Finish.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model\n\nprice_index = list(range(1, 41))\nbuy_index = list(range(84, 96))\nsell_index = list(range(96, 108))\n\ndef FE_infer(test_data):\n    test_data[0, buy_index+sell_index] = test_data[0, sell_index+buy_index]\n    test_data[0, price_index] = - test_data[0, price_index]\n    return test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096\nhidden_units = [160, 160, 160]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\n# oof = np.zeros(len(train['action']))\n# gkf = GroupKFold(n_splits = 5)\n# for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n    \n#     X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n#     y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n    \n#     ckp_path = f'JSModel_{fold}.hdf5'\n#     model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n#     rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n#                             min_delta = 1e-4, mode = 'max')\n#     ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n#                           save_best_only = True, save_weights_only = True, mode = 'max')\n#     es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n#                        baseline = None, restore_best_weights = True, verbose = 0)\n#     model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 1000, \n#               batch_size = batch_size, callbacks = [rlr, ckp, es], verbose = 0)\n                \n#     oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n#     score = roc_auc_score(y_val, oof[te])\n#     print(f'Fold {fold} ROC AUC:\\t', score)\n    \n#     # Finetune 3 epochs on validation set with small learning rate\n#     model = create_mlp(X_tr.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate / 100)\n#     model.load_weights(ckp_path)\n#     model.fit(X_val, y_val, epochs = 3, batch_size = batch_size, verbose = 0)\n#     model.save_weights(ckp_path)\n    \n#     K.clear_session()\n#     del model\n#     rubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score_oof = roc_auc_score(train['action'].values, oof)\n# print(score_oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_models = 3\n\nmodels = []\nfor i in range(num_models):\n    clf = create_mlp(len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)\n    clf.load_weights(f'../input/nn-ensemble-all-normal-busy-fe-by-side/JSNN_model_{i}.h5')\n\n    models.append(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = np.load('../input/na-filling/f_mean.npy')\nf_median = np.load('../input/na-filling/f_median.npy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submitting\n\nJust use two models to reduce running time."},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"th = 0.50\nensemble_weight = [0.3, 0.5, 0.2]\nindex_features = [n for n,col in enumerate(test_df.columns) if col in features]\n\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        # FE:\n        x_tt = test_df.values[0, index_features].reshape(1,-1)\n        if np.isnan(x_tt[0, :].sum()):\n            x_tt[:, :] = np.nan_to_num(x_tt[:, :]) + np.isnan(x_tt[:, :]) * f_median\n        if test_df['feature_0'].item()<0:\n            x_tt = FE_infer(x_tt)\n            \n        # Inference:\n        pred = np.median(np.average([model(x_tt, training=False).numpy() for model in models], axis=0, weights=ensemble_weight))\n        pred_df[\"action\"].values[0] = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df[\"action\"].values[0] = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}