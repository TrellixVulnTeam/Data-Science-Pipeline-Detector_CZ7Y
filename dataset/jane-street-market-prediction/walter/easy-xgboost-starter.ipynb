{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pickle_file = '../input/pickling/train.csv.pandas.pickle'\ntrain = pickle.load(open(train_pickle_file, 'rb'))\n\nfeatures = [c for c in train.columns if \"feature\" in c]\ntrain = train[train['weight'] != 0]\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain.fillna(train.mean(),inplace=True)\n\nf_mean = np.mean(train[features[1:]].values,axis=0)\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\ngroups = train['date'].values\n\ny = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T #Multitarget","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid = train.loc[(train.date >= 450) & (train.date < 500)].reset_index(drop=True)\ntrain = train.loc[train.date < 450].reset_index(drop=True)\n\nX_train = train.loc[:, train.columns.str.contains('feature')].values\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n\nX_valid = valid.loc[:, valid.columns.str.contains('feature')].values\ny_valid = np.stack([(valid[c] > 0).astype('int') for c in resp_cols]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom tqdm import tqdm\n\n\nparams_1 = {'n_estimators': 494, 'max_depth': 8, 'min_child_weight': 6, 'learning_rate': 0.009624384025871735, \n            'subsample': 0.8328412036014541, 'gamma': 0, 'colsample_bytree': 0.715303237773365,\n           'objective':'binary:logistic', 'eval_metric': 'auc','tree_method': 'hist', 'random_state': 42,}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING= False\n\nif TRAINING:\n    model = xgb.XGBClassifier(**params_1,n_jobs=-1)\n    model.fit(X_train, y_train[:,3], eval_set=[(X_valid, y_valid[:,3])], eval_metric='auc',verbose=100, callbacks = [xgb.callback.EarlyStopping(rounds=300,save_best=True)])\n    pickle.dump(model,open(\"./simple-xgb.dat\",\"rb\"))\nelse:\n    model = pickle.load(open(\"../input/jsxgb/simple-xgb.dat\",\"rb\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport janestreet\nfrom numba import njit\nenv = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit\ndef fillna_npwhere_njit(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\ntest_df_columns = ['weight'] + [f'feature_{i}' for i in range(130)] + ['date']\nindex_features = [n for n,col in enumerate(test_df_columns) if col in features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].values[0]>0:\n        x_tt = test_df.values[0][index_features].reshape(1,-1)\n        x_tt[:, 1:] = fillna_npwhere_njit(x_tt[:, 1:][0], f_mean)\n        y_pred = model.predict(x_tt)\n        pred_df.action = int(y_pred)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}