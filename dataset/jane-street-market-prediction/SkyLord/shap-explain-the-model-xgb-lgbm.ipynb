{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SHAP values & model interpretability \n\nSHAP values explain the change in the expected model prediction based on the feature values. \n\n![](https://unsplash.com/photos/lOcP_QZzitI)\n\n> \n> SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations.\n> \n"},{"metadata":{},"cell_type":"markdown","source":"![](https://commons.wikimedia.org/wiki/File:Anne-nygard-lOcP_QZzitI-unsplash.jpg)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 500)\n\n\n# Standard plotly imports\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\nimport os\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Create Environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost version:\", xgb.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('# File sizes')\ntotal_size = 0\nstart_path = '../input/jane-street-market-prediction'  # To get size of current directory\nfor path, dirs, files in os.walk(start_path):\n    for f in files:\n        fp = os.path.join(path, f)\n        total_size += os.path.getsize(fp)\nprint(\"Directory size: \" + str(round(total_size/ 1000000, 2)) + 'MB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\nfeatures = pd.read_csv('../input/jane-street-market-prediction/features.csv')\nexample_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nprint (\"Data is loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reducting memory usage by 75% \n\nSource: https://www.kaggle.com/sbunzini/reduce-memory-usage-by-75"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_memory_usage(df):\n    \n    start_memory = df.memory_usage().sum() / 1024**2\n    print(f\"Memory usage of dataframe is {start_memory} MB\")\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    pass\n        else:\n            df[col] = df[col].astype('category')\n    \n    end_memory = df.memory_usage().sum() / 1024**2\n    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_memory_usage(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing/total_cells) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing before training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I have taked this cell from https://www.kaggle.com/jazivxt/the-market-is-reactive\n# And https://www.kaggle.com/drcapa/jane-street-market-prediction-starter-xgb\n\ntrain = train[train['weight'] != 0]\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\ny_train = train.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.fillna(-999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training\n##### To activate GPU usage, simply use tree_method='gpu_hist' (took me an hour to figure out, I wish XGBoost documentation was clearer about that)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# The training part taked from here https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s\n\nclf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=10,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Shap library & **initjs()**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The next few blocks of code will take some time to run!"},{"metadata":{},"cell_type":"markdown","source":"Since computing the shap values for the entire set takes an *inordinately* long time, we will use only a small sample(of around ~10k).   "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# compute the SHAP values for every prediction in the validation dataset\nexplainer = shap.TreeExplainer(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_sample = X_train.sample(10000)\nshap_values = explainer.shap_values(X_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value, shap_values[0,:], X_sample.iloc[0,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort the features indexes by their importance in the model\n# (sum of SHAP value magnitudes over the validation dataset)\ntop_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n\n# make SHAP plots of the three most important features\nfor i in range(20):\n    shap.dependence_plot(top_inds[i], shap_values, X_sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGB model"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = features.set_index('feature')\nfeatures = features.T * 1\nfeatures.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nfrom sklearn import *\n\nk = cluster.KMeans(n_clusters=29, random_state=0).fit(features[['feature_' + str(i) for i in range(130)]])\nn = preprocessing.Normalizer()\nX_train['k'] = k.predict(n.fit_transform(X_train[['feature_' + str(i) for i in range(130)]].fillna(-999)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = [c for c in X_train.columns if c not in ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id', 'date', 'action']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'objective':'binary', 'boosting': 'gbdt', 'learning_rate': 0.2, 'max_depth': -1, 'random_state': 20, 'device':'gpu'}\nx1, x2, y1, y2 = model_selection.train_test_split(X_train[col], y_train, test_size=0.3, random_state=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(params, lgb.Dataset(x1, y1), 450,  lgb.Dataset(x2, y2), verbose_eval=100, early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# compute the SHAP values for every prediction in the validation dataset\nexplainer = shap.TreeExplainer(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_sample = x2.sample(10000)\nshap_values = explainer.shap_values(X_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value[0], shap_values[0][0,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort the features indexes by their importance in the model\n# (sum of SHAP value magnitudes over the validation dataset)\ntop_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n\n# make SHAP plots of the three most important features\nfor i in range(20):\n    shap.dependence_plot(top_inds[0][i], shap_values[0], X_sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Credits to the following notebooks**\n\n[Reduce Memory Usage by 75%](https://www.kaggle.com/sbunzini/reduce-memory-usage-by-75)\n\n[Market Prediction: XGBoost with GPU (Fit in 1min)](https://www.kaggle.com/hamditarek/market-prediction-xgboost-with-gpu-fit-in-1min)\n\n[The market is reactive](https://www.kaggle.com/jazivxt/the-market-is-reactive)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}