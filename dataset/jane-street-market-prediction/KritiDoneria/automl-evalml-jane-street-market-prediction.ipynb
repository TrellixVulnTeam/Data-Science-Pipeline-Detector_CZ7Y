{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello.\n\nI find AutoML tools the best for baseline models, so here I'm trying another one called EvalML. You may find my other AutoML notebooks [here ](https://www.kaggle.com/kritidoneria/code?userId=1260510&sortBy=dateRun&tab=profile&language=Python&privacy=public)\n\nA huge shoutout to [this](https://www.kaggle.com/gauravduttakiit/automate-the-ml-pipelines-with-evalml) Notebook for introducing me to this library.\n[I've also used EvalML to compete in TPS May](https://www.kaggle.com/kritidoneria/automl-tps-may21-using-evalml)\nAnother reference for this work is [here](https://www.kaggle.com/tsnarendran14/jane-street-simple-xgb-model/data)","metadata":{}},{"cell_type":"markdown","source":"<h1> Introduction to library </h1>","metadata":{}},{"cell_type":"markdown","source":"Source: https://github.com/alteryx/evalml\n\nEvalML is an AutoML library which builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.\n\n**Key Functionality**\n\n1. Automation - Makes machine learning easier. Avoid training and tuning models by hand. Includes data quality checks, cross-validation and more.\n2. Data Checks - Catches and warns of problems with your data and problem setup before modeling.\n3. End-to-end - Constructs and optimizes pipelines that include state-of-the-art preprocessing, feature engineering, feature selection, and a variety of modeling techniques.\n4. Model Understanding - Provides tools to understand and introspect on models, to learn how they'll behave in your problem domain.\n5. Domain-specific - Includes repository of domain-specific objective functions and an interface to define your own.","metadata":{}},{"cell_type":"markdown","source":"<h1> Installation from Pypi </h1>","metadata":{}},{"cell_type":"code","source":"!pip install evalml","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Load the Dataset </h1>","metadata":{}},{"cell_type":"code","source":"import evalml\nfrom evalml import AutoMLSearch\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv',nrows=1000)\n#limiting rows here because of computational bottlenecks\ny = pd.read_csv('/kaggle/input/jane-street-market-prediction/example_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Preprocessing</h2>","metadata":{}},{"cell_type":"code","source":"# Only selecting the columns where missing values is less than7 percent\nfinal_cols = X.isnull().mean()[X.isnull().mean() < 0.07]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting only the required columns\nX = X[final_cols.index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling NA values with median\nX = X.fillna(X.median())\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['action'] = np.where((X.resp_1 > 0) & (X.resp_2 > 0) & (X.resp_3 > 0) & (X.resp_4 > 0) & (X.resp > 0),1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X.drop(columns = ['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id','action']),X['action'], problem_type='binary')\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the search for the best classification model.","metadata":{}},{"cell_type":"code","source":"#limiting search for efficiency\nautoml = AutoMLSearch(X_train=X_train, y_train=y_train,   problem_type='binary',allowed_model_families=['xgboost', 'lightgbm','catboost'],max_batches=5)\nautoml.search() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Model rankings and best pipeline </h1>","metadata":{}},{"cell_type":"code","source":"automl.rankings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Making predictions </h1>","metadata":{}},{"cell_type":"code","source":"winner = automl.best_pipeline\ndf_submission = winner.predict_proba(y.drop(columns=['ts_id'])).to_dataframe()\ndf_submission['ts_id'] = y['ts_id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.set_index('ts_id').to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}