{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 500)\n\n\n# Standard plotly imports\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\nimport os\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport janestreet\n\n\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb\n\nprint(\"XGBoost version:\", xgb.__version__)\n\n\ntrain = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv') ##, nrows=500)\nfeatures = pd.read_csv('../input/jane-street-market-prediction/features.csv')\nexample_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nprint (\"Data is loaded!\")\n\nprint('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))\n\n#train.head()\n\n# I have taked this cell from https://www.kaggle.com/jazivxt/the-market-is-reactive\n# And https://www.kaggle.com/drcapa/jane-street-market-prediction-starter-xgb\n\ntrain = train[train['weight'] != 0]\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\ny_train = train.loc[:, 'action']\n\nX_train = X_train.fillna(-999)\n\n\ny = train['action'].value_counts().values\n\n# trace2 = go.Bar(\n#          x=x ,\n#          y=y,\n#          marker=dict(\n#                       color=y,\n#                       colorscale = 'Viridis',\n#                       reversescale = True\n#                   ),\n#          name=\"Imbalance\",\n#      )\n# layout = dict(\n#          title=\"Data imbalance - action\",\n#          #width = 900, height = 500,\n#          xaxis=go.layout.XAxis(\n#                   automargin=True),\n#          yaxis=dict(\n#                       showgrid=False,\n#                       showline=False,\n#                       showticklabels=True,\n#               #         domain=[0, 0.85],\n#                   ),\n#     )\n# fig1 = go.Figure(data=[trace2], layout=layout)\n# iplot(fig1)\n\n\n# del x, y, train\n\n# The training part taked from here https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s\n\n#import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# clf = xgb.XGBClassifier(\n#         n_estimators=500,\n#         max_depth=13,\n#         learning_rate=0.05,\n#         subsample=0.9,\n#         colsample_bytree=0.7,\n#         missing=-999,\n#         random_state=2020,\n#         tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n#     )\n\n##%time clf.fit(X_train, y_train)\n\n### begin linear regression\n\n#y_train,X_train\n\n\n# Load the diabetes dataset\n#diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True) ## two arrays\n\n# Use only one feature\n#diabetes_X = diabetes_X[:, np.newaxis, 2]\n\n# Split the data into training/testing sets\n# diabetes_X_train = diabetes_X[:-20]\n# diabetes_X_test = diabetes_X[-20:]\n\n# # Split the targets into training/testing sets\n# diabetes_y_train = diabetes_y[:-20]\n# diabetes_y_test = diabetes_y[-20:]\n\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\n##regr.fit(diabetes_X_train, diabetes_y_train)\n\nregr.fit(X_train, y_train)\n\n# Make predictions using the testing set\n# diabetes_y_pred = regr.predict(diabetes_X_test)\n\n# # The coefficients\n# print('Coefficients: \\n', regr.coef_)\n# # The mean squared error\n# print('Mean squared error: %.2f'\n#             % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n# # The coefficient of determination: 1 is perfect prediction\n# print('Coefficient of determination: %.2f'\n#             % r2_score(diabetes_y_test, diabetes_y_pred))\n\n# Plot outputs\n# plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n# plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n\n# plt.xticks(())\n# plt.yticks(())\n\n# plt.show()\n### end linear regression\n\nfor (test_df, sample_prediction_df) in iter_test:\n  X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n  X_test.fillna(-999, inplace = True)\n  y_preds = regr.predict(X_test)\n  print(len(y_preds))\n  ##y_preds = clf.predict(X_test)\n  if y_preds >= 0.004:\n    sample_prediction_df.action = 1\n  else:\n    sample_prediction_df.action = 0          \n  env.predict(sample_prediction_df)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}