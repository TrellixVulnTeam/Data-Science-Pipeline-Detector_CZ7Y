{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datatable as dt\nimport matplotlib.pyplot as plt\nimport gc\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nimport pickle\n\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\nfrom sklearn import set_config\nset_config(display='diagram') \n\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=pd.core.common.SettingWithCopyWarning)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\nclass PurgedGroupTimeSeriesSplitStacking(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Allows for a gap in groups to avoid potentially leaking info from\n    train into test if the model has windowed or lag features.\n    Provides train/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    stacking_mode : bool, default=True\n        Whether to provide an additional set to test a stacking classifier or not. \n    max_train_group_size : int, default=Inf\n        Maximum group size for a single training set.\n    max_val_group_size : int, default=Inf\n        Maximum group size for a single validation set.\n    max_test_group_size : int, default=Inf\n        We discard this number of groups from the end of each train split, if stacking_mode = True and None \n        it defaults to max_val_group_size.\n    val_group_gap : int, default=None\n        Gap between train and validation\n    test_group_gap : int, default=None\n        Gap between validation and test, if stacking_mode = True and None \n        it defaults to val_group_gap.\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 stacking_mode=True,\n                 max_train_group_size=np.inf,\n                 max_val_group_size=np.inf,\n                 max_test_group_size=np.inf,\n                 val_group_gap=None,\n                 test_group_gap=None,\n                 verbose=False\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_group_size = max_train_group_size\n        self.max_val_group_size = max_val_group_size\n        self.max_test_group_size = max_test_group_size\n        self.val_group_gap = val_group_gap\n        self.test_group_gap = test_group_gap\n        self.verbose = verbose\n        self.stacking_mode = stacking_mode\n        \n    def split(self, X, y=None, groups=None):\n        if self.stacking_mode:\n            return self.split_ensemble(X, y, groups)\n        else:\n            return self.split_standard(X, y, groups)\n        \n    def split_standard(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and validation set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/validation set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        val : ndarray\n            The validation set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_splits = self.n_splits\n        group_gap = self.val_group_gap\n        max_val_group_size = self.max_val_group_size\n        max_train_group_size = self.max_train_group_size\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_val_size = min(n_groups // n_folds, max_val_group_size)\n        group_val_starts = range(n_groups - n_splits * group_val_size,\n                                  n_groups, group_val_size)\n        for group_val_start in group_val_starts:\n            train_array = []\n            val_array = []\n\n            group_st = max(0, group_val_start - group_gap - max_train_group_size)\n            for train_group_idx in unique_groups[group_st:(group_val_start - group_gap)]:\n                train_array_tmp = group_dict[train_group_idx]\n                \n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n \n            for val_group_idx in unique_groups[group_val_start:\n                                                group_val_start +\n                                                group_val_size]:\n                val_array_tmp = group_dict[val_group_idx]\n                val_array = np.sort(np.unique(\n                                              np.concatenate((val_array,\n                                                              val_array_tmp)),\n                                     axis=None), axis=None)\n\n            val_array  = val_array[group_gap:]\n            \n            \n            if self.verbose > 0:\n                    pass\n                    \n            yield [int(i) for i in train_array], [int(i) for i in val_array]\n            \n    def split_ensemble(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training, validation and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        val : ndarray\n            The validation set indices for that split (testing indices for base classifiers).\n        test : ndarray\n            The testing set indices for that split (testing indices for final classifier)\n        \"\"\"\n\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n            \n        X, y, groups = indexable(X, y, groups)\n        n_splits = self.n_splits\n        val_group_gap = self.val_group_gap\n        test_group_gap = self.test_group_gap\n        if test_group_gap is None:\n            test_group_gap = val_group_gap\n        max_train_group_size = self.max_train_group_size\n        max_val_group_size = self.max_val_group_size\n        max_test_group_size = self.max_test_group_size\n        if max_test_group_size is None:\n            max_test_group_size = max_val_group_size\n            \n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_val_size = min(n_groups // n_folds, max_val_group_size)\n        group_test_size = min(n_groups // n_folds, max_test_group_size)\n        \n        group_test_starts = range(n_groups - n_splits * group_test_size, n_groups, group_test_size)\n        train_indices= []\n        val_indices= []\n        test_indices= []\n        \n        for group_test_start in group_test_starts:\n\n            train_array = []\n            val_array = []\n            test_array = []\n            \n            val_group_st = max(max_train_group_size + val_group_gap, \n                               group_test_start - test_group_gap - max_val_group_size)\n\n            train_group_st = max(0, val_group_st - val_group_gap - max_train_group_size)\n\n            for train_group_idx in unique_groups[train_group_st:(val_group_st - val_group_gap)]:\n\n                train_array_tmp = group_dict[train_group_idx]\n\n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n\n            for val_group_idx in unique_groups[val_group_st:(group_test_start - test_group_gap)]:\n                val_array_tmp = group_dict[val_group_idx]\n                val_array = np.sort(np.unique(\n                                              np.concatenate((val_array,\n                                                              val_array_tmp)),\n                                     axis=None), axis=None)\n\n            val_array  = val_array[val_group_gap:]\n\n            for test_group_idx in unique_groups[group_test_start:(group_test_start + group_test_size)]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n\n            test_array  = test_array[test_group_gap:]\n\n            yield [int(i) for i in train_array], [int(i) for i in val_array], [int(i) for i in test_array]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pickle save and load fitted model"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/jane-street-market-prediction/'\nsave_path = './'\n# LOAD_PATH = '../input/mlp012003weights'\n# f\"{CACHE_PATH}/online_model{_fold}.pth\"\n\ndef save_pickle(dic, save_path):\n    with open(save_path, 'wb') as f:\n    # with gzip.open(save_path, 'wb') as f:\n        pickle.dump(dic, f)\n\ndef load_pickle(load_path):\n    with open(load_path, 'rb') as f:\n    # with gzip.open(load_path, 'rb') as f:\n        message_dict = pickle.load(f)\n    return message_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = (\n    dt.fread('../input/jane-street-market-prediction/train.csv')\n      .to_pandas()\n)\npd.set_option('display.max_columns', None)\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns})[train['date']>85]\ntrain_85 = train[train['date']<=85]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ignoring rows with weight=0 (which are included for completeness)\ntrain = train.query('weight > 0').reset_index(drop = True)\n\n#Last value imputation using ffillna\nfeatures = [c for c in train.columns if 'feature' in c]\ntrain[features] = train[features].fillna(method = 'ffill').fillna(0)\ntrain['action'] = (train['resp'] > 0).astype('int')\n\n#feature drop\nto_be_dropped = ['feature_21','feature_24','feature_25','feature_55',\n                  'feature_58','feature_121','feature_127','feature_61',\n                  'feature_63','feature_5','feature_3','feature_38',\n                  'feature_66','feature_69', 'feature_12', 'feature_26', 'feature_68',\n                  'feature_7','feature_8','feature_17','feature_18',\n                  'feature_27','feature_28','feature_72','feature_78',\n                  'feature_84','feature_90','feature_96','feature_102',\n                  'feature_108','feature_114',\n                  'feature_35','feature_36','feature_32','feature_40',\n                  'feature_48','feature_122','feature_128','feature_76',\n                  'feature_110','feature_101','feature_113','feature_116',\n                  'feature_107','feature_119','feature_129','feature_126'] \n#to_be_selected = [x for x in features if (x not in to_be_dropped)]\nto_be_selected = ['feature_41','feature_42','feature_43', 'feature_55', 'feature_56',\n                  'feature_57','feature_58','feature_59','feature_60',\n                  'feature_1','feature_2','feature_3', 'feature_4','feature_5',\n                  'feature_6','feature_7','feature_8','feature_9',\n                  'feature_44','feature_45','feature_90','feature_92','feature_93',\n                  'feature_99','feature_101','feature_119','feature_104','feature_107',\n                  'feature_102','feature_105','feature_73','feature_74','feature_75',\n                  'feature_120','feature_121','feature_122','feature_123','feature_124',\n                  'feature_125','feature_126','feature_127','feature_128']\n\n#train = train.drop(columns=to_be_dropped)\nto_be_selected.append('date')\nto_be_selected.append('action')\ntrain = train.loc[:,to_be_selected]\nf_mean = np.mean(train.loc[:,to_be_selected].values,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X,y\nX_utility = train.copy()\nX = train.loc[:, [c for c in train.columns if 'feature' in c]]\n#standard scaling\nX = StandardScaler().fit_transform(X)\ny = train.loc[:,'action']\nX_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X), y, test_size=0.2, random_state = 42)\ngroups=train.iloc[X_train.index]['date'].values","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from matplotlib.colors import ListedColormap\n\nname_dict = {True: 'With_Stacking_Set', \n             False: 'No_Stacking_Set'}\n\ndef plot_cv_indices_stacking(cv, X, y, group, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    \n    cmap_cv = plt.cm.coolwarm\n\n    jet = plt.cm.get_cmap('jet', 256)\n    seq = np.linspace(0, 1, 256)\n    _ = np.random.shuffle(seq)   # inplace\n    cmap_data = ListedColormap(jet(seq))\n\n    # Generate the training/testing visualizations for each CV split\n    for ii, indices_split in enumerate(cv.split(X=X, y=y, groups=groups)):\n        # Fill in indices with the training/test groups\n        \n        indices = np.array([np.nan] * len(X))\n        indices[indices_split[0]] = 1\n        indices[indices_split[1]] = 0\n        if cv.stacking_mode:\n            indices[indices_split[2]] = -1\n\n        # Visualize the results\n        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n                   vmin=-.2, vmax=1.2)\n\n    # Plot the data classes and groups at the end\n    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n\n    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n               c=group, marker='_', lw=lw, cmap=cmap_data)\n    \n    if cv.stacking_mode:\n        ax.scatter(range(len(X)), [ii + 3.5] * len(X),\n               c=group, marker='_', lw=lw, cmap=cmap_data)\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + ['target', 'day']\n    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n           xlabel='Sample index', ylabel=\"CV iteration\",\n           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n    \n    ax.set_title('{}'.format(name_dict[cv.stacking_mode]), fontsize=15)\n    #ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train,X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig, ax = plt.subplots(1, 1, figsize = (20, 12))\n\n#plot_cv_indices_stacking(cv, train[to_be_selected], train['action'], train['date'], \n#                         Sax, 5, lw=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optuna optimization + purged cv "},{"metadata":{"trusted":true},"cell_type":"code","source":"N_SPLITS = 5\nSTACKING_MODE = True\nVAL_GROUP_GAP = 20 #Days between end of training set and start of validation set\nTEST_GROUP_GAP = 20 #Days between end of validation set and start of testing/stacking set\nMAX_DAYS_TRAIN = 120\nMAX_DAYS_VAL = 60\nMAX_DAYS_TEST = 60\nRANDOM_SEED = 28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = PurgedGroupTimeSeriesSplitStacking(n_splits=N_SPLITS,\n    stacking_mode=STACKING_MODE,\n    max_train_group_size=MAX_DAYS_TRAIN, max_val_group_size=MAX_DAYS_VAL,\n    max_test_group_size=MAX_DAYS_TEST, val_group_gap=VAL_GROUP_GAP,\n    test_group_gap=TEST_GROUP_GAP)\n\n# Use the following to test your pipeline\ncv_dummy = PurgedGroupTimeSeriesSplitStacking(n_splits=2,\n    stacking_mode=STACKING_MODE,\n    max_train_group_size=1, max_val_group_size=1,\n    max_test_group_size=1, val_group_gap=1,\n    test_group_gap=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n#from sklearn.ensemble import AdaBoostClassifier\n#from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression # 메타 모델\n#from sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import VotingClassifier\n#import xgboost as xgb\n#import lightgbm as lgb \nfrom sklearn.ensemble import RandomForestClassifier as rf\n\n\nN_TRIALS=5\ndef objective(trial, cv=cv_dummy):\n    \n    #xgb parameters\n    param_xgb = {\n        \"verbosity\": 0,\n        \"tree_method\": \"gpu_hist\",\n        \"objective\": \"binary:logistic\",\n        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n        \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 9),\n        \"learning_rate\" : trial.suggest_float(\"eta\", 1e-8, 1.0, log=True),\n        \"gamma\" : trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n        \"grow_policy\" : trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n    }\n\n\n    param_lgb = {\n        \"objective\": \"binary\",\n        \"metric\": \"binary_logloss\",\n        \"verbose\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"device\" : \"gpu\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    \n    model_1 = XGBClassifier(**param_xgb)\n    model_2 = LGBMClassifier(**param_lgb)\n    final_estimator = RandomForestClassifier()\n    \n    # Ensemble bass models\n    models = [\n    ('xgb',model_1),\n    ('lgb',model_2),\n    #('rf',rfclf)\n    ]\n\n    #stack_clf = StackingClassifier(models,final_estimator=final_estimator)   \n    stack_clf = VotingClassifier(estimators=models,voting='hard',weights=[0.35, 0.65],n_jobs=-1)\n\n    val_aucs = []\n    aucs = []\n    for kfold, (train_idx, val_idx, test_idx) in enumerate(cv.split(X_train, \n                                                                    y_train, \n                                                                    groups)):\n\n        %time stack_clf.fit(X_train, y_train)\n    \n        stack_final_pred = stack_clf.predict(X_test) \n        auc = roc_auc_score(y_test, stack_final_pred)\n        print('Classifier: {}\\tFold: {}\\t AUC: {}\\n'.format(type(final_estimator).__name__, kfold, auc))\n        aucs.append(auc)\n    \n    print('Average AUC: {}'.format(np.average(auc)))\n    return np.average(aucs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\n\nstudy = optuna.create_study(study_name = 'stacking_parameter_opt', direction=\"maximize\")\nstudy.optimize(objective, n_trials=N_TRIALS) #Here use N_TRIALS when doing it properly\n\ntrial = study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classifier: AdaBoostClassifier\tFold: 1\t AUC: 0.5887123760591787\n\n# Average AUC: 0.5887123760591787\n#   Value: 0.5887322343881863\nbest_param = {\n    'booster': 'dart',\n    'lambda':0.02269898576617538,\n    'alpha': 1.7519279647804202e-07,\n    'max_depth': 1,\n    'eta': 5.853592180789002e-07,\n    'gamma': 0.00010007997910296745,\n    'grow_policy': 'lossguide',\n    'lambda_l1': 0.10062669044437277,\n    'lambda_l2': 2.7130351663800012e-08,\n    'num_leaves': 255,\n    'feature_fraction':0.9163826994819885,\n    'bagging_fraction':0.8581532897936976,\n    'bagging_freq': 5,\n    'min_child_samples': 70,\n    'tree_method' : 'gpu_hist',\n    'device': 'gpu',\n    'subsample': 0.3\n}\n\n# best_param = {\n#     'lambda': 2.4991265196872308e-08,\n#     'alpha': 0.08940927931061919,\n#     'max_depth': 1,\n#     'eta': 1.4499980913381051e-06,\n#     'gamma': 1.3137575007318098e-05,\n#     'lambda_l1': 0.00010104042809601234,\n#     'lambda_l2': 1.4677308343245044e-07,\n#     'num_leaves': 235,\n#     'feature_fraction': 0.6740934145011883,\n#     'bagging_fraction': 0.7732904443272498,\n#     'bagging_freq': 6,\n#     'min_child_samples': 45,\n#     'subsample' : 0.3 \n# }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#best_param = study.best_trial.params.items()\nmodel_1 = XGBClassifier(**best_param)\nmodel_2 = LGBMClassifier(**best_param)\nfinal_estimator = RandomForestClassifier()\n\n# Ensemble bass models\nmodels = [\n('xgb',model_1),\n('lgb',model_2),\n#('rf',rfclf)\n]\n\nstack_clf_best = VotingClassifier(estimators=models,voting='hard',weights=[0.35, 0.65],n_jobs=-1)\nstack_clf_best.fit(X_train, y_train)\n\n#del X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_pickle(stack_clf_best, './stacking_purgedcv4.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(stack_clf_best))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install hummingbird-ml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hummingbird.ml import convert\nstack_pytorch = convert(stack_clf_best, 'pytorch',None,'gpu')\nprint(type(stack_pytorch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_pickle(stack_pytorch, './stacking_pytorch.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport janestreet\nenv = janestreet.make_env() \niter_test = env.iter_test() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th = 0.503\nf = np.median\n\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    if test_df['weight'].item() > 0 :\n        x_tt = test_df.loc[:, to_be_selected].values     \n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n        y_preds = stack_clf.predict(x_tt)\n        sample_prediction_df.action = np.where(y_preds >= th, 1,0).astype(int)\n    else:\n        sample_prediction_df.action = 0\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utility function"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_utility = X_utility.loc[X_test.index,['date','resp','weight','action']]\n\ndate = X_utility['date'].values\nweight = X_utility['weight'].values\nresp = X_utility['resp'].values\naction = X_utility['action'].values\n\n#import njit\nfrom numba import njit\n\n@njit(fastmath = True)\ndef utility_score_numba(date, weight, resp, action):\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n    u = min(max(t, 0), 6) * np.sum(Pi)\n    return u\nutility_score_numba(date, weight, resp, action)/44000 # * (public test set size)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}