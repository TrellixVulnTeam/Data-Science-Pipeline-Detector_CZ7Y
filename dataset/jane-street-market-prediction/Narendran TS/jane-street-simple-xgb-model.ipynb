{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a simple XGB Model which uses only train data with no feature engineering to check the baseline performance","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom xgboost import XGBClassifier\nimport seaborn as sns\nnp.random.seed(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the data\ntrain = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\nfeatures = pd.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\nsample_submission = pd.read_csv(\"/kaggle/input/jane-street-market-prediction/example_sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.feature.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quick view of text data\nprint(train.head())\nprint(train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting missing value historgram to remove columns with high missing values\nplt.hist(train.isnull().mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only selecting the columns where missing values is less than7 percent based on above graph\nfinal_cols = train.isnull().mean()[train.isnull().mean() < 0.07]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting only the required columns\ntrain = train[final_cols.index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling NA values with median\ntrain = train.fillna(train.median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting correlation\n\nf, ax = plt.subplots(figsize=(10, 8))\n\nsns.heatmap(train.drop(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id'], axis = 1).corr(), \n            mask=np.zeros_like(train.drop(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id'], axis = 1).corr(), dtype=np.bool), \n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Y Variable based on the condition that is resp is greater than 0 for all five columns then the action will be 1\ntrain['action'] = np.where((train.resp_1 > 0) & (train.resp_2 > 0) & (train.resp_3 > 0) & (train.resp_4 > 0) & (train.resp > 0),1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the number responders\ntrain.action.sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A parameter grid for XGBoost\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5],\n        'learning_rate' : [0.02, 0.5], \n        'n_estimators' : [400,600]        \n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decalring XGB\nxgb = XGBClassifier(nthread = -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the train data using default XGB model to remove columns with zero feature importance\nxgb.fit(train.drop(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id', 'action'], axis = 1),train.action, verbose = 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_imp = pd.DataFrame({\"features\":train.drop(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id', 'action'], axis = 1).columns, \"importances\" : xgb.feature_importances_})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting only those columns where feature importance is not equal to zero and selecting only top 20 columns\nfeat_imp = feat_imp[feat_imp['importances']!=0]\nfeat_imp = feat_imp.sort_values(by='importances', ascending=False)\nfeat_imp = feat_imp.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_imp.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform 3 fold random search CV\nfolds = 2\nparam_comb = 2\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, \n                                   cv=skf.split(train[feat_imp.features],train.action), verbose=3, random_state=1001 )\n\n# Here we go\nrandom_search.fit(train[feat_imp.features], train.action)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Prediction on test data. Please refer to https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n# import janestreet\n# env = janestreet.make_env() # initialize the environment\n# iter_test = env.iter_test() # an iterator which loops over the test set\n# for (test_df, sample_prediction_df) in iter_test:\n#     test_df = train.fillna(test_df.median())\n#     test_df['action'] = np.where(test_df['weight'] > 0, xgb.predict(test_df[feat_imp.features]), 0) #make your 0/1 prediction here\n#     env.predict(test_df[['action']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Prediction on test data. Please refer to https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n# feat_imp = pd.DataFrame({\"features\":train.drop(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id', 'action'], axis = 1).columns, \"importances\" : 1})\n# import janestreet\n# env = janestreet.make_env() # initialize the environment\n# iter_test = env.iter_test(np.where(test_df['weight'] > 0, xgb.predict(test_df[feat_imp.features]), 0)) # an iterator which loops over the test set\n# for (test_df, sample_prediction_df) in iter_test:\n#     test_df = train.fillna(test_df.median())\n#     predictions = test_df[feat_imp.features]\n#     sample_prediction_df.action = 0 #make your 0/1 prediction here\n# #     sample_prediction_df.action\n#     env.predict(sample_prediction_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Prediction on test data. Please refer to https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\nimport janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\nfor (test_df, pred_df) in iter_test:\n        if test_df['weight'].item() > 0:\n            X_test = test_df.loc[:, feat_imp.features.values]\n            for k in feat_imp.features.values:\n                if k not in X_test:\n                    X_test[k] = np.nan\n            X_test = test_df.fillna(train[feat_imp.features.values].median())\n            print(X_test.columns)\n            pred = xgb.predict(X_test)\n            pred_df.action = np.where(pred >= 0.5, 1, 0).astype(int)\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}