{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, random, cv2, gc, warnings, math, matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tqdm import tqdm_notebook\nimport tensorflow as tf\ntry:\n    from tensorflow.contrib import keras as keras\n    print ('load keras from tensorflow package')\nexcept:\n    print ('update your tensorflow')\nfrom tensorflow.contrib.keras import models\nfrom tensorflow.contrib.keras import layers\n\nfrom keras import backend as K\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model\nfrom keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n\nwarnings.filterwarnings(\"ignore\")\npath        = '../input/understanding_cloud_organization/'\nimg_width   = 128 \nimg_height  = 128\nnum_classes = 4\ntr          = pd.read_csv(path + 'train.csv')\nprint(len(tr))\ntr.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )\n\ndef mask2rle(img):\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nimg_names_all = tr['Image_Label'].apply(lambda x: x.split('_')[0]).unique()\nlen(img_names_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_ep = True\ndef keras_generator(batch_size):  \n    global new_ep\n    while True:   \n        \n        x_batch = []\n        y_batch = []        \n        for _ in range(batch_size):                         \n            if new_ep == True:\n                img_names =  img_names_all\n                new_ep = False\n            \n            fn = img_names[random.randrange(0, len(img_names))]                                   \n\n            img = cv2.imread(path + 'train_images/'+ fn)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)                       \n            masks = []\n            for rle in tr[tr['Image_Label'].apply(lambda x: x.split('_')[0]) == fn]['EncodedPixels']:                \n                if pd.isnull(rle):\n                    mask = np.zeros((img_width, img_height))\n                else:\n                    mask = rle2mask(rle, img.shape)\n                    mask = cv2.resize(mask, (img_width, img_height))\n                masks.append(mask)                                        \n            img = cv2.resize(img, (img_width, img_height))            \n            x_batch += [img]\n            y_batch += [masks] \n\n            img_names = img_names[img_names != fn]   \n \n        x_batch = np.array(x_batch)\n        y_batch = np.transpose(np.array(y_batch), (0, 2, 3, 1))        \n\n        yield x_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smooth = 1.\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n\ndef get_model():\n    inputs = Input((img_width,img_height, 3))\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv9)\n\n    model = Model(inputs=[inputs], outputs=[conv10])\n#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n#     model.compile(optimizer=Adam(lr=0.001), loss=dice_coef_loss, metrics=[dice_coef])\n    model.compile(optimizer='sgd', loss='binary_crossentropy',metrics=['accuracy'])\n\n    return model\n\nmodel = get_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EpochBegin(keras.callbacks.Callback):\n    def on_epoch_begin (self, epoch, logs={}):\n        global new_ep\n        new_ep = True\nEpoch_Begin_Clb = EpochBegin()\n\nreduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n                              monitor='loss',\n                              mode='auto',\n                              factor=0.666,\n                              patience=1,\n                              min_lr=0,\n                              cooldown=0,\n                              verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nbatch_size=16\nmodel.fit_generator(keras_generator(batch_size),\n              steps_per_epoch=200,                    \n              epochs=2,\n              callbacks=[Epoch_Begin_Clb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_img = []\ntestfiles=os.listdir(path + 'test_images/')\nfor fn in tqdm_notebook(testfiles):     \n        img = cv2.imread( path + 'test_images/'+fn )\n        img = cv2.resize(img,(img_width, img_height))       \n        test_img.append(img)\nlen(test_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npredict = model.predict(np.asarray(test_img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npred_rle = []\nfor img in predict:      \n    img = cv2.resize(img, (525, 350))\n    tmp = np.copy(img)\n    tmp[tmp<np.mean(img)] = 0\n    tmp[tmp>0] = 1\n    for i in range(tmp.shape[-1]):\n        pred_rle.append(mask2rle(tmp[:,:,i]))\nlen(pred_rle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(5, figsize=(20, 20))\naxs[0].imshow(cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350)))\nfor i in range(4):\n    axs[i+1].imshow(rle2mask(pred_rle[i], img.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv( path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '} )\nsub['EncodedPixels'] = pred_rle\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}