{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport json\n\nimport multiprocessing\n\nimport gc\n\nimport albumentations as albu\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras.utils import Sequence\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dropout\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.optimizers import Adam, Nadam\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom copy import deepcopy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n!pip install segmentation-models --quiet\nimport segmentation_models as sm\n\nfrom skimage.exposure import adjust_gamma","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs_folder = '../input/understanding_cloud_organization/test_images/'\ntrain_imgs_folder = '../input/understanding_cloud_organization/train_images/'\nnum_cpu_cores = multiprocessing.cpu_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/understanding_cloud_organization/train.csv')\n# Split Image_Label into ImageId and Label\ntrain_df['ImageId'] = train_df['Image_Label'].apply(lambda x : x.split('_')[0])\ntrain_df['Label'] = train_df['Image_Label'].apply(lambda x : x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)\nprint(mask_count_df.shape)\nmask_count_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"train_ohe_df = train_df[~train_df['EncodedPixels'].isnull()]\nclasses = train_ohe_df['Label'].unique()\ntrain_ohe_df = train_ohe_df.groupby('ImageId')['Label'].agg(set).reset_index()\nfor class_name in classes:\n    train_ohe_df[class_name] = train_ohe_df['Label'].map(lambda x: 1 if class_name in x else 0)\nprint(train_ohe_df.shape)\ntrain_ohe_df.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dictionary for fast access to ohe vectors\nimg_2_ohe_vector = {img:vec for img, vec in zip(train_ohe_df['ImageId'], train_df.iloc[:, 2:].values)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('/kaggle/input/understanding_cloud_organization/sample_submission.csv')\nsubmission_df['ImageId'] = submission_df['Image_Label'].apply(lambda x: x.split('_')[0])\ntest_images = pd.DataFrame(submission_df['ImageId'].unique(), columns=['ImageId'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"np_resize, build_masks, build_rles","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def np_resize(img, input_shape):\n    \"\"\"\n    Reshape a numpy array, which is input_shape=(height, width), \n    as opposed to input_shape=(width, height) for cv2\n    \"\"\"\n    height, width = input_shape\n    return cv2.resize(img, (width, height))\n    \ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n                                         \ndef build_masks(rles, input_shape, reshape=None):\n    depth = len(rles)\n    if reshape is None:\n        masks = np.zeros((*input_shape, depth))\n    else:\n        masks = np.zeros((*reshape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            if reshape is None:\n                masks[:, :, i] = rle2mask(rle, input_shape)\n            else:\n                mask = rle2mask(rle, input_shape)\n                reshaped_mask = np_resize(mask, reshape)\n                masks[:, :, i] = reshaped_mask\n    \n    return masks\n\ndef build_rles(masks, reshape=None):\n    width, height, depth = masks.shape\n    \n    rles = []\n    \n    for i in range(depth):\n        mask = masks[:, :, i]\n        \n        if reshape:\n            mask = mask.astype(np.float32)\n            mask = np_resize(mask, reshape).astype(np.int64)\n        \n        rle = mask2rle(mask)\n        rles.append(rle)\n        \n    return rles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LOSS FUNCTION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(                intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DATA Generator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nBACKBONE = 'resnet18'\nENCODER_WEIGHTS = 'imagenet'\nACTIVATION = 'sigmoid'\nEPOCHS = 50\n# LEARNING_RATE = 1e-4\nLEARNING_RATE = 0.002\nHEIGHT = 320\nWIDTH = 480\nCHANNELS = 3\nES_PATIENCE = 5\nRLROP_PATIENCE = 3\nDECAY_DROP = 0.5\nN_CLASSES = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/understanding_cloud_organization/train_images',\n                 batch_size=BATCH_SIZE, dim=(1400, 2100), n_channels=CHANNELS, reshape=None,gamma=None,\n                 augment=False, n_classes=4, random_state=42, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.reshape = reshape\n        self.gamma = gamma\n        self.n_channels = n_channels\n        self.augment = augment\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n#         self.graystyle = graystyle\n        \n        self.on_epoch_end()\n        np.random.seed(self.random_state)\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            \n            if self.augment:\n                X, y = self.__augment_batch(X, y)\n            \n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        if self.reshape is None:\n            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        else:\n            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n#             img = cv2.imread(img_path)\n#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#             img = img.astype(np.float32) / 255.\n            \n            if self.reshape is not None:\n                img = np_resize(img, self.reshape)\n            \n            # Adjust gamma\n            if self.gamma is not None:\n                img = adjust_gamma(img, gamma=self.gamma)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        if self.reshape is None:\n            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        else:\n            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            \n            if self.reshape is not None:\n                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n            else:\n                masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img\n\n    \n    def __random_transform(self, img, masks):\n        composition = albu.Compose([\n            albu.HorizontalFlip(),\n            albu.VerticalFlip(),\n            albu.Rotate(limit=30),\n            albu.GridDistortion()],p=1)\n            \n        \n        composed = composition(image=img, mask=masks)\n        aug_img = composed['image']\n        aug_masks = composed['mask']\n        \n        return aug_img, aug_masks\n    \n    def __augment_batch(self, img_batch, masks_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i, ], masks_batch[i, ] = self.__random_transform(\n                img_batch[i, ], masks_batch[i, ])\n        \n        return img_batch, masks_batch\n    \n    def get_labels(self):\n        if self.shuffle:\n            images_current = self.list_IDs[:self.len * self.batch_size]\n            labels = [img_to_ohe_vector[img] for img in images_current]\n        else:\n            labels = self.labels\n        return np.array(labels)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_idx, val_idx = train_test_split(train_ohe_df['ImageId'].index, \n                                        test_size=0.2, \n                                        stratify=train_ohe_df['Label'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n                                        random_state=10)\n# train_idx, val_idx = train_test_split(\n#     mask_count_df.index, \n#     test_size=0.2,\n#     random_state=10 \n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(train_idx, \n                                df=mask_count_df, \n                                target_df=train_df, \n                                batch_size=BATCH_SIZE,\n                                reshape=(HEIGHT, WIDTH),\n                                gamma=0.8,\n                                augment=True,\n#                                 graystyle=False,\n                                shuffle = True,\n                                n_channels=CHANNELS,\n                                n_classes=N_CLASSES)\nprint(\"Train generator load\")\n\nval_generator = DataGenerator(val_idx, \n                              df=mask_count_df, \n                              target_df=train_df, \n                              batch_size=BATCH_SIZE, \n                              reshape=(HEIGHT, WIDTH),\n                              gamma=0.8,\n                              augment=False,\n#                               graystyle=False,\n                              shuffle = False,\n                              n_channels=CHANNELS,\n                              n_classes=N_CLASSES)\nprint(\"Validation generator load\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def standard_unit(input_tensor, stage, nb_filter, kernel_size=3):\n\n    act = 'elu'\n\n    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(input_tensor)\n    x = Dropout(dropout_rate, name='dp'+stage+'_1')(x)\n    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(x)\n    x = Dropout(dropout_rate, name='dp'+stage+'_2')(x)\n\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Nest_Net(img_rows, img_cols, color_type=1, num_class=1, deep_supervision=False):\n\n    nb_filter = [32,64,128,256,512]\n    act = 'elu'\n\n    bn_axis = 3\n    img_input = Input(shape=(img_rows, img_cols, color_type), name='main_input')\n\n    conv1_1 = standard_unit(img_input, stage='11', nb_filter=nb_filter[0])\n    pool1 = MaxPool2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n\n    conv2_1 = standard_unit(pool1, stage='21', nb_filter=nb_filter[1])\n    pool2 = MaxPool2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n\n    up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n    conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n    conv1_2 = standard_unit(conv1_2, stage='12', nb_filter=nb_filter[0])\n\n    conv3_1 = standard_unit(pool2, stage='31', nb_filter=nb_filter[2])\n    pool3 = MaxPool2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n\n    up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n    conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n    conv2_2 = standard_unit(conv2_2, stage='22', nb_filter=nb_filter[1])\n\n    up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n    conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n    conv1_3 = standard_unit(conv1_3, stage='13', nb_filter=nb_filter[0])\n\n    conv4_1 = standard_unit(pool3, stage='41', nb_filter=nb_filter[3])\n    pool4 = MaxPool2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n\n    up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n    conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n    conv3_2 = standard_unit(conv3_2, stage='32', nb_filter=nb_filter[2])\n\n    up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n    conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n    conv2_3 = standard_unit(conv2_3, stage='23', nb_filter=nb_filter[1])\n\n    up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n    conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n    conv1_4 = standard_unit(conv1_4, stage='14', nb_filter=nb_filter[0])\n\n    conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n\n    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n    conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n    conv4_2 = standard_unit(conv4_2, stage='42', nb_filter=nb_filter[3])\n\n    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n    conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n    conv3_3 = standard_unit(conv3_3, stage='33', nb_filter=nb_filter[2])\n\n    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n    conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n    conv2_4 = standard_unit(conv2_4, stage='24', nb_filter=nb_filter[1])\n\n    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n    conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n    conv1_5 = standard_unit(conv1_5, stage='15', nb_filter=nb_filter[0])\n\n    nestnet_output_1 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_2)\n    nestnet_output_2 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_3)\n    nestnet_output_3 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_3', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_4)\n    nestnet_output_4 = Conv2D(num_class, (1, 1), activation='sigmoid', name='output_4', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n\n    if deep_supervision:\n        model = Model(img_input, [nestnet_output_1,nestnet_output_2,nestnet_output_3,nestnet_output_4])\n    else:\n        model = Model(img_input, [nestnet_output_4])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unet(input_shape):\n\n    inputs = Input(input_shape)\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2), padding='same') (c1)\n\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2), padding='same') (c2)\n\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2), padding='same') (c3)\n\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n    p4 = MaxPooling2D((2, 2), padding='same') (c4)\n\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n    p5 = MaxPooling2D((2, 2), padding='same') (c5)\n\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n    u6 = concatenate([u6, c5])\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n\n    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u71 = concatenate([u71, c4])\n    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n\n    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"earlystopping = EarlyStopping(monitor='val_loss', \n                             mode='min', \n                             patience=ES_PATIENCE,\n                             restore_best_weights=True,\n                             verbose=1)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              mode='min',\n                              patience=RLROP_PATIENCE,\n                              factor=DECAY_DROP,\n                              min_lr=1e-6,\n                              verbose=1)\n\nmetric_list = [dice_coef]\ncallback_list = [earlystopping, reduce_lr]\noptimizer = Adam(lr = LEARNING_RATE)\n\n# model = unet((HEIGHT,WIDTH,CHANNELS))\nmodel = sm.Unet(\n    BACKBONE, \n    classes=N_CLASSES,\n    input_shape=(HEIGHT, WIDTH, CHANNELS),\n    activation=ACTIVATION\n)\n\nmodel.compile(optimizer=optimizer, \n              loss=bce_dice_loss, \n              metrics=metric_list)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, earlystopping, reduce_lr],\n    epochs=EPOCHS,\n#     epochs=2,\n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(str(history.history), f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['dice_coef', 'val_dice_coef']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def post_process(probability, threshold, min_size):\n    \"\"\"\n    Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored\n    \"\"\"\n    \n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    \n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((350, 525), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sigmoid = lambda x: 1 / (1 + np.exp(-x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = []\nencoded_pixels = []\nTEST_BATCH_SIZE = 500\nbest_threshold = 0.5\nbest_size = 25000\n\nfor i in range(0, test_images.shape[0], TEST_BATCH_SIZE):\n    batch_idx = list(\n        range(i, min(test_images.shape[0], i + TEST_BATCH_SIZE))\n    )\n\n    test_generator = DataGenerator(\n        batch_idx,\n        df=test_images,\n        shuffle=False,\n        mode='predict',\n        dim=(350, 525),\n        reshape=(320,480),\n        n_channels=3,\n        gamma=0.8,\n#         graystyle=False,\n        base_path='../input/understanding_cloud_organization/test_images',\n        target_df=submission_df,\n        batch_size=1,\n        n_classes=4\n    )\n\n    batch_pred_masks = model.predict_generator(\n        test_generator, \n        workers=1,\n        verbose=1\n    ) \n    # Predict out put shape is (320X480X4)\n    # 4  = 4 classes, Fish, Flower, Gravel Surger.\n    \n    for j, idx in enumerate(batch_idx):\n        filename = test_images['ImageId'].iloc[idx]\n        image_df = submission_df[submission_df['ImageId'] == filename].copy()\n        \n        # Batch prediction result set\n        pred_masks = batch_pred_masks[j, ].round().astype(int)\n        pred_rles = build_rles(pred_masks, reshape=(350, 525))\n        \n        image_df['EncodedPixels'] = pred_rles\n        \n        test_df.append(image_df)\n        \n        \n        for k in range(pred_masks.shape[-1]):\n            pred_mask = pred_masks[...,k].astype('float32') \n            \n            if pred_mask.shape != (350, 525):\n                pred_mask = cv2.resize(pred_mask, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n                \n            pred_mask, num_predict = post_process(sigmoid(pred_mask), best_threshold, best_size )\n            \n            if num_predict == 0:\n                encoded_pixels.append('')\n            else:\n                r = mask2rle(pred_mask)\n                encoded_pixels.append(r)\n        \"\"\"\n        # pred_rles = build_rles(pred_masks, reshape=(350, 525))\n\n            #image_df['EncodedPixels'] = encoded_pixels\n            #test_df.append(image_df)\n        \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['EncodedPixels'] = encoded_pixels\nsubmission_df.to_csv('submission.csv', columns=['Image_Label', 'EncodedPixels'], index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}