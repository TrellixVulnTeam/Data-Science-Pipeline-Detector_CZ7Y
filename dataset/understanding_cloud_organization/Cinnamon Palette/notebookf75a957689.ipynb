{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models-pytorch\n!pip install albumentations\nimport segmentation_models_pytorch as smp\n\n\nimport pandas as pd\nimport numpy as np\n\nimport os\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n\n#красивые картиночки\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-12-09T13:42:32.84415Z","iopub.execute_input":"2021-12-09T13:42:32.844543Z","iopub.status.idle":"2021-12-09T13:43:00.204259Z","shell.execute_reply.started":"2021-12-09T13:42:32.844451Z","shell.execute_reply":"2021-12-09T13:43:00.203445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Предобработка csv","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/understanding_cloud_organization'\ntrain = pd.read_csv(f'{path}/train.csv')\nsub = pd.read_csv(f'{path}/sample_submission.csv')\n\ntrain['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\nsub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\nsub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])\nid_mask_count = train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label']\nid_mask_count = id_mask_count.apply(lambda x: x.split('_')[0]).value_counts()\nid_mask_count = id_mask_count.reset_index().rename(columns={'index': 'img_id', 'Image_Label': 'count'})\n\ntrain_ids, valid_ids = train_test_split(id_mask_count['img_id'].values,\n                                        random_state=42, \n                                        stratify=id_mask_count['count'],\n                                        test_size=0.1)\ntest_ids = sub['Image_Label'].apply(lambda x: x.split('_')[0]).drop_duplicates().values\n\ntrain_ids[0:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:00.206132Z","iopub.execute_input":"2021-12-09T13:43:00.206393Z","iopub.status.idle":"2021-12-09T13:43:04.613446Z","shell.execute_reply.started":"2021-12-09T13:43:00.206355Z","shell.execute_reply":"2021-12-09T13:43:04.612715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# для ривования картинок\ndef get_img(x,\n            path: str = '../input/understanding_cloud_organization',\n            folder: str = 'train_images'):\n    \"\"\"\n    Return image based on image name and folder.\n    \"\"\"\n    data_folder = f\"{path}/{folder}\"\n    image_path = os.path.join(data_folder, x)\n    img = cv2.imread(image_path)\n    return img\n\ndef dice(img1, img2):\n    img1 = np.asarray(img1).astype(np.bool)\n    img2 = np.asarray(img2).astype(np.bool)\n\n    intersection = np.logical_and(img1, img2)\n\n    return 2. * intersection.sum() / (img1.sum() + img2.sum())\n\n\ndef soft_dice_score(\n    output: torch.Tensor, target: torch.Tensor, smooth: float = 0.0, eps: float = 1e-7, dims=None\n) -> torch.Tensor:\n    \"\"\"\n    :param output:\n    :param target:\n    :param smooth:\n    :param eps:\n    :return:\n    Shape:\n        - Input: :math:`(N, NC, *)` where :math:`*` means any number\n            of additional dimensions\n        - Target: :math:`(N, NC, *)`, same shape as the input\n        - Output: scalar.\n    \"\"\"\n    assert output.size() == target.size()\n    if dims is not None:\n        intersection = torch.sum(output * target, dim=dims)\n        cardinality = torch.sum(output + target, dim=dims)\n    else:\n        intersection = torch.sum(output * target)\n        cardinality = torch.sum(output + target)\n    dice_score = (2.0 * intersection + smooth) / (cardinality + smooth).clamp_min(eps)\n    return dice_score\n\n\n\ndef rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n    '''\n    Decode rle encoded mask.\n\n    :param mask_rle: run-length as string formatted (start length)\n    :param shape: (height, width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n\ndef make_mask(df: pd.DataFrame, image_name: str = 'img.jpg', shape: tuple = (1400, 2100)):\n    \"\"\"\n    Create mask based on df, image name and shape.\n    \"\"\"\n    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n\n    for idx, label in enumerate(encoded_masks.values):\n        if label is not np.nan:\n            mask = rle_decode(label)\n            masks[:, :, idx] = mask\n\n    return masks\n\n#из cv2 в съедобную для торча\ndef to_tensor(x, **kwargs):\n    \"\"\"\n    Convert image or mask.\n    \"\"\"\n    return x.transpose(2, 0, 1).astype('float32')\n\ndef mask2rle(img):\n    '''\n    Convert mask to rle.\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\n# картинки\ndef visualize(image, mask, original_image=None, original_mask=None):\n    \"\"\"\n    Plot image and masks.\n    If two pairs of images and masks are passes, show both.\n    \"\"\"\n    fontsize = 14\n    class_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n    \n    if original_image is None and original_mask is None:\n        f, ax = plt.subplots(1, 5, figsize=(24, 24))\n\n        ax[0].imshow(image)\n        for i in range(4):\n            ax[i + 1].imshow(mask[:, :, i])\n            ax[i + 1].set_title(f'Mask {class_dict[i]}', fontsize=fontsize)\n    else:\n        f, ax = plt.subplots(2, 5, figsize=(24, 12))\n\n        ax[0, 0].imshow(original_image)\n        ax[0, 0].set_title('Original image', fontsize=fontsize)\n                \n        for i in range(4):\n            ax[0, i + 1].imshow(original_mask[:, :, i])\n            ax[0, i + 1].set_title(f'Original mask {class_dict[i]}', fontsize=fontsize)\n        \n        ax[1, 0].imshow(image)\n        ax[1, 0].set_title('Transformed image', fontsize=fontsize)\n        \n        \n        for i in range(4):\n            ax[1, i + 1].imshow(mask[:, :, i])\n            ax[1, i + 1].set_title(f'Transformed mask {class_dict[i]}', fontsize=fontsize)\n            \n# картинки и маска вероятностей            \ndef visualize_with_raw(image, mask, original_image=None, original_mask=None, raw_image=None, raw_mask=None):\n    \"\"\"\n    Plot image and masks.\n    If two pairs of images and masks are passes, show both.\n    \"\"\"\n    fontsize = 14\n    class_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n\n    f, ax = plt.subplots(3, 5, figsize=(24, 12))\n\n    ax[0, 0].imshow(original_image)\n    ax[0, 0].set_title('Original image', fontsize=fontsize)\n\n    for i in range(4):\n        ax[0, i + 1].imshow(original_mask[:, :, i])\n        ax[0, i + 1].set_title(f'Original mask {class_dict[i]}', fontsize=fontsize)\n\n\n    ax[1, 0].imshow(raw_image)\n    ax[1, 0].set_title('Original image', fontsize=fontsize)\n\n    for i in range(4):\n        ax[1, i + 1].imshow(raw_mask[:, :, i])\n        ax[1, i + 1].set_title(f'Raw predicted mask {class_dict[i]}', fontsize=fontsize)\n        \n    ax[2, 0].imshow(image)\n    ax[2, 0].set_title('Transformed image', fontsize=fontsize)\n\n\n    for i in range(4):\n        ax[2, i + 1].imshow(mask[:, :, i])\n        ax[2, i + 1].set_title(f'Predicted mask with processing {class_dict[i]}', fontsize=fontsize)\n            \n# картинки + ауг            \ndef plot_with_augmentation(image, mask, augment):\n    \"\"\"\n    Wrapper for `visualize` function.\n    \"\"\"\n    augmented = augment(image=image, mask=mask)\n    image_flipped = augmented['image']\n    mask_flipped = augmented['mask']\n    visualize(image_flipped, mask_flipped, original_image=image, original_mask=mask)\n    \n    \nsigmoid = lambda x: 1 / (1 + np.exp(-x))\n\n\n\n#\ndef post_process(probability, threshold, min_size):\n\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((350, 525), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:04.614963Z","iopub.execute_input":"2021-12-09T13:43:04.61521Z","iopub.status.idle":"2021-12-09T13:43:04.652269Z","shell.execute_reply.started":"2021-12-09T13:43:04.615178Z","shell.execute_reply":"2021-12-09T13:43:04.651472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CloudDataset(Dataset):\n    def __init__(self, df: pd.DataFrame = None,\n                 datatype: str = 'train',\n                 img_ids: np.array = None,\n                 transforms=None,\n                 preprocessing=None,\n                 path='../input/understanding_cloud_organization'):\n        self.df = df\n        if datatype != 'test':\n            self.data_folder = f\"{path}/train_images\"\n        else:\n            self.data_folder = f\"{path}/test_images\"\n        self.img_ids = img_ids\n        self.transforms = transforms\n        self.preprocessing = preprocessing\n\n    def __getitem__(self, idx):\n        image_name = self.img_ids[idx]\n        mask = make_mask(self.df, image_name)\n        image_path = os.path.join(self.data_folder, image_name)\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']\n        mask = augmented['mask']\n        if self.preprocessing:\n            preprocessed = self.preprocessing(image=img, mask=mask)\n            img = preprocessed['image']\n            mask = preprocessed['mask']\n        return img, mask\n\n    def __len__(self):\n        return len(self.img_ids)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:04.654183Z","iopub.execute_input":"2021-12-09T13:43:04.654631Z","iopub.status.idle":"2021-12-09T13:43:04.672597Z","shell.execute_reply.started":"2021-12-09T13:43:04.654595Z","shell.execute_reply":"2021-12-09T13:43:04.671752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ENCODER = 'resnet18'\nENCODER_WEIGHTS = 'imagenet'\nDEVICE = 'cuda'\n\nACTIVATION = None\nmodel = smp.Unet(\n    encoder_name=ENCODER,\n    encoder_weights=ENCODER_WEIGHTS,\n    classes=4,\n    activation=ACTIVATION,\n)\n#print(model)\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:04.674881Z","iopub.execute_input":"2021-12-09T13:43:04.675656Z","iopub.status.idle":"2021-12-09T13:43:10.531935Z","shell.execute_reply.started":"2021-12-09T13:43:04.675616Z","shell.execute_reply":"2021-12-09T13:43:10.531245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:10.533016Z","iopub.execute_input":"2021-12-09T13:43:10.533255Z","iopub.status.idle":"2021-12-09T13:43:10.539557Z","shell.execute_reply.started":"2021-12-09T13:43:10.533222Z","shell.execute_reply":"2021-12-09T13:43:10.538883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_t = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0),\n        A.GridDistortion(p=0.5),\n        A.OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n        A.Resize(320, 640)\n    ])\n\ntransform_v = A.Resize(320, 640)\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\npreprocess = A.Compose([\n        A.Lambda(image=preprocessing_fn),\n        A.Lambda(image=to_tensor, mask=to_tensor)\n    ]) ","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:10.540989Z","iopub.execute_input":"2021-12-09T13:43:10.541319Z","iopub.status.idle":"2021-12-09T13:43:10.548774Z","shell.execute_reply.started":"2021-12-09T13:43:10.541285Z","shell.execute_reply":"2021-12-09T13:43:10.548112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 34\nnum_workers = 4\n\nvalid_dataset = CloudDataset(df=train, datatype='valid', img_ids=valid_ids)\ntrain_dataset = CloudDataset(df=train, \n                             datatype='train',\n                             img_ids=train_ids, \n                             transforms = transform_t,\n                             preprocessing=preprocess)\nvalid_dataset = CloudDataset(df=train,\n                             datatype='valid',\n                             img_ids=valid_ids,\n                             transforms = transform_v,\n                             preprocessing=preprocess)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\nvalid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:10.550419Z","iopub.execute_input":"2021-12-09T13:43:10.551108Z","iopub.status.idle":"2021-12-09T13:43:10.563643Z","shell.execute_reply.started":"2021-12-09T13:43:10.550978Z","shell.execute_reply":"2021-12-09T13:43:10.562814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (image, mask) in enumerate(train_loader):\n    fig = plt.figure(figsize=(25, 6))\n    if i == 4:\n        break\n    ax = fig.add_subplot(1, 5, 1, xticks=[], yticks=[])\n    \n    image = image[0]\n    mask = mask[0]\n    image = np.transpose(image, (1,2,0))\n    #mask = np.transpose(mask, (1,2,0))\n    image = np.array(255*image, dtype = np.int)\n    mask = np.array(mask, dtype = np.int)\n    plt.imshow(image)\n    cm = ['Reds', 'Greens', 'Accent', 'Blues']\n    #plt.imshow(masks[2], alpha = 0.3, cmap= 'Reds')\n    #image = (image - 127.5) / 128\n\n    for j in range(4):\n        ax = fig.add_subplot(1, 5, 2 + j, xticks=[], yticks=[])\n        plt.imshow(image)\n        plt.imshow(mask[j], alpha = 0.5, cmap= 'gray')\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:43:10.565396Z","iopub.execute_input":"2021-12-09T13:43:10.565984Z","iopub.status.idle":"2021-12-09T13:44:28.709733Z","shell.execute_reply.started":"2021-12-09T13:43:10.565934Z","shell.execute_reply":"2021-12-09T13:44:28.70875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam([\n    {'params': model.decoder.parameters(), 'lr': 1e-2}, \n    {'params': model.encoder.parameters(), 'lr': 1e-3},  \n])\nscheduler = ReduceLROnPlateau(optimizer, factor=0.15, patience=2)\ncriterion = smp.utils.losses.BCEWithLogitsLoss()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:44:28.715892Z","iopub.execute_input":"2021-12-09T13:44:28.716744Z","iopub.status.idle":"2021-12-09T13:44:28.729459Z","shell.execute_reply.started":"2021-12-09T13:44:28.716691Z","shell.execute_reply":"2021-12-09T13:44:28.728072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_epochs = 25\n\n# # model, criterion, optimizer\n# optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n\n# scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n# criterion = smp.utils.losses.BCEWithLogitsLoss()\n\n# probabilites = nn.Sigmoid()\n# best_dice = 0\n\n# for epoch in range(num_epochs):\n#     model.train()\n#     scheduler.step(epoch)\n\n#     train_loss = 0\n#     num_samples = 0\n#     train_dice = 0\n\n#     for i, (img, mask) in enumerate(train_loader):\n#         i += 1\n#         img = img.cuda()\n#         mask = mask.cuda()\n\n#         optimizer.zero_grad()\n\n#         prediction = model(img)\n#         loss = criterion(prediction, mask)\n#         loss.backward()\n#         optimizer.step()\n#         loss = loss.cpu().detach().numpy()\n#         train_loss += loss * img.size(0)\n#         num_samples += img.size(0)\n\n#         dice = soft_dice_score(probabilites(prediction), mask)\n#         train_dice += dice.cpu().detach().numpy() * img.size(0)\n\n#         if i % 100 == 0 or i % len(train_loader) == 0:\n#             print('Epoch:', epoch, 'Train_loss:', train_loss/num_samples, 'Train_dice:', train_dice/num_samples,\n#                   'Sample/Total:', i, '/', len(train_loader))\n\n#     model.eval()\n#     val_dice = 0\n#     num_samples = 0\n#     with torch.no_grad():\n#         for img, mask in valid_loader:\n#             img = img.cuda()\n#             mask = mask.cuda()\n\n#             pred = model(img)\n#             dice = soft_dice_score(probabilites(pred), mask)\n#             val_dice += dice.cpu().detach().numpy() * img.size(0)\n#             num_samples += img.size(0)\n\n#     print('')\n#     print('VAL_DICE:', val_dice/num_samples)\n#     if val_dice/num_samples > best_dice:\n#         best_dice = val_dice/num_samples\n#         torch.save(model.state_dict(), 'unet_eff.pth')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:44:28.731143Z","iopub.execute_input":"2021-12-09T13:44:28.731683Z","iopub.status.idle":"2021-12-09T13:44:28.741921Z","shell.execute_reply.started":"2021-12-09T13:44:28.731639Z","shell.execute_reply":"2021-12-09T13:44:28.741057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!kaggle kernels output cinnamonpalette/notebookf75a957689 ","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:52:58.328274Z","iopub.execute_input":"2021-12-09T13:52:58.328597Z","iopub.status.idle":"2021-12-09T13:53:00.08891Z","shell.execute_reply.started":"2021-12-09T13:52:58.328549Z","shell.execute_reply":"2021-12-09T13:53:00.088052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/arabel1a/hg-set.git\n!pip install -q kaggle\n!mkdir -p ~/.kaggle\n!cp ./hg-set/kaggle.json ~/.kaggle/\n!kaggle kernels output cinnamonpalette/notebookf75a957689 -p /path/to/dest\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:44:28.746352Z","iopub.execute_input":"2021-12-09T13:44:28.746745Z","iopub.status.idle":"2021-12-09T13:44:41.691132Z","shell.execute_reply.started":"2021-12-09T13:44:28.746708Z","shell.execute_reply":"2021-12-09T13:44:41.690278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/aaaaaa/unet_resnet50(4).pth'))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:54:56.075781Z","iopub.execute_input":"2021-12-09T13:54:56.076436Z","iopub.status.idle":"2021-12-09T13:54:56.145983Z","shell.execute_reply.started":"2021-12-09T13:54:56.076399Z","shell.execute_reply":"2021-12-09T13:54:56.145075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tqdm\nmodel.eval()\npredicts = []\nwith torch.no_grad():\n    for img, mask in tqdm.tqdm(valid_loader):\n        img = img.cuda()\n        mask = mask.cuda()\n        pred = model(img)\n#         prob = probabilites(pred)\n#         predicts.append(pred.detach().cpu().numpy())\n        predicts.append(pred.detach().cpu().numpy())\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:54:56.147619Z","iopub.execute_input":"2021-12-09T13:54:56.147946Z","iopub.status.idle":"2021-12-09T13:55:46.765404Z","shell.execute_reply.started":"2021-12-09T13:54:56.14791Z","shell.execute_reply":"2021-12-09T13:55:46.763892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicts[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:55:46.767054Z","iopub.execute_input":"2021-12-09T13:55:46.767345Z","iopub.status.idle":"2021-12-09T13:55:46.776666Z","shell.execute_reply.started":"2021-12-09T13:55:46.767303Z","shell.execute_reply":"2021-12-09T13:55:46.776003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.split(predicts[0], 34)[0].shape\np_predicts = []\nfor batch in predicts:\n    for mask in np.split(batch, batch.shape[0]):\n        mask.resize(mask.shape[1:])\n        p_predicts.append(mask)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:55:46.778977Z","iopub.execute_input":"2021-12-09T13:55:46.779252Z","iopub.status.idle":"2021-12-09T13:55:46.787431Z","shell.execute_reply.started":"2021-12-09T13:55:46.779215Z","shell.execute_reply":"2021-12-09T13:55:46.786429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_masks = []\nprobabilities = np.zeros((4*len(valid_dataset), 350, 525))\nprobabilities.shape\nfor i, (batch, output) in enumerate(tqdm.tqdm(zip(\n        valid_dataset, p_predicts))):\n    image, mask = batch\n    for m in mask:\n        if m.shape != (350, 525):\n            m = cv2.resize(m, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n        valid_masks.append(m)\n\n    for j, probability in enumerate(output):\n        if probability.shape != (350, 525):\n            probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n        probabilities[i * 4 + j, :, :] = probability","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:55:46.789228Z","iopub.execute_input":"2021-12-09T13:55:46.789639Z","iopub.status.idle":"2021-12-09T13:56:43.534724Z","shell.execute_reply.started":"2021-12-09T13:55:46.789602Z","shell.execute_reply":"2021-12-09T13:56:43.533272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_params = {}\nfor class_id in range(4):\n    print(class_id)\n    attempts = []\n    for t in tqdm.tqdm(range(0, 100, 5)):\n        t /= 100\n        for ms in [5000, 10000, 25000, 50000, 100000]:\n            masks = []\n            for i in range(class_id, len(probabilities), 4):\n                probability = probabilities[i]\n                predict, num_predict = post_process(sigmoid(probability), t, ms)\n                masks.append(predict)\n\n            d = []\n            for i, j in zip(masks, valid_masks[class_id::4]):\n                if (i.sum() == 0) & (j.sum() == 0):\n                    d.append(1)\n                else:\n                    d.append(dice(i, j))\n\n            attempts.append((t, ms, np.mean(d)))\n\n    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n\n\n    attempts_df = attempts_df.sort_values('dice', ascending=False)\n    print(attempts_df.head())\n    best_threshold = attempts_df['threshold'].values[0]\n    best_size = attempts_df['size'].values[0]\n    \n    class_params[class_id] = (best_threshold, best_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T13:56:43.536311Z","iopub.execute_input":"2021-12-09T13:56:43.536587Z","iopub.status.idle":"2021-12-09T14:11:19.860476Z","shell.execute_reply.started":"2021-12-09T13:56:43.536552Z","shell.execute_reply":"2021-12-09T14:11:19.859576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_params)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:11:19.862181Z","iopub.execute_input":"2021-12-09T14:11:19.862459Z","iopub.status.idle":"2021-12-09T14:11:19.867581Z","shell.execute_reply.started":"2021-12-09T14:11:19.86242Z","shell.execute_reply":"2021-12-09T14:11:19.866835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (input, output) in enumerate(zip(\n        valid_dataset, p_predicts)):\n    image, mask = input\n        \n    image_vis = image.transpose(1, 2, 0)\n    mask = mask.astype('uint8').transpose(1, 2, 0)\n    pr_mask = np.zeros((350, 525, 4))\n    for j in range(4):\n        probability = cv2.resize(output.transpose(1, 2, 0)[:, :, j], dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n        pr_mask[:, :, j], _ = post_process(sigmoid(probability), class_params[j][0], class_params[j][1])\n    #pr_mask = (sigmoid(output) > best_threshold).astype('uint8').transpose(1, 2, 0)\n    \n        \n    visualize_with_raw(image=image_vis, mask=pr_mask, original_image=image_vis, original_mask=mask, raw_image=image_vis, raw_mask=output.transpose(1, 2, 0))\n    \n    if i >= 2:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:11:19.868883Z","iopub.execute_input":"2021-12-09T14:11:19.869646Z","iopub.status.idle":"2021-12-09T14:11:27.335388Z","shell.execute_reply.started":"2021-12-09T14:11:19.869607Z","shell.execute_reply":"2021-12-09T14:11:27.334753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CloudDataset(df=sub, datatype='test', img_ids=test_ids, transforms = transform_v, preprocessing=preprocess)\ntest_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=6)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:11:27.336555Z","iopub.execute_input":"2021-12-09T14:11:27.336971Z","iopub.status.idle":"2021-12-09T14:11:27.34363Z","shell.execute_reply.started":"2021-12-09T14:11:27.336934Z","shell.execute_reply":"2021-12-09T14:11:27.342366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_pixels = []\nimage_id = 0\nmodel.eval()\npredicts = []\nwith torch.no_grad():        \n    for i, (img, mask) in enumerate(tqdm.tqdm(test_loader)):\n        img = img.cuda()\n        mask = mask.cuda()\n        pred = model(img)\n        for i, batch in enumerate(pred):\n            for probability in batch:\n                probability = probability.cpu().detach().numpy()\n                if probability.shape != (350, 525):\n                    probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n                predict, num_predict = post_process(sigmoid(probability), class_params[image_id % 4][0], class_params[image_id % 4][1])\n                if num_predict == 0:\n                    encoded_pixels.append('')\n                else:\n                    r = mask2rle(predict)\n                    encoded_pixels.append(r)\n                image_id += 1","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:11:27.346593Z","iopub.execute_input":"2021-12-09T14:11:27.347084Z","iopub.status.idle":"2021-12-09T14:17:51.004381Z","shell.execute_reply.started":"2021-12-09T14:11:27.347048Z","shell.execute_reply":"2021-12-09T14:17:51.003451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['EncodedPixels'] = encoded_pixels\nsub.to_csv('submission.csv', columns=['Image_Label', 'EncodedPixels'], index=False)\nlen(sub)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T14:17:51.008964Z","iopub.execute_input":"2021-12-09T14:17:51.011561Z","iopub.status.idle":"2021-12-09T14:17:51.941909Z","shell.execute_reply.started":"2021-12-09T14:17:51.011508Z","shell.execute_reply":"2021-12-09T14:17:51.941158Z"},"trusted":true},"execution_count":null,"outputs":[]}]}