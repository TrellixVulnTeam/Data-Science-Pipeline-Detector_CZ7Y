{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.mkdir('/kaggle/working/data/')\nos.mkdir('/kaggle/working/weights/')\nos.mkdir('/kaggle/working/msk/')\nos.mkdir('/kaggle/working/subm/')\n!ls","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom shapely.wkt import loads as wkt_loads\nimport tifffile as tiff\nimport os\nimport random\nfrom keras.models import Model\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import Input, Convolution2D, UpSampling2D, Reshape, core, Dropout, Cropping2D, ZeroPadding2D, Flatten, Dropout, Dense, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as K\nfrom sklearn.metrics import jaccard_score\nfrom shapely.geometry import MultiPolygon, Polygon\nimport shapely.wkt\nimport shapely.affinity\nfrom collections import defaultdict\nimport zipfile\n\nN_Cls = 1\ninDir = '../input/dstl-satellite-imagery-feature-detection'\n\nDF = pd.read_csv(inDir + '/train_wkt_v4.csv.zip')\nGS = pd.read_csv(inDir + '/grid_sizes.csv.zip', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\nSB = pd.read_csv(os.path.join(inDir, 'sample_submission.csv.zip'))\nISZ = 160\nsmooth = 1e-12\n\n\ndef _convert_coordinates_to_raster(coords, img_size, xymax):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    Xmax, Ymax = xymax\n    H, W = img_size\n    W1 = 1.0 * W * W / (W + 1)\n    H1 = 1.0 * H * H / (H + 1)\n    xf = W1 / Xmax\n    yf = H1 / Ymax\n    coords[:, 1] *= yf\n    coords[:, 0] *= xf\n    coords_int = np.round(coords).astype(np.int32)\n    return coords_int\n\n\ndef _get_xmax_ymin(grid_sizes_panda, imageId):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n    return (xmax, ymin)\n\n\ndef _get_polygon_list(wkt_list_pandas, imageId, cType):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n    polygonList = None\n    if len(multipoly_def) > 0:\n        assert len(multipoly_def) == 1\n        polygonList = wkt_loads(multipoly_def.values[0])\n    return polygonList\n\n\ndef _get_and_convert_contours(polygonList, raster_img_size, xymax):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    perim_list = []\n    interior_list = []\n    if polygonList is None:\n        return None\n    for k in range(len(polygonList)):\n        poly = polygonList[k]\n        perim = np.array(list(poly.exterior.coords))\n        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n        perim_list.append(perim_c)\n        for pi in poly.interiors:\n            interior = np.array(list(pi.coords))\n            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n            interior_list.append(interior_c)\n    return perim_list, interior_list\n\n\ndef _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    img_mask = np.zeros(raster_img_size, np.uint8)\n    if contours is None:\n        return img_mask\n    perim_list, interior_list = contours\n    cv2.fillPoly(img_mask, perim_list, class_value)\n    cv2.fillPoly(img_mask, interior_list, 0)\n    return img_mask\n\n\ndef generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n    mask = _plot_mask_from_contours(raster_size, contours, 1)\n    return mask\n\n\ndef getImage(imName):\n    zip_path = '../input/dstl-satellite-imagery-feature-detection/sixteen_band.zip'\n    tgtImg = '{}_M.tif'.format(imName)\n    with zipfile.ZipFile(zip_path) as myzip:\n        files_in_zip = myzip.namelist()\n        for fname in files_in_zip:\n            if fname.endswith(tgtImg):\n                with myzip.open(fname) as myfile:\n                    img = tiff.imread(myfile)\n                    img = np.rollaxis(img, 0, 3)\n                    return img\n\n                \ndef fitToArray(img):\n    imgArr = np.zeros_like(img)\n    bands = img.shape[2]\n#     print(\"Bands \", bands)\n    for i in range(bands):\n        bandLow = np.percentile(img[:, :, i], 5)\n        bandHigh = np.percentile(img[:, :, i], 95)\n        norm = (img[:, :, i] - bandLow)/ (bandHigh - bandLow)\n        norm[norm < 0] = 0\n        norm[norm > 1] = 1\n        imgArr[:, :, i] = norm\n\n    arr = imgArr.astype(np.float32)\n    return arr\n\ndef jaccard_coef(y_true, y_pred):\n    # __author__ = Vladimir Iglovikov\n    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n\n    return K.mean(jac)\n\n\ndef jaccard_coef_int(y_true, y_pred):\n    # __author__ = Vladimir Iglovikov\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n\n    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return K.mean(jac)\n\n\ndef prepareData():\n    print(\"Preparing Data as Training Set\")\n    minSize = 835\n\n    x = np.zeros((5 * minSize, 5 * minSize, 8))\n    y = np.zeros((5 * minSize, 5 * minSize, N_Cls))\n\n    uniqIds = sorted(DF.ImageId.unique())\n    print(\"Number of Unique Images = \", len(uniqIds))\n    \n    for i in range(5):\n        for j in range(5):\n\n            imId = uniqIds[5 * i + j]\n            img = getImage(imId)\n            imgArr = fitToArray(img)\n            print (imId, imgArr.shape, np.amax(imgArr), np.amin(imgArr))\n            x[minSize * i:minSize * i + minSize, minSize * j:minSize * j + minSize, :] = imgArr[:minSize, :minSize, :]\n            for z in range(N_Cls):\n                y[minSize * i:minSize * i + minSize, minSize * j:minSize * j + minSize, z] = generate_mask_for_image_and_class((imgArr.shape[0], imgArr.shape[1]), imId, z + 1)[:minSize, :minSize]\n\n    print (np.amax(y), np.amin(y))\n\n    np.save('data/x_trn_%d' % N_Cls, x)\n    np.save('data/y_trn_%d' % N_Cls, y)\n\n\ndef get_patches(img, msk, amt=10000, aug=True):\n#     __author__ = \"n01z3\"\n#     Link = https://www.kaggle.com/drn01z3/end-to-end-baseline-with-u-net-keras\n    is2 = int(1.0 * ISZ)\n    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n\n    x, y = [], []\n\n    threshVal = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.0001, 0.0005]\n    for i in range(amt):\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n        for j in range(N_Cls):\n            sm = np.sum(ms[:, :, j])\n            if 1.0 * sm / is2 ** 2 > threshVal[j]:\n                if aug:\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[::-1]\n                        ms = ms[::-1]\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[:, ::-1]\n                        ms = ms[:, ::-1]\n\n                x.append(im)\n                y.append(ms)\n\n    x, y = 2 * np.transpose(x, (0, 1, 2, 3)) - 1, np.transpose(y, (0, 1, 2, 3))\n    print (x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n#     y = np.delete(y, 2)\n#     y = np.delete(y, 3)\n    return x, y\n\ndef sepValidation():\n    print (\"Partitioning Cross Validation Set\")\n    \n    img = np.load('data/x_trn_%d.npy' % N_Cls)\n    msk = np.load('data/y_trn_%d.npy' % N_Cls)\n\n    x, y = get_patches(img, msk, amt=3000)\n\n    np.save('data/x_tmp_%d' % N_Cls, x)\n    np.save('data/y_tmp_%d' % N_Cls, y)\n\ndef get_crop_shape(tgt, ref):\n    widthDiff = tgt.get_shape()[2] - ref.get_shape()[2] \n    assert (widthDiff >= 0)\n    cw1 = int(widthDiff/2)\n    cw2 = cw1\n    \n    if widthDiff % 2 != 0:\n        cw2 += 1        \n    \n    heightDiff = tgt.get_shape()[1] - ref.get_shape()[1]\n    assert (heightDiff >= 0)\n    ch1 = int(heightDiff/2)\n    ch2 = ch1\n    \n    if heightDiff % 2 != 0:\n        ch2 += 1\n    \n    return (ch1, ch2), (cw1, cw2)\n\ndef get_cnn():\n    concat_axis = 3\n\n    inputs = Input((ISZ, ISZ, 8))\n    \n    conv1 = Conv2D(32, (3, 3), padding=\"same\", name=\"conv1_1\", activation=\"relu\", data_format=\"channels_last\")(inputs)\n    conv1 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n\n    conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(pool1)\n    conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n\n    conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(pool2)\n    conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv3)\n\n    up_conv3 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv3)\n    ch, cw = get_crop_shape(conv2, up_conv3)\n    crop_conv2 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv2)\n    up8   = concatenate([up_conv3, crop_conv2], axis=concat_axis)\n    conv8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up8)\n    conv8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv8)\n\n    up_conv8 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv8)\n    ch, cw = get_crop_shape(conv1, up_conv8)\n    crop_conv1 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv1)\n    up9   = concatenate([up_conv8, crop_conv1], axis=concat_axis)\n    conv9 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up9)\n    conv9 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv9)\n\n    ch, cw = get_crop_shape(inputs, conv9)\n    conv9  = ZeroPadding2D(padding=(ch[0],cw[0]), data_format=\"channels_last\")(conv9)\n    conv10 = Conv2D(N_Cls, (1, 1), data_format=\"channels_last\", activation=\"sigmoid\")(conv9)\n        \n    model = Model(inputs=inputs, outputs=conv10)\n#     model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n\n\ndef calc_jacc(model):\n    img = np.load('data/x_tmp_%d.npy' % N_Cls)\n    msk = np.load('data/y_tmp_%d.npy' % N_Cls)\n\n    prd = model.predict(img, batch_size=4)\n    print (prd.shape, msk.shape)\n    avg, trs = [], []\n\n    for i in range(N_Cls):\n        t_msk = msk[:, i, :, :]\n        t_prd = prd[:, i, :, :]\n        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n\n        m, b_tr = 0, 0\n        for j in range(10):\n            tr = j / 10.0\n            pred_binary_mask = t_prd > tr\n\n            jk = jaccard_score(t_msk, pred_binary_mask)\n            if jk > m:\n                m = jk\n                b_tr = tr\n        print (i, m, b_tr)\n        avg.append(m)\n        trs.append(b_tr)\n\n    score = sum(avg)\n    return score, trs\n\n\ndef mask_for_polygons(polygons, im_size):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n    img_mask = np.zeros(im_size, np.uint8)\n    if not polygons:\n        return img_mask\n    int_coords = lambda x: np.array(x).round().astype(np.int32)\n    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n    interiors = [int_coords(pi.coords) for poly in polygons\n                 for pi in poly.interiors]\n    cv2.fillPoly(img_mask, exteriors, 1)\n    cv2.fillPoly(img_mask, interiors, 0)\n    return img_mask\n\n\ndef mask_to_polygons(mask, epsilon=5, min_area=1.):\n    obj = ((mask == 1) * 255).astype(np.uint8)\n    print(obj.shape)\n#     print(hasattr(((mask == 1) * 255).astype(np.uint8), '__iter__'))\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n\n    # first, find contours with cv2: it's much faster than shapely\n    contours, hierarchy = cv2.findContours(obj, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n    # create approximate contours to have reasonable submission size\n    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n                       for cnt in contours]\n    if not contours:\n        return MultiPolygon()\n    # now messy stuff to associate parent and child contours\n    cnt_children = defaultdict(list)\n    child_contours = set()\n    assert hierarchy.shape[0] == 1\n    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n        if parent_idx != -1:\n            child_contours.add(idx)\n            cnt_children[parent_idx].append(approx_contours[idx])\n    # create actual polygons filtering by area (removes artifacts)\n    all_polygons = []\n    for idx, cnt in enumerate(approx_contours):\n        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n            assert cnt.shape[1] == 1\n            poly = Polygon(\n                shell=cnt[:, 0, :],\n                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n                       if cv2.contourArea(c) >= min_area])\n            all_polygons.append(poly)\n    # approximating polygons might have created invalid ones, fix them\n    all_polygons = MultiPolygon(all_polygons)\n    if not all_polygons.is_valid:\n        all_polygons = all_polygons.buffer(0)\n        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n        # need to keep it a Multi throughout\n        if all_polygons.type == 'Polygon':\n            all_polygons = MultiPolygon([all_polygons])\n    return all_polygons\n\ndef get_scalers(im_size, x_max, y_min):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n    h, w = float(h), float(w)\n    w_ = 1.0 * w * (w / (w + 1))\n    h_ = 1.0 * h * (h / (h + 1))\n    return w_ / x_max, h_ / y_min\n\n\ndef train_net():\n    print (\"Start training Network\")\n    \n    x_val = np.load('data/x_tmp_%d.npy' % N_Cls)\n    y_val = np.load('data/y_tmp_%d.npy' % N_Cls)\n    \n    img = np.load('data/x_trn_%d.npy' % N_Cls)\n    msk = np.load('data/y_trn_%d.npy' % N_Cls)\n\n    x_trn, y_trn = get_patches(img, msk)\n    \n    print(\"Number of Patches = \", len(x_trn))\n    \n    model = get_cnn()\n    print(\"creating checkpoint\")\n    model_checkpoint = ModelCheckpoint('weights/unet_tmp.hdf5', monitor='loss', save_best_only=True)\n    print(\"start fitting\")\n    for i in range(1):\n        model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True, callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n        del x_trn\n        del y_trn\n        x_trn, y_trn = get_patches(img, msk)\n        score, trs = calc_jacc(model)\n        print ('validation jaccardian score =', score)\n        model.save_weights('weights/unet_10_jk%.4f' % score)\n\n    return model\n\ndef predict_id(imId, model, trs):\n    cnv = np.zeros((960, 960, 8)).astype(np.float32)\n    prd = np.zeros((N_Cls, 960, 960)).astype(np.float32)\n\n    img = getImage(imId)\n    x = fitToArray(img)\n\n    cnv[:img.shape[0], :img.shape[1], :] = x\n\n    for i in range(0, 6):\n        line = []\n        for j in range(0, 6):\n            line.append(cnv[i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ])\n\n        x = 2 * np.transpose(line, (0, 1, 2, 3)) - 1\n        tmp = model.predict(x, batch_size=4)\n        for j in range(tmp.shape[0]):\n#             print(tmp[j].shape)\n            prd[:, i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ] = np.transpose(tmp[j], (2, 0, 1))\n\n    # trs = [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1]\n    for i in range(N_Cls):\n        prd[i] = prd[i] > trs[i]\n\n    return prd[:, :img.shape[0], :img.shape[1]]\n\n\ndef predict_test(model, trs):\n    print (\"predict test\")\n    for i, id in enumerate(sorted(set(SB['ImageId'].tolist()))):\n        msk = predict_id(id, model, trs)\n        np.save('msk/10_%s' % id, msk)\n        if i % 100 == 0: print (i, id)\n\n\nif __name__ == '__main__':\n    prepareData()\n    sepValidation()\n    model = train_net()\n    score, trs = calc_jacc(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/working/weights/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#     '6120_2_1 6090_4_0 6070_3_2 6020_1_3 6050_2_2 6060_1_1 6120_2_2\ndef check_predict(imId='6180_2_0'):\n#     '6120_2_1 6090_4_0 6070_3_2 6020_1_3 6050_2_2 6060_1_1 6120_2_2\n    model = get_cnn()\n    model.load_weights('weights/unet_10_jk0.4266')\n\n    msk = predict_id(imId, model, [0.5, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n    img = getImage(imId)\n\n#     print(msk[0])\n    plt.figure(figsize=(20, 20))\n    ax1 = plt.subplot(311)\n    ax1.set_title('image ID : ' + imId)\n    ax1.imshow(img[:, :, 5], cmap=plt.get_cmap('gist_ncar'))\n    ax2 = plt.subplot(312)\n    ax2.set_title('predicted pixels')\n    ax2.imshow(msk[0], cmap=plt.get_cmap('gray'))\n    ax3 = plt.subplot(313)\n    ax3.set_title('predicted polygones')\n    ax3.imshow(mask_for_polygons(mask_to_polygons(msk[0], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n\n    plt.show()\n    \ncheck_predict('6120_2_3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_predict('6090_4_0')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_predict('6070_3_2')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_predict('6020_1_3')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_predict('6050_2_2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_predict('6060_1_1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -zcvf BuildingCNN.tar.gz /kaggle/working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def make_submit():\n#     print (\"make submission file\")\n#     df = pd.read_csv(os.path.join(inDir, 'sample_submission.csv.zip'))\n#     print (df.head())\n#     for idx, row in df.iterrows():\n#         id = row[0]\n#         kls = row[1] - 1\n\n#         msk = np.load('msk/10_%s.npy' % id)[kls]\n#         pred_polygons = mask_to_polygons(msk)\n#         x_max = GS.loc[GS['ImageId'] == id, 'Xmax'].as_matrix()[0]\n#         y_min = GS.loc[GS['ImageId'] == id, 'Ymin'].as_matrix()[0]\n\n#         x_scaler, y_scaler = get_scalers(msk.shape, x_max, y_min)\n\n#         scaled_pred_polygons = shapely.affinity.scale(pred_polygons, xfact=1.0 / x_scaler, yfact=1.0 / y_scaler,\n#                                                       origin=(0, 0, 0))\n\n#         df.iloc[idx, 2] = shapely.wkt.dumps(scaled_pred_polygons)\n#         if idx % 100 == 0: print (idx)\n#     print( df.head())\n#     df.to_csv('subm/1.csv', index=False)\n\n# make_submit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict_test(model, trs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(os.getcwd())\n# inDir = '../input/dstl-satellite-imagery-feature-detection/'\n# !ls ../input/\n# #inDir = '/home/n01z3/dataset/dstl'\n# DF = pd.read_csv(inDir + '/train_wkt_v4.csv.zip')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}