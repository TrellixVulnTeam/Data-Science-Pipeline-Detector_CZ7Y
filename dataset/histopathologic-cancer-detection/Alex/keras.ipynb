{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# References\nFramework from https://www.kaggle.com/gomezp/complete-beginner-s-guide-eda-keras-lb-0-93","metadata":{"_uuid":"a6717103051c3f8b781161d917a4fe7352be60e4"}},{"cell_type":"code","source":"# load modules\nfrom glob import glob \nimport numpy as np\nimport pandas as pd\nimport keras,cv2,os\nimport gc\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\nfrom tqdm import tqdm_notebook,trange\nimport matplotlib.pyplot as plt\n\n# load labels & filenames\npath = \"../input/\" \ntrain_path = path + 'train/'\ntest_path = path + 'test/'\ndf = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))}) # filenames\ndf['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) \nlabels = pd.read_csv(path+\"train_labels.csv\")\ndf = df.merge(labels, on = \"id\") \n\n# load data function\ndef load_data(N,df):\n    X = np.zeros([N,96,96,3],dtype=np.uint8) \n    y = np.squeeze(df.as_matrix(columns=['label']))[0:N]\n    for i, row in tqdm_notebook(df.iterrows(), total=N):\n        if i == N:\n            break\n        X[i] = cv2.imread(row['path'])\n    return X,y\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA using N = 1,000\nN=1000\nX,y = load_data(N=N,df=df) \n\n# 16 random, labeled images\nfig = plt.figure(figsize=(10, 4), dpi=150)\nnp.random.seed(10) #random seed\nfor plotNr,idx in enumerate(np.random.randint(0,N,16)):\n    ax = fig.add_subplot(2, 16//2, plotNr+1, xticks=[], yticks=[]) #subplots\n    plt.imshow(X[idx]) #plot\n    if y[idx] == 0:\n        a = \" \"\n    else:\n        a = \"Cancer\"\n    ax.set_title(a)\n    \n# pie chart data distribution\nlabels = 'Negative', 'Positive (Cancer)'\nsizes = [(y==0).sum(), (y==1).sum()]\nexplode = (0, 0.1)\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.show()","metadata":{"_uuid":"ffed68f7b732222097006f1047744950ad085ed8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\nN = df[\"path\"].size\n#N = 100000 \nx_train, y_train = load_data(N=N,df=df)\n\n# 20,000 samples for validation\nx_val = x_train[-20000:]\ny_val = y_train[-20000:]\nx_train = x_train[:-20000]\ny_train = y_train[:-20000]","metadata":{"_uuid":"30e69a2a034e279da6eeb0fc09f1a58b58fc0401","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_size = (3,3)\npool_size= (2,2)\nfirst_filter = 32\nsecond_filter = 64\nthird_filter = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.5\n\nmodel = Sequential()\n\n# 1st layer \nmodel.add(Conv2D(first_filter, kernel_size, input_shape = (96, 96, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\n# 2nd layer \nmodel.add(Conv2D(second_filter, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\n# 3rd layer \nmodel.add(Conv2D(third_filter, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\n# end layer\nmodel.add(Flatten())\nmodel.add(Dense(256, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(1, activation = \"sigmoid\"))","metadata":{"_uuid":"9434b86b47f6132843b328d4fbf326aad01b24c0","_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compiling the model\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.001), \n              metrics=['accuracy'])\n\n# training the model\nmodel.fit(\n    x_train,\n    y_train,\n    batch_size=50,\n    epochs=4,\n    validation_data=(x_val, y_val),\n)","metadata":{"_uuid":"43c6aea09f1541f2411ad651ada5a3552304ac0b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = None\ny = None\ngc.collect();\n\nbase_test_dir = path + 'test/' \ntest_files = glob(os.path.join(base_test_dir,'*.tif')) \nsubmission = pd.DataFrame() \nfile_batch = 5000 \nmax_idx = len(test_files) \nfor idx in range(0, max_idx, file_batch): \n    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]}) \n    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) \n    test_df['image'] = test_df['path'].map(cv2.imread) \n    K_test = np.stack(test_df[\"image\"].values) \n    predictions = model.predict(K_test,verbose = 1) \n    test_df['label'] = predictions \n    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n#submission.head()","metadata":{"_uuid":"6d5d71c896efb4018434d00d1aab03d3355cb367","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False, header = True) #submission ","metadata":{"_uuid":"a6113e9f267e0902a423490b75fa331f524e2aae","trusted":true},"execution_count":null,"outputs":[]}]}