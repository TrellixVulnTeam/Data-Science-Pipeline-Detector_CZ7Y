{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\"\"\"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\"\"\"\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/histopathologic-cancer-detection')\nos.listdir()\ntest_files=os.listdir('test') # Name of the images of the test dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.applications.resnet import ResNet50\nfrom keras.layers import Dense,Conv2D,MaxPool2D,BatchNormalization,Dropout,Flatten,AvgPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD,RMSprop,Adam\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA,LatentDirichletAllocation\nimport eli5","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"sample_submission.csv\")\ntrain_labels = pd.read_csv(\"train_labels.csv\")\ntrain_labels['label']=train_labels['label'].apply(lambda x:str(x))\ntrain_labels['id']=train_labels['id'].apply(lambda x:str(x)+'.tif')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['label'].value_counts().plot(kind='bar')\nprint(train_labels['label'].value_counts())\nplt.yticks(color='yellow')\nplt.xticks(color='yellow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The dataset is imbalanced. So we will check ADASYN or SMOTE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_datagen=ImageDataGenerator(rescale=1./255,validation_split=0.15)\ntest_datagen=ImageDataGenerator(rescale=1./255)\ntraindir='train'\ntestdir='test'\ntrain=train_datagen.flow_from_dataframe(train_labels,directory=traindir,\n                                        x_col='id',y_col='label',\n                                        subset='training',\n                                        target_size=(96,96),\n                                        batch_size=64,class_mode='binary')\n\nvalidation=train_datagen.flow_from_dataframe(train_labels,directory=traindir,\n                                        x_col='id',y_col='label',\n                                        subset='validation',\n                                        target_size=(96,96),\n                                        batch_size=64,class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Length of the training dataset is {len(train)*64} ,validation {len(validation)*64} ,test {len(test_files)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing some examples\ntemp_img,temp_label=next(iter(train))\nj=0\nfig=plt.figure(figsize=(10,10))\nfor idx, img in enumerate(temp_img):\n    if j==16:\n        break\n    j+=1\n    ax = fig.add_subplot(4,4, idx+1)\n    plt.imshow(img)\n    lab = temp_label[idx]\n    ax.set_title('Label: %s'%lab,color='yellow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing with T-Stochastic Neighbour Embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne=TSNE(n_components=2,init='pca')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nims=[] # For Images\nlbs=[] # For labels\nfor idx,batch in enumerate(train):\n    image,label=batch\n    image=[i.reshape(-1) for i in image]\n    ims+=image\n    for i in label:\n        lbs.append(i)\n    if len(ims)>1000:\n        print(len(ims))\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplt.figure(figsize=(10,10))\nims=tsne.fit_transform(ims)\nplt.scatter(ims[:,0],ims[:,1],c=lbs)\nplt.legend([\"Not a Cancer Cell\",\"Cancer Cell\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So we can see how the classes are clustered and how one class actually","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=Sequential()\n\n# Conv1 Layer\nclassifier.add(Conv2D(16,(3,3),strides=(1,1),input_shape=(96,96,3),activation='relu'))\nclassifier.add(Conv2D(16,(3,3),activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n# Conv2 Layer\nclassifier.add(Conv2D(32,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(32,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(32,(3,3),strides=1,activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n\n# Conv3 Layer\nclassifier.add(Conv2D(64,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(64,(3,3),strides=1,activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n\n# Conv4 Layer\nclassifier.add(Conv2D(128,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(128,(3,3),strides=1,activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n\n# Dense Layer\nclassifier.add(Flatten())\nclassifier.add(Dense(units=128,activation='relu'))\nclassifier.add(Dense(units=64,activation='relu'))\nclassifier.add(Dense(units=32,activation='relu'))\nclassifier.add(Dense(units=1,activation='sigmoid'))\n\nclassifier.compile(optimizer=Adam(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=classifier.fit_generator(train,epochs=9,validation_data=validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def occlusion_analysis(image,label,occluding_size,occluding_pixel,occluding_stride):\n    \"\"\" Convnet Visualization \"\"\"\n    \n    \n    height,width,_=image.shape\n    image=np.expand_dims(image,axis=0)\n    out=classifier.predict(image)\n    \n    # Setting up output height and output width\n    \n    output_height=int(np.floor((height-occluding_size)/occluding_stride+1))\n    output_width=int(np.floor((width-occluding_size)/occluding_stride+1))\n    heatmap=np.zeros((output_height,output_width))\n    \n    for h in range(output_height):\n        for w in range(output_width):\n            # Occluder region\n            \n            h_start=h*occluding_stride\n            h_end=min(height,h_start+occluding_size)\n            \n            w_start=w*occluding_stride\n            w_end=min(width,w_start+occluding_size)\n            \n            input_image=image.copy()\n            \n            input_image[:,h_start:h_end,w_start:w_end,:]=occluding_pixel\n            \n            predict=classifier.predict(input_image)\n            \n            heatmap[h,w]=predict\n            \n    f=plt.figure(figsize=(10,10))\n    f.add_subplot(2,2,1)\n    sns.heatmap(heatmap,xticklabels=True)\n    f.add_subplot(2,2,3\"]))\n    plt.imshow(image[0])\n    plt.title(label)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y1,l1=next(iter(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#occlusion_analysis(y1[2],l1[2],occluding_size=40,occluding_pixel=2,occluding_stride=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.imshow(y1[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}