{"cells":[{"metadata":{"_uuid":"3c692dc79ee40c97e69ce91195e187872e8f49fb"},"cell_type":"markdown","source":"Batch size: 64\nAdded seed\n\nCommit 2:\n- 8 epochs\n\nCommit 3:\n- added use of callbacks\n\nCommit 4:\n- change to val_loss\n\nCommit 5:\n- 10 epochs\n\nCommit 6:\n- batch_size: 64"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom datetime import datetime\n\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Dense,Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\nfrom keras import regularizers, optimizers\nfrom keras.optimizers import Adam, SGD\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.applications.vgg19 import VGG19\n\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler\n\nimport matplotlib.pyplot as plt \nplt.rcParams['figure.figsize'] = (20,10)\n\ndef append_ext(fn):\n    return fn+\".tif\"\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['train', 'test', 'train_labels.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"61d3b8a9782b6911f3ade7f1a3e3e2c292fb07f1"},"cell_type":"code","source":"#seed\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(1)","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"traindf=pd.read_csv(\"../input/train_labels.csv\",dtype=str)\ntrain_size = 180000\ntraindf = traindf.sort_values(by=['label','id'])\ntraindf = traindf.iloc[:int(train_size/2)].append(traindf.iloc[-int(train_size/2):])\ntestdf=pd.read_csv(\"../input/sample_submission.csv\",dtype=str)\ntraindf[\"id\"]=traindf[\"id\"].apply(append_ext)\ntestdf[\"id\"]=testdf[\"id\"].apply(append_ext)\ndatagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a6c1776132938fe9d7453158405e16ecb7aab65","scrolled":true},"cell_type":"code","source":"batch_size = 64\n\ntrain_generator=datagen.flow_from_dataframe(\n                                            dataframe=traindf,\n                                            directory=\"../input/train/\",\n                                            x_col=\"id\",\n                                            y_col=\"label\",\n                                            subset=\"training\",\n                                            batch_size=batch_size,\n                                            seed=42,\n                                            shuffle=True,\n                                            class_mode=\"binary\",\n                                            target_size=(96, 96)\n)\n\nvalid_generator=datagen.flow_from_dataframe(\n                                            dataframe=traindf,\n                                            directory=\"../input/train/\",\n                                            x_col=\"id\",\n                                            y_col=\"label\",\n                                            subset=\"validation\",\n                                            batch_size=batch_size,\n                                            seed=42,\n                                            shuffle=True,\n                                            class_mode=\"binary\",\n                                            target_size=(96, 96)\n)\n\ntest_datagen=ImageDataGenerator(rescale=1./255.)\n\ntest_generator=test_datagen.flow_from_dataframe(\n                                                dataframe=testdf,\n                                                directory=\"../input/test/\",\n                                                x_col=\"id\",\n                                                y_col=None,\n                                                batch_size=batch_size,\n                                                seed=42,\n                                                shuffle=False,\n                                                class_mode=None,\n                                                target_size=(96, 96)\n)","execution_count":4,"outputs":[{"output_type":"stream","text":"Found 135000 images belonging to 2 classes.\nFound 45000 images belonging to 2 classes.\nFound 57458 images.\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"2206edd0a86b806d201eec4085cea486888873bd"},"cell_type":"code","source":"train_generator.n//train_generator.batch_size","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"2109"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"490fb2646bf8985a4b18ef8c3d0c0ff3ff68b552"},"cell_type":"code","source":"def auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfed64d51239dd4468c19b2c838e997b3eb09494"},"cell_type":"code","source":"def make_model(model_choice, input_shape):\n    '''Function to create a model\n    \n    Output:\n    - model made with keras.model.Model'''\n    \n    base_model = model_choice\n    x = base_model(input_shape)\n    out = Dense(1, activation=\"softmax\")(x)\n    model = Model(base_model.input, out)\n    \n    model.summary()\n\n    return model","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0d0250ce5c82fc437f554acc0fd3a98661f45db"},"cell_type":"code","source":"input_shape = (96, 96, 3)\n\nResNet50_model=make_model(ResNet50(include_top=False, pooling='avg', input_tensor=None, input_shape=input_shape), input_shape)","execution_count":null,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94658560/94653016 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"21595d376ea69733fc4d9cfaaadd8f4589639bbb"},"cell_type":"code","source":"#Callbacks\nbest_model_weights = './base.model'\n\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor = 'val_loss',\n    save_best_only = True,\n    mode='min',\n    verbose=1,\n    save_weights_only=False,\n    period = 1)\n\nearlyStop = EarlyStopping(\n    monitor = 'val_loss',\n    min_delta=0.01,\n    patience = 5,\n    verbose = 1,\n    mode = 'min')\n\ntensorBoard = TensorBoard(\n    log_dir = './logs',\n    histogram_freq=0,\n    batch_size=batch_size,\n    write_graph=True,\n    write_grads=True,\n    write_images=False)\n\n#learnrate = LearningRateSchedule(lambda x: 1. / (1. + x))\n\nreduce = ReduceLROnPlateau(monitor='val_loss',\n                           factor=0.5,\n                          patience=3,\n                          verbose=1,\n                          mode='min'\n                          )\n\ncsvlogger = CSVLogger(filename='training_csv.log',\n                     separator=',',\n                     append=False)\n\ncallbacks = [checkpoint, tensorBoard, csvlogger, reduce]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aededed59ed88c1552e019219133e4ce3432503c"},"cell_type":"code","source":"start=datetime.now()\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44f2e750633c9d0fb6e96ec6d95f05656ea35238","scrolled":false},"cell_type":"code","source":"ResNet50_model.compile(optimizer=SGD(lr=1e-4, momentum=0.99), loss=binary_crossentropy, metrics=['accuracy', auc])\n\nhistory = ResNet50_model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=6,\n                    callbacks=callbacks\n)\nend = datetime.now()\n\nprint(\"Elapsed time:\",end-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46bb59009b62f2dfbb5ec3ca87ac281a08c32483"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('ResNet50 model accuracy')\nplt.legend(['ResNet50 training','ResNet50 validation'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d95d438e7ced78af5a3cebee9b23a2c174d6c31"},"cell_type":"code","source":"plt.plot(history.history['auc'])\nplt.plot(history.history['val_auc'])\nplt.title('ResNet50 Model AUC')\nplt.legend(['ResNet50 Training','ResNet50 Validation'])\nplt.ylabel('AUC')\nplt.xlabel('epoch')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8014927b53f47202da07266df891e52171d90079"},"cell_type":"code","source":"ResNet50_model.load_weights(best_model_weights)\nResNet50_model.evaluate_generator (generator=valid_generator,\n                         steps=STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1db185935cf9cf7fc8d5350f8bac4b8897999eea"},"cell_type":"code","source":"def get_results(model_used):\n\n    test_generator.reset()\n    pred=model_used.predict_generator(test_generator,\n                                       steps=STEP_SIZE_TEST+1,\n                                       verbose=1)\n\n    predicted_class_indices=np.argmax(pred,axis=1)\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predictions = [labels[k] for k in predicted_class_indices]\n    filenames=test_generator.filenames\n    results=pd.DataFrame({\"id\":[f[:-4] for f in filenames],\n                      \"label\":[x[0] for x in pred]})\n\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"603ce956976bfad5b8643cbcb196e6028d6e3cf2"},"cell_type":"code","source":"results = get_results(ResNet50_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ce9ae2c7381630dc6fae58c0f9e2d5c2d68a880"},"cell_type":"code","source":"results.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"428fa4094e5cb2bdaef921132fab7c9b3542ebe9"},"cell_type":"code","source":"results.to_csv(\"results.csv\",\n               index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93c534bc61424bb0bc54095a0364d2ea6fa33b0e"},"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = './logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 8080 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d1ba82407ef2be56f4b695398d45bff15bff5ef"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}