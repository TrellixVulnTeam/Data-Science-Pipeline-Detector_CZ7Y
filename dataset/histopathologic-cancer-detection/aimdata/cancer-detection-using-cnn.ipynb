{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3981653f3df0bd61eaf4dea13b7b4ebb38b58b15"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\n\nIMG_SIZE = (96, 96)\nIN_SHAPE = (*IMG_SIZE, 3)\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9d070e1bc2762a687107733e35d9478db2d533e"},"cell_type":"code","source":"# CROP_TEST = 36\n# IN_SHAPE_TEST = (CROP_TEST,CROP_TEST,3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"161f9afec7c2e0c16684f1d8c8450386f5c8abbe"},"cell_type":"code","source":"df_data = pd.read_csv('../input/train_labels.csv')\ntrain_dir = \"../input/train/\"\ntest_dir = \"../input/test\"\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d6f9874e74b0b35ffdb485f0c58f41fe2eeea99"},"cell_type":"markdown","source":"Negative examples.\n\nCredit: https://www.kaggle.com/byrachonok/cancer-detection-show-data"},{"metadata":{"trusted":true,"_uuid":"69afdacc30f9e491aec315bdd676fd8fd1a2b679"},"cell_type":"code","source":"#Taken from https://www.kaggle.com/byrachonok/cancer-detection-show-data\nfig, ax = plt.subplots(1,3, figsize=(20,5))\nfor i, idx in enumerate(df_data[df_data['label'] == 0]['id'][:3]):\n    path = os.path.join('/kaggle/input/train/', idx)\n    ax[i].imshow(Image.open(path+'.tif'))\n    pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n            fc=(0.0, 0.0, 0.0, 0.0), \n            ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n    ax[i].add_patch(pf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"210f96944b518f60ac0b4ac1749f8e44fd8baf5e"},"cell_type":"markdown","source":"Positive examples"},{"metadata":{"trusted":true,"_uuid":"45ef2ed81f1f3aec29f0f363c1e37143724630fd"},"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(20,5))\nfor i, idx in enumerate(df_data[df_data['label'] == 1]['id'][:3]):\n    path = os.path.join('/kaggle/input/train/', idx)\n    ax[i].imshow(Image.open(path+'.tif'))\n    pt = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n            fc=(0.0, 0.0, 0.0, 0.0), \n            ec=(0.9, 0.0, 0.0 ,0.9), lw=4, linestyle='--')\n    ax[i].add_patch(pt)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80068460f612096d9aa938de0e2e9bab75300542"},"cell_type":"markdown","source":"Credit: https://www.kaggle.com/fadhli/starter-code-keras-resnet50-0-9275-lb"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train, valid = train_test_split(df_data,test_size=0.15)\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rotation_range=90, shear_range=0.05, zoom_range=0.1 )\n\ntest_datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = train,\n    directory='../input/train/',\n    x_col='id',\n    y_col='label',\n    has_ext=False,\n    batch_size=BATCH_SIZE,\n    seed=2018,\n    shuffle=True,\n    class_mode='binary',\n    target_size=IMG_SIZE)\n\nvalid_generator = test_datagen.flow_from_dataframe(\n    dataframe = valid,\n    directory='../input/train/',\n    x_col='id',\n    y_col='label',\n    has_ext=False,\n    batch_size=BATCH_SIZE,\n    seed=2018,\n    shuffle=False,\n    class_mode='binary',\n    target_size=IMG_SIZE\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d64c222f62e82cc2c6c8e128592f895a6eed541"},"cell_type":"markdown","source":"Model using VGG16 as base"},{"metadata":{"trusted":true,"_uuid":"6ccc1ce66b3cb545cf77a2a1e12ed55cd90598f3"},"cell_type":"code","source":"# conv_base = ResNet50(\n#     weights='imagenet',\n#     include_top=False,\n#     input_shape=IN_SHAPE\n# )\n\n# VGG model without the last classifier layers (include_top = False)\nconv_base = VGG16(include_top = False,\n                    input_shape = IN_SHAPE,\n                    weights='imagenet')\n    \n# Freeze the layers \nfor layer in conv_base.layers[:-12]:\n    layer.trainable = False\n    \n# Check the trainable status of the individual layers\nfor layer in conv_base.layers:\n    print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"afc63b073a1f10c5b41c0a2be540eed68512538c"},"cell_type":"code","source":"model = Sequential()\n# model.add(Cropping2D(cropping=((CROP_TEST,CROP_TEST), (48,48)), input_shape=IN_SHAPE))\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation=\"relu\"))\nmodel.add(Dropout(0.6))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.6))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nconv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cab3886f879f3cafef23a8c4511d4bf412ae32cb"},"cell_type":"code","source":"# conv_base.Trainable=True\n\n# set_trainable=False\n# for layer in conv_base.layers:\n#     if layer.name == 'res5a_branch2a':\n#         set_trainable = True\n#     if set_trainable:\n#         layer.trainable = True\n#     else:\n#         layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f8f84ea82cc6886845f56c2b216b4b7d957e05f"},"cell_type":"code","source":"model.compile(optimizers.Adam(0.001), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2aaf9a35be1991d415fa7a8042ee643ea4da3d4f"},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n\nearlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\nlearning_rate_decay = ReduceLROnPlateau(monitor='acc', patience=2, verbose=1, factor=0.3, min_lr=1e-5)\n\nhistory = model.fit_generator(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=50,\n                   callbacks=[learning_rate_decay, earlystopper])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58560aa0f27664dd4b9b99bf171ee1bc257b3043"},"cell_type":"markdown","source":"Submission"},{"metadata":{"trusted":true,"_uuid":"7a59f9d613cea6724a64d07f6e6d153cc7882edf"},"cell_type":"code","source":"from glob import glob\nfrom skimage.io import imread\n\nbase_test_dir = '../input/test/'\ntest_files = glob(os.path.join(base_test_dir,'*.tif'))\nsubmission = pd.DataFrame()\nfile_batch = 5000\nmax_idx = len(test_files)\nfor idx in range(0, max_idx, file_batch):\n    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n    test_df['image'] = test_df['path'].map(imread)\n    K_test = np.stack(test_df[\"image\"].values)\n    K_test = (K_test - K_test.mean()) / K_test.std()\n    predictions = model.predict(K_test)\n    test_df['label'] = predictions\n    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76c3e0d63abfc0aee3666db6aafde91d5abf2235"},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False, header = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90e4868a34a23a69d6131c6ffd227381090c6692"},"cell_type":"code","source":"# Save the last model\n#model.save('../input/model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69a4cd5d4f72e5a1d193ef89ca25dc0cb14f698d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}