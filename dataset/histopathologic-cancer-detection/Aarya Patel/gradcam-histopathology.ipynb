{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.applications.densenet import DenseNet201, preprocess_input,decode_predictions\nfrom keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalAveragePooling2D, GlobalMaxPooling2D, Flatten, Concatenate\nfrom keras.models import Model\nimport pandas as pd\nfrom random import shuffle\nimport numpy as np\nimport cv2\nimport glob\nimport gc\nimport os\nimport tensorflow as tf\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Input, BatchNormalization, Add, GlobalAveragePooling2D,AveragePooling2D,GlobalMaxPooling2D,concatenate\nfrom keras.layers import Lambda, Reshape, DepthwiseConv2D, ZeroPadding2D, Add, MaxPooling2D,Activation, Flatten, Conv2D, Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard,TerminateOnNaN\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.models import Model,load_model\nfrom keras.applications import NASNetMobile,MobileNetV2,densenet,resnet50,xception\n\nfrom keras_applications.resnext import ResNeXt50\nfrom albumentations import Resize,Compose, RandomRotate90, Transpose, Flip, OneOf, CLAHE, IAASharpen, IAAEmboss, RandomBrightnessContrast, JpegCompression, Blur, GaussNoise, HueSaturationValue, ShiftScaleRotate, Normalize\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom skimage import data, exposure\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init_model = load_model('../input/densenet-8020/densenet169_one_cycle_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install vis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\nimport vis ## keras-vis\nimport matplotlib.pyplot as plt\nimport numpy as np\nprint(\"keras      {}\".format(keras.__version__))\nprint(\"tensorflow {}\".format(tf.__version__))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# init_model.summary()\n# for ilayer, layer in enumerate(init_model.layers):\n#     print(\"{:3.0f} {:10}\".format(ilayer, layer.name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_label = ['no_tumor','tumor']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras-vis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis0 = df.loc[df['label'] == 0]['id'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis1 = df.loc[df['label'] == 1]['id'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\n#_img = load_img(\"duck.jpg\",target_size=(224,224))\n_img0 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis0[15] + '.tif')\nplt.imshow(_img0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bgr = cv2.imread('/kaggle/input/histopathologic-cancer-detection/train/' + lis0[15] + '.tif')\n\nlab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n\nlab_planes = cv2.split(lab)\n\nclahe = cv2.createCLAHE(clipLimit=40,tileGridSize=(20,20))\n\nlab_planes[0] = clahe.apply(lab_planes[0])\n\nlab = cv2.merge(lab_planes)\n\nbgr0 = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(bgr0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\n#_img = load_img(\"duck.jpg\",target_size=(224,224))\n_img1 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis1[10001] + '.tif')\nplt.imshow(_img1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bgr = cv2.imread('/kaggle/input/histopathologic-cancer-detection/train/' + lis1[10001] + '.tif')\n\nlab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n\nlab_planes = cv2.split(lab)\n\nclahe = cv2.createCLAHE(clipLimit=20,tileGridSize=(9,9))\n\nlab_planes[0] = clahe.apply(lab_planes[0])\n\nlab = cv2.merge(lab_planes)\n\nbgr1 = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(bgr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.figure(1)\nplt.subplot(121)\nplt.title('Input Image')\nplt.imshow(_img1)\n\nplt.subplot(122)\nplt.title('CLAHE Preprocessed Image')\nplt.imshow(bgr1)\nplt.show()\nplt.savefig('clahe.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img0               = img_to_array(_img0)\nimg0               = preprocess_input(img0)\ny_pred0            = init_model.predict(img0[np.newaxis,...])\nclass_index = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img1       = img_to_array(_img1)\nimg1               = preprocess_input(img1)\ny_pred1            = init_model.predict(img1[np.newaxis,...])\nclass_index = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from vis.utils import utils\n# Utility to search for layer index by name. \n# Alternatively we can specify this as -1 since it corresponds to the last layer.\nlayer_idx = utils.find_layer_idx(init_model, 'dense_3')\n# Swap softmax with linear\ninit_model.layers[layer_idx].activation = keras.activations.linear\nmodel = utils.apply_modifications(init_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_t_0 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis1[10001] + '.tif')\nimg_t_1 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis1[10002] + '.tif')\nimg_t_2 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis1[10003] + '.tif')\nimg_t_3 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis1[10004] + '.tif')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_nt_0 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis0[15] + '.tif')\nimg_nt_1 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis0[16] + '.tif')\nimg_nt_2 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis0[1001] + '.tif')\nimg_nt_3 = load_img('/kaggle/input/histopathologic-cancer-detection/train/' + lis0[101] + '.tif')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis_img_t = [img_t_0,img_t_1,img_t_2,img_t_3]\nlis_img_nt = [img_nt_0,img_nt_1,img_nt_2,img_nt_3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from vis.visualization import visualize_cam\npenultimate_layer_idx = utils.find_layer_idx(model, \"relu\") \n\nseed_input = img0\ngrad_top1_0_  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from vis.visualization import visualize_cam\npenultimate_layer_idx = utils.find_layer_idx(model, \"relu\") \n\nseed_input = img1\ngrad_top1_1_  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_img_t_0               = img_to_array(img_t_0)\n_img_t_0               = preprocess_input(_img_t_0)\ny_pred_0_t            = init_model.predict(_img_t_0[np.newaxis,...])\n\nseed_input = _img_t_0\n\ngrad_top1_t_0  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)\n\n_img_t_1               = img_to_array(img_t_1)\n_img_t_1               = preprocess_input(_img_t_1)\ny_pred_1_t            = init_model.predict(_img_t_1[np.newaxis,...])\n\nseed_input = _img_t_1\n\ngrad_top1_t_1  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)\n\n_img_t_2               = img_to_array(img_t_2)\n_img_t_2               = preprocess_input(_img_t_2)\ny_pred_2_t            = init_model.predict(_img_t_2[np.newaxis,...])\n\nseed_input = _img_t_2\n\ngrad_top1_t_2  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)\n\n_img_t_3               = img_to_array(img_t_3)\n_img_t_3               = preprocess_input(_img_t_3)\ny_pred_3_t            = init_model.predict(_img_t_3[np.newaxis,...])\n\nseed_input = _img_t_3\ngrad_top1_t_3  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_img_nt_0               = img_to_array(img_nt_0)\n_img_nt_0               = preprocess_input(_img_nt_0)\ny_pred_0_nt            = init_model.predict(_img_nt_0[np.newaxis,...])\n\nseed_input = _img_nt_0\n\ngrad_top1_nt_0  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)\n\n_img_nt_1               = img_to_array(img_nt_1)\n_img_nt_1               = preprocess_input(_img_nt_1)\ny_pred_1_nt            = init_model.predict(_img_nt_1[np.newaxis,...])\n\nseed_input = _img_nt_1\n\ngrad_top1_nt_1  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)\n\n_img_nt_2               = img_to_array(img_nt_2)\n_img_nt_2               = preprocess_input(_img_nt_2)\ny_pred_2_nt            = init_model.predict(_img_nt_2[np.newaxis,...])\n\nseed_input = _img_nt_2\n\ngrad_top1_nt_2  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)\n\n_img_nt_3               = img_to_array(img_nt_3)\n_img_nt_3               = preprocess_input(_img_nt_3)\ny_pred_3_nt            = init_model.predict(_img_nt_3[np.newaxis,...])\n\nseed_input = _img_nt_3\ngrad_top1_nt_3  = visualize_cam(model, layer_idx, 0, seed_input, \n                           penultimate_layer_idx = penultimate_layer_idx,#None,\n                           backprop_modifier = None,\n                           grad_modifier = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred_nt = [y_pred_0_nt,y_pred_1_nt,y_pred_2_nt,y_pred_3_nt]\nypred_t = [y_pred_0_t,y_pred_1_t,y_pred_2_t,y_pred_3_t]\nnt = [grad_top1_nt_0,grad_top1_nt_1,grad_top1_nt_2,grad_top1_nt_3]\nt = [grad_top1_t_0,grad_top1_t_1,grad_top1_t_2,grad_top1_t_3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_map(grads):\n    fig, axes = plt.subplots(1,2,figsize=(14,5))\n    axes[0].imshow(_img0)\n    axes[1].imshow(_img0)\n    i = axes[1].imshow(grads,cmap=\"jet\",alpha=0.8)\n    fig.colorbar(i)\n    plt.suptitle(\"Pr(class={}) = {:5.6f}\".format(\n                      class_label[0],\n                      y_pred0[0,0]))\n    plt.savefig('no_tumor_class.png')\nplot_map(grad_top1_nt_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_map(grads):\n    fig, axes = plt.subplots(1,2,figsize=(14,5))\n    axes[0].imshow(_img1)\n    axes[1].imshow(_img1)\n    i = axes[1].imshow(grads,cmap=\"jet\",alpha=0.8)\n    fig.colorbar(i)\n    plt.suptitle(\"Pr(class={}) = {:5.6f}\".format(\n                      class_label[1],\n                      y_pred1[0,0]))\n    plt.savefig('tumor_class.png')\nplot_map(grad_top1_t_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_map():\n    fig, axes = plt.subplots(2,4, figsize=(16,12))\n    fig.suptitle('Grad-CAM\\nPredicted / Actual / Probability',fontsize=20)\n    for i in range(4):\n        axes[0,i].imshow(lis_img_nt[i])\n        axes[0,i].imshow(nt[i],cmap=\"jet\",alpha=0.8)\n        axes[0,i].set_xticks([])\n        axes[0,i].set_yticks([])\n        axes[0,i].set_title(f'{class_label[ypred_nt[i][0,0] > 0.5]} / {class_label[0]} / {ypred_nt[i][0,0]:.4f}')\n    axes[0,0].set_ylabel('Non Tumor\\nSamples', fontsize=16, rotation=0, labelpad=80)\n    for i in range(4):\n        axes[1,i].imshow(lis_img_t[i])\n        axes[1,i].imshow(t[i],cmap=\"jet\",alpha=0.8)\n        axes[1,i].set_xticks([])\n        axes[1,i].set_yticks([])\n        axes[1,i].set_title(f'{class_label[ypred_t[i][0,0] > 0.5]} / {class_label[1]} / {ypred_t[i][0,0]:.4f}')\n    axes[1,0].set_ylabel('Tumor Samples', fontsize=16, rotation=0, labelpad=80)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.savefig('tumor_class.png')\nplot_map()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}