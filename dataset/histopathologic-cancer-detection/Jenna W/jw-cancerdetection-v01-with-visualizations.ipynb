{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Exploratory Data Exploration Notebook**","metadata":{}},{"cell_type":"markdown","source":"This notebook will look at the histopathologic cancer detection images and how they are represented in our final model.","metadata":{}},{"cell_type":"markdown","source":"# Import namespaces","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport matplotlib.image as mpimg\n\nfrom sklearn.model_selection import train_test_split\n\nimport pickle\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-10T15:11:50.20433Z","iopub.execute_input":"2021-12-10T15:11:50.205079Z","iopub.status.idle":"2021-12-10T15:11:56.000282Z","shell.execute_reply.started":"2021-12-10T15:11:50.204974Z","shell.execute_reply":"2021-12-10T15:11:55.999532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"# Load the training data into a DataFrame named 'train'. \n# Print the shape of the resulting DataFrame. \n\ntrain = pd.read_csv(f'../input/histopathologic-cancer-detection/train_labels.csv', dtype=str)\n\nprint('Training Set Size:', train.shape)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:12:21.070151Z","iopub.execute_input":"2021-12-10T15:12:21.070425Z","iopub.status.idle":"2021-12-10T15:12:21.281369Z","shell.execute_reply.started":"2021-12-10T15:12:21.070395Z","shell.execute_reply":"2021-12-10T15:12:21.280612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets update the dataset to include filename extensions","metadata":{}},{"cell_type":"code","source":"train['id'] = train['id'].apply(lambda x: f'{x}.tif')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:12:24.454465Z","iopub.execute_input":"2021-12-10T15:12:24.45473Z","iopub.status.idle":"2021-12-10T15:12:24.544566Z","shell.execute_reply.started":"2021-12-10T15:12:24.4547Z","shell.execute_reply":"2021-12-10T15:12:24.543674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Distribution","metadata":{}},{"cell_type":"code","source":"(train.label.value_counts() / len(train)).to_frame().sort_index().T","metadata":{"execution":{"iopub.status.busy":"2021-12-10T02:52:56.267981Z","iopub.execute_input":"2021-12-10T02:52:56.268272Z","iopub.status.idle":"2021-12-10T02:52:56.308688Z","shell.execute_reply.started":"2021-12-10T02:52:56.268241Z","shell.execute_reply":"2021-12-10T02:52:56.308038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View Sample of Images","metadata":{}},{"cell_type":"code","source":"#Sample images of original dataset\n\ntrain_path = \"../input/histopathologic-cancer-detection/train\"\nprint('Training Images:', len(os.listdir(train_path)))\n\nsample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(8,8))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row.id}')    \n    label = row.label\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:42:18.778838Z","iopub.execute_input":"2021-12-05T18:42:18.77913Z","iopub.status.idle":"2021-12-05T18:42:20.147111Z","shell.execute_reply.started":"2021-12-05T18:42:18.779099Z","shell.execute_reply":"2021-12-05T18:42:20.146187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:42:27.835736Z","iopub.execute_input":"2021-12-05T18:42:27.836454Z","iopub.status.idle":"2021-12-05T18:42:27.840536Z","shell.execute_reply.started":"2021-12-05T18:42:27.836413Z","shell.execute_reply":"2021-12-05T18:42:27.839753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of images for Class = 1\nimg_names = train[train['label']=='1']['id'][:16]\n\nplt.figure(figsize=[8,8])\ni = 1\nfor img_name in img_names:\n    img = mpimg.imread(\"../input/histopathologic-cancer-detection/train/%s\" % img_name)[...,[2, 1, 0]] \n    plt.subplot(4, 4, i)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class 1', color='k')\n    i += 1\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:26:19.844488Z","iopub.execute_input":"2021-12-05T18:26:19.844797Z","iopub.status.idle":"2021-12-05T18:26:20.952507Z","shell.execute_reply.started":"2021-12-05T18:26:19.844761Z","shell.execute_reply":"2021-12-05T18:26:20.951474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of images for Class = 0\nimg_names0 = train[train['label']==\"0\"]['id'][:16]\n\nplt.figure(figsize=[8,8])\ni = 1\nfor img_name0 in img_names0:\n    img = mpimg.imread(\"../input/histopathologic-cancer-detection/train/%s\" % img_name0)[...,[2, 1, 0]] \n    plt.subplot(4, 4, i)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class 0', color='k')\n    i += 1\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:49:28.215776Z","iopub.execute_input":"2021-12-05T18:49:28.216065Z","iopub.status.idle":"2021-12-05T18:49:29.363472Z","shell.execute_reply.started":"2021-12-05T18:49:28.216032Z","shell.execute_reply":"2021-12-05T18:49:29.362656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generators","metadata":{}},{"cell_type":"code","source":"#Using original dataset\nRANDOM_SEED = 1982\ntrain_df, valid_df = train_test_split(train, test_size=0.2, random_state=RANDOM_SEED, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:12:34.571142Z","iopub.execute_input":"2021-12-10T15:12:34.571854Z","iopub.status.idle":"2021-12-10T15:12:34.920915Z","shell.execute_reply.started":"2021-12-10T15:12:34.571802Z","shell.execute_reply":"2021-12-10T15:12:34.92006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create image data generators for both the training set and the validation set. \n# Use the data generators to scale the pixel values by a factor of 1/255. \n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    vertical_flip = True,\n    horizontal_flip = True,\n    rotation_range=90,\n    zoom_range=0.2, \n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    channel_shift_range=0.1,\n    fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale=1/255)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:12:37.932519Z","iopub.execute_input":"2021-12-10T15:12:37.933179Z","iopub.status.idle":"2021-12-10T15:12:37.93878Z","shell.execute_reply.started":"2021-12-10T15:12:37.933141Z","shell.execute_reply":"2021-12-10T15:12:37.937602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Complete the code for the data loaders below. \n\nBATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (96,96)\n)\n\nvalid_loader = valid_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (96,96)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:50:21.368281Z","iopub.execute_input":"2021-12-05T18:50:21.368788Z","iopub.status.idle":"2021-12-05T18:55:47.079011Z","shell.execute_reply.started":"2021-12-05T18:50:21.368735Z","shell.execute_reply":"2021-12-05T18:55:47.078124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Look at some augmented images\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(3, 5, figsize=(10,10))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n    plt.tight_layout()\n    plt.show()\n    \n    \naugmented_images = [train_loader[0][0][0] for i in range(15)]\nplotImages(augmented_images)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:57:10.521572Z","iopub.execute_input":"2021-12-05T18:57:10.521904Z","iopub.status.idle":"2021-12-05T18:57:16.095395Z","shell.execute_reply.started":"2021-12-05T18:57:10.521865Z","shell.execute_reply":"2021-12-05T18:57:16.094689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T18:57:22.877693Z","iopub.execute_input":"2021-12-05T18:57:22.878147Z","iopub.status.idle":"2021-12-05T18:57:22.884465Z","shell.execute_reply.started":"2021-12-05T18:57:22.878108Z","shell.execute_reply":"2021-12-05T18:57:22.88366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.image as mpimg","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:39:02.806187Z","iopub.execute_input":"2021-12-11T16:39:02.806583Z","iopub.status.idle":"2021-12-11T16:39:07.317625Z","shell.execute_reply.started":"2021-12-11T16:39:02.806497Z","shell.execute_reply":"2021-12-11T16:39:07.316868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:39:19.483369Z","iopub.execute_input":"2021-12-11T16:39:19.483915Z","iopub.status.idle":"2021-12-11T16:39:19.487617Z","shell.execute_reply.started":"2021-12-11T16:39:19.483876Z","shell.execute_reply":"2021-12-11T16:39:19.486914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn = keras.models.load_model('../input/finalmodel/LP_HCD_VGG16_Model.h5')\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:39:23.770337Z","iopub.execute_input":"2021-12-11T16:39:23.77071Z","iopub.status.idle":"2021-12-11T16:39:29.236165Z","shell.execute_reply.started":"2021-12-11T16:39:23.770672Z","shell.execute_reply":"2021-12-11T16:39:29.235254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VGG16(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(96, 96, 3)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:42:55.634535Z","iopub.execute_input":"2021-12-11T16:42:55.63482Z","iopub.status.idle":"2021-12-11T16:42:55.892821Z","shell.execute_reply.started":"2021-12-11T16:42:55.634791Z","shell.execute_reply":"2021-12-11T16:42:55.89211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:43:26.695159Z","iopub.execute_input":"2021-12-11T16:43:26.695411Z","iopub.status.idle":"2021-12-11T16:43:26.709431Z","shell.execute_reply.started":"2021-12-11T16:43:26.695382Z","shell.execute_reply":"2021-12-11T16:43:26.708555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualize Filters**","metadata":{}},{"cell_type":"markdown","source":"**Visualizing 6 filters out of 64 from the first layer of the VGG16 Model**\n\nThe dark squares indicate small or inhibitory weights and the light squares represent large or excitatory weights. ","metadata":{}},{"cell_type":"code","source":"#Iterate thru all the layers of the model\nfor layer in model.layers:\n    if 'conv' in layer.name:\n        weights, bias= layer.get_weights()\n        #print(layer.name)\n        #print(layer.name, filters.shape)\n        \n        #normalize filter values between  0 and 1 for visualization\n        f_min, f_max = weights.min(), weights.max()\n        filters = (weights - f_min) / (f_max - f_min)  \n        #print(filters.shape[3])\n        filter_cnt=1","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:42:05.069062Z","iopub.execute_input":"2021-12-10T15:42:05.069313Z","iopub.status.idle":"2021-12-10T15:42:05.129489Z","shell.execute_reply.started":"2021-12-10T15:42:05.069286Z","shell.execute_reply":"2021-12-10T15:42:05.128592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\n\nn_filters = 6\nix=1\nfig = pyplot.figure(figsize=(20,15))\nfor i in range(n_filters):\n    # get the filters\n    f = filters[:,:,:,i]\n    for j in range(3):\n        # subplot for 6 filters and 3 channels\n        pyplot.subplot(n_filters,3,ix)\n        pyplot.imshow(f[:,:,j])\n        ix+=1\n#plot the filters \npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:42:06.895557Z","iopub.execute_input":"2021-12-10T15:42:06.895882Z","iopub.status.idle":"2021-12-10T15:42:08.58267Z","shell.execute_reply.started":"2021-12-10T15:42:06.895848Z","shell.execute_reply":"2021-12-10T15:42:08.58198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualize Feature Maps**","metadata":{}},{"cell_type":"markdown","source":"The activation maps, called feature maps, capture the result of applying the filters to input, such as the input image or another feature map.\n\nThe idea of visualizing a feature map for a specific input image would be to understand what features of the input are detected or preserved in the feature maps. The expectation would be that the feature maps close to the input detect small or fine-grained detail, whereas feature maps close to the output of the model capture more general features.","metadata":{}},{"cell_type":"code","source":"cancer_data = train[(train.label==\"1\")]\nnon_cancer_data = train[(train.label==\"0\")]\n\nrow0 = non_cancer_data.iloc[6,:]\nimg0 = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row0.id}')    \n\nrow1 = cancer_data.iloc[4,:]\nimg1 = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row1.id}')    \n\nplt.subplot(1,2,1)\nplt.imshow(img0)\nplt.text(0, -2, 'No Cancer', color='k')\nplt.axis('off')\n\nplt.subplot(1,2,2)\nplt.imshow(img1)\nplt.text(0, -2, 'Cancer', color='k')\nplt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:42:12.089513Z","iopub.execute_input":"2021-12-10T15:42:12.089779Z","iopub.status.idle":"2021-12-10T15:42:12.352809Z","shell.execute_reply.started":"2021-12-10T15:42:12.089748Z","shell.execute_reply":"2021-12-10T15:42:12.352025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor0 = img0.reshape(1,96,96,3)/255\ntensor1 = img1.reshape(1,96,96,3)/255","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:42:15.195164Z","iopub.execute_input":"2021-12-10T15:42:15.195894Z","iopub.status.idle":"2021-12-10T15:42:15.200151Z","shell.execute_reply.started":"2021-12-10T15:42:15.195856Z","shell.execute_reply":"2021-12-10T15:42:15.19941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_layer(layer_index, activations, cmap):\n    layer_activations = activations[layer_index]\n    n_filters = layer_activations.shape[-1]\n       \n    n_cols = 8\n    n_rows = n_filters // n_cols\n    \n    print(f'{model.layers[layer_index].name} - {n_filters} Filters')\n    plt.figure(figsize=[2*n_cols, 2*n_rows])\n    \n    for i in range(n_filters):\n        img = layer_activations[0,:,:,i]\n        plt.subplot(n_rows, n_cols, i+1)\n        plt.imshow(img, cmap=cmap)\n        plt.axis('off')\n    plt.show() \n\n\ndef display_activations(img_tensor, layer_indices=[], cmap='viridis'):\n    layer_outputs = [layer.output for layer in model.layers]\n    activation_model = tf.keras.models.Model(inputs=model.inputs, outputs=layer_outputs)\n    activations = activation_model(img_tensor)\n    \n    for i in layer_indices:\n        display_layer(i, activations, cmap)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:55:30.288629Z","iopub.execute_input":"2021-12-10T15:55:30.28941Z","iopub.status.idle":"2021-12-10T15:55:30.297501Z","shell.execute_reply.started":"2021-12-10T15:55:30.289365Z","shell.execute_reply":"2021-12-10T15:55:30.296823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cancerous Feature Map","metadata":{}},{"cell_type":"markdown","source":"Feature map for the block1_conv1 and block1_conv2 filters.","metadata":{}},{"cell_type":"code","source":"display_activations(tensor1, [1,2], cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:56:16.735973Z","iopub.execute_input":"2021-12-10T15:56:16.736232Z","iopub.status.idle":"2021-12-10T15:56:23.073161Z","shell.execute_reply.started":"2021-12-10T15:56:16.736202Z","shell.execute_reply":"2021-12-10T15:56:23.070852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Non Cancerous Feature Map","metadata":{}},{"cell_type":"code","source":"display_activations(tensor0, [1,2], cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:56:55.611696Z","iopub.execute_input":"2021-12-10T15:56:55.612108Z","iopub.status.idle":"2021-12-10T15:57:01.795828Z","shell.execute_reply.started":"2021-12-10T15:56:55.612073Z","shell.execute_reply":"2021-12-10T15:57:01.795177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Class Activation Map**","metadata":{}},{"cell_type":"markdown","source":"This technique involves creating heatmaps that shows you what part of an image the network is most interested in when determining its classifications. For any image, you can create one heatmap for each class. The heatmap will tell you what part of the image most strongly indicates the presence of the class in question.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport pickle\nimport cv2\nfrom tqdm import tqdm \nimport matplotlib as mpl\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport zipfile ","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:58:52.042451Z","iopub.execute_input":"2021-12-10T15:58:52.042704Z","iopub.status.idle":"2021-12-10T15:58:52.225414Z","shell.execute_reply.started":"2021-12-10T15:58:52.042674Z","shell.execute_reply":"2021-12-10T15:58:52.224658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heatmap Function","metadata":{}},{"cell_type":"code","source":"def create_grad_model(model):\n    for layer in reversed(model.layers):\n        if len(layer.output_shape) == 4:\n            last_conv_layer = layer.name\n            break\n\n    grad_model = tf.keras.models.Model(\n        inputs=[model.inputs],\n        outputs=[model.get_layer(last_conv_layer).output, model.output])\n    \n    return grad_model \n\ndef compute_heatmap(image, class_ix, grad_model):\n\n    with tf.GradientTape() as tape:\n        inputs = tf.cast(image, tf.float32)\n        (conv_outputs, predictions) = grad_model(inputs)\n        loss = predictions[:, class_ix]\n    grads = tape.gradient(loss, conv_outputs)\n\n    cast_conv_outputs = tf.cast(conv_outputs > 0, \"float32\")\n    cast_grads = tf.cast(grads > 0, \"float32\")\n    guided_grads = cast_conv_outputs * cast_grads * grads\n\n    conv_outputs = conv_outputs[0]\n    guided_grads = guided_grads[0]\n\n    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n\n    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs), axis=-1)\n\n    (w, h) = (image.shape[2], image.shape[1])\n    heatmap = cv2.resize(cam.numpy(), (w, h))\n        \n    return heatmap","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:58:57.502178Z","iopub.execute_input":"2021-12-10T15:58:57.502892Z","iopub.status.idle":"2021-12-10T15:58:57.513129Z","shell.execute_reply.started":"2021-12-10T15:58:57.502855Z","shell.execute_reply":"2021-12-10T15:58:57.512146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Example: First Heatmap","metadata":{}},{"cell_type":"code","source":"# Create Gradient Model\ngm = create_grad_model(model)\n\n# Select Image and Create Heatmap\nfilename = train.id[0]\n#img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/'{filename})    \nimg = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{filename}')\ntensor = img.reshape((1,) + img.shape) / 255\nheatmap = compute_heatmap(tensor, 1, gm)\n\nplt.figure(figsize=[9,3])\n\n# Display Image\nplt.subplot(1,3,1)\nplt.imshow(img)\nplt.axis('off')\n\n# Display Heatmap\nplt.subplot(1,3,2)\nplt.imshow(heatmap, cmap='coolwarm')\nplt.axis('off')\n\n# Display Image and Heatmap Together\nplt.subplot(1,3,3)\nplt.imshow(img, alpha=0.8, cmap='binary_r')\nplt.imshow(heatmap, alpha=0.6, cmap='coolwarm')\nplt.axis('off')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:59:11.908612Z","iopub.execute_input":"2021-12-10T15:59:11.908927Z","iopub.status.idle":"2021-12-10T15:59:12.755622Z","shell.execute_reply.started":"2021-12-10T15:59:11.908884Z","shell.execute_reply":"2021-12-10T15:59:12.754799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying Multiple Heatmaps\n","metadata":{}},{"cell_type":"code","source":"def get_heatmap_dist(df, class_ix, gm):\n\n    values = None\n    for i, row in tqdm(df.iterrows()):\n        img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row.id}')    \n        tensor = img.reshape((1,) + img.shape) / 255\n        hm = compute_heatmap(tensor, class_ix, gm)\n\n        if values is None:\n            values = hm.flatten()\n        else:\n            values = np.hstack([values, hm.flatten()])\n\n    return values","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:59:26.112406Z","iopub.execute_input":"2021-12-10T15:59:26.112663Z","iopub.status.idle":"2021-12-10T15:59:26.118902Z","shell.execute_reply.started":"2021-12-10T15:59:26.112633Z","shell.execute_reply":"2021-12-10T15:59:26.117941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = get_heatmap_dist(train.sample(1000, random_state=1), 1, gm)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T15:59:28.389642Z","iopub.execute_input":"2021-12-10T15:59:28.390205Z","iopub.status.idle":"2021-12-10T15:59:59.237947Z","shell.execute_reply.started":"2021-12-10T15:59:28.390165Z","shell.execute_reply":"2021-12-10T15:59:59.237109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"low = np.quantile(values, 0.10)\nhigh = np.quantile(values, 0.96)\n\nnorm = mpl.colors.Normalize(vmin=low, vmax=high)\n\nprint(low)\nprint(high)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T16:00:06.816021Z","iopub.execute_input":"2021-12-10T16:00:06.816516Z","iopub.status.idle":"2021-12-10T16:00:06.900978Z","shell.execute_reply.started":"2021-12-10T16:00:06.816478Z","shell.execute_reply":"2021-12-10T16:00:06.900094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select which images to display\nindices = range(12)\n\nfor i in indices:  \n    row = train.iloc[i,:]\n    img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row.id}')    \n    label = row.label\n    \n    tensor = img.reshape((1,) + img.shape) / 255\n    heatmap = compute_heatmap(tensor, 1, gm)\n\n    if(label == '1'):\n        print('Cancer Present')\n    else:\n        print('No Cancer')\n    \n    plt.figure(figsize=[9,3])\n\n    plt.subplot(1,3,1)\n    plt.imshow(img)\n    plt.axis('off')\n\n    plt.subplot(1,3,2)\n    plt.imshow(heatmap, cmap='coolwarm', norm=norm)\n    plt.axis('off')\n\n    plt.subplot(1,3,3)\n    plt.imshow(img, alpha=0.6, cmap='binary_r')\n    plt.imshow(heatmap, alpha=0.6, cmap='coolwarm', norm=norm)\n    plt.axis('off')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T16:00:09.96599Z","iopub.execute_input":"2021-12-10T16:00:09.966521Z","iopub.status.idle":"2021-12-10T16:00:13.366624Z","shell.execute_reply.started":"2021-12-10T16:00:09.966481Z","shell.execute_reply":"2021-12-10T16:00:13.365953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Distribution of Pixel Channels**","metadata":{}},{"cell_type":"markdown","source":"# All Training Images","metadata":{}},{"cell_type":"markdown","source":"This shows how the pixel values in each channel are distributed for images with each label (cancerous vs. non-cancerous).","metadata":{}},{"cell_type":"code","source":"path = \"../input/histopathologic-cancer-detection/\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating lists\n\n#Noncancerous Red\navg_list_00=[]\n#Noncancerous Green\navg_list_01=[]\n#Noncancerous Blue\navg_list_02=[]\n#Cancerous Red\navg_list_10=[]\n#Cancerous Green\navg_list_11=[]\n#Cancerous Blue\navg_list_12=[]","metadata":{"execution":{"iopub.status.busy":"2021-12-06T21:07:49.512605Z","iopub.execute_input":"2021-12-06T21:07:49.512894Z","iopub.status.idle":"2021-12-06T21:07:49.519284Z","shell.execute_reply.started":"2021-12-06T21:07:49.512859Z","shell.execute_reply":"2021-12-06T21:07:49.518352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loop over the cancerous entries\n\nfor i, row in cancer_data.iterrows():\n    img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row.id}')   \n    red_channel = img[:,:,0]\n    green_channel = img[:,:,1]\n    blue_channel = img[:,:,2]\n    redavg=np.average(red_channel)\n    greenavg=np.average(green_channel)\n    blueavg=np.average(blue_channel)\n    avg_list_10.append(redavg)\n    avg_list_11.append(greenavg)\n    avg_list_12.append(blueavg)\n     ","metadata":{"execution":{"iopub.status.busy":"2021-12-06T21:07:51.980054Z","iopub.execute_input":"2021-12-06T21:07:51.98031Z","iopub.status.idle":"2021-12-06T21:18:27.57115Z","shell.execute_reply.started":"2021-12-06T21:07:51.980281Z","shell.execute_reply":"2021-12-06T21:18:27.570394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loop over the non-cancerous entries\n\nfor i, row in non_cancer_data.iterrows():\n    img = mpimg.imread(f'../input/histopathologic-cancer-detection/train/{row.id}')   \n    red_channel0 = img[:,:,0]\n    green_channel0 = img[:,:,1]\n    blue_channel0 = img[:,:,2]\n    redavg0=np.average(red_channel0)\n    greenavg0=np.average(green_channel0)\n    blueavg0=np.average(blue_channel0)\n    avg_list_00.append(redavg0)\n    avg_list_01.append(greenavg0)\n    avg_list_02.append(blueavg0)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T21:27:09.298591Z","iopub.execute_input":"2021-12-06T21:27:09.299362Z","iopub.status.idle":"2021-12-06T21:42:07.375738Z","shell.execute_reply.started":"2021-12-06T21:27:09.299314Z","shell.execute_reply":"2021-12-06T21:42:07.374968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=[10,10])\n\nplt.subplot(3, 2, 1)\nplt.hist(avg_list_10, bins = 256, color = 'red')\n#plt.xlabel('Intensity')\n#plt.ylabel('Quantity')\nplt.ylim(0, 2000)\nplt.legend(['Red_Channel'])\nplt.title(\"Cancerous Red\")\n\nplt.subplot(3, 2, 2)\nplt.hist(avg_list_00, bins = 256, color = 'red')\n#plt.xlabel('Intensity')\n#plt.ylabel('Quantity')\nplt.ylim(0, 2000)\nplt.legend(['Red_Channel'])\nplt.title(\"Non-cancerous Red\")\n\nplt.subplot(3, 2, 3)\nplt.hist(avg_list_11, bins = 256, color = 'green')\n#plt.xlabel('Intensity')\n#plt.ylabel('Quantity')\nplt.ylim(0, 2000)\nplt.legend(['Green_Channel'])\nplt.title(\"Cancerous Green\")\n\nplt.subplot(3, 2, 4)\nplt.hist(avg_list_01, bins = 256, color = 'green')\n#plt.xlabel('Intensity')\n#plt.ylabel('Quantity')\nplt.ylim(0, 2000)\nplt.legend(['Green_Channel'])\nplt.title(\"Non-cancerous Green\")\n\nplt.subplot(3, 2, 5)\nplt.hist(avg_list_12, bins = 256, color = 'blue')\n#plt.xlabel('Intensity')\n#plt.ylabel('Quantity')\nplt.ylim(0, 2000)\nplt.legend(['Blue_Channel'])\nplt.title(\"Cancerous Blue\")\n\nplt.subplot(3, 2, 6)\nplt.hist(avg_list_02, bins = 256, color = 'blue')\n#plt.xlabel('Intensity')\n#plt.ylabel('Quantity')\nplt.ylim(0, 2000)\nplt.legend(['Blue_Channel'])\nplt.title(\"Non-cancerous Blue\")\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T21:51:11.398078Z","iopub.execute_input":"2021-12-06T21:51:11.398879Z","iopub.status.idle":"2021-12-06T21:51:19.365483Z","shell.execute_reply.started":"2021-12-06T21:51:11.398806Z","shell.execute_reply":"2021-12-06T21:51:19.364716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Cancerous Image","metadata":{}},{"cell_type":"code","source":"# With cv2\n#cancer_data = train[(train.label==\"1\")]\ncancer_image = cancer_data.iloc[900]['id']\nimg = cv2.imread(path + \"train/\" + cancer_image)\nplt.imshow(img)\nplt.title(\"Cancer Cell\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T19:19:16.907861Z","iopub.execute_input":"2021-12-05T19:19:16.908144Z","iopub.status.idle":"2021-12-05T19:19:17.170247Z","shell.execute_reply.started":"2021-12-05T19:19:16.908115Z","shell.execute_reply":"2021-12-05T19:19:17.169355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(img[:, :, 0].ravel(), bins = 256, color = 'red')\nplt.hist(img[:, :, 1].ravel(), bins = 256, color = 'Green')\nplt.hist(img[:, :, 2].ravel(), bins = 256, color = 'Blue')\nplt.xlabel('Intensity')\nplt.ylabel('Quantity')\nplt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.title(\"The frequency of the color channels of the cancer cells\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T19:19:19.506035Z","iopub.execute_input":"2021-12-05T19:19:19.506318Z","iopub.status.idle":"2021-12-05T19:19:21.743849Z","shell.execute_reply.started":"2021-12-05T19:19:19.50629Z","shell.execute_reply":"2021-12-05T19:19:21.743169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Non-Cancerous Image","metadata":{}},{"cell_type":"code","source":"#non_cancer_data = train[(train.label==\"0\")]\nnon_cancer_image = non_cancer_data.iloc[500]['id']\nimg = cv2.imread(path + \"train/\" + non_cancer_image)\nplt.imshow(img)\nplt.title(\"Non-Cancerous Cell\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T19:19:47.298082Z","iopub.execute_input":"2021-12-05T19:19:47.298687Z","iopub.status.idle":"2021-12-05T19:19:47.553955Z","shell.execute_reply.started":"2021-12-05T19:19:47.298653Z","shell.execute_reply":"2021-12-05T19:19:47.553111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(img[:, :, 0].ravel(), bins = 256, color = 'red')\nplt.hist(img[:, :, 1].ravel(), bins = 256, color = 'Green')\nplt.hist(img[:, :, 2].ravel(), bins = 256, color = 'Blue')\nplt.xlabel('Intensity')\nplt.ylabel('Quantity')\nplt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.title(\"The frequency of the color channels in the absence of cancer cells\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T19:19:51.052963Z","iopub.execute_input":"2021-12-05T19:19:51.053266Z","iopub.status.idle":"2021-12-05T19:19:53.587962Z","shell.execute_reply.started":"2021-12-05T19:19:51.053235Z","shell.execute_reply":"2021-12-05T19:19:53.587152Z"},"trusted":true},"execution_count":null,"outputs":[]}]}