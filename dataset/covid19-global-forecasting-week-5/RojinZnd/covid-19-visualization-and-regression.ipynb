{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import scale\nimport sklearn.linear_model as skl_lm\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n#Libraries to import\n\nimport datetime as dt\nimport requests\nimport sys\nfrom itertools import chain\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/test.csv\")\n\ndisplay(train.head())\ndisplay(train.describe())\ntrain.info()\ntrain.isnull().sum()\ntest.isnull().sum()\n\nprint(\"Number of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province/State informed: \", train.loc[train['Province_State']!='None']['Country_Region'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ID=train['Id']\nFID=test['ForecastId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_date_min = train['Date'].min()\ntrain_date_max = train['Date'].max()\nprint('Minimum date from training set: {}'.format(train_date_min))\nprint('Maximum date from training set: {}'.format(train_date_max))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_date_min = test['Date'].min()\ntest_date_max = test['Date'].max()\nprint('Minimum date from test set: {}'.format(test_date_min))\nprint('Maximum date from test set: {}'.format(test_date_max))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ** **Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(train, values='TargetValue', names='Target')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(train, values='TargetValue', names='Country_Region')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(train, values='Population', names='Country_Region')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Feature Selection**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train.corr()     #computing correlation between features and output\nprint(corr_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = train.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Modeling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(columns=['County','Province_State','Id'])\ntest=test.drop(columns=['County','Province_State','ForecastId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"da= pd.to_datetime(train['Date'], errors='coerce')\ntrain['Date']= da.dt.strftime(\"%Y%m%d\").astype(int)\nda= pd.to_datetime(test['Date'], errors='coerce')\ntest['Date']= da.dt.strftime(\"%Y%m%d\").astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nX = train.iloc[:,0].values\ntrain.iloc[:,0] = l.fit_transform(X.astype(str))\n\nX = train.iloc[:,4].values\ntrain.iloc[:,4] = l.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nX = test.iloc[:,0].values\ntest.iloc[:,0] = l.fit_transform(X.astype(str))\n\nX = test.iloc[:,4].values\ntest.iloc[:,4] = l.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train['TargetValue']\nx_train=train.drop(['TargetValue'],axis=1)\n\nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg=LinearRegression()\nlin_reg.fit(x_train,y_train)\n\nprint(lin_reg.intercept_)\nprint(lin_reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc1=lin_reg.score(x_test,y_test)\nacc1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression performs poorly.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Polynomial Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg2=PolynomialFeatures(degree=2)\nx_poly=poly_reg2.fit_transform(x_train)\nlin_reg_2=LinearRegression()\nlin_reg_2.fit(x_poly,y_train)\n\nprint(\"Coefficients of polynimial(degree2) are\", lin_reg_2.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing estimators\nfrom sklearn.ensemble import RandomForestRegressor \nmodel = RandomForestRegressor(n_jobs=-1)\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(x_train, y_train)\n    scores.append(model.score(x_test, y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\np = Pipeline([('scaler2' , StandardScaler()),\n                        ('RandomForestRegressor: ', RandomForestRegressor())])\np.fit(x_train , y_train)\nprediction = p.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc2=p.score(x_test,y_test)\nacc2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The performance of the is well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predict=p.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=pd.DataFrame({'id':FID,'TargetValue':predict})\noutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=output.groupby(['id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['id'])['TargetValue'].quantile(q=0.95).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}