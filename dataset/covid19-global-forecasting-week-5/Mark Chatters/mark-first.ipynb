{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/covid19-global-forecasting-week-5/train.csv')\ntest_data = pd.read_csv('../input/covid19-global-forecasting-week-5/test.csv')\nsample_data = pd.read_csv('../input/covid19-global-forecasting-week-5/submission.csv')\ncountry_data = pd.read_csv('/kaggle/input/country-data-population/country_data_population.csv')\n\nprint(\"Train shape: \", train_data.shape)\nprint(\"Test shape: \", test_data.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.merge(train_data,country_data, left_on=['Country_Region'],right_on=['Country'], how='left')\ntrain_data.drop(['Country','Lending Category','UrbanRuralDesignation','GeoRegion','Continent'], axis=1, inplace=True)\n\ntest_data = pd.merge(test_data,country_data, left_on=['Country_Region'],right_on=['Country'], how='left')\ntest_data.drop(['Country','Lending Category','UrbanRuralDesignation','GeoRegion','Continent'], axis=1, inplace=True)\n\ntrain_data['GeoSubregion'].fillna('', inplace=True)\ntest_data['GeoSubregion'].fillna('', inplace=True)\n\ntrain_data['Income Group'].fillna('', inplace=True)\ntest_data['Income Group'].fillna('', inplace=True)\n\ntrain_data['Province_State'].fillna('', inplace=True)\ntest_data['Province_State'].fillna('', inplace=True)\n\ntrain_data['County'].fillna('', inplace=True)\ntest_data['County'].fillna('', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n\n#turn Target_Value absolute value to a per 1000000 factor\ntrain_data['TargetValue'] = train_data['TargetValue'].abs()\ntrain_data['TargetValue_per_mill'] = (train_data['TargetValue'] /  train_data['Population']) * 1000000\ntrain_data['TargetValue_cumm'] = train_data.groupby(['Country_Region','Province_State','County','Target'])['TargetValue_per_mill'].cumsum()\n\ntrain_data['log_TargetValue_cumm'] = np.log2(train_data['TargetValue_cumm']+1)\n\ntrain_data.head(300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_short = train_data[train_data['Target']=='ConfirmedCases']\ntest_data_short  = test_data[test_data['Target']=='ConfirmedCases']\n\ntrain_data_short = train_data_short[['Country_Region','Date','Province_State','County','Target','TargetValue']]\ntest_data_short  = test_data_short[['Country_Region','Date','Province_State','County','Target']]\n\nall_data = pd.merge(train_data_short, test_data_short ,how='outer', on=['Country_Region','Date','Province_State','County','Target'])\n\nall_data.sort_values(['Country_Region','Province_State','County','Date','Target'], ascending = True, inplace = True)\nall_data = all_data.reset_index(drop=True)\n\nall_data.head(300)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Populate days_since_confirmedcases - not a very pythonic way of doing this \n\nall_data['days_since_confirmedcases'] = 0.0\nall_data['days_since_max_day']        = 0.0\nall_data['TargetValue'].fillna(0.0, inplace=True)\n\ncount = 0\nsave_province_state = \"\"\nsave_country_region = \"\"\nsave_county         = \"\"\nsave_confirmedcases = 0.0\nfirst_confirmedcase = 0\nmax_confirmedcase   = 0\nsave_max_count      = 0\n\nfor index, row in all_data.iterrows():\n\n    if save_province_state != row['Province_State'] or save_country_region != row['Country_Region'] or save_county != row['County']:\n        \n        save_province_state = row['Province_State'] \n        save_country_region = row['Country_Region']  \n        save_county         = row['County']  \n        first_confirmedcase = 0 \n        save_confirmedcases = 0\n        max_confirmedcase   = 0\n        \n        if save_max_count > 0:\n            all_data['days_since_max_day'][save_max_count] = 1\n            \n        save_max_count           = 0\n        count_within_group       = 0\n\n    if row['Target'] == 'ConfirmedCases':\n\n        if (save_confirmedcases == 0.0) and (row['TargetValue'] > 4.0):\n            save_confirmedcases = row['TargetValue']\n            first_confirmedcase = count \n        \n        if first_confirmedcase > 0:\n            all_data['days_since_confirmedcases'][count] = count - first_confirmedcase\n            \n        if row['TargetValue'] > max_confirmedcase:\n            max_confirmedcase = row['TargetValue']\n            save_max_count    = count \n\n        count += 1\n    \nall_data.head(500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nsave_province_state = \"\"\nsave_country_region = \"\"\nsave_county         = \"\"\nsave_max_count      = 0\n\nfor index, row in all_data.iterrows():\n\n    if save_province_state != row['Province_State'] or save_country_region != row['Country_Region'] or save_county != row['County']:\n        \n        save_province_state = row['Province_State'] \n        save_country_region = row['Country_Region']  \n        save_county         = row['County']  \n        save_max_count      = 0\n\n    if row['Target'] == 'ConfirmedCases':\n\n        if row['days_since_max_day'] > 0.0:\n            save_max_count   = count \n        \n        if save_max_count > 0:\n            all_data['days_since_max_day'][count] = count - save_max_count\n\n        count += 1\n    \nall_data.head(500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head(500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.merge(train_data,all_data[['County','Province_State','Country_Region','Date','days_since_confirmedcases','days_since_max_day']], left_on=['County','Province_State','Country_Region','Date'],right_on=['County','Province_State','Country_Region','Date'], how='left')\n\n\ntest_data = pd.merge(test_data,all_data[['County','Province_State','Country_Region','Date','days_since_confirmedcases','days_since_max_day']], left_on=['County','Province_State','Country_Region','Date'],right_on=['County','Province_State','Country_Region','Date'], how='left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel all_data,train_data_short,test_data_short\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n#convert Date to number\ntrain_data['Date_dt']   = pd.to_datetime(train_data['Date'])\ntrain_data['Date_days'] = train_data['Date_dt'] - datetime(2019, 1, 1)\ntrain_data['Date_days'] = train_data['Date_days'].apply(lambda x: x.days)\n\ntest_data['Date_dt']   = pd.to_datetime(test_data['Date'])\ntest_data['Date_days'] = pd.to_datetime(test_data['Date_dt']) - datetime(2019, 1, 1)\ntest_data['Date_days'] = test_data['Date_days'].apply(lambda x: x.days)\n\ntrain_data.head(10)\nprint (train_data.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder1 = LabelEncoder()\nlabel_encoder2 = LabelEncoder()\nlabel_encoder3 = LabelEncoder()\nlabel_encoder4 = LabelEncoder()\nlabel_encoder5 = LabelEncoder()\nlabel_encoder6 = LabelEncoder()\n\ntrain_data['Province_State_encode'] = label_encoder1.fit_transform(train_data['Province_State'])\ntest_data['Province_State_encode'] = label_encoder1.transform(test_data['Province_State'])\n\ntrain_data['Country_Region_encode'] = label_encoder2.fit_transform(train_data['Country_Region'])\ntest_data['Country_Region_encode'] = label_encoder2.transform(test_data['Country_Region'])\n\ntrain_data['GeoSubregion_encode'] = label_encoder3.fit_transform(train_data['GeoSubregion'])\ntest_data['GeoSubregion_encode'] = label_encoder3.transform(test_data['GeoSubregion'])\n\ntrain_data['Income Group_encode'] = label_encoder4.fit_transform(train_data['Income Group'])\ntest_data['Income Group_encode'] = label_encoder4.transform(test_data['Income Group'])\n\ntrain_data['County_encode'] = label_encoder5.fit_transform(train_data['County'])\ntest_data['County_encode'] = label_encoder5.transform(test_data['County'])\n\ntrain_data['Target_encode'] = label_encoder6.fit_transform(train_data['Target'])\ntest_data['Target_encode'] = label_encoder6.transform(test_data['Target'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_model(in_features,in_categorical_features,in_target_value,in_train_data,in_test_data):\n\n\n    build_data = in_train_data[in_train_data.Date_dt < datetime(2020, 4, 20)]\n    build_data = build_data[build_data.days_since_confirmedcases > 14]\n    val_data   = in_train_data[in_train_data.Date_dt >= datetime(2020, 4, 20)]\n\n    y_train = in_train_data[in_target_value].values\n    y_build = build_data[in_target_value].values\n    y_val   = val_data[in_target_value].values\n\n    test_ids = in_test_data.ForecastId.astype(int).astype(str).values\n\n    x_train = in_train_data[in_features]\n    x_build = build_data[in_features]\n    x_val   = val_data[in_features]\n    x_test  = in_test_data[in_features]\n\n    print(\"Build shape: \", build_data.shape)\n    print(\"Val shape: \", val_data.shape)\n    print(\"Train shape: \", in_train_data.shape)\n    print(\"Test shape: \", in_test_data.shape)\n\n    dtrain = lgb.Dataset(x_train, label = y_train, categorical_feature = in_categorical_features)\n    dbuild = lgb.Dataset(x_build, label = y_build, categorical_feature = in_categorical_features)\n    dval = lgb.Dataset(x_val, label = y_val, categorical_feature = in_categorical_features)\n\n    params = {\n    \"objective\": \"regression_l2\",\n    \"num_leaves\": 300,\n    \"learning_rate\": 0.013,\n    \"bagging_fraction\": 0.91,\n    \"feature_fraction\": 0.81,\n    \"reg_alpha\": 0.13,\n    \"reg_lambda\": 0.13,\n    \"metric\": \"mae\",\n    \"seed\": 2357\n    }\n\n    model_lgb_val = lgb.train(params, train_set = dbuild, valid_sets = [dval], num_boost_round = 2000, early_stopping_rounds = 100, verbose_eval = 50)\n    model_lgb     = lgb.train(params, train_set = dtrain, num_boost_round = model_lgb_val.best_iteration)\n    \n    y_pred = model_lgb.predict(x_test)\n\n    #feature importance\n    df_model = pd.DataFrame({\"feature\": features, \"importance\": model_lgb.feature_importance()})\n\n    df_model.sort_values(\"importance\", ascending = False, inplace = True)\n\n    print(df_model)\n    \n    #dataset\n    predictions = pd.DataFrame(y_pred)\n    in_test_data['Pred_TargetValue']=predictions.iloc[:, 0].values\n    in_test_data['Pred_TargetValue']=in_test_data['Pred_TargetValue'].clip(lower=0)\n    \n    #Create Original Values\n    in_test_data['Pred_TargetValue_total'] = np.power((in_test_data['Pred_TargetValue']),2) - 1\n    in_test_data['Pred_TargetValue_total'] = in_test_data['Pred_TargetValue_total'] * (in_test_data['Population'] / 1000000)\n    in_test_data['Pred_TargetValue_by_day'] = in_test_data.groupby(['Country_Region','Province_State','County','Target'])['Pred_TargetValue_total'].diff().fillna(0)\n    \n    all_data_with_pred = pd.merge(in_train_data, in_test_data ,how='outer', on=['Country_Region','Date','Province_State','County','Target'])\n\n    all_data_with_pred.sort_values(['Country_Region','Province_State','County','Date','Target'], ascending = True, inplace = True)\n    all_data_with_pred = all_data_with_pred.reset_index(drop=True)\n    \n    return all_data_with_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef display_comparison(in_target_value,in_pred_target_value,in_region,in_target,in_df):\n    plot_df = in_df.query(\"Country_Region=='\"+in_region+\"' and Target=='\"+in_target+\"'\")\n    \n    plt.plot(plot_df[in_target_value].values)\n    plt.plot(plot_df[in_pred_target_value].values)\n    plt.title(\"Comparison between the actual data and our predictions for the number of cases\")\n    plt.ylabel('Number of cases')\n    plt.xlabel('Date')\n    plt.xticks(range(len(plot_df.Date.values)),plot_df.Date.values,rotation='vertical')\n    plt.legend(['Groundtruth', 'Prediction'], loc='best')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = ['County_encode','Province_State_encode','Country_Region_encode','GeoSubregion_encode','Income Group_encode','Target_encode']\nfeatures = ['County_encode','Province_State_encode','Country_Region_encode','GeoSubregion_encode','Income Group_encode','Target_encode','days_since_confirmedcases','days_since_max_day','Population','Population Density']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_value_to_predict = 'log_TargetValue_cumm'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#eval_train_data = train_data.query(\"Province_State=='' and Target=='ConfirmedCases'\")\n#eval_test_data  = test_data.query(\"Province_State=='' and Target=='ConfirmedCases'\")\n\n#eval_all_data_with_pred = process_model(features,categorical_features,target_value_to_predict,eval_train_data,eval_test_data)\n#eval_all_data_with_pred.to_csv('temp_out.csv', index = False)\n\n#display_comparison(target_value_to_predict,'Pred_TargetValue','Germany','ConfirmedCases',eval_all_data_with_pred)\n#display_comparison('TargetValue','Pred_TargetValue_by_day','Germany','ConfirmedCases',eval_all_data_with_pred)\n\n#display_comparison(target_value_to_predict,'Pred_TargetValue','United Kingdom','ConfirmedCases',eval_all_data_with_pred)\n#display_comparison('TargetValue','Pred_TargetValue_by_day','United Kingdom','ConfirmedCases',eval_all_data_with_pred)\n\n#display_comparison(target_value_to_predict,'Pred_TargetValue','New Zealand','ConfirmedCases',eval_all_data_with_pred)\n#display_comparison('TargetValue','Pred_TargetValue_by_day','New Zealand','ConfirmedCases',eval_all_data_with_pred)\n\n\n#display_comparison(target_value_to_predict,'Pred_TargetValue','Russia','ConfirmedCases',eval_all_data_with_pred)\n#display_comparison('TargetValue','Pred_TargetValue_by_day','Russia','ConfirmedCases',eval_all_data_with_pred)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_value_to_predict = 'TargetValue'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_train_data = train_data.query(\"Province_State=='' and Target=='ConfirmedCases'\")\neval_test_data  = test_data.query(\"Province_State=='' and Target=='ConfirmedCases'\")\n\neval_all_data_with_pred1 = process_model(features,categorical_features,target_value_to_predict,eval_train_data,eval_test_data)\neval_all_data_with_pred1.to_csv('temp_out1.csv', index = False)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','Germany','ConfirmedCases',eval_all_data_with_pred1)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','United Kingdom','ConfirmedCases',eval_all_data_with_pred1)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','New Zealand','ConfirmedCases',eval_all_data_with_pred1)\n\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','Russia','ConfirmedCases',eval_all_data_with_pred1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_train_data = train_data.query(\"Province_State!='' and Target=='ConfirmedCases'\")\neval_test_data  = test_data.query(\"Province_State!='' and Target=='ConfirmedCases'\")\n\neval_all_data_with_pred2 = process_model(features,categorical_features,target_value_to_predict,eval_train_data,eval_test_data)\neval_all_data_with_pred2.to_csv('temp_out2.csv', index = False)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','Australia','ConfirmedCases',eval_all_data_with_pred2)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','China','ConfirmedCases',eval_all_data_with_pred2)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_train_data = train_data.query(\"Province_State=='' and Target=='Fatalities'\")\neval_test_data  = test_data.query(\"Province_State=='' and Target=='Fatalities'\")\n\neval_all_data_with_pred3 = process_model(features,categorical_features,target_value_to_predict,eval_train_data,eval_test_data)\neval_all_data_with_pred3.to_csv('temp_out3.csv', index = False)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','Germany','Fatalities',eval_all_data_with_pred3)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','United Kingdom','Fatalities',eval_all_data_with_pred3)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','New Zealand','Fatalities',eval_all_data_with_pred3)\n\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','Russia','Fatalities',eval_all_data_with_pred3)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_train_data = train_data.query(\"Province_State!='' and Target=='Fatalities'\")\neval_test_data  = test_data.query(\"Province_State!='' and Target=='Fatalities'\")\n\neval_all_data_with_pred4 = process_model(features,categorical_features,target_value_to_predict,eval_train_data,eval_test_data)\neval_all_data_with_pred4.to_csv('temp_out4.csv', index = False)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','Australia','Fatalities',eval_all_data_with_pred4)\n\ndisplay_comparison(target_value_to_predict,'Pred_TargetValue','China','Fatalities',eval_all_data_with_pred4)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_all_data_with_pred = pd.concat([eval_all_data_with_pred1,eval_all_data_with_pred2,eval_all_data_with_pred3,eval_all_data_with_pred4], axis=0)\n\nprediction_data = eval_all_data_with_pred.loc[eval_all_data_with_pred['ForecastId'].notnull(),['Country_Region','Province_State','County','Date','Target','ForecastId', 'Pred_TargetValue' ]]\nprediction_data.to_csv('prediction_data.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## submission\n#df_pred_q05 = pd.DataFrame({\"ForecastId_Quantile\": test_ids + \"_0.05\", \"TargetValue\": 0.85 * y_pred})\n\ndf_pred_q05 = prediction_data[['ForecastId','Pred_TargetValue']]\ndf_pred_q05['ForecastId'] = df_pred_q05['ForecastId'].astype(int).astype(str) + \"_0.05\"\ndf_pred_q05['Pred_TargetValue'] = df_pred_q05['Pred_TargetValue'].values * 0.85\n\ndf_pred_q50 = prediction_data[['ForecastId','Pred_TargetValue']]\ndf_pred_q50['ForecastId'] = df_pred_q50['ForecastId'].astype(int).astype(str) + \"_0.5\"\n\n\ndf_pred_q95 = prediction_data[['ForecastId','Pred_TargetValue']]\ndf_pred_q95['ForecastId'] = df_pred_q95['ForecastId'].astype(int).astype(str) + \"_0.95\"\ndf_pred_q95['Pred_TargetValue'] = df_pred_q95['Pred_TargetValue'].values * 1.15\ndf_pred_q95['Pred_TargetValue'] = df_pred_q95['Pred_TargetValue'].clip(lower=1)\n\ndf_submit = pd.concat([df_pred_q05, df_pred_q50, df_pred_q95])\n\ndf_submit.columns = ['ForecastId_Quantile','TargetValue']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_submit.shape)\ndf_submit.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}