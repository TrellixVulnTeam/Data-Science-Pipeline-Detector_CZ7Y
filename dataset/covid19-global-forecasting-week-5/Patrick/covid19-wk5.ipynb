{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/c/covid19-global-forecasting-week-5\n\nDue May 11"},{"metadata":{},"cell_type":"markdown","source":"# Plan:\n1. look at each county, province, country\n\n        > min(test.Date)\n        '2020-04-27'\n        > max(test.Date)\n        '2020-06-10'\n        > max(train.Date)\n        '2020-05-08'\n\n\n2. add intercept (Weight constant based on Population), x square, fit ridge, alpha = 0.1\n        # add some noise\n        tmp.y1 = tmp.y1 + np.random.normal(size = tmp.shape[0], scale=.05)\n        tmp.y1[200:220] = tmp.y1[200:220] + 1\n        tmp['intercept'] = 1\n        tmp['x2'] = tmp['x']**2\n        tmp['nutch'] = 0\n        tmp['nutch'][330:] = -1\n\n        train = tmp[:start_test]\n        test = tmp[start_test:]\n        # train = train.drop(['y2','y_sum'])\n        # test = test.drop(['y2','y_sum'])\n\n        feat = ['intercept','x', 'x2']\n        y = train.y1\n        x = train[feat]\n        \n        f = Ridge(alpha=1.0).fit(x,y)  # higher alpha, the higher the penalization\n        fitted = f.predict(train[feat])\n        y_pred = f.predict(test[feat])\n3. add predictions back to train, get quantiles:\n        resid = fitted - y\n        fig, ax = plt.subplots()\n        ax.plot(resid)\n        for q in [0.05,0.5,0.95]:\n            print(f'resid q={q}', np.quantile(resid, q=q))\n4. Output (predict daily quantiles):\n        ForecastId\tCounty\tProvince_State\tCountry_Region\tPopulation\tWeight\tDate\tTarget\tq0.05\tq0.5\tq0.95\n        0\t1\t\t\tAfghanistan\t27657145\t0.058359\t2020-04-27\tConfirmedCases\t0.0\t1.0\t171.7\n        1\t2\t\t\tAfghanistan\t27657145\t0.583587\t2020-04-27\tFatalities\t0.0\t0.0\t4.7\n        2\t3\t\t\tAfghanistan\t27657145\t0.058359\t2020-04-28\tConfirmedCases\t0.0\t1.0\t171.7\n        \n        \n                    ForecastId_Quantile\tTargetValue\n        0\t1_0.05\t0.0\n        1\t2_0.05\t0.0\n        2\t3_0.05\t0.0\n        \n        \n# Ref\n* https://coronavirus.jhu.edu/map.html\n* https://www.kaggle.com/c/covid19-global-forecasting-week-5/discussion\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor, LinearRegression, Lasso, Ridge, LogisticRegression\n\nfrom scipy import stats\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom datetime import timedelta\n\nimport pickle\nimport statsmodels.api as sm\nlowess = sm.nonparametric.lowess\n\nimport warnings\nwarnings.filterwarnings(action='once')\n\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_rows', 1000)\nplt.rcParams['figure.figsize'] = [8, 4]  # 12, 8  width\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/covid19-global-forecasting-week-5/train.csv')\ntrain['Date'] = pd.to_datetime(train['Date'])\ntrain['County']=train['County'].fillna(\"\")\ntrain['Province_State']=train['Province_State'].fillna(\"\")\nprint(min(train.Date),max(train.Date))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# negative TargetValue?\ntrain.sort_values(by='TargetValue').head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=train.groupby(['County','Province_State','Country_Region','Target'])['TargetValue'].quantile(q=0.05).reset_index()\nb=train.groupby(['County','Province_State','Country_Region','Target'])['TargetValue'].quantile(q=0.5).reset_index()\nc=train.groupby(['County','Province_State','Country_Region','Target'])['TargetValue'].quantile(q=0.95).reset_index()\na.columns=['County','Province_State','Country_Region','Target','q0.05']\nb.columns=['County','Province_State','Country_Region','Target','q0.5']\nc.columns=['County','Province_State','Country_Region','Target','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05'].clip(0,10000)\na['q0.5']=a['q0.5'].clip(0,10000)\na['q0.95']=a['q0.95'].clip(0,10000)\na.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/covid19-global-forecasting-week-5/test.csv')\ntest['Date'] = pd.to_datetime(test['Date'])\ntest['County']=test['County'].fillna(\"\")\ntest['Province_State']=test['Province_State'].fillna(\"\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train', min(train.Date), max(train.Date))\nprint('test', min(test.Date), max(test.Date))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndt_pred = pd.date_range(pd.to_datetime(max(train.Date)) + timedelta(days=1), max(test.Date))\nx_cols = ['Weight','x', 'x2']\ny_col = ['TargetValue']\ni = 0\na = pd.DataFrame()\nmodels = dict()\n\nfor key,grp in tqdm(train.groupby(['County','Province_State','Country_Region','Target'])):\n    print(f'key={key}')\n    \n    grp = grp.sort_values(by=['Date'])\n\n    n_train = grp.shape[0]\n    n_test  = dt_pred.shape[0]\n    n_all   = n_train + n_test\n\n    df_test = grp.head(len(dt_pred)).copy()\n    df_test['Id'] = -1\n    df_test['Date'] = dt_pred\n    df_test['TargetValue'] = 0.\n    df = grp.append(df_test).copy().reset_index(drop=True)\n    test_filter = df.Date >= min(dt_pred)\n    df_test = df[test_filter]\n\n    # features\n    df['q0.05'] = 0.\n    df['q0.5'] = 0.\n    df['q0.95'] = 0.\n    df['x'] = list(range(df.shape[0]))\n    df['x2'] = df.x**2\n\n\n    # train / fit\n    df_train, df_test = df[:n_train], df[n_train:]\n\n    # start with first non-zero\n    try:\n        start_x = min(df_train.query('TargetValue > 0')['x'])\n    except:\n        start_x = min(df_train.x)\n    df_train = df_train.query(f'x >= {start_x}')\n\n    X_train, y_train = df_train[x_cols], df_train[y_col]\n    X_test, y_test = df_test[x_cols], df_train[y_col]\n\n\n    # median / mean\n    f = Ridge(alpha=10.0).fit(X_train,y_train)\n    models[key] = f\n    fitted = f.predict(X_train)\n    y_test = f.predict(X_test)   \n    fitted_resid = fitted - y_train\n\n    quant = dict()\n    for q in [0.05, 0.5, 0.95]:\n        quant[q] = np.quantile(fitted_resid, q=q)\n\n\n    # 0.05\n    fitted_05 = fitted + (quant[0.05])\n    y_test_05 = y_test + (quant[0.05])\n\n    # 0.95  \n    fitted_95 = fitted + (quant[0.95])\n    y_test_95 = y_test + (quant[0.95])\n\n\n#         df_train['q0.05'], df_train['q0.5'], df_train['q0.95'] = fitted_05.clip(0,10000), fitted.clip(0,10000), fitted_95.clip(0,10000)\n#         df_test.loc[:,'q0.05'], df_test.loc[:,'q0.5'], df_test.loc[:,'q0.95'] = y_test_05.clip(0,10000), y_test.clip(0,10000), y_test_95.clip(0,10000)\n#         df = df_train.append(df_test)\n    try:\n        start_x_dt = min(df.query('TargetValue > 0')['Date'])\n    except:\n        start_x_dt = min(df.Date)\n    df.loc[df.Date >= start_x_dt, 'q0.05'] = np.concatenate([fitted_05,y_test_05]).clip(0, 10000)\n    df.loc[df.Date >= start_x_dt, 'q0.5'] = np.concatenate([fitted,y_test]).clip(0, 10000)\n    df.loc[df.Date >= start_x_dt, 'q0.95'] = np.concatenate([fitted_95,y_test_95]).clip(0, 10000)\n\n    a_cols = ['County','Province_State','Country_Region','Target','Date','q0.05','q0.5','q0.95']\n    a = a.append(df.query(f'Date>=\"{min(test.Date)}\"')[a_cols])\n\n    country = key[2]\n    prov    = key[1]\n    # Note: US has a LOT of counties\n    if i <= 4 or country in ['Spain','Italy','Monaco','China','UK','Canada','Mexico','Brazil','France', 'Japan', 'Taiwan*'] \\\n        or prov in ['British Columbia','Hong Kong','New York']:\n        fig, ax = plt.subplots()\n        ax.plot(X_train.x, y_train, label='data')\n        ax.plot(X_train.x, fitted, label='fitted')\n        ax.plot(X_test.x, y_test, label='pred')\n        ax.plot(X_train.x, fitted_95, label='fitted_95')\n        ax.plot(X_test.x, y_test_95, label='pred_95')\n        ax.plot(X_train.x, fitted_05, label='fitted_05')\n        ax.plot(X_test.x, y_test_05, label='pred_05')\n        ax.legend()\n        title = f\"{key}\"\n        ax.set_title(title)\n\n#         if i >= 4:\n#             break\n\n    i += 1\n        \nm_fn = 'models.pickle'\nwith open(m_fn, 'wb') as f:\n    pickle.dump(models, f)\nprint(f'Saved {len(models)} to {m_fn}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = test.merge(a,on=['Country_Region','County','Province_State','Target', 'Date'],how='left')\ntest2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test=test.merge(a,on=['Country_Region','County','Province_State','Target'],how='left')\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.melt(test2[['ForecastId','q0.05','q0.5','q0.95']], id_vars=['ForecastId'], value_vars=['q0.05','q0.5','q0.95'])\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub=pd.melt(test2, id_vars=['ForecastId'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['ForecastId'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}