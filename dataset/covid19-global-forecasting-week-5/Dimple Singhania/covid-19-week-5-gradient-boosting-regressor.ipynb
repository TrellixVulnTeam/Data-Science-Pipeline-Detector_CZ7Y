{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor \nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"parse_date = lambda val : pd.datetime.strptime(val, '%y-%m-%d')\ndf_train = pd.read_csv('../input/covid19-global-forecasting-week-5/train.csv', parse_dates = ['Date'])\ndf_test = pd.read_csv('../input/covid19-global-forecasting-week-5/test.csv', parse_dates = ['Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Created week and month features from datetime.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['week_day'] = df_train['Date'].apply(lambda val: val.day_name())\ndf_train['month'] = df_train['Date'].apply(lambda val: val.month)\n\ndf_test['week_day'] = df_test['Date'].apply(lambda val: val.day_name())\ndf_test['month'] = df_test['Date'].apply(lambda val: val.month)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One-hot encoding of week_day variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot = pd.get_dummies(df_train['week_day'])\n\n# df_train = df_train.drop('week_day',axis = 1)\ndf_train = df_train.join(one_hot)\n\ndf_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_test = pd.get_dummies(df_test['week_day'])\n\ndf_test = df_test.drop('week_day',axis = 1)\ndf_test = df_test.join(one_hot_test)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cases are show a weekly seasonal pattern. Cases decrease on weekends and increase on weekdays. So, I created the weekend variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['is_weekend'] = df_train['Saturday'] + df_train['Sunday']\ndf_test['is_weekend'] = df_test['Saturday'] + df_test['Sunday']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_na_county_value(row):\n    if pd.isnull(row['Province_State']) and pd.isnull(row['County']):\n        val = row['Country_Region']\n    elif pd.isnull(row['County']):\n        val = str(row['Country_Region']) + \"_\" + str(row['Province_State'])\n    else:\n        val = str(row['Country_Region']) + \"_\" + str(row['Province_State']) + \"_\" + row['County']\n    return val\n\ndf_train['County'] = df_train.apply(fill_na_county_value, axis=1)\ndf_test['County'] = df_test.apply(fill_na_county_value, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_submission = pd.DataFrame(columns=['ForecastId_Quantile', 'TargetValue'])\n\nfor name in df_train.County.unique():\n    df_train_county = \"df_train_{0}.format(name)\"\n    df_train_county = df_train[df_train['County']==name]\n    \n    df_test_county = \"df_test_{0}.format(name)\"\n    df_test_county = df_test[df_test['County']==name]\n    \n    df_train_county_cases = df_train_county[df_train_county['Target'] == 'ConfirmedCases']\n    df_test_county_cases = df_test_county[df_test_county['Target'] == 'ConfirmedCases']\n    test_county_cases_index = df_test_county_cases.ForecastId\n    \n    df_train_county_deaths = df_train_county[df_train_county['Target'] == 'Fatalities']\n    df_test_county_deaths = df_test_county[df_test_county['Target'] == 'Fatalities']\n    test_county_deaths_index = df_test_county_deaths.ForecastId\n    \n\n    X_train_cases = df_train_county_cases[['month', 'Sunday', 'Monday', 'Tuesday', 'Wednesday',\n                                           'Thursday', 'Friday', 'Saturday', 'is_weekend']]\n    y_train_cases = df_train_county_cases[['TargetValue']]\n    \n    X_test_cases = df_test_county_cases[['month', 'Sunday', 'Monday', 'Tuesday', 'Wednesday',\n                                           'Thursday', 'Friday', 'Saturday', 'is_weekend']]\n    y_test_cases = df_test_county_cases[['ForecastId']]\n\n    gbm = GradientBoostingRegressor(loss='quantile', alpha=0.95,\n                                    n_estimators=250, max_depth=3,\n                                    learning_rate=.1, min_samples_leaf=9,\n                                    min_samples_split=9)\n    \n    gbm.fit(X_train_cases, y_train_cases)\n\n    # Predicting upper threshold\n    y_upper_cases = gbm.predict(X_test_cases)\n    y_test_cases['ForecastId_Quantile'] = test_county_cases_index.apply(lambda val: str(val) + '_0.95')\n    y_test_cases['TargetValue'] = y_upper_cases\n    df_submission = df_submission.append(y_test_cases)\n    \n    # Predicting lower threshold\n    gbm.set_params(alpha=0.05)\n    gbm.fit(X_train_cases, y_train_cases)\n    y_lower_cases = gbm.predict(X_test_cases)\n    y_test_cases['ForecastId_Quantile'] = test_county_cases_index.apply(lambda val: str(val) + '_0.05')\n    y_test_cases['TargetValue'] = y_lower_cases\n    df_submission = df_submission.append(y_test_cases)\n    \n    # Predicting actual cases\n    gbm.set_params(loss='ls')\n    gbm.fit(X_train_cases, y_train_cases)\n\n    # Make the prediction on the meshed x-axis\n    y_pred_cases = gbm.predict(X_test_cases)\n    y_test_cases['ForecastId_Quantile'] = test_county_cases_index.apply(lambda val: str(val) + '_0.5')\n    y_test_cases['TargetValue'] = y_pred_cases\n    df_submission = df_submission.append(y_test_cases)\n    \n    \n    \n    # predicting deaths\n    \n    X_train_deaths = df_train_county_deaths[['month', 'Sunday', 'Monday', 'Tuesday', 'Wednesday',\n                                           'Thursday', 'Friday', 'Saturday', 'is_weekend']]\n    y_train_deaths = df_train_county_deaths[['TargetValue']]\n    \n    X_test_deaths = df_test_county_deaths[['month', 'Sunday', 'Monday', 'Tuesday', 'Wednesday',\n                                           'Thursday', 'Friday', 'Saturday', 'is_weekend']]\n    y_test_deaths = df_test_county_deaths[['ForecastId']]\n    \n    gbm = GradientBoostingRegressor(loss='quantile', alpha=0.95,\n                                    n_estimators=250, max_depth=3,\n                                    learning_rate=.1, min_samples_leaf=9,\n                                    min_samples_split=9)\n    \n    gbm.fit(X_train_deaths, y_train_deaths)\n\n    # Predicting upper threshold\n    y_upper_deaths = gbm.predict(X_test_deaths)\n    y_test_deaths['ForecastId_Quantile'] = test_county_deaths_index.apply(lambda val: str(val) + '_0.95')\n    y_test_deaths['TargetValue'] = y_upper_deaths\n    df_submission = df_submission.append(y_test_deaths)\n    \n    # Predicting lower threshold\n    gbm.set_params(alpha=0.05)\n    gbm.fit(X_train_deaths, y_train_deaths)\n    y_lower_deaths = gbm.predict(X_test_deaths)\n    y_test_deaths['ForecastId_Quantile'] = test_county_deaths_index.apply(lambda val: str(val) + '_0.05')\n    y_test_deaths['TargetValue'] = y_lower_deaths\n    df_submission = df_submission.append(y_test_deaths)\n\n    # Predicting actual deaths\n    gbm.set_params(loss='ls')\n    gbm.fit(X_train_deaths, y_train_deaths)\n\n    # Make the prediction on the meshed x-axis\n    y_pred_deaths = gbm.predict(X_test_deaths)\n    y_test_deaths['ForecastId_Quantile'] = test_county_deaths_index.apply(lambda val: str(val) + '_0.5')\n    y_test_deaths['TargetValue'] = y_pred_deaths\n    df_submission = df_submission.append(y_test_deaths)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = df_submission.drop('ForecastId', axis=1)\ndf_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}