{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Grid Search ARIMA inspired by work from Jason Brownlee\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\n# evaluate an ARIMA model for a given order (p,d,q)\ndef evaluate_arima_model(X, arima_order):\n    # prepare training dataset\n    X.index = pd.RangeIndex(len(X.index))\n    train_size = int(len(X) * 0.8)\n    train, test = X[0:train_size], X[train_size:]\n    history = X.TargetValue.tolist()\n    # make predictions\n    predictions = list()\n    for t, row in test.iterrows():\n        model = ARIMA(history, order=arima_order)\n        model_fit = model.fit(disp=0)\n        yhat = model_fit.forecast()[0]\n        predictions.append(yhat)\n        history.append(test.TargetValue[t])\n        # calculate out of sample error\n    error = mean_squared_error(test, predictions)\n    return error\n\n# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype('float64')\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    mse = evaluate_arima_model(dataset, order)\n                    if mse < best_score:\n                        best_score, best_cfg = mse, order\n#                    print('ARIMA%s MSE=%.3f' % (order,mse))\n                except:\n                    continue\n    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n    return best_cfg\n\ndef timeseries_models(x):\n\n    p_values = [0]\n    d_values = [0, 1] #[0, 1]\n    q_values = [0, 1] #[0, 1]\n    warnings.filterwarnings(\"ignore\")\n\n    x = pd.DataFrame({'Date': x.Date, 'TargetValue': x.TargetValue})\n    x.set_index('Date', inplace=True)\n    pdq = evaluate_models(x, p_values, d_values, q_values)\n    \n    model = ARIMA(x, order= pdq)\n    model_fit = model.fit(disp=0)\n   \n    forecasts, stderr, interval = model_fit.forecast(steps = 33, alpha = 0.05)\n    maxdate = test_data.Date.max()\n    mindate = '2020-01-24'\n#    model_fit.plot_predict(start = mindate, end = maxdate)\n    \n    return forecasts, stderr, interval\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('C:\\\\Users\\\\Vincent\\\\Documents\\\\Python\\\\Kaggle\\\\Titanic'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\ntrain_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-5/test.csv\")\n\n#train_data.head()\n#train_data.info()\n#test_data.head()\n#test_data.info()\n\n# Observations\n# Date is in string. Convert to datetime format\n# Id is unique\n# Target: ConfirmedCases and Fatalities\n# Target values are counted multiple times. ie., Santa Clara, California, US has value for the same date\n#   treat each of them as separate\n\n# Convert Date to Datatime for Time Series Analysis\n#train_data['Date'] = pd.to_datetime(train_data['Date'], format = '%Y-%m-%d')\n#test_data['Date'] = pd.to_datetime(test_data['Date'], format = '%Y-%m-%d')\n\n# Create unique area\ntest_data.loc[(test_data.County.isnull()), 'County'] = 'None'\ntrain_data.loc[(train_data.County.isnull()), 'County'] = 'None'\ntest_data.loc[(test_data.Province_State.isnull()), 'Province_State'] = 'None'\ntrain_data.loc[(train_data.Province_State.isnull()), 'Province_State'] = 'None'\ntest_data['Name'] = test_data['Country_Region'] + '_' + test_data['Province_State'] + '_' + test_data['County']\ntrain_data['Name'] = train_data['Country_Region'] + '_' + train_data['Province_State'] + '_' + train_data['County']\n\nname_list = train_data.Name.unique()\ntarget_list = train_data.Target.unique()\n\n#name_list = ['Uruguay_None_None', 'US_Ohio_None']\ndf_out = pd.DataFrame()\n\n#for c, name in enumerate(name_list):\n#    print(str(c), 'out of', str(len(name_list)), name)\n#    for target in target_list:\n#        print(target)\n#        df_temp = pd.DataFrame()\n#        train_df = train_data.loc[(train_data['Name'] == name) & (train_data['Target'] == target)]\n#        forecasts, stderr, interval = timeseries_models(train_df)\n#        df_temp['0.5'] = forecasts\n#        df_temp['0.05'] = interval[:,[0]]\n#        df_temp['0.95'] = interval[:,[1]]\n#        df_temp['Name'] = name\n#        df_temp['Target'] = target\n#        df_temp['Date'] = pd.date_range(start=\"2020-05-09\",end=\"2020-06-10\")\n#        df_temp['Date']=df_temp['Date'].dt.strftime('%Y-%m-%d')\n#        df_out = pd.concat([df_out, df_temp])\n \n## df_out.to_csv('temp_output.csv', index = False)\n\ndf_out = pd.read_csv(\"/kaggle/input/modeloutput/temp_output.csv\")\n  \n# %%  \n#test_data1 = test_data.loc[test_data['Name'] == 'US_Ohio_None']\ntest_data1 = test_data.copy()\ntest_data1 = test_data1[['ForecastId','Date','Name','Target']]\ntest_data1 = test_data1.merge(train_data[['Date','Name','Target','TargetValue']], \n        left_on=['Date','Name','Target'], right_on=['Date','Name','Target'], how='left')\ntest_data1['0.05'] = test_data1.TargetValue\ntest_data1['0.5'] = test_data1.TargetValue\ntest_data1['0.95'] = test_data1.TargetValue\ntest_data1 = test_data1.loc[test_data1['Date'] <= '2020-05-08']\n\ntest_data2 = test_data.copy()\ntest_data2 = test_data2.merge(df_out, left_on=['Date','Name','Target'], right_on=['Date','Name','Target'], how = 'left')\ntest_data2 = test_data2.loc[test_data2['Date'] > '2020-05-08']\n\ntest_data1 = test_data1[['ForecastId','0.05','0.5','0.95']]\ntest_data2 = test_data2[['ForecastId','0.05','0.5','0.95']]\ntest_data3 = pd.concat([test_data1, test_data2])\ntest_data3 = test_data3.melt(id_vars = ['ForecastId'])\ntest_data3['ForecastId_Quantile'] = test_data3['ForecastId'].astype(str)+'_'+test_data3['variable']\ntest_data3['TargetValue'] = test_data3['value']\ntest_data4 = test_data3[['ForecastId_Quantile', 'TargetValue']]\ntest_data4.loc[test_data4.TargetValue.isnull() , 'TargetValue'] = 0\ntest_data4['TargetValue'] = test_data4.TargetValue.astype(int)\ntest_data4.to_csv('submission.csv', index = False)\nprint('Done')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}