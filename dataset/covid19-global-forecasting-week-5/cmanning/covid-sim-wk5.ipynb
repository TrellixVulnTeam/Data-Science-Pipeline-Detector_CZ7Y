{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom statsmodels.tsa.statespace.exponential_smoothing import ExponentialSmoothing\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom warnings import catch_warnings\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nplt.rcParams[\"figure.figsize\"] = (20, 6)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def auto_ets(df, trend=True, damped_trend=True, seasonal=None):\n    df = df.asfreq('D')\n    ets = ExponentialSmoothing(df, trend=trend, damped_trend=damped_trend, seasonal=seasonal).fit(maxiter=200)\n    return ets\n\ndef fit_simulate(data, forecast_period=45, repetitions=1000):\n    model = auto_ets(data)\n    return model, model.simulate(forecast_period, repetitions=repetitions, anchor='end')\n\ndef simulate_all(dat):\n    factor_list = [fit_simulate(dat.loc[factor, :])[1] for factor in dat.index]\n    # Convert list of factors with sims as columns to list of sims with factors as columns\n    sim_list = []\n    for sim in range(len(factor_list[0].columns)):\n        f = pd.DataFrame(index=factor_list[0].index, columns=dat.index)\n        for factor in range(len(factor_list)):\n            f.iloc[:, factor] = factor_list[factor].iloc[:, sim]\n        sim_list.append(f)\n    return sim_list","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/covid19-global-forecasting-week-5/train.csv', parse_dates=['Date'])\ntest = pd.read_csv('../input/covid19-global-forecasting-week-5/test.csv', parse_dates=['Date'])\nsubmission = pd.read_csv('../input/covid19-global-forecasting-week-5/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['key'] = train['Country_Region'].astype('str') + \" \" + train['Province_State'].astype('str') + \" \" + train['County'].astype('str')\ntest['key'] = test['Country_Region'].astype('str') + \" \" + test['Province_State'].astype('str') + \" \" + test['County'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(train.key)), len(set(test.key))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases = train[train.Target == 'ConfirmedCases']\ntrain = train[train.Target == 'Fatalities']\ncases.reset_index(drop=True, inplace=True)\ntrain.reset_index(drop=True, inplace=True)\ntrain['ConfirmedCases'] = cases.TargetValue\ntrain.rename(columns={'TargetValue': 'Fatalities'}, inplace=True)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.Country_Region=='US']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases = train.pivot('key', 'Date', 'ConfirmedCases')\nfatalities = train.pivot('key', 'Date', 'Fatalities')\ncases.index += ' cases'\nfatalities.index += ' fatal'\ncombined = pd.concat([cases, 10 * fatalities])\n#combined = combined.iloc[:, -45:]\ncombined","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases.sum().cumsum().plot(label='Confirmed cases', legend=True)\nfatalities.sum().cumsum().plot(label='Fatalities', legend=True, title='COVID19 Global Confirmed Cases and Fatalities', logy=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m, f = fit_simulate(cases.sum())\nf[:30].clip(0).plot(title='Aggregate check on new cases', legend=False, alpha=0.1)\ncases.sum()[-45:].plot()\nm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m, f = fit_simulate(fatalities.sum())\nf[:30].clip(0).plot(title='Aggregate check on new deaths', legend=False, alpha=0.1)\nfatalities.sum()[-45:].plot()\nm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd = TruncatedSVD(100)\nsvd_factors = pd.DataFrame(svd.fit_transform(combined.clip(0).T).T, columns=combined.columns)\nsvd_factors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd.explained_variance_ratio_[:5].round(3), sum(svd.explained_variance_ratio_).round(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd_factors.T.iloc[:, :5].plot(title='Top five SVD components');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m, f = fit_simulate(svd_factors.loc[0, :])\nf[:30].plot(title='Projected component 0', legend=False, alpha=0.05)\nsvd_factors.iloc[0, -45:].plot()\nm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m, f = fit_simulate(svd_factors.loc[1, :])\nf[:30].plot(title='Projected component 1', legend=False, alpha=0.05)\nsvd_factors.iloc[1, -45:].plot()\nm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsim_list = simulate_all(svd_factors)\nsim_list[0].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proj_list = []\nfor sim in sim_list:\n    proj_list.append(pd.DataFrame(svd.inverse_transform(sim).T, index=combined.index, columns=sim.index).clip(0))\nproj_list[0].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proj_array = np.empty((len(proj_list), len(proj_list[0].index), len(proj_list[0].columns)))\nfor proj in range(len(proj_list)):\n    proj_array[proj, :, :] = proj_list[proj].values\nproj_quantiles = np.quantile(proj_array, [0.05, 0.50, 0.95], axis=0)\nforecast_combined_05 = pd.DataFrame(proj_quantiles[0, :, :], index=proj_list[0].index, columns=proj_list[0].columns)\nforecast_combined_50 = pd.DataFrame(proj_quantiles[1, :, :], index=proj_list[0].index, columns=proj_list[0].columns)\nforecast_combined_95 = pd.DataFrame(proj_quantiles[2, :, :], index=proj_list[0].index, columns=proj_list[0].columns)\nforecast_combined_50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_cases_05 = forecast_combined_05.iloc[:len(cases), :]\nforecast_cases_50 = forecast_combined_50.iloc[:len(cases), :]\nforecast_cases_95 = forecast_combined_95.iloc[:len(cases), :]\nforecast_fatalities_05 = forecast_combined_05.iloc[len(cases):, :] / 10\nforecast_fatalities_50 = forecast_combined_50.iloc[len(cases):, :] / 10\nforecast_fatalities_95 = forecast_combined_95.iloc[len(cases):, :] / 10\nforecast_fatalities_50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases.sum()[-45:].plot()\nforecast_cases_05.sum()[:30].plot(title='Daily confirmed cases (including double-counted aggregates)');\nforecast_cases_50.sum()[:30].plot();\nforecast_cases_95.sum()[:30].plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalities.sum()[-45:].plot()\nforecast_fatalities_05.sum()[:30].plot(title='Daily confirmed fatalities (including double-counted aggregates)');\nforecast_fatalities_50.sum()[:30].plot();\nforecast_fatalities_95.sum()[:30].plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(fatalities.sum() / cases.sum())[-45:].plot();\n(forecast_fatalities_05.sum() / forecast_cases_05.sum())[:30].plot(title='Aggregated daily fatalities as proportion of confirmed cases')\n(forecast_fatalities_50.sum() / forecast_cases_50.sum())[:30].plot()\n(forecast_fatalities_95.sum() / forecast_cases_95.sum())[:30].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_melt_05 = forecast_cases_05.reset_index().melt('key', var_name='Date', value_name='ConfirmedCases')\nfatalities_melt_05 = forecast_fatalities_05.reset_index().melt('key', var_name='Date', value_name='Fatalities')\ncases_melt_05.key = [key[:-6] for key in cases_melt_05.key]\nfatalities_melt_05.key = [key[:-6] for key in fatalities_melt_05.key]\n\ncases_melt_50 = forecast_cases_50.reset_index().melt('key', var_name='Date', value_name='ConfirmedCases')\nfatalities_melt_50 = forecast_fatalities_50.reset_index().melt('key', var_name='Date', value_name='Fatalities')\ncases_melt_50.key = [key[:-6] for key in cases_melt_50.key]\nfatalities_melt_50.key = [key[:-6] for key in fatalities_melt_50.key]\n\ncases_melt_95 = forecast_cases_95.reset_index().melt('key', var_name='Date', value_name='ConfirmedCases')\nfatalities_melt_95 = forecast_fatalities_95.reset_index().melt('key', var_name='Date', value_name='Fatalities')\ncases_melt_95.key = [key[:-6] for key in cases_melt_95.key]\nfatalities_melt_95.key = [key[:-6] for key in fatalities_melt_95.key]\n\nfatalities_melt_95","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cases = test[test.Target == 'ConfirmedCases']\ntest_fatalities = test[test.Target == 'Fatalities']\ntest_fatalities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fatalities_05 = test_fatalities.copy(); test_cases_05 = test_cases.copy()\ntest_cases_05 = test_cases_05.merge(cases_melt_05, how='left', on=['key', 'Date'])\ntest_fatalities_05 = test_fatalities_05.merge(fatalities_melt_05, how='left', on=['key', 'Date'])\ntest_cases_05['ForecastValue'] = test_cases_05.ConfirmedCases\ntest_fatalities_05['ForecastValue'] = test_fatalities_05.Fatalities\ntest_cases_05.drop(columns='ConfirmedCases', inplace=True)\ntest_fatalities_05.drop(columns='Fatalities', inplace=True)\n\ntest_fatalities_50 = test_fatalities.copy(); test_cases_50 = test_cases.copy()\ntest_cases_50 = test_cases_50.merge(cases_melt_50, how='left', on=['key', 'Date'])\ntest_fatalities_50 = test_fatalities_50.merge(fatalities_melt_50, how='left', on=['key', 'Date'])\ntest_cases_50['ForecastValue'] = test_cases_50.ConfirmedCases\ntest_fatalities_50['ForecastValue'] = test_fatalities_50.Fatalities\ntest_cases_50.drop(columns='ConfirmedCases', inplace=True)\ntest_fatalities_50.drop(columns='Fatalities', inplace=True)\n\ntest_fatalities_95 = test_fatalities.copy(); test_cases_95 = test_cases.copy()\ntest_cases_95 = test_cases_95.merge(cases_melt_95, how='left', on=['key', 'Date'])\ntest_fatalities_95 = test_fatalities_95.merge(fatalities_melt_95, how='left', on=['key', 'Date'])\ntest_cases_95['ForecastValue'] = test_cases_95.ConfirmedCases\ntest_fatalities_95['ForecastValue'] = test_fatalities_95.Fatalities\ntest_cases_95.drop(columns='ConfirmedCases', inplace=True)\ntest_fatalities_95.drop(columns='Fatalities', inplace=True)\n\ntest_fatalities_95","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_05 = pd.concat([test_cases_05, test_fatalities_05])\ntest_50 = pd.concat([test_cases_50, test_fatalities_50])\ntest_95 = pd.concat([test_cases_95, test_fatalities_95])\ntest_50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_05.ForecastId = [str(fid) + '_0.05' for fid in test_05.ForecastId]\ntest_50.ForecastId = [str(fid) + '_0.5' for fid in test_50.ForecastId]\ntest_95.ForecastId = [str(fid) + '_0.95' for fid in test_95.ForecastId]\ntest_all = pd.concat([test_05, test_50, test_95])\ntest_all.rename(columns={'ForecastId': 'ForecastId_Quantile'}, inplace=True)\ntest_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = submission.merge(test_all.loc[:, ['ForecastId_Quantile', 'ForecastValue']], how='left', on='ForecastId_Quantile')\nsubmission.drop(columns='TargetValue', inplace=True)\nsubmission.rename(columns={'ForecastValue': 'TargetValue'}, inplace=True)\nsubmission.TargetValue = submission.TargetValue.fillna(0)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}