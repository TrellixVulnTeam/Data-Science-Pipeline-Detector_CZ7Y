{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/covid19-global-forecasting-week-5/train.csv',parse_dates=['Date'])\ntest = pd.read_csv('../input/covid19-global-forecasting-week-5/test.csv',parse_dates=['Date'])\nsubmission = pd.read_csv('../input/covid19-global-forecasting-week-5/submission.csv')\n\ntrain['dayofyear'] = train.Date.dt.dayofyear\ntest['dayofyear'] = test.Date.dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([train,test],axis=0,sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(data['County'].isna() & data['Province_State'].isna()).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['County'].isna() & data['Province_State'].isna(),'place_id'] = data.loc[data['County'].isna() & data['Province_State'].isna(),'Country_Region']\ndata.loc[data['County'].isna() & ~data['Province_State'].isna(),'place_id'] = data.loc[data['County'].isna() & ~data['Province_State'].isna(),'Country_Region'] + ' - ' + data.loc[data['County'].isna() & ~data['Province_State'].isna(),'Province_State']\ndata.loc[data['place_id'].isna(),'place_id'] = data.loc[data['place_id'].isna(),'Country_Region'] + ' - ' + data.loc[data['place_id'].isna(),'Province_State'] + ' - ' + data.loc[data['place_id'].isna(),'County']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['place_id'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['County','Province_State','Country_Region','Date'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ndata['place_id'] = le.fit_transform(data['place_id'])\ndata['Target'] = le.fit_transform(data['Target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data[~data.Id.isna()].drop(['ForecastId'],axis=1)\ntest = data[data.Id.isna()].drop(['Id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.set_index('ForecastId',inplace=True)\ntest.drop('TargetValue',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_score(true,pred,weight):\n    true = np.array(true) if type(true) is pd.Series else true\n    pred = np.array(pred) if type(pred) is pd.Series else pred\n    weight = np.array(weight) if type(weight) is pd.Series else weight\n    score = np.round((np.abs(true) * weight).sum()/len(true),4)\n    return score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\nresult = pd.DataFrame(index=[],columns=['ForecastId','TargetValue'])\nfor SEED in range(100):\n#     if SEED == 3:\n#         break\n    X = train.drop(['Id','TargetValue'],axis=1)\n    y = train['TargetValue']\n    X_train,X_valid,y_train,y_valid = train_test_split(X,y,random_state=SEED)\n    model = RandomForestRegressor(random_state=SEED)\n    model.set_params(n_estimators=10)\n    model.fit(X_train,y_train)\n#     score = model.score(X_valid,y_valid)\n#     print('score: ' + str(round(score,4)))\n    y_pred = model.predict(test)\n    scores.append(eval_score(y_valid, y_pred, X_valid['Weight']))\n    pred = y_pred.astype(int)\n    pred[pred<0] = 0\n    tmp = test.reset_index()[['ForecastId']]\n    tmp['TargetValue'] = pred\n    result = pd.concat([result,tmp])\nresult = result.astype(int)\nprint(np.mean(scores))\nprint(result.shape)\nresult.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = result.groupby('ForecastId')['TargetValue'].quantile(q=0.05)\ntmp.rename('_0.05',inplace=True)\ntmp = pd.DataFrame(tmp)\ntmp['_0.5'] = result.groupby('ForecastId')['TargetValue'].quantile(q=0.5)\ntmp['_0.95'] = result.groupby('ForecastId')['TargetValue'].quantile(q=0.95)\ntmp.reset_index(inplace=True)\nsub = pd.melt(tmp, id_vars=['ForecastId'], value_vars=['_0.05','_0.5','_0.95'])\nsub['ForecastId_Quantile']=sub['ForecastId'].astype(str)+sub['variable']\nsub = pd.merge(submission,sub,on='ForecastId_Quantile')\nsub.drop('TargetValue',axis=1,inplace=True)\nsub.rename(columns={'value':'TargetValue'},inplace=True)\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\n# sub\nsub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}