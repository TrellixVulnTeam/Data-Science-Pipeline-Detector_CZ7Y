{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SUB_PATH = \"/kaggle/input/covid19-global-forecasting-week-5/submission.csv\"\nTRAIN_PATH = \"/kaggle/input/covid19-global-forecasting-week-5/train.csv\"\nTEST_PATH = \"/kaggle/input/covid19-global-forecasting-week-5/test.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data and check it's basic properties"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(TRAIN_PATH)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train data EDA and preprocessing\nIt seems like there is some data with negative value for fatalities / cases, lets have a look at them. Those can either be errors or the values are may be representing difference between the day and previous day."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train[\"Target\"].str.contains(\"Fatalities\")) & (train[\"TargetValue\"] < 0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see the data on the plots. We will plot ConfirmedCases and Fatalities across the whole time peroid. Since County and Province_State is missing for some records and some Countries appear multiple times, let's concatenate location into one field. Also lets convert Date column to numerical Day, drop unused columns and encode Target as a binary value."},{"metadata":{"trusted":true},"cell_type":"code","source":"START_DAY = pd.to_datetime(train[\"Date\"]).min()\n\ndef preprocess(df, drop_cols):\n    df[\"Region\"] = df[\"Country_Region\"].str.cat(others=[df[\"Province_State\"], df[\"County\"]], sep=\" \", na_rep=\"\")\n    df[\"Region\"] = df[\"Region\"].str.strip()\n    df[\"Day\"] = (pd.to_datetime(df[\"Date\"]) - START_DAY).dt.days\n    df[\"Target\"] = df[\"Target\"].str.contains(\"ConfirmedCases\").astype(int)\n    return df.drop(drop_cols, axis=1)\n\ntrain = preprocess(train, [\"Date\", \"County\", \"Province_State\", \"Country_Region\"])\n\nassert train[train[\"Day\"] < 0].count().all() == 0\n    \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like it works fine, so lets create plots for few random countries. US was excluded since there were too many similar cases there."},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(1234)\n\nall_regions = [r for r in train[\"Region\"].unique() if \"US\" not in r]\nregions_to_plot = random.sample(all_regions, 12)\n\nconfirmed_cases = train[train[\"Target\"] & train[\"Region\"].isin(regions_to_plot)]\nfatalities = train[train[\"Target\"] & train[\"Region\"].isin(regions_to_plot)]\n\nsns.set(rc={'figure.figsize':(24,10)})\n\nf, (ax1, ax2) = plt.subplots(1, 2)\nsns.lineplot(x=\"Day\", y=\"TargetValue\", hue=\"Region\", data=confirmed_cases, ax=ax1).set(ylabel=\"ConfirmedCases\", title=\"ConfirmedCases in different countries\");\nsns.lineplot(x=\"Day\", y=\"TargetValue\", hue=\"Region\", data=fatalities, ax=ax2).set(ylabel=\"Fatalities\", title=\"Fatalities in different countries\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also lets plot the 5 countries with lowest / highest cases. Lets also exclude US here - for largest values, US and has 4x more cases compared to next country, and for the lowest there are multiple Counties in the US with total 0 cases (lack of data ?) "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_outliers(df):\n    all_regions = [r for r in df[\"Region\"].unique() if \"US\" not in r]\n    confirmed_cases = df[df[\"Target\"] & (df[\"Region\"].isin(all_regions))]\n    fatalities = df[~df[\"Target\"] & (df[\"Region\"].isin(all_regions))]\n\n    most_confirmed_cases = confirmed_cases.groupby(\"Region\").sum()[\"TargetValue\"].nlargest(10).index\n    least_confirmed_cases = confirmed_cases.groupby(\"Region\").sum()[\"TargetValue\"].nsmallest(10).index\n    most_fatalities = fatalities.groupby(\"Region\").sum()[\"TargetValue\"].nlargest(10).index\n    least_fatalities = fatalities.groupby(\"Region\").sum()[\"TargetValue\"].nsmallest(10).index\n\n    sns.set(rc={'figure.figsize':(24,24)})\n    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n    sns.lineplot(x=\"Day\", y=\"TargetValue\", hue=\"Region\", data=confirmed_cases[confirmed_cases[\"Region\"].isin(most_confirmed_cases)], ax=ax1).set(ylabel=\"ConfirmedCases\", title=\"Countries with most confirmed cases\");\n    sns.lineplot(x=\"Day\", y=\"TargetValue\", hue=\"Region\", data=confirmed_cases[confirmed_cases[\"Region\"].isin(least_confirmed_cases)], ax=ax3).set(ylabel=\"ConfirmedCases\", title=\"Countries with least confirmed cases\");\n    \n    sns.lineplot(x=\"Day\", y=\"TargetValue\", hue=\"Region\", data=fatalities[fatalities[\"Region\"].isin(most_fatalities)], ax=ax2).set(ylabel=\"Fatalities\", title=\"Countries with most fatalities\");\n    sns.lineplot(x=\"Day\", y=\"TargetValue\", hue=\"Region\", data=fatalities[fatalities[\"Region\"].isin(least_fatalities)], ax=ax4).set(ylabel=\"Fatalities\", title=\"Countries with least fatalities\");\n    \nplot_outliers(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those plots look just fine aside from random negative values. In case of Austria on the first and second plot the values are always positive but we know that pandemic has slowed here already, so that puts an end to hypothesis that negative values are differential. Also there are not many negative points, but they look really random (like sudden change from positive to -2000 and to positive again in case of Spain). Let's treat those values as errors and replace with zeros."},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_zeros(df):\n    df[\"TargetValue\"][df[\"TargetValue\"] < 0] = 0\n    return df\n    \ntrain = remove_zeros(train)\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets plot cleaned outliers again"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_outliers(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks much better (although outlier plots for fatalities are not really useful). Let's check if there is the same number of data points for each region"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Day\"].value_counts().unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks good. Now check correlations between columns in train set."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(20,8)})\nf, (ax1, ax2) = plt.subplots(1, 2)\n\n\ncases = train[train[\"Target\"] == 1].drop([\"Target\"], axis=1)\ncases[\"Region\"] = cases[\"Region\"].astype(\"category\").cat.codes\nfatalities = train[train[\"Target\"] == 0].drop([\"Target\"], axis=1)\nfatalities[\"Region\"] = fatalities[\"Region\"].astype(\"category\").cat.codes\n\ncorr = cases.corr(method=\"spearman\")\nsns.heatmap(corr, vmin=-1, vmax=1, cmap=\"YlGnBu\", ax=ax1).set(title=\"Spearman correlation for cases\");\n\ncorr = fatalities.corr(method=\"spearman\")\nplot = sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"YlGnBu\", ax=ax2).set(title=\"Spearman correlation for fatalities\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like Population and to lesser extent Day are correlated to TargetValue, which is to be expected. Region as a categorical value shouldn't be correlated with TargetValue and the plots show that it is indeed uncorrelated. Id also isn't correlated with TargetValue. Correlation plots are pretty resonable.\n\nPlots indicate that Weight as a feature might be unnecessary - is calculated based on population, eg Weight for ConfirmedCases = log(population+1)^−1 and Weight for Fatalities = 10⋅log(population+1)^−1. For now it will be kept.\n\nLets check and preprocess test data and submission data"},{"metadata":{},"cell_type":"markdown","source":"# Check test and sumbission data "},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(TEST_PATH)\nsub = pd.read_csv(SUB_PATH)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform test data the same way training data was transformed\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = preprocess(test, [\"County\", \"Province_State\", \"Country_Region\", \"Date\"])\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the timespans of data to train and data to predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Time span for train set: {train['Day'].min()}-{train['Day'].max()}\")\nprint(f\"Time span for test set: {test['Day'].min()}-{test['Day'].max()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check submission data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and evaluate simple LinearRegression model"},{"metadata":{},"cell_type":"markdown","source":"We will use simple model without history. Lets create X and Y and split datasets. Id and Region features are removed as they are not useful according to correlation plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train.drop(['TargetValue', 'Id', 'Region'], axis=1)\nY = train[\"TargetValue\"]\n\ntrain_X, val_X, train_Y, val_Y = train_test_split(X, Y, train_size=0.8, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit basic model. No need to scale values as it is already provided with default linear regression parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlinear_model = LinearRegression().fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict values with trained model and evaluate MSE and MAE for cases and fatalities separately"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\n\ndef evaluate(model, x, y):\n    pred = model.predict(x)\n    \n    combined_mse = mse(y, pred)\n    combined_mae = mae(y, pred)\n    \n    pred_cases = pred[x[\"Target\"] == 1]\n    pred_fatalities = pred[x[\"Target\"] == 0]\n    true_cases = y[x[\"Target\"] == 1]\n    true_fatalities = y[x[\"Target\"] == 0]\n    \n    cases_mse = mse(true_cases, pred_cases)\n    fatalities_mse = mse(true_fatalities, pred_fatalities)\n    cases_mae = mae(true_cases, pred_cases)\n    fatalities_mae = mae(true_fatalities, pred_fatalities)\n    \n    print(f\"Combined\\t\\tMSE = {combined_mse},\\tMAE = {combined_mae},\\tmean true value: {y.mean()}\")\n    print(f\"Cases\\t\\t\\tMSE = {cases_mse},\\tMAE = {cases_mae},\\tmean true value: {true_cases.mean()}\")\n    print(f\"Fatalities\\t\\tMSE = {fatalities_mse},\\tMAE = {fatalities_mae},\\tmean true value: {true_fatalities.mean()}\")\n\nevaluate(linear_model, val_X, val_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check if we can make this model better with feature engineering before moving on to more sophisticated models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.pipeline import Pipeline\n\ndef mapper(population, weight, day):\n    mapper = DataFrameMapper([\n        (['Population'], PolynomialFeatures(population, include_bias=False)),\n        (['Weight'], PolynomialFeatures(weight, include_bias=False)),\n        (['Day'], PolynomialFeatures(day, include_bias=False)),\n        ('Target', None)])\n    return mapper\n\nfor day in [1, 2, 3]:\n    for weight in [0, 1, 2, 3]:\n        for population in [1, 2, 3]:\n            print(f\"Evaluation for polynomial coefficients: day={day}, weight={weight}, population={population}\")\n            pipeline = Pipeline([('mapper', mapper(population, weight, day)), ('linear_regression', LinearRegression())])\n            pipeline.fit(train_X, train_Y);\n            evaluate(pipeline, val_X, val_Y)\n            print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForestRegressor\nLinearRegression model is bad, and additional features don't help, which was to be expected. Weight feature is almost useless for linear model.\n\nNow we can try other algorithms and compare them to LinearRegression baseline. Let's start with RandomForestRegressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfr_model = RandomForestRegressor(n_estimators=10, verbose=1, n_jobs=-1)\nrfr_model.fit(train_X, train_Y);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_model.verbose=0\nevaluate(rfr_model, val_X, val_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model looks way better! Lets check if we can get better results by scaling features and running grid search to tune some parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef map_scale():\n    mapper = DataFrameMapper([\n        (['Population'], StandardScaler()),\n        (['Weight'], StandardScaler()),\n        (['Day'], StandardScaler()),\n        ('Target', None)])\n    return mapper\n\nrbf_pipe_scale = Pipeline([('scale', map_scale()), \n                           ('regressor', RandomForestRegressor(n_estimators=10, verbose=1, n_jobs=-1))]);\nrbf_pipe_scale.fit(train_X, train_Y);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rbf_pipe_scale.steps[1][1].verbose=0\nevaluate(rbf_pipe_scale, val_X, val_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like using a scaler makes results slightly worse, so lets not use the pipeline at all and do the gird search on number of used estimators. Lets stick to the small numbers for now to make search faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n\"\"\" This is commented out as it takes a lot of time \"\"\"\n\n# param_grid = {\n#     \"n_estimators\": [5, 10, 15, 20]\n# }\n\n# grid_search = GridSearchCV(RandomForestRegressor(), param_grid, verbose=10, n_jobs=-1);\n# grid_search.fit(X, Y)\n# rfr_model = grid_search.best_estimator_\n\n# print(f\"Best parameter (CV score={grid_search.best_score_})\")\n# print(grid_search.best_params_)\n# print(grid_search.best_estimator_)\n# evaluate(rfr_model, train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, plot predictions of the model along with the real values for the best model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_train_test(model, train, test, country):\n    pd.set_option('mode.chained_assignment', None)\n    train = train[train[\"Region\"].str.match(country)];\n    test = test[test[\"Region\"].str.match(country)];\n    \n    test[\"TargetValue\"] = model.predict(test.drop([\"ForecastId\", \"Region\"], axis=1));\n    \n    train_cases = train[train[\"Target\"] == 1]\n    train_fatalities = train[train[\"Target\"] == 0]\n    test_cases = test[test[\"Target\"] == 1]\n    test_fatalities = test[test[\"Target\"] == 0]\n    \n    sns.set(rc={'figure.figsize':(24,12)})\n    f, (ax1, ax2) = plt.subplots(1, 2)\n    sns.lineplot(x=\"Day\", y=\"TargetValue\", data=train_cases, ax=ax1, label=\"True values\");\n    sns.lineplot(x=\"Day\", y=\"TargetValue\", data=test_cases, ax=ax1, label=\"Predicted values\").set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases in {country}\");\n    \n    sns.lineplot(x=\"Day\", y=\"TargetValue\", data=train_fatalities, ax=ax2, label=\"True values\");\n    sns.lineplot(x=\"Day\", y=\"TargetValue\", data=test_fatalities, ax=ax2, label=\"Predicted values\").set(ylabel=\"Fatalities\", title=f\"Real and predicted fatalities in {country}\");\n    pd.set_option('mode.chained_assignment', 'warn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_test(rfr_model, train, test, \"Russia\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_test(rfr_model, train, test, \"Brazil\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_test(rfr_model, train, test, \"Poland\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Models learned to approximate training data really well, but they fail to generalize in the future. Let's try other approach with SVR"},{"metadata":{},"cell_type":"markdown","source":"# Simple neural network"},{"metadata":{},"cell_type":"markdown","source":"Lets feed the data to simple neural network and see if it performs better than RFR"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm\n\ns_pop = MinMaxScaler(feature_range=(0, 1))\ntrain[\"Population\"] = s_pop.fit_transform(train[\"Population\"].values[:,np.newaxis])\n\ncases_data = train[train[\"Target\"] == 1]\nfatalities_data = train[train[\"Target\"] == 0]\n\ns_cas = MinMaxScaler(feature_range=(0, 1))\ns_fat = MinMaxScaler(feature_range=(0, 1))\n\ncases_data[\"TargetValue\"] = s_cas.fit_transform(cases_data[\"TargetValue\"].values[:,np.newaxis])\nfatalities_data[\"TargetValue\"] = s_fat.fit_transform(fatalities_data[\"TargetValue\"].values[:,np.newaxis])\n\ndef split_x_y(df, time_span):\n    df = df.drop([\"Id\", \"Target\", \"Region\"], axis=1)\n    end_day = df[\"Day\"].max()+1\n    df = df.drop([\"Day\"], axis=1)\n    df = df.values.reshape((-1, end_day, 3))\n\n    x = []\n    y = []\n    \n    for i in tqdm(range(df.shape[0])):\n        for j in range(time_span, end_day):\n            idx = range(j-time_span, j)\n            x.append(df[i,idx,:])\n            y.append(df[i,j,2])\n    \n    return np.array(x), np.array(y)\n\nc_x, c_y = split_x_y(cases_data, 50)\nf_x, f_y = split_x_y(fatalities_data, 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create separate models for cases and for fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport keras.backend as K\nfrom keras import Model\nfrom keras.layers import *\n\ndef swish(x):\n    return x * K.sigmoid(x)\n\ndef get_model(input_shape):\n    inp = Input(input_shape)\n    x = Bidirectional(GRU(16, return_sequences=True))(inp)\n    x = Activation(swish)(x)\n    x = Dropout(0.3)(x)\n    x = Bidirectional(GRU(16, return_sequences=True))(x)\n    x = Activation(swish)(x)\n    x = Dropout(0.3)(x)\n    x = Bidirectional(GRU(16, return_sequences=False))(x)\n    x = Activation(swish)(x)\n    x = Dropout(0.3)(x)\n    out = Dense(1, activation=swish)(x)\n\n    model = Model(inp, [out])\n    model.compile(loss=['mean_squared_error'],\n              optimizer='RMSprop',\n              metrics=['mean_squared_error'])\n    print(model.summary())\n    return model\n    \ncases_model = get_model((c_x.shape[1],c_x.shape[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_model.fit(c_x, c_y, epochs=100, batch_size=1024, shuffle=True, validation_split=0.2, callbacks=[\n    keras.callbacks.ModelCheckpoint(\"model_cases.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min'), \n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_separate(model, X, Y, scaler):\n    pred = model.predict(X, batch_size=1024, verbose=1)\n    pred = scaler.inverse_transform(pred)\n    Y = scaler.inverse_transform(Y[:,np.newaxis])\n    print(f\"MSE: {((Y-pred)**2).mean()}\\tMAE: {(np.abs(Y-pred)).mean()}\\tmean Y value: {Y.mean()}\")\n\ncases_model.load_weights(\"model_cases.h5\")\nevaluate_separate(cases_model, c_x, c_y, s_cas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train another model for fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalities_model = get_model((f_x.shape[1],f_x.shape[2]))\n\nfatalities_model.fit(f_x, f_y, epochs=100, batch_size=1024, shuffle=True, validation_split=0.2, callbacks=[\n    keras.callbacks.ModelCheckpoint(\"model_fatalities.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min'), \n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalities_model.load_weights(\"model_fatalities.h5\")\nevaluate_separate(fatalities_model, f_x, f_y, s_fat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets create pltos similar to those made earlier for RFR"},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_preds = cases_model.predict(c_x, batch_size=1024, verbose=1)\nfatalities_preds = fatalities_model.predict(f_x, batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_nn(y, preds, predict_last_n, time_step, regions, scaler, ax, region_idx):    \n    time_span = int(y.shape[0] / regions)\n    y = scaler.inverse_transform(y[:,np.newaxis])\n    y = y.reshape(regions, time_span)\n    y = y[region_idx, :]\n    y_days = list(range(time_step, time_step+time_span))\n    \n    preds = scaler.inverse_transform(preds)\n    preds = preds.reshape(regions, time_span)\n    preds = preds[region_idx, -predict_last_n:]\n    preds_days = list(range(time_step+time_span-predict_last_n, time_step+time_span))\n\n    sns.lineplot(x=y_days, y=y, ax=ax, label=\"True values\");\n    return sns.lineplot(x=preds_days, y=preds, ax=ax, label=\"Predicted values\")\n    \nlast_n = train[\"Day\"].max() - test[\"Day\"].min()\n\nsns.set(rc={'figure.figsize':(24,12)})\nf, (ax1, ax2) = plt.subplots(1, 2)\ncases_plot = plot_nn(c_y, cases_preds, last_n, 50, len(train[\"Region\"].unique()), s_cas, ax1, 154).set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases\");\nfatalities_plot = plot_nn(f_y, fatalities_preds, last_n, 50, len(train[\"Region\"].unique()), s_fat, ax2, 154).set(ylabel=\"Fatalities\", title=f\"Fatalities\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(24,12)})\nf, (ax1, ax2) = plt.subplots(1, 2)\ncases_plot = plot_nn(c_y, cases_preds, last_n, 50, len(train[\"Region\"].unique()), s_cas, ax1, 141).set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases\");\nfatalities_plot = plot_nn(f_y, fatalities_preds, last_n, 50, len(train[\"Region\"].unique()), s_fat, ax2, 141).set(ylabel=\"Fatalities\", title=f\"Fatalities\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(24,12)})\nf, (ax1, ax2) = plt.subplots(1, 2)\ncases_plot = plot_nn(c_y, cases_preds, last_n, 50, len(train[\"Region\"].unique()), s_cas, ax1, 120).set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases\");\nfatalities_plot = plot_nn(f_y, fatalities_preds, last_n, 50, len(train[\"Region\"].unique()), s_fat, ax2, 120).set(ylabel=\"Fatalities\", title=f\"Fatalities\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally predict for last days in test set. Use last 50 days from training set to predict values for the next day, then use last 49 and new predicted value for next day etc"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_unknown(model, x, time_span, regions, n_times):\n    x = x.reshape((regions, -1, time_span, 3))\n    x = x[:, -1:, :, :]\n    x = x.reshape(-1, time_span, 3)\n    \n    preds = []\n    for i in range(n_times):\n        y = model.predict(x, batch_size=1024, verbose=1)\n        preds.append(y[:,0])\n        temp = np.zeros(x.shape)\n        temp[:,:-1,:] = x[:,1:,:]\n        temp[:,-1,:] = x[:,-1,:]\n        temp[:,-1,2] = y[:,0]\n        x = temp\n    return np.array(preds)\n\ndays_to_predict = test[\"Day\"].max() - train[\"Day\"].max() + 1\noutput_cases = predict_unknown(cases_model, c_x, 50, len(train[\"Region\"].unique()), days_to_predict)\noutput_fatalities = predict_unknown(fatalities_model, f_x, 50, len(train[\"Region\"].unique()), days_to_predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenate predictions for training set and for unknown days to plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_cases = s_cas.inverse_transform(np.swapaxes(output_cases,0,1))\noutput_fatalities = s_fat.inverse_transform(np.swapaxes(output_fatalities,0,1))\ntrain_set_cases_preds = s_cas.inverse_transform(np.reshape(cases_preds, (output_cases.shape[0], -1)))\ntrain_set_fatalities_preds = s_fat.inverse_transform(np.reshape(fatalities_preds, (output_fatalities.shape[0], -1)))\n\nfinal_cases = np.concatenate((train_set_cases_preds, output_cases), axis=1)\nfinal_fatalities = np.concatenate((train_set_fatalities_preds, output_fatalities), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_y = s_cas.inverse_transform(c_y[:,np.newaxis])\nfatalities_y = s_fat.inverse_transform(f_y[:,np.newaxis])\ncases_y = np.reshape(cases_y, (final_cases.shape[0],-1))\nfatalities_y = np.reshape(fatalities_y, (final_fatalities.shape[0],-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_final(true, pred, true_days, pred_days, ax, batch_idx): \n    true = true[batch_idx,:]\n    pred = pred[batch_idx,:]\n    sns.lineplot(x=true_days, y=true, ax=ax, label=\"True values\");\n    return sns.lineplot(x=pred_days, y=pred, ax=ax, label=\"Predicted values\")\n    \ntrue_days = list(range(49, train[\"Day\"].max()))\npred_days = list(range(test[\"Day\"].max() - final_cases.shape[1], test[\"Day\"].max()))\nsns.set(rc={'figure.figsize':(24,12)})\nf, (ax1, ax2) = plt.subplots(1, 2)\ncases_plot = plot_final(cases_y, final_cases, true_days, pred_days, ax1, 154).set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases\");\nfatalities_plot = plot_final(fatalities_y, final_fatalities, true_days, pred_days, ax2, 154).set(ylabel=\"Fatalities\", title=f\"Fatalities\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(24,12)})\nf, (ax1, ax2) = plt.subplots(1, 2)\ncases_plot = plot_final(cases_y, final_cases, true_days, pred_days, ax1, 141).set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases\");\nfatalities_plot = plot_final(fatalities_y, final_fatalities, true_days, pred_days, ax2, 141).set(ylabel=\"Fatalities\", title=f\"Fatalities\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(24,12)})\nf, (ax1, ax2) = plt.subplots(1, 2)\ncases_plot = plot_final(cases_y, final_cases, true_days, pred_days, ax1, 120).set(ylabel=\"ConfirmedCases\", title=f\"Real and predicted cases\");\nfatalities_plot = plot_final(fatalities_y, final_fatalities, true_days, pred_days, ax2, 120).set(ylabel=\"Fatalities\", title=f\"Fatalities\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NN model is far from best, but it is able to somehow generalize into future. For some regions it's predictions look sensible, if not precise, but sadly sometimes model happens to predict negative numbers. This is mostly due to training on normalized data. Ideally, we would train on unnormalized data and use ReLU activation to ensure positive output, but in this case models didn't train well on unormalized data."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}