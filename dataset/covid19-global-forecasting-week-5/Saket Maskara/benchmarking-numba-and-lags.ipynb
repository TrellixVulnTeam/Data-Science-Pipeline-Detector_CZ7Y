{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dftrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain.TargetValue.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numba import vectorize, jit\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport seaborn as sns\n\ndef test(a):\n    return np.sqrt(a)\n\n# numbatest = vectorize(['int64(int64)'], nopython=True, target=\"parallel\")(test)\nnumbadefault = vectorize(nopython=True)(test)\nnumbaparallel = vectorize(['int64(int64)'], nopython=True, target=\"parallel\")(test)\nnumpytest = np.vectorize(test, otypes = [np.uint64])\nnumbadefault(1)\nnumbaparallel(1)\nnumpytest(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numba\nnumba.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance = pd.DataFrame()\nfor i in range(1000, 1000000, 50000): #, \n    print(f\"Running {i} operations\")\n    arr = np.array(range(i))\n    output = pd.DataFrame({\n        'input' : arr\n    })\n    ### list comprehension\n    start = time()\n    output['ls'] = [test(a) for a in output['input']]\n    end = time()\n    lstime = end-start\n    \n    ## numba default\n    start = time()\n    output['ndefault'] = numbadefault(output['input'].values)\n    end = time()\n    ndtime = end-start\n\n    ## numba parallel\n    start = time()\n    output['nparallel'] = numbaparallel(output['input'].values)\n    end = time()\n    numbaptime = end-start\n\n    ### numpy\n    start = time()\n    output['numpy'] = numpytest(output['input'].values)\n    end = time()\n    nptime = end-start\n \n    ### pandas eval\n    start = time()\n    output['pandas'] = output.eval('input**2')\n    end = time()\n    pdtime = end-start\n    \n#     ### pandas eval numba\n#     start = time()\n#     output['pandasnumba'] = output['input'].apply(lambda x: np.sqrt(x), engine='numba', raw=True)\n#     end = time()\n#     pdnumbatime = end-start\n \n    \n    obs = pd.DataFrame({\n        'Elements' : [i]*5,\n        'Type' : ['List Comprehension', 'Numba Vectorize', 'Numba Parallel Vectorize', 'Numpy Vectorize', 'Pandas eval'],\n        'Time' : [lstime, ndtime, numbaptime, nptime, pdtime]\n    })\n    \n    performance = pd.concat([performance, obs], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x=\"Elements\", y=\"Time\", hue=\"Type\", data=performance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x=\"Elements\", y=\"Time\", hue=\"Type\", data=performance[~performance.Type.isin(['List Comprehension', 'Numpy Vectorize'])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### creating lags","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fn_lags_apply(df, colname, lags):\n    \"\"\"\n    Function to create lags \n    \"\"\"    \n    if type(lags) == int:\n        lagslist = list(range(1, lags + 1))\n    else:\n        lagslist = lags\n    for x in lagslist:\n        df.loc[:, colname + '_lag' + str(x)] = df['TargetValue'].shift(x).fillna(0)\n    return df\n\ndef fn_lags_gsc(df, colname, lags):\n    \"\"\"\n    Function to create lags \n    \"\"\"    \n    if type(lags) == int:\n        lagslist = list(range(1, lags + 1))\n    else:\n        lagslist = lags\n    \n    for x in lagslist:        \n        df.loc[:, colname + '_lag' + str(x)] = df.groupby(['Country_Region', 'Target']).shift(x)[colname].fillna(0)\n\n    return df\n\ndef fn_lags_gcs(df, colname, lags):\n    \"\"\"\n    Function to create lags \n    \"\"\"    \n    if type(lags) == int:\n        lagslist = list(range(1, lags + 1))\n    else:\n        lagslist = lags\n    \n    for x in lagslist:        \n        df.loc[:, colname + '_lag' + str(x)] = df.groupby(['Country_Region', 'Target'])[colname].shift(x).fillna(0)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance = pd.DataFrame()\nfor i in range(1, 20):\n    print(f\"Adding {i} lags\")\n    starttime = time()\n    dftrainwithlags = fn_lags_gcs(dftrain, 'TargetValue', i)\n    endtime = time()\n    gcs = endtime - starttime\n\n    starttime = time()\n    dftrainwithlags = fn_lags_gsc(dftrain, 'TargetValue', i)\n    endtime = time()\n    gsc = endtime - starttime\n\n    starttime = time()\n    dftrainwithlags = dftrain.groupby(['Country_Region', 'Target'], as_index=False).apply(fn_lags_apply, colname='TargetValue', lags=10)\n    endtime = time()\n    gapp = endtime - starttime\n\n    \n    \n    obs = pd.DataFrame({\n        'Lags' : [i]*3,\n        'Type' : ['groupby()[colname].shift', 'groupby().shift()[colname]', 'groupby().apply'],\n        'Time' : [gcs, gsc, gapp]\n    })\n    \n    performance = pd.concat([performance, obs], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x=\"Lags\", y=\"Time\", hue=\"Type\", data=performance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}