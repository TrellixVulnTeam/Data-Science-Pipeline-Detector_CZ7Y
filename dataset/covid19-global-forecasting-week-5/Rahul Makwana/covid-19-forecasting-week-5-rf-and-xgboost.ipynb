{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/train.csv')\ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/test.csv')\ndf_sample = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing all the Province_State that are null by the Country_Region values\ndf_train.Province_State.fillna(df_train.Country_Region, inplace=True)\ndf_test.Province_State.fillna(df_test.Country_Region, inplace=True)\n\ndf_train.County.fillna(df_train.Province_State, inplace=True)\ndf_test.County.fillna(df_test.Province_State, inplace=True)\n\ndf_train.isnull().sum()\ndf_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking care of categorical values from train set\n# we can also use labelencoder for date column\nfrom sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf_train['Country_Region'] = labelencoder.fit_transform(df_train['Country_Region'])\ndf_train['Target'] = labelencoder.fit_transform(df_train['Target'])\n# df_train['Date'] = labelencoder.fit_transform(df_train['Date'])\n\n# taking care of categorical values from test set\n\ndf_test['Country_Region'] = labelencoder.fit_transform(df_test['Country_Region'])\ndf_test['Target'] = labelencoder.fit_transform(df_test['Target'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking care of the date column\ndf_train['Date'] = pd.to_datetime(df_train['Date'], infer_datetime_format=True)\ndf_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)\n\ndf_train.loc[:, 'Date'] = df_train.Date.dt.strftime(\"%Y%m%d\")\ndf_train.loc[:, 'Date'] = df_train['Date'].astype(int)\n\ndf_test.loc[:, 'Date'] = df_test.Date.dt.strftime(\"%Y%m%d\")\ndf_test.loc[:, 'Date'] = df_test['Date'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ID=df_train['Id']\nFID=df_test['ForecastId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dataset for training and testing\n\ny_train=df_train['TargetValue']\nX_train=df_train.drop(['Id', 'County', 'Province_State','TargetValue'],axis=1)\ndf_test=df_test.drop(columns=['County','Province_State','ForecastId'])\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **RANDOM FOREST**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Regression to the dataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_jobs=-1)\nestimators = 100\nmodel.set_params(n_estimators=estimators)\n\nscores = []\n\npipeline = Pipeline([('scaler2' , StandardScaler()),\n                        ('RandomForestRegressor: ', model)])\npipeline.fit(X_train , y_train)\ny_pred = pipeline.predict(X_test)\n\nscores.append(pipeline.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores)\n\n\ny_pred_main = pipeline.predict(df_test)\n\n\nmain_submission = pd.DataFrame({'id':FID,'TargetValue':y_pred_main})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# cross-validation method\nfrom sklearn.model_selection import cross_val_score, KFold\n\ncv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\nprint(\"cross-validation score:\",cv_scores.mean())\n\n# Cross-validation with a k-fold method\n\nkfold = KFold(n_splits=10, shuffle=True)\nkf_cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kfold)\nprint(\"K-fold CV average score:\" ,kf_cv_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, mean_squared_error\nfrom math import sqrt\n\nprint('explained variance_score:', explained_variance_score(y_test, y_pred))\nprint('max_error:', max_error(y_test, y_pred))\nprint('mean_absolute_error score:', mean_absolute_error(y_test, y_pred))\nprint('mean_squared_error score:', mean_squared_error(y_test, y_pred))\nprint('root mean_squared_error:', sqrt(mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **XGBOOST**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting xgboost Regressor to the dataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRegressor \n\nmodel_2 = XGBRegressor(n_jobs=-1)\nestimators = 1000\nmodel_2.set_params(n_estimators=estimators)\n\nscores = []\n\npipeline_2 = Pipeline([('scaler2' , StandardScaler()),\n                        ('XGBRegressor: ', model)])\npipeline_2.fit(X_train , y_train)\ny_pred_2 = pipeline_2.predict(X_test)\n\nscores.append(pipeline_2.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores)\n\n\ny_pred_main=pipeline.predict(df_test)\n\n\nmain_submission_2 = pd.DataFrame({'id':FID,'TargetValue':y_pred_main})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_submission_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, mean_squared_error\nfrom math import sqrt\n\nprint('explained variance_score:', explained_variance_score(y_test, y_pred_2))\nprint('max_error:', max_error(y_test, y_pred_2))\nprint('mean_absolute_error score:', mean_absolute_error(y_test, y_pred_2))\nprint('mean_squared_error score:', mean_squared_error(y_test, y_pred_2))\nprint('root mean_squared_error:', sqrt(mean_squared_error(y_test, y_pred_2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**making csv file for submission using random forest prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"main_pred=pd.DataFrame({'id':FID,'TargetValue':y_pred_main})\nprint(main_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=main_pred.groupby(['id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=main_pred.groupby(['id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=main_pred.groupby(['id'])['TargetValue'].quantile(q=0.95).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**please do upvote if you like and inform if you find any mistake.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}