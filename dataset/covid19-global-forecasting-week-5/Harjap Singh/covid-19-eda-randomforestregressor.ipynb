{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing all the necessary libraries."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd #for input/output and data processing\nimport matplotlib.pyplot as plt    #for visualizations\nimport plotly.express as px\nfrom sklearn.ensemble import RandomForestRegressor\n!pip install plotly\nimport plotly.express as px\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Picking up the dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"d_train = pd.read_csv('../input/covid19-global-forecasting-week-5/train.csv')\nd_test = pd.read_csv('../input/covid19-global-forecasting-week-5/test.csv')\nd_sample = pd.read_csv('../input/covid19-global-forecasting-week-5/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_sample.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train.sort_values(by=['TargetValue'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_pie = px.pie(d_train, values='TargetValue', names='Country_Region')\nfig_pie.update_traces(textposition='inside')\nfig_pie.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig_pie.show()\n#Here, we get an exact idea about the top 10 countries with most cases with COVID-19.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train.groupby('Country_Region')['TargetValue'].mean().plot(kind = 'bar', figsize= (40,20), title= \"Countries with COVID-19 MAX\", color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_date = d_train.Date.max()\ndf_countries = d_train[d_train['Date']==last_date]\ndf_countries = df_countries.groupby('Country_Region', as_index=False)['TargetValue'].sum()\ndf_countries = df_countries.nlargest(10,'TargetValue')\ndf_trend = d_train.groupby(['Date','Country_Region'], as_index=False)['TargetValue'].sum()\ndf_trend = df_trend.merge(df_countries, on='Country_Region')\ndf_trend.rename(columns={'Country_Region':'Country', 'TargetValue_x':'Cases'}, inplace=True)\npx.line(df_trend, x='Date', y='Cases', color='Country', title='COVID19 Total Cases growth for top 10 worst affected countries in the World')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = d_train.drop(['County','Province_State','Country_Region','Target'], axis=1)\nd_test = d_test.drop(['County','Province_State','Country_Region','Target'], axis=1)\n\nd_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\ndef create_feature(df):\n    df['day'] = df['Date'].dt.day\n    df['month'] = df['Date'].dt.month\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['dayofyear'] = df['Date'].dt.dayofyear\n    df['quarter'] = df['Date'].dt.quarter\n    df['weekofyear'] = df['Date'].dt.weekofyear\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_split(data, days):\n    date = data['Date'].max() - dt.timedelta(days=days)\n    return data[data['Date'] <= date], data[data['Date'] > date]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_date_min = d_test['Date'].min()\ntest_date_max = d_test['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def avoid_date_leakage(data, date=test_date_min):\n    return data[data['Date'] < date]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_integer(dt_time):\n    return 10000*dt_time.year + 100*dt_time.month + dt_time.day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train['Date'] = pd.to_datetime(d_train['Date'])\nd_test['Date'] = pd.to_datetime(d_test['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train['Date'] = d_train['Date'].dt.strftime('%Y%m%d')\nd_test['Date'] = d_test['Date'].dt.strftime('%Y%m%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Date is fixed and in a string form now."},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, doing train and test split to the model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = d_train.iloc[:,1:4]\nY = d_train.iloc[:,4]\nfrom sklearn.model_selection import train_test_split\n\npredictors = d_train.drop(['TargetValue', 'Id'], axis=1)\ntarget = d_train['TargetValue']\nX_train, X_test, Y_train, Y_test = train_test_split(predictors,target, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying Random Forest using 100 estimators."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\npipeline_dt = Pipeline([('scaler2' , StandardScaler()),('RandomForestRegressor: ', RandomForestRegressor(n_jobs = -1 , random_state = 0))])\npipeline_dt.fit(X_train , Y_train)\nprediction = pipeline_dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating the score."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score\nscore = pipeline_dt.score(X_test, Y_test)\nprint(\"Score: \"+ str(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_test.drop(['ForecastId'], axis=1, inplace=True)\nd_test.index.name = 'Id'\nd_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2 = pipeline_dt.predict(X_test)\ny_pred2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pipeline_dt.predict(d_test)\n\npred_list = [int(x) for x in predictions]\n\noutput = pd.DataFrame({'Id': d_test.index, 'TargetValue': pred_list})\nprint(output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Output"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = output.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index() \ng = output.groupby(['Id'])['TargetValue'].quantile(q=0.5).reset_index() \nh = output.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f.columns=['Id','q0.05']\ng.columns=['Id','q0.5']\nh.columns=['Id','q0.95']\nf=pd.concat([f,g['q0.5'],h['q0.95']],1)\nf['q0.05']=f['q0.05'].clip(0,10000)\nf['q0.5']=f['q0.5'].clip(0,10000)\nf['q0.95']=f['q0.95'].clip(0,10000)\nf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f['Id'] = f['Id'] + 1\nf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.melt(f, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make sure to press that Upvote button if you like it!\n# Will surely try to update and improve the score..."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}