{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, validation_curve\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nRANDOM_STATE = 1\nTEST_SIZE = .2\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace(np.nan,'',regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert datetime to days from 1-Jan-2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"days = []\nfor index in df.index:\n    if(df.iloc[index].Date.month == 1):\n        days.append(df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 2):\n        days.append((31) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 3):\n        days.append((31+29) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 4):\n        days.append((31*2+29) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 5):\n        days.append((31*2+29+30) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 6):\n        days.append((31*3+29+30*1) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 7):\n        days.append((31*3+29+30*2) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 8):\n        days.append((31*4+29+30*2) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 9):\n        days.append((31*5+29+30*2) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 10):\n        days.append((31*5+29+30*3) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 11):\n        days.append((31*6+29+30*3) + df.iloc[index].Date.day)\n    elif(df.iloc[index].Date.month == 12):\n        days.append((31*6+29+30*4) + df.iloc[index].Date.day)\n        \ndf.insert(0,'days', days)        \ndf.drop('Date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge Country region, Provinence state, country to single feature and apply binary encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Region'] = df['Country_Region'] + df['Province_State'] + df['County']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Id','Country_Region', 'Province_State', 'County'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\nencoder = ce.BinaryEncoder(cols = ['Region'])\ndfbin = encoder.fit_transform(df['Region'])\ndf = pd.concat([df, dfbin],axis=1)\ndf.drop('Region', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split covid dataset into 2 models confirmed cases and fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmCasesDf = df[df['Target'] == 'ConfirmedCases']\nfatalitiesDf = df[df['Target'] == 'Fatalities']\n\nconfirmCasesDf.drop('Target', axis=1, inplace=True)\nfatalitiesDf.drop('Target', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = fatalitiesDf.drop('TargetValue', axis=1)\ny = fatalitiesDf.TargetValue\nxFatalities_train, xFatalities_test, yFatalities_train, yFatalities_test = train_test_split(X,\n                                                                                            y,\n                                                                                            test_size=TEST_SIZE,\n                                                                                            random_state=RANDOM_STATE) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = confirmCasesDf.drop('TargetValue', axis=1)\ny = confirmCasesDf.TargetValue\nxConfirmCases_train, xConfirmCases_test, yConfirmCases_train, yConfirmCases_test = train_test_split(X,\n                                                                                                    y,\n                                                                                                    test_size=TEST_SIZE,\n                                                                                                    random_state=RANDOM_STATE) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create fatalities model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalitiesModel = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1, oob_score=True, n_estimators=300)\nfatalitiesModel.fit(xFatalities_train, yFatalities_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalitiesModel.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalitiesModel.score(xFatalities_train, yFatalities_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalitiesModel.score(xFatalities_test, yFatalities_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Create confirmed cases model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmedCaseModel = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1, oob_score=True, n_estimators=300)\nconfirmedCaseModel.fit(xConfirmCases_train, yConfirmCases_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmedCaseModel.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmedCaseModel.score(xConfirmCases_train, yConfirmCases_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmedCaseModel.score(xConfirmCases_test, yConfirmCases_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ###Load test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"testDf = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/test.csv')\ntestDf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Do preprocessing on Date, County, Provinence_state, Country region "},{"metadata":{"trusted":true},"cell_type":"code","source":"testDf['Date'] = pd.to_datetime(testDf['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDf = testDf.replace(np.nan,'',regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndays = []\nfor index in testDf.index:\n    if(testDf.iloc[index].Date.month == 1):\n        days.append(testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 2):\n        days.append((31) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 3):\n        days.append((31+29) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 4):\n        days.append((31*2+29) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 5):\n        days.append((31*2+29+30) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 6):\n        days.append((31*3+29+30*1) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 7):\n        days.append((31*3+29+30*2) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 8):\n        days.append((31*4+29+30*2) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 9):\n        days.append((31*5+29+30*2) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 10):\n        days.append((31*5+29+30*3) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 11):\n        days.append((31*6+29+30*3) + testDf.iloc[index].Date.day)\n    elif(testDf.iloc[index].Date.month == 12):\n        days.append((31*6+29+30*4) + testDf.iloc[index].Date.day)\n        \ntestDf.insert(0,'days', days)        \ntestDf.drop('Date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDf['Region'] = testDf['Country_Region'] + testDf['Province_State'] + testDf['County']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDf.drop(['Country_Region', 'Province_State', 'County'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\nencoder = ce.BinaryEncoder(cols = ['Region'])\ndfbin = encoder.fit_transform(testDf['Region'])\ntestDf = pd.concat([testDf, dfbin],axis=1)\ntestDf.drop('Region', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testConfirmCasesDf = testDf[testDf['Target'] == 'ConfirmedCases']\ntestFatalitiesDf = testDf[testDf['Target'] == 'Fatalities']\n\nconfirmedCasesForecastIds = testConfirmCasesDf.ForecastId\nfatilitiesForecastIds = testFatalitiesDf.ForecastId\n\ntestConfirmCasesDf.drop(['Target', 'ForecastId'], axis=1, inplace=True)\ntestFatalitiesDf.drop(['Target', 'ForecastId'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict using fatalities and confirmed cases model"},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmTargetScore = confirmedCaseModel.predict(testConfirmCasesDf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatalitiesScore = fatalitiesModel.predict(testFatalitiesDf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmTargetDict = dict(zip(confirmedCasesForecastIds, confirmTargetScore))\nfatalitiesDict = dict(zip(fatilitiesForecastIds, fatalitiesScore))\n\nfinalDict = { **confirmTargetDict, **fatalitiesDict }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultDf = pd.DataFrame({\"ForecastId\":list(finalDict.keys()), 'TargetValue':list(finalDict.values())})\nresultDf.sort_values(by=['ForecastId'], inplace=True)\nresultDf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=resultDf.groupby(['ForecastId'])['TargetValue'].quantile(q=0.05).reset_index()\nb=resultDf.groupby(['ForecastId'])['TargetValue'].quantile(q=0.5).reset_index()\nc=resultDf.groupby(['ForecastId'])['TargetValue'].quantile(q=0.95).reset_index()\na.columns=['ForecastId','q0.05']\nb.columns=['ForecastId','q0.5']\nc.columns=['ForecastId','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05'].clip(0,10000)\na['q0.5']=a['q0.5'].clip(0,10000)\na['q0.95']=a['q0.95'].clip(0,10000)\na\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.melt(a, id_vars=['ForecastId'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['ForecastId'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save final result"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}