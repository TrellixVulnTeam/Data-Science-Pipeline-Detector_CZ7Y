{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-09T00:16:17.921996Z","iopub.execute_input":"2022-04-09T00:16:17.922864Z","iopub.status.idle":"2022-04-09T00:16:20.68977Z","shell.execute_reply.started":"2022-04-09T00:16:17.922729Z","shell.execute_reply":"2022-04-09T00:16:20.688805Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*wli6Okh8p3vgaH69PdijkA.png)medium.com","metadata":{}},{"cell_type":"code","source":"!pip install kornia","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:16:30.236546Z","iopub.execute_input":"2022-04-09T00:16:30.236891Z","iopub.status.idle":"2022-04-09T00:16:40.877282Z","shell.execute_reply.started":"2022-04-09T00:16:30.236853Z","shell.execute_reply":"2022-04-09T00:16:40.876371Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torchvision\nimport kornia as K","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:20:24.712563Z","iopub.execute_input":"2022-04-09T00:20:24.713238Z","iopub.status.idle":"2022-04-09T00:20:27.020338Z","shell.execute_reply.started":"2022-04-09T00:20:24.713189Z","shell.execute_reply":"2022-04-09T00:20:27.019284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load an image with OpenCV","metadata":{}},{"cell_type":"code","source":"img_bgr: np.array = cv2.imread('../input/image-matching-challenge-2022/train/taj_mahal/images/05106170_2123793679.jpg')  # HxWxC / np.uint8\nimg_rgb: np.array = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb); plt.axis('off');","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:24:31.928827Z","iopub.execute_input":"2022-04-09T00:24:31.929202Z","iopub.status.idle":"2022-04-09T00:24:32.260949Z","shell.execute_reply.started":"2022-04-09T00:24:31.929165Z","shell.execute_reply":"2022-04-09T00:24:32.259994Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load an image with Torchvision\n\nIt returns the images in a torch.Tensor in the shape (C,H,W).","metadata":{}},{"cell_type":"code","source":"x_rgb: torch.tensor = torchvision.io.read_image('../input/image-matching-challenge-2022/train/taj_mahal/images/05106170_2123793679.jpg')  # CxHxW / torch.uint8\nx_rgb = x_rgb.unsqueeze(0)  # BxCxHxW\nprint(x_rgb.shape);","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:26:09.622768Z","iopub.execute_input":"2022-04-09T00:26:09.623166Z","iopub.status.idle":"2022-04-09T00:26:09.66089Z","shell.execute_reply.started":"2022-04-09T00:26:09.62313Z","shell.execute_reply":"2022-04-09T00:26:09.660083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load an image with Kornia\n\n\"The utility is kornia.image_to_tensor which casts a numpy.ndarray to a torch.Tensor and permutes the channels to leave the image ready for being used with any other PyTorch or Kornia component. The image is casted into a 4D torch.Tensor with zero-copy.\"\n\nhttps://kornia-tutorials.readthedocs.io/en/latest/hello_world_tutorial.html","metadata":{}},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/hello_world_tutorial.html\n\nx_bgr: torch.tensor = K.image_to_tensor(img_bgr)  # CxHxW / torch.uint8\nx_bgr = x_bgr.unsqueeze(0)  # 1xCxHxW\nprint(f\"convert from '{img_bgr.shape}' to '{x_bgr.shape}'\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:26:54.798684Z","iopub.execute_input":"2022-04-09T00:26:54.799011Z","iopub.status.idle":"2022-04-09T00:26:54.808399Z","shell.execute_reply.started":"2022-04-09T00:26:54.798975Z","shell.execute_reply":"2022-04-09T00:26:54.807411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Convert from BGR to RGB with a kornia.color component.","metadata":{}},{"cell_type":"code","source":"x_rgb: torch.tensor = K.color.bgr_to_rgb(x_bgr)  # 1xCxHxW / torch.uint8","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:27:43.973843Z","iopub.execute_input":"2022-04-09T00:27:43.974166Z","iopub.status.idle":"2022-04-09T00:27:43.987573Z","shell.execute_reply.started":"2022-04-09T00:27:43.974133Z","shell.execute_reply":"2022-04-09T00:27:43.98677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Visualize an image with Matplotib","metadata":{}},{"cell_type":"code","source":"img_bgr: np.array = K.tensor_to_image(x_bgr)\nimg_rgb: np.array = K.tensor_to_image(x_rgb)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:28:19.333285Z","iopub.execute_input":"2022-04-09T00:28:19.333621Z","iopub.status.idle":"2022-04-09T00:28:19.341785Z","shell.execute_reply.started":"2022-04-09T00:28:19.333586Z","shell.execute_reply":"2022-04-09T00:28:19.340876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/hello_world_tutorial.html\n\nfig, axs = plt.subplots(1, 2, figsize=(32, 16))\naxs = axs.ravel()\n\naxs[0].axis('off')\naxs[0].imshow(img_rgb)\n\naxs[1].axis('off')\naxs[1].imshow(img_bgr)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:29:01.250886Z","iopub.execute_input":"2022-04-09T00:29:01.251239Z","iopub.status.idle":"2022-04-09T00:29:02.318691Z","shell.execute_reply.started":"2022-04-09T00:29:01.251203Z","shell.execute_reply":"2022-04-09T00:29:02.317582Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Let's take a shot with T≈çdai-ji (Temple in Nara)","metadata":{}},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/hello_world_tutorial.html\n\nimg_bgr1: np.array = cv2.imread('../input/image-matching-challenge-2022/train/temple_nara_japan/images/07628787_6482156727.jpg')  # HxWxC / np.uint8\nimg_rgb1: np.array = cv2.cvtColor(img_bgr1, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img_rgb1); plt.axis('off');","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:31:38.190084Z","iopub.execute_input":"2022-04-09T00:31:38.190407Z","iopub.status.idle":"2022-04-09T00:31:38.486132Z","shell.execute_reply.started":"2022-04-09T00:31:38.190374Z","shell.execute_reply":"2022-04-09T00:31:38.485292Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/hello_world_tutorial.html\n\nx_bgr1: torch.tensor = K.image_to_tensor(img_bgr1)  # CxHxW / torch.uint8\nx_bgr1 = x_bgr1.unsqueeze(0)  # 1xCxHxW\nprint(f\"convert from '{img_bgr1.shape}' to '{x_bgr1.shape}'\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:32:33.026124Z","iopub.execute_input":"2022-04-09T00:32:33.02648Z","iopub.status.idle":"2022-04-09T00:32:33.03446Z","shell.execute_reply.started":"2022-04-09T00:32:33.026439Z","shell.execute_reply":"2022-04-09T00:32:33.033333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert from BGR to RGB with a kornia.color component.\n\nx_rgb1: torch.tensor = K.color.bgr_to_rgb(x_bgr1)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:35:37.715712Z","iopub.execute_input":"2022-04-09T00:35:37.716098Z","iopub.status.idle":"2022-04-09T00:35:37.724711Z","shell.execute_reply.started":"2022-04-09T00:35:37.716062Z","shell.execute_reply":"2022-04-09T00:35:37.723597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize an image with Matplotib\n\nimg_bgr1: np.array = K.tensor_to_image(x_bgr1)\nimg_rgb1: np.array = K.tensor_to_image(x_rgb1)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:35:52.148082Z","iopub.execute_input":"2022-04-09T00:35:52.148392Z","iopub.status.idle":"2022-04-09T00:35:52.153593Z","shell.execute_reply.started":"2022-04-09T00:35:52.148361Z","shell.execute_reply":"2022-04-09T00:35:52.152888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/hello_world_tutorial.html\n\nfig, axs = plt.subplots(1, 2, figsize=(32, 16))\naxs = axs.ravel()\n\naxs[0].axis('off')\naxs[0].imshow(img_rgb1)\n\naxs[1].axis('off')\naxs[1].imshow(img_bgr1)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:36:12.12873Z","iopub.execute_input":"2022-04-09T00:36:12.129469Z","iopub.status.idle":"2022-04-09T00:36:13.351529Z","shell.execute_reply.started":"2022-04-09T00:36:12.129419Z","shell.execute_reply":"2022-04-09T00:36:13.349965Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/data_augmentation_sequential.html\n\nfrom kornia import augmentation as K\nfrom kornia.augmentation import AugmentationSequential\nfrom kornia.geometry import bbox_to_mask\nfrom kornia.utils import image_to_tensor, tensor_to_image\nfrom torchvision.transforms import transforms\n\nto_tensor = transforms.ToTensor()\nto_pil = transforms.ToPILImage()\n\ndef plot_resulting_image(img, bbox, keypoints, mask):\n    img = img * mask\n    img_draw = cv2.polylines(np.array(to_pil(img)), bbox.numpy(), isClosed=True, color=(255, 0, 0))\n    for k in keypoints[0]:\n        img_draw = cv2.circle(img_draw, tuple(k.numpy()[:2]), radius=6, color=(255, 0, 0), thickness=-1)\n    return img_draw\n\nimg = cv2.imread(\"../input/image-matching-challenge-2022/train/piazza_san_marco/images/07961084_7175726083.jpg\", cv2.IMREAD_COLOR)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nh, w = img.shape[:2]\n\nimg_tensor = image_to_tensor(img).float() / 255.\nplt.imshow(img); plt.axis('off');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-09T01:30:20.818783Z","iopub.execute_input":"2022-04-09T01:30:20.819137Z","iopub.status.idle":"2022-04-09T01:30:21.157402Z","shell.execute_reply.started":"2022-04-09T01:30:20.819102Z","shell.execute_reply":"2022-04-09T01:30:21.15642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Define Augmentation Sequential and Different Labels","metadata":{}},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/data_augmentation_sequential.html\n\naug_list = AugmentationSequential(\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1.0),\n    K.RandomAffine(360, [0.1, 0.1], [0.7, 1.2], [30., 50.], p=1.0),\n    K.RandomPerspective(0.5, p=1.0),\n    data_keys=[\"input\", \"bbox\", \"keypoints\", \"mask\"],\n    return_transform=False,\n    same_on_batch=False,\n)\n\nbbox = torch.tensor([[[355,10],[660,10],[660,250],[355,250]]])\nkeypoints = torch.tensor([[[465, 115], [545, 116]]])\nmask = bbox_to_mask(torch.tensor([[[155,0],[900,0],[900,400],[155,400]]]), w, h).float()\n\nimg_out = plot_resulting_image(img_tensor, bbox, keypoints, mask)\nplt.imshow(img_out); plt.axis('off');","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:48:02.689583Z","iopub.execute_input":"2022-04-09T00:48:02.690065Z","iopub.status.idle":"2022-04-09T00:48:03.083085Z","shell.execute_reply.started":"2022-04-09T00:48:02.690016Z","shell.execute_reply":"2022-04-09T00:48:03.081773Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Forward Computations","metadata":{}},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/data_augmentation_sequential.html\n\nout_tensor = aug_list(img_tensor, bbox.float(), keypoints.float(), mask)\nimg_out = plot_resulting_image(\n    out_tensor[0][0],\n    out_tensor[1].int(),\n    out_tensor[2].int(),\n    out_tensor[3][0],\n)\nplt.imshow(img_out); plt.axis('off');","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:49:46.967756Z","iopub.execute_input":"2022-04-09T00:49:46.968119Z","iopub.status.idle":"2022-04-09T00:49:47.901Z","shell.execute_reply.started":"2022-04-09T00:49:46.968084Z","shell.execute_reply":"2022-04-09T00:49:47.899977Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Inverse Transformations","metadata":{}},{"cell_type":"code","source":"out_tensor_inv = aug_list.inverse(*out_tensor)\nimg_out = plot_resulting_image(\n    out_tensor_inv[0][0],\n    out_tensor_inv[1].int(),\n    out_tensor_inv[2].int(),\n    out_tensor_inv[3][0],\n)\nplt.imshow(img_out); plt.axis('off');","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:51:40.117165Z","iopub.execute_input":"2022-04-09T00:51:40.117765Z","iopub.status.idle":"2022-04-09T00:51:40.596941Z","shell.execute_reply.started":"2022-04-09T00:51:40.117709Z","shell.execute_reply":"2022-04-09T00:51:40.595237Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Patch Augmentation Sequential with patchwise_apply=True\n\npatchwise_apply is a feature that used to define unique processing pipeline for each patch location. If patchwise_apply=True, the number of pipelines defined must be as same as the number of patches in an image.\n\nhttps://kornia-tutorials.readthedocs.io/en/latest/data_patch_sequential.html","metadata":{}},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/data_patch_sequential.html\n\nfrom kornia.augmentation import PatchSequential, ImageSequential\n\npseq = PatchSequential(\n    ImageSequential(\n        K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n        K.RandomPerspective(0.2, p=0.5),\n        K.RandomSolarize(0.1, 0.1, p=0.5),\n    ),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    K.RandomPerspective(0.2, p=0.5),\n    ImageSequential(\n        K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n        K.RandomPerspective(0.2, p=0.5),\n        K.RandomSolarize(0.1, 0.1, p=0.5),\n    ),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    K.RandomPerspective(0.2, p=0.5),\n    K.RandomSolarize(0.1, 0.1, p=0.5),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    ImageSequential(\n        K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n        K.RandomPerspective(0.2, p=0.5),\n        K.RandomSolarize(0.1, 0.1, p=0.5),\n    ),\n    K.RandomSolarize(0.1, 0.1, p=0.5),\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.5),\n    K.RandomAffine(15, [0.1, 0.1], [0.7, 1.2], [0., 20.], p=0.5),\n    K.RandomPerspective(0.2, p=0.5),\n    K.RandomSolarize(0.1, 0.1, p=0.5),\n    patchwise_apply=True,\n    same_on_batch=True,\n)\nout_tensor = pseq(img_tensor[None].repeat(2, 1, 1, 1))\nto_pil(torch.cat([out_tensor[0], out_tensor[1]], dim=2))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:54:03.098912Z","iopub.execute_input":"2022-04-09T00:54:03.099257Z","iopub.status.idle":"2022-04-09T00:54:03.840939Z","shell.execute_reply.started":"2022-04-09T00:54:03.099221Z","shell.execute_reply":"2022-04-09T00:54:03.840119Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Patch Augmentation Sequential rocks!","metadata":{}},{"cell_type":"markdown","source":"#Patch Augmentation Sequential with patchwise_apply=False\n\nIf patchwise_apply=False, all the args will be combined and applied as one pipeline for each patch.\n\nhttps://kornia-tutorials.readthedocs.io/en/latest/data_patch_sequential.html","metadata":{}},{"cell_type":"code","source":"#Code by https://kornia-tutorials.readthedocs.io/en/latest/data_patch_sequential.html\n\npseq = PatchSequential(\n    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=0.75),\n    K.RandomElasticTransform(alpha=(4., 4.)),\n    patchwise_apply=False,\n    same_on_batch=False\n)\nout_tensor = pseq(img_tensor[None].repeat(2, 1, 1, 1))\nto_pil(torch.cat([out_tensor[0], out_tensor[1]], dim=2))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T00:55:53.148025Z","iopub.execute_input":"2022-04-09T00:55:53.14838Z","iopub.status.idle":"2022-04-09T00:55:56.518646Z","shell.execute_reply.started":"2022-04-09T00:55:53.14834Z","shell.execute_reply":"2022-04-09T00:55:56.517265Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install kornia_moons","metadata":{"execution":{"iopub.status.busy":"2022-04-09T01:15:13.067351Z","iopub.execute_input":"2022-04-09T01:15:13.067721Z","iopub.status.idle":"2022-04-09T01:15:22.529271Z","shell.execute_reply.started":"2022-04-09T01:15:13.067687Z","shell.execute_reply":"2022-04-09T01:15:22.528339Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2\nimport torch\nimport kornia as K\nfrom typing import List\nimport matplotlib.pyplot as plt\n\nfrom kornia_moons.feature import *","metadata":{"execution":{"iopub.status.busy":"2022-04-09T01:18:31.176272Z","iopub.execute_input":"2022-04-09T01:18:31.176613Z","iopub.status.idle":"2022-04-09T01:18:31.186622Z","shell.execute_reply.started":"2022-04-09T01:18:31.176579Z","shell.execute_reply":"2022-04-09T01:18:31.18565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Aziz Amindzhanov  https://www.kaggle.com/code/azizdzhon/kornia-moons-imc-2022\n\nimg = cv2.cvtColor(cv2.imread('../input/image-matching-challenge-2022/train/taj_mahal/images/05106170_2123793679.jpg'), cv2.COLOR_BGR2RGB)\n\ndet = cv2.ORB_create(500)\nkps, descs = det.detectAndCompute(img, None)\n\nout_img = cv2.drawKeypoints(img, kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\nplt.imshow(out_img)\n\n\nlafs = laf_from_opencv_ORB_kpts(kps)\nvisualize_LAF(K.image_to_tensor(img, False), lafs, 0)\n\nkps_back = opencv_ORB_kpts_from_laf(lafs)\nout_img2 = cv2.drawKeypoints(img, kps_back, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\nplt.imshow(out_img2)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T01:18:36.022078Z","iopub.execute_input":"2022-04-09T01:18:36.022648Z","iopub.status.idle":"2022-04-09T01:18:37.518087Z","shell.execute_reply.started":"2022-04-09T01:18:36.022612Z","shell.execute_reply":"2022-04-09T01:18:37.51717Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Acknowledgements:\n\nKornia AI is on the mission to leverage and democratize the next generation of Computer Vision tools and Deep Learning libraries within the context of an Open Source community.\n\nhttps://kornia.readthedocs.io/en/latest/\n\nAziz Amindzhanov  https://www.kaggle.com/code/azizdzhon/kornia-moons-imc-2022","metadata":{}}]}