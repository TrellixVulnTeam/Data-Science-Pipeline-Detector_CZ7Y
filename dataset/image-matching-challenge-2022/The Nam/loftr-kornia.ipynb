{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls /kaggle/input/\n!pip install kornia --no-index --find-links=file:///kaggle/input/imc2022-dependencies/pip/kornia/ --upgrade \n!pip install kornia_moons --no-index --find-links=file:///kaggle/input/imc2022-dependencies/pip/kornia_moons/ --no-deps  --upgrade \nprint('Done!')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-12T15:38:29.874769Z","iopub.execute_input":"2022-04-12T15:38:29.875199Z","iopub.status.idle":"2022-04-12T15:38:42.428883Z","shell.execute_reply.started":"2022-04-12T15:38:29.875109Z","shell.execute_reply":"2022-04-12T15:38:42.428053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/loftrutils/einops-0.4.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:38:42.430951Z","iopub.execute_input":"2022-04-12T15:38:42.431891Z","iopub.status.idle":"2022-04-12T15:39:10.485303Z","shell.execute_reply.started":"2022-04-12T15:38:42.43185Z","shell.execute_reply":"2022-04-12T15:39:10.484393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/imutils/imutils-0.5.3/ /\n!pip install /imutils-0.5.3/","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:10.486932Z","iopub.execute_input":"2022-04-12T15:39:10.487232Z","iopub.status.idle":"2022-04-12T15:39:40.966013Z","shell.execute_reply.started":"2022-04-12T15:39:10.487192Z","shell.execute_reply":"2022-04-12T15:39:40.964693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/loftrutils/LoFTR-master/LoFTR-master/')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:40.968899Z","iopub.execute_input":"2022-04-12T15:39:40.969216Z","iopub.status.idle":"2022-04-12T15:39:40.97467Z","shell.execute_reply.started":"2022-04-12T15:39:40.969173Z","shell.execute_reply":"2022-04-12T15:39:40.97387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport kornia as K\nimport kornia.feature as KF\nfrom kornia.feature.loftr import LoFTR\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport glob\nimport random\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport matplotlib.cm as cm\n\nfrom kornia_moons.feature import *\n\n# from src.loftr import LoFTR, default_cfg\nfrom src.utils.plotting import make_matching_figure","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:40.975836Z","iopub.execute_input":"2022-04-12T15:39:40.976195Z","iopub.status.idle":"2022-04-12T15:39:43.08665Z","shell.execute_reply.started":"2022-04-12T15:39:40.976146Z","shell.execute_reply":"2022-04-12T15:39:43.085885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda:0'\nWEIGHT_PATH = '../input/loftrutils/outdoor_ds.ckpt'\n# LONGEST_EDGE = 1500","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:43.088207Z","iopub.execute_input":"2022-04-12T15:39:43.088766Z","iopub.status.idle":"2022-04-12T15:39:43.093538Z","shell.execute_reply.started":"2022-04-12T15:39:43.088727Z","shell.execute_reply":"2022-04-12T15:39:43.092095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matcher = LoFTR(pretrained=None)\nmatcher.load_state_dict(torch.load(WEIGHT_PATH)['state_dict'])\nmatcher = matcher.to(DEVICE)\nmatcher.eval()\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:43.095118Z","iopub.execute_input":"2022-04-12T15:39:43.095487Z","iopub.status.idle":"2022-04-12T15:39:46.939425Z","shell.execute_reply.started":"2022-04-12T15:39:43.095449Z","shell.execute_reply":"2022-04-12T15:39:46.937881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\nsrc = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:46.94094Z","iopub.execute_input":"2022-04-12T15:39:46.941204Z","iopub.status.idle":"2022-04-12T15:39:46.950663Z","shell.execute_reply.started":"2022-04-12T15:39:46.941167Z","shell.execute_reply":"2022-04-12T15:39:46.949918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(ims):\n    \n    fig, axes = plt.subplots(3, 3, figsize=(20,20))\n    \n    for idx, img in enumerate(ims):\n        i = idx % 3 \n        j = idx // 3 \n        image = Image.open(img)\n        image = image.resize((300,300))\n        axes[i, j].imshow(image)\n        axes[i, j].set_title(img.split('/')[-1])\n\n    plt.subplots_adjust(wspace=0, hspace=.2)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:39:46.953593Z","iopub.execute_input":"2022-04-12T15:39:46.955043Z","iopub.status.idle":"2022-04-12T15:39:46.963654Z","shell.execute_reply.started":"2022-04-12T15:39:46.95501Z","shell.execute_reply":"2022-04-12T15:39:46.962644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def load_image(fname, target_size=(640, 480)):\n#     img_raw = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n#     img_raw = cv2.resize(img_raw, target_size)\n#     return img_raw\n\n# def to_tensor(img_raw):\n#     img = torch.from_numpy(img_raw)[None][None].cuda() / 255.\n#     return img\n\nimport imutils\ndef resize_keep_ratio(img, longest_size=1500):\n    height, width = img.shape[:2]\n    if height >= width:\n        resized_img = imutils.resize(img, height=longest_size)\n    else:\n        resized_img = imutils.resize(img, width=longest_size)\n    return resized_img\n\ndef resize(img, target_size=(640,480)):\n    resized_img = cv2.resize(img, target_size)\n    return resized_img\n\ndef load_torch_image(fname):\n    img = cv2.imread(fname)\n#     img = resize_keep_ratio(img)\n#     img = cv2.resize(img, (img.shape[1]//8*8, img.shape[0]//8*8))  # input size should be divisible by 8\n    img = K.image_to_tensor(img, False).float() /255.\n    img = K.color.bgr_to_rgb(img)\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:03.893954Z","iopub.execute_input":"2022-04-12T15:40:03.89422Z","iopub.status.idle":"2022-04-12T15:40:03.901922Z","shell.execute_reply.started":"2022-04-12T15:40:03.89419Z","shell.execute_reply":"2022-04-12T15:40:03.90118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def match(img_path0, img_path1, matcher, device=DEVICE):\n    img0 = load_torch_image(img_path0)\n    img1 = load_torch_image(img_path1)\n        \n    input_dict = {\"image0\": K.color.rgb_to_grayscale(img0).to(device), \n                  \"image1\": K.color.rgb_to_grayscale(img1).to(device)}\n    \n    with torch.no_grad():\n        correspondences = matcher(input_dict)\n        \n    mkpts0 = correspondences['keypoints0'].cpu().numpy()\n    mkpts1 = correspondences['keypoints1'].cpu().numpy()\n        \n    return mkpts0, mkpts1\n        \ndef get_F_matrix(mkpts0, mkpts1):\n\n    # Make sure we do not trigger an exception here.\n    if len(mkpts0) > 8:\n        F, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.5, 0.999, 100000)\n\n        assert F.shape == (3, 3), 'Malformed F?'\n    else:\n        F = np.zeros((3, 3))\n\n    return F","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:04.933777Z","iopub.execute_input":"2022-04-12T15:40:04.934288Z","iopub.status.idle":"2022-04-12T15:40:04.945306Z","shell.execute_reply.started":"2022-04-12T15:40:04.934227Z","shell.execute_reply":"2022-04-12T15:40:04.944562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def match_and_draw(img_path0, img_path1, matcher, device=DEVICE, drop_outliers=False):\n    \n    img0 = load_torch_image(img_path0)\n    img1 = load_torch_image(img_path1)\n    \n    print(img0.shape, img1.shape)\n    \n    input_dict = {\"image0\": K.color.rgb_to_grayscale(img0).to(device), \n                  \"image1\": K.color.rgb_to_grayscale(img1).to(device)}\n    \n    with torch.no_grad():\n        correspondences = matcher(input_dict)\n        \n    mkpts0 = correspondences['keypoints0'].cpu().numpy()\n    mkpts1 = correspondences['keypoints1'].cpu().numpy()\n    \n    if len(mkpts0) > 8:\n        F, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.5, 0.999, 100000)\n\n        assert F.shape == (3, 3), 'Malformed F?'\n    else:\n        F = np.zeros((3, 3))\n            \n    if drop_outliers:\n        print(len(mkpts0))\n        mkpts0 = mkpts0[inliers.reshape(-1) > 0]\n        mkpts1 = mkpts1[inliers.reshape(-1) > 0]\n        inliers = inliers[inliers > 0]\n    \n        print(len(mkpts0))\n    \n    draw_LAF_matches(\n        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n                                    torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n                                    torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n\n        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n        torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n        K.tensor_to_image(img0),\n        K.tensor_to_image(img1),\n        inliers,\n        draw_dict={'inlier_color': (0.2, 1, 0.2),\n                   'tentative_color': None, \n                   'feature_color': (0.2, 0.5, 1), 'vertical': False})\n    \n    del correspondences, input_dict\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:05.377893Z","iopub.execute_input":"2022-04-12T15:40:05.378161Z","iopub.status.idle":"2022-04-12T15:40:05.392592Z","shell.execute_reply.started":"2022-04-12T15:40:05.378131Z","shell.execute_reply":"2022-04-12T15:40:05.390843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_matching(samples, files):\n    for i in range(samples.shape[1]):\n        path0 = files[samples[0][i]]\n        path1 = files[samples[1][i]]\n        print(f'Matching: {path0} to {path1}')\n        match_and_draw(path0, path1, matcher)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:05.795064Z","iopub.execute_input":"2022-04-12T15:40:05.795808Z","iopub.status.idle":"2022-04-12T15:40:05.801102Z","shell.execute_reply.started":"2022-04-12T15:40:05.795764Z","shell.execute_reply":"2022-04-12T15:40:05.800169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint('Ploting on sample test set')\nfor i, row in tqdm(enumerate(test_samples), total=len(test_samples)):\n    print(i)\n    sample_id, batch_id, image_0_id, image_1_id = row\n    img_path0 = f'{src}/test_images/{batch_id}/{image_0_id}.png'\n    img_path1 = f'{src}/test_images/{batch_id}/{image_1_id}.png'\n    match_and_draw(img_path0, img_path1, matcher)    \n    \n    if i >= 3:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:06.123288Z","iopub.execute_input":"2022-04-12T15:40:06.123995Z","iopub.status.idle":"2022-04-12T15:40:21.635805Z","shell.execute_reply.started":"2022-04-12T15:40:06.123953Z","shell.execute_reply":"2022-04-12T15:40:21.635138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run submission","metadata":{}},{"cell_type":"code","source":"%%time\nF_dict = {}\nfor i, row in tqdm(enumerate(test_samples), total=len(test_samples)):\n    sample_id, batch_id, image_0_id, image_1_id = row\n    img_path0 = f'{src}/test_images/{batch_id}/{image_0_id}.png'\n    img_path1 = f'{src}/test_images/{batch_id}/{image_1_id}.png'\n    mkpts0, mkpts1 = match(img_path0, img_path1, matcher)\n    F_dict[sample_id] = get_F_matrix(mkpts0, mkpts1)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:21.637194Z","iopub.execute_input":"2022-04-12T15:40:21.638409Z","iopub.status.idle":"2022-04-12T15:40:24.467588Z","shell.execute_reply.started":"2022-04-12T15:40:21.638363Z","shell.execute_reply":"2022-04-12T15:40:24.466859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FlattenMatrix(M, num_digits=8):\n    '''Convenience function to write CSV files.'''\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:24.468897Z","iopub.execute_input":"2022-04-12T15:40:24.469318Z","iopub.status.idle":"2022-04-12T15:40:24.479363Z","shell.execute_reply.started":"2022-04-12T15:40:24.46928Z","shell.execute_reply":"2022-04-12T15:40:24.477637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:24.481839Z","iopub.execute_input":"2022-04-12T15:40:24.482192Z","iopub.status.idle":"2022-04-12T15:40:24.494014Z","shell.execute_reply.started":"2022-04-12T15:40:24.482094Z","shell.execute_reply":"2022-04-12T15:40:24.493157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:40:24.496315Z","iopub.execute_input":"2022-04-12T15:40:24.498666Z","iopub.status.idle":"2022-04-12T15:40:24.524242Z","shell.execute_reply.started":"2022-04-12T15:40:24.498622Z","shell.execute_reply":"2022-04-12T15:40:24.523323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}