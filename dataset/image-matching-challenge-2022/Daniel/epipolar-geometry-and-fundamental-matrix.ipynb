{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Matching Challenge 2022\n\n## Epipolar Geometry and Fundamental Matrix\n\nIn this notebook we will look at the coherence between the Epipolar Geometry of a stereo camera and the given Fundamental Matrix. This should illustrate the understanding of the task. We are going to visualize the Epipolar Lines to simplify the correspondance problem of two pictures with different point of views.","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-18T09:07:07.606132Z","iopub.execute_input":"2022-04-18T09:07:07.606493Z","iopub.status.idle":"2022-04-18T09:07:08.020223Z","shell.execute_reply.started":"2022-04-18T09:07:07.60639Z","shell.execute_reply":"2022-04-18T09:07:08.019282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# root directory for image matching challenge\n\nROOT = '../input/image-matching-challenge-2022/'\n\n# generate a list with all scenes showed in the dataset\n\nscenes = os.listdir(ROOT+'train')\nscenes.remove('LICENSE.txt')\nscenes.remove('scaling_factors.csv')\n\n# scaling factory for the scenes\n\nsf = pd.read_csv(ROOT+'train/scaling_factors.csv')\n\ndf = pd.DataFrame()\nfor scene in scenes:\n    \n    # load calibration data and assign the corresponding scaling factors and scenes\n    \n    scene_df = pd.read_csv(ROOT+'train/'+scene+'/calibration.csv')\n    scene_df['scaling_factor'] = sf[sf.scene==scene].values[0][1]\n    scene_df['scene'] = scene\n    \n    # generate the complete image path\n    \n    scene_df['image_path'] = ROOT+'train/'+scene+'/images/'+scene_df['image_id']+'.jpg'\n    \n    df = df.append(scene_df, ignore_index=True)\n    \n# load all pair_covisibility.csv files\n# with this DataFrame we can look at the different\n# pairs and can access the fundamental matrix\n\npairs = pd.DataFrame()\nfor scene in scenes:\n    scene_df = pd.read_csv(ROOT+'train/'+scene+'/pair_covisibility.csv')\n    scene_df['scene'] = scene\n    pairs = pairs.append(scene_df, ignore_index=True)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T09:07:09.891224Z","iopub.execute_input":"2022-04-18T09:07:09.891703Z","iopub.status.idle":"2022-04-18T09:07:18.311357Z","shell.execute_reply.started":"2022-04-18T09:07:09.891651Z","shell.execute_reply":"2022-04-18T09:07:18.310347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot an example image\n\nLet's look at an example image. The picture shows the Brandenburg Gate in Berlin, Germany. The images were taken from two different angles and different distances, but they show the same object.","metadata":{}},{"cell_type":"code","source":"# IMAGE PLOTTING FUNCTIONS\n\n# extract image file from dataset DataFrame\ndef read_img(image_name):\n    pth = df.image_path[df.image_id==image_name].values[0]\n    img = cv2.imread(pth)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n# plot two images side by side\ndef plot_image_pair(img1, img2):\n    fig, axs = plt.subplots(1, 2, figsize=(20,10))\n    axs[0].imshow(img1)\n    axs[1].imshow(img2)\n    axs[0].axis('off'); axs[1].axis('off')\n    \n# PLOT THE EXAMPLE PICTURE\nsmpl = pairs.loc[1383416]\nimgs = smpl.pair.split('-')\nimg1 = read_img(imgs[0])\nimg2 = read_img(imgs[1])\nplot_image_pair(img1, img2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T09:07:18.312997Z","iopub.execute_input":"2022-04-18T09:07:18.313518Z","iopub.status.idle":"2022-04-18T09:07:19.498396Z","shell.execute_reply.started":"2022-04-18T09:07:18.313484Z","shell.execute_reply":"2022-04-18T09:07:19.497584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fundamental Matrix\n\nThe fundamental matrix $F$ of the image pair is given and describes the geometric relation of the two images. The two different viewing angles create a stereo camera perspective, which makes a three-dimensional view possible.\n\nLet's have a first look at the matrix. The matrix is a 3x3 dimensional array and describes the relationship between perspective 1 and 2 in the form shown.","metadata":{}},{"cell_type":"code","source":"np.set_printoptions(precision=3, suppress=True)\ndef string_to_matrix(s):\n    s = s.split(' ')\n    s = list(map(float, s))\n    return np.array(s).reshape(3,3)\n\nF = string_to_matrix(smpl.fundamental_matrix)\nprint(F)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T09:07:19.500568Z","iopub.execute_input":"2022-04-18T09:07:19.501484Z","iopub.status.idle":"2022-04-18T09:07:19.511441Z","shell.execute_reply.started":"2022-04-18T09:07:19.501425Z","shell.execute_reply":"2022-04-18T09:07:19.510099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calibration Matrix\n\nThe calibration matrices (```camera_intrinsics```) of the cameras are also given and include the intrinsic parameters. They are an important part of the geometric relationship.","metadata":{}},{"cell_type":"code","source":"K1 = df.camera_intrinsics[df.image_id==imgs[0]].values[0]\nK1 = string_to_matrix(K1)\nprint(K1)\n\nK2 = df.camera_intrinsics[df.image_id==imgs[1]].values[0]\nK2 = string_to_matrix(K2)\nprint(K2)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T09:07:28.271837Z","iopub.execute_input":"2022-04-18T09:07:28.272136Z","iopub.status.idle":"2022-04-18T09:07:28.281111Z","shell.execute_reply.started":"2022-04-18T09:07:28.2721Z","shell.execute_reply":"2022-04-18T09:07:28.2805Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Essential Matrix\n\nWith the given fundamental matrix $F$ and the calibration matrices $K$ of the individual cameras, the essential matrix $E$ can be calculated. This is also suitable for describing the perspective relationships. \n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#E4E4E4;\n           font-size:100%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              text-align:center;\n              color:black;\">\n            $E=(K_1)^T \\cdot F \\cdot K_2$\n        </p>\n    </div>","metadata":{}},{"cell_type":"code","source":"E = K1.transpose() * F * K2\nprint(E)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T09:07:31.357555Z","iopub.execute_input":"2022-04-18T09:07:31.358309Z","iopub.status.idle":"2022-04-18T09:07:31.363972Z","shell.execute_reply.started":"2022-04-18T09:07:31.358264Z","shell.execute_reply":"2022-04-18T09:07:31.362991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Epipolar Lines\n\nThe relationship between two images that show the same object from different angles can be described using epipolar geometry. \n\nA main topic of image recognition is the solution of the correspondence problem. This deals with the matching of a point seen on both images of a stereo camera. A pixel on the left image must be matched with the corresponding pixel on the right image. \n\nWith the fundamental matrix it is possible to simplify the correspondence problem. We can use it to calculate the epipolar line on the right image from one pixel of the left image. The point we are looking for lies on this line. With this Calculation, the problem could be changed from a 2D image to a 1D line and simplifies the matching considerably.\n\nCalculate the line with a matrix multiplication of the fundamental matrix and the point on the other image:\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#E4E4E4;\n           font-size:100%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              text-align:center;\n              color:black;\">\n            $L = F \\cdot p$\n        </p>\n    </div>","metadata":{}},{"cell_type":"code","source":"# point on first (left) image with the pixel coordinates\npoint = np.array([523, 235, 1])\n\n# calculate the line on the second (right) image\nline = F @ point\nline = line.reshape(-1, 3)\nprint(line[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T09:07:34.355042Z","iopub.execute_input":"2022-04-18T09:07:34.355581Z","iopub.status.idle":"2022-04-18T09:07:34.361943Z","shell.execute_reply.started":"2022-04-18T09:07:34.355541Z","shell.execute_reply":"2022-04-18T09:07:34.361319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1st image\nimg1 = cv2.circle(img1, point[:2], 10, (255,0,0), -1)\n\n# 2nd image\ndef draw_lines(img, line):\n    for i,l in enumerate(line):\n        p1 = np.array([0, (-l[2]/l[1])], dtype=np.int32)\n        p2 = np.array([img.shape[1], (-l[0]/l[1])*img.shape[1]+(-l[2]/l[1])], dtype=np.int32)\n        img = cv2.line(img, tuple(p1), tuple(p2), (255,0,0), 3)\n    return img\n\nimg2 = draw_lines(img2, line)\nplot_image_pair(img1, img2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T09:08:02.65933Z","iopub.execute_input":"2022-04-18T09:08:02.660407Z","iopub.status.idle":"2022-04-18T09:08:03.351482Z","shell.execute_reply.started":"2022-04-18T09:08:02.660363Z","shell.execute_reply":"2022-04-18T09:08:03.35059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see in the image, the line in the right image passes through the corresponding point. To solve the correspondence problem, only the line must now be searched for the target point instead of each individual pixel in the whole image.","metadata":{}}]}