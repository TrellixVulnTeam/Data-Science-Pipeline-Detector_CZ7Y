{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"pixyz  \nlast update 2022 04 11  \nゆっくりしていってね！  ","metadata":{"id":"3aM8dNjwKVmY"}},{"cell_type":"markdown","source":"# Trends\n## add test\nIMC 2022 ammarali32's add test  \nhttps://www.kaggle.com/code/lunapandachan/imc-2022-ammarali32-s-add-test","metadata":{}},{"cell_type":"markdown","source":"# Data list\n* [**train**](#train)\n    * [**images**](#images)\n    * [**calibration.csv**](#calibration.csv)\n    * [**pair_convisibility.csv**](#pair_convisibility.csv)\n* [**test**](#test)\n    * [**test.csv**](#test.csv)\n    * [**test_images**](#test_images)\n* [**sample_submission.csv**](#sample_submission.csv)    ","metadata":{}},{"cell_type":"markdown","source":"# Overview","metadata":{}},{"cell_type":"markdown","source":"**霊夢：今日も画像のコンペだね。**\n\n**魔理沙：まずは概要を読んでみよう。**\n\n**Reimu: It's an image competition today as well.**\n\n**Marisa: Let's read the overview first.**","metadata":{"id":"PgIt2tfOKYvb"}},{"cell_type":"markdown","source":"For most of us, our best camera is part of the phone in our pocket. We may take a snap of a landmark, like the Trevi Fountain in Rome, and share it with friends. By itself, that photo is two-dimensional and only includes the perspective of our shooting location. Of course, a lot of people have taken photos of that fountain. Together, we may be able to create a more complete, three-dimensional view. What if machine learning could help better capture the richness of the world using the vast amounts of unstructured image collections freely available on the internet?\n\nThe process to reconstruct 3D objects and buildings from images is called Structure-from-Motion (SfM). Typically, these images are captured by skilled operators under controlled conditions, ensuring homogeneous, high-quality data. It is much more difficult to build 3D models from assorted images, given a wide variety of viewpoints, lighting and weather conditions, occlusions from people and vehicles, and even user-applied filters.\n\nThe first part of the problem is to identify which parts of two images capture the same physical points of a scene, such as the corners of a window. This is typically achieved with local features (key locations in an image that can be reliably identified across different views). Local features contain short description vectors that capture the appearance around the point of interest. By comparing these descriptors, likely correspondences can be established between the pixel coordinates of image locations across two or more images. This “image registration” makes it possible to recover the 3D location of the point by triangulation.\n\nGoogle employs Structure-from-Motion techniques across many Google Maps services, such as the 3D models created from StreetView and aerial imagery. In order to accelerate research into this topic, and better leverage the volume of data already publicly available, Google presents this competition in collaboration with the University of British Columbia and Czech Technical University.\n\nIn this code competition, you’ll create a machine learning algorithm that registers two images from different viewpoints. With access to a dataset of thousands of images to train and test your model, top-scoring notebooks will do so with the most accuracy.\n\nIf successful, you'll help solve this well-known problem in computer vision, making it possible to map the world with unstructured image collections. Your solutions will have applications in photography and cultural heritage preservation, along with Google Maps. Winners will also be invited to give a presentation as part of the Image Matching: Local Features and Beyond workshop at the Conference on Computer Vision and Pattern Recognition (CVPR) in June.\n\n私たちのほとんどにとって、私たちの最高のカメラは私たちのポケットの中の電話の一部です。ローマのトレビの泉のようなランドマークを撮って、友達と共有することもできます。その写真自体は2次元であり、撮影場所の視点のみが含まれています。もちろん、多くの人がその噴水の写真を撮りました。一緒に、より完全な3次元ビューを作成できる場合があります。機械学習が、インターネット上で無料で入手できる膨大な量の非構造化画像コレクションを使用して、世界の豊かさをよりよく捉えるのに役立つとしたらどうでしょうか。\n\n画像から3Dオブジェクトと建物を再構築するプロセスは、Structure-from-Motion（SfM）と呼ばれます。通常、これらの画像は、管理された条件下で熟練したオペレーターによってキャプチャされ、均質で高品質のデータを保証します。さまざまな視点、照明や気象条件、人や車からのオクルージョン、さらにはユーザーが適用したフィルターを考えると、さまざまな画像から3Dモデルを構築することははるかに困難です。\n\n問題の最初の部分は、2つの画像のどちらの部分が、窓の角など、シーンの同じ物理的なポイントをキャプチャするかを特定することです。これは通常、ローカル機能（さまざまなビューで確実に識別できる画像内の主要な場所）を使用して実現されます。ローカルフィーチャには、関心のあるポイントの周囲の外観をキャプチャする短い説明ベクトルが含まれています。これらの記述子を比較することにより、2つ以上の画像にわたる画像位置のピクセル座標間におそらく対応を確立することができます。この「画像レジストレーション」により、三角測量によりポイントの3D位置を復元することができます。\n\nGoogleは、ストリートビューや航空写真から作成された3Dモデルなど、多くのGoogleマップサービスでStructure-from-Motion技術を採用しています。このトピックの研究を加速し、すでに公開されているデータの量をより有効に活用するために、Googleはブリティッシュコロンビア大学とチェコ工科大学と共同でこのコンテストを開催します。\n\nこのコードコンテストでは、異なる視点から2つの画像を登録する機械学習アルゴリズムを作成します。モデルをトレーニングおよびテストするための何千もの画像のデータセットにアクセスできるため、最高スコアのノートブックは最も正確にそれを実行します。\n\n成功すれば、コンピュータビジョンでよく知られているこの問題の解決に役立ち、非構造化画像コレクションを使用して世界をマッピングできるようになります。あなたのソリューションは、Googleマップとともに、写真や文化遺産の保存に応用できます。受賞者は、6月に開催されるコンピュータービジョンとパターン認識（CVPR）の会議で、画像マッチング：ローカル機能とその先のワークショップの一環としてプレゼンテーションを行うこともできます。\n\n![https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/trevi-canvas-licensed-nonoderivs.jpg](https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/trevi-canvas-licensed-nonoderivs.jpg)\n\n![https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/image3.gif](https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/image3.gif)","metadata":{"id":"qqlnWh3yKZ-R"}},{"cell_type":"markdown","source":"このコンペは、画像処理の中でも特殊なコンペです。このコンペの目的は、2つの画像間の相対的なポーズを推定することです。","metadata":{}},{"cell_type":"markdown","source":"**霊夢:同じ建物の写真同士を比較するコンペだね、難しそう..**\n\n**魔理沙：次はデータを見てみよう！**\n\n**Reimu: It's a competition to compare photos of the same building, it seems difficult ..**\n\n**Marisa: Let's take a look at the data next!**\n\n<img src=\"https://4.bp.blogspot.com/-uoVuBWIbdiA/WvQHqpx_YCI/AAAAAAABL8g/NiFZ6K71VBc_0_dcKb3_4nhnvFJ_JMNuACLcBGAs/s450/network_dennou_sekai_figure.png\" width=200>","metadata":{"id":"8eZi9TNGKdl3"}},{"cell_type":"markdown","source":"# train","metadata":{}},{"cell_type":"markdown","source":"ENG\n\ntrain/*/calibration.csv\n\n* image_id: The image filename.\n\n* camera_intrinsics: The 3×3 calibration matrix K for this image, flattened into a vector by row-major indexing.\n\n* rotation_matrix: The 3×3 rotation matrix R for this image, flattened into a vector by row-major indexing.\n\n* translation_vector: The translation vector T.\n\ntrain/*/pair_covisibility.csv\n\n* pair: A string identifying a pair of images, encoded as two image filenames (without the extension) separated by a hyphen, as key1-key2, where key1 > key2.\n\n* covisibility: An estimate of the overlap between the two images. Higher numbers indicate greater overlap. We recommend using all pairs with a covisibility estimate of 0.1 or above. The procedure used to derive this number is described in Section 3.2 and Figure 5 of this paper.\n\n* fundamental_matrix: The target column as derived from the calibration files. Please see [the problem definition page](https://www.kaggle.com/competitions/image-matching-challenge-2022/overview/problem-definition) for more details.\n\ntrain/scaling_factors.csv The poses for each scene where reconstructed via [Structure-from-Motion](https://en.wikipedia.org/wiki/Structure_from_motion), and are only accurate up to a scaling factor. This file contains a scalar for each scene which can be used to convert them to meters. For code examples, please refer to this notebook.\n\ntrain/*/images/ A batch of images all taken near the same location.\n\ntrain/LICENSE.txt Records of the specific source of and license for each image.\n\n日本語\ntrain/*/calibration.csv\n\n* image_id：画像のファイル名。\n\n* camera_intrinsics：キャリブレーションマトリックスこの画像の場合、行メジャーインデックスによってベクトルにフラット化されます。\n\n* rotation_matrix：回転行列この画像の場合、行メジャーインデックスによってベクトルにフラット化されます。\n\n* translation_vector：翻訳ベクトル。\n\ntrain/*/pair_covisibility.csv\n\n* pair：ハイフンで区切られた2つの画像ファイル名（拡張子なし）としてエンコードされた画像のペアを識別する文字列。key1-key2ここで、key1> key2。\n\n* covisibility：2つの画像間のオーバーラップの推定。数値が大きいほど、オーバーラップが大きいことを示します。共可視性の推定値が0.1以上のすべてのペアを使用することをお勧めします。この数を導き出すために使用される手順は、このペーパーのセクション3.2および図5で説明されています。\n\n* fundamental_matrix：キャリブレーションファイルから得られたターゲットカラム。詳細については、[問題定義のページ](https://www.kaggle.com/competitions/image-matching-challenge-2022/overview/problem-definition)を参照してください。\n\ntrain/scaling_factors.csvStructure -from-Motionを介して再構築された各シーンのポーズ。正確なのはスケーリング係数までです。このファイルには、シーンをメートルに変換するために使用できる各シーンのスカラーが含まれています。コード例については、このノートブックを参照してください。\n\ntrain / * /images/すべて同じ場所の近くで撮影された画像のバッチ。\n\ntrain/LICENSE.txt各画像の特定のソースとライセンスの記録。","metadata":{"id":"Q2U_WmKrKxA0"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom os import listdir\nimport os\nimport cv2\nimport glob\nimport random","metadata":{"id":"gjVvKrXcKs1o","execution":{"iopub.status.busy":"2022-04-21T12:06:20.188658Z","iopub.execute_input":"2022-04-21T12:06:20.189521Z","iopub.status.idle":"2022-04-21T12:06:20.585768Z","shell.execute_reply.started":"2022-04-21T12:06:20.189312Z","shell.execute_reply":"2022-04-21T12:06:20.584949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:trainフォルダの中に、16個の建物の名前のフォルダが入ってるな。**\n\n**霊夢:その建物名のフォルダの中には、画像が入ったimagesフォルダ、calibration.csv,pair_convisibility.csvが入ってるよ。**\n\n**魔理沙:ひとつひとつ見ていこうか、まずは適当に画像を表示させてみよう！**\n\n**Marisa: Inside the train folder, there are folders with the names of 16 buildings.**\n\n**Reimu: In the folder with the building name, there is an images folder containing images, calibration.csv, pair_convisibility.csv.**\n\n**Marisa: Let's take a look at each one, or let's display the images appropriately!**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://3.bp.blogspot.com/-3q31Kj8zFHc/V6BP6vEGe1I/AAAAAAAA83s/YD0NZlG5wmgMiB_iX9QMDy8KF2IEid6qQCLcB/s450/figure_korobu.png\" width=\"100\">","metadata":{"id":"Zh46yWyzQZLX"}},{"cell_type":"markdown","source":"## images","metadata":{}},{"cell_type":"code","source":"def getImagePaths(pathes):\n\n    image_names = []\n    for path in pathes:\n        for dirname, _, filenames in os.walk(path):\n            for filename in filenames:\n                fullpath = os.path.join(dirname, filename)\n                image_names.append(fullpath)\n    random.shuffle(image_names)\n    return image_names\n\ndef display_multiple_img(images_paths, rows, cols):\n\n    figure, ax = plt.subplots(nrows=rows,ncols=cols,figsize=(16,8) )\n    for ind,image_path in enumerate(images_paths):\n        image=cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n        try:\n            ax.ravel()[ind].imshow(image)\n            ax.ravel()[ind].set_axis_off()\n        except:\n            continue;\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:20.589264Z","iopub.execute_input":"2022-04-21T12:06:20.589534Z","iopub.status.idle":"2022-04-21T12:06:20.596992Z","shell.execute_reply.started":"2022-04-21T12:06:20.589495Z","shell.execute_reply":"2022-04-21T12:06:20.596251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_dirs = glob.glob('../input/image-matching-challenge-2022/train/*/images')\nimages_path = getImagePaths(images_dirs)\ndisplay_multiple_img(images_path[0:16], 4,4)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:20.598429Z","iopub.execute_input":"2022-04-21T12:06:20.598766Z","iopub.status.idle":"2022-04-21T12:06:25.868657Z","shell.execute_reply.started":"2022-04-21T12:06:20.598738Z","shell.execute_reply":"2022-04-21T12:06:25.866758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:写真の真ん中にでっかく人が写ってる写真もあるのか！？**\n\n**霊夢:こっちの写真にも人が写ってるぞ！**\n\n**魔理沙:いや、それは銅像だ、ややこしいな。**\n\n**Marisa: Is there a big picture of a person in the middle of the picture? ??**\n\n**Reimu: You can see people in this picture too!**\n\n**Marisa: No, it's a statue, it's confusing.**\n\n<img src=\"https://4.bp.blogspot.com/-liGcpla15a0/V8VFFp4dPbI/AAAAAAAA9ZQ/jEosBaAAGvQPta9EgxeC8feKSY4Oqg3XQCLcB/s400/sekkouzou_mars.png\" width=200>","metadata":{}},{"cell_type":"markdown","source":"## calibration.csv","metadata":{}},{"cell_type":"markdown","source":"**魔理沙:次に、calibration.csvを見ていくぜ**\n\n**霊夢:例として、britich_museumのファイルを見ていくよ。**\n\n**Marisa: Next, let's take a look at calibration.csv**\n\n**Reimu: As an example, let's take a look at the britich_museum file.**","metadata":{}},{"cell_type":"code","source":"df_calibration = pd.read_csv(\"../input/image-matching-challenge-2022/train/british_museum/calibration.csv\")\ndf_calibration.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:25.870809Z","iopub.execute_input":"2022-04-21T12:06:25.871594Z","iopub.status.idle":"2022-04-21T12:06:25.902352Z","shell.execute_reply.started":"2022-04-21T12:06:25.871549Z","shell.execute_reply":"2022-04-21T12:06:25.901469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_calibration)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:25.903679Z","iopub.execute_input":"2022-04-21T12:06:25.904677Z","iopub.status.idle":"2022-04-21T12:06:25.911423Z","shell.execute_reply.started":"2022-04-21T12:06:25.904634Z","shell.execute_reply":"2022-04-21T12:06:25.910305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:image_idはそのまま写真のidだよね。他の3つのカラムは何を表しているのかな？**\n\n**魔理沙:rotation_matrixは3×3の行列で、カメラの姿勢を表す行列で、translation_vectorは、カメラの場所を表す行列のようだね。camera_intrinsicsは、この2つを合わせたような行列なのかな？**\n\n**Reimu: image_id is just the id of the photo. What do the other three columns represent?**\n\n**Marisa: rotation_matrix is a 3x3 matrix that represents the camera's attitude, and translation_vector is like a matrix that represents the location of the camera. Is camera_intrinsics a matrix that combines the two?**\n\n<img src=\"https://1.bp.blogspot.com/-WU8_Td-FBwU/WUdYTYOASOI/AAAAAAABE6U/Cl9PJsn_xbwoOZRYH8d9OpxS_lqG7kGrACLcBGAs/s400/camera_stabilizer.png\" width=200>","metadata":{}},{"cell_type":"markdown","source":"**魔理沙:imageの数を集計して、グラフにしてみよう！**\n\n**Marisa: Let's add up the number of images and make a graph!**","metadata":{}},{"cell_type":"code","source":"pair_dirs = glob.glob('../input/image-matching-challenge-2022/train/*/')\nimage_sizes = []\nimage_names = []\nfor i in range(len(pair_dirs)):\n    df_calibration = pd.read_csv(pair_dirs[i]+'/calibration.csv')\n    image_names.append(pair_dirs[i][45:-1])\n    image_sizes.append(len(df_calibration))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:25.91252Z","iopub.execute_input":"2022-04-21T12:06:25.913235Z","iopub.status.idle":"2022-04-21T12:06:26.13636Z","shell.execute_reply.started":"2022-04-21T12:06:25.913198Z","shell.execute_reply":"2022-04-21T12:06:26.135249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nplt.rcParams['font.size'] = 20\nplt.barh(image_names,image_sizes)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:26.137721Z","iopub.execute_input":"2022-04-21T12:06:26.137999Z","iopub.status.idle":"2022-04-21T12:06:26.43784Z","shell.execute_reply.started":"2022-04-21T12:06:26.137964Z","shell.execute_reply":"2022-04-21T12:06:26.436875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:多くて900、少なくて100未満かな？結構差があるね。**\n\n**Reimu: At most 900, at least less than 100? There are quite a few differences.**","metadata":{}},{"cell_type":"markdown","source":"## pair_covisibility.csv","metadata":{}},{"cell_type":"code","source":"df_pair = pd.read_csv(\"../input/image-matching-challenge-2022/train/british_museum/pair_covisibility.csv\")\ndf_pair.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:26.43909Z","iopub.execute_input":"2022-04-21T12:06:26.439351Z","iopub.status.idle":"2022-04-21T12:06:26.526445Z","shell.execute_reply.started":"2022-04-21T12:06:26.439318Z","shell.execute_reply":"2022-04-21T12:06:26.525781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_pair)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:26.52733Z","iopub.execute_input":"2022-04-21T12:06:26.528127Z","iopub.status.idle":"2022-04-21T12:06:26.534159Z","shell.execute_reply.started":"2022-04-21T12:06:26.528089Z","shell.execute_reply":"2022-04-21T12:06:26.533272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:covisibilityってのはどれくらい、写真が共通してるってことかな？**\n\n**魔理沙:[ここ](https://www.kaggle.com/competitions/image-matching-challenge-2022/overview/problem-definition)に計算方法が書いてるね。covisibilityが高いデータと低いデータで比較してみよう。**\n\n**Reimu: How much covisibility does the photo have in common?**\n\n**Marisa: The calculation method is written in [here](https://www.kaggle.com/competitions/image-matching-challenge-2022/overview/problem-definition). Let's compare the data with high covisibility and the data with low covisibility.**","metadata":{}},{"cell_type":"code","source":"pair = df_pair.loc[0,'pair']\npath1 = pair[0:19]\npath2 = pair[20:]\nprint(path1)\nprint(path2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:26.53779Z","iopub.execute_input":"2022-04-21T12:06:26.53865Z","iopub.status.idle":"2022-04-21T12:06:26.555776Z","shell.execute_reply.started":"2022-04-21T12:06:26.538598Z","shell.execute_reply":"2022-04-21T12:06:26.554294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_path = [\n    f'../input/image-matching-challenge-2022/train/british_museum/images/{path1}.jpg',\n    f'../input/image-matching-challenge-2022/train/british_museum/images/{path2}.jpg'\n]\ndisplay_multiple_img(images_path, 1,2)\ndf_pair.loc[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:26.557092Z","iopub.execute_input":"2022-04-21T12:06:26.557948Z","iopub.status.idle":"2022-04-21T12:06:27.225028Z","shell.execute_reply.started":"2022-04-21T12:06:26.557877Z","shell.execute_reply":"2022-04-21T12:06:27.22423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:これは、covisibilityが0.8以上の画像だぜ。**\n\n**霊夢:少し角度は違うけど、ほとんど同じに場所、角度で撮ってるように見えるね。**\n\n**Marisa: This is an image with a visibility of 0.8 or higher.**\n\n**Reimu: The angle is a little different, but it looks like you're shooting at almost the same location and angle.**","metadata":{}},{"cell_type":"code","source":"df = df_pair[df_pair['covisibility'] < 0.5]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:27.226407Z","iopub.execute_input":"2022-04-21T12:06:27.226717Z","iopub.status.idle":"2022-04-21T12:06:27.242724Z","shell.execute_reply.started":"2022-04-21T12:06:27.226687Z","shell.execute_reply":"2022-04-21T12:06:27.242143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pair = df_pair.loc[2506,'pair']\npath1 = pair[0:19]\npath2 = pair[20:]\nprint(path1)\nprint(path2)\nimages_path = [\n    f'../input/image-matching-challenge-2022/train/british_museum/images/{path1}.jpg',\n    f'../input/image-matching-challenge-2022/train/british_museum/images/{path2}.jpg'\n]\ndisplay_multiple_img(images_path, 1,2)\ndf_pair.loc[2506]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:27.243792Z","iopub.execute_input":"2022-04-21T12:06:27.244699Z","iopub.status.idle":"2022-04-21T12:06:27.881727Z","shell.execute_reply.started":"2022-04-21T12:06:27.244663Z","shell.execute_reply":"2022-04-21T12:06:27.880849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:これは、covisibilityが0.5以下の画像だぜ。**\n\n**霊夢:角度とか場所とかが結構違うね。でもどっちの写真も正面から撮っているね**\n\n**Marisa: This is an image with a visibility of 0.5 or less.**\n\n**Reimu: The angle and location are quite different. But both pictures are taken from the front**","metadata":{}},{"cell_type":"code","source":"df = df_pair[df_pair['covisibility'] < 0.3]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:27.88295Z","iopub.execute_input":"2022-04-21T12:06:27.883187Z","iopub.status.idle":"2022-04-21T12:06:27.895538Z","shell.execute_reply.started":"2022-04-21T12:06:27.883152Z","shell.execute_reply":"2022-04-21T12:06:27.894615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pair = df_pair.loc[9748,'pair']\npath1 = pair[0:19]\npath2 = pair[20:]\nprint(path1)\nprint(path2)\nimages_path = [\n    f'../input/image-matching-challenge-2022/train/british_museum/images/{path1}.jpg',\n    f'../input/image-matching-challenge-2022/train/british_museum/images/{path2}.jpg'\n]\ndisplay_multiple_img(images_path, 1,2)\ndf_pair.loc[9748]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:27.89665Z","iopub.execute_input":"2022-04-21T12:06:27.897272Z","iopub.status.idle":"2022-04-21T12:06:28.629694Z","shell.execute_reply.started":"2022-04-21T12:06:27.897238Z","shell.execute_reply":"2022-04-21T12:06:28.628798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:これは、covisibilityが0.2付近の画像だぜ。**\n\n**霊夢:角度も場所もほとんど違うね。右の画像に至ってはでっかく人が写ってるし**\n\n**Marisa: This is an image with a visibility around 0.2.**\n\n**Reimu: The angles and locations are almost different. The image on the right shows a huge person**","metadata":{}},{"cell_type":"markdown","source":"**魔理沙:様々なcovisibilityを比較してみたけど実際にcovisibilityの分配はどうなっているのかな？**\n\n**霊夢:グラフにして調べてみよう！**\n\n**Marisa: I compared various covisibility, but what is the actual distribution of covisibility?**\n\n**Reimu: Let's make a graph and check it out!**","metadata":{}},{"cell_type":"code","source":"for i in range(len(pair_dirs)):\n    df_pair = pd.read_csv(pair_dirs[i]+'/pair_covisibility.csv')\n    title = pair_dirs[i][45:-1]\n    df_pair['covisibility'].plot(kind='hist', bins=10,range = [0.0,1.0], figsize=(15, 6));\n    plt.title(title, weight='bold', fontsize=16);\n    plt.show()","metadata":{"id":"sGCOiF_2PZZS","execution":{"iopub.status.busy":"2022-04-21T12:06:28.631015Z","iopub.execute_input":"2022-04-21T12:06:28.631373Z","iopub.status.idle":"2022-04-21T12:06:39.296886Z","shell.execute_reply.started":"2022-04-21T12:06:28.631337Z","shell.execute_reply":"2022-04-21T12:06:39.295973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:建物ごとに結構違いがあるね。**\n\n**魔理沙:0.5未満にほとんどのグラフが固まっているようにみえるなあ**\n\n**Reimu: There are quite a few differences between buildings.**\n\n**Marisa: Most of the graphs seem to be solidified below 0.5**","metadata":{}},{"cell_type":"markdown","source":"## scaling_factors.csv","metadata":{}},{"cell_type":"markdown","source":"train/scaling_factors.csv: The poses for each scene where reconstructed via [Structure-from-Motion](https://en.wikipedia.org/wiki/Structure_from_motion), and are only accurate up to a scaling factor. This file contains a scalar for each scene which can be used to convert them to meters. For code examples, please refer to [this notebook](https://www.kaggle.com/eduardtrulls/imc2022-tutorial-load-and-evaluate-training-data).\n\ntrain/scaling_factors.csv: [Structure-from-Motion](https://en.wikipedia.org/wiki/Structure_from_motion)を介して再構築された各シーンのポーズ。正確なのはスケーリング係数までです。このファイルには、シーンをメートルに変換するために使用できる各シーンのスカラーが含まれています。コード例については、[このノートブック](https://www.kaggle.com/eduardtrulls/imc2022-tutorial-load-and-evaluate-training-data)を参照してください。","metadata":{}},{"cell_type":"code","source":"df_scaling = pd.read_csv(\"../input/image-matching-challenge-2022/train/scaling_factors.csv\")\ndf_scaling.head()","metadata":{"id":"74V8FJWGK3cF","execution":{"iopub.status.busy":"2022-04-21T12:06:39.298466Z","iopub.execute_input":"2022-04-21T12:06:39.299011Z","iopub.status.idle":"2022-04-21T12:06:39.315289Z","shell.execute_reply.started":"2022-04-21T12:06:39.298959Z","shell.execute_reply":"2022-04-21T12:06:39.314083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_scaling)","metadata":{"id":"OG4ej4ohLJQT","execution":{"iopub.status.busy":"2022-04-21T12:06:39.316698Z","iopub.execute_input":"2022-04-21T12:06:39.316978Z","iopub.status.idle":"2022-04-21T12:06:39.328682Z","shell.execute_reply.started":"2022-04-21T12:06:39.316945Z","shell.execute_reply":"2022-04-21T12:06:39.327644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:scaling_factorsって何だ？**\n\n**魔理沙:wikipediaによると、「対象となるもののスケール、すなわち尺度を表す量」の事らしいね。ここでいう「対象」は実際の建物の事かな？**\n\n**Reimu: What are scaling_factors?**\n\n**Marisa: According to wikipedia, it's the scale of the object, that is, the quantity that represents the scale. Is the \"object\" here the actual building?**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"http://3.bp.blogspot.com/-KmQQLtEkmLw/U1T3r7D0NdI/AAAAAAAAfVI/c2d4n2kG00U/s400/figure_question.png\" width=\"100\">","metadata":{"id":"VUzMUqJVNYGY"}},{"cell_type":"markdown","source":"# test","metadata":{}},{"cell_type":"markdown","source":"**魔理沙：次はテストを見てみよう**\n\n**Marisa: Let's take a look at the test next**","metadata":{"id":"GbcARKHhNeuh"}},{"cell_type":"markdown","source":"test.csv非表示のテストセットに約10,000ペアの画像が表示されることを期待してください。\n\nsample_id：画像ペアの一意の識別子。\n\nbatch_id：バッチID。\n\nimage_[1/2]_id：ペアの各画像のファイル名。\n\ntest_imagesテストセット。テストデータは、電車のデータとは異なるソースから取得され、さまざまな程度のオーバーラップがあるほとんどの都市のシーンの写真が含まれています。ペアを形成する2つの画像は、数か月または数年離れて収集された可能性がありますが、24時間以上離れていることはありません。このドメインギャップを埋めることは競争の一部です。画像は、最長のエッジが約800ピクセルになるようにサイズ変更されており、アスペクト比（縦向きと横向きを含む）が異なる場合があり、直立しています。\n\ntest.csv Expect to see roughly 10,000 pairs of images in the hidden test set.\n\n* sample_id: The unique identifier for the image pair.\n\n* batch_id: The batch ID.\n\n* image_[1/2]_id: The filenames of each image in the pair.\n\ntest_images The test set. The test data comes from a different source than the train data and contains photos of mostly urban scenes with variable degrees of overlap. The two images forming a pair may have been collected months or years apart, but never less than 24 hours. Bridging this domain gap is part of the competition. The images have been resized so that the longest edge is around 800 pixels, may have different aspect ratios (including portrait and landscape), and are upright.","metadata":{"id":"lQZFjTdpN6W9"}},{"cell_type":"markdown","source":"## test.csv","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/image-matching-challenge-2022/test.csv\")\ndf_test.head()","metadata":{"id":"8o85jqaBNjRV","execution":{"iopub.status.busy":"2022-04-21T12:06:39.330445Z","iopub.execute_input":"2022-04-21T12:06:39.330876Z","iopub.status.idle":"2022-04-21T12:06:39.354223Z","shell.execute_reply.started":"2022-04-21T12:06:39.330828Z","shell.execute_reply":"2022-04-21T12:06:39.353277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_test)","metadata":{"id":"_WgueE3hN1cV","execution":{"iopub.status.busy":"2022-04-21T12:06:39.355641Z","iopub.execute_input":"2022-04-21T12:06:39.356139Z","iopub.status.idle":"2022-04-21T12:06:39.362655Z","shell.execute_reply.started":"2022-04-21T12:06:39.35609Z","shell.execute_reply":"2022-04-21T12:06:39.361866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:2つの画像のidが書いてあるね。**\n\n**魔理沙:これを比較するんだろうな。**\n\n**Reimu: The ids of the two images are written.**\n\n**Marisa: I wonder if this will be compared.**","metadata":{}},{"cell_type":"markdown","source":"## test_images","metadata":{}},{"cell_type":"markdown","source":"**魔理沙:写真を表示させてみよう**\n\n**Marisa: Let's display the photo**","metadata":{}},{"cell_type":"code","source":"for i in range(len(df_test)):\n    batch_id = df_test.loc[i,'batch_id']\n    path1 = df_test.loc[i,'image_1_id']\n    path2 = df_test.loc[i,'image_2_id']\n    print(path1)\n    print(path2)\n    images_path = [\n        f'../input/image-matching-challenge-2022/test_images/{batch_id}/{path1}.png',\n        f'../input/image-matching-challenge-2022/test_images/{batch_id}/{path2}.png'\n    ]\n    display_multiple_img(images_path, 1,2)\n    df_test.loc[i]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:39.363849Z","iopub.execute_input":"2022-04-21T12:06:39.364487Z","iopub.status.idle":"2022-04-21T12:06:41.150775Z","shell.execute_reply.started":"2022-04-21T12:06:39.364439Z","shell.execute_reply":"2022-04-21T12:06:41.150103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:いや、どの建物を比較すれば良いんじゃ！？**\n\n**魔理沙:他の建物だったり、人、車、とか対象の建物とは関係ないものがたくさん映り込んでいるな。**\n\n**Reimu: No, which building should I compare! ??**\n\n**Marisa: There are a lot of other buildings, people, cars, and other things that have nothing to do with the target building.**","metadata":{}},{"cell_type":"markdown","source":"# sample_submission.csv","metadata":{}},{"cell_type":"markdown","source":"**魔理沙：最後にsample_submissionを見てみよう**\n\n**Marisa: Finally, let's take a look at sample_submission**","metadata":{"id":"ImOk5OYoN9UL"}},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/image-matching-challenge-2022/sample_submission.csv\")\nsample_submission","metadata":{"id":"p0maxlzeOFem","execution":{"iopub.status.busy":"2022-04-21T12:06:41.151894Z","iopub.execute_input":"2022-04-21T12:06:41.152784Z","iopub.status.idle":"2022-04-21T12:06:41.172541Z","shell.execute_reply.started":"2022-04-21T12:06:41.152747Z","shell.execute_reply":"2022-04-21T12:06:41.171033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_submission.loc[0,'fundamental_matrix'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:06:41.173576Z","iopub.execute_input":"2022-04-21T12:06:41.173815Z","iopub.status.idle":"2022-04-21T12:06:41.180878Z","shell.execute_reply.started":"2022-04-21T12:06:41.173788Z","shell.execute_reply":"2022-04-21T12:06:41.180185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:9つの実数が書いてあるけど、何だ？**\n\n**魔理沙:3×3の行列で、2つの画像を撮影したカメラの位置や姿勢の差を表しているんだと思うぜ。詳しくは[このページ](https://en.wikipedia.org/wiki/Fundamental_matrix_(computer_vision))を読めばわかるかもしれないだぜ。**\n\n**Reimu: Nine real numbers are written, what is it?**\n\n**Marisa: I think it's a 3x3 matrix that represents the difference in position and posture of the cameras that took the two images. You may find out more by reading [this page](https://en.wikipedia.org/wiki/Fundamental_matrix_(computer_vision)).**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"http://3.bp.blogspot.com/-KmQQLtEkmLw/U1T3r7D0NdI/AAAAAAAAfVI/c2d4n2kG00U/s400/figure_question.png\" width=\"100\">","metadata":{"id":"VUzMUqJVNYGY"}},{"cell_type":"markdown","source":"**霊夢:結構難易度が高そうなコンペだね。**\n\n**魔理沙:そうだな、いろんな人のコードを読んで学ばないとだな。**\n\n**Reimu: It's a competition that seems to be quite difficult.**\n\n**Marisa: Well, I have to read and learn the codes of various people.**","metadata":{}},{"cell_type":"markdown","source":"![](https://1.bp.blogspot.com/-PNcKwFw1PpM/U1T3oDIr9CI/AAAAAAAAfT4/gEn86X8Ppx0/s400/figure_goodjob.png)","metadata":{"id":"1aNcrxfQOVvu"}}]}