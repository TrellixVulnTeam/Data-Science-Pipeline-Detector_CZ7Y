{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install kornia --no-index --find-links=file:///kaggle/input/k/oldufo/imc2022-dependencies/pip/kornia/ --upgrade \n!pip install kornia_moons --no-index --find-links=file:///kaggle/input/k/oldufo/imc2022-dependencies/pip/kornia_moons/ --no-deps  --upgrade\n!cp -r ../input/imutils/imutils-0.5.3/ /\n!pip install /imutils-0.5.3/\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T05:59:44.669632Z","iopub.execute_input":"2022-04-14T05:59:44.669934Z","iopub.status.idle":"2022-04-14T06:00:26.338814Z","shell.execute_reply.started":"2022-04-14T05:59:44.669901Z","shell.execute_reply":"2022-04-14T06:00:26.337845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport kornia as K\nimport kornia.feature as KF\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport gc\nfrom kornia_moons.feature import *\nfrom tqdm.notebook import tqdm\nimport kornia.augmentation as KA\n\nif not torch.cuda.is_available():\n    print('You may want to enable the GPU switch?')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:00:26.341212Z","iopub.execute_input":"2022-04-14T06:00:26.341711Z","iopub.status.idle":"2022-04-14T06:00:26.349152Z","shell.execute_reply.started":"2022-04-14T06:00:26.341666Z","shell.execute_reply":"2022-04-14T06:00:26.348388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"DEVICE = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:00:26.350669Z","iopub.execute_input":"2022-04-14T06:00:26.350933Z","iopub.status.idle":"2022-04-14T06:00:26.362362Z","shell.execute_reply.started":"2022-04-14T06:00:26.350897Z","shell.execute_reply":"2022-04-14T06:00:26.361626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = 8000\n\n\nclass KeyNetAffNetHardNet(KF.LocalFeature):\n    \"\"\"Convenience module, which implements KeyNet detector + AffNet + HardNet descriptor.\"\"\"\n    def __init__(self,\n                 num_features: int = 5000,\n                 upright: bool = True,\n                 device: torch.device = torch.device('cuda')):\n        ori_module = KF.PassLAF()\n        detector = KF.KeyNetDetector(False,\n                                  ori_module=ori_module,\n                                  aff_module=KF.LAFAffNetShapeEstimator(False).eval()).to(device)\n        detector.model.load_state_dict(torch.load('/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/keynet_pytorch.pth')['state_dict'])\n        detector.aff.load_state_dict(torch.load('/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/AffNet.pth')['state_dict'])\n        descriptor = KF.LAFDescriptor(KF.HardNet8(False),\n                                   patch_size=32,\n                                   grayscale_descriptor=True).to(device)\n        descriptor.descriptor.load_state_dict(torch.load('/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/hardnet8v2.pt'))\n        super().__init__(detector, descriptor)\n        \nkeynet_affnet_hardnet8 = KeyNetAffNetHardNet(num_features).eval()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:00:26.365113Z","iopub.execute_input":"2022-04-14T06:00:26.365669Z","iopub.status.idle":"2022-04-14T06:00:27.337128Z","shell.execute_reply.started":"2022-04-14T06:00:26.36563Z","shell.execute_reply":"2022-04-14T06:00:27.336281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/image-matching-challenge-2022/test_images'\n\ndef load_torch_image(fname):\n    img = cv2.imread(fname)\n    #img = resize_keep_ratio(img)\n    img = K.image_to_tensor(img, False).float() /255.\n    img = K.color.bgr_to_rgb(img)\n    return img\n\ndef get_images_filenames(scence):\n    path = train_path + '/' + scence \n    img_filename_list = os.listdir(path)\n    return img_filename_list, path\n\ndef generate_dict(img1_filename, img2_filename):\n    img1 = load_torch_image(img1_filename)\n    img2 = load_torch_image(img2_filename)\n    \n    input_dict = {\"image0\": K.color.rgb_to_grayscale(img1).to(DEVICE), # LofTR works on grayscale images only \n                  \"image1\": K.color.rgb_to_grayscale(img2).to(DEVICE)}\n    \n    return input_dict\n\ndef FlattenMatrix(M, num_digits=8):\n    '''Convenience function to write CSV files.'''\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:00:27.338617Z","iopub.execute_input":"2022-04-14T06:00:27.338883Z","iopub.status.idle":"2022-04-14T06:00:27.350975Z","shell.execute_reply.started":"2022-04-14T06:00:27.338846Z","shell.execute_reply":"2022-04-14T06:00:27.348955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(fname):\n    img = cv2.imread(fname)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = K.image_to_tensor(img, False).float() /255.\n    img = K.color.rgb_to_grayscale(img).to(DEVICE)\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:00:27.352619Z","iopub.execute_input":"2022-04-14T06:00:27.352901Z","iopub.status.idle":"2022-04-14T06:00:27.362907Z","shell.execute_reply.started":"2022-04-14T06:00:27.352861Z","shell.execute_reply":"2022-04-14T06:00:27.361964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **lafs:** Detected local affine frames with shape(1, 2048, 2, 3).\n* **resps** Response function values for corresponding lafs with shape(1, 2048).\n* **descriptor** ocal descriptors of shape(1, 2048, 128) where 128 is descriptor size.","metadata":{}},{"cell_type":"code","source":"import csv\n\nsrc = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:00:27.364315Z","iopub.execute_input":"2022-04-14T06:00:27.36487Z","iopub.status.idle":"2022-04-14T06:00:27.373546Z","shell.execute_reply.started":"2022-04-14T06:00:27.364828Z","shell.execute_reply":"2022-04-14T06:00:27.372751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Fundamental_Matrix","metadata":{}},{"cell_type":"code","source":"num_features = 5000\nmatcher = KF.DescriptorMatcher('snn', 0.99)\n\n# Compute this many samples, and fill the rest with random values, to generate a quick submission and check it works without waiting for a full run. Set to -1 to use all samples.\n# how_many_to_fill = 500\nhow_many_to_fill = -1\n\nF_dict = {}\nfor i, row in enumerate(test_samples):\n    sample_id, batch_id, image_1_id, image_2_id = row\n    \n    if how_many_to_fill >= 0 and i >= how_many_to_fill:\n        F_dict[sample_id] = np.random.rand(3, 3)\n        continue\n\n    # Extract features.\n    with torch.no_grad():\n        img1 = load_image(f'{src}/test_images/{batch_id}/{image_1_id}.png')\n        img2 = load_image(f'{src}/test_images/{batch_id}/{image_2_id}.png')\n        lafs1, resps1, descriptors_1 = keynet_affnet_hardnet8(img1)\n        lafs2, resps2, descriptors_2 = keynet_affnet_hardnet8(img2)\n        \n        if descriptors_1.size(1) == 0 or descriptors_2.size(1) == 0:\n            F_dict[sample_id] = np.zeros((3, 3))\n            continue\n\n        dists, idxs  = matcher(descriptors_1[0], descriptors_2[0])\n        cur_kp1 = KF.get_laf_center(lafs1).detach().cpu().numpy().reshape(-1, 2)\n        cur_kp2 = KF.get_laf_center(lafs2).detach().cpu().numpy().reshape(-1, 2)\n        match_idxs = idxs.detach().cpu().numpy()\n\n    # Make sure we do not trigger an exception here.\n    if len(match_idxs) > 8:\n        F, inlier_mask = cv2.findFundamentalMat(cur_kp1[match_idxs[:, 0]], cur_kp2[match_idxs[:, 1]],\n                                                cv2.USAC_MAGSAC,\n                                                ransacReprojThreshold=0.5,\n                                                confidence=0.99999,\n                                                maxIters=10000)\n        assert F.shape == (3, 3), 'Malformed F?'\n        F_dict[sample_id] = F\n    else:\n        F_dict[sample_id] = np.zeros((3, 3))\n        continue\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:01:39.772038Z","iopub.execute_input":"2022-04-14T06:01:39.772878Z","iopub.status.idle":"2022-04-14T06:01:41.582173Z","shell.execute_reply.started":"2022-04-14T06:01:39.772835Z","shell.execute_reply":"2022-04-14T06:01:41.581355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make an submission","metadata":{}},{"cell_type":"code","source":"with open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:01:45.031013Z","iopub.execute_input":"2022-04-14T06:01:45.031672Z","iopub.status.idle":"2022-04-14T06:01:45.039069Z","shell.execute_reply.started":"2022-04-14T06:01:45.031609Z","shell.execute_reply":"2022-04-14T06:01:45.038151Z"},"trusted":true},"execution_count":null,"outputs":[]}]}