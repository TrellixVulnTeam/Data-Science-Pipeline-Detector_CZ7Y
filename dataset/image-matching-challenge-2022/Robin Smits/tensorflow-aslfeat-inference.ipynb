{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this new notebook I'am using the Tensorflow implementation of 'ASLFeat: Learning Local Features of Accurate Shape and Localization' as described in the paper [https://arxiv.org/abs/2003.10071](https://arxiv.org/abs/2003.10071) to predict the fundamental matrix for this competition.\n\nThe original implementation in [github](https://github.com/lzx551402/ASLFeat) is made in Tensorflow 1.X. I've used the available tools to upgrade the code to Tensorflow 2.X and made some slight modifications to be able to run it. More improvements could be made to the code.\n\nAnother change compared to the original code is that I'am using the cv2.FLANNBasedMatcher instead of the cv2.BFMatcher.\n\nI hope you like the code .. and if you do please give it an upvote ;-)","metadata":{}},{"cell_type":"code","source":"# Import Modules\nimport numpy as np \nimport pandas as pd\nimport csv\nimport cv2\nimport gc\nimport tensorflow as tf\nimport sys\nimport yaml\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\n# Import ASLFeat\nsys.path.append('../input/aslfeat')\nfrom models import get_model\n\n# Disable Eager Execution\ntf.compat.v1.disable_eager_execution()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.019969,"end_time":"2022-05-20T21:53:44.598475","exception":false,"start_time":"2022-05-20T21:53:39.578506","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-23T17:26:39.954415Z","iopub.execute_input":"2022-05-23T17:26:39.955309Z","iopub.status.idle":"2022-05-23T17:26:45.149692Z","shell.execute_reply.started":"2022-05-23T17:26:39.955211Z","shell.execute_reply":"2022-05-23T17:26:45.148502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Data","metadata":{"papermill":{"duration":0.011906,"end_time":"2022-05-20T21:53:44.622118","exception":false,"start_time":"2022-05-20T21:53:44.610212","status":"completed"},"tags":[]}},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]","metadata":{"papermill":{"duration":0.022022,"end_time":"2022-05-20T21:53:44.655142","exception":false,"start_time":"2022-05-20T21:53:44.63312","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-23T17:26:53.968933Z","iopub.execute_input":"2022-05-23T17:26:53.969628Z","iopub.status.idle":"2022-05-23T17:26:53.979079Z","shell.execute_reply.started":"2022-05-23T17:26:53.969589Z","shell.execute_reply":"2022-05-23T17:26:53.977818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Functions","metadata":{}},{"cell_type":"code","source":"def FlattenMatrix(M, num_digits = 8):\n    '''Convenience function to write CSV files.'''    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\ndef get_fundamental_matrix(kpts1, kpts2, err_thld):    \n    if len(kpts1) > 7:\n        F, inliers = cv2.findFundamentalMat(kpts1, \n                                            kpts2, \n                                            cv2.USAC_MAGSAC, \n                                            ransacReprojThreshold = err_thld, \n                                            confidence = 0.99999, \n                                            maxIters = 100000) # Lower maxIters to increase speed / lower accuracy\n        return F, inliers\n    else:\n        return np.random.rand(3, 3), None","metadata":{"execution":{"iopub.status.busy":"2022-05-23T17:26:54.96827Z","iopub.execute_input":"2022-05-23T17:26:54.969342Z","iopub.status.idle":"2022-05-23T17:26:54.979822Z","shell.execute_reply.started":"2022-05-23T17:26:54.969295Z","shell.execute_reply":"2022-05-23T17:26:54.978646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup ASLFeat","metadata":{"papermill":{"duration":0.010855,"end_time":"2022-05-20T21:53:44.676932","exception":false,"start_time":"2022-05-20T21:53:44.666077","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Import Config\nwith open('../input/aslfeat/configs/matching_eval2.yaml', 'r') as f:\n        config = yaml.load(f, Loader=yaml.FullLoader)\n\n# There are 2 checkpoints in the pretrained folder. This one should be the best...\naslfeat_model_path = '../input/aslfeat/pretrained/aslfeatv2/model.ckpt-60000' \nconfig['model_path'] = aslfeat_model_path\nconfig['net']['config']['kpt_n'] = 8192 # Original config 8000 ... just for convenience ;-)\n\n# Summary config\nprint(config)","metadata":{"papermill":{"duration":0.048941,"end_time":"2022-05-20T21:53:44.736999","exception":false,"start_time":"2022-05-20T21:53:44.688058","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-23T17:28:19.223922Z","iopub.execute_input":"2022-05-23T17:28:19.224246Z","iopub.status.idle":"2022-05-23T17:28:19.238627Z","shell.execute_reply.started":"2022-05-23T17:28:19.224215Z","shell.execute_reply":"2022-05-23T17:28:19.23756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Model\nmodel = get_model('feat_model')(aslfeat_model_path, **config['net'])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T17:29:04.035894Z","iopub.execute_input":"2022-05-23T17:29:04.036347Z","iopub.status.idle":"2022-05-23T17:29:10.681942Z","shell.execute_reply.started":"2022-05-23T17:29:04.036304Z","shell.execute_reply":"2022-05-23T17:29:10.680869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ASLFeat Functions    \ndef load_imgs(img_paths):\n    rgb_list = []\n    gray_list = []\n    \n    for img_path in img_paths:\n        img = cv2.imread(img_path)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)[..., np.newaxis]\n        img = img[..., ::-1]\n        rgb_list.append(img)\n        gray_list.append(gray)\n        \n    return rgb_list, gray_list\n\ndef extract_local_features(gray_list):    \n    descs = []\n    kpts = []\n    \n    for gray_img in gray_list:\n        desc, kpt = [], []\n        desc, kpt, _ = model.run_test_data(gray_img)\n        descs.append(desc)\n        kpts.append(kpt)\n        \n    return descs, kpts\n\nclass MatcherWrapper(object):\n    \"\"\"OpenCV matcher wrapper.\"\"\"\n\n    def __init__(self):\n        # Swapped BFMatcher to FlannBasedMatcher\n        # FLANN parameters\n        FLANN_INDEX_KDTREE = 0\n        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n        search_params = dict(checks = 100)   # or pass empty dictionary\n        self.matcher = cv2.FlannBasedMatcher(index_params, search_params)\n    \n    def get_matches(self, feat1, feat2, cv_kpts1, cv_kpts2, ratio = 0.8, cross_check = True, err_thld = 0.5):\n        \"\"\"Compute putative and inlier matches.\n        Args:\n            feat: (n_kpts, 128) Local features.\n            cv_kpts: A list of keypoints represented as cv2.KeyPoint.\n            ratio: The threshold to apply ratio test.\n            cross_check: (True by default) Whether to apply cross check.\n            err_thld: Epipolar error threshold.\n        Returns:\n            good_matches: Putative matches.\n            mask: The mask to distinguish inliers/outliers on putative matches.\n        \"\"\"\n        \n        init_matches1 = self.matcher.knnMatch(feat1, feat2, k = 2)\n        init_matches2 = self.matcher.knnMatch(feat2, feat1, k = 2)\n\n        good_matches = []\n\n        for i in range(len(init_matches1)):\n            cond = True\n            if cross_check:\n                cond1 = cross_check and init_matches2[init_matches1[i][0].trainIdx][0].trainIdx == i\n                cond *= cond1\n            if ratio is not None and ratio < 1:\n                cond2 = init_matches1[i][0].distance <= ratio * init_matches1[i][1].distance\n                cond *= cond2\n            if cond:\n                good_matches.append(init_matches1[i][0])\n\n        if type(cv_kpts1) is list and type(cv_kpts2) is list:\n            good_kpts1 = np.array([cv_kpts1[m.queryIdx].pt for m in good_matches])\n            good_kpts2 = np.array([cv_kpts2[m.trainIdx].pt for m in good_matches])\n        elif type(cv_kpts1) is np.ndarray and type(cv_kpts2) is np.ndarray:\n            good_kpts1 = np.array([cv_kpts1[m.queryIdx] for m in good_matches])\n            good_kpts2 = np.array([cv_kpts2[m.trainIdx] for m in good_matches])\n        else:\n            good_kpts1 = np.empty(0)\n            good_kpts2 = np.empty(0)\n            \n        # Calculate Fundamental Mask and inliers\n        F, mask = get_fundamental_matrix(good_kpts1, good_kpts2, err_thld)\n        return F, good_matches, mask\n            \n    def draw_matches(self, img1, cv_kpts1, img2, cv_kpts2, good_matches, mask, match_color = (0, 255, 0), pt_color = (0, 0, 255)):\n        \"\"\"Draw matches.\"\"\"\n        if type(cv_kpts1) is np.ndarray and type(cv_kpts2) is np.ndarray:\n            cv_kpts1 = [cv2.KeyPoint(cv_kpts1[i][0], cv_kpts1[i][1], 1) for i in range(cv_kpts1.shape[0])]\n            cv_kpts2 = [cv2.KeyPoint(cv_kpts2[i][0], cv_kpts2[i][1], 1) for i in range(cv_kpts2.shape[0])]\n            \n        display = cv2.drawMatches(img1, cv_kpts1, img2, cv_kpts2, good_matches,\n                                  None,\n                                  matchColor = match_color,\n                                  singlePointColor = pt_color,\n                                  matchesMask = mask.ravel().tolist(), flags=4)\n        return display","metadata":{"papermill":{"duration":5.821703,"end_time":"2022-05-20T21:53:50.570746","exception":false,"start_time":"2022-05-20T21:53:44.749043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-21T21:35:27.128967Z","iopub.execute_input":"2022-05-21T21:35:27.130286Z","iopub.status.idle":"2022-05-21T21:35:27.159545Z","shell.execute_reply.started":"2022-05-21T21:35:27.130244Z","shell.execute_reply":"2022-05-21T21:35:27.1588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_aslfeat_fmatrix(batch_id, img_id1, img_id2, plot = False):\n    image_fpath_1 = f'{src}/test_images/{batch_id}/{img_id1}.png'\n    image_fpath_2 = f'{src}/test_images/{batch_id}/{img_id2}.png'\n    \n    # Load Test Image Pair\n    rgb_list, gray_list = load_imgs([image_fpath_1, image_fpath_2])    \n\n    # Extract Local Features\n    descs, kpts = extract_local_features(gray_list)\n        \n    # feature matching and draw matches.\n    matcher = MatcherWrapper()\n    fundamental_matrix, match, mask = matcher.get_matches(descs[0], descs[1], kpts[0], kpts[1],\n                                                          ratio = None, \n                                                          cross_check = True, # I'am only using the Cross Check...not the ratio test.\n                                                          err_thld = 0.20)\n\n    if plot:\n        # Draw Matches\n        disp = matcher.draw_matches(rgb_list[0], kpts[0], rgb_list[1], kpts[1], match, mask)\n\n        # Save Plot Image\n        output_name = f'{batch_id}.jpg'\n        plt.imsave(output_name, disp) \n        \n        # Show Plot Image\n        plt.figure(figsize = (18, 18))\n        plt.imshow(disp)\n        plt.show() \n        \n        # Info\n        print(f'n_putative: {len(match)}  n_inlier: {np.count_nonzero(mask)}')\n\n    return fundamental_matrix","metadata":{"papermill":{"duration":0.024504,"end_time":"2022-05-20T21:53:50.669519","exception":false,"start_time":"2022-05-20T21:53:50.645015","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-21T21:35:27.161473Z","iopub.execute_input":"2022-05-21T21:35:27.162027Z","iopub.status.idle":"2022-05-21T21:35:27.172884Z","shell.execute_reply.started":"2022-05-21T21:35:27.161988Z","shell.execute_reply":"2022-05-21T21:35:27.172076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{"papermill":{"duration":0.012525,"end_time":"2022-05-20T21:53:50.696456","exception":false,"start_time":"2022-05-20T21:53:50.683931","status":"completed"},"tags":[]}},{"cell_type":"code","source":"f_matrix_dict = {}\nfor i, row in tqdm(enumerate(test_samples)):\n    sample_id, batch_id, img_id1, img_id2 = row\n\n    # Set Plot\n    plot = False\n    if i < 3: plot = True\n        \n    # Get Fundamental matrix with ASLFeat And FLANNBasedMatcher\n    f_matrix_dict[sample_id] = get_aslfeat_fmatrix(batch_id, img_id1, img_id2, plot)","metadata":{"papermill":{"duration":15.987459,"end_time":"2022-05-20T21:54:06.696847","exception":false,"start_time":"2022-05-20T21:53:50.709388","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-21T21:35:27.174655Z","iopub.execute_input":"2022-05-21T21:35:27.175037Z","iopub.status.idle":"2022-05-21T21:35:43.739091Z","shell.execute_reply.started":"2022-05-21T21:35:27.174998Z","shell.execute_reply":"2022-05-21T21:35:43.738501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission","metadata":{"papermill":{"duration":0.013985,"end_time":"2022-05-20T21:54:06.726583","exception":false,"start_time":"2022-05-20T21:54:06.712598","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Write Submission File   \nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in f_matrix_dict.items():                \n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"papermill":{"duration":0.02138,"end_time":"2022-05-20T21:54:06.762139","exception":false,"start_time":"2022-05-20T21:54:06.740759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-21T21:35:43.74035Z","iopub.execute_input":"2022-05-21T21:35:43.740879Z","iopub.status.idle":"2022-05-21T21:35:43.746604Z","shell.execute_reply.started":"2022-05-21T21:35:43.740843Z","shell.execute_reply":"2022-05-21T21:35:43.745973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"papermill":{"duration":0.035163,"end_time":"2022-05-20T21:54:06.811535","exception":false,"start_time":"2022-05-20T21:54:06.776372","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-21T21:35:43.748607Z","iopub.execute_input":"2022-05-21T21:35:43.74933Z","iopub.status.idle":"2022-05-21T21:35:43.771297Z","shell.execute_reply.started":"2022-05-21T21:35:43.749297Z","shell.execute_reply":"2022-05-21T21:35:43.77063Z"},"trusted":true},"execution_count":null,"outputs":[]}]}