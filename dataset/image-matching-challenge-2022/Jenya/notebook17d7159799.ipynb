{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T21:13:25.696785Z","iopub.execute_input":"2022-04-21T21:13:25.697198Z","iopub.status.idle":"2022-04-21T21:13:25.703188Z","shell.execute_reply.started":"2022-04-21T21:13:25.697159Z","shell.execute_reply":"2022-04-21T21:13:25.702095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-21T19:51:59.423535Z","iopub.execute_input":"2022-04-21T19:51:59.424565Z","iopub.status.idle":"2022-04-21T19:52:00.188499Z","shell.execute_reply.started":"2022-04-21T19:51:59.424493Z","shell.execute_reply":"2022-04-21T19:52:00.187229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport csv\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:15:34.570352Z","iopub.execute_input":"2022-04-21T21:15:34.570764Z","iopub.status.idle":"2022-04-21T21:15:34.576041Z","shell.execute_reply.started":"2022-04-21T21:15:34.570733Z","shell.execute_reply":"2022-04-21T21:15:34.575466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dry_run = False","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:15:35.325916Z","iopub.execute_input":"2022-04-21T21:15:35.326328Z","iopub.status.idle":"2022-04-21T21:15:35.330543Z","shell.execute_reply.started":"2022-04-21T21:15:35.326297Z","shell.execute_reply":"2022-04-21T21:15:35.32994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ExtractSiftFeatures(image, detector, num_features):\n    \n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    return detector.detectAndCompute(gray, None)[:num_features]\n\n\ndef ArrayFromCvKps(kps):\n    \n    return np.array([kp.pt for kp in kps])\n\n\ndef FlattenMatrix(M, num_digits=8):\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\n\ndef BuildCompositeImage(im1, im2, axis=1, margin=0, background=1):\n    \n    if background != 0 and background != 1:\n        background = 1\n    if axis != 0 and axis != 1:\n        raise RuntimeError('Axis must be 0 (vertical) or 1 (horizontal')\n\n    h1, w1, _ = im1.shape\n    h2, w2, _ = im2.shape\n\n    if axis == 1:\n        composite = np.zeros((max(h1, h2), w1 + w2 + margin, 3), dtype=np.uint8) + 255 * background\n        if h1 > h2:\n            voff1, voff2 = 0, (h1 - h2) // 2\n        else:\n            voff1, voff2 = (h2 - h1) // 2, 0\n        hoff1, hoff2 = 0, w1 + margin\n    else:\n        composite = np.zeros((h1 + h2 + margin, max(w1, w2), 3), dtype=np.uint8) + 255 * background\n        if w1 > w2:\n            hoff1, hoff2 = 0, (w1 - w2) // 2\n        else:\n            hoff1, hoff2 = (w2 - w1) // 2, 0\n        voff1, voff2 = 0, h1 + margin\n    composite[voff1:voff1 + h1, hoff1:hoff1 + w1, :] = im1\n    composite[voff2:voff2 + h2, hoff2:hoff2 + w2, :] = im2\n\n    return (composite, (voff1, voff2), (hoff1, hoff2))\n\n\ndef DrawMatches(im1, im2, kp1, kp2, matches, axis=1, margin=0, background=0, linewidth=2):\n    '''Draw keypoints and matches.'''\n    \n    composite, v_offset, h_offset = BuildCompositeImage(im1, im2, axis, margin, background)\n\n    # Draw all keypoints.\n    for coord_a, coord_b in zip(kp1, kp2):\n        composite = cv2.drawMarker(composite, (int(coord_a[0] + h_offset[0]), int(coord_a[1] + v_offset[0])), color=(255, 0, 0), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1)\n        composite = cv2.drawMarker(composite, (int(coord_b[0] + h_offset[1]), int(coord_b[1] + v_offset[1])), color=(255, 0, 0), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1)\n    \n    # Draw matches, and highlight keypoints used in matches.\n    for idx_a, idx_b in matches:\n        composite = cv2.drawMarker(composite, (int(kp1[idx_a, 0] + h_offset[0]), int(kp1[idx_a, 1] + v_offset[0])), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=12, thickness=1)\n        composite = cv2.drawMarker(composite, (int(kp2[idx_b, 0] + h_offset[1]), int(kp2[idx_b, 1] + v_offset[1])), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=12, thickness=1)\n        composite = cv2.line(composite,\n                             tuple([int(kp1[idx_a][0] + h_offset[0]),\n                                   int(kp1[idx_a][1] + v_offset[0])]),\n                             tuple([int(kp2[idx_b][0] + h_offset[1]),\n                                   int(kp2[idx_b][1] + v_offset[1])]), color=(0, 0, 255), thickness=1)\n    return composite","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:15:36.16968Z","iopub.execute_input":"2022-04-21T21:15:36.170345Z","iopub.status.idle":"2022-04-21T21:15:36.189987Z","shell.execute_reply.started":"2022-04-21T21:15:36.170301Z","shell.execute_reply":"2022-04-21T21:15:36.188808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]\n\nif dry_run:\n    for sample in test_samples:\n        print(sample)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:15:38.403095Z","iopub.execute_input":"2022-04-21T21:15:38.403376Z","iopub.status.idle":"2022-04-21T21:15:38.409181Z","shell.execute_reply.started":"2022-04-21T21:15:38.403341Z","shell.execute_reply":"2022-04-21T21:15:38.408557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = 8000\n\n\ndetector = cv2.SIFT_create(num_features, contrastThreshold=-10000, edgeThreshold=-10000)\n\n# Brute-force matcher with bi-directionaly check.\nbf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n\nhow_many_to_fill = -1\n\nF_dict = {}\nfor i, row in enumerate(test_samples):\n    sample_id, batch_id, image_1_id, image_2_id = row\n    \n    if how_many_to_fill >= 0 and i >= how_many_to_fill:\n        F_dict[sample_id] = np.random.rand(3, 3)\n        continue\n    \n    # Load the images.\n    image_1 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_1_id}.png'), cv2.COLOR_BGR2RGB)\n    image_2 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_2_id}.png'), cv2.COLOR_BGR2RGB)\n\n    keypoints_1, descriptors_1 = ExtractSiftFeatures(image_1, detector, num_features)\n    keypoints_2, descriptors_2 = ExtractSiftFeatures(image_2, detector, num_features)\n    \n    # Compute matches.\n    cv_matches = bf.match(descriptors_1, descriptors_2)\n    \n    # Compute fundamental matrix.\n    cur_kp_1 = ArrayFromCvKps(keypoints_1)\n    cur_kp_2 = ArrayFromCvKps(keypoints_2)\n    matches = np.array([[m.queryIdx, m.trainIdx] for m in cv_matches])\n    F, inlier_mask = cv2.findFundamentalMat(cur_kp_1[matches[:, 0]], cur_kp_2[matches[:, 1]], cv2.USAC_MAGSAC, ransacReprojThreshold=0.25, confidence=0.99999, maxIters=100000)\n    F_dict[sample_id] = F\n    \n    if dry_run:\n        matches_after_ransac = np.array([match for match, is_inlier in zip(matches, inlier_mask) if is_inlier])\n        im_inliers = DrawMatches(image_1, image_2, cur_kp_1, cur_kp_2, matches_after_ransac)\n        fig = plt.figure(figsize=(15, 15))\n        plt.title(f'{image_1_id}-{image_2_id}')\n        plt.imshow(im_inliers)\n        plt.axis('off')\n        plt.show()\n\nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:15:40.333634Z","iopub.execute_input":"2022-04-21T21:15:40.333938Z","iopub.status.idle":"2022-04-21T21:15:45.137669Z","shell.execute_reply.started":"2022-04-21T21:15:40.333902Z","shell.execute_reply":"2022-04-21T21:15:45.136755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-04-21T21:15:45.139518Z","iopub.execute_input":"2022-04-21T21:15:45.139805Z","iopub.status.idle":"2022-04-21T21:15:45.936133Z","shell.execute_reply.started":"2022-04-21T21:15:45.139763Z","shell.execute_reply":"2022-04-21T21:15:45.935094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}