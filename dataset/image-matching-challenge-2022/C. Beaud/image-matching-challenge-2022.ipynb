{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hi Kagglers üôã‚Äç‚ôÄÔ∏è\n\n*Please upvote [original Notebook](https://www.kaggle.com/code/ammarali32/image-matching-challenge-2022-baseline-kornia)*\n\n<center>\n    <h2 style=\"color: #dc3545\"> Your UPVOTE can make my day ü§ó </h2>","metadata":{}},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/trevi-canvas-licensed-nonoderivs.jpg)","metadata":{}},{"cell_type":"markdown","source":"# ***Install Libs***","metadata":{}},{"cell_type":"code","source":"dry_run = False\n!ls /kaggle/input/k/oldufo\n!pip install kornia --no-index --find-links=file:///kaggle/input/k/oldufo/imc2022-dependencies/pip/kornia/ --upgrade \n!pip install kornia_moons --no-index --find-links=file:///kaggle/input/k/oldufo/imc2022-dependencies/pip/kornia_moons/ --no-deps  --upgrade \nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:25:28.714988Z","iopub.execute_input":"2022-04-09T12:25:28.715618Z","iopub.status.idle":"2022-04-09T12:25:40.699258Z","shell.execute_reply.started":"2022-04-09T12:25:28.715516Z","shell.execute_reply":"2022-04-09T12:25:40.698408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Import dependencies***","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport csv\nfrom glob import glob\nimport torch\nimport matplotlib.pyplot as plt\nimport kornia\nimport kornia.feature as kornia_feature\nfrom kornia_moons.feature import *","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:25:40.702466Z","iopub.execute_input":"2022-04-09T12:25:40.702672Z","iopub.status.idle":"2022-04-09T12:25:42.776363Z","shell.execute_reply.started":"2022-04-09T12:25:40.702647Z","shell.execute_reply":"2022-04-09T12:25:42.775612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = [\"/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/AffNet.pth\",\n        \"/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/hardnet8v2.pt\",\n        \"/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/OriNet.pth\",\n        \"/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/HyNet_LIB.pth\",\n        \"/kaggle/input/imgs-matching/tfeat-liberty.params\",\n        \"/kaggle/input/imgs-matching/sosnet_32x32_liberty.pth\",\n        \"/kaggle/input/k/oldufo/imc2022-dependencies/pretrained/keynet_pytorch.pth\"\n        ]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:25:42.777713Z","iopub.execute_input":"2022-04-09T12:25:42.777969Z","iopub.status.idle":"2022-04-09T12:25:42.78353Z","shell.execute_reply.started":"2022-04-09T12:25:42.777936Z","shell.execute_reply":"2022-04-09T12:25:42.782539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***CFG***","metadata":{}},{"cell_type":"code","source":"class CFG:\n    ori_module = {\"pass\":{\"model\":kornia_feature.PassLAF(),\"path\":None},\n                  \"orinet\":{\"model\": kornia_feature.LAFOrienter(angle_detector = kornia_feature.OriNet(pretrained=False)),\"path\":paths[2]}}\n    \n    aff_module = {\"alfaffnet\":{\"model\":kornia_feature.LAFAffNetShapeEstimator(False),\"path\":paths[0]}}\n    \n    descriptor = {\"hardnet8v2\":{\"model\":kornia_feature.HardNet8(False),\"path\":paths[1]},\n                 \"HyNet\":{\"model\":kornia_feature.HyNet(False),\"path\":paths[3]},\n                 \"TFeat\":{\"model\":kornia_feature.TFeat(False),\"path\":paths[4]},\n                 \"SOSNet\":{\"model\":kornia_feature.SOSNet(False),\"path\":paths[5]}}\n    \n    detector_path = paths[-1]\n    num_features = 4000\n    DescriptorMatcher = \"snn\" ## [\"nn\", \"snn\", \"mnn\", \"smnn\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:25:42.785744Z","iopub.execute_input":"2022-04-09T12:25:42.786005Z","iopub.status.idle":"2022-04-09T12:25:43.685182Z","shell.execute_reply.started":"2022-04-09T12:25:42.785966Z","shell.execute_reply":"2022-04-09T12:25:43.684456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Models***","metadata":{}},{"cell_type":"code","source":"class KeyNetAffNetHardNet(kornia_feature.LocalFeature):\n    \"\"\"Convenience module, which implements KeyNet detector + AffNet + HardNet descriptor.\"\"\"\n    def __init__(self,\n                 ori_module_name = \"pass\",\n                 aff_module_name = \"alfaffnet\",\n                 descriptor_name = \"hardnet8v2\",\n                 num_features: int = CFG.num_features,\n                 upright: bool = True,\n                 device: torch.device = torch.device('cuda')):\n        ori_module = CFG.ori_module[ori_module_name][\"model\"]\n        detector = kornia_feature.KeyNetDetector(False,\n                                  ori_module=ori_module,\n                                  aff_module=CFG.aff_module[aff_module_name][\"model\"].eval()).to(device)\n        detector.model.load_state_dict(torch.load(CFG.detector_path)['state_dict'])\n        detector.aff.load_state_dict(torch.load(CFG.aff_module[aff_module_name][\"path\"])['state_dict'])\n        if CFG.ori_module[ori_module_name][\"path\"] is not None:\n            detector.ori.angle_detector.load_state_dict(torch.load(CFG.ori_module[ori_module_name][\"path\"])['state_dict'])\n        descriptor = kornia_feature.LAFDescriptor(CFG.descriptor[descriptor_name][\"model\"],\n                                   patch_size=32,\n                                   grayscale_descriptor=True).to(device)\n        descriptor.descriptor.load_state_dict(torch.load(CFG.descriptor[descriptor_name][\"path\"]))\n        super().__init__(detector, descriptor)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:25:43.68661Z","iopub.execute_input":"2022-04-09T12:25:43.686852Z","iopub.status.idle":"2022-04-09T12:25:43.696814Z","shell.execute_reply.started":"2022-04-09T12:25:43.686818Z","shell.execute_reply":"2022-04-09T12:25:43.696184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Utils*","metadata":{}},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]\n\n\ndef FlattenMatrix(M, num_digits=8):\n    '''Convenience function to write CSV files.'''\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\n\nhelp(draw_LAF_matches)\n\n# We will draw only inliers and tentative matches:\ndraw_dict={\n    'inlier_color': (0.2, 1, 0.2),  # Green: inliers.\n    'tentative_color': (1, 1, 0.2, 0.5),  #Light yellow: tentative matches.\n    'feature_color': None,\n    'vertical': False\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:25:43.698013Z","iopub.execute_input":"2022-04-09T12:25:43.698408Z","iopub.status.idle":"2022-04-09T12:25:43.715643Z","shell.execute_reply.started":"2022-04-09T12:25:43.698373Z","shell.execute_reply":"2022-04-09T12:25:43.714792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Inference***","metadata":{}},{"cell_type":"code","source":"import gc\n\nhow_many_to_fill = -1\n\ndevice = torch.device('cuda')\nkeynet_affnet_hardnet8 = KeyNetAffNetHardNet().eval()\nkeynet_affnet_hynet = KeyNetAffNetHardNet(descriptor_name = \"HyNet\").eval()\nkeynet_affnet_sosnet = KeyNetAffNetHardNet(descriptor_name = \"SOSNet\").eval()\n\nmatcher = kornia_feature.DescriptorMatcher(CFG.DescriptorMatcher, 0.9)\n\nF_dict = {}\nfor i, row in enumerate(test_samples):\n    sample_id, batch_id, image_1_id, image_2_id = row\n    \n    if how_many_to_fill >= 0 and i >= how_many_to_fill:\n        F_dict[sample_id] = np.random.rand(3, 3)\n        continue\n\n    # Load the images.\n    image_1 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_1_id}.png'), cv2.COLOR_BGR2RGB)\n    image_2 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_2_id}.png'), cv2.COLOR_BGR2RGB)\n\n    # Extract features.\n    with torch.no_grad():\n        timg1 = kornia.image_to_tensor(image_1, False).float() / 255.\n        timg1 = kornia.color.rgb_to_grayscale(timg1).to(device)\n        timg2 = kornia.image_to_tensor(image_2, False).float() / 255.\n        timg2 = kornia.color.rgb_to_grayscale(timg2).to(device)\n        \n        lafs1, resps1, descriptors_1 = keynet_affnet_hardnet8(timg1)\n        lafs2, resps2, descriptors_2 = keynet_affnet_hardnet8(timg2)\n        \n        lafs3, resps3, descriptors_3 = keynet_affnet_hynet(timg1)\n        lafs4, resps4, descriptors_4 = keynet_affnet_hynet(timg2)\n        \n        lafs5, resps5, descriptors_5 = keynet_affnet_sosnet(timg1)\n        lafs6, resps6, descriptors_6 = keynet_affnet_sosnet(timg2)\n\n        if descriptors_1.size(1) == 0 or descriptors_2.size(1) == 0:\n            F_dict[sample_id] = np.zeros((3, 3))\n            continue\n\n        dists, idxs  = matcher(descriptors_1[0], descriptors_2[0])\n        dists2, idxs2  = matcher(descriptors_3[0], descriptors_4[0])\n        dists3, idxs3  = matcher(descriptors_5[0], descriptors_6[0])\n        \n        cur_kp1 = kornia_feature.get_laf_center(lafs1).detach().cpu().numpy().reshape(-1, 2)\n        cur_kp2 = kornia_feature.get_laf_center(lafs2).detach().cpu().numpy().reshape(-1, 2)\n        \n        cur_kp3 = kornia_feature.get_laf_center(lafs3).detach().cpu().numpy().reshape(-1, 2)\n        cur_kp4 = kornia_feature.get_laf_center(lafs4).detach().cpu().numpy().reshape(-1, 2)\n        \n        cur_kp5 = kornia_feature.get_laf_center(lafs5).detach().cpu().numpy().reshape(-1, 2)\n        cur_kp6 = kornia_feature.get_laf_center(lafs6).detach().cpu().numpy().reshape(-1, 2)\n        \n        cur_kp1 = np.concatenate((cur_kp1, cur_kp3, cur_kp5))\n        cur_kp2 = np.concatenate((cur_kp2, cur_kp4, cur_kp6))\n        \n        match_idxs = np.concatenate((idxs.detach().cpu().numpy(), idxs2.detach().cpu().numpy(), idxs3.detach().cpu().numpy()))\n\n    # Make sure we do not trigger an exception here.\n    if len(match_idxs) > 8:\n        F, inlier_mask = cv2.findFundamentalMat(cur_kp1[match_idxs[:, 0]], cur_kp2[match_idxs[:, 1]],\n                                                cv2.USAC_MAGSAC,\n                                                ransacReprojThreshold=0.25,\n                                                confidence=0.79,\n                                                maxIters=10000)\n        assert F.shape == (3, 3), 'Malformed F?'\n        F_dict[sample_id] = F\n    else:\n        F_dict[sample_id] = np.zeros((3, 3))\n        continue\n    gc.collect()\n\n    if i < 2:\n        draw_LAF_matches(lafs1.cpu(), lafs2.cpu(),\n                         match_idxs, image_1, image_2,\n                         inlier_mask=inlier_mask.astype(np.bool), draw_dict=draw_dict)\n        plt.title(f'{image_1_id}-{image_2_id}')\n        plt.axis('off')\n        plt.show()\n\nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')\n\nif dry_run:\n    !cat submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:28:39.638672Z","iopub.execute_input":"2022-04-09T12:28:39.638937Z","iopub.status.idle":"2022-04-09T12:28:49.135107Z","shell.execute_reply.started":"2022-04-09T12:28:39.638908Z","shell.execute_reply":"2022-04-09T12:28:49.134234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center>\n    <h2 style=\"color: #dc3545\"> Thanks for reading ü§ó </h2>","metadata":{}}]}