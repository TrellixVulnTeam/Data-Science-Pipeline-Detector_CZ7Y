{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***If you found it useful please upvote ))***\n\n\n![](https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/trevi-canvas-licensed-nonoderivs.jpg)","metadata":{}},{"cell_type":"markdown","source":"# ***Install Libs***","metadata":{}},{"cell_type":"code","source":"dry_run = False\n!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-04-14T18:49:40.305524Z","iopub.execute_input":"2022-04-14T18:49:40.305924Z","iopub.status.idle":"2022-04-14T18:50:36.766944Z","shell.execute_reply.started":"2022-04-14T18:49:40.305837Z","shell.execute_reply":"2022-04-14T18:50:36.766134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Import dependencies***","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport csv\nfrom glob import glob\nimport torch\nimport matplotlib.pyplot as plt\nimport kornia\nfrom kornia_moons.feature import *\nimport kornia as K\nimport kornia.feature as KF\nimport gc\n","metadata":{"execution":{"iopub.status.busy":"2022-04-14T18:50:36.769211Z","iopub.execute_input":"2022-04-14T18:50:36.769418Z","iopub.status.idle":"2022-04-14T18:50:38.793299Z","shell.execute_reply.started":"2022-04-14T18:50:36.769393Z","shell.execute_reply":"2022-04-14T18:50:38.792459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Model***","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda')\nmatcher = KF.LoFTR(pretrained=None)\nmatcher.load_state_dict(torch.load(\"../input/kornia-loftr/loftr_outdoor.ckpt\")['state_dict'])\nmatcher = matcher.to(device).eval()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T18:50:38.797975Z","iopub.execute_input":"2022-04-14T18:50:38.800156Z","iopub.status.idle":"2022-04-14T18:50:42.404641Z","shell.execute_reply.started":"2022-04-14T18:50:38.800116Z","shell.execute_reply":"2022-04-14T18:50:42.403931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Utils*","metadata":{}},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]\n\n\ndef FlattenMatrix(M, num_digits=8):\n    '''Convenience function to write CSV files.'''\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\n\ndef load_torch_image(fname, device):\n    img = cv2.imread(fname)\n    scale = 840 / max(img.shape[0], img.shape[1]) \n    w = int(img.shape[1] * scale)\n    h = int(img.shape[0] * scale)\n    img = cv2.resize(img, (w, h))\n    img = K.image_to_tensor(img, False).float() /255.\n    img = K.color.bgr_to_rgb(img)\n    return img.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T19:00:59.103803Z","iopub.execute_input":"2022-04-14T19:00:59.104317Z","iopub.status.idle":"2022-04-14T19:00:59.113818Z","shell.execute_reply.started":"2022-04-14T19:00:59.104276Z","shell.execute_reply":"2022-04-14T19:00:59.113156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Inference***","metadata":{}},{"cell_type":"code","source":"F_dict = {}\nimport time\nfor i, row in enumerate(test_samples):\n    sample_id, batch_id, image_1_id, image_2_id = row\n    # Load the images.\n    st = time.time()\n    image_1 =load_torch_image(f'{src}/test_images/{batch_id}/{image_1_id}.png', device)\n    image_2 = load_torch_image(f'{src}/test_images/{batch_id}/{image_2_id}.png', device)\n    print(image_1.shape)\n    input_dict = {\"image0\": K.color.rgb_to_grayscale(image_1), \n              \"image1\": K.color.rgb_to_grayscale(image_2)}\n\n    with torch.no_grad():\n        correspondences = matcher(input_dict)\n        \n    mkpts0 = correspondences['keypoints0'].cpu().numpy()\n    mkpts1 = correspondences['keypoints1'].cpu().numpy()\n    \n    if len(mkpts0) > 7:\n        F, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.5, 0.99999, 100000)\n        inliers = inliers > 0\n        assert F.shape == (3, 3), 'Malformed F?'\n        F_dict[sample_id] = F\n    else:\n        F_dict[sample_id] = np.zeros((3, 3))\n        continue\n    gc.collect()\n    nd = time.time()    \n    if (i < 3):\n        print(\"Running time: \", nd - st, \" s\")\n        draw_LAF_matches(\n        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n                                    torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n                                    torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n\n        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n        torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n        K.tensor_to_image(image_1),\n        K.tensor_to_image(image_2),\n        inliers,\n        draw_dict={'inlier_color': (0.2, 1, 0.2),\n                   'tentative_color': None, \n                   'feature_color': (0.2, 0.5, 1), 'vertical': False})\n    \nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T19:01:09.844182Z","iopub.execute_input":"2022-04-14T19:01:09.844433Z","iopub.status.idle":"2022-04-14T19:01:19.891213Z","shell.execute_reply.started":"2022-04-14T19:01:09.844405Z","shell.execute_reply":"2022-04-14T19:01:19.890281Z"},"trusted":true},"execution_count":null,"outputs":[]}]}