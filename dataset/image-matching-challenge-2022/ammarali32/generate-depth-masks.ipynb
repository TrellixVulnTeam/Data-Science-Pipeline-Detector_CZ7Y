{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T10:28:21.887455Z","iopub.execute_input":"2022-04-25T10:28:21.887779Z","iopub.status.idle":"2022-04-25T10:28:31.731628Z","shell.execute_reply.started":"2022-04-25T10:28:21.887679Z","shell.execute_reply":"2022-04-25T10:28:31.730768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport csv\nfrom glob import glob\nimport torch\nimport matplotlib.pyplot as plt\nimport gc\nimport sys\nimport cv2\nimport urllib.request\n\nmodel_type = \"DPT_Large\" \ndepth_estimator = torch.hub.load(\"intel-isl/MiDaS\", model_type)\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndepth_estimator.to(device)\ndepth_estimator.eval()\nmidas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\ntransform = midas_transforms.dpt_transform","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:28:31.733898Z","iopub.execute_input":"2022-04-25T10:28:31.734161Z","iopub.status.idle":"2022-04-25T10:30:36.114138Z","shell.execute_reply.started":"2022-04-25T10:28:31.734126Z","shell.execute_reply":"2022-04-25T10:30:36.113095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/image-matching-challenge-2022/train/\"\nlst = os.listdir(path)\nif not os.path.exists(\"depth_maps\"):\n    os.mkdir(\"depth_maps\")\nfor _folder in lst:\n    if os.path.isdir(path + _folder):\n        if not os.path.exists(\"depth_maps/\" + _folder):\n            os.mkdir(\"depth_maps/\" + _folder)\n        lst2 = os.listdir(path + _folder + \"/images/\")\n        for fname in lst2:\n            img = cv2.imread(path + _folder + \"/images/\" + fname)\n            scale = 640 / max(img.shape[0], img.shape[1]) \n            w = int(img.shape[1] * scale)\n            h = int(img.shape[0] * scale)\n            img = cv2.resize(img, (w, h))\n            input_batch = transform(img).to(device)\n            with torch.no_grad():\n                mask = depth_estimator(input_batch)\n\n                mask = torch.nn.functional.interpolate(\n                    mask.unsqueeze(1),\n                    size=img.shape[:2],\n                    mode=\"bicubic\",\n                    align_corners=False,\n                ).squeeze()\n\n            mask = mask.cpu().numpy()\n            cv2.imwrite(\"depth_maps/\" + _folder + \"/\" + fname, mask)\n            break","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:30:36.116184Z","iopub.execute_input":"2022-04-25T10:30:36.116808Z","iopub.status.idle":"2022-04-25T10:30:45.401669Z","shell.execute_reply.started":"2022-04-25T10:30:36.116763Z","shell.execute_reply":"2022-04-25T10:30:45.400904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}