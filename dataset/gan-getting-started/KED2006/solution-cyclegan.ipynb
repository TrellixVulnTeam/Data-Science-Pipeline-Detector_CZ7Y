{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Загрузка данных:","metadata":{"id":"ngdpeC1HqlBm"}},{"cell_type":"code","source":"#from google.colab import files\n#files.upload()\n\n#!mkdir -p ~/.kaggle\n#!cp kaggle.json ~/.kaggle/\n#!pip install kaggle\n#!chmod 600 /root/.kaggle/kaggle.json\n#!kaggle competitions download -c gan-getting-started\n#!unzip /content/gan-getting-started.zip","metadata":{"id":"7UladDi9qQIJ","outputId":"8000ad94-57c8-4970-9c52-7e89c8bb3abf","execution":{"iopub.status.busy":"2022-05-01T11:11:08.432126Z","iopub.execute_input":"2022-05-01T11:11:08.432577Z","iopub.status.idle":"2022-05-01T11:11:08.460596Z","shell.execute_reply.started":"2022-05-01T11:11:08.432461Z","shell.execute_reply":"2022-05-01T11:11:08.459717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms","metadata":{"id":"_1-MpZE2qqQm","execution":{"iopub.status.busy":"2022-05-01T11:30:03.802714Z","iopub.execute_input":"2022-05-01T11:30:03.80371Z","iopub.status.idle":"2022-05-01T11:30:05.637737Z","shell.execute_reply.started":"2022-05-01T11:30:03.803578Z","shell.execute_reply":"2022-05-01T11:30:05.636712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nimport random\n\nclass PairImageDataset(Dataset):\n    def __init__(self, transforms):\n        super().__init__()\n        self.path_monet = '../input/gan-getting-started/monet_jpg'\n        self.path_photoes = '../input/gan-getting-started/photo_jpg'\n        self.transforms = transforms\n\n        filenames_monet = []\n        for root, dirs, filenames in os.walk(self.path_monet):\n            for file_name in filenames:\n              if file_name.endswith('.jpg'):\n                filenames_monet.append(os.path.join( self.path_monet, file_name))\n\n        filenames_photoes = []\n        for root, dirs, filenames in os.walk(self.path_photoes):\n            for file_name in filenames:\n              if file_name.endswith('.jpg'):\n                filenames_photoes.append(os.path.join(self.path_photoes, file_name))\n        \n        self.images_monet = []\n        self.images_photoes = []\n        for file_name in filenames_monet:\n            with Image.open(file_name) as img:\n                self.images_monet.append(img.copy())\n        for file_name in filenames_photoes:\n            with Image.open(file_name) as img:\n                self.images_photoes.append(img.copy())\n\n    def __len__(self):\n        return min(len(self.images_monet) , len(self.images_photoes))\n\n    def __getitem__(self, index):\n        index_photo = index\n        index_photo = random.randint(0, len(self.images_photoes) - 1)\n        index_monet = index\n        #print(self.images_photoes[index_photo])\n        #print(self.transforms)\n        return self.transforms(self.images_photoes[index_photo]), self.transforms(self.images_monet[index_monet])\n        ","metadata":{"id":"yyi7MNqEr7YP","execution":{"iopub.status.busy":"2022-05-01T11:30:05.639604Z","iopub.execute_input":"2022-05-01T11:30:05.639943Z","iopub.status.idle":"2022-05-01T11:30:05.65333Z","shell.execute_reply.started":"2022-05-01T11:30:05.639912Z","shell.execute_reply":"2022-05-01T11:30:05.652218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"id":"QB4eojdjw02E","execution":{"iopub.status.busy":"2022-05-01T11:30:06.084767Z","iopub.execute_input":"2022-05-01T11:30:06.085355Z","iopub.status.idle":"2022-05-01T11:30:06.090445Z","shell.execute_reply.started":"2022-05-01T11:30:06.085321Z","shell.execute_reply":"2022-05-01T11:30:06.089247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = PairImageDataset(transformer)","metadata":{"id":"vPiFsKRjxIcJ","execution":{"iopub.status.busy":"2022-05-01T11:30:06.497734Z","iopub.execute_input":"2022-05-01T11:30:06.498316Z","iopub.status.idle":"2022-05-01T11:30:43.564906Z","shell.execute_reply.started":"2022-05-01T11:30:06.498282Z","shell.execute_reply":"2022-05-01T11:30:43.56396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimage_photo, image_monet = dataset[0]\nplt.imshow(image_photo.permute(1, 2, 0))\nplt.show()\nplt.imshow(image_monet.permute(1, 2, 0))\nplt.show()","metadata":{"id":"9tbmChgBxQoS","outputId":"420d8faf-cc42-4722-f388-66e8392800ad","execution":{"iopub.status.busy":"2022-05-01T11:30:43.567365Z","iopub.execute_input":"2022-05-01T11:30:43.567727Z","iopub.status.idle":"2022-05-01T11:30:44.165721Z","shell.execute_reply.started":"2022-05-01T11:30:43.567687Z","shell.execute_reply":"2022-05-01T11:30:44.164854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size = 5, num_workers = 0)","metadata":{"id":"K23GevW9x9Cr","execution":{"iopub.status.busy":"2022-05-01T11:30:44.166932Z","iopub.execute_input":"2022-05-01T11:30:44.167589Z","iopub.status.idle":"2022-05-01T11:30:44.173274Z","shell.execute_reply.started":"2022-05-01T11:30:44.167544Z","shell.execute_reply":"2022-05-01T11:30:44.172198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"IBASUTD8mets","execution":{"iopub.status.busy":"2022-05-01T11:30:44.176405Z","iopub.execute_input":"2022-05-01T11:30:44.177422Z","iopub.status.idle":"2022-05-01T11:30:44.251976Z","shell.execute_reply.started":"2022-05-01T11:30:44.177342Z","shell.execute_reply":"2022-05-01T11:30:44.251037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(dataset.images_monet))\nprint(len(dataset.images_photoes))","metadata":{"id":"tlOnY8acKZr_","outputId":"896c447b-6f4d-4184-de42-bed2c2842736","execution":{"iopub.status.busy":"2022-05-01T11:30:44.253619Z","iopub.execute_input":"2022-05-01T11:30:44.254083Z","iopub.status.idle":"2022-05-01T11:30:44.266019Z","shell.execute_reply.started":"2022-05-01T11:30:44.254039Z","shell.execute_reply":"2022-05-01T11:30:44.264964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создадим класс для обучения и сохранения модели","metadata":{"id":"VAdeUC_gVoHL"}},{"cell_type":"code","source":"import itertools\n\nclass CycleGAN:\n    def __init__(self, \n                 generator_monet2photo,\n                 generator_photo2monet,\n                 descriminator_photo,\n                 descriminator_monet):\n        self.generator_monet2photo = generator_monet2photo\n        self.generator_photo2monet = generator_photo2monet\n        self.descriminator_monet = descriminator_monet\n        self.descriminator_photo = descriminator_photo\n\n        self.descriminator_loss = nn.MSELoss()\n        self.image_loss = nn.L1Loss()\n\n        self.optimizer_generator_monet = torch.optim.Adam(\n            self.generator_monet2photo.parameters(), \n            lr = 1e-3, betas = (0.5, 0.996))\n        self.optimizer_generator_photo = torch.optim.Adam(\n            self.generator_photo2monet.parameters(), \n            lr = 1e-3, betas = (0.5, 0.996))\n\n        self.optimizer_descriminator_monet = torch.optim.Adam(self.descriminator_monet.parameters(), lr = 1e-3, betas = (0.5, 0.996))\n        self.optimizer_descriminator_photo = torch.optim.Adam(self.descriminator_photo.parameters(), lr = 1e-3, betas = (0.5, 0.996))\n\n    def fit_one_batch(self, photoes, monets, alpha):\n\n        self.optimizer_generator_photo.zero_grad()\n        self.optimizer_generator_monet.zero_grad()\n        #generator_photo2monet loss\n\n        ones = torch.ones((monets.shape[0], 1 * 16 * 16)).to(device)\n        zeros = torch.zeros((monets.shape[0], 1 * 16 * 16)).to(device)\n        \n        fake_monet = self.generator_photo2monet(photoes)\n        fake_photo = self.generator_monet2photo(monets)\n        \n        reconstructed_photo = self.generator_monet2photo(fake_monet)\n        reconstructed_monet = self.generator_photo2monet(fake_photo)\n        \n        loss_gen = 2 * (self.image_loss(fake_monet, photoes) + self.image_loss(fake_photo, monets)) / 2 \n        \n        loss_gen += (self.descriminator_loss(self.descriminator_monet(fake_monet), ones) + \\\n                     self.descriminator_loss(self.descriminator_photo(fake_photo), ones)) / 2\n        \n        \n        loss_gen += 9 * (self.image_loss(reconstructed_photo, photoes) +\\\n                     self.image_loss(reconstructed_monet, monets)) / 2 \n        \n        loss_gen.backward()\n        self.optimizer_generator_photo.step()\n        self.optimizer_generator_monet.step()\n\n        #descriminator_monet loss\n\n        self.optimizer_descriminator_monet.zero_grad()\n\n        real_monets_score = self.descriminator_monet(monets)\n        target_real_monets_score = torch.ones((monets.shape[0], 1 * 16 * 16)).to(device)\n\n        fake_monets_score = self.descriminator_monet(fake_monet.detach())\n        target_fake_monets_score = torch.zeros((fake_monet.shape[0], 1 * 16 * 16)).to(device)\n\n        loss_descriminator_monet = self.descriminator_loss(real_monets_score, target_real_monets_score) + \\\n                                   self.descriminator_loss(fake_monets_score, target_fake_monets_score)\n        loss_descriminator_monet /= 2\n        loss_descriminator_monet.backward()\n        self.optimizer_descriminator_monet.step()\n\n        #descriminator_photos loss\n        self.optimizer_descriminator_photo.zero_grad()\n\n        real_photos_score = self.descriminator_photo(photoes)\n        target_real_photos_score = torch.ones((photoes.shape[0], 1 * 16 * 16)).to(device)\n\n        fake_photos_score = self.descriminator_photo(fake_photo.detach())\n        target_fake_photos_score = torch.zeros((fake_photo.shape[0],1 * 16 * 16)).to(device)\n\n        loss_descriminator_photos = self.descriminator_loss(real_photos_score, target_real_photos_score) + \\\n                                    self.descriminator_loss(fake_photos_score, target_fake_photos_score)\n        loss_descriminator_photos /= 2\n\n        loss_descriminator_photos.backward()\n        self.optimizer_descriminator_photo.step()\n\n    def predict(self, photo):\n        return self.generator_photo2monet(photo)\n    \n    def predict_monet(self, photo):\n        return self.generator_monet2photo(photo)\n\n    def save(self, epoch):\n        torch.save(self.generator_photo2monet, f'generator_photo2monet_{epoch}.bin')\n        #torch.save(self.generator_monet2photo, f'generator_monet2photo_{epoch}.bin')\n        #torch.save(self.descriminator_monet, f'descriminator_monet_{epoch}.bin')\n        #torch.save(self.descriminator_photo, f'descriminator_photo_{epoch}.bin')\n        \n    def pretrain_generators(self, photoes, monets):\n        \n        self.pretrain_optimizer_p2m.zero_grad()\n        fake_photoes = self.generator_photo2monet(photoes)\n        loss_photoes = self.pretrain_loss(fake_photoes, photoes)\n        loss_photoes.backward()\n        self.pretrain_optimizer_p2m.step()\n\n        self.pretrain_optimizer_m2p.zero_grad()\n        fake_monets = self.generator_monet2photo(monets)\n        loss_monets = self.pretrain_loss(fake_monets, monets)\n        loss_monets.backward()\n        self.pretrain_optimizer_m2p.step()\n\n    def load(self, path):\n        self.generator_photo2monet = torch.load(path)\n        \n    def train(self):\n        self.generator_photo2monet.train()\n        self.generator_monet2photo.train()\n        self.descriminator_monet.train()\n        self.descriminator_photo.train()\n        \n    def eval(self):\n        self.generator_photo2monet.eval()\n        self.generator_monet2photo.eval()\n        self.descriminator_monet.eval()\n        self.descriminator_photo.eval()","metadata":{"id":"lPgQx-qhBLG3","execution":{"iopub.status.busy":"2022-05-01T11:30:44.267859Z","iopub.execute_input":"2022-05-01T11:30:44.268542Z","iopub.status.idle":"2022-05-01T11:30:44.327573Z","shell.execute_reply.started":"2022-05-01T11:30:44.268488Z","shell.execute_reply":"2022-05-01T11:30:44.3261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создадим сами модели","metadata":{"id":"AhFqdeNjVvn3"}},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.module = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.01),\n        )\n\n    def forward(self, X):\n        return self.module(X)\n\n    \nclass BlockConv2(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, 2, 1),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.01),\n        )\n\n    def forward(self, X):\n        return self.model(X)","metadata":{"id":"mb_soFOGVjLV","execution":{"iopub.status.busy":"2022-05-01T11:30:44.329963Z","iopub.execute_input":"2022-05-01T11:30:44.330814Z","iopub.status.idle":"2022-05-01T11:30:44.358969Z","shell.execute_reply.started":"2022-05-01T11:30:44.33065Z","shell.execute_reply":"2022-05-01T11:30:44.356625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpNet(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Upsample(scale_factor = 2, mode='nearest'),\n            Block(in_channels, out_channels),\n            Block(out_channels, out_channels),\n        )\n    def forward(self, X):\n        return self.model(X)","metadata":{"id":"CuCE7LKMVjLV","execution":{"iopub.status.busy":"2022-05-01T11:30:44.361964Z","iopub.execute_input":"2022-05-01T11:30:44.362328Z","iopub.status.idle":"2022-05-01T11:30:44.37846Z","shell.execute_reply.started":"2022-05-01T11:30:44.362278Z","shell.execute_reply":"2022-05-01T11:30:44.376378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.model = nn.Sequential(\n            Block(in_channels, out_channels),\n            Block(out_channels, out_channels)\n        )\n    def forward(self, X):\n        return self.model(X) + X\n    \nclass ResNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            Block(3, 16),\n            BlockConv2(16, 64),\n            BlockConv2(64, 128),\n            #BlockConv2(128, 128),\n            \n            ResBlock(128, 128),\n            ResBlock(128, 128),\n            ResBlock(128, 128),\n            ResBlock(128, 128),\n            ResBlock(128, 128),\n            ResBlock(128, 128),\n            ResBlock(128, 128),\n            \n            #UpNet(128, 128),\n            UpNet(128, 64),\n            UpNet(64, 16),\n            #ResBlock(64, 64),\n            nn.Conv2d(16, 3, 3, 1, 1),\n            nn.Tanh()\n        )\n    def forward(self, X):\n        return self.model(X)","metadata":{"id":"yOJxWatkVjLV","execution":{"iopub.status.busy":"2022-05-01T11:30:44.379858Z","iopub.execute_input":"2022-05-01T11:30:44.383034Z","iopub.status.idle":"2022-05-01T11:30:44.404874Z","shell.execute_reply.started":"2022-05-01T11:30:44.382988Z","shell.execute_reply":"2022-05-01T11:30:44.402206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiscriminatorRes(nn.Module):\n    def __init__(self):\n        super(DiscriminatorRes, self).__init__()\n        \n        self.model = nn.Sequential(\n            Block(3, 16),\n            BlockConv2(16, 32),#128\n            Block(32, 64), \n            BlockConv2(64, 64),#64\n            Block(64, 128),\n            BlockConv2(128, 128), # 32\n            BlockConv2(128, 128), # 16\n            nn.Conv2d(128, 1, 3, 1, 1),\n            nn.Flatten()\n        )\n        \n        self.scale_factor = 16\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"id":"L3MOmmyoVjLW","execution":{"iopub.status.busy":"2022-05-01T11:30:44.412157Z","iopub.execute_input":"2022-05-01T11:30:44.412893Z","iopub.status.idle":"2022-05-01T11:30:44.422698Z","shell.execute_reply.started":"2022-05-01T11:30:44.412847Z","shell.execute_reply":"2022-05-01T11:30:44.421376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Загружу предобученную(мной) модель","metadata":{"id":"WwvReNOnVy1H"}},{"cell_type":"code","source":"model = CycleGAN(ResNet().to(device), \n                 ResNet().to(device),\n                 DiscriminatorRes().to(device), \n                 DiscriminatorRes().to(device))\n\n\nmodel.load('../input/last-120/generator_photo2monet_80.bin')","metadata":{"id":"AKZKF7bGgvxM","execution":{"iopub.status.busy":"2022-05-01T11:30:44.425168Z","iopub.execute_input":"2022-05-01T11:30:44.42611Z","iopub.status.idle":"2022-05-01T11:30:48.145701Z","shell.execute_reply.started":"2022-05-01T11:30:44.426056Z","shell.execute_reply":"2022-05-01T11:30:48.144808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В оригинале я обучал на 80 эпохах, здесь num_epochs = 1 поставленно для демонстрации результатов","metadata":{"id":"KoFhzudXV3Ro"}},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom torchvision.utils import make_grid\n\ndef convert_image(x):\n    return make_grid(x, nrows = x.shape[0], normalize=True)\n\nnum_epochs = 1\ni = 0\n\nfor epoch in tqdm(range(num_epochs)):\n    for photo_batch, monet_batch in tqdm(dataloader):\n        i += 1\n        alpha = 10\n        if epoch > 10:\n            alpha = 4\n        model.fit_one_batch(photo_batch.to(device), monet_batch.to(device), alpha)\n        \n        if True:\n            fig = plt.figure(figsize=(15, 15))\n            predicted_photo = model.predict(photo_batch.to(device))\n            fig.add_subplot(1, 3, 1)\n            \n            plt.imshow(convert_image(photo_batch[0]).permute(1, 2, 0).cpu())\n\n            fig.add_subplot(1, 3, 2)\n            plt.imshow(convert_image(monet_batch[0]).permute(1, 2, 0).cpu())\n\n            fig.add_subplot(1, 3, 3)\n            plt.imshow(convert_image(predicted_photo[0]).permute(1, 2, 0).cpu().detach().numpy())\n            \n            \n            plt.title(f\"epoch {epoch + 1}\")\n            plt.show()\n    if epoch % 5 == 4:\n        model.save(epoch + 1)","metadata":{"id":"09ZdxIhcjag5","outputId":"d242217d-e434-4237-d826-0c908f19b013","execution":{"iopub.status.busy":"2022-05-01T11:30:48.148063Z","iopub.execute_input":"2022-05-01T11:30:48.148398Z","iopub.status.idle":"2022-05-01T11:31:55.281867Z","shell.execute_reply.started":"2022-05-01T11:30:48.148358Z","shell.execute_reply":"2022-05-01T11:31:55.281046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission to Kaggle:","metadata":{"id":"pXpXSeJ9WH32"}},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nclass ImageDataset(Dataset):\n    def __init__(self, transforms):\n        super().__init__()\n        self.path_monet = '../input/gan-getting-started/monet_jpg'\n        self.path_photoes = '../input/gan-getting-started/photo_jpg'\n        self.transforms = transforms\n\n        filenames_monet = []\n        for root, dirs, filenames in os.walk(self.path_monet):\n            for file_name in filenames:\n                if file_name.endswith('.jpg'):\n                    filenames_monet.append(os.path.join( self.path_monet, file_name))\n\n        filenames_photoes = []\n        for root, dirs, filenames in os.walk(self.path_photoes):\n            for file_name in filenames:\n                if file_name.endswith('.jpg'):\n                    filenames_photoes.append(os.path.join(self.path_photoes, file_name))\n        \n        self.images_monet = []\n        self.images_photoes = []\n        for file_name in filenames_monet:\n            with Image.open(file_name) as img:\n                self.images_monet.append(img.copy())\n        for file_name in filenames_photoes:\n            with Image.open(file_name) as img:\n                self.images_photoes.append(img.copy())\n\n    def __len__(self):\n        return len(self.images_photoes)\n\n    def __getitem__(self, index):\n        index_monet = index \n        index_photo = index\n        #print(self.images_photoes[index_photo])\n        #print(self.transforms)\n        return self.transforms(self.images_photoes[index_photo])\n        ","metadata":{"id":"9fejxsgUVjLX","execution":{"iopub.status.busy":"2022-05-01T11:31:55.283505Z","iopub.execute_input":"2022-05-01T11:31:55.284547Z","iopub.status.idle":"2022-05-01T11:31:55.313529Z","shell.execute_reply.started":"2022-05-01T11:31:55.284505Z","shell.execute_reply":"2022-05-01T11:31:55.311896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_ans = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"id":"zgU03TGyVjLY","execution":{"iopub.status.busy":"2022-05-01T11:31:55.315653Z","iopub.execute_input":"2022-05-01T11:31:55.316753Z","iopub.status.idle":"2022-05-01T11:31:55.330933Z","shell.execute_reply.started":"2022-05-01T11:31:55.316709Z","shell.execute_reply":"2022-05-01T11:31:55.3295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_for_ans = ImageDataset(transformer_ans)","metadata":{"id":"7KadiuKSVjLY","execution":{"iopub.status.busy":"2022-05-01T11:31:55.332854Z","iopub.execute_input":"2022-05-01T11:31:55.333308Z","iopub.status.idle":"2022-05-01T11:32:11.995142Z","shell.execute_reply.started":"2022-05-01T11:31:55.333246Z","shell.execute_reply":"2022-05-01T11:32:11.994223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ../images","metadata":{"id":"5VYMDOIAVjLY","execution":{"iopub.status.busy":"2022-05-01T11:32:11.996683Z","iopub.execute_input":"2022-05-01T11:32:11.996992Z","iopub.status.idle":"2022-05-01T11:32:12.847748Z","shell.execute_reply.started":"2022-05-01T11:32:11.996951Z","shell.execute_reply":"2022-05-01T11:32:12.846319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ph_dl = DataLoader(dataset_for_ans, batch_size=1, pin_memory=True)","metadata":{"id":"fparRQcdVjLY","execution":{"iopub.status.busy":"2022-05-01T11:32:12.850439Z","iopub.execute_input":"2022-05-01T11:32:12.851022Z","iopub.status.idle":"2022-05-01T11:32:12.858421Z","shell.execute_reply.started":"2022-05-01T11:32:12.85097Z","shell.execute_reply":"2022-05-01T11:32:12.857232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ntrans = transforms.ToPILImage()\n\n\nt = tqdm(ph_dl, leave=False, total=ph_dl.__len__())\nfor i, photo in enumerate(t):\n    with torch.no_grad():\n        output = model.predict(photo.to(device))\n        output = convert_image(output)\n        pred_monet = output.reshape(3, 256, 256)\n        pred_monet = pred_monet.cpu().detach()\n        if i % 400 == 0:\n            fig = plt.figure(figsize=(10, 10))\n            plt.imshow(pred_monet.permute(1,2,0))\n            plt.show()\n    #print(pred_monet.shape)\n    img = trans(pred_monet).convert(\"RGB\")\n    img.save(\"../images/\" + str(i+1) + \".jpg\")","metadata":{"id":"Y-yHRLR8VjLZ","execution":{"iopub.status.busy":"2022-05-01T11:32:12.860658Z","iopub.execute_input":"2022-05-01T11:32:12.86105Z","iopub.status.idle":"2022-05-01T11:33:54.516577Z","shell.execute_reply.started":"2022-05-01T11:32:12.860973Z","shell.execute_reply":"2022-05-01T11:33:54.515289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")\n","metadata":{"id":"cx1srnJUVjLZ","execution":{"iopub.status.busy":"2022-05-01T11:33:54.518417Z","iopub.execute_input":"2022-05-01T11:33:54.518898Z","iopub.status.idle":"2022-05-01T11:33:58.904812Z","shell.execute_reply.started":"2022-05-01T11:33:54.518822Z","shell.execute_reply":"2022-05-01T11:33:58.903833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Такое решение дает скор примерно 57","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"zlCPuPF6VjLZ"},"execution_count":null,"outputs":[]}]}