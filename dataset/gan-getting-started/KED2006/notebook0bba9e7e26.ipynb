{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T09:50:15.218029Z","iopub.execute_input":"2022-04-05T09:50:15.218635Z","iopub.status.idle":"2022-04-05T09:50:16.921972Z","shell.execute_reply.started":"2022-04-05T09:50:15.218536Z","shell.execute_reply":"2022-04-05T09:50:16.921259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nclass PairImageDataset(Dataset):\n    def __init__(self, transforms):\n        super().__init__()\n        self.path_monet = '../input/gan-getting-started/monet_jpg'\n        self.path_photoes = '../input/gan-getting-started/photo_jpg'\n        self.transforms = transforms\n\n        filenames_monet = []\n        for root, dirs, filenames in os.walk(self.path_monet):\n            for file_name in filenames:\n                if file_name.endswith('.jpg'):\n                    filenames_monet.append(os.path.join( self.path_monet, file_name))\n\n        filenames_photoes = []\n        for root, dirs, filenames in os.walk(self.path_photoes):\n            for file_name in filenames:\n                if file_name.endswith('.jpg'):\n                    filenames_photoes.append(os.path.join(self.path_photoes, file_name))\n        \n        self.images_monet = []\n        self.images_photoes = []\n        for file_name in filenames_monet:\n            with Image.open(file_name) as img:\n                self.images_monet.append(img.copy())\n        for file_name in filenames_photoes:\n            with Image.open(file_name) as img:\n                self.images_photoes.append(img.copy())\n\n    def __len__(self):\n        return min(len(self.images_monet) , len(self.images_photoes))\n\n    def __getitem__(self, index):\n        index_monet = index \n        index_photo = index\n        #print(self.images_photoes[index_photo])\n        #print(self.transforms)\n        return self.transforms(self.images_photoes[index_photo]), self.transforms(self.images_monet[index_monet])\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:16.923735Z","iopub.execute_input":"2022-04-05T09:50:16.923979Z","iopub.status.idle":"2022-04-05T09:50:16.935444Z","shell.execute_reply.started":"2022-04-05T09:50:16.923946Z","shell.execute_reply":"2022-04-05T09:50:16.93419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:16.936736Z","iopub.execute_input":"2022-04-05T09:50:16.937203Z","iopub.status.idle":"2022-04-05T09:50:16.944835Z","shell.execute_reply.started":"2022-04-05T09:50:16.937169Z","shell.execute_reply":"2022-04-05T09:50:16.944107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = PairImageDataset(transformer)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:16.948514Z","iopub.execute_input":"2022-04-05T09:50:16.948735Z","iopub.status.idle":"2022-04-05T09:50:48.309023Z","shell.execute_reply.started":"2022-04-05T09:50:16.948712Z","shell.execute_reply":"2022-04-05T09:50:48.308284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimage_photo, image_monet = dataset[0]\nplt.imshow(image_photo.permute(1, 2, 0))\nplt.show()\nplt.imshow(image_monet.permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.310677Z","iopub.execute_input":"2022-04-05T09:50:48.311252Z","iopub.status.idle":"2022-04-05T09:50:48.771473Z","shell.execute_reply.started":"2022-04-05T09:50:48.311211Z","shell.execute_reply":"2022-04-05T09:50:48.770832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size = 10, num_workers = 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.772605Z","iopub.execute_input":"2022-04-05T09:50:48.773282Z","iopub.status.idle":"2022-04-05T09:50:48.777428Z","shell.execute_reply.started":"2022-04-05T09:50:48.773246Z","shell.execute_reply":"2022-04-05T09:50:48.776597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.778668Z","iopub.execute_input":"2022-04-05T09:50:48.779056Z","iopub.status.idle":"2022-04-05T09:50:48.829454Z","shell.execute_reply.started":"2022-04-05T09:50:48.779006Z","shell.execute_reply":"2022-04-05T09:50:48.828673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 16, 3, 1, 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n            # 16 * 256 * 256\n\n            nn.Conv2d(16, 8, 4, 2, 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(8),\n            #8 * 128 * 128\n\n            nn.Conv2d(8, 8, 4, 2, 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(8),\n            #8 * 64 * 64,\n\n            nn.Conv2d(8, 4, 4, 2, 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(4),\n            # 4 * 32 * 32\n            \n            nn.Conv2d(4, 1, 4, 2, 1),\n            nn.ReLU(),\n            nn.BatchNorm2d(1),\n            # 1 * 16 * 16\n            nn.Flatten(),\n            nn.Linear(16 * 16, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        ).to(device)\n    def forward(self, X):\n        return self.model(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.830839Z","iopub.execute_input":"2022-04-05T09:50:48.83122Z","iopub.status.idle":"2022-04-05T09:50:48.946285Z","shell.execute_reply.started":"2022-04-05T09:50:48.831184Z","shell.execute_reply":"2022-04-05T09:50:48.9448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeneratorPhoto(nn.Module):\n    def __init__(self, alpha = 0.01):\n        super().__init__()\n        self.alpha = alpha\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 16, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(16),\n            #16 * 256 * 256\n            nn.Conv2d(16, 8, 4, 2, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(8),\n            #8 * 128 * 128\n            nn.Conv2d(8, 4, 4, 2, 1),\n            nn.LeakyReLU(self.alpha), \n            nn.BatchNorm2d(4),\n            # 4 * 64 * 64  \n            nn.Conv2d(4, 2, 3, 1, 1),\n\n            nn.Upsample(scale_factor = 2, mode='nearest'),\n            nn.Conv2d(2, 4, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(4),\n            # 4 * 128 * 128\n            nn.Upsample(scale_factor = 2, mode='nearest'),\n            nn.Conv2d(4, 16, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(16),\n            # 16 * 256 * 256\n            nn.Conv2d(16, 8, 3, 1, 1)\n        ).to(device)\n\n        self.after_concat = nn.Sequential(\n            nn.Conv2d(11, 6, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(6),\n\n            nn.Conv2d(6, 6, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(6),\n\n            nn.Conv2d(6, 3, 3, 1, 1),\n            nn.Sigmoid()\n        ).to(device)\n    def forward(self, X):\n        hidden = self.model(X)\n        hidden = torch.cat((hidden, X), 1)\n        return self.after_concat(hidden)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.947767Z","iopub.execute_input":"2022-04-05T09:50:48.948215Z","iopub.status.idle":"2022-04-05T09:50:48.960959Z","shell.execute_reply.started":"2022-04-05T09:50:48.948179Z","shell.execute_reply":"2022-04-05T09:50:48.960274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, alpha = 0.01):\n        super().__init__()\n        self.alpha = alpha\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 16, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(16),\n            #16 * 256 * 256\n            nn.Conv2d(16, 8, 4, 2, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(8),\n            #8 * 128 * 128\n            nn.Conv2d(8, 4, 4, 2, 1),\n            nn.LeakyReLU(self.alpha), \n            nn.BatchNorm2d(4),\n            # 4 * 64 * 64  \n            nn.Conv2d(4, 2, 3, 1, 1),\n\n            nn.Upsample(scale_factor = 2, mode='nearest'),\n            nn.Conv2d(2, 4, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(4),\n            # 4 * 128 * 128\n            nn.Upsample(scale_factor = 2, mode='nearest'),\n            nn.Conv2d(4, 16, 3, 1, 1),\n            nn.LeakyReLU(self.alpha),\n            nn.BatchNorm2d(16),\n            # 16 * 256 * 256\n            nn.Conv2d(16, 3, 3, 1, 1)\n        ).to(device)\n\n    def forward(self, X):\n        hidden = self.model(X)\n        return hidden","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.964301Z","iopub.execute_input":"2022-04-05T09:50:48.964563Z","iopub.status.idle":"2022-04-05T09:50:48.975593Z","shell.execute_reply.started":"2022-04-05T09:50:48.964528Z","shell.execute_reply":"2022-04-05T09:50:48.974899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.module = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n            nn.LeakyReLU(0.01),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, X):\n        return self.module(X)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.978476Z","iopub.execute_input":"2022-04-05T09:50:48.978665Z","iopub.status.idle":"2022-04-05T09:50:48.986586Z","shell.execute_reply.started":"2022-04-05T09:50:48.978641Z","shell.execute_reply":"2022-04-05T09:50:48.98579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BlockConv2(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, 2, 1),\n            nn.LeakyReLU(0.01),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, X):\n        return self.model(X)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:50:48.9878Z","iopub.execute_input":"2022-04-05T09:50:48.988077Z","iopub.status.idle":"2022-04-05T09:50:48.995786Z","shell.execute_reply.started":"2022-04-05T09:50:48.98802Z","shell.execute_reply":"2022-04-05T09:50:48.995081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n                  BlockConv2(3, 16), \n                  Block(16, 16)\n        )\n        self.pool1 = nn.MaxPool2d(4, 2, 1, return_indices=True)\n        # 16 * 64 * 64\n        self.conv2 = nn.Sequential(\n                BlockConv2(16, 8), \n                Block(8, 8)\n        )     \n        # 8 * 32 * 32 \n        self.pool2 = nn.MaxPool2d(4, 2, 1, return_indices=True)\n        # 8 * 16 * 16\n        self.conv3 = Block(8, 8)\n        # 4 * 16 * 16\n        # 8 * 32 * 32\n        self.unpool1 = nn.MaxUnpool2d(4, 2, 1)\n\n        self.up1 = nn.Sequential(\n                nn.Upsample(scale_factor = 2, mode='nearest'),\n                Block(8, 8),\n                Block(8, 16)\n        )\n        # 8 * 64 * 64\n        self.unpool2 = nn.MaxUnpool2d(4, 2, 1)\n\n        self.up2 = nn.Sequential(\n                nn.Upsample(scale_factor= 2, mode='nearest'),\n                Block(16, 16),\n                Block(16, 3)\n        )\n        # 3 * 256 * 256\n        self.last = nn.Sequential(\n            Block(6, 9),\n            Block(9, 6),\n            nn.Conv2d(6, 3, 3, 1, 1)\n        )\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, X):\n        hidden = self.conv1(X)\n        hidden, ind1 = self.pool1(hidden) \n        hidden = self.conv2(hidden) \n        hidden, ind2 = self.pool2(hidden) \n        hidden = self.conv3(hidden) \n        #print(hidden.shape, ind2.shape)\n        hidden = self.unpool1(hidden, ind2)\n        hidden = self.up1(hidden) \n        hidden = self.unpool2(hidden, ind1)\n        hidden = self.up2(hidden)\n        hidden = torch.cat((hidden, X), 1)\n        return self.sigmoid(self.last(hidden))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:09.147193Z","iopub.execute_input":"2022-04-05T09:53:09.147753Z","iopub.status.idle":"2022-04-05T09:53:09.160326Z","shell.execute_reply.started":"2022-04-05T09:53:09.147714Z","shell.execute_reply":"2022-04-05T09:53:09.158931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(dataset.images_monet))\nprint(len(dataset.images_photoes))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:09.498715Z","iopub.execute_input":"2022-04-05T09:53:09.49922Z","iopub.status.idle":"2022-04-05T09:53:09.505271Z","shell.execute_reply.started":"2022-04-05T09:53:09.499184Z","shell.execute_reply":"2022-04-05T09:53:09.504574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGAN:\n    def __init__(self, \n                 generator_monet2photo,\n                 generator_photo2monet,\n                 descriminator_photo,\n                 descriminator_monet):\n        self.generator_monet2photo = generator_monet2photo\n        self.generator_photo2monet = generator_photo2monet\n        self.descriminator_monet = descriminator_monet\n        self.descriminator_photo = descriminator_photo\n\n        self.descriminator_loss = nn.BCELoss()\n        self.image_loss = nn.MSELoss()\n\n        self.optimizer_generator_monet2photo = torch.optim.Adam(self.generator_monet2photo.parameters(), lr = 1e-3)\n        self.optimizer_generator_photo2monet = torch.optim.Adam(self.generator_photo2monet.parameters(), lr = 1e-3)\n\n        self.optimizer_descriminator_monet = torch.optim.Adam(self.descriminator_monet.parameters(), lr = 3e-5)\n        self.optimizer_descriminator_photo = torch.optim.Adam(self.descriminator_photo.parameters(), lr = 3e-5)\n\n        self.pretrain_optimizer_p2m = torch.optim.Adam(self.generator_photo2monet.parameters(), lr = 1e-3)\n        self.pretrain_optimizer_m2p = torch.optim.Adam(self.generator_monet2photo.parameters(), lr = 1e-3)\n\n        self.pretrain_loss = nn.MSELoss()\n\n\n    def fit_one_batch(self, photoes, monets, alpha):\n\n        #generator_photo2monet loss\n\n        fake_photo = self.generator_monet2photo(self.generator_photo2monet(photoes))\n        \n        fake_monet = self.generator_photo2monet(photoes)\n        score_fake_monet = self.descriminator_monet(fake_monet)\n        expected_score_fake_monet = torch.ones((fake_monet.shape[0], 1)).to(device) \n        \n        loss_photo2monet = alpha * self.image_loss(fake_photo, photoes) + self.descriminator_loss(score_fake_monet, expected_score_fake_monet)\n\n        #generator_monet2photo loss\n\n        fake_monet = self.generator_photo2monet(self.generator_monet2photo(monets))\n\n        fake_photo = self.generator_monet2photo(monets)\n        score_fake_photo = self.descriminator_photo(fake_photo)\n        excpected_score_fake_photo = torch.ones((fake_photo.shape[0], 1)).to(device) \n\n        loss_monet2photo = alpha * self.image_loss(fake_monet, monets) + self.descriminator_loss(score_fake_photo, excpected_score_fake_photo)\n\n        self.optimizer_generator_monet2photo.zero_grad()\n        self.optimizer_generator_photo2monet.zero_grad()\n        loss_photo2monet.backward()\n        loss_monet2photo.backward()\n        self.optimizer_generator_monet2photo.step()\n        self.optimizer_generator_photo2monet.step()\n\n        #descriminator_monet loss\n\n        real_monets_score = self.descriminator_monet(monets)\n        target_real_monets_score = torch.ones((monets.shape[0], 1)).to(device)\n\n        fake_monets = self.generator_photo2monet(photoes)\n        fake_monets_score = self.descriminator_monet(fake_monets)\n        target_fake_monets_score = torch.zeros((fake_monets.shape[0], 1)).to(device)\n\n        loss_descriminator_monet = self.descriminator_loss(real_monets_score, target_real_monets_score) + \\\n                                   self.descriminator_loss(fake_monets_score, target_fake_monets_score)\n\n        #descriminator_photos loss\n\n        real_photos_score = self.descriminator_photo(photoes)\n        target_real_photos_score = torch.ones((photoes.shape[0], 1)).to(device)\n\n        fake_photos = self.generator_monet2photo(monets)\n        fake_photos_score = self.descriminator_photo(fake_photos)\n        target_fake_photos_score = torch.zeros((fake_photos.shape[0], 1)).to(device)\n\n        loss_descriminator_photos = self.descriminator_loss(real_photos_score, target_real_photos_score) + \\\n                                    self.descriminator_loss(fake_photos_score, target_fake_photos_score)\n\n\n        self.optimizer_descriminator_monet.zero_grad()\n        self.optimizer_descriminator_photo.zero_grad()\n        loss_descriminator_monet.backward()\n        loss_descriminator_photos.backward()\n        self.optimizer_descriminator_monet.step()\n        self.optimizer_descriminator_photo.step()\n\n    def predict(self, photo):\n        return self.generator_photo2monet(photo)\n\n    def save(self, epoch):\n        torch.save(self.generator_photo2monet, f'generator_photo2monet_{epoch}.bin')\n        torch.save(self.generator_monet2photo, f'generator_monet2photo_{epoch}.bin')\n        torch.save(self.descriminator_monet, f'descriminator_monet_{epoch}.bin')\n        torch.save(self.descriminator_photo, f'descriminator_photo_{epoch}.bin')\n        \n    def load(self, \n             path_generator_photo2monet, \n             path_generator_monet2photo,\n             path_descriminator_monet,\n             path_descriminator_photo):\n        self.generator_photo2monet = torch.load(path_generator_photo2monet)\n        self.generator_monet2photo = torch.load(path_generator_monet2photo)\n        self.descriminator_monet = torch.load(path_descriminator_monet)\n        self.descriminator_photo = torch.load(path_descriminator_photo)\n        \n    def pretrain_generators(self, photoes, monets):\n        \n        self.pretrain_optimizer_p2m.zero_grad()\n        fake_photoes = self.generator_photo2monet(photoes)\n        loss_photoes = self.pretrain_loss(fake_photoes, photoes)\n        loss_photoes.backward()\n        self.pretrain_optimizer_p2m.step()\n\n        self.pretrain_optimizer_m2p.zero_grad()\n        fake_monets = self.generator_monet2photo(monets)\n        loss_monets = self.pretrain_loss(fake_monets, monets)\n        loss_monets.backward()\n        self.pretrain_optimizer_m2p.step()\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:09.666426Z","iopub.execute_input":"2022-04-05T09:53:09.666948Z","iopub.status.idle":"2022-04-05T09:53:09.693521Z","shell.execute_reply.started":"2022-04-05T09:53:09.666908Z","shell.execute_reply":"2022-04-05T09:53:09.692592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CycleGAN(UNet().to(device), \n                 UNet().to(device),\n                 Discriminator().to(device), \n                 Discriminator().to(device))\n\nmodel.load('../input/unet25/generator_photo2monet_25.bin',\n          '../input/unet25/generator_monet2photo_25.bin',\n          '../input/unet25/descriminator_monet_25.bin',\n          '../input/unet25/descriminator_photo_25.bin')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:09.826191Z","iopub.execute_input":"2022-04-05T09:53:09.826453Z","iopub.status.idle":"2022-04-05T09:53:09.885169Z","shell.execute_reply.started":"2022-04-05T09:53:09.826417Z","shell.execute_reply":"2022-04-05T09:53:09.884425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nclass ImageDataset(Dataset):\n    def __init__(self, transforms):\n        super().__init__()\n        self.path_monet = '../input/gan-getting-started/monet_jpg'\n        self.path_photoes = '../input/gan-getting-started/photo_jpg'\n        self.transforms = transforms\n\n        filenames_monet = []\n        for root, dirs, filenames in os.walk(self.path_monet):\n            for file_name in filenames:\n                if file_name.endswith('.jpg'):\n                    filenames_monet.append(os.path.join( self.path_monet, file_name))\n\n        filenames_photoes = []\n        for root, dirs, filenames in os.walk(self.path_photoes):\n            for file_name in filenames:\n                if file_name.endswith('.jpg'):\n                    filenames_photoes.append(os.path.join(self.path_photoes, file_name))\n        \n        self.images_monet = []\n        self.images_photoes = []\n        for file_name in filenames_monet:\n            with Image.open(file_name) as img:\n                self.images_monet.append(img.copy())\n        for file_name in filenames_photoes:\n            with Image.open(file_name) as img:\n                self.images_photoes.append(img.copy())\n\n    def __len__(self):\n        return len(self.images_photoes)\n\n    def __getitem__(self, index):\n        index_monet = index \n        index_photo = index\n        #print(self.images_photoes[index_photo])\n        #print(self.transforms)\n        return self.transforms(self.images_photoes[index_photo])\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:09.993784Z","iopub.execute_input":"2022-04-05T09:53:09.994143Z","iopub.status.idle":"2022-04-05T09:53:10.004786Z","shell.execute_reply.started":"2022-04-05T09:53:09.99411Z","shell.execute_reply":"2022-04-05T09:53:10.003649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer_ans = transforms.Compose([\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:10.167619Z","iopub.execute_input":"2022-04-05T09:53:10.167982Z","iopub.status.idle":"2022-04-05T09:53:10.171649Z","shell.execute_reply.started":"2022-04-05T09:53:10.167948Z","shell.execute_reply":"2022-04-05T09:53:10.170992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_for_ans = ImageDataset(transformer_ans)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:10.354175Z","iopub.execute_input":"2022-04-05T09:53:10.354514Z","iopub.status.idle":"2022-04-05T09:53:23.773965Z","shell.execute_reply.started":"2022-04-05T09:53:10.354485Z","shell.execute_reply":"2022-04-05T09:53:23.773198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ../images","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:23.775772Z","iopub.execute_input":"2022-04-05T09:53:23.776273Z","iopub.status.idle":"2022-04-05T09:53:24.571554Z","shell.execute_reply.started":"2022-04-05T09:53:23.776235Z","shell.execute_reply":"2022-04-05T09:53:24.570669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ph_dl = DataLoader(dataset_for_ans, batch_size=1, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:24.574521Z","iopub.execute_input":"2022-04-05T09:53:24.574801Z","iopub.status.idle":"2022-04-05T09:53:24.580339Z","shell.execute_reply.started":"2022-04-05T09:53:24.574768Z","shell.execute_reply":"2022-04-05T09:53:24.578977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ntrans = transforms.ToPILImage()\n\n\nt = tqdm(ph_dl, leave=False, total=ph_dl.__len__())\nfor i, photo in enumerate(t):\n    with torch.no_grad():\n        pred_monet = model.predict(photo.to(device)).reshape(3, 256, 256)\n        pred_monet = pred_monet.cpu().detach()\n        if i == 0:\n            plt.imshow(pred_monet.permute(1,2,0))\n            plt.show()\n    #print(pred_monet.shape)\n    img = trans(pred_monet).convert(\"RGB\")\n    img.save(\"../images/\" + str(i+1) + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:53:24.582712Z","iopub.execute_input":"2022-04-05T09:53:24.58326Z","iopub.status.idle":"2022-04-05T09:54:35.790414Z","shell.execute_reply.started":"2022-04-05T09:53:24.583224Z","shell.execute_reply":"2022-04-05T09:54:35.789583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:54:35.791748Z","iopub.execute_input":"2022-04-05T09:54:35.792085Z","iopub.status.idle":"2022-04-05T09:54:38.736675Z","shell.execute_reply.started":"2022-04-05T09:54:35.792034Z","shell.execute_reply":"2022-04-05T09:54:38.735984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}