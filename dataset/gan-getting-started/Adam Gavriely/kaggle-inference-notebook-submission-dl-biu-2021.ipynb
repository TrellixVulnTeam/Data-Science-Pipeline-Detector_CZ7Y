{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Deep Learning Inference Notebook**\n### Authors: Simon Raviv, Adam Gavriely\n##### Deep Learning Course BIU, 2021.\n---\n<br/>\n\nIn this project we were asked to train a Cycle GAN that can transfer style from images painted by Monet to 'regular' images using only 30 monet images.\n\nThe training notebook was submitted to the [Kaggle competition](https://www.kaggle.com/c/gan-getting-started) which use MiFID metric to evaluate the model performance.  \nOur best MiFID score was : **59.4**","metadata":{"id":"8vs_s613kymw"}},{"cell_type":"markdown","source":"# Load Required Libraries","metadata":{"id":"GLeFyk9ElBQn"}},{"cell_type":"code","source":"!pip install -q tensorflow-addons\n!pip install -q gdown","metadata":{"id":"CzCPMwMbW_PG","outputId":"9b1d9318-b173-4396-8b72-e45c31d6e02a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom glob import glob\nfrom tensorflow_addons.layers import InstanceNormalization","metadata":{"id":"xULApCVXdglG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Global Parameters & Paths","metadata":{"id":"TuqKyGcGeke1"}},{"cell_type":"code","source":"input_image_size = (256, 256, 3)\n\nchosen_monet_file_id = \"1diLgk2a-snDTHI7_nbqjJjKEZR8kXjPQ\"\nphotos_zip_file_id = \"1HCYFybMEle_KQaL2KBKoOPjEVq2eA0dz\"\nmonet_generator_file_id = '1c5aILyVkbBj20zxV2tpIDBn2esh1Q4le'\n\nchosen_monet_filename = 'chosen_monet.tfrec'\nphotos_tfrec_folder_name = 'photo_tfrec'\nmonet_generator_filename = 'monet_generator_model.h5'","metadata":{"id":"Ec6f-Q-ieTPN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the Data\n","metadata":{"id":"yFHaUZ4Mec7s"}},{"cell_type":"markdown","source":"## Download Remote Data","metadata":{"id":"nV8UFsuNWf6V"}},{"cell_type":"code","source":"def local_download_files_from_drive(id, filename, isZip=False):\n    file_url = f\"https://drive.google.com/uc?id={id}\"\n    ext = '.zip' if isZip else ''\n    gdown.download(file_url, filename+ext, quiet=True)\n    if isZip is True:\n        shutil.unpack_archive(filename+ext, extract_dir=filename)\n        os.remove(filename+ext)","metadata":{"id":"B3Iri4I-WlF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download all remote files to local memory:\nlocal_download_files_from_drive(monet_generator_file_id, monet_generator_filename)\nlocal_download_files_from_drive(chosen_monet_file_id, chosen_monet_filename)\nlocal_download_files_from_drive(photos_zip_file_id, photos_tfrec_folder_name, isZip=True)","metadata":{"id":"JO1n7I8sWfaF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility Function for Image Processing","metadata":{"id":"cajrgj0leodu"}},{"cell_type":"code","source":"# Map values in the range [-1, 1]\ndef normalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return (img / 127.5) - 1.0\n\n# Map values in the range [0, 255]\ndef denormalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return tf.cast((img + 1.0) * 127.5, tf.uint8)\n    \ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = normalize_img(image)\n    image = tf.reshape(image, [*input_image_size])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord)\n    return dataset\n\ndef visualize_dataset(dataset, rows, cols, images_normalized=True, imsize=3):\n    plt.figure(figsize=(cols*imsize,rows*imsize))\n    for i, im in enumerate(dataset.take(rows*cols)):\n        if images_normalized is True:\n            im = denormalize_img(im)\n        plt.subplot(rows, cols, i+1)\n        plt.imshow(im)\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"SrkN6IrseTde"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the non-Monet Photos","metadata":{"id":"hKVwICGyjFxv"}},{"cell_type":"code","source":"filenames = glob(f\"./{photos_tfrec_folder_name}/*.tfrec\")\nphoto_dataset = load_dataset(filenames)\nvisualize_dataset(photo_dataset, rows=2, cols=6)","metadata":{"id":"jxpVYpD1IF2L","outputId":"5a844236-d3bc-43f6-8fd4-c69a3242012d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Chosen Monet Files","metadata":{"id":"b5Q4x09EfCF2"}},{"cell_type":"code","source":"chosen_monet_dataset = load_dataset(chosen_monet_filename)\nvisualize_dataset(chosen_monet_dataset, rows=5, cols=6)","metadata":{"id":"szHLR6BDfBVG","outputId":"444db2a7-02a9-4b78-ce42-2f2cfd4cadad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Model and Visualize Predictions","metadata":{"id":"99nCLOYBjWtW"}},{"cell_type":"markdown","source":"We must define the special reflection padding layer in order to load the model","metadata":{"id":"yB8Z1UohsMB-"}},{"cell_type":"code","source":"class ReflectionPadding2D(tf.keras.layers.Layer):\n\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n\n    def call(self, input_tensor, mask=None):\n        padding_width, padding_height = self.padding\n        padding_tensor = [\n            [0, 0],\n            [padding_height, padding_height],\n            [padding_width, padding_width],\n            [0, 0],\n        ]\n        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'padding': self.padding\n        })\n        return config","metadata":{"id":"I0p_f1-GsK7u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_generator = tf.keras.models.load_model('./' + monet_generator_filename, compile=False, custom_objects={'ReflectionPadding2D': ReflectionPadding2D})","metadata":{"id":"aqt7ToA8WWYu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Predictions","metadata":{"id":"3JWxx93MjVR3"}},{"cell_type":"code","source":"def visualize_predictions(model, images_dateset, rows, cols, imsize=3):\n    plt.figure(figsize=(cols*imsize, rows*imsize))\n    amount_to_show = rows*cols\n    for i, img in zip(range(1, amount_to_show, 2), images_dateset.take(amount_to_show).batch(1)):\n        input_img = denormalize_img(img[0]).numpy()\n        plt.subplot(rows, cols, i)\n        plt.title(\"Input image\")\n        plt.imshow(input_img)\n\n        prediction = model(img, training=False).numpy()\n        prediction = denormalize_img(prediction[0])\n        plt.subplot(rows, cols, i+1)\n        plt.title(\"Translated image\")\n        plt.imshow(prediction)\n\n    plt.tight_layout()\n    plt.show()\n\nvisualize_predictions(monet_generator, photo_dataset, rows=3, cols=6, imsize=4)","metadata":{"id":"lZmrc6hOjUt-","outputId":"38efcf2b-5416-4905-f6bb-8122ac0a8f6a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see we perform pretty well on nature images such as water, skies, mountains etc. and perform not quite as well on other stuff images e.g geometric objects, animals or people.\n\nWe believe this is due to the fact that Monet chose to focused mainly on nature in his paintings. You can see from our manually selected 30 Monet images that we chose focus on that part of his paintings to make the learning of the model more accurate.\n","metadata":{"id":"NVur1pBBpcmA"}},{"cell_type":"markdown","source":"# Generate All the Photos to Monet Images\n\nFor kaggle submissions, set IN_KAGGLE to True.","metadata":{"id":"mBbYzUPM8NXm"}},{"cell_type":"code","source":"IN_KAGGLE = True\n\nif IN_KAGGLE is True:\n    !mkdir ../images\n    from PIL import Image\n    i = 1\n    for img in tqdm(photo_dataset.batch(1)):\n        prediction = monet_generator.predict(img)\n        prediction = denormalize_img(prediction)\n        im = Image.fromarray(prediction[0].numpy())\n        im.save(\"../images/\" + str(i) + \".jpg\")\n        i += 1\n\n    shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","metadata":{"id":"sJwcszCBtk5B"},"execution_count":null,"outputs":[]}]}