{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"  --- baseline ---  \n* v02 : batch_size=1, label smooth, ReflectionPad2d, LeakyReLU(0.2), BCELoss for adv_loss, 30epochs, aug(h-flip), init_normal, 0.5 x dis_loss, lambda_cyc=10, lambda_idt=5, CycleGAN baseline, lr_G=2e-4, lr_D=2e-4, beta=(0.5,0.999), LB=62.62883  \n* v03 : set_epoch, affine=True for InstanceNorm2d, batch_size=1, label smooth, ReflectionPad2d, LeakyReLU(0.2), BCELoss for adv_loss, 30epochs, aug(h-flip), init_normal, 0.5 x dis_loss, lambda_cyc=10, lambda_idt=5, CycleGAN baseline, lr_G=2e-4, lr_D=2e-4, beta=(0.5,0.999), LB=61.30498  \n* v07 : batch_size=32, n_procs=8, 1000epochs, aug(random resized crop, h-flip), set_epoch, affine=True for InstanceNorm2d, label smooth, ReflectionPad2d, LeakyReLU(0.2), BCELoss for adv_loss, init_normal, 0.5 x dis_loss, lambda_cyc=10, lambda_idt=5, CycleGAN baseline, lr_G=2e-4, lr_D=2e-4, beta=(0.5,0.999), LB=  ","metadata":{"papermill":{"duration":0.026183,"end_time":"2021-07-10T00:26:51.342994","exception":false,"start_time":"2021-07-10T00:26:51.316811","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"papermill":{"duration":11.071215,"end_time":"2021-07-10T00:27:02.439995","exception":false,"start_time":"2021-07-10T00:26:51.36878","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:29:51.844536Z","iopub.execute_input":"2021-07-20T13:29:51.84517Z","iopub.status.idle":"2021-07-20T13:30:03.859956Z","shell.execute_reply.started":"2021-07-20T13:29:51.845047Z","shell.execute_reply":"2021-07-20T13:30:03.858927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"papermill":{"duration":1.154933,"end_time":"2021-07-10T00:27:03.621735","exception":false,"start_time":"2021-07-10T00:27:02.466802","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:30:03.861446Z","iopub.execute_input":"2021-07-20T13:30:03.861781Z","iopub.status.idle":"2021-07-20T13:30:04.988843Z","shell.execute_reply.started":"2021-07-20T13:30:03.861733Z","shell.execute_reply":"2021-07-20T13:30:04.987839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n#!python pytorch-xla-env-setup.py --version nightly  --apt-packages libomp5 libopenblas-dev\n\n#!pip install -q cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl\n!pip install -q albumentations==0.4.6","metadata":{"executionInfo":{"elapsed":28623,"status":"ok","timestamp":1624373906447,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"qD8n0zXwWiRt","outputId":"8f142559-7309-4d1c-80d9-21f03d9499f4","papermill":{"duration":25.533887,"end_time":"2021-07-10T00:27:29.181592","exception":false,"start_time":"2021-07-10T00:27:03.647705","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:30:04.990703Z","iopub.execute_input":"2021-07-20T13:30:04.991171Z","iopub.status.idle":"2021-07-20T13:30:31.02301Z","shell.execute_reply.started":"2021-07-20T13:30:04.991138Z","shell.execute_reply":"2021-07-20T13:30:31.02186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n\n# os.environ['XLA_USE_BF16'] = \"1\"\n# os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'","metadata":{"papermill":{"duration":0.08628,"end_time":"2021-07-10T00:27:29.346473","exception":false,"start_time":"2021-07-10T00:27:29.260193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:30:31.026177Z","iopub.execute_input":"2021-07-20T13:30:31.026733Z","iopub.status.idle":"2021-07-20T13:30:31.032645Z","shell.execute_reply.started":"2021-07-20T13:30:31.026677Z","shell.execute_reply":"2021-07-20T13:30:31.031653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.__name__, torch.__version__)\n\nimport torch_xla\nprint(torch_xla.__name__, torch_xla.__version__)\n\nimport numpy as np\nprint(np.__name__, np.__version__)\n\n#device = xm.xla_device()\n#print(device)","metadata":{"executionInfo":{"elapsed":45691,"status":"ok","timestamp":1624373952124,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"jsnDmisBjN-2","outputId":"f015e348-0e9d-4d00-e8b6-c1ce3c02eace","papermill":{"duration":46.402035,"end_time":"2021-07-10T00:28:15.825424","exception":false,"start_time":"2021-07-10T00:27:29.423389","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:30:31.033869Z","iopub.execute_input":"2021-07-20T13:30:31.034569Z","iopub.status.idle":"2021-07-20T13:31:16.214693Z","shell.execute_reply.started":"2021-07-20T13:30:31.034536Z","shell.execute_reply":"2021-07-20T13:31:16.213061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.tensor([1.0]).numpy()","metadata":{"papermill":{"duration":0.099929,"end_time":"2021-07-10T00:28:16.00247","exception":false,"start_time":"2021-07-10T00:28:15.902541","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:16.216378Z","iopub.execute_input":"2021-07-20T13:31:16.216797Z","iopub.status.idle":"2021-07-20T13:31:16.236429Z","shell.execute_reply.started":"2021-07-20T13:31:16.216754Z","shell.execute_reply":"2021-07-20T13:31:16.235197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{"id":"LgH6G4wHY2rT","papermill":{"duration":0.077122,"end_time":"2021-07-10T00:28:16.156442","exception":false,"start_time":"2021-07-10T00:28:16.07932","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import random\nimport os\nimport torch\n\nVERSION = ''\n\ndef get_config():\n    config = {\n        'VERSION':VERSION,\n        'OUTPUT_PATH':'./',\n        'INPUT_PATH':'../input/gan-getting-started/',\n\n        'pretrain_path':None, \n        \n        'resolution':(256,256),\n        'input_resolution':(256,256),\n        \n        'lambda_cyc':10,\n        'lambda_idt':5,\n        'lr_G':8*2e-4,\n        'lr_D':8*2e-4,\n        'beta1':0.5,\n        'beta2':0.999,\n        'n_ite_D':1,\n        'num_workers':0, #8,\n        'fixed_noise_size':32,\n        'seed':42,\n        'epochs':1000, #30,\n        'show_epoch_list':[1]+np.arange(0,1000+10,10).tolist(),\n        'output_freq':100, #10,\n        'h_out':30,\n        'w_out':30,\n        'nprocs':8, #1,\n        'label_smooth':True,\n        \n        'tta':1,\n        'batch_size':32, #1, #8,\n        \n        'FP16':False,\n        #'device':xm.xla_device()\n    }\n    return config\n\nconfig = get_config()\n#device = config['device']\n#print(device)","metadata":{"papermill":{"duration":0.088078,"end_time":"2021-07-10T00:28:16.321935","exception":false,"start_time":"2021-07-10T00:28:16.233857","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:16.237936Z","iopub.execute_input":"2021-07-20T13:31:16.238225Z","iopub.status.idle":"2021-07-20T13:31:16.247778Z","shell.execute_reply.started":"2021-07-20T13:31:16.238199Z","shell.execute_reply":"2021-07-20T13:31:16.246644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries and Data","metadata":{"id":"2kewwDBUY4HP","papermill":{"duration":0.077481,"end_time":"2021-07-10T00:28:16.47651","exception":false,"start_time":"2021-07-10T00:28:16.399029","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.get_option(\"display.max_columns\")\npd.set_option('display.max_columns', 300)\npd.get_option(\"display.max_rows\")\npd.set_option('display.max_rows', 300)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport sys\nimport os\nfrom os.path import join as opj\nimport gc\nimport cv2\n\nos.makedirs(config['OUTPUT_PATH'], exist_ok=True)","metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1624373971294,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"Ufs97CGHWiTu","papermill":{"duration":0.276133,"end_time":"2021-07-10T00:28:16.829367","exception":false,"start_time":"2021-07-10T00:28:16.553234","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:16.250097Z","iopub.execute_input":"2021-07-20T13:31:16.250621Z","iopub.status.idle":"2021-07-20T13:31:16.4336Z","shell.execute_reply.started":"2021-07-20T13:31:16.250573Z","shell.execute_reply":"2021-07-20T13:31:16.432877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\n\nmonet_jpg_list = sorted(glob.glob(opj(config['INPUT_PATH'],'monet_jpg/*')))\nphoto_jpg_list = sorted(glob.glob(opj(config['INPUT_PATH'],'photo_jpg/*')))\n\nprint('len(monet_jpg_list) = ', len(monet_jpg_list))\nprint('len(photo_jpg_list) = ', len(photo_jpg_list))","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1624373973865,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"7b3-bHxiH1be","outputId":"f5019b3b-ce51-4ca1-8460-490774aba16e","papermill":{"duration":0.320184,"end_time":"2021-07-10T00:28:17.225446","exception":false,"start_time":"2021-07-10T00:28:16.905262","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:16.436564Z","iopub.execute_input":"2021-07-20T13:31:16.43695Z","iopub.status.idle":"2021-07-20T13:31:17.114169Z","shell.execute_reply.started":"2021-07-20T13:31:16.436918Z","shell.execute_reply":"2021-07-20T13:31:17.112919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"jiCUC8yQZZ-4","papermill":{"duration":0.076594,"end_time":"2021-07-10T00:28:17.378879","exception":false,"start_time":"2021-07-10T00:28:17.302285","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import random\nimport torch\nimport numpy as np\nimport os\nimport time\n\ndef fix_seed(seed):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \ndef elapsed_time(start_time):\n    return time.time() - start_time\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nfix_seed(2021)","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1624373973865,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"buVVwyO3ZbED","papermill":{"duration":0.094741,"end_time":"2021-07-10T00:28:17.550973","exception":false,"start_time":"2021-07-10T00:28:17.456232","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:17.116077Z","iopub.execute_input":"2021-07-20T13:31:17.116374Z","iopub.status.idle":"2021-07-20T13:31:17.129345Z","shell.execute_reply.started":"2021-07-20T13:31:17.116346Z","shell.execute_reply":"2021-07-20T13:31:17.127837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"lbVaoAKeZYCM","papermill":{"duration":0.078307,"end_time":"2021-07-10T00:28:17.707727","exception":false,"start_time":"2021-07-10T00:28:17.62942","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\ndef conv3x3(in_channel, out_channel): #not change resolusion\n    return nn.Conv2d(in_channel,out_channel,\n                      kernel_size=3,stride=1,padding=1,dilation=1,bias=False)\n\ndef conv1x1(in_channel, out_channel): #not change resolution\n    return nn.Conv2d(in_channel,out_channel,\n                      kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n\ndef init_weight(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        #nn.init.orthogonal_(m.weight, gain=1)\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            m.bias.data.zero_()\n            \n    elif classname.find('Batch') != -1:\n        m.weight.data.normal_(1,0.02)\n        m.bias.data.zero_()\n    \n    elif classname.find('Linear') != -1:\n        #nn.init.orthogonal_(m.weight, gain=1)\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    \n    elif classname.find('Embedding') != -1:\n        #nn.init.orthogonal_(m.weight, gain=1)\n        nn.init.normal_(m.weight, 0, 0.02)","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1624373973865,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"K5BiJAZ8VjRl","papermill":{"duration":0.091945,"end_time":"2021-07-10T00:28:17.87784","exception":false,"start_time":"2021-07-10T00:28:17.785895","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:17.130912Z","iopub.execute_input":"2021-07-20T13:31:17.131207Z","iopub.status.idle":"2021-07-20T13:31:17.146377Z","shell.execute_reply.started":"2021-07-20T13:31:17.13118Z","shell.execute_reply":"2021-07-20T13:31:17.144842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, use_norm=True):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, \n                              kernel_size=4, stride=2, padding=1, bias=False).apply(init_weight)\n        if use_norm:\n            self.norm = nn.InstanceNorm2d(out_channels, affine=True).apply(init_weight)\n        else:\n            self.norm = nn.Identity()\n        self.relu = nn.LeakyReLU(0.2, True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = self.relu(x)\n        return x\n\n\nclass UpBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, dropout=False):\n        super().__init__()\n        self.conv = nn.ConvTranspose2d(in_channels, out_channels, \n                                       kernel_size=4, stride=2, padding=1, bias=False).apply(init_weight)\n        self.norm = nn.InstanceNorm2d(out_channels, affine=True).apply(init_weight)\n        if dropout:\n            self.dropout = nn.Dropout2d(0.5)\n        else:\n            self.dropout = nn.Identity()\n        self.relu = nn.ReLU(True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.norm(x)\n        x = self.dropout(x)\n        x = self.relu(x)\n        return x\n\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.down_stack = nn.ModuleList([\n            DownBlock(  3, 64, use_norm=False), # (bs,64,128,128)\n            DownBlock( 64,128), # (bs,128,64,64)\n            DownBlock(128,256), # (bs,256,32,32)\n            DownBlock(256,512), # (bs,512,16,16)\n            DownBlock(512,512), # (bs,512,8,8)\n            DownBlock(512,512), # (bs,512,4,4)\n            DownBlock(512,512), # (bs,512,2,2)\n            #DownBlock(512,512), # (bs,512,1,1)\n           ])\n        self.up_stack = nn.ModuleList([\n            #UpBlock( 512,512, dropout=True), # (bs,512,2,2)\n            UpBlock( 512,512, dropout=True), # (bs,512,4,4)\n            UpBlock(1024,512, dropout=True), # (bs,512,8,8)\n            UpBlock(1024,512), # (bs,512,16,16)\n            UpBlock(1024,256), # (bs,256,32,32)\n            UpBlock( 512,128), # (bs,128,64,64)\n            UpBlock( 256, 64), # (bs,64,128,128)\n        ])\n        self.last_layer = nn.Sequential(\n            nn.ConvTranspose2d(128,3, kernel_size=4, stride=2, padding=1, bias=False).apply(init_weight),\n            nn.Tanh()\n        )\n\n    def forward(self, x): # (bs,3,256,256)\n        skips = []\n        for down in self.down_stack:\n            x = down(x)\n            skips.append(x)\n        skips = reversed(skips[:-1])\n        for up,skip in zip(self.up_stack, skips):\n            x = torch.cat([up(x), skip], dim=1)\n        x = self.last_layer(x)\n        return x \n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.down_blocks = nn.Sequential(\n            DownBlock(  3, 64, use_norm=False),\n            DownBlock( 64,128),\n            DownBlock(128,256),\n        )\n        #self.pad = nn.ZeroPad2d(1)\n        self.pad = nn.ReflectionPad2d(1)\n        self.conv = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=0, bias=False).apply(init_weight),\n            nn.InstanceNorm2d(512, affine=True).apply(init_weight),\n            nn.LeakyReLU(0.2, True)\n        )\n        self.last_conv = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False).apply(init_weight)\n\n    def forward(self, x): # (bs,3,256,256)\n        x = self.down_blocks(x) # (bs,256,32,32)\n        x = self.pad(x) # (bs,256,34,34)\n        x = self.conv(x) # (bs,256,31,31)\n        x = self.pad(x) # (bs,256,33,33)\n        x = self.last_conv(x) # (bs,256,30,30)\n        return x","metadata":{"executionInfo":{"elapsed":456,"status":"ok","timestamp":1624373974317,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"JhVRHpqOoajw","papermill":{"duration":0.107575,"end_time":"2021-07-10T00:28:18.06262","exception":false,"start_time":"2021-07-10T00:28:17.955045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:17.148424Z","iopub.execute_input":"2021-07-20T13:31:17.148822Z","iopub.status.idle":"2021-07-20T13:31:17.176525Z","shell.execute_reply.started":"2021-07-20T13:31:17.148786Z","shell.execute_reply":"2021-07-20T13:31:17.174534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('count_paramters(Generator()) = {:.2f} M'.format(count_parameters(Generator()) / 1e+6))\nprint('count_paramters(Discriminator()) = {:.2f} M'.format(count_parameters(Discriminator()) / 1e+6))\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:31:17.178393Z","iopub.execute_input":"2021-07-20T13:31:17.178732Z","iopub.status.idle":"2021-07-20T13:31:18.339798Z","shell.execute_reply.started":"2021-07-20T13:31:17.178703Z","shell.execute_reply":"2021-07-20T13:31:18.33888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# net = Generator()\n# a = torch.randn(2,3,256,256)\n# net(a).shape","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1624373974317,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"vYCfzvNGV79a","papermill":{"duration":1.571407,"end_time":"2021-07-10T00:28:19.712258","exception":false,"start_time":"2021-07-10T00:28:18.140851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:18.34151Z","iopub.execute_input":"2021-07-20T13:31:18.341967Z","iopub.status.idle":"2021-07-20T13:31:18.346013Z","shell.execute_reply.started":"2021-07-20T13:31:18.341925Z","shell.execute_reply":"2021-07-20T13:31:18.344837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"tIsg0790ZcJB","papermill":{"duration":0.077214,"end_time":"2021-07-10T00:28:19.868605","exception":false,"start_time":"2021-07-10T00:28:19.791391","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom albumentations import (Compose, HorizontalFlip, VerticalFlip, Rotate, RandomRotate90,\n                            ShiftScaleRotate, ElasticTransform, GridDistortion,\n                            Resize, RandomResizedCrop, RandomSizedCrop, RandomCrop, CenterCrop,\n                            RandomBrightnessContrast, HueSaturationValue, IAASharpen,\n                            RandomGamma, RandomBrightness, RandomBrightnessContrast,\n                            GaussianBlur,CLAHE,\n                            Cutout, CoarseDropout, GaussNoise, ChannelShuffle, ToGray, OpticalDistortion,\n                            Normalize, OneOf, NoOp)\nfrom albumentations.pytorch import ToTensor, ToTensorV2\n#from get_config import *\n#config = get_config()\n\n#MEAN = np.array([0.485, 0.456, 0.406])\n#STD  = np.array([0.229, 0.224, 0.225])\n\nMEAN = np.array([0.5, 0.5, 0.5])\nSTD = np.array([0.5, 0.5, 0.5])\n\n\ndef get_transforms_train():\n    transforms = Compose([\n        Resize(config['input_resolution'][0], config['input_resolution'][1]),\n        RandomResizedCrop(config['input_resolution'][0], config['input_resolution'][1],\n                          scale=(0.75,1.0), ratio=(1,1), interpolation=1, p=1.0),\n        HorizontalFlip(p=0.5),\n        Normalize(mean=MEAN, std=STD),\n        ToTensorV2(),\n    ] )\n    return transforms\n\n\ndef get_transforms_test():\n    transforms = Compose([\n        Resize(config['input_resolution'][0], config['input_resolution'][1]),\n        Normalize(mean=MEAN, std=STD),\n        ToTensorV2(),\n    ] )\n    return transforms\n\ndef denormalize(z, mean=MEAN.reshape(-1,1,1), std=STD.reshape(-1,1,1)):\n    return std*z + mean","metadata":{"executionInfo":{"elapsed":1643,"status":"ok","timestamp":1624373975958,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"eBFXy8ViZiXG","papermill":{"duration":2.003959,"end_time":"2021-07-10T00:28:21.951457","exception":false,"start_time":"2021-07-10T00:28:19.947498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:18.347564Z","iopub.execute_input":"2021-07-20T13:31:18.348008Z","iopub.status.idle":"2021-07-20T13:31:20.048285Z","shell.execute_reply.started":"2021-07-20T13:31:18.347965Z","shell.execute_reply":"2021-07-20T13:31:20.047379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass MonetPhotoDatasetTrain(Dataset):\n    def __init__(self, monet_jpg_list, photo_jpg_list, mode='train'):\n        super().__init__()\n        if mode=='train':\n            self.transforms = get_transforms_train()\n        elif mode=='valid':\n            self.transforms = get_transforms_test()\n        self.h, self.w = config['resolution']\n        self.monet_jpg_list = monet_jpg_list\n        self.photo_jpg_list = photo_jpg_list\n        self.rand = np.random.permutation(np.arange(len(self.photo_jpg_list)))[:len(self.monet_jpg_list)]\n\n    def __len__(self):\n        return len(self.monet_jpg_list)\n\n    def __getitem__(self, idx):\n        img_monet = cv2.imread(self.monet_jpg_list[idx])\n        img_monet = cv2.cvtColor(img_monet, cv2.COLOR_BGR2RGB)\n        img_photo = cv2.imread(self.photo_jpg_list[self.rand[idx]])\n        img_photo = cv2.cvtColor(img_photo, cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            img_monet = self.transforms(image=img_monet.astype(np.uint8))['image']\n            img_photo = self.transforms(image=img_photo.astype(np.uint8))['image']\n        return {'img_monet':img_monet, 'img_photo':img_photo}\n\n\n\nclass PhotoDatasetTest(Dataset):\n    def __init__(self, photo_jpg_list):\n        super().__init__()\n        self.transforms = get_transforms_test()\n        self.h, self.w = config['resolution']\n        self.photo_jpg_list = photo_jpg_list\n\n    def __len__(self):\n        return len(self.photo_jpg_list)\n\n    def __getitem__(self, idx):\n        img_photo = cv2.imread(self.photo_jpg_list[idx])\n        img_photo = cv2.cvtColor(img_photo, cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            img_photo = self.transforms(image=img_photo.astype(np.uint8))['image']\n        return {'img_photo':img_photo}","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1624373975967,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"noISdPySZiun","papermill":{"duration":0.0933,"end_time":"2021-07-10T00:28:22.123745","exception":false,"start_time":"2021-07-10T00:28:22.030445","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:20.049616Z","iopub.execute_input":"2021-07-20T13:31:20.049966Z","iopub.status.idle":"2021-07-20T13:31:20.063933Z","shell.execute_reply.started":"2021-07-20T13:31:20.04993Z","shell.execute_reply":"2021-07-20T13:31:20.063011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 0\ndummy = MonetPhotoDatasetTrain(monet_jpg_list, photo_jpg_list, mode='train')[idx]\n\nimg_monet = dummy['img_monet'].numpy()\nimg_monet = denormalize(img_monet).transpose(1,2,0)\nimg_photo = dummy['img_photo'].numpy()\nimg_photo = denormalize(img_photo).transpose(1,2,0)\n\n\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.imshow(img_monet)\nplt.subplot(1,2,2)\nplt.imshow(img_photo)\nplt.show()","metadata":{"executionInfo":{"elapsed":625,"status":"ok","timestamp":1624373976582,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"Pwwfyl5-ZihX","outputId":"664b4520-8e8e-4eb8-8c56-8f52823972b5","papermill":{"duration":0.534163,"end_time":"2021-07-10T00:28:22.735473","exception":false,"start_time":"2021-07-10T00:28:22.20131","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:20.065034Z","iopub.execute_input":"2021-07-20T13:31:20.065504Z","iopub.status.idle":"2021-07-20T13:31:20.543389Z","shell.execute_reply.started":"2021-07-20T13:31:20.065472Z","shell.execute_reply":"2021-07-20T13:31:20.542597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train (on Multicore TPU)","metadata":{"papermill":{"duration":0.08978,"end_time":"2021-07-10T00:28:22.917981","exception":false,"start_time":"2021-07-10T00:28:22.828201","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def generate_img(epoch, imgs):\n    for i in range(len(imgs)):\n        # denormalize\n        img = denormalize(imgs[i].numpy())\n        img = (255*img).astype(np.uint8)\n        # save\n        save_path = opj(config['OUTPUT_PATH'], 'img_{:02d}_epoch{}.jpg'.format(i, epoch))\n        img = img.transpose(1,2,0)\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # rgb -> bgr\n        cv2.imwrite(save_path, img) # bgr -> rgb","metadata":{"papermill":{"duration":0.097736,"end_time":"2021-07-10T00:28:23.105151","exception":false,"start_time":"2021-07-10T00:28:23.007415","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:20.544363Z","iopub.execute_input":"2021-07-20T13:31:20.544739Z","iopub.status.idle":"2021-07-20T13:31:20.550839Z","shell.execute_reply.started":"2021-07-20T13:31:20.544711Z","shell.execute_reply":"2021-07-20T13:31:20.549724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport pandas as pd\nimport numpy as np\nimport gc\nfrom os.path import join as opj\nimport pickle\nfrom tqdm import tqdm_notebook as tqdm\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.serialization as xser\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.utils.data import DataLoader\n\n\ndef map_fn(index, netG_m2p, netG_p2m, netD_m, netD_p, config, monet_jpg_list, photo_jpg_list, fixed_img_photo):\n    # setup\n    start_time = time.time()\n    torch.manual_seed(config['seed'])\n    device = xm.xla_device()\n\n    # model\n    xm.master_print(\"model setup...\")\n\n    netG_m2p = netG_m2p.to(device)\n    netG_p2m = netG_p2m.to(device)\n    netD_m = netD_m.to(device)\n    netD_p = netD_p.to(device)\n\n    if config['label_smooth']:\n        real_label = 0.9\n    else:\n        real_label = 1.0\n    fake_label = 0.0\n\n    h_out = config['h_out']\n    w_out = config['w_out']\n    \n    G_m2p_loss_list = []\n    G_p2m_loss_list = []\n    D_m_loss_list = []\n    D_p_loss_list = []\n    consistency_loss_list = []\n    identity_loss_list = []\n    \n    xm.master_print('loss setup...')\n    dis_criterion = nn.BCEWithLogitsLoss().to(device)\n    #dis_criterion = nn.MSELoss().to(device)\n    cycle_criterion = nn.L1Loss().to(device)\n    identity_criterion = nn.L1Loss().to(device)\n\n    xm.master_print('optimizer setup...')\n    optimizerG_m2p = optim.Adam(netG_m2p.parameters(), lr=config['lr_G'], betas=(config['beta1'], config['beta2']))\n    optimizerG_p2m = optim.Adam(netG_p2m.parameters(), lr=config['lr_G'], betas=(config['beta1'], config['beta2']))\n    optimizerD_m = optim.Adam(netD_m.parameters(), lr=config['lr_D'], betas=(config['beta1'], config['beta2']))\n    optimizerD_p = optim.Adam(netD_p.parameters(), lr=config['lr_D'], betas=(config['beta1'], config['beta2']))\n\n    netG_m2p.train()\n    netG_p2m.train()\n    netD_m.train()\n    netD_p.train()\n\n    # Barrier to prevent master from exiting before workers connect.\n    xm.rendezvous('init')\n\n    #training\n    print(\"Process {}, training start.\".format(index)) \n    for epoch in range(1,config['epochs']+1):\n\n        # dataset\n        train_dataset = MonetPhotoDatasetTrain(monet_jpg_list, photo_jpg_list, mode='train')\n        \n        # sampler\n        train_sampler = DistributedSampler(\n            train_dataset,\n            num_replicas=config['nprocs'], #xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n        )\n        \n        train_sampler.set_epoch(epoch)\n\n        # dataloader\n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=config['batch_size'],\n            sampler=train_sampler, \n            num_workers=config['num_workers'], \n            drop_last=True,\n            )     \n\n        tracker = xm.RateTracker()\n        para_train_loader = pl.ParallelLoader(train_loader, [device]).per_device_loader(device)\n\n        count = 0\n        D_m_running_loss = 0\n        D_p_running_loss = 0\n        G_m2p_running_loss = 0\n        G_p2m_running_loss = 0\n        consistency_loss = 0\n        identity_loss = 0\n        \n        for ii, data in enumerate(para_train_loader):\n            batch_size = len(data)\n            \n            # label\n            pos_label = torch.full((config['batch_size'], 1, h_out, w_out), real_label, device=device)\n            neg_label = torch.full((config['batch_size'], 1, h_out, w_out), fake_label, device=device)\n            \n            # real images\n            img_monet_real = data['img_monet'].to(device, non_blocking=True) \n            img_photo_real = data['img_photo'].to(device, non_blocking=True) \n            \n            ############################\n            # Update G network\n            ###########################\n            netG_p2m.zero_grad()\n            netG_m2p.zero_grad()\n            \n            # monet to photo back to monet\n            img_photo_fake  = netG_m2p(img_monet_real)\n            img_monet_cycle = netG_p2m(netG_m2p(img_monet_real))\n            \n            # photo to monet back to photo\n            img_monet_fake  = netG_p2m(img_photo_real)\n            img_photo_cycle = netG_m2p(netG_p2m(img_photo_real))\n            \n            # generating itself\n            img_monet_same = netG_p2m(img_monet_real)\n            img_photo_same = netG_m2p(img_photo_real)\n            \n            # loss for generator\n            loss_gen_monet = dis_criterion(netD_m(img_monet_fake), pos_label)\n            loss_gen_photo = dis_criterion(netD_p(img_photo_fake), pos_label)\n            \n            loss_gen_cycle  = config['lambda_cyc'] * cycle_criterion(img_monet_cycle, img_monet_real)\n            loss_gen_cycle += config['lambda_cyc'] * cycle_criterion(img_photo_cycle, img_photo_real)\n            \n            loss_gen_same   = config['lambda_idt'] * identity_criterion(img_monet_same, img_monet_real)\n            loss_gen_same  += config['lambda_idt'] * identity_criterion(img_photo_same, img_photo_real)\n            \n            # backward\n            loss_gen_monet.backward(retain_graph=True)\n            loss_gen_photo.backward(retain_graph=True)\n            loss_gen_cycle.backward(retain_graph=False)\n            loss_gen_same.backward(retain_graph=False)\n            \n            # update\n            xm.optimizer_step(optimizerG_m2p)  # Note: barrier=True not needed when using ParallelLoader \n            xm.optimizer_step(optimizerG_p2m)  # Note: barrier=True not needed when using ParallelLoader \n            \n            # logging\n            count += 1.0\n            G_p2m_running_loss += loss_gen_monet.item()\n            G_m2p_running_loss += loss_gen_photo.item()\n            consistency_loss   += loss_gen_cycle.item()\n            identity_loss      += loss_gen_same.item()\n            \n            ############################\n            # Update D network\n            ###########################\n            netD_m.zero_grad()\n            netD_p.zero_grad()\n            \n            # monet discriminator\n            dis_monet_real = netD_m(img_monet_real)\n            dis_monet_fake = netD_m(netG_p2m(img_photo_real).detach())\n            \n            # photo discriminator\n            dis_photo_real = netD_p(img_photo_real)\n            dis_photo_fake = netD_p(netG_m2p(img_monet_real).detach())\n            \n            # loss for discriminator\n            loss_dis_monet  = dis_criterion(dis_monet_real, pos_label)\n            loss_dis_monet += dis_criterion(dis_monet_fake, neg_label)\n            loss_dis_monet *= 0.5\n            loss_dis_photo  = dis_criterion(dis_photo_real, pos_label)\n            loss_dis_photo += dis_criterion(dis_photo_fake, neg_label)\n            loss_dis_photo *= 0.5\n            \n            # backward\n            loss_dis_monet.backward(retain_graph=False)\n            loss_dis_photo.backward(retain_graph=False)\n            \n            # update\n            xm.optimizer_step(optimizerD_m)  # Note: barrier=True not needed when using ParallelLoader \n            xm.optimizer_step(optimizerD_p)  # Note: barrier=True not needed when using ParallelLoader \n            \n            # logging\n            D_m_running_loss += loss_dis_monet.item()\n            D_p_running_loss += loss_dis_photo.item()\n            \n        \n        del para_train_loader\n        gc.collect()\n        \n        # normalize\n        D_m_running_loss /= count\n        D_p_running_loss /= count\n        G_m2p_running_loss /= count\n        G_p2m_running_loss /= count\n        consistency_loss /= count\n        identity_loss /= count\n        \n        # output\n        if (epoch==1) or (epoch % config['output_freq'] == 0):\n            #xm.save(netG_m2p.state_dict(), opj(config['OUTPUT_PATH'], f\"generator_m2p_epoch{epoch}.bin\"))\n            #xm.save(netG_p2m.state_dict(), opj(config['OUTPUT_PATH'], f\"generator_p2m_epoch{epoch}.bin\"))\n            #xm.save(netD_m.state_dict(), opj(config['OUTPUT_PATH'], f\"discriminator_m_epoch{epoch}.bin\"))\n            #xm.save(netD_p.state_dict(), opj(config['OUTPUT_PATH'], f\"discriminator_p_epoch{epoch}.bin\"))\n            #xm.do_on_ordinals(generate_img, (epoch, netG_p2m(fixed_img_photo.to(device)).detach()), (0,))\n            xm.master_print('[Process {}, {:d}/{:d}] D_m_loss = {:.3f}, D_p_loss = {:.3f}, elapsed_time = {:.1f} min'.format(index, epoch, config['epochs'], \n                                                                                                      D_m_running_loss, D_p_running_loss,\n                                                                                                      elapsed_time(start_time)/60))\n            xm.master_print('  G_m2p_loss = {:.3f}, G_p2m_loss = {:.3f}, consistency loss = {:.3f}, identity_loss = {:.3f}'.format(G_m2p_running_loss, G_p2m_running_loss,\n                                                                                                      consistency_loss, identity_loss))\n            \n        gc.collect()\n        # log\n        D_m_loss_list.append(D_m_running_loss)\n        D_p_loss_list.append(D_p_running_loss)\n        G_m2p_loss_list.append(G_m2p_running_loss)\n        G_p2m_loss_list.append(G_p2m_running_loss)\n        consistency_loss_list.append(consistency_loss)\n        identity_loss_list.append(identity_loss)\n            \n    gc.collect()\n    xm.master_print('Saving Model...')\n    xm.save(netG_m2p.state_dict(), opj(config['OUTPUT_PATH'], \"generator_m2p.bin\"))\n    xm.save(netG_p2m.state_dict(), opj(config['OUTPUT_PATH'], \"generator_p2m.bin\"))\n    xm.save(netD_m.state_dict(), opj(config['OUTPUT_PATH'], \"discriminator_m.bin\"))\n    xm.save(netD_p.state_dict(), opj(config['OUTPUT_PATH'], \"discriminator_p.bin\"))\n    xm.master_print('Model Saved.')\n\n    if xm.is_master_ordinal():  # Divergent CPU-only computation (no XLA tensors beyond this point!)\n        with open(opj(config['OUTPUT_PATH'], 'D_m_loss_list'), 'wb') as f:\n            pickle.dump(D_m_loss_list, f)\n        with open(opj(config['OUTPUT_PATH'], 'D_p_loss_list'), 'wb') as f:\n            pickle.dump(D_p_loss_list, f)\n        with open(opj(config['OUTPUT_PATH'], 'G_m2p_loss_list'), 'wb') as f:\n            pickle.dump(G_m2p_loss_list, f)\n        with open(opj(config['OUTPUT_PATH'], 'G_p2m_loss_list'), 'wb') as f:\n            pickle.dump(G_p2m_loss_list, f)\n        with open(opj(config['OUTPUT_PATH'], 'consistency_loss_list'), 'wb') as f:\n            pickle.dump(consistency_loss_list, f)\n        with open(opj(config['OUTPUT_PATH'], 'identity_loss_list'), 'wb') as f:\n            pickle.dump(identity_loss_list, f)\n\n\ndef run_on_TPU(config, monet_jpg_list, photo_jpg_list):\n#     netG_m2p = Generator()\n#     netG_p2m = Generator()\n#     netD_m = Discriminator()\n#     netD_p = Discriminator()\n#     print('count_paramters(netG_m2p) = {:.2f} M'.format(count_parameters(netG_m2p) / 1e+6))\n#     print('count_paramters(netG_p2m) = {:.2f} M'.format(count_parameters(netG_p2m) / 1e+6))\n#     print('count_paramters(netD_m) = {:.2f} M'.format(count_parameters(netD_m) / 1e+6))\n#     print('count_paramters(netD_p) = {:.2f} M'.format(count_parameters(netD_p) / 1e+6))\n    netG_m2p = xmp.MpModelWrapper(Generator())\n    netG_p2m = xmp.MpModelWrapper(Generator())\n    netD_m = xmp.MpModelWrapper(Discriminator())\n    netD_p = xmp.MpModelWrapper(Discriminator())\n\n    # dataset\n    train_dataset = MonetPhotoDatasetTrain(monet_jpg_list, photo_jpg_list, mode='train')\n    fixed_img_photo = torch.stack([train_dataset[i]['img_photo'] for i in range(config['fixed_noise_size']) ])\n    del train_dataset\n    gc.collect()\n    \n    xmp.spawn(map_fn, args=(netG_m2p, netG_p2m, netD_m, netD_p, \n                            config, monet_jpg_list, photo_jpg_list, fixed_img_photo, ), \n              nprocs=config['nprocs'], start_method='fork')","metadata":{"papermill":{"duration":0.144488,"end_time":"2021-07-10T00:28:23.338443","exception":false,"start_time":"2021-07-10T00:28:23.193955","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:20.552058Z","iopub.execute_input":"2021-07-20T13:31:20.552486Z","iopub.status.idle":"2021-07-20T13:31:20.604811Z","shell.execute_reply.started":"2021-07-20T13:31:20.552459Z","shell.execute_reply":"2021-07-20T13:31:20.603992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n!free -h","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:31:20.60596Z","iopub.execute_input":"2021-07-20T13:31:20.60639Z","iopub.status.idle":"2021-07-20T13:31:21.5673Z","shell.execute_reply.started":"2021-07-20T13:31:20.606339Z","shell.execute_reply":"2021-07-20T13:31:21.566381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\nimport pickle\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nrun_on_TPU(config, monet_jpg_list, photo_jpg_list)","metadata":{"papermill":{"duration":4014.356583,"end_time":"2021-07-10T01:35:17.784436","exception":false,"start_time":"2021-07-10T00:28:23.427853","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:31:21.568719Z","iopub.execute_input":"2021-07-20T13:31:21.569196Z","iopub.status.idle":"2021-07-20T13:45:45.896336Z","shell.execute_reply.started":"2021-07-20T13:31:21.569163Z","shell.execute_reply":"2021-07-20T13:45:45.894346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(opj(config['OUTPUT_PATH'], 'D_m_loss_list'), 'rb') as f:\n    D_m_loss_list = pickle.load(f)\nwith open(opj(config['OUTPUT_PATH'], 'D_p_loss_list'), 'rb') as f:\n    D_p_loss_list = pickle.load(f)\nwith open(opj(config['OUTPUT_PATH'], 'G_m2p_loss_list'), 'rb') as f:\n    G_m2p_loss_list = pickle.load(f)\nwith open(opj(config['OUTPUT_PATH'], 'G_p2m_loss_list'), 'rb') as f:\n    G_p2m_loss_list = pickle.load(f)\nwith open(opj(config['OUTPUT_PATH'], 'consistency_loss_list'), 'rb') as f:\n    consistency_loss_list = pickle.load(f)\nwith open(opj(config['OUTPUT_PATH'], 'identity_loss_list'), 'rb') as f:\n    identity_loss_list = pickle.load(f)\n\nplt.figure(figsize=(12,6))\nplt.plot(D_m_loss_list, label='D_m_loss')\nplt.plot(D_p_loss_list, label='D_p_loss')\nplt.plot(G_m2p_loss_list, label='G_m2p_loss')\nplt.plot(G_p2m_loss_list, label='G_p2m_loss')\nplt.plot(consistency_loss_list, label='consistency_loss')\nplt.plot(identity_loss_list, label='identity_loss')\nplt.grid()\nplt.legend()\nplt.title('loss history');","metadata":{"papermill":{"duration":0.375838,"end_time":"2021-07-10T01:35:18.253885","exception":false,"start_time":"2021-07-10T01:35:17.878047","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:45:45.89916Z","iopub.execute_input":"2021-07-20T13:45:45.899764Z","iopub.status.idle":"2021-07-20T13:45:46.178854Z","shell.execute_reply.started":"2021-07-20T13:45:45.899683Z","shell.execute_reply":"2021-07-20T13:45:46.17781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import glob\n\n# def show_generate_imgs(img_path_list):\n#     fig = plt.figure(figsize=(25, 16))\n#     for i, path in enumerate(img_path_list):\n#         img = cv2.imread(path)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#         ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n#         plt.imshow(img)\n#     plt.show()\n#     plt.close()\n\n# for epoch in config['show_epoch_list']:\n#     if epoch==0:\n#         continue\n#     print('epoch = ', epoch)\n#     img_path_list = sorted(glob.glob(opj(config['OUTPUT_PATH'], '*epoch{}.jpg'.format(epoch))))\n#     show_generate_imgs(img_path_list)","metadata":{"papermill":{"duration":8.912649,"end_time":"2021-07-10T01:35:27.261538","exception":false,"start_time":"2021-07-10T01:35:18.348889","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:48:21.057323Z","iopub.execute_input":"2021-07-20T13:48:21.05798Z","iopub.status.idle":"2021-07-20T13:48:21.061633Z","shell.execute_reply.started":"2021-07-20T13:48:21.057944Z","shell.execute_reply":"2021-07-20T13:48:21.060944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"nckYetovt1QW","papermill":{"duration":0.326088,"end_time":"2021-07-10T01:35:27.919959","exception":false,"start_time":"2021-07-10T01:35:27.593871","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# model\nnetG_p2m = Generator()\nnetG_p2m.load_state_dict(torch.load(opj(config['OUTPUT_PATH'],'generator_p2m.bin')))\nnetG_p2m = netG_p2m.to(xm.xla_device()).eval()\n\n# photo data\nphoto_ds = PhotoDatasetTest(photo_jpg_list)\nprint('len(photo_ds) = ', len(photo_ds))","metadata":{"executionInfo":{"elapsed":18927,"status":"ok","timestamp":1624373995502,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"ER7f1miQqbmH","outputId":"4dd8d714-4fd3-44bd-d262-d5af6fa7ee57","papermill":{"duration":2.090398,"end_time":"2021-07-10T01:35:30.333272","exception":false,"start_time":"2021-07-10T01:35:28.242874","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:45:46.65778Z","iopub.execute_input":"2021-07-20T13:45:46.658143Z","iopub.status.idle":"2021-07-20T13:45:54.003302Z","shell.execute_reply.started":"2021-07-20T13:45:46.658111Z","shell.execute_reply":"2021-07-20T13:45:54.00143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(photo_ds)):\n    if i==4:\n        break\n    img_photo = photo_ds[i]['img_photo']\n    img_pred  = netG_p2m(img_photo[None].to(xm.xla_device())).cpu().detach().numpy()[0]\n    img_pred  = denormalize(img_pred).transpose(1,2,0)\n    img_pred  = (255*img_pred).astype(np.uint8)\n    img_photo = denormalize(img_photo.numpy()).transpose(1,2,0)\n    img_photo = (255*img_photo).astype(np.uint8)\n\n    plt.figure(figsize=(12,6))\n    plt.subplot(1,2,1)\n    plt.imshow(img_photo)\n    plt.title('photo')\n    plt.subplot(1,2,2)\n    plt.imshow(img_pred)\n    plt.title('monet-esque')\n    plt.show()","metadata":{"papermill":{"duration":4.887337,"end_time":"2021-07-10T01:35:35.545347","exception":false,"start_time":"2021-07-10T01:35:30.65801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:45:54.005361Z","iopub.execute_input":"2021-07-20T13:45:54.00578Z","iopub.status.idle":"2021-07-20T13:45:58.916316Z","shell.execute_reply.started":"2021-07-20T13:45:54.005738Z","shell.execute_reply":"2021-07-20T13:45:58.915413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport PIL\nfrom tqdm.notebook import tqdm\n\nos.makedirs('../images', exist_ok=True)\n\nfor i in tqdm(range(len(photo_ds))):\n    img_photo = photo_ds[i]['img_photo']\n    img_pred  = netG_p2m(img_photo[None].to(xm.xla_device())).cpu().detach().numpy()[0]\n    img_pred  = denormalize(img_pred).transpose(1,2,0)\n    img_pred  = (255 * img_pred).astype(np.uint8)\n    #img_pred = cv2.cvtColor(img_pred, cv2.COLOR_RGB2BGR) # rgb -> bgr\n    save_path = '../images/{:04d}.jpg'.format(i)\n    #cv2.imwrite(save_path, img_pred) # bgr -> rgb\n    im = PIL.Image.fromarray(img_pred)\n    im.save(save_path)","metadata":{"executionInfo":{"elapsed":297267,"status":"ok","timestamp":1624374299929,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"gVa3PrRorgc2","outputId":"b166f4d2-0870-41d0-b304-65b047f1b37b","papermill":{"duration":203.12119,"end_time":"2021-07-10T01:38:59.051172","exception":false,"start_time":"2021-07-10T01:35:35.929982","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:47:46.915585Z","iopub.execute_input":"2021-07-20T13:47:46.916044Z","iopub.status.idle":"2021-07-20T13:47:59.498411Z","shell.execute_reply.started":"2021-07-20T13:47:46.916012Z","shell.execute_reply":"2021-07-20T13:47:59.497606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('/kaggle/working/images', 'zip', root_dir='../images')","metadata":{"executionInfo":{"elapsed":13813464,"status":"error","timestamp":1624388113379,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"TOW-WgI9ttsP","outputId":"5f4ac212-06b4-49c6-976b-c1958c573435","papermill":{"duration":9.690437,"end_time":"2021-07-10T01:39:09.110907","exception":false,"start_time":"2021-07-10T01:38:59.42047","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:45:59.452292Z","iopub.execute_input":"2021-07-20T13:45:59.452608Z","iopub.status.idle":"2021-07-20T13:45:59.46142Z","shell.execute_reply.started":"2021-07-20T13:45:59.452578Z","shell.execute_reply":"2021-07-20T13:45:59.460294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\ndef remove_glob(pathname, recursive=True):\n    for p in glob.glob(pathname, recursive=recursive):\n        if os.path.isfile(p):\n            os.remove(p)\n\nremove_glob('../images/*.jpg')","metadata":{"executionInfo":{"elapsed":397,"status":"aborted","timestamp":1624388112911,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"-nOo-5Kat831","papermill":{"duration":0.686103,"end_time":"2021-07-10T01:39:10.178874","exception":false,"start_time":"2021-07-10T01:39:09.492771","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-20T13:45:59.463251Z","iopub.execute_input":"2021-07-20T13:45:59.463677Z","iopub.status.idle":"2021-07-20T13:45:59.85976Z","shell.execute_reply.started":"2021-07-20T13:45:59.463637Z","shell.execute_reply":"2021-07-20T13:45:59.85881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"executionInfo":{"elapsed":396,"status":"aborted","timestamp":1624388112913,"user":{"displayName":"Takesako Tomohiro","photoUrl":"","userId":"06066946747265411870"},"user_tz":-540},"id":"BYD4H7lgwD4Z","papermill":{"duration":0.368764,"end_time":"2021-07-10T01:39:10.913891","exception":false,"start_time":"2021-07-10T01:39:10.545127","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}