{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e4e4caaf-1137-488b-a203-2f73a5fb7376","_cell_guid":"ddf47e42-f8be-48ff-9580-688a638d4883","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:05.235449Z","iopub.execute_input":"2021-06-21T09:20:05.235995Z","iopub.status.idle":"2021-06-21T09:20:05.239569Z","shell.execute_reply.started":"2021-06-21T09:20:05.235962Z","shell.execute_reply":"2021-06-21T09:20:05.238803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport random\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport keras\nfrom keras.layers import Input, Conv2D, add, Conv2DTranspose, Activation, LeakyReLU\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.optimizers import Adam\nimport numpy as np\nimport glob\nimport cv2\nimport os\n%matplotlib inline","metadata":{"_uuid":"8f8aee73-a872-4e71-822c-65763dc286b2","_cell_guid":"ccba5618-a6bf-414c-a632-0aeea8c4e824","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:05.240987Z","iopub.execute_input":"2021-06-21T09:20:05.241425Z","iopub.status.idle":"2021-06-21T09:20:05.265791Z","shell.execute_reply.started":"2021-06-21T09:20:05.241396Z","shell.execute_reply":"2021-06-21T09:20:05.264963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = (256,256,3)\nkernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\ngamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)","metadata":{"_uuid":"3e2b268e-3096-4139-80a1-ee31e655ee5e","_cell_guid":"9ba55528-85ac-4177-a03b-e4b52a704625","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:05.267734Z","iopub.execute_input":"2021-06-21T09:20:05.268223Z","iopub.status.idle":"2021-06-21T09:20:05.273586Z","shell.execute_reply.started":"2021-06-21T09:20:05.268192Z","shell.execute_reply":"2021-06-21T09:20:05.272202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#setup img\n\nfiles_monet = glob.glob(\"/kaggle/input/gan-getting-started/monet_jpg/*\")\nmonet = np.zeros((len(files_monet),256,256,3))\ni = 0\nfor f in files_monet:\n  monet[i] = cv2.imread(f)\n  i+=1\n  \n\n#まずは練習用でデータ数をmonetに合わせる\nfiles_photo = glob.glob(\"/kaggle/input/gan-getting-started/photo_jpg/*\")\n#img = np.zeros((len(files),256,256,3))\nprint(len(files_photo))\nphoto = np.zeros((300,256,256,3))\ni = 0\nfor f in files_photo:\n  photo[i] = cv2.imread(f)\n  i+=1\n  if i ==300:\n      break;\n# print(photo[3])\n# print(photo[1].shape)\nphoto[23] /= 256\nplt.imshow(photo[23])\nplt.show()","metadata":{"_uuid":"158a2368-71e4-456c-8667-2c3285d057da","_cell_guid":"5e880ccb-be44-4e1e-af21-81d239193fe7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:05.275171Z","iopub.execute_input":"2021-06-21T09:20:05.275467Z","iopub.status.idle":"2021-06-21T09:20:08.128176Z","shell.execute_reply.started":"2021-06-21T09:20:05.275438Z","shell.execute_reply":"2021-06-21T09:20:08.126917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalizing(image):\n    #image = tf.cast(image, tf.float32)\n    #image = (image / 127.5) - 1\n    image = image/255\n    return image","metadata":{"_uuid":"0dde7403-c0ba-4dfd-bc99-d220e74b285c","_cell_guid":"375e7964-75dd-473b-80e9-cb6dca348ec5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:08.12944Z","iopub.execute_input":"2021-06-21T09:20:08.129743Z","iopub.status.idle":"2021-06-21T09:20:08.135121Z","shell.execute_reply.started":"2021-06-21T09:20:08.129685Z","shell.execute_reply":"2021-06-21T09:20:08.133953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet = normalizing(monet)\nphoto = normalizing(photo)\n\ntrain_monet = monet[:250]\ntrain_photo = photo[:250]\ntest_monet = monet[250:]\ntest_photo = photo[250:]","metadata":{"_uuid":"a6969a60-5707-4ac8-9ce2-6a396d993056","_cell_guid":"3e12b7ba-35b7-4636-aaa8-f457673c0ce2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:08.13659Z","iopub.execute_input":"2021-06-21T09:20:08.136914Z","iopub.status.idle":"2021-06-21T09:20:08.580617Z","shell.execute_reply.started":"2021-06-21T09:20:08.136887Z","shell.execute_reply":"2021-06-21T09:20:08.579561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build gan model\n\ndef downsample(x, filters, activation, kernel_initializer=kernel_init,\n               kernel_size=(3,3), strides=(2,2), padding=\"same\",\n               gamma_initializer=gamma_init, use_bias=False,):\n    \n    x = Conv2D(filters, kernel_size, strides=strides, kernel_initializer=kernel_initializer,\n               padding=padding, use_bias=use_bias,)(x)\n    #x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n    if activation:\n        x = activation(x)\n    return x\n\ndef get_u_net(img_size):\n    num_classes = 3\n    inputs = Input(shape=img_size)\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"tanh\", padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model\n\n\n\n\ndef get_discriminator(filters=64, kernel_initializer=kernel_init, num_downsampling=3):\n    \n    inputs = Input(shape=input_size)\n    x = Conv2D(filters, (4,4), strides=(2,2), padding=\"same\", kernel_initializer=kernel_init)(inputs)\n    x = LeakyReLU(0.2)(x)\n    \n    for i in range(num_downsampling):\n        filters *= 2\n        if i < 2:\n            x = downsample(x, filters=filters, activation=LeakyReLU(0.2), kernel_size=(4, 4), strides=(2, 2))\n        else:\n            x = downsample(x, filters=filters, activation=LeakyReLU(0.2), kernel_size=(4, 4), strides=(1,1))\n    \n    x = Conv2D(1, (3,3), strides=(1,1), padding=\"valid\", kernel_initializer=kernel_init)(x)\n    x = layers.Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs=inputs, outputs=x)\n    return model\n\n\n\n#======================\ngene_monet = get_u_net(input_size)\ngene_photo = get_u_net(input_size)\ndisc_monet = get_discriminator()\ndisc_photo = get_discriminator()\n#=======================","metadata":{"_uuid":"61f77064-eb6d-4f63-a822-4aaa4d60002c","_cell_guid":"a7d9b306-5594-4bc9-873a-642b329816f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:08.582434Z","iopub.execute_input":"2021-06-21T09:20:08.582776Z","iopub.status.idle":"2021-06-21T09:20:09.819088Z","shell.execute_reply.started":"2021-06-21T09:20:08.582746Z","shell.execute_reply":"2021-06-21T09:20:09.818066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=======================================================\n#compile\n\noptimizer = Adam(2e-4, beta_1=0.5)\noptimizer1 = Adam(5e-4, beta_1=0.5)\n\n\nz_monet = Input(shape=input_size)\nz_photo = Input(shape=input_size)\n\nfake_photo = gene_photo(z_monet)\ncycle_monet = gene_monet(fake_photo)\n\nfake_monet = gene_monet(z_photo)\ncycle_photo = gene_photo(fake_monet)\n\nsame_monet = gene_monet(z_monet)\nsame_photo = gene_photo(z_photo)\n\ndisc_monet_real = disc_monet(z_monet)\ndisc_photo_real = disc_photo(z_photo)\n\n# disc_monet_fake = disc_monet(fake_monet)\n# disc_photo_fake = disc_photo(fake_photo)\n\n    \n\n#gene_photo->gene_monet (cycle)\ncycle1 = Model(z_monet, cycle_monet)\ncycle1.compile(loss=\"binary_crossentropy\", optimizer=optimizer1)\n#gene_monet->gene_photo (cycle)\ncycle2 = Model(z_photo, cycle_photo)\ncycle2.compile(loss='binary_crossentropy', optimizer=optimizer1)\n\n#gene_photo->gene_monet (same)\nsame1 = Model(z_monet, same_monet)\nsame1.compile(loss='binary_crossentropy', optimizer=optimizer1)\n#gene_monet->gene_photo (same)\nsame2 = Model(z_photo, same_photo)\nsame2.compile(loss='binary_crossentropy', optimizer=optimizer)\n\ndisc_monet.compile(loss='binary_crossentropy', optimizer=optimizer)\ndisc_photo.compile(loss='binary_crossentropy', optimizer=optimizer)\ndisc_monet.trainable = False\ndisc_photo.trainable = False\n\ndisc_monet_fake = disc_monet(fake_monet)\ndisc_photo_fake = disc_photo(fake_photo)\n\n\n#gene_photo->disc_photo (gene_loss)\ngene_loss1 = Model(z_monet, disc_photo_fake)\ngene_loss1.compile(loss='binary_crossentropy', optimizer=optimizer)\n#gene_monet->disc_monet (gene_loss)\ngene_loss2 = Model(z_photo, disc_monet_fake)\ngene_loss2.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n# #real_photo->disc_photo (disc_real)\n# disc_real1 = Model(z_photo, disc_photo_real)\n# disc_real1.compile(loss='binary_crossentropy', optimizer=optimizer)\n# #real_monet->disc_monet (disc_real)\n# disc_real2 = Model(z_monet, disc_monet_real)\n# disc_real2.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n# #gene_photo->disc_photo (disc_fake)\n# disc_fake1 = Model(z_monet, disc_photo_fake)\n# disc_fake1.compile(loss='binary_crossentropy', optimizer=optimizer)\n# #gene_monet->disc_monet (disc_fake)\n# disc_fake2 = Model(z_photo, disc_monet_fake)\n# disc_fake2.compile(loss='binary_crossentropy', optimizer=optimizer)","metadata":{"_uuid":"af2a09fb-1f55-4c82-a58a-911b3995d557","_cell_guid":"092ea0d1-b7ee-4724-963e-d64bdb67811b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:09.820917Z","iopub.execute_input":"2021-06-21T09:20:09.821314Z","iopub.status.idle":"2021-06-21T09:20:11.431908Z","shell.execute_reply.started":"2021-06-21T09:20:09.821272Z","shell.execute_reply":"2021-06-21T09:20:11.430763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#========================================================================\n#train\n\nEPOCH = 0\nstep = 0\ni = 0\nif files_monet > files_photo:\n    step = len(files_photo)\nelse:\n    step = len(files_monet)\n\n#test用があるので今回は\nstep = 250\n\nfor epoch in range(EPOCH):\n    print(\"epoch:\",epoch+1)\n    \n    start = time.time()\n    n = 0\n    \n    g_monet_loss = 0\n    g_photo_loss = 0\n    d_monet_loss = 0\n    d_photo_loss = 0\n    \n    for i in range(step):\n        \n        target_monet = train_monet[i].reshape(-1,256,256,3)\n        target_photo = train_photo[i].reshape(-1,256,256,3)\n        ones = np.ones((1,30,30,1))\n        zero = np.zeros((1,30,30,1))\n        \n        #train_on_batch\n        fake_photo = gene_photo.predict(target_monet)\n        fake_monet = gene_monet.predict(target_photo)\n        c1 = cycle1.train_on_batch(target_monet, target_monet)\n        c2 = cycle2.train_on_batch(target_photo, target_photo)\n        s1 = same1.train_on_batch(target_monet, target_monet)\n        s2 = same2.train_on_batch(target_photo, target_photo)\n        dr1 = disc_photo.train_on_batch(target_photo, ones)\n        dr2 = disc_monet.train_on_batch(target_monet, ones)\n        df1 = disc_photo.train_on_batch(fake_photo, zero)\n        df2 = disc_monet.train_on_batch(fake_monet, zero)\n        g1 = gene_loss1.train_on_batch(target_monet, ones)\n        g2 = gene_loss2.train_on_batch(target_photo, ones)\n        \n        g_monet_loss += g2\n        g_photo_loss += g1\n        d_monet_loss += (dr2 + df1)/2\n        d_photo_loss += (dr1 + df2)/2\n        \n        \n        if n % 10 == 0:\n            print(\".\", end=\"\")\n        n += 1\n    \n    \n#     #choice random number\n#     rand = random.randrange(step)\n    \n#     #predict monet\n#     target_photo = train_photo[rand].reshape(-1,256,256,3)\n#     predict = gene_monet.predict(target_photo)\n#     predict = predict.reshape(256,256,3)\n#     predict = (predict * 255)\n#     t_photo = (train_photo[rand] * 255)\n#     # predict = (predict + 1) * 127.5\n#     # t_photo = (train_photo[rand] + 1) * 127.5\n#     cv2.imwrite(\"train/train{}_a_gene_.jpg\".format(epoch), predict)\n#     cv2.imwrite(\"train/train{}_a_origin.jpg\".format(epoch), t_photo)\n    \n#     #predict photo\n#     target_monet = train_monet[rand].reshape(-1,256,256,3)\n#     predict = gene_photo.predict(target_monet)\n#     predict = predict.reshape(256,256,3)\n#     predict = (predict * 255)\n#     t_monet = (train_monet[rand] * 255)\n#     # predict = (predict + 1) * 127.5\n#     # t_monet = (train_monet[rand] + 1) * 127.5\n#     cv2.imwrite(\"train/train{}_b_gene.jpg\".format(epoch), predict)\n#     cv2.imwrite(\"train/train{}_b_origin.jpg\".format(epoch), t_monet)\n    \n    g_monet_loss /= step\n    g_photo_loss /= step\n    d_monet_loss /= step\n    d_photo_loss /= step\n    step_time = time.time() - start\n    print('Time taken for epoch {} is %f sec'.format(epoch+1) % step_time)\n    print(\"gene_monet_loss:\", g_monet_loss)\n    print(\"gene_photo_loss:\", g_photo_loss)\n    print(\"disc_monet_loss:\", d_monet_loss)\n    print(\"disc_photo_loss:\", d_photo_loss)\n    print(\"\")\n\n#gene_monet.save('C:/Users/user01/Desktop/AI/cnn/gene_monet_model.h5')","metadata":{"_uuid":"da10a387-4cf9-4c53-aabb-dd3df2d7f447","_cell_guid":"1f7eaed0-2e18-4b27-95b5-24993a365562","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:20:11.433421Z","iopub.execute_input":"2021-06-21T09:20:11.433898Z","iopub.status.idle":"2021-06-21T09:20:11.449584Z","shell.execute_reply.started":"2021-06-21T09:20:11.433855Z","shell.execute_reply":"2021-06-21T09:20:11.448864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test././\nos.makedirs('images') # Create folder to save generated images\ntest = 50\nfor i in range(50):\n    testphoto = test_photo[i].reshape(-1,256,256,3)\n    predict = gene_monet.predict([testphoto])\n    predict = predict.reshape(256,256,3)\n    #predict = (predict + 1) * 127.5\n    predict = predict * 255\n    cv2.imwrite(\"/images/test{}.jpg\".format(i), predict)","metadata":{"_uuid":"23c311a2-3984-43e4-bd20-f461f3a92085","_cell_guid":"3e43cc46-76af-4e52-a9d8-dd16f5310cf0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-21T09:21:04.537551Z","iopub.execute_input":"2021-06-21T09:21:04.537931Z","iopub.status.idle":"2021-06-21T09:21:13.510056Z","shell.execute_reply.started":"2021-06-21T09:21:04.537898Z","shell.execute_reply":"2021-06-21T09:21:13.508839Z"},"trusted":true},"execution_count":null,"outputs":[]}]}