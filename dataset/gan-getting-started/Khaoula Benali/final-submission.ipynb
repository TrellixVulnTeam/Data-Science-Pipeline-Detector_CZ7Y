{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-04T21:23:20.372484Z","iopub.execute_input":"2022-01-04T21:23:20.372825Z","iopub.status.idle":"2022-01-04T21:23:20.37845Z","shell.execute_reply.started":"2022-01-04T21:23:20.372796Z","shell.execute_reply":"2022-01-04T21:23:20.377243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0. Importing Necessary libraries :","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom math import floor\nimport pandas as pd \nimport cv2\nimport matplotlib.gridspec as gridspec\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as layers\n\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam\nfrom numpy.random import randn\n\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=2","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:25:32.270354Z","iopub.execute_input":"2022-01-04T21:25:32.27067Z","iopub.status.idle":"2022-01-04T21:25:32.274475Z","shell.execute_reply.started":"2022-01-04T21:25:32.270633Z","shell.execute_reply":"2022-01-04T21:25:32.273599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH=KaggleDatasets().get_gcs_path()\n\nmonet_filenames=tf.io.gfile.glob(str(GCS_PATH+'/monet_tfrec/*.tfrec'))\nphoto_filenames=tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\n\nprint('monet_filenames',len(monet_filenames))\nprint('photo_filenames',len(photo_filenames))\n\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE \nprint(tf.__version__)\n\n\n\nimage_size=[256,256]\ndef decode_img(img):\n    img=tf.image.decode_image(img,channels=3)\n    img=(tf.cast(img,tf.float32)/127.5)-1\n    img=tf.reshape(img,[*image_size,3])\n    return img\n\n\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_img(example['image'])\n    return image\n\ndef load_dataset(filenames,labeled=True,ordered=False):\n    dataset=tf.data.TFRecordDataset(filenames)\n    dataset=dataset.map(read_tfrecord,num_parallel_calls=AUTOTUNE)\n    return dataset\n\n\nmonet_ds=load_dataset(monet_filenames,labeled=True).batch(BATCH_SIZE)\nphoto_ds=load_dataset(photo_filenames,labeled=True).batch(BATCH_SIZE)\n\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:29:02.624542Z","iopub.execute_input":"2022-01-04T21:29:02.624897Z","iopub.status.idle":"2022-01-04T21:29:05.249157Z","shell.execute_reply.started":"2022-01-04T21:29:02.624868Z","shell.execute_reply":"2022-01-04T21:29:05.247612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef Plot(arr1,arr2,flag):\n\n    arr1=next(iter(arr1))\n    arr1 = (arr1 + 1) / 2.0\n    fig, axes = plt.subplots(2, 2)\n    fig.set_size_inches(10,6)\n    count = 0\n   \n    for j in range(2):\n            axes[0, j].imshow(arr1[count])\n            axes[0, j].axis('off')\n            count += 1\n\n    if flag==True:    \n        arr2=next(iter(arr2))\n        arr2 = (arr2 + 1) / 2.0\n    count = 0\n    for i in range(2):\n       \n            axes[1, i].imshow(arr2[count])\n            axes[1, i].axis('off')\n            count += 1\n\n    plt.tight_layout() \n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:29:33.650391Z","iopub.execute_input":"2022-01-04T21:29:33.650799Z","iopub.status.idle":"2022-01-04T21:29:33.658062Z","shell.execute_reply.started":"2022-01-04T21:29:33.650748Z","shell.execute_reply":"2022-01-04T21:29:33.656877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Plot(monet_ds,photo_ds,True)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:29:38.460447Z","iopub.execute_input":"2022-01-04T21:29:38.460761Z","iopub.status.idle":"2022-01-04T21:29:39.889149Z","shell.execute_reply.started":"2022-01-04T21:29:38.460731Z","shell.execute_reply":"2022-01-04T21:29:39.887581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Plot(monet_ds,photo_ds,True)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:29:53.624379Z","iopub.execute_input":"2022-01-04T21:29:53.624699Z","iopub.status.idle":"2022-01-04T21:29:54.41742Z","shell.execute_reply.started":"2022-01-04T21:29:53.624669Z","shell.execute_reply":"2022-01-04T21:29:54.416678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator():\n  \n    inputs = layers.Input(shape=[256,256,3,])\n    \n    init= RandomNormal(mean=0.0, stddev=0.02)\n    gamma_init =keras.initializers.RandomNormal(mean=0.0, stddev=0.02)    \n    \n    conv1 = layers.Conv2D(32,4,strides=2,padding='same',kernel_initializer=init)(inputs)\n    conv1=layers.BatchNormalization(gamma_initializer=gamma_init)(conv1)\n    #conv1=layers.Dropout(0.5)(conv1)\n    conv1=layers.LeakyReLU()(conv1)\n    \n    \n    conv2 = layers.Conv2D(64,4,strides=2,padding='same',kernel_initializer=init)(conv1)\n    conv2=layers.BatchNormalization(gamma_initializer=gamma_init)(conv2)\n   # conv2=layers.Dropout(0.5)(conv2)\n    conv2=layers.LeakyReLU()(conv2)\n   \n    \n    conv3 = layers.Conv2D(128,4,strides=2,padding='same',kernel_initializer=init)(conv2)\n    conv3=layers.BatchNormalization(gamma_initializer=gamma_init)(conv3)\n   # conv3=layers.Dropout(0.5)(conv3)\n    conv3=layers.LeakyReLU()(conv3)\n\n    \n    conv4 = layers.Conv2D(256,4,strides=2,padding='same',kernel_initializer=init)(conv3)\n    conv4=layers.BatchNormalization(gamma_initializer=gamma_init)(conv4)\n   # conv4=layers.Dropout(0.5)(conv4)\n    conv4=layers.LeakyReLU()(conv4)\n  \n    \n    \n    conv5 = layers.Conv2D(512,4,strides=2,padding='same',kernel_initializer=init)(conv4)\n    conv5=layers.BatchNormalization(gamma_initializer=gamma_init)(conv5)\n    #conv5=layers.Dropout(0.5)(conv5)\n    conv5=layers.LeakyReLU()(conv5)\n    \n    \n     \n    up1 = layers.Conv2DTranspose(256,4,strides=(2,2),padding='same',kernel_initializer=init)(conv5)\n    up1=layers.BatchNormalization(gamma_initializer=gamma_init)(up1)\n    #up1=layers.Dropout(0.5)(up1)\n    up1=layers.LeakyReLU()(up1)\n    merge1 = layers.concatenate([up1, conv4], axis=3) \n    \n\n    \n    up2 = layers.Conv2DTranspose(128,4,strides=(2,2),padding='same',kernel_initializer=init)(merge1)\n    up2=layers.BatchNormalization(gamma_initializer=gamma_init)(up2)\n    #up2=layers.Dropout(0.5)(up2)\n    up2=layers.LeakyReLU()(up2)\n    merge2 = layers.concatenate([up2, conv3], axis=3) \n    \n\n\n    up3 = layers.Conv2DTranspose(64,4,strides=(2,2),padding='same',kernel_initializer=init)(merge2)\n    up3=layers.BatchNormalization(gamma_initializer=gamma_init)(up3)\n    up3=layers.Dropout(0.5)(up3)\n    up3=layers.LeakyReLU()(up3)\n    merge3 = layers.concatenate([up3, conv2], axis=3) \n   \n\n   \n    \n    up4 = layers.Conv2DTranspose(32,4,strides=(2,2),padding='same',kernel_initializer=init)(merge3)\n    up4=layers.BatchNormalization(gamma_initializer=gamma_init)(up4)\n    up4=layers.Dropout(0.5)(up4)\n    up4=layers.LeakyReLU()(up4)\n    merge4 = layers.concatenate([up4, conv1], axis=3) \n    \n   \n \n    x = layers.Conv2DTranspose(3, 4, strides=(2,2),activation = 'tanh', padding = 'same')(merge4)  # tanh to get values between 1 and -1 same as monet images\n\n    generator = keras.Model(inputs=inputs, outputs=x)\n\n    generator.summary()\n\n    return generator","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:01.645083Z","iopub.execute_input":"2022-01-04T21:30:01.645418Z","iopub.status.idle":"2022-01-04T21:30:01.808529Z","shell.execute_reply.started":"2022-01-04T21:30:01.645389Z","shell.execute_reply":"2022-01-04T21:30:01.80724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Discrimnator():\n    discriminator_input = layers.Input(shape=[256, 256, 3], name='input_image')\n    init= RandomNormal(mean=0.0, stddev=0.02)\n    \n    x = layers.Conv2D(64, 4,kernel_initializer=init)(discriminator_input)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2D(128, 4, strides = 2,kernel_initializer=init)(x)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU(0.2)(x)\n  \n    x = layers.Conv2D(128, 4, strides = 2,kernel_initializer=init)(x)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n  \n    x = layers.Flatten()(x)\n  \n    x = layers.Dense(1, activation = 'sigmoid')(x)\n  \n    discriminator = keras.models.Model(discriminator_input, x)\n    discriminator.summary()\n\n    return discriminator\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:07.363028Z","iopub.execute_input":"2022-01-04T21:30:07.363534Z","iopub.status.idle":"2022-01-04T21:30:07.370662Z","shell.execute_reply.started":"2022-01-04T21:30:07.363498Z","shell.execute_reply":"2022-01-04T21:30:07.369552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator=Generator()\ndiscriminator=Discrimnator()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:17.024379Z","iopub.execute_input":"2022-01-04T21:30:17.024703Z","iopub.status.idle":"2022-01-04T21:30:17.305198Z","shell.execute_reply.started":"2022-01-04T21:30:17.024673Z","shell.execute_reply":"2022-01-04T21:30:17.304325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intial=generator(next(iter(photo_ds)),training=False)\nPlot(photo_ds,intial,False)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:27.738226Z","iopub.execute_input":"2022-01-04T21:30:27.738533Z","iopub.status.idle":"2022-01-04T21:30:34.597558Z","shell.execute_reply.started":"2022-01-04T21:30:27.738506Z","shell.execute_reply":"2022-01-04T21:30:34.596658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN(keras.Model):\n    \n    def __init__(self, gen, disc):\n        super().__init__()\n        self.gen = gen\n        self.disc= disc\n\n    def compile(self,gen_optimizer,disc_optimizer,gen_loss_fn,disc_loss_fn):\n        super().compile()\n        self.gen_optimizer = gen_optimizer\n        self.disc_optimizer = disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n       \n        \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n       \n            generated_images = self.gen(real_photo, training=True)\n            \n            real_output = self.disc(real_monet, training=True)\n            fake_output = self.disc(generated_images, training=True)\n            \n            gen_loss = self.gen_loss_fn(fake_output)\n            disc_loss =self.disc_loss_fn(real_output,fake_output)\n            \n       \n        generator_gradients = tape.gradient(gen_loss,self.gen.trainable_variables)\n        discriminator_gradients = tape.gradient(disc_loss,self.disc.trainable_variables)\n        \n        self.gen_optimizer.apply_gradients(zip(generator_gradients, self.gen.trainable_variables))\n        self.disc_optimizer.apply_gradients(zip(discriminator_gradients,self.disc.trainable_variables))\n\n        \n        return {\n            \"gen_loss\": gen_loss,\n            \"disc_loss\":disc_loss\n        }\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:41.503391Z","iopub.execute_input":"2022-01-04T21:30:41.503744Z","iopub.status.idle":"2022-01-04T21:30:41.513216Z","shell.execute_reply.started":"2022-01-04T21:30:41.503706Z","shell.execute_reply":"2022-01-04T21:30:41.512391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n#generator.compile(optimizer = generator_optimizer, loss = 'categorical_crossentropy')\n\ndiscriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n#discriminator.compile(optimizer = discriminator_optimizer,loss='binary_crossentropy')\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:47.298015Z","iopub.execute_input":"2022-01-04T21:30:47.298346Z","iopub.status.idle":"2022-01-04T21:30:47.303449Z","shell.execute_reply.started":"2022-01-04T21:30:47.298317Z","shell.execute_reply":"2022-01-04T21:30:47.302404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Get_Noise_Batch():\n    random_latent_vectors = randn(latent_dim * batch_size)\n    # update to have the range [-1, 1]\n    random_latent_vectors = -1 + random_latent_vectors * 2\n    random_latent_vectors = random_latent_vectors.reshape((batch_size, latent_dim))\n    \n    return random_latent_vectors","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:52.342435Z","iopub.execute_input":"2022-01-04T21:30:52.342859Z","iopub.status.idle":"2022-01-04T21:30:52.34869Z","shell.execute_reply.started":"2022-01-04T21:30:52.34282Z","shell.execute_reply":"2022-01-04T21:30:52.347792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Get_True_Batch(idx):\n    real_images=original[idx:idx+batch_size]\n    return real_images","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:30:54.709428Z","iopub.execute_input":"2022-01-04T21:30:54.709852Z","iopub.status.idle":"2022-01-04T21:30:54.714347Z","shell.execute_reply.started":"2022-01-04T21:30:54.709811Z","shell.execute_reply":"2022-01-04T21:30:54.71288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def G_loss(fake_output):\n     return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:31:02.503312Z","iopub.execute_input":"2022-01-04T21:31:02.503748Z","iopub.status.idle":"2022-01-04T21:31:02.51003Z","shell.execute_reply.started":"2022-01-04T21:31:02.503716Z","shell.execute_reply":"2022-01-04T21:31:02.507098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def D_loss(real_output,fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    return real_loss+fake_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:31:06.467603Z","iopub.execute_input":"2022-01-04T21:31:06.467987Z","iopub.status.idle":"2022-01-04T21:31:06.472421Z","shell.execute_reply.started":"2022-01-04T21:31:06.467946Z","shell.execute_reply":"2022-01-04T21:31:06.47155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GAN(generator,discriminator)\nmodel.compile(generator_optimizer,discriminator_optimizer,G_loss,D_loss)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:31:08.148535Z","iopub.execute_input":"2022-01-04T21:31:08.148869Z","iopub.status.idle":"2022-01-04T21:31:08.169613Z","shell.execute_reply.started":"2022-01-04T21:31:08.148838Z","shell.execute_reply":"2022-01-04T21:31:08.168846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(tf.data.Dataset.zip((monet_ds, photo_ds)),epochs=60)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:31:14.423237Z","iopub.execute_input":"2022-01-04T21:31:14.423581Z","iopub.status.idle":"2022-01-04T21:37:25.067553Z","shell.execute_reply.started":"2022-01-04T21:31:14.42355Z","shell.execute_reply":"2022-01-04T21:37:25.06682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perd=generator(next(iter(photo_ds)),training=False)\nPlot(photo_ds,perd,False)  ","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:37:41.424925Z","iopub.execute_input":"2022-01-04T21:37:41.425251Z","iopub.status.idle":"2022-01-04T21:37:42.290167Z","shell.execute_reply.started":"2022-01-04T21:37:41.425223Z","shell.execute_reply":"2022-01-04T21:37:42.288874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\n! mkdir ../images\ni = 1\n\nfor img in photo_ds:\n    prediction = generator(img, training=False).numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    \n    im = PIL.Image.fromarray(prediction[0])\n    im.save(\"../images/\" + str(i) + \".jpg\")\n    i += 1\n    im = PIL.Image.fromarray(prediction[1])\n    im.save(\"../images/\" + str(i) + \".jpg\")\n    i += 1\n    \nimport shutil\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T21:37:56.44946Z","iopub.execute_input":"2022-01-04T21:37:56.449808Z","iopub.status.idle":"2022-01-04T21:39:11.397153Z","shell.execute_reply.started":"2022-01-04T21:37:56.449765Z","shell.execute_reply":"2022-01-04T21:39:11.396183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}