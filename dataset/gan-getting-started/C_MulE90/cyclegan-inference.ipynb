{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T05:04:40.933317Z","iopub.execute_input":"2021-11-28T05:04:40.933678Z","iopub.status.idle":"2021-11-28T05:04:40.957803Z","shell.execute_reply.started":"2021-11-28T05:04:40.933602Z","shell.execute_reply":"2021-11-28T05:04:40.957142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport datetime\nimport glob\nimport time\nimport cv2\nimport itertools\nfrom tqdm.notebook import tqdm\nimport shutil\n\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:04:42.081056Z","iopub.execute_input":"2021-11-28T05:04:42.081902Z","iopub.status.idle":"2021-11-28T05:04:43.859939Z","shell.execute_reply.started":"2021-11-28T05:04:42.081853Z","shell.execute_reply":"2021-11-28T05:04:43.85923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '../input/gan-getting-started/'\nmonet_path = glob.glob(img_path + 'monet_jpg/*')\nphoto_path = glob.glob(img_path + 'photo_jpg/*')\n\nprint('Dataset')\nprint(f'- monet data : {len(monet_path)}\\n- photo data : {len(photo_path)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:04:43.861617Z","iopub.execute_input":"2021-11-28T05:04:43.861873Z","iopub.status.idle":"2021-11-28T05:04:44.4841Z","shell.execute_reply.started":"2021-11-28T05:04:43.861841Z","shell.execute_reply":"2021-11-28T05:04:44.483182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Custom_dataset(Dataset):\n    def __init__(self, img_path : list , transforms = None, mode = 'train'):\n        super().__init__()\n\n        self.path_monet = img_path[0]\n        self.path_photo = img_path[1]\n        self.transforms = transforms\n        self.mode = mode\n        \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            monet_img = self.path_monet[idx]\n            monet_img = Image.open(monet_img).convert('RGB')\n            monet_img = self.transforms(monet_img)\n            \n            photo_idx = np.random.randint(0, len(self.path_photo))\n            photo_img = self.path_photo[photo_idx]\n            photo_img = Image.open(photo_img).convert('RGB')\n            photo_img = self.transforms(photo_img)\n            \n            return monet_img, photo_img\n\n        elif self.mode == 'test':\n            photo_img = self.path_photo[idx]\n            photo_img = Image.open(photo_img).convert('RGB')\n            photo_img = self.transforms(photo_img)\n            return photo_img    \n        \n    def __len__(self):\n        if self.mode == 'train':\n            return len(self.path_monet)\n        elif self.mode == 'test':\n            return len(self.path_photo)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:11:22.57778Z","iopub.execute_input":"2021-11-28T05:11:22.578551Z","iopub.status.idle":"2021-11-28T05:11:22.587892Z","shell.execute_reply.started":"2021-11-28T05:11:22.578464Z","shell.execute_reply":"2021-11-28T05:11:22.587149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data loader\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], \n                                [0.5, 0.5, 0.5])\n])\n\ntest_dataset = Custom_dataset([monet_path, photo_path], transforms = transform, mode = 'test')\ntest_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:12:45.402892Z","iopub.execute_input":"2021-11-28T05:12:45.403143Z","iopub.status.idle":"2021-11-28T05:12:45.408961Z","shell.execute_reply.started":"2021-11-28T05:12:45.403116Z","shell.execute_reply":"2021-11-28T05:12:45.408255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n- photo -> monet","metadata":{}},{"cell_type":"code","source":"# Define Conv Block\n'''\n1. Conv_up\n2. Conv_down\n3. Residual_block\n'''\n\n# 1.Conv_up\nclass Conv_up(nn.Module):\n    '''\n    convTranspose - instanceNorm - ReLU - (dropout)\n    '''\n    def __init__(self, in_ch, out_ch, kernel_size = 4, stride = 2, \n                 padding = 1, output_padding = 1, drop_out = True):\n        super().__init__()\n        \n        self.convT = nn.ConvTranspose2d(in_ch, out_ch,\n                                       kernel_size = kernel_size,\n                                       stride = stride,\n                                       padding = padding,\n                                       output_padding = output_padding,\n                                       bias = False)\n        self.instance_norm = nn.InstanceNorm2d(out_ch)\n        self.relu = nn.ReLU()\n        self.drop_out = drop_out\n        \n    def forward(self, x):\n        x = self.convT(x)\n        x = self.instance_norm(x)\n        x = self.relu(x)\n        if self.drop_out:\n            x = nn.Dropout2d(0.5)(x)\n\n        return x\n\n# 2. Conv_down\nclass Conv_down(nn.Module):\n    '''\n    Conv2d - instanceNorm - LeakyReLU\n    '''\n    def __init__(self, in_ch, out_ch,\n                 kernel_size = 4,\n                 stride = 2,\n                 padding = 1,\n                 batch_Norm = True):\n        super().__init__()\n        \n        self.conv = nn.Conv2d(in_ch, out_ch,\n                             kernel_size = kernel_size,\n                             stride = stride,\n                             padding = padding,\n                             bias = True)\n        self.instance_norm = nn.InstanceNorm2d(out_ch)\n        self.relu = nn.ReLU()\n        self.batch = batch_Norm\n        \n    def forward(self, x):\n        x = self.conv(x)\n        if self.batch:\n            x = self.instance_norm(x)\n        x = self.relu(x)\n        \n        return x\n    \n# 3. Residual_block\nclass Residual_block(nn.Module):\n    '''\n    Conv2d - InstanceNorm - Relu - Conv2d - InstanceNorm\n    '''\n    def __init__(self, in_ch, out_ch, kernel_size = 3, stride = 1, padding = 1):\n        super().__init__()\n        \n        self.res = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     padding_mode = 'reflect',\n                     bias = False),\n            nn.InstanceNorm2d(out_ch),\n            nn.ReLU(),\n            nn.Conv2d(out_ch, out_ch,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     padding_mode = 'reflect',\n                     bias = False),\n            nn.InstanceNorm2d(out_ch)\n        )\n    \n    def forward(self, x):\n        return x + self.res(x)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:10:08.875775Z","iopub.execute_input":"2021-11-28T05:10:08.876452Z","iopub.status.idle":"2021-11-28T05:10:08.894272Z","shell.execute_reply.started":"2021-11-28T05:10:08.876414Z","shell.execute_reply":"2021-11-28T05:10:08.893454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    '''\n    kernel   D64 - D128 - D256 - R256 * n - U128 - U64 - U3\n    filter   7x7 - 3x3  - 3x3  -          -  3x3 - 3x3 - 7x7\n    stride    1     2      2       1          2     2     1\n    '''\n    def __init__(self, n_features = 64, n_res = 9):\n        super().__init__()\n        \n        self.main = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            Conv_down(3, n_features, 7, 1, 0, False),\n            Conv_down(n_features * 1, n_features * 2, 3, 2),\n            Conv_down(n_features * 2, n_features * 4, 3, 2),\n            *[\n                Residual_block(n_features * 4, n_features * 4) for _ in range(n_res)\n            ],\n            Conv_up(n_features * 4, n_features * 2, 3, 2, 1),\n            Conv_up(n_features * 2, n_features * 1, 3, 2, 1),\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(n_features, 3, 7, 1, 0, bias = False),\n            nn.Tanh()   \n        )\n        \n    def forward(self, x):\n        x = self.main(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:10:09.157817Z","iopub.execute_input":"2021-11-28T05:10:09.15965Z","iopub.status.idle":"2021-11-28T05:10:09.167713Z","shell.execute_reply.started":"2021-11-28T05:10:09.159604Z","shell.execute_reply":"2021-11-28T05:10:09.167012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load netG_B\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = torch.load('../input/cyclegan-baseline/model_G/netG(uNet)_B100.pt').to(device)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:25:57.861136Z","iopub.execute_input":"2021-11-28T05:25:57.861411Z","iopub.status.idle":"2021-11-28T05:25:59.385005Z","shell.execute_reply.started":"2021-11-28T05:25:57.861382Z","shell.execute_reply":"2021-11-28T05:25:59.384238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unNormalize(img, mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5]):\n    img = img[0].cpu().detach()\n    np_img = np.transpose(img.numpy(), (1, 2, 0))\n    np_img = np_img * std + mean\n    np_img = (np_img * 255).astype('uint8')\n    return np_img","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:27:48.058471Z","iopub.execute_input":"2021-11-28T05:27:48.059173Z","iopub.status.idle":"2021-11-28T05:27:48.065028Z","shell.execute_reply.started":"2021-11-28T05:27:48.059138Z","shell.execute_reply":"2021-11-28T05:27:48.063585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir images","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:20:56.452765Z","iopub.execute_input":"2021-11-28T05:20:56.453262Z","iopub.status.idle":"2021-11-28T05:20:57.152424Z","shell.execute_reply.started":"2021-11-28T05:20:56.453224Z","shell.execute_reply":"2021-11-28T05:20:57.151432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, photo in tqdm(enumerate(test_loader), total = len(test_loader)):\n    with torch.no_grad():\n        photo = photo.to(device)\n        out = model(photo)\n        img = unNormalize(out)\n        img = Image.fromarray(img)\n        img.save('../working/images/' + str(i + 1) + '.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:28:01.88428Z","iopub.execute_input":"2021-11-28T05:28:01.884561Z","iopub.status.idle":"2021-11-28T05:30:56.66718Z","shell.execute_reply.started":"2021-11-28T05:28:01.884529Z","shell.execute_reply":"2021-11-28T05:30:56.666407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('../working/images', 'zip', '../working/images')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T05:32:22.927145Z","iopub.execute_input":"2021-11-28T05:32:22.927397Z"},"trusted":true},"execution_count":null,"outputs":[]}]}