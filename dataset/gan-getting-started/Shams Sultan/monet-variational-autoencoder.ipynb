{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import plot_model\n\nfrom tqdm import tqdm\nfrom numpy import asarray\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Sampling Layer","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoder","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_dim = 2\ntotal_epoch = 100\nbatch_size = 64\nimg_dim = (256, 256)\n\nencoder_inputs = keras.Input(shape=(*img_dim, 3))\n\nx = layers.Conv2D(16, kernel_size=(5,5), strides=(2,2), padding='SAME')(encoder_inputs)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(32, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(64, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(128, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256, activation=\"relu\")(x)\n\nz_mean    = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz         = Sampling()([z_mean, z_log_var])\n\nencoder = keras.Model(encoder_inputs, \n                      [z_mean, z_log_var, z], name=\"encoder\")\n\nencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoder Plot","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_model(encoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decoder","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(16 * 16 * 128, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((16, 16, 128))(x)\n\nx = layers.Conv2DTranspose(128, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(64, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(32, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(16, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\ndecoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decoder Plots","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_model(decoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def train_step(self, data):\n        if isinstance(data, tuple):\n            data = data[0]\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = encoder(data)\n            reconstruction = decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                keras.losses.binary_crossentropy(data, reconstruction)\n            )\n            reconstruction_loss *= 28 * 28\n            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n            kl_loss = tf.reduce_mean(kl_loss)\n            kl_loss *= -0.5\n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        return {\n            \"loss\": total_loss,\n            \"reconstruction_loss\": reconstruction_loss,\n            \"kl_loss\": kl_loss,\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_images = os.listdir('../input/gan-getting-started/monet_jpg')\ntrn_sizes = []\n\nfor i, img_path in enumerate(tqdm(trn_images)):\n    img = load_img(os.path.join('../input/gan-getting-started/monet_jpg',\n                                f'{img_path}'), target_size=(256, 256))\n    img_ary = img_to_array(img)\n    trn_sizes.append(img_ary.astype(\"float32\")/255.0)\n    \ntrn_sizes = asarray(trn_sizes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nvae.fit(trn_sizes, \n        epochs=100, \n        batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Work In Progress","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}