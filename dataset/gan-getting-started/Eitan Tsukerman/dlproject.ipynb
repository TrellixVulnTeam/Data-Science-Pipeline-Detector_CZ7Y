{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport keras\nfrom keras import layers\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as pp\nimport os\nimport random\nimport PIL\nimport shutil\nimport math\n\nfrom keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\nfrom keras.models import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Conv2DTranspose\nfrom tensorflow_addons.layers import InstanceNormalization\nfrom keras.losses import MeanSquaredError\nfrom keras.losses import MeanAbsoluteError\nfrom keras.initializers import RandomNormal\nfrom keras.losses import Reduction\nfrom keras.callbacks import LearningRateScheduler\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nimg_size=(256,256,3)\nMSE=MeanSquaredError()\nMAE=MeanAbsoluteError()\n\ndef img2tensorm(image):\n    image = tf.image.decode_jpeg(image, channels=3)    \n    image = tf.image.random_flip_left_right(image) #mirror        \n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*[256,256], 3])   \n    return image\n\ndef get_tfrecm(img):\n    tfrec_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    img = tf.io.parse_single_example(img, tfrec_format)\n    image = img2tensorm(img['image'])\n    return image\n\ndef img2tensorp(image):\n    image = tf.image.decode_jpeg(image, channels=3)        \n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*[256,256], 3])   \n    return image\n\ndef get_tfrecp(img):\n    tfrec_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    img = tf.io.parse_single_example(img, tfrec_format)\n    image = img2tensorp(img['image'])\n    return image\n\nmfiles = tf.io.gfile.glob('/kaggle/input/gan-getting-started/monet_tfrec/*.tfrec')\nmds = tf.data.TFRecordDataset(mfiles)\nmds = mds.shuffle(1000)\nmds = mds.take(30)\nmds = mds.repeat(count=10)\nmds = mds.map(get_tfrecm, num_parallel_calls=AUTOTUNE)\nmds = mds.batch(1)\nmds = mds.cache()\nmds = mds.prefetch(AUTOTUNE)\n\npfiles = tf.io.gfile.glob('/kaggle/input/gan-getting-started/photo_tfrec/*.tfrec')\npds = tf.data.TFRecordDataset(pfiles)\npds = pds.map(get_tfrecp, num_parallel_calls=AUTOTUNE)\npds = pds.batch(1)\npds = pds.cache()\npds = pds.prefetch(AUTOTUNE)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-05T15:47:26.797428Z","iopub.execute_input":"2021-08-05T15:47:26.797846Z","iopub.status.idle":"2021-08-05T15:47:35.757478Z","shell.execute_reply.started":"2021-08-05T15:47:26.797757Z","shell.execute_reply":"2021-08-05T15:47:35.756406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator():\n    init = tf.random_normal_initializer(0, 0.02)\n    g_init = RandomNormal(mean=0, stddev=0.02)\n    img = Input(shape=img_size)\n    \n    out = Conv2D(64, 4, 2, padding='same', kernel_initializer=init)(img)\n    out = LeakyReLU()(out) \n    out = Conv2D(128, 4, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = LeakyReLU()(out)\n    out = Conv2D(256, 4, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = LeakyReLU()(out)\n    out = Conv2D(512, 4, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = LeakyReLU()(out)\n    out = Conv2D(512, 4, 1, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = LeakyReLU()(out)\n    \n    out = Conv2D(1, 4, 1, padding='same', kernel_initializer=init)(out)\n    return Model(img, out)\n \ndisc_m = discriminator()\ndisc_p = discriminator()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:38.702445Z","iopub.execute_input":"2021-08-05T15:47:38.702832Z","iopub.status.idle":"2021-08-05T15:47:39.917873Z","shell.execute_reply.started":"2021-08-05T15:47:38.7028Z","shell.execute_reply":"2021-08-05T15:47:39.916841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rblock(filters, out0):\n    init = tf.random_normal_initializer(0, 0.02)\n    g_init = RandomNormal(mean=0, stddev=0.02)\n    out = tf.pad(out0, [[0,0], [1,1], [1,1], [0,0]], mode=\"REFLECT\")    \n    \n    out = Conv2D(filters, 3, 1, padding='valid', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n    \n    out = tf.pad(out, [[0,0], [1,1], [1,1], [0,0]], mode=\"REFLECT\")\n    \n    out = Conv2D(filters, 3, 1, padding='valid', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Concatenate()([out, out0])\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:41.749892Z","iopub.execute_input":"2021-08-05T15:47:41.750334Z","iopub.status.idle":"2021-08-05T15:47:41.759876Z","shell.execute_reply.started":"2021-08-05T15:47:41.75028Z","shell.execute_reply":"2021-08-05T15:47:41.758399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator():\n    init = tf.random_normal_initializer(0, 0.02)\n    g_init = RandomNormal(mean=0, stddev=0.02)\n    img = Input(shape=img_size)\n    \n    out = tf.pad(img, [[0,0], [3,3], [3,3], [0,0]], mode=\"REFLECT\")\n    \n    out = Conv2D(64, 7, kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n    out = Conv2D(128, 3, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)  \n    out = Conv2D(256, 3, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n    out = Conv2D(512, 3, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n\n    for ii in range(9):\n        out = rblock(512, out)\n        \n    out = Conv2DTranspose(256, 3, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n    out = Conv2DTranspose(128, 3, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n    out = Conv2DTranspose(64, 3, 2, padding='same', kernel_initializer=init,use_bias=False)(out)\n    out = InstanceNormalization(axis=-1,gamma_initializer=g_init)(out)\n    out = Activation('relu')(out)\n    \n    out = tf.pad(out, [[0,0], [3,3], [3,3], [0,0]], mode=\"REFLECT\")\n       \n    out = Conv2D(3, 7, padding='valid')(out)\n    out_img = Activation('tanh')(out)\n    return Model(img, out_img)\n\ngen_m2p=generator()\ngen_p2m=generator()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:45.220593Z","iopub.execute_input":"2021-08-05T15:47:45.221089Z","iopub.status.idle":"2021-08-05T15:47:47.768348Z","shell.execute_reply.started":"2021-08-05T15:47:45.221024Z","shell.execute_reply":"2021-08-05T15:47:47.767198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getfromPool(pool, img):\n    if(len(pool) < 50):\n        pool.append(img)\n        return img\n    elif(random.choice([0, 1])):\n        if(img in pool):\n            pool.remove(img)\n    else:\n        i = random.randint(0, 49)\n        pool[i] = img\n    i = random.randint(0, 49)   \n    return pool[i]","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:49.841282Z","iopub.execute_input":"2021-08-05T15:47:49.841635Z","iopub.status.idle":"2021-08-05T15:47:49.850439Z","shell.execute_reply.started":"2021-08-05T15:47:49.841604Z","shell.execute_reply":"2021-08-05T15:47:49.849101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FullCycleGanModel(keras.Model):\n    def __init__(self,gen_m2p,gen_p2m,disc_m,disc_p):\n        super(FullCycleGanModel, self).__init__()\n        self.gen_m2p = gen_m2p\n        self.gen_p2m = gen_p2m\n        self.disc_m = disc_m\n        self.disc_p = disc_p\n        self.pool_generated = list()\n        \n    def compile(self,gen_opt_m,gen_opt_p,disc_opt_m,disc_opt_p,gen_loss,disc_loss,c_loss,id_loss):\n        super(FullCycleGanModel, self).compile()\n        self.gen_opt_m = gen_opt_m\n        self.gen_opt_p = gen_opt_p\n        self.disc_opt_m = disc_opt_m\n        self.disc_opt_p = disc_opt_p\n        self.gen_loss = gen_loss\n        self.disc_loss = disc_loss\n        self.c_loss = c_loss\n        self.id_loss = id_loss\n        \n        \n    def train_step(self, batch):\n        real_p, real_m = batch\n        with tf.GradientTape(persistent=True) as tape:\n            generated_m = self.gen_p2m(real_p, training=True)\n            generated_p = self.gen_m2p(real_m, training=True)\n            generated_real_p = self.gen_m2p(generated_m, training=True)\n            generated_real_m = self.gen_p2m(generated_p, training=True)\n            id_p = self.gen_m2p(real_p, training=True)\n            id_m = self.gen_p2m(real_m, training=True)\n            \n            generated_m = getfromPool(self.pool_generated, generated_m)\n\n            disc_real_m = self.disc_m(real_m, training=True)\n            disc_real_p = self.disc_p(real_p, training=True)\n            disc_generated_m = self.disc_m(generated_m, training=True)\n            disc_generated_p = self.disc_p(generated_p, training=True)\n\n            gen_loss_m = self.gen_loss(disc_generated_m)\n            gen_loss_p = self.gen_loss(disc_generated_p)\n            gen_real_loss_m = self.c_loss(real_m, generated_real_m) * 10\n            gen_real_loss_p = self.c_loss(real_p, generated_real_p) * 10\n            id_loss_m = (self.id_loss(real_m, id_m)* 10 * 0.5)\n            id_loss_p = (self.id_loss(real_p, id_p)* 10 * 0.5)\n            \n            \n            loss_m = gen_loss_m + gen_real_loss_m + id_loss_m\n            loss_p = gen_loss_p + gen_real_loss_p + id_loss_p\n            disc_loss_m = self.disc_loss(disc_real_m, disc_generated_m) * 0.5\n            disc_loss_p = self.disc_loss(disc_real_p, disc_generated_p) * 0.5\n\n\n        grads_m = tape.gradient(loss_m, self.gen_p2m.trainable_variables)\n        grads_p = tape.gradient(loss_p, self.gen_m2p.trainable_variables)\n        disc_grads_m = tape.gradient(disc_loss_m, self.disc_m.trainable_variables)\n        disc_grads_p = tape.gradient(disc_loss_p, self.disc_p.trainable_variables)\n\n        self.gen_opt_m.apply_gradients(zip(grads_m, self.gen_p2m.trainable_variables))\n        self.gen_opt_p.apply_gradients(zip(grads_p, self.gen_m2p.trainable_variables))\n        self.disc_opt_m.apply_gradients(zip(disc_grads_m, self.disc_m.trainable_variables))\n        self.disc_opt_p.apply_gradients(zip(disc_grads_p, self.disc_p.trainable_variables))\n\n        return {\"loss_m\": loss_m,\"loss_p\": loss_p,\"disc_loss_m\": disc_loss_m,\"disc_loss_p\": disc_loss_p}","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:53.309829Z","iopub.execute_input":"2021-08-05T15:47:53.31022Z","iopub.status.idle":"2021-08-05T15:47:53.328442Z","shell.execute_reply.started":"2021-08-05T15:47:53.310176Z","shell.execute_reply":"2021-08-05T15:47:53.326899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def disc_loss(real, generated):\n    real_loss = MSE(tf.ones_like(real), real)\n    gen_loss = MSE(tf.zeros_like(generated), generated)\n    return (real_loss + gen_loss)\n\ndef gen_loss(generated):\n    gen_loss = MSE(tf.ones_like(generated), generated)\n    return gen_loss\n\ndef c_loss(real,generated):\n    cl=MAE(real,generated)\n    return cl\n\ndef id_loss(real,generated):\n    il=MAE(real,generated)\n    return il","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:55.530339Z","iopub.execute_input":"2021-08-05T15:47:55.53069Z","iopub.status.idle":"2021-08-05T15:47:55.537956Z","shell.execute_reply.started":"2021-08-05T15:47:55.530659Z","shell.execute_reply":"2021-08-05T15:47:55.536518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decayLR(epoch, lr):\n    if (epoch >= 25):\n        lr = 0.0002\n    return lr\n\nsched = LearningRateScheduler(decayLR)\nmodel = FullCycleGanModel(gen_m2p, gen_p2m, disc_m, disc_p)\nmodel.compile(Adam(learning_rate=0.002, beta_1=0.5),Adam(learning_rate=0.002, beta_1=0.5),\n            Adam(learning_rate=0.002, beta_1=0.5),Adam(learning_rate=0.002, beta_1=0.5),gen_loss,disc_loss,c_loss,id_loss)\n\nmd = model.fit(tf.data.Dataset.zip((pds, mds)),epochs=50,callbacks=[sched])\nhist = md.history\nmodel.save_weights(\"/kaggle/working/cgan_w.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:47:57.855531Z","iopub.execute_input":"2021-08-05T15:47:57.855906Z","iopub.status.idle":"2021-08-05T15:54:43.655659Z","shell.execute_reply.started":"2021-08-05T15:47:57.855864Z","shell.execute_reply":"2021-08-05T15:54:43.654122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir ../images\n\ni = 1\nfor img in pds:\n    pred = model.gen_p2m(img, training=False)[0].numpy()\n    pred = (pred * 127.5 + 127.5).astype(np.uint8)            \n    image = PIL.Image.fromarray(pred)\n    image.save(\"../images/\" + str(i) + \".jpg\")\n    i += 1\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","metadata":{"execution":{"iopub.status.busy":"2021-08-05T15:34:00.541307Z","iopub.execute_input":"2021-08-05T15:34:00.543612Z","iopub.status.idle":"2021-08-05T15:34:20.337393Z","shell.execute_reply.started":"2021-08-05T15:34:00.543562Z","shell.execute_reply":"2021-08-05T15:34:20.335497Z"},"trusted":true},"execution_count":null,"outputs":[]}]}