{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os , re, PIL\nfrom PIL import ImageDraw\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.callbacks import Callback\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nimport shutil\n","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:45:51.53856Z","iopub.execute_input":"2021-08-12T18:45:51.53899Z","iopub.status.idle":"2021-08-12T18:45:58.619373Z","shell.execute_reply.started":"2021-08-12T18:45:51.538896Z","shell.execute_reply":"2021-08-12T18:45:58.618339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\nprint(GCS_PATH)\n\nMONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\nprint('Monet TFRecord Files:', len(MONET_FILENAMES))\n\nPHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\nprint('Photo TFRecord Files:', len(PHOTO_FILENAMES))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:47:07.527778Z","iopub.execute_input":"2021-08-12T18:47:07.528202Z","iopub.status.idle":"2021-08-12T18:47:08.103816Z","shell.execute_reply.started":"2021-08-12T18:47:07.528163Z","shell.execute_reply":"2021-08-12T18:47:08.10268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nprint(tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:47:12.150726Z","iopub.execute_input":"2021-08-12T18:47:12.151088Z","iopub.status.idle":"2021-08-12T18:47:17.9407Z","shell.execute_reply.started":"2021-08-12T18:47:12.151057Z","shell.execute_reply":"2021-08-12T18:47:17.939912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\n\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset\n\ndef get_dataset(filenames, batch_size=1):\n    dataset = load_dataset(filenames)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:47:20.61519Z","iopub.execute_input":"2021-08-12T18:47:20.615755Z","iopub.status.idle":"2021-08-12T18:47:20.625518Z","shell.execute_reply.started":"2021-08-12T18:47:20.615712Z","shell.execute_reply":"2021-08-12T18:47:20.624687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_ds = load_dataset(MONET_FILENAMES).batch(1)\nphoto_ds = load_dataset(PHOTO_FILENAMES).batch(1)\nphotos = get_dataset(PHOTO_FILENAMES, batch_size=1)\nmodel_path = '../input/bestmodel/model16.h5'\nmodel = tf.keras.models.load_model(model_path)\n_, ax = plt.subplots(5, 2, figsize=(12, 12))\nfor i, img in enumerate(photo_ds.take(5)):\n    prediction = model(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet-esque\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:47:27.023513Z","iopub.execute_input":"2021-08-12T18:47:27.024065Z","iopub.status.idle":"2021-08-12T18:47:35.286288Z","shell.execute_reply.started":"2021-08-12T18:47:27.02403Z","shell.execute_reply":"2021-08-12T18:47:35.285194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('../images/')\ni = 1\nfor img in photos:\n    prediction = model(img, training=False)[0].numpy() # make predition\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n    im = PIL.Image.fromarray(prediction)\n    im.save('../images/' + str(i) + '.jpg')\n    i += 1\n\nshutil.make_archive('/kaggle/working/images/', 'zip', '../images')\n\nprint(f\"Generated samples: {len([name for name in os.listdir('../images/') if os.path.isfile(os.path.join('../images/', name))])}\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:49:10.840277Z","iopub.execute_input":"2021-08-12T18:49:10.840687Z","iopub.status.idle":"2021-08-12T19:11:13.014762Z","shell.execute_reply.started":"2021-08-12T18:49:10.840652Z","shell.execute_reply":"2021-08-12T19:11:13.013354Z"},"trusted":true},"execution_count":null,"outputs":[]}]}