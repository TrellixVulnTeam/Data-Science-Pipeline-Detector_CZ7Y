{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Shopee 競賽","metadata":{}},{"cell_type":"markdown","source":"## 匯入Model與所需 Package","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom tqdm.notebook import tqdm\nimport sklearn.feature_extraction.text\nfrom transformers import (BertTokenizer, AutoConfig, AutoModel)\nfrom sklearn.model_selection import StratifiedKFold\nimport regex","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:14.506908Z","iopub.execute_input":"2021-12-29T11:56:14.507307Z","iopub.status.idle":"2021-12-29T11:56:23.335602Z","shell.execute_reply.started":"2021-12-29T11:56:14.50722Z","shell.execute_reply":"2021-12-29T11:56:23.334854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##xiangwei add\n\"\"\"\ndf = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf['label_group'].value_counts()\n\npossible_labels = df.label_group.unique()\npossible_labels.sort()\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\ndf['label'] = df.label_group.replace(label_dict)\nimport torch\n\nfrom tqdm.notebook import tqdm\n\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\n\nfrom transformers import BertForSequenceClassification\nfrom sklearn.metrics import f1_score\nimport pandas as pd\nimport numpy as np\n\ndevice = torch.device(\"cuda\")\nx_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\nx_model.to(device)\n#model.to(device)\n\nx_model.load_state_dict(torch.load('../input/bert-pretrain/finetuned_BERT_epoch_30.pt', map_location=torch.device('cpu')))\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:23.337299Z","iopub.execute_input":"2021-12-29T11:56:23.337531Z","iopub.status.idle":"2021-12-29T11:56:23.351102Z","shell.execute_reply.started":"2021-12-29T11:56:23.337498Z","shell.execute_reply":"2021-12-29T11:56:23.349621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = Path('../input/shopee-product-matching')\n\nBERT_PATH = '../input/bertindo15g'\nbert_model_file = '../input/shopee-small-models/bert_indo_val0.pth'\n#bert_model_file = '../input/bert-pretrain/finetuned_BERT_epoch_30.pt'\nimage_model_file = '../input/shopee-small-models/resnet18val0.pth'\n\n# Neighborhood Blending 的 thresholds\nRECIPROCAL_THRESHOLD = .99 #.97\nMIN_PAIR_THRESHOLD = .7 #.6","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:23.352476Z","iopub.execute_input":"2021-12-29T11:56:23.352961Z","iopub.status.idle":"2021-12-29T11:56:23.363481Z","shell.execute_reply.started":"2021-12-29T11:56:23.352926Z","shell.execute_reply":"2021-12-29T11:56:23.362755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert_indo","metadata":{}},{"cell_type":"code","source":"class BertTextModel(nn.Module):\n    def __init__(self, bert_model):\n        super().__init__()\n        self.bert_model = bert_model\n    def forward(self, x):\n        output = self.bert_model(*x)\n        return output.last_hidden_state[:,0,:]\n    \ndef load_bert_model(fname):\n    model = AutoModel.from_config(AutoConfig.from_pretrained(BERT_PATH))\n    state = torch.load(fname)\n    model.load_state_dict(state)\n    return BertTextModel(model).cuda().eval()\n#Taken from https://www.kaggle.com/c/shopee-product-matching/discussion/233605#1278984\ndef string_escape(s, encoding='utf-8'):\n    return s.encode('latin1').decode('unicode-escape').encode('latin1').decode(encoding)\n\nclass TitleTransform(Transform):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n               \n    def encodes(self, row):\n        text = row.title\n        text=string_escape(text)\n        encodings = self.tokenizer(text, padding = 'max_length', max_length=100, truncation=True,return_tensors='pt')\n        keys =['input_ids', 'attention_mask', 'token_type_ids'] \n        #keys =['input_ids', 'attention_mask', 'labels'] \n        return tuple(encodings[key].squeeze() for key in keys)\n\ndef get_text_dls():\n    tfm = TitleTransform()\n\n    data_block = DataBlock(\n        blocks = (TransformBlock(type_tfms=tfm), \n                  CategoryBlock(vocab=train_df.label_group.to_list())),\n        splitter=ColSplitter(),\n        get_y=ColReader('label_group'),\n        )\n    return  data_block.dataloaders(train_df, bs=256)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:23.365498Z","iopub.execute_input":"2021-12-29T11:56:23.366257Z","iopub.status.idle":"2021-12-29T11:56:23.379303Z","shell.execute_reply.started":"2021-12-29T11:56:23.36606Z","shell.execute_reply":"2021-12-29T11:56:23.378574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet18","metadata":{}},{"cell_type":"code","source":"class ResnetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.body = create_body(resnet18, cut=-2, pretrained=False)\n        self.after_conv=nn.Sequential(\n            AdaptiveConcatPool2d(),\n            Flatten(),\n            nn.BatchNorm1d(1024)\n        )\n    def forward(self, x):\n        x = self.body(x)\n        return self.after_conv(x)\ndef load_image_model(fname):\n    state_dict = torch.load(fname)\n    model = ResnetModel()\n    model.load_state_dict(state_dict)\n    model = model.eval().cuda()\n    return model\ndef get_img_file(row):\n    img =row.image\n    fn  = PATH/'train_images'/img\n    if not fn.is_file():\n        fn = PATH/'test_images'/img\n    return fn\n\ndef get_image_dls(size, bs):\n    data_block = DataBlock(blocks = (ImageBlock(), CategoryBlock(vocab=train_df.label_group.to_list())),\n                 splitter=ColSplitter(),\n                 get_y=ColReader('label_group'),\n                 get_x=get_img_file,\n                 item_tfms=Resize(int(size*1.5), resamples=(Image.BICUBIC,Image.BICUBIC)), \n                 batch_tfms=aug_transforms(size=size, min_scale=0.75)+[Normalize.from_stats(*imagenet_stats)],\n                 )\n    return data_block.dataloaders(train_df, bs=bs)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:23.380507Z","iopub.execute_input":"2021-12-29T11:56:23.381345Z","iopub.status.idle":"2021-12-29T11:56:23.393006Z","shell.execute_reply.started":"2021-12-29T11:56:23.381308Z","shell.execute_reply":"2021-12-29T11:56:23.392353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper code","metadata":{}},{"cell_type":"code","source":"def add_target_groups(data_df, source_column='label_group', target_column='target'):\n    target_groups = data_df.groupby(source_column).indices\n    data_df[target_column]=data_df[source_column].map(target_groups)\n    return data_df\n\ndef add_splits(train_df, valid_group=0):\n    grouped = train_df.groupby('label_group').size()\n\n    labels, sizes =grouped.index.to_list(), grouped.to_list()\n\n    skf = StratifiedKFold(5)\n    splits = list(skf.split(labels, sizes))\n\n    group_to_split =  dict()\n    for idx in range(5):\n        labs = np.array(labels)[splits[idx][1]]\n        group_to_split.update(dict(zip(labs, [idx]*len(labs))))\n\n    train_df['split'] = train_df.label_group.replace(group_to_split)\n    train_df['is_valid'] = train_df['split'] == valid_group\n    return train_df\n\ndef embs_from_model(model, dl):\n    all_embs = []\n    all_ys=[]\n    for batch in tqdm(dl):\n        if len(batch) ==2:\n            bx,by=batch\n        else:\n            bx,=batch\n            by=torch.zeros(1)\n        with torch.no_grad():\n            embs = model(bx)\n            all_embs.append(embs.half())\n        all_ys.append(by)\n    all_embs = F.normalize(torch.cat(all_embs))\n    return all_embs, torch.cat(all_ys)\n\ndef get_targets_shape(train_df):\n    all_targets = add_target_groups(train_df).target.to_list()\n    all_targets_lens = [len(t) for t in all_targets]\n    targets_shape = []\n    for size in range(min(all_targets_lens), max(all_targets_lens)+1):\n        count = all_targets_lens.count(size) / len(all_targets)\n        targets_shape.append((size,count))\n    return targets_shape\n\ndef chisel(groups, groups_p, pos, target_count):\n    probs = []\n    groups_lens = [len(g)for g in groups]\n    current_count = groups_lens.count(pos)\n    if current_count >= target_count:\n\n        return\n    to_cut = target_count - current_count\n    for i in range(len(groups)):\n        if len(groups_p[i])>pos:\n            probs.append((i, groups_p[i][pos]))\n    probs.sort(key=lambda x:x[1])\n    for i in range(min(to_cut, len(probs))):\n        group_idx = probs[i][0] \n        groups[group_idx]=groups[group_idx][:pos]\n        groups_p[group_idx]=groups_p[group_idx][:pos]\ndef sorted_pairs(distances, indices):\n    triplets = []\n    n= len(distances)\n    for x in range(n):\n        used=set()\n        for ind, dist in zip(indices[x].tolist(), distances[x].tolist()):\n            if not ind in used:\n                triplets.append((x, ind, dist))\n                used.add(ind)\n    return sorted(triplets, key=lambda x: -x[2])\ndef do_chunk(embs):\n    step = 1000\n    for chunk_start in range(0, embs.shape[0], step):\n        chunk_end = min(chunk_start+step, len(embs))\n        yield embs[chunk_start:chunk_end]\ndef get_nearest(embs, emb_chunks, K=None, sorted=True):\n    if K is None:\n        K = min(51, len(embs))\n    distances = []\n    indices = []\n    for chunk in emb_chunks:\n        sim = embs @ chunk.T\n        top_vals, top_inds = sim.topk(K, dim=0, sorted=sorted)\n        distances.append(top_vals.T)\n        indices.append(top_inds.T)\n    return torch.cat(distances), torch.cat(indices)\n\ndef combined_distances(embs_list):\n    K = min(len(embs_list[0]), 51)\n    combined_inds =[get_nearest(embs, do_chunk(embs))[1] for embs in embs_list]\n    combined_inds = torch.cat(combined_inds, dim=1)\n    res_inds,res_dists = [],[]\n    for x in range(len(combined_inds)):\n        inds = combined_inds[x].unique()\n        Ds = [embs[None,x] @ embs[inds].T for embs in embs_list]\n        D = Ds[0] + Ds[1] - Ds[0] * Ds[1]\n        top_dists, top_inds = D.topk(K)\n        res_inds.append(inds[top_inds])\n        res_dists.append(top_dists)\n    return torch.cat(res_inds), torch.cat(res_dists)\n\ndef blend_embs(embs_list, threshold, m2_threshold, data_df):\n    combined_inds, combined_dists = combined_distances(embs_list)\n    check_measurements(combined_dists, combined_inds, data_df)\n    new_embs_list = L((torch.empty_like(embs) for embs in embs_list))\n    for x in range(len(embs_list[0])):\n        neighs = combined_dists[x] > threshold\n        if neighs.sum() == 1 and combined_dists[x][1]>m2_threshold:\n            neighs[1]=1\n        neigh_inds, neigh_ratios = combined_inds[x, neighs], combined_dists[x,neighs]\n        for embs, new_embs in zip(embs_list, new_embs_list):\n            new_embs[x] = (embs[neigh_inds] * neigh_ratios.view(-1,1)).sum(dim=0)\n    return new_embs_list.map(F.normalize)\n# Not used in solution, just for illustration purpose\ndef f1(tp, fp, num_tar):\n    return 2 * tp / (tp+fp+num_tar)\n\ndef build_from_pairs(pairs, target, display = True):\n    score =0\n    tp = [0]*len(target)\n    fp = [0]*len(target)\n    scores=[]\n    vs=[]\n    group_sizes = [len(x) for x in target]\n    for x, y, v in pairs:\n        group_size = group_sizes[x]\n        score -= f1(tp[x], fp[x], group_size)\n        if y in target[x]: tp[x] +=1\n        else: fp[x] +=1\n        score += f1(tp[x], fp[x], group_size) \n        scores.append(score / len(target))\n        vs.append(v)\n    if display:\n        plt.plot(scores)\n        am =torch.tensor(scores).argmax()\n        print(f'{scores[am]:.3f} at {am/len(target)} pairs or {vs[am]:.3f} threshold')\n    return scores\n\n\ndef score_distances(dist, targets, display=False):\n    triplets = dist_to_edges(dist)[:len(dist)*10]\n    return max(build_from_pairs(triplets, targets, display))\n\ndef score_group(group, target):\n    tp = len(set(group).intersection(set(target)))\n    return 2 * tp / (len(group)+len(target))\ndef score_all_groups(groups, targets):\n    scores = [score_group(groups[i], targets[i]) for i in range(len(groups))]\n    return sum(scores)/len(scores)\ndef show_groups(groups, targets):\n    groups_lens = [len(g)for g in groups]\n    targets_lens = [len(g) for g in targets]\n    plt.figure(figsize=(8,8)) \n    plt.hist((groups_lens,targets_lens) ,bins=list(range(1,52)), label=['preds', 'targets'])\n    plt.legend()\n    plt.title(f'score: {score_all_groups(groups, targets):.3f}')\n    plt.show()\n\n#Helper code for units of measurement matching\nmeasurements = {\n    'weight': [('mg',1), ('g', 1000), ('gr', 1000), ('gram', 1000), ('kg', 1000000)],\n    'length': [('mm',1), ('cm', 10), ('m',1000), ('meter', 1000)],\n    'pieces': [ ('pc',1)],\n    'memory': [('gb', 1)],\n    'volume': [('ml', 1), ('l', 1000), ('liter',1000)]\n}\n\ndef to_num(x, mult=1):\n    x = x.replace(',','.')\n    return int(float(x)*mult)\n\ndef extract_unit(tit, m):\n    pat = f'\\W(\\d+(?:[\\,\\.]\\d+)?) ?{m}s?\\W'\n    matches = regex.findall(pat, tit, overlapped=True)\n    return set(matches)\n\ndef extract(tit):\n\n    res =dict()\n    tit = ' '+tit.lower()+' '\n    for cat, units in measurements.items():\n        cat_values=set()\n        for unit_name, mult in units:\n            values = extract_unit(tit, unit_name)\n            values = {to_num(v, mult) for v in values}\n            cat_values = cat_values.union(values)\n        if cat_values:\n            res[cat] = cat_values\n    return res\n\ndef add_measurements(data):\n    data['measurement'] = data.title.map(extract)\n    return data\n\ndef match_measures(m1, m2):\n    k1,k2 = set(m1.keys()), set(m2.keys())\n    common = k1.intersection(k2)\n    if not common: return True\n    for key in common:\n        s1,s2 = m1[key], m2[key]\n        if s1.intersection(s2):\n            return True\n    return False\n\ndef check_measurements(combined_dists, combined_inds, data_df):\n    K = min(8, len(data_df)) * len(data_df)\n    _, inds_k = combined_dists.view(-1).topk(K)\n    removed = 0\n    inds_k = inds_k.tolist()\n    for idx in inds_k:\n        x = idx // combined_inds.shape[1]\n        y_idx = idx % combined_inds.shape[1]\n        y = combined_inds[x,y_idx] \n        if not match_measures(data_df.iloc[x].measurement, data_df.iloc[y.item()].measurement):\n            removed +=1\n            combined_dists[x][y_idx]=0\n    print('removed', removed, 'matches')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:23.394525Z","iopub.execute_input":"2021-12-29T11:56:23.395072Z","iopub.status.idle":"2021-12-29T11:56:23.609472Z","shell.execute_reply.started":"2021-12-29T11:56:23.395037Z","shell.execute_reply":"2021-12-29T11:56:23.608664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## validation set","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(PATH/'train.csv')\ntrain_df = add_splits(train_df)\n\nvalid_df = train_df[train_df.is_valid==True].reset_index()\nvalid_df=add_measurements(valid_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:23.610576Z","iopub.execute_input":"2021-12-29T11:56:23.6109Z","iopub.status.idle":"2021-12-29T11:56:25.791826Z","shell.execute_reply.started":"2021-12-29T11:56:23.610851Z","shell.execute_reply":"2021-12-29T11:56:25.791081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 取得特徵","metadata":{}},{"cell_type":"code","source":"bert_embs, ys = embs_from_model(load_bert_model(bert_model_file), get_text_dls().valid)\n#bert_embs, ys = embs_from_model(BertTextModel(x_model).cuda().eval(), get_text_dls().valid)\nimg_embs,ys = embs_from_model(load_image_model(image_model_file), get_image_dls(224,256).valid)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:56:25.79404Z","iopub.execute_input":"2021-12-29T11:56:25.794665Z","iopub.status.idle":"2021-12-29T11:59:18.053135Z","shell.execute_reply.started":"2021-12-29T11:56:25.794623Z","shell.execute_reply":"2021-12-29T11:59:18.052317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_embs","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:59:18.055031Z","iopub.execute_input":"2021-12-29T11:59:18.055642Z","iopub.status.idle":"2021-12-29T11:59:18.066921Z","shell.execute_reply.started":"2021-12-29T11:59:18.055596Z","shell.execute_reply":"2021-12-29T11:59:18.066208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_embs","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:59:18.07079Z","iopub.execute_input":"2021-12-29T11:59:18.071055Z","iopub.status.idle":"2021-12-29T11:59:18.080022Z","shell.execute_reply.started":"2021-12-29T11:59:18.071029Z","shell.execute_reply":"2021-12-29T11:59:18.079317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 通過簡單將所有匹配項置於固定閾值之上而獲得的分數","metadata":{}},{"cell_type":"code","source":"set_size = len(img_embs)\ntarget_matrix= ys[:,None]==ys[None,:]\ntargets = [torch.where(t)[0].tolist() for t in target_matrix] \n\ncombined_inds, combined_dists = combined_distances([img_embs, bert_embs])\npairs = sorted_pairs(combined_dists, combined_inds)\n_=build_from_pairs(pairs[:10*len(combined_inds)], targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:59:18.081489Z","iopub.execute_input":"2021-12-29T11:59:18.081796Z","iopub.status.idle":"2021-12-29T11:59:23.797419Z","shell.execute_reply.started":"2021-12-29T11:59:18.081761Z","shell.execute_reply":"2021-12-29T11:59:23.796723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  經過 Neighborhood Blending 後的 score","metadata":{}},{"cell_type":"code","source":"new_embs = blend_embs([img_embs, bert_embs], RECIPROCAL_THRESHOLD, MIN_PAIR_THRESHOLD, valid_df)\n\ncombined_inds, combined_dists = combined_distances(new_embs)\npairs = sorted_pairs(combined_dists, combined_inds)\n_=build_from_pairs(pairs[:10*len(combined_inds)], targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:59:23.798551Z","iopub.execute_input":"2021-12-29T11:59:23.798896Z","iopub.status.idle":"2021-12-29T11:59:55.01085Z","shell.execute_reply.started":"2021-12-29T11:59:23.798841Z","shell.execute_reply":"2021-12-29T11:59:55.009396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 根據測量值去除false positives","metadata":{}},{"cell_type":"code","source":"check_measurements(combined_dists, combined_inds, valid_df)\npairs = sorted_pairs(combined_dists, combined_inds)\n_=build_from_pairs(pairs[:10*len(combined_inds)], targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T11:59:55.012302Z","iopub.execute_input":"2021-12-29T11:59:55.012568Z","iopub.status.idle":"2021-12-29T12:00:14.585117Z","shell.execute_reply.started":"2021-12-29T11:59:55.012533Z","shell.execute_reply":"2021-12-29T12:00:14.583686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### perform the chisel step to match the two distributions (顯示無作用)","metadata":{}},{"cell_type":"code","source":"groups = [[] for _ in range(set_size)]\ngroups_p = [[] for _ in range(set_size)]\nfor x,y,v in pairs:\n    groups[x].append(y)\n    groups_p[x].append(v)\nfor pos, size_pct in get_targets_shape(train_df):\n    chisel(groups, groups_p, pos, int(size_pct * len(groups)))\nshow_groups(groups, targets)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:14.586479Z","iopub.execute_input":"2021-12-29T12:00:14.586743Z","iopub.status.idle":"2021-12-29T12:00:15.578398Z","shell.execute_reply.started":"2021-12-29T12:00:14.586706Z","shell.execute_reply":"2021-12-29T12:00:15.577723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test set","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(PATH/'test.csv')\ntest_df = add_measurements(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:15.57953Z","iopub.execute_input":"2021-12-29T12:00:15.581046Z","iopub.status.idle":"2021-12-29T12:00:15.596949Z","shell.execute_reply.started":"2021-12-29T12:00:15.581004Z","shell.execute_reply":"2021-12-29T12:00:15.596324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRIAL_RUN=False\n\nif TRIAL_RUN:\n    fake_test_df = train_df[['posting_id', 'image', 'image_phash', 'title', 'label_group']].copy()\n    fake_test_df = pd.concat([fake_test_df, fake_test_df])\n    fake_test_df = add_target_groups(fake_test_df)\n    test_df = fake_test_df","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:15.598807Z","iopub.execute_input":"2021-12-29T12:00:15.599216Z","iopub.status.idle":"2021-12-29T12:00:15.604271Z","shell.execute_reply.started":"2021-12-29T12:00:15.599179Z","shell.execute_reply":"2021-12-29T12:00:15.603559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_embs,_ = embs_from_model(load_bert_model(bert_model_file), get_text_dls().test_dl(test_df))\n\nimg_embs,_ =embs_from_model(load_image_model(image_model_file), get_image_dls(224, 256).test_dl(test_df))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:15.60559Z","iopub.execute_input":"2021-12-29T12:00:15.605903Z","iopub.status.idle":"2021-12-29T12:00:19.261416Z","shell.execute_reply.started":"2021-12-29T12:00:15.60585Z","shell.execute_reply":"2021-12-29T12:00:19.260623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_size = len(img_embs)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.263027Z","iopub.execute_input":"2021-12-29T12:00:19.263712Z","iopub.status.idle":"2021-12-29T12:00:19.267992Z","shell.execute_reply.started":"2021-12-29T12:00:19.263664Z","shell.execute_reply":"2021-12-29T12:00:19.267191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nnew_embs = blend_embs([img_embs, bert_embs], RECIPROCAL_THRESHOLD, MIN_PAIR_THRESHOLD, test_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.269164Z","iopub.execute_input":"2021-12-29T12:00:19.269478Z","iopub.status.idle":"2021-12-29T12:00:19.294771Z","shell.execute_reply.started":"2021-12-29T12:00:19.269439Z","shell.execute_reply":"2021-12-29T12:00:19.294109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_inds, combined_dists = combined_distances(new_embs)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.295904Z","iopub.execute_input":"2021-12-29T12:00:19.296136Z","iopub.status.idle":"2021-12-29T12:00:19.304401Z","shell.execute_reply.started":"2021-12-29T12:00:19.296104Z","shell.execute_reply":"2021-12-29T12:00:19.303634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_measurements(combined_dists, combined_inds, test_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.307491Z","iopub.execute_input":"2021-12-29T12:00:19.30768Z","iopub.status.idle":"2021-12-29T12:00:19.31828Z","shell.execute_reply.started":"2021-12-29T12:00:19.307657Z","shell.execute_reply":"2021-12-29T12:00:19.317007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs = sorted_pairs(combined_dists, combined_inds)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.320285Z","iopub.execute_input":"2021-12-29T12:00:19.320478Z","iopub.status.idle":"2021-12-29T12:00:19.390907Z","shell.execute_reply.started":"2021-12-29T12:00:19.320446Z","shell.execute_reply":"2021-12-29T12:00:19.390142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = [[] for _ in range(set_size)]\ngroups_p = [[] for _ in range(set_size)]\nfor x,y,v in pairs:\n    groups[x].append(y)\n    groups_p[x].append(v)\nfor pos, size_pct in get_targets_shape(train_df):\n    chisel(groups, groups_p, pos, int(size_pct * len(groups)))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.392364Z","iopub.execute_input":"2021-12-29T12:00:19.392857Z","iopub.status.idle":"2021-12-29T12:00:19.475976Z","shell.execute_reply.started":"2021-12-29T12:00:19.39282Z","shell.execute_reply":"2021-12-29T12:00:19.475217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matches = [' '.join(test_df.iloc[g].posting_id.to_list()) for g in groups]\ntest_df['matches'] = matches\n\ntest_df[['posting_id','matches']].to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.478731Z","iopub.execute_input":"2021-12-29T12:00:19.478943Z","iopub.status.idle":"2021-12-29T12:00:19.491506Z","shell.execute_reply.started":"2021-12-29T12:00:19.478918Z","shell.execute_reply":"2021-12-29T12:00:19.490736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:19.492952Z","iopub.execute_input":"2021-12-29T12:00:19.49336Z","iopub.status.idle":"2021-12-29T12:00:19.508282Z","shell.execute_reply.started":"2021-12-29T12:00:19.493318Z","shell.execute_reply":"2021-12-29T12:00:19.507526Z"},"trusted":true},"execution_count":null,"outputs":[]}]}