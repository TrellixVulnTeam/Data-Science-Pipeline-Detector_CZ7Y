{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\ntest = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\nsub = pd.read_csv(\"../input/shopee-product-matching/sample_submission.csv\")\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#找出每欄位unique有幾類\n#for col in train.columns:\n    #print(col + \":\" + str(len(train[col].unique())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#正確答案\n#tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n#train['target'] = train.label_group.map(tmp)\n#print('train shape is', train.shape )\n#train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#以tiltes分類可分成33117類，預測一樣的title會有一樣的label_group\n\n#labels = train.groupby(\"title\")[\"image\"].count().reset_index()\n#labels.columns=[\"title\",\"image_num\"]\n#titles = labels.sort_values(\"image_num\")\n#titles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 計算TFIDF","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english',binary = True, max_features = 25000)\ntfidf_matrix = vectorizer.fit_transform(test.title)\nprint(type(tfidf_matrix))\nprint(tfidf_matrix.shape)\n\ntfidfs = tfidf_matrix.toarray()\nwords = vectorizer.get_feature_names()\n#pd.DataFrame(tfidfs,columns=words)\n#tfidfs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# cosine_similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\n#計算相似度\ncosine_similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n#print(cosine_similarity_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cosine_similarity_matrix.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# cosine_sim[0] 為第一個文件與其他文件的相似度\ncosine_sim = cosine_similarity_matrix[0]\n\n# 去除第一個文件(查詢文件)\ncosine_sim = cosine_sim[1:]\n\n# 將文件編號與文件相似度打包為tuple\nsim_scores = list(enumerate(cosine_sim))\n\n# 以相似度降冪排列\nsim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n# 設定threshold取出相似的title\ntop10 = sim_scores[:10]\n\nthreshold = 0.8\nprint(\"第一句\", train.title[0])\n\nfor i in sim_scores:\n    idx, score = i[0] , i[1]\n    \n    if score > threshold:\n        #train[\"title_pred\"]= train.posting_id[idx]\n        print(\"與其相似為:\",idx, train.title[idx],score)\n    else:\n        break\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def similarity(title):\n    cntx = test[['title', 'posting_id']]\n    #Reverse mapping of the index\n    indices = pd.Series(test.index, index = test['title']).drop_duplicates()\n         \n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_similarity_matrix[idx-1]))\n    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n    uplimit = len(test['title']) if len(test['title']) < 50 else 50\n    sim_scores = sim_scores[0:uplimit]\n    post_indices = [i[0] for i in sim_scores if i[1] > .8]\n    recommend = cntx.iloc[post_indices]\n    output=[]\n    output.append(cntx.iloc[idx,1])\n    for index, row in recommend.iterrows():\n        output.append(row['posting_id'])\n    return output\n\n    #return ' '.join( np.unique(output))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# The Top 3 similar matches\n#threshold = 0.8\n\ndef similarity(title):\n    cntx = train[['title', 'posting_id']]\n    #Reverse mapping of the index\n    indices = pd.Series(train.index, index = train['title']).drop_duplicates()\n         \n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_similarity_matrix[idx-1]))\n    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n    #sim_scores = sim_scores[0:1]\n    \n    for i in sim_scores:\n        book_indices,scores  = i[0],i[1]\n        if scores > threshold:\n            recommend = cntx.iloc[book_indices]\n            output=''\n            for index, row in recommend.iteritems():\n                output+=row['posting_id']+\" \"\n        else:\n            break \n        return output\n'''\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use image phash","metadata":{}},{"cell_type":"code","source":"#正確答案\n#tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n#train['target'] = train.label_group.map(tmp)\n#print('train shape is', train.shape )\n#train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train['f1'] = train.apply(getMetric('phash_pred'),axis=1)\n#print('CV score for baseline =',train.f1.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def getMetric(col):\n    def f1score(row):\n        n = len(np.intersect1d(row.target, row[col]))\n        return 2*n / (len(row.target) + len(row[col]))\n    return f1score'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#一樣image phash match在一起\n\ntmp2 = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['phash_pred'] = test.image_phash.map(tmp2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def tostr(x):\n#    return ' '.join(x)\n#test['phash_pred'] = test.phash_pred.map(tostr)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['title_pred']=test['title'].apply(similarity)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to combine predictions\ndef combine_predictions(row):\n    x = np.concatenate([row['phash_pred'], row['title_pred']])\n    return ' '.join( np.unique(x) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['matches'] = test.apply(combine_predictions, axis = 1)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['posting_id', 'matches']].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['posting_id', 'matches']].to_csv('submission.csv', index = False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def tostr(x):\n#    return ' '.join(x)\n#train['phash_pred'] = train.phash_pred.map(tostr)\n#train['target'] = train.target.map(tostr)\n#train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}