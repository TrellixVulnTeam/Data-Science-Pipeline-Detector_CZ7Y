{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We start by loading the data.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initial EDA","metadata":{}},{"cell_type":"markdown","source":"Let's start by looking for missing values.","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like there are no missing values! Now let's look for unique values in each column.","metadata":{}},{"cell_type":"code","source":"print(np.shape(train))\nprint(f\"Unique phashes: {len(np.unique(train['image_phash']))}\")\nprint(f\"Unique images: {len(np.unique(train['image']))}\")\nprint(f\"Unique titles: {len(np.unique(train['title']))}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can already see that while there are 34,250 listings in the training set, there are only 28,735 unique phashes and 33,117 unique titles, suggesting that several listings have the exact same image or title. In terms of image ids, it looks like a few thousand listings also share the exact same image id.","metadata":{}},{"cell_type":"markdown","source":"# A Basic Submission\n\nLet's make a submission in which we assume all items with the same phash are the same item.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nids = []\nmatches = []\nfor ind in test.index:\n   ids.append(test['posting_id'][ind])\n   indices = np.where(test['image_phash'] == test['image_phash'][ind])\n   matches.append(' '.join(list(test.loc[indices[0]]['posting_id'])))\n        \nprint(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\nsubmission.to_csv('submission.csv', index = False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code had a submission score of 0.559 and took about 20-30 minutes to score. Now let's try matching all products with identical titles, images, OR phashes.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nids = []\nmatches = []\nfor ind in test.index:\n   ids.append(test['posting_id'][ind])\n   indices_phash = np.where(test['image_phash'] == test['image_phash'][ind])[0]\n   indices_title = np.where(test['title'] == test['title'][ind])[0]\n   indices_image = np.where(test['image'] == test['image'][ind])[0]\n   indices = set(indices_phash).union(set(indices_title)).union(set(indices_image))\n   matches.append(' '.join(list(test.loc[indices]['posting_id'])))\n        \nprint(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\nsubmission.to_csv('submission.csv', index = False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code took about 30 mins to run after submission and scored 0.573. Let's try only matching identical titles.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nids = []\nmatches = []\nfor ind in test.index:\n   ids.append(test['posting_id'][ind])\n   indices = np.where(test['title'] == test['title'][ind])[0]\n   matches.append(' '.join(list(test.loc[indices]['posting_id'])))\n        \nprint(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\nsubmission.to_csv('submission.csv', index = False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This resulted in a submission score of 0.481. Let's try refining the code that matches images, phashes, and titles such that any two listings that match each other also match everything the other matches. i.e. if item A matches item B, and item B also matches C, A and C should also be listed as matches.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nids = []\nitem_group = [] # tracks which group an item is in\ngroups = {} # tracks which items are in each group\nfor ind in test.index:\n    \n    indices_phash = test.loc[(test['image_phash'] == test['image_phash'][ind])].index \n    indices_title = test.loc[(test['title'] == test['title'][ind])].index \n    indices_image = test.loc[(test['image'] == test['image'][ind])].index\n    indices = set(indices_phash).union(set(indices_title)).union(set(indices_image))\n    \n    # check if an item this matches already has a group\n    match_ids = list(test.loc[indices]['posting_id'])\n    if set(match_ids).intersection(ids):\n        existing_group = item_group[ids.index(list(set(match_ids).intersection(ids))[0])]\n        item_group.append(existing_group)\n        groups[existing_group] = set(groups[existing_group]).union(match_ids)\n    else:\n        item_group.append(len(groups))\n        groups[len(groups)] = match_ids\n        \n    ids.append(test['posting_id'][ind])\n    \nmatches = [' '.join(list(groups[ind])) for ind in item_group]\n\nprint(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\nsubmission.to_csv('submission.csv', index = False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code above took just over 30 mins to score after submission and resulted in a score of 0.576. We can try building off of this moving forwards.","metadata":{}},{"cell_type":"markdown","source":"# Checking Runtime on Train Set\n\nThe test set we are scored on has over twice the amount of data as the train set. So to make sure the code runs without any memory issues, we can run our code on the training set concatenated with itself to simulate a dataset as large as the test set.","metadata":{}},{"cell_type":"code","source":"#train.loc[(train['image_phash'] == 'be9c90c3c16f631c')].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_2 = pd.concat([train,train],axis=0,ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#start_time = time.time()\n\n#ids = []\n#item_group = [] # tracks which group an item is in\n#groups = {} # tracks which items are in each group\n#for ind in train_2.index:\n    \n#    indices_phash = train_2.loc[(train_2['image_phash'] == train_2['image_phash'][ind])].index #np.where(train_2['image_phash'] == train_2['image_phash'][ind])[0]\n#    indices_title = train_2.loc[(train_2['title'] == train_2['title'][ind])].index #np.where(train_2['title'] == train_2['title'][ind])[0]\n#    indices_image = train_2.loc[(train_2['image'] == train_2['image'][ind])].index #np.where(train_2['image'] == train_2['image'][ind])[0]\n#    indices = set(indices_phash).union(set(indices_title)).union(set(indices_image))\n    \n    # check if an item this matches already has a group\n#    match_ids = list(train_2.loc[indices]['posting_id'])\n#    if set(match_ids).intersection(ids):\n#        existing_group = item_group[ids.index(list(set(match_ids).intersection(ids))[0])]\n#        item_group.append(existing_group)\n#        groups[existing_group] = set(groups[existing_group]).union(match_ids)\n#    else:\n#        item_group.append(len(groups))\n#        groups[len(groups)] = match_ids\n        \n#    ids.append(train_2['posting_id'][ind])\n    \n#matches = [' '.join(list(groups[ind])) for ind in item_group]\n\n#print(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#start_time = time.time()\n\n#ids = []\n#item_group = [] # tracks which group an item is in\n#groups = {} # tracks which items are in each group\n#for ind in train_2.index:\n    \n#    indices_phash = np.where(train_2['image_phash'] == train_2['image_phash'][ind])[0]\n#    indices_title = np.where(train_2['title'] == train_2['title'][ind])[0]\n#    indices_image = np.where(train_2['image'] == train_2['image'][ind])[0]\n#    indices = set(indices_phash).union(set(indices_title)).union(set(indices_image))\n    \n    # check if an item this matches already has a group\n#    match_ids = list(train_2.loc[indices]['posting_id'])\n#    if set(match_ids).intersection(ids):\n#        existing_group = item_group[ids.index(list(set(match_ids).intersection(ids))[0])]\n#        item_group.append(existing_group)\n#        groups[existing_group] = set(groups[existing_group]).union(match_ids)\n#    else:\n#        item_group.append(len(groups))\n#        groups[len(groups)] = match_ids\n        \n#    ids.append(train_2['posting_id'][ind])\n    \n#matches = [' '.join(list(groups[ind])) for ind in item_group]\n\n#print(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\n#train_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some helpful resources: \n\nhttps://www.kaggle.com/ishandutta/v7-shopee-indepth-eda-one-stop-for-all-your-needs#notebook-container\n\nhttps://www.kaggle.com/maksymshkliarevskyi/shopee-before-we-start-eda-phash-baseline#Shopee-Price-Match-Guarantee:-Before-we-start\n\nhttps://www.kaggle.com/isaienkov/shopee-data-understanding-and-analysis#notebook-container","metadata":{}}]}