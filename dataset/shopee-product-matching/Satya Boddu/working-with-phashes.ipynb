{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#   for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport Levenshtein as lev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding similar phashes","metadata":{}},{"cell_type":"markdown","source":"From the EDA notebook, we know that group 3627744656 has 51 matching items. Let's try using Levenshtein distance as a way of finding similar phashes in that group.","metadata":{}},{"cell_type":"code","source":"same_group = train.iloc[np.where(train['label_group'] == 3627744656)]\nsame_group.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distance = lev.distance('be9c95c3c16a631c', 'be9c90c3c16f631c')\nprint(distance)\nratio = lev.ratio('be9c95c3c16a631c', 'be9c90c3c16f631c')\nprint(ratio)\n\ndistance = lev.distance('be9c95c3c16a631c', 'be9d95c1c16a631c')\nprint(distance)\nratio = lev.ratio('be9c95c3c16a631c', 'be9d95c1c16a631c')\nprint(ratio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor phash in same_group['image_phash']:\n    if lev.distance('be9c95c3c16a631c', phash) <= 2:\n        print(phash)\n        count += 1\n        \nprint(count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Putting this together with our submission","metadata":{}},{"cell_type":"code","source":"def similar_phash(phash):\n    matching = []\n    for ind in test.index:\n        #print(ind)\n        #print(test['image_phash'][ind])\n        if lev.distance(phash, test['image_phash'][ind]) <= 2:\n            matching.append(ind)\n            \n    #print(matching)\n    return matching","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\nids = []\nitem_group = [] # tracks which group an item is in\ngroups = {} # tracks which items are in each group\nfor ind in test.index:\n    \n    indices_phash = np.where(test['image_phash'] == test['image_phash'][ind])[0]\n    indices_title = np.where(test['title'] == test['title'][ind])[0]\n    indices_image = np.where(test['image'] == test['image'][ind])[0]\n    indices_phash_similar = similar_phash(test['image_phash'][ind])\n    indices = set(indices_phash).union(set(indices_title)).union(set(indices_image)).union(set(indices_phash_similar))\n    \n    # check if an item this matches already has a group\n    match_ids = list(test.loc[indices]['posting_id'])\n    if set(match_ids).intersection(ids):\n        existing_group = item_group[ids.index(list(set(match_ids).intersection(ids))[0])]\n        item_group.append(existing_group)\n        groups[existing_group] = set(groups[existing_group]).union(match_ids)\n    else:\n        item_group.append(len(groups))\n        groups[len(groups)] = match_ids\n        \n    ids.append(test['posting_id'][ind])\n    \nmatches = [' '.join(list(groups[ind])) for ind in item_group]\n\nprint(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\nsubmission.to_csv('submission.csv', index = False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking on Train Set","metadata":{}},{"cell_type":"code","source":"#def similar_phash(phash):\n#    matching = []\n#    for ind in train.index:\n#        if lev.distance(phash, train['image_phash'][ind]) <= 2:\n#            matching.append(ind)\n            \n#    return matching","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#start_time = time.time()\n\n#train_ids = []\n#train_item_group = [] # tracks which group an item is in\n#train_groups = {} # tracks which items are in each group\n#for ind in train.index:\n    \n#    indices_phash = np.where(train['image_phash'] == train['image_phash'][ind])[0]\n#    indices_title = np.where(train['title'] == train['title'][ind])[0]\n#    indices_image = np.where(train['image'] == train['image'][ind])[0]\n#    indices_phash_similar = similar_phash(train['image_phash'][ind])\n#    indices = set(indices_phash).union(set(indices_title)).union(set(indices_image)).union(set(indices_phash_similar))\n    \n    # check if an item this matches already has a group\n#    match_ids = list(train.loc[indices]['posting_id'])\n#    if set(match_ids).intersection(train_ids):\n#        existing_group = train_item_group[train_ids.index(list(set(match_ids).intersection(train_ids))[0])]\n#        train_item_group.append(existing_group)\n#        train_groups[existing_group] = set(train_groups[existing_group]).union(match_ids)\n#    else:\n#        train_item_group.append(len(train_groups))\n#        train_groups[len(train_groups)] = match_ids\n        \n#    train_ids.append(train['posting_id'][ind])\n    \n#train_matches = [' '.join(list(train_groups[ind])) for ind in train_item_group]\n\n#print(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#similar_phash('be9c95c3c16a631c')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for ind in similar_phash('be9c95c3c16a631c'):\n#    print(train['label_group'][ind])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_matches[32164]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}