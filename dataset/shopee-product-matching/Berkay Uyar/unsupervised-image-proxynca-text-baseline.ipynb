{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# DATA_PATH = '../input/'\nDATA_PATH = '../input/shopee-product-matching/'\n\nimport psutil","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:13.247406Z","start_time":"2021-03-18T09:59:13.24369Z"},"papermill":{"duration":0.046153,"end_time":"2021-05-03T23:37:34.061153","exception":false,"start_time":"2021-05-03T23:37:34.015","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modified from = https://www.kaggle.com/finlay/unsupervised-image-text-baseline-in-20min","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport gc\n\n# import cudf, cuml, cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:14.869532Z","start_time":"2021-03-18T09:59:14.482759Z"},"papermill":{"duration":0.215554,"end_time":"2021-05-03T23:37:34.294524","exception":false,"start_time":"2021-05-03T23:37:34.07897","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stopwords(col):\n    col = col.apply(lambda x: [item for item in x if item not in stop])\n    return col","metadata":{"papermill":{"duration":0.024417,"end_time":"2021-05-03T23:37:34.336349","exception":false,"start_time":"2021-05-03T23:37:34.311932","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV = False\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","metadata":{"papermill":{"duration":0.035944,"end_time":"2021-05-03T23:37:34.389915","exception":false,"start_time":"2021-05-03T23:37:34.353971","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#COMPUTE_CV = False\n\nif COMPUTE_CV:\n    train = pd.read_csv(DATA_PATH + 'train.csv')\n    train['image'] = DATA_PATH + 'train_images/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    # train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\nelse:\n    train = pd.read_csv(DATA_PATH + 'test.csv')\n    train['image'] = DATA_PATH + 'test_images/' + train['image']\n    # train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n    \nprint('train shape is', train.shape )\ntrain.head()","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:15.92512Z","start_time":"2021-03-18T09:59:15.308672Z"},"papermill":{"duration":0.061042,"end_time":"2021-05-03T23:37:34.469488","exception":false,"start_time":"2021-05-03T23:37:34.408446","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image hash","metadata":{"papermill":{"duration":0.018377,"end_time":"2021-05-03T23:37:34.506543","exception":false,"start_time":"2021-05-03T23:37:34.488166","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:19.569052Z","start_time":"2021-03-18T09:59:18.284395Z"},"papermill":{"duration":0.029661,"end_time":"2021-05-03T23:37:34.554594","exception":false,"start_time":"2021-05-03T23:37:34.524933","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:21.98207Z","start_time":"2021-03-18T09:59:20.62671Z"},"papermill":{"duration":0.025049,"end_time":"2021-05-03T23:37:34.598074","exception":false,"start_time":"2021-05-03T23:37:34.573025","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# text word2vec","metadata":{"papermill":{"duration":0.018575,"end_time":"2021-05-03T23:37:34.635474","exception":false,"start_time":"2021-05-03T23:37:34.616899","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# train['title_word'] = train['title'].apply(lambda x: x.lower().split(' '))\n\n# from gensim.test.utils import get_tmpfile\n# from gensim.models import KeyedVectors\n\n# vectors = KeyedVectors.load_word2vec_format(\"../input/glove2word2vec/glove_w2v.txt\") # import the data file","metadata":{"execution":{"iopub.execute_input":"2021-05-03T23:37:34.676686Z","iopub.status.busy":"2021-05-03T23:37:34.676056Z","iopub.status.idle":"2021-05-03T23:37:34.679002Z","shell.execute_reply":"2021-05-03T23:37:34.678536Z"},"papermill":{"duration":0.025,"end_time":"2021-05-03T23:37:34.679104","exception":false,"start_time":"2021-05-03T23:37:34.654104","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# title_feats = []\n# for title in tqdm_notebook(train['title_word'].values[:]):\n#     title_feat = []\n#     for word in title:\n#         if word in vectors:\n#             title_feat.append(vectors[word])\n#     if len(title_feat) == 0:\n#         title_feat = np.random.rand(200)\n#     else:\n#         title_feat = np.vstack(title_feat).max(0)\n#     title_feats.append(title_feat)\n#     # break\n    \n# del vectors;","metadata":{"execution":{"iopub.execute_input":"2021-05-03T23:37:34.719683Z","iopub.status.busy":"2021-05-03T23:37:34.71906Z","iopub.status.idle":"2021-05-03T23:37:34.722027Z","shell.execute_reply":"2021-05-03T23:37:34.721568Z"},"papermill":{"duration":0.024476,"end_time":"2021-05-03T23:37:34.722132","exception":false,"start_time":"2021-05-03T23:37:34.697656","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import normalize\n\n# # l2 norm to kill all the sim in 0-1\n# title_feats = np.vstack(title_feats)\n# title_feats = normalize(title_feats)","metadata":{"execution":{"iopub.execute_input":"2021-05-03T23:37:34.765906Z","iopub.status.busy":"2021-05-03T23:37:34.765211Z","iopub.status.idle":"2021-05-03T23:37:34.767556Z","shell.execute_reply":"2021-05-03T23:37:34.768046Z"},"papermill":{"duration":0.027185,"end_time":"2021-05-03T23:37:34.768162","exception":false,"start_time":"2021-05-03T23:37:34.740977","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds = []\n# CHUNK = 1024*4\n\n# title_feats = cupy.array(title_feats)\n\n# print('Finding similar images...')\n# CTS = len(title_feats)//CHUNK\n# if len(title_feats)%CHUNK!=0: CTS += 1\n# for j in range( CTS ):\n    \n#     a = j*CHUNK\n#     b = (j+1)*CHUNK\n#     b = min(b, len(title_feats))\n#     print('chunk',a,'to',b)\n    \n#     distances = cupy.matmul(title_feats, title_feats[a:b].T).T\n#     # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n#     for k in range(b-a):\n#         IDX = cupy.where(distances[k,]>0.90)[0]\n#         # IDX = np.where(distances[k,]>0.95)[0][:]\n#         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n#         preds.append(o)\n        \n# # del imagefeat, imgmodel","metadata":{"execution":{"iopub.execute_input":"2021-05-03T23:37:34.809754Z","iopub.status.busy":"2021-05-03T23:37:34.809137Z","iopub.status.idle":"2021-05-03T23:37:34.811573Z","shell.execute_reply":"2021-05-03T23:37:34.812012Z"},"papermill":{"duration":0.025118,"end_time":"2021-05-03T23:37:34.812132","exception":false,"start_time":"2021-05-03T23:37:34.787014","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train['oof_w2v'] = preds\n\n# if COMPUTE_CV:\n#     train['f1'] = train.apply(getMetric('oof_w2v'),axis=1)\n#     print('CV score for baseline =',train.f1.mean())","metadata":{"execution":{"iopub.execute_input":"2021-05-03T23:37:34.853196Z","iopub.status.busy":"2021-05-03T23:37:34.852501Z","iopub.status.idle":"2021-05-03T23:37:34.855426Z","shell.execute_reply":"2021-05-03T23:37:34.854991Z"},"papermill":{"duration":0.024577,"end_time":"2021-05-03T23:37:34.855595","exception":false,"start_time":"2021-05-03T23:37:34.831018","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image CNN","metadata":{"papermill":{"duration":0.019204,"end_time":"2021-05-03T23:37:34.894745","exception":false,"start_time":"2021-05-03T23:37:34.875541","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nclass ShopeeImageDataset(Dataset):\n    def __init__(self, img_path, transform):\n        self.img_path = img_path\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n        img = self.transform(img)\n        return img\n    \n    def __len__(self):\n        return len(self.img_path)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:24.147684Z","start_time":"2021-03-18T09:59:23.6933Z"},"papermill":{"duration":1.605119,"end_time":"2021-05-03T23:37:36.519023","exception":false,"start_time":"2021-05-03T23:37:34.913904","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ScaleIntensities():\n    def __init__(self, in_range, out_range):\n        \"\"\" Scales intensities. For example [-1, 1] -> [0, 255].\"\"\"\n        self.in_range = in_range\n        self.out_range = out_range\n\n    def __oldcall__(self, tensor):\n        tensor.mul_(255)\n        return tensor\n\n    def __call__(self, tensor):\n        tensor = (\n            tensor - self.in_range[0]\n        ) / (\n            self.in_range[1] - self.in_range[0]\n        ) * (\n            self.out_range[1] - self.out_range[0]\n        ) + self.out_range[0]\n        return tensor\n    \nclass Identity(): # used for skipping transforms\n    def __call__(self, im):\n        return im","metadata":{"papermill":{"duration":0.028423,"end_time":"2021-05-03T23:37:36.567295","exception":false,"start_time":"2021-05-03T23:37:36.538872","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgb_to_bgr = False \nintensity_scale = [[0, 1], [0, 1]]\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\nsz_crop = 256\nsz_resize = 288\n\nimagedataset = ShopeeImageDataset(\n    train['image'].values,\n  transforms.Compose([\n        RGBToBGR() if rgb_to_bgr else Identity(),\n        #transforms.RandomRotation(rotate) if COMPUTE_CV and (not isinstance(rotate, numbers.Number)) else Identity(),\n        transforms.RandomResizedCrop(sz_crop) if COMPUTE_CV else Identity(),\n        transforms.Resize(sz_resize) if not COMPUTE_CV else Identity(),\n        transforms.CenterCrop(sz_crop) if not COMPUTE_CV else Identity(),\n        transforms.RandomHorizontalFlip() if COMPUTE_CV else Identity(),\n        transforms.ToTensor(),\n        ScaleIntensities(\n            *intensity_scale) if intensity_scale is not None else Identity(),\n        transforms.Normalize(\n            mean=mean,\n            std=std,\n        )\n    ]))\n    \nimageloader = torch.utils.data.DataLoader(\n    imagedataset,\n    batch_size=40, shuffle=False, num_workers=2\n)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:25.6502Z","start_time":"2021-03-18T09:59:25.64389Z"},"papermill":{"duration":0.029561,"end_time":"2021-05-03T23:37:36.616476","exception":false,"start_time":"2021-05-03T23:37:36.586915","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\n\nclass Feature(nn.Module):\n    def __init__(self, model='resnet50', pool='avg', use_lnorm=False):\n        nn.Module.__init__(self)\n        self.model = model\n\n        self.base = models.__dict__[model](pretrained=True)\n        if pool == 'avg':\n            self.pool = nn.AdaptiveAvgPool2d((1, 1))        \n        elif pool == 'max':\n            self.pool = nn.AdaptiveMaxPool2d((1, 1))\n        else:\n            raise Exception('pool: %s pool must be avg or max', str(pool))\n\n        self.lnorm = None\n        if use_lnorm:\n            self.lnorm = nn.LayerNorm(2048, elementwise_affine=False).cuda()\n\n    def forward(self, x):\n        x = self.base.conv1(x)\n        x = self.base.bn1(x)\n        x = self.base.relu(x)\n        x = self.base.maxpool(x)\n\n        x = self.base.layer1(x)\n        x = self.base.layer2(x)\n        x = self.base.layer3(x)\n        x = self.base.layer4(x)\n        x1 = self.pool(x)\n        x = x1\n        x = x.reshape(x.size(0), -1)\n\n        if self.lnorm != None:\n            x = self.lnorm(x)\n\n        return x\n\nclass Feat_resnet50_max(Feature):\n     def __init__(self):\n        Feature.__init__(self, model='resnet50', pool='max')\n\nclass Feat_resnet50_avg(Feature):\n     def __init__(self):\n        Feature.__init__(self, model='resnet50', pool='avg')\n\nclass Feat_resnet50_max_n(Feature):\n     def __init__(self):\n        Feature.__init__(self, model='resnet50', pool='max', use_lnorm=True)\n\nclass Feat_resnet50_avg_n(Feature):\n     def __init__(self):\n        Feature.__init__(self, model='resnet50', pool='avg', use_lnorm=True)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:27.08827Z","start_time":"2021-03-18T09:59:27.083495Z"},"papermill":{"duration":0.034213,"end_time":"2021-05-03T23:37:36.670138","exception":false,"start_time":"2021-05-03T23:37:36.635925","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/pretrained-pytorch-models/resnet18-5c106cde.pth /root/.cache/torch/hub/checkpoints/\n!cp ../input/pretrained-pytorch-models/resnet50-19c8e357.pth /root/.cache/torch/hub/checkpoints/","metadata":{"papermill":{"duration":6.371348,"end_time":"2021-05-03T23:37:43.061072","exception":false,"start_time":"2021-05-03T23:37:36.689724","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda'#turn to cuda for gpu \n\nfeat = Feat_resnet50_max_n()\nfeat.eval()\nin_sz = feat(torch.rand(1, 3, 256, 256)).squeeze().size(0)\nemb = torch.nn.Linear(in_sz, 2048)\nmodel = torch.nn.Sequential(feat, emb)\nmodel = torch.nn.DataParallel(model)\nPATH = \"../input/proxxy/shopee_shopee_trainval_0.pt\"\n#PATH = PATH.to(DEVICE)\nmodel.load_state_dict(torch.load(PATH)) \nmodel.eval()\n\nimgmodel = model.cuda() #delete hash for gpu usage\nimagefeat = []\nwith torch.no_grad():\n    for data in tqdm_notebook(imageloader):\n        data = data.to(DEVICE)\n        feat = imgmodel(data)\n        feat = feat.reshape(feat.shape[0], feat.shape[1])\n        feat = feat.data.cpu().numpy()\n        \n        imagefeat.append(feat)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:20.420477Z","start_time":"2021-03-18T09:59:28.809744Z"},"papermill":{"duration":9.797185,"end_time":"2021-05-03T23:37:52.879531","exception":false,"start_time":"2021-05-03T23:37:43.082346","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import normalize\n\n# l2 norm to kill all the sim in 0-1\nimagefeat = np.vstack(imagefeat)\nimagefeat = normalize(imagefeat)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:43.818543Z","start_time":"2021-03-18T10:01:43.401624Z"},"papermill":{"duration":0.829849,"end_time":"2021-05-03T23:37:53.73491","exception":false,"start_time":"2021-05-03T23:37:52.905061","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagefeat = torch.from_numpy(imagefeat)\nimagefeat = imagefeat.cuda()","metadata":{"papermill":{"duration":0.028521,"end_time":"2021-05-03T23:37:53.784557","exception":false,"start_time":"2021-05-03T23:37:53.756036","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\n\nprint('Finding similar images...')\nCTS = len(imagefeat)//CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n    distances = distances.data.cpu().numpy()\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n    for k in range(b-a):\n        # IDX = cupy.where(distances[k,]>0.95)[0]\n        IDX = np.where(distances[k,]>0.93)[0][:]\n        o = train.iloc[IDX].posting_id.values\n#         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel imagefeat, imgmodel","metadata":{"papermill":{"duration":0.035171,"end_time":"2021-05-03T23:37:53.841008","exception":false,"start_time":"2021-05-03T23:37:53.805837","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['oof_cnn'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('CV score for baseline =',train.f1.mean())\n    \n    \n# 0.6527899883424048 0.95\n# 0.6686372611222741 0.94\n# 0.6762305764407363 0.93","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:58.132852Z","start_time":"2021-03-18T10:01:56.678412Z"},"papermill":{"duration":0.030727,"end_time":"2021-05-03T23:37:53.893613","exception":false,"start_time":"2021-05-03T23:37:53.862886","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"papermill":{"duration":0.038786,"end_time":"2021-05-03T23:37:53.953637","exception":false,"start_time":"2021-05-03T23:37:53.914851","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# title TFIDF","metadata":{"papermill":{"duration":0.021774,"end_time":"2021-05-03T23:37:53.997892","exception":false,"start_time":"2021-05-03T23:37:53.976118","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=55000)\ntext_embeddings = model.fit_transform(train.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:02:00.631468Z","start_time":"2021-03-18T10:01:59.851964Z"},"papermill":{"duration":0.052291,"end_time":"2021-05-03T23:37:54.072577","exception":false,"start_time":"2021-05-03T23:37:54.020286","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_embeddings = torch.from_numpy(text_embeddings)\ntext_embeddings = text_embeddings.cuda()","metadata":{"papermill":{"duration":0.029049,"end_time":"2021-05-03T23:37:54.124069","exception":false,"start_time":"2021-05-03T23:37:54.09502","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)//CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nCTS_index = 0\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n    cts = cts.data.cpu().numpy()\n    print(cts.shape)\n    for k in range(b-a):\n        # IDX = np.where(cts[k,]>0.7)[0]\n        IDX = np.where(cts[k,]>0.58)[0]\n        o = train.iloc[IDX].posting_id.values\n        preds.append(o)\n        CTS_index += 1","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:05:46.252393Z","start_time":"2021-03-18T10:02:01.803979Z"},"papermill":{"duration":0.036368,"end_time":"2021-05-03T23:37:54.184119","exception":false,"start_time":"2021-05-03T23:37:54.147751","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n    print('CV score for baseline =',train.f1.mean())\n    \n    \n# 0.6137154152579091 0.7\n# 0.6507316994356058 0.6","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:03.146166Z","start_time":"2021-03-18T10:06:01.83687Z"},"papermill":{"duration":0.030797,"end_time":"2021-05-03T23:37:54.237674","exception":false,"start_time":"2021-05-03T23:37:54.206877","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_for_sub(row):\n    #x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    x = np.concatenate([row.oof_cnn])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:04.931476Z","start_time":"2021-03-18T10:06:04.925838Z"},"papermill":{"duration":0.030811,"end_time":"2021-05-03T23:37:54.291466","exception":false,"start_time":"2021-05-03T23:37:54.260655","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    train['f1'] = train.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train.f1.mean() )\n\ntrain['matches'] = train.apply(combine_for_sub,axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:09.759812Z","start_time":"2021-03-18T10:06:05.955972Z"},"papermill":{"duration":0.035262,"end_time":"2021-05-03T23:37:54.349552","exception":false,"start_time":"2021-05-03T23:37:54.31429","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:12.385916Z","start_time":"2021-03-18T10:06:12.180234Z"},"papermill":{"duration":0.178604,"end_time":"2021-05-03T23:37:54.551471","exception":false,"start_time":"2021-05-03T23:37:54.372867","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.023683,"end_time":"2021-05-03T23:37:54.59917","exception":false,"start_time":"2021-05-03T23:37:54.575487","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}