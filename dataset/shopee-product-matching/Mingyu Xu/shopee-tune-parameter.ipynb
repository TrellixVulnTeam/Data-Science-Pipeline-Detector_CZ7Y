{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nfrom shutil import copyfile\n\ncopyfile(src = \"../input/shopee-utils/utils.py\", dst = \"../working/utils.py\")\nsys.path.append(\"../input/timm-pytorch-image-models/pytorch-image-models-master\")","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:37.691862Z","iopub.execute_input":"2022-05-11T15:04:37.692199Z","iopub.status.idle":"2022-05-11T15:04:37.704775Z","shell.execute_reply.started":"2022-05-11T15:04:37.692111Z","shell.execute_reply":"2022-05-11T15:04:37.704025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torchvision import transforms\nfrom utils import ShopeeTrainDataset, ShopeeImageDataset, ShopeeTextTrainDataset, ShopeeTextDataset\nfrom utils import get_metric, validate\n\nfrom transformers import AutoTokenizer, AutoModel\nimport timm\n\nimport cudf\nimport cuml\n\nimport os\nfrom tqdm import tqdm\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:37.70671Z","iopub.execute_input":"2022-05-11T15:04:37.707147Z","iopub.status.idle":"2022-05-11T15:04:42.357231Z","shell.execute_reply.started":"2022-05-11T15:04:37.707111Z","shell.execute_reply":"2022-05-11T15:04:42.356479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    PATH = \"../input/shopee-product-matching/\"\n    \n    image_model_name = \"eca_nfnet_l0\"\n    image_model_path = \"../input/shopeemodel/eca_nfnet_l0_flexibleMargin_epoch_8.pt\"\n    text_model_name = \"distilbert-base-multilingual-cased\"\n    text_model_path = \"../input/shopeemodel/distilbert-base-multilingual-cased_epoch_6.pt\"\n    \n    n_classes = 9024\n    batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:42.35844Z","iopub.execute_input":"2022-05-11T15:04:42.358674Z","iopub.status.idle":"2022-05-11T15:04:42.363567Z","shell.execute_reply.started":"2022-05-11T15:04:42.358642Z","shell.execute_reply":"2022-05-11T15:04:42.36237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcFace(nn.Module):\n    \"\"\" NN module for projecting extracted embeddings onto the sphere surface \"\"\"\n    \n    def __init__(self, in_features, out_features, s=30, m=0.5):\n        super(ArcFace, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.cos_m = math.cos(self.m)\n        self.sin_m = math.sin(self.m)\n        self.arc_min = math.cos(math.pi - self.m)\n        self.margin_min = math.sin(math.pi - self.m) * self.m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n    \n    def _update_margin(self, new_margin):\n        self.m = new_margin\n        self.cos_m = math.cos(self.m)\n        self.sin_m = math.sin(self.m)\n        self.arc_min = math.cos(math.pi - self.m)\n        self.margin_min = math.sin(math.pi - self.m) * self.m\n\n    def forward(self, embedding, label):\n        cos = F.linear(F.normalize(embedding), F.normalize(self.weight))\n        sin = torch.sqrt(1.0 - torch.pow(cos, 2)).clamp(0, 1)\n        phi = cos * self.cos_m - sin * self.sin_m\n        phi = torch.where(cos > self.arc_min, phi, cos - self.margin_min)\n\n        one_hot = torch.zeros(cos.size(), device=device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        logits = one_hot * phi + (1.0 - one_hot) * cos\n        logits *= self.s\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:42.364784Z","iopub.execute_input":"2022-05-11T15:04:42.365414Z","iopub.status.idle":"2022-05-11T15:04:42.380641Z","shell.execute_reply.started":"2022-05-11T15:04:42.365375Z","shell.execute_reply":"2022-05-11T15:04:42.380027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model_name, n_classes, margin=0.5, fc_dim=1024):\n        super(Model, self).__init__()\n        print(\"Building Model Backbone for {} model\".format(model_name))\n        self.model_name = model_name\n        self.backbone = timm.create_model(model_name, pretrained=True)\n        \n        if \"resnet\" in model_name:\n            feat_size = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n        \n        elif \"eca_nfnet\" in model_name:\n            feat_size = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n            self.backbone.head.global_pool = nn.Identity()\n                \n        elif \"efficientnet\" in model_name:\n            feat_size = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n        \n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(p=0.1)\n        self.fc = nn.Linear(feat_size, fc_dim)\n        self.bn = nn.BatchNorm1d(fc_dim)\n        self.margin = ArcFace(fc_dim, n_classes, m=margin)\n        self._init_params()\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, x, labels=None):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n        \n        x = self.dropout(x)\n        x = self.fc(x)\n        x = self.bn(x)\n        x = F.normalize(x,dim=1)\n        if labels is not None:\n            return self.margin(x,labels)\n        else:\n            return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:42.383437Z","iopub.execute_input":"2022-05-11T15:04:42.383809Z","iopub.status.idle":"2022-05-11T15:04:42.399635Z","shell.execute_reply.started":"2022-05-11T15:04:42.383773Z","shell.execute_reply":"2022-05-11T15:04:42.398889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextModel(nn.Module):\n    def __init__(self, model_name, n_classes, margin=0.5, fc_dim=1024):\n        super(TextModel, self).__init__()\n        print(\"Building Model Backbone for {} model\".format(model_name))\n        self.model_name = model_name\n        self.tokenizer = AutoTokenizer.from_pretrained(\"{model_name}\".format(model_name=model_name), TOKENIZERS_PARALLELISM=False)\n        self.backbone = AutoModel.from_pretrained(\"{model_name}\".format(model_name=model_name))\n        self.feat_size = self.backbone.config.hidden_size\n\n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(p=0.1)\n        self.fc = nn.Linear(self.feat_size, fc_dim)\n        self.bn = nn.BatchNorm1d(fc_dim)\n        self.margin = ArcFace(fc_dim, n_classes, m=margin)\n        self._init_params()\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, text, labels=None):\n        inputs = self.tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n        output = self.backbone(input_ids = inputs[\"input_ids\"].to(device), attention_mask = inputs[\"attention_mask\"].to(device))\n        embedding = output[0][:, 0, :] \n        x = self.dropout(embedding)\n        x = self.fc(x)\n        x = self.bn(x)\n        x = F.normalize(x,dim=1)\n        if labels is not None:\n            return self.margin(x,labels)\n        else:\n            return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:42.401262Z","iopub.execute_input":"2022-05-11T15:04:42.401551Z","iopub.status.idle":"2022-05-11T15:04:42.415699Z","shell.execute_reply.started":"2022-05-11T15:04:42.401516Z","shell.execute_reply":"2022-05-11T15:04:42.414785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dataset(name=\"train\"):\n    assert name in {\"train\", \"test\"}\n    df = pd.read_csv(config.PATH + '{}.csv'.format(name))\n    df[\"image_path\"] = config.PATH + '{}_images/'.format(name) + df['image']\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:42.417241Z","iopub.execute_input":"2022-05-11T15:04:42.417594Z","iopub.status.idle":"2022-05-11T15:04:42.427839Z","shell.execute_reply.started":"2022-05-11T15:04:42.417555Z","shell.execute_reply":"2022-05-11T15:04:42.427188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = read_dataset(\"train\")\nlabel_group_dict = df.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\ndf['target'] = df.label_group.map(label_group_dict)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:42.429095Z","iopub.execute_input":"2022-05-11T15:04:42.429295Z","iopub.status.idle":"2022-05-11T15:04:43.123669Z","shell.execute_reply.started":"2022-05-11T15:04:42.429272Z","shell.execute_reply":"2022-05-11T15:04:43.122921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = len(df[\"label_group\"].unique())\nnum = int(0.2 * n_classes)\nnp.random.seed(1)\ntest_group = np.random.choice(df[\"label_group\"].unique(), num)\n#test_group\ndf_test = df[df[\"label_group\"].isin(test_group)]\ndf_train = df[~df[\"label_group\"].isin(test_group)]\n\nif torch.cuda.is_available():\n    df_cu = cudf.DataFrame(df) \n    df_train_cu = cudf.DataFrame(df_train) \n    df_test_cu = cudf.DataFrame(df_test) \n\nprint(len(df_train), len(df_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:43.125036Z","iopub.execute_input":"2022-05-11T15:04:43.125464Z","iopub.status.idle":"2022-05-11T15:04:46.721698Z","shell.execute_reply.started":"2022-05-11T15:04:43.125426Z","shell.execute_reply":"2022-05-11T15:04:46.720956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\ntest_dataset = ShopeeImageDataset(df_test, transform = transform)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\ndf_text_dataset = ShopeeTextDataset(df_test)\ndf_text_dataloader = torch.utils.data.DataLoader(df_text_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n\nwhole_dataset = ShopeeImageDataset(df, transform = transform)\nwhole_dataloader = torch.utils.data.DataLoader(whole_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:46.723007Z","iopub.execute_input":"2022-05-11T15:04:46.7233Z","iopub.status.idle":"2022-05-11T15:04:46.731249Z","shell.execute_reply.started":"2022-05-11T15:04:46.723249Z","shell.execute_reply":"2022-05-11T15:04:46.730564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n\ndef get_model(model_name, model_path, n_classes):\n    model = Model(model_name, n_classes)\n    if model_path is not None:\n        model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n    return model.to(device)\n\ndef get_text_model(model_name, model_path, n_classes):\n    model = TextModel(model_name, n_classes)\n    if model_path is not None:\n        model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n    return model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:46.732798Z","iopub.execute_input":"2022-05-11T15:04:46.733585Z","iopub.status.idle":"2022-05-11T15:04:46.742425Z","shell.execute_reply.started":"2022-05-11T15:04:46.733547Z","shell.execute_reply":"2022-05-11T15:04:46.741634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_feature(model, dataloader):\n    image_features = []\n    with torch.no_grad():\n        for images in tqdm(dataloader):\n            images = images.to(device)\n            features = model(images)\n            image_features.append(features)\n            del images\n    image_features = torch.cat(image_features, axis=0)\n\n    torch.cuda.empty_cache()   \n    return image_features\n\n\ndef get_tfidf_feature(df, max_features):\n    if torch.cuda.is_available():\n        from cuml.feature_extraction.text import TfidfVectorizer\n    else:\n        from sklearn.feature_extraction.text import TfidfVectorizer\n    \n    model = TfidfVectorizer(stop_words='english', max_features=max_features)\n    model.fit(df.title)\n\n    tfidf_features = model.transform(df.title).toarray()\n    tfidf_features = torch.Tensor(tfidf_features).to(device)\n    return tfidf_features\n\ndef get_bert_feature(model, dataloader):\n    text_features = []\n    with torch.no_grad():\n        for text in tqdm(dataloader):\n            text = list(text)\n            features = model(text)\n            text_features.append(features)\n            del text\n    text_features = torch.cat(text_features, axis=0)\n\n    torch.cuda.empty_cache()   \n    return text_features","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:04:46.743986Z","iopub.execute_input":"2022-05-11T15:04:46.744581Z","iopub.status.idle":"2022-05-11T15:04:46.755495Z","shell.execute_reply.started":"2022-05-11T15:04:46.744547Z","shell.execute_reply":"2022-05-11T15:04:46.754785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PRETRAIN","metadata":{}},{"cell_type":"code","source":"model_name = \"resnet34\"\nmodel = get_model(model_name, None, config.n_classes)\n\nimage_features = get_image_feature(model, test_dataloader)\n\nthresholds = np.arange(0.6, 0.95, 0.05)\n# least_thresholds = np.arange(0.2, 0.6, 0.1)\n# least_thresholds = np.arange(0.4, 0.5, 0.1)\nfor threshold in thresholds:\n#     for least_threshold in least_thresholds:\n    f1, prec, rec = validate(image_features, df_test, threshold)\n    print(\"Threshold: {:2f} F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T15:16:44.051975Z","iopub.execute_input":"2022-05-10T15:16:44.052294Z","iopub.status.idle":"2022-05-10T15:18:34.709541Z","shell.execute_reply.started":"2022-05-10T15:16:44.052261Z","shell.execute_reply":"2022-05-10T15:18:34.708413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"bert-base-multilingual-cased\"\ntext_model = get_text_model(model_name, None, config.n_classes)\nbert_features = get_bert_feature(text_model, df_text_dataloader)\n\nthresholds = np.arange(0.6, 0.95, 0.05)\n# least_thresholds = np.arange(0.2, 0.6, 0.1)\n# least_thresholds = np.arange(0.4, 0.5, 0.1)\nfor threshold in thresholds:\n#     for least_threshold in least_thresholds:\n    f1, prec, rec = validate(bert_features, df_test, threshold)\n    print(\"Threshold: {:2f}  F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T15:46:26.932992Z","iopub.execute_input":"2022-05-10T15:46:26.933323Z","iopub.status.idle":"2022-05-10T15:47:50.75555Z","shell.execute_reply.started":"2022-05-10T15:46:26.933285Z","shell.execute_reply":"2022-05-10T15:47:50.753749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(config.image_model_name, config.image_model_path, config.n_classes)\nimage_features = get_image_feature(model, test_dataloader)\n\n# thresholds = np.arange(0.6, 0.95, 0.05)\n# least_thresholds = np.arange(0.2, 0.6, 0.1)\n# least_thresholds = np.arange(0.4, 0.5, 0.1)\n# for threshold in thresholds:\n#     for least_threshold in least_thresholds:\n#     f1, prec, rec = validate(image_features, df_test, threshold)\n#     print(\"Threshold: {:2f} F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))\n\nIMAGE_THRESHOLD = 0.8\nIMAGE_LEAST_THRESHOLD = 0.6\n\nf1, prec, rec = validate(image_features, df_test, IMAGE_THRESHOLD, least_threshold=IMAGE_LEAST_THRESHOLD)\nprint(\"Threshold: {:2f} F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(IMAGE_THRESHOLD, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:19:54.389184Z","iopub.execute_input":"2022-05-11T15:19:54.389477Z","iopub.status.idle":"2022-05-11T15:21:09.521476Z","shell.execute_reply.started":"2022-05-11T15:19:54.389446Z","shell.execute_reply":"2022-05-11T15:21:09.52058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_features = get_image_feature(model, whole_dataloader)\n\n# thresholds = np.arange(0.4, 0.9,0.05)\n# for threshold in thresholds:\n#     f1, prec, rec = validate(image_features, threshold, df)\n#     print(\"Threshold: {:2f} F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T08:19:45.393541Z","iopub.execute_input":"2021-11-10T08:19:45.393994Z","iopub.status.idle":"2021-11-10T08:22:43.429468Z","shell.execute_reply.started":"2021-11-10T08:19:45.393953Z","shell.execute_reply":"2021-11-10T08:22:43.428185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_model = get_text_model(config.text_model_name, config.text_model_path, config.n_classes)\nbert_features = get_bert_feature(text_model, df_text_dataloader)\n\n# thresholds = np.arange(0.6, 0.95, 0.05)\n# # least_thresholds = np.arange(0.2, 0.6, 0.1)\n# # least_thresholds = np.arange(0.4, 0.5, 0.1)\n# for threshold in thresholds:\n# #     for least_threshold in least_thresholds:\n#     f1, prec, rec = validate(bert_features, df_test, threshold)\n#     print(\"Threshold: {:2f}  F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))\n\nBERT_THRESHOLD = 0.85\nBERT_LEAST_THRESHOLD = 0.65\n\nf1, prec, rec = validate(bert_features, df_test, BERT_THRESHOLD, least_threshold=BERT_LEAST_THRESHOLD)\nprint(\"Threshold: {:2f}  F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(BERT_THRESHOLD, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:21:09.523376Z","iopub.execute_input":"2022-05-11T15:21:09.524145Z","iopub.status.idle":"2022-05-11T15:21:21.1407Z","shell.execute_reply.started":"2022-05-11T15:21:09.524103Z","shell.execute_reply":"2022-05-11T15:21:21.139749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_features = torch.cat([image_features, bert_features], axis=1)\n\n# thresholds = np.arange(0.6, 0.95, 0.05)\n# # least_thresholds = np.arange(0.2, 0.6, 0.1)\n# # least_thresholds = np.arange(0.3, 0.35, 0.1)\n# for threshold in thresholds:\n# #     for least_threshold in least_thresholds:\n#         f1, prec, rec = validate(concat_features, df_test, threshold)\n#         print(\"Threshold: {:2f} F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))\n\nCONCAT_THRESHOLD = 0.65\nCONCAT_LEAST_THRESHOLD = 0.45\n\nf1, prec, rec = validate(concat_features, df_test, CONCAT_THRESHOLD, least_threshold=CONCAT_LEAST_THRESHOLD)\nprint(\"Threshold: {:2f}  F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(CONCAT_THRESHOLD, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:21:21.142785Z","iopub.execute_input":"2022-05-11T15:21:21.143065Z","iopub.status.idle":"2022-05-11T15:21:23.352371Z","shell.execute_reply.started":"2022-05-11T15:21:21.143026Z","shell.execute_reply":"2022-05-11T15:21:23.351626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TFIDF_FEATURES = 25000\ntfidf_features = get_tfidf_feature(df_cu, TFIDF_FEATURES)\nthresholds = np.arange(0.6, 0.95, 0.05)\nfor threshold in thresholds:\n    f1, prec, rec = validate(tfidf_features, df, threshold)\n    print(\"Threshold: {:2f} F1: {:5f} Precision: {:5f} Recall: {:5f}\".format(threshold, f1, prec, rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:35:30.821062Z","iopub.execute_input":"2022-05-10T14:35:30.821372Z","iopub.status.idle":"2022-05-10T14:39:08.231772Z","shell.execute_reply.started":"2022-05-10T14:35:30.821339Z","shell.execute_reply":"2022-05-10T14:39:08.230738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import DistancePredict\nfrom functools import reduce\n\ndef union(x,y):\n    return np.union1d(x,y)\n\ndef intersect(x,y):\n    return np.intersect1d(x,y)\n\n# df[\"pred\"] = df.apply(lambda row: union(row['image_pred'], row[\"tfidf_pred\"]),axis=1)\n# df[\"wait\"] = df.apply(lambda row: intersect(row['image_pred_wait'], row[\"text_pred_wait\"]),axis=1)\n# df[\"pred\"] = df.apply(lambda row: union(row['pred'], row[\"wait\"]),axis=1)\n\ndf_test[\"image_pred\"] = DistancePredict(image_features, df_test, threshold= IMAGE_THRESHOLD, least_threshold=IMAGE_LEAST_THRESHOLD)\ndf_test[\"text_pred\"] = DistancePredict(bert_features, df_test, threshold= BERT_THRESHOLD, least_threshold=BERT_LEAST_THRESHOLD)\ndf_test[\"concat_pred\"] = DistancePredict(concat_features, df_test, threshold= CONCAT_THRESHOLD, least_threshold=CONCAT_LEAST_THRESHOLD)\n\ndf_test[\"pred\"] = df_test.apply(lambda row: reduce(union, [row['image_pred'], row[\"text_pred\"], row[\"concat_pred\"]]),axis=1)\n\nf1, prec, rec = get_metric(df_test[\"target\"], df_test[\"pred\"])\nprint(\"Mean F1: {:f}\".format(f1))\nprint(\"Mean Precision: {:f}\".format(prec))\nprint(\"Mean Recall: {:f}\".format(rec))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T15:21:23.354859Z","iopub.execute_input":"2022-05-11T15:21:23.355265Z","iopub.status.idle":"2022-05-11T15:21:28.609494Z","shell.execute_reply.started":"2022-05-11T15:21:23.355227Z","shell.execute_reply":"2022-05-11T15:21:28.608791Z"},"trusted":true},"execution_count":null,"outputs":[]}]}