{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Shopee Product Match","metadata":{"papermill":{"duration":0.021402,"end_time":"2021-05-09T07:05:51.639251","exception":false,"start_time":"2021-05-09T07:05:51.617849","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torchvision import transforms\nimport transformers\n\nimport os\nimport sys\nimport gc\n\nimport math\nimport cv2\nfrom torch.utils.data import DataLoader,Dataset\nfrom tqdm.notebook import tqdm\n\nif torch.cuda.is_available():\n    import cuml\n    import cudf\n    import cupy\n\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nimport torchvision","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.50671,"end_time":"2021-05-09T07:06:00.165766","exception":false,"start_time":"2021-05-09T07:05:51.659056","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/shopee-product-matching/\"\nos.listdir(PATH)","metadata":{"papermill":{"duration":0.0315,"end_time":"2021-05-09T07:06:00.218127","exception":false,"start_time":"2021-05-09T07:06:00.186627","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(PATH + 'test.csv')\nif len(test) > 3:\n    TRAIN = False\nelse:\n    TRAIN = True","metadata":{"papermill":{"duration":0.03565,"end_time":"2021-05-09T07:06:00.27442","exception":false,"start_time":"2021-05-09T07:06:00.23877","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before submitting, you should set TRAIN = False to see whether the notebook can run on test set normally\n\n#TRAIN = False\nDEBUG = False","metadata":{"papermill":{"duration":0.027654,"end_time":"2021-05-09T07:06:00.322585","exception":false,"start_time":"2021-05-09T07:06:00.294931","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dataset(name=\"train\"):\n    df = pd.read_csv('/kaggle/input/shopee-product-matching/{}.csv'.format(name))\n    df[\"image_path\"] = '/kaggle/input/shopee-product-matching/{}_images/'.format(name) + df['image']\n\n    return df","metadata":{"papermill":{"duration":0.026837,"end_time":"2021-05-09T07:06:00.37027","exception":false,"start_time":"2021-05-09T07:06:00.343433","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    train = read_dataset(\"train\")\n    label_group_dict = train.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n    train['target'] = train.label_group.map(label_group_dict)\nelse:\n    train = read_dataset(\"test\")\n\nif DEBUG:\n    train = pd.concat([train]*2)   \n\nif torch.cuda.is_available():\n    train_cu = cudf.DataFrame(train)    \n    \ntrain.head()","metadata":{"papermill":{"duration":11.1453,"end_time":"2021-05-09T07:06:11.536129","exception":false,"start_time":"2021-05-09T07:06:00.390829","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = len(train[\"label_group\"].unique())\nnum = int(0.15 * n_classes)\nnp.random.seed(1)\ntest_group = np.random.choice(train[\"label_group\"].unique(), num)\ndf_test = train[train[\"label_group\"].isin(test_group)].reset_index(drop=True)\ndf_train = train[~train[\"label_group\"].isin(test_group)].reset_index(drop=True)\nlen(df_train), len(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_test\nif torch.cuda.is_available():\n    train_cu = cudf.DataFrame(train)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"papermill":{"duration":0.031159,"end_time":"2021-05-09T07:06:11.589189","exception":false,"start_time":"2021-05-09T07:06:11.55803","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def euclidean_dist(x, y, norm=False):\n    m, n = x.size(0), y.size(0)\n    \n    if norm:\n        x = x / x.norm(p=2, dim=1, keepdim=True)\n        y = y / y.norm(p=2, dim=1, keepdim=True)\n    \n    xx = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(m, n)\n    yy = torch.pow(y, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n    dist = xx + yy\n    dist.addmm_(1, -2, x, y.t())\n    dist = dist.clamp(min=1e-12).sqrt()\n    return dist\n\ndef cosine_dist(x,y):\n    m, n = x.size(0), y.size(0)\n    \n    norm_x = x.norm(p=2, dim=1, keepdim=True).expand(m,n)\n    norm_y = y.norm(p=2, dim=1, keepdim=True).expand(n,m).t()\n    dist = torch.matmul(x, y.t()) / (norm_x * norm_y)\n    return dist\n\ndef DistancePredict(features, threshold = 0.9, chunk = 1024, distance_type=\"cosine\"):\n    assert(distance_type in (\"cosine\",\"euclidean\"))\n    \n    predict = []\n    n = (features.size(0) + chunk - 1) // chunk\n    with torch.no_grad():\n        for i in tqdm(range(n)):\n            a = i*chunk\n            b = (i+1)*chunk\n            b = min(b, features.size(0))\n            x = features[a:b]\n            y = features\n\n            if distance_type ==\"cosine\":\n                distance = cosine_dist(x,y).data.cpu().numpy()\n            elif distance_type == \"euclidean\":\n                distance = euclidean_dist(x,y, norm=True).data.numpy()\n\n            for k in range(b-a):\n                if distance_type == \"euclidean\":\n                    mask = distance[k] < threshold\n                else :\n                    mask = distance[k] > threshold\n                    \n                if np.sum(mask) > 50:\n                    index = np.argwhere(mask == True).flatten()\n                    index_idx = np.argsort(-distance[k, index])[:50]\n                    mask = index[index_idx]\n                    \n                pred = train.posting_id[mask].to_numpy()\n                predict.append(pred)\n            del x,y,distance\n            \n    return predict","metadata":{"papermill":{"duration":0.03735,"end_time":"2021-05-09T07:06:11.648271","exception":false,"start_time":"2021-05-09T07:06:11.610921","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1(target, predict):\n    n = len(np.intersect1d(target,predict))\n    return 2*n/(len(target)+len(predict))\n\ndef precision(target, predict):\n    n = len(np.intersect1d(target,predict))\n    return n / len(predict)\n    \ndef recall(target, predict):\n    n = len(np.intersect1d(target,predict))\n    return n / len(target)\n\ndef get_metric(target, predict):\n    tmp = pd.DataFrame({\"target\":target.reset_index(drop=True), \"predict\":predict.reset_index(drop=True)})\n    f1_score = tmp.apply(lambda row: f1(row['target'], row[\"predict\"]),axis=1)\n    precision_score = tmp.apply(lambda row: precision(row['target'], row[\"predict\"]),axis=1)\n    recall_score = tmp.apply(lambda row: recall(row['target'], row[\"predict\"]),axis=1)\n    print(\"Mean F1: {:f}\".format(f1_score.mean()))\n    print(\"Mean Precision: {:f}\".format(precision_score.mean()))\n    print(\"Mean Recall: {:f}\".format(recall_score.mean()))","metadata":{"papermill":{"duration":0.031844,"end_time":"2021-05-09T07:06:11.701706","exception":false,"start_time":"2021-05-09T07:06:11.669862","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image","metadata":{"papermill":{"duration":0.021847,"end_time":"2021-05-09T07:06:11.745689","exception":false,"start_time":"2021-05-09T07:06:11.723842","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ShopeeImageDataset(Dataset):\n    def __init__(self, dataset, transform=None, train=True, resize = 256):\n        self.dataset = dataset\n        self.transform = transform\n        self.train = train\n        self.resize = resize\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, index):\n        image_path = self.dataset.image_path.iloc[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (self.resize,self.resize))\n        if self.transform:\n            image = self.transform(image)\n        if self.train:\n            label_group = self.dataset.label_group.iloc[index]\n            return image, label_group\n        else:\n            return image","metadata":{"papermill":{"duration":0.030364,"end_time":"2021-05-09T07:06:11.798037","exception":false,"start_time":"2021-05-09T07:06:11.767673","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n\nshopee_image_dataset = ShopeeImageDataset(train, transform = transform, train = TRAIN)\nshopee_image_dataloader =  torch.utils.data.DataLoader(shopee_image_dataset, batch_size=64, shuffle=False, num_workers=2, prefetch_factor = 8)\n\nshopee_swin_dataset = ShopeeImageDataset(train, transform = transform, train = TRAIN, resize = 224)\nshopee_swin_dataloader =  torch.utils.data.DataLoader(shopee_swin_dataset, batch_size=64, shuffle=False, num_workers=2, prefetch_factor = 8)","metadata":{"papermill":{"duration":0.030973,"end_time":"2021-05-09T07:06:11.851885","exception":false,"start_time":"2021-05-09T07:06:11.820912","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_feature(model_name):\n    # load\n    if TRAIN and os.path.exists(\"image_features_{}.pt\".format(model_name)):\n        image_features = torch.load(\"image_features_{}.pt\".format(model_name), map_location = device)\n    else:\n        dataloader = shopee_image_dataloader if \"swin\" not in model_name else shopee_swin_dataloader\n        model = get_model(model_name)\n        image_features = []\n        with torch.no_grad():\n            if TRAIN:\n                for (images, labels) in tqdm(dataloader):\n                    images, labels = images.to(device), labels.to(device)\n                    features = model(images)\n                    image_features.append(features)\n                    del images, labels\n            else:\n                for images in tqdm(dataloader):\n                    images = images.to(device)\n                    features = model(images)\n                    image_features.append(features.data)\n                    del images \n        image_features = torch.cat(image_features, axis=0)\n        # save\n        if TRAIN:\n            torch.save(image_features, \"image_features_{}.pt\".format(model_name))\n        \n        del model\n        gc.collect()\n        torch.cuda.empty_cache()   \n    \n    print(image_features.shape)\n    return image_features","metadata":{"papermill":{"duration":0.035248,"end_time":"2021-05-09T07:06:11.910731","exception":false,"start_time":"2021-05-09T07:06:11.875483","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcFace(nn.Module):\n    \"\"\" NN module for projecting extracted embeddings onto the sphere surface \"\"\"\n    \n    def __init__(self, in_features, out_features, s=30, m=0.5):\n        super(ArcFace, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.arc_min = math.cos(math.pi - m)\n        self.margin_min = math.sin(math.pi - m) * m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n\n    def forward(self, embedding, label):\n        cos = F.linear(F.normalize(embedding), F.normalize(self.weight))\n        sin = torch.sqrt(1.0 - torch.pow(cos, 2)).clamp(0, 1)\n        phi = cos * self.cos_m - sin * self.sin_m\n        phi = torch.where(cos > self.arc_min, phi, cos - self.margin_min)\n\n        one_hot = torch.zeros(cos.size(), device='cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        logits = one_hot * phi + (1.0 - one_hot) * cos\n        logits *= self.s\n        return logits","metadata":{"papermill":{"duration":0.034126,"end_time":"2021-05-09T07:06:11.966885","exception":false,"start_time":"2021-05-09T07:06:11.932759","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model_name, n_classes, fc_dim=512):\n        super(Model, self).__init__()\n        print(\"Building Model Backbone for {} model\".format(model_name))\n        \n        if \"eca_nfnet\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n                \n        elif \"efficientnet\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n\n        elif \"dm_nfnet\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n        \n        elif \"swin\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.head.in_features\n            self.backbone.head = nn.Identity()\n        \n        else:\n            raise ValueError(\"Invalid model name: {}\".format(model_name))\n        \n        self.fc = nn.Linear(feat_size, fc_dim)\n        self.margin = ArcFace(fc_dim, n_classes)\n        \n    def forward(self, x, labels=None):\n        x = self.backbone(x)\n        x = self.fc(x)\n        if labels is not None:\n            return self.margin(x,labels)\n        return F.normalize(x,dim=1)","metadata":{"papermill":{"duration":0.033091,"end_time":"2021-05-09T07:06:12.022228","exception":false,"start_time":"2021-05-09T07:06:11.989137","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(model_name):\n    name = \"_\".join(model_name.split(\"_\")[:-2])\n    if \"swin\" in name:\n        model = Model(name, 9977)\n    else:\n        model = Model(name, 9499)\n    model.load_state_dict(torch.load(\"../input/arcface-pretrained-model/{}.pt\".format(model_name), map_location=device))\n    model.to(device)\n\n    # eval\n    model.eval()\n    \n    return model","metadata":{"papermill":{"duration":0.029668,"end_time":"2021-05-09T07:06:12.074846","exception":false,"start_time":"2021-05-09T07:06:12.045178","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Weighted Ensemble","metadata":{"papermill":{"duration":0.023275,"end_time":"2021-05-09T07:06:12.219582","exception":false,"start_time":"2021-05-09T07:06:12.196307","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def WeightedEnsemblePredict(model_names, weights = None, threshold = 0.8):\n    n = len(model_names)\n    if not weights:\n        weights = [1/n] * n\n    \n    weighted_features = None\n    for model_name, weight in zip(model_names, weights):\n        model_features = get_image_feature(model_name)\n        if weighted_features is None:\n            weighted_features = weight * model_features\n        else:\n            weighted_features.add_(weight * model_features)\n    weighted_features /= sum(weights)\n    print(weighted_features.shape)\n    # predict\n    weighted_pred = DistancePredict(weighted_features, threshold=threshold)\n    del weighted_features\n    gc.collect()\n    torch.cuda.empty_cache()\n    return weighted_pred","metadata":{"papermill":{"duration":0.031585,"end_time":"2021-05-09T07:06:12.274815","exception":false,"start_time":"2021-05-09T07:06:12.24323","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"MODEL_NAMES = [\"efficientnet-b0_arcface_0015\", \"efficientnet-b4_arcface_0015\"]\nTHRESHOLD = 0.7\n\nweighted_pred = WeightedEnsemblePredict(MODEL_NAMES, threshold = THRESHOLD)\ntrain[\"image_pred\"] = weighted_pred\nif TRAIN:\n    print(\"\\nMODEL: Weighted Ensemble\")\n    get_metric(train[\"target\"], train[\"image_pred\"])\n\"\"\"","metadata":{"papermill":{"duration":0.029944,"end_time":"2021-05-09T07:06:12.327738","exception":false,"start_time":"2021-05-09T07:06:12.297794","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### UnionEnsemble","metadata":{"papermill":{"duration":0.023315,"end_time":"2021-05-09T07:06:12.374441","exception":false,"start_time":"2021-05-09T07:06:12.351126","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Union/Intersect Ensemble\ndef EasyEnsemblePredict(model_names, thresholds, ensemble_type=\"union\"):\n    tmp = pd.DataFrame()\n    for model_name, threshold in zip(MODEL_NAME, THRESHOLD):\n        # extract feature\n        image_features = get_image_feature(model_name)\n\n        # distance-based prediction\n        image_pred = DistancePredict(image_features, threshold=threshold)\n        tmp[\"{}_pred\".format(model_name)] = image_pred\n        \n        del image_features\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        # metric\n        if TRAIN:\n            print(\"MODEL: {} THRESHOLD: {}\".format(model_name, threshold))\n            get_metric(train[\"target\"], tmp[\"{}_pred\".format(model_name)])\n    # ensemble\n    n = len(model_names)\n    from functools import reduce\n    if ensemble_type == \"union\":\n        ensemble_pred = tmp.apply(lambda row: reduce(np.union1d, row), axis=1)\n    elif ensemble_type == \"intersect\":\n        ensemble_pred = tmp.apply(lambda row: reduce(np.intersect1d, row), axis=1)\n    \n    return ensemble_pred, tmp","metadata":{"papermill":{"duration":0.033369,"end_time":"2021-05-09T07:06:12.431102","exception":false,"start_time":"2021-05-09T07:06:12.397733","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"MODEL_NAME = [\"eca_nfnet_l0_arcface_7\", \"eca_nfnet_l1_arcface_8\" , \"efficientnet_b4_arcface_13\"]\nTHRESHOLD = [0.5, 0.5, 0.55]\n\nensemble_pred, tmp = EasyEnsemblePredict(MODEL_NAME, THRESHOLD, ensemble_type=\"union\")\ntrain[\"image_pred\"] = ensemble_pred\n    \nif TRAIN:\n    print(\"\\nMODEL:  UnionEnsemble\")\n    get_metric(train[\"target\"], train[\"image_pred\"])\"\"\"","metadata":{"papermill":{"duration":1049.190316,"end_time":"2021-05-09T07:23:41.644995","exception":false,"start_time":"2021-05-09T07:06:12.454679","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ConcatEnsemblePredict(model_names, threshold, normalize = True, distance_type=\"cosine\"):\n    concat_features = []\n    for model_name in model_names:\n        image_features = get_image_feature(model_name)\n        concat_features.append(image_features)\n    concat_features = torch.hstack(concat_features)\n    print(concat_features.shape)\n    # normalize\n    if normalize:\n        concat_features = F.normalize(concat_features, dim=1)\n    # predict\n    concat_pred = DistancePredict(concat_features, threshold=threshold, distance_type=distance_type)\n    \n    del concat_features\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return concat_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Concat Ensemble","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = [\"eca_nfnet_l0_arcface_7\", \"eca_nfnet_l1_arcface_8\" , \"efficientnet_b4_arcface_13\"]\nTHRESHOLD = 0.65\n\nconcat_pred = ConcatEnsemblePredict(MODEL_NAME, THRESHOLD)\ntrain[\"image_pred\"] = concat_pred\n    \nif TRAIN:\n    print(\"\\nMODEL:  ConcatEnsemble THRESHOLD: {}\".format(THRESHOLD))\n    get_metric(train[\"target\"], train[\"image_pred\"])\n\ntorch.cuda.empty_cache()\n\nTHRESHOLD = 0.46\n\nconcat_pred = ConcatEnsemblePredict(MODEL_NAME, THRESHOLD)\ntrain[\"image_pred_wait\"] = concat_pred\n    \nif TRAIN:\n    print(\"\\nMODEL:  ConcatEnsemble THRESHOLD: {}\".format(THRESHOLD))\n    get_metric(train[\"target\"], train[\"image_pred_wait\"])\n\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text","metadata":{"papermill":{"duration":0.03026,"end_time":"2021-05-09T07:23:41.707754","exception":false,"start_time":"2021-05-09T07:23:41.677494","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### TF-IDF","metadata":{"papermill":{"duration":0.030411,"end_time":"2021-05-09T07:23:41.767903","exception":false,"start_time":"2021-05-09T07:23:41.737492","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def TFIDFExtractFeature(df, max_features):\n    if torch.cuda.is_available():\n        from cuml.feature_extraction.text import TfidfVectorizer\n    else:\n        from sklearn.feature_extraction.text import TfidfVectorizer\n    \n    model = TfidfVectorizer(stop_words='english', max_features=max_features)\n    model.fit(df.title)\n\n    tfidf_features = model.transform(df.title).toarray()\n    print(tfidf_features.shape)\n    return tfidf_features","metadata":{"papermill":{"duration":0.038281,"end_time":"2021-05-09T07:23:41.836488","exception":false,"start_time":"2021-05-09T07:23:41.798207","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_FEATURES = 25000\nTHRESHOLD = 0.75\n\nif torch.cuda.is_available():\n    text_features = TFIDFExtractFeature(train_cu, MAX_FEATURES)\nelse:\n    text_features = TFIDFExtractFeature(train, MAX_FEATURES)\ntext_features = torch.Tensor(text_features).to(device)\ntext_pred = DistancePredict(text_features, threshold = THRESHOLD, distance_type=\"cosine\")\ntrain[\"text_pred\"] = text_pred\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"text_pred\"])\n\nTHRESHOLD = 0.51\ntext_pred = DistancePredict(text_features, threshold = THRESHOLD, distance_type=\"cosine\")\ntrain[\"text_pred_wait\"] = text_pred\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"text_pred_wait\"])\n\ndel text_features\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"papermill":{"duration":38.909925,"end_time":"2021-05-09T07:24:20.778442","exception":false,"start_time":"2021-05-09T07:23:41.868517","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bert","metadata":{"papermill":{"duration":0.030212,"end_time":"2021-05-09T07:24:20.839255","exception":false,"start_time":"2021-05-09T07:24:20.809043","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ShopeeTextDataset(Dataset):\n    def __init__(self, dataset, train):\n        self.dataset = dataset\n        self.train = train\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, index):\n        title = self.dataset.title.iloc[index]\n        if self.train:\n            label_group = self.dataset.label_group.iloc[index]\n            return title, label_group\n        else:\n            return title\n    \nshopee_text_dataset = ShopeeTextDataset(train, train=TRAIN)\nshopee_text_dataloader =  torch.utils.data.DataLoader(shopee_text_dataset, batch_size=64, shuffle=False, num_workers=2)","metadata":{"papermill":{"duration":0.040054,"end_time":"2021-05-09T07:24:20.909687","exception":false,"start_time":"2021-05-09T07:24:20.869633","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeTextDataset(Dataset):\n    def __init__(self, dataset, train):\n        self.dataset = dataset\n        self.train = train\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, index):\n        title = self.dataset.title.iloc[index]\n        if self.train:\n            label_group = self.dataset.label_group.iloc[index]\n            return title, label_group\n        else:\n            return title\n    \nshopee_text_dataset = ShopeeTextDataset(train, train=TRAIN)\nshopee_text_dataloader =  torch.utils.data.DataLoader(shopee_text_dataset, batch_size=64, shuffle=False, num_workers=2)","metadata":{"papermill":{"duration":0.041848,"end_time":"2021-05-09T07:24:20.98139","exception":false,"start_time":"2021-05-09T07:24:20.939542","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_feature(model_name, max_length):\n    # load\n    if TRAIN and os.path.exists(\"text_features_{}.pt\".format(model_name)):\n        image_features = torch.load(\"text_features_{}.pt\".format(model_name), map_location = device)\n    else:\n        tokenizer = BertTokenizer.from_pretrained(\"../input/roberta-base/vocab.json\")\n        #bert = BertModel.from_pretrained(\"../input/roberta-base/pytorch_model.bin\",\n        #                                 config = \"../input/roberta-base/config.json\").to(device)\n        model = get_model(model_name) # e.g. roberta-based\n        text_features = []\n        with torch.no_grad():\n            if TRAIN:\n                for (texts, labels) in tqdm(shopee_text_dataloader):\n                    inputs = tokenizer(texts, max_length = max_length, truncation=True, padding=True, return_tensors=\"pt\")\n                    input_ids = inputs[\"input_ids\"].to(device)\n                    token_type_ids = inputs[\"token_type_ids\"].to(device)\n                    attention_mask = inputs[\"attention_mask\"].to(device)\n                    features = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n                    text_features.append(features.data)\n                    del inputs, input_ids, token_type_ids, attention_mask\n            else:\n                for texts in tqdm(shopee_text_dataloader):\n                    inputs = tokenizer(texts, max_length = max_length, truncation=True, padding=True, return_tensors=\"pt\")\n                    input_ids = inputs[\"input_ids\"].to(device)\n                    token_type_ids = inputs[\"token_type_ids\"].to(device)\n                    attention_mask = inputs[\"attention_mask\"].to(device)\n                    features = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n                    text_features.append(features.data)\n                    del inputs, input_ids, token_type_ids, attention_mask\n        text_features = torch.cat(text_features, axis=0)\n        # save\n        if TRAIN:\n            torch.save(text_features, \"text_features_{}.pt\".format(model_name))\n        \n        del model\n        gc.collect()\n        torch.cuda.empty_cache()   \n    \n    print(text_features.shape)\n    return text_features","metadata":{"papermill":{"duration":0.042959,"end_time":"2021-05-09T07:24:21.05427","exception":false,"start_time":"2021-05-09T07:24:21.011311","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"MAX_LENGTH = 30\nTHRESHOLD = 0.7\ntext_features = get_text_feature(model_name, max_length=MAX_LENGTH) # roberta-based\ntext_pred = DistancePredict(text_features, threshold = THRESHOLD, distance_type=\"cosine\")\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"text_pred\"])\n    \ndel text_features\ngc.collect()\ntorch.cuda.empty_cache()    \n\"\"\"","metadata":{"papermill":{"duration":0.037474,"end_time":"2021-05-09T07:24:21.121744","exception":false,"start_time":"2021-05-09T07:24:21.08427","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MultiModal Fusion","metadata":{"papermill":{"duration":0.031545,"end_time":"2021-05-09T07:24:21.183789","exception":false,"start_time":"2021-05-09T07:24:21.152244","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def union(x,y):\n    return np.union1d(x,y)\n\ndef intersect(x,y):\n    return np.intersect1d(x,y)\n\ntrain[\"pred\"] = train.apply(lambda row: union(row['image_pred'], row[\"text_pred\"]),axis=1)\ntrain[\"wait\"] = train.apply(lambda row: intersect(row['image_pred_wait'], row[\"text_pred_wait\"]),axis=1)\ntrain[\"pred\"] = train.apply(lambda row: union(row['pred'], row[\"wait\"]),axis=1)\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"pred\"])","metadata":{"papermill":{"duration":6.452458,"end_time":"2021-05-09T07:24:27.666671","exception":false,"start_time":"2021-05-09T07:24:21.214213","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission(row):\n    return ' '.join(row)\n\ntrain[\"matches\"] = train[\"pred\"].apply(lambda x: submission(x))\n# submit\ntrain[['posting_id','matches']].to_csv('submission.csv',index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission.head()","metadata":{"papermill":{"duration":0.371996,"end_time":"2021-05-09T07:24:28.070883","exception":false,"start_time":"2021-05-09T07:24:27.698887","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.031642,"end_time":"2021-05-09T07:24:28.134174","exception":false,"start_time":"2021-05-09T07:24:28.102532","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}