{"cells":[{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"!pip install sentence_transformers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nfrom sentence_transformers import *\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nimport matplotlib.cm as cm\nimport torch\nfrom nlp_package_pv import *\nimport imagehash\nimport cv2\nimport keras\nimport tqdm\nfrom tqdm.auto import tqdm as tqdmp\ntqdmp.pandas()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path='../input/shopee-product-matching/train_images/'\ntrain=pd.read_csv('../input/shopee-product-matching/train.csv')\ntest=pd.read_csv('../input/shopee-product-matching/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the preprocessing function to preprocess the tweet data\npreprocess_tweet_data(train,'title')\n# Using tokenizer and removing the stopwords\nrem_stopwords_tokenize(train,'title')\n# Converting all the texts back to sentences\nmake_sentences(train,'title')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Model From Sentence Transformer"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"model=torch.load('../input/bert-model-gpu-sentence-transformer/Large_bert_model.h5')\n# device = torch.device(\"cuda\")\n# model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting a model\n# model=SentenceTransformer('bert-large-nli-mean-tokens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting The Text To Word Embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = model.encode(train['title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting Relatable Text From The Data And It's Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"query='paper bag victoria secret'\nprint(query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_embedding = model.encode(query)\ntop_k=5\ncos_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\ncos_scores = cos_scores.cpu()\n\n#We use torch.topk to find the highest 5 scores\ntop_results = torch.topk(cos_scores, k=top_k)\n\nprint(\"\\n\\n======================\\n\\n\")\nprint(\"Item Text:\", query)\nprint(\"\\nTop 5 most similar sentences in corpus:\")\nimage_id=[]\nfor score, idx in zip(top_results[0], top_results[1]):\n    image_id.append(train['image'].values[idx])\n    print(train['title'].values[idx], \"(Score: %.4f)\" % (score),\"Image Id :%s\" % train['image'].values[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Showing Similar Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a function to convert the image to fixed length for subplots\ndef show_image(main_path,image_path,dim=(256,256)):\n    im=cv2.imread(main_path+image_path)\n    im=cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n    im=cv2.resize(im,dim)\n    plt.imshow(im)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's have a look at the similar images\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    show_image(train_path,image_id[i])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's try to improve this method using phash"},{"metadata":{},"cell_type":"markdown","source":"## Let's Try to make a dataframe which has top 50 results using above method"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_text(dataset,name):\n    # Using the preprocessing function to preprocess the tweet data\n    preprocess_tweet_data(dataset,name)\n    # Using tokenizer and removing the stopwords\n    rem_stopwords_tokenize(dataset,name)\n    # Converting all the texts back to sentences\n    make_sentences(dataset,name)\ndef make_embeddings(dataset,name):\n    embeddings = model.encode(dataset[name])\n    return embeddings\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making a function to return results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We Define a threshold for our score so we get reasonable results\ndef return_results(dataset=train,embedding=embeddings,number=50,ultimate_point=0.95):\n    result=[]\n    if number>len(dataset):\n        number=len(dataset)\n    for i in dataset['title'].values :\n        query_embedding = model.encode(i)\n        top_k=number\n        cos_scores = util.pytorch_cos_sim(query_embedding, embedding)[0]\n        cos_scores = cos_scores.cpu()\n\n        #We use torch.topk to find the highest 5 scores\n        top_results = torch.topk(cos_scores, k=top_k)\n        s=''\n        count=0\n        for score, idx in zip(top_results[0], top_results[1]):\n            if score>=ultimate_point :\n                count+=1\n                if count==1:\n                    s+=dataset['posting_id'].values[idx]\n                else:\n                    s+=' '+dataset['posting_id'].values[idx]\n        result.append(s)\n    return result\n        \n                \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try this on the test_data\n# Preprocessing text on test data\npreprocess_text(test,'title')\n\n# Creating Embeddings for the test data title columns\nembeddings_test=make_embeddings(test,'title')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_results(test,embeddings_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding result to submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss=pd.read_csv('../input/shopee-product-matching/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['matches']=return_results(test,embeddings_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Up till now we predicted similar products using just text :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}