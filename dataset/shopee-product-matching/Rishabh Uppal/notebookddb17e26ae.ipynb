{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we are limiting the RAM availability for the GPU for more availability for RAPIDS","metadata":{}},{"cell_type":"code","source":"LIMIT = 1\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n  except RuntimeError as e:\n    print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Data\nHere, we have loaded the training dataset and we have created a target column by simply finding items that have the same label group.","metadata":{}},{"cell_type":"code","source":"COMPUTE_CV = True\n\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def countHashinGroups(train):\n    hash_group = train.image_phash.unique()\n    count = 0\n    hash_li = []\n    count_li = []\n    for each in hash_group:\n        label_count = len(train[train.image_phash == each].label_group.unique())\n        if label_count > 1:\n            count += 1\n            hash_li.append(each) # collect the hash that are labelled wrongly in the dataset\n            count_li.append(label_count) # store the count to get more detail information\n    print('{:.2f}% of the image are labelled in more than 2 groups'.format(100*count/len(hash_group)))\n    print('{} out of {} are labelled in more than 2 groups'.format(count, len(hash_group)))\n    return hash_li, count_li","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_li, count_li = countHashinGroups(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def makeOneLabel(train, phash):\n    '''\n    input: dataset, phash\n        find the index of certain phash, and then find out the max count of label in new dataset. In the end, change all\n        label to the max-count label\n    output: dataset\n    '''\n    train_correct = train\n    train_hash = train[train.image_phash == phash]\n    idx = train_hash.index.tolist()\n    allLabels = train_hash.label_group.value_counts(ascending=False).index.tolist()\n    label = train_hash.label_group.value_counts(ascending=False).index[0]\n    train_correct.label_group.iloc[idx] = label\n    print('phash: {}, index: {}, \\n all label: {}, new label: {} \\n'.format(phash, idx, allLabels, label))\n    return train_correct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Baseline CV Score\n\nWe are computing a baseline CV score based on image_phash values being duplicate.","metadata":{}},{"cell_type":"code","source":"tmp = train_correct.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain_correct['oof'] = train_correct.image_phash.map(tmp)\n\ntrain_correct.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['f1'] = train_correct.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute RAPIDS Model CV\nWe are now using the images, image_phash and titles combined to get a better CV score.","metadata":{}},{"cell_type":"code","source":"if COMPUTE_CV:\n    test = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_gf = cudf.read_csv('../input/shopee-product-matching/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def countHashinGroups(train):\n    hash_group = train.image_phash.unique()\n    count = 0\n    hash_li = []\n    count_li = []\n    for each in hash_group:\n        label_count = len(train[train.image_phash == each].label_group.unique())\n        if label_count > 1:\n            count += 1\n            hash_li.append(each) # collect the hash that are labelled wrongly in the dataset\n            count_li.append(label_count) # store the count to get more detail information\n    print('{:.2f}% of the image are labelled in more than 2 groups'.format(100*count/len(hash_group)))\n    print('{} out of {} are labelled in more than 2 groups'.format(count, len(hash_group)))\n    return hash_li, count_li","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_li, count_li = countHashinGroups(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for phash in hash_li:\n    test_correct = makeOneLabel(test, phash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_correct.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gf = cudf.DataFrame(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using images to make a model to predict labels.\nWe are making use of RAPIDS cuml K-Nearest Neighbour model to predict labels.\nIn order to avoid memory errors, the computation is done in chunks.","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/test_images/'\nif COMPUTE_CV: BASE = '../input/shopee-product-matching/train_images/'\n\nWGT = '../input/model1/efficientnetb0_notop.h5'\nmodel = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n\nembeds = []\nCHUNK = 1024*4\n\nprint('Computing image embeddings...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor i,j in enumerate( range( CTS ) ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    test_gen = DataGenerator(test.iloc[a:b], batch_size=32, path=BASE)\n    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n    embeds.append(image_embeddings)\n\n    #if i>=1: break\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\nprint('image embeddings shape',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)//CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    print('chunk',a,'to',b)\n    distances, indices = model.kneighbors(image_embeddings[a:b,])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k,]<6.0)[0]\n        IDS = indices[k,IDX]\n        o = test.iloc[IDS].posting_id.values\n        preds.append(o)\n        \ndel model, distances, indices, image_embeddings, embeds\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds2'] = preds\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using title to make a model to predict labels.\nWe are making use of Tfidf vectorirzer to predict labels.","metadata":{}},{"cell_type":"code","source":"print('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntext_embeddings = model.fit_transform(test_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel model, text_embeddings\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds'] = preds\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using image_phash to get labels labels.\nCreating a target column by getting all posting_id values for each phash.","metadata":{}},{"cell_type":"code","source":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['preds3'] = test.image_phash.map(tmp)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculating CV Score\nHere, we have concatenated all the three predicted columns into a single one for calculating the CV score.","metadata":{}},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return np.unique(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['oof'] = test.apply(combine_for_cv,axis=1)\n    test['f1'] = test.apply(getMetric('oof'),axis=1)\n    print('CV Score =', test.f1.mean() )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Got a CV score of >0.72!","metadata":{}},{"cell_type":"markdown","source":"# Write Submission CSV\n","metadata":{}},{"cell_type":"code","source":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}