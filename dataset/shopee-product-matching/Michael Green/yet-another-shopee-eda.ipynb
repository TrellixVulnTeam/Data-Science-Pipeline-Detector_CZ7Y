{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Constants\nSet of variables I use throughout the notebook. Not sure if these cause submissions to fail."},{"metadata":{"trusted":true},"cell_type":"code","source":"SHOPEE_ROOT = \"/kaggle/input/shopee-product-matching\"\nSHOPEE_TRAIN_IMAGES = SHOPEE_ROOT+\"/\"+\"train_images\"\nRANDOM_STATE = 42\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seeding numpy randomizer\nnp.random.seed(RANDOM_STATE)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Shopee Dataset EDA\nDoing some exploratory data analysis. WIll make some hypethesis and then generate data to either prove or disprove hypothesis."},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning\nIt's not a good idea to just straightaway use the data set to train and test a model.\nDatasets can be dirty:\n\n* They could can contain duplicate entries\n* They could contain entries that are invalid\n\nSo I will look for and remove any two entries that have the same `posting_id`"},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_train_df = pd.read_csv(SHOPEE_ROOT+\"/\"+\"train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping entries with identical posting_id values\nshopee_train_df.drop_duplicates([\"posting_id\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nothing dropped"},{"metadata":{},"cell_type":"markdown","source":"Any entries that have the same `(image, image_phash,title)` tuple can be for the purposes of creating a training set considered redundant(?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_train_df.drop_duplicates([\"image\", \"image_phash\", \"title\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shopee_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nothing dropped yet. Data doesn't have redundante entries ☺️"},{"metadata":{"trusted":true},"cell_type":"code","source":"#just taking a look\nshopee_train_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many unique `label_group` exist in `train.csv`?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number unique label_groups = {}\".format( len(shopee_train_df[\"label_group\"].unique()) ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many images are there per label group?"},{"metadata":{"trusted":true},"cell_type":"code","source":"hash_of_label_group_images = {}\nhash_of_image_count_per_label = {}\n\nfor mylabel in shopee_train_df[\"label_group\"]:\n    hash_of_label_group_images[mylabel]  = shopee_train_df[ shopee_train_df[\"label_group\"]==mylabel]\n    hash_of_image_count_per_label[mylabel] =  len(shopee_train_df[ shopee_train_df[\"label_group\"]==mylabel])\n    #print(\"for label_group = {} number of images is {}\".format(mylabel,len(hash_of_label_group_images)))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I leave the line 7 commented out. You can comment it out if you want to see the very verbose printout"},{"metadata":{},"cell_type":"markdown","source":"Which are the top 10 most populus and least populus `label_groups`?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sorting the keys (the label_groups) by the values (thenumber of images per label_group)\nsorted_label_groups = sorted(hash_of_image_count_per_label,key=hash_of_image_count_per_label.__getitem__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#10 least populated (by distinct image count) label groups\nlabel_group_image_counts = []\nfor i,my_label in enumerate(sorted_label_groups):\n    if i > 9:\n        break\n    label_group_image_counts.append(hash_of_image_count_per_label[my_label])\n    print(\"label {} has {} images\".format(my_label,hash_of_image_count_per_label[my_label] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#10 most populated (by distinct image count) label groups\nfor i in range(len(sorted_label_groups)-11,len(sorted_label_groups)-1,1):\n    label_group_image_counts.append(hash_of_image_count_per_label[ sorted_label_groups[i]  ])\n    print(\"label {} has {} images\".format(sorted_label_groups[i],hash_of_image_count_per_label[sorted_label_groups[i]  ] ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the whole data set is ugly\n#will plot the first 20 label groups: The label_groups with the 10 lowest and 10 highest number of images per said label group\nlabel_groups_to_plot = sorted_label_groups[:10]\nlabel_groups_to_plot.extend(sorted_label_groups[-11:-1])\nlabel_groups_to_plot = [str(mylabel) for mylabel in label_groups_to_plot]\nprint(label_groups_to_plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(40,40))\nplt.grid()\nplt.barh(label_groups_to_plot, np.log10(label_group_image_counts))\nplt.ylabel(\"label_group\",fontsize=30)\nplt.xlabel(\"log(number_of_images_per_label_group)\",fontsize=30)\nplt.title(\"The 10 Most and Least Populated label_groups and their Distinct Image Counts\",fontsize=35)\nplt.yticks(fontsize=20)\nplt.xticks(fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a little over an order of magnitude difference in the number of images in the largest `label_group` when compared to the smallest `label_group`"},{"metadata":{},"cell_type":"markdown","source":"Now I'm going to try to validate or better understand the data set by making some hypotheses and then examine the data set to prove/disprove them. These are not 100% conclusive findings but I feel give me an OK idea of the nature of the data set. If I am lucky I may find mislabeled data which will be helpful to know before I start doing long training and cross validation runs. I'm open to suggestions on more comprehensive ways to validate a data set. I image for data sets where the relationship between features follows some rule, a checker can be coded up to read each row. In this case I can't think of a rule-based checker so I'm hoping to luck out by randomly picking rows that have certain relationships and hoping to _see_ images that don't fit with my expectation."},{"metadata":{},"cell_type":"markdown","source":"Hypothesis: All images belonging to the same `label_group` are of the same object"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first just pick a random set of label_groups\nlabel_groups = np.array(sorted_label_groups)\nnp.random.shuffle(label_groups)\nlabel_group_subset = label_groups[:5]\nprint(label_group_subset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5,ncols=2,figsize=(30,30))\nfor i, mylabel in enumerate(label_group_subset):\n    image_names =  shopee_train_df[ shopee_train_df[\"label_group\"] == mylabel ][\"image\"]\n    image_titles = shopee_train_df[ shopee_train_df[\"label_group\"] == mylabel ][\"title\"]\n    \n    for j, image_name in enumerate(image_names):\n        if j>=2:\n            break\n        img = plt.imread(SHOPEE_TRAIN_IMAGES+\"/\"+image_name)\n        ax[i,j].set_title(str(image_titles.iloc[j])+\"\\nlg: \"+str(mylabel))\n        ax[i,j].imshow(img)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding**: Looks like the objects in the images that belong to the same `label_group` are the same. We can trust the labeling."},{"metadata":{},"cell_type":"markdown","source":"Hypothesis all images with the same phash are the same object"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_phash = shopee_train_df[\"image_phash\"].unique()\nprint(\"number of unique_phashes is {}\".format(len(unique_phash)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of phashes to randomly select\nNUM_OF_PHASHES = 10\n\nunique_phash = np.array(unique_phash)\nnp.random.shuffle(unique_phash)\nunique_phash_subset = []\ni = 0\n\nfor myphash in unique_phash:\n    numb_images = len(shopee_train_df[shopee_train_df[\"image_phash\"] == myphash][\"image\"])\n    #print(\"phash {} has {} images\".format(myphash,numb_images))\n    if numb_images > 1:\n        i += 1\n        unique_phash_subset.append(myphash)\n        \n    if i >= NUM_OF_PHASHES:\n        break\n        \nprint(\"unique_phash_subset = {}\".format(unique_phash_subset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=NUM_OF_PHASHES,ncols=2,figsize=(20,80))\n\n\nfor i,myphash in enumerate( unique_phash_subset):\n    myimages = shopee_train_df[shopee_train_df[\"image_phash\"] == myphash][\"image\"]\n    mytitles = shopee_train_df[shopee_train_df[\"image_phash\"] == myphash][\"title\"]\n    #print(\"number of images at phash = {} is {}\".format(len(myimages),myphash))\n  \n    for j, myimage in enumerate(myimages):\n        if j >= 2:\n            break\n        ax[i,j].set_title(mytitles.iloc[j]+\"\\n phash: \"+ str(myphash)+\"\\n image: \"+str(myimage),fontsize=10)\n        img = plt.imread(SHOPEE_TRAIN_IMAGES+\"/\"+myimage)\n        ax[i,j].imshow(img)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Findings**: Images that have the same phash are images of the same object. Seems that image files can have different `image` file names, but yet are the same image (AFAICT). I notice that people submit the same thing but call it something different (`titles` are different). I also notice that two different images can be different (slighlty) but have the same phash (see \"MUKENA DEWASA\" product images). \n🤔"},{"metadata":{},"cell_type":"markdown","source":"Hypothesis: Not all images that belong to the same `label_group` have identical `image_phash` values"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5,ncols=2,figsize=(40,40))\n#ax = ax.flatten()\n\nfor i, mylabel in enumerate(label_group_subset):\n    image_names =  shopee_train_df[ shopee_train_df[\"label_group\"] == mylabel ][\"image\"]\n    image_phashes = shopee_train_df[ shopee_train_df[\"label_group\"] == mylabel ][\"image_phash\"]\n    image_titles = shopee_train_df[ shopee_train_df[\"label_group\"] == mylabel ][\"title\"]\n\n    for j,myphash1 in enumerate(image_phashes):\n        for k, myphash2 in enumerate(image_phashes):\n            if myphash1 != myphash2:\n                img1 = plt.imread(SHOPEE_TRAIN_IMAGES + \"/\" + image_names.iloc[j])\n                ax[i,0].set_title(str(image_titles.iloc[j]+\"\\nphash: \"+str(myphash1) + \"\\nlg: \"+str(mylabel)))\n                ax[i,0].imshow(img1)\n                img2 = plt.imread(SHOPEE_TRAIN_IMAGES + \"/\" + image_names.iloc[k])\n                ax[i,1].set_title(str(image_titles.iloc[k]+\"\\nphash: \"+str(myphash2) + \"\\nlg: \"+str(mylabel)))\n                ax[i,1].imshow(img2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding**: Yes there are many images whose `image_phash` are not identical yet these images belong to the same  `label_group`. So sometimes people do submit different pictures of the same product (presumably)."},{"metadata":{},"cell_type":"markdown","source":"# Conclusions\n\n* There are no duplicates (either by `posting_id` or `(image, image_phash,title)`\n* There is pretty large difference in number of distinct images between the most and least populus `label_group`\n* All `label_groups` have at least 2 images. I think this is good for training a CNN.\n* Images that belong to the same `label_group` so far appear to be images of the same object. So currently no concern of mislabled entries in `train.csv`. But this is not conclusive\n* Seems there are copies of the same image under in `train.csv` that have different `image` names. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}