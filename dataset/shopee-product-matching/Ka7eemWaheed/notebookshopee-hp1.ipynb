{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory ../input/train-images-namepkl/train_feature_images_name.pkl\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory  ../input/train-feature/bk2_train_vgg_feature.pkl\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import vgg16\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.models import Model\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial import distance\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import requests\n\n# url = 'https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n# r = requests.get(url, allow_redirects=True)\n# open('./vgg16_weights_tf_dim_ordering_tf_kernels.h5', 'wb').write(r.content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_path =\"../input/shopee-product-matching/train_images/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv_df=pd.read_csv('../input/shopee-product-matching/train.csv')\ntest_csv_df=pd.read_csv('../input/shopee-product-matching/test.csv')\n\n# print(train_csv_df.head())\n# print(test_csv_df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imgs_path = \"style/\"\nimgs_model_width, imgs_model_height = 224, 224\nnb_closest_images = 5 # number of most similar images to retrieve\n# load the model\n# vgg_model = vgg16.VGG16(weights='imagenet', include_top=False)\n# vgg_model = vgg16.VGG16(weights = None)\nvgg_model = vgg16.VGG16(weights = '../input/vgg-weight-1/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n# vgg_model.load_weights('./vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n\n# remove the last layers in order to get features instead of predictions\nfeat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer(\"fc2\").output)\n\n# print the layers of the CNN\nfeat_extractor.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = [x for x in os.listdir(imgs_path)]\n# print(\"number of images:\",len(files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # load an image in PIL format\n# original = load_img(imgs_path+files[0], target_size=(imgs_model_width, imgs_model_height))\n# plt.imshow(original)\n# plt.show()\n# print(\"image loaded successfully!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save to file\nfrom pickle import dump,load\nimport pickle\nimport copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importedImages = []\nimportedImages_names = []\ncounter = 0\nimgs_features_pkl=[]\nimgs_names_pkl=[]\n\ntest_imgs_features_pkl=[]\ntest_imgs_features_name_pkl=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###################3 TEST\nposting_ids=[]\nfor item in test_csv_df[['posting_id','image']].values.tolist():\n    # print(item[0],item[1])\n    given_img='../input/shopee-product-matching/test_images/'+item[1]\n#     print(f)\n    counter=counter+1\n    # filename = f\n    original = load_img(given_img, target_size=(224, 224))\n    numpy_image = img_to_array(original)\n    image_batch = np.expand_dims(numpy_image, axis=0)\n    importedImages.append(image_batch)\n    test_imgs_features_name_pkl.append(item[1])\n    if counter==1000:\n        images = np.vstack(importedImages)\n        processed_imgs = preprocess_input(images.copy())\n        # extract the images features\n        imgs_features = feat_extractor.predict(processed_imgs)\n        if len(test_imgs_features_pkl)>0:\n            test_imgs_features_pkl = np.append(test_imgs_features_pkl, imgs_features, axis=0)\n#             print(len(test_imgs_features_pkl))\n            counter=0\n            importedImages = []\n        else:\n            images = np.vstack(importedImages)\n            processed_imgs = preprocess_input(images.copy())\n          # extract the images features\n            test_imgs_features_pkl = feat_extractor.predict(processed_imgs)\n            counter=0\n            importedImages = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remaining_count=len(test_imgs_features_pkl)\n# print(remaining_count)\n# print(len(test_imgs_features_name_pkl))\ntest_imgs_features_name_pkl=test_imgs_features_name_pkl[:remaining_count]\n# print(len(test_imgs_features_name_pkl))\n# print(len(test_csv_df[['posting_id','image']].values.tolist()))\nrmaining_images = test_csv_df[['posting_id','image']].values.tolist()[remaining_count:]\n# print(rmaining_images)\n# print(len(rmaining_images))\ncounter=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###################3 TEST\nposting_ids=[]\nimportedImages = []\nimportedImages_names = []\nfor item in rmaining_images:\n    # print(item[0],item[1])\n    given_img='../input/shopee-product-matching/test_images/'+item[1]\n    # print(f)\n    counter=counter+1\n    # filename = f\n    original = load_img(given_img, target_size=(224, 224))\n    numpy_image = img_to_array(original)\n    image_batch = np.expand_dims(numpy_image, axis=0)\n    importedImages.append(image_batch)\n    test_imgs_features_name_pkl.append(item[1])\n    if counter==len(rmaining_images):\n        images = np.vstack(importedImages)\n        processed_imgs = preprocess_input(images.copy())\n        # extract the images features\n        imgs_features = feat_extractor.predict(processed_imgs)\n        if len(test_imgs_features_pkl)>0:\n#             print('if')\n            test_imgs_features_pkl = np.append(test_imgs_features_pkl, imgs_features, axis=0)\n#             print(len(test_imgs_features_pkl))\n            counter=0\n            importedImages = []\n        else:\n#             print('else')\n            test_imgs_features_pkl = imgs_features\n#             print(len(test_imgs_features_pkl))\n            counter=0\n            importedImages = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_features_pkl=[]\nimportedImages_names = []\nwith open(\"../input/train-feature/bk2_train_vgg_feature.pkl\", 'rb') as file:\n    imgs_features_pkl = load(file)\n    print(len(imgs_features_pkl))\n\nwith open(\"../input/train-images-namepkl/train_feature_images_name.pkl\", 'rb') as file:\n    importedImages_names = load(file)\n    print(len(importedImages_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importedImages_names111 = np.append(importedImages_names,test_imgs_features_name_pkl,  axis=0)\nimgs_features_pkl111 = np.append(imgs_features_pkl,test_imgs_features_pkl,  axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cosSimilarities = cosine_similarity(imgs_features_pkl111)\nposting_ids=[]\n# print(len(cosSimilarities))\ncos_similarities_df = pd.DataFrame(cosSimilarities, columns=importedImages_names111, index=importedImages_names111)\n# print(cos_similarities_df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in test_csv_df[['posting_id','image']].values.tolist():\n#     print(item[0],item[1])\n    given_img=item[1]\n    closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index\n    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]\n    temp_list=[]\n    temp_list.append(item[0])\n    for i in range(0,len(closest_imgs)):\n        original = load_img('../input/shopee-product-matching/train_images/'+closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))\n        posting=train_csv_df[train_csv_df['image']==closest_imgs[i]]\n#         print(list(posting['posting_id']))\n        temp_list.append(list(posting['posting_id'])[0])\n      # plt.savefig('')\n#         plt.imshow(original)\n#         plt.show()\n#         print(\"similarity score : \",closest_imgs_scores[i])\n    posting_ids.append([item[0],\" \".join(temp_list)])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"posting_id_df= pd.DataFrame(posting_ids,columns=['posting_id','matches'])\nposting_id_df.to_csv(\"./submission.csv\" ,index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# posting_ids=[]\n# for item in test_csv_df[['posting_id','image']].values.tolist():\n# #     print(item[0],item[1])\n#     given_img='../input/shopee-product-matching/test_images/'+item[1]\n#   #########################################3\n#     cosSimilarities=None\n#     imgs_features=None\n#     original = load_img(given_img, target_size=(imgs_model_width, imgs_model_height))\n# #     plt.imshow(original)\n# #     plt.show()\n# #     print(\"image loaded successfully!\")\n#     # convert the PIL image to a numpy array\n#     # in PIL - image is in (width, height, channel)\n#     # in Numpy - image is in (height, width, channel)\n#     numpy_image1 = img_to_array(original)\n#     # convert the image / images into batch format\n#     # expand_dims will add an extra dimension to the data at a particular axis\n#     # we want the input matrix to the network to be of the form (batchsize, height, width, channels)\n#     # thus we add the extra dimension to the axis 0.\n#     image_batch1 = np.expand_dims(numpy_image1, axis=0)\n#     # prepare the image for the VGG model\n#     processed_image1 = preprocess_input(image_batch1.copy())\n#     img_features111 = feat_extractor.predict(processed_image1)\n#     counter=0\n#     cosSimilarities_1={}\n#     for img_train in imgs_features_pkl:\n#         result = cosine_similarity(img_features111, img_train.reshape(1,4096))\n#         if result > 0.65:\n#             cosSimilarities_1[str(result[0][0])] = importedImages_names[counter]\n#         counter +=1\n#     update_list = sorted(cosSimilarities_1.items(),reverse=True)\n# #     print(update_list)\n#   ##############################################\n#     temp_list=[]\n#     temp_list.append(item[0])\n#     for k in update_list[:10]:\n# #         print(k)\n#         original = load_img('../input/shopee-product-matching/train_images/'+k[1], target_size=(imgs_model_width, imgs_model_height))\n#         posting=train_csv_df[train_csv_df['image']==k[1]]\n# #         print(list(posting['posting_id']))\n#         temp_list.append(list(posting['posting_id'])[0])\n#         # plt.savefig('')\n# #         plt.imshow(original)\n# #         plt.show()\n#         # print(\"image loaded successfully!\")\n# #         print(\"similarity score : \",k[0])\n#     posting_ids.append([item[0],\" \".join(temp_list)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# posting_id_df= pd.DataFrame(posting_ids,columns=['posting_id','matches'])\n# # \" \".join(list(posting_id_df['matches'][0]))\n# posting_id_df.to_csv(\"./submission.csv\" ,index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}