{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"-----------------","metadata":{}},{"cell_type":"markdown","source":"# **说明**","metadata":{}},{"cell_type":"markdown","source":"### Baseline 方法为无监督方法，即不使用反向传播更新网络，直接使用test数据集推理，不使用train数据集进行监督学习训练，train用于评测无监督结果\n\n### 简单思路：\n\n### 本比赛主要有两个数据信息，图片信息和文本标题信息，你需要利用这两个信息，根据test所给的图像，检索出train数据集中与之相似的同款图片\n\n### 对于图片信息，我们使用 Resnet18 或 Resnet50 进行特征提取\n\n### 你若不知道resnet是什么可以看链接： 原始论文：https://arxiv.org/abs/1512.03385   人话：https://www.cnblogs.com/shine-lee/p/12363488.html\n\n### 对于文本信息，我们使用 TF-IDF 信息进行特征提取\n\n\n### 分别计算两个特征各自内部的相似度，最后得到综合结果\n","metadata":{}},{"cell_type":"code","source":"import os, sys\nsys.path = ['../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master', ] + sys.path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------------","metadata":{}},{"cell_type":"markdown","source":"# **第一步 导包**","metadata":{}},{"cell_type":"code","source":"# 基本操作包\nimport numpy as np\nimport pandas as pd\n\nimport random\n# 图片加载包\nimport cv2, matplotlib.pyplot as plt\nfrom PIL import Image\n\n# 进度条辅助包\nfrom tqdm.notebook import tqdm\n\n# 正则化和TF-IDF包，用于提取文本特征\nfrom sklearn.preprocessing import normalize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# 导入深度学习框架pytorch用于使用resnet网络提取图像特征\nimport torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nfrom efficientnet_pytorch import EfficientNet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第二步 固定随机数**","metadata":{}},{"cell_type":"code","source":"# 随机性固定\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE','first_project.settings')\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # 是否将卷积算子的计算实现固定。torch 的底层有不同的库来实现卷积算子\n    torch.backends.cudnn.deterministic = True\n    # 是否开启自动优化，选择最快的卷积计算方法\n    torch.backends.cudnn.benchmark = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_torch(2021)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第三步 配置基本Config信息**","metadata":{}},{"cell_type":"code","source":"# 设置数据集的路径，这样后续就可以直接快速使用了。\nDATA_PATH = '../input/shopee-product-matching/'\n# 批大小\nBATCH_SIZE = 32\n# 多线程\nNum_workers = 2\n# CNN特征相似度大于95%才列入相似\nCNN_Confident = 0.95\n# TF-IDF特征相似度大于80%才能列入相似\nTFIDF_Confident = 0.80\n# 是否用于提交，本地测试的时候请改为False，查看交叉验证成绩，提交时请改为True\nIS_SUB = True\n# IS_SUB = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第四步 加载数据集**","metadata":{}},{"cell_type":"code","source":"# 读取数据集\nif IS_SUB:\n    query = pd.read_csv(DATA_PATH + 'test.csv')\nelse:\n    query = pd.read_csv(DATA_PATH + 'train.csv')\n\n# 打印数据集信息\nprint('query shapes', query.shape)\nquery.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 可以发现数据由5个属性构成，分别是如下意思\n\n### posting_id 图片id号，用于标识图片；\n\n### image 图片文件名，需要加上DATA_PATH才是真正的地址；\n\n### image_phash 图片哈希，即图片指纹，用于快速鉴别重复图像；\n\n### title 图片描述的商品名，文本信息\n\n### label_group 相同数字代表同一类东西。（测试集没有，在无监督的方法中，我们不使用该属性，你可以思考监督方法怎么应用这一个属性）","metadata":{}},{"cell_type":"markdown","source":"### **为PyTorch框架构建读取数据集**","metadata":{}},{"cell_type":"code","source":"# 继承pytorch的Dataset，重写方法，必须要__getitem__和__len__两个方法的重写。\nclass load_dataset_for_pyTorch(Dataset):\n    def __init__(self, img_path, transform):\n        # 图片地址\n        if IS_SUB:\n            self.img_path = DATA_PATH + 'test_images/' + img_path\n        else:\n            self.img_path = DATA_PATH + 'train_images/' + img_path\n        # 图片变换\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        # 读取图片\n        img = Image.open(self.img_path[index]).convert('RGB')\n        # 进行图片变换\n        img = self.transform(img)\n        return img\n    \n    def __len__(self):\n        # 返回图片长度\n        return len(self.img_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = load_dataset_for_pyTorch(query['image'].values,transforms.Compose([transforms.Resize((512, 512)),# 裁剪至512 * 512\n                                                                           transforms.ToTensor(), # 转换成张量形式\n                                                                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])) # 正则化\n    \nimageloader = torch.utils.data.DataLoader(image,batch_size=BATCH_SIZE, shuffle=False, num_workers=Num_workers) # 转换为pytorch的数据加载器","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 测试是否正常生成：\ntestloader = torch.utils.data.DataLoader(image,batch_size=BATCH_SIZE, shuffle=False, num_workers=Num_workers) # 转换为pytorch的数据加载器\nbatch = next(iter(testloader))\nprint('正常读取图片！数据维度为：', batch.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第五步 计算哈希值，用于快速筛查重复图片**","metadata":{}},{"cell_type":"code","source":"# 将相同的哈希值聚集在一起\nrepeat = query.groupby('image_phash').posting_id.agg('unique').to_dict()\n# 将聚集结果映射到每一个图片上\nquery['hash'] = query.image_phash.map(repeat)\n# 查看结果\nquery.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第六步 利用Resnet18计算图片特征**","metadata":{}},{"cell_type":"markdown","source":"### **首先创建pytorch模型**","metadata":{}},{"cell_type":"code","source":"# class Resnet18(nn.Module):\n#     # 初始化\n#     def __init__(self):\n#         super(Resnet18, self).__init__()\n#         # 快速加载pytorch提供好的resnet\n#         model = models.resnet18(True)\n#         # 对于图像检索任务，下采样通常使用最大下采样，因为需要找到突出特点\n# #         model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n#         # 去除最后一层全连接分类层，只要倒数第二个特征图\n#         model = nn.Sequential(*list(model.children())[:-1])\n#         # 停用dropout，进入推理状态\n#         model.eval()\n#         self.model = model\n        \n#     # 前向推理\n#     def forward(self, img):        \n#         out = self.model(img)\n#         return out\n# class EfficientNet(nn.Module):\n#     def __init__(self, backbone='ef', out_dim=6):\n#         super(EfficientNet, self).__init__()\n#         self.enet = EfficientNet.from_name('efficientnet-b1')\n        \n#         self.fc = nn.Linear(self.enet._fc.in_features, out_dim)\n#         self.enet._fc = nn.Identity()\n    \n#     def forward(self, x):\n#         x = self.enet(x)\n#         x = self.fc(x)\n#         return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **离线状态下拷贝预训练模型**","metadata":{}},{"cell_type":"markdown","source":"本来我想上传到数据集的，结果发现别人早就上传了，然后kaggle有查重机制，不可上传跟别人一样的文件，所以这里只能用别人的数据集包，右边Add data 搜索：Pretrained PyTorch models，第一个即可","metadata":{}},{"cell_type":"code","source":"!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/pretrained-pytorch-models/resnet18-5c106cde.pth /root/.cache/torch/hub/checkpoints/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **声明使用模型 (这部分其实建议使用GPU加速，不然很慢，CPU：2小时推理 GPU：10分钟推理)**","metadata":{}},{"cell_type":"code","source":"net = EfficientNet.from_name('efficientnet-b7')\n\n \n# open_gpu = False\nopen_gpu = True\n\nif open_gpu:\n    net.to(torch.device('cuda'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **前向传播捕获特征**","metadata":{}},{"cell_type":"code","source":"# 用于存储特征\nimage_features = []\n\nwith torch.no_grad():\n    # 循环数据读取\n    for data in tqdm(imageloader):\n        if open_gpu:\n            data = data.to(torch.device('cuda'))\n        # 前向传播\n        features = net.extract_features(data)\n        # 将输出结果 [batch_size, 512, 1, 1] 变化成 [batch_size, 512]\n        features = features.reshape(32, -1)\n        \n        # 若为gpu版本，训练好后提取为cpu版本\n        if open_gpu:\n            features = features.data.cpu().numpy()\n        \n        # 存储结果\n        image_features.append(features)\n\n# 展开维度\nimage_features = np.vstack(image_features)\n# 正则化\nimage_features = normalize(image_features)\nimage_features=image_features.reshape(3,-1)\n# 查看\nimage_features[:1].shape\n\nprint(image_features.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **计算相似度**","metadata":{}},{"cell_type":"code","source":"# 存储结果\ntemp = []\n\n# 分块计算，免得矩阵太大\nCHUNK = 4096\ntimes = len(image_features)//CHUNK\n\n# 补全最后不刚好完整的块\nif len(image_features) % CHUNK != 0:\n    times += 1\n\n# 计算相似度\nfor index in range( times ):\n    # 每次运算的起点\n    left = index * CHUNK\n    # min的作用是防止超界\n    right = min((index + 1) * CHUNK, len(image_features))\n    \n    print('chunk',left,'to',right)\n    \n    distances = np.dot(image_features[left:right,], image_features.T)\n    print(image_features[left:right,].shape)    \n    for k in range(right - left):\n        # 取置信度大于CNN_Confident相似的，可以调这个上分\n        IDX = np.where(distances[k,]>CNN_Confident)[0][:]\n        # 将相似的图片加入到结果中\n        \n        o = query.iloc[IDX].posting_id.values\n        temp.append(o)\n\nquery['cnn'] = temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第七步 利用TF-IDF计算文本相似度**","metadata":{}},{"cell_type":"markdown","source":"### **搭建模型 前向传播 计算特征**","metadata":{}},{"cell_type":"code","source":"# sklearn构建模型\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=10000)\n# 前向传播\ntext_features = model.fit_transform(query.title).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **计算相似度**","metadata":{}},{"cell_type":"code","source":"# 存储结果\ntemp = []\n\n# 分块计算，免得矩阵太大\nCHUNK = 4096\ntimes = len(text_features)//CHUNK\n\n# 补全最后不刚好完整的块\nif len(text_features) % CHUNK != 0:\n    times += 1\n\n# 计算相似度\nfor index in tqdm(range( times )):\n    # 每次运算的起点\n    left = index * CHUNK\n    # min的作用是防止超界\n    right = min((index + 1) * CHUNK, len(text_features))\n    \n    print('chunk',left,'to',right)\n    \n    distances = np.dot(text_features[left:right,], text_features.T)\n    \n    for k in range(right - left):\n        # 取置信度大于CNN_Confident相似的，可以调这个上分\n        IDX = np.where(distances[k,]>TFIDF_Confident)[0]\n        # 将相似的图片加入到结果中\n        o = query.iloc[IDX].posting_id.values\n        temp.append(o)\n\ndel model, text_features\nquery['tfidf'] = temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **第八步 合成结果提交**","metadata":{}},{"cell_type":"code","source":"# 合成函数用于提交【模板】\ndef combine_for_sub(row):\n    # 结合三种答案的所有答案\n    x = np.concatenate([row.hash, row.cnn, row.tfidf])\n    # unique去重\n    return ' '.join( np.unique(x) )\n\n\n\n# 合成函数用于本地测试【模板】\ndef combine_for_cv(row):\n    x = np.concatenate([row.hash, row.cnn, row.tfidf])\n    return np.unique(x)\n\n# 得到分数【通用模板】\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]))\n        if len(row[col])==0:\n            p = 0\n        else:\n            p = n/len(row[col])\n        if len(row.target) == 0:\n            r = 0\n        else:\n            r = n/len(row.target)\n        return p, r, 2*n/(len(row.target)+len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 应用合成【模板】\nquery['matches'] = query.apply(combine_for_sub,axis=1)\n\n\n# 保存结果【模板】\nquery[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **附录：若为本地，可根据label_group测试结果**","metadata":{}},{"cell_type":"code","source":"if not IS_SUB:\n    # 将相同group号聚集\n    temp = query.groupby('label_group').posting_id.agg('unique').to_dict()\n    # 映射到答案上\n    query['target'] = query.label_group.map(temp)\n    # 更改格式用于计算分数\n    query['matches'] = query.apply(combine_for_cv,axis=1)\n    # 计算F1分数\n    query['score'] = query.apply(getMetric('matches'),axis=1)\n    # 查看结果\n    print('本地测试分数：')\n    print('准确率P分数：',query['score'].apply(lambda x:x[0]).mean())\n    print('召回率R分数：',query['score'].apply(lambda x:x[1]).mean())\n    print('F1分数：',query['score'].apply(lambda x:x[2]).mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **注：你还可以使用cudf, cuml, cupy代替numpy和pandas的运算，将运算迁移至cuda gpu上加速运算，这样TF-IDF可以使用更大的特征维度**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}