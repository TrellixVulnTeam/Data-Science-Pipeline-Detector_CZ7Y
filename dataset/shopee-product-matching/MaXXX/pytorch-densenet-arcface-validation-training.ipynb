{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport time\nimport cv2\nimport PIL.Image\nimport random\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport albumentations\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport gc\nfrom sklearn.metrics import roc_auc_score\n%matplotlib inline\nimport seaborn as sns\nfrom pylab import rcParams\nfrom warnings import filterwarnings\nfrom sklearn.preprocessing import LabelEncoder\nimport math\nimport glob\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nfilterwarnings(\"ignore\")\nimport torchvision.models as models\n\n\ndevice = torch.device('cuda')","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:09.530415Z","start_time":"2021-03-31T05:32:45.024356Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-03-22T22:23:08.868175Z","iopub.status.busy":"2021-03-22T22:23:08.867563Z","iopub.status.idle":"2021-03-22T22:23:13.559878Z","shell.execute_reply":"2021-03-22T22:23:13.560514Z"},"papermill":{"duration":4.717118,"end_time":"2021-03-22T22:23:13.560901","exception":false,"start_time":"2021-03-22T22:23:08.843783","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False # set True to be faster\n    print(f'Setting all seeds to be {seed} to reproduce...')\nseed_everything(42)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:09.561766Z","start_time":"2021-03-31T05:33:09.53249Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:13.612686Z","iopub.status.busy":"2021-03-22T22:23:13.611796Z","iopub.status.idle":"2021-03-22T22:23:13.623978Z","shell.execute_reply":"2021-03-22T22:23:13.625185Z"},"papermill":{"duration":0.042601,"end_time":"2021-03-22T22:23:13.625808","exception":false,"start_time":"2021-03-22T22:23:13.583207","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration","metadata":{"papermill":{"duration":0.024522,"end_time":"2021-03-22T22:23:13.675571","exception":false,"start_time":"2021-03-22T22:23:13.651049","status":"completed"},"tags":[]}},{"cell_type":"code","source":"image_size = 224\nbatch_size = 16\nn_worker = 4\ninit_lr = 3e-4\nn_epochs = 6 # from my experiments, use > 25 when margin = 0.5\nfold_id = 0\nholdout_id = 0\nvalid_every = 5\nsave_after = 10\nmargin = 0.5 # 0 for faster convergence, larger may be beneficial\nsearch_space = np.arange(40, 100, 10) # in my experiments, thresholds should be between 40 - 90 (/100) for cosine similarity\nuse_amp = False # todo: figure how to work with pytorch native amp\ndebug = True # set this to False to train in full\nkernel_type = 'baseline'\nmodel_dir = './weights/'\ndata_dir = '../input/shopee-product-matching/train_images'\n# data_dir = '../input/train_images'\n\n! mkdir $model_dir","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:09.798941Z","start_time":"2021-03-31T05:33:09.565395Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:13.734774Z","iopub.status.busy":"2021-03-22T22:23:13.733968Z","iopub.status.idle":"2021-03-22T22:23:14.617047Z","shell.execute_reply":"2021-03-22T22:23:14.61655Z"},"papermill":{"duration":0.917142,"end_time":"2021-03-22T22:23:14.617169","exception":false,"start_time":"2021-03-22T22:23:13.700027","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Folds","metadata":{"papermill":{"duration":0.013194,"end_time":"2021-03-22T22:23:14.644373","exception":false,"start_time":"2021-03-22T22:23:14.631179","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_train['file_path'] = df_train.image.apply(lambda x: os.path.join(data_dir, x))\ndf_train.head(5)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:10.314956Z","start_time":"2021-03-31T05:33:09.80153Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:14.691726Z","iopub.status.busy":"2021-03-22T22:23:14.691178Z","iopub.status.idle":"2021-03-22T22:23:14.956812Z","shell.execute_reply":"2021-03-22T22:23:14.957218Z"},"papermill":{"duration":0.287277,"end_time":"2021-03-22T22:23:14.957363","exception":false,"start_time":"2021-03-22T22:23:14.670086","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=5)\ndf_train['fold'] = -1\nfor fold, (train_idx, valid_idx) in enumerate(gkf.split(df_train, None, df_train.label_group)):\n    df_train.loc[valid_idx, 'fold'] = fold","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:16.540504Z","start_time":"2021-03-31T05:33:16.455802Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:14.992238Z","iopub.status.busy":"2021-03-22T22:23:14.991458Z","iopub.status.idle":"2021-03-22T22:23:15.06224Z","shell.execute_reply":"2021-03-22T22:23:15.061731Z"},"papermill":{"duration":0.090181,"end_time":"2021-03-22T22:23:15.062359","exception":false,"start_time":"2021-03-22T22:23:14.972178","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\ndf_train.label_group = le.fit_transform(df_train.label_group)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:17.796298Z","start_time":"2021-03-31T05:33:17.786976Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:15.094574Z","iopub.status.busy":"2021-03-22T22:23:15.093762Z","iopub.status.idle":"2021-03-22T22:23:15.099964Z","shell.execute_reply":"2021-03-22T22:23:15.099538Z"},"papermill":{"duration":0.023617,"end_time":"2021-03-22T22:23:15.10007","exception":false,"start_time":"2021-03-22T22:23:15.076453","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transforms","metadata":{"papermill":{"duration":0.014065,"end_time":"2021-03-22T22:23:15.128118","exception":false,"start_time":"2021-03-22T22:23:15.114053","status":"completed"},"tags":[]}},{"cell_type":"code","source":"transforms_train = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n    albumentations.HueSaturationValue(p=0.5, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n    albumentations.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n    albumentations.CoarseDropout(p=0.5),\n    albumentations.Normalize()\n])\n\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    albumentations.Normalize()\n])","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:19.748378Z","start_time":"2021-03-31T05:33:19.742501Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:15.16336Z","iopub.status.busy":"2021-03-22T22:23:15.162857Z","iopub.status.idle":"2021-03-22T22:23:15.166906Z","shell.execute_reply":"2021-03-22T22:23:15.166491Z"},"papermill":{"duration":0.024984,"end_time":"2021-03-22T22:23:15.167004","exception":false,"start_time":"2021-03-22T22:23:15.14202","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"papermill":{"duration":0.013743,"end_time":"2021-03-22T22:23:15.19449","exception":false,"start_time":"2021-03-22T22:23:15.180747","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class SHOPEEDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        img = cv2.imread(row.file_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img)\n            img = res['image']\n                \n        img = img.astype(np.float32)\n        img = img.transpose(2,0,1)\n        \n        if self.mode == 'test':\n            return torch.tensor(img).float()\n        else:\n            return torch.tensor(img).float(), torch.tensor(row.label_group).float()","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:22.094983Z","start_time":"2021-03-31T05:33:22.089203Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:15.230948Z","iopub.status.busy":"2021-03-22T22:23:15.230062Z","iopub.status.idle":"2021-03-22T22:23:15.231914Z","shell.execute_reply":"2021-03-22T22:23:15.232345Z"},"papermill":{"duration":0.023957,"end_time":"2021-03-22T22:23:15.232497","exception":false,"start_time":"2021-03-22T22:23:15.20854","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = SHOPEEDataset(df_train, 'train', transform = transforms_train)\nrcParams['figure.figsize'] = 15,5\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = i*5 + p\n        img, label = dataset[idx]\n        axarr[p].imshow(img.transpose(0,1).transpose(1,2).squeeze())\n        axarr[p].set_title(label.item())","metadata":{"execution":{"iopub.execute_input":"2021-03-22T22:23:15.266895Z","iopub.status.busy":"2021-03-22T22:23:15.266102Z","iopub.status.idle":"2021-03-22T22:23:16.921254Z","shell.execute_reply":"2021-03-22T22:23:16.921699Z"},"papermill":{"duration":1.675417,"end_time":"2021-03-22T22:23:16.921855","exception":false,"start_time":"2021-03-22T22:23:15.246438","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"papermill":{"duration":0.023507,"end_time":"2021-03-22T22:23:16.970498","exception":false,"start_time":"2021-03-22T22:23:16.946991","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ArcModule(nn.Module):\n    def __init__(self, in_features, out_features, s = 10, m = margin):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = torch.tensor(math.cos(math.pi - m))\n        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n\n    def forward(self, inputs, labels):\n        cos_th = F.linear(inputs, F.normalize(self.weight))\n        cos_th = cos_th.clamp(-1, 1)\n        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n\n        cond_v = cos_th - self.th\n        cond = cond_v <= 0\n        cos_th_m[cond] = (cos_th - self.mm)[cond]\n\n        if labels.dim() == 1:\n            labels = labels.unsqueeze(-1)\n        onehot = torch.zeros(cos_th.size()).cuda()\n        labels = labels.type(torch.LongTensor).cuda()\n        onehot.scatter_(1, labels, 1.0)\n        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n        outputs = outputs * self.s\n        return outputs","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:43.806236Z","start_time":"2021-03-31T05:33:43.798261Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:17.026489Z","iopub.status.busy":"2021-03-22T22:23:17.025773Z","iopub.status.idle":"2021-03-22T22:23:17.029358Z","shell.execute_reply":"2021-03-22T22:23:17.028886Z"},"papermill":{"duration":0.036576,"end_time":"2021-03-22T22:23:17.029493","exception":false,"start_time":"2021-03-22T22:23:16.992917","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" models.resnet101(True)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:33:58.046111Z","start_time":"2021-03-31T05:33:55.881981Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SHOPEEDenseNet(nn.Module):\n\n    def __init__(self, channel_size, out_feature, dropout=0.5, backbone='densenet121', pretrained=True):\n        super(SHOPEEDenseNet, self).__init__()\n        self.channel_size = channel_size\n        self.out_feature = out_feature\n        \n        if backbone == 'resnet18':\n            self.backbone = models.resnet18(True)\n            self.in_features = self.backbone.fc.in_features\n            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n            self.fc1 = nn.Linear(self.in_features * 7 * 7 , self.channel_size)\n        if backbone == 'resnet101':\n            self.backbone = models.resnet101(True)\n            self.in_features = self.backbone.fc.in_features\n            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n            self.fc1 = nn.Linear(self.in_features * 7 * 7 , self.channel_size)\n        print(self.backbone)\n        \n        self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n        self.bn1 = nn.BatchNorm2d(self.in_features)\n        self.dropout = nn.Dropout2d(dropout)\n        self.bn2 = nn.BatchNorm1d(self.channel_size)\n        \n    def forward(self, x, labels=None):\n        features = self.backbone(x)\n        features = self.dropout(features)\n        features = features.view(features.size(0), -1)\n        # print(features.shape)\n        features = self.fc1(features)\n        features = F.normalize(features)\n        if labels is not None:\n            return self.margin(features, labels)\n        return features\n    \n    def test(self):\n        x = torch.rand(1, 3, 224, 224).cuda()\n        print(self.forward(x))","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:14.631988Z","start_time":"2021-03-31T05:34:14.621285Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:17.08325Z","iopub.status.busy":"2021-03-22T22:23:17.082726Z","iopub.status.idle":"2021-03-22T22:23:17.085924Z","shell.execute_reply":"2021-03-22T22:23:17.085427Z"},"papermill":{"duration":0.033471,"end_time":"2021-03-22T22:23:17.086029","exception":false,"start_time":"2021-03-22T22:23:17.052558","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SHOPEEDenseNet(512, df_train.label_group.nunique(), backbone='resnet101')\nmodel.to(device);","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:35.228148Z","start_time":"2021-03-31T05:34:20.558743Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:17.137507Z","iopub.status.busy":"2021-03-22T22:23:17.136958Z","iopub.status.idle":"2021-03-22T22:23:24.511965Z","shell.execute_reply":"2021-03-22T22:23:24.511122Z"},"papermill":{"duration":7.402071,"end_time":"2021-03-22T22:23:24.512162","exception":false,"start_time":"2021-03-22T22:23:17.110091","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.test()","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:35.93711Z","start_time":"2021-03-31T05:34:35.229844Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"papermill":{"duration":0.037054,"end_time":"2021-03-22T22:23:24.588638","exception":false,"start_time":"2021-03-22T22:23:24.551584","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_func(train_loader):\n    model.train()\n    bar = tqdm(train_loader)\n    if use_amp:\n        scaler = torch.cuda.amp.GradScaler()\n    losses = []\n    for batch_idx, (images, targets) in enumerate(bar):\n        images, targets = images.to(device), targets.to(device).long()\n        \n        if debug and batch_idx == 100:\n            print('Debug Mode. Only train on first 100 batches.')\n            break\n            \n        if use_amp:\n            with torch.cuda.amp.autocast():\n                logits = model(images, targets)\n                loss = criterion(logits, targets)\n            scaler.scale(loss).backward()\n            if ((batch_idx + 1) %  accumulation_step == 0) or ((batch_idx + 1) == len(train_loader)):\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n        else:\n            logits = model(images, targets)\n            loss = criterion(logits, targets)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n        losses.append(loss.item())\n        smooth_loss = np.mean(losses[-30:])\n\n        bar.set_description(f'loss: {loss.item():.5f}, smth: {smooth_loss:.5f}')\n\n    loss_train = np.mean(losses)\n    return loss_train\n\n\ndef valid_func(valid_loader):\n    model.eval()\n    bar = tqdm(valid_loader)\n\n    PROB = []\n    TARGETS = []\n    losses = []\n    PREDS = []\n\n    with torch.no_grad():\n        for batch_idx, (images, targets) in enumerate(bar):\n            images, targets = images.to(device), targets.to(device).long()\n            logits = model(images, targets)\n\n            PREDS += [torch.argmax(logits, 1).detach().cpu()]\n            TARGETS += [targets.detach().cpu()]\n\n            loss = criterion(logits, targets)\n            losses.append(loss.item())\n           \n            bar.set_description(f'loss: {loss.item():.5f}')\n\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n    accuracy = (PREDS==TARGETS).mean()\n   \n    loss_valid = np.mean(losses)\n    return loss_valid, accuracy\n\ndef generate_test_features(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    \n    FEAS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for batch_idx, (images) in enumerate(bar):\n            images = images.to(device)\n            features = model(images)\n            FEAS += [features.detach().cpu()]\n    FEAS = torch.cat(FEAS).cpu().numpy()\n    return FEAS","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:40.64471Z","start_time":"2021-03-31T05:34:40.631529Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:24.68741Z","iopub.status.busy":"2021-03-22T22:23:24.6859Z","iopub.status.idle":"2021-03-22T22:23:24.690333Z","shell.execute_reply":"2021-03-22T22:23:24.69128Z"},"papermill":{"duration":0.066199,"end_time":"2021-03-22T22:23:24.691496","exception":false,"start_time":"2021-03-22T22:23:24.625297","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def row_wise_f1_score(labels, preds):\n    scores = []\n    for label, pred in zip(labels, preds):\n        n = len(np.intersect1d(label, pred))\n        score = 2 * n / (len(label)+len(pred))\n        scores.append(score)\n    return scores, np.mean(scores)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:41.972514Z","start_time":"2021-03-31T05:34:41.96615Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:24.773621Z","iopub.status.busy":"2021-03-22T22:23:24.772768Z","iopub.status.idle":"2021-03-22T22:23:24.774954Z","shell.execute_reply":"2021-03-22T22:23:24.774297Z"},"papermill":{"duration":0.047158,"end_time":"2021-03-22T22:23:24.775214","exception":false,"start_time":"2021-03-22T22:23:24.728056","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_threshold(df, lower_count_thresh, upper_count_thresh, search_space):\n    '''\n    Compute the optimal threshold for the given count threshold.\n    '''\n    score_by_threshold = []\n    best_score = 0\n    best_threshold = -1\n    for i in tqdm(search_space):\n        sim_thresh = i/100\n        selection = ((FEAS@FEAS.T) > sim_thresh).cpu().numpy()\n        matches = []\n        oof = []\n        for row in selection:\n            oof.append(df.iloc[row].posting_id.tolist())\n            matches.append(' '.join(df.iloc[row].posting_id.tolist()))\n        tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n        df['target'] = df.label_group.map(tmp)\n        scores, score = row_wise_f1_score(df.target, oof)\n        df['score'] = scores\n        df['oof'] = oof\n        \n        selected_score = df.query(f'count > {lower_count_thresh} and count < {upper_count_thresh}').score.mean()\n        score_by_threshold.append(selected_score)\n        if selected_score > best_score:\n            best_score = selected_score\n            best_threshold = i\n            \n#     plt.title(f'Threshold Finder for count in [{lower_count_thresh},{upper_count_thresh}].')\n#     plt.plot(score_by_threshold)\n#     plt.axis('off')\n#     plt.show()\n    print(f'Best score is {best_score} and best threshold is {best_threshold/100}')","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:45.757585Z","start_time":"2021-03-31T05:34:45.748983Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:24.861548Z","iopub.status.busy":"2021-03-22T22:23:24.857571Z","iopub.status.idle":"2021-03-22T22:23:24.866749Z","shell.execute_reply":"2021-03-22T22:23:24.867755Z"},"papermill":{"duration":0.056119,"end_time":"2021-03-22T22:23:24.867955","exception":false,"start_time":"2021-03-22T22:23:24.811836","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"papermill":{"duration":0.022994,"end_time":"2021-03-22T22:23:24.922283","exception":false,"start_time":"2021-03-22T22:23:24.899289","status":"completed"},"tags":[]}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr = init_lr)\nscheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.000001, max_lr=0.1)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:48.120572Z","start_time":"2021-03-31T05:34:48.111465Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:24.981302Z","iopub.status.busy":"2021-03-22T22:23:24.979577Z","iopub.status.idle":"2021-03-22T22:23:24.981901Z","shell.execute_reply":"2021-03-22T22:23:24.9823Z"},"papermill":{"duration":0.037034,"end_time":"2021-03-22T22:23:24.982454","exception":false,"start_time":"2021-03-22T22:23:24.94542","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_this = df_train[df_train['fold'] != fold_id]\ndf_valid_this = df_train[df_train['fold'] == fold_id]\n\ndf_valid_this['count'] = df_valid_this.label_group.map(df_valid_this.label_group.value_counts().to_dict())\n\ndataset_train = SHOPEEDataset(df_train_this, 'train', transform = transforms_train)\ndataset_valid = SHOPEEDataset(df_valid_this, 'test', transform = transforms_valid)\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers = n_worker)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers = n_worker)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:49.666903Z","start_time":"2021-03-31T05:34:49.64023Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:25.036154Z","iopub.status.busy":"2021-03-22T22:23:25.035538Z","iopub.status.idle":"2021-03-22T22:23:25.065302Z","shell.execute_reply":"2021-03-22T22:23:25.064423Z"},"papermill":{"duration":0.059449,"end_time":"2021-03-22T22:23:25.065443","exception":false,"start_time":"2021-03-22T22:23:25.005994","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_space = np.arange(40, 100, 10)","metadata":{"ExecuteTime":{"end_time":"2021-03-31T05:34:51.084855Z","start_time":"2021-03-31T05:34:51.081705Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"debug = False\nfor epoch in range(n_epochs):\n    scheduler.step()\n    loss_train = train_func(train_loader)\n    if epoch % valid_every == 0: \n        print('Now generating features for the validation set to simulate the submission.')\n        FEAS = generate_test_features(valid_loader)\n        FEAS = torch.tensor(FEAS).cuda()\n        print('Finding Best Threshold in the given search space.')\n        find_threshold(df = df_valid_this, \n               lower_count_thresh = 0, \n               upper_count_thresh = 999,\n               search_space = search_space)\n        if epoch >= save_after:\n            torch.save(model.state_dict(), f'{model_dir}{kernel_type}_fold{fold_id}_densenet_{image_size}_epoch{epoch}.pth')","metadata":{"ExecuteTime":{"end_time":"2021-03-31T10:16:02.901674Z","start_time":"2021-03-31T05:34:51.790946Z"},"execution":{"iopub.execute_input":"2021-03-22T22:23:25.142428Z","iopub.status.busy":"2021-03-22T22:23:25.141535Z","iopub.status.idle":"2021-03-22T22:34:15.655174Z","shell.execute_reply":"2021-03-22T22:34:15.654556Z"},"papermill":{"duration":650.566909,"end_time":"2021-03-22T22:34:15.655353","exception":false,"start_time":"2021-03-22T22:23:25.088444","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argsort([0.5, 0.4, 0.8])[-2]","metadata":{"ExecuteTime":{"end_time":"2021-03-26T08:01:21.705863Z","start_time":"2021-03-26T08:01:21.699473Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}