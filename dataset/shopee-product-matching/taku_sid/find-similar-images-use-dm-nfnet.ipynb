{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"timm_path = \"../input/timm-pytorch-image-models/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport os\nfrom tqdm.notebook import tqdm\n\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntest_df = pd.read_csv(\"/kaggle/input/shopee-product-matching/test.csv\")\ntest_dataset_dir = \"../input/shopee-product-matching/test_images/\"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"dataset_dir = \"../input/shopee-product-matching/train_images/\"\n\n\nclass Shopee:\n    def __init__(self):\n\n        image_size = 128\n        num_embeddings = 512\n        weights_path = \"../input/shopee-embedding-df/NFNet_f0_10.pth\"\n        embedding_path = '../input/shopee-embedding-df/train_df_embeddings.csv'\n        \n        self.df = pd.read_csv(embedding_path)\n        self.embeddings = []\n        for emb_str in self.df['embedding']:\n            emb_str = emb_str[1:-1]\n            emb = [float(_) for _ in emb_str.split(', ')]\n            self.embeddings.append(emb)\n        self.embeddings = np.array(self.embeddings)\n        \n        self.model = timm.create_model('dm_nfnet_f0', pretrained=False)\n        num_features = self.model.head.fc.in_features\n        self.model.head.fc = nn.Linear(num_features, num_embeddings)\n        update_param_names = ['head.fc.weight', 'head.fc.bias']\n        load_weghts = torch.load(weights_path)\n        self.model.load_state_dict(load_weghts)\n        self.model.eval()\n        _ = self.model.to(device)\n        \n        \n        self.valid_aug = A.Compose([\n                            A.LongestMaxSize(max_size=image_size, p=1.0),\n                            A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=0, p=1.0),\n                            A.Normalize(p=1.0),\n                            ToTensorV2(p=1.0)\n                            ])\n        \n    def display_image(self, image):\n        plt.xticks([])\n        plt.yticks([])\n        plt.imshow(image)\n        plt.show()\n    \n    \n    def find_similar(self, image_path, top_n=100,threshold=0.95):\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n        print('query image')\n        self.display_image(image)\n        \n        transformed = self.valid_aug(image=image)\n        aug_image = transformed['image']\n        \n        query_embedding = self.model(aug_image.unsqueeze(0).to(device)).cpu().detach().numpy()\n        numerator = np.sum(self.embeddings*query_embedding, axis=1)\n        denominator = np.sqrt(np.sum(self.embeddings**2, axis=1))*np.sqrt(np.sum(query_embedding**2))\n        cos_sims = numerator/denominator\n        \n        plot_list = []\n        for top_i, index in enumerate(np.argsort(-cos_sims)[0:top_n]):\n            if cos_sims[index] < threshold:\n                    break\n            plot_list.append(dataset_dir + self.df.iloc[index].image)\n\n        images_number = len(plot_list)\n        size = np.sqrt(images_number)\n        if int(size)*int(size) < images_number:\n            size = int(size) + 1\n        plt.figure(figsize=(20, 20))\n\n        ind=0\n        for image_id in plot_list:\n            plt.subplot(size, size, ind + 1)\n            image = cv2.imread(image_id)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n            plt.imshow(image)\n            plt.title(image_id, fontsize=6)\n            plt.axis(\"off\")\n            ind+=1\n        plt.show()\n                \nfinder = Shopee()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time finder.find_similar(os.path.join(dataset_dir , '027478fc15b3caf7d9be5465ad7bdf5c.jpg'), top_n=100,threshold=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time finder.find_similar(os.path.join(test_dataset_dir , test_df.loc[0,\"image\"]), top_n=60,threshold=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time finder.find_similar(os.path.join(test_dataset_dir , test_df.loc[1,\"image\"]), top_n=60,threshold=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time finder.find_similar(os.path.join(test_dataset_dir , test_df.loc[2,\"image\"]), top_n=60,threshold=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}