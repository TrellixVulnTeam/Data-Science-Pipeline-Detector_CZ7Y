{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Shopee Price Match Guarantee: Create Training Data","metadata":{}},{"cell_type":"markdown","source":"This notebook will demonstrate how we can generate the triplets of **anchor**, **positive** and **negative** posting ids which would be used to train a **Siamese Network** for **image based product matching**.\n\nThis can be achieved by leveraging the **group_label** column for positive and negative sampling. Addtionally, we can create **image and title triplets** using the posting id triplets for improving the predictions later on. All the results of this notebook are saved in CSV files for later use.","metadata":{}},{"cell_type":"markdown","source":"### Reference:\nThe inspiration to prep the data is drawn from Shopee - Generate data for triplet loss: https://www.kaggle.com/xhlulu/shopee-generate-data-for-triplet-loss/comments","metadata":{}},{"cell_type":"code","source":"#Import required libraries\nimport pandas as pd\nimport random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the training data\ntrain_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n\n#View sample train data\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a dictionary of label group and corresponding products\nlabel_group_dict = dict(list(train_df.groupby('label_group')))\n\n#View sample records in title dictionary\ndict_items = label_group_dict.items()\nlist(dict_items)[:2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define a custom fuction to create training triplets for siamese network training\ndef create_train_triplets(df):\n    \n    #Set a random seed value\n    random.seed(123)\n    \n    #Create a dictionary of label group and corresponding products\n    label_group_dict = dict(list(df.groupby('label_group')))\n\n    #Create alist of all label groups\n    label_groups = list(label_group_dict.keys())\n    \n    #Create a empty dataframe to store triplet records\n    triplet_df = pd.DataFrame(columns = ['anchor', 'positive', 'negative'])\n    \n    #Loop through all label groups to create anchor, positive and negative columns  \n    for current_label in label_groups:\n        \n        #Create a list of all posting ids in current label group\n        current_label_posting_ids = label_group_dict[current_label].posting_id.tolist()\n        \n        #Create triplets per posting id in current label group\n        for current_posting_id in current_label_posting_ids:\n            \n            #Set the anchor\n            anchor_id = current_posting_id\n            \n            ##---------------------------------------------------------------##\n            ##---- We will create the positive data from same label group ---##\n            ##---------------------------------------------------------------##\n            \n            #Create a list of all posting ids excluding the anchor id \n            other_positive_ids = [n for n in current_label_posting_ids if n != current_posting_id]\n            \n            #Set the positive image randomly from other positive ids of current label group\n            positive_id = random.choice(other_positive_ids)\n            \n            \n            ##---------------------------------------------------------------##\n            ##--- We will create the negative data from other label groups --##\n            ##---------------------------------------------------------------##\n            \n            #Create a list of all other label groups than current label group for negative id\n            other_label_groups = [n for n in label_groups if n != current_label]\n            \n            #Set the negative image randomly from one of the other label groups than current label group\n            negative_id = label_group_dict[random.choice(other_label_groups)].posting_id.tolist()[0]\n            \n            \n            ##---------------------------------------------------------------##\n            ##--- We will update the triplet dataframe with latest record ---##\n            ##---------------------------------------------------------------##\n            #update triplet_df\n            triplet_df = triplet_df.append({'anchor': anchor_id,\n                                            'positive': positive_id,\n                                            'negative': negative_id},\n                                            ignore_index = True)\n            \n            \n    \n    return triplet_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create training data posting ids triplet dataframe\ntrain_ids_triplets_df = create_train_triplets(train_df)\n\n#View sample records in train_ids_triplets_df\ntrain_ids_triplets_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, we have created the posting ids triplets data to train the Siamese Network. We can now leverage this id triplets to create similar dataframes for title and image information as well to make use of them in deciding the final matches.","metadata":{}},{"cell_type":"code","source":"#create a dictionary of all training product images\nimage_dictionary = train_df.set_index('posting_id').image.to_dict()\n\n#View sample records in image dictionary\ndict_items = image_dictionary.items()\nlist(dict_items)[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create images triplets dataframe using image_dictionary\ntrain_images_triplets_df = train_ids_triplets_df.applymap(lambda i: image_dictionary[i])\n\n#View sample records in train_images_triplets_df\ntrain_images_triplets_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have the image information mapping of the posting ids from the training triplets data.","metadata":{}},{"cell_type":"code","source":"#create a dictionary of all training product titles\ntitle_dictionary = train_df.set_index('posting_id').title.to_dict()\n\n#View sample records in title dictionary\ndict_items = title_dictionary.items()\nlist(dict_items)[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create titles triplets dataframe using title_dictionary\ntrain_titles_triplets_df = train_ids_triplets_df.applymap(lambda t: title_dictionary[t])\n\n#View sample records in train_titles_triplets_df\ntrain_titles_triplets_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have the title information mapping of the posting ids from the training triplets data.","metadata":{}},{"cell_type":"markdown","source":"We will now save all 3 data frames for training the model and improving the final matches.","metadata":{}},{"cell_type":"code","source":"#Save the information to csv files\ntrain_ids_triplets_df.to_csv('train_ids_triplets.csv', index=False)\ntrain_images_triplets_df.to_csv('train_images_triplets.csv', index=False)\ntrain_titles_triplets_df.to_csv('train_titles_triplets_df.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}