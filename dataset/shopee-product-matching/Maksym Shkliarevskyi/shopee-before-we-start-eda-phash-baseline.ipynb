{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Shopee Price Match Guarantee: Before we start\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/24286/logos/header.png?t=2021-01-07-16-57-37)\n\nDo you scan online retailers in search of the best deals? You're joined by the many savvy shoppers who don't like paying extra for the same product depending on where they shop. Retail companies use a variety of methods to assure customers that their products are the cheapest. Among them is product matching, which allows a company to offer products at rates that are competitive to the same product sold by another retailer. To perform these matches automatically requires a thorough machine learning approach, which is where your data science skills could help.\n\nTwo different images of similar wares may represent the same product or two completely different items. Retailers want to avoid misrepresentations and other issues that could come from conflating two dissimilar products. Currently, a combination of deep learning and traditional machine learning analyzes image and text information to compare similarity. But major differences in images, titles, and product descriptions prevent these methods from being entirely effective.\n\nShopee is the leading e-commerce platform in Southeast Asia and Taiwan. Customers appreciate its easy, secure, and fast online shopping experience tailored to their region. The company also provides strong payment and logistical support along with a 'Lowest Price Guaranteed' feature on thousands of Shopee's listed products.\n\nIn this competition, youâ€™ll apply your machine learning skills to build a model that predicts which items are the same products.\n\nThe applications go far beyond Shopee or other retailers. Your contributions to product matching could support more accurate product categorization and uncover marketplace spam. Customers will benefit from more accurate listings of the same or similar products as they shop. Perhaps most importantly, this will aid you and your fellow shoppers in your hunt for the very best deals."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tqdm\nfrom tqdm.auto import tqdm as tqdmp\ntqdmp.pandas()\n\n# Work with phash\nimport imagehash\n\nimport cv2, os\nimport skimage.io as io\nfrom PIL import Image\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:white; background:#f15335; border:0'><center>Work directory</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"WORK_DIR = '../input/shopee-product-matching'\nos.listdir(WORK_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:white; background:#f15335; border:0'><center>Fast look at the data</center></h2>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\nss = pd.read_csv('../input/shopee-product-matching/sample_submission.csv', index_col = 0)\nprint('-'*40, 'Train head', '-'*40)\nprint(train.head())\nprint('-'*40, 'Test head', '-'*40)\nprint(test.head())\nprint('-'*30, 'Sample submission head', '-'*30)\nprint(ss.head())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Train images: %d' %len(os.listdir(os.path.join(WORK_DIR, \"train_images\"))))\nprint('Test images: %d' %len(os.listdir(os.path.join(WORK_DIR, \"test_images\"))))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"train_images = WORK_DIR + \"/train_images/\" + train['image']\ntrain['path'] = train_images\n\ntest_images = WORK_DIR + \"/test_images/\" + test['image']\ntest['path'] = test_images\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('label_group unique values: {}'.format(train['label_group'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nplt.figure(figsize = (10, 6))\nplt.title('Distribution of title length', fontsize = '15')\nsns.kdeplot(train['title'].apply(lambda x: len(x)), fill = True, \n            color = '#f15335', \n            edgecolor = 'black', alpha = 0.9)\nplt.xlabel('Title length')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4 style='color:white; background:#f15335; border:0'><center>Image shapes distribution</center></h4>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Shape columns\ntrain['img_shape'] = train['path'].progress_apply(lambda x: np.shape(io.imread(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"shapes = pd.DataFrame().from_records(train['img_shape'])\nshapes.columns = ['Width', 'Height', 'Colors']\n\nsns.set_style(\"white\")\nsns.jointplot(x = shapes.iloc[:, 0].astype('float32'), \n              y = shapes.iloc[:, 1].astype('float32'),\n              height = 8, color = '#f15335')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:white; background:#f15335; border:0'><center>Work with image PHASH</center></h2>"},{"metadata":{},"cell_type":"markdown","source":"The data has 'phash' values for images, which can greatly simplify our work.\n\nPhash algorithm is really simple. It breaks images into fragments (in our case, the shape is 8x8), then analyzes the image structure on luminance (without color information) and simply assigns True or False depending on the value (above or below the mean). In order to analyze the similarity, it is necessary to subtract one phash matrix from another. Similar fragments will receive a null value (True - True = 0, False - False = 0). The closer the sum of all differences is to zero, the more similar the images are.\n\nFor instance, the phash matrix of the first image looks like this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"imagehash.hex_to_hash(train['image_phash'][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's write a little test function."},{"metadata":{"trusted":true},"cell_type":"code","source":"def match_matrix(phash_array):\n    \"\"\"\n    A function that checks for matches by phash value.\n    Takes phash values as input.\n    Output - phash diff matrix (pandas data frame)\n    \"\"\"\n    phashs = phash_array.apply(lambda x: imagehash.hex_to_hash(x))\n    phash_matrix = pd.DataFrame()\n    pbar = tqdm.tqdm(total = len(phash_array), desc = 'Progress:', \n                     position = 0, leave = True)\n    for idx, i in enumerate(phash_array):\n        pbar.update(1)\n        phash_matrix = pd.concat([phash_matrix, phashs - imagehash.hex_to_hash(i)], \n                                 axis = 1)\n    pbar.close()\n    phash_matrix.columns = range(len(phash_array))\n    return phash_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the process of composing a matrix is quite resource-intensive, for clarity, we will take only the first thousand images."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_part = train.iloc[:1000, :]\nmatches = match_matrix(train_part['image_phash'])\nmatches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_match = match_matrix(test['image_phash'][:3])\ntest_match","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match = []\nfor i in range(len(matches)):\n    match.append(matches.iloc[i, :][(matches.iloc[i, :] == 0)].index.values)\nmatch = pd.Series(match)\n\nmatch[match.apply(lambda x: len(x) > 1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at a few matches."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def image_viz(image_path):\n    \"\"\"\n    Function for visualization.\n    Takes path to image as input.\n    \"\"\"\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n    plt.imshow(img)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_part.loc[[11,12],['posting_id','image_phash','title','label_group']]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[11, 'path'], \n                         train_part.loc[12, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_part.loc[[889,890,891],['posting_id','image_phash','title','label_group']]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[889, 'path'], \n                         train_part.loc[890, 'path'], \n                         train_part.loc[891, 'path']]):\n    plt.subplot(1, 3, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_part.loc[[997,520],['posting_id','image_phash','title','label_group']]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[997, 'path'], \n                         train_part.loc[520, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Phash analysis allows you to find matches. It allows you to find not only exact copies but also approximate ones. For instance:"},{"metadata":{"trusted":true},"cell_type":"code","source":"match = []\nfor i in range(len(matches)):\n    match.append(matches.iloc[i, :][(matches.iloc[i, :] > 0) & \n                                    (matches.iloc[i, :] <= 5)].index.values)\nmatch = pd.Series(match)\n\nmatch[match.apply(lambda x: len(x) >= 1)]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[55, 'path'], \n                         train_part.loc[312, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[128, 'path'], \n                         train_part.loc[515, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[216, 'path'], \n                         train_part.loc[567, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It works very well. In this competition, we don't need to compute phash ourselves. But this can be easily done using the [imagehash library](https://pypi.org/project/ImageHash/)"},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:white; background:#f15335; border:0'><center>Baseline prediction</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Work functions\ndef phash_match(phash_array, element):\n    \"\"\"\n    A function that calculates phash diffs.\n    Takes phashs array and element as input.\n    Output - phash diff\n    \"\"\"\n    phash_diff = phash_array - phash_array[element]\n    return phash_diff\n\ndef add_match(phash, i, dataset = train, threshold = 5):\n    \"\"\"\n    A function that returns match names.\n    Takes phash array, i element, dataset and threshold (default = 5).\n    \"\"\"\n    diffs = phash_match(phash, i)\n    matches = [x for x in diffs[diffs <= threshold].index.drop(i).values]\n    str_matches = ''\n    str_matches = str_matches + dataset.iloc[i, 0] + ' '\n    for j in matches:\n        str_matches = str_matches + dataset.iloc[j, 0] + ' '\n    str_matches = str_matches[:-1]\n    return str_matches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phashs = train['image_phash'][:1000].apply(lambda x: imagehash.hex_to_hash(x))\nstr_matches = []\n\nfor i in tqdm.tqdm(range(len(phashs)), desc = 'Progress:', position = 0, leave = True):\n    str_matches.append(add_match(phashs, i))\n\nstr_matches[:15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4 style='color:white; background:#f15335; border:0'><center>Test images</center></h4>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate(test['path']):\n    plt.subplot(1, 3, idx + 1)\n    image_viz(i)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_phashs = test['image_phash'].apply(lambda x: imagehash.hex_to_hash(x))\ntest_matches = []\n\nfor i in tqdm.tqdm(range(len(test_phashs)), desc = 'Progress:', \n                   position = 0, leave = True):\n    test_matches.append(add_match(test_phashs, i, test, threshold = 7))\n\ntest_matches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['matches'] = test_matches\nss.to_csv(\"submission.csv\")\nss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This analysis is convenient and simple, but it has one disadvantage - speed. For large test data, we cannot use it, and therefore we restrict ourselves to the usual finding of all identical PHASH codes for each image."},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_match(dataset, element):\n    \"\"\"\n    A function that returns match names.\n    Takes dataset and i element.\n    \"\"\"\n    matches = dataset[dataset['image_phash'] == \n                      dataset['image_phash'][element]]['posting_id'].drop(element).values\n    str_matches = ''\n    str_matches = str_matches + dataset.iloc[element, 0] + ' '\n    for j in matches:\n        str_matches = str_matches + j + ' '\n    str_matches = str_matches[:-1]\n    return str_matches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_for_s = train[['posting_id', 'image_phash']]\nstr_matches = []\n\nfor i in tqdm.tqdm(range(len(train_for_s)), desc = 'Progress:', \n                   position = 0, leave = True):\n    str_matches.append(simple_match(train_for_s, i))\n\nstr_matches[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_for_s = test.loc[:2, ['posting_id', 'image_phash']]\ntest_matches = []\n\nfor i in tqdm.tqdm(range(len(test_for_s)), desc = 'Progress:', \n                   position = 0, leave = True):\n    test_matches.append(simple_match(test_for_s, i))\n    \ntest_matches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ss['matches'] = test_matches\n# ss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ss.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style='color:white; background:#f15335; border:0'><center>WORK IN PROGRESS...</center></h2>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}