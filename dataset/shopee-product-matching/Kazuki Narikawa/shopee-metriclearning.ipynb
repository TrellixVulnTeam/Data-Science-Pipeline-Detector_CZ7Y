{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 4/26目標:カスタムトレーニングループorAPIでの学習の実装(subclassingAPIでのkerasAplicationが正しく動くか確認)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_seed = 2021\nnp.random.seed(random_seed)\nlearning_rate = 1e-5\nalpha = 0.2\nbatch = 32\nnum_batches_per_step = 100\nepochs = 10\nckpt_dir = \"./train/\"\nprint(3*batch*num_batches_per_step*epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\ngroup_names = train_df.label_group.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def triplet_gen(df, group_names, dir_prefix, batch=1):\n    # dfからトリプレットを抽出\n    while True:\n        data = np.empty((batch*3,224,224,3), np.float32)\n        idx = 0\n        for _ in range(batch):\n            # グループ名決定\n            two_groups = np.random.choice(group_names, size=2, replace=False, p=None)\n            np.random.shuffle(two_groups)\n\n            # positive, negativeのグループ決定\n            p_group, n_group = two_groups\n            p_images = df[df.label_group == p_group].image.values\n            n_images = df[df.label_group == n_group].image.values\n            np.random.shuffle(p_images)\n            np.random.shuffle(n_images)\n\n            # anchor, positive, negativeの画像名取得\n            anchor, positive = np.random.choice(p_images, size=2, replace=False, p=None)\n            negative = np.random.choice(n_images, size=1, replace=False, p=None)[0]\n\n            # 画像読み込み\n            # Pillowのリサイズ: img.resize((width, height), method)\n            anchor_img = np.asarray(Image.open(dir_prefix.format(anchor)).resize((224,224)), dtype=np.float32)\n            positive_img = np.asarray(Image.open(dir_prefix.format(positive)).resize((224,224)), dtype=np.float32)\n            negative_img = np.asarray(Image.open(dir_prefix.format(negative)).resize((224,224)), dtype=np.float32)\n            \n            data[idx] = anchor_img / 255.0\n            idx += 1\n            data[idx] = positive_img / 255.0\n            idx += 1\n            data[idx] = negative_img / 255.0\n            idx += 1\n        # yield p_group, n_group, anchor_img, positive_img, negative_img\n        yield data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Subclassing API\nclass MetricLearningModel(tf.keras.Model):\n    def __init__(self, alpha=0.2, batch=1):\n        # モデル定義(keras.application使用)\n        super(MetricLearningModel, self).__init__()\n        self.resnet50 = ResNet50(include_top=False, weights='imagenet', input_shape=None)\n        self.flatten = layers.Flatten()\n        self.dense = layers.Dense(128)\n        self.anchors_idx = tf.range(start=0, limit=batch*3, delta=3)\n        self.positives_idx = tf.range(start=1, limit=batch*3+1, delta=3)\n        self.negatives_idx = tf.range(start=2, limit=batch*3+2, delta=3)\n        self.margin = alpha\n        \n    def call(self, x):\n        # 特徴量の抽出\n        x = self.resnet50(x)\n        flatten = self.flatten(x)\n        return self.dense(flatten)\n    \n    def loss(self, inputs):\n        # トリプレットロスの計算\n        # バッチごとのトリプレットロスの平均を返す\n        anchors = tf.gather(inputs, self.anchors_idx, axis=0)\n        positives = tf.gather(inputs, self.positives_idx, axis=0)\n        negatives = tf.gather(inputs, self.negatives_idx, axis=0)\n        p_dists = tf.norm(anchors-positives, axis=1)\n        n_dists = tf.norm(anchors-negatives, axis=1)\n        loss_matrix = tf.maximum(p_dists-n_dists+self.margin, 0.0)\n        return tf.reduce_mean(loss_matrix)\n        \n        \n# # Functional API\n# def create_model():\n#     image_tensor = layers.Input((224,224,3))\n#     model = ResNet50(include_top=False, weights='imagenet', input_tensor=image_tensor)\n#     x = model.layers[-1].output\n#     flatten = layers.Flatten()(x)\n#     vector = layers.Dense(512)(flatten)\n#     return tf.keras.Model(image_tensor, vector)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(x):\n    with tf.GradientTape() as tape:\n        vectors = model.call(x)\n        loss_value = model.loss(vectors)        \n    grads = tape.gradient(loss_value, model.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    return loss_value\n\ndef train(model, data_gen, epochs):\n    ckpt.restore(manager.latest_checkpoint)\n    if manager.latest_checkpoint:\n        print(\"Restored from {}\".format(manager.latest_checkpoint))\n    else:\n        print(\"Initializing from scratch.\")\n        \n    for epoch in range(1, epochs+1):\n        print(\"Start of epoch {}\".format(epoch))\n        start_time = time.perf_counter()\n        \n        for step_in_epoch in range(1, num_batches_per_step+1):\n            total_step = num_batches_per_step*(epoch-1) + step_in_epoch\n            loss_value = train_step(data_gen.__next__())\n            ckpt.step.assign_add(1)\n            \n            if total_step % 50 == 0:\n                print(\"Training loss (for one batch) at step {}: {:.5f}\".format(total_step, loss_value))\n                print(\"Seen so far: {} samples\".format((total_step+1)*3*batch))\n                \n            if int(ckpt.step) % 10 == 0:\n                save_path = manager.save()\n                print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n                \n        print(\"Time taken: {:.2f}s\".format(time.perf_counter()-start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# モデルのビルド、サマリーの表示\nmodel = MetricLearningModel(alpha=alpha, batch=batch)\nmodel.build(input_shape=(batch*3, 224, 224, 3))\n# 事前学習済みのベースモデルのパラメータ更新をオフ\nmodel.layers[0].trainable = False\nmodel.summary()\n# ジェネレータ, オプティマイザ等の定義\ngen = triplet_gen(train_df, group_names, '../input/shopee-product-matching/train_images/{}', batch)\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nckpt = tf.train.Checkpoint(step=tf.Variable(1), net=model)\nmanager = tf.train.CheckpointManager(ckpt, ckpt_dir, max_to_keep=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習\ntrain(model, gen, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}