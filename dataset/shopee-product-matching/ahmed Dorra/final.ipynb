{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! pip install cudf\n# ! pip install cuml\n# ! pip install cupy\n! pip install keras==2.1.0\n# !pip install tensorflow==2.1\n\nfrom functools import partial\nimport os\nimport random\nimport tensorflow as tf\nfrom pathlib import Path\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications import resnet\nimport numpy as np\nimport pandas as pd\nimport gc,cv2,math\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# For this project i am using the RAPIDS Library developed by NVIDIA\n# The RAPIDS suite of open source software libraries and APIs gives you the ability \n# to execute end-to-end data science and analytics pipelines entirely on GPUs\n# more information: https://rapids.ai/\nimport cudf,cuml,cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport tensorflow_addons as tfa\nimport PIL,cv2\nfrom tensorflow.keras.applications import EfficientNetB4,ResNet101,EfficientNetB5,ResNet50\nfrom sklearn.model_selection import train_test_split\n\ngpus = tf.config.experimental.list_physical_devices('GPU') \nfor gpu in gpus: \n    tf.config.experimental.set_memory_growth(gpu, True)\n    \n    \n#     jjjj\nprint(keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:13:05.694865Z","iopub.execute_input":"2022-06-05T11:13:05.695249Z","iopub.status.idle":"2022-06-05T11:13:13.370747Z","shell.execute_reply.started":"2022-06-05T11:13:05.695216Z","shell.execute_reply":"2022-06-05T11:13:13.369332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Library versions ->\")\nprint(\"RAPIDS:\",cuml.__version__)\nprint(\"TF:\",tf.__version__,'\\n')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T13:52:15.696378Z","iopub.execute_input":"2022-06-04T13:52:15.696851Z","iopub.status.idle":"2022-06-04T13:52:44.105644Z","shell.execute_reply.started":"2022-06-04T13:52:15.696749Z","shell.execute_reply":"2022-06-04T13:52:44.104699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LIMIT=1\ngpus=tf.config.experimental.list_physical_devices(\"GPU\")\n\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus=tf.config.experimental.list_logical_devices(\"GPU\")\n        \n        print(len(gpus),\"Physical GPUs\")\n        print(len(logical_gpus),\"Logical GPUs\")\n        \n    except RuntimeError as e:\n        print(e)\n            \nprint(f\"Tensorflow restricted to {LIMIT}GB RAM\")\nprint(f\"RAPIDS has {16-LIMIT}GB RAM available for use \")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:24:23.251456Z","iopub.execute_input":"2022-06-04T14:24:23.251774Z","iopub.status.idle":"2022-06-04T14:24:28.623765Z","shell.execute_reply.started":"2022-06-04T14:24:23.251747Z","shell.execute_reply":"2022-06-04T14:24:28.621776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT,WIDTH=256,256\nCHANNELS=3\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE=32\n\n# SETTING UP DATA\ntrain = pd.read_csv('../input/shopee-product-matching/train.csv')\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\ntrain_jpg_directory = '../input/shopee-product-matching/train_images'\ntest_jpg_directory = '../input/shopee-product-matching/test_images'\ntrain.head()\nDATA_PATH='../input/shopee-product-matching/'\nIMG_BASE=DATA_PATH+'train_images/'\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:34:26.134691Z","iopub.execute_input":"2022-06-04T14:34:26.135043Z","iopub.status.idle":"2022-06-04T14:34:26.241519Z","shell.execute_reply.started":"2022-06-04T14:34:26.135012Z","shell.execute_reply":"2022-06-04T14:34:26.240607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trgt=train.groupby(\"label_group\").posting_id.agg(\"unique\")\ntrain['target']=train.label_group.map(trgt)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:34:29.223155Z","iopub.execute_input":"2022-06-04T14:34:29.223483Z","iopub.status.idle":"2022-06-04T14:34:29.896986Z","shell.execute_reply.started":"2022-06-04T14:34:29.223454Z","shell.execute_reply":"2022-06-04T14:34:29.895975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['image_path']=DATA_PATH+'train_images/'+train.image","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:34:58.594591Z","iopub.execute_input":"2022-06-04T14:34:58.595162Z","iopub.status.idle":"2022-06-04T14:34:58.634955Z","shell.execute_reply.started":"2022-06-04T14:34:58.595114Z","shell.execute_reply":"2022-06-04T14:34:58.633461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_to_label_mapping=dict(zip(train.label_group.unique(),range(train.label_group.nunique())))\ntrain[\"label_number\"]=train.label_group.map(id_to_label_mapping)\n\nNUM_CLASSES=train.label_group.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:35:32.409836Z","iopub.execute_input":"2022-06-04T14:35:32.410185Z","iopub.status.idle":"2022-06-04T14:35:32.436178Z","shell.execute_reply.started":"2022-06-04T14:35:32.410157Z","shell.execute_reply":"2022-06-04T14:35:32.435342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert train pandas dataframe into cudf dataframe for RAPIDS use\ntrain_gf = cudf.DataFrame(train)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:35:54.721803Z","iopub.execute_input":"2022-06-04T14:35:54.722164Z","iopub.status.idle":"2022-06-04T14:35:54.820735Z","shell.execute_reply.started":"2022-06-04T14:35:54.722136Z","shell.execute_reply":"2022-06-04T14:35:54.819966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# embeddings chunk size\nCHUNK=1024*1\nC_LEN=len(train)//CHUNK\nif len(train)%CHUNK!=0: C_LEN += 1\n\nprint(\"Sample of available data\")\nprint(f\"Train Data shape is {train.shape}\")\nprint(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:36:25.545177Z","iopub.execute_input":"2022-06-04T14:36:25.545594Z","iopub.status.idle":"2022-06-04T14:36:25.561854Z","shell.execute_reply.started":"2022-06-04T14:36:25.545561Z","shell.execute_reply":"2022-06-04T14:36:25.561032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metric for measuring accuracy of pipeline\n# F1 score\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\n\n#  SETTING A BASELINE USING PHASH VALUES\nIMG_PHASH=train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['phash']=train.image_phash.map(IMG_PHASH)\ntrain[\"f1\"]=train.apply(getMetric(\"phash\"),axis=1)\nprint(f\"F1 Score for phash baseline = {train.f1.mean()}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:36:55.869632Z","iopub.execute_input":"2022-06-04T14:36:55.869984Z","iopub.status.idle":"2022-06-04T14:37:00.803471Z","shell.execute_reply.started":"2022-06-04T14:36:55.869955Z","shell.execute_reply":"2022-06-04T14:37:00.802454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Generator for faster and efficient usage of GPU for embeddings generations\n# more information: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:52:04.030234Z","iopub.execute_input":"2022-06-04T14:52:04.030578Z","iopub.status.idle":"2022-06-04T14:52:04.040605Z","shell.execute_reply.started":"2022-06-04T14:52:04.030547Z","shell.execute_reply":"2022-06-04T14:52:04.038957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting image path dataset to a image dataset\ndef process_data(image_path,label):\n    img=tf.io.read_file(image_path)\n    img=tf.image.decode_jpeg(img,channels=CHANNELS)\n    img=tf.image.resize(img,[HEIGHT,WIDTH])\n    # img = tf.cast(img, tf.float32) / 255.0\n    return img,label\n\n# Converting tf.data.dataset in a manner to make it usable for arcface layer\ndef arcface_format(image,label):\n    return {'image_input':image,'label_input':label},label\n\n# Final dataset producing function using image path and label\ndef get_dataset(image,label):\n    ds=tf.data.Dataset.from_tensor_slices((image,label))\n    ds=ds.map(process_data,num_parallel_calls=AUTOTUNE)\n    ds=ds.map(arcface_format,num_parallel_calls=AUTOTUNE)\n    ds=ds.batch(8)\n    \n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:58:11.920433Z","iopub.execute_input":"2022-06-04T14:58:11.920764Z","iopub.status.idle":"2022-06-04T14:58:11.927704Z","shell.execute_reply.started":"2022-06-04T14:58:11.920734Z","shell.execute_reply":"2022-06-04T14:58:11.926688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nImplements large margin arc distance.\n\nReference:\n    https://arxiv.org/pdf/1801.07698.pdf\n    https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n        blob/master/src/modeling/metric_learning.py\n'''\n\nclass ArcMarginProduct(tf.keras.layers.Layer):\n\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-06-04T14:58:32.094223Z","iopub.execute_input":"2022-06-04T14:58:32.094545Z","iopub.status.idle":"2022-06-04T14:58:32.108202Z","shell.execute_reply.started":"2022-06-04T14:58:32.094518Z","shell.execute_reply":"2022-06-04T14:58:32.107332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(pretrained_model):  \n    \n    model=tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ])\n    \n    return model\n\n# Arcface model creation function\ndef create_model_arcface(pretrained_model):    \n    margin = ArcMarginProduct(\n            n_classes = NUM_CLASSES, \n            s = 30, \n            m = 0.5, \n            name='head/arc_margin', \n            dtype='float32'\n            )\n#     model=tf.keras.Sequential([\n#         pretrained_model,\n#         tf.keras.layers.GlobalAveragePooling2D(),\n#         margin([tf.keras.layers.GlobalAveragePooling2D(),tf.keras.layers.Input(shape = (), name = 'label_input')]),\n#         tf.keras.layers.Softmax(dtype='float32')\n#     ])\n#     model_untrained.layers[0].set_weights(extracted_weights)\n    \n    inp = tf.keras.layers.Input(shape = (HEIGHT,WIDTH, 3), name = 'image_input')\n    label = tf.keras.layers.Input(shape = (), name = 'label_input')\n    x = pretrained_model(inp)\n#     x = ResNet50(weights=None,include_top=False,input_shape=(HEIGHT,WIDTH, 3))(inp)\n#     x.layers[0].set_weights(extracted_weights)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = margin([x, label])\n\n    output = tf.keras.layers.Softmax(dtype='float32')(x)\n\n    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:02:12.318375Z","iopub.execute_input":"2022-06-04T15:02:12.318694Z","iopub.status.idle":"2022-06-04T15:02:12.326409Z","shell.execute_reply.started":"2022-06-04T15:02:12.318666Z","shell.execute_reply":"2022-06-04T15:02:12.325522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate embedding using sequential model function\ndef embeddings_generation_Normal(model):\n    image_embeds=[]\n    for i,j in enumerate(range(C_LEN)):\n        a=j*CHUNK\n        b=min((j+1)*CHUNK,len(train))\n        print('CHUNK:',a,\"to\",b)\n\n        curr_test_gen=DataGenerator(train.iloc[a:b],batch_size=32,path=IMG_BASE)\n\n        image_embeddings=model.predict(curr_test_gen,verbose=1,use_multiprocessing=True,workers=4)\n        image_embeds.append(image_embeddings)\n\n    del model\n    _=gc.collect()\n    \n    return np.concatenate(image_embeds)\n\n# Function to generate embedding using arcface based model function\n# the process is preformed in part due to RAM limitations\ndef embeddings_generation_arcface(model):\n    image_embeds=[]\n    for i,j in enumerate(range(C_LEN)):\n        a=j*CHUNK\n        b=min((j+1)*CHUNK,len(train))\n        print('CHUNK:',a,\"to\",b)\n\n        curr_test_gen=get_dataset(train.iloc[a:b].image_path.values,train.iloc[a:b].label_number.values)\n        \n        image_embeddings=model.predict(curr_test_gen,verbose=1,use_multiprocessing=True,workers=-1)\n        image_embeds.append(image_embeddings)\n\n    del model\n    _=gc.collect()\n    \n    return np.concatenate(image_embeds)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:02:16.336456Z","iopub.execute_input":"2022-06-04T15:02:16.336776Z","iopub.status.idle":"2022-06-04T15:02:16.346428Z","shell.execute_reply.started":"2022-06-04T15:02:16.336748Z","shell.execute_reply":"2022-06-04T15:02:16.34535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction generation using KNN and Threshold value\ndef predictions_KNN(embeddings,neighbor_cnt,THRESHOLD_VALUE):\n    model=NearestNeighbors(n_neighbors=neighbor_cnt)\n    model.fit(embeddings)\n\n    preds=[]\n    IMAGE_THRESHOLD_DISTANCE=THRESHOLD_VALUE\n\n    for j in range(C_LEN):\n        a=j*CHUNK\n        b=min((j+1)*CHUNK,len(train))\n        #print('    CHUNK:',a,\"to\",b)\n\n        distances,indices=model.kneighbors(embeddings[a:b,])\n\n        for k in range(b-a):\n            ID_SMALLER_DISTANCE=np.where(distances[k,]<IMAGE_THRESHOLD_DISTANCE)[0]\n            ID_INDICES=indices[k,ID_SMALLER_DISTANCE]\n            CURR_PREDS=train.iloc[ID_INDICES].posting_id.values\n            preds.append(CURR_PREDS)\n\n    del model,distances,indices\n    _ = gc.collect()    \n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:00:28.991836Z","iopub.execute_input":"2022-06-04T15:00:28.992355Z","iopub.status.idle":"2022-06-04T15:00:28.999578Z","shell.execute_reply.started":"2022-06-04T15:00:28.992314Z","shell.execute_reply":"2022-06-04T15:00:28.998531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction generation using Cosine Similarity and Threshold value\ndef predictions_cosine(embeddings,THRESHOLD_VALUE):\n    cos_mat=cosine_similarity(embeddings,embeddings)\n    cosine_threshold =THRESHOLD_VALUE\n    mat=(cos_mat>cosine_threshold)\n\n    cosine_predictions=[]\n    for i in range(len(mat)):\n        cosine_predictions.append(train[mat[i]].posting_id.values)\n\n    cosine_predictions=pd.Series(cosine_predictions)\n    \n    del cos_mat,mat\n    _=gc.collect()\n    \n    return cosine_predictions\n\n# Normalize the embeddings to make the process of generating predictions easier\ndef normalize_embeddings(embeddings):\n    for x in embeddings:\n        norm = np.linalg.norm(x)\n        x/=norm\n    return embeddings","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:00:44.774487Z","iopub.execute_input":"2022-06-04T15:00:44.774806Z","iopub.status.idle":"2022-06-04T15:00:44.781044Z","shell.execute_reply.started":"2022-06-04T15:00:44.774778Z","shell.execute_reply":"2022-06-04T15:00:44.780078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Image Embeddings using EfficientNetB4\")\npretrained_model=EfficientNetB4( weights=None,include_top=False,input_shape=None)\nmodel=create_model(pretrained_model)\nmodel.load_weights('../input/efficientnet-b4-weights/best_model_efnb4.h5')\n# model.summary()\nintermediate_model = tf.keras.models.Model(inputs=model.input,outputs=model.get_layer(index=2).output)\n\nefficient_net_b4_embedding=embeddings_generation_Normal(intermediate_model)\nefficient_net_b4_embedding=normalize_embeddings(efficient_net_b4_embedding)\nnp.save('efficient_net_b4_finetune_embedding.npy',efficient_net_b4_embedding)\nprint(f\"Shape of EFFNETB4 embeddings:{efficient_net_b4_embedding.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:35:47.496742Z","iopub.execute_input":"2022-06-04T16:35:47.497139Z","iopub.status.idle":"2022-06-04T16:39:01.736493Z","shell.execute_reply.started":"2022-06-04T16:35:47.497109Z","shell.execute_reply":"2022-06-04T16:39:01.735486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Image Embeddings using EfficientNetB5\")\npretrained_model=EfficientNetB5(weights=None,include_top=False,input_shape=None)\nmodel=create_model(pretrained_model)\nmodel.load_weights('../input/efficientnet-b5-weights/best_model_efnb5.h5')\nintermediate_model = tf.keras.models.Model(inputs=model.input,outputs=model.get_layer(index=2).output)\n\n\nefficient_net_b5_embedding=embeddings_generation_Normal(intermediate_model)\nefficient_net_b5_embedding=normalize_embeddings(efficient_net_b5_embedding)\nnp.save('efficient_net_b5_finetune_embedding.npy',efficient_net_b5_embedding)\nprint(f\"Shape of EFFNETB5 embeddings:{efficient_net_b5_embedding.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T17:11:14.292966Z","iopub.execute_input":"2022-06-04T17:11:14.293374Z","iopub.status.idle":"2022-06-04T17:14:18.304098Z","shell.execute_reply.started":"2022-06-04T17:11:14.293342Z","shell.execute_reply":"2022-06-04T17:14:18.298744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.models import load_model\n# model_trained = load_model('../input/resnet101-weights/best_model_resnet101.h5')\n# extracted_weights = model_trained.layers[0].get_weights()\n\nprint(\"Image Embeddings using ResNet101\")\npretrained_model=ResNet101(weights=None,include_top=False,input_shape=None)\nmodel=create_model(pretrained_model)\nmodel.load_weights('../input/resnet101-weights/best_model_resnet101.h5')\nintermediate_model = tf.keras.models.Model(inputs=model.input,outputs=model.get_layer(index=2).output)\n\nresnet101_embedding=embeddings_generation_Normal(intermediate_model)\nresnet101_embedding=normalize_embeddings(resnet101_embedding)\nnp.save('resnet101_embedding_finetune_embedding.npy',resnet101_embedding)\nprint(f\"Shape of RESNET101 embeddings:{resnet101_embedding.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T17:30:14.257769Z","iopub.execute_input":"2022-06-04T17:30:14.258152Z","iopub.status.idle":"2022-06-04T17:33:31.826285Z","shell.execute_reply.started":"2022-06-04T17:30:14.258122Z","shell.execute_reply":"2022-06-04T17:33:31.825267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-04T17:36:09.552884Z","iopub.execute_input":"2022-06-04T17:36:09.553228Z","iopub.status.idle":"2022-06-04T17:36:09.560464Z","shell.execute_reply.started":"2022-06-04T17:36:09.553198Z","shell.execute_reply":"2022-06-04T17:36:09.559253Z"},"trusted":true},"execution_count":null,"outputs":[]}]}