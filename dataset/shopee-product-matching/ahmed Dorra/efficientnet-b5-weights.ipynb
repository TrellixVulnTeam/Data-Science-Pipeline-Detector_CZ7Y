{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport PIL,cv2\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import EfficientNetB4,ResNet101,EfficientNetB5\nfrom sklearn.model_selection import train_test_split\n\nSEED=48\nDEBUG=False\n\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH='../input/shopee-product-matching/'\ntrain=pd.read_csv(BASE_PATH+\"train.csv\")\ntrain['image_path']=BASE_PATH+'train_images/'+train.image\n\nid_to_label_mapping=dict(zip(train.label_group.unique(),range(train.label_group.nunique())))\ntrain[\"label_number\"]=train.label_group.map(id_to_label_mapping)\n\nNUM_CLASSES=train.label_group.nunique()\nHEIGHT,WIDTH=256,256\nCHANNELS=3\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE=32\n\nprint(\"Sample of Available Data\")\nprint(train.head(),'\\n')\n\n# Data processing function for creating tf.data dataset \n# Converting image path dataset to image label dataset\ndef process_data(image_path,label):\n    img=tf.io.read_file(image_path)\n    img=tf.image.decode_jpeg(img,channels=CHANNELS)\n    img=tf.image.resize(img,[HEIGHT,WIDTH])\n    return img,label\n\n# function to improve dataset processing speed \ndef configure_for_performance(ds,batch_size):\n    ds=ds.cache('/kaggle/dump.tfcache')\n    \n    ds=ds.shuffle(buffer_size=1024)\n    ds=ds.batch(BATCH_SIZE)\n    ds=ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\nx_train,x_valid=train_test_split(train,test_size=0.1,random_state=SEED,shuffle=True)\n\n# image path & label dataset\ntrain_ds=tf.data.Dataset.from_tensor_slices((x_train.image_path.values,x_train.label_number.values))\nvalid_ds=tf.data.Dataset.from_tensor_slices((x_valid.image_path.values,x_valid.label_number.values))\n\n# image & label dataset\ntrain_ds=train_ds.map(process_data,num_parallel_calls=AUTOTUNE)\nvalid_ds=valid_ds.map(process_data,num_parallel_calls=AUTOTUNE)\n\n# improving dataset by shuffling dataset,creating image batch and prefetching dataset\n# more information : https://www.tensorflow.org/guide/data_performance\n# Batch image and label dataset\ntrain_ds_batch = configure_for_performance(train_ds, 8)\nvalid_ds_batch = valid_ds.batch(8)\n\nprint(\"Dataset before reconfiguring\")\nprint(\"train data:\",train_ds.cardinality())\nprint(\"valid data\",valid_ds.cardinality(),'\\n')\n\nprint(\"Dataset after reconfiguring(BATCH+SHUFFLE+PREFETCH)\")\nprint(\"train data:\",train_ds_batch.cardinality())\nprint(\"valid data\",valid_ds_batch.cardinality(),'\\n')\n\n# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# loss function \n# https://github.com/AdrianUng/keras-triplet-loss-mnist#:~:text=Triplet%20Loss%20explained%3A,-Figures%20taken%20from&text=By%20pairing%20the%20images%20into,respect%20to%20all%20other%20classes.&text=Where%20d(A%2CP),the%20Positive%20and%20Negative%20pairs.\n\ndef pairwise_distances(embeddings):\n    dot_product = tf.linalg.matmul(embeddings, tf.transpose(embeddings))\n    square_norm = tf.linalg.diag_part(dot_product)\n    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n    distances = tf.math.maximum(distances, 0.0)\n\n    mask = tf.cast(tf.equal(distances, 0.0),tf.float32)\n    distances = distances + mask * 1e-16\n    distances = tf.math.sqrt(distances)\n    distances = distances * (1.0 - mask)\n\n    return distances\n\ndef get_anchor_positive_triplet_mask(labels):\n    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n    indices_not_equal = tf.math.logical_not(indices_equal)\n\n    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n    mask = tf.math.logical_and(indices_not_equal, labels_equal)\n\n    return mask\n\ndef get_anchor_negative_triplet_mask(labels):\n    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n    mask = tf.math.logical_not(labels_equal)\n\n    return mask\n\ndef get_triplet_mask(labels):\n    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n    indices_not_equal = tf.math.logical_not(indices_equal)\n    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n\n    distinct_indices = tf.math.logical_and(tf.math.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n\n\n    label_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n    i_equal_j = tf.expand_dims(label_equal, 2)\n    i_equal_k = tf.expand_dims(label_equal, 1)\n\n    valid_labels = tf.math.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n\n    mask = tf.math.logical_and(distinct_indices, valid_labels)\n\n    return mask\n\n\nclass TripletLossFn(tf.keras.losses.Loss):\n    def __init__(self,margin=1.0,**kwargs):\n        super().__init__(**kwargs)\n        self.margin = margin\n  \n    def call(self,y_true,y_pred):\n\n        labels = tf.convert_to_tensor(y_true)\n        labels = tf.squeeze(labels,axis=-1)\n        embeddings = tf.convert_to_tensor(y_pred)\n\n        pairwise_dist = pairwise_distances(embeddings)\n\n        mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n        mask_anchor_positive = tf.cast(mask_anchor_positive,tf.float32)\n\n        anchor_positive_dist = tf.math.multiply(mask_anchor_positive, pairwise_dist)\n\n        hardest_positive_dist = tf.math.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n\n\n        mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n        mask_anchor_negative = tf.cast(mask_anchor_negative,tf.float32)\n\n        max_anchor_negative_dist = tf.math.reduce_max(pairwise_dist, axis=1, keepdims=True)\n        anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n\n\n        hardest_negative_dist = tf.math.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n    \n\n        triplet_loss = tf.math.maximum(hardest_positive_dist - hardest_negative_dist + self.margin, 0.0)\n\n        triplet_loss = tf.math.reduce_mean(triplet_loss)\n\n        return triplet_loss\n    \n    def get_config(self):\n        base_config = super().get_config()\n        return {**base_config,\"margin\":self.margin}\n\n# Model creation using a pretrained model\ndef create_model(pretrained_model):  \n    \n    model=tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ])\n    \n    return model\n\n# funtion to compile a choosen model\ndef compile_model(model,LR=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=LR)\n    \n    loss=TripletLossFn(0.7)\n    \n    metrics = [\n       tf.keras.metrics.SparseCategoricalAccuracy()\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss)\n    \n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callback list generation\ndef callback_creation(model_path):\n    \n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        mode='min',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n    \n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=model_path,\n        monitor='val_loss',\n        mode='min',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        mode='min',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks=[reduce_lr,model_checkpoint,early_stopping]\n    \n    return callbacks","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model training\ndef model_training(pretrained_model,model_path):\n    EPOCH_COUNTS=50\n    VERBOSE=1\n    LR=0.0001\n\n    tf.keras.backend.clear_session();\n\n    model=create_model(pretrained_model)\n    model=compile_model(model,LR=LR)\n    callback_list=callback_creation(model_path)\n\n    history=model.fit(\n                        train_ds_batch,\n                        validation_data=valid_ds_batch,\n                        epochs=EPOCH_COUNTS,\n                        callbacks=callback_list,\n                    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efnb5_model_path='./best_model_efnb5.h5'\npretrained_model=EfficientNetB5(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\nmodel_training(pretrained_model,efnb5_model_path)","metadata":{},"execution_count":null,"outputs":[]}]}