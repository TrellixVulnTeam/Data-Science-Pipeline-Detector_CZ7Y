{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Importing pandas & numpy library\n2. Importing Seaborn & Matplotlib to image rendering\n3. Importing IMread from Open CV\n4. Text library to make longer to multiple lines\n5. Library to read images without completly loading file\n6. Tensor flow library required for Text + image processing + model\n7. NLTK library for text processing + other text library","metadata":{}},{"cell_type":"code","source":"import pandas as  pd\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cv2 import imread","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textwrap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install imagesize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport imagesize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NLTK library for text processing\nimport nltk\nfrom string import punctuation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sklearn library for textprocessing & clustering\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA,TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity, cosine_distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Required Data path\n#     1. train_csv --> Info about Train images + caption info \n#     2. test_csv  --> Has Test images + caption info \n#     3. train_dir --> Directory containing train images\n#     4. test_dir  --> Directory containing test images\n#     5. train_df  --> train_csv file read to pandas data frame for further processing \n#     6. test_df   --> test_csv file read to pandas data frame for further processing","metadata":{}},{"cell_type":"code","source":"# all path info \ntrain_csv = \"../input/shopee-product-matching/train.csv\"\ntest_csv = \"../input/shopee-product-matching/test.csv\"\ntrain_dir = \"../input/shopee-product-matching/train_images/\"\ntest_dir =\"../input/shopee-product-matching/test_images/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading train_csv & test_cs to data frame\n\ntrain_df = pd.read_csv( train_csv, sep =\",\")\ntest_df  = pd.read_csv( test_csv, sep =\",\")\nprint (\"Current dimension of train data frame ={}\".format( train_df.shape))\nprint (\"Current dimension of test data frame ={}\".format( test_df.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking train_df ( train data frame ) to check how data table is.","metadata":{}},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets chek for number of categories present in the data frame train_df","metadata":{}},{"cell_type":"code","source":"print ( \"Number of categories present in the train df ={}\".format( train_df[\"label_group\"].nunique()) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11014 unique groups are present in the data frame","metadata":{}},{"cell_type":"markdown","source":"# Lets check number of unique image present in the train_df ","metadata":{}},{"cell_type":"code","source":"print ( \"Number of Unique images present in the train df ={}\".format( train_df[\"image\"].nunique()) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We have 32412 unique images, were as total number of rows we have is 34250\n# Roughly we mush have good number sample images for each group","metadata":{}},{"cell_type":"code","source":"print (\"Max number of images present for each group/category ={}\".format( train_df.groupby( 'label_group').count().max().iloc[0] ) )\nprint (\"Min number of images present for each group/category ={}\".format( train_df.groupby( 'label_group').count().min().iloc[0] ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets visualize few images with, caption with 3X3 grid\n    * We have to perform 2 operation \n        1. to read image to numpy array \n        2. then plot the read data to image along with Text.","metadata":{}},{"cell_type":"code","source":"train_df[[\"image\",\"label_group\",\"title\"]].iloc[23].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_image():\n    fig = plt.figure( figsize = (7,7), dpi = 80 )\n    #for i in range( 0, 4 ):\n    plt.subplot ( 1, 2, 1 )    \n    random_num = np.random.randint(train_df.shape[0])\n    image,group,caption = train_df[[\"image\",\"label_group\",\"title\"]].iloc[random_num].values\n\n    plt.imshow( imread(train_dir + image ))\n    plt.title( \"group = \" +str(group))\n    plt.subplot ( 1, 2,2 )\n    plt.text( 0.5,0.5 , \"\\n\".join( textwrap.wrap( caption, 20 ) ) )\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_image()\ncreate_image()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    # Not all words in the caption are english, have take care of it as well ","metadata":{}},{"cell_type":"markdown","source":"# Lets check dimension of all images, how see the dimension spread","metadata":{}},{"cell_type":"code","source":"dimension = np.zeros( shape = ( train_df[\"image\"].nunique(),2)  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, x in enumerate( train_df[\"image\"].unique() ) :\n    dimension[i] = imagesize.get ( train_dir + x )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure( figsize = (5,5), dpi =90 )\nsns.scatterplot( x = [ x[0] for x  in dimension ], y = [ x[1] for x  in dimension ] )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dimension of image is not uniform, wehave scale image toresonable size","metadata":{}},{"cell_type":"markdown","source":"# Text Processing usig NLTK","metadata":{}},{"cell_type":"markdown","source":"    1. Tokenizing Text data\n    2. Remove stop words \n    ","metadata":{}},{"cell_type":"code","source":"def remove_stop_words_and_tokenize( data_list ):\n\n    processed_text_data = []\n    stop_words = nltk.corpus.stopwords.words (\"english\")  +list(punctuation)\n\n    for x in data_list:\n\n        nltk_tokenized_data = nltk.word_tokenize( x.lower()  )\n        nltk_tokenized_data = [ x for x in nltk_tokenized_data if  ( (x not in stop_words) and x.isalpha() and len(x) >1 ) ]\n        #nltk_tokenized_data = [ x for x in nltk_tokenized_data if len(x) >1 ]\n        processed_text_data.append( \" \".join ( nltk_tokenized_data) )\n\n    print (\"length of tokenized words from train data = {}\".format(len(processed_text_data) ) )\n    print ( \"first 10 words = {}\".format( processed_text_data[3:10]))\n    \n    return ( processed_text_data )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    * Adding new text to train_df pandas data frame","metadata":{}},{"cell_type":"code","source":"train_df[\"new_title\"] = remove_stop_words_and_tokenize( train_df[\"title\"])\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# >Lets check captions and its features","metadata":{}},{"cell_type":"code","source":"#Tokanizing text to words & removingspecial characters \n\ntokenized_data = keras.preprocessing.text.Tokenizer ( num_words = None,\n                                                    filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',\n                                                    lower = True,\n                                                    oov_token =\"<unk>\",\n                                                    split=\" \")\ntokenized_data.fit_on_texts ( train_df[\"new_title\"] )\ntokenized_data.word_index[\"<pad>\"] = 0\ntokenized_data.index_word[0] =\"<pad>\"\ntrain_seq_text = tokenized_data.texts_to_sequences ( train_df[\"new_title\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"total number of words are ={}\".format ( len ( tokenized_data.word_counts)  ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwords_df = pd.DataFrame( data ={ \"words\":[ x for x,y in tokenized_data.word_counts.items()],\n                                \"count\":[ y for x,y in tokenized_data.word_counts.items()]}\n                       )\nwords_df.sort_values( \"count\", inplace = True,ascending = False )\nwords_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig ,axis = plt.subplots( nrows = 2, ncols = 1,  figsize =(20,20 ), dpi = 90 )\nsns.barplot( data =words_df.head(100), x = \"words\",y =\"count\", ax = axis [0])\naxis[0].tick_params(axis=\"x\", rotation = 90 )\naxis[0].title.set_text( \" First 100 most common words \")\nsns.barplot( data =words_df.tail(100), x = \"words\",y =\"count\", ax = axis [1])\naxis[1].tick_params(axis=\"x\", rotation = 90 )\naxis[1].title.set_text( \" last 100 most common words \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# As we have close 18k words, Picking 10K frequent words for model building ","metadata":{}},{"cell_type":"code","source":"#Tokanizing text to words & removingspecial characters \n\ntokenized_data = keras.preprocessing.text.Tokenizer ( num_words = None,\n                                                    filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',\n                                                    lower = True,\n                                                    oov_token =\"<unk>\",\n                                                    split=\" \")\ntokenized_data.fit_on_texts ( train_df[\"new_title\"] )\ntokenized_data.word_index[\"<pad>\"] = 0\ntokenized_data.index_word[0] =\"<pad>\"\ntrain_seq_text = tokenized_data.texts_to_sequences ( train_df[\"new_title\"])\nprint (\"total number of words are ={}\".format ( len ( tokenized_data.word_counts)  ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"caption_vector\"] = train_seq_text\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NGRAMS_TXT = 3\ndef remove_stop_words_and_tokenize_tf_idf( data_list, NGRAMS_TXT = NGRAMS_TXT ):\n\n    #processed_text_data = []\n    stop_words = nltk.corpus.stopwords.words (\"english\")  +list(punctuation)\n    #print (data_list)\n    #for x in data_list:\n\n    nltk_tokenized_data = nltk.word_tokenize( data_list.lower()  )\n    nltk_tokenized_data = [ x for x in nltk_tokenized_data if  ( (x not in stop_words) and x.isalpha() and len(x) >1 ) ]\n    nltk_tokenized_data = [ x for x in nltk_tokenized_data if len(x) >1 ]\n    #n_grams_data= list ( nltk.ngrams( nltk_tokenized_data, NGRAMS_TXT ) )\n    #processed_text_data.append( \" \".join ( nltk_tokenized_data) )\n\n    #print (\"length of tokenized words from train data = {}\".format(len(processed_text_data) ) )\n    #print ( \"first 10 words = {}\".format( processed_text_data[3:10]))\n    \n    return ( nltk_tokenized_data )#+ n_grams_data )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_data = remove_stop_words_and_tokenize_tf_idf (train_df[\"title\"].iloc[4] )\nprint( \"processed data = {}\".format(processed_data))\nprint (  train_df[\"title\"].iloc[10] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NGRAMS_TXT = \ntf_idf = TfidfVectorizer( analyzer= remove_stop_words_and_tokenize_tf_idf,ngram_range= (1,4)).fit( train_df[\"title\"] )\n#tf_idf = TfidfVectorizer( ngram_range= (1,2),lowercase=True,stop_words= \"english\")\n#tf_idf.fit( train_df[\"title\"] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Lenght of vocabulary ={} words\".format( len ( tf_idf.vocabulary_) ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_tf_idf = tf_idf.fit_transform( train_df[\"title\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" np.where ( cosine_similarity( transformed_tf_idf[6], transformed_tf_idf[1:] ) > 0.8)[1] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label= train_df[\"label_group\"].iloc[4]\ngroup = train_df.groupby( by =\"label_group\" )\ngroup.get_group( label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_tf_idf[4] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"group.get_group( label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"plt.imshow( imread(r\"../input/shopee-product-matching/train_images/\" + \"00117e4fc239b1b641ff08340b429633.jpg\" ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow( imread(r\"../input/shopee-product-matching/train_images/\" + \"52f5b2e6f6647325817eb99db17709f0.jpg\" ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Tensorflow Extracting features from iamge ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, (299, 299))\n    img = tf.keras.applications.inception_v3.preprocess_input(img)\n    return img, image_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, path = load_image( \"../input/shopee-product-matching/train_images/\" + train_df[\"image\"].iloc[1] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cosine_similarity ( img,img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}