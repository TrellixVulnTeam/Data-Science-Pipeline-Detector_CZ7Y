{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertModel\nimport logging\nimport matplotlib.pyplot as plt\nimport transformers\nfrom transformers import *\nfrom tokenizers import BertWordPieceTokenizer\nimport pandas as pd\nimport numpy as np\nfrom scipy.spatial.distance import cosine\n# import cudf, cuml, cupy\nimport gc\nimport numpy as np\nfrom sklearn.preprocessing import normalize\nfrom scipy.spatial.distance import hamming\nfrom IPython.display import clear_output\nimport imagehash","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfVectorizer\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline, FeatureUnion\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# groups = train.groupby('label_group')['posting_id'].apply(lambda x: ' '.join(x)).reset_index()\n# groups.columns = ['label_group', 'posting_id_list']\n# train = train.merge(groups)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cudf\nimport re\n\n\ndef string_filter(line: str):\n    for char in '?-*.!/\\;:':  \n        line = line.replace(char,'')\n    return line\n\n# train = pd.read_csv('../input/shopee-product-matching/train.csv')\n# train['title'] = train['title'].apply(lambda x: x.lower())\n# train['title'] = train['title'].apply(lambda x: string_filter(x))\n\n# groups = train.groupby('label_group')['posting_id'].apply(lambda x: ' '.join(x)).reset_index()\n# groups.columns = ['label_group', 'posting_id_list']\n# train = train.merge(groups)\n# train = cudf.from_pandas(train)\n\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\ntest['title'] = test['title'].apply(lambda x: x.lower())\ntest['title'] = test['title'].apply(lambda x: string_filter(x))\n\n# groups = test.groupby('label_group')['posting_id'].apply(lambda x: ' '.join(x)).reset_index()\n# groups.columns = ['label_group', 'posting_id_list']\n# test = test.merge(groups)\ntest = cudf.from_pandas(test)\n\n# test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 5), max_features=10000)\ntext_vectorizer = TfidfVectorizer(\n    stop_words=\"english\",\n    analyzer=\"char\",\n    ngram_range=(2, 5),\n    max_features=10000\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = test['title'].fillna('')\n# labels = test['label_group']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train, X_val, y_train, y_val = train_test_split(\n#     texts, \n#     labels, \n#     random_state=0, \n#     test_size=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntfidf_matrix = text_vectorizer.fit_transform(texts)\n\nprint(tfidf_matrix.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cuml.common.sparsefuncs import csr_row_normalize_l2\nimport cupy\n\n\ndef efficient_csr_cosine_similarity(query, tfidf_matrix, matrix_normalized=False):\n    query = csr_row_normalize_l2(query, inplace=False)\n    if not matrix_normalized:\n        tfidf_matrix = csr_row_normalize_l2(tfidf_matrix, inplace=False)\n    \n    return tfidf_matrix.dot(query.T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_df = test\n\n\ndef document_search(series, top_n=3):\n    query_vecs = text_vectorizer.transform(series)\n    query_vec = cupy.sparse.csr_matrix(query_vecs.toarray()[0])\n    similarities = efficient_csr_cosine_similarity(query_vec, tfidf_matrix, matrix_normalized=True)\n    similarities = similarities.todense().reshape(-1)\n    best_idx = similarities.argsort()[-top_n:][::-1]\n\n    pp = cudf.DataFrame({\n        'posting_id': text_df['posting_id'].iloc[best_idx],\n        'text': text_df['title'].iloc[best_idx],\n        'distance': 1 - similarities[best_idx]\n    })\n    return pp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_text = train['title'][:2]\n# print(test_text)\n\n# similarities = document_search(\n#     series=test_text\n# )\n\n# print(similarities.to_pandas())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tnrange\n\nj = 0\nall_similarities = []\ntf_matches = []\n\nfor i in tnrange(2, test.shape[0]+2):\n    srez = text_df['title'][j:i]\n#     print(srez)\n    similarities = document_search(\n        series=srez\n    ).to_pandas()\n    top_dists = similarities['distance']\n    top_texts = similarities['text']\n    top_posting_ids = similarities['posting_id']\n    indexes = similarities.index\n    \n    a = ' '.join([top_posting_ids[i] for i in indexes if top_dists[i] < 0.3])\n    tf_matches.append(a)\n    \n#     all_similarities.append({\"p_id\": top_posting_id, \"dist\": top_dist, \"id\": index})\n    j += 1\n#     print(top_texts, top_dists, indexes, '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train.to_pandas()\n# test = test.to_pandas()\n\nposting_ids = test['posting_id'].to_arrow().to_pylist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tfidf_matches = []\n\n# for match_dict in tqdm(all_similarities):\n#     distance = match_dict['dist']\n#     index = match_dict['id']\n#     if distance < 0.3:\n#         match = ' '.join([str(index)])\n#         tfidf_matches.append(match)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f1_score = []\n# for tfidf_match, posting_id in zip(tf_matches, posting_ids):\n#     match = set(tfidf_match.split())\n#     posting_id_list = set(posting_id.split())\n#     precision = 1 - len(match - posting_id_list) / len(match)\n#     recall = 1 - len(posting_id_list - match) / len(posting_id_list)\n#     f1_score.append(2 * precision * recall / (precision + recall))\n# f1_score = np.mean(f1_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': posting_ids, 'matches': tf_matches})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}