{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/nfnets-keras')\n\n!pip install --quiet ../input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n# !pip install --quiet ../input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl\n\nimport os\nimport math\nimport re\nimport random\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport numpy as np\nimport tensorflow.keras.backend as K\n# import efficientnet.keras as efn\n# import efficientnet\nimport itertools\nimport matplotlib\nimport scipy\nimport pandas as pd\nimport sklearn\nfrom matplotlib import pyplot as plt\nfrom datetime import datetime\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\nimport pickle\nfrom sklearn.preprocessing import StandardScaler\nfrom nfnet import NFNet, nfnet_params\n\n# import cudf\n# import cuml\n# import cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nSEED = 42\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device: ', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    DEVICE = \"TPU\"\nexcept:\n    DEVICE = 'notTPU'\n    strategy = tf.distribute.get_strategy()\nprint(DEVICE)\n\nFOLD = 3\nAUTO = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path(f'shopee-tfrecord-512-gkf-4-folds-230421')\nREPLICAS = strategy.num_replicas_in_sync\nBATCH_SIZE = 32 * REPLICAS\nFILENAMES = tf.io.gfile.glob(GCS_PATH + f'/fold_{FOLD}/*.tfrec')\nFILENAMES","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (512, 512)\n\nEPOCHS = 100\nLR = 0.001\n\nCLASSES = 11014","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(image, img_size):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, img_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return tf.reshape(image, [*img_size, 3])\n\n# parse tfrecord files\ndef _parse_image(proto, train):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"title_vec\": tf.io.FixedLenFeature([100], tf.float32),  # shape [] means single element\n        \"phash_vec\": tf.io.FixedLenFeature([25], tf.float32),\n        \"label\": tf.io.FixedLenFeature([], tf.int64),  \n    }\n    return tf.io.parse_single_example(proto, features)\n\n# get image and label_group\ndef get_image_and_label(proto, train, img_size):\n    sample = _parse_image(proto, train=train)\n    sample[\"image\"] = decode_image(sample[\"image\"], img_size)\n    image = sample[\"image\"]\n    title_vec = sample[\"title_vec\"]\n    phash_vec = sample[\"phash_vec\"]\n    label = tf.cast(sample['label'], tf.int32)\n#     label = tf.one_hot(tf.cast(sample['label'], tf.int32), len(CLASSES))\n    return (image, title_vec, label), label\n\ndef get_training_dataset(tfr, batchsize, img_size = (512,512)):\n    return tfr.map(partial(get_image_and_label, train=True, img_size=img_size)).repeat().map(\n        lambda x,y: image_augmentation(x,y)).shuffle(1000).batch(batchsize).prefetch(AUTO)\n\ndef get_validation_dataset(tfr, batchsize, img_size=(512, 512), train=True):\n    return tfr.map(partial(get_image_and_label, train=train, img_size=img_size)).batch(batchsize).prefetch(AUTO)\n\ndef get_tfrecord_size(tfrecord):\n    return sum(1 for _ in tfrecord)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmentation function & tf.image functions (flip, brightness, contrast, saturation, hue)\n# for train\n# @tf.function\ndef image_augmentation(iw, label):\n    image, title_vec, label = iw\n\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n\n    return ((image, title_vec, label), label)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model, Sequential\nimport keras.backend as K\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.layers import (\n    Input, \n    Flatten, \n    Dense, \n    Dropout, \n    AveragePooling2D, \n    GlobalAveragePooling2D, \n    SpatialDropout2D, \n    BatchNormalization, \n    Activation, \n    Concatenate,\n    Embedding,\n    GlobalAveragePooling1D,\n    Lambda\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plt_lr(epoch_count):\n    if epoch_count > 50:\n        epoch_count = 50\n    \n    rng = [i for i in range(epoch_count)]\n\n    plt.figure()\n    y = [lrfn(x) for x in rng]\n    plt.title(f'Learning rate schedule: {y[0]} to {y[epoch_count-1]}')\n    plt.plot(rng, y)\n\ndef plt_acc(h):\n    plt.figure()\n    plt.plot(h.history[\"sparse_categorical_accuracy\"])\n    if 'val_sparse_categorical_accuracy' in h.history:\n        plt.plot(h.history[\"val_sparse_categorical_accuracy\"]) \n        plt.legend([\"training\",\"validation\"])       \n    else:\n        plt.legend([\"training\"])\n    plt.xlabel(\"epoch\")\n    plt.title(\"Sparse Categorical Accuracy\")\n    plt.show()\n    \ndef plt_f1_score(h):\n    plt.figure()\n    plt.plot(h.history[\"f1_score\"])\n    if 'f1_score' in h.history:\n        plt.plot(h.history[\"f1_score\"]) \n        plt.legend([\"training\",\"validation\"])       \n    else:\n        plt.legend([\"training\"])\n    plt.xlabel(\"epoch\")\n    plt.title(\"F1 Score\")\n    plt.show()\n\ndef plt_loss(h):\n    plt.figure()\n    plt.plot(h.history[\"loss\"])\n    if 'val_loss' in h.history:\n        plt.plot(h.history[\"val_loss\"]) \n        plt.legend([\"training\",\"validation\"])       \n    else:\n        plt.legend([\"training\"])\n    plt.legend([\"training\",\"validation\"])\n    plt.xlabel(\"epoch\")\n    plt.title(\"Loss\")\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es_val_f1 = tf.keras.callbacks.EarlyStopping(\n    monitor='f1_score', min_delta=0.001, patience=10, verbose=1, mode='max',\n    baseline=None, restore_best_weights=True\n)\n\nes_val_f1_stage2 = tf.keras.callbacks.EarlyStopping(\n    monitor='f1_score', min_delta=0.001, patience=15, verbose=1, mode='max',\n    baseline=None, restore_best_weights=True\n)\n\ncb_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"backup_weights_nfnet.h5\",\n    monitor=\"f1_score\", verbose=1, mode='max', save_best_only=True, save_weights_only=True)\n\ncb_checkpoint._supports_tf_logs = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# swish activation\nfrom keras.backend import sigmoid\ndef swish(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\n\nget_custom_objects().update({'swish': Activation(swish)})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional, Conv1D, GlobalMaxPooling1D, Conv2D\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path(f'nfnet-model-checkpoints-270421')\nMODEL_FILENAMES = tf.io.gfile.glob(GCS_PATH + f'/NFNET-F0/*')\n\ndef get_nfnet(weights='gs://kds-b135c9e4ed7b978eb1b05abe18f78523f1fe076527cd1f64555bd7b1/NFNET-F0/F0_NFNet'):\n    nfnet_ = NFNet(\n        num_classes=1000,\n        variant='F0',\n        drop_rate=0.2,\n        label_smoothing=0.1,\n        ema_decay=0.99999,\n        clipping_factor=0.01,\n        include_top=False,\n    )\n    if weights is not None:\n        nfnet_.load_weights(weights)\n\n    model_image = Sequential([\n        nfnet_,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    model_image.build((None, *IMAGE_SIZE, 3))\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1, name='title-conv'),\n        GlobalMaxPool1D(name='title-globalMax'),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model\n\n# model = get_nfnet()\n# model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callback():\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# custom callback for f1 evaluation metric\n# val_data = pd.read_parquet(f'../input/shopee-tfrecord-512-gkf-4-folds-230421/fold_{FOLD}/unseen.parquet', engine='pyarrow')\n# tmp = val_data.groupby('label_group').posting_id.agg('unique').to_dict()\n# val_data['target'] = val_data.label_group.map(tmp)\n# del tmp\n# customF1Score = CustomF1Score(validation_data = val_data)\n\n# for randomness\nignore_order = tf.data.Options()\nignore_order.experimental_deterministic = False\n\ntrain_records = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads=AUTO)\ntrain_records = train_records.with_options(ignore_order)\ntrain_data = get_training_dataset(train_records, BATCH_SIZE, IMAGE_SIZE)\ntrain_data = train_data.map(lambda x, y: (x, y))    \ntrain_size = get_tfrecord_size(train_records)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold 0: 22\n# fold 1: 24\n# fold 2: 14\n# fold 3: 12\n# avg: (22+24+14+12)/4 = 18\n# total epoch: 18 + 18*25/100 = 22.5 = 23\n\nwith strategy.scope():\n    model = get_nfnet()\n    model.compile(\n        optimizer = tfa.optimizers.LAMB(LR),\n        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n    )\nmodel.summary()\n    \nmodel.fit(\n    train_data, \n    steps_per_epoch=train_size//BATCH_SIZE,\n    epochs = 23,\n    callbacks=[get_lr_callback()], verbose=1\n)\n\nh = model.history\nplt_acc(h)\nplt_loss(h)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('model_weights.h5')","metadata":{},"execution_count":null,"outputs":[]}]}