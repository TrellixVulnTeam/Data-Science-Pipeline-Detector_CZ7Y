{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import all libraries","metadata":{}},{"cell_type":"code","source":"!pip install --quiet ../input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install --quiet ../input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl\n\nimport sys\nsys.path.append('../input/nfnets-keras')\n\nimport os\nimport math\nimport re\nimport random\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport numpy as np\nimport tensorflow.keras.backend as K\nimport efficientnet.keras as efn\nimport efficientnet\nimport itertools\nimport matplotlib\nimport scipy\nimport pandas as pd\nimport sklearn\nfrom matplotlib import pyplot as plt\nfrom datetime import datetime\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\nimport pickle\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\n## for bert language model\nimport transformers\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom transformers import RobertaTokenizer, TFRobertaModel\nfrom nfnet import NFNet, nfnet_params\n\nimport cudf\nimport cuml\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nfrom nltk.corpus import stopwords\nimport string\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n\nimport gc\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:04:59.786398Z","iopub.execute_input":"2021-06-15T03:04:59.786751Z","iopub.status.idle":"2021-06-15T03:06:06.538095Z","shell.execute_reply.started":"2021-06-15T03:04:59.786671Z","shell.execute_reply":"2021-06-15T03:06:06.537325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Memory adjustment","metadata":{}},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n# SO THAT WE HAVE 14GB RAM FOR RAPIDS\nLIMIT = 5.0\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))\n\nAUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 32\nIMAGE_SIZE = (380, 380)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:09.516293Z","iopub.execute_input":"2021-06-15T03:06:09.516627Z","iopub.status.idle":"2021-06-15T03:06:20.389088Z","shell.execute_reply.started":"2021-06-15T03:06:09.516596Z","shell.execute_reply":"2021-06-15T03:06:20.387641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Help functions for text preprocessing","metadata":{}},{"cell_type":"code","source":"# Preprocessing function helper\n# replace word that concatenate with other word\ndef remove_concatenate_2_words(text):\n    list_words = ['khusus']\n    for w in list_words:\n        text = text.replace(w, '')\n    return text\n\nPUNCT_TO_REMOVE = string.punctuation\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\nSTOPWORDS_ID = set(stopwords.words('indonesian'))\nSTOPWORDS_EN = set(stopwords.words('english'))\ndef remove_stopwords(list_text):\n    text_not_in_ID = [word for word in list_text if word not in STOPWORDS_EN]\n    text = [word for word in text_not_in_ID if word not in STOPWORDS_ID]\n    return text\n\n# remove big number and split text that contains word and number\ndef remove_big_number(list_text):\n    words = []\n    for w in list_text:\n        sub_w = re.split('(\\d+)',w)\n        for item in sub_w:\n            try:\n                tmp = int(item)\n                if tmp < 7000:\n                    if (tmp>1000) and (tmp % 100 == 0): # for even number\n                        words.append(str(tmp))\n                    elif (tmp<=1000) and (tmp>100) and (tmp % 10 == 0 ):\n                        words.append(str(tmp))\n                    elif (tmp<=100) and (tmp % 2 == 0):\n                        words.append(str(tmp))\n            except:\n                words.append(item)\n    return words\n\ndef remove_zero_val(list_text):\n    return [w for w in list_text if w not in ['0']]\n\ndef remove_common_words(list_text):\n    common_words = \"hari keren kere kw super baik jual jualan quality best free  kwalitas berkualitas kualitas bagus terbaik kembali dijamin beli gratis murah free diskon ongkir cek berkualitas original asli kualitas uang jaminan jamin terjamin buatan buat kirim wilayah luar kota jawa bali jakarta surabaya bulan month year day tahun hari harian anda your nikmat singapore malaysia indonesia vietnam thailand filipina bangkok jepang buy one get dapat dua two satu meriah kirim send pengiriman paket hemat uang kembali dapat guarantee buatan lokal dalam internasional karya termurah paling murah terbaik cheap murah biaya\".split(' ')\n    return [w for w in list_text if w not in common_words]\n\ndef remove_strange_words(list_text):\n    strange_words = ['aaa', 'aaaa', 'aaaaa', 'abc', 'abcd', 'bb', 'bbb', 'bbbb', 'ccc', 'cccc', 'thn', 'th', 'bln']\n    return [w for w in list_text if w not in strange_words]\n\ndef text_vectorizer(max_features, max_len, vocab):\n    # max_features: Maximum vocab size.\n    # max_len: Sequence length to pad the outputs to.\n    \n    text_dataset = tf.data.Dataset.from_tensor_slices(vocab)\n    \n    # Create the layer.\n    vectorize_layer = TextVectorization(\n        max_tokens = max_features,\n        output_mode = 'int',\n        output_sequence_length = max_len\n    )\n\n    vectorize_layer.adapt(text_dataset.batch(64))\n\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n    model.add(vectorize_layer)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:22.515005Z","iopub.execute_input":"2021-06-15T03:06:22.515406Z","iopub.status.idle":"2021-06-15T03:06:22.543762Z","shell.execute_reply.started":"2021-06-15T03:06:22.515359Z","shell.execute_reply":"2021-06-15T03:06:22.54192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n    ## clean (convert to lowercase and remove punctuations and characters and then strip\n    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n            \n    ## Tokenize (convert from string to list)\n    lst_text = text.split()\n    ## remove Stopwords\n    if lst_stopwords is not None:\n        for stopwords in lst_stopwords:\n            lst_text = [word for word in lst_text if word not in \n                        stopwords]\n                \n    ## Stemming (remove -ing, -ly, ...)\n    if flg_stemm == True:\n        # english stemming\n        ps = nltk.stem.porter.PorterStemmer()\n        lst_text = [ps.stem(word) for word in lst_text]\n        \n        # indonesian stemming\n#         factory = StemmerFactory()\n#         id_stemmer = factory.create_stemmer()\n\n#         lst_text = [id_stemmer.stem(word) for word in lst_text]\n                \n    ## Lemmatisation (convert the word into root word)\n    if flg_lemm == True:\n        lem = nltk.stem.wordnet.WordNetLemmatizer()\n        lst_text = [lem.lemmatize(word) for word in lst_text]\n        \n    # remove_zero_val\n    lst_text = [w for w in lst_text if w not in ['0']]\n    \n    # remove strange words\n    strange_words = ['aaa', 'aaaa', 'aaaaa', 'abc', 'abcd', 'bb', 'bbb', 'bbbb', 'ccc', 'cccc', 'thn', 'th', 'bln']\n    lst_text = [w for w in lst_text if w not in strange_words]\n            \n    ## back to string from list\n    text = \" \".join(lst_text)\n    return text\n\ndef string_escape(s, encoding='utf-8'):\n    return (\n        s.encode('latin1')  # To bytes, required by 'unicode-escape'\n        .decode('unicode-escape')  # Perform the actual octal-escaping decode\n        .encode('latin1')  # 1:1 mapping back to bytes\n        .decode(encoding)\n    )  # Decode original encoding\n\ndef regular_encode(texts, tokenizer, maxlen=512):\n    enc_di = tokenizer.batch_encode_plus(\n        texts, \n#         add_special_tokens = True,\n        return_attention_mask = True,\n        return_token_type_ids=True,\n        pad_to_max_length=True,\n        max_length=maxlen\n        )\n    \n    return np.array(enc_di['input_ids']), np.array(enc_di['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:24.016434Z","iopub.execute_input":"2021-06-15T03:06:24.016754Z","iopub.status.idle":"2021-06-15T03:06:24.028743Z","shell.execute_reply.started":"2021-06-15T03:06:24.016722Z","shell.execute_reply":"2021-06-15T03:06:24.027687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Title preprocessing (train vocab)","metadata":{}},{"cell_type":"code","source":"# extract vocab from train data\ndf = pd.read_csv('../input/shopee-product-matching/train.csv')\n    \ndf['title'] = df['title'].apply(lambda x: string_escape(x))\ndf['title'] = df['title'].apply(lambda x: remove_concatenate_2_words(x))\ndf['title'] = df['title'].str.lower()\ndf['title'] = df['title'].apply(lambda x: remove_punctuation(x))\ndf['title'] = df['title'].apply(lambda x: str(x).split())\ndf['title'] = df['title'].apply(lambda x: remove_stopwords(x))\n# df['title'] = df['title'].apply(lambda x: remove_big_number(x))\ndf['title'] = df['title'].apply(lambda x: remove_zero_val(x))\ndf['title'] = df['title'].apply(lambda x: remove_common_words(x))\ndf['title'] = df['title'].apply(lambda x: remove_strange_words(x))\ndf['title'] = df['title'].apply(lambda x: list(np.unique(x)))\n\n# title vocab\nwords = list(df['title'])\ntrain_vocab = list(np.unique(np.concatenate(words)))","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:11:08.211Z","iopub.execute_input":"2021-06-15T03:11:08.211351Z","iopub.status.idle":"2021-06-15T03:11:10.702526Z","shell.execute_reply.started":"2021-06-15T03:11:08.211321Z","shell.execute_reply":"2021-06-15T03:11:10.701671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load test dataset","metadata":{}},{"cell_type":"code","source":"GET_CV = False\nCHECK_RAM = False\n\nif GET_CV:\n    if CHECK_RAM:\n        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n        df = pd.concat([df,df], axis=0)\n    else:\n        df = pd.read_parquet('../input/shopee-tfrecords-380-gkf-four-folds/fold_3/unseen.parquet', engine='pyarrow')\nelse:\n    df = pd.read_csv('../input/shopee-product-matching/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:11:10.70455Z","iopub.execute_input":"2021-06-15T03:11:10.704922Z","iopub.status.idle":"2021-06-15T03:11:10.717498Z","shell.execute_reply.started":"2021-06-15T03:11:10.704884Z","shell.execute_reply":"2021-06-15T03:11:10.716654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing for MLP","metadata":{}},{"cell_type":"code","source":"################ for Image + MLP ################\n# title preprocessing for test dataset\ndf['tmp'] = df['title'].apply(lambda x: string_escape(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_concatenate_2_words(x))\ndf['tmp'] = df['tmp'].str.lower()\ndf['tmp'] = df['tmp'].apply(lambda x: remove_punctuation(x))\ndf['tmp'] = df['tmp'].apply(lambda x: str(x).split())\ndf['tmp'] = df['tmp'].apply(lambda x: remove_stopwords(x))\n# df['tmp'] = df['tmp'].apply(lambda x: remove_big_number(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_zero_val(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_common_words(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_strange_words(x))\ndf['tmp'] = df['tmp'].apply(lambda x: list(np.unique(x)))\n\n# title vocab\nwords = list(df['tmp'])\nwords = list(np.unique(np.concatenate(words)))\nwords = train_vocab + words\n\n# Text vectorizer\nmodel = text_vectorizer(max_features = 25000, max_len = 100, vocab = words)\nlist_text = [' '.join(x) for x in df['tmp']]\ntitle_vec = model.predict(list_text)\ndf['title_vec'] = list(title_vec)\ndf['input_ids'] = None\ndf['att_mask'] = None\n\ndel words, model, list_text, title_vec, df['tmp'], train_vocab\ngc.collect()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:11:10.718751Z","iopub.execute_input":"2021-06-15T03:11:10.719254Z","iopub.status.idle":"2021-06-15T03:11:11.614845Z","shell.execute_reply.started":"2021-06-15T03:11:10.719217Z","shell.execute_reply":"2021-06-15T03:11:11.614003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Help functions for datasets","metadata":{}},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\n\ndef read_dataset(df):\n    if GET_CV:\n        image_paths = '/kaggle/input/shopee-product-matching/train_images/' + df['image']\n    else:\n        image_paths = '/kaggle/input/shopee-product-matching/test_images/' + df['image']\n    input_ids = np.stack(df['input_ids'], axis=0)\n    att_mask = np.stack(df['att_mask'], axis=0)\n    title_vec = np.stack(df['title_vec'], axis=0)\n    return image_paths, input_ids, att_mask, title_vec\n\ndef decode_image(image, img_size):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, img_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return tf.reshape(image, [*img_size, 3])\n\n# Function to read our test image and return image\ndef read_image(filename, title_vec):\n    image = tf.io.read_file(filename)\n    image = decode_image(image, IMAGE_SIZE)\n    if ONLY_IMAGE:\n        return (image), np.empty((0), dtype=int)\n    else:\n        return (image, title_vec), np.empty((0), dtype=int)\n\n# Function to get our dataset that read images\ndef get_dataset(image, title_vec):\n    dataset = tf.data.Dataset.from_tensor_slices((image, title_vec))\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_text_dataset(input_ids, att_mask, title_vec):\n    dataset = tf.data.Dataset.from_tensor_slices((input_ids, att_mask, title_vec))\n    dataset = dataset.map(lambda x,y,z: ((x,y,z), ()), num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:48.693266Z","iopub.execute_input":"2021-06-15T03:06:48.693586Z","iopub.status.idle":"2021-06-15T03:06:48.707115Z","shell.execute_reply.started":"2021-06-15T03:06:48.693555Z","shell.execute_reply":"2021-06-15T03:06:48.705864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import library for Deep Learning Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model, Sequential\nimport keras.backend as K\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.layers import (\n    Input, \n    Flatten, \n    Dense, \n    Dropout, \n    AveragePooling2D, \n    GlobalAveragePooling2D, \n    SpatialDropout2D, \n    BatchNormalization, \n    Activation, \n    Concatenate,\n    Embedding,\n    GlobalAveragePooling1D,\n    Lambda\n)\n\nfrom keras.backend import sigmoid\ndef swish(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\n\nget_custom_objects().update({'swish': Activation(swish)})\n\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, multiply, Reshape\nfrom keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional, Conv1D, GlobalMaxPooling1D, Conv2D\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50, InceptionResNetV2, Xception","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:50.349445Z","iopub.execute_input":"2021-06-15T03:06:50.349792Z","iopub.status.idle":"2021-06-15T03:06:50.361713Z","shell.execute_reply.started":"2021-06-15T03:06:50.349762Z","shell.execute_reply":"2021-06-15T03:06:50.3607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Arc margin implementation","metadata":{}},{"cell_type":"code","source":"class ArcMarginProduct(keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:52.060388Z","iopub.execute_input":"2021-06-15T03:06:52.060722Z","iopub.status.idle":"2021-06-15T03:06:52.074947Z","shell.execute_reply.started":"2021-06-15T03:06:52.06069Z","shell.execute_reply":"2021-06-15T03:06:52.073992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Deep learning models (Image + MLP for title)","metadata":{}},{"cell_type":"code","source":"def effb1(weights='noisy-student'):\n    efn1 = efn.EfficientNetB1(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    for layer in efn1.layers:\n        layer.trainable = False\n    \n    model_image = Sequential([\n        efn1,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    \n    eff_aux = Model(\n        inputs = efn1.input, \n        outputs = efn1.get_layer('block5b_activation').output)\n    aux_model = Sequential([\n        eff_aux,\n        Conv2D(128, kernel_size=(3, 3), activation='relu', name='aux-conv1'),\n        BatchNormalization(name='aux-bn1'),\n        GlobalAveragePooling2D(name='aux-pooling'),\n        # Flatten(),\n        Dropout(0.5),\n        Dense(1024, name='aux-dense1'),\n        Activation('swish'),\n    ], name='aux-model')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 70, input_length=100, name='title-embed'),\n#         GlobalAveragePooling1D(name='title-pooling'),\n        Flatten(name='title-flatten'),\n        BatchNormalization(name='title-bn1'),\n        Dropout(0.2),\n        Dense(650, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n#         Dropout(0.1),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    concatenate2 = Concatenate(name='concatenate2')([concatenate, aux_model.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate2, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, aux_model.input, model_title.input, label], outputs=output)\n    return model\n\ndef effb1_512_v2(weights='noisy-student'):\n    efn1 = efn.EfficientNetB1(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    for layer in efn1.layers:\n        layer.trainable = False\n    \n    model_image = Sequential([\n        efn1,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    \n    eff_aux = Model(\n        inputs = efn1.input, \n        outputs = efn1.get_layer('block5b_activation').output)\n    aux_model = Sequential([\n        eff_aux,\n        Conv2D(128, kernel_size=(3, 3), activation='relu', name='aux-conv1'),\n        BatchNormalization(name='aux-bn1'),\n        GlobalAveragePooling2D(name='aux-pooling'),\n        Dropout(0.5),\n        Dense(1024, name='aux-dense1'),\n        Activation('swish'),\n    ], name='aux-model')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    concatenate2 = Concatenate(name='concatenate2')([concatenate, aux_model.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate2, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, aux_model.input, model_title.input, label], outputs=output)\n    return model\n\ndef effb1_512_v3(weights='noisy-student'):\n    efn1 = efn.EfficientNetB1(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    model_image = Sequential([\n        efn1,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model\n\ndef effb2(weights='noisy-student'):\n    efn2 = efn.EfficientNetB2(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    for layer in efn2.layers:\n        layer.trainable = False\n    \n    model_image = Sequential([\n        efn2,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    \n    eff_aux = Model(\n        inputs = efn2.input, \n        outputs = efn2.get_layer('block5b_activation').output)\n    aux_model = Sequential([\n        eff_aux,\n        Conv2D(128, kernel_size=(3, 3), activation='relu', name='aux-conv1'),\n        BatchNormalization(name='aux-bn1'),\n        GlobalAveragePooling2D(name='aux-pooling'),\n        # Flatten(),\n        Dropout(0.5),\n        Dense(1024, name='aux-dense1'),\n        Activation('swish'),\n    ], name='aux-model')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = 8261, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate2 = Concatenate(name='concatenate2')([model_image.output, aux_model.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate2, label])\n    output = Dense(8261, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, aux_model.input, label], outputs=output)\n    return model\n\ndef effb5(weights='noisy-student'):\n    effb5 = efn.EfficientNetB5(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3),\n                                drop_connect_rate=0  # the hack\n                              )\n    \n    model_image = Sequential([\n        effb5,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model\n\ndef effb7(weights='noisy-student'):\n    img_inp = Input(shape=(*IMAGE_SIZE, 3))\n    effb5 = efn.EfficientNetB7(weights=weights, input_shape=(*IMAGE_SIZE, 3), include_top=False)\n    \n    pt_depth = effb5.layers[-1].get_output_shape_at(0)[-1]\n    pt_features = effb5(img_inp)\n    bn_features = BatchNormalization()(pt_features)\n    \n    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n    \n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', \n                   use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n    \n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.25)(gap)\n    img_embed = Dense(2400, activation = 'swish', name='img-embed')(gap_dr)\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n    \n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([img_embed, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[img_inp, label], outputs=output)\n    return model\n\ndef effb7_v2(weights='noisy-student'):\n    img_inp = Input(shape=(*IMAGE_SIZE, 3))\n    effb7 = efn.EfficientNetB7(weights=weights, input_shape=(*IMAGE_SIZE, 3), include_top=False)\n    \n    pt_depth = effb7.layers[-1].get_output_shape_at(0)[-1]\n    pt_features = effb7(img_inp)\n    bn_features = BatchNormalization()(pt_features)\n    \n    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n    \n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', \n                   use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n    \n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.25)(gap)\n    img_embed = Dense(2400, activation = 'swish')(gap_dr)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(22000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([img_embed, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[img_inp, model_title.input, label], outputs=output)\n    return model\n\ndef effb5_v2(weights='noisy-student'):\n    img_inp = Input(shape=(*IMAGE_SIZE, 3))\n    effb5 = efn.EfficientNetB5(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    pt_depth = effb5.layers[-1].get_output_shape_at(0)[-1]\n    pt_features = effb5(img_inp)\n    bn_features = BatchNormalization()(pt_features)\n    \n    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n    \n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', \n                   use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n    \n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.25)(gap)\n    img_embed = Dense(2400, activation = 'swish', name='img-embed')(gap_dr)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([img_embed, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[img_inp, model_title.input, label], outputs=output)\n    return model\n\ndef effb1_244_v4(weights='noisy-student'):\n    \n    effb1 = efn.EfficientNetB1(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    model_image = Sequential([\n        effb1,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n    ], name='effb1-img')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(420, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.5, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model\n\ndef effb3(weights='noisy-student'):\n    img_inp = Input(shape=(*IMAGE_SIZE, 3))\n    effb3 = efn.EfficientNetB3(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    pt_depth = effb3.layers[-1].get_output_shape_at(0)[-1]\n    pt_features = effb3(img_inp)\n    bn_features = BatchNormalization()(pt_features)\n    \n    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n    \n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', \n                   use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n    \n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.25)(gap)\n    img_embed = Dense(2400, activation = 'swish', name='img-embed')(gap_dr)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([img_embed, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[img_inp, model_title.input, label], outputs=output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:54.055407Z","iopub.execute_input":"2021-06-15T03:06:54.055727Z","iopub.status.idle":"2021-06-15T03:06:54.14226Z","shell.execute_reply.started":"2021-06-15T03:06:54.055697Z","shell.execute_reply":"2021-06-15T03:06:54.141256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def incepV2(weights='imagenet'):\n    inceptionV2 = InceptionResNetV2(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    for layer in inceptionV2.layers:\n        layer.trainable = False\n        \n    model_image = Sequential([\n        inceptionV2,\n        GlobalAveragePooling2D(name='incep-pooling'),\n        BatchNormalization(name='incep_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='incep_dense1'),\n        Activation('swish', name='incep_act1'),\n    ], name='incep-img')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 70, input_length=100, name='title-embed'),\n#         GlobalAveragePooling1D(name='title-pooling'),\n        Flatten(name='title-flatten'),\n        BatchNormalization(name='title-bn1'),\n        Dropout(0.2),\n        Dense(650, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n#         Dropout(0.1),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    eff_aux = Model(\n        inputs = inceptionV2.input, \n        outputs = inceptionV2.get_layer('block17_7_mixed').output)\n    aux_model = Sequential([\n        eff_aux,\n        Conv2D(128, kernel_size=(3, 3), activation='relu', name='aux-conv1'),\n        BatchNormalization(name='aux-bn1'),\n        GlobalAveragePooling2D(name='aux-pooling'),\n        Dropout(0.5),\n        Dense(1024, name='aux-dense1'),\n        Activation('swish'),\n    ], name='aux-model')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.5, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    concatenate2 = Concatenate(name='concatenate2')([concatenate, aux_model.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate2, label])\n#     embeddings = Dense(3050, activation='swish', name='embedding')(concatenate)\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, aux_model.input, model_title.input, label], outputs=output)\n    return model\n\ndef incepV2_512_v3(weights='imagenet'):\n    inceptionV2 = InceptionResNetV2(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    model_image = Sequential([\n        inceptionV2,\n        GlobalAveragePooling2D(name='incep-pooling'),\n        BatchNormalization(name='incep_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='incep_dense1'),\n        Activation('swish', name='incep_act1'),\n    ], name='incep-img')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:55.488022Z","iopub.execute_input":"2021-06-15T03:06:55.488388Z","iopub.status.idle":"2021-06-15T03:06:55.508816Z","shell.execute_reply.started":"2021-06-15T03:06:55.488359Z","shell.execute_reply":"2021-06-15T03:06:55.50801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xception(weights='imagenet'):\n    xcep = Xception(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    for layer in xcep.layers:\n        layer.trainable = False\n        \n    model_image = Sequential([\n        xcep,\n        GlobalAveragePooling2D(name='incep-pooling'),\n        BatchNormalization(name='incep_bn1'),\n        Dropout(0.3),\n        Dense(2400, name='incep_dense1'),\n        Activation('swish', name='incep_act1'),\n    ], name='incep-img')\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 100, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    aux_model = Model(inputs=xcep.input, outputs=xcep.get_layer('block8_sepconv3_act').output)\n    aux_model = Sequential([\n        aux_model,\n        Conv2D(128, kernel_size=(3, 3), activation='relu', name='aux-conv1'),\n        BatchNormalization(name='aux-bn1'),\n        GlobalAveragePooling2D(name='aux-pooling'),\n        Dropout(0.5),\n        Dense(240, name='aux-dense1'),\n        Activation('swish'),\n    ])\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    concatenate2 = Concatenate(name='concatenate2')([concatenate, aux_model.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate2, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, aux_model.input, model_title.input, label], outputs=output)\n    return model\n\ndef xception_512_v3(weights='imagenet'):\n    xcep = Xception(weights=weights, include_top=False, input_shape=(*IMAGE_SIZE, 3))\n    \n    model_image = Sequential([\n        xcep,\n        GlobalAveragePooling2D(name='incep-pooling'),\n        BatchNormalization(name='incep_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='incep_dense1'),\n        Activation('swish', name='incep_act1'),\n    ], name='incep-img')\n        \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    \n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:55.699666Z","iopub.execute_input":"2021-06-15T03:06:55.699944Z","iopub.status.idle":"2021-06-15T03:06:55.717714Z","shell.execute_reply.started":"2021-06-15T03:06:55.699919Z","shell.execute_reply":"2021-06-15T03:06:55.716739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nfnet_f0(weights='gs://kds-b135c9e4ed7b978eb1b05abe18f78523f1fe076527cd1f64555bd7b1/NFNET-F0/F0_NFNet'):\n    nfnet_ = NFNet(\n        num_classes=1000,\n        variant='F0',\n        drop_rate=0.2,\n        label_smoothing=0.1,\n        ema_decay=0.99999,\n        clipping_factor=0.01,\n        include_top=False,\n    )\n    if weights is not None:\n        nfnet_.load_weights(weights)\n\n    model_image = Sequential([\n        nfnet_,\n        GlobalAveragePooling2D(name='effb1-pooling'),\n        BatchNormalization(name='effb1_bn1'),\n        Dropout(0.2),\n        Dense(2400, name='effb1_dense1'),\n        Activation('swish', name='effb1_act1'),\n    ], name='effb1-img')\n    model_image.build((None, *IMAGE_SIZE, 3))\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1, name='title-conv'),\n        GlobalMaxPool1D(name='title-globalMax'),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([model_image.output, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[model_image.input, model_title.input, label], outputs=output)\n    return model\n\ndef get_nfnet_f1(weights='gs://kds-1d6d6565dd2a34e7cc1a72d6d664184726bc52e3022d6010d9f9b173/NFNET-F1/F1_NFNet'):\n    \n    img_inp = Input(shape=(*IMAGE_SIZE, 3))\n    nfnet_ = NFNet(\n        num_classes=1000,\n        variant='F1',\n        drop_rate=0.2,\n        label_smoothing=0.1,\n        ema_decay=0.99999,\n        clipping_factor=0.01,\n        include_top=False,\n    )\n    if weights is not None:\n        nfnet_.load_weights(weights)\n    \n    pt_depth = 3072\n    pt_features = nfnet_(img_inp)\n    bn_features = BatchNormalization()(pt_features)\n    \n    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n    \n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', \n                   use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n    \n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.25)(gap)\n    img_embed = Dense(2400, activation = 'swish', name='img-embed')(gap_dr)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1, name='title-conv'),\n        GlobalMaxPool1D(name='title-globalMax'),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n\n    concatenate = Concatenate(name='concatenate')([img_embed, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[img_inp, model_title.input, label], outputs=output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:56.913495Z","iopub.execute_input":"2021-06-15T03:06:56.913798Z","iopub.status.idle":"2021-06-15T03:06:56.937951Z","shell.execute_reply.started":"2021-06-15T03:06:56.91377Z","shell.execute_reply":"2021-06-15T03:06:56.936753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bert model","metadata":{}},{"cell_type":"code","source":"bert_model = '../input/bert-base-uncased-220421/bert_base'\n\ndef get_bert_model(mname):\n    \n    idx = layers.Input((105), dtype=\"int32\", name=\"input_idx\")\n    masks = layers.Input((105), dtype=\"int32\", name=\"input_masks\")\n    \n    nlp = transformers.TFBertModel.from_pretrained(mname)\n    bert_out= nlp([idx, masks])[0]\n    \n    ## fine-tuning\n    x = layers.GlobalAveragePooling1D()(bert_out)\n    x = layers.Dense(750, activation=\"swish\", name='text-embed')(x)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 100, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n    \n    concatenate = Concatenate(name='concatenate')([x, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    \n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n\n    # Compile model\n    model = tf.keras.Model(inputs=[idx, masks, model_title.input, label], outputs=[output])\n    return model\n\nxlm_model_base = '../input/tf-xlm-roberta-base'\ndef xlm_roberta(mname):\n    \n    idx = layers.Input((105), dtype=\"int32\", name=\"input_idx\")\n    masks = layers.Input((105), dtype=\"int32\", name=\"input_masks\")\n    \n#     nlp = TFAutoModel.from_pretrained(mname)\n    nlp = transformers.TFXLMRobertaModel.from_pretrained(mname)\n    bert_out= nlp([idx, masks])[0]\n    \n    ## fine-tuning\n    x = layers.GlobalAveragePooling1D()(bert_out)\n    x = layers.Dense(750, activation=\"swish\", name='text-embed')(x)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.5, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n    \n    concatenate = Concatenate(name='concatenate')([x, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[idx, masks, model_title.input, label], outputs=[output])\n    \n    return model\n\nroberta_base_id_model = '../input/tfroberta-base-indonesian/roberta-base-indonesian-522M'\ndef get_roberta_base_id(mname = roberta_base_id_model):\n    \n    idx = layers.Input((105), dtype=\"int32\", name=\"input_idx\")\n    masks = layers.Input((105), dtype=\"int32\", name=\"input_masks\")\n    \n    nlp = TFAutoModel.from_pretrained(mname)\n    bert_out= nlp([idx, masks])[0]\n    \n    ## fine-tuning\n    x = layers.GlobalAveragePooling1D()(bert_out)\n    x = layers.Dense(750, activation=\"swish\", name='text-embed')(x)\n    \n    model_title = Sequential([\n        Input(shape=(100,), name='title-input'),\n        Embedding(25000, 150, input_length=100, name='title-embed'),\n        Dropout(0.2),\n        Conv1D(300, 3, padding='valid', activation='relu', strides=1),\n        GlobalMaxPool1D(),\n        Dense(720, name='title-dense1'), #650 -> 0.81\n        Activation('swish', name='title-act1'),\n        Dropout(0.2),\n        \n        Dense(650, name='title-dense2'),\n        BatchNormalization(name='title-bn2'),\n        Activation('swish', name='title-act2'),\n    ], name='title-vec')\n    \n    margin = ArcMarginProduct(\n        n_classes = CLASSES, \n        s = 30, \n        m = 0.7, \n        name='head/arc_margin', \n        dtype='float32'\n    )\n    \n    concatenate = Concatenate(name='concatenate')([x, model_title.output])\n    label = Input(shape=(), name='arc-input')\n    arc_face = margin([concatenate, label])\n    output = Dense(CLASSES, activation='softmax', name='output')(arc_face)\n    \n    model = Model(inputs=[idx, masks, model_title.input, label], outputs=[output])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:06:58.876323Z","iopub.execute_input":"2021-06-15T03:06:58.876638Z","iopub.status.idle":"2021-06-15T03:06:58.902544Z","shell.execute_reply.started":"2021-06-15T03:06:58.876609Z","shell.execute_reply":"2021-06-15T03:06:58.901552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Help functions to get embeddings and predictions","metadata":{}},{"cell_type":"code","source":"def get_image_embeddings(model):\n    preds = []\n    chunk = 5000\n    iterator = np.arange(np.ceil(len(df)/chunk))\n    for j in iterator:\n        a = int(j * chunk)\n        b = int((j+1) * chunk)\n        img_paths, input_ids, att_mask, title_vec = read_dataset(df.iloc[a:b])\n        image_dataset = get_dataset(img_paths, title_vec)\n        img_embeddings = model.predict(image_dataset)\n        preds.append(img_embeddings)\n    del model, img_paths, title_vec\n    img_embeddings = np.concatenate(preds)\n    del preds\n    return img_embeddings\n\ndef get_text_embeddings(model):\n    preds = []\n    chunk = 5000\n    iterator = np.arange(np.ceil(len(df)/chunk))\n    for j in iterator:\n        a = int(j * chunk)\n        b = int((j+1) * chunk)\n        img_paths, input_ids, att_mask, title_vec = read_dataset(df.iloc[a:b])\n        image_dataset = get_text_dataset(input_ids, att_mask, title_vec)\n        img_embeddings = model.predict(image_dataset)\n        preds.append(img_embeddings)\n    del model, img_paths, title_vec\n    img_embeddings = np.concatenate(preds)\n    del preds\n    return img_embeddings\n\ndef get_neighbors(embeddings, KNN=50):\n    KNN = 50 if len(embeddings)>3 else 3\n        \n    model = NearestNeighbors(n_neighbors=KNN, metric = 'correlation')\n    nearest_model = model.fit(embeddings)\n    distances, indices = nearest_model.kneighbors(embeddings)\n\n    return distances, indices\n\ndef get_predictions(number_of_embeds, distances, indices, th=40):\n    # get predictions\n    predictions = []\n    for k in range(number_of_embeds):\n        idx = np.where(distances[k,] < th)[0]\n        ids = indices[k, idx]\n        posting_ids = np.unique(df['posting_id'].iloc[ids].values)\n        predictions.append(posting_ids)\n        \n    for th1 in np.arange(th, th+0.3, 0.02):\n        for k in range(number_of_embeds):\n            if len(predictions[k]) <= 1:\n                idx = np.where(distances[k,] < th1)[0]\n                ids = indices[k, idx]\n                posting_ids = np.unique(df['posting_id'].iloc[ids].values)\n                predictions[k] = np.concatenate([predictions[k], posting_ids])\n                predictions[k] = np.unique(predictions[k])\n            \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:07:00.969836Z","iopub.execute_input":"2021-06-15T03:07:00.970174Z","iopub.status.idle":"2021-06-15T03:07:00.984209Z","shell.execute_reply.started":"2021-06-15T03:07:00.970141Z","shell.execute_reply":"2021-06-15T03:07:00.983328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get model choices","metadata":{}},{"cell_type":"code","source":"def get_model(weight_path, model_name):\n    if model_name == 'effb1':\n        model = effb1(weights=None)\n        for layer in model.get_layer('efficientnet-b1').layers[-170:]:\n            if not isinstance(layer, layers.BatchNormalization):\n                layer.trainable = True\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[2]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb1_512_v2':\n        model = effb1_512_v2(weights=None)\n        for layer in model.get_layer('efficientnet-b1').layers[-170:]:\n            if not isinstance(layer, layers.BatchNormalization):\n                layer.trainable = True\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[2]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb1_512_v3':\n        model = effb1_512_v3(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb1_244_v4':\n        model = effb1_244_v4(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb2':\n        model = effb2(weights=None)\n        for layer in model.get_layer('efficientnet-b2').layers[-190:]:\n            if not isinstance(layer, layers.BatchNormalization):\n                layer.trainable = True\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0]], outputs=model.get_layer('effb1_act1').output)\n    elif model_name == 'effb3':\n        model = effb3(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb5':\n        model = effb5(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb5_v2':\n        model = effb5_v2(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'effb7':\n        model = effb7(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0]], outputs=model.get_layer('img-embed').output)\n    elif model_name == 'effb7_v2':\n        model = effb7_v2(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'incepv2':\n        model = incepV2(weights=None)\n        for layer in model.get_layer('inception_resnet_v2').layers[-380:]:\n            if not isinstance(layer, layers.BatchNormalization):\n                layer.trainable = True\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[2]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'incepV2_512_v3':\n        model = incepV2_512_v3(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'xception':\n        model = xception_512(weights=None)\n        for layer in model.get_layer('xception').layers[-80:]:\n            if not isinstance(layer, layers.BatchNormalization):\n                layer.trainable = True\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[2]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'xception_512_v3':\n        model = xception_512_v3(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'nfnet_f0':\n        model = get_nfnet_f0(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'nfnet_f1':\n        model = get_nfnet_f1(weights=None)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1]], outputs=model.get_layer('concatenate').output)\n    elif model_name == 'bert':\n        model = get_bert_model(bert_model)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1], model.input[2]], \n                      outputs=model.get_layer('concatenate').output)\n    elif model_name == 'xlm-roberta':\n        model = xlm_roberta(xlm_model_base)\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1], model.input[2]], \n                      outputs=model.get_layer('concatenate').output) \n    elif model_name == 'roberta_base_id':\n        model = get_roberta_base_id()\n        model.load_weights(weight_path)\n        model = Model(inputs=[model.input[0], model.input[1], model.input[2]], \n                      outputs=model.get_layer('concatenate').output) \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:07:03.96894Z","iopub.execute_input":"2021-06-15T03:07:03.969295Z","iopub.status.idle":"2021-06-15T03:07:03.999477Z","shell.execute_reply.started":"2021-06-15T03:07:03.969262Z","shell.execute_reply":"2021-06-15T03:07:03.998587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image predictions","metadata":{}},{"cell_type":"code","source":"model_weights = [\n    ('../input/shopee-effb3-512/model_weights.h5', 'effb3', 0.35, (512, 512), False),\n    ('../input/shopee-effb5-512-v2/model_weights.h5', 'effb5_v2', 0.35, (512, 512), False),\n    ('../input/shopee-nfnet-512/model_weights.h5', 'nfnet_f0', 0.35, (512, 512), False),\n    ('../input/shopee-nfnet-f1-512/model_weights.h5', 'nfnet_f1', 0.35, (512, 512), False),\n]\n\nuse_weight = False\nimg_predictions = []\nimg_embeds_avg = []\nfor n, (weight_path, model_name, th, img_size, only_img) in enumerate(model_weights):\n    print(f'Get predictions of model {n}')\n    CLASSES = [11014, 11014, 11014, 11014, 11014][n] \n    IMAGE_SIZE = img_size\n    ONLY_IMAGE = only_img\n    model = get_model(weight_path, model_name)\n    # get image embeds\n    img_embed = get_image_embeddings(model)\n    del model\n\n    # scale embedding\n    scaler = StandardScaler()\n    img_embed = scaler.fit_transform(img_embed)\n\n    if use_weight:\n        weights = [1, 1, 1, 1, 1]\n        img_embeds_avg.append(img_embed)\n        del img_embed, scaler\n    else:\n        # get neighbors\n        distances, indices = get_neighbors(img_embed)\n\n        # get predictions\n        preds = get_predictions(img_embed.shape[0], distances, indices, th=th)\n        img_predictions.append(preds)\n\n        del distances, indices, img_embed, preds, scaler\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:11:19.850195Z","iopub.execute_input":"2021-06-15T03:11:19.850522Z","iopub.status.idle":"2021-06-15T03:12:29.612085Z","shell.execute_reply.started":"2021-06-15T03:11:19.850494Z","shell.execute_reply":"2021-06-15T03:12:29.611345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_weight:\n    img_embeds_avg = np.concatenate([\n        img_embeds_avg[0], \n        img_embeds_avg[1], \n        img_embeds_avg[2], \n        img_embeds_avg[3],\n    ], axis=1)\n    distances, indices = get_neighbors(img_embeds_avg)\n    preds = get_predictions(img_embeds_avg.shape[0], distances, indices, th=0.35)\n    img_predictions.append(preds)\n    del img_embeds_avg\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:12:29.613698Z","iopub.execute_input":"2021-06-15T03:12:29.613952Z","iopub.status.idle":"2021-06-15T03:12:29.818572Z","shell.execute_reply.started":"2021-06-15T03:12:29.613928Z","shell.execute_reply":"2021-06-15T03:12:29.817585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text predictions","metadata":{}},{"cell_type":"code","source":"text_predictions = []\nbert_predictions = []\ntxt_embeds_avg = []\n\n# for roberta base indonesian\n# extract vocab from train data\ndf = pd.read_csv('../input/shopee-product-matching/train.csv')\n    \ndf['title'] = df['title'].apply(lambda x: remove_concatenate_2_words(x))\ndf['title'] = df['title'].str.lower()\ndf['title'] = df['title'].apply(lambda x: remove_punctuation(x))\ndf['title'] = df['title'].apply(lambda x: str(x).split())\ndf['title'] = df['title'].apply(lambda x: remove_stopwords(x))\ndf['title'] = df['title'].apply(lambda x: remove_zero_val(x))\ndf['title'] = df['title'].apply(lambda x: remove_strange_words(x))\ndf['title'] = df['title'].apply(lambda x: list(np.unique(x)))\n\n# title vocab\nwords = list(df['title'])\ntrain_vocab = list(np.unique(np.concatenate(words)))\n\ndf = pd.read_csv('../input/shopee-product-matching/test.csv')\ndf['tmp'] = df['title'].apply(lambda x: string_escape(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_concatenate_2_words(x))\ndf['tmp'] = df['tmp'].str.lower()\ndf['tmp'] = df['tmp'].apply(lambda x: remove_punctuation(x))\ndf['tmp'] = df['tmp'].apply(lambda x: str(x).split())\ndf['tmp'] = df['tmp'].apply(lambda x: remove_stopwords(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_zero_val(x))\ndf['tmp'] = df['tmp'].apply(lambda x: remove_strange_words(x))\ndf['tmp'] = df['tmp'].apply(lambda x: list(np.unique(x)))\n\n# for mlp input\n# title vocab\nwords = list(df['tmp'])\nwords = list(np.unique(np.concatenate(words)))\nwords = train_vocab + words\n\n# Text vectorizer\nmodel = text_vectorizer(max_features = 25000, max_len = 100, vocab = words)\nlist_text = [' '.join(x) for x in df['tmp']]\ntitle_vec = model.predict(list_text)\ndf['title_vec'] = list(title_vec)\ndel model, list_text, title_vec, words, train_vocab\n\nMAX_LEN = 105\nMODEL = '../input/tfroberta-base-indonesian/roberta-base-indonesian-522M'\ntokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)\n\ndf['tmp'] = df['title'].apply(lambda x: string_escape(x))\ndf[\"tmp\"] = df[\"tmp\"].apply(lambda x: utils_preprocess_text(\n    x, flg_stemm=False, flg_lemm=False, lst_stopwords=None))\n\n# for BERT\nids, att_mask = regular_encode(list(df[\"tmp\"].values), tokenizer, maxlen=MAX_LEN)\ndf['input_ids'] = list(ids)\ndf['att_mask'] = list(att_mask)\ndel ids, att_mask\n\n# bad, decrease the LB\nmodel_weights = [\n    ('../input/shopee-roberta-base-id/model_weights.h5', 'roberta_base_id', 0.50)\n]\n\nfor n, (weight_path, model_name, th) in enumerate(model_weights):\n    print(f'Get predictions of model {n}')\n    CLASSES = [11014, 11014, 11014][n] \n    model = get_model(weight_path, model_name)\n    # get text embeds\n    txt_embed = get_text_embeddings(model)\n    del model\n\n    # scale embedding\n    scaler = StandardScaler()\n    txt_embed = scaler.fit_transform(txt_embed)\n    txt_embeds_avg.append(txt_embed)\n    \n    del txt_embed, scaler\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:14:01.903828Z","iopub.execute_input":"2021-06-15T03:14:01.904182Z","iopub.status.idle":"2021-06-15T03:14:24.725668Z","shell.execute_reply.started":"2021-06-15T03:14:01.904135Z","shell.execute_reply":"2021-06-15T03:14:24.724944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"txt_embeds_avg = np.concatenate([\n    txt_embeds_avg[0], \n], axis=1)\ndistances, indices = get_neighbors(txt_embeds_avg)\npreds = get_predictions(txt_embeds_avg.shape[0], distances, indices, th=0.50)\ntext_predictions.append(preds)\ndel txt_embeds_avg\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:14:24.727262Z","iopub.execute_input":"2021-06-15T03:14:24.727526Z","iopub.status.idle":"2021-06-15T03:14:25.085481Z","shell.execute_reply.started":"2021-06-15T03:14:24.7275Z","shell.execute_reply":"2021-06-15T03:14:25.084465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TFIDF predictions","metadata":{}},{"cell_type":"code","source":"def get_text_predictions(df, title_cu, max_features = 25_000):\n    \n    text_preds = []\n    for stopw in ['english', STOPWORDS_ID]:\n        model = TfidfVectorizer(stop_words = stopw, binary = True, max_features = max_features)\n        text_embeddings = model.fit_transform(title_cu).toarray()\n\n        preds = []\n        CHUNK = 1024*4\n\n        print('Finding similar titles...')\n        CTS = len(df)//CHUNK\n        if len(df)%CHUNK!=0: CTS += 1\n        for j in range( CTS ):\n\n            a = j*CHUNK\n            b = (j+1)*CHUNK\n            b = min(b,len(df))\n            print('chunk',a,'to',b)\n\n            # COSINE SIMILARITY DISTANCE\n            cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n\n            for k in range(b-a):\n                IDX = cupy.where(cts[k,] > 0.75)[0]\n                o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n                preds.append(o)\n                \n        text_preds.append(preds)\n        del model,text_embeddings, preds\n        gc.collect()\n    return text_preds\n\ndef string_escape(s, encoding='utf-8'):\n    return (\n        s.encode('latin1')  # To bytes, required by 'unicode-escape'\n        .decode('unicode-escape')  # Perform the actual octal-escaping decode\n        .encode('latin1')  # 1:1 mapping back to bytes\n        .decode(encoding)\n    )  # Decode original encoding\n\ndf = pd.read_csv('../input/shopee-product-matching/test.csv')\ndf['title'] = df['title'].apply(lambda x: string_escape(x))\ndf['title'] = df['title'].apply(lambda x: remove_punctuation(x))\n\ntitle_cu = cudf.Series(df['title'])\ntext_predictions = text_predictions + (get_text_predictions(df, title_cu, max_features = 25000))\ndel title_cu\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:14:30.121024Z","iopub.execute_input":"2021-06-15T03:14:30.121392Z","iopub.status.idle":"2021-06-15T03:14:44.95697Z","shell.execute_reply.started":"2021-06-15T03:14:30.12136Z","shell.execute_reply":"2021-06-15T03:14:44.956208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Combine predictions (Image + BertText + TFIDF)","metadata":{}},{"cell_type":"code","source":"def combine_predictions(row):\n    all_preds = []\n    res = []\n    if len(img_predictions)>0:\n        for i in range(len(img_predictions)):\n            all_preds.append(row[f'img_prediction_{i}'])\n        x = np.concatenate(all_preds)\n\n        # remove item if item count less than 1\n        c = Counter(x)\n        res = np.array([i for i in x if c[i] >= 3])\n        del x\n    \n    # text preds\n    txt_pred=[]\n    if len(text_predictions) > 0:\n        all_preds = []\n        for i in range(len(text_predictions)):\n            all_preds.append(row[f'text_prediction_{i}'])\n        x = np.concatenate(all_preds)\n\n        # remove item if item count less than 1\n        c = Counter(x)\n        txt_pred = np.array([i for i in x if c[i] >= 2])\n        del x, c\n    y=[]\n    if len(bert_predictions) > 0:\n        all_preds = []\n        for i in range(len(bert_predictions)):\n            all_preds.append(row[f'bert_prediction_{i}'])\n        y = np.concatenate(all_preds)\n    del all_preds\n    res = [res, txt_pred, y]\n    res = np.concatenate(res)\n    del txt_pred, y\n    \n    if GET_CV:\n        return np.unique(res)\n    else:\n        return ' '.join( np.unique(res) )","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:14:50.078499Z","iopub.execute_input":"2021-06-15T03:14:50.078813Z","iopub.status.idle":"2021-06-15T03:14:50.09063Z","shell.execute_reply.started":"2021-06-15T03:14:50.078784Z","shell.execute_reply":"2021-06-15T03:14:50.089876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make submission","metadata":{}},{"cell_type":"code","source":"for n, prediction in enumerate(img_predictions):\n    df[f'img_prediction_{n}'] = prediction\nfor n, prediction in enumerate(bert_predictions):\n    df[f'bert_prediction_{n}'] = prediction\nfor n, prediction in enumerate(text_predictions):\n    df[f'text_prediction_{n}'] = prediction\ndf['matches'] = df.apply(combine_predictions, axis=1)\ndf = df[['posting_id', 'matches']]\ndf.to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:14:51.980692Z","iopub.execute_input":"2021-06-15T03:14:51.981002Z","iopub.status.idle":"2021-06-15T03:14:52.147036Z","shell.execute_reply.started":"2021-06-15T03:14:51.980971Z","shell.execute_reply":"2021-06-15T03:14:52.146288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('./submission.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T03:14:53.913516Z","iopub.execute_input":"2021-06-15T03:14:53.91386Z","iopub.status.idle":"2021-06-15T03:14:53.931487Z","shell.execute_reply.started":"2021-06-15T03:14:53.913828Z","shell.execute_reply":"2021-06-15T03:14:53.930805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}