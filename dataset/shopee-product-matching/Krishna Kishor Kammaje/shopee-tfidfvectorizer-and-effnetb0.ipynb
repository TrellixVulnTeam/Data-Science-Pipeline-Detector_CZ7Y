{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Thanks to: https://www.kaggle.com/cdeotte/rapids-cuml-tfidfvectorizer-and-knn","metadata":{}},{"cell_type":"code","source":"import cudf, cuml, cupy\nimport cv2\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport pandas as pd\nimport textwrap","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install git+https://github.com/jmcarpenter2/swifter.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\n\n# RESTRICT TENSORFLOW TO 12GB OF GPU RAM\n# SO THAT WE HAVE GPU RAM FOR RAPIDS CUML KNN\nLIMIT = 12\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('Restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('so RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phase = 'train'\n# phase = 'test'\nBASE = f'../input/shopee-product-matching/{phase}_images/'\ntrain = pd.read_csv(f\"../input/shopee-product-matching/{phase}.csv\")\ntrain_gf = cudf.read_csv(f\"../input/shopee-product-matching/{phase}.csv\")\nWGT = '../input/effnetb0/efficientnetb0_notop.h5'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = 50\nif train.shape[0] == 3:\n    KNN = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# samples = train.sample(9)                    \n# fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(16, 20))\n# count=0\n# for row in ax:\n#     for col in row:\n#         col.imshow(plt.imread('../input/shopee-product-matching/test_images/'+samples.iloc[count]['image']))\n#         col.set_title('\\n'.join(textwrap.wrap(samples.iloc[count]['title'], 35)))\n#         count += 1\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Similarity in title only","metadata":{}},{"cell_type":"code","source":"model = TfidfVectorizer(stop_words='english', binary=True)\ntext_embeddings = model.fit_transform(train_gf.title).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NearestNeighbors(n_neighbors=KNN)\n\n#Unsupervised learning finding k nearest neighbours for each row\nmodel.fit(text_embeddings)\n\n#Distances has the distances and corresponding indices are in indices\ndistances, text_indices = model.kneighbors(text_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Let us check the result\n# for i in range(5):\n#     print(train_gf.iloc[text_indices[i, 0:5]][['title']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Similarity in Images","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=BASE): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get embeddings for each image (for comparing)","metadata":{}},{"cell_type":"code","source":"model = EfficientNetB0(weights=WGT, include_top=False, pooling='avg', input_shape=None)\ntrain_gen = DataGenerator(train, batch_size=128)\nimage_embeddings = model.predict(train_gen,verbose=1)\nimage_embeddings.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#49 neighbors\nmodel = NearestNeighbors(n_neighbors=KNN)\n#Unsupervised learning finding k nearest neighbours for each row\nmodel.fit(image_embeddings)\n#Distances has the distances and corresponding indices are in indices\ndistances, image_indices = model.kneighbors(image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# indices_df = pd.DataFrame(image_indices)\n# samples = indices_df.sample(9)                    \n# fig, ax = plt.subplots(nrows=9, ncols=4, figsize=(26, 80))\n# line=0\n# for row in ax:\n#     column=0\n#     for col in row:\n#         item = train.iloc[samples.iloc[line:line+1, column:column+1].values[0][0]]\n#         col.imshow(plt.imread('../input/shopee-product-matching/train_images/'+item['image']))\n#         col.set_title('\\n'.join(textwrap.wrap(item['title'], 35)))\n#         column += 1\n#     line += 1\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['posting_id'] = train['posting_id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = np.hstack((image_indices, text_indices.get()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_text(x, len=50):\n    x = np.unique(x)\n    if x.shape[0] < 50: len = x.shape[0]\n    return ' '.join(train.iloc[x]['posting_id'].values[0:len])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = np.apply_along_axis(get_top_text, 1, indices )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['matches'] = l\n# submission['matches'] = matchFunction(indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}