{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RESNET 50\n\n## References \n1. https://www.kaggle.com/parthdhameliya77/pytorch-resnext50-32x4d-image-tfidf-inference\n2. https://www.kaggle.com/karthur10/resnet-sbert-unsupervised-baseline\n","metadata":{}},{"cell_type":"markdown","source":"## Importing required libraries like torch, cuml, cv2, cudf etc","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cupy, cudf\nimport gc\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\nimport random\nimport torch\nimport torchvision\nfrom torchvision import  models, transforms\nfrom transformers import BertTokenizer, BertModel\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nimport glob\nfrom PIL import Image\nimport seaborn as sns\nimport cv2, matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom textwrap import wrap","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Test and Train Image Data","metadata":{}},{"cell_type":"code","source":"device = 'cuda'if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/shopee-product-matching/'\nPATH_TO_IMG = '../input/shopee-product-matching/train_images/'\nPATH_TO_TEST = '../input/shopee-product-matching/test_images/'\nos.listdir(PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV = True\nif len(pd.read_csv(PATH + 'test.csv')) > 3: COMPUTE_CV = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    dataset = pd.read_csv(PATH + 'train.csv')\n    tmp = dataset.groupby('label_group').posting_id.agg('unique').to_dict()\n    dataset['target'] = dataset.label_group.map(tmp)\nelse:    \n    dataset = pd.read_csv(PATH + 'test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display Random Images using CV2","metadata":{}},{"cell_type":"code","source":"def show_random_img():\n    # choose randomly two instances per each class\n    labels_to_show = np.random.choice(dataset.label_group.unique(), \n                                      replace=False, size=24)\n    img_to_show = []\n    for label in labels_to_show:\n        rows = dataset[dataset.label_group==label].copy()\n        pair = np.random.choice([i for i in range(len(rows))], \n                                    replace=False, size=2)\n        img_pair = rows.iloc[pair][['image', 'title']].values\n        \n        img_to_show += list(img_pair)\n    \n    fig, axes = plt.subplots(figsize = (18, 12), nrows=4,ncols=6)\n    for imp, ax in zip(img_to_show, axes.ravel()):\n        img = cv2.imread(PATH_TO_IMG + imp[0])\n        title = '\\n'.join(wrap(imp[1], 20))\n        ax.set_title(title)\n        ax.imshow(img)\n        ax.axis('off')\n\n    fig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    show_random_img()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50 block with tranform using Pretrained model,","metadata":{}},{"cell_type":"code","source":"class ResNetEmbedder(nn.Module):\n    \n    def __init__(self, device='cpu'):\n        super(ResNetEmbedder, self).__init__()\n        self.model = models.resnet50(pretrained=False)\n        self.device = device\n        path = '../input/pretrained-model-weights-pytorch/resnet50-19c8e357.pth'\n        self.model.load_state_dict(torch.load(path))\n#         to freeze weights\n        for param in self.model.parameters():\n                param.requires_grad = False\n        self.model.to(device)\n        \n    \n    def transform(self, img):\n        image_transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.Resize(256),\n                transforms.CenterCrop(224),\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize(\n                    mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)\n                ),\n            ]\n        )\n        return image_transform(img)\n    \n    def forward(self, img):\n        img_tr = self.transform(img).unsqueeze(0)\n        img_tr = img_tr.to(self.device)\n        features = self.model(img_tr).squeeze()\n        return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_img = ResNetEmbedder(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorize_img(img_path):\n    img = Image.open(img_path).convert('RGB')\n    model_img.eval()\n    with torch.no_grad():\n        output = model_img(img).cpu().numpy()\n    return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif COMPUTE_CV:\n    dataset['resnet_v'] = dataset['image'].progress_apply(lambda x: vectorize_img(PATH_TO_IMG + x))\nelse:\n    dataset['resnet_v'] = dataset['image'].progress_apply(lambda x: vectorize_img(PATH_TO_TEST + x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing the vectors","metadata":{}},{"cell_type":"code","source":"vectors = np.stack(dataset.resnet_v)\nvectors = torch.Tensor(vectors).to(device)\nvectors = F.normalize(vectors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding similar titles in chunks of 1024","metadata":{}},{"cell_type":"code","source":"preds = []\nCHUNK = 1024\n\nprint('Finding similar titles...')\nCTS = len(dataset)//CHUNK\nif len(dataset)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(dataset))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = torch.matmul( vectors, vectors[a:b].T).T\n    cts = cts.cpu().numpy()\n    \n    for k in range(b-a):\n        IDX = np.where(cts[k,]>0.9)[0]\n        o = dataset.iloc[IDX].posting_id.values\n        preds.append(o)\n\ndel vectors, cts, IDX, o\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions and computation of F1 score","metadata":{}},{"cell_type":"code","source":"dataset['preds_resnet'] = preds\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['f1_resnet'] = dataset.apply(getMetric('preds_resnet'), axis=1)\n    print('F1 Score =', dataset.f1_resnet.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}