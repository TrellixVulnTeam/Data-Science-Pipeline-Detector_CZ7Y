{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nSUBMIT = False\n\nif SUBMIT:\n    train = pd.read_csv('../input/shopee-product-matching/test.csv', usecols=[\"posting_id\", \"title\"])\nelse:\n    train = pd.read_csv('../input/shopee-product-matching/train.csv', usecols=[\"posting_id\", \"title\", \"label_group\"])\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\n\ntitle = train['title'].apply(lambda s : s.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))))\n\ntfidf_vec = TfidfVectorizer(stop_words='english', \n                            binary=True,\n                            max_features=30000)\ntext_embeddings = tfidf_vec.fit_transform(title).toarray().astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntext_tensor = torch.from_numpy(text_embeddings).to(device)\n\nout_preds = []\nchunk = 64\nfor i in tqdm(list(range(0, train.shape[0], chunk)) + [train.shape[0]-chunk]):\n    arr = text_tensor[i : i + chunk] @ text_tensor.T\n\n    indices = torch.nonzero(arr > 0.525)\n\n    preds = dict()\n    for k in range(arr.shape[0]):\n        preds[k] = []\n    for ind in range(indices.size(0)):\n        preds[indices[ind, 0].item()].append(indices[ind, 1].item())\n\n    out_preds.extend([(train.iloc[k].posting_id, train.iloc[v].posting_id.tolist()) for k, v in preds.items()])\n\nout_preds = out_preds[:train.shape[0]]\ndf = pd.DataFrame(out_preds, columns=[\"index\",\"pred\"])\ndf.set_index(\"index\")\n\nif not SUBMIT:\n    df[\"true\"] = train[\"target\"]\n\n    f1 = []\n    for index, row in df[[\"true\", \"pred\"]].iterrows():\n        f1.append((2 * len(set(row[\"true\"]) & set(row[\"pred\"])))/(len(row[\"true\"]) + len(row[\"pred\"])))\n\n    print(f'F1: {np.mean(f1)}')\nelse:\n    df[\"posting_id\"] = train[\"posting_id\"]\n    df[\"matches\"] = df[\"pred\"].apply(lambda x : \" \".join(x))\n    df[['posting_id','matches']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}