{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Triplet Loss Pytorch\n\nIn this notebook I demonstrate how to train a Siamese Net with Triplet Loss. I use automatic mixed presicion to speed up training.  \n\nTriplet loss requires anchors, positives and negatives examples. This notebook demonstrates how to prepare the dataset: https://www.kaggle.com/njelicic/tripletloss-pytorch-data-preparation\n\nInference: WIP\n\n**Room for improvement:**\n* Larger sample size\n* Larger model \n* Longer training\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SAMPLE_SIZE = 1000 # Due to long GPU runtime, this notebook only demonstrates training on a handfull of examples","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom tqdm.notebook import tqdm\nimport numpy as np \nimport pandas as pd \nimport sqlite3\nimport warnings\nimport cv2\nwarnings.filterwarnings(\"ignore\")\nimport concurrent\nimport os\n\ntorch.cuda.empty_cache()\n\ntorch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anchor_pos_neg = pd.read_csv('../input/tripletloss-pytorch-data-preparation/anchor_pos_neg.csv').sample(SAMPLE_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_name = '/kaggle/input/timm-pretrained-mobilenetv3/mobilenetv3/mobilenetv3_large_100_ra-f55367f5.pth'\n\nmodel = timm.create_model('mobilenetv3_large_100', pretrained=False)\n\nmodel.load_state_dict(torch.load(file_name))\n\nmodel.reset_classifier(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n\n\n\ntransform = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                transforms.Normalize(\n                                    mean=torch.tensor(IMAGENET_DEFAULT_MEAN),\n                                    std=torch.tensor(IMAGENET_DEFAULT_STD)),\n                                transforms.RandomErasing()\n                               ])\n\ndef load_image(file_name):\n    file_path = f'/kaggle/input/shopee-product-matching/train_images/{file_name}'\n\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (224, 224))\n    tensor_img = torch.tensor(img)\n    tensor_img = tensor_img.permute(( 2, 0, 1)).float()\n    tensor_img = transform(tensor_img)\n    return tensor_img\n    \nclass TrainDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.anchor = df['anchor'].values\n        self.positive = df['positive'].values\n        self.negative = df['negative'].values\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        anchor = self.anchor[idx]\n        positive = self.positive[idx]\n        negative = self.negative[idx]\n        \n        anchor = load_image(anchor)\n        positive = load_image(positive)\n        negative = load_image(negative)\n\n\n        \n        return anchor, positive, negative","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.anchor = df['anchor'].values\n\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        anchor = self.anchor[idx]\n        anchor = load_image(anchor)\n        return anchor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TrainDataset(anchor_pos_neg)\ntrain_loader = DataLoader(train_dataset,\n                         batch_size=200,\n                         shuffle=True,\n                         num_workers=4,\n                         pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.TripletMarginWithDistanceLoss(distance_function=nn.CosineSimilarity())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs =10\nmodel.train()\n\nscaler = torch.cuda.amp.GradScaler()\n\nfor epoch in tqdm(range(epochs), desc=\"Epochs\"):\n    running_loss = []\n    for step, (anchor_img, positive_img, negative_img) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n        anchor_img = anchor_img.to(device)\n        positive_img = positive_img.to(device)\n        negative_img = negative_img.to(device)\n        \n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast():\n            anchor_out = model(anchor_img)\n            positive_out = model(positive_img)\n            negative_out = model(negative_img)\n        \n            loss = criterion(anchor_out, positive_out, negative_out)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        \n        running_loss.append(loss.cpu().detach().numpy())\n    \n    print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss)))\ntorch.save(model, './pretrained-model.pt')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}