{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How does the Data look like? ðŸ—ƒ\nSo, the data provided to us in this competition consists of 3 .csv files and 2 folders (training_images and testing_images).\n\nBelow is the breakdown of the .csv files and image folders;\n\n* **ðŸ“„ train.csv** - This is the Training set metadata. Each row contains the data for a single posting. Multiple postings might have the exact same image ID, but with different titles or vice versa.\n* **ðŸ“„ test.csv** - Same as train.csv except the label_group column. This file will be what we are going to use at inference time. Currently it only consists of 3 samples but it will be replaced by a bigger private test set at submission time.\n* **ðŸ“„ sample_submission.csv **- The Sample submission file in the format we are expected to follow.\n* **ðŸ“‚ train_images/** - Folder with all the training images.\n* **ðŸ“‚ test_images/ **- Folder with all the testing images (again, only 4 images for now, but will be around ~70,000 images during submission)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nimport glob\nimport random\nfrom wordcloud import WordCloud, STOPWORDS\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\ntrain_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\ntest_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's find out how many images are under the directory\ntotal_train_files = glob.glob(\"../input/shopee-product-matching/train_images/*.jpg\")\ntotal_test_files = glob.glob(\"../input/shopee-product-matching/test_images/*.jpg\")\n\nprint(f\"Total Training Images: {len(total_train_files)}\")\nprint(f\"Total Testing Images: {len(total_test_files)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's figure out the unique number for each columns.\nfor col in train_file.columns:\n    print(col + \":\" + str(len(train_file[col].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file.nunique().to_frame().rename(columns={0:\"Unique Values\"}).style.background_gradient(cmap=\"plasma\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing values in the training data\ntrain_file.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Image Label Groups by No. of Images\ntop10_names = train_file['label_group'].value_counts().index.tolist()[:15]\ntop10_values = train_file['label_group'].value_counts().tolist()[:15]\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=top10_names, y=top10_values)\nplt.xticks(rotation=45)\nplt.xlabel(\"Label Group\")\nplt.ylabel(\"Image Count\")\nplt.title(\"Top-15 Label Groups by Image Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = set(STOPWORDS) \nwordcloud = WordCloud(width = 1000, \n                      height = 500,\n                      background_color ='white',\n                      min_font_size = 10,\n                      stopwords = stopwords,).generate(' '.join(train_file['title'])) \n\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(num):\n    IMG_PATHS = \"../input/shopee-product-matching/train_images/\"\n    sq_num = np.sqrt(num)\n    assert sq_num == int(sq_num), \"Number of Images must be a perfect Square!\"\n\n    sq_num = int(sq_num)\n    image_ids = os.listdir(IMG_PATHS)\n    random.shuffle(image_ids)\n    fig, ax = plt.subplots(nrows=sq_num, ncols=sq_num, figsize=(10, 10))\n\n    for i in range(sq_num):\n        for j in range(sq_num):\n            idx = i*sq_num + j\n            ax[i, j].axis('off')\n            img = cv2.imread(IMG_PATHS + '/' + image_ids[idx])\n            img = img[:, :, ::-1]\n            ax[i, j].imshow(img); ax[i, j].set_title(f'{image_ids[idx]}', fontsize=6.5)\n\n    plt.show()\n    \n    \ndef plot_from_label(group):\n    IMG_PATHS = \"../input/shopee-product-matching/train_images/\"\n    image_list = train_file[train_file['label_group'] == group]\n    image_list = image_list['image'].tolist()\n    num = len(image_list)\n    \n    sq_num = np.sqrt(num)\n\n    sq_num = int(sq_num)\n    image_ids = os.listdir(IMG_PATHS)\n    random.shuffle(image_ids)\n    fig, ax = plt.subplots(nrows=sq_num, ncols=sq_num, figsize=(10, 10))\n    \n    path = [os.path.join(IMG_PATHS, x) for x in image_list]\n    \n    for i in range(sq_num):\n        for j in range(sq_num):\n            idx = i*sq_num + j\n            ax[i, j].axis('off')\n            img = cv2.imread(path[idx])\n            img = img[:, :, ::-1]\n            ax[i, j].imshow(img)\n\n    plt.show()\n\ndef plot_from_title(title):\n    IMG_PATHS = \"../input/shopee-product-matching/train_images/\"\n    image_list = train_file[train_file['title'] == title]\n    image_list = image_list['image'].tolist()\n    num = len(image_list)\n    \n    sq_num = np.sqrt(num)\n    sq_num = int(sq_num)\n    \n    image_ids = os.listdir(IMG_PATHS)\n    random.shuffle(image_ids)\n    fig, ax = plt.subplots(nrows=sq_num, ncols=sq_num, figsize=(10, 10))\n    fig.suptitle(f\"Product Name: {title}\")\n    path = [os.path.join(IMG_PATHS, x) for x in image_list]\n    \n    for i in range(sq_num):\n        for j in range(sq_num):\n            idx = i*sq_num + j\n            ax[i, j].axis('off')\n            img = cv2.imread(path[idx])\n            img = img[:, :, ::-1]\n            ax[i, j].imshow(img)\n            \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot(16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_from_label(994676122)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_from_title(\"Koko syubbanul muslimin koko azzahir koko baju\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_from_title(\"Monde Boromon Cookies 1 tahun+ 120gr\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}