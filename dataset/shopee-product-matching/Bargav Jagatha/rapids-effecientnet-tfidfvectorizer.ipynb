{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n  #  for filename in filenames:\n   #     print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport cudf, cuml, cupy\n\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.applications import EfficientNetB3\n\nimport gc   # garbage collect","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Restrict TensorFlow to 1GB OF GPU RAM so that we have 15GB RAM for RAPIDS","metadata":{}},{"cell_type":"code","source":"LIMIT = 1\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    \n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    \n  except RuntimeError as e:\n    print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV = True\n\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\n\nif(len(test) > 3): COMPUTE_CV = False\nelse: print('This submission notebook will compute CV score, but commit notebook will not')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\n\ntemp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n\ntrain['target'] = train.label_group.map(temp)\n\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        num_intersect = len(np.intersect1d(row['target'], row[col]))\n        return 2 * num_intersect / (len(row['target']) + len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compute Baseline CV score","metadata":{}},{"cell_type":"code","source":"temp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n\ntrain['oof'] = train.image_phash.map(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['f1'] = train.apply(getMetric('oof'), axis = 1)\n\nprint('Baseline CV score : {}'.format(train['f1'].mean()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compute RAPIDS Model CV","metadata":{}},{"cell_type":"code","source":"if COMPUTE_CV:\n    test = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test_cdf = cudf.DataFrame(test)\n    print('Commit is On, i.e using train as test\\n')\nelse:\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_cdf = cudf.read_csv('../input/shopee-product-matching/test.csv')\n    print('Submission is On\\n')\n    \n \nprint('Shape : {}'.format(test_cdf.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cdf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Image Embeddings","metadata":{}},{"cell_type":"code","source":"if COMPUTE_CV:\n    base = '../input/shopee-product-matching/train_images/'\nelse:\n    base = '../input/shopee-product-matching/test_images/'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = EfficientNetB3(weights = 'imagenet', include_top = False, pooling = 'avg', input_shape = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save_weights('modelweights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = EfficientNetB3(weights = None, include_top = False, pooling = 'avg', input_shape = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../input/efficientnetb3-imagenet-weights/modelweights(1).h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom DataGenrator for generating Data","metadata":{}},{"cell_type":"code","source":"import math\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    # Generates data for keras'\n    \n    def __init__(self, df, img_size = 256, batch_size = 32, path = ''):\n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indices = np.arange(len(self.df))\n        \n    def __len__(self):                     # Denotes the number of batches per epoch\n        return math.ceil(len(self.df) / self.batch_size)\n    \n    def __getitem__(self, index):   # Generates one batch of data\n        \n        indices = self.indices[ index*self.batch_size : min((index+1)*self.batch_size, len(self.df))]\n        X = np.zeros((len(indices), self.img_size, self.img_size, 3))\n        df = self.df.iloc[indices]\n        \n        for i , (index, row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path + row.image)\n            X[i,] = cv2.resize(img, (self.img_size, self.img_size))\n        \n        return X\n            \n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### To prevent memory errors, we will compute image embeddings in chunks ","metadata":{}},{"cell_type":"code","source":"embeds = []\nchunk_size = 1024*4\n\nnum_chunks = math.ceil(len(test) / chunk_size)\n\nfor i in range(num_chunks):\n    low = i*chunk_size\n    high = min((i+1)*chunk_size , len(test))\n    \n    print('chunk : {} - {}'.format(low, high))\n    \n    test_gen = DataGenerator(test.iloc[low : high], path = base)\n    \n    image_embeddings = model.predict(test_gen, verbose = 1, use_multiprocessing = True, workers = 4)\n    \n    embeds.append(image_embeddings)\n    \n\nimage_embeddings = np.concatenate(embeds)\n\nprint('image embeddings shape : ',image_embeddings.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model   # model will delete it but the TF graph will have no changes.\n\n_ = gc.collect()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We will find similar images with RAPIDS cuML KNN in chunks","metadata":{}},{"cell_type":"code","source":"KNN = 50\n\nif(len(test) == 3): KNN = 2\n\nmodel = NearestNeighbors(n_neighbors = KNN)\n\nmodel.fit(image_embeddings)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nchunk_size = 1024*4\n\nnum_chunks = math.ceil(len(image_embeddings)/chunk_size)\n\nfor i in range(num_chunks):\n    \n    low = i * chunk_size\n    high = min((i+1) * chunk_size , len(image_embeddings))\n    \n    print('chunk : {} - {}'.format(low, high))\n    \n    distances, indices = model.kneighbors(image_embeddings[low:high])\n    \n    for k in range(high-low):\n        ind = np.where(distances[k,] < 6.0)[0]\n        ids = indices[k, ind]\n        sim_img_ids = test.iloc[ids].posting_id.values\n        preds.append(sim_img_ids)\n        \ndel model, distances, indices, embeds, image_embeddings\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['pred2'] = preds\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Text Embeddings","metadata":{}},{"cell_type":"code","source":"model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = 25000)\n\ntext_embeddings = model.fit_transform(test_cdf.title).toarray()\n\nprint('text embeddings shape : ',text_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nchunk_size = 1024*4\n\nnum_chunks = math.ceil(len(test) / chunk_size)\n\nfor i in range(num_chunks):\n    low = i * chunk_size\n    high = min((i+1)*chunk_size, len(test))\n    \n    print('chunk : {} - {}'.format(low, high))\n    \n    distances = cupy.matmul(text_embeddings, text_embeddings[low:high].T).T\n    \n    for k in range(high-low):\n        ind = cupy.where(distances[k,] > 0.7)[0]\n        #sim_titles = test.iloc[ind].posting_id.values\n        sim_titles = test.iloc[cupy.asnumpy(ind)].posting_id.values\n        preds.append(sim_titles)\n        \ndel model, text_embeddings\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds'] = preds\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using phash feature","metadata":{}},{"cell_type":"code","source":"temp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\n\ntest['preds3']  = test['image_phash'].map(temp)\n\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compute CV score","metadata":{}},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds, row.pred2, row.preds3])\n    return \" \".join(np.unique(x))\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds, row.pred2, row.preds3])\n    return np.unique(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    temp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test['label_group'].map(temp)\n    test['oof'] = test.apply(combine_for_cv, axis = 1)\n    test['f1'] = test.apply(getMetric('oof'), axis = 1)\n    print('CV score : ',test['f1'].mean())\n    \ntest['matches'] = test.apply(combine_for_sub,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['posting_id', 'matches']].to_csv('submission.csv',index=False)\n\nsub = pd.read_csv('submission.csv')\n\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}