{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport pandas as pd\nfrom skimage import io\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class gen_triplets(Dataset):\n    def __init__(self,csv_file,root_dir,transform=None):\n        self.df=pd.read_csv(csv_file)\n        self.root_dir=root_dir\n        self.transform=transform\n        self.group2df=dict(list(self.df.groupby('label_group')))\n        self.id_to_img=self.df.set_index('posting_id')['image'].to_dict()\n        self.id_to_title=self.df.set_index('posting_id')[\"title\"].to_dict()\n        \n    def __len__(self):\n        return len(self.df)\n    \n    \n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx=idx.tolist()\n        anchor=self.df.loc[idx,\"posting_id\"]\n        ids=self.group2df[self.df.loc[idx,\"label_group\"]][\"posting_id\"].tolist()\n        ids.remove(anchor)\n        positive=random.choice(ids)\n        \n        groups=list(self.group2df.keys())\n        groups.remove(self.df.loc[idx,\"label_group\"])\n        neg_group=random.choice(groups)\n        negative=random.choice(self.group2df[neg_group][\"posting_id\"].to_list())\n        print(\"Anchor: \",self.id_to_title[anchor],\"\\nPositive: \",self.id_to_title[positive],\"\\nNegative: \",self.id_to_title[negative])\n        anchor_img=io.imread(os.path.join(self.root_dir,self.id_to_img[anchor]))\n        positive_img=io.imread(os.path.join(self.root_dir,self.id_to_img[positive]))\n        negative_img=io.imread(os.path.join(self.root_dir,self.id_to_img[negative]))\n        if self.transform:\n            anchor_img=transform(anchor_img)\n            positive_img=transform(positive_img)\n            negative_img=transform(negative_img)\n                                                           \n        \n        return anchor_img,positive_img,negative_img\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform=transforms.Compose([\n     transforms.ToTensor(),\n     transforms.Resize((128,128)),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"triples=gen_triplets(\"/kaggle/input/shopee-product-matching/train.csv\",\"/kaggle/input/shopee-product-matching/train_images\",transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anchor_img,positive_img,negative_img=triples[12]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(anchor_img.permute(1,2,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(positive_img.permute(1,2,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(negative_img.permute(1,2,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}