{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## packages","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nimport cv2,math,gc\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch.nn import Parameter\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\n!pip install \"../input/efficient-net/dist/efficientnet_pytorch-0.7.0.tar\"\nfrom efficientnet_pytorch import EfficientNet\n\n!pip install \"../input/faissgpuwheel/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\"\nimport faiss\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport warnings\nwarnings.simplefilter('ignore')\n\ntorch.backends.cudnn.benchmark = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## pre-processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\nlabels = list(set(df.label_group.values))\nlabels.sort()\nlabels_length = len(labels)\nsingle_fold_length = labels_length//5 + 1\nrank = dict()\nfor i, label in enumerate(labels):\n    rank[label] = i\ndf['rank'] = df.label_group.map(rank)\ndf['fold'] = df['rank'].apply(lambda x: x//single_fold_length)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class cfg:\n    img_size = (380,380)\n    feavec_num1 = 512\n    feavec_num2 = 1280\n    fea_norm = 64\n    margin = 0.35\n    batch = 16\n    mname = 'efficientnet-b3'\n    clsize = 8812\n    lr = 0.001\n    momentum = 0.9\n    weight_decay = 0.0005\n    log_interval = 1000\n    epochs = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\ndf['target'] = df.label_group.map(tmp)\ndf['target'] = df['target'].apply(lambda x: ' '.join(x))\ndf_cu = cudf.DataFrame(df)\n\nprint('df shape is', df.shape )\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model_1 training","metadata":{}},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.30, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output  #need softmax then\n\n\nclass Model(nn.Module):\n    def __init__(self,name,clustersize,feavec=512):\n        super(Model, self).__init__()\n        self.eff = EfficientNet.from_pretrained(name)\n        self.out = nn.Linear(1000,feavec)\n        self.margin = ArcMarginProduct(in_features=feavec, \n                                       out_features = clustersize, \n                                       s=cfg.fea_norm, \n                                       m=cfg.margin)      \n\n    def forward(self, x, labels=None):\n        x = self.eff(x)\n        x = self.out(x)\n        if labels is not None:\n            return self.margin(x,labels)\n        return F.normalize(x,dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Model(name=cfg.mname,clustersize=cfg.clsize).to(device)\noptimizer = optim.SGD(model1.parameters(), lr=cfg.lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(file_name):\n    file_path = f'/kaggle/input/shopee-product-matching/train_images/{file_name}'\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, cfg.img_size)\n    tensor_img = torch.tensor(img)\n    tensor_img = tensor_img.permute(( 2, 0, 1)).float()/255.0\n    return tensor_img\n\nclass valDataset(Dataset):\n    def __init__(self, df):\n        self.img = df.image.values\n        self.label = df.label.values\n        \n    def __len__(self):\n        return len(self.img)\n\n    def __getitem__(self, idx):\n        img = self.img[idx]\n        img = load_image(img)\n        label = self.label[idx]\n        return (img, label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df[df.fold!=4]\ndf1_val = df[df.fold==4]\ndf1_val['label'] = 1\nranks = list(set(df1[\"rank\"].values))\nranks.sort()\nranks_length = len(ranks)\nprint(ranks_length)\nlabel = dict()\nfor i, rank in enumerate(ranks):\n    label[rank] = i\ndf1['label'] = df1[\"rank\"].map(label)\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = valDataset(df1)\ntrain_loader = DataLoader(dataset,\n                    batch_size=cfg.batch,\n                    shuffle=False,\n                    num_workers=2,\n                    pin_memory=True,\n                    drop_last=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    model1.train()\n    epoch_loss = 0\n    for batch_idx, (images, label) in enumerate(train_loader):\n        images = images.to(device)\n        label = label.to(device)\n        images, label = Variable(images), Variable(label)\n        optimizer.zero_grad()\n        output = model1(images, label)\n        loss = nn.CrossEntropyLoss()(output, label)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % cfg.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(images), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n        epoch_loss = epoch_loss + loss.item()\n    return epoch_loss/len(train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_embeddings(df):\n    dataset = valDataset(df)\n    loader = DataLoader(dataset,\n                        batch_size=cfg.batch,\n                        shuffle=False,\n                        num_workers=2,\n                        pin_memory=True,\n                        drop_last=False)\n    \n    model1.eval()\n    print('start collection')\n    feavec = 512\n    embedded1 = np.empty((0,feavec),dtype='float32')\n    with torch.no_grad():\n        for idx,(images,label) in enumerate(loader):\n            images = images.to(device,non_blocking=True)\n            outputs = model1(images)\n            embedded1 = np.append(embedded1, outputs.cpu().detach().numpy(),axis=0)\n\n            if idx%100==0:\n                print(idx,len(loader))\n                print(embedded1.shape)\n    return embedded1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\ndef predict_img(df,embeddings,topk=50,threshold=0.63):\n    N,D = embeddings.shape\n    cpu_index = faiss.IndexFlatL2(D)\n    gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n    gpu_index.add(embeddings)\n    cluster_distance,cluster_index = gpu_index.search(x=embeddings, k=topk)\n    \n    df['pred_images'] = ''\n    pred = []\n    for k in range(embeddings.shape[0]):\n        idx = np.where(cluster_distance[k,] < threshold)[0]\n        ids = cluster_index[k,idx]\n        #posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n        posting_ids = df['posting_id'].iloc[ids].values\n        pred.append(posting_ids)\n    df['pred_images'] = pred\n    \n    df['pred_imgonly'] = df.pred_images.apply(lambda x: ' '.join(x))\n    df['f1_img'] = f1_score(df['target'], df['pred_imgonly'])\n    score = df['f1_img'].mean()\n    #print(f'Our f1 score for threshold {threshold} is {score}')\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_list = []\ntrain_f1_list = []\nval_f1_list = []\nfor epoch in range(1,cfg.epochs + 1):\n    loss_list.append(train(epoch))\n    \n    embeddings_train = image_embeddings(df1)\n    embeddings_val = image_embeddings(df1_val)\n    train_f1_score = predict_img(df1,embeddings_train, topk=50,threshold=0.88)\n    val_f1_score = predict_img(df1_val,embeddings_val, topk=50,threshold=0.88)\n    \n    train_f1_list.append(train_f1_score)\n    val_f1_list.append(val_f1_score)\n    \n    torch.save(model1.state_dict(), \"{}_arcface_epoch_{}.pt\".format(cfg.mname, epoch))\n    print(\"train_f1_score:\", train_f1_score)\n    print(\"val_f1_score:\", val_f1_score)\n\nloss_list = np.array(loss_list)\ntrain_f1_list = np.array(train_f1_list)\nval_f1_list = np.array(val_f1_list)\n\nnp.save('image_only_train_loss.npy', loss_list)\nnp.save('image_only_train_f1.npy', train_f1_list)\nnp.save('image_only_val_f1.npy', val_f1_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(loss_list)\nplt.xlabel('epoch')\nplt.ylabel('train loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_f1_list)\nplt.xlabel('epoch')\nplt.ylabel('train f1 score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(val_f1_list)\nplt.xlabel('epoch')\nplt.ylabel('validation f1 score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}