{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nimport cv2,math,gc\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torch.nn import Parameter\n\n!pip install \"../input/efficient-net/dist/efficientnet_pytorch-0.7.0.tar\"\nfrom efficientnet_pytorch import EfficientNet\n\n!pip install \"../input/faissgpuwheel/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\"\nimport faiss\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport warnings\nwarnings.simplefilter('ignore')\n    \ntorch.backends.cudnn.benchmark = True\nfrom transformers import (BertTokenizer, BertModel,\n                          DistilBertTokenizer, DistilBertModel)\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm.autonotebook import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class cfg:\n    img_size = (380,380)\n    feavec_num1 = 512\n    feavec_num2 = 1280\n    fea_norm = 64\n    margin = 0.35\n    batch = 50\n    wpath = \"../input/my-weight/efficientnet-b3_arcface_epoch_10.pt\"\n    mname = 'efficientnet-b3'\n    clsize = 8812","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    DistilBERT = True # if set to False, BERT model will be used\n    bert_hidden_size = 768\n    \n    batch_size = 64\n    epochs = 100\n    num_workers = 4\n    learning_rate = 1e-5\n    scheduler = \"ReduceLROnPlateau\"\n    step = 'epoch'\n    patience = 2\n    factor = 0.8\n    dropout = 0.5\n    model_path = \"/kaggle/working\"\n    max_length = 30\n    model_save_name = \"model.pt\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = False\nNUM_CLASSES = 11014","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.DistilBERT:\n    model_name='cahya/distilbert-base-indonesian'\n    tokenizer = DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseindonesianfte1\")\n    bert_model = DistilBertModel.from_pretrained(\"../input/distilbertbaseindonesianfte1\")\nelse:\n    model_name='cahya/bert-base-indonesian-522M'\n    tokenizer = BertTokenizer.from_pretrained(model_name)\n    bert_model = BertModel.from_pretrained(model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    df = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n    lbl_encoder = LabelEncoder()\n    df['label_code'] = lbl_encoder.fit_transform(df['label_group'])\n    NUM_CLASSES = df['label_code'].nunique()\n\n    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n    df['target'] = df.label_group.map(tmp)\n    df['target'] = df['target'].apply(lambda x: ' '.join(x))\n    \nelse:\n    df = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\n    df['label_code'] = 1\n    \ndf_cu = cudf.DataFrame(df)\n\nif len(df)==3:\n    cfg.batch = 3\n    \nprint('df shape is', df.shape )\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.30, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n        return output\n\n\nclass Model(nn.Module):\n    def __init__(self,name,clustersize,feavec=512):\n        super(Model, self).__init__()\n        self.eff = EfficientNet.from_name(name)\n        self.out = nn.Linear(1000,feavec)\n        self.margin = ArcMarginProduct(in_features=feavec, \n                                       out_features = clustersize, \n                                       s=cfg.fea_norm, \n                                       m=cfg.margin)      \n\n    def forward(self, x, labels=None):\n        x = self.eff(x)\n        x = self.out(x)\n        if labels is not None:\n            return self.margin(x,labels)\n        return F.normalize(x,dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Model(name=cfg.mname,clustersize=cfg.clsize).to(device)\nmodel1.load_state_dict(torch.load(cfg.wpath, map_location=device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make image Datasets\ndef load_image(file_name):\n    if TRAIN:\n        file_path = f'/kaggle/input/shopee-product-matching/train_images/{file_name}'\n    else:\n        file_path = f'/kaggle/input/shopee-product-matching/test_images/{file_name}'\n\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, cfg.img_size)\n    tensor_img = torch.tensor(img)\n    tensor_img = tensor_img.permute(( 2, 0, 1)).float()/255.0\n    return tensor_img\n\nclass valDataset(Dataset):\n    def __init__(self, df):\n        self.img = df.image.values\n        \n    def __len__(self):\n        return len(self.img)\n\n    def __getitem__(self, idx):\n        img = self.img[idx]\n        img = load_image(img)\n        return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_embeddings(df):\n    dataset = valDataset(df)\n    loader = DataLoader(dataset,\n                        batch_size=cfg.batch,\n                        shuffle=False,\n                        num_workers=2,\n                        pin_memory=True,\n                        drop_last=False)\n    \n    model1.eval()\n    print('start collection')\n    feavec = 512\n    embedded1 = np.empty((0,feavec),dtype='float32')\n    with torch.no_grad():\n        for idx,images in enumerate(loader):\n            images = images.to(device,non_blocking=True)\n            outputs = model1(images)\n            embedded1 = np.append(embedded1, outputs.cpu().detach().numpy(),axis=0)\n\n            if idx%100==0:\n                print(idx,len(loader))\n                print(embedded1.shape)\n    return embedded1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, tokenizer, mode=\"train\", max_length=None):\n        self.dataframe = dataframe\n        if mode != \"test\":\n            self.targets = dataframe['label_code'].values\n        texts = list(dataframe['title'].apply(lambda o: str(o)).values)\n        self.encodings = tokenizer(texts, \n                                   padding=True, \n                                   truncation=True, \n                                   max_length=max_length)\n        self.mode = mode\n        \n        \n    def __getitem__(self, idx):\n        # putting each tensor in front of the corresponding key from the tokenizer\n        # HuggingFace tokenizers give you whatever you need to feed to the corresponding model\n        item = {key: torch.tensor(values[idx]) for key, values in self.encodings.items()}\n        # when testing, there are no targets so we won't do the following\n        if self.mode != \"test\":\n            item['labels'] = torch.tensor(self.targets[idx]).long()\n        return item\n    \n    def __len__(self):\n        return len(self.dataframe)\n\nclass Model(nn.Module):\n    def __init__(self, \n                 bert_model, \n                 num_classes=NUM_CLASSES, \n                 last_hidden_size=CFG.bert_hidden_size):\n        \n        super().__init__()\n        self.bert_model = bert_model\n        self.arc_margin = ArcMarginProduct(last_hidden_size, \n                                           num_classes, \n                                           s=30.0, \n                                           m=0.50, \n                                           easy_margin=False)\n    \n    def get_bert_features(self, batch):\n        output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n        last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n        CLS_token_state = last_hidden_state[:, 0, :] # obtaining CLS token state which is the first token.\n        return CLS_token_state\n    \n    def forward(self, batch):\n        CLS_hidden_state = self.get_bert_features(batch)\n        output = self.arc_margin(CLS_hidden_state, batch['labels'])\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bert = Model(bert_model).to(CFG.device)\nmodel_bert.load_state_dict(torch.load(\"../input/my-weight/bert_model.pt\", map_location=device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_text_embeddings(df):\n    \n    bert_dataset = TextDataset(df, tokenizer, max_length=CFG.max_length)\n    bert_loader = torch.utils.data.DataLoader(bert_dataset,\n                                           batch_size=CFG.batch_size, \n                                           num_workers=CFG.num_workers, \n                                           shuffle=False)\n    \n    model_bert.eval()\n    print('start collection')\n    feavec = CFG.bert_hidden_size\n    embedded1 = np.empty((0,feavec),dtype='float32')\n    \n    tqdm_object = tqdm(bert_loader, total=len(bert_loader))\n    with torch.no_grad():\n        for batch in tqdm_object:\n            batch = {k: v.to(CFG.device) for k, v in batch.items()}\n            outputs = model_bert.get_bert_features(batch)\n            outputs = F.normalize(outputs,dim=1)\n            \n            embedded1 = np.append(embedded1, outputs.cpu().detach().numpy(),axis=0)\n    print(embedded1.shape)\n    return embedded1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\ndef predict_img(df,embeddings,topk=50,threshold=0.63):\n    N,D = embeddings.shape\n    cpu_index = faiss.IndexFlatL2(D)\n    gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n    gpu_index.add(embeddings)\n    cluster_distance,cluster_index = gpu_index.search(x=embeddings, k=topk)\n    \n    df['pred_images'] = ''\n    pred = []\n    for k in range(embeddings.shape[0]):\n        idx = np.where(cluster_distance[k,] < threshold)[0]\n        ids = cluster_index[k,idx]\n        #posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n        posting_ids = df['posting_id'].iloc[ids].values\n        pred.append(posting_ids)\n    df['pred_images'] = pred\n\n    #print(f'Our f1 score for threshold {threshold} is {score}')\n    return df\n\ndef predict_text_bert(df,embeddings,topk=50,threshold=0.63):\n    N,D = embeddings.shape\n    cpu_index = faiss.IndexFlatL2(D)\n    gpu_index = faiss.index_cpu_to_all_gpus(cpu_index)\n    gpu_index.add(embeddings)\n    cluster_distance,cluster_index = gpu_index.search(x=embeddings, k=topk)\n    \n    df['pred_text_bert'] = ''\n    pred = []\n    for k in range(embeddings.shape[0]):\n        idx = np.where(cluster_distance[k,] < threshold)[0]\n        ids = cluster_index[k,idx]\n        #posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n        posting_ids = df['posting_id'].iloc[ids].values\n        pred.append(posting_ids)\n    df['pred_text_bert'] = pred\n    if TRAIN:\n        df['bert_only'] = df.pred_text_bert.apply(lambda x: ' '.join(x))\n        df['f1_bert'] = f1_score(df['target'], df['bert_only'])\n        score = df['f1_bert'].mean()\n        print(f'Our f1 score for threshold {threshold} is {score}')\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_predictions(df, max_features = 25000,threshold=0.7):\n    from cuml.feature_extraction.text import TfidfVectorizer\n    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n    text_embeddings = model.fit_transform(df_cu.title).toarray()\n    #print(text_embeddings)\n    preds = []\n    CHUNK = 1024*4\n\n    print('Finding similar titles...')\n    CTS = len(df)//CHUNK\n    if len(df)%CHUNK!=0: CTS += 1\n    for j in range( CTS ):\n\n        a = j*CHUNK\n        b = (j+1)*CHUNK\n        b = min(b,len(df))\n        print('chunk',a,'to',b)\n\n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n\n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>threshold)[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n    df['pred_text'] = preds\n    del model,text_embeddings\n    gc.collect()\n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings1= image_embeddings(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = predict_img(df,image_embeddings1,topk=50,threshold=0.88)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = get_text_predictions(df, max_features = 25000,threshold=0.75)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_embeddings = bert_text_embeddings(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = predict_text_bert(df,bert_embeddings, topk=50,threshold=0.88)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x1 = np.intersect1d(row['pred_images'], row['pred_text'])\n    x2 = np.intersect1d(row['pred_images'], row['pred_text_bert'])\n    x3 = np.intersect1d(row['pred_text'], row['pred_text_bert'])\n    \n    tmp = np.union1d(x1, x2)\n    x = np.union1d(tmp, x3)\n    return ' '.join( np.unique(x) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['matches'] = df.apply(combine_predictions, axis=1)\n#df['matches'] = df['pred_images'].apply(lambda x: ' '.join(x))\nwith open('submission.csv', 'w') as outf:\n    print('posting_id,matches', file=outf)\n    for i,(idnum,match) in enumerate(zip(df['posting_id'],df['matches'])):\n        print(f'{idnum},{match}', file=outf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_t = pd.read_csv(\"submission.csv\")\nprint(df_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}