{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Calculate CV with only Pytorch\nI had trouble installing rapids to colab, which lead to calculating CV with torch.\n\nIn this notebook, we use pytorch cuda to calculate cosine simularity, which is quite fast!\n\nThe computaton is fast as cuml neighbors.\n\n(Wish that rapids were easy to install on remote machines as well..)","metadata":{}},{"cell_type":"markdown","source":"![](https://i.imgflip.com/561676.jpg)","metadata":{}},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preliminaries\nfrom tqdm import tqdm\nimport math\nimport random\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\n# Visuals and CV2\nimport cv2\n\n# albumentations for augs\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#torch\nimport torch\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"executionInfo":{"elapsed":2028,"status":"ok","timestamp":1618284181104,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"jFcEwg3R6m6w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{"id":"h2V3T5me6m6x"}},{"cell_type":"code","source":"DIM = (512,512)\n\nNUM_WORKERS = 8\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nEPOCHS = 20\nSEED = 42\n\ndevice = torch.device('cuda')\n\nmodel_name = 'efficientnet_b3' #efficientnet_b0-b7\nnum_ch = 1536","metadata":{"executionInfo":{"elapsed":1498,"status":"ok","timestamp":1618284181530,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"TpxznYwt6m6x","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"h6j6faVE6m6y"}},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(SEED)","metadata":{"executionInfo":{"elapsed":1428,"status":"ok","timestamp":1618284181530,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"pPVIzOSj6m6y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms():\n\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n            albumentations.Normalize(),\n        ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"executionInfo":{"elapsed":1265,"status":"ok","timestamp":1618284181532,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"7LFkhlOs6m60","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"N67D9Kcx6m60"}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, csv, transforms=None):\n\n        self.csv = csv.reset_index()\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        text = row.title\n        \n        image = cv2.imread(row.filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']       \n        \n        \n        return image,torch.tensor(row.label_group)","metadata":{"executionInfo":{"elapsed":1198,"status":"ok","timestamp":1618284181532,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"JvEpDay86m60","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"laWVQJqE6m60"}},{"cell_type":"code","source":"class Net(nn.Module):\n\n    def __init__(self,\n                 model_name='efficientnet_b0'):\n        super(Net, self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.backbone = timm.create_model(model_name, pretrained=True)\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        \n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n        \n    def forward(self, x, label):\n        feature = self.extract_feat(x)\n        return feature\n\n    def extract_feat(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        return x","metadata":{"executionInfo":{"elapsed":511,"status":"ok","timestamp":1618284181931,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"P313RlC86m61","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get embeddings","metadata":{"id":"A7KTKtP_6m66"}},{"cell_type":"code","source":"def get_img_emb(data_loader,model,criterion,device):\n    model.eval()\n    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n    outs = np.zeros([len(valid), num_ch])\n    with torch.no_grad():      \n        for i,(bi,d) in enumerate(tk0):\n            batch_size = d[0].size()[0]\n\n            image = d[0]\n            targets = d[1]\n\n            image = image.to(device)\n            targets = targets.to(device)\n            # Inference\n            output = model.extract_feat(image)\n            outs[i*batch_size:i*batch_size+batch_size] = output.cpu().detach().numpy()      \n    return outs","metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1618284186600,"user":{"displayName":"ken yos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzkUCd50LH48gEiHcGcv_ANhcMmDlPTC9WRUfMZvs=s64","userId":"17097843443677736067"},"user_tz":-540},"id":"BhrkuNDL6m66","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup dataloader","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\ndf_train = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\nskf = GroupKFold(5)\ndf_train['fold'] = -1\nfor i, (train_idx, valid_idx) in enumerate(skf.split(X=df_train, groups=df_train['label_group'])):\n    df_train.loc[valid_idx, 'fold'] = i\ntrain_df = df_train\ndf_train.tail()\n\ndata = df_train\ndata['filepath'] = data['image'].apply(lambda x: os.path.join('../input/shopee-product-matching/train_images', x))\nlen(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 0\ntrain = data[data['fold']!=fold].reset_index(drop=True)\nvalid = data[data['fold']==fold].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset = ShopeeDataset(\n    csv=valid,\n    transforms=get_valid_transforms(),\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=VALID_BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    shuffle=False,\n    pin_memory=True,\n    drop_last=False,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining Device\ndevice = torch.device(\"cuda\")\n\n# Defining Model for specific fold\nmodel = Net(model_name)\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\n\nfrom sklearn.preprocessing import normalize\nimport gc\n\ndef get_cv(df, outs):\n    thresholds = list(np.arange(0.2, 0.8, 0.1))\n    scores = []\n    \n    # set target\n    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n    df['target'] = df.label_group.map(tmp)\n\n    # Normalize\n    outsn = normalize(outs)\n\n    # to torch\n    outsn_torch = torch.from_numpy(outsn).cuda()\n    \n    # calculate cosine simularity with torch cuda()\n    distances = 1 - torch.matmul(outsn_torch, outsn_torch.T).cpu().T\n    \n    for threshold in thresholds:\n        predictions = []\n        for k in range(outs.shape[0]):\n            idx = np.where(distances[k,] < threshold)[0]\n            o = df.iloc[idx].posting_id.values\n            predictions.append(o)\n        df[\"preds\"] = predictions\n        #df['oof'] = df.apply(combine_for_cv,axis=1)\n        df['f1'] = df.apply(getMetric(\"preds\"),axis=1)\n        score = df['f1'].mean()\n        print(f'Our f1 score for threshold {threshold} is {score}')\n        scores.append(score)\n    thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n    max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n    best_threshold = max_score['thresholds'].values[0]\n    best_score = max_score['scores'].values[0]\n    print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return best_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run CV","metadata":{}},{"cell_type":"code","source":"# get embeddings\nouts = get_img_emb(valid_loader,model,None,device)\n\n# calculate CV\nbest = get_cv(valid, outs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}