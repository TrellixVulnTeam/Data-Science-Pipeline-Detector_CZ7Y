{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# DATA_PATH = '../input/'\nDATA_PATH = '../input/shopee-product-matching/'\n","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:37:54.312074Z","start_time":"2021-03-26T06:37:54.308349Z"},"papermill":{"duration":0.021384,"end_time":"2021-03-18T23:07:51.080696","exception":false,"start_time":"2021-03-18T23:07:51.059312","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import normalize\nimport math\nimport torch\nfrom torch.optim.lr_scheduler import StepLR\n\n# import cudf, cuml, cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\n\n# 定义评价函数：准确率、召回率，F1\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]))\n        if len(row[col])==0:\n            p = 0\n        else:\n            p = n/len(row[col])\n        if len(row.target) == 0:\n            r = 0\n        else:\n            r = n/len(row.target)\n        return p, r, 2*n/(len(row.target)+len(row[col]))\n    return f1score","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:41:01.504348Z","start_time":"2021-03-26T06:41:01.499123Z"},"papermill":{"duration":4.978277,"end_time":"2021-03-18T23:07:56.071802","exception":false,"start_time":"2021-03-18T23:07:51.093525","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from contextlib import contextmanager\nimport os, sys, time, psutil\n\n# 计算当前代码所使用的内存和时间\n@contextmanager\ndef timer_memory(name):\n    t0 = time.time()\n    yield\n    print(f'Memory: {(psutil.Process(os.getpid()).memory_info().rss/2**30):.02f}GB')\n    print(f'{name} done in {time.time()-t0:.0f}s')","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:38:01.42867Z","start_time":"2021-03-26T06:38:01.424616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV = True\ndevice = 'cuda'\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\nwith timer_memory('Reading CSV'):\n    if COMPUTE_CV:\n        train = pd.read_csv(DATA_PATH + 'train.csv')\n        train['image'] = DATA_PATH + 'train_images/' + train['image']\n        tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n        train['target'] = train.label_group.map(tmp)\n    else:\n        train = pd.read_csv(DATA_PATH + 'test.csv')\n        train['image'] = DATA_PATH + 'test_images/' + train['image']\n    \nprint('train shape is', train.shape )\ntrain.head()","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:44:32.312066Z","start_time":"2021-03-26T06:44:26.704002Z"},"papermill":{"duration":4.860382,"end_time":"2021-03-18T23:08:00.945626","exception":false,"start_time":"2021-03-18T23:07:56.085244","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image hash","metadata":{"papermill":{"duration":0.014127,"end_time":"2021-03-18T23:08:00.975238","exception":false,"start_time":"2021-03-18T23:08:00.961111","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:48:36.890006Z","start_time":"2021-03-26T06:48:35.608363Z"},"papermill":{"duration":1.949333,"end_time":"2021-03-18T23:08:02.938733","exception":false,"start_time":"2021-03-18T23:08:00.9894","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train.label_group.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mappingdic={}\nmappingback={}\nfor a in range(len(train.label_group.unique())):\n    mappingdic[train.label_group.unique()[a]]=a\n    mappingback[a]=train.label_group.unique()[a]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['map_label'] = train.label_group.map(mappingdic)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['oof_hash'] = train.image_phash.map(tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:48:38.821723Z","start_time":"2021-03-26T06:48:36.892097Z"},"papermill":{"duration":2.170568,"end_time":"2021-03-18T23:08:05.124618","exception":false,"start_time":"2021-03-18T23:08:02.95405","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image CNN","metadata":{"papermill":{"duration":0.014027,"end_time":"2021-03-18T23:08:05.154766","exception":false,"start_time":"2021-03-18T23:08:05.140739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nclass SHOPEEDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        img = cv2.imread(row.image)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img)\n            img = res['image']\n                \n        img = img.astype(np.float32)\n       # print('i am the img',img.shape)\n        img = img.transpose(2,0,1)\n        \n        if self.mode == 'test':\n            return torch.tensor(img).float()\n        else:\n            return torch.tensor(img).float(), torch.tensor(row.map_label).float()\n\nclass ArcModule(nn.Module):\n    def __init__(self, in_features, out_features, s = 10, m = 0.5):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n        print('i am self weight',self.weight.shape)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = torch.tensor(math.cos(math.pi - m))\n        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n\n    def forward(self, inputs, labels):\n        cos_th = F.linear(inputs, F.normalize(self.weight))\n        cos_th = cos_th.clamp(-1, 1)\n        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n\n        cond_v = cos_th - self.th\n        cond = cond_v <= 0\n        cos_th_m[cond] = (cos_th - self.mm)[cond]\n\n        if labels.dim() == 1:\n            labels = labels.unsqueeze(-1)\n        onehot = torch.zeros(cos_th.size()).cuda()\n        labels = labels.type(torch.LongTensor).cuda()\n        onehot.scatter_(1, labels, 1.0)\n        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n        outputs = outputs * self.s\n        print('i am arc output',outputs.shape)\n        return outputs\n    \n    \nclass SHOPEEDenseNet(nn.Module):\n\n    def __init__(self, channel_size, out_feature, dropout=0.5, backbone='densenet121', pretrained=True):\n        super(SHOPEEDenseNet, self).__init__()\n        self.channel_size = channel_size\n        self.out_feature = out_feature\n        \n        if backbone == 'resnet18':\n            self.backbone = models.resnet18(False)\n            self.in_features = self.backbone.fc.in_features\n            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n            self.fc1 = nn.Linear(self.in_features * 7 * 7 , self.channel_size)\n      \n        self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n        self.bn1 = nn.BatchNorm2d(self.in_features)\n        self.dropout = nn.Dropout2d(dropout)\n        self.bn2 = nn.BatchNorm1d(self.channel_size)\n        \n    def forward(self, x, labels=None):\n        print(x.shape,'i am faetures')\n\n        features = self.backbone(x)\n        print(features.shape,'i am faetures')\n\n        features = self.dropout(features)\n        features = features.view(features.size(0), -1)\n        print(features.shape,'i am faetures1')\n        features = self.fc1(features)\n        print(features.shape,'i am faetures2')\n\n        features = F.normalize(features)\n        \n        print(features.shape,'i am faetures3')\n        print(features,'i am faetures3')\n\n        #margin=self.margin(features, labels)\n        #print(margin,'i am margin')\n\n        if labels is not None:\n            return self.margin(features, labels)\n        return features\n    \n    def test(self):\n        x = torch.rand(1, 3, 224, 224).cuda()\n        print(self.forward(x))\n","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:44:11.172699Z","start_time":"2021-03-26T06:44:11.154328Z"},"papermill":{"duration":1.229058,"end_time":"2021-03-18T23:08:06.398043","exception":false,"start_time":"2021-03-18T23:08:05.168985","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SHOPEEDenseNet(512, 11014, backbone='resnet18')\nmodel.to('cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ll ../input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/shopee-models/baseline_fold0_densenet_224_epoch50.pth'))\nmodel.to('cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SHOPEEDenseNet(512, 11014, backbone='resnet18')\nmodel.load_state_dict(torch.load('../input/shopee-models/baseline_fold0_densenet_224_epoch30.pth'))\nmodel.to('cuda')","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:41:14.013532Z","start_time":"2021-03-26T06:41:13.645045Z"},"papermill":{"duration":0.023628,"end_time":"2021-03-18T23:08:06.436361","exception":false,"start_time":"2021-03-18T23:08:06.412733","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_test_features(test_loader):\n    model.eval()\n    bar = tqdm_notebook(test_loader)\n    \n    FEAS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for batch_idx, (images) in enumerate(bar):\n            print('ddddd',batch_idx)\n            #images = images.to('cuda')\n            features = model(images)\n            FEAS += [features.detach().cpu()]\n            if batch_idx==1:\n               break\n                \n    FEAS = torch.cat(FEAS).cpu().numpy()\n    return FEAS","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:41:30.384356Z","start_time":"2021-03-26T06:41:30.378507Z"},"papermill":{"duration":0.023376,"end_time":"2021-03-18T23:08:06.473926","exception":false,"start_time":"2021-03-18T23:08:06.45055","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir -p /root/.cache/torch/hub/checkpoints/\n# !cp ../input/pretrained-pytorch-models/resnet18-5c106cde.pth /root/.cache/torch/hub/checkpoints/","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:41:31.098158Z","start_time":"2021-03-26T06:41:31.095297Z"},"papermill":{"duration":3.195146,"end_time":"2021-03-18T23:08:09.683356","exception":false,"start_time":"2021-03-18T23:08:06.48821","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize()\n])\n\ndataset_test = SHOPEEDataset(train, 'test', transform=transforms_valid)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, \n                                          shuffle=False, num_workers=4, pin_memory=True)\nimagefeat = generate_test_features(test_loader)\nimagefeat = torch.tensor(imagefeat)","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:46:10.814194Z","start_time":"2021-03-26T06:44:36.573028Z"},"papermill":{"duration":639.514314,"end_time":"2021-03-18T23:18:49.212965","exception":false,"start_time":"2021-03-18T23:08:09.698651","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize()\n])\ndataset_test = SHOPEEDataset(train, 'train', transform=transforms_valid)\ntrain_loader = torch.utils.data.DataLoader(dataset_test, batch_size=16, \n                                          shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_epoch = 50\nlr = 1e-1  # initial learning rate\nlr_step = 10\nlr_decay = 0.95  # when val_loss increase, lr = lr*lr_decay\nweight_decay = 5e-4\noptimizer_p = 'sgd'\nloss_p=''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if loss_p == 'focal_loss':\n        criterion = FocalLoss(gamma=2)\nelse:\n        criterion = torch.nn.CrossEntropyLoss()\n\nif optimizer_p == 'sgd':\n   optimizer = torch.optim.SGD(model.parameters(),\n                                    lr=lr, weight_decay=weight_decay)\nelse:\n   optimizer = torch.optim.Adam( model.parameters(),\n                                     lr=lr, weight_decay=weight_decay)\nscheduler = StepLR(optimizer, step_size=lr_step, gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nfor i in range(max_epoch):\n        scheduler.step()\n\n        model.train()\n        for ii, data in enumerate(train_loader):\n            data_input, label = data\n            data_input = data_input.to(device)\n            label = label.to(device).long()\n            output = model(data_input, label)\n            loss = criterion(output, label)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            iters = i * len(train_loader) + ii\n\n            if iters % 100 == 0:\n                output = output.data.cpu().numpy()\n                output = np.argmax(output, axis=1)\n                label = label.data.cpu().numpy()\n                # print(output)\n                # print(label)\n                acc = np.mean((output == label).astype(int))\n                speed = 100 / (time.time() - start)\n                time_str = time.asctime(time.localtime(time.time()))\n                print('{} train epoch {} iter {} {} iters/s loss {} acc {}'.format(time_str, i, ii, speed, loss.item(), acc))\n                if False:\n                    visualizer.display_current_results(iters, loss.item(), name='train_loss')\n                    visualizer.display_current_results(iters, acc, name='train_acc')\n\n                start = time.time()\n\n        if i % 10 == 0 or i == max_epoch:\n            save_model(model, './', 'resenet', i)\n\n        model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ii, data in enumerate(test_loader):\n    print(ii,data)\n    print(len(data))\n    print(data[0].size())\n    print(data[1].size())\n\n    if ii==1:\n       break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagefeat = imagefeat.cuda()","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:46:17.961462Z","start_time":"2021-03-26T06:46:17.942996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Finding similar images...')\n\npreds = []\npreds_index = []\nCHUNK = 1024*4\n\nCTS = len(imagefeat)//CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\n\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n    distances = distances.data.cpu().numpy()\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n    for k in range(b-a):\n        # IDX = cupy.where(distances[k,]>0.95)[0]\n        IDX = np.where(distances[k,]>0.9)[0][:]\n        o = train.iloc[IDX].posting_id.values\n#         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        preds_index.append(IDX)\n        \n# del imagefeat, imgmodel","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:46:47.225075Z","start_time":"2021-03-26T06:46:19.957145Z"},"papermill":{"duration":24.168528,"end_time":"2021-03-18T23:19:14.187138","exception":false,"start_time":"2021-03-18T23:18:50.01861","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['oof_cnn'] = preds\nprint(train['oof_cnn'].apply(len).mean())\n\nif COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:46:51.751008Z","start_time":"2021-03-26T06:46:49.61973Z"},"papermill":{"duration":2.243774,"end_time":"2021-03-18T23:19:16.449648","exception":false,"start_time":"2021-03-18T23:19:14.205874","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# title TFIDF","metadata":{"papermill":{"duration":0.018247,"end_time":"2021-03-18T23:19:16.4871","exception":false,"start_time":"2021-03-18T23:19:16.468853","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embeddings = model.fit_transform(train.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:46:59.945709Z","start_time":"2021-03-26T06:46:58.690579Z"},"papermill":{"duration":15.643462,"end_time":"2021-03-18T23:19:32.149674","exception":false,"start_time":"2021-03-18T23:19:16.506212","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_embeddings = torch.from_numpy(text_embeddings)\ntext_embeddings = text_embeddings.cuda()","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:47:00.912896Z","start_time":"2021-03-26T06:47:00.64134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)//CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nCTS_index = 0\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n    cts = cts.data.cpu().numpy()\n    print(cts.shape)\n    for k in range(b-a):\n        IDX = np.where(cts[k,]>0.7)[0]\n        # IDX = np.where(cts[k,list(preds_index[CTS_index])]>0.7)[0]\n        # IDX = [preds_index[CTS_index][x] for x in IDX]\n        o = train.iloc[IDX].posting_id.values\n        preds.append(o)\n        CTS_index += 1\n# del model, text_embeddings","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:48:35.60669Z","start_time":"2021-03-26T06:47:40.848693Z"},"papermill":{"duration":30.707718,"end_time":"2021-03-18T23:20:02.87689","exception":false,"start_time":"2021-03-18T23:19:32.169172","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_text'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:48:53.997671Z","start_time":"2021-03-26T06:48:52.108085Z"},"papermill":{"duration":2.190156,"end_time":"2021-03-18T23:20:05.095732","exception":false,"start_time":"2021-03-18T23:20:02.905576","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:48:54.896973Z","start_time":"2021-03-26T06:48:54.891361Z"},"papermill":{"duration":0.034801,"end_time":"2021-03-18T23:20:05.157135","exception":false,"start_time":"2021-03-18T23:20:05.122334","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    \n    train['cv_score'] = train.apply(getMetric('oof'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())\n    \ntrain['matches'] = train.apply(combine_for_sub,axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-03-26T06:50:19.601308Z","start_time":"2021-03-26T06:50:15.125103Z"},"papermill":{"duration":7.245672,"end_time":"2021-03-18T23:20:12.426532","exception":false,"start_time":"2021-03-18T23:20:05.18086","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:12.385916Z","start_time":"2021-03-18T10:06:12.180234Z"},"papermill":{"duration":0.358857,"end_time":"2021-03-18T23:20:12.808034","exception":false,"start_time":"2021-03-18T23:20:12.449177","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}