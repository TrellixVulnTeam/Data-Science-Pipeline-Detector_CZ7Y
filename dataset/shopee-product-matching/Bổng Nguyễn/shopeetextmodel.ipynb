{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import library\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport transformers\nimport gc\n\nfrom torch.nn import Parameter\nfrom torch.nn import functional as F\n\nfrom cuml.neighbors import NearestNeighbors\n\nfrom tqdm import tqdm\nimport pickle as pkl\n! pwd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-08T14:55:09.764977Z","iopub.execute_input":"2022-01-08T14:55:09.765251Z","iopub.status.idle":"2022-01-08T14:55:10.490447Z","shell.execute_reply.started":"2022-01-08T14:55:09.765222Z","shell.execute_reply":"2022-01-08T14:55:10.489652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global values and config\nNUM_WORKERS = 2\nBATCH_SIZE = 16\nPRETRAINED_MODEL = \"../input/xlnet-model/xlnet-base-cased\"\nFINE_TUNING_MODEL = dict(list(torch.load(\"../input/xlnet-model/fine_tuning_xlnet_base_cased.bin\").items())[:-1])\nMAX_LENGTH = 128\n\nprint(torch.cuda.is_available())\ndevice = torch.device('cuda')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.493914Z","iopub.execute_input":"2022-01-08T14:55:10.494562Z","iopub.status.idle":"2022-01-08T14:55:10.822236Z","shell.execute_reply.started":"2022-01-08T14:55:10.494529Z","shell.execute_reply":"2022-01-08T14:55:10.821426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(drop=False):\n    train_file = \"../input/shopee-product-matching/train.csv\"\n    df = pd.read_csv(train_file)\n    # add matches col in data frame\n    temp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n    df['matches'] = df['label_group'].map(temp)\n    # convert matches from \"[train_1, train_2]\" to \"train_1, train_2\"\n    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n    if drop:\n        df = df.drop(['image', 'image_phash', 'label_group'], 1)\n        \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.823796Z","iopub.execute_input":"2022-01-08T14:55:10.824057Z","iopub.status.idle":"2022-01-08T14:55:10.830249Z","shell.execute_reply.started":"2022-01-08T14:55:10.82402Z","shell.execute_reply":"2022-01-08T14:55:10.829511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeTextData(Dataset):\n    def __init__(self, data):\n        self.data = data.reset_index()\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n\n    def __len__(self):\n        return self.data.shape[0]\n        \n    def __getitem__(self, index):\n        title = self.data.iloc[index][\"title\"]\n        text = self.tokenizer(title, max_length = MAX_LENGTH, truncation=True, padding='max_length', return_tensors=\"pt\")\n        input_ids = text['input_ids'][0]\n        attention_mask = text['attention_mask'][0]  \n        return input_ids, attention_mask","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.832618Z","iopub.execute_input":"2022-01-08T14:55:10.833094Z","iopub.status.idle":"2022-01-08T14:55:10.842804Z","shell.execute_reply.started":"2022-01-08T14:55:10.833057Z","shell.execute_reply":"2022-01-08T14:55:10.84206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeModel(nn.Module):\n    #init from pretrained model: xlnet-base\n    def __init__(self, n_classes=11014 , pretrained_model=PRETRAINED_MODEL):\n        super(ShopeeModel,self).__init__()\n        self.transformer = transformers.AutoModel.from_pretrained(pretrained_model)\n\n    #forward \n    def forward(self, input_ids,attention_mask):\n        feature = self.transformer(input_ids,attention_mask)[0]\n        # remove seq_length\n        feature = feature[:,0,:]\n        # return [batch_size, hidden_size]\n        return F.normalize(feature)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.843919Z","iopub.execute_input":"2022-01-08T14:55:10.844313Z","iopub.status.idle":"2022-01-08T14:55:10.853154Z","shell.execute_reply.started":"2022-01-08T14:55:10.844275Z","shell.execute_reply":"2022-01-08T14:55:10.852458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text_embeddings(df):\n    embeddings = []\n    model = ShopeeModel()\n    model.eval()\n    # fine-tuning model Shopee \n    model.load_state_dict(FINE_TUNING_MODEL)\n    model = model.to(device)\n    # prepare data\n    text_data = ShopeeTextData(df)\n    text_dataloader = torch.utils.data.DataLoader(text_data, batch_size=BATCH_SIZE, \n                                                  num_workers=NUM_WORKERS,pin_memory=True,\n                                                  drop_last=False,)\n    # generate text_embeddings\n    with torch.no_grad():\n        for input_ids, attention_mask in tqdm(text_dataloader):\n            input_ids = input_ids.cuda()\n            attention_mask = attention_mask.cuda()\n            feature = model(input_ids, attention_mask)\n            embeddings.append(feature.detach().cpu().numpy())\n            \n    text_embeddings = np.concatenate(embeddings)\n    # delete and collect gabage\n    del embeddings, model\n    gc.collect()\n    print('text_embeddings shape:', text_embeddings.shape)\n    return text_embeddings\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.854362Z","iopub.execute_input":"2022-01-08T14:55:10.854872Z","iopub.status.idle":"2022-01-08T14:55:10.864413Z","shell.execute_reply.started":"2022-01-08T14:55:10.854835Z","shell.execute_reply":"2022-01-08T14:55:10.863634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\ndef get_neighbors_knn(df, text_embeddings, KNN=50, threshold=0.9):\n    # create KNN model and calculate distances\n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(text_embeddings)\n    distances, ids = model.kneighbors(text_embeddings)\n    \n    predictions = []\n    n_id = text_embeddings.shape[0]\n    # iterate all data rows and pick ids that distance < threshold\n    for row in range(n_id):\n        col = np.where(distances[row,] < threshold)[0]\n        pos = ids[row,col]\n        posting_ids = ' '.join(df['posting_id'].iloc[pos].values)\n        predictions.append(posting_ids)\n    del model, distances, ids\n    gc.collect()\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.865736Z","iopub.execute_input":"2022-01-08T14:55:10.866047Z","iopub.status.idle":"2022-01-08T14:55:10.878566Z","shell.execute_reply.started":"2022-01-08T14:55:10.866011Z","shell.execute_reply":"2022-01-08T14:55:10.877778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot img in same label\ndef get_list_img_same_label(label,train_data_labels):\n  list_name =[]\n  list_title = []\n  for i in range(len(train_data_labels)):\n    if label == train_data_labels[i]:\n      list_name.append(\"../input/shopee-product-matching/train_images/\" + train_data_imgs[i])\n      list_title.append(str(i) + \"\\n\" + train_data_titles[i])\n  return list_name,list_title\n\ndef show_data_img(list_name, list_title):\n  list_len = len(list_name)\n  fig = plt.figure(figsize=(10, 10))\n  i=1\n  cols = int(list_len/4) + 1\n  rows = int(list_len / (cols)) +1\n  for j in range(len(list_name)):\n    img_file = list_name[j]\n    img_title = list_title[j]\n    plt.subplot(rows, cols, i)\n    plt.axis(False)\n    img = Image.open(img_file)\n    plt.title(img_title)\n    plt.imshow(img)\n    i = i+1\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.879792Z","iopub.execute_input":"2022-01-08T14:55:10.880235Z","iopub.status.idle":"2022-01-08T14:55:10.890792Z","shell.execute_reply.started":"2022-01-08T14:55:10.8802Z","shell.execute_reply":"2022-01-08T14:55:10.890024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare data\ndf = load_data()\ndf.head()\n\n# plot image\ntrain_data_names, train_data_imgs, train_data_titles = df[\"posting_id\"], df[\"image\"], df[\"title\"]\n# choose 1 label to plot\nnum = 412\nlabel = df[\"label_group\"][num]\ntrain_data_labels = df[\"label_group\"]\n\n\n  \nshow_data_img(*get_list_img_same_label(label,train_data_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:10.892104Z","iopub.execute_input":"2022-01-08T14:55:10.892483Z","iopub.status.idle":"2022-01-08T14:55:12.369204Z","shell.execute_reply.started":"2022-01-08T14:55:10.892434Z","shell.execute_reply":"2022-01-08T14:55:12.368507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_embeddings = generate_text_embeddings(df)\n# save text_embeddings\n# with open('text_embeddings.pkl', 'wb') as file:\n#     pkl.dump(text_embeddings, file)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:55:12.371401Z","iopub.execute_input":"2022-01-08T14:55:12.371919Z","iopub.status.idle":"2022-01-08T14:58:25.749743Z","shell.execute_reply.started":"2022-01-08T14:55:12.371877Z","shell.execute_reply":"2022-01-08T14:58:25.748961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_predictions = get_neighbors_knn(df,text_embeddings)\n\nresult = df.loc[:,['posting_id','matches']]\nresult['predictions'] = text_predictions\nresult['f1'] = f1_score(result['matches'],result['predictions'])\ndisplay(result)\n\nplt.figure()\nresult['f1'][::200].plot()\nplt.title(\"f1 mean: \" + str(result['f1'].mean()))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:58:25.751623Z","iopub.execute_input":"2022-01-08T14:58:25.752141Z","iopub.status.idle":"2022-01-08T14:58:29.619246Z","shell.execute_reply.started":"2022-01-08T14:58:25.752096Z","shell.execute_reply":"2022-01-08T14:58:29.61854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit\nmysubmission = df.loc[:,['posting_id','matches']]\nmysubmission['matches'] = text_predictions\nmysubmission.to_csv('submission.csv',index=False)\ndisplay(mysubmission)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T14:58:29.620761Z","iopub.execute_input":"2022-01-08T14:58:29.621262Z","iopub.status.idle":"2022-01-08T14:58:29.845365Z","shell.execute_reply.started":"2022-01-08T14:58:29.621221Z","shell.execute_reply":"2022-01-08T14:58:29.844584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}