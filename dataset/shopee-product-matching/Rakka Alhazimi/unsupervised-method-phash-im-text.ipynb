{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Your Trustwhorty Libraries","metadata":{}},{"cell_type":"code","source":"# We always do this\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\n# Mainly for deep learning\nimport keras\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport tensorflow.keras.backend as K\n\n# Array powered-CUDA\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import normalize\n\n# Python std. libraries\nimport os, threading, logging, gc, tqdm\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameter\nBATCH = 64\nIMAGE_SIZE = (512, 512)\nN_CLASS = 11014\n\nDATA_PATH = \"../input/shopee-product-matching/\"\nTRAIN_PATH = DATA_PATH + \"train_images/\"\nTEST_PATH = DATA_PATH + \"test_images/\"\nSPLITS = 100 # for spliting dataset\n\n# True: for CV , False: for Commit\nGET_CV = False ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n# SO THAT WE HAVE 14GB RAM FOR RAPIDS\nLIMIT = 2.0\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pandas dataframe\ntrain = pd.read_csv(DATA_PATH + \"train.csv\")\ntest = pd.read_csv(DATA_PATH + \"test.csv\")\n\n# RAPIDS dataframe\ntrain_cuda = cudf.read_csv(DATA_PATH + 'train.csv')\ntest_cuda = cudf.read_csv(DATA_PATH + 'test.csv')\n\nif GET_CV:\n    # Use train data\n    df = train\n    df_cuda = train_cuda\n    MAIN_PATH = TRAIN_PATH\n    \nelse:\n    # Use test data\n    df = test\n    df_cuda = test_cuda\n    MAIN_PATH = TEST_PATH\n\ntrain_cuda.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A little sanity checks on dataframe","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many class in here\ntrain[\"label_group\"].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"if GET_CV:\n    target = df.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n    df[\"target\"] = df[\"label_group\"].map(target)\n\npred_phash = df.groupby(\"image_phash\").posting_id.agg(\"unique\").to_dict()\ndf[\"pred_phash\"] = df[\"image_phash\"].map(pred_phash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if GET_CV:\n    # Metrics: F1 Score\n    def get_metric(col):\n        def f1_score(row):\n            n = len( np.intersect1d(row.target,row[col]) )\n            return 2*n / (len(row.target)+len(row[col]))\n        return f1_score\n\n    df[\"f1_phash\"] = df.apply(get_metric(\"pred_phash\"), axis=1) # axis=1 will return df row\n    print(\"F1 score with baseline model (phash) {}\".format(df[\"f1_phash\"].mean()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image_phash LB score: 0.559","metadata":{}},{"cell_type":"markdown","source":"# Image Features\n","metadata":{}},{"cell_type":"markdown","source":"## Backbone model: EfficientNetB0","metadata":{}},{"cell_type":"code","source":"# Build pretrained model and load its weights\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\nweight_path = \"../input/keras-pretrained-models/EfficientNetB0_NoTop_ImageNet.h5\"\npre_CNN = EfficientNetB0(include_top=False, \n                         weights=weight_path,\n                         pooling=\"avg\")\n\npre_CNN.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read image in dataset\ndef read_im(path):\n    file = tf.io.read_file(path)\n    image = tf.io.decode_jpeg(file, channels=0)\n    image = tf.image.resize(image, (512, 512))\n    image = tf.cast(image, dtype=tf.float32) / 255.\n    \n    return image\n\n# Dataset pipeline from filenames --> image arrays\ndef get_image_dataset(filenames):\n    image_dataset = tf.data.Dataset.from_tensor_slices(filenames)\n    image_dataset = image_dataset.map(read_im, num_parallel_calls=tf.data.AUTOTUNE)\\\n                                 .prefetch(tf.data.AUTOTUNE)\n    return image_dataset\n    \n\ndef get_embedding(filenames):\n    embeds = []\n    # So, we split our array into N-splits and extract their features one by one.\n    splits = np.array_split(filenames, SPLITS)\n    for split in tqdm.tqdm( splits ):\n        \n        # when no data left, stop immediately (when test data len is still 3)\n        if not split.any(): \n            break\n        dataset = get_image_dataset(split)\n        features = pre_CNN.predict(dataset)\n        embeds.append(features)\n        \n    return tf.concat(embeds,axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = MAIN_PATH + df[\"image\"]\nimage_embedding = get_embedding(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def im_preds(df, feature, splits):\n    feature_chunks = cupy.array_split(feature, splits)\n    preds = []\n\n    for fc in tqdm.tqdm(feature_chunks):\n\n        # Dot product of unit vector = Cosine Similarity\n        # When their dot product got higher, the closer they are\n        dp = cupy.matmul(feature, fc.T).T\n        \n        # This mask is consist of series of true-false value\n        # It is True when the dot product is above the limit\n        mask = cupy.where(dp > 1., True, False)\n        for m in mask:\n            preds.append( df.posting_id[m.get()].values ) # we use .get() to convert cupy to np\n\n    return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_norm = normalize(image_embedding, axis=1)\nim_norm = cupy.array(im_norm)\nimage_preds = im_preds(df, im_norm, SPLITS)\n\n# Delete variable and perform garbage collection\n# RAM: You know, this CUDA-thing made me full. I feels relaxed, now.\ndel im_norm\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"pred_images\"] = image_preds\n\nif GET_CV:\n    df[\"f1_images\"] = df.apply(get_metric(\"pred_images\"), axis=1)\n    df[\"f1_images\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ignore this, just tuning the threshold\n\n# z = normalize(image_embedding, axis=1)\n# z = (z @ z[:2].T).T\n# x = np.where(z > 0.9999999, True, False)\n# for y in x:\n#     print(df[y].posting_id)\n#     print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Label for each distinct group\n# labels = train[\"label_group\"].unique()\n# labels_map = {label: index for index, label in enumerate(labels)}\n# train[\"label\"] = train[\"label_group\"].map(labels_map)\n# image_labels = train[\"label\"].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Features","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embed = tfidf.fit_transform(df_cuda.title).toarray()\ntext_embed = cupy.array(text_embed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = 100\n\ndef text_preds(df, feature, splits):\n    feature_chunks = cupy.array_split(feature, splits)\n    preds = []\n\n    for fc in tqdm.tqdm(feature_chunks):\n\n        # Dot product of unit vector = Cosine Similarity\n        # When their dot product got higher, the closer they are\n        dp = cupy.matmul(feature, fc.T).T\n        \n        # This mask is consist of series of true-false value\n        # It is True when the dot product is above the limit\n        mask = cupy.where(dp > 0.7, True, False)\n        for m in mask: \n            preds.append( df.posting_id[m.get()].values ) # we use .get() to convert cupy to np\n            \n    return preds\n\npreds = text_preds(df, text_embed, splits)\n\n# Delete variable and perform garbage collection\n# RAM: Okay, I'm taking my vacation, good luck !\ndel text_embed\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New column of text embed predictions\ndf[\"pred_text_embed\"] = preds\n\nif GET_CV:\n    # Compute f1 score\n    df[\"f1_text\"] = df.apply(get_metric(\"pred_text_embed\"), axis=1)\n    f1 = df[\"f1_text\"].mean()\n    print(\"f1_score with text embeddings: {}\".format(f1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine Baseline, Images and Text features predictions","metadata":{}},{"cell_type":"code","source":"def concat_pred(row):\n    preds = np.concatenate([row.pred_phash, row.pred_images, row.pred_text_embed])\n    return np.unique(preds)\n\ndf[\"matches\"] = df.apply(concat_pred, axis=1)\n\nif GET_CV:\n    df[\"f1_match\"] = train.apply(get_metric(\"matches\"), axis=1)\n    df[\"f1_match\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\"posting_id\": df.posting_id, \"matches\": df.matches})\nsubmission[\"matches\"] = submission[\"matches\"].map(lambda x: \" \".join(x))\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}