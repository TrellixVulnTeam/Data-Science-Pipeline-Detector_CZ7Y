{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\n\nimport sys\nimport torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\"\"\"\nif torch.cuda.is_available():\n    !cp ../input/rapids/rapids.0.18.0 /opt/conda/envs/rapids.tar.gz\n    !cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n    sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n    sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n    sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n    !cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\n\ntqdm.pandas()\nimport os\nimport copy\nimport time\nimport math\nimport cv2\nimport PIL.Image as Image\nimport random\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm.notebook import tqdm\nimport gc\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, models\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\n\nif torch.cuda.is_available():\n    import cudf, cuml, cupy\n    from cuml.feature_extraction.text import TfidfVectorizer\n    from cuml.neighbors import NearestNeighbors\n    print('RAPIDS',cuml.__version__)\n\nimport albumentations\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 512\nbatch_size = 42\ndata_dir = '../input/shopee-product-matching/'\n\nCOMPUTE_CV = False\n\nif COMPUTE_CV:\n    test_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test_df['file_path'] = test_df.image.apply(lambda x: os.path.join(data_dir + 'train_images', x))\n    le = LabelEncoder()\n    test_df.label_group = le.fit_transform(test_df.label_group)\nelse:\n    test_df = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_df['file_path'] = test_df.image.apply(lambda x: os.path.join(data_dir + 'test_images', x))\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_train = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    #albumentations.HorizontalFlip(p=0.5),\n    #albumentations.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n    #albumentations.HueSaturationValue(p=0.5, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n    #albumentations.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n    #albumentations.CoarseDropout(p=0.5),\n    albumentations.Normalize()\n])\n\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    albumentations.Normalize()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SHOPEEDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        \n        img1 = self.df.iloc[index]\n        if COMPUTE_CV == True:\n            img1_label = img1.label_group\n        img1 = cv2.imread(img1.file_path)\n        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img1)\n            img1 = res['image']\n                \n        img1 = img1.astype(np.float32)\n        img1 = img1.transpose(2,0,1)\n        \n        if self.mode == 'test':\n            return torch.tensor(img1).reshape(3,image_size,image_size).float()\n        else:\n            return torch.tensor(img1).reshape(3,image_size,image_size).float(), torch.tensor(img1_label).long()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\n\ndef combine_predictions(row):\n    x = np.concatenate([row['img_preds'], row['txt_preds'], row['phash_predictions']])\n    if COMPUTE_CV == False:\n        return ' '.join(np.unique(x))\n    else:\n        return np.unique(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Shopee_model(nn.Module):\n    def __init__(self, fc_dim, num_classes, use_pretrained=True):\n        super(Shopee_model, self).__init__()\n        \n        self.model_ft = timm.create_model('efficientnet_b0', pretrained=use_pretrained)\n        \n        in_features = self.model_ft.classifier.in_features\n        self.model_ft.classifier = nn.Identity()\n        self.model_ft.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(p=0.1)\n        self.classifier = nn.Linear(in_features, fc_dim)\n        self.bn = nn.BatchNorm1d(fc_dim)\n        self._init_params()\n        self.arc_layer = ArcMarginProduct(in_feature=fc_dim, out_feature=num_classes, s=30, m=0.50, easy_margin=False)\n        \n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.constant_(self.classifier.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    def forward(self, img, labels):\n        features = self.extract_features(img)\n        if self.training:\n            logits = self.arc_layer(features, labels)\n            return logits\n        else:\n            return features\n        \n    def extract_features(self, x):\n        batch_size = x.shape[0]\n        x = self.model_ft(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        if self.training:\n            x = self.dropout(x)\n            x = self.classifier(x)\n            x = self.bn(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_feature=128, out_feature=10575, s=30, m=0.50, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_feature = in_feature\n        self.out_feature = out_feature\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.Tensor(out_feature, in_feature))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n\n        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, x, label):\n        # cos(theta)\n        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n        # cos(theta + m)\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n\n        #one_hot = torch.zeros(cosine.size(), device='cuda' if torch.cuda.is_available() else 'cpu')\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, label.view(-1, 1), 1)\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output = output * self.s\n\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV == True:\n    tmp = test_df.groupby('label_group').posting_id.agg('unique').to_dict()\n    test_df['target'] = test_df.label_group.map(tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def query_expansion(model, embeds):\n    CHUNK = 1024 * 2\n    n = len(embeds)\n    CTS = n // CHUNK\n    if n % CHUNK != 0: CTS += 1\n    new_embeds = []\n\n    for j in range(CTS):\n        a = j * CHUNK\n        b = (j + 1) * CHUNK\n        b = min(b, n)\n        print('chunk',a,'to',b)\n\n        distances, indices = model.kneighbors(embeds[a:b,])\n        for i in range(b - a):\n            IDS = indices[i,].get()\n            o = embeds[IDS].sum(axis=0)\n            o = torch.tensor(o).reshape(1, -1)\n            o = F.normalize(o)\n            new_embeds.append(o[0].detach().cpu().numpy())\n    return new_embeds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(df, embeds, threshold, data_type='img', metric='euclidean', KNN=100):\n    CHUNK = 1024 * 2\n    n = len(df)\n    preds = []\n    CTS = n // CHUNK\n    model = NearestNeighbors(n_neighbors=KNN, metric=metric)\n    model.fit(embeds)\n    if n % CHUNK != 0: CTS += 1\n    f1_name = data_type + '_f1'\n    preds_name = data_type + '_preds'\n    if data_type == 'img':\n        for j in range(CTS):\n            a = j * CHUNK\n            b = (j + 1) * CHUNK\n            b = min(b, n)\n            print('chunk',a,'to',b)\n\n            distances, indices = model.kneighbors(embeds[a:b,])\n            for k in range(b - a):\n                IDX = np.where(distances[k,] < threshold)[0]\n                IDS = indices[k,IDX].get()\n                o = df.iloc[IDS].posting_id.values\n                preds.append(o)\n    else:\n        for j in range(CTS):\n            a = j * CHUNK\n            b = (j + 1) * CHUNK\n            b = min(b, n)\n            print('chunk',a,'to',b)\n\n            distances, indices = model.kneighbors(embeds[a:b,])\n            for k in range(b - a):\n                IDX = np.where(distances[k,] < threshold)[0]\n                IDS = indices[k,IDX].get()\n                o = df.iloc[IDS].posting_id.values\n                preds.append(o)\n                \n    df[preds_name] = preds\n    del model\n    if COMPUTE_CV == True:\n        df[f1_name] = df.apply(getMetric(preds_name), axis=1)\n        mean = df[f1_name].mean()\n        print('CV score for for threshold with {} Dist {} ='.format(metric, threshold), mean)\n        return df, mean\n    else:\n        return df, 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 11014\nfc_dim = 512\n\nmodel_ft = Shopee_model(fc_dim ,num_classes, use_pretrained=False)\nmodel_ft.load_state_dict(torch.load('../input/modelstate52v1/model (5).pt'))\nmodel_ft.eval()\nmodel_ft.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = SHOPEEDataset(test_df, 'test', transform=transforms_train)\nembeds = []\ndata_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=12, shuffle=False, num_workers=4)\nwith torch.no_grad():\n    for img in tqdm(data_loader_test):\n        img = img.to(device)\n        img = model_ft.extract_features(img)\n        embeds.append(img.detach().cpu().numpy())\ndel model_ft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeds = np.array(embeds)\nimg_embeds = []\nfor batch in embeds:\n    for x in batch:\n        img_embeds.append(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\ncomp = min(len(img_embeds), 500)\npca = PCA(n_components=comp)\npca.fit(img_embeds)\nimg_embeds_pca = pca.transform(img_embeds)\nprint(pca.explained_variance_ratio_.sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_embeds = cupy.asarray(img_embeds_pca)\nmodel = NearestNeighbors(n_neighbors=2, metric='euclidean')\nmodel.fit(img_embeds)\nfor _ in range(1):\n\n    img_embeds = query_expansion(model, img_embeds)\n    img_embeds = cupy.asarray(img_embeds)\ndel model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV == True:\n    best = 0\n    img_embeds = cupy.asarray(img_embeds)\n    for thresh in list(np.arange(.9, 1, 0.05)):\n        tmp_df, tmp_score = get_score(test_df, img_embeds, thresh, data_type='img', metric='euclidean')\n        if tmp_score > best:\n            test_df = tmp_df\n            best = tmp_score\nelse:\n    thresh = 0.5\n    img_embeds = cupy.asarray(img_embeds)\n    KNN = min(100, len(test_df))\n    test_df, _ = get_score(test_df, img_embeds, thresh, data_type='img', metric='euclidean', KNN=KNN)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cuml.feature_extraction.text import TfidfVectorizer\n\ndf_cu = cudf.DataFrame(test_df)\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=15000)\ntext_embeddings = model.fit_transform(df_cu['title']).toarray()\nprint('text embeddings shape',text_embeddings.shape)\ndel model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV == True\nif COMPUTE_CV == True:\n    best = 0\n    for thresh in list(np.arange(0.9, 1, 0.05)):\n        tmp_df, tmp_score = get_score(test_df, text_embeddings, thresh, data_type='txt', metric='euclidean')\n        if tmp_score > best:\n            test_df = tmp_df\n            best = tmp_score\nelse:\n    thresh = .65\n    text_embeddings = cupy.asarray(text_embeddings)\n    KNN = min(100, len(test_df))\n    test_df, _ = get_score(test_df, text_embeddings, thresh, data_type='txt', metric='euclidean', KNN=KNN)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = test_df.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest_df['phash_predictions'] = test_df.image_phash.map(tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['matches'] = test_df.apply(combine_predictions, axis=1)\nif COMPUTE_CV == True:\n    test_df['final_f1'] = test_df.apply(getMetric('matches'), axis=1)\n    print('CV score =',test_df.final_f1.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[['posting_id', 'matches']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}