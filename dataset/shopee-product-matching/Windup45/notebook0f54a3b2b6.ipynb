{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\n!pip install tensorflow_addons\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom tqdm.notebook import tqdm\nfrom kaggle_datasets import KaggleDatasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cudf\nimport cuml\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml import PCA\nfrom cuml.neighbors import NearestNeighbors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\nBATCH_SIZE = 8\nIMAGE_SIZE =[512,512]\n\nN_CLASSES = 11011\nLIMIT = 4.0\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\nlogical_gpus = tf.config.experimental.list_logical_devices('GPU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dataset():\n    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n    df['matches'] = df['label_group'].map(tmp)\n    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n    image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n    return df, image_paths\n\ndef read_image(image):\n    image = tf.io.read_file(image)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) /255.0\n    return image\n\ndef get_dataset(image):\n    dataset = tf.data.Dataset.from_tensor_slices(image)\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(tf.keras.layers.Layer):\n    def __init__(self, n_classes, s = 30, m = 0.50, **kwargs):\n        super(ArcMarginProduct, self).__init__(**kwargs)\n        \n        self.n_classes = N_CLASSES\n        self.s = s\n        self.m = m\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi -m)\n        self.mm = tf.math.sin(math.pi -m) *m\n        \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n        })\n        \n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n        \n    def call(self,inputs):\n        X,y = inputs\n        y = tf.cast(y,dtype=tf.int32)\n        \n        cosine= tf.matmul(tf.math.l2_normalize(X,axis =1), \n                          tf.math.l2_normalize(self.W,axis=0))\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine,2))\n        \n        phi = cosine*self.cos_m - sine*self.sin_m\n        phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.one_hot(y, depth = self.n_classes)\n        \n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_embeddings(image_paths):\n    with tf.device('/GPU:0'):\n        embeddings = []\n        margin = ArcMarginProduct(\n            n_classes = N_CLASSES,\n            s = 30,\n            m = 0.7,\n            name = 'arc_margin',\n            dtype = 'float32')\n\n        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE,3), name = 'inp1')\n        label = tf.keras.layers.Input(shape=(), name = 'inp2')\n        x = efn.EfficientNetB5(weights = 'imagenet', include_top = False)(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        x = margin([x,label])\n\n        output = tf.keras.layers.Softmax(dtype='float32')(x)\n        model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n        model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n        \n        #The following seems to be the common consensus on minimizing memeory errors\n        #In summary, process the images in chunks\n\n        subset = 2000\n        iterator = np.arange(np.ceil(len(data)/subset))\n        for i in iterator:\n            a = int(i * subset)\n            b = int((i+1) * subset)\n            image_dataset = get_dataset(image_paths[a:b])\n            image_embeddings = model.predict(image_dataset)\n            embeddings.append(image_embeddings)\n            print(f'finished {i + 1}/{iterator[-1]} of the images')\n\n        del image_embeddings\n        image_embeddings = np.concatenate(embeddings)\n        \n        return image_embeddings\n\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors(df, embeddings, KNN = 50, image = True):\n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n\n  \n    thresholds = list(np.arange(3.0, 5.0, 0.1))\n    scores = []\n    for threshold in thresholds:\n        predictions = []\n        for k in range(embeddings.shape[0]):\n            idx = np.where(distances[k,] < threshold)[0]\n            ids = indices[k,idx]\n            posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n            predictions.append(posting_ids)\n        df['pred_matches'] = predictions\n        df['f1'] = f1_score(df['matches'], df['pred_matches'])\n        score = df['f1'].mean()\n        print(f'Our f1 score for threshold {threshold} is {score}')\n        scores.append(score)\n    thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n    max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n    best_threshold = max_score['thresholds'].values[0]\n    best_score = max_score['scores'].values[0]\n    print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n\n    # Use threshold\n    predictions = []\n    for k in range(embeddings.shape[0]):\n        # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n        idx = np.where(distances[k,] < 4.0)[0]\n       \n        ids = indices[k,idx]\n        posting_ids = df['posting_id'].iloc[ids].values\n        predictions.append(posting_ids)\n\n    del model, distances, indices\n    return df, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data, image_paths = read_dataset()\n\nimage_embeddings = get_image_embeddings(image_paths)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, image_predictions = get_neighbors(data, image_embeddings, KNN = 50, image = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}