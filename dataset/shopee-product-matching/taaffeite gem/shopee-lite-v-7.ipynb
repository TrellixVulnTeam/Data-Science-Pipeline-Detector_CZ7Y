{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport math\nimport numpy as np\nimport cudf\nfrom keras.models import Model\n\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, GlobalAveragePooling2D,Dropout,Flatten\nfrom keras.layers import MaxPooling2D,Dense\nfrom keras.layers.merge import concatenate\nfrom keras.utils import plot_model\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers, models\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\n\n\nfrom tqdm import tqdm  \n\nfrom sklearn.utils import shuffle\n\nimport itertools\n\nimport random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(tf.config.experimental.list_physical_devices('GPU'))< 1:\n    raise Exception(\"Sorry, no GPU found\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/shopee-product-matching/train.csv')\ntest_df = pd.read_csv('../input/shopee-product-matching/test.csv')\nlen_data_train  = len(train_df)\nlen_data_test  = len(test_df)\nBATCH_SIZE = 32\nTRAIN_BATCHES = math.ceil(len_data_train/BATCH_SIZE)\nTEST_BATCHES = math.ceil(len_data_test/BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not len_data_test > 3: FRONT_END = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = '../input/shopee-product-matching/train_images'\ntest_images = '../input/shopee-product-matching/test_images'\nIMG_SIZE = 32\neta = 1/1000.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def myzip(s,t):\n    return [(s[i], t[i]) for i in range(len(s))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(set(train_df.label_group.tolist()))\n \nlabels.sort()\nno_classes = len(labels)\n\nlabel=[]\nmapped=[]\nfor index,value in enumerate(labels):\n    label.append(value)\n    mapped.append(index)\nzipper = myzip(label, mapped)\nreverse = myzip(mapped,label)\nlabel_dict = dict(zipper)\nreverse_dict = dict(reverse)\n\nfor index,label in enumerate(train_df.label_group):    \n    train_df.at[index,'label_group'] = label_dict[label]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ys = train_df.label_group.to_numpy().astype(np.float32)\n\nxs_train_image = train_df.image.to_numpy()\nxs_test_image = test_df.image.to_numpy()\n\nxs_train_image,ys = shuffle(xs_train_image,ys)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_images(test_batch):\n    if isinstance(test_batch, str):\n        test_batch = [test_batch]\n    xs_test = np.empty([len(test_batch),IMG_SIZE,IMG_SIZE,3])\n    for index,image in enumerate(test_batch):\n        path = os.path.join(test_images,image)\n        img = tf.keras.preprocessing.image.load_img(path) \n        img = tf.keras.preprocessing.image.img_to_array(img) \n        img = tf.keras.preprocessing.image.smart_resize(img,size=(IMG_SIZE,IMG_SIZE)) \n        img = np.array([img])\n        xs_test[index] = img/255.0\n    return xs_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xs = np.empty([len_data_train,IMG_SIZE,IMG_SIZE,3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_xs(xs_batch,batch):\n    for index,image in enumerate(xs_batch):\n        path = os.path.join(train_images,image)\n        img = tf.keras.preprocessing.image.load_img(path) \n        img = tf.keras.preprocessing.image.img_to_array(img)         \n        img = tf.keras.preprocessing.image.smart_resize(img,size=(IMG_SIZE,IMG_SIZE)) \n        img = np.array([img])\n        xs[BATCH_SIZE*batch+index] = img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in tqdm(range(TRAIN_BATCHES)):\n        get_xs(xs_train_image[batch * BATCH_SIZE : min(BATCH_SIZE*batch + BATCH_SIZE,len_data_train)],batch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,    \n    rotation_range=23,\n    width_shift_range=0.23,\n    height_shift_range=0.23,\n    horizontal_flip=True,\n    zoom_range=0.23,\n    \n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator( \n    rescale=1./255,    \n    rotation_range=29,\n    width_shift_range=0.29,\n    height_shift_range=0.29,\n    horizontal_flip=True,\n    zoom_range=0.29,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def divergence(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n    # 1x1 conv\n    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n    # 3x3 conv\n    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n    # 5x5 conv\n    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n    # max pooling\n    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n    # concatenate filters and max pool community\n    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n    layer_out = MaxPooling2D((2,2), strides=(2,2))(layer_out)\n    return layer_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for creating output block\ndef out_block(layer_in,classes):\n    layer_in = Dropout(0.31)(layer_in)\n    layer_in = Flatten()(layer_in)\n    layer_in = Dense(classes)(layer_in)\n    return layer_in","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    # define model input\n    visible = Input(shape=(IMG_SIZE, IMG_SIZE, 3))    \n    layer = divergence(visible, 128,   64, 128, 32, 64,    64)\n    layer = divergence(layer, 256,      128, 256, 64, 128,     128)\n    layer = out_block(layer, no_classes)\n    return Model(inputs=visible, outputs=layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\n  \nmodel.compile(optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes=True, to_file='divergence.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_datagen.flow(xs, ys, batch_size=BATCH_SIZE),\n              steps_per_epoch=len(xs) / BATCH_SIZE, epochs=45,validation_data=(test_datagen.flow(xs, ys, batch_size=BATCH_SIZE)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FRONT_END:\n    import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FRONT_END:\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    test_loss, test_acc = model.evaluate(test_datagen.flow(xs, ys, batch_size=32), verbose=2)\n\n    print(test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(xs_test):    \n    return np.argmax(model.predict(xs_test), axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not 'label_group' in test_df:\n    test_df['label_group'] = test_df.image.map(get_test_images).map(predict).map(lambda x: x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = test_df.groupby('label_group').posting_id.agg('unique').to_dict()\ntest_df['match_post'] = test_df.label_group.map(temp)\ntemp = test_df.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest_df['match_phash'] = test_df.image_phash.map(temp)\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/cdeotte\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.match_post,row[col]) )\n        return 2*n / (len(row.match_post)+len(row[col]))\n    return f1score\n\ndef combine_for_sub(row):\n    x = np.concatenate([row.match_post,row.match_phash])\n    return ' '.join( np.unique(x) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FRONT_END:\n    test_df['f1'] = test_df.apply(getMetric('match_phash'),axis=1)\n    print('CV score for baseline =',test_df.f1.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['matches'] = test_df.apply(combine_for_sub,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[['posting_id','matches']].to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FRONT_END:\n    xs_test = get_test_images(xs_test_image)\n    predictions = predict(xs_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FRONT_END:\n    for index,prediction in enumerate(predictions):\n   \n        matches = train_df.loc[train_df['label_group'] == prediction].index.values.tolist()\n        plt.figure(figsize=(10,10))\n        for i,match in enumerate(matches[:25]):\n            image = train_df.iloc[match].image\n            path = os.path.join(train_images,image)\n            img = tf.keras.preprocessing.image.load_img(path) \n        \n            plt.subplot(5,5,i+1)\n            plt.xticks([])\n            plt.yticks([])\n            plt.grid(False)\n            plt.imshow(img, cmap=plt.cm.binary)\n            plt.xlabel(reverse_dict[prediction])#reverse lookup dictionary\n        plt.show()\n        posting_id = test_df.iloc[index,:].posting_id\n    \n        image = test_df.iloc[index,:].image\n        path = os.path.join(test_images,image)\n        img = tf.keras.preprocessing.image.load_img(path)     \n        plt.figure(figsize=(32,32))\n        plt.subplot(5,5,1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(img, cmap=plt.cm.binary)\n        plt.xlabel(posting_id)\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}