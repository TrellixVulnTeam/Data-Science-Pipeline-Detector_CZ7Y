{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:4]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.layers import Conv2D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG(object):\n  \"\"\"CONFIG\"\"\"\n  def __init__(self):\n    self.img_size = (224, 224)\n    self.base = '../input/shopee-product-matching/'\n    self.df = '../input/shopee-product-matching/train.csv'\n    self.batch_size = 32\n    self.val_split = 0.25\n    self.seed = 22\n    self.n_epochs = 40\n    \n    \ncfg= CONFIG()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv(cfg.df)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_img(img_id):\n    path = cfg.base + 'train_images/' + img_id\n    img = cv2.imread(path)\n    img = cv2.resize(img, cfg.img_size)\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_decoder(with_labels=True, target_size=cfg.img_size, ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n            \n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n#         img = tf.cast((img> 0.9), tf.float32)\n        return img\n    \n    def decode_with_labels(path):\n        x = decode(path)\n        return x, x\n    \n    return decode_with_labels if with_labels else decode\n\nimg_decoder = build_decoder(with_labels=True, target_size= cfg.img_size,  ext='jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TPU or GPU detection\ndef auto_select_accelerator():\n    \"\"\"\n    Reference: \n        * https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n        * https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training\n    \"\"\"\n    try:  # detect TPUs\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  ## detect TPUs\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n        #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n        #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n        \n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    return strategy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = keras.Sequential([\n    preprocessing.RandomRotation([-0.07, 0.07]),\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomTranslation([-0.1, 0.1], [-0.1, 0.1]),\n    preprocessing.RandomZoom([0, 0.1]),\n    preprocessing.RandomContrast(0.05)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment(img, label):\n    img = tf.reshape(img, [-1, 224, 224, 3])\n    img = data_augmentation(img)\n    img = tf.reshape(img, [224, 224, 3])\n    return img, img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Build_dataset(paths, labels= None, apply_aug=False, batch= cfg.batch_size,\n                  decode_fn=img_decoder,repeat= True, shuffle= cfg.seed):\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    if apply_aug:\n        dset = dset.map(augment, num_parallel_calls=AUTO)\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(batch).prefetch(AUTO)\n    \n    return dset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_NAME  = \"shopee-product-matching\"\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * cfg.batch_size\n\ntpu_bsize= cfg.batch_size * strategy.num_replicas_in_sync\ntpu_bsize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(DATASET_NAME)\nGCS_DS_PATH","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_paths = GCS_DS_PATH + '/train_images/' + pd.Series(os.listdir('../input/shopee-product-matching/train_images/'))\n\n# Train test split\n(train_paths, valid_paths)\\\n    = train_test_split(img_paths, test_size=cfg.val_split, random_state=11)\n\nprint(train_paths.shape, valid_paths.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the tensorflow datasets\nimg_gen1 = Build_dataset(train_paths, labels= None, repeat=False, shuffle=False)\nimg_gen2 = Build_dataset(train_paths, labels=None, apply_aug=True, repeat=False, shuffle=False)\nimg_gen = img_gen1.concatenate(img_gen2)\n\nval_gen = Build_dataset(valid_paths, labels= None, repeat=False, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_gen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data, _ = img_gen.take(2)\nimages = data[0].numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(3, 4, figsize=(15,10))\naxes = axes.flatten()\nfor img, ax in zip(images, axes):\n    ax.imshow(img, aspect= True)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install efficientunet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgd = keras.optimizers.SGD(learning_rate=0.01)\nadam = keras.optimizers.Adam(learning_rate=0.01)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientunet import *\n\nwith strategy.scope():\n    model = get_efficient_unet_b0((224, 224, 3), pretrained=True, block_type='transpose', concat_input=True)\n    out = Conv2D(3, (1,1), activation='sigmoid')(model.layers[-2].output)\n    model = keras.Model(inputs=model.input, outputs=out)\n    for layer in model.layers: # Freeze first 4 blocks\n        if 'blocks_9' in layer.name:\n            break\n        layer.trainable = False\n        \n    model.compile(optimizer=sgd,\n              loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001),\n              # loss=tf.keras.losses.MeanSquaredError(),\n              metrics=['accuracy'])\n        \nmodel.summary(line_length=120)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git config --global user.name \"kaggle-notebook\"\n!git config --global user.email theinnocentman1@gmail.com","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!xargs -a /kaggle/input/kaggleutilities/github_credential.txt -I {} git clone https://{}@github.com/khiemledev/kaggle-shopee","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./kaggle-shopee/EfficientNetB0_Unet.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#callbacks\nrlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, verbose = 1, \n                                min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n        \nckp = ModelCheckpoint('Unet_model.h5', monitor = 'val_loss',\n                      verbose = 1, save_best_only = True, mode = 'min')\n        \nes = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 7, mode = 'min', \n                    restore_best_weights = True, verbose = 1)\n\nsteps_per_epoch = (train_paths.shape[0] // cfg.batch_size) / 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(img_gen,                      \n                    validation_data=val_gen,                                       \n                    epochs=30,\n                    callbacks=[rlr,es,ckp],\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(val_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.plot( history.history[\"loss\"], label = \"Training Loss\", marker='o')\nplt.plot( history.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_group_count = df.groupby(['label_group']).size().reset_index()\nlabel_group_count.columns = ['label_group', 'count']\nlabel_group_count.sort_values(by='count', ascending=False, inplace=True)\nlabel_group_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = df[df.label_group == 1163569239].image.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timages = [load_img(img) for img in img_list]\nfig, axes = plt.subplots(1, 4, figsize=(15,10))\naxes = axes.flatten()\nfor img, ax in zip(timages, axes):\n    ax.imshow(img, aspect= True)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.array([img_decoder(GCS_DS_PATH + '/train_images/{}'.format(img))[0] for img in img_list])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list2 = df[df.label_group == 159351600].image.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timages = [load_img(img) for img in img_list2]\nfig, axes = plt.subplots(1, 4, figsize=(15,10))\naxes = axes.flatten()\nfor img, ax in zip(timages, axes):\n    ax.imshow(img, aspect= True)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images2 = np.array([img_decoder(GCS_DS_PATH + '/train_images/{}'.format(img))[0] for img in img_list2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model = keras.Model(inputs=model.input, outputs=model.layers[-48].output)\n# new_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred= new_model.predict(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred2= new_model.predict(images2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import spatial\ndef cosine_distance(a, b):\n    a = a.reshape(-1)\n    b = b.reshape(-1)\n    dist = spatial.distance.cosine(a, b)\n    return dist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_group1 = y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"group_distance = []\nfor pred1 in pred_group1:\n    for pred2 in y_pred:\n        if pred1 is pred2: continue\n        group_distance.append(cosine_distance(pred1, pred2))\nplt.ylim([0, 200])\n_ = plt.hist(group_distance, bins=50, range=[0, 0.05])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_group1 = y_pred2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"group_distance = []\nfor pred1 in pred_group1:\n    for pred2 in y_pred2:\n        if pred1 is pred2: continue\n        group_distance.append(cosine_distance(pred1, pred2))\nplt.ylim([0, 200])\n_ = plt.hist(group_distance, bins=50, range=[0, 0.05])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_group1 = y_pred2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"group_distance = []\nfor pred1 in pred_group1:\n    for pred2 in y_pred:\n        if pred1 is pred2: continue\n        group_distance.append(cosine_distance(pred1, pred2))\nplt.ylim([0, 200])\n_ = plt.hist(group_distance, bins=50, range=[0, 0.05])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}