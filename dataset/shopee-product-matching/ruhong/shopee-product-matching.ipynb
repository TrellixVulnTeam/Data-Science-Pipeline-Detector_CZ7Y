{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport glob\nimport os\nimport sys\nimport json\nimport math\nimport configparser\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.neighbors import NearestNeighbors\nfrom pathlib import Path\nimport lightgbm as lgb\nfrom typing import Iterable, Dict, Set, List, Optional\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2 as cv\nimport pytesseract","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT = '/kaggle/input'\nDATA = f'{INPUT}/shopee-product-matching'\nOUTPUT = '/kaggle/temp'\nRESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'\n#LGB_MODEL_DIR = f'{RESOURCE_DIR}/models/lgb/20210220_213935'\n#LGB_MODEL_DIR = f'{RESOURCE_DIR}/models/lgb/20210220_130330'\n#MLP_MODEL_DIR = f'{RESOURCE_DIR}/models/mlp_20210222_221918'\n#FEATURES_DIR = f'{RESOURCE_DIR}/features'\nsys.path.append(f'{INPUT}/sgcharts-ml/src')\nsys.path.append(f\"{INPUT}/sentence-transformers/sentence-transformers-1.0.4\")\nsys.path.append(f'{RESOURCE_DIR}/src')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport mylib\nimport scml\nfrom scml.nlp import strip_punctuation, to_ascii_str\nscml.seed_everything()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE = True\nTITLE = True\nPHASH = True\nOCR = False\nMODEL = 'efficientnetb3'\npd.set_option(\"use_inf_as_na\", True)\npd.set_option(\"display.max_columns\", 9999)\npd.set_option(\"display.max_rows\", 9999)\npd.set_option('max_colwidth', 9999)\n#os.environ[\"OMP_THREAD_LIMIT\"] = \"1\"\nCONF = configparser.ConfigParser()\nCONF.read(f\"{RESOURCE_DIR}/app.ini\")\nresolution = int(CONF[MODEL][\"resolution\"])\nprint(f\"resolution={resolution}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(f\"{DATA}/test.csv\", engine=\"c\", low_memory=False)\nposting_ids = test[\"posting_id\"].tolist()\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IMAGE:\n    model_dir = f\"{RESOURCE_DIR}/models/eb3_arc_20210510_2300\"\n    m0 = keras.models.load_model(f\"{model_dir}/trial_0/model.h5\")\n    m0 = keras.models.Model(inputs=m0.input[0], outputs=m0.get_layer(\"embedding_output\").output)\n    m0.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IMAGE:\n    idg = keras.preprocessing.image.ImageDataGenerator(\n        rescale=1./255,\n        data_format=\"channels_last\",\n        dtype=np.float32\n    )\n    data = idg.flow_from_dataframe(\n        dataframe=test,\n        x_col=\"image\",\n        y_col=\"posting_id\",  # y_col not needed for inference\n        directory=f\"{DATA}/test_images\",\n        target_size=(resolution, resolution),\n        color_mode=\"rgb\",\n        batch_size=400,\n        shuffle=False,\n        class_mode=\"raw\",\n        interpolation=\"bicubic\",\n    )\n    y0 = m0.predict(data, verbose=1)\n    em = y0.astype(np.float32)\n    print(f\"em.shape={em.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IMAGE:\n    threshold = 1e-4\n    nn = NearestNeighbors(\n        n_neighbors=min(49, len(posting_ids) - 1), metric=\"euclidean\"\n    )\n    nn.fit(em)\n    distances, indices = nn.kneighbors()\n    res: List[List[str]] = [[] for _ in range(len(indices))]\n    for i in range(len(indices)):\n        for j in range(len(indices[0])):\n            if distances[i][j] > threshold:\n                break\n            res[i].append(posting_ids[indices[i][j]])\n    test[\"image_matches\"] = res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# phash embedding","metadata":{}},{"cell_type":"code","source":"if PHASH:\n    test[\"phash_matches\"] = mylib.phash_matches(test, threshold=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SBERT sentence embedding ","metadata":{}},{"cell_type":"code","source":"# required for post-processing\ntest[\"title_p\"] = test.apply(mylib.preprocess(\"title\"), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TITLE:\n    st_name = \"stsb-distilbert-base\"\n    #st_name = \"paraphrase-xlm-r-multilingual-v1\"\n    test[\"title_matches\"] = mylib.sbert_matches(\n        model_path=f\"{RESOURCE_DIR}/pretrained/sentence-transformers/{st_name}\",\n        sentences=test[\"title_p\"].tolist(),\n        posting_ids=posting_ids,\n        threshold=0.5\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OCR Image to Text","metadata":{}},{"cell_type":"code","source":"def erode_dilate(img):\n    kernel = np.ones((2, 2), np.uint8)\n    img = cv.erode(img, kernel, iterations=1)\n    img = cv.dilate(img, kernel, iterations=1)\n    return img\n\n\ndef image_to_text(img_path, mode: str, timeout: float, neighbours: int=41, psm: int=3) -> Optional[str]:\n    config = f\"--psm {psm}\"\n    s1, s2 = None, None\n    img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n    #img = cv.resize(img, None, fx=0.5, fy=0.5, interpolation=cv.INTER_AREA)\n    img = cv.medianBlur(img, 3)\n    if mode == \"binary_inverted\" or mode == \"binary\":\n        th = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, neighbours, 2)\n        th = erode_dilate(th)\n        try:\n            s1 = pytesseract.image_to_string(th, timeout=timeout, config=config)\n        except:\n            s1 = None\n    if mode == \"binary_inverted\" or mode == \"inverted\":\n        th = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, neighbours, 2)\n        th = erode_dilate(th)\n        try:\n            s2 = pytesseract.image_to_string(th, timeout=timeout, config=config)\n        except:\n            s2 = None\n    if s1 is None and s2 is None:\n        return None\n    tokens = []\n    if s1 is not None:\n        s1 = to_ascii_str(s1)\n        s1 = strip_punctuation(s1)\n        tokens += s1.split()\n    if s2 is not None:\n        s2 = to_ascii_str(s2)\n        s2 = strip_punctuation(s2)\n        tokens += s2.split()\n    return \" \".join(tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OCR:\n    res = []\n    for t in test.itertuples():\n        img_path = getattr(t, \"image_path\")\n        s = image_to_text(img_path, mode=\"inverted\", timeout=0.4, neighbours=41, psm=11)\n        if s is None:\n            s = \"\"\n        res.append(s)\n    test[\"itext\"] = res\n    test[\"text\"] = test[\"title\"] + \" \" + test[\"itext\"]\n    st_name = \"stsb-distilbert-base\"\n    #st_name = \"paraphrase-xlm-r-multilingual-v1\"\n    test[\"text_p\"] = test.apply(mylib.preprocess(\"text\"), axis=1)\n    test[\"text_matches\"] = mylib.sbert_matches(\n        model_path=f\"{RESOURCE_DIR}/pretrained/sentence-transformers/{st_name}\",\n        sentences=test[\"text_p\"].tolist(),\n        posting_ids=posting_ids,\n        threshold=0.5\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post-processing","metadata":{}},{"cell_type":"code","source":"imap = {}\nfor t in test.itertuples():\n    pid = getattr(t, \"posting_id\")\n    title = getattr(t, \"title_p\")\n    imap[pid] = mylib.extract(title)\nfs = []\nif IMAGE:\n    fs.append(\"image_matches\")\nif TITLE:\n    fs.append(\"title_matches\")\nif PHASH:\n    fs.append(\"phash_matches\")\nif OCR:\n    fs.append(\"text_matches\")\ntest[\"matches\"] = test.apply(mylib.combine_as_string(\n    fs,\n    imap=imap,\n    brand_threshold=0.3,\n    measurement_threshold=0.3\n), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = test[[\"posting_id\", \"matches\"]]\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debug","metadata":{}},{"cell_type":"code","source":"#!pip list","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}