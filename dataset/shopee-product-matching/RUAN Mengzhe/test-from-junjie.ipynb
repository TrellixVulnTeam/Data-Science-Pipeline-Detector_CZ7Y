{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#basics\nimport numpy as np\nimport pandas as pd\nimport csv\nimport os\nimport sys\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nimport math\n\n#modeling\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import *\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import train_test_split\n#import transformers\n\n#image preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom PIL import Image\nimport cv2\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_accuracy\n\n#visualization\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n\n#warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nK.clear_session()\nnp.random.seed(2021); tf.random.set_seed(2021)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\n\nlabel_dict = train.groupby('label_group').posting_id.agg('unique').to_dict()\nnew_label_dict = {}\nlabel_counts = 1\nfor k, v in label_dict.items():\n    if len(v) <= 3:\n        new_label_dict[k] = 0\n    else:\n        new_label_dict[k] = label_counts\n        label_counts += 1\nnum_class = label_counts\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_jpg_directory = '../input/shopee-product-matching/train_images'\n\ntrain_image_path = []\nfor img in train.image:\n    train_image_path.append(os.path.join(train_jpg_directory, img))\ntrain['img_path'] = train_image_path\n\nN_tot = len(train)\nall_ind = np.arange(N_tot)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LIMIT = 15\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rough idea is that, we can apply Additive Angular Margin Loss proposed in \"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\" to firstly do the classification. It is by finely tuning a pretrained model over the training dataset. After that, we extract CNN features from the deep model and then compute the similarity score between images, with which the ranking list is obtained. A threshold $\\theta$ is used to cut the ranking list.\n\nBelow is the ArcFace layer for classification","metadata":{}},{"cell_type":"code","source":"from keras.metrics import categorical_accuracy\nfrom keras import regularizers\n\nimport math\n\nfrom keras.metrics import categorical_accuracy\n\nimport tensorflow as tf\nimport math as m\n\n\nclass ArcFace(Layer):\n    '''Custom Keras layer implementing ArcFace including:\n    1. Generation of embeddings\n    2. Loss function\n    3. Accuracy function\n    '''\n\n    def __init__(self, output_dim, class_num, margin=0.5, scale=64., **kwargs):\n        self.output_dim = output_dim\n        self.class_num = class_num\n        self.margin = margin\n        self.s = scale\n\n        self.cos_m = tf.math.cos(margin)\n        self.sin_m = tf.math.sin(margin)\n        self.mm = self.sin_m * margin\n        self.threshold = tf.math.cos(tf.constant(m.pi) - margin)\n        super(ArcFace, self).__init__(**kwargs)\n\n\n    def build(self, input_shape):\n        # Create a trainable weight variable for this layer.\n        self.kernel = self.add_weight(name='kernel', \n                                      shape=(input_shape[1], self.class_num),\n                                      initializer='glorot_normal',\n                                      trainable=True)\n        super(ArcFace, self).build(input_shape)  # Be sure to call this at the end\n\n\n    def call(self, x):\n        embeddings = tf.nn.l2_normalize(x, axis=1, name='normed_embeddings')\n        weights = tf.nn.l2_normalize(self.kernel, axis=0, name='normed_weights')\n        cos_t = tf.matmul(embeddings, weights, name='cos_t')\n        return cos_t\n\n\n    def get_logits(self, labels, y_pred):\n        cos_t = y_pred\n        cos_t2 = tf.square(cos_t, name='cos_2')\n        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n        sin_t = tf.sqrt(sin_t2, name='sin_t')\n        cos_mt = self.s * tf.subtract(tf.multiply(cos_t, self.cos_m), tf.multiply(sin_t, self.sin_m), name='cos_mt')\n        cond_v = cos_t - self.threshold\n        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n        keep_val = self.s*(cos_t - self.mm)\n        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n        mask = tf.one_hot(labels, depth=self.class_num, name='one_hot_mask')\n        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n        s_cos_t = tf.multiply(self.s, cos_t, name='scalar_cos_t')\n        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_logits')\n        return output\n\n\n    def loss(self, y_true, y_pred):\n        labels = K.argmax(y_true, axis=-1)\n        logits = self.get_logits(labels, y_pred)\n        loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n        return loss\n\n\n    def accuracy(self, y_true, y_pred):\n        labels = K.argmax(y_true, axis=-1)\n        logits = self.get_logits(labels, y_pred)\n        accuracy = categorical_accuracy(y_true=labels, y_pred=logits)\n        return accuracy\n    \n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.output_dim)\n\n\nfrom tensorflow.keras.applications import EfficientNetB4\nmodel = EfficientNetB4(include_top=False, weights='../input/tfkerasefficientnetimagenetnotop/efficientnetb4_notop.h5', pooling='avg', input_shape=None)\n\naf_layer = ArcFace(output_dim=num_class, class_num=num_class, margin=0.5, scale=30.)\n#Y_input =  Input(shape=(num_class,))\n\nx = Dropout(rate = 0.2, name = \"added_dropout\")(model.output)\nx = Dense(units = 512, name = \"added_fc_layer\")(x)\nx = BatchNormalization(name = \"added_bn_layer\")(x)\n\naf_output = af_layer(x)\n\nmodel = Model(inputs=model.input, outputs=af_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use the ResNet as backbone for feature learning.","metadata":{}},{"cell_type":"code","source":"import skimage.io\nimport skimage.transform\nfrom sklearn import *\n\n#AUTO = tf.data.experimental.AUTOTUNE\nIMAGE_SIZE = [256, 256]\n\nfrom tensorflow.keras.applications import EfficientNetB4\nmodel = EfficientNetB4(include_top=False, weights=None, pooling='avg', input_shape=None)\nmodel.load_weights('../input/finetune2/my_model_weights_fine_tune4.h5', by_name=True)\n\ndef create_batch(train, batch_index):\n    x_inputs = np.zeros((len(batch_index), 256, 256, 3))\n    x_labels = np.zeros((len(batch_index), num_class))\n    for i, iindex in enumerate(batch_index):\n        x_anchor = train.iloc[iindex].img_path\n        x_anchor = tf.io.read_file(x_anchor)\n        x_anchor = tf.image.decode_jpeg(x_anchor, channels=3)\n        x_anchor = tf.image.resize(x_anchor, IMAGE_SIZE)\n\n        x_inputs[i] = x_anchor\n        x_labels[i, new_label_dict[train.iloc[iindex].label_group]] = 1.0\n    \n\n    return x_inputs, x_labels\n\n\ntrain_set = np.arange(N_tot)\ntrain_index = train_set[2*10: 3*10]\nx_data, y_data = create_batch(train, train_index)\nprint(y_data)\n\ny_pred = model.predict(x_data)\nprint(y_pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate=1e-3,\n#     decay_steps=15000,\n#     decay_rate=0.8)\n\n# op = Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n# #model.compile(optimizer=op, loss=arcf.loss, metrics=[arcf.accuracy])\n\n# train_set = np.arange(N_tot)\n# BATCH_SIZE = 64\n# EPOCH = 10\n# train_size = len(train_set)\n# ITER = int(train_size/BATCH_SIZE)\n\n# loss_fn = af_layer.loss\n# train_acc_metric = af_layer.accuracy\n\n\n# for iepoch in range(EPOCH):\n#     np.random.shuffle(train_set)\n#     print(\"Training epoch %d --------\"%(iepoch))\n#     for it in range(ITER):\n#         train_index = train_set[it*BATCH_SIZE: (it+1)*BATCH_SIZE]\n#         x_data, y_data = create_batch(train, train_index)\n#         #print (np.argmax(y_data, axis = 1))\n#         with tf.GradientTape() as tape:\n#             y_pred = model(x_data, training=True)\n#             loss_value = loss_fn(y_data, y_pred)\n#         grads = tape.gradient(loss_value, model.trainable_weights)\n#         op.apply_gradients(zip(grads, model.trainable_weights))\n        \n#         if it % 20 == 0:\n#             batch_acc =  train_acc_metric(y_data, y_pred)\n#             print(\"Seen so far: %s samples, Training loss at step %d: %.4f, Acc by far %.4f\"% (((it + 1) * BATCH_SIZE), it, float(loss_value), np.mean(batch_acc)))\n    \n#     #print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n#     if (iepoch + 1) % 2 == 0:\n#         mwp = \"my_model_weights_fine_tune\" + str(iepoch + 1)+ \".h5\"\n#         model.save_weights(mwp)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}