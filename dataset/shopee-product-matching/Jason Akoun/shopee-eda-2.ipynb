{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.notebook import tqdm\nimport torchvision.models as models\nfrom torch.utils.data import random_split\nfrom sklearn.neighbors import NearestNeighbors","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.168538Z","iopub.execute_input":"2021-05-25T17:53:46.169137Z","iopub.status.idle":"2021-05-25T17:53:46.19172Z","shell.execute_reply.started":"2021-05-25T17:53:46.169065Z","shell.execute_reply":"2021-05-25T17:53:46.190854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.notebook import tqdm\nimport torchvision.models as models\nfrom torch.utils.data import random_split\nfrom sklearn.neighbors import NearestNeighborsdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device available now:', device)\ndf_train = pd.read_csv(\"../input/shopee-product-matching/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.195637Z","iopub.execute_input":"2021-05-25T17:53:46.195885Z","iopub.status.idle":"2021-05-25T17:53:46.207616Z","shell.execute_reply.started":"2021-05-25T17:53:46.195862Z","shell.execute_reply":"2021-05-25T17:53:46.206592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\ndf_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:09.166837Z","iopub.execute_input":"2021-05-25T17:59:09.1672Z","iopub.status.idle":"2021-05-25T17:59:09.265643Z","shell.execute_reply.started":"2021-05-25T17:59:09.167169Z","shell.execute_reply":"2021-05-25T17:59:09.264874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Augmentation data x8\nfor i in range(3):\n    df_train = pd.concat([df_train, df_train], ignore_index=True)\n    df_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:11.63436Z","iopub.execute_input":"2021-05-25T17:59:11.634714Z","iopub.status.idle":"2021-05-25T17:59:11.682664Z","shell.execute_reply.started":"2021-05-25T17:59:11.634683Z","shell.execute_reply":"2021-05-25T17:59:11.68168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = df_train.groupby('label_group').posting_id.agg('unique').to_dict()\ndf_train['target'] = df_train.label_group.map(tmp)\ndf_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:15.562761Z","iopub.execute_input":"2021-05-25T17:59:15.563112Z","iopub.status.idle":"2021-05-25T17:59:16.295484Z","shell.execute_reply.started":"2021-05-25T17:59:15.56308Z","shell.execute_reply":"2021-05-25T17:59:16.294474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating shopee dataset","metadata":{}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    \n    def __init__(self, csv, train=True):\n        self.csv = csv.reset_index()\n        self.train = train\n        self.transform_random = transforms.Compose([\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.RandomVerticalFlip(),\n                                            transforms.RandomRotation(90),\n                                            transforms.Resize((256, 256)),\n                                            transforms.ToTensor(),])\n        \n    def __len__(self):\n        return len(self.csv)\n    \n    def __getitem__(self, index):\n        if self.train:\n            image = Image.open('../input/shopee-product-matching/train_images/' +\n                               self.csv.image[index])\n        else:\n            image = Image.open('../input/shopee-product-matching/test_images/' +\n                               self.csv.image[index])\n        \n\n        image = self.transform_random(image)\n        image = torch.div(image, 255)\n        \n        if self.train:\n            label = torch.tensor(self.csv.label_group[index])\n            return image, label\n        \n        else:\n            return image","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:44.902394Z","iopub.execute_input":"2021-05-25T17:59:44.902737Z","iopub.status.idle":"2021-05-25T17:59:44.911979Z","shell.execute_reply.started":"2021-05-25T17:59:44.902708Z","shell.execute_reply":"2021-05-25T17:59:44.91104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ShopeeDataset(csv=df_train)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, num_workers=4)\n\nprint(\"Dataset length: {}\".format(len(train_dataset)), \"\\n\" +\n      \"Shape of images: {}\".format(train_dataset[0][0].shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:49.986128Z","iopub.execute_input":"2021-05-25T17:59:49.986438Z","iopub.status.idle":"2021-05-25T17:59:50.048364Z","shell.execute_reply.started":"2021-05-25T17:59:49.986408Z","shell.execute_reply":"2021-05-25T17:59:50.047549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing model ResNet18","metadata":{}},{"cell_type":"code","source":"resnet18 = models.resnet18(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:54.496592Z","iopub.execute_input":"2021-05-25T17:59:54.496909Z","iopub.status.idle":"2021-05-25T17:59:54.794335Z","shell.execute_reply.started":"2021-05-25T17:59:54.496881Z","shell.execute_reply":"2021-05-25T17:59:54.79348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting embeddings from train images using ResNet18","metadata":{}},{"cell_type":"code","source":"def extract_embeddings(model, dataloader):\n    embeddings = []\n\n    with torch.no_grad():\n        for image, label in tqdm(dataloader):\n            if torch.cuda.is_available():\n                image = image.to('cuda')\n                model.to('cuda')\n\n            img_emd = model(image)\n            img_emd = img_emd.detach().cpu().numpy()\n            embeddings.append(img_emd)\n\n    embeddings = np.concatenate(embeddings)\n    print(\"Shape of embeddings: {}\".format(embeddings.shape))\n    \n    return embeddings","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:59:59.505182Z","iopub.execute_input":"2021-05-25T17:59:59.505515Z","iopub.status.idle":"2021-05-25T17:59:59.511501Z","shell.execute_reply.started":"2021-05-25T17:59:59.505485Z","shell.execute_reply":"2021-05-25T17:59:59.510497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#embeddings = extract_embeddings(resnet18, train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:00:03.894466Z","iopub.execute_input":"2021-05-25T18:00:03.894783Z","iopub.status.idle":"2021-05-25T18:09:43.946463Z","shell.execute_reply.started":"2021-05-25T18:00:03.894752Z","shell.execute_reply":"2021-05-25T18:09:43.942273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(\"image_embeddings\", embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:09:43.949354Z","iopub.status.idle":"2021-05-25T18:09:43.951577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making predictions","metadata":{}},{"cell_type":"code","source":"def get_f1_score(y, y_pred):\n    intr_sect = np.array([len(set(x1).intersection(x2)) for x1, x2 in zip(y, y_pred)])\n    len_y = y.apply(lambda x: len(x)).values\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    f1 = 2 * intr_sect / (len_y + len_y_pred)\n    \n    return f1","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.573313Z","iopub.status.idle":"2021-05-25T17:53:46.574227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, val_set, train_emd, val_emd, train_df, val_df, threshold):\n    predictions = []\n    \n    knn_model = NearestNeighbors(n_neighbors=50, algorithm='brute', metric='cosine')\n    knn_model.fit(train_emd)\n    dists, idx = knn_model.kneighbors(val_emd)\n    \n    for i in range(val_emd.shape[0]):\n        mask = dists[i] < threshold\n        pred = train_df.loc[idx[i][mask]].posting_id.values\n        predictions.append(pred)\n        \n    val_df['prediction'] = predictions\n    val_df['f1_score'] = get_f1_score(val_df['target'], val_df['prediction'])\n    score = val_df['f1_score'].mean()\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.575629Z","iopub.status.idle":"2021-05-25T17:53:46.576588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_imgs = len(train_dataset)\nnum_train_imgs = int(num_imgs*.8)\nidx = np.array(range(num_imgs))\nnp.random.shuffle(idx)\nidx_train, idx_val = idx[:num_train_imgs], idx[num_train_imgs:]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.5798Z","iopub.status.idle":"2021-05-25T17:53:46.580638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = ShopeeDataset(csv=df_train.loc[idx_train])\ntrain_loader = DataLoader(train_set, batch_size=16, num_workers=4)\n\nval_set = ShopeeDataset(csv=df_train.loc[idx_val])\nval_loader = DataLoader(val_set, batch_size=16, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.581956Z","iopub.status.idle":"2021-05-25T17:53:46.582754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embd = extract_embeddings(resnet18, train_loader)\nval_embd = extract_embeddings(resnet18, val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.589091Z","iopub.status.idle":"2021-05-25T17:53:46.59012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df_train.loc[idx_train].reset_index(drop=True)\nval_df = df_train.loc[idx_val].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.591272Z","iopub.status.idle":"2021-05-25T17:53:46.592202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = .3\nf1_score = predict(resnet18, val_set, train_embd, val_embd, train_df, val_df, threshold)\nprint('F1 score: {}'.format(f1_score))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:53:46.593402Z","iopub.status.idle":"2021-05-25T17:53:46.594243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPLORE DATA","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.notebook import tqdm\nimport torchvision.models as models\nfrom torch.utils.data import random_split\nfrom sklearn.neighbors import NearestNeighbors\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk import pos_tag, ne_chunk\nfrom textblob import TextBlob\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom tqdm import tqdm\nfrom textblob import TextBlob\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device available now:', device)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:24:45.403949Z","iopub.execute_input":"2021-06-04T12:24:45.404315Z","iopub.status.idle":"2021-06-04T12:24:48.257936Z","shell.execute_reply.started":"2021-06-04T12:24:45.404237Z","shell.execute_reply":"2021-06-04T12:24:48.257059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\ndf_test = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\nprint(len(df_train))\nprint(len(df_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:24:49.373466Z","iopub.execute_input":"2021-06-04T12:24:49.37381Z","iopub.status.idle":"2021-06-04T12:24:49.518504Z","shell.execute_reply.started":"2021-06-04T12:24:49.373771Z","shell.execute_reply":"2021-06-04T12:24:49.517673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:56:49.651762Z","iopub.execute_input":"2021-06-04T07:56:49.652132Z","iopub.status.idle":"2021-06-04T07:56:49.67886Z","shell.execute_reply.started":"2021-06-04T07:56:49.652082Z","shell.execute_reply":"2021-06-04T07:56:49.678057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See different titles for same product\n\ndf = pd.DataFrame(index = [0, 1, 2], columns = [\"Title 1\", \"Title 2\"])\nlabels = [3648931069, 1565741687, 249114794]\nn= len(labels)\nfor l in range(n):\n    indexes = df_train[df_train[\"label_group\"]==labels[l]].index.values \n    titles = df_train[\"title\"].iloc[indexes].values\n    df.iloc[l] = titles\n\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:56:54.060724Z","iopub.execute_input":"2021-06-04T07:56:54.061109Z","iopub.status.idle":"2021-06-04T07:56:54.09828Z","shell.execute_reply.started":"2021-06-04T07:56:54.061064Z","shell.execute_reply":"2021-06-04T07:56:54.097541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2)\nimg_A = np.array(Image.open('../input/shopee-product-matching/train_images/' +  df_train[\"image\"].iloc[indexes[0]]))\nimg_B = np.array(Image.open('../input/shopee-product-matching/train_images/' +  df_train[\"image\"].iloc[indexes[1]]))\nax[0].imshow(img_A)\nax[1].imshow(img_B)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:56:58.490064Z","iopub.execute_input":"2021-06-04T07:56:58.490408Z","iopub.status.idle":"2021-06-04T07:56:58.927102Z","shell.execute_reply.started":"2021-06-04T07:56:58.490377Z","shell.execute_reply":"2021-06-04T07:56:58.926204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESS","metadata":{}},{"cell_type":"code","source":"res = 256\n\ntransform = transforms.Compose([transforms.Resize((res, res)),\n                                transforms.ToTensor(),])\nimage = Image.open('../input/shopee-product-matching/train_images/' +  df_train[\"image\"].iloc[indexes[1]])\nimage_ = transform(image)\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(image)\nax[1].imshow(image_.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:01:19.841266Z","iopub.execute_input":"2021-06-04T11:01:19.84162Z","iopub.status.idle":"2021-06-04T11:01:19.869413Z","shell.execute_reply.started":"2021-06-04T11:01:19.841583Z","shell.execute_reply":"2021-06-04T11:01:19.867907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n    \n# Preprocess titles\noriginal_titles = df_train[\"title\"]\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess_title(title):\n    title_clean = title.lower().translate(str.maketrans('','',string.punctuation)).strip()\n    title_tokenize = word_tokenize(title_clean)\n    title_w_stopword = [w for w in title_tokenize if not w in stopwords.words()]\n    title_lemmatized = [lemmatizer.lemmatize(w) for w in title_w_stopword]\n    return \" \".join(title_lemmatized)\n\ndef pos_title(title):\n    return TextBlob(' '.join(title)).tags\n    \nfor i in [0, 1, 2, 4, 5]:\n    print(color.BOLD + \"Orginial Title -\" + color.END, original_titles.iloc[i])\n    print(color.BOLD + \"Preprocessed Title -\" + color.END, preprocess_title(original_titles.iloc[i]))\n    print('\\n')\n#print(\"Part Of Speech : \", pos_title(preprocess_title(original_titles.iloc[5])))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:25:19.620522Z","iopub.execute_input":"2021-06-04T12:25:19.62083Z","iopub.status.idle":"2021-06-04T12:25:21.622832Z","shell.execute_reply.started":"2021-06-04T12:25:19.6208Z","shell.execute_reply":"2021-06-04T12:25:21.622047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\n\ndf_train[\"preprocess_title\"] = df_train[\"title\"].progress_apply(lambda x: preprocess_title(x))\ndf_train[\"preprocess_title\"] = df_train[\"preprocess_title\"].astype('U')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:25:24.515422Z","iopub.execute_input":"2021-06-04T12:25:24.515756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get title embeddings\ndf_train[\"preprocess_title\"] = df_train[\"preprocess_title\"].astype('U')\npreprocess_title = df_train[\"preprocess_title\"].values\ntf_idf = TfidfVectorizer(stop_words='english', binary=True, max_features=25000)\ntext_embeddings = tf_idf.fit_transform(preprocess_title).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cupy \n\n\npredictions = []\nBATCH = 4096\nN = len(text_embeddings) \nprint(N)\n\nprint(\"Title based prediction...\")\n\nfor i in range(N//BATCH):\n    \n    a = i * BATCH\n    b = min((i+1) * BATCH, N)\n    print(\"BATCH : \", a, \"-\", b)\n    \n    # Cosine similarity distance\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        index = cupy.where(cts[k,] > 0.7)[0]\n        index = cupy.asnumpy(index)\n        pred = df_train.iloc[index][\"posting_id\"].values\n        \n        predictions.append(pred)\n\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:58:47.606773Z","iopub.execute_input":"2021-06-03T13:58:47.607151Z","iopub.status.idle":"2021-06-03T13:58:49.06328Z","shell.execute_reply.started":"2021-06-03T13:58:47.60712Z","shell.execute_reply":"2021-06-03T13:58:49.061739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}