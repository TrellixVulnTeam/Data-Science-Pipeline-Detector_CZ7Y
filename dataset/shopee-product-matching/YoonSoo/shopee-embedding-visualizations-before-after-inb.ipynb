{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is written to show the effect of **INB(Iterative Neighborhood Blending)** technique, which is part of the 1st place solution of *Shopee - Price Match Guarantee* competition.\n\nWe will use the validation set embedding from our model as the base embedding, and compare two visualizations.\n1. TSNE visualization of the embedding **before** applying INB\n2. TSNE visualization of the embedding **after** applying INB\n\nNote that validation f1-score increased from 0.9060 to 0.9256 when we applied INB.\n\nYou can find explanation of the INB technique and overall solution [here](https://www.kaggle.com/c/shopee-product-matching/discussion/238136)","metadata":{}},{"cell_type":"code","source":"import joblib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cuml\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(emb, title, lg, ylim=None, xlim=None, target_lg=None):\n    x, y = emb[:, 0], emb[:, 1]\n    sns.scatterplot(x=x, y=y, hue=lg, legend=False)\n    if xlim is not None: plt.xlim(xlim[0], xlim[1])\n    if ylim is not None: plt.ylim(ylim[0], ylim[1])\n    for i, txt in enumerate(lg):\n        if target_lg is not None:\n            if txt != target_lg:\n                continue\n        plt.annotate(txt, (x[i], y[i]))\n    plt.title(title)\n    \n    \ndef plot_cropped(emb, cur_lg, lg, title, margin=5):\n    cur = emb[np.where(lg==cur_lg)[0]]\n    min_y, max_y = cur[:, 0].min(), cur[:, 0].max()\n    min_x, max_x = cur[:, 1].min(), cur[:, 1].max()\n    ylim = (min_y-margin, max_y+margin)\n    xlim = (min_x-margin, max_x+margin)\n    index = np.where((emb[:, 0]>ylim[0])&(emb[:, 0]<ylim[1])&(emb[:, 1]>xlim[0])&(emb[:, 1]<xlim[1]))[0]\n    plot(emb[index], title, lg[index], ylim=xlim, xlim=ylim, target_lg=cur_lg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orig_emb = joblib.load('../input/shopee-visualization/orig_emb.jl')\ninb_emb = joblib.load('../input/shopee-visualization/inb_emb.jl')\nlg = joblib.load('../input/shopee-visualization/label_group.jl')\nlg = pd.factorize(lg)[0]\nlg_diff = pd.read_pickle('../input/shopee-visualization/lg_diff.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`lg_diff` contains gap between these two\n* mean f1 score per label group before applying INB\n* mean f1 score per label group after applying INB","metadata":{}},{"cell_type":"code","source":"lg_diff","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Improvement in validation set f1 score after applying INB')\nprint((lg_diff*lg_diff.index.map(pd.Series(lg).value_counts())).sum()/len(lg))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne = cuml.TSNE(random_state=0)\norig_emb_tsne = tsne.fit_transform(orig_emb)\ninb_emb_tsne = tsne.fit_transform(inb_emb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TSNE Visualization of the Whole Validation Set Embeddings\n\nYou can open the output images in another tab or download it, and zoom it to see the label annotations.","metadata":{}},{"cell_type":"markdown","source":"### 1. Embeddings Before Applying INB","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(100, 100))\nplot(orig_emb_tsne, 'TSNE VISUALIZATION OF EMBEDDINGS BEFORE INB', lg)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Embeddings After Applying INB","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(100, 100))\nplot(inb_emb_tsne, 'TSNE VISUALIZATION OF EMBEDDINGS AFTER INB', lg)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the clusters became clearer after we applied INB.","metadata":{}},{"cell_type":"markdown","source":"# TSNE Visualizations of the Embeddings from Most Improved Label Groups\n\nWe'll pick label groups that improved the most, with group size > 3. Then we'll visualize how the positions of the items of that label group changed after applying INB. We will zoom into the relevant areas in the above visualizations to show you the effect better.","metadata":{}},{"cell_type":"code","source":"for cur_lg in lg_diff.index[:100]:    \n    if (lg==cur_lg).sum() < 4:\n        continue \n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plot_cropped(orig_emb_tsne, cur_lg, lg, f'{cur_lg} (BEFORE INB)')\n    plt.subplot(1, 2, 2)\n    plot_cropped(inb_emb_tsne, cur_lg, lg, f'{cur_lg} (AFTER INB)')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the items of the same label group tends to cluster better after we apply INB.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}