{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport math\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\n\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.metrics import accuracy_score\n\ntimm_path = \"../input/timm-pytorch-image-models/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.autograd.set_detect_anomaly(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeM2(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM2,self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df  = pd.read_csv(\"../input/rarity-folds/rarity_folds.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_aug = A.Compose(\n    [  \n\n        A.Resize(490,490,p=1.0),\n        A.RandomCrop(448,448),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.Transpose(p=0.5),\n        A.Rotate(limit=120, p=0.5),\n            A.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n        A.Normalize(p=1.0),\n        ToTensorV2(p=1.0)\n    ]\n)\nval_aug = A.Compose(\n    [  \n\n        A.Resize(width=512, height=512, p=1.0),\n     A.Normalize(p=1.0),\n        ToTensorV2(p=1.0)\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Shop(Dataset):\n    def __init__(self,df,augs=None):\n        self.df = df\n        self.augs = augs\n        \n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        img_src = self.df.path.iloc[idx]\n        image = cv2.imread(img_src)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n        \n        p_id =  self.df.posting_id.iloc[idx]\n        \n        if (self.augs):\n            transformed = self.augs(image=image)\n            image = transformed['image']\n        \n        label = self.df.iloc[idx].rarity\t\n        label =torch.tensor(label, dtype=torch.long)\n        \n        return image,label,p_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,output_size =10 ,pretrained=False):\n        super().__init__()\n        self.op = output_size\n        self.backbone = timm.create_model('tf_efficientnet_b2_ns', features_only=True, \n                                          pretrained=pretrained)\n        self.gem2 = GeM2()\n        self.fc1 = nn.Linear(352,144)\n        self.fc2 = nn.Linear(144,self.op)\n        self.do = nn.Dropout(p=0.25)\n        self.bn1 = nn.BatchNorm1d(352)\n        self.bn2 = nn.BatchNorm1d(144)\n        self.pl = nn.PReLU()\n        \n        nn.init.kaiming_normal_(self.fc1.weight)\n        nn.init.zeros_(self.fc1.bias)\n\n    def forward(self,x,labels=None):\n        y = self.backbone(x)\n        #y1 = self.gem1(y[2])\n        y2 = self.gem2(y[4])\n        \n        #y1 = y1.view(x.shape[0],-1)\n        y2 = y2.view(x.shape[0],-1)\n        y2 = self.bn1(y2)\n        \n        #concat = torch.cat((y1,y2),dim = 1)\n        fc1 = self.do(self.fc1(y2))\n        feat1 = self.pl(self.bn2(fc1))\n        \n        feat1 = self.fc2(feat1)\n        \n        return feat1\n        \n       \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef train_one_epoch(train_loader,model,optimizer,criterion,e,epochs,scheduler):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    \n    model.train()\n    global_step = 0\n    loop = tqdm(enumerate(train_loader),total = len(train_loader))\n    \n    for step,(image,labels,_) in loop:\n        image = image.to(device)\n        labels= labels.to(device)\n        logitss = model(image)\n        batch_size = labels.size(0)\n        loss  = criterion(logitss,labels)\n        \n        out = logitss.softmax(1)\n        outputs = torch.argmax(out, dim=1).cpu().detach().numpy()\n        targets = labels.cpu().detach().numpy()\n        accuracy = accuracy_score(targets, outputs)\n        \n        losses.update(loss.item(), batch_size)\n        scores.update(accuracy.item(), batch_size)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        #torch.nn.utils.clip_grad_norm_(m.parameters(), 1000 )\n        optimizer.step()\n        scheduler.step() \n        global_step += 1\n        \n        loop.set_description(f\"Epoch {e+1}/{epochs}\")\n        loop.set_postfix(loss = loss.item(), accuracy = accuracy.item(), stage = 'train')\n        \n        \n    return losses.avg,scores.avg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_one_epoch(loader,model,optimizer,criterion):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    model.eval()\n    global_step = 0\n    loop = tqdm(enumerate(loader),total = len(loader))\n    \n    for step,(image,labels,_) in loop:\n        image = image.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.no_grad():\n            output = model(image)\n        loss = criterion(output,labels)\n        \n        output = output.softmax(1)\n        outputs = torch.argmax(output, dim=1).cpu().detach().numpy()\n        targets = labels.cpu().detach().numpy()\n        accuracy = accuracy_score(targets, outputs)\n        \n        losses.update(loss.item(), batch_size)\n        scores.update(accuracy.item(), batch_size)\n        loop.set_postfix(loss = loss.item(), accuracy = accuracy.item(), stage = 'valid')\n        \n        global_step += 1\n        \n    \n        \n    return losses.avg,scores.avg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(pretrained=True)\nmodel.to(device);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(fold):\n  \n    df_train = df[(df.fold == 1) | (df.fold == 2) | (df.fold == 4) ].reset_index(drop=True)\n    df_valid = df[(df.fold == 0) | (df.fold == 3)].reset_index(drop=True)\n    \n    train_data = Shop(df_train,augs= train_aug)\n    val_data   = Shop(df_valid,augs=val_aug)\n    \n    train_loader = DataLoader(train_data,shuffle=True,\n                        num_workers=4,\n                        batch_size=16,\n                        drop_last=True,\n                            pin_memory=True)\n    \n    val_loader = DataLoader(val_data,shuffle=False,\n                        num_workers=4,\n                            pin_memory=True,\n                        batch_size=16)\n    criterion= nn.CrossEntropyLoss()\n    epochs = 8\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4 , weight_decay = 1e-4)\n    \n    num_train_steps = math.ceil(len(train_loader))\n    warmup_epochs = 1\n    num_warmup_steps= num_train_steps * warmup_epochs\n    num_training_steps=int(num_train_steps * epochs)\n    scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps = num_warmup_steps,num_training_steps =num_training_steps)\n    \n    best_acc = 0\n    loop = range(epochs)\n    for e in loop:\n        \n        train_loss,train_accuracy = train_one_epoch(train_loader,model,optimizer,criterion,e,epochs,scheduler)\n        print(f'For epoch {e+1}/{epochs}')\n        print(f'average train_loss {train_loss}')\n        print(f'average train_accuracy {train_accuracy}' )\n        \n        val_loss,val_accuracy = val_one_epoch(val_loader,model,optimizer,criterion)\n        \n        scheduler.step(val_loss)\n        \n        print(f'avarage val_loss { val_loss }')\n        print(f'avarage val_accuracy {val_accuracy}')\n        \n        if (val_accuracy>best_acc):\n            best_acc = val_accuracy\n            print(f'saving model for {best_acc}')\n            torch.save(model.state_dict(),OUTPUT_DIR+ f'Fold {fold} model with val_acc {best_acc}.pth') \n        \n        \n    \n    \nfit(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),'image_modelT1_256_seresnext.pth') \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}