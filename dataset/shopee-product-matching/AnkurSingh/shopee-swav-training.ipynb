{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Self-supervised learning with fastai\n\nInspired by [Ayush Thakur's work](https://www.kaggle.com/ayuraj/v2-self-supervised-pretraining-with-swav?scriptVersionId=59516445), I started exploring more about SwAV. The results in the [paper](https://arxiv.org/abs/2006.09882) were quite impressive. Hence, I decided to implement it.\n\nLucky for me, I found a pytorch implementation. Also, it used fastai. This was like a dream come true. Fastai is my comfort zone. You can find more about the [implementation here](https://keremturgutlu.github.io/self_supervised/). I will highly recommend checking out the documentation. Not just SwAV, the repository has fastai implementations of other state-of-the-art algorithms as well.\n\nI followed [this tutorial](https://keremturgutlu.github.io/self_supervised/04%20-%20training_swav_iwang.html) for creating this notebook that you are reading now. So, if something looks off or doesn't make sense, then please refer the original tutorial.\n\nLets get started . . .","metadata":{}},{"cell_type":"markdown","source":"### Installation & imports","metadata":{}},{"cell_type":"code","source":"!pip install self-supervised -Uq","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\n\nfrom sklearn.model_selection import StratifiedKFold\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To train the model, we will also need a validation set. I will use simple `StratifiedKFold` technique to split my data into train & validation set.","metadata":{}},{"cell_type":"code","source":"sk_fold = StratifiedKFold(5)\ndf['is_valid'] = False\nfor i, (trn_idx, val_idx) in enumerate(sk_fold.split(df, df.label_group)):\n    df.loc[val_idx, 'is_valid'] = True\n    break\n    \ndf.groupby('is_valid').label_group.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As per the warning, there are some label groups with less than 5 posting. lets see how many such label group we have . . . ","metadata":{}},{"cell_type":"code","source":"sum(df.label_group.value_counts() < 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 9620 `label_group` with less than 5 postings. Quite a lot, huh! (lets handle it in version-2).\n\n### Dataloaders\n\nFor now, lets create some helper functions to create dataloaders.","metadata":{}},{"cell_type":"code","source":"def get_x(x): return '../input/shopee-product-matching/train_images/' + x['image']\n\ndef get_dls(size, bs, workers=None):\n    path = Path('../input/shopee-product-matching/train_images/')\n    \n    db = DataBlock(blocks = (ImageBlock(), CategoryBlock()),\n              get_x = get_x, get_y=ColReader('label_group'),\n              splitter=ColSplitter(),\n              item_tfms=RandomResizedCrop(size, min_scale=1.))\n    dls = db.dataloaders(df, bs=bs, num_workers=workers)\n    return dls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets create our dataloaders . . . ","metadata":{}},{"cell_type":"code","source":"bs, resize, size = 24, 256, 224\ndls = get_dls(resize, bs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model & Callbacks\n\nFinally, lets initialize our model & SwAV callbacks","metadata":{}},{"cell_type":"code","source":"## Model\narch = \"resnet50\"\nencoder = create_encoder(arch, pretrained=True, n_in=3)\nmodel = create_swav_model(encoder)\n\n## SwAV callback\nK = bs*2**4\naug_pipelines = get_swav_aug_pipelines(num_crops=[2, 6],\n                                       crop_sizes=[size,int(3/4*size)], \n                                       min_scales=[0.25, 0.20],\n                                       max_scales=[1.00, 0.35],\n                                       rotate=True, rotate_deg=10, jitter=True, bw=True, blur=False)\ncbs=[SWAV(aug_pipelines, crop_assgn_ids=[0,1], K=K, queue_start_pct=0.5, temp=0.1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great, we have our data, model, & also the callbacks. Fastai has this amazing class called `Learner` which put everything together for training.","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls, model, cbs=cbs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we actually training the model, lets look at some of the samples. ","metadata":{}},{"cell_type":"code","source":"b = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\nlearn.swav.show(n=5);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training \n\nTime to train the model . . . ","metadata":{}},{"cell_type":"code","source":"lr, wd = 1e-2, 1e-2\nepochs = 5 # try using 40 or 50\nlearn.unfreeze()\nlearn.fit_flat_cos(epochs, lr, wd=wd, pct_start=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_name = f'swav_iwang_sz{size}_epc{epochs}'\nlearn.save(save_name)\ntorch.save(learn.model.encoder.state_dict(), learn.path/learn.model_dir/f'{save_name}_encoder.pth')\nlearn.recorder.plot_loss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is only intended for learning. To get better score, try using different model architecture, bigger image size, etc.\n\nI can find the inference notebook, [here](https://www.kaggle.com/ankursingh12/shopee-swav-inference)\n\nHope you enjoyed reading this notebook. If yes, then please consider **upvoting**!","metadata":{}}]}