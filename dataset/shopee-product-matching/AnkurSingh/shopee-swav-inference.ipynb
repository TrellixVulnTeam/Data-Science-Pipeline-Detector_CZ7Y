{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Self-supervised learning with fastai (inference)\n\nThis is an inference notebook. You can find the training notebook **[here](https://www.kaggle.com/ankursingh12/shopee-swav-training)**\n\nIn this notebook, we will see how our fine-tuned Resnet50 performs against the following:\n- Pretrained Resnet50 (from pytorch)\n- Resnet50 trained using SwAV (by facebook)\n\nHold tight, its time for the final verdict (just kidding) . . .","metadata":{}},{"cell_type":"code","source":"!pip install self-supervised -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport os \nimport cv2\nimport timm\nimport random\n\nimport numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\n\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors\n\nimport albumentations as A \nfrom albumentations.pytorch.transforms import ToTensorV2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('../input/shopee-product-matching')\n\nclass CFG:\n    img_size = 512\n    batch_size = 12\n    seed = 2020\n    \n    device = 'cuda'\n    classes = 11014\n    \n    scale = 30 \n    margin = 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(CFG.seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"def read_dataset():\n    df = pd.read_csv(path/'train.csv')\n    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n    df['target'] = df.label_group.map(tmp)\n    \n    image_paths = str(path) + '/train_images/' + df['image']\n    return df, image_paths\n\ndef get_test_transforms():\n    return A.Compose([A.Resize(CFG.img_size, CFG.img_size, always_apply=True),\n                      A.Normalize(), ToTensorV2(p=1.0)])\n\nclass ShopeeDataset(Dataset):\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.image_paths.shape[0]\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']       \n    \n        return image,torch.tensor(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_embeddings(image_paths, model, model_path=None):\n    embeds = []\n    model.eval()\n    \n    if model_path:\n        model.load_state_dict(torch.load(model_path))\n        model = model.to(CFG.device)\n    \n    image_dataset = ShopeeDataset(image_paths,transforms = get_test_transforms())\n    image_loader = DataLoader(image_dataset, batch_size=CFG.batch_size, pin_memory=True, \n                              drop_last=False,num_workers=4)\n    \n    with torch.no_grad():\n        for img,label in tqdm(image_loader): \n            img = img.cuda()\n            feat = model(img)\n            image_embeddings = feat.detach().cpu().numpy()\n            embeds.append(image_embeddings)\n            \n    image_embeddings = np.concatenate(embeds)\n    print(f'Our image embeddings shape is {image_embeddings.shape}')\n    \n    del embeds, model\n    gc.collect()\n    return image_embeddings\n\n\ndef get_image_predictions(df, embeddings,threshold = 0.0):\n    if len(df) > 3: KNN = 50\n    else : KNN = 3\n    \n    model = NearestNeighbors(n_neighbors = KNN, metric = 'euclidean')\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    predictions = []\n    for k in tqdm(range(embeddings.shape[0])):\n        idx = np.where(distances[k,] < threshold)[0]\n        ids = indices[k,idx]\n        posting_ids = df['posting_id'].iloc[ids].values\n        predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.concatenate([row['image_predictions']])\n    return ' '.join( np.unique(x))\n\ndef getMetric(row, col):\n        n = len(np.intersect1d(row.target,row[col]))\n        return 2*n / (len(row.target)+len(row[col]))\n    \ndef evaluate_model(models):\n    img_embeddings = 0\n    \n    if isinstance(models, list):\n        for m in models:\n            img_embeddings += get_image_embeddings(image_paths.values, m)\n        img_embeddings /= len(models)\n    else:\n        img_embeddings = get_image_embeddings(image_paths.values, models)\n        \n    img_embeddings = img_embeddings.squeeze()\n    image_predictions = get_image_predictions(df, img_embeddings, threshold = 0.36)\n    \n    df['image_predictions'] = image_predictions\n    f1_scores = df.apply(lambda r: getMetric(r, 'image_predictions'), axis=1)\n    print(f'CV score for baseline = {f1_scores.mean()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading data","metadata":{}},{"cell_type":"code","source":"df,image_paths = read_dataset()\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference \n\nLets evalutate how our model performs","metadata":{}},{"cell_type":"markdown","source":"### 1. Pretrained Resnet50 from pytorch","metadata":{}},{"cell_type":"code","source":"## Pretrained Resnet50 from pytorch\nmodel = models.resnet50(pretrained=True)\nmodel_enc = torch.nn.Sequential(*(list(model.children())[:-1])).cuda()\nmodel_enc.eval()\nevaluate_model(model_enc)\n# euclidean -  CV score = 0.4930072045298856","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Resnet50 trained using SwAV, by faceboook","metadata":{}},{"cell_type":"code","source":"## Resnet50 trained using SwAV, by faceboook\nmodel = torch.hub.load('facebookresearch/swav', 'resnet50')\nmodel_enc = torch.nn.Sequential(*(list(model.children())[:-1])).cuda()\nmodel_enc.eval()\nevaluate_model(model_enc)\n# euclidean - CV score = 0.5134202771430936","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice, from 0.49 to 0.51 just by using weights from facebook.\n\n### 3. Fine-tuned Resnet50 \n\nFinally, lets test our model","metadata":{}},{"cell_type":"code","source":"## Fine-tuned Resnet50\narch = 'resnet50'\nencoder_path = '../input/shopee-swav-training/models/swav_iwang_sz224_epc5_encoder.pth'\nencoder = create_encoder(arch, pretrained=False, n_in=3)\nencoder.load_state_dict(torch.load(encoder_path))\nencoder.cuda()\nencoder.eval()\nevaluate_model(encoder)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Important resources \n\n- Want to train your own model using SwAV, refer [training notebook](https://www.kaggle.com/ankursingh12/shopee-swav-training)\n- Want to learn more about SwAV, refer [this](https://www.kaggle.com/ayuraj/v2-self-supervised-pretraining-with-swav?scriptVersionId=59516445)\n- Want to read the SwAV paper, refer [this](https://arxiv.org/abs/2006.09882)\n\nHope you learnt something new in this notebook. Please consider **upvoting** if you found this notebook helpful in any way.","metadata":{}}]}