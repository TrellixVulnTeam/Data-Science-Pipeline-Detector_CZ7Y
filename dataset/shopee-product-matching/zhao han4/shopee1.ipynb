{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom os.path import join\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Determine the path of the current document","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cupy\nimport cudf\nimport os\nfrom os.path import join\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport logging\nlogging.basicConfig()\nimport struct\n# use keras backend (K) to force channels-last ordering\nimport tensorflow.keras.applications.resnet50 as resnet\nfrom tensorflow.keras.applications import EfficientNetB0\nimport gc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2, matplotlib.pyplot as plt\nimport skimage\ndefault_dir = '../input/shopee-product-matching'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## compute_test\n\n* This committed notebook computes CV score but when we submit this notebook it does not compute CV. Instead it will load the 70,000 row test.csv file and compute matches in the test dataset. Because the variable `compute_test = True` when we commit this notebook. But when we submit this notebook to Kaggle then the length of test.csv will be longer than 3 and the if-statement below will change to `compute_test=False`.","metadata":{}},{"cell_type":"code","source":"compute_test=False\nif compute_test:\n    train_data=pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')    \nelse:   \n    train_data=pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml import PCA\nfrom cuml.neighbors import NearestNeighbors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore the relevant information of the training data, including the dimensions and data types of the training data","metadata":{}},{"cell_type":"code","source":"print(train_data.head())\nprint(train_data.shape)\nprint(train_data.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore the number of post_id under each image, and check the data through several samples.","metadata":{}},{"cell_type":"code","source":"count_stats=train_data.groupby(['image']).count().reset_index()\ncount_stats.sort_values(by=['posting_id'],ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[train_data.image=='0cca4afba97e106abd0843ce72881ca4.jpg']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Embedding","metadata":{}},{"cell_type":"markdown","source":"## Generate batch data","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### different image model\n* Here we use transfer learning to explore multiple image models: efficientnetb0, vgg16 and ResNet50, vgg16 and ResNet50 are not good, efficientnetb0 has better results, so we finally use the efficientnetb0 model","metadata":{}},{"cell_type":"code","source":"choose_model='efficientnetb0'\nif choose_model=='VGG':\n    model = VGG16(weights='imagenet', include_top=False,pooling='avg')\nelif choose_model=='ResNet50':\n    # create an instance of the model w/o the last layer\n    model = resnet.ResNet50(weights='imagenet',\n    include_top=False, # remove the classification layer\n    pooling='avg')\nelse:\n    WGT = '../input/efficientnetb0/efficientnetb0_notop.h5'\n    model = EfficientNetB0(weights=WGT, include_top=False, pooling='avg', input_shape=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Select the path of the picture set according to the symbol set by compute_test","metadata":{}},{"cell_type":"code","source":"if compute_test:\n    BASE = join(default_dir, 'test_images/')\nelse: BASE = join(default_dir, 'train_images/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeds = []\nCHUNK = 1024 * 4\n\nprint('Computing image embeddings...')\nCTS = len(train_data) // CHUNK\nif len(train_data) % CHUNK != 0: CTS += 1\nfor i, j in enumerate(range(CTS)):\n\n    a = j * CHUNK\n    b = (j+1) * CHUNK\n    b = min(b, len(train_data))\n    print('chunk', a, 'to', b)\n\n    test_gen = DataGenerator(train_data.iloc[a:b], img_size=512, batch_size=8, path=BASE)\n    image_embeddings = model.predict(test_gen, verbose=1, use_multiprocessing=True, workers=4)\n    embeds.append(image_embeddings)\nimage_embeddings = np.concatenate(embeds)\n\n# Saving a NumPy Array to CSV File\ndel model\nnp.savetxt('image_embeddings_vgg.csv', image_embeddings, delimiter=',')\nprint('image embeddings shape',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## check Similar Images\nAgain, we will now ignore the ground truth and try to find similar items in train data using only the item's image. First we will extract image embeddings using EffNetB0. We will then compare image embeddings with RAPIDS cuML KNN to find images that are similar.","metadata":{}},{"cell_type":"code","source":"image_embeddings = np.loadtxt('/kaggle/input/img-embed/image_embeddings.csv',\n                             delimiter=',')\nprint('image embeddings shape is',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = 30\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)\ndistances, indices = model.kneighbors(image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE = join(default_dir, 'train_images/')\ndef displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):\n    for k in range(ROWS):\n        plt.figure(figsize=(20,5))\n        for j in range(COLS):\n            if random: row = np.random.randint(0,len(train))\n            else: row = COLS*k + j\n            name = train.iloc[row,1]\n            title = train.iloc[row,3]\n            title_with_return = \"\"\n            for i,ch in enumerate(title):\n                title_with_return += ch\n                if (i!=0)&(i%20==0): title_with_return += '\\n'\n            img = cv2.imread(path+name)\n            \n            # color fixing\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            plt.subplot(1,COLS,j+1)\n            plt.title(title_with_return)\n            plt.axis('off')\n            plt.imshow(img)\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(100,105):\n    plt.figure(figsize=(20,3))\n    plt.plot(np.arange(30),cupy.asnumpy(distances[k,]),'o-')\n    plt.title('Image Distance From Train Row %i to Other Train Rows'%k,size=16)\n    plt.ylabel('Distance to Train Row %i'%k,size=14)\n    plt.xlabel('Index Sorted by Distance to Train Row %i'%k,size=14)\n    plt.show()\n    \n    cluster = train_data.loc[cupy.asnumpy(indices[k,:8])] \n    displayDF(cluster, random=False, ROWS=2, COLS=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We tried different cluster values, and we can see from the above that imgae_embedding has a good effect","metadata":{}},{"cell_type":"markdown","source":"### select NearestNeighbors\nPlease Note! As stated in competition's evaluation page:<br>\n* Group sizes were capped at 50, so there is no benefit to predict more than 50 matches.* <br>\n* AS we can see, if length of data is 3 ,then we select 2 NearestNeighbors,else we set NearestNeighbors is 100 *","metadata":{}},{"cell_type":"code","source":"from cuml.neighbors import NearestNeighbors\n\nKNN = 100\nif len(train_data) == 3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings) // CHUNK\nif len(image_embeddings) % CHUNK != 0: CTS += 1\nfor j in range(CTS):\n    \n    a = j * CHUNK\n    b = (j+1) * CHUNK\n    b = min(b, len(image_embeddings))\n    print('chunk', a, 'to', b)\n    distances, indices = model.kneighbors(image_embeddings[a:b, ])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k, ] < 6.0)[0]\n        IDS = indices[k, IDX]\n        o = train_data.iloc[IDS].posting_id.values\n        preds.append(o)\n        \ndel model, distances, indices, image_embeddings # embeds\n_ = gc.collect()\ntrain_data['preds2'] = preds\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Title Embedding","metadata":{}},{"cell_type":"code","source":"import cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nprint('RAPIDS',cuml.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We use TFIDF to extract text features, we set `max_features=30000` to ensure that the model does not lose too much text information","metadata":{}},{"cell_type":"code","source":"from cuml.feature_extraction.text import TfidfVectorizer\n\nprint('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=30000)\ntext_embeddings = model.fit_transform(cudf.Series(train_data['title'].tolist())).toarray()\n\nprint('text embeddings shape',text_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Because the array data type of cudf cannot be stored by numpy, we need to convert to numpy array for storage","metadata":{}},{"cell_type":"code","source":"# text_embeddings=text_embeddings.get()\n# text_embeddings.shape\n# np.savetxt('text_embeddings.csv', text_embeddings, delimiter=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### check title similar","metadata":{}},{"cell_type":"code","source":"KNN = 50\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(text_embeddings)\ndistances, indices = model.kneighbors(text_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(3):\n    plt.figure(figsize=(20,3))\n    plt.plot(np.arange(50),cupy.asnumpy(distances[k,]),'o-')\n    plt.title('Text Distance From Train Row %i to Other Train Rows'%k,size=16)\n    plt.ylabel('Distance to Train Row %i'%k,size=14)\n    plt.xlabel('Index Sorted by Distance to Train Row %i'%k,size=14)\n    plt.show()\n    \n    print( train_data.loc[cupy.asnumpy(indices[k,:10]),['title','label_group']] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We tried different cluster values, and we can see from the above that imgae_embedding has a good effect","metadata":{}},{"cell_type":"markdown","source":"###  ","metadata":{}},{"cell_type":"code","source":"KNN = 100 #50\nif len(train_data) == 3: KNN = 2\nmodel = NearestNeighbors(n_neighbors = KNN)\nmodel.fit(text_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COSINE_SIMILARITY=True\npreds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train_data) // CHUNK\nif len(train_data) % CHUNK != 0: CTS += 1\nfor j in range(CTS):\n    \n    a = j * CHUNK\n    b = (j+1) * CHUNK\n    b = min(b, len(train_data))\n    print('chunk', a, 'to', b)\n    \n    if COSINE_SIMILARITY:\n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n\n        for k in range(b-a):\n            IDX = cupy.where(cts[k, ] > 0.7)[0]\n            o = train_data.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n    \n    else:\n        # KNN\n        distances, indices = model.kneighbors(text_embeddings[a:b,])\n        \n        for k in range(b-a):\n            IDX = cupy.where(indices[k, ] < 6.0)[0]\n            o = train_data.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n            \n            # IDX = np.where(distances[k, ] < 6.0)[0]\n            # IDS = indices[k, IDX]\n            # o = test.iloc[IDS].posting_id.values\n            # preds.append(o)\n            \n            # TypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n            # https://stackoverflow.com/questions/65008297/attempting-numpy-conversion-when-not-needed-in-cupy\n            \ndel model, text_embeddings\n_ = gc.collect()\ntrain_data['preds'] = preds\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Phash Feature\n\nWe will predict all items with the same phash as duplicates:<br>","metadata":{}},{"cell_type":"markdown","source":"### Here we choose several images of one label_group","metadata":{}},{"cell_type":"markdown","source":"### Calculate the difference between two hash values of the images","metadata":{}},{"cell_type":"code","source":"def campHash(hash1, hash2):\n    n = 0\n    # hash长度不同返回-1,此时不能比较\n    if len(hash1) != len(hash2):\n        return -1\n    # 如果hash长度相同遍历长度\n    for i in range(len(hash1)):\n        if hash1[i] != hash2[i]:\n            n = n+1\n    return n\n# print(campHash('e925873ed09cd08f','e9b5833e929e909c'))\n# print(campHash('e925873ed09cd08f','ea97861c926a71e3'))\n# print(campHash('e9b5833e929e909c','ea97861c926a71e3'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = train_data.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain_data['preds3'] = train_data.image_phash.map(tmp)\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target, row[col]) )\n        return 2*n / (len(row.target) + len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds2, row.preds3])\n    return np.unique(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if compute_test:\n    train_data['matches'] = train_data.apply(combine_for_sub,axis=1)\nelse:\n    tmp = train_data.groupby('label_group').posting_id.agg('unique').to_dict()\n    train_data['target'] = train_data.label_group.map(tmp)\n    train_data['oof'] = train_data.apply(combine_for_cv,axis=1)\n    train_data['f1'] = train_data.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train_data.f1.mean())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Submission CSV\n\nIn this notebook, the submission file below looks funny containing train information. But when we submit this notebook, the size of `test.csv` dataframe will be longer than 3 rows and the variable `compute_test` will subsequently set to `False`. Then our submission notebook will compute the correct matches using the real test dataset and our submission csv for LB will be ok.","metadata":{}},{"cell_type":"code","source":"train_data[['posting_id', 'matches']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}