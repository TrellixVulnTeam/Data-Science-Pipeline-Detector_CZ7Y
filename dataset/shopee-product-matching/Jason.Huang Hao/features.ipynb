{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport shutil\nfrom keras.preprocessing import image\nimport os\nimport json\nimport math\nfrom tqdm import tqdm \n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom keras import layers, optimizers\nfrom keras.applications import MobileNetV2\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Model\n\nimport keras.backend as K\nfrom keras.models import Sequential\nimport cv2\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.applications import imagenet_utils\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nimport numpy as np\nfrom IPython.display import Image\nfrom keras.optimizers import Adam","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\nsample = pd.read_csv('../input/shopee-product-matching/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = '../input/shopee-product-matching/train_images'\ndef get_image_array(file, show=False):\n    \n    img = image.load_img(os.path.join(img_path,file), target_size=(128, 128))\n    img_tensor =image.img_to_array(img)                    # (height, width, channels)\n    #img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n\n\n    return img_tensor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_path = '../input/shopee-product-matching/train_images'\n# #     testimg=load_image(os.path.join(img_path,imag))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_array=[]\nfor file in tqdm(train['image'][0:5]): #先取五個當範例\n    image_array=get_image_array(file)\n    dataset_array.append(image_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_array = np.array(dataset_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_labels = np.array(train['label_group'][0:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(\"train_dataset_array.npy\", dataset_array)\nnp.save(\"train_dataset_array_labels.npy\", dataset_labels)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nbase_model = load_model('../input/model50e/MobileNet_TransferLearning.h5')\n#base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = Model(inputs=base_model.input, outputs=base_model.get_layer('global_average_pooling2d').output)\n\n#train_dataset_array = dataset_array\n\ntrain_features = model2.predict(dataset_array)\nbase_model = np.save('MobileNet_Train_Features.npy', train_features)\nprint(train_features.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\nfrom sklearn.neural_network import MLPClassifier\nimport joblib\n\n\ntrain_dataset_array_labels = dataset_labels\n#print(\"Train Features Shape\", train_features.shape)\n\nclassifier = MLPClassifier(solver='adam', hidden_layer_sizes=(500, 150), max_iter=20000)\n\nclassifier.fit(train_features, train_dataset_array_labels)\n\njoblib.dump(classifier, 'MobileNet_TransferLearning.joblib')\n\ntrain_predictions = classifier.predict(train_features)\n\ntrain_correct_predictions = np.array(np.where(train_predictions == train_dataset_array_labels))\ntrain_accuracy = np.round((train_correct_predictions.shape[1]/train_features.shape[0])*100, 2)\nprint(\"Train Accuracy : \", train_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x= classifier.predict(train_features[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy\n# import keras\n# import os\n# import tensorflow as tf\n\n# def images_to_array(dataset_dir, image_size):\n#     dataset_array = []\n#     dataset_labels = []\n\n#     class_counter = 0\n\n#     classes_names = os.listdir(dataset_dir)\n#     for current_class_name in classes_names:\n#         class_dir = os.path.join(dataset_dir, current_class_name)\n#         images_in_class = os.listdir(class_dir)\n\n#         #print(\"Class index\", class_counter, \", \", current_class_name, \":\" , len(images_in_class))\n\n#         for image_file in images_in_class:\n#             image_file_dir = os.path.join(class_dir, image_file)\n#             img = keras.preprocessing.image.load_img(image_file_dir, target_size=(image_size, image_size))\n#             img_array = keras.preprocessing.image.img_to_array(img)\n#             img_array = img_array/255.0\n#             dataset_array.append(img_array)\n#             dataset_labels.append(class_counter)\n#         class_counter = class_counter + 1\n#     dataset_array = numpy.array(dataset_array)\n#     dataset_labels = numpy.array(dataset_labels)\n#     return dataset_array, dataset_labels\n\n\n\n# train_dir = '../input/test1/kaggle/working/class/'\n# image_size = 224\n# train_dataset_array, train_dataset_array_labels = images_to_array(dataset_dir=train_dir, image_size=image_size)\n# print(\"Training Data Array Shape :\", train_dataset_array.shape)\n# numpy.save(\"train_dataset_array.npy\", train_dataset_array)\n# numpy.save(\"train_dataset_array_labels.npy\", train_dataset_array_labels)\n\n# # test_dir = \"/root/.keras/datasets/fruits-360/Test\"\n# # test_dataset_array, test_dataset_array_labels = images_to_array(dataset_dir=test_dir, image_size=image_size)\n# # print(\"Test Data Array Shape :\", test_dataset_array.shape)\n# # numpy.save(\"test_dataset_array.npy\", test_dataset_array)\n# # numpy.save(\"test_dataset_array_labels.npy\", test_dataset_array_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}