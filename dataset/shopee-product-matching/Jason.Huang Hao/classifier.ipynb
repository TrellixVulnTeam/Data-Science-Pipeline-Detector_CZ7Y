{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import lib","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nprint('TF',tf.__version__)\n#Text Color\nfrom termcolor import colored\nfrom wordcloud import WordCloud, STOPWORDS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 12GB OF GPU RAM\n# SO THAT WE HAVE GPU RAM FOR RAPIDS CUML KNN\nLIMIT = 1\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('Restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('so RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train= pd.read_csv('../input/shopee-product-matching/train.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use Image Embeddings","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE='../input/shopee-product-matching/train_images/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nbase_model = load_model('../input/model50e/MobileNet_TransferLearning.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nmodel2 = Model(inputs=base_model.input, outputs=base_model.get_layer('global_average_pooling2d').output)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeds = []\nCHUNK = 1024 * 4\n\nprint('Computing image embeddings...')\nCTS = len(train) // CHUNK\nif len(train) % CHUNK != 0: CTS += 1\nfor i, j in enumerate(range(CTS)):\n\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(train))\n        print('chunk', a, 'to', b)\n        \n        \n        train_gen = DataGenerator(train.iloc[a:b], img_size=512, batch_size=6, path=BASE)\n        \n        image_embeddings = model2.predict(train_gen, verbose=1, use_multiprocessing=True, workers=4)\n        embeds.append(image_embeddings)\n\n        #if i>=1: break\n\n\nimage_embeddings = np.concatenate(embeds)\n\n# Saving a NumPy Array to CSV File\n# if SAVE_IMGEMBEDDING: np.savetxt('image_embeddings_EfficientNetB6.csv', image_embeddings, delimiter=',')\n\n# else:\n#     print('Loading image embeddings...')\n#     if EfficientNetB0:\n#         image_embeddings = np.loadtxt('../input/shopee-price-match-guarantee-embeddings/image_embeddings.csv',\n#                                  delimiter=',')\n#     else: raise ValueError('Please select the correspondent model and embeddings in \"../input/shopee-price-match-guarantee-embeddings\".')\n\n# print('image embeddings shape',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings = np.concatenate(embeds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_labels = np.array(train['label_group'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.neural_network import MLPClassifier\nimport joblib\n\n\ntrain_dataset_array_labels = dataset_labels\n#print(\"Train Features Shape\", train_features.shape)\n\nclassifier = MLPClassifier(solver='adam', hidden_layer_sizes=(500, 150), max_iter=20000)\n\nclassifier.fit(image_embeddings, train_dataset_array_labels)\n\njoblib.dump(classifier, 'MobileNet_TransferLearning.joblib')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions = classifier.predict(image_embeddings)\n\ntrain_correct_predictions = np.array(np.where(train_predictions == train_dataset_array_labels))\n#train_accuracy = np.round((train_correct_predictions.shape[1]/train_features.shape[0])*100, 2)\n#print(\"Train Accuracy : \", train_accuracy)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}