{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Necessary libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport cv2\nimport imagehash\nfrom fuzzywuzzy import fuzz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions","metadata":{}},{"cell_type":"code","source":"def make_wordcloud(df):\n    lst=list(df['title'])\n    wordcloud_text=[]\n    for ele in lst:\n        wordcloud_text.extend(ele.split())\n    wordcloud_text=' '.join(wordcloud_text)\n    wordcloud = WordCloud().generate(wordcloud_text)\n\n    # Display the generated image:\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()\n    \n    \n\ndef hamming_distance(val1,val2):\n    res=0\n    for v1,v2 in zip(val1,val2):\n        if v1!=v2:\n            res=res+1\n    return res\n\n        \ndef image_matrix(hash_values):\n \n    phashs = hash_values.apply(lambda x: imagehash.hex_to_hash(x))\n    \n    hash_matrix = pd.DataFrame()\n\n    for idx, i in enumerate(hash_values):\n      \n        hash_matrix = pd.concat([hash_matrix, phashs - imagehash.hex_to_hash(i)], \n                                 axis = 1)\n        \n\n    hash_matrix.columns = range(len(hash_values))\n    return hash_matrix\n\n\ndef fuzz_calculation(idx,df):\n    val=[]\n    for i,ele in enumerate(df['title']):\n        temp=fuzz.ratio(str.lower(df['title'][idx]),str.lower(ele))\n        val.append((temp,i))\n    return val\n\ndef fuzz_calculation_with_sep(idx,df):\n    val=[]\n    '''As some of out titles have multiple titles separated by / we will split the title on this \n    value if / is present and calculate fuzz_ratio for each of them'''\n    \n    vals=df['title'][idx].split('/')\n    \n    for i,ele in enumerate(df['title']):\n        temp1=ele.split('/')\n        max_val=0\n        \n        for sent1 in vals:\n            for sent2 in temp1:\n                temp=fuzz.ratio(str.lower(sent1),str.lower(sent2))\n                if temp>max_val:\n                    max_val=temp\n            \n        val.append((max_val,i))\n\n    return val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Train Data","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv(r'/kaggle/input/shopee-product-matching/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\nWe have 34,250 train images. In our dataframe we have the image title as text feature.We also have image_phash and label_group as other features. Similar posting_id is what we need to predict for each image. ","metadata":{}},{"cell_type":"markdown","source":"# Analyzing Test Data","metadata":{}},{"cell_type":"code","source":"test_df=pd.read_csv(r'/kaggle/input/shopee-product-matching/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Train DataFrame\n\nSimilar images belong to the same label_group. Hence, let us first begin analyzing this column","metadata":{}},{"cell_type":"code","source":"label_group_df=train_df[['posting_id','label_group']].groupby(['label_group']).count().reset_index()\nlabel_group_df.columns=['label_group','count']\nlabel_group_df=label_group_df.sort_values(by=['count'],ascending=False)\nlabel_group_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analyzing duplicate label_group\nvar=train_df[train_df[\"label_group\"].duplicated() == True].shape[0]\nprint('Number of duplicated label_groups: ',var)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var=train_df[train_df[\"posting_id\"].duplicated() == True].shape[0]\nprint('Number of duplicated posting_id: ',var)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of unique label groups: ',label_group_df.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=label_group_df['label_group'][:50],y=label_group_df['count'][:50])\nplt.title('Number of pictures in same label for first 50 label_groups')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=label_group_df['label_group'][-50:],y=label_group_df['count'][-50:])\nplt.title('Number of pictures in same label for last 50 label_groups')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n1. From the above information we can see that for any label_group the maximum number of products belonging to the similar label_group are 51\n2. There are 23236 duplicate label groups in our train dataset as many products share the same label_group.\n","metadata":{}},{"cell_type":"markdown","source":"# Exploring Title\nNow, we have given the titles of each image as well. We will explore this area and find out how similar these tiles are for similar products/images.","metadata":{}},{"cell_type":"markdown","source":"***We now see the length of every title***","metadata":{}},{"cell_type":"code","source":"train_df['title_length']=[len(train_df['title'][i].split()) for i in range(train_df.shape[0])]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sort_values(by='title_length',ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sort_values(by='title_length',ascending=False).tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observaion:\nWe see that maximum number of words in any title is 61(not a very large number) and minimum is 1.","metadata":{}},{"cell_type":"code","source":"#selecting a label_group at random and seeing the titles for that group\nsample_df=train_df[train_df['label_group']==1163569239]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For a clearer idea let us draw a wordcloud on the titles for this label group and see if we find something**","metadata":{}},{"cell_type":"code","source":"print('Wordcloud for images from group_label: 1163569239')\nprint('Total number of images for this group_label are: ',\n      label_group_df[label_group_df['label_group']==1163569239]['count'])\nmake_wordcloud(sample_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=sample_df['posting_id'],y=sample_df['title_length'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsample_df.value_counts(['image_phash']).plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let us try making wordcloud for more group_labels**","metadata":{}},{"cell_type":"code","source":"#selecting a label_group at random and seeing the titles for that group\nsample_df2=train_df[train_df['label_group']==2126962532]\nprint('Wordcloud for images from group_label: 2126962532')\nprint('Total number of images for this group_label are: ',label_group_df[label_group_df['label_group']==2126962532]['count'])\nmake_wordcloud(sample_df2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=sample_df2['posting_id'],y=sample_df2['title_length'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df2.value_counts(['image_phash']).plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#selecting a label_group at random and seeing the titles for that group\nsample_df3=train_df[train_df['label_group']==2357508171]\nprint('Wordcloud for images from group_label: 2357508171')\nprint('Total number of images for this group_label are: ',\n      label_group_df[label_group_df['label_group']==2357508171]['count'])\nmake_wordcloud(sample_df3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=sample_df3['posting_id'],y=sample_df3['title_length'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df3.value_counts(['image_phash']).plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#selecting a label_group at random and seeing the titles for that group\nsample_df4=train_df[train_df['label_group']==3627744656]\nprint('Wordcloud for images from group_label: 3627744656')\nprint('Total number of images for this group_label are: ',label_group_df[label_group_df['label_group']==3627744656]['count'])\nmake_wordcloud(sample_df4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=sample_df4['posting_id'],y=sample_df4['title_length'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df4.value_counts(['image_phash']).plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observations:\n1. Products belonging to different label_groups have quite different words. Hence, it can be concluded that title plays a major role in this problem.\n2. Also, for products belonging to same label_group there are few words appearing more frequently this once again supports the above statement.\n3. There is no relation between number of words in title for images that belong to the same label_group.\n4. The hash_value is widely scattered for images in the same label_group.","metadata":{}},{"cell_type":"markdown","source":"# Hash_Value Check:\nWe have checked that images belonging to the same label_group might have different hash_values. Let us check if the images with same hash_value has differet label_groups or not.","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df=train_df[['image_phash','posting_id']].groupby(['image_phash']).count().reset_index()\nhash_df.columns=['image_phash','count']\nhash_df.sort_values(by='count',ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df.sort_values(by='count',ascending=False)[10:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample=train_df[train_df['image_phash']=='fad28daa2ad05595'].groupby(['label_group']).count()\nhash_df_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample=train_df[train_df['image_phash']=='d0c0ea37bd9acce0'].groupby(['label_group']).count()\nhash_df_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample=train_df[train_df['image_phash']=='f6d98134b904b56b'].groupby(['label_group']).count()\nhash_df_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample=train_df[train_df['image_phash']=='be12e12f9ec1e198'].groupby(['label_group']).count()\nhash_df_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample=train_df[train_df['image_phash']=='ada4c4781f93686e'].groupby(['label_group']).count()\nhash_df_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample=train_df[train_df['image_phash']=='ad29e81e92b295b5'].groupby(['label_group']).count()\nhash_df_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n1. There are cases in which the same hash_value images belong to different groups. But it can be said that the majority belong to the same label_group only.\n\n2. We are given perceptual hashing value, hence for calculating the similarity between two images we will consider hamming distance.","metadata":{}},{"cell_type":"markdown","source":"# Plotting Some Images:\n","metadata":{}},{"cell_type":"code","source":"#plt.figure(figsize=(30,30))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+train_df['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For better observation let us try plotting images that belong to the same label_group","metadata":{}},{"cell_type":"code","source":"#plt.figure(figsize=(30,30))\nsample_df=sample_df.reset_index()\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+sample_df['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(30,30))\nsample_df2=sample_df2.reset_index()\nfor i in range(8):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+sample_df2['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(30,30))\nsample_df3=sample_df3.reset_index()\nfor i in range(2):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+sample_df3['image'][i])\n    plt.subplot(1,2,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Images with Similar Hash Value\nNow we will see few image plots where the image had the same hash_value","metadata":{}},{"cell_type":"code","source":"hash_df_sample1=train_df[train_df['image_phash']=='ada4c4781f93686e'].reset_index()\n#plt.figure(figsize=(30,30))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+hash_df_sample1['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hash_df_sample2=train_df[train_df['image_phash']=='f6d98134b904b56b'].reset_index()\n#plt.figure(figsize=(30,30))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+hash_df_sample2['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n1. Hash_value of each image is an important feature for any given image and it helps in grouping similar images together.\n2. For perceptual hashing hamming distance is the main measure of calculating the similarity between two given images.\n3. The shorter (smaller value) the value of hamming distance the more similar are the images.","metadata":{}},{"cell_type":"markdown","source":"# Phash Analysis\nBased on the phash_value we will first calculate the has","metadata":{}},{"cell_type":"code","source":"hash_matrix_1_1000 = image_matrix(train_df['image_phash'][:1000])\nhash_matrix_1_1000.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Further Steps:\n1. We are looking for similar product images. So, here to begin with what we can do is for every product take the 50 most similar product based on the value calculated here.","metadata":{}},{"cell_type":"code","source":"simialrity_dic={}\nfor i in range(len(hash_matrix_1_1000)):\n    var=[(hash_matrix_1_1000[i][j],j) for j in range(len(hash_matrix_1_1000[i]))]\n    var=sorted(var)\n    simialrity_dic[i]=[var[k][1] for k in range(50)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Similar Products Based on Above Observation","metadata":{}},{"cell_type":"code","source":"similar_pdts_0=train_df['image'][simialrity_dic[0][:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_0['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_pdts_1=train_df['image'][simialrity_dic[1][:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_1['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_pdts_11=train_df['image'][simialrity_dic[11][:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_11['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\nBased on these the results are not very promising. This might also be because we are only taking a sample of images. Let us try with first 10 images taking their matching hash_value with all the images in the dataset.","metadata":{}},{"cell_type":"code","source":"hash_dic = {}\nvar=[]\nval=imagehash.hex_to_hash(train_df['image_phash'][0])\nfor idx,ele in enumerate(train_df['image_phash']):\n    temp=imagehash.hex_to_hash(ele)\n    var.append((val-temp,idx))\nhash_dic[0]=var","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val=sorted(hash_dic[0])\nval=[val[i][1] for i in range(len(val))]\n\nsimilar_pdts_0_all=train_df['image'][val[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_0_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let us now check for these 50 images, how many of them have same label_group","metadata":{}},{"cell_type":"code","source":"print('Label_group of image_0 is: ',train_df['label_group'][0])\nfor ele in val[:50]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Index 2937\n","metadata":{}},{"cell_type":"code","source":"hash_dic = {}\nvar=[]\nval=imagehash.hex_to_hash(train_df['image_phash'][2937])\nfor idx,ele in enumerate(train_df['image_phash']):\n    temp=imagehash.hex_to_hash(ele)\n    var.append((val-temp,idx))\nhash_dic[2937]=var","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val=sorted(hash_dic[2937])\nval=[val[i][1] for i in range(len(val))]\n\nsimilar_pdts_2937_all=train_df['image'][val[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_2937_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_0 is: ',train_df['label_group'][2937])\nfor ele in val[:50]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][2937])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n1. We get good results but only in the case when there are images with same hash_value. Hence, one could rely on this technique till some extent. This also clearly shows that hash_value is an important parameter to consider here.\n2. We see that for none of the top 50 similar images based on hash_difference is bringing the image of the same label. We will repeat these steps with Hamming distance and see if we find something","metadata":{}},{"cell_type":"markdown","source":"# Analyzing How Good Hamming Distance is Performing\n","metadata":{}},{"cell_type":"code","source":"labelgroup_sample_0=train_df[train_df['label_group']==train_df['label_group'][0]].reset_index()\nlabelgroup_sample_0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hamming_dic = {}\nvar=[]\nfor idx,ele in enumerate(train_df['image_phash']):\n    var.append((hamming_distance(train_df['image_phash'][0],ele),idx))\nhamming_dic[0]=var","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=sorted(hamming_dic[0])\nprint(temp[:200])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n1. The  most similar image for the image at index_0 has same group label for the image with index_33161. But the hamming distance between these two is 14. This is quite a big value and because of which image at index_33161 do not come even in the top 200 similar images with image at index_0 based on hamming distance value. Hence, this further gives us the idea that we just cannot rely on the hamming distance value only.","metadata":{}},{"cell_type":"code","source":"val=sorted(hamming_dic[0])\nval=[val[i][1] for i in range(len(val))]\n\nsimilar_pdts_0_all=train_df['image'][val[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_0_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_0 is: ',train_df['label_group'][0])\nfor ele in val[:50]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Index 2937","metadata":{}},{"cell_type":"code","source":"var=[]\nfor idx,ele in enumerate(train_df['image_phash']):\n    var.append((hamming_distance(train_df['image_phash'][2937],ele),idx))\nhamming_dic[2937]=var","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val=sorted(hamming_dic[2937])\nval=[val[i][1] for i in range(len(val))]\n\nsimilar_pdts_2937_all=train_df['image'][val[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_2937_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(2):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+labelgroup_sample_0['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing Similarity Based on Titles:\nWe have considered the hamming distance and hash difference. Let us now see how good it performs for titles.","metadata":{}},{"cell_type":"code","source":"fuzz.ratio(str.lower(train_df['title'][0]),str.lower(train_df['title'][33161]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fuzz_dic={}\nfuzz_dic[0]=fuzz_calculation(0,train_df)\nfuzz_dic[10]=fuzz_calculation(10,train_df)\nfuzz_dic[30]=fuzz_calculation(30,train_df)\nfuzz_dic[2937]=fuzz_calculation(2937,train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Index 0:","metadata":{}},{"cell_type":"code","source":"val_0=sorted(fuzz_dic[0],reverse=True)\nval_0=[val_0[i][1] for i in range(len(val_0))]\n\nsimilar_pdts_0_all=train_df['image'][val_0[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+\n                   similar_pdts_0_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_0 is: ',train_df['label_group'][0])\nfor ele in val_0[:12]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Index 10:","metadata":{}},{"cell_type":"code","source":"val_10=sorted(fuzz_dic[10],reverse=True)\nval_10=[val_10[i][1] for i in range(len(val_10))]\n\nsimilar_pdts_10_all=train_df['image'][val_10[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+\n                   similar_pdts_10_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_0 is: ',train_df['label_group'][10])\nfor ele in val_10[:12]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['label_group']==train_df['label_group'][10]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Index 30:","metadata":{}},{"cell_type":"code","source":"val_30=sorted(fuzz_dic[30],reverse=True)\nval_30=[val_30[i][1] for i in range(len(val_30))]\n\nsimilar_pdts_30_all=train_df['image'][val_30[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+\n                   similar_pdts_30_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_30 is: ',train_df['label_group'][30])\nfor ele in val_30[:12]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][30])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['label_group']==train_df['label_group'][30]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fuzz_dic[30]=fuzz_calculation_with_sep(30,train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_30=sorted(fuzz_dic[30],reverse=True)\nval_30=[val_30[i][1] for i in range(len(val_30))]\n\nsimilar_pdts_30_all=train_df['image'][val_30[:12]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(12):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+\n                   similar_pdts_30_all['image'][i])\n    plt.subplot(3,4,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_30 is: ',train_df['label_group'][30])\nfor ele in val_30[:12]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][30])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Index 2937 ","metadata":{}},{"cell_type":"code","source":"val_2937=sorted(fuzz_dic[2937],reverse=True)\nval_2937=[val_2937[i][1] for i in range(len(val_2937))]\n\nsimilar_pdts_2937_all=train_df['image'][val_2937[:20]].reset_index()\nplt.figure(figsize=(10,10))\nfor i in range(20):\n    img=cv2.imread(r'/kaggle/input/shopee-product-matching/train_images/'+similar_pdts_2937_all['image'][i])\n    plt.subplot(4,5,i+1)\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Label_group of image_2937 is: ',train_df['label_group'][2937])\nfor ele in val_2937[:20]:\n    print(ele,train_df['label_group'][ele],train_df['label_group'][ele]==train_df['label_group'][2937])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['label_group']==train_df['label_group'][2937]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation:\n1. Title is an important feature. We should not ignore words in the title. The higher the fuzz ratio the more similar the images are turning out to be.","metadata":{}}]}