{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd, gc\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\n\nimport cudf, cuml, cupy\nfrom cuml.neighbors import NearestNeighbors\n\nfrom tqdm import tqdm\n# timm.list_models(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:36:59.220622Z","iopub.execute_input":"2022-05-01T17:36:59.220879Z","iopub.status.idle":"2022-05-01T17:37:00.413626Z","shell.execute_reply.started":"2022-05-01T17:36:59.220849Z","shell.execute_reply":"2022-05-01T17:37:00.410797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constant\nTRAIN_PATH=\"../input/shopee-product-matching/train.csv\"\nTRAIN_SIAMESE_PATH=\"../input/code-for-data-generation-for-siamese-training/siamese_data.csv\"\nTEST_PATH=\"../input/shopee-product-matching/test.csv\"\nTRAIN_IMAGE_PATH=\"../input/shopee-product-matching/train_images/\" # + image id\nTEST_IMAGE_PATH=\"../input/shopee-product-matching/test_images/\"\n\n'''\nefficientnet_b0\nefficientnet_b4\nefficientnetv2_rw_m\nvgg16\nswin_large_patch4_window12_384\ngluon_resnext101_32x4d\n'''\nBASE_MODEL = \"efficientnet_b0\"\n\nDIM = (512, 512)\n# DIM = (384, 384)\n# DIM = (320, 320)\n# DIM = (256, 256)\nN_CLASS = 11014\n\nBATCH_SIZE=32\n\nCOMPUTE_CV = False","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.414485Z","iopub.status.idle":"2022-05-01T17:37:00.414783Z","shell.execute_reply.started":"2022-05-01T17:37:00.41463Z","shell.execute_reply":"2022-05-01T17:37:00.414651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_device():\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n        torch.backends.cudnn.benchmark = True\n    else:\n        device = torch.device('cpu') # don't have GPU \n    return device\nDEVICE = get_device()\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.416835Z","iopub.status.idle":"2022-05-01T17:37:00.417506Z","shell.execute_reply.started":"2022-05-01T17:37:00.417255Z","shell.execute_reply":"2022-05-01T17:37:00.41728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\n\ntrain_df['target'] = train_df.label_group.map(\n    train_df.groupby('label_group').posting_id.agg('unique').to_dict()\n)\n\nN_CLASS = train_df['label_group'].nunique()\nprint(\"n_trian: {} n_unique: {} n_per_images: {}\"\n         .format(train_df['label_group'].shape[0],\n                 train_df['label_group'].nunique(),\n                 train_df['label_group'].shape[0]/train_df['label_group'].nunique())\n         )\n\nsample_img = cv2.imread(TRAIN_IMAGE_PATH+train_df.loc[0, 'image'])\nsample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n# plt.imshow(sample_img)\n# plt.show()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.418735Z","iopub.status.idle":"2022-05-01T17:37:00.419377Z","shell.execute_reply.started":"2022-05-01T17:37:00.419142Z","shell.execute_reply":"2022-05-01T17:37:00.419166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Transform only image'''\ndef train_transforms():\n    return A.Compose([\n        A.Normalize(\n            max_pixel_value=255.0, always_apply=True\n        ),\n        ToTensorV2()\n    ])\n\nx = train_transforms()(image=sample_img)['image']\nprint(x.shape, x.min(), x.max())","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.42057Z","iopub.status.idle":"2022-05-01T17:37:00.421192Z","shell.execute_reply.started":"2022-05-01T17:37:00.420962Z","shell.execute_reply":"2022-05-01T17:37:00.420987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = train_df.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain_df['oof'] = train_df.image_phash.map(tmp)\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\ntrain_df['f1'] = train_df.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train_df.f1.mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.422374Z","iopub.status.idle":"2022-05-01T17:37:00.42302Z","shell.execute_reply.started":"2022-05-01T17:37:00.422766Z","shell.execute_reply":"2022-05-01T17:37:00.42279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    test = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_gf = cudf.read_csv('../input/shopee-product-matching/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.42422Z","iopub.status.idle":"2022-05-01T17:37:00.424857Z","shell.execute_reply.started":"2022-05-01T17:37:00.424622Z","shell.execute_reply":"2022-05-01T17:37:00.424647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageModel(nn.Module):\n    def __init__(self, model_name=BASE_MODEL, pretrained=True):\n        self.model_name = model_name\n        self.pretrained=pretrained\n        super().__init__()\n        \n        if model_name==\"resnet50\":\n            self.backbone_model = torchvision.models.resnet50(pretrained=True)\n        \n        else:\n            self.backbone_model = timm.create_model(model_name, pretrained=self.pretrained)\n            if not self.pretrained:\n                checkpoint_path = '../input/newefficentnetb0weights/efficientnet_b0_ra-3dd342df.pth'\n                pretrained_weights = torch.load(checkpoint_path)\n#                 print(pretrained_weights)\n                self.backbone_model.load_state_dict(pretrained_weights)\n            \n        \n    def forward(self, image):\n        output = self.backbone_model(image)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.42611Z","iopub.status.idle":"2022-05-01T17:37:00.426738Z","shell.execute_reply.started":"2022-05-01T17:37:00.426503Z","shell.execute_reply":"2022-05-01T17:37:00.426528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, image,labels,dim=DIM, augmentation=None, is_train=True):\n        self.image = image\n        self.labels = labels\n        self.dim = dim\n        self.is_train = is_train\n        self.augmentation = augmentation\n        \n    def get_image(self, image_path, is_train=True):\n        if self.is_train:\n            img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, image_path))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, self.dim)\n        else:\n            img = cv2.imread(os.path.join(TEST_IMAGE_PATH, image_path))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, self.dim)\n        return img\n        \n    def __len__(self):\n        return len(self.image)\n    \n    def __getitem__(self, idx):\n        img = self.image[idx]\n        img = self.get_image(img)\n        \n        if self.augmentation:\n            tmp = self.augmentation(image=img)\n            img = tmp['image']\n            \n        return img\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.427959Z","iopub.status.idle":"2022-05-01T17:37:00.428606Z","shell.execute_reply.started":"2022-05-01T17:37:00.428358Z","shell.execute_reply":"2022-05-01T17:37:00.428382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BASE = '../input/shopee-product-matching/test_images/'\n# if COMPUTE_CV: BASE = '../input/shopee-product-matching/train_images/'\n\nmodel = ImageModel(pretrained=False)\nmodel = model.to(DEVICE)\nembeds = []\n# print(len(train_df['label_group'].values.tolist()))\n\nif COMPUTE_CV:\n    train_ds = ShopeeDataset(\n        image = train_df['image'].values.tolist(),\n        labels = 0,\n        dim = DIM,\n        is_train = True,\n        augmentation=train_transforms(),\n    )\nelse:\n    train_ds = ShopeeDataset(\n        image = test_df['image'].values.tolist(),\n        labels = 0,\n        dim = DIM,\n        is_train = False,\n        augmentation=train_transforms(),\n    )\n    print(COMPUTE_CV, test_df['image'].values.tolist())\n\ntrain_dl = DataLoader(\n    train_ds,\n    batch_size=32,\n#     pin_memory=True,\n    num_workers=2\n)\n\n# for e,  in train_dl:\n#     print(e)\n\nprint('Computing image embeddings...')\nfor i, tmp in enumerate(tqdm(train_dl)):\n    with torch.no_grad():\n        tmp = tmp.to(DEVICE)\n        image_embeddings = model(tmp)\n        embeds.append(image_embeddings.cpu())\n\nimage_embeddings = np.concatenate(embeds)\ndel train_ds, train_dl, embeds, model\n_ = gc.collect()\nprint('image embeddings shape',image_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.429827Z","iopub.status.idle":"2022-05-01T17:37:00.430455Z","shell.execute_reply.started":"2022-05-01T17:37:00.430223Z","shell.execute_reply":"2022-05-01T17:37:00.430247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.431657Z","iopub.status.idle":"2022-05-01T17:37:00.432308Z","shell.execute_reply.started":"2022-05-01T17:37:00.432073Z","shell.execute_reply":"2022-05-01T17:37:00.432099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"===============","metadata":{}},{"cell_type":"code","source":"!pip install ../input/fairseq0102/sacrebleu-2.0.0-py3-none-any.whl\n!pip install ../input/importlib523/importlib_resources-5.2.3-py3-none-any.whl\n!pip install ../input/testtesttest/antlr4_python3_runtime-4.8-py3-none-any.whl\n!pip install ../input/fairseq0102/omegaconf-2.1.2-py3-none-any.whl\n!pip install ../input/fairseq0102/hydra_core-1.1.2-py3-none-any.whl\n!pip install ../input/fairseq0102/fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2022-05-01T18:30:42.542996Z","iopub.execute_input":"2022-05-01T18:30:42.543268Z","iopub.status.idle":"2022-05-01T18:33:37.848471Z","shell.execute_reply.started":"2022-05-01T18:30:42.543237Z","shell.execute_reply":"2022-05-01T18:33:37.847644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom fairseq.models.roberta import RobertaModel","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:56:45.200906Z","iopub.execute_input":"2022-05-01T17:56:45.20118Z","iopub.status.idle":"2022-05-01T17:56:46.983447Z","shell.execute_reply.started":"2022-05-01T17:56:45.201142Z","shell.execute_reply":"2022-05-01T17:56:46.982683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH_NUM = 0\nLR = 1e-05\nBATCH_SIZE = 32\nBATCH_PER_EPOCH = 1000","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.437211Z","iopub.status.idle":"2022-05-01T17:37:00.437851Z","shell.execute_reply.started":"2022-05-01T17:37:00.437614Z","shell.execute_reply":"2022-05-01T17:37:00.437638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta = RobertaModel.from_pretrained('../input/roberta-mnli-weights/roberta.large.mnli')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:57:50.885851Z","iopub.execute_input":"2022-05-01T17:57:50.886469Z","iopub.status.idle":"2022-05-01T17:58:41.842746Z","shell.execute_reply.started":"2022-05-01T17:57:50.886431Z","shell.execute_reply":"2022-05-01T17:58:41.841325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta.cuda()\nloss_fn = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(roberta.model.classification_heads[\"mnli\"].parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.440865Z","iopub.status.idle":"2022-05-01T17:37:00.441521Z","shell.execute_reply.started":"2022-05-01T17:37:00.441275Z","shell.execute_reply":"2022-05-01T17:37:00.441299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_tensor_size = 500\n\ndef convert(sent):\n    res = torch.zeros(max_tensor_size - 1, dtype=torch.int64, device=DEVICE)\n    t = roberta.encode(sent).to(DEVICE)\n    res[0] = t.shape[0]\n    res[1:t.shape[0] + 1] = t\n    return res\n\ntemp_df = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n\nclass MyDataset(Dataset):\n    \n    def __init__(self):\n        super().__init__()\n        self.df_length = temp_df.shape[0]\n        self.data = torch.zeros(self.df_length, max_tensor_size, dtype=torch.int64, device=DEVICE)\n        self.data[:, 0] = torch.tensor(temp_df[\"label_group\"], dtype=torch.int64, device=DEVICE)\n        \n        temp = temp_df[\"title\"].map(convert).to_numpy()\n        for i, row in enumerate(temp):\n            self.data[i, 1:max_tensor_size] = row\n    \n    def __getitem__(self, idx):\n        first_idx = idx // self.df_length\n        second_idx = idx % self.df_length\n        return self.get_features(first_idx, second_idx)\n    \n    def get_features(self, idx1, idx2):\n        target = 2 if self.data[idx1, 0] == self.data[idx2, 0] else 1\n        first_len = self.data[idx1, 1]\n        second_len = self.data[idx2, 1]\n        x = torch.empty(first_len + second_len, dtype=torch.int64, device=DEVICE)\n        x[:first_len] = self.data[idx1, 2:first_len + 2]\n        x[first_len] = 2\n        x[first_len + 1:] = self.data[idx2, 3:second_len + 2]\n        return (roberta.extract_features(x)[:,0,:].detach().reshape(1, 1, -1), target)\n    \n    def __len__(self):\n        return self.df_length ** 2\n\ndataset = MyDataset()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.442752Z","iopub.status.idle":"2022-05-01T17:37:00.44339Z","shell.execute_reply.started":"2022-05-01T17:37:00.443157Z","shell.execute_reply":"2022-05-01T17:37:00.443181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(epoch, samples_set):\n    tp = 0\n    tn = 0\n    fp = 0\n    fn = 0\n    \n    print(\"validating...\")\n    for sample_idx in tqdm(range(samples_set.shape[0])):\n        sample_idx %= dataset.df_length\n        \n        X, target = dataset.get_features(int(samples_set[sample_idx, 0]), int(samples_set[sample_idx, 1]))\n        target = 1 if target == 2 else 0\n        prediction = roberta.model.classification_heads[\"mnli\"](X).argmax().item()\n        prediction = 1 if prediction == 2 else 0\n        \n        if target == 0:\n            if target == prediction:\n                tn += 1\n            else:\n                fp += 1\n        elif target == 1:\n            if target == prediction:\n                tp += 1\n            else:\n                fn += 1  \n                \n    accuracy = (tp + tn) / test_size\n    recall = (tp / (tp + fp)) if (tp + fp) != 0 else 0\n    precision = (tp / (tp + fn)) if (tp + fn) != 0 else 0\n    f_score = (2 * recall * precision / (recall + precision)) if (recall + precision) != 0 else 0\n    print(\"Epoch (\" + str(epoch) + \")\", end=\" \")\n    print(\"Accuracy :\", accuracy, end=\" \")\n    print(\"Recall :\", recall, end=\" \")\n    print(\"Precision :\", precision, end=\" \")\n    print(\"F Score :\", f_score)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.444618Z","iopub.status.idle":"2022-05-01T17:37:00.445256Z","shell.execute_reply.started":"2022-05-01T17:37:00.445025Z","shell.execute_reply":"2022-05-01T17:37:00.445049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = []\nwill_valid = False\ntest_size = math.floor(dataset.df_length * 0.1)\n\nfor epoch in range(EPOCH_NUM):\n    total_loss = 0\n    \n    samples_set = np.random.randint(0, high=dataset.df_length, size=(BATCH_SIZE * BATCH_PER_EPOCH, 2))\n\n    current_sample = 0\n    for batch in range(BATCH_PER_EPOCH):\n        Xs = torch.empty(BATCH_SIZE, 1, 1024, device=DEVICE)\n        targets = torch.zeros(BATCH_SIZE, 3, device=DEVICE)\n        for i in range(BATCH_SIZE):\n            X, y = dataset.get_features(int(samples_set[current_sample, 0]), int(samples_set[current_sample, 1]))\n            current_sample += 1\n            if current_sample >= len(dataset):\n                current_sample = 0\n            Xs[i][:] = X\n            targets[i][y] = 1\n        \n        optimizer.zero_grad()\n        predictions = roberta.model.classification_heads[\"mnli\"](Xs)\n        \n        loss = loss_fn(predictions, targets)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    \n    if will_valid:\n        test_samples_set = np.random.randint(0, high=dataset.df_length, size=(test_size, 2))\n        valid(epoch, test_samples_set)\n    loss_history.append(total_loss)\n    print(\"EPOCH loss :\", total_loss)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.446496Z","iopub.status.idle":"2022-05-01T17:37:00.447126Z","shell.execute_reply.started":"2022-05-01T17:37:00.44687Z","shell.execute_reply":"2022-05-01T17:37:00.446894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(loss_history)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.448325Z","iopub.status.idle":"2022-05-01T17:37:00.448985Z","shell.execute_reply.started":"2022-05-01T17:37:00.448731Z","shell.execute_reply":"2022-05-01T17:37:00.448756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"========\nMERGER","metadata":{}},{"cell_type":"code","source":"def predict_nlp(idx1, idx2):\n    encoded = roberta.encode(test[\"title\"].iloc[idx1], test[\"title\"].iloc[idx2])\n    features = roberta.extract_features(encoded)\n    res = roberta.model.classification_heads[\"mnli\"](features).argmax().item()\n    return res == 2","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.450324Z","iopub.status.idle":"2022-05-01T17:37:00.451065Z","shell.execute_reply.started":"2022-05-01T17:37:00.45077Z","shell.execute_reply":"2022-05-01T17:37:00.450798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(TS=18.0, print_data=True):\n    preds = []\n    CHUNK = 1024\n\n    \n    print('Finding similar images...')\n    CTS = len(image_embeddings)//CHUNK\n    if len(image_embeddings)%CHUNK!=0: CTS += 1\n    for j in range( CTS ):\n\n        a = j*CHUNK\n        b = (j+1)*CHUNK\n        b = min(b,len(image_embeddings))\n        if print_data: print('chunk',a,'to',b)\n        distances, indices = model.kneighbors(image_embeddings[a:b,])\n\n        for k in range(b-a):\n            IDX = np.where(distances[k,]<TS)[0]\n            IDS = indices[k,IDX]\n            \n            temp = []\n            for i in range(IDS.shape[0]):\n                current = IDS[i]\n                if predict_nlp(len(preds), current):\n                    temp.append(current)\n            \n            \n            IDS = np.array(temp)\n            o = test.iloc[IDS].posting_id.values\n            preds.append(o)\n        \n    return preds\n\npreds = predict(30)\n# preds\n# del model, distances, indices, image_embeddings, embeds\n# _ = gc.collect()\n# best ts for efficientnet_b0: 18.0 f1_score: 0.6358098027565081 (512, 512)\n# best ts for efficientnet_b0: 24.0 f1_score: 0.6201323875459158 (256, 256)\n# best ts for efficientnetv2_rw_m: 13.5 f1_score: 0.5539241111324119 (320, 320) from paper\n# best ts for efficientnetv2_rw_m: 12.0 f1_score: 0.5642019980069831 (512, 512)\n# best ts for vgg16: 17.0 f1_score: 0.6318011447485347 (512, 512)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.452348Z","iopub.status.idle":"2022-05-01T17:37:00.453008Z","shell.execute_reply.started":"2022-05-01T17:37:00.452753Z","shell.execute_reply":"2022-05-01T17:37:00.452777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds'] = preds\ntmp = [e.shape[0] for e in test['preds']]\nprint(max(tmp))\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.454201Z","iopub.status.idle":"2022-05-01T17:37:00.454821Z","shell.execute_reply.started":"2022-05-01T17:37:00.454587Z","shell.execute_reply":"2022-05-01T17:37:00.454611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return np.unique(x)\n\ndef my_combine_for_sub(row):\n    x = row.preds\n    return ' '.join( np.unique(x) )\n\ndef my_for_cv(row):\n    return row.preds","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.456047Z","iopub.status.idle":"2022-05-01T17:37:00.456722Z","shell.execute_reply.started":"2022-05-01T17:37:00.456479Z","shell.execute_reply":"2022-05-01T17:37:00.456505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(combine=my_for_cv):\n    if COMPUTE_CV:\n        tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n        test['target'] = test.label_group.map(tmp)\n        test['oof'] = test.apply(combine,axis=1)\n        test['f1'] = test.apply(getMetric('oof'),axis=1)\n        print('CV Score =', test.f1.mean() )\n\nget_score()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.457965Z","iopub.status.idle":"2022-05-01T17:37:00.458606Z","shell.execute_reply.started":"2022-05-01T17:37:00.458353Z","shell.execute_reply":"2022-05-01T17:37:00.458376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def something():\n    if COMPUTE_CV:\n        log = []\n        index_log = []\n        for i in np.arange(9.0, 30.0, 0.5):\n            test['preds'] = predict(i, print_data=False)\n            tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n            test['target'] = test.label_group.map(tmp)\n            test['oof'] = test.apply(my_for_cv,axis=1)\n            test['f1'] = test.apply(getMetric('oof'),axis=1)\n            print('TS = {},CV Score = {}'.format(i, test.f1.mean()))\n            index_log.append(i)\n            log.append(test.f1.mean())\n    \nsomething()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.459819Z","iopub.status.idle":"2022-05-01T17:37:00.460453Z","shell.execute_reply.started":"2022-05-01T17:37:00.460219Z","shell.execute_reply":"2022-05-01T17:37:00.460243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['matches'] = test.apply(my_combine_for_sub,axis=1)\ntest[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T17:37:00.461649Z","iopub.status.idle":"2022-05-01T17:37:00.462296Z","shell.execute_reply.started":"2022-05-01T17:37:00.462059Z","shell.execute_reply":"2022-05-01T17:37:00.462083Z"},"trusted":true},"execution_count":null,"outputs":[]}]}