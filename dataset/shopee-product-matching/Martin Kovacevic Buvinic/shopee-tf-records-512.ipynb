{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport re\nimport math\nimport os\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\nimport cudf\nimport cuml\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml import PCA\nfrom joblib import dump, load\nimport gc\n\n\n# Amount of tf records we want to create\nFOLDS = 15\n# Random seed for stratification\nSEED = 123\n# Image size \nIMAGE_SIZE = (512, 512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to get our text title embeddings (we also use pca to reduce the dimension)\ndef get_text_embeddings(df_cu, max_features = 15000, n_components = 5000):\n    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    # Save tfidf model to disk for inference\n    dump(model, 'TfidfVectorizer.joblib')\n    # Sanity Check\n    model = load('TfidfVectorizer.joblib')\n    # Save pca model to disk for inference\n    pca = PCA(n_components = n_components)\n    text_embeddings = pca.fit_transform(text_embeddings).get()\n    dump(pca, 'PCA.joblib')\n    print(f'Our title text embedding shape is {text_embeddings.shape}')\n    del model, pca\n    gc.collect()\n    return text_embeddings\n\n# Function to read and preprocess our data\ndef preprocess():\n    # Read train and test csv\n    train = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    label_mapper = dict(zip(train['label_group'].unique(), np.arange(len(train['label_group'].unique()))))\n    train['label_group'] = train['label_group'].map(label_mapper)\n    # Get ground truth labels format\n    tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n    train['matches'] = train['label_group'].map(tmp)\n    train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n    # Calculate title features with tfidf\n    train_cu = cudf.DataFrame(train)\n    text_embeddings = get_text_embeddings(train_cu)\n    # Calculate naive score using self-post\n    train['f1'] = f1_score(train['matches'], train['posting_id'])\n    score = train['f1'].mean()\n    print(f'Using the same posting id as prediction our f1 score is {score}')\n    return train, text_embeddings\n\ntrain, text_embeddings = preprocess()\n\nkfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nfor fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train['label_group'])):\n    train.loc[val_ind, 'fold'] = fold\ntrain['fold'] = train['fold'].astype(int)\n\n# Save train\ntrain.to_csv('train_folds.csv', index = False)\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_array(array):\n    tensor = tf.convert_to_tensor(array)\n    result = tf.io.serialize_tensor(tensor)\n    return result\n\ndef serialize_example(posting_id, image, title, label_group, matches):\n    feature = {\n        'posting_id': _bytes_feature(posting_id),\n        'image': _bytes_feature(image),\n        'title': _bytes_feature(title),\n        'label_group': _int64_feature(label_group),\n        'matches': _bytes_feature(matches)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\n\nfor fold in range(FOLDS):\n    print('\\n')\n    print('-'*50)\n    print(f'Writing TFRecord {fold} of {FOLDS - 1}...')\n    train_ = train[train['fold'] == fold]\n    # Get indices to slice our text features\n    text_embeddings_ = text_embeddings[train_.index]\n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(fold, train_.shape[0])) as writer:\n        for k in range(train_.shape[0]):\n            row = train_.iloc[k]\n            image = cv2.imread('../input/shopee-product-matching/train_images/' + row['image'])\n            image = cv2.resize(image, IMAGE_SIZE)\n            image = cv2.imencode('.jpg', image, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tobytes()\n            title = text_embeddings_[k].astype(np.float64)\n            title = serialize_array(title)\n            posting_id = row['posting_id']\n            label_group = row['label_group']\n            matches = row['matches']\n            example = serialize_example(str.encode(posting_id),\n                                        image,\n                                        title,\n                                        label_group,\n                                        str.encode(matches))\n            writer.write(example)\n            if k%100==0: print(k,', ',end='')\n                \n\n# Save csv\ntrain.to_csv('train_folds.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}