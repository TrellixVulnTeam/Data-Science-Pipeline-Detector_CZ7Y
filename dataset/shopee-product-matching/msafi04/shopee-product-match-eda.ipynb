{"cells":[{"metadata":{},"cell_type":"markdown","source":"__Shopee is the leading e-commerce platform in Southeast Asia and Taiwan.__"},{"metadata":{},"cell_type":"markdown","source":"# Competition Goal\n\n__In this competition, youâ€™ll apply your machine learning skills to build a model that predicts which items are the same products.__"},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Metric\n\n__Submissions will be evaluated based on their mean F1 score.__"},{"metadata":{},"cell_type":"markdown","source":"# Code Requirements\n\nSubmissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n\n- CPU Notebook <= 9\n- GPU Notebook <= 2\n- Internet access disabled\n- Freely & publicly available external data is allowed, including pre-trained models\n- Submission file must be named \"submission.csv\""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n#pd.set_option('display.max_rows', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set3')\n\nimport cv2\nimport gc\n\nimport os\nprint(os.listdir('/kaggle/input/shopee-product-matching/'))\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))\n\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/shopee-product-matching/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(base_dir + 'train.csv')\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(base_dir + 'test.csv')\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(base_dir + 'sample_submission.csv')\nprint(sub.shape)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of train images: {len(os.listdir(base_dir + \"train_images/\"))}')\nprint(f'Number of test images: {len(os.listdir(base_dir + \"test_images/\"))}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Let's add a column in the train/test set with the train/test images path"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['image_path'] = base_dir + 'train_images/' + train['image']\ntest['image_path'] = base_dir + 'test_images/' + test['image']\ndisplay(train.head(2), test.head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images(paths, rows, cols, title = None):\n    fig, ax = plt.subplots(rows, cols, figsize = (16, 12))\n    ax = ax.flatten()\n    for i, path in enumerate(image_paths):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        ax[i].set_title(img.shape)\n        ax[i].imshow(img)\n        ax[i].grid(False)\n    if title:\n        plt.suptitle(title, fontsize = 15, y = 1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display random train Images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'], 9)\ndisplay_images(image_paths, 3, 3, 'Display Random Train Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'], 9)\ndisplay_images(image_paths, 3, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display Test Images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = test['image_path'].values\ndisplay_images(image_paths, 1, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display Images by Label_Group__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label_group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'][train['label_group'] == 3627744656].values, 9)\ndisplay_images(image_paths, 3, 3, 'Train Images with most frequent label group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'][train['label_group'] == 994676122].values, 9)\ndisplay_images(image_paths, 3, 3, 'Train Images with most frequent label group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = train['image_path'][train['label_group'] == 1615893885].values\ndisplay_images(image_paths, 1, 2, 'Train Images with least frequent label group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Distribution of trainset title length')\nsns.histplot(train['title'].apply(lambda x: len(x)), kde = True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of unqiue titles in trainset: {train[\"title\"].nunique()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So there are images with same title in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['title_len'] = train['title'].apply(lambda x: len(x))\nprint(f'Max. title length: {train[\"title_len\"].max()}')\nprint(f'Min. title length: {train[\"title_len\"].min()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display Images with same title__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 'Koko syubbanul muslimin koko azzahir koko baju'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 'Emina Glossy Stain'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 'Viva Air Mawar'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Finding Similar Images using Nearest Neighbor__\n\n- Extract image embeddings using a pre-trained tensorflow model\n- Find nearest neighbor of an image based on Euclidean Distance using sklearn "},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import EfficientNetB1\n\nprint(f'Tensorflow version: {tf.__version__}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TPU CONFIG\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nBATCH_SIZE = 128 * strategy.num_replicas_in_sync\nprint(BATCH_SIZE)\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nprint(GCS_DS_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths = GCS_DS_PATH + '/train_images/' + train['image']\ntrain_paths[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create TF Dataset\ndef decode_image(filename, label = None, image_size = (256, 256)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels = 3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths))\n    .map(decode_image, num_parallel_calls = AUTO)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for t in train_dataset.unbatch().batch(10):\n    print(t.numpy().shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Check Images have loaded correctly__"},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in train_dataset.take(1):\n    for i in range(12):\n        ax = plt.subplot(3, 4, i + 1)\n        plt.imshow(img[i].numpy())\n        plt.grid(False)\n        plt.axis('off')\n        plt.title(img[i].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EfficientNetB1(weights = 'imagenet', include_top = False, pooling = 'avg', input_shape = None)\nimage_embeddings = model.predict(train_dataset, verbose = 1)\nprint(f'Train Image Embeddings shape: {image_embeddings.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\n\nknn = 20\nnn = NearestNeighbors(n_neighbors = knn)\nnn.fit(image_embeddings)\ndistances, indices = nn.kneighbors(image_embeddings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Predict similar images of few train images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_similar(index):\n    query_image = image_embeddings[index].reshape(1, -1)\n    distances, indices = nn.kneighbors(query_image)\n\n    dist = np.where(distances[0] < 3.0)[0]\n    idx = indices[0][dist]\n    posting_ids = train.iloc[idx]['posting_id'].values\n    #print(posting_ids)\n    return posting_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_similar(postings):\n    for i in range(6):\n        ax = plt.subplot(2, 3, i + 1)\n        img = cv2.imread(train['image_path'][train['posting_id'] == str(postings[i])].values[0])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        img = cv2.resize(img, (256, 256))\n        plt.imshow(img)\n        plt.grid(False)\n        plt.axis('off')\n        if i == 0:\n            plt.title('Query Image')\n        else:\n            plt.title('Prediction Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"posting_ids = find_similar(1000)\nplot_similar(posting_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"posting_ids = find_similar(100)\nplot_similar(posting_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"posting_ids = find_similar(1990)\nplot_similar(posting_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}