{"cells":[{"metadata":{},"cell_type":"markdown","source":"__Shopee is the leading e-commerce platform in Southeast Asia and Taiwan.__"},{"metadata":{},"cell_type":"markdown","source":"Thanks to Chris @cdeotte for his great works and sharing the knowledge!!"},{"metadata":{},"cell_type":"markdown","source":"# Competition Goal\n\n__In this competition, youâ€™ll apply your machine learning skills to build a model that predicts which items are the same products.__"},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Metric\n\n__Submissions will be evaluated based on their mean F1 score.__"},{"metadata":{},"cell_type":"markdown","source":"# Code Requirements\n\nSubmissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n\n- CPU Notebook <= 9\n- GPU Notebook <= 2\n- Internet access disabled\n- Freely & publicly available external data is allowed, including pre-trained models\n- Submission file must be named \"submission.csv\""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_colwidth', None)\n#pd.set_option('display.max_rows', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set3')\n\nimport cv2\nimport gc\n\nimport itertools\nimport collections\nfrom collections import Counter\n\nfrom nltk.corpus import stopwords\n\nimport re\nfrom wordcloud import WordCloud\n\nimport os\nprint(os.listdir('/kaggle/input/shopee-product-matching/'))\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))\n\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/shopee-product-matching/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(base_dir + 'train.csv')\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(base_dir + 'test.csv')\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(base_dir + 'sample_submission.csv')\nprint(sub.shape)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of train images: {len(os.listdir(base_dir + \"train_images/\"))}')\nprint(f'Number of test images: {len(os.listdir(base_dir + \"test_images/\"))}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Let's add a column in the train/test set with the train/test images path"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['image_path'] = base_dir + 'train_images/' + train['image']\ntest['image_path'] = base_dir + 'test_images/' + test['image']\ndisplay(train.head(), test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = train.groupby('label_group')['posting_id'].agg('unique').to_dict()\ntrain['target'] = train['label_group'].map(tmp)\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_f1metric(col):\n    def f1score(row):\n        n = len(np.intersect1d(row.target, row[col]))\n        return 2 * n / (len(row.target) + len(row[col]))\n    return f1score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To calculate F1 score - local\ntmp = train.groupby('image_phash')['posting_id'].agg('unique').to_dict()\ntrain['oof'] = train['image_phash'].map(tmp)\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['f1_base'] = train.apply(get_f1metric('oof'), axis = 1)\nprint(f\"Train F1 Score: {train['f1_base'].mean()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images(paths, rows, cols, title = None):\n    fig, ax = plt.subplots(rows, cols, figsize = (16, 12))\n    ax = ax.flatten()\n    for i, path in enumerate(image_paths):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        ax[i].set_title(img.shape)\n        ax[i].imshow(img)\n        ax[i].grid(False)\n    if title:\n        plt.suptitle(title, fontsize = 15, y = 1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display random train Images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'], 9)\ndisplay_images(image_paths, 3, 3, 'Display Random Train Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'], 9)\ndisplay_images(image_paths, 3, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display Test Images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = test['image_path'].values\ndisplay_images(image_paths, 1, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display Images by Label_Group__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label_group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'][train['label_group'] == 3627744656].values, 9)\ndisplay_images(image_paths, 3, 3, 'Train Images with most frequent label group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = np.random.choice(train['image_path'][train['label_group'] == 994676122].values, 9)\ndisplay_images(image_paths, 3, 3, 'Train Images with most frequent label group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = train['image_path'][train['label_group'] == 1615893885].values\ndisplay_images(image_paths, 1, 2, 'Train Images with least frequent label group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Distribution of trainset title length')\nsns.histplot(train['title'].apply(lambda x: len(x)), kde = True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of unqiue titles in trainset: {train[\"title\"].nunique()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So there are images with same title in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['title_len'] = train['title'].apply(lambda x: len(x))\ntest['title_len'] = test['title'].apply(lambda x: len(x))\n\nprint(f'Max. train title length: {train[\"title_len\"].max()}')\nprint(f'Min. train title length: {train[\"title_len\"].min()}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Title Text WordCloud__"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_wordcloud(data, senti = None, text = None):\n    stop = stopwords.words('english')\n    all_words = [word for each in data['title'] for word in each.split() if word not in stop]\n    word_freq = Counter(all_words)\n\n    wordcloud = WordCloud(width = 900,\n                          height = 500,\n                          max_words = 200,\n                          max_font_size = 100,\n                          relative_scaling = 0.5,\n                          background_color = \"rgba(255, 255, 255, 0)\", \n                          mode = \"RGBA\",\n                          normalize_plurals = True).generate_from_frequencies(word_freq)\n    plt.figure(figsize = (16, 12))\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.title(text)\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_wordcloud(train, text = 'Train Title WordCloud')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display Images with same title__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 'Koko syubbanul muslimin koko azzahir koko baju'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 'Emina Glossy Stain'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 'Viva Air Mawar'\nimage_paths = np.random.choice(train['image_path'][train['title'] == t].values, 6)\ndisplay_images(image_paths, 2, 3, t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For submission test set will be replaced with bigger dataset\nif len(test) == 3:\n    df = train\n    img_dir = '../input/shopee-product-matching/train_images/'\n    print(df.shape)\nelse:\n    df = test\n    img_dir = '../input/shopee-product-matching/test_images/'\n    print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Finding Similar Images using Nearest Neighbor__\n\n- Extract image embeddings using a pre-trained tensorflow model\n- Find nearest neighbor of an image based on Euclidean Distance using sklearn "},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.applications import EfficientNetB0\n\nprint(f'Tensorflow version: {tf.__version__}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find similar images using image embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDataGen(tf.keras.utils.Sequence):\n    def __init__(self, img_path, data, batch_size, \n                 dim, shuffle = False):\n        self.dim  = dim\n        self.data = data\n        self.shuffle  = shuffle\n        self.img_path = img_path\n        self.batch_size = batch_size\n        self.list_idx = self.data.index.values\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(float(len(self.data)) / float(self.batch_size)))\n    \n    def __getitem__(self, index):\n        batch_idx = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n        \n        idx = [self.list_idx[k] for k in batch_idx]\n        \n        Data   = np.zeros((len(batch_idx), self.dim, self.dim, 3), dtype = 'float32')\n        \n        for i, k in enumerate(idx):\n            # load the image file using cv2\n            image = cv2.imread(self.img_path + self.data['image'][k])\n            image = cv2.resize(image, (self.dim, self.dim))\n            \n            # assign \n            Data[i, ] =  image\n            \n        return Data\n    \n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.list_idx))\n        if self.shuffle:\n            np.random.shuffle(self.indices)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Check Images have loaded correctly__"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(dataset, row, col):\n    plt.rcParams['figure.figsize'] = 20, 10\n    for i in range(row):\n        f, ax = plt.subplots(1, col)\n        for p in range(col):\n            idx = np.random.randint(0, len(dataset))\n            img = dataset[idx]\n            ax[p].grid(False)\n            ax[p].axis('off')\n            ax[p].imshow(img[0].astype('uint8'))\n    plt.show()\n    \ntraingen = ImageDataGen(img_dir, df, batch_size = 32, dim = 256)\nplot_images(traingen, 3, 3)\n\ndel traingen\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Define model to extract embeddings__"},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = '../input/tfkeras-efficientnet-weights/efficientnetb0_notop.h5'\n\nmodel = EfficientNetB0(weights = weights, include_top = False, pooling = 'avg', input_shape = None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Since GPU Notebook should < 2 hours, we chunk the inout data to speed up "},{"metadata":{"trusted":true},"cell_type":"code","source":"def chunker(data, size):\n    return (data[start: start + size] for start in range(0, len(data), size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nchunk_size = 4096\nembeddings = []\n\nfor k, chunk in enumerate(chunker(df, chunk_size)):\n    print(f'Chunk: {k + 1}')\n    datagen = ImageDataGen(img_dir, chunk, batch_size = 128, dim = 256)\n    img_embed = model.predict(datagen, verbose = 1)\n    embeddings.append(img_embed)\n    \nimage_embeddings = np.concatenate(embeddings)\nprint(f'Train Image Embeddings shape: {image_embeddings.shape}')\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Use KNN to find similar images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 50\nnn = NearestNeighbors(n_neighbors = n)\nnn.fit(image_embeddings)\n#distances, indices = nn.kneighbors(image_embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#chunk_size = 4096\npreds = []\n\nfor k, chunk in enumerate(chunker(image_embeddings, chunk_size)):\n    print(f'Chunk: {k + 1}')\n    distances, indices = nn.kneighbors(chunk)\n    for i in range(len(chunk)):\n        dists = np.where(distances[i,] < 6.0)[0]\n        idx = indices[i, dists]\n        post_ids = df['posting_id'].iloc[idx].values\n        preds.append(post_ids)\n\nprint(len(preds))\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['matches'] = preds\ndf['num_similar_img'] = df['matches'].apply(lambda x: len(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Display similar images__"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textwrap import wrap\n\ndef plot_similar():\n    while(True):\n        pid = np.random.choice(df['posting_id'].values, 1)\n        pred_ids = df['matches'][df['posting_id'] == pid[0]].values[0]\n        #print(pred_ids)\n        if len(pred_ids) > 1:\n            break\n\n    if len(pred_ids) > 7:\n        col = 6\n    else:\n        col = len(pred_ids)\n    fig, ax = plt.subplots(1, col, figsize = (10, 4))\n\n    for i, ids in enumerate(pred_ids[:col]):\n        path = df['image_path'][df['posting_id'] == ids].values[0]\n        title = df['title'][df['posting_id'] == ids].values[0]\n        img = cv2.imread(path)\n        ax[i].imshow(img)\n        ax[i].set_title(\"\\n\".join(wrap(title, 30)), fontsize = 10)\n        ax[i].grid(False)\n        ax[i].axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_similar()\nplot_similar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To calculate F1 score - local\ntmp = df.groupby('label_group')['posting_id'].agg('unique').to_dict()\ndf['target'] = df['label_group'].map(tmp)\ndf['f1_img'] = df.apply(get_f1metric('matches'), axis = 1)\nprint(f\"CV Score: {df['f1_img'].mean()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\nsubs = pd.read_csv('submission.csv')\nsubs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}