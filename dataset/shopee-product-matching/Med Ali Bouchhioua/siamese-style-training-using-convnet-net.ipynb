{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T14:16:25.169382Z","iopub.execute_input":"2022-04-16T14:16:25.16969Z","iopub.status.idle":"2022-04-16T14:16:25.1979Z","shell.execute_reply.started":"2022-04-16T14:16:25.169609Z","shell.execute_reply":"2022-04-16T14:16:25.197209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport gc\nimport math\nimport random\nimport os\nimport pandas as pd\nimport numpy as np\n\n# Visuals and CV2\nimport matplotlib.pyplot as plt\n#import cudf, cuml, cupy\nimport cv2\n\n# albumentations for augs\nimport albumentations\nimport torchvision.transforms as transforms\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#torch\nimport torch\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn.functional as F \nfrom torch import nn \nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:25.200801Z","iopub.execute_input":"2022-04-16T14:16:25.202965Z","iopub.status.idle":"2022-04-16T14:16:30.136782Z","shell.execute_reply.started":"2022-04-16T14:16:25.202935Z","shell.execute_reply":"2022-04-16T14:16:30.135925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Configuration","metadata":{}},{"cell_type":"code","source":"#DIM = (512,512)\n\nNUM_WORKERS = 4\nBATCH_SIZE = 8\n\nEPOCHS = 20\nSEED = 2020\nLR = 3e-4\n\n#TRAIN_IMG = '../input/signature-verification-dataset/sign_data/train'\n#shop_csv = '../input/shopee-product-matching/train.csv'\n#shop_train = '../input/shopee-product-matching/train.csv'\n\ntraining_csv = '../input/signature-verification-dataset/sign_data/train_data.csv'\ntraining_dir = '../input/signature-verification-dataset/sign_data/train/'\n\nDEVICE = \"cuda\"\n\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\n\n\n################################################# MODEL ####################################################################\n\nMODEL_NAME = 'resnet50d' #efficientnet_b3 #efficientnetb5 #efficientnetb7\n\nSCHEDULER = 'CosineAnnealingWarmRestarts' #'CosineAnnealingLR'\nT_0=3 # CosineAnnealingWarmRestarts\nmin_lr=1e-6","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.139005Z","iopub.execute_input":"2022-04-16T14:16:30.139273Z","iopub.status.idle":"2022-04-16T14:16:30.145558Z","shell.execute_reply.started":"2022-04-16T14:16:30.139238Z","shell.execute_reply":"2022-04-16T14:16:30.144809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread('../input/shopee-product-matching/train_images/0000a68812bc7e98c42888dfb1c07da0.jpg')\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.147812Z","iopub.execute_input":"2022-04-16T14:16:30.148274Z","iopub.status.idle":"2022-04-16T14:16:30.199582Z","shell.execute_reply.started":"2022-04-16T14:16:30.148238Z","shell.execute_reply":"2022-04-16T14:16:30.198917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread('../input/signature-verification-dataset/sign_data/train/001/001_01.PNG')\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.202588Z","iopub.execute_input":"2022-04-16T14:16:30.202776Z","iopub.status.idle":"2022-04-16T14:16:30.226044Z","shell.execute_reply.started":"2022-04-16T14:16:30.202753Z","shell.execute_reply":"2022-04-16T14:16:30.225293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### train test split","metadata":{}},{"cell_type":"code","source":"#read train csv\ntrain_all = pd.read_csv(training_csv)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.227407Z","iopub.execute_input":"2022-04-16T14:16:30.227648Z","iopub.status.idle":"2022-04-16T14:16:30.259132Z","shell.execute_reply.started":"2022-04-16T14:16:30.227616Z","shell.execute_reply":"2022-04-16T14:16:30.258484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = '../input/signature-verification-dataset/sign_data/train_data.csv'\ntrain_dir = '../input/signature-verification-dataset/sign_data/train/'","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.260227Z","iopub.execute_input":"2022-04-16T14:16:30.260488Z","iopub.status.idle":"2022-04-16T14:16:30.264384Z","shell.execute_reply.started":"2022-04-16T14:16:30.260454Z","shell.execute_reply":"2022-04-16T14:16:30.263703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.265546Z","iopub.execute_input":"2022-04-16T14:16:30.265998Z","iopub.status.idle":"2022-04-16T14:16:30.27769Z","shell.execute_reply.started":"2022-04-16T14:16:30.265948Z","shell.execute_reply":"2022-04-16T14:16:30.27703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.280112Z","iopub.execute_input":"2022-04-16T14:16:30.280433Z","iopub.status.idle":"2022-04-16T14:16:30.28856Z","shell.execute_reply.started":"2022-04-16T14:16:30.280375Z","shell.execute_reply":"2022-04-16T14:16:30.287914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Augs","metadata":{}},{"cell_type":"code","source":"def get_train_transforms():\n    return albumentations.Compose(\n        [\n            #albumentations.HorizontalFlip(p=0.5),\n            #albumentations.VerticalFlip(p=0.5),\n            #albumentations.Rotate(limit=120, p=0.8),\n            #albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n            #albumentations.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n            #albumentations.ShiftScaleRotate(\n             #   shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n            #),\n            albumentations.Normalize(\n                MEAN, STD, max_pixel_value=255.0, always_apply=True\n            ),\n        \n            ToTensorV2(p=1.0),\n        ]\n    )\n\ndef get_valid_transforms():\n\n    return albumentations.Compose(\n        [albumentations.Normalize(MEAN, STD, max_pixel_value=255.0, always_apply=True),\n        ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.291346Z","iopub.execute_input":"2022-04-16T14:16:30.291526Z","iopub.status.idle":"2022-04-16T14:16:30.297203Z","shell.execute_reply.started":"2022-04-16T14:16:30.291505Z","shell.execute_reply":"2022-04-16T14:16:30.296536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"class SiameseNetworkDataset(Dataset):\n    \n    def __init__(self,dim=(256,256),training_csv=None,training_dir=None,augmentation=None):\n        self.train_df=pd.read_csv(training_csv)\n        self.train_df.columns =[\"image1\",\"image2\",\"label\"]\n        self.train_dir = training_dir \n        self.dim = dim\n        self.augmentation = augmentation\n\n\n    def __len__(self):\n        return len(self.train_df)\n        \n    def __getitem__(self,index):\n        # getting the image path\n        image1_path=os.path.join(self.train_dir,self.train_df.iat[index,0])\n        image2_path=os.path.join(self.train_dir,self.train_df.iat[index,1])\n        label = self.train_df.iat[index,2]\n        \n        img_0 = cv2.imread(image1_path)\n        img_1 = cv2.imread(image1_path)\n        \n        img_0 = cv2.cvtColor(img_0, cv2.COLOR_BGR2RGB)\n        img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n        \n        if self.dim:\n            img_0 = cv2.resize(img_0,self.dim)\n            img_1 = cv2.resize(img_1,self.dim)\n        \n        \n        if self.augmentation:\n            augmented_0 = self.augmentation(image=img_0)\n            augmented_1 = self.augmentation(image=img_1)\n            img_0 = augmented_0['image']\n            img_1 = augmented_1['image']\n        \n        \n        # from numpy to torch\n        #img_0 = torch.from_numpy(img_0)\n        #img_1 = torch.from_numpy(img_1)\n        #\n        #img_0 = torch.permute(img_0, (2, 0, 1)) \n        #img_1 = torch.permute(img_1, (2, 0, 1)) \n        \n        \n        # adding batch size dimension\n        #img_0 = img_0.unsqueeze(0)\n        #img_1 = img_0.unsqueeze(0)\n            \n        #if self.augmentation:\n        #    augmented_0 = self.augmentation(image=img_0)\n        #    augmented_1 = self.augmentation(image=img_1)\n        #    img_0 = augmented_0['image']\n        #    img_1 = augmented_1['image']\n            \n    \n        return img_0, img_1 ,torch.tensor(label,dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.300495Z","iopub.execute_input":"2022-04-16T14:16:30.300919Z","iopub.status.idle":"2022-04-16T14:16:30.312413Z","shell.execute_reply.started":"2022-04-16T14:16:30.300849Z","shell.execute_reply":"2022-04-16T14:16:30.31167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining DataSet\ntrain_dataset = SiameseNetworkDataset(\ntraining_csv=train_csv,\ntraining_dir=train_dir,\naugmentation=get_train_transforms()\n\n)\n    \ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    pin_memory=True,\n    drop_last=False,\n    num_workers=NUM_WORKERS\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.314564Z","iopub.execute_input":"2022-04-16T14:16:30.315021Z","iopub.status.idle":"2022-04-16T14:16:30.338303Z","shell.execute_reply.started":"2022-04-16T14:16:30.314967Z","shell.execute_reply":"2022-04-16T14:16:30.337675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(train_dataset[0][2])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.339545Z","iopub.execute_input":"2022-04-16T14:16:30.339787Z","iopub.status.idle":"2022-04-16T14:16:30.378963Z","shell.execute_reply.started":"2022-04-16T14:16:30.339755Z","shell.execute_reply":"2022-04-16T14:16:30.378326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#img = cv2.imread('../input/signature-verification-dataset/sign_data/train/001/001_01.PNG')\n#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#print(img.shape)\n#img = torch.from_numpy(img)\n#print(img.shape)\n#\n#img = torch.permute(img, (2, 0, 1)) \n#print(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.380748Z","iopub.execute_input":"2022-04-16T14:16:30.381219Z","iopub.status.idle":"2022-04-16T14:16:30.386016Z","shell.execute_reply.started":"2022-04-16T14:16:30.381182Z","shell.execute_reply":"2022-04-16T14:16:30.38527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Defining DataSet\n#train_dataset = SiameseNetworkDataset(\n#training_csv=train_csv,\n#training_dir=train_dir,\n#augmentation=get_train_transforms()\n#\n#)\n#    \n#train_loader = torch.utils.data.DataLoader(\n#    train_dataset,\n#    batch_size=BATCH_SIZE,\n#    pin_memory=True,\n#    drop_last=False,\n#    num_workers=NUM_WORKERS\n#)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.387022Z","iopub.execute_input":"2022-04-16T14:16:30.387483Z","iopub.status.idle":"2022-04-16T14:16:30.394167Z","shell.execute_reply.started":"2022-04-16T14:16:30.38745Z","shell.execute_reply":"2022-04-16T14:16:30.393211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_dataset[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.395674Z","iopub.execute_input":"2022-04-16T14:16:30.396293Z","iopub.status.idle":"2022-04-16T14:16:30.402765Z","shell.execute_reply.started":"2022-04-16T14:16:30.396255Z","shell.execute_reply":"2022-04-16T14:16:30.402058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path = '../input/signature-verification-dataset/sign_data/train/001/001_01.PNG'\n#img = cv2.imread(path)\n#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#img.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.405681Z","iopub.execute_input":"2022-04-16T14:16:30.406385Z","iopub.status.idle":"2022-04-16T14:16:30.41184Z","shell.execute_reply.started":"2022-04-16T14:16:30.406344Z","shell.execute_reply":"2022-04-16T14:16:30.41103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path = '../input/shopee-product-matching/train_images/0000a68812bc7e98c42888dfb1c07da0.jpg'\n#img = cv2.imread(path)\n#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#img.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.413068Z","iopub.execute_input":"2022-04-16T14:16:30.413716Z","iopub.status.idle":"2022-04-16T14:16:30.420065Z","shell.execute_reply.started":"2022-04-16T14:16:30.413659Z","shell.execute_reply":"2022-04-16T14:16:30.419386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ranger Optimizer","metadata":{}},{"cell_type":"code","source":"#credit : https://github.com/Yonghongwei/Gradient-Centralization\n\ndef centralized_gradient(x, use_gc=True, gc_conv_only=False):\n    if use_gc:\n        if gc_conv_only:\n            if len(list(x.size())) > 3:\n                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n        else:\n            if len(list(x.size())) > 1:\n                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n    return x\n\n\nclass Ranger(Optimizer):\n\n    def __init__(self, params, lr=1e-3,                       # lr\n                 alpha=0.5, k=5, N_sma_threshhold=5,           # Ranger options\n                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n                 use_gc=True, gc_conv_only=False, gc_loc=True\n                 ):\n\n        # parameter checks\n        if not 0.0 <= alpha <= 1.0:\n            raise ValueError(f'Invalid slow update rate: {alpha}')\n        if not 1 <= k:\n            raise ValueError(f'Invalid lookahead steps: {k}')\n        if not lr > 0:\n            raise ValueError(f'Invalid Learning Rate: {lr}')\n        if not eps > 0:\n            raise ValueError(f'Invalid eps: {eps}')\n\n        # parameter comments:\n        # beta1 (momentum) of .95 seems to work better than .90...\n        # N_sma_threshold of 5 seems better in testing than 4.\n        # In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.\n\n        # prep defaults and init torch.optim base\n        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas,\n                        N_sma_threshhold=N_sma_threshhold, eps=eps, weight_decay=weight_decay)\n        super().__init__(params, defaults)\n\n        # adjustable threshold\n        self.N_sma_threshhold = N_sma_threshhold\n\n        # look ahead params\n\n        self.alpha = alpha\n        self.k = k\n\n        # radam buffer for state\n        self.radam_buffer = [[None, None, None] for ind in range(10)]\n\n        # gc on or off\n        self.gc_loc = gc_loc\n        self.use_gc = use_gc\n        self.gc_conv_only = gc_conv_only\n        # level of gradient centralization\n        #self.gc_gradient_threshold = 3 if gc_conv_only else 1\n\n        print(\n            f\"Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}\")\n        if (self.use_gc and self.gc_conv_only == False):\n            print(f\"GC applied to both conv and fc layers\")\n        elif (self.use_gc and self.gc_conv_only == True):\n            print(f\"GC applied to conv layers only\")\n\n    def __setstate__(self, state):\n        print(\"set state called\")\n        super(Ranger, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        # note - below is commented out b/c I have other work that passes back the loss as a float, and thus not a callable closure.\n        # Uncomment if you need to use the actual closure...\n\n        # if closure is not None:\n        #loss = closure()\n\n        # Evaluate averages and grad, update param tensors\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n\n                if grad.is_sparse:\n                    raise RuntimeError(\n                        'Ranger optimizer does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]  # get state dict for this param\n\n                if len(state) == 0:  # if first time to run...init dictionary with our desired entries\n                    # if self.first_run_check==0:\n                    # self.first_run_check=1\n                    #print(\"Initializing slow buffer...should not see this at load from saved model!\")\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n\n                    # look ahead weight storage now in state dict\n                    state['slow_buffer'] = torch.empty_like(p.data)\n                    state['slow_buffer'].copy_(p.data)\n\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(\n                        p_data_fp32)\n\n                # begin computations\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                # GC operation for Conv layers and FC layers\n                # if grad.dim() > self.gc_gradient_threshold:\n                #    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n                if self.gc_loc:\n                    grad = centralized_gradient(grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n\n                state['step'] += 1\n\n                # compute variance mov avg\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n\n                # compute mean moving avg\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n\n                buffered = self.radam_buffer[int(state['step'] % 10)]\n\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * \\\n                        state['step'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n                    if N_sma > self.N_sma_threshhold:\n                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (\n                            N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n                    else:\n                        step_size = 1.0 / (1 - beta1 ** state['step'])\n                    buffered[2] = step_size\n\n                # if group['weight_decay'] != 0:\n                #    p_data_fp32.add_(-group['weight_decay']\n                #                     * group['lr'], p_data_fp32)\n\n                # apply lr\n                if N_sma > self.N_sma_threshhold:\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    G_grad = exp_avg / denom\n                else:\n                    G_grad = exp_avg\n\n                if group['weight_decay'] != 0:\n                    G_grad.add_(p_data_fp32, alpha=group['weight_decay'])\n                # GC operation\n                if self.gc_loc == False:\n                    G_grad = centralized_gradient(G_grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n\n                p_data_fp32.add_(G_grad, alpha=-step_size * group['lr'])\n                p.data.copy_(p_data_fp32)\n\n                # integrated look ahead...\n                # we do it at the param level instead of group level\n                if state['step'] % group['k'] == 0:\n                    # get access to slow param tensor\n                    slow_p = state['slow_buffer']\n                    # (fast weights - slow weights) * alpha\n                    slow_p.add_(p.data - slow_p, alpha=self.alpha)\n                    # copy interpolated weights to RAdam param tensor\n                    p.data.copy_(slow_p)\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.422252Z","iopub.execute_input":"2022-04-16T14:16:30.422783Z","iopub.status.idle":"2022-04-16T14:16:30.453712Z","shell.execute_reply.started":"2022-04-16T14:16:30.422748Z","shell.execute_reply":"2022-04-16T14:16:30.452902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"#create a siamese network\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        # Setting up the Sequential of CNN Layers\n        self.cnn1 = nn.Sequential(\n            nn.Conv2d(3, 96, kernel_size=11,stride=1),\n            nn.Mish(),\n            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n            nn.MaxPool2d(3, stride=2),\n            \n            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n            nn.Mish(),\n            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n\n            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n            nn.Mish(),\n            \n            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n            nn.Mish(),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n            \n            nn.Conv2d(256,126 , kernel_size=3,stride=1,padding=1),\n            nn.Mish(),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n            \n            nn.Conv2d(126,28 , kernel_size=3,stride=1,padding=1),\n            nn.Mish(),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout2d(p=0.3),\n        )\n        # Defining the fully connected layers\n        self.fc1 = nn.Sequential(\n            nn.Linear(1008, 1024),\n            nn.Mish(),\n            nn.Dropout2d(p=0.5),\n            \n            nn.Linear(1024, 128),\n            nn.Mish(),\n            \n            nn.Linear(128,2))\n        \n    def forward_once(self, x):\n        # Forward pass\n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        # forward pass of input 1\n        output1 = self.forward_once(input1)\n        # forward pass of input 2\n        output2 = self.forward_once(input2)\n        return output1, output2\n    \nd = SiameseNetwork()\nt1 = torch.ones((1,3,256,256))\nt2 = torch.ones((1,3,256,256))\nx1,x2 = d(t1,t2)\n\n#print(x1.size())\n#print(x2.size())\n\ndel x1,t1,t2,d\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:30.455065Z","iopub.execute_input":"2022-04-16T14:16:30.455571Z","iopub.status.idle":"2022-04-16T14:16:32.445476Z","shell.execute_reply.started":"2022-04-16T14:16:30.455532Z","shell.execute_reply":"2022-04-16T14:16:32.444759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"256*61*61","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.448539Z","iopub.execute_input":"2022-04-16T14:16:32.448739Z","iopub.status.idle":"2022-04-16T14:16:32.456638Z","shell.execute_reply.started":"2022-04-16T14:16:32.448715Z","shell.execute_reply":"2022-04-16T14:16:32.455933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loss","metadata":{}},{"cell_type":"code","source":"class ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n\n\n        return loss_contrastive","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.458024Z","iopub.execute_input":"2022-04-16T14:16:32.458279Z","iopub.status.idle":"2022-04-16T14:16:32.467192Z","shell.execute_reply.started":"2022-04-16T14:16:32.458244Z","shell.execute_reply":"2022-04-16T14:16:32.466466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-Loop","metadata":{}},{"cell_type":"code","source":"def train_fn(dataloader,model,criterion,optimizer,device,epoch,scheduler=None):\n    model.train()\n    loss_score = AverageMeter()\n    \n    tk0 = tqdm(dataloader, total=len(dataloader))\n    for img_0,img_1,label in tk0:\n        \n        img_0 = img_0.to(device)\n        img_1 = img_1.to(device)\n\n        label = label.to(device)\n        \n        batch_size = img_0.shape[0]\n        \n        optimizer.zero_grad()\n        \n        output_1,output_2 = model(img_0,img_1)\n        \n        loss = criterion(output_1,output_2,label)\n        loss.backward()\n        optimizer.step()\n        \n        loss_score.update(loss.detach().item(), batch_size)\n        \n        \n        tk0.set_postfix(Train_Loss=loss_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n    \n    if scheduler is not None:\n            scheduler.step()\n        \n    return loss_score","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.469152Z","iopub.execute_input":"2022-04-16T14:16:32.469412Z","iopub.status.idle":"2022-04-16T14:16:32.483697Z","shell.execute_reply.started":"2022-04-16T14:16:32.46938Z","shell.execute_reply":"2022-04-16T14:16:32.483091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Engine","metadata":{}},{"cell_type":"code","source":"## Defining DataSet\n#train_dataset = SiameseNetworkDataset(\n#training_csv=training_csv,\n#training_dir=training_dir,\n#augmentation=get_train_transforms(),\n#)\n#    \n#train_loader = torch.utils.data.DataLoader(\n#    train_dataset,\n#    batch_size=BATCH_SIZE,\n#    pin_memory=True,\n#    drop_last=False,\n#    num_workers=NUM_WORKERS\n#)\n#","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.486353Z","iopub.execute_input":"2022-04-16T14:16:32.486563Z","iopub.status.idle":"2022-04-16T14:16:32.493028Z","shell.execute_reply.started":"2022-04-16T14:16:32.486539Z","shell.execute_reply":"2022-04-16T14:16:32.492298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#device = torch.device(\"cpu\")\n#    \n## Defining Model for specific fold\n#model = SiameseModel(model_name= MODEL_NAME,out_features=64,pretrained=True)\n#model.to(device)\n#\n##DEfining criterion\n#criterion = ContrastiveLoss()\n#criterion.to(device)\n#\n#optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n##Defining LR SCheduler\n#scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=T_0)\n#train_loss = train_fn(train_loader, model,criterion, optimizer, device,scheduler=scheduler,epoch=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.494398Z","iopub.execute_input":"2022-04-16T14:16:32.494874Z","iopub.status.idle":"2022-04-16T14:16:32.500852Z","shell.execute_reply.started":"2022-04-16T14:16:32.494841Z","shell.execute_reply":"2022-04-16T14:16:32.500183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_dataset[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.50205Z","iopub.execute_input":"2022-04-16T14:16:32.502622Z","iopub.status.idle":"2022-04-16T14:16:32.511664Z","shell.execute_reply.started":"2022-04-16T14:16:32.502586Z","shell.execute_reply":"2022-04-16T14:16:32.510935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    \n    #df = pd.read_csv('../input/shopee-siamese-training/siamese_data.csv')\n\n    \n    # Defining DataSet\n    #train_dataset = SiameseNetworkDataset(\n    #    image_1=df['image_1'].values.tolist(),\n    #    image_2 = df['image_2'].values.tolist(),\n    #    labels=df['label'].values.tolist(),\n    #    dim = DIM,\n    #    augmentation=get_train_transforms(),\n    #)\n    # Defining DataSet\n    train_dataset = SiameseNetworkDataset(\n    training_csv=train_csv,\n    training_dir=train_dir,\n    augmentation=get_train_transforms()\n    \n    )\n        \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        pin_memory=True,\n        drop_last=False,\n        num_workers=NUM_WORKERS\n    )\n    \n\n    # Defining Device\n    device = torch.device(\"cuda\")\n    \n    # Defining Model for specific fold\n    model = SiameseNetwork()\n    model.to(device)\n    \n    #DEfining criterion\n    criterion = ContrastiveLoss()\n    criterion.to(device)\n    \n    #optimizer = Ranger(model.parameters(), lr = LR)\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n    #Defining LR SCheduler\n    scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=T_0)\n    \n    # THE ENGINE LOOP\n    best_loss = 10000\n    for epoch in range(EPOCHS):\n        train_loss = train_fn(train_loader, model,criterion, optimizer, device,epoch=epoch,scheduler=scheduler)\n        if train_loss.avg < best_loss:\n            best_loss = train_loss.avg\n            torch.save(model.state_dict(),f'model_best_loss.pt')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.514641Z","iopub.execute_input":"2022-04-16T14:16:32.51507Z","iopub.status.idle":"2022-04-16T14:16:32.524134Z","shell.execute_reply.started":"2022-04-16T14:16:32.515033Z","shell.execute_reply":"2022-04-16T14:16:32.52318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = run()\ntorch.save(model.state_dict(), \"model.pt\")\nprint(\"Model Saved Successfully\")","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:16:32.52523Z","iopub.execute_input":"2022-04-16T14:16:32.525915Z"},"trusted":true},"execution_count":null,"outputs":[]}]}