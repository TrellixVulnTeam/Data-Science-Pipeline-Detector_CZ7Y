{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Notebook that detects objects in Shopee train set and outputs information in lists. Note that when reading the csv you will need to convert these lists back to a Python list using the *eval* function","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tqdm\nimport math\nimport torch\nimport glob\nfrom collections import defaultdict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"YOLO_CONFIDENCE = 0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Object Detector","metadata":{}},{"cell_type":"code","source":"yolov5 = torch.hub.load('../input/yolov5-git/yolov5-master/yolov5-master', 'yolov5m', source='local')\nyolov5.conf = YOLO_CONFIDENCE  # confidence threshold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict objects","metadata":{}},{"cell_type":"markdown","source":"Get names of photos","metadata":{}},{"cell_type":"code","source":"photos = glob.glob('../input/shopee-product-matching/train_images/*.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auxiliary functions","metadata":{}},{"cell_type":"code","source":"def get_area(x1, x2, y1, y2):\n    return round(abs(x1-x2) * abs(y1-y2), 2)\n\ndef get_distance_to_center(x1, x2, y1, y2):\n    # Distance of normalized coordinates to image center (0.5, 0.5)\n    return round(((x1+x2)/2 - 0.5)**2 + ((y1+y2)/2 - 0.5)**2, 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict objects. For each element, the following is obtained:\n* class_index: list of objects detected. Each object is identified by an index. To access the name of the object, do yolov5.names[index]\n* coordinates: coordinates of the bounding box in [x1, y1, x2, y2] format (not normalized)\n* confidence: confidence of prediction\n* norm_area: normalized area (computed with normalized coordinates, which go from 0 to 1)\n* norm_dis_to_org: normalized distance to the origin of the image from the center of the object (computed with normalized coordinates, which go from 0 to 1)","metadata":{}},{"cell_type":"code","source":"elements_per_batch = 70\nn_batches = math.ceil(len(photos)/elements_per_batch)\nlast_index = 0\nlast_slash = photos[0].rfind('/')  # Index for last slash is always the same\n\npredictions_dict = {}\n\nfor _ in tqdm.tqdm(range(n_batches)):\n    if last_index + elements_per_batch > len(photos):\n        current_photos = photos[last_index:]\n    else:\n        current_photos = photos[last_index:last_index+elements_per_batch]\n    current_photos_names = list(current_photos)  # the model modifies this list, so we keep a copy\n    \n    results = yolov5(current_photos)\n    \n    for photo_index, (photo_name, predictions) in enumerate(zip(current_photos_names, results.pred)):\n        photo_name = photo_name[last_slash+1:]\n        predictions_by_photo = defaultdict(list)\n        for prediction_index, p in enumerate(predictions):\n            x1, y1, x2, y2, confidence, class_index = [round(element, 2) for element in p.tolist()]\n            class_index = int(class_index)\n            predictions_by_photo['class_index'].append(class_index)\n            predictions_by_photo['coordinates'].append([x1, y1, x2, y2])\n            predictions_by_photo['confidence'].append(confidence)\n            # Get normalized coordinates to compute distance to center and area\n            x1_n, y1_n, x2_n, y2_n = results.xyxyn[photo_index][prediction_index].tolist()[:4]\n            predictions_by_photo['norm_area'].append(get_area(x1_n, x2_n, y1_n, y2_n))\n            predictions_by_photo['norm_dis_to_org'].append(get_distance_to_center(x1_n, x2_n, y1_n, y2_n))\n            \n        predictions_dict[photo_name] = predictions_by_photo\n                \n    last_index += elements_per_batch\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Objects to DataFrame","metadata":{}},{"cell_type":"markdown","source":"Create empty columns for all objects to then get values with .apply per row","metadata":{}},{"cell_type":"code","source":"features = ['class_index', 'confidence', 'norm_area', 'coordinates', 'norm_dis_to_org']\nnew_cols = [f'objects_{feature}' for feature in features]\n\ndf_train = df_train.reindex(columns=df_train.columns.tolist() + new_cols, fill_value=[])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auxiliary function to transfer data to DataFrame","metadata":{}},{"cell_type":"code","source":"def get_values_for_row(row):\n    predictions = predictions_dict[row['image']]\n    return pd.Series([predictions[feature] for feature in features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[new_cols] = df_train.apply(get_values_for_row, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv(f'train_obj_0{int(YOLO_CONFIDENCE*10)}.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}