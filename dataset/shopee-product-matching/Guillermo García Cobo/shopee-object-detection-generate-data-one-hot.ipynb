{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Notebook that detects objects in Shopee train set and outputs information in One-Hot format","metadata":{"papermill":{"duration":1.585651,"end_time":"2021-04-08T15:50:30.025374","exception":false,"start_time":"2021-04-08T15:50:28.439723","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport tqdm\nimport math\nimport torch\nimport glob\nfrom collections import defaultdict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"YOLO_CONFIDENCE = 0.3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{"papermill":{"duration":0.008017,"end_time":"2021-04-08T15:50:30.042755","exception":false,"start_time":"2021-04-08T15:50:30.034738","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf_train","metadata":{"papermill":{"duration":0.223545,"end_time":"2021-04-08T15:50:30.274433","exception":false,"start_time":"2021-04-08T15:50:30.050888","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Object Detector","metadata":{"papermill":{"duration":0.008539,"end_time":"2021-04-08T15:50:30.292737","exception":false,"start_time":"2021-04-08T15:50:30.284198","status":"completed"},"tags":[]}},{"cell_type":"code","source":"yolov5 = torch.hub.load('../input/yolov5-git/yolov5-master/yolov5-master', 'yolov5m', source='local')\nyolov5.conf = YOLO_CONFIDENCE  # confidence threshold","metadata":{"papermill":{"duration":8.545868,"end_time":"2021-04-08T15:50:38.847558","exception":false,"start_time":"2021-04-08T15:50:30.30169","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict objects","metadata":{"papermill":{"duration":0.009255,"end_time":"2021-04-08T15:50:38.866353","exception":false,"start_time":"2021-04-08T15:50:38.857098","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Get names of photos","metadata":{"papermill":{"duration":0.008963,"end_time":"2021-04-08T15:50:38.884441","exception":false,"start_time":"2021-04-08T15:50:38.875478","status":"completed"},"tags":[]}},{"cell_type":"code","source":"photos = glob.glob('../input/shopee-product-matching/train_images/*.jpg')","metadata":{"papermill":{"duration":1.199575,"end_time":"2021-04-08T15:50:40.093312","exception":false,"start_time":"2021-04-08T15:50:38.893737","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auxiliary functions","metadata":{"papermill":{"duration":0.010566,"end_time":"2021-04-08T15:50:40.11523","exception":false,"start_time":"2021-04-08T15:50:40.104664","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_area(x1, x2, y1, y2):\n    return round(abs(x1-x2) * abs(y1-y2), 2)\n\ndef get_distance_to_center(x1, x2, y1, y2):\n    # Distance of normalized coordinates to image center (0.5, 0.5)\n    return round(((x1+x2)/2 - 0.5)**2 + ((y1+y2)/2 - 0.5)**2, 4)","metadata":{"papermill":{"duration":0.016985,"end_time":"2021-04-08T15:50:40.142222","exception":false,"start_time":"2021-04-08T15:50:40.125237","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict objects. For each element, the following is obtained:\n* class_index: list of objects detected. Each object is identified by an index. To access the name of the object, do yolov5.names[index]\n* n_occurences: more than one instance per object may be detected, so the count is stored here\n* presence: variable equal to n_occurences > 0, but stored for easier access\n* confidence: confidence of prediction. Note that becuase of One-Hot format only the information of the instance with highest confidence per object is stored\n* norm_area: normalized area (computed with normalized coordinates, which go from 0 to 1)\n* norm_dis_to_org: normalized distance to the origin of the image from the center of the object (computed with normalized coordinates, which go from 0 to 1)","metadata":{}},{"cell_type":"code","source":"elements_per_batch = 70\nn_batches = math.ceil(len(photos)/elements_per_batch)\nlast_index = 0\nlast_slash = photos[0].rfind('/')  # Index for last slash is always the same\n\npredictions_dict = {}\n\nfor _ in tqdm.tqdm(range(n_batches)):\n    if last_index + elements_per_batch > len(photos):\n        current_photos = photos[last_index:]\n    else:\n        current_photos = photos[last_index:last_index+elements_per_batch]\n    current_photos_names = list(current_photos)  # the model modifies this list, so we keep a copy\n    \n    results = yolov5(current_photos)\n    \n    for photo_name, predictions in zip(current_photos_names, results.xyxyn):\n        photo_name = photo_name[last_slash+1:]\n        predictions_by_photo = defaultdict(list)\n        for p in predictions:\n            x1, y1, x2, y2, confidence, class_index = [round(element, 2) for element in p.tolist()]\n            class_index = int(class_index)\n            try:\n                element_index = predictions_by_photo['class_index'].index(class_index)\n                predictions_by_photo['n_occurences'][element_index] += 1\n                if confidence > predictions_by_photo['confidence'][element_index]:  # I think that the model returns predictions ordered by confidence, but just in case\n                    predictions_by_photo['confidence'][element_index] = confidence\n                    predictions_by_photo['norm_area'][element_index] = get_area(x1, x2, y1, y2)\n                    predictions_by_photo['norm_dis_to_org'][element_index] = get_distance_to_center(x1, x2, y1, y2)\n            except ValueError:  # class first occurence\n                predictions_by_photo['class_index'].append(class_index)\n                predictions_by_photo['n_occurences'].append(1)\n                predictions_by_photo['presence'].append(1)\n                predictions_by_photo['confidence'].append(confidence)\n                predictions_by_photo['norm_area'].append(get_area(x1, x2, y1, y2))\n                predictions_by_photo['norm_dis_to_org'].append(get_distance_to_center(x1, x2, y1, y2))\n            \n        predictions_dict[photo_name] = predictions_by_photo\n                \n    last_index += elements_per_batch\n    ","metadata":{"papermill":{"duration":855.872253,"end_time":"2021-04-08T16:04:56.02408","exception":false,"start_time":"2021-04-08T15:50:40.151827","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Objects to DataFrame","metadata":{}},{"cell_type":"markdown","source":"Create empty columns for all objects to then get values with .apply per row","metadata":{"papermill":{"duration":0.125424,"end_time":"2021-04-08T16:04:56.275523","exception":false,"start_time":"2021-04-08T16:04:56.150099","status":"completed"},"tags":[]}},{"cell_type":"code","source":"obj_names_without_spaces = [name.replace(' ', '-') for name in yolov5.names]\nfeatures = ['n_occurences', 'confidence', 'norm_area', 'norm_dis_to_org', 'presence']\nnew_cols = [f'objects_{feature}_{obj_names_without_spaces[object_index]}' for object_index in range(len(yolov5.names)) for feature in features]\n\ndf_train = df_train.reindex(columns=df_train.columns.tolist() + new_cols, fill_value=0)","metadata":{"papermill":{"duration":0.155198,"end_time":"2021-04-08T16:04:56.556173","exception":false,"start_time":"2021-04-08T16:04:56.400975","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auxiliary function to transfer data to DataFrame","metadata":{}},{"cell_type":"code","source":"def get_values_for_row(row):\n    predictions = predictions_dict[row['image']]\n    values = [0] * len(features) * len(yolov5.names)  # Fill all values with 0s and only replace the not null ones\n    for element_index, class_index in enumerate(predictions['class_index']):\n        for feature_index, feature_name in enumerate(features):\n            # Replace 0 with actual value\n            values[class_index*len(features) + feature_index] = predictions[feature_name][element_index]\n    return pd.Series(values)","metadata":{"papermill":{"duration":0.135547,"end_time":"2021-04-08T16:04:56.817546","exception":false,"start_time":"2021-04-08T16:04:56.681999","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[new_cols] = df_train.apply(get_values_for_row, axis=1)","metadata":{"papermill":{"duration":13.349296,"end_time":"2021-04-08T16:05:10.293702","exception":false,"start_time":"2021-04-08T16:04:56.944406","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"papermill":{"duration":0.177438,"end_time":"2021-04-08T16:05:10.597685","exception":false,"start_time":"2021-04-08T16:05:10.420247","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv(f'train_obj_0{int(YOLO_CONFIDENCE*10)}_one-hot.csv')","metadata":{"papermill":{"duration":9.117722,"end_time":"2021-04-08T16:05:19.846696","exception":false,"start_time":"2021-04-08T16:05:10.728974","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}