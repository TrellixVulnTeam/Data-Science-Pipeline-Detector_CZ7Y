{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Directory settiings","metadata":{"papermill":{"duration":0.02722,"end_time":"2021-05-03T14:48:49.843775","exception":false,"start_time":"2021-05-03T14:48:49.816555","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR='./'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nROOT_DIR = '../input/shopee-product-matching/'\nTRAIN_PATH = ROOT_DIR + 'train_images/'\nTEST_PATH = ROOT_DIR + 'test_images/'","metadata":{"papermill":{"duration":0.036616,"end_time":"2021-05-03T14:48:49.904576","exception":false,"start_time":"2021-05-03T14:48:49.86796","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CFG","metadata":{"papermill":{"duration":0.025176,"end_time":"2021-05-03T14:48:49.954138","exception":false,"start_time":"2021-05-03T14:48:49.928962","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug = False\n    CHECK_SUB = False\n    GET_CV = False\n    num_workers = 4\n    model_name_cnn = 'tf_efficientnet_b3_ns'\n    model_name_bert = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n    size = 512\n    batch_size = 8\n    seed = 42\n    target_size = 8811\n    classes = 11014\n    target_size_list = [8811, 8812, 8811, 8811, 8811]\n    target_col = 'label_group'\n    use_fc = False\n    use_arcface = True\n    scale = 30\n    margin = 0.5\n    fc_dim = 512\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    train = False\n    inference = True","metadata":{"papermill":{"duration":0.037537,"end_time":"2021-05-03T14:48:50.016197","exception":false,"start_time":"2021-05-03T14:48:49.97866","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(test)>3: \n    CFG.GET_CV = False\nelse: \n    print('this submission notebook will compute CV score, but commit notebook will not')","metadata":{"papermill":{"duration":0.046422,"end_time":"2021-05-03T14:48:50.087061","exception":false,"start_time":"2021-05-03T14:48:50.040639","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library","metadata":{"papermill":{"duration":0.025226,"end_time":"2021-05-03T14:48:50.13842","exception":false,"start_time":"2021-05-03T14:48:50.113194","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, _LRScheduler\n\nimport transformers\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport gc\nimport matplotlib.pyplot as plt\nimport cudf\nimport cuml\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml import PCA\nfrom cuml.neighbors import NearestNeighbors\n\nimport timm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":10.534565,"end_time":"2021-05-03T14:49:00.697854","exception":false,"start_time":"2021-05-03T14:48:50.163289","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"papermill":{"duration":0.025615,"end_time":"2021-05-03T14:49:00.749677","exception":false,"start_time":"2021-05-03T14:49:00.724062","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\ndef combine_predictions(row):\n    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n    return ' '.join( np.unique(x) )\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n#LOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(CFG.model_name_bert)","metadata":{"papermill":{"duration":2.429563,"end_time":"2021-05-03T14:49:03.204773","exception":false,"start_time":"2021-05-03T14:49:00.77521","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{"papermill":{"duration":0.026014,"end_time":"2021-05-03T14:49:03.257961","exception":false,"start_time":"2021-05-03T14:49:03.231947","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def read_dataset():\n    if CFG.GET_CV:\n        \n        # create folds\n        # trainingの時と同じようにfoldを切っています。\n        folds = pd.read_csv('../input/shopee-product-matching/train.csv')\n        if CFG.debug:\n            folds = folds.sample(n=300, random_state=CFG.seed).reset_index(drop=True)  \n        Fold = GroupKFold(n_splits=CFG.n_fold)\n        groups = folds['label_group'].values\n        for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col], groups)):\n            folds.loc[val_index, 'fold'] = int(n)\n        folds['fold'] = folds['fold'].astype(int)\n        display(folds.groupby('fold').size())\n        \n        tmp = folds.groupby('label_group')['posting_id'].unique().to_dict()\n        folds['matches'] = folds['label_group'].map(tmp)\n        folds['matches'] = folds['matches'].apply(lambda x: ' '.join(x))\n        folds['file_path'] = folds['image'].apply(lambda x: TRAIN_PATH + x)\n        \n        if CFG.CHECK_SUB:\n            folds = pd.concat([folds, folds], axis=0)\n            folds.reset_index(drop=True, inplace=True)\n        folds_cu = cudf.DataFrame(folds)\n    else:\n        folds = pd.read_csv('../input/shopee-product-matching/test.csv')\n        folds['file_path'] = folds['image'].apply(lambda x: TEST_PATH + x)\n        folds_cu = cudf.DataFrame(folds)\n        \n    return folds, folds_cu","metadata":{"papermill":{"duration":0.046555,"end_time":"2021-05-03T14:49:03.331091","exception":false,"start_time":"2021-05-03T14:49:03.284536","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"papermill":{"duration":0.026915,"end_time":"2021-05-03T14:49:03.384114","exception":false,"start_time":"2021-05-03T14:49:03.357199","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    \n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_paths = df['file_path'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        file_path = self.file_paths[idx]\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            \n        return image, torch.tensor(1)","metadata":{"papermill":{"duration":0.037355,"end_time":"2021-05-03T14:49:03.44739","exception":false,"start_time":"2021-05-03T14:49:03.410035","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset_BERT(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.loc[idx, 'title']\n        text = tokenizer(text, padding='max_length', truncation=True, max_length=64, return_tensors='pt')  # 'pt': pytorch\n        input_ids = text['input_ids'][0]\n        attention_mask = text['attention_mask'][0]\n        return input_ids, attention_mask","metadata":{"papermill":{"duration":0.036278,"end_time":"2021-05-03T14:49:03.50964","exception":false,"start_time":"2021-05-03T14:49:03.473362","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loader","metadata":{"papermill":{"duration":0.025735,"end_time":"2021-05-03T14:49:03.561481","exception":false,"start_time":"2021-05-03T14:49:03.535746","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            #Resize(CFG.size, CFG.size),\n            RandomResizedCrop(CFG.size, CFG.size),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    \n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"papermill":{"duration":0.037863,"end_time":"2021-05-03T14:49:03.625436","exception":false,"start_time":"2021-05-03T14:49:03.587573","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"papermill":{"duration":0.026089,"end_time":"2021-05-03T14:49:03.677459","exception":false,"start_time":"2021-05-03T14:49:03.65137","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scale = scale\n        self.margin = margin\n        self.ls_eps = ls_eps\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(margin)\n        self.sin_m = math.sin(margin)\n        self.th = math.cos(math.pi - margin)\n        self.mm = math.sin(math.pi - margin) * margin\n        \n    def forward(self, input, label):\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n    \n        one_hot = torch.zeros(cosine.size(), device='cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.scale\n\n        return output, nn.CrossEntropyLoss()(output,label)\n\nclass CustomEfficientNet(nn.Module):\n    \n    def __init__(\n        self,\n        n_classes = CFG.target_size,\n        model_name = CFG.model_name_cnn,\n        fc_dim = CFG.fc_dim,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True,\n        pretrained = True):\n        \n        super(CustomEfficientNet,self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        \n        if use_fc:\n            self.dropout = nn.Dropout(p=0.1)\n            self.classifier = nn.Linear(in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            in_features = fc_dim\n\n        self.final = ArcMarginProduct(\n            in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n        \n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.constant_(self.classifier.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    def forward(self, image, label):\n        features = self.extract_features(image)\n        if self.training:\n            logits = self.final(features, label)\n            return logits\n        else:\n            return features\n        \n    def extract_features(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        if self.use_fc and self.training:\n            x = self.dropout(x)\n            x = self.classifier(x)\n            x = self.bn(x)\n        return x","metadata":{"papermill":{"duration":0.053414,"end_time":"2021-05-03T14:49:03.757306","exception":false,"start_time":"2021-05-03T14:49:03.703892","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeModel(nn.Module):\n\n    def __init__(\n        self,\n        n_classes = CFG.classes,\n        model_name = CFG.model_name_cnn,\n        fc_dim = 512,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True,\n        pretrained = False):\n\n\n        super(ShopeeModel,self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n\n        if model_name == 'resnext50_32x4d':\n            final_in_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n\n        elif model_name == 'efficientnet_b3':\n            final_in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n\n        elif model_name == 'tf_efficientnet_b5_ns':\n            final_in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n        \n        elif model_name == 'eca_nfnet_l0':\n            final_in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n            self.backbone.head.global_pool = nn.Identity()\n\n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n\n        self.use_fc = use_fc\n\n        self.dropout = nn.Dropout(p=0.0)\n        self.fc = nn.Linear(final_in_features, fc_dim)\n        self.bn = nn.BatchNorm1d(fc_dim)\n        self._init_params()\n        final_in_features = fc_dim\n\n        self.final = ArcMarginProduct(\n            final_in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, image, label):\n        feature = self.extract_feat(image)\n        #logits = self.final(feature,label)\n        return feature\n\n    def extract_feat(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        if self.use_fc:\n            x = self.dropout(x)\n            x = self.fc(x)\n            x = self.bn(x)\n        return x\nclass Mish_func(torch.autograd.Function):\n    \n    \"\"\"from: https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\"\"\"\n    \n    @staticmethod\n    def forward(ctx, i):\n        result = i * torch.tanh(F.softplus(i))\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n  \n        v = 1. + i.exp()\n        h = v.log() \n        grad_gh = 1./h.cosh().pow_(2) \n\n        # Note that grad_hv * grad_vx = sigmoid(x)\n        #grad_hv = 1./v  \n        #grad_vx = i.exp()\n        \n        grad_hx = i.sigmoid()\n\n        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n        \n        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n        \n        return grad_output * grad_f \n\n\nclass Mish(nn.Module):\n    def __init__(self, **kwargs):\n        super().__init__()\n        pass\n    def forward(self, input_tensor):\n        return Mish_func.apply(input_tensor)\n\n\ndef replace_activations(model, existing_layer, new_layer):\n    \n    \"\"\"A function for replacing existing activation layers\"\"\"\n    \n    for name, module in reversed(model._modules.items()):\n        if len(list(module.children())) > 0:\n            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n\n        if type(module) == existing_layer:\n            layer_old = module\n            layer_new = new_layer\n            model._modules[name] = layer_new\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomSEResNeXt(nn.Module):\n    def __init__(\n        self,\n        n_classes = CFG.target_size,\n        model_name = CFG.model_name_cnn,\n        fc_dim = CFG.fc_dim,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True,\n        pretrained = True):\n        \n        super(CustomSEResNeXt, self).__init__()\n        print(f'Building Model Backbone for {model_name} model')\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        \n        if use_fc:\n            self.dropout = nn.Dropout(p=0.1)\n            self.fc = nn.Linear(in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            in_features = fc_dim\n        \n        self.final = ArcMarginProduct(\n            in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n    \n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    def forward(self, image, label):\n        features = self.extract_features(image)\n        if self.training:\n            logits = self.final(features, label)\n            return logits\n        else:\n            return features\n        \n    def extract_features(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n        \n        if self.use_fc:\n            x = self.dropout(x)\n            x = self.fc(x)\n            x = self.bn(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomSEResNet152D(nn.Module):\n    def __init__(\n        self,\n        n_classes = CFG.target_size,\n        model_name = CFG.model_name_cnn,\n        fc_dim = CFG.fc_dim,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True,\n        pretrained = True):\n        \n        super(CustomSEResNet152D, self).__init__()\n        print(f'Building Model Backbone for {model_name} model')\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        \n        if use_fc:\n            self.dropout = nn.Dropout(p=0.1)\n            self.fc = nn.Linear(in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            in_features = fc_dim\n        \n        self.final = ArcMarginProduct(\n            in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n    \n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    def forward(self, image, label):\n        features = self.extract_features(image)\n        if self.training:\n            logits = self.final(features, label)\n            return logits\n        else:\n            return features\n        \n    def extract_features(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n        \n        if self.use_fc:\n            x = self.dropout(x)\n            x = self.fc(x)\n            x = self.bn(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model0 = ShopeeModel(model_name = 'eca_nfnet_l0').to(device)\n        self.model0 = replace_activations(self.model0, torch.nn.SiLU, Mish())\n        self.model0.load_state_dict(torch.load('../input/shopee-nfnetl0-ver0506/eca_nfnet_l0_exp027_fold0_epoch15.pth')['model'])\n        self.model1 = CustomEfficientNet(n_classes=8812, pretrained=False)\n        self.model1.load_state_dict(torch.load('../input/shopee-002-data-ver37/tf_efficientnet_b3_ns_fold1_best.pth')['model'])\n        self.model2 = CustomEfficientNet(n_classes=8811, pretrained=False)\n        self.model2.load_state_dict(torch.load('../input/shopee-002-data-ver37/tf_efficientnet_b3_ns_fold2_best.pth')['model'])\n        self.model3 = CustomSEResNeXt(model_name = 'seresnext50_32x4d', n_classes=CFG.target_size, pretrained=False)\n        self.model3.load_state_dict(torch.load('../input/shopee-007-seresnext-ver3/seresnext50_32x4d_fold3_best.pth')['model'])\n        self.model4 = CustomSEResNet152D(model_name = 'seresnet152d', n_classes=CFG.target_size, pretrained=False)\n        self.model4.load_state_dict(torch.load('../input/shopee-009-seresnet152d-ver4/seresnet152d_fold4_best.pth')['model'])\n        \n        #self.model0 = CustomEfficientNet(n_classes=8811, pretrained=False)\n        #self.model0.load_state_dict(torch.load('../input/shopee-002-data-local/tf_efficientnet_b3_ns_fold0_best.pth')['model'])\n\n        \n        \n    def forward(self, image, label):\n        x0 = self.model0(image, label)\n        x1 = self.model1(image, label)\n        x2 = self.model2(image, label)\n        x3 = self.model3(image, label)\n        x4 = self.model4(image, label)\n        #x = (x0+x1+x2+x3)/4\n        return x0,x1,x2,x3,x4","metadata":{"papermill":{"duration":0.039421,"end_time":"2021-05-03T14:49:03.823683","exception":false,"start_time":"2021-05-03T14:49:03.784262","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomBERT(nn.Module):\n    def __init__(\n        self,\n        n_classes = CFG.target_size,\n        model_name = CFG.model_name_bert,\n        fc_dim = CFG.fc_dim,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = CFG.use_fc,\n        use_arcface = CFG.use_arcface,\n        pretrained = True):\n        \n        super(CustomBERT, self).__init__()\n        print(f'Building Model Backbone for {model_name} model')\n        self.bert = transformers.AutoModel.from_pretrained(model_name)\n        in_features = self.bert.config.hidden_size\n        self.use_fc = use_fc\n        self.use_arcface = use_arcface\n        \n        if self.use_fc:\n            self.dropout = nn.Dropout(p=0.1)\n            self.classifier = nn.Linear(in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            in_features = fc_dim\n        \n        if self.use_arcface:\n            self.final = ArcMarginProduct(\n            in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n        else:\n            self.final = nn.Linear(in_features, n_classes)\n    \n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.constant_(self.classifier.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n    def forward(self, input_ids, attention_mask):\n        features = self.extract_features(input_ids, attention_mask)\n        return features\n        \n    def extract_features(self, input_ids, attention_mask):\n        x = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        features = x[0]\n        features = features[:, 0, :]\n        \n        if self.use_fc:\n            features = self.dropout(features)\n            features = self.classifier(features)\n            features = self.bn(features)\n        return features","metadata":{"papermill":{"duration":0.0436,"end_time":"2021-05-03T14:49:03.894332","exception":false,"start_time":"2021-05-03T14:49:03.850732","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## inference functions","metadata":{"papermill":{"duration":0.028602,"end_time":"2021-05-03T14:49:03.956231","exception":false,"start_time":"2021-05-03T14:49:03.927629","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_image_embeddings(folds, fold):\n    \n    model = CustomModel()\n    model.eval()\n    \n    #if CFG.model_name == 'eca_nfnet_l0':\n    #    model = replace_activations(model, torch.nn.SiLU, Mish())\n        \n    #model.load_state_dict(torch.load('../input/shopee-models/eca_nfnet_l0_exp017_fold0_epoch14.pth')['model'])\n    model = model.to(device)\n    \n    image_dataset = TestDataset(folds, transform=get_transforms(data='valid'))\n    image_loader = DataLoader(image_dataset,\n                              batch_size=CFG.batch_size,\n                              num_workers=CFG.num_workers,\n                              pin_memory=True,\n                              drop_last=False)\n    \n    \n    \n    embeds0 = []\n    embeds1 = []\n    embeds2 = []\n    embeds3 = []\n    embeds4 = []\n    with torch.no_grad():\n        pbar = tqdm(image_loader, total=len(image_loader))\n        for img, label in pbar:\n            img = img.to(device)\n            label = label.to(device)\n            f0,f1,f2,f3,f4 = model(img, label)\n            \n            i0,i1,i2,i3,i4 = f0.detach().cpu().numpy(),f1.detach().cpu().numpy(),f2.detach().cpu().numpy(),f3.detach().cpu().numpy(),f4.detach().cpu().numpy()\n            embeds0.append(i0)\n            embeds1.append(i1)\n            embeds2.append(i2)\n            embeds3.append(i3)\n            embeds4.append(i4)\n            \n    del model\n    image_embeddings0 = np.concatenate(embeds0)\n    image_embeddings1 = np.concatenate(embeds1)\n    image_embeddings2 = np.concatenate(embeds2)\n    image_embeddings3 = np.concatenate(embeds3)\n    image_embeddings4 = np.concatenate(embeds4)\n    #print(f'Our image embeddings shape is {image_embeddings.shape}')\n    del embeds0,embeds1,embeds2,embeds3, embeds4\n    gc.collect()\n    return [image_embeddings0,image_embeddings1,image_embeddings2,image_embeddings3,image_embeddings4]","metadata":{"papermill":{"duration":0.045227,"end_time":"2021-05-03T14:49:04.030174","exception":false,"start_time":"2021-05-03T14:49:03.984947","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_embeddings(folds, fold):\n    \n    model = CustomBERT(pretrained=False).to(device)\n    model_path = f'../input/shopee-bert/paraphrase-xlm-r-multilingual-v1_fold0_best.pth'\n    model.load_state_dict(torch.load(model_path)['model'])\n    model.eval()\n    \n    text_dataset = TestDataset_BERT(folds)\n    text_loader = DataLoader(text_dataset,\n                              batch_size=CFG.batch_size,\n                              num_workers=CFG.num_workers,\n                              pin_memory=True,\n                              drop_last=False)\n    embeds = []\n    with torch.no_grad():\n        pbar = tqdm(text_loader, total=len(text_loader))\n        for input_ids, attention_mask in pbar:\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            features = model(input_ids, attention_mask)\n            text_embeddings = features.detach().cpu().numpy()\n            embeds.append(text_embeddings)\n            \n    del model\n    text_embeddings = np.concatenate(embeds)\n    print(f'Our text embeddings shape is {text_embeddings.shape}')\n    del embeds\n    gc.collect()\n    return text_embeddings\n\n","metadata":{"papermill":{"duration":0.039736,"end_time":"2021-05-03T14:49:04.097872","exception":false,"start_time":"2021-05-03T14:49:04.058136","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_predictions(df, df_cu, max_features=25_000, thresh=0.75):\n    \n    model = TfidfVectorizer(stop_words='english',\n                            binary=True,\n                            max_features=max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    \n    print('Finding similar titles...')\n    CHUNK = 1024 * 4\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n        \n    preds = []\n    for j in range( CTS ):\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(df))\n        print('chunk', a, 'to', b)\n        \n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n        \n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>thresh)[0]  # 変える余地がありそう\n            if len(IDX) == 1:\n                #print('置き換える１')\n                IDX = cupy.where(cts[k,] > (thresh-0.04))[0]\n                if len(IDX) == 1:\n                    #print('置き換える２')\n                    IDX = cupy.where(cts[k,] > (thresh-0.08))[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n            \n    del model, text_embeddings\n    gc.collect()\n    return preds\n\n\n\ndef get_text_predictions_nostopwords(df, df_cu, max_features=25_000, thresh=0.75):\n    \n#     model = TfidfVectorizer(stop_words='english',\n#                             binary=True,\n#                             max_features=max_features)\n    model = TfidfVectorizer(stop_words=None,\n                            binary=True,\n                            max_features=max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    \n    \n    print('Finding similar titles...')\n    CHUNK = 1024 * 4\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n        \n    preds = []\n    for j in range( CTS ):\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(df))\n        print('chunk', a, 'to', b)\n        \n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n        \n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>thresh)[0]  # 変える余地がありそう\n            if len(IDX) == 1:\n                #print('置き換える１')\n                IDX = cupy.where(cts[k,] > (thresh-0.04))[0]\n                if len(IDX) == 1:\n                    #print('置き換える２')\n                    IDX = cupy.where(cts[k,] > (thresh-0.08))[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n            \n    del model, text_embeddings\n    gc.collect()\n    return preds\n\n\nfrom stop_words import get_stop_words\n\ndef get_text_predictions_stopid(df, df_cu, max_features=25_000, thresh=0.75):\n    \n#     model = TfidfVectorizer(stop_words='english',\n#                             binary=True,\n#                             max_features=max_features)\n    idstop_words = get_stop_words('indonesian')\n    model = TfidfVectorizer(stop_words=idstop_words,\n                            binary=True,\n                            max_features=max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    \n    \n    print('Finding similar titles...')\n    CHUNK = 1024 * 4\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n        \n    preds = []\n    for j in range( CTS ):\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(df))\n        print('chunk', a, 'to', b)\n        \n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n        \n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>thresh)[0]  # 変える余地がありそう\n            if len(IDX) == 1:\n                #print('置き換える１')\n                IDX = cupy.where(cts[k,] > (thresh-0.04))[0]\n                if len(IDX) == 1:\n                    #print('置き換える２')\n                    IDX = cupy.where(cts[k,] > (thresh-0.08))[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n            \n    del model, text_embeddings\n    gc.collect()\n    return preds\n\n# 数字\n# def get_text_predictions_stopnumber(df, df_cu, max_features=25_000, thresh=0.75):\n    \n#     model = TfidfVectorizer(stop_words='english',\n#                             binary=True,\n#                             max_features=max_features)\n#     _ = model.fit_transform(df_cu['title']).toarray()\n    \n#     vocabulary = model.vocabulary_.to_pandas()\n#     vocabulary = [s for s in vocabulary if not s.isdigit()]\n    \n#     model_ = TfidfVectorizer(vocabulary=vocabulary)\n#     text_embeddings = model_.fit_transform(df_cu['title']).toarray()\n    \n    \n#     print('Finding similar titles...')\n#     CHUNK = 1024 * 4\n#     CTS = len(df) // CHUNK\n#     if (len(df)%CHUNK) != 0:\n#         CTS += 1\n        \n#     preds = []\n#     for j in range( CTS ):\n#         a = j * CHUNK\n#         b = (j+1) * CHUNK\n#         b = min(b, len(df))\n#         print('chunk', a, 'to', b)\n        \n#         # COSINE SIMILARITY DISTANCE\n#         cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n        \n#         for k in range(b-a):\n#             IDX = cupy.where(cts[k,]>thresh)[0]  # 変える余地がありそう\n#             if len(IDX) == 1:\n#                 #print('置き換える１')\n#                 IDX = cupy.where(cts[k,] > (thresh-0.04))[0]\n#                 if len(IDX) == 1:\n#                     #print('置き換える２')\n#                     IDX = cupy.where(cts[k,] > (thresh-0.08))[0]\n#             o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n#             preds.append(o)\n            \n#     del model, text_embeddings\n#     gc.collect()\n#     return preds","metadata":{"papermill":{"duration":0.041289,"end_time":"2021-05-03T14:49:04.166285","exception":false,"start_time":"2021-05-03T14:49:04.124996","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 英語\ndef get_text_predictions_additional(df, df_cu, max_features=25_000, thresh=0.75):\n    \n    model = TfidfVectorizer(stop_words='english',\n                            binary=True,\n                            max_features=max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    \n    print('Finding similar titles...')\n    CHUNK = 1024 * 4\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n        \n    preds = []\n    for j in range( CTS ):\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(df))\n        print('chunk', a, 'to', b)\n        \n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n        \n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>thresh)[0]  # 変える余地がありそう\n            if len(IDX) == 1:\n                #print('置き換える１')\n                IDX = cupy.where(cts[k,] > (thresh-0.05))[0]\n                if len(IDX) == 1:\n                    #print('置き換える２')\n                    IDX = cupy.where(cts[k,] > (thresh-0.1))[0]\n                    if len(IDX) == 1:\n                        #print('置き換える3')\n                        IDX = cupy.where(cts[k,] > (thresh-0.15))[0]\n                        if len(IDX) == 1:\n                            #print('置き換える5')\n                            IDX = cupy.where(cts[k,] > (thresh-0.2))[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n            \n    del model, text_embeddings\n    gc.collect()\n    return preds\n\n# 追加アルゴリズム by beluga\n# インドネシア語\ndef get_text_predictions_additional_nomatch_id(df, df_cu, max_features=25_000, thresh=0.75):\n    \n    idstop_words = get_stop_words('indonesian')\n    model = TfidfVectorizer(stop_words=idstop_words,\n                            binary=True,\n                            max_features=max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    \n    print('Finding similar titles...')\n    CHUNK = 1024 * 4\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n        \n    preds = []\n    for j in range( CTS ):\n        a = j * CHUNK\n        b = (j+1) * CHUNK\n        b = min(b, len(df))\n        print('chunk', a, 'to', b)\n        \n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n        \n        for k in range(b-a):\n            IDX = cupy.where(cts[k,]>thresh)[0]  # 変える余地がありそう\n            if len(IDX) == 1:\n                #print('置き換える１')\n                IDX = cupy.where(cts[k,] > (thresh-0.05))[0]\n                if len(IDX) == 1:\n                    #print('置き換える２')\n                    IDX = cupy.where(cts[k,] > (thresh-0.1))[0]\n                    if len(IDX) == 1:\n                        #print('置き換える3')\n                        IDX = cupy.where(cts[k,] > (thresh-0.15))[0]\n                        if len(IDX) == 1:\n                            #print('置き換える5')\n                            IDX = cupy.where(cts[k,] > (thresh-0.2))[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n            \n    del model, text_embeddings\n    gc.collect()\n    return preds","metadata":{"papermill":{"duration":0.041289,"end_time":"2021-05-03T14:49:04.166285","exception":false,"start_time":"2021-05-03T14:49:04.124996","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors(df, embeddings, KNN = 100, image = True, thres = 0.28):\n    \n    #distances = np.zeros(shape=(len(df), KNN), dtype='float16')\n    distances_list = []\n    indices_list = []\n    for i in range(len(embeddings)):\n        model = NearestNeighbors(n_neighbors = KNN, metric='cosine')\n        model.fit(embeddings[i])\n        distances_tmp, indices_tmp = model.kneighbors(embeddings[i])\n        #distances += np.array(distances_tmp, dtype='float16')/len(embeddings)\n        #distances = distances.astype('float16')\n        distances_list.append(distances_tmp)\n        indices_list.append(indices_tmp)\n        del distances_tmp, indices_tmp\n    \n    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n    if CFG.GET_CV:\n        if image:\n            thresholds = list(np.arange(0.3, 0.6, 0.02))\n        else:\n            thresholds = list(np.arange(0.1, 1, 0.05))  # changed\n        scores = []\n        for threshold in thresholds:\n            predictions = []\n            for k in tqdm(range(embeddings[0].shape[0])):\n                # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n                distances = []\n                indices = []\n                for i in range(len(distances_list)):\n                    distances.append(distances_list[i][k])\n                    indices.append(indices_list[i][k])\n                #↓あとで書き直す\n                dfs = []\n                for i in range(len(distances_list)):\n                    dfs.append(pd.DataFrame({f'ind': indices[i], f'dis{i}': distances[i]}))\n                df_tmp = repeate_merge(dfs)\n                if image:\n                    df_tmp['dis'] = 0\n                    for i in range(len(distances_list)):\n                        df_tmp['dis'] += df_tmp[f'dis{i}'] / len(distances_list)\n                    #if k < 1:\n                    #    display(df_tmp)\n                    dis = df_tmp['dis'].values\n                    idx = np.where(dis < threshold)[0]\n                    idx = idx.astype(int)\n                else:\n                    idx = np.where(distances[k,] < 0.60)[0]\n                #ids = indices[k,idx]\n                #print(indices)\n                indices = df_tmp['ind'].values\n                ids = indices[idx]\n                \n                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n                predictions.append(posting_ids)\n            df['pred_matches'] = predictions\n            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n            score = df['f1'].mean()\n            print(f'Our f1 score for threshold {threshold} is {score}')\n            # for debug\n            #display(df)\n            scores.append(score)\n        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n        best_threshold  = max_score['thresholds'].values[0]\n        best_score = max_score['scores'].values[0]\n        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n        \n        # Use threshold\n        predictions = []\n        for k in range(embeddings[0].shape[0]):\n            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n            distances = []\n            indices = []\n            for i in range(len(distances_list)):\n                distances.append(distances_list[i][k])\n                indices.append(indices_list[i][k])\n            #↓あとで書き直す\n            dfs = []\n            for i in range(len(distances_list)):\n                dfs.append(pd.DataFrame({f'ind': indices[i], f'dis{i}': distances[i]}))\n            df_tmp = repeate_merge(dfs)\n            if image:\n                df_tmp['dis'] = 0\n                for i in range(len(distances_list)):\n                    df_tmp['dis'] += df_tmp[f'dis{i}'] / len(distances_list)\n                dis = df_tmp['dis'].values\n                idx = np.where(dis < thres)[0]\n                idx = idx.astype(int)\n                #if len(idx) == 1:\n                #    idx = np.where(dis < thres)[0]\n            else:\n                idx = np.where(distances[k,] < 0.60)[0]\n            #ids = indices[k,idx]\n            #print(indices)\n            indices = df_tmp['ind'].values\n            ids = indices[idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n            \n    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n    else:\n        predictions = []\n        for k in range(embeddings[0].shape[0]):\n            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n            distances = []\n            indices = []\n            for i in range(len(distances_list)):\n                distances.append(distances_list[i][k])\n                indices.append(indices_list[i][k])\n            #↓あとで書き直す\n            dfs = []\n            for i in range(len(distances_list)):\n                dfs.append(pd.DataFrame({f'ind': indices[i], f'dis{i}': distances[i]}))\n            df_tmp = repeate_merge(dfs)\n            if image:\n                df_tmp['dis'] = 0\n                for i in range(len(distances_list)):\n                    df_tmp['dis'] += df_tmp[f'dis{i}'] / len(distances_list)\n                dis = df_tmp['dis'].values\n                idx = np.where(dis < thres)[0]\n                if len(idx) == 1:\n                    #print('置き換える１')\n                    idx = np.where(dis < (thres+0.04))[0]\n                    if len(idx) == 1:\n                        #print('置き換える２')\n                        idx = np.where(dis < (thres+0.08))[0]\n                        if len(idx) == 1:\n                        #print('置き換える２')\n                            idx = np.where(dis < (thres+0.12))[0]\n                idx = idx.astype(int)\n            else:\n                idx = np.where(distances[k,] < 0.60)[0]\n            #ids = indices[k,idx]\n            #print(indices)\n            indices = df_tmp['ind'].values\n            if len(test) == 3:\n                display(df_tmp)\n            ids = indices[idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return df, predictions","metadata":{"papermill":{"duration":0.063575,"end_time":"2021-05-03T14:49:04.256441","exception":false,"start_time":"2021-05-03T14:49:04.192866","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors_for_txt(df, embeddings, KNN = 50, image = True):\n    \n    model = NearestNeighbors(n_neighbors = KNN, metric='cosine')\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n    if CFG.GET_CV:\n        if image:\n            thresholds = list(np.arange(0.4, 0.5, 0.1))\n        else:\n            thresholds = list(np.arange(0.4, 0.6, 0.1))  # changed\n        scores = []\n        for threshold in thresholds:\n            predictions = []\n            for k in range(embeddings.shape[0]):\n                idx = np.where(distances[k,] < threshold)[0]\n                ids = indices[k, idx]\n                # 追加アルゴ\n                if len(ids) == 1:\n                    ids = indices[k, [1,2]]\n                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n                predictions.append(posting_ids)\n            df['pred_matches'] = predictions\n            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n            score = df['f1'].mean()\n            print(f'Our f1 score for threshold {threshold} is {score}')\n            scores.append(score)\n        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n        best_threshold  = max_score['thresholds'].values[0]\n        best_score = max_score['scores'].values[0]\n        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n        \n        # Use threshold\n        predictions = []\n        for k in range(embeddings.shape[0]):\n            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n            if image:\n                idx = np.where(distances[k,] < 0.3)[0]\n            else:\n                idx = np.where(distances[k,] < 0.3)[0]\n            ids = indices[k, idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n            \n    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n    else:\n        predictions = []\n        for k in tqdm(range(embeddings.shape[0])):\n            if image:\n                idx = np.where(distances[k,] < 0.3)[0]\n            else:\n                idx = np.where(distances[k,] < 0.3)[0]\n            ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return df, predictions","metadata":{"papermill":{"duration":0.051676,"end_time":"2021-05-03T14:49:04.335634","exception":false,"start_time":"2021-05-03T14:49:04.283958","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculating Predictions","metadata":{"papermill":{"duration":0.027705,"end_time":"2021-05-03T14:49:04.391017","exception":false,"start_time":"2021-05-03T14:49:04.363312","status":"completed"},"tags":[]}},{"cell_type":"code","source":"folds, folds_cu = read_dataset()\nfolds.head()","metadata":{"papermill":{"duration":8.352544,"end_time":"2021-05-03T14:49:12.770972","exception":false,"start_time":"2021-05-03T14:49:04.418428","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def repeate_merge(dfs):\n    df = pd.merge(dfs[0],dfs[1], on='ind')\n    for _ in range(len(dfs)-2):\n        df = pd.merge(df, dfs[_+2], on='ind')\n    return df","metadata":{"papermill":{"duration":0.036789,"end_time":"2021-05-03T14:49:12.837348","exception":false,"start_time":"2021-05-03T14:49:12.800559","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def match_algo_interpolation_train(submit_df):\n    match_dic = {}\n    \n    def count_match(row):\n        return len(row[\"pred_matches\"].split())-1\n    \n    def match_diff(row):\n        posting_id = np.array(row[\"posting_id\"])\n        pred_matches = np.array(row[\"pred_matches\"].split())\n        pred_match = np.array(np.setdiff1d(pred_matches, posting_id)).tolist()\n        if row[\"match_num\"] > 0:\n            return \" \".join(pred_match)\n        else:\n            return\n\n    def get_match_dic(row):\n        if row[\"match_num\"] > 0:\n            if not match_dic.get(row[\"pred_match\"]):\n                match_dic[row[\"pred_match\"]] = [row[\"posting_id\"]]\n            else:\n                match_dic[row[\"pred_match\"]].append(row[\"posting_id\"])\n\n    def join_list():\n        for k, v in match_dic.items():\n            match_dic[k] = \" \".join(v)\n\n    def column_merge(row):\n        if row[\"match_num\"] > 0:\n            x = row['pred_matches'] + \" \" + row['posting_id_2']\n            x = np.array(x.split())\n            return ' '.join( np.unique(x) )\n        else:\n            return row['pred_matches']\n        \n    submit_df['match_num'] = submit_df.apply(count_match, axis=1)\n    submit_df['pred_match'] = submit_df.apply(match_diff, axis=1)\n    submit_df.apply(get_match_dic, axis=1)\n    \n    join_list()\n    match_df = pd.DataFrame.from_dict(match_dic, orient='index')\n    match_df = match_df.reset_index()\n    match_df = match_df.rename(columns = {'index': 'pred_match', 0: 'posting_id_2'}, inplace = False)\n    \n    submit_df = pd.merge(submit_df, match_df, on='pred_match', how='left')\n    submit_df[\"pred_matches_2\"] = submit_df.apply(column_merge, axis=1)\n    \n    submit_df['f1_1'] = f1_score(submit_df['matches'], submit_df['pred_matches'])\n    submit_df['f1_2'] = f1_score(submit_df['matches'], submit_df['pred_matches_2'])\n\n    score_1 = submit_df['f1_1'].mean()\n    score_2 = submit_df['f1_2'].mean()\n\n    print(f'Our final f1 origin cv score is {score_1}')\n    print(f'Our final f1 match algo cv score is {score_2}')\n    \n    submit_df_2 = pd.DataFrame()\n    submit_df_2[['posting_id', 'pred_matches']] = submit_df[['posting_id', 'pred_matches_2']]\n    return submit_df_2\n\ndef match_algo_interpolation_inference(submit_df):\n    match_dic = {}\n    \n    def count_match(row):\n        return len(row[\"matches\"].split())-1\n    \n    def match_diff(row):\n        posting_id = np.array(row[\"posting_id\"])\n        pred_matches = np.array(row[\"matches\"].split())\n        pred_match = np.array(np.setdiff1d(pred_matches, posting_id)).tolist()\n        if row[\"match_num\"] > 0:\n            return \" \".join(pred_match)\n        else:\n            return row[\"matches\"]\n\n    def get_match_dic(row):\n        if row[\"match_num\"] > 0:\n            if not match_dic.get(row[\"matches\"]):\n                match_dic[row[\"matches\"]] = [row[\"posting_id\"]]\n            else:\n                match_dic[row[\"matches\"]].append(row[\"posting_id\"])\n\n    def join_list():\n        for k, v in match_dic.items():\n            match_dic[k] = \" \".join(v)\n\n    def column_merge(row):\n        if row[\"match_num\"] > 0:\n            x = row['matches'] + \" \" + row['posting_id_2']\n            x = np.array(x.split())\n            return ' '.join( np.unique(x) )\n        else:\n            return row['matches']\n        \n    submit_df['match_num'] = submit_df.apply(count_match, axis=1)\n    submit_df['matches'] = submit_df.apply(match_diff, axis=1)\n    submit_df.apply(get_match_dic, axis=1)\n    \n    join_list()\n    match_df = pd.DataFrame.from_dict(match_dic, orient='index')\n    match_df = match_df.reset_index()\n    match_df = match_df.rename(columns = {'index': 'matches', 0: 'posting_id_2'}, inplace = False)\n    \n    submit_df = pd.merge(submit_df, match_df, on='matches', how='left')\n    submit_df[\"pred_matches_2\"] = submit_df.apply(column_merge, axis=1)\n    \n    submit_df_2 = pd.DataFrame()\n    submit_df_2[['posting_id', 'matches']] = submit_df[['posting_id', 'pred_matches_2']]\n    return submit_df_2","metadata":{"papermill":{"duration":0.056552,"end_time":"2021-05-03T14:49:12.922218","exception":false,"start_time":"2021-05-03T14:49:12.865666","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get neighbors for image_embeddings\nif CFG.GET_CV:\n    oof_df = pd.DataFrame()\n    for fold in CFG.trn_fold:\n        folds_ = folds[folds['fold'] == fold].reset_index(drop=True)\n        folds_cu_ = folds_cu[folds['fold'] == fold].reset_index(drop=True)\n        image_embeddings = get_image_embeddings(folds_, fold)\n        text_embeddings = get_text_embeddings(folds_, fold)\n        text_predictions_tfidf = get_text_predictions(folds_, folds_cu_, max_features=25_000, thresh=0.75)\n        oof_df_, image_predictions = get_neighbors(folds_, image_embeddings, KNN=50 if len(folds)>3 else 3, image=True)\n        oof_df_, text_predictions_bert = get_neighbors(folds_, text_embeddings, KNN=50 if len(folds) > 3 else 3, image=False)\n        oof_df_['image_predictions'] = image_predictions\n        oof_df_['text_predictions'] = text_predictions_tfidf\n        oof_df_['text_predictions_bert'] = text_predictions_bert\n        oof_df_['text_predictions_bert_len'] = oof_df_['text_predictions_bert'].apply(lambda x: len(x))\n        oof_df_['text_predictions'].mask(oof_df_['text_predictions_bert_len'] == 2, oof_df_['text_predictions_bert'], inplace=True)\n        oof_df_['pred_matches'] = oof_df_.apply(combine_predictions, axis = 1)\n        # oofだけを切り出す\n#         oof_df_ = oof_df_[folds['fold'] == fold]\n        oof_df = pd.concat([oof_df, oof_df_])\n    display(oof_df.head())\nelse:\n    image_embeddings = get_image_embeddings(folds, fold=0)  # 後で調整する\n    text_embeddings = get_text_embeddings(folds, fold=0)\n    \n    # 追加アルゴリズム by beluga\n#     text_predictions_tfidf = get_text_predictions(folds, folds_cu, max_features=25_000, thresh=0.75)\n#     text_predictions_tfidf_nostopwords = get_text_predictions_nostopwords(folds, folds_cu, max_features=25_000, thresh=0.75)\n    text_predictions_tfidf_stopwordsid = get_text_predictions_stopid(folds, folds_cu, max_features=25_000, thresh=0.75)\n#     text_predictions_tfidf_stopwordsnumber = get_text_predictions_stopnumber(folds, folds_cu, max_features=25_000, thresh=0.75)\n    \n    df, text_predictions_bert = get_neighbors_for_txt(folds, text_embeddings, KNN=50 if len(folds) > 3 else 3, image=False)\n    df, image_predictions = get_neighbors(folds, image_embeddings, KNN=100 if len(folds)>3 else 3, image=True)\n    \n    df.head()","metadata":{"papermill":{"duration":64.398319,"end_time":"2021-05-03T14:50:17.34873","exception":false,"start_time":"2021-05-03T14:49:12.950411","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 追加アルゴリズム by beluga\n# def combine_predictions_notmatch3(row):\n# #     x = np.concatenate([row['text_predictions_en'], row['text_predictions_no'], row['text_predictions_id'], row['text_predictions_num']])\n#     x = np.concatenate([row['text_predictions_id'], row['text_predictions_num']])\n# #     return ' '.join(np.unique(x))\n#     return np.unique(x)\n\n\nif CFG.GET_CV:\n#     oof_df['image_predictions'] = image_predictions\n#     oof_df['text_predictions'] = text_predictions\n#     oof_df['pred_matches'] = oof_df.apply(combine_predictions, axis = 1)\n    oof_df = match_algo_interpolation_train(oof_df) # マッチ補間関数\n    oof_df['f1'] = f1_score(oof_df['matches'], oof_df['pred_matches'])\n    display(oof_df)\n    score = oof_df['f1'].mean()\n    print(f'Our final f1 cv score is {score}')\n    oof_df[['posting_id', 'pred_matches']].to_csv('submission.csv', index = False)\nelse:\n    df['image_predictions'] = image_predictions\n    \n    # 追加アルゴリズム by beluga\n#     df['text_predictions'] = text_predictions_tfidf\n#     df['text_predictions_en'] = text_predictions_tfidf\n#     df['text_predictions_no'] = text_predictions_tfidf_nostopwords\n#     df['text_predictions_id'] = text_predictions_tfidf_stopwordsid\n#     df['text_predictions_num'] = text_predictions_tfidf_stopwordsnumber\n#     df['text_predictions'] = df.apply(combine_predictions_notmatch3, axis=1)\n    \n#     df['text_predictions'] = text_predictions_tfidf_stopwordsnumber\n    df['text_predictions'] = text_predictions_tfidf_stopwordsid\n\n    df['text_predictions_bert'] = text_predictions_bert\n    df['text_predictions_bert_len'] = df['text_predictions_bert'].apply(lambda x: len(x))\n    df['text_predictions'].mask(df['text_predictions_bert_len'] == 2, df['text_predictions_bert'], inplace=True)\n    df['matches'] = df.apply(combine_predictions, axis = 1)\n    # =================================================================\n    # additional prediction\n    # =================================================================\n    df['matches_len'] = df['matches'].apply(lambda x: len(x.split()))\n    df_notmatch = df[df['matches_len']==1]\n    df_notmatch_cu = cudf.DataFrame(df_notmatch)\n#     additional_predictions = get_text_predictions_additional(df_notmatch, df_notmatch_cu, max_features=25000, thresh=0.6)\n    additional_predictions = get_text_predictions_additional_nomatch_id(df_notmatch, df_notmatch_cu, max_features=25000, thresh=0.6)# 追加アルゴリズム by beluga\n    \n    df_notmatch['matches'] = additional_predictions\n    df_notmatch['matches_len'] = df_notmatch['matches'].apply(lambda x: len(x))\n    df_notmatch_ = df_notmatch[df_notmatch['matches_len']>1]\n    df_notmatch_['matches'] = df_notmatch_['matches'].apply(lambda x: ' '.join(x))\n    index_notmatch = df_notmatch_.index\n    df.loc[index_notmatch, 'matches'] = df_notmatch_['matches']\n    \n    df_notmatch2 = df_notmatch[df_notmatch['matches_len']==1]\n    df_notmatch_cu2 = cudf.DataFrame(df_notmatch2)\n#     additional_predictions2 = get_text_predictions_additional(df_notmatch2, df_notmatch_cu2, max_features=25000, thresh=0.6)\n    additional_predictions2 = get_text_predictions_additional_nomatch_id(df_notmatch2, df_notmatch_cu2, max_features=25000, thresh=0.6)# 追加アルゴリズム by beluga\n    df_notmatch2['matches'] = additional_predictions2\n    df_notmatch2['matches_len'] = df_notmatch2['matches'].apply(lambda x: len(x))\n    df_notmatch2_ = df_notmatch2[df_notmatch2['matches_len']>1]\n    df_notmatch2_['matches'] = df_notmatch2_['matches'].apply(lambda x: ' '.join(x))\n    index_notmatch2 = df_notmatch2_.index\n    df.loc[index_notmatch2, 'matches'] = df_notmatch2_['matches']\n    \n    df_afteralgo = match_algo_interpolation_inference(df) # マッチ補間関数\n    df['matches'] = df_afteralgo['matches']\n    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"papermill":{"duration":0.242615,"end_time":"2021-05-03T14:50:17.627273","exception":false,"start_time":"2021-05-03T14:50:17.384658","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv').head()","metadata":{"papermill":{"duration":0.054495,"end_time":"2021-05-03T14:50:17.717163","exception":false,"start_time":"2021-05-03T14:50:17.662668","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.036611,"end_time":"2021-05-03T14:50:17.790482","exception":false,"start_time":"2021-05-03T14:50:17.753871","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.036176,"end_time":"2021-05-03T14:50:17.863209","exception":false,"start_time":"2021-05-03T14:50:17.827033","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}