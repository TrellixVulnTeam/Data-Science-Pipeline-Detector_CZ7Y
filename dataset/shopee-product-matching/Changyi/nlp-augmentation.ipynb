{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is a demo of [nlpaug](https://github.com/makcedward/nlpaug) package, which contains a variety of augmentations to supplement text data and introduce noise that may help your model generalize."},{"metadata":{},"cell_type":"markdown","source":"### Installation"},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install nlpaug fairseq >> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\n\ntest_sentence = \"B33F My Food Shop Shopping Trolley - ST. 003 troli mainan edukasi anak keranjang belanja\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Character Augmenter"},{"metadata":{},"cell_type":"markdown","source":"1. keyboard : Augmenter that apply typo error simulation to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = nac.KeyboardAug(name='Keyboard_Aug', aug_char_min=1, aug_char_max=10, aug_char_p=0.3, aug_word_p=0.3, \n                      aug_word_min=1, aug_word_max=10, stopwords=None, tokenizer=None, reverse_tokenizer=None, \n                      include_special_char=True, include_numeric=True, include_upper_case=True, lang='en', verbose=0, \n                      stopwords_regex=None, model_path=None, min_char=4)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. ocr : Augmenter that apply ocr error simulation to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = nac.OcrAug(name='OCR_Aug', aug_char_min=1, aug_char_max=10, aug_char_p=0.3, aug_word_p=0.3, aug_word_min=1, \n                 aug_word_max=10, stopwords=None, tokenizer=None, reverse_tokenizer=None, verbose=0, stopwords_regex=None, \n                 min_char=1)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. random : Augmenter that apply random character error to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = nac.RandomCharAug(action='substitute', name='RandomChar_Aug', aug_char_min=1, aug_char_max=10, aug_char_p=0.3, \n                        aug_word_p=0.3, aug_word_min=1, aug_word_max=10, include_upper_case=True, include_lower_case=True, \n                        include_numeric=True, min_char=4, swap_mode='adjacent', spec_char='!@#$%^&*()_+', stopwords=None, \n                        tokenizer=None, reverse_tokenizer=None, verbose=0, stopwords_regex=None, candidiates=None)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Word Augmenter"},{"metadata":{},"cell_type":"markdown","source":"1. antonym : Augmenter that apply semantic meaning based to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.AntonymAug(name='Antonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', stopwords=None, tokenizer=None, \n                     reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n\ntest_sentence_aug = aug.augment(\"very interesting\")\nprint(\"very interesting\")\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. back_translation : Augmenter that apply operation (word level) to textual input based on back translation.\n\n**Need about 15mn for models downloading**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# aug = naw.BackTranslationAug(from_model_name='transformer.wmt19.en-de', to_model_name='transformer.wmt19.de-en', \n#                              from_model_checkpt='model1.pt', to_model_checkpt='model1.pt', tokenizer='moses', \n#                              bpe='fastbpe', is_load_from_github=True, name='BackTranslationAug', device='cpu', \n#                              force_reload=False, verbose=0)\n\n# test_sentence_aug = aug.augment(test_sentence)\n# print(test_sentence)\n# print(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. context_word_embedding : Augmenter that apply operation (word level) to textual input based on contextual word embeddings."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', model_type='', action='substitute', temperature=1.0, \n                                top_k=100, top_p=None, name='ContextualWordEmbs_Aug', aug_min=1, aug_max=10, aug_p=0.3, \n                                stopwords=None, device='cpu', force_reload=False, optimize=None, stopwords_regex=None, \n                                verbose=0, silence=True)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. random : Augmenter that apply random word operation to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.RandomWordAug(action='delete', name='RandomWord_Aug', aug_min=1, aug_max=10, aug_p=0.3, stopwords=None, \n                        target_words=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. spelling : Augmenter that apply spelling error simulation to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.SpellingAug(dict_path=None, name='Spelling_Aug', aug_min=1, aug_max=10, aug_p=0.3, stopwords=None, \n                      tokenizer=None, reverse_tokenizer=None, include_reverse=True, stopwords_regex=None, verbose=0)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. split : Augmenter that apply word splitting operation to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.SplitAug(name='Split_Aug', aug_min=1, aug_max=10, aug_p=0.3, min_char=4, stopwords=None, tokenizer=None, \n                   reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7. synonym : Augmenter that apply semantic meaning based to textual input."},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = naw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', \n                     stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, force_reload=False, \n                     verbose=0)\n\ntest_sentence_aug = aug.augment(test_sentence)\nprint(test_sentence)\nprint(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. tfidf : Augmenter that apply TF-IDF based to textual input.\n\n**TfIdfAug have to been trained based on your data. You can refer to this notebook for step of training.** see : https://github.com/makcedward/nlpaug/blob/master/example/tfidf-train_model.ipynb"},{"metadata":{"trusted":true},"cell_type":"code","source":"# aug = naw.TfIdfAug(model_path='.', action='substitute', name='TfIdf_Aug', aug_min=1, aug_max=10, aug_p=0.3, top_k=5, \n#                    stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n# \n# test_sentence_aug = aug.augment(test_sentence)\n# print(test_sentence)\n# print(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"9. word_embs : Augmenter that apply operation to textual input based on word embeddings."},{"metadata":{"trusted":true},"cell_type":"code","source":"# aug = naw.WordEmbsAug(model_type='word2vec', model_path='.', model=None, action='substitute', name='WordEmbs_Aug', \n#                       aug_min=1, aug_max=10, aug_p=0.3, top_k=100, n_gram_separator='_', stopwords=None, tokenizer=None, \n#                       reverse_tokenizer=None, force_reload=False, stopwords_regex=None, verbose=0)\n\n# test_sentence_aug = aug.augment(test_sentence)\n# print(test_sentence)\n# print(test_sentence_aug)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# References :\n* [GitHub](https://github.com/makcedward/nlpaug)\n* [Augmenting the Data](https://www.kaggle.com/jpmiller/augmenting-the-data)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}