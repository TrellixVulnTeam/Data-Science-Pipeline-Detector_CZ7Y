{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi!\n<br>It's not a secret that using of tfrecords provide better efficienty with tf.data.* API\n<br>I've made an attempt to write as compact code as possible for Shopee matching competition tfrecords generation \n<br>Sure, datast splitting is not mandatory\n<br>You could find resulting dataset here: https://www.kaggle.com/alturutin/shopee-product-match-tfrecords\n<br>Hope it will help someone","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make tfrecords\n\ndef image_feature(value):\n    \"\"\"Returns a bytes_list from a jpeg\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n\n\ndef bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n\n\ndef float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef float_feature_list(value):\n    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef preprocess_img(file_path, img_size=512):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_image(image, channels = 3)\n    image = tf.image.resize(image, [img_size, img_size])\n    image = tf.cast(image, tf.uint8)\n    return image\n\ndef create_example(image, label, label_name):\n    feature = {\n        \"image\": image_feature(image),\n        \"label\": int64_feature(label),\n        \"label_name\": int64_feature(label_name)\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\ndef parse_tfrecord_fn(example):\n    feature_description = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label_name\": tf.io.FixedLenFeature([], tf.int64),\n        \"label\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n    return example\n\n\ndef validation_split(df):\n    x_train, x_val, y_train, y_val = train_test_split(df[['image']], df['label_group'], shuffle = True, random_state = 2021, test_size = 0.5)\n    return (\n        x_train.squeeze().values, \n        x_val.squeeze().values, \n        y_train.values, \n        y_val.values\n    )\n\ndef preprocess_train(df):\n    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n    df['matches'] = df['label_group'].map(tmp)\n    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n    encoder = LabelEncoder()\n    df['label_group'] = encoder.fit_transform(df['label_group'])\n    return df[['posting_id', 'image', 'label_group']], encoder\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\ntrain, label_encoder = preprocess_train(train)\nx_train, x_val, y_train, y_val = validation_split(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir tfrec_512x512\n!mkdir tfrec_512x512/train\n!mkdir tfrec_512x512/valid\n\n!mkdir tfrec_300x300\n!mkdir tfrec_300x300/train\n!mkdir tfrec_300x300/valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_tfrecords(x, y, label_encoder, sample_size, path, img_size):\n    n_shardes = int(np.ceil(len(x_train) / sample_size))\n    for i in tqdm(range(n_shardes)):\n        images = x[i*sample_size:(i+1)*sample_size]\n        labels = y[i*sample_size:(i+1)*sample_size]\n        source_labels = label_encoder.inverse_transform(labels)\n        with tf.io.TFRecordWriter(f\"{path}/{i}.tfrec\") as writer:\n            for im, lb, sl in zip(images, labels, source_labels):\n                image_path = f\"../input/shopee-product-matching/train_images/{im}\"\n                image = preprocess_img(image_path, img_size)\n                example = create_example(image, lb, sl)\n                writer.write(example.SerializeToString())\n                \nwrite_tfrecords(x_train, y_train, label_encoder, 1024, \"tfrec_300x300/train\", 300)\nwrite_tfrecords(x_val, y_val, label_encoder, 1024, \"tfrec_300x300/valid\", 300)\n\nwrite_tfrecords(x_train, y_train, label_encoder, 1024, \"tfrec_512x512/train\", 512)\nwrite_tfrecords(x_val, y_val, label_encoder, 1024, \"tfrec_512x512/valid\", 512)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l --block-size=MB tfrec_300x300/train/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l --block-size=MB tfrec_300x300/valid/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l --block-size=MB tfrec_512x512/train/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l --block-size=MB tfrec_512x512/valid/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read tfrecords example \n\n# import matplotlib.pyplot as plt\n\n# dataset = tf.data.TFRecordDataset(sorted(tf.io.gfile.glob('tfrec/train/*.tfrec')))\n# dataset = dataset.map(parse_tfrecord_fn)\n\n# for features in dataset.take(1):\n#     for key in features.keys():\n#         if key != \"image\":\n#             print(f\"{key}: {features[key]}\")\n#     print(f\"Image shape: {features['image'].shape}\")\n#     plt.figure(figsize=(7, 7))\n#     plt.imshow(features[\"image\"].numpy())\n#     plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}