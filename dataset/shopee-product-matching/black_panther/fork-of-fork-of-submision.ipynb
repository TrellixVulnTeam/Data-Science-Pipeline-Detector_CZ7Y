{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings as w\nfrom scipy import spatial\nfrom tqdm.notebook import tqdm\nimport random, math, cv2, os, string, re, gc\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers as L\nimport tensorflow.keras as K\nfrom sklearn.model_selection import train_test_split\nimport cudf, cuml, cupy\nfrom cuml.neighbors import NearestNeighbors\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n\nw.filterwarnings('ignore')\n\nTRAIN_BASE = '../input/shopee-product-matching/train_images/'\nTEST_BASE = '../input/shopee-product-matching/test_images/'\nSEED = 101\nIMG_SIZE = 250\nEPOCHS = 10\n\nsample_sub = pd.read_csv(\"../input/shopee-product-matching/sample_submission.csv\")\ntest = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\ntrain = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n\n# test = pd.concat([test, test, test[:2000]], axis = 0)\n# test.reset_index(drop = True, inplace = True)\n# print(\"shape: \", test.shape)\n# test.drop('label_group', axis = 1, inplace = True)\ntest.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CAP = 2.0\nIS_GPU_AVAIL = tf.config.experimental.list_physical_devices('GPU')\nif IS_GPU_AVAIL:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(IS_GPU_AVAIL[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*CAP)])\n        lgpu = tf.config.experimental.list_logical_devices('GPU')\n        \n    except RuntimeError as ex:\n        print(ex)\n        \nprint(f'Tensorflow GPU space {CAP}GB GPU RAM')\nprint(f'RAPIDS GPU space {16 - CAP}GB GPU RAM')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_predictions(df, embeddings,threshold = 3.4):\n    \n    if len(df) > 3:\n        KNN = 50\n    else : \n        KNN = 3\n    \n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    predictions = []\n    for k in tqdm(range(embeddings.shape[0])):\n        idx = np.where(distances[k,] < threshold)[0]\n        ids = indices[k,idx]\n        posting_ids = df['posting_id'].iloc[ids].values\n        predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return predictions\n\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \ndef process_data(df):\n    label_to_encoded = {idx:item for idx,item in enumerate(df.label_group.unique())}\n    encoded_to_label = {item:idx for idx,item in enumerate(df.label_group.unique())}\n    classes = df.label_group.nunique()\n    return label_to_encoded, encoded_to_label, classes\n\nseed_everything(SEED)\nlabel_to_encoded, encoded_to_label, NUM_CLASSES = process_data(train)\n\nfor col in train.columns:\n    print(f\"Number of unique {col} entries : \", train[col].nunique(), \" against the dataset of size \", train.shape)\n    \nclass DataGeneratorForTest(K.utils.Sequence):\n    def __init__(self, df, batchSize, filepath = TEST_BASE, \n                 img_size = IMG_SIZE):\n        self.df = df\n        self.indexes = np.arange(len(df))\n        self.path = filepath\n        self.batch = batchSize \n        self.img_size = IMG_SIZE\n        \n    def __len__(self):\n        '''Total number of steps in a epoch'''\n        return int(np.floor(self.df.shape[0]/self.batch))\n    \n    def __getitem__(self, index):\n        '''Generate One batch of files'''\n        indexes = self.indexes[index*self.batch:(index+1)*self.batch]\n        temp_df = self.df.iloc[indexes]\n        X = np.zeros(((len(indexes), self.img_size, self.img_size, 3)))\n        for idx,(index, row) in enumerate(temp_df.iterrows()):\n            img = cv2.imread(self.path + row.image)\n            X[idx,] = cv2.resize(img, (self.img_size, self.img_size)) / 255\n        return X\n\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\ndef clean(text):\n    text = ''.join([k for k in text if k not in string.punctuation])\n    text = str(text).lower()\n    text = re.sub('[^a-zA-Z]', ' ', text)\n    text = re.sub(' +', ' ', text)\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  \n                               u\"\\U0001F300-\\U0001F5FF\"  \n                               u\"\\U0001F680-\\U0001F6FF\"  \n                               u\"\\U0001F1E0-\\U0001F1FF\"  \n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    return text\n\n\ndef train_test_split_data(df, features, label, test_size = 0.33):\n    train_x, val_x, train_y, val_y = train_test_split(df[features], df[label], test_size = test_size,\n                                                      random_state = SEED, shuffle = True)\n    return train_x, val_x, train_y, val_y\n\ndef learning_rate_scheduler():\n    starting_pt_lr   = 0.0001\n    exp_decay = 0.1\n    def lrfn(epoch):\n        if epoch < 5:\n            return starting_pt_lr\n        else:\n            return starting_pt_lr * math.exp(-exp_decay * epoch)\n    lr = K.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr\n\ntqdm.pandas()\n# if predict_test:\ntest['title'] = test['title'].progress_apply(clean)\n# else:\n#     train['title'] = train['title'].progress_apply(clean)\n\n# complete_generator = None\n# if predict_test:\nparams = {'batchSize': 3,\n          'filepath': TEST_BASE,         \n          'img_size' : IMG_SIZE}\ncomplete_generator = DataGeneratorForTest(test[['image']], **params)\n# else:\n#     params = {'batchSize': 5,\n#           'code_to_labels': encoded_to_label,\n#           'filepath': TRAIN_BASE,\n#           'shuffle': False,\n#           'img_size' : IMG_SIZE,\n#           'classes' : NUM_CLASSES}\n#     complete_generator = DataGenerator(train[['image', 'label_group']], **params)\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_model(pretrained_layer = K.applications.EfficientNetB0(\n#         include_top=False, weights='../input/notop-weights/efficientnetb0_notop.h5', input_shape=(IMG_SIZE, IMG_SIZE, 3)), \n#               classes = NUM_CLASSES):\n    \n#     inp = L.Input(shape = (IMG_SIZE, IMG_SIZE, 3))\n    \n#     x = pretrained_layer(inp)\n#     x = L.GlobalAveragePooling2D()(x)\n#     x = L.BatchNormalization()(x)\n#     image_ = K.models.Model(inputs = inp, \n#                            outputs = x)\n#     return image_\n\n# pretrained_layer2 = K.applications.InceptionV3(include_top=False, \n#                                                weights='../input/notop-weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', \n#                                                input_shape=(IMG_SIZE, IMG_SIZE, 3))\n# image_embeddings = get_model(pretrained_layer = pretrained_layer2)\n# image_embeddings.summary()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings = K.applications.EfficientNetB0(\n        include_top=False, weights='../input/notop-weights/efficientnetb0_notop.h5', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling = 'avg')\n# image_embeddings = K.applications.InceptionV3(include_top=False, \n#                                                weights='../input/notop-weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', \n#                                                input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling = 'avg')\nimage_embeddings = image_embeddings.predict(complete_generator,\n                                verbose = 1)\n\"Image embedding shape is :- \", image_embeddings.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def combine_preds(x):\n#     all_combined = x['image_preds']+\" \"+ x['text_preds']\n#     return ' '.join( set(all_combined.split(\" \")) )\n\n# def get_nearest_neighors(df, embeds, n = 50, image = True, predict_score = PREDICT_SCORE):\n#     model = NearestNeighbors(n_neighbors = n)\n#     model.fit(embeds)\n#     dist_arr, idx_arr = model.kneighbors(embeds)\n#     if predict_score:\n#         scores = []\n#         if image:\n#             print(\"Predicting for image\")\n#             scores = np.arange(1.0,6.0,0.2)\n#         else:\n#             print(\"Predicting for text\")\n#             scores = np.arange(20,35,0.5)\n            \n#         allscores = []\n#         for th in scores:\n#             preds = []\n#             for idx in range(embeds.shape[0]):\n#                 index_clear_of_th = np.where(dist_arr[idx,] < th)[0]\n#                 preds.append(' '.join(df.posting_id.iloc[idx_arr[idx,index_clear_of_th]].values))\n            \n#             df[\"pred_values\"] = preds\n#             df[\"f1_score\"] = f1_score(df['matches'], df['pred_values'])\n#             print(f\"f1 Score for the threshold {th} is {df['f1_score'].mean()}\")\n#             allscores.append(df['f1_score'].mean())\n        \n#         score_df = pd.DataFrame({\"All_Scores\" : allscores, \"Thresholds\" : scores})\n#         best_record = score_df[score_df.All_Scores == score_df.All_Scores.max()]\n#         print(f\"Best iteration is with score {best_record.All_Scores.values} and threshold {best_record.Thresholds.values}\")\n        \n#         preds = []\n#         th = best_record.Thresholds.values[0]\n            \n#         for idx in range(embeds.shape[0]):\n#             index_clear_of_th = np.where(dist_arr[idx,] < th)[0]\n#             preds.append(\" \".join(df.posting_id.iloc[idx_arr[idx,index_clear_of_th]].values))\n            \n#     else:\n#         preds = []\n#         th = 0\n#         if image:\n#             print(\"Predicting for image\")\n#             th = 2.4\n#         else:\n#             print(\"Predicting for text\")\n#             th = 24.0\n            \n#         for idx in range(embeds.shape[0]):\n#             index_clear_of_th = np.where(dist_arr[idx,] < th)[0]\n#             preds.append(\" \".join(df.posting_id.iloc[idx_arr[idx,index_clear_of_th]].values))\n            \n#     return df, preds\n\n# if PREDICT_SCORE:\n#     tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n#     train['matches'] = train['label_group'].map(tmp)\n#     train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n    \n#     train, image_preds = get_nearest_neighors(train, image_embeddings, n = 50, image = True)\n\n#     train['image_preds'] = image_preds\n#     train['matches'] = image_preds\n#     train[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n#     print(train.head())\n# else:\n#     test, image_preds = get_nearest_neighors(test, image_embeddings, n = 50, image = True)\n    \n#     test['image_preds'] = image_preds\n#     test['matches'] = image_preds\n#     test[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n#     print(test.head())","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_predictions = get_image_predictions(test, image_embeddings, threshold = 2.75)\ntest['image_predictions'] = image_predictions\n# test['text_predictions'] = text_predictions\n# test['matches'] = test.apply(combine_predictions, axis = 1)\ntest['matches'] = test.apply(lambda x: \" \".join(np.unique(x['image_predictions'])), axis = 1)#\" \".join(set(list(test['image_predictions'])))\ntest[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}