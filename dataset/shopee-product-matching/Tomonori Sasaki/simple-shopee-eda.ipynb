{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><img src = \"https://klgadgetguy.com/wp-content/uploads/2018/10/6ce1f4f6d79353c5f24ee047a5132d77.jpg\" width = \"750\" height = \"500\"/></center>  ","metadata":{}},{"cell_type":"markdown","source":"# The Goal of this Competition\nFinding near-duplicates in large datasets is an important problem for many online businesses. Our task is to identify which products have been posted repeatedly. ","metadata":{"papermill":{"duration":0.022084,"end_time":"2021-03-12T22:16:08.91533","exception":false,"start_time":"2021-03-12T22:16:08.893246","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Evaluation Criteria\nSubmissions will be evaluated based on their mean F1 score. The mean is calculated in a sample-wise fashion, meaning that an [F1 score](https://deepai.org/machine-learning-glossary-and-terms/f-score) is calculated for every predicted row, then averaged.","metadata":{}},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Overview</center></h2>","metadata":{"papermill":{"duration":0.019858,"end_time":"2021-03-12T22:16:08.955568","exception":false,"start_time":"2021-03-12T22:16:08.93571","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"What is Shopee ?\n[Wikipedia page](https://en.wikipedia.org/wiki/Shopee) says that Shopee Pte Ltd (/ʃɒpiː/ SHO-pee) is a Singaporean multinational technology company which focuses mainly on e-commerce. Headquartered under Sea Group (previously known as Garena),[2] Shopee was first launched in Singapore in 2015, and later expanded its reach to Malaysia, Thailand, Taiwan, Indonesia, Vietnam, the Philippines and Brazil.\n\n[The competition page](https://www.kaggle.com/c/shopee-product-matching/data) states that Shopee is the leading e-commerce platform in Southeast Asia and Taiwan. Customers appreciate its easy, secure, and fast online shopping experience tailored to their region. The company also provides strong payment and logistical support along with a 'Lowest Price Guaranteed' feature on thousands of Shopee's listed products.","metadata":{"papermill":{"duration":0.019842,"end_time":"2021-03-12T22:16:08.996369","exception":false,"start_time":"2021-03-12T22:16:08.976527","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[The competition page](https://www.kaggle.com/c/shopee-product-matching/data) states the following about each ID.\nFiles\n[train/test].csv - the training set metadata. Each row contains the data for a single posting. Multiple postings might have the exact same image ID, but with different titles or vice versa.\n\n* posting_id - the ID code for the posting.\n\n* image - the image id/md5sum.\n\n* image_phash - a perceptual hash of the image.\n\n* title - the product description for the posting.\n\n* label_group - ID code for all postings that map to the same product. Not provided for the test set.\n\n* [train/test]images - the images associated with the postings.\n\n* sample_submission.csv - a sample submission file in the correct format.\n\n* posting_id - the ID code for the posting.\n\n* matches - Space delimited list of all posting IDs that match this posting. Posts always self-match. Group sizes were capped at 50, so there's no need to predict more than 50 matches.","metadata":{"papermill":{"duration":0.019849,"end_time":"2021-03-12T22:16:09.037171","exception":false,"start_time":"2021-03-12T22:16:09.017322","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pip install textfeatures","metadata":{"papermill":{"duration":9.180921,"end_time":"2021-03-12T22:16:18.238333","exception":false,"start_time":"2021-03-12T22:16:09.057412","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* NLTK (Natural Language Toolkit) is useful for natural language processing. The official documentation is [here](http://www.nltk.org/).","metadata":{}},{"cell_type":"code","source":"import plotly.express as px","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Prepare a library to draw a histogram.","metadata":{}},{"cell_type":"code","source":"!pip install hvplot\nimport hvplot.pandas  # custom install\n\nfrom glob import glob\n\nfrom bq_helper import BigQueryHelper\nfrom dask import bag, diagnostics \nfrom urllib import request\n\nimport missingno as msno","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport re\nimport pydicom\nimport matplotlib.pyplot as plt\n\n# import useful tools\nfrom glob import glob\nfrom PIL import Image\nimport cv2\nimport pydicom as dcm\nimport random\nimport matplotlib.patches as patches\nfrom sklearn.model_selection import KFold\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom sklearn.model_selection import StratifiedKFold\nimport warnings\n\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\n\n# Work with phash\nimport imagehash\n\n# import data visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport matplotlib\nimport pydicom as dicom\n\nfrom bokeh.plotting import figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs\nimport skimage.io as io\n\n# import data augmentation\nimport albumentations as albu\n\n# import math module\nimport math\n\n# Libraries\nimport pandas_profiling\nimport xgboost as xgb\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport tqdm\nfrom tqdm.auto import tqdm as tqdmp\ntqdmp.pandas()\n\n# One-hot encoding\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Other\nfrom random import randint\nimport warnings\nimport csv\nwarnings.filterwarnings(\"ignore\")","metadata":{"papermill":{"duration":6.911454,"end_time":"2021-03-12T22:16:25.174131","exception":false,"start_time":"2021-03-12T22:16:18.262677","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Color scheme\ncolors = [\"#EDAC54\", \"#F4C5B7\", \"#DD7555\", \"#B95F18\", \"#000080\"]","metadata":{"papermill":{"duration":0.04089,"end_time":"2021-03-12T22:16:25.237726","exception":false,"start_time":"2021-03-12T22:16:25.196836","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Usefull functuions</center></h2>","metadata":{"papermill":{"duration":0.022854,"end_time":"2021-03-12T22:16:25.283338","exception":false,"start_time":"2021-03-12T22:16:25.260484","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_images(images_number):\n    \n    plot_list = train_df['image'].sample(n=images_number).tolist()\n    size = np.sqrt(images_number)\n    if int(size)*int(size) < images_number:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(10, 10))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(os.path.join('../input/shopee-product-matching/train_images/', image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(image_id, fontsize=12)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()","metadata":{"papermill":{"duration":0.033397,"end_time":"2021-03-12T22:16:25.343141","exception":false,"start_time":"2021-03-12T22:16:25.309744","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Loading data</center></h2>","metadata":{"papermill":{"duration":0.0221,"end_time":"2021-03-12T22:16:25.387825","exception":false,"start_time":"2021-03-12T22:16:25.365725","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Setup the paths to train and test images\n\nTEST_DIR = \"../input/shopee-product-matching/test_images/\"\nTRAIN_DIR = \"../input/shopee-product-matching/train_images/\"\ndataset_dir = \"../input/shopee-product-matching/\"","metadata":{"papermill":{"duration":0.029363,"end_time":"2021-03-12T22:16:25.439952","exception":false,"start_time":"2021-03-12T22:16:25.410589","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Glob the directories and get the lists of train and test images\ntrain_fns = glob(TRAIN_DIR + '*')\ntest_fns = glob(TEST_DIR + '*')\n\n# Loading training data and test data\ntrain_df = pd.read_csv(dataset_dir+'train.csv')\ntest = pd.read_csv(dataset_dir+'test.csv')\nsample = pd.read_csv(dataset_dir+'sample_submission.csv')","metadata":{"papermill":{"duration":1.283841,"end_time":"2021-03-12T22:16:26.746503","exception":false,"start_time":"2021-03-12T22:16:25.462662","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = dataset_dir + \"/train_images/\" + train_df['image']\ntrain_df['path'] = train_images\n\ntest_images = dataset_dir + \"/test_images/\" + test['image']\ntest['path'] = test_images","metadata":{"papermill":{"duration":0.066182,"end_time":"2021-03-12T22:16:26.836512","exception":false,"start_time":"2021-03-12T22:16:26.77033","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Statistics</center></h2>","metadata":{}},{"cell_type":"code","source":"# Let's find out how many images are under the directory\nprint('Train images: %d' %len(os.listdir(os.path.join(dataset_dir, \"train_images\"))))\nprint('Test images: %d' %len(os.listdir(os.path.join(dataset_dir, \"test_images\"))))","metadata":{"papermill":{"duration":0.051984,"end_time":"2021-03-12T22:16:26.911631","exception":false,"start_time":"2021-03-12T22:16:26.859647","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's figure out the unique number for each columns.","metadata":{}},{"cell_type":"code","source":"train_df.head(5)","metadata":{"papermill":{"duration":0.053267,"end_time":"2021-03-12T22:16:26.988405","exception":false,"start_time":"2021-03-12T22:16:26.935138","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"papermill":{"duration":0.066928,"end_time":"2021-03-12T22:16:27.079685","exception":false,"start_time":"2021-03-12T22:16:27.012757","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.nunique().to_frame().rename(columns={0:\"Unique Values\"}).style.background_gradient(cmap=\"plasma\")","metadata":{"papermill":{"duration":0.148778,"end_time":"2021-03-12T22:16:27.253129","exception":false,"start_time":"2021-03-12T22:16:27.104351","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The number of uniqueness is the same for image and path. image_phash and label_group are fewer in number than image, so there is a possibility to aggregate common images with these.","metadata":{}},{"cell_type":"code","source":"# Display of training data\nprint(train_df)","metadata":{"papermill":{"duration":0.041938,"end_time":"2021-03-12T22:16:27.320475","exception":false,"start_time":"2021-03-12T22:16:27.278537","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values in the training data\ntrain_df.isnull().sum()","metadata":{"papermill":{"duration":0.058376,"end_time":"2021-03-12T22:16:27.405523","exception":false,"start_time":"2021-03-12T22:16:27.347147","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Fortunately, it turns out there are no missing values.","metadata":{}},{"cell_type":"markdown","source":"* Understanding same label_groups\n* Counting the number of images in each label group","metadata":{}},{"cell_type":"code","source":"labels = train_df.groupby(\"label_group\")[\"image\"].count().reset_index()\nlabels.columns=[\"label_group\",\"image_num\"]\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sortlabels = labels.sort_values(\"image_num\")\nsortlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* minimum images are 2, max images are 51","metadata":{}},{"cell_type":"markdown","source":"# Display Duplicated Items from Train Data\nUsing the column label_group which is the ground truth, we can display examples of duplicated items.","metadata":{}},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/train_images/'\n\ndef displayDF(train_df, random=False, COLS=6, ROWS=4, path=BASE):\n    for k in range(ROWS):\n        plt.figure(figsize=(20,5))\n        for j in range(COLS):\n            if random: row = np.random.randint(0,len(train_df))\n            else: row = COLS*k + j\n            name = train_df.iloc[row,1]\n            title = train_df.iloc[row,3]\n            title_with_return = \"\"\n            for i,ch in enumerate(title):\n                title_with_return += ch\n                if (i!=0)&(i%20==0): title_with_return += '\\n'\n            img = cv2.imread(path+name)\n            plt.subplot(1,COLS,j+1)\n            plt.title(title_with_return)\n            plt.axis('off')\n            plt.imshow(img)\n        plt.show()\n        \ndisplayDF(train_df,random=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = train_df.label_group.value_counts()\nplt.figure(figsize=(20,5))\nplt.plot(np.arange(len(groups)),groups.values)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Index of Unique Item',size=14)\nplt.title('Duplicate Count vs. Unique Item Count',size=16)\nplt.show()\n\nplt.figure(figsize=(20,5))\nplt.bar(groups.index.values[:50].astype('str'),groups.values[:50])\nplt.xticks(rotation = 45)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Label Group',size=14)\nplt.title('Top 50 Duplicated Items',size=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(5):\n    print('#'*40)\n    print('### TOP %i DUPLICATED ITEM:'%(k+1),groups.index[k])\n    print('#'*40)\n    top = train_df.loc[train_df.label_group==groups.index[k]]\n    displayDF(top, random=False, ROWS=2, COLS=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test","metadata":{"papermill":{"duration":0.02591,"end_time":"2021-03-12T22:16:27.457868","exception":false,"start_time":"2021-03-12T22:16:27.431958","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Display of test data\nprint(test)","metadata":{"papermill":{"duration":0.038565,"end_time":"2021-03-12T22:16:27.522798","exception":false,"start_time":"2021-03-12T22:16:27.484233","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sample","metadata":{"papermill":{"duration":0.026424,"end_time":"2021-03-12T22:16:27.575849","exception":false,"start_time":"2021-03-12T22:16:27.549425","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Display of sample data\nprint(sample)","metadata":{"papermill":{"duration":0.037671,"end_time":"2021-03-12T22:16:27.640128","exception":false,"start_time":"2021-03-12T22:16:27.602457","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[The competition page](https://www.kaggle.com/c/shopee-product-matching/data) states the following about the IDs of the submitted file.\n\n* sample_submission.csv - a sample submission file in the correct format.\n\n* posting_id - the ID code for the posting.\n\nmatches - Space delimited list of all posting IDs that match this posting. Posts always self-match. Group sizes were capped at 50, so there's no need to predict more than 50 matches.**","metadata":{"papermill":{"duration":0.026802,"end_time":"2021-03-12T22:16:27.694243","exception":false,"start_time":"2021-03-12T22:16:27.667441","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\n\nfor num,a in enumerate(test[\"path\"]):\n    \n    plt.subplot(1,3,num+1)\n    img = cv2.imread(a)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    plt.imshow(img)\n    plt.axis(\"off\")","metadata":{"papermill":{"duration":0.612338,"end_time":"2021-03-12T22:16:28.333832","exception":false,"start_time":"2021-03-12T22:16:27.721494","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(8)","metadata":{"papermill":{"duration":1.528948,"end_time":"2021-03-12T22:16:29.892572","exception":false,"start_time":"2021-03-12T22:16:28.363624","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Data Visualization</center></h2>","metadata":{}},{"cell_type":"markdown","source":"Image Label Groups by No. of Images","metadata":{}},{"cell_type":"code","source":"top10_names = train_df['label_group'].value_counts().index.tolist()[:15]\ntop10_values = train_df['label_group'].value_counts().tolist()[:15]\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=top10_names, y=top10_values)\nplt.xticks(rotation=45)\nplt.xlabel(\"Label Group\")\nplt.ylabel(\"Image Count\")\nplt.title(\"Top-15 Label Groups by Image Count\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Take a look at the distribution of the number of images in Label Groups. There are some groups with a small number of images, but there are neither groups with a large number of images nor groups with a small number of images.","metadata":{}},{"cell_type":"markdown","source":"[](http://)<h2 style='color:white; background:#000080; border:0'><center>Titles analysis</center></h2>","metadata":{"papermill":{"duration":0.042231,"end_time":"2021-03-12T22:16:29.976571","exception":false,"start_time":"2021-03-12T22:16:29.93434","status":"completed"},"tags":[]}},{"cell_type":"code","source":"stopwords = set(STOPWORDS) \nwordcloud = WordCloud(width = 800, \n                      height = 800,\n                      background_color ='white',\n                      min_font_size = 10,\n                      stopwords = stopwords,).generate(' '.join(train_df['title'])) \n\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Basic NLP","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text, flg_stemm=False, flg_lemm=True):\n\n    lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n    \n    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n            \n    ## Tokenize (convert from string to list)\n    lst_text = text.split()\n    ## remove Stopwords\n    if lst_stopwords is not None:\n        lst_text = [word for word in lst_text if word not in \n                    lst_stopwords]\n                \n    ## Stemming (remove -ing, -ly, ...)\n    if flg_stemm == True:\n        ps = nltk.stem.porter.PorterStemmer()\n        lst_text = [ps.stem(word) for word in lst_text]\n                \n    ## Lemmatisation (convert the word into root word)\n    if flg_lemm == True:\n        lem = nltk.stem.wordnet.WordNetLemmatizer()    \n        lst_text = [lem.lemmatize(word) for word in lst_text]\n            \n    ## back to string from list\n    text = \" \".join(lst_text)\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Clean Address\ntrain_df[\"clean_title\"] = train_df[\"title\"].apply(lambda x: preprocess_text(x, flg_stemm=False, flg_lemm=True, ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Length of Title\ntrain_df['clean_title_len'] = train_df['clean_title'].apply(lambda x: len(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Word Count\ntrain_df['clean_title_word_count'] =train_df[\"clean_title\"].apply(lambda x: len(str(x).split(\" \")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Character Count\ntrain_df['clean_title_char_count'] = train_df[\"clean_title\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Average Word Length\ntrain_df['clean_title_avg_word_length'] = train_df['clean_title_char_count'] / train_df['clean_title_word_count']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(x, title):\n\n    fig = px.histogram(\n    train_df, \n    x = x,\n    width = 800,\n    height = 500,\n    title = title\n    )\n    \n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(x = 'clean_title_len', title = 'Title Length Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(x = 'clean_title_word_count', title = 'Word Count Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(x = 'clean_title_char_count', title = 'Character Count Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(x = 'clean_title_avg_word_length', title = 'Average Word Length Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Images analysis</center></h2>","metadata":{"papermill":{"duration":0.045512,"end_time":"2021-03-12T22:16:31.637617","exception":false,"start_time":"2021-03-12T22:16:31.592105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"phashgroup = train_df.groupby(\"image_phash\")[\"path\"].count().reset_index()\nphashgroup.columns=[\"image_phash\",\"counts\"]\nphashgroup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sortphash = phashgroup.sort_values(\"counts\")\nsortphash","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* maximum counts are 26.","metadata":{}},{"cell_type":"code","source":"tmpdf = train_df[train_df[\"image_phash\"]==sortphash[\"image_phash\"].iloc[-1]]\ntmpdf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape columns\ntrain_df['img_shape'] = train_df['path'].progress_apply(lambda x: np.shape(io.imread(x)))","metadata":{"papermill":{"duration":551.372454,"end_time":"2021-03-12T22:25:43.0562","exception":false,"start_time":"2021-03-12T22:16:31.683746","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Draw the height, width, and color of the image as a scatter plot with histogram.","metadata":{}},{"cell_type":"code","source":"shapes = pd.DataFrame().from_records(train_df['img_shape'])\nshapes.columns = ['Width', 'Height', 'Colors']\n\nsns.set_style(\"white\")\nsns.jointplot(x = shapes.iloc[:, 0].astype('float32'), \n              y = shapes.iloc[:, 1].astype('float32'),\n              height = 8, color = '#000080')\nplt.show()","metadata":{"papermill":{"duration":1.555922,"end_time":"2021-03-12T22:25:44.658421","exception":false,"start_time":"2021-03-12T22:25:43.102499","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Duplicated Images","metadata":{"papermill":{"duration":0.046675,"end_time":"2021-03-12T22:25:44.751997","exception":false,"start_time":"2021-03-12T22:25:44.705322","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Get the count of apparitions per image\nimage_count = train_df[\"image\"].value_counts().reset_index()\nimage_count.columns = [\"image\", \"count\"]\nimage_count_duplicates = image_count[image_count[\"count\"] > 1]\nprint(\"Total no. of images with duplicates: {:,}\".format(len(image_count_duplicates)))\n\n#Plot\nfig, ax = plt.subplots(figsize=(16, 7))\nplt.bar(x=image_count_duplicates.iloc[::16][\"image\"],\n        height=image_count_duplicates.iloc[::16][\"count\"],\n        color=colors[4])\nplt.title(\"Duplicated Images: How many apparitions?\", fontsize=20)\nplt.xticks([])\nplt.xlabel(\"Image ID\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16);","metadata":{"papermill":{"duration":0.367493,"end_time":"2021-03-12T22:25:45.167806","exception":false,"start_time":"2021-03-12T22:25:44.800313","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There are 1,246 images that have 2 or more apparitions\n* the title differs for most of them\n* the label_group differs for most of them as well","metadata":{"papermill":{"duration":0.048634,"end_time":"2021-03-12T22:25:45.266035","exception":false,"start_time":"2021-03-12T22:25:45.217401","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def image_viz(image_path):\n    \"\"\"\n    Function for visualization.\n    Takes path to image as input.\n    \"\"\"\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n    plt.imshow(img)\n    plt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def match_matrix(phash_array):\n    \"\"\"\n    A function that checks for matches by phash value.\n    Takes phash values as input.\n    Output - phash diff matrix (pandas data frame)\n    \"\"\"\n    phashs = phash_array.apply(lambda x: imagehash.hex_to_hash(x))\n    phash_matrix = pd.DataFrame()\n    pbar = tqdm.tqdm(total = len(phash_array), desc = 'Progress:', \n                     position = 0, leave = True)\n    for idx, i in enumerate(phash_array):\n        pbar.update(1)\n        phash_matrix = pd.concat([phash_matrix, phashs - imagehash.hex_to_hash(i)], \n                                 axis = 1)\n    pbar.close()\n    phash_matrix.columns = range(len(phash_array))\n    return phash_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Check the fit by Phash value.","metadata":{}},{"cell_type":"code","source":"train_part = train_df.iloc[:1000, :]\nmatches = match_matrix(train_part['image_phash'])\nmatches","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_match = match_matrix(test['image_phash'][:3])\ntest_match","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_part.loc[[11,12],['title']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Posting_id is different, but title, image_phash and label_group are the same image.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[11, 'path'], \n                         train_part.loc[12, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_part.loc[[889,890,891],['posting_id','image_phash','title','label_group']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Posting_id and title are different, but image_phash and label_group are the same image.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[889, 'path'], \n                         train_part.loc[890, 'path'], \n                         train_part.loc[891, 'path']]):\n    plt.subplot(1, 3, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[997, 'path'], \n                         train_part.loc[520, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* An example of a similar, but not identical, image is shown below.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[55, 'path'], \n                         train_part.loc[312, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* An example of a similar, but not identical, image is shown below.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[128, 'path'], \n                         train_part.loc[515, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* An example of a similar, but not identical, image is shown below.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate([train_part.loc[216, 'path'], \n                         train_part.loc[567, 'path']]):\n    plt.subplot(1, 2, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Test Image</center></h2>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\nfor idx, i in enumerate(test['path']):\n    plt.subplot(1, 3, idx + 1)\n    image_viz(i)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coding: utf-8\nfrom tqdm import tqdm\nimport time\n\n# Set the total value \nbar = tqdm(total = 1000)\n# Add description\nbar.set_description('Progress rate')\nfor i in range(100):\n    # Set the progress\n    bar.update(25)\n    time.sleep(1)","metadata":{"papermill":{"duration":100.307469,"end_time":"2021-03-12T22:27:25.622296","exception":false,"start_time":"2021-03-12T22:25:45.314827","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style='color:white; background:#000080; border:0'><center>Acknowledgements</center></h2>","metadata":{"papermill":{"duration":0.079203,"end_time":"2021-03-12T22:27:25.783209","exception":false,"start_time":"2021-03-12T22:27:25.704006","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"* [Shopee - Data understanding and analysis](https://www.kaggle.com/isaienkov/shopee-data-understanding-and-analysis)\n* [Shopee: Before we start (EDA, PHASH, Baseline)](https://www.kaggle.com/maksymshkliarevskyi/shopee-before-we-start-eda-phash-baseline)\n* [EDA of Shopee for starter](https://www.kaggle.com/chumajin/eda-of-shopee-for-starter)\n* [Shopee: text prep | FE | image augmentation](https://www.kaggle.com/andradaolteanu/shopee-text-prep-fe-image-augmentation)\n* [[V5]Shopee InDepth EDA:One stop for all your needs](https://www.kaggle.com/ishandutta/v5-shopee-indepth-eda-one-stop-for-all-your-needs)\n* [[V7]Shopee InDepth EDA:One stop for all your needs](https://www.kaggle.com/ishandutta/v7-shopee-indepth-eda-one-stop-for-all-your-needs)\n* [Shopee: Before we start (EDA, PHASH, Baseline)](https://www.kaggle.com/maksymshkliarevskyi/shopee-before-we-start-eda-phash-baseline)\n* [RAPIDS cuML TfidfVectorizer and KNN](https://www.kaggle.com/cdeotte/rapids-cuml-tfidfvectorizer-and-knn)","metadata":{"papermill":{"duration":0.079965,"end_time":"2021-03-12T22:27:25.943955","exception":false,"start_time":"2021-03-12T22:27:25.86399","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Work in progress…","metadata":{"papermill":{"duration":0.081336,"end_time":"2021-03-12T22:27:26.106443","exception":false,"start_time":"2021-03-12T22:27:26.025107","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Your upvote is my motivation","metadata":{"papermill":{"duration":0.079595,"end_time":"2021-03-12T22:27:26.265665","exception":false,"start_time":"2021-03-12T22:27:26.18607","status":"completed"},"tags":[]}}]}