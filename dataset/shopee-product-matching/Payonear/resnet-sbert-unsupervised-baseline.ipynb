{"cells":[{"metadata":{},"cell_type":"markdown","source":"Big thanks to Chris for his [kernel](https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport cupy, cudf\nimport gc\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\nimport random\nimport torch\nimport torchvision\nfrom torchvision import  models, transforms\nfrom transformers import BertTokenizer, BertModel\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nimport glob\nfrom PIL import Image\nimport seaborn as sns\nimport cv2, matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom textwrap import wrap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data import"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda'if torch.cuda.is_available() else 'cpu'\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/shopee-product-matching/'\nPATH_TO_IMG = '../input/shopee-product-matching/train_images/'\nPATH_TO_TEST = '../input/shopee-product-matching/test_images/'\nos.listdir(PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"COMPUTE_CV = True\nif len(pd.read_csv(PATH + 'test.csv')) > 3: COMPUTE_CV = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset = pd.read_csv(PATH + 'train.csv')\n    tmp = dataset.groupby('label_group').posting_id.agg('unique').to_dict()\n    dataset['target'] = dataset.label_group.map(tmp)\nelse:    \n    dataset = pd.read_csv(PATH + 'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_random_img():\n    # choose randomly two instances per each class\n    labels_to_show = np.random.choice(dataset.label_group.unique(), \n                                      replace=False, size=24)\n    img_to_show = []\n    for label in labels_to_show:\n        rows = dataset[dataset.label_group==label].copy()\n        pair = np.random.choice([i for i in range(len(rows))], \n                                    replace=False, size=2)\n        img_pair = rows.iloc[pair][['image', 'title']].values\n        \n        img_to_show += list(img_pair)\n    \n    fig, axes = plt.subplots(figsize = (18, 12), nrows=4,ncols=6)\n    for imp, ax in zip(img_to_show, axes.ravel()):\n        img = cv2.imread(PATH_TO_IMG + imp[0])\n        title = '\\n'.join(wrap(imp[1], 20))\n        ax.set_title(title)\n        ax.imshow(img)\n        ax.axis('off')\n\n    fig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    show_random_img()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet block"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNetEmbedder(nn.Module):\n    \n    def __init__(self, device='cpu'):\n        super(ResNetEmbedder, self).__init__()\n        self.model = models.resnet50(pretrained=False)\n        self.device = device\n        path = '../input/pretrained-model-weights-pytorch/resnet50-19c8e357.pth'\n        self.model.load_state_dict(torch.load(path))\n#         to freeze weights\n        for param in self.model.parameters():\n                param.requires_grad = False\n        self.model.to(device)\n        \n    \n    def transform(self, img):\n        image_transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.Resize(256),\n                transforms.CenterCrop(224),\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize(\n                    mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)\n                ),\n            ]\n        )\n        return image_transform(img)\n    \n    def forward(self, img):\n        img_tr = self.transform(img).unsqueeze(0)\n        img_tr = img_tr.to(self.device)\n        features = self.model(img_tr).squeeze()\n        return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_img = ResNetEmbedder(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vectorize_img(img_path):\n    img = Image.open(img_path).convert('RGB')\n    model_img.eval()\n    with torch.no_grad():\n        output = model_img(img).cpu().numpy()\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif COMPUTE_CV:\n    dataset['resnet_v'] = dataset['image'].progress_apply(lambda x: vectorize_img(PATH_TO_IMG + x))\nelse:\n    dataset['resnet_v'] = dataset['image'].progress_apply(lambda x: vectorize_img(PATH_TO_TEST + x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model_img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check cosine metrics. Vectors should be normalized."},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors = np.stack(dataset.resnet_v)\nvectors = torch.Tensor(vectors).to(device)\nvectors = F.normalize(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024\n\nprint('Finding similar titles...')\nCTS = len(dataset)//CHUNK\nif len(dataset)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(dataset))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = torch.matmul( vectors, vectors[a:b].T).T\n    cts = cts.cpu().numpy()\n    \n    for k in range(b-a):\n        IDX = np.where(cts[k,]>0.9)[0]\n        o = dataset.iloc[IDX].posting_id.values\n        preds.append(o)\n\ndel vectors, cts, IDX, o\n_ = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['preds_resnet'] = preds\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['f1_resnet'] = dataset.apply(getMetric('preds_resnet'), axis=1)\n    print('CV score for baseline =', dataset.f1_resnet.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentence Bert block"},{"metadata":{},"cell_type":"markdown","source":"To familiarize with implementation details please see [documentation](https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens)."},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERTEmbedder(nn.Module):\n    \n    def __init__(self, device='cpu'):\n        super(BERTEmbedder, self).__init__()\n        self.bert_path = \"../input/sentence-transformer/\"\n        self.model = BertModel.from_pretrained(self.bert_path)\n#         to freeze weights\n        for param in self.model.parameters():\n                param.requires_grad = False\n        self.model.to(device)\n        \n    def transform(self, txt):\n        tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n        encoded_input  = tokenizer.encode_plus( txt, \n                                                truncation=True, \n                                                max_length=128,\n                                                add_special_tokens=True,\n                                                padding=True,\n                                                return_tensors='pt').values()\n        return encoded_input\n    \n    def mean_pooling(self, model_output, attention_mask):\n        token_embeddings = model_output[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n        return sum_embeddings / sum_mask\n        \n    def forward(self, txt):\n        inputs_ids, token_type_ids, attention_mask = self.transform(txt)\n        inputs_ids, token_type_ids, attention_mask = inputs_ids.to(device), \\\n                                                token_type_ids.to(device), attention_mask.to(device)\n        with torch.no_grad():\n            encoded_layers = self.model(inputs_ids, \n                                        attention_mask=attention_mask, \n                                        token_type_ids=token_type_ids)\n        features = self.mean_pooling(encoded_layers, attention_mask)\n        return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_txt = BERTEmbedder(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vectorize_txt(txt):\n    model_txt.eval()\n    with torch.no_grad():\n        output = model_txt(txt).cpu().numpy()\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndataset['sbert_v'] = dataset['title'].progress_apply(lambda x: vectorize_txt(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model_txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors = np.stack(dataset.sbert_v).squeeze(1)\nvectors = torch.Tensor(vectors).to(device)\nvectors = F.normalize(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024\n\nprint('Finding similar titles...')\nCTS = len(dataset)//CHUNK\nif len(dataset)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(dataset))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = torch.matmul( vectors, vectors[a:b].T).T\n    cts = cts.cpu().numpy()\n    \n    for k in range(b-a):\n        IDX = np.where(cts[k,]>0.95)[0]\n        o = dataset.iloc[IDX].posting_id.values\n        preds.append(o)\n\ndel vectors, cts, IDX, o\n_ = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['preds_sbert'] = preds\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['f1_sbert'] = dataset.apply(getMetric('preds_sbert'), axis=1)\n    print('CV score for baseline =', dataset.f1_sbert.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Concatenation block"},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat():\n    def cat(row):\n        comm = np.concatenate([row.resnet_v,row.sbert_v.squeeze()])\n        return comm\n    return cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['concat_v'] = dataset.progress_apply(concat(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors = np.stack(dataset.concat_v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN = 50\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(vectors)//CHUNK\nif len(vectors)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(vectors))\n    print('chunk',a,'to',b)\n    distances, indices = model.kneighbors(vectors[a:b,])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k,]<35.0)[0]\n        IDS = indices[k,IDX]\n        o = dataset.iloc[IDS].posting_id.values\n        preds.append(o)\n        \ndel model, distances, indices, vectors, IDX, o, IDS\n_ = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['preds_concat'] = preds\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['f1_concat'] = dataset.apply(getMetric('preds_concat'), axis=1)\n    print('CV score for baseline =', dataset.f1_concat.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Phash block"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = dataset.groupby('image_phash').posting_id.agg('unique').to_dict()\ndataset['preds_phash'] = dataset.image_phash.map(tmp)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del tmp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF block"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_gf = cudf.DataFrame(dataset[['posting_id', 'title']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntext_embeddings = model.fit_transform(dataset_gf.title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024\n\nprint('Finding similar titles...')\nCTS = len(dataset)//CHUNK\nif len(dataset)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(dataset))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = text_embeddings.dot(text_embeddings[a:b].T).T.toarray()\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = dataset.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel text_embeddings, IDX, o, cts\n_ = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['preds_tfidf'] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['f1_tfidf'] = dataset.apply(getMetric('preds_tfidf'), axis=1)\n    print('CV score for baseline =', dataset.f1_tfidf.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission block"},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds_concat,row.preds_phash, row.preds_tfidf])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_train(row):\n    x = np.concatenate([row.preds_concat,row.preds_phash, row.preds_tfidf])\n    return list(np.unique(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['matches'] = dataset.apply(combine_for_train, axis=1)\nelse:\n    dataset['matches'] = dataset.apply(combine_for_sub, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.to_pickle('train_data.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[['posting_id', 'matches']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm = pd.read_csv('submission.csv')\nsubm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    dataset['f1_final'] = dataset.apply(getMetric('matches'), axis=1)\n    print('CV score for baseline =', dataset.f1_final.mean())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}