{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Notebook that uses information of objects detection to crop images by most centered object or biggest object","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nfrom IPython.display import display\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/shopee-train-with-objects/train_obj_05.csv')\n# Since dataframe is recovered from file, lists have to be converted from strings to Python lists. \n# This step (with high cost) will not be necessary in the test eval, since objects are computed in same instance\nfeatures = ['class_index', 'confidence', 'norm_area', 'coordinates', 'norm_dis_to_org']\nnew_cols = [f'objects_{feature}' for feature in features]\nfor col in new_cols:\n    df[col] = df.apply(lambda row: eval(row[col]), axis=1)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get object names to specify objects to crop by name and not by index","metadata":{}},{"cell_type":"code","source":"objects_names = eval(open('../input/shopee-train-with-objects/objects_names.txt').read())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Path to images","metadata":{}},{"cell_type":"code","source":"path_to_images = '../input/shopee-product-matching/train_images/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Specify which objects to crop\n\nNote that this could just be done by filtering the detected objects. However, the way it is done you can change this value dinamically without having to load the objects again","metadata":{}},{"cell_type":"code","source":"objects_to_crop = ['bottle']  # objects_to_crop = objects_names (to consider all)\nindexes_to_crop = [objects_names.index(obj) for obj in objects_to_crop]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auxiliary functions to filter objects to consider","metadata":{}},{"cell_type":"code","source":"def get_indexes_to_consider(row):\n    return [i for i, object_index in enumerate(row['objects_class_index']) if object_index in indexes_to_crop]\ndef items_from_indexes(row, attribute, indexes_to_consider):\n    return [row[attribute][index] for index in indexes_to_consider]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions to choose object to crop","metadata":{}},{"cell_type":"code","source":"def most_center_coordinates(row, objects_coordinates, indexes_to_consider):\n    objects_center_distance = items_from_indexes(row, 'objects_norm_dis_to_org', indexes_to_consider)\n    most_center_index = objects_center_distance.index(min(objects_center_distance))\n    return objects_coordinates[most_center_index]\n\ndef biggest_coordinates(row, objects_coordinates, indexes_to_consider):\n    objects_area = items_from_indexes(row, 'objects_norm_area', indexes_to_consider)\n    biggest_object_index = objects_area.index(max(objects_area))\n    return objects_coordinates[biggest_object_index]\n\ndef best_coordinates(row, indexes_to_consider):\n    objects_coordinates = items_from_indexes(row, 'objects_coordinates', indexes_to_consider)\n    return biggest_coordinates(row, objects_coordinates, indexes_to_consider)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Crop images","metadata":{}},{"cell_type":"code","source":"paths = []\ndef crop_image(row):\n    if row['objects_norm_area']:  # First check if there are any detected objects\n        indexes_to_consider = get_indexes_to_consider(row)  # Second check if there are objects from the desired list\n        if indexes_to_consider:\n            image_path = path_to_images + row['image']\n            img = Image.open(image_path)\n            img_cropped = img.crop(best_coordinates(row, indexes_to_consider))\n            image_path_cropped = row['image'][:-4] + '_cropped' + row['image'][-4:]\n            paths.append(image_path_cropped)\n            img_cropped.save(image_path_cropped)\n            return image_path_cropped","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf.apply(crop_image, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check crops","metadata":{}},{"cell_type":"code","source":"img = Image.open('../input/shopee-product-matching/train_images/0c4d36922e3907cd4ece22654fd998b9.jpg')\ndisplay(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open('0c4d36922e3907cd4ece22654fd998b9_cropped.jpg')\ndisplay(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open('../input/shopee-product-matching/train_images/d6c97d3fbc979bdd5e70c998433bb958.jpg')\ndisplay(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open('d6c97d3fbc979bdd5e70c998433bb958_cropped.jpg')\ndisplay(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}