{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setting","metadata":{}},{"cell_type":"code","source":"! pip install contractions\n! pip install Unidecode\n! pip install word2number","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom tqdm.notebook import tqdm as note_book_tqdm\n\nimport contractions\nimport nltk\nfrom wordcloud import WordCloud, STOPWORDS\nfrom unidecode import unidecode\nfrom word2number import w2n\nimport re\n\nnote_book_tqdm.pandas(desc=\"progress: \")\n\nimport tensorflow as tf\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nprint('TF', tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"font.size\"] = 16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Reading","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/shopee-product-matching/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data observation","metadata":{}},{"cell_type":"markdown","source":"### Train Data shape and sample rows","metadata":{}},{"cell_type":"code","source":"print('shape', df_train.shape)\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Data info","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### label_group to index","metadata":{}},{"cell_type":"code","source":"label_mapper = dict(zip(df_train['label_group'].unique(), np.arange(len(df_train['label_group'].unique()))))\ndf_train['label_group'] = df_train['label_group'].map(label_mapper)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of items per label group ","metadata":{}},{"cell_type":"code","source":"label_groups = df_train['label_group'].value_counts(ascending=False)\nprint('Unique Item Count', len(label_groups))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Memo\n- the number of data is different for each label group.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.plot(np.arange(len(label_groups)),label_groups.values)\nplt.ylabel('LabelGroup Item Count',size=14)\nplt.xlabel('Index of Unique Item',size=14)\nplt.title('Number of items per group',size=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Images","metadata":{}},{"cell_type":"markdown","source":"#### plot random images","metadata":{}},{"cell_type":"code","source":"def plot_random_images(images_count):\n    \n    plot_list = df_train['image'].sample(n=images_count).tolist()\n    size = np.sqrt(images_count)\n    if int(size)*int(size) < images_count:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(f'../input/shopee-product-matching/train_images/{image_id}', )\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        plt.imshow(image)\n        plt.title(image_id, fontsize=12)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_random_images(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### plot group images","metadata":{}},{"cell_type":"code","source":"def plot_group_images(group_id, df):\n    \n    plot_list = df[df['label_group'] == group_id]\n    plot_list = plot_list['image'].tolist()\n    images_count = len(plot_list)\n    size = np.sqrt(images_count)\n    if int(size)*int(size) < images_count:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(f'../input/shopee-product-matching/train_images/{image_id}', )\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(image_id, fontsize=6)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()\n    \n    sample = df[df['label_group'] == group_id]\n    print(f'Total number of items in group {group_id}: {len(sample)}, number of unique titles: {sample.nunique()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.bar(label_groups.index.values[:50].astype('str'), label_groups.values[:50])\nplt.xticks(rotation = 45)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Label Group',size=14)\nplt.title('Top 50 Duplicated Items',size=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(106, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(48, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(307, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(979, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(252, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(283, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(714, df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Memo\n- there are several images that are exactly the same in the same group.","metadata":{}},{"cell_type":"markdown","source":"### Remove Dupilicated Data","metadata":{}},{"cell_type":"code","source":"def remove_duplicated_row(df, col_name):\n    df_removed = df_train.drop_duplicates([col_name])\n    print('Original data size', len(df))\n    print('Reamoved data size', len(df_removed))\n    removed_duplicated_label_groups = df_removed['label_group'].value_counts(ascending=False)\n    print('Original Unique Item Count', len(label_groups))\n    print('Reamoved Unique Item Count', len(removed_duplicated_label_groups))\n    \n    return df_removed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Same Imgae name","metadata":{}},{"cell_type":"code","source":"df_removed_same_image = remove_duplicated_row(df_train, 'image')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(979, df_removed_same_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Same title","metadata":{}},{"cell_type":"code","source":"df_removed_same_title = remove_duplicated_row(df_train, 'title')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(979, df_removed_same_title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Same image_phash","metadata":{}},{"cell_type":"code","source":"df_removed_same_phash = remove_duplicated_row(df_train, 'image_phash')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(979, df_removed_same_phash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Same dhash","metadata":{}},{"cell_type":"code","source":"def dhash(image_name, hashSize=8):\n    \"\"\"calculation to create a numerical representation of the image.\"\"\"\n    image_path = f'../input/shopee-product-matching/train_images/{image_name}'\n    image = cv2.imread(image_path, )\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(gray, (hashSize + 1, hashSize))\n    diff = resized[:, 1:] > resized[:, :-1]\n    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[:, 'dhash'] = df_train.image.progress_apply(dhash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_removed_same_dhash = remove_duplicated_row(df_train, 'dhash')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_group_images(979, df_removed_same_dhash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of image shapes","metadata":{}},{"cell_type":"code","source":"def get_image_shape(image_name):\n    image_path = f'../input/shopee-product-matching/train_images/{image_name}'\n    image = cv2.imread(image_path)\n    return image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[:, 'shape'] = df_train.image.progress_apply(get_image_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[['width', 'height', 'chanel']] = pd.DataFrame(df_train['shape'].tolist(), index=df_train.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_shape = df_train['shape'].value_counts(ascending=False)\nprint('image shape variations', len(images_shape))\nimages_shape.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.scatter(df_train['width'], df_train['height'], alpha=0.3)\nplt.xlabel('image width')\nplt.ylabel('image height')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Memo\n- Most of the images are square in shape.\n- The most common size is 640✖️640","metadata":{}},{"cell_type":"markdown","source":"### Distribution of title length","metadata":{}},{"cell_type":"code","source":"df_train.loc[:, 'title_length'] = df_train.title.progress_apply(lambda x: len(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title_length = df_train['title_length'].value_counts(ascending=False)\ntitle_length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (TODO)Analyze the title column\n- wordcloud\n- preporocess\n- etc","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ndef text_preprocess(title):\n    # Convert Accented Characters\n    title = unidecode(title)\n    # Expand Contractions\n    title = contractions.fix(title)\n    # Lowercase all texts\n    title = title.lower()\n    # Remove special characters\n    title = re.sub(r\"[^a-zA-Z0-9]+\", ' ', title)\n    # title to word list\n    title = word_tokenize(title)\n    # Remove stopwords\n    title = [w for w in title if not w in stop_words]\n    title = ' '.join(title)\n\n\n    return title","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[:, 'clean_title'] = df_train.title.progress_apply(text_preprocess)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[:, 'clean_title_length'] = df_train.clean_title.progress_apply(lambda x: len(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_title_length = df_train['clean_title_length'].value_counts(ascending=False)\nclean_title_length.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 8))\nfig.suptitle(\"Difference in the number of characters between the original title and the clean title\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\nax1.set_xlabel('original title length')\nax1.set_ylabel('item count')\nax2.set_xlabel('clean title length')\nax2.set_ylabel('item count')\nax1.bar(clean_title_length.index, clean_title_length.values, width=1, color='b', alpha=0.5)\nax2.bar(title_length.index, title_length.values, width=1, color='r', alpha=0.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple model for the same titles","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/shopee-product-matching/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check = test.groupby(['title']).count().reset_index()['title'].tolist()\na = []\nb = []\nfor item in check:\n    res = test[test['title']== item]['posting_id'].tolist()\n    ans = \"\"\n    for id_item in res:\n        ans = ans + str(id_item) + \" \"\n    for id_item in res:\n        a.append(id_item)\n        b.append(ans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.DataFrame()\nsubmission1['posting_id'] = a\nsubmission1['matches'] = b\nsubmission1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check = test.groupby(['image_phash']).count().reset_index()['image_phash'].tolist()\na = []\nb = []\nfor item in check:\n    res = test[test['image_phash']== item]['posting_id'].tolist()\n    ans = \"\"\n    for id_item in res:\n        ans = ans + str(id_item) + \" \"\n    ans = ans[:-1]\n    for id_item in res:\n        a.append(id_item)\n        b.append(ans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = pd.DataFrame()\nsubmission2['posting_id'] = a\nsubmission2['matches'] = b\nsubmission2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = pd.DataFrame()\nsubmission2['posting_id'] = a\nsubmission2['matches'] = b\nsubmission2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.merge(submission1, submission2, on='posting_id', how='inner')\nsub['list'] = sub['matches_x'] + sub['matches_y']\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final = []\nfor index, row in sub.iterrows():\n    res = list(set(row['list'].split(' ')))\n    ans = \"\"\n    for item in res:\n        ans = ans + str(item) + \" \"\n    ans = ans[:-1]\n    final.append(ans)\n    \nsubmission = pd.DataFrame()\nsubmission['posting_id'] = sub['posting_id']\nsubmission['matches'] = final\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}