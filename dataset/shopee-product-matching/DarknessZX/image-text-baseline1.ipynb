{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Train-Baseline"},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:13.247406Z","start_time":"2021-03-18T09:59:13.24369Z"},"trusted":true},"cell_type":"code","source":"# DATA_PATH = '../input/'\n# 数据输入路径\nDATA_PATH = '../input/shopee-product-matching/'","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:14.869532Z","start_time":"2021-03-18T09:59:14.482759Z"},"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\n# 计算F1 score\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:15.92512Z","start_time":"2021-03-18T09:59:15.308672Z"},"trusted":true},"cell_type":"code","source":"# 标识是不是计算验证得分\nCOMPUTE_CV = True\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\n# 如果测试集大于3行，进入提交模式\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\n\nif COMPUTE_CV:\n    train = pd.read_csv(DATA_PATH + 'train.csv')\n    train['image'] = DATA_PATH + 'train_images/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\nelse:\n    train = pd.read_csv(DATA_PATH + 'test.csv')\n    train['image'] = DATA_PATH + 'test_images/' + train['image']\n    train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n    \nprint('train shape is', train.shape )\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# image hash"},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:19.569052Z","start_time":"2021-03-18T09:59:18.284395Z"},"trusted":true},"cell_type":"code","source":"# 相同哈希值当作一组\ntmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:21.98207Z","start_time":"2021-03-18T09:59:20.62671Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('CV score for baseline =',train.f1.mean())\n\n# 聚类包括自己的，应该是大于0.5的","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# image CNN"},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:24.147684Z","start_time":"2021-03-18T09:59:23.6933Z"},"trusted":true},"cell_type":"code","source":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\n# 自定义一个数据集\n# 实例化d=ShopeeImageDataset()\n# d[10] getitem\n# len(d)\nclass ShopeeImageDataset(Dataset):\n    def __init__(self, img_path, transform):\n        self.img_path = img_path\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n        img = self.transform(img)\n        return img\n    \n    def __len__(self):\n        return len(self.img_path)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:25.6502Z","start_time":"2021-03-18T09:59:25.64389Z"},"trusted":true},"cell_type":"code","source":"# 实例化\n\nimagedataset = ShopeeImageDataset(\n    train['image'].values,\n    transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),# pillow->tensor,0-255=>0-1\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]))\n\n# dataloader批量读取，batch_size=10,shuffle不打乱\nimageloader = torch.utils.data.DataLoader(\n    imagedataset,\n    batch_size=10, shuffle=False, num_workers=2\n)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T09:59:27.08827Z","start_time":"2021-03-18T09:59:27.083495Z"},"trusted":true},"cell_type":"code","source":"# 用resnet18\nclass ShopeeImageEmbeddingNet(nn.Module):\n    def __init__(self):\n        super(ShopeeImageEmbeddingNet, self).__init__()\n        \n        #\n        model = models.resnet81(True) # True表示使用预训练参数\n        # mean-pooling=>max-pooling 会好一些\n        model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n        \n        model = nn.Sequential(*list(model.children())[:-1])\n        \n        # 原始image_net1000类，不需要全连接，只需要embedding\n        model.eval()# 关闭bn，关闭dropout\n        self.model = model\n    # 正向传播\n    def forward(self, img):        \n        out = self.model(img)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 本地与训练模型保存的文件夹\n!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/pretrained-pytorch-models/resnet18-5c106cde.pth /root/.cache/torch/hub/checkpoints/","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:20.420477Z","start_time":"2021-03-18T09:59:28.809744Z"},"trusted":true},"cell_type":"code","source":"DEVICE = 'cuda'\n\nimgmodel = ShopeeImageEmbeddingNet()\nimgmodel = imgmodel.to(DEVICE)\n\nimagefeat = []\nwith torch.no_grad():\n    for data in tqdm_notebook(imageloader):\n        data = data.to(DEVICE)\n        feat = imgmodel(data)\n        \n        feat = feat.reshape(feat.shape[0], -1)\n        \n        feat = feat.data.cpu().numpy()\n        \n        imagefeat.append(feat)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:43.818543Z","start_time":"2021-03-18T10:01:43.401624Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import normalize\n\n# l2 norm to kill all the sim in 0-1\nimagefeat = np.vstack(imagefeat)\nimagefeat = normalize(imagefeat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nKNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(imagefeat)\n'''","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:54.771453Z","start_time":"2021-03-18T10:01:44.50243Z"},"trusted":true},"cell_type":"code","source":"preds = []\n# 4096一批计算相似度\nCHUNK = 1024*4\n\nimagefeat = cupy.array(imagefeat)\n\nprint('Finding similar images...')\nCTS = len(imagefeat)//CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = cupy.matmul(imagefeat, imagefeat[a:b].T).T\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n    for k in range(b-a):\n        # 如果相似度大于0.95就算\n        IDX = cupy.where(distances[k,]>0.95)[0]\n        # IDX = np.where(distances[k,]>0.95)[0][:]\n        o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \n# del imagefeat, imgmodel","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:01:58.132852Z","start_time":"2021-03-18T10:01:56.678412Z"},"trusted":true},"cell_type":"code","source":"train['oof_cnn'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# title TFIDF"},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:02:00.631468Z","start_time":"2021-03-18T10:01:59.851964Z"},"trusted":true},"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embeddings = model.fit_transform(train_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:05:46.252393Z","start_time":"2021-03-18T10:02:01.803979Z"},"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)//CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        # IDX = np.where(cts[k,]>0.7)[0]\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel model, text_embeddings","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:03.146166Z","start_time":"2021-03-18T10:06:01.83687Z"},"trusted":true},"cell_type":"code","source":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:04.931476Z","start_time":"2021-03-18T10:06:04.925838Z"},"trusted":true},"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:09.759812Z","start_time":"2021-03-18T10:06:05.955972Z"},"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    train['f1'] = train.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train.f1.mean() )\n\ntrain['matches'] = train.apply(combine_for_sub,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-03-18T10:06:12.385916Z","start_time":"2021-03-18T10:06:12.180234Z"},"trusted":true},"cell_type":"code","source":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}