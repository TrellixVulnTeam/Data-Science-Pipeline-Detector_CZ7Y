{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport math\nimport random\nimport os \nimport cv2\nimport timm\n\nfrom tqdm.notebook import tqdm \n\nimport albumentations as A \nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch \nfrom torch.utils.data import Dataset \nfrom torch import nn\nimport torch.nn.functional as F \n\nimport gc\nimport cudf\nimport cuml\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n#     img_size = 512\n    batch_size = 4\n    seed = 1\n    device = 'cuda'\n#     classes = 11014\n    model_name = 'tf_mobilenetv3_small_minimal_100' # 'resnext50_32x4d'\n#     model_path = '../input/shopee-pytorch-models/arcface_512x512_resnext32x4d.pt'\n#     scale = 30 \n#     margin = 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    model = timm.create_model(CFG.model_name, pretrained=False)\n    model.load_state_dict(torch.load('../input/timm-pretrained-mobilenetv3/mobilenetv3/tf_mobilenetv3_small_minimal_100-922a7843.pth'))\n    model.eval()\n    model = model.to(CFG.device)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.image_paths.shape[0]\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_transforms():\n    return A.Compose(\n        [\n            A.SmallestMaxSize(256),\n            A.CenterCrop(224, 224),\n            A.Normalize(),\n            ToTensorV2(p=1.0)\n        ]\n    )\n\ndef get_image_embeddings(image_paths):\n    embeds = []\n    \n    model = create_model()\n    \n    image_dataset = ShopeeDataset(image_paths=image_paths, transforms=get_test_transforms())\n    image_loader = torch.utils.data.DataLoader(\n        image_dataset,\n        batch_size=CFG.batch_size,\n        pin_memory=True,\n        drop_last=False,\n        num_workers=4\n    )\n    \n    with torch.no_grad():\n        for img in tqdm(image_loader): \n            img = img.cuda()\n            feat = model.forward_features(img)\n#             print(feat.shape)\n            feat = feat.squeeze()\n            image_embeddings = feat.detach().cpu().numpy()\n            embeds.append(image_embeddings)\n    \n    del model\n    image_embeddings = np.concatenate(embeds)\n    print(f'Our image embeddings shape is {image_embeddings.shape}')\n    del embeds\n    gc.collect()\n    return image_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dataset():\n    df = pd.read_csv('../input/shopee-product-matching/test.csv')\n#     df = pd.concat([df]*30000, ignore_index=True)\n    df_cu = cudf.DataFrame(df)\n    image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n    return df, df_cu, image_paths","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n    return ' '.join( np.unique(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\ndef get_image_predictions(df, embeddings, threshold=0.2*math.pi):\n    if len(df) > 3:\n        KNN = 50\n    else : \n        KNN = 3\n    \n    model = NearestNeighbors(n_neighbors = KNN, metric='cosine')\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n#     print(distances)\n#     print(indices)\n    \n    predictions = []\n    for k in tqdm(range(embeddings.shape[0])):\n        idx = np.where(distances[k,] < threshold)[0]\n        ids = indices[k, idx]\n        posting_ids = df['posting_id'].iloc[ids].values\n        predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_predictions(df, max_features = 25_000):\n    \n    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    preds = []\n    CHUNK = 1024*4\n\n    print('Finding similar titles...')\n    CTS = len(df)//CHUNK\n    if len(df)%CHUNK!=0: CTS += 1\n    for j in range( CTS ):\n\n        a = j*CHUNK\n        b = (j+1)*CHUNK\n        b = min(b,len(df))\n        print('chunk',a,'to',b)\n\n        # COSINE SIMILARITY DISTANCE\n        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n\n        for k in range(b - a):\n            IDX = cupy.where(cts[k,] > 0.75)[0]\n            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n            preds.append(o)\n    \n    del model,text_embeddings\n    gc.collect()\n    return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, df_cu, image_paths = read_dataset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings = get_image_embeddings(image_paths.values)\nimage_predictions = get_image_predictions(df, image_embeddings)\ntext_predictions = get_text_predictions(df, max_features = 25_000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['image_predictions'] = image_predictions\ndf['text_predictions'] = text_predictions\ndf['matches'] = df.apply(combine_predictions, axis = 1)\ndf[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.read_csv('./submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}