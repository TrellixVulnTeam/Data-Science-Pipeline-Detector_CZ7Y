{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"模式识别大作业之商品分类_黄国正_20210529\n\n说明：本笔记为PCbighomework_main_hgz的补充，用神经网络方法进一步处理图像信息并进行分类。文本分类和图像分类的大部分方法实现和调参见PCbighomework_main_hgz；综合文本和图像信息的方法见PCbighomework_mix_hgz","metadata":{}},{"cell_type":"markdown","source":"声明：本笔记在kaggle提供的GPU加速器环境下执行速度较快，如采用CPU可能花费较长时间；需预安装imutils包","metadata":{}},{"cell_type":"code","source":"pip install imutils","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:47.504538Z","iopub.execute_input":"2021-05-29T07:29:47.505013Z","iopub.status.idle":"2021-05-29T07:29:52.916547Z","shell.execute_reply.started":"2021-05-29T07:29:47.504962Z","shell.execute_reply":"2021-05-29T07:29:52.915533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n#加载所有需要的包\n#数据处理\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#绘图读图\nimport matplotlib.pyplot as plt # plt 用于显示图片\nimport matplotlib.image as mpimg # mpimg 用于读取图片\nimport matplotlib\n%matplotlib inline\nimport seaborn as sns\n\n#学习\nfrom sklearn.model_selection import train_test_split#划分数据集\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n#神经网络keras工具\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import img_to_array\n\n#图像&文件处理\nfrom imutils import paths\nimport argparse\nimport random\nimport pickle\nimport cv2\nimport os\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nprint(\"Set up complete!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:52.918512Z","iopub.execute_input":"2021-05-29T07:29:52.918882Z","iopub.status.idle":"2021-05-29T07:29:52.934078Z","shell.execute_reply.started":"2021-05-29T07:29:52.918842Z","shell.execute_reply":"2021-05-29T07:29:52.932655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#读取数据\ntotaldata = pd.read_csv(\"../input/shopee-product-matching/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:52.936513Z","iopub.execute_input":"2021-05-29T07:29:52.937125Z","iopub.status.idle":"2021-05-29T07:29:53.04058Z","shell.execute_reply.started":"2021-05-29T07:29:52.937075Z","shell.execute_reply":"2021-05-29T07:29:53.039669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#测试集划分\nx_train,x_test, y_train, y_test = train_test_split(totaldata,totaldata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:53.042897Z","iopub.execute_input":"2021-05-29T07:29:53.043149Z","iopub.status.idle":"2021-05-29T07:29:53.063153Z","shell.execute_reply.started":"2021-05-29T07:29:53.043124Z","shell.execute_reply":"2021-05-29T07:29:53.062279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#超小测试样本及划分\ntoydata=totaldata[0:100]\n#将toydata中所有标签的样本提取出来，这将大大提升准确率\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)\n#超小测试图像样本及划分\ntoyimagedata=toydata[['image','label_group']]\ntimagex_train,timagex_test, timagey_train, timagey_test = train_test_split(toyimagedata,toyimagedata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:53.06592Z","iopub.execute_input":"2021-05-29T07:29:53.066163Z","iopub.status.idle":"2021-05-29T07:29:53.079776Z","shell.execute_reply.started":"2021-05-29T07:29:53.066139Z","shell.execute_reply":"2021-05-29T07:29:53.078992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#自训练小型VGG网络\nclass SmallerVGGNet:\n    @staticmethod\n    def build(width, height, depth, classes, finalAct=\"softmax\"):\n        # initialize the model along with the input shape to be\n        # \"channels last\" and the channels dimension itself\n        model = Sequential()\n        inputShape = (height, width, depth)\n        chanDim = -1\n \n        # if we are using \"channels first\", update the input shape\n        # and channels dimension\n        if K.image_data_format() == \"channels_first\":\n            inputShape = (depth, height, width)\n            chanDim = 1\n            \n                # CONV => RELU => POOL\n        model.add(Conv2D(32, (3, 3), padding=\"same\",\n            input_shape=inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(3, 3)))\n        model.add(Dropout(0.25))\n        \n        # (CONV => RELU) * 2 => POOL\n        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n \n        # (CONV => RELU) * 2 => POOL\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n         # first (and only) set of FC => RELU layers\n        model.add(Flatten())\n        model.add(Dense(1024))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n \n        # use a *softmax* activation for single-label classification\n        # and *sigmoid* activation for multi-label classification\n        model.add(Dense(classes))\n        model.add(Activation(finalAct))\n \n        # return the constructed network architecture\n        return model","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:53.081077Z","iopub.execute_input":"2021-05-29T07:29:53.081447Z","iopub.status.idle":"2021-05-29T07:29:53.094031Z","shell.execute_reply.started":"2021-05-29T07:29:53.081413Z","shell.execute_reply":"2021-05-29T07:29:53.093159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#参数设置，可调整\n# initialize the number of epochs to train for, initial learning rate,\n# batch size, and image dimensions\nEPOCHS = 75\nINIT_LR = 1e-3\nBS = 32\nIMAGE_DIMS = (512, 512, 3)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:53.095257Z","iopub.execute_input":"2021-05-29T07:29:53.095756Z","iopub.status.idle":"2021-05-29T07:29:53.106593Z","shell.execute_reply.started":"2021-05-29T07:29:53.09572Z","shell.execute_reply":"2021-05-29T07:29:53.105699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#读取图片\nprint(\"[INFO] loading images...\")\nimagePaths = []\nfor i in range(len(toyimagedata)):\n    imagePaths.append('../input/shopee-product-matching/train_images/'+toyimagedata.image[toyimagedata.index[i]])\n# initialize the data and labels\ndata = []\nlabels = []\n# loop over the input images\nfor imagePath in imagePaths:\n    # load the image, pre-process it, and store it in the data list\n    image = cv2.imread(imagePath)\n    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n    image = img_to_array(image)\n    data.append(image)\n    # extract set of class labels from the image path and update the\n    # labels list\nlabels=toyimagedata.label_group\nprint('Ok')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:53.109245Z","iopub.execute_input":"2021-05-29T07:29:53.109835Z","iopub.status.idle":"2021-05-29T07:29:57.934868Z","shell.execute_reply.started":"2021-05-29T07:29:53.1098Z","shell.execute_reply":"2021-05-29T07:29:57.933987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#数据读取转化清洗\n# scale the raw pixel intensities to the range [0, 1]\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\nlabels=labels.reshape(-1,1)\nprint(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n    len(imagePaths), data.nbytes / (1024 * 1000.0)))\n\n# binarize the labels using scikit-learn's special multi-label\n# binarizer implementation\n# print(\"[INFO] class labels:\")\nmlb = MultiLabelBinarizer()\nlabels = mlb.fit_transform(labels)\n\n# loop over each of the possible class labels and show them\n# for (i, label) in enumerate(mlb.classes_):\n#     print(\"{}. {}\".format(i + 1, label))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:57.936399Z","iopub.execute_input":"2021-05-29T07:29:57.936742Z","iopub.status.idle":"2021-05-29T07:29:59.012253Z","shell.execute_reply.started":"2021-05-29T07:29:57.936706Z","shell.execute_reply":"2021-05-29T07:29:59.011112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#数据处理设置\n# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(trainX, testX, trainY, testY) = train_test_split(data,\n    labels, test_size=0.2, random_state=42)\n \n# construct the image generator for data augmentation\naug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n    horizontal_flip=True, fill_mode=\"nearest\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:29:59.013694Z","iopub.execute_input":"2021-05-29T07:29:59.01405Z","iopub.status.idle":"2021-05-29T07:30:01.227651Z","shell.execute_reply.started":"2021-05-29T07:29:59.014009Z","shell.execute_reply":"2021-05-29T07:30:01.222592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#模型训练，100个标签用GPU需半小时，CPU更长\n# initialize the model using a sigmoid activation as the final layer\n# in the network so we can perform multi-label classification\nprint(\"[INFO] compiling model...\")\nmodel = SmallerVGGNet.build(\n    width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n    depth=IMAGE_DIMS[2], classes=len(mlb.classes_),\n    finalAct=\"sigmoid\")\n \n# initialize the optimizer\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n# compile the model using binary cross-entropy rather than\n# categorical cross-entropy -- this may seem counterintuitive for\n# multi-label classification, but keep in mind that the goal here\n# is to treat each output label as an independent Bernoulli\n# distribution\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])\n \n# train the network\nprint(\"[INFO] training network...\")\nH = model.fit(\n    aug.flow(trainX, trainY, batch_size=BS),\n    validation_data=(testX, testY),\n    steps_per_epoch=len(trainX) // BS,\n    epochs=EPOCHS, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:30:01.23272Z","iopub.execute_input":"2021-05-29T07:30:01.233086Z","iopub.status.idle":"2021-05-29T07:32:01.892818Z","shell.execute_reply.started":"2021-05-29T07:30:01.23305Z","shell.execute_reply":"2021-05-29T07:32:01.891954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#绘制结果图\npd.plotting.register_matplotlib_converters()\n\nprint(\"Setup Complete\")\n# Set the width and height of the figure\nplt.figure(figsize=(16,6))\n# Line chart showing how FIFA rankings evolved over time \nplt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"SmallerVGGNet Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T07:32:01.901749Z","iopub.execute_input":"2021-05-29T07:32:01.902093Z","iopub.status.idle":"2021-05-29T07:32:02.138227Z","shell.execute_reply.started":"2021-05-29T07:32:01.902054Z","shell.execute_reply":"2021-05-29T07:32:02.137477Z"},"trusted":true},"execution_count":null,"outputs":[]}]}