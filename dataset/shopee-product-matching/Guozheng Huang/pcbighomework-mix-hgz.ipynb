{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"模式识别大作业之商品分类_黄国正_20210529\n\n说明：本笔记为PCbighomework_main_hgz的补充，整合了其中表现最好的文本信息特征TF-IDF和最好的图像信息处理SIFT，并用对应方法进行进一步处理和评估。文本分类和图像分类的大部分方法实现和调参见PCbighomework_main_hgz；采用神经网络的方法见PCbighomework_network_hgz","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#加载所有需要的包\n#数据处理\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\n#绘图读图\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg \nimport seaborn as sns\n\n#学习\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC,SVC\nimport sklearn.svm as svm\nfrom sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score,roc_auc_score,average_precision_score\nfrom sklearn import neighbors\nfrom sklearn import datasets\nfrom sklearn.datasets import load_digits,load_boston\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor,VotingClassifier,RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import preprocessing\n\n#文本处理\nimport spacy\nfrom spacy.util import minibatch, compounding\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#图像处理\nimport os\nimport cv2\nimport glob\nimport joblib\n#执行代码时尽量从前往后执行，避免因重复命名报错\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nprint(\"Set up complete!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:27:35.377024Z","iopub.execute_input":"2021-05-29T06:27:35.379074Z","iopub.status.idle":"2021-05-29T06:27:37.461211Z","shell.execute_reply.started":"2021-05-29T06:27:35.378475Z","shell.execute_reply":"2021-05-29T06:27:37.460018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"综合文本和图片信息进行分类改进","metadata":{}},{"cell_type":"code","source":"#加载全部数据\ntotaldata = pd.read_csv(\"../input/shopee-product-matching/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:28:42.501717Z","iopub.execute_input":"2021-05-29T06:28:42.502261Z","iopub.status.idle":"2021-05-29T06:28:42.967282Z","shell.execute_reply.started":"2021-05-29T06:28:42.502228Z","shell.execute_reply":"2021-05-29T06:28:42.966284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TF-IDF模型\n#超小测试样本及划分\ntoydata=totaldata[0:100]\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)\n#超小测试文本样本及划分\ntoytextdata=toydata[['title','label_group']]\nttextx_train,ttextx_test, ttexty_train, ttexty_test = train_test_split(toytextdata,toytextdata.label_group,test_size=0.3, random_state=0)\n#tiidf特征提取\ncount_vec = TfidfVectorizer(binary=False, decode_error='ignore', stop_words='english')\nresponse = count_vec.fit_transform(ttextx_train.title) # s must be string\ntrainfeature = response.toarray()\nresponse = count_vec.transform(ttextx_test.title) # s must be string\ntestfeature = response.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:30:12.333532Z","iopub.execute_input":"2021-05-29T06:30:12.333934Z","iopub.status.idle":"2021-05-29T06:30:12.365649Z","shell.execute_reply.started":"2021-05-29T06:30:12.333902Z","shell.execute_reply":"2021-05-29T06:30:12.364799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TF-IDF特征上做SVM预测，为了生成概率预测，没有采用线性SVC\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score,roc_auc_score,average_precision_score\n# Set dual=False to speed up training, and it's not needed\nclf = svm.SVC(random_state=1,  max_iter=10000,probability=True)\nclf.fit(trainfeature, ttexty_train)\nprint(f\"TF-IDF SVM Accuracy: {clf.score(testfeature,ttexty_test) * 100:.3f}%\", )\nprint(f\"TF-IDF SVM Precision score: {precision_score(ttexty_test,clf.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF SVM Recall score: {recall_score(ttexty_test,clf.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF SVM F1 score: {f1_score(ttexty_test,clf.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:43:46.934042Z","iopub.execute_input":"2021-05-29T06:43:46.934428Z","iopub.status.idle":"2021-05-29T06:43:48.142423Z","shell.execute_reply.started":"2021-05-29T06:43:46.934395Z","shell.execute_reply":"2021-05-29T06:43:48.141309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#图像数据\n#超小测试图像样本及划分\ntoyimagedata=toydata[['image','label_group']]\ntimagex_train,timagex_test, timagey_train, timagey_test = train_test_split(toyimagedata,toyimagedata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:34:03.89682Z","iopub.execute_input":"2021-05-29T06:34:03.897248Z","iopub.status.idle":"2021-05-29T06:34:03.905636Z","shell.execute_reply.started":"2021-05-29T06:34:03.89721Z","shell.execute_reply":"2021-05-29T06:34:03.904464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SIFT特征提取，时间较长\ndef calcSiftFeature(img):\n    #设置图像sift特征关键点最大为200\n    sift = cv2.SIFT_create()\n    #计算图片的特征点和特征点描述\n    keypoints, features = sift.detectAndCompute(img, None)\n    return features\n\n#计算词袋\ndef learnVocabulary(features):\n    wordCnt = 50\n    #criteria表示迭代停止的模式   eps---精度0.1，max_iter---满足超过最大迭代次数20\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.1)\n    #得到k-means聚类的初始中心点\n    flags = cv2.KMEANS_RANDOM_CENTERS\n    # 标签，中心 = kmeans(输入数据（特征)、聚类的个数K,预设标签，聚类停止条件、重复聚类次数、初始聚类中心点\n    compactness, labels, centers = cv2.kmeans(features, wordCnt, None,criteria, 20, flags)\n    return centers\n\ndef calcFeatVec(features, centers):\n    featVec = np.zeros((1, 50))\n    for i in range(0, features.shape[0]):\n        #第i张图片的特征点\n        fi = features[i]\n        diffMat = np.tile(fi, (50, 1)) - centers\n        #axis=1按行求和，即求特征到每个中心点的距离\n        sqSum = (diffMat**2).sum(axis=1)\n        dist = sqSum**0.5\n        #升序排序\n        sortedIndices = dist.argsort()\n        #取出最小的距离，即找到最近的中心点\n        idx = sortedIndices[0]\n        #该中心点对应+1\n        featVec[0][idx] += 1\n    return featVec\n\nfeatures = np.float32([]).reshape(0, 128)#存放训练集图片的特征\nfor i in range(len(toyimagedata)):\n    img = cv2.imread('../input/shopee-product-matching/train_images/'+toyimagedata.image[toyimagedata.index[i]])\n    #获取图片sift特征点\n    img_f = calcSiftFeature(img)\n    #特征点加入训练数据\n    features = np.append(features, img_f, axis=0)\n#训练集的词袋\ncenters = learnVocabulary(features)\n\ndata_vec = np.float32([]).reshape(0, 50)#存放训练集图片的特征\nlabels = np.float32([])\nfor i in range(len(toyimagedata)):\n    img = cv2.imread('../input/shopee-product-matching/train_images/'+toyimagedata.image[toyimagedata.index[i]])\n    img_f = calcSiftFeature(img)\n    img_vec = calcFeatVec(img_f, centers)\n    data_vec = np.append(data_vec,img_vec,axis=0)\n    labels = np.append(labels,toyimagedata.label_group[toyimagedata.index[i]])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:34:34.13132Z","iopub.execute_input":"2021-05-29T06:34:34.131707Z","iopub.status.idle":"2021-05-29T06:42:14.389641Z","shell.execute_reply.started":"2021-05-29T06:34:34.131676Z","shell.execute_reply":"2021-05-29T06:42:14.388433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization,可调整\ntt=data_vec\ndata_vec = preprocessing.normalize(tt, norm='l2')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:42:45.49372Z","iopub.execute_input":"2021-05-29T06:42:45.49413Z","iopub.status.idle":"2021-05-29T06:42:45.499547Z","shell.execute_reply.started":"2021-05-29T06:42:45.494097Z","shell.execute_reply":"2021-05-29T06:42:45.498577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sift数据划分\ntsiftdatax_train, tsiftdatax_test, tsiftdatay_train, tsiftdatay_test = train_test_split(data_vec, labels,\n                                                    test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:42:47.329856Z","iopub.execute_input":"2021-05-29T06:42:47.33026Z","iopub.status.idle":"2021-05-29T06:42:47.33639Z","shell.execute_reply.started":"2021-05-29T06:42:47.330227Z","shell.execute_reply":"2021-05-29T06:42:47.335675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sift上做SVM预测\nclf2 = svm.SVC(random_state=1, max_iter=10000,probability=True)\nclf2.fit(tsiftdatax_train, tsiftdatay_train)\nprint(f\"SIFT SVM Accuracy: {accuracy_score(tsiftdatay_test,clf2.predict(tsiftdatax_test)) * 100:.3f}%\", )\nprint(f\"SIFT SVM Precision score: {precision_score(tsiftdatay_test,clf2.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT SVM Recall score: {recall_score(tsiftdatay_test,clf2.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT SVM F1 score: {f1_score(tsiftdatay_test,clf2.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:42:49.118354Z","iopub.execute_input":"2021-05-29T06:42:49.118869Z","iopub.status.idle":"2021-05-29T06:42:49.492254Z","shell.execute_reply.started":"2021-05-29T06:42:49.118835Z","shell.execute_reply":"2021-05-29T06:42:49.491492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"现在我们已有基于TF-IDF的SVM模型和基于SIFT的SVM模型，我们想利用其概率预测的并集生成新的判断模型，在这之前我们先用SIFT进行实验","metadata":{}},{"cell_type":"code","source":"label=np.unique(tsiftdatay_train)\n\nprobsift = clf2.predict_proba(tsiftdatax_test)\n#用概率生成预测\nidxsift = np.argmax(probsift, axis=1)\nprosift = np.amax(probsift, axis=1)\npredictsift = label[idxsift]\nprint(f\"SIFT SVM Recall score: {recall_score(tsiftdatay_test,predictsift ,average='macro',zero_division=0) * 100:.3f}%\", )\n#类别不连续，predict_prob最高的标签不一定是predict标签\nsum(predictsift==clf2.predict(tsiftdatax_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:42:52.832694Z","iopub.execute_input":"2021-05-29T06:42:52.833135Z","iopub.status.idle":"2021-05-29T06:42:52.934406Z","shell.execute_reply.started":"2021-05-29T06:42:52.833097Z","shell.execute_reply":"2021-05-29T06:42:52.933201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现用模型生成的概率来推断的标签和直接由模型给出的标签并不相同，这可能是标签不连续导致出现了未曾训练过的新标签造成的，因此之后取并集时需要注意这一点进行灵活预测","metadata":{}},{"cell_type":"markdown","source":"下面我们在不同的方法上对TF-IDF和SIFT的分类模型进行整合；通常选取两模型中预测概率更高的标签，但如果出现概率选择与预测标签不一致的情况，我们直接选择TF-IDF的标签。对SVM、KNN、决策树决策森林、Adaboost方法我们都可以取并集并给出结果。","metadata":{}},{"cell_type":"code","source":"#TF-IDF与SIFT SVM并集\nlabel=np.unique(tsiftdatay_train)\n\nprobtf = clf.predict_proba(testfeature)\n#用概率生成预测\nidxtf = np.argmax(probtf, axis=1)\nprotf = np.amax(probtf, axis=1)\n\n\nprobsift = clf2.predict_proba(tsiftdatax_test)\n#用概率生成预测\nidxsift = np.argmax(probsift, axis=1)\nprosift = np.amax(probsift, axis=1)\npredictsift = label[idxsift]\n\n#结合生成新的预测，考虑到predict_prob不如predict效果好，不同时我们只采用TF-IDF模型的predict值\npredictcombine=np.zeros(idxsift.shape[0])\nfor i in range(idxsift.shape[0]):\n    #出现不一致，只考虑TF-IDF\n    if(label[idxtf[i]]!=clf.predict(testfeature)[i] or label[idxsift[i]]!=clf2.predict(tsiftdatax_test)[i]):\n        predictcombine[i]=clf.predict(testfeature)[i]\n    else:\n        if(protf[i]>prosift[i]):\n            predictcombine[i]=label[idxtf[i]]\n        else:\n            predictcombine[i]=label[idxsift[i]]\n#打印准确率，测试集相同\nprint(f\"Combining TF-IDF&SIFT SVM Accuracy score: {accuracy_score(tsiftdatay_test,predictcombine) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT SVM Precision score: {precision_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT SVM Recall score: {recall_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT SVM F1 score: {f1_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:46:06.075079Z","iopub.execute_input":"2021-05-29T06:46:06.075432Z","iopub.status.idle":"2021-05-29T06:46:15.507414Z","shell.execute_reply.started":"2021-05-29T06:46:06.075404Z","shell.execute_reply":"2021-05-29T06:46:15.506667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN分析合并\n\n#TF-IDF特征上做knn分析\nfrom sklearn import neighbors\nfrom sklearn import datasets\n#参数k可训练\nfor k in [3,4,5,6,7,8,9,10,11,12]:\n    print(\"k=\"+str(k))\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n    clf.fit(trainfeature, ttexty_train)\n    clf2 = neighbors.KNeighborsClassifier(n_neighbors=k)\n    clf2.fit(tsiftdatax_train, tsiftdatay_train)\n    label=np.unique(tsiftdatay_train)\n\n    probtf = clf.predict_proba(testfeature)\n    #用概率生成预测\n    idxtf = np.argmax(probtf, axis=1)\n    protf = np.amax(probtf, axis=1)\n\n\n    probsift = clf2.predict_proba(tsiftdatax_test)\n    #用概率生成预测\n    idxsift = np.argmax(probsift, axis=1)\n    prosift = np.amax(probsift, axis=1)\n    predictsift = label[idxsift]\n\n    #结合生成新的预测，考虑到predict_prob不如predict效果好，不同时我们只采用TF-IDF模型的predict值\n    predictcombine=np.zeros(idxsift.shape[0])\n    for i in range(idxsift.shape[0]):\n        #出现不一致，只考虑TF-IDF\n        if(label[idxtf[i]]!=clf.predict(testfeature)[i] or label[idxsift[i]]!=clf2.predict(tsiftdatax_test)[i]):\n            predictcombine[i]=clf.predict(testfeature)[i]\n        else:\n            if(protf[i]>prosift[i]):\n                predictcombine[i]=label[idxtf[i]]\n            else:\n                predictcombine[i]=label[idxsift[i]]\n    #打印准确率，测试集相同\n    print(f\"Combining TF-IDF&SIFT KNN Accuracy score: {accuracy_score(tsiftdatay_test,predictcombine) * 100:.3f}%\", )\n    print(f\"Combining TF-IDF&SIFT KNN Precision score: {precision_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Combining TF-IDF&SIFT KNN Recall score: {recall_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Combining TF-IDF&SIFT KNN F1 score: {f1_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:14:07.589383Z","iopub.execute_input":"2021-05-28T12:14:07.589668Z","iopub.status.idle":"2021-05-28T12:14:45.739906Z","shell.execute_reply.started":"2021-05-28T12:14:07.589642Z","shell.execute_reply":"2021-05-28T12:14:45.738862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时KNN选取参数k=3效果最好","metadata":{}},{"cell_type":"code","source":"#决策树和随机森林合并\n#TF-IDF\ndt = DecisionTreeClassifier(random_state=1)\ndt.fit(trainfeature, ttexty_train)\nrf = RandomForestClassifier(random_state=1)\nrf.fit(trainfeature, ttexty_train)\n#基于SIFT决策树和随机森林\ndt2 = DecisionTreeClassifier(random_state=1)\ndt2.fit(tsiftdatax_train, tsiftdatay_train)\nrf2 = RandomForestClassifier(random_state=1)\nrf2.fit(tsiftdatax_train, tsiftdatay_train)\n#合并dt\nlabel=np.unique(tsiftdatay_train)\n\nprobtf = dt.predict_proba(testfeature)\n#用概率生成预测\nidxtf = np.argmax(probtf, axis=1)\nprotf = np.amax(probtf, axis=1)\n\n\nprobsift = dt2.predict_proba(tsiftdatax_test)\n#用概率生成预测\nidxsift = np.argmax(probsift, axis=1)\nprosift = np.amax(probsift, axis=1)\npredictsift = label[idxsift]\n\n#结合生成新的预测，考虑到predict_prob不如predict效果好，不同时我们只采用TF-IDF模型的predict值\npredictcombine=np.zeros(idxsift.shape[0])\nfor i in range(idxsift.shape[0]):\n    #出现不一致，只考虑TF-IDF\n    if(label[idxtf[i]]!=dt.predict(testfeature)[i] or label[idxsift[i]]!=dt2.predict(tsiftdatax_test)[i]):\n        predictcombine[i]=dt.predict(testfeature)[i]\n    else:\n        if(protf[i]>prosift[i]):\n            predictcombine[i]=label[idxtf[i]]\n        else:\n            predictcombine[i]=label[idxsift[i]]\n#打印准确率，测试集相同\nprint(f\"Combining TF-IDF&SIFT DecisionTree Accuracy score: {accuracy_score(tsiftdatay_test,predictcombine) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT DecisionTree Precision score: {precision_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT DecisionTree Recall score: {recall_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT DecisionTree F1 score: {f1_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\n#合并rf\nlabel=np.unique(tsiftdatay_train)\n\nprobtf = rf.predict_proba(testfeature)\n#用概率生成预测\nidxtf = np.argmax(probtf, axis=1)\nprotf = np.amax(probtf, axis=1)\n\n\nprobsift = rf2.predict_proba(tsiftdatax_test)\n#用概率生成预测\nidxsift = np.argmax(probsift, axis=1)\nprosift = np.amax(probsift, axis=1)\npredictsift = label[idxsift]\n\n#结合生成新的预测，考虑到predict_prob不如predict效果好，不同时我们只采用TF-IDF模型的predict值\npredictcombine=np.zeros(idxsift.shape[0])\nfor i in range(idxsift.shape[0]):\n    #出现不一致，只考虑TF-IDF\n    if(label[idxtf[i]]!=rf.predict(testfeature)[i] or label[idxsift[i]]!=rf2.predict(tsiftdatax_test)[i]):\n        predictcombine[i]=rf.predict(testfeature)[i]\n    else:\n        if(protf[i]>prosift[i]):\n            predictcombine[i]=label[idxtf[i]]\n        else:\n            predictcombine[i]=label[idxsift[i]]\n#打印准确率，测试集相同\nprint(f\"Combining TF-IDF&SIFT RandomForest Accuracy score: {accuracy_score(tsiftdatay_test,predictcombine)* 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT RandomForest Precision score: {precision_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT RandomForest Recall score: {recall_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Combining TF-IDF&SIFT RandomForest F1 score: {f1_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:47:35.153472Z","iopub.execute_input":"2021-05-29T06:47:35.153873Z","iopub.status.idle":"2021-05-29T06:47:41.536838Z","shell.execute_reply.started":"2021-05-29T06:47:35.153841Z","shell.execute_reply":"2021-05-29T06:47:41.535746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"可见合并后的随机森林准确率有质的提升，体现出文本图像信息综合利用的优点。这也是我们最终展示的模型之一。","metadata":{}},{"cell_type":"code","source":"#adaboost合并\n\nfor l in [0.01,0.1,0.3,0.5,1]:\n    print(\"learning rate=\"+str(l))\n    #TF-IDF\n    ab = AdaBoostClassifier(learning_rate=l,base_estimator=DecisionTreeClassifier(),random_state=1)\n    ab.fit(trainfeature, ttexty_train)\n\n    #SIFT\n    ab2 = AdaBoostClassifier(learning_rate=l,base_estimator=DecisionTreeClassifier(),random_state=1)\n    ab2.fit(tsiftdatax_train, tsiftdatay_train)\n\n    #合并ab\n    label=np.unique(tsiftdatay_train)\n\n    probtf = ab.predict_proba(testfeature)\n    #用概率生成预测\n    idxtf = np.argmax(probtf, axis=1)\n    protf = np.amax(probtf, axis=1)\n\n\n    probsift = ab2.predict_proba(tsiftdatax_test)\n    #用概率生成预测\n    idxsift = np.argmax(probsift, axis=1)\n    prosift = np.amax(probsift, axis=1)\n    predictsift = label[idxsift]\n\n    #结合生成新的预测，考虑到predict_prob不如predict效果好，不同时我们只采用TF-IDF模型的predict值\n    predictcombine=np.zeros(idxsift.shape[0])\n    for i in range(idxsift.shape[0]):\n        #出现不一致，只考虑TF-IDF\n        if(label[idxtf[i]]!=ab.predict(testfeature)[i] or label[idxsift[i]]!=ab2.predict(tsiftdatax_test)[i]):\n            predictcombine[i]=ab.predict(testfeature)[i]\n        else:\n            if(protf[i]>prosift[i]):\n                predictcombine[i]=label[idxtf[i]]\n            else:\n                predictcombine[i]=label[idxsift[i]]\n    #打印准确率，测试集相同\n    print(f\"Combining TF-IDF&SIFT AdaBoost Accuracy score: {accuracy_score(tsiftdatay_test,predictcombine) * 100:.3f}%\", )\n    print(f\"Combining TF-IDF&SIFT AdaBoost Precision score: {precision_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Combining TF-IDF&SIFT AdaBoost Recall score: {recall_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Combining TF-IDF&SIFT AdaBoost F1 score: {f1_score(tsiftdatay_test,predictcombine,average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:54:55.245799Z","iopub.execute_input":"2021-05-29T06:54:55.246217Z","iopub.status.idle":"2021-05-29T06:54:56.980678Z","shell.execute_reply.started":"2021-05-29T06:54:55.246184Z","shell.execute_reply":"2021-05-29T06:54:56.979632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时Adaboost的学习率对其无影响","metadata":{}},{"cell_type":"markdown","source":"综上，我们结合文本特征TF-IDF和图像处理SIFT的不同模型整合出了新的分类器，希望综合文本和图像分类的优点给出更好的判断。准确率确实有较大提升，尤其是随机森林，效果已经可以应用。更多文本图像综合处理的方法还有待进一步研究。","metadata":{}}]}