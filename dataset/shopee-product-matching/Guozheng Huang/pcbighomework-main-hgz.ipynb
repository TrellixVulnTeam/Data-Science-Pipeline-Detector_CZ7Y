{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"模式识别大作业之商品分类_黄国正_20210529\n\n说明：本笔记依托于kaggle比赛项目Shopee - Price Match Guarantee,使得读取数据更加方便。全部数据均来自Shopee数据集shopee-product-matching的训练集数据,加入比赛后可直接读取。\n\n本笔记实现了文本分类和图像分类的大部分方法实现；采用神经网络的方法见PCbighomework_network_hgz；文本图像结合的方法见PCbighomework_mix_hgz","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#加载所有需要的包\n#数据处理\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\n#绘图读图\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg \nimport seaborn as sns\n\n#学习\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC,SVC\nimport sklearn.svm as svm\nfrom sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score,roc_auc_score,average_precision_score\nfrom sklearn import neighbors\nfrom sklearn import datasets\nfrom sklearn.datasets import load_digits,load_boston\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor,VotingClassifier,RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import preprocessing\n\n#文本处理\nimport spacy\nfrom spacy.util import minibatch, compounding\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#图像处理\nimport os\nimport cv2\nimport glob\nimport joblib\n#执行代码时尽量从前往后执行，避免因重复命名报错\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nprint(\"Set up complete!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:47.09278Z","iopub.execute_input":"2021-05-29T06:13:47.093161Z","iopub.status.idle":"2021-05-29T06:13:47.108594Z","shell.execute_reply.started":"2021-05-29T06:13:47.09313Z","shell.execute_reply":"2021-05-29T06:13:47.107487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"一、数据整理","metadata":{}},{"cell_type":"code","source":"#加载全部数据，来自kaggle数据集shopee-product-matching（本地资源只需改变路径）\ntotaldata = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n#展示前几个数据，可以看到image为图片索引，phash为图片phash映射值，title为文本信息，\n#是我们之后要用到的信息量，最终有一个标签label_group，这一数值比较大而广，我们先观察一下其分布。\ntotaldata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:47.148211Z","iopub.execute_input":"2021-05-29T06:13:47.148723Z","iopub.status.idle":"2021-05-29T06:13:47.279625Z","shell.execute_reply.started":"2021-05-29T06:13:47.148691Z","shell.execute_reply":"2021-05-29T06:13:47.27873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#观察label_group的分布，用sns绘制各种图形进行可视化\ntotallabel=totaldata['label_group']\npd.plotting.register_matplotlib_converters()\n# Set the width and height of the figure\nplt.figure(figsize=(16,6))\nplt.title(\"label group\")\n# Line chart图 \nsns.lineplot(data=totallabel)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:47.281024Z","iopub.execute_input":"2021-05-29T06:13:47.281331Z","iopub.status.idle":"2021-05-29T06:13:49.789945Z","shell.execute_reply.started":"2021-05-29T06:13:47.281288Z","shell.execute_reply":"2021-05-29T06:13:49.789284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#散点图，发现标签比较均匀\nsns.scatterplot(data=totallabel)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:49.791292Z","iopub.execute_input":"2021-05-29T06:13:49.791662Z","iopub.status.idle":"2021-05-29T06:13:50.058033Z","shell.execute_reply.started":"2021-05-29T06:13:49.791632Z","shell.execute_reply":"2021-05-29T06:13:50.057306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#概率图\nsns.kdeplot(data=totallabel, shade=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.059356Z","iopub.execute_input":"2021-05-29T06:13:50.059642Z","iopub.status.idle":"2021-05-29T06:13:50.446778Z","shell.execute_reply.started":"2021-05-29T06:13:50.059612Z","shell.execute_reply":"2021-05-29T06:13:50.44589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#接着我们分析每个标签平均有几个样本在数据中，先取出唯一标签\nlabeluni=totallabel.unique()\n#输出标签长度，可以看出每个标签的平均样本数很少\nlen(labeluni)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.44795Z","iopub.execute_input":"2021-05-29T06:13:50.44824Z","iopub.status.idle":"2021-05-29T06:13:50.455896Z","shell.execute_reply.started":"2021-05-29T06:13:50.448197Z","shell.execute_reply":"2021-05-29T06:13:50.454987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#对唯一标签散点图，可以看到仍然很均匀\nsns.scatterplot(data=labeluni)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.45755Z","iopub.execute_input":"2021-05-29T06:13:50.457974Z","iopub.status.idle":"2021-05-29T06:13:50.651632Z","shell.execute_reply.started":"2021-05-29T06:13:50.457931Z","shell.execute_reply":"2021-05-29T06:13:50.65068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#概率图\nsns.kdeplot(data=labeluni, shade=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.653158Z","iopub.execute_input":"2021-05-29T06:13:50.653579Z","iopub.status.idle":"2021-05-29T06:13:50.917111Z","shell.execute_reply.started":"2021-05-29T06:13:50.653536Z","shell.execute_reply":"2021-05-29T06:13:50.91611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"关于每个标签对应样本少的解决方案：建立mini数据集时，将选定标签的所有样本加入训练集中，避免单一标签的样本过多；测试时也注意考虑测试集样本中出现训练集中没有标签的情况，进行相应的插值操作。经测试这一观察能大大提升准确率。","metadata":{}},{"cell_type":"code","source":"#进一步分析标签，对数据标签进行排序\ntotaldata.label_group.sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.920843Z","iopub.execute_input":"2021-05-29T06:13:50.921126Z","iopub.status.idle":"2021-05-29T06:13:50.932464Z","shell.execute_reply.started":"2021-05-29T06:13:50.921097Z","shell.execute_reply":"2021-05-29T06:13:50.93142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#观察标签相邻的样本，这里选择4294197112和4293276364\ntotaldata.loc[totaldata.label_group == 4293276364]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.934697Z","iopub.execute_input":"2021-05-29T06:13:50.935315Z","iopub.status.idle":"2021-05-29T06:13:50.947991Z","shell.execute_reply.started":"2021-05-29T06:13:50.935269Z","shell.execute_reply":"2021-05-29T06:13:50.946937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"totaldata.loc[totaldata.label_group == 4294197112]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.94961Z","iopub.execute_input":"2021-05-29T06:13:50.950012Z","iopub.status.idle":"2021-05-29T06:13:50.962974Z","shell.execute_reply.started":"2021-05-29T06:13:50.949971Z","shell.execute_reply":"2021-05-29T06:13:50.962129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现标签相邻并不代表物品类似；同时标签中还出现了印尼语，说明商品文本可能不适合进行英语模型的训练，需要注意","metadata":{}},{"cell_type":"markdown","source":"二、用文本信息进行分类预测","metadata":{}},{"cell_type":"markdown","source":"由于算力和kaggle笔记本的限制，之后的训练方法采用的数据均在原训练集中划分出toy数据集，按照之前的讨论，先确定标签个数，再在所有样本中找到这些标签的所有样本进行训练和测试。由于不同算法的速度不同，效果展示的标签个数略有不同，但可以调整，当扩大为全集长度时，toy数据集就是全训练集。","metadata":{}},{"cell_type":"code","source":"#超小测试样本及划分\ntoydata=totaldata[0:100]\n#将toydata中所有标签的样本提取出来，这将大大提升准确率\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.964091Z","iopub.execute_input":"2021-05-29T06:13:50.964601Z","iopub.status.idle":"2021-05-29T06:13:50.977831Z","shell.execute_reply.started":"2021-05-29T06:13:50.964559Z","shell.execute_reply":"2021-05-29T06:13:50.977168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#超小测试文本样本及划分\ntoytextdata=toydata[['title','label_group']]\nttextx_train,ttextx_test, ttexty_train, ttexty_test = train_test_split(toytextdata,toytextdata.label_group,test_size=0.1, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.979157Z","iopub.execute_input":"2021-05-29T06:13:50.979446Z","iopub.status.idle":"2021-05-29T06:13:50.987508Z","shell.execute_reply.started":"2021-05-29T06:13:50.979419Z","shell.execute_reply":"2021-05-29T06:13:50.986902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.Word embedding 方法：采用spacy中预训练好的模型，将文本数据映射成向量，并用于之后的分类","metadata":{}},{"cell_type":"code","source":"#word embedding 方法\n# Need to load the large model to get the vectors\nnlp = spacy.load('en_core_web_lg')\n# Disabling other pipes because we don't need them and it'll speed up this part a bit\nwith nlp.disable_pipes():\n    doc_vectors = np.array([nlp(text).vector for text in toytextdata.title])\n#数据划分\nttextdataemx_train, ttextdataemx_test, ttextdataemy_train, ttextdataemy_test = train_test_split(doc_vectors, toytextdata.label_group,\n                                                    test_size=0.3, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:13:50.989078Z","iopub.execute_input":"2021-05-29T06:13:50.98969Z","iopub.status.idle":"2021-05-29T06:14:02.498437Z","shell.execute_reply.started":"2021-05-29T06:13:50.98965Z","shell.execute_reply":"2021-05-29T06:14:02.497459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"之后我们调用sklearn中对应的包，对得到的embedding向量用SVM、KNN、决策树、随机森林、Adaboost、GradientBoosting、Voting等方法进行预测，并输出对应的准确率、召回率、F1 score等衡量预测效果的值。对其中一些方法还进行了参数调整，方便选取最优的模型。","metadata":{}},{"cell_type":"code","source":"#word embedding 上做SVM预测\n# Set dual=False to speed up training, and it's not needed\nsvc = LinearSVC(random_state=1, dual=False, max_iter=10000)\nsvc.fit(ttextdataemx_train, ttextdataemy_train)\nprint(f\"Embedding SVM Accuracy: {svc.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\nprint(f\"Embedding SVM Precision score: {precision_score(ttextdataemy_test,svc.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding SVM Recall score: {recall_score(ttextdataemy_test,svc.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding SVM F1 score: {f1_score(ttextdataemy_test,svc.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:14:02.499901Z","iopub.execute_input":"2021-05-29T06:14:02.500315Z","iopub.status.idle":"2021-05-29T06:14:03.093142Z","shell.execute_reply.started":"2021-05-29T06:14:02.500271Z","shell.execute_reply":"2021-05-29T06:14:03.092008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#word embedding 上做knn分析\n#参数k可调\nfor k in [3,4,5,6,7,8,9,10,11,12]:\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n    clf.fit(ttextdataemx_train, ttextdataemy_train)\n    print(\"k=\"+str(k))\n    print(f\"Embedding KNN Accuracy: {clf.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\n    print(f\"Embedding KNN Precision score: {precision_score(ttextdataemy_test,clf.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Embedding KNN Recall score: {recall_score(ttextdataemy_test,clf.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Embedding KNN F1 score: {f1_score(ttextdataemy_test,clf.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:14:03.094881Z","iopub.execute_input":"2021-05-29T06:14:03.09549Z","iopub.status.idle":"2021-05-29T06:14:03.703126Z","shell.execute_reply.started":"2021-05-29T06:14:03.09544Z","shell.execute_reply":"2021-05-29T06:14:03.702107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时KNN算法的最佳参数为k=3","metadata":{}},{"cell_type":"code","source":"#基于Embedding决策树和随机森林\n#决策树可调参criterion,splitter,max_depth等，此处略去\ndt = DecisionTreeClassifier(random_state=1)\ndt.fit(ttextdataemx_train,ttextdataemy_train)\nprint(f\"Embedding DecisionTree Accuracy: {dt.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\nprint(f\"Embedding DecisionTree Precision score: {precision_score(ttextdataemy_test,dt.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding DecisionTree Recall score: {recall_score(ttextdataemy_test,dt.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding DecisionTree F1 score: {f1_score(ttextdataemy_test,dt.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )\n#随机森林n_estimators可调，但n_estimators越大效果一般越好\nrf = RandomForestClassifier(random_state=1)\nrf.fit(ttextdataemx_train,ttextdataemy_train)\nprint(f\"Embedding RandomForest Accuracy: {rf.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\nprint(f\"Embedding RandomForest Precision score: {precision_score(ttextdataemy_test,rf.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding RandomForest Recall score: {recall_score(ttextdataemy_test,rf.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding RandomForest F1 score: {f1_score(ttextdataemy_test,rf.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:50:54.506747Z","iopub.execute_input":"2021-05-29T06:50:54.507272Z","iopub.status.idle":"2021-05-29T06:50:56.017329Z","shell.execute_reply.started":"2021-05-29T06:50:54.507209Z","shell.execute_reply":"2021-05-29T06:50:56.01615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adaboost\n#base_estimator可调整,n_estimators可调,learning_rate可调\nfor l in [0.01,0.1,0.3,0.5,1]:\n    print(\"learning rate=\"+str(l))\n    ab = AdaBoostClassifier(learning_rate=l,base_estimator=DecisionTreeClassifier(),random_state=1)\n    ab.fit(ttextdataemx_train,ttextdataemy_train)\n    print(f\"Embedding AdaBoost Accuracy: {ab.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\n    print(f\"Embedding AdaBoost Precision score: {precision_score(ttextdataemy_test,ab.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Embedding AdaBoost Recall score: {recall_score(ttextdataemy_test,ab.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"Embedding AdaBoost F1 score: {f1_score(ttextdataemy_test,ab.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:14:05.017061Z","iopub.execute_input":"2021-05-29T06:14:05.01736Z","iopub.status.idle":"2021-05-29T06:15:45.491833Z","shell.execute_reply.started":"2021-05-29T06:14:05.017331Z","shell.execute_reply":"2021-05-29T06:15:45.491011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adaboost的默认学习率1依然效果最好","metadata":{}},{"cell_type":"code","source":"#梯度增强方法\nfor l in [0.01,0.03,0.1,0.3,0.5]:\n    print(\"learning rate=\"+str(l))\n    gbt = GradientBoostingRegressor(learning_rate=l,random_state=1)\n    gbt.fit(ttextdataemx_train,ttextdataemy_train)\n    print(f\"Embedding GradientBoosting Accuracy: {gbt.score(ttextdataemx_test,ttextdataemy_test) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:15:45.493012Z","iopub.execute_input":"2021-05-29T06:15:45.493295Z","iopub.status.idle":"2021-05-29T06:15:56.778264Z","shell.execute_reply.started":"2021-05-29T06:15:45.493268Z","shell.execute_reply":"2021-05-29T06:15:56.777147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时梯度增强算法在学习率为0.1时效果最好","metadata":{}},{"cell_type":"code","source":"#Voting Classifier方法，一种ensemble方法，分为硬投票（各方法权值相同）和软投票（权重可调整）\n#各种估计方法ensemble，参数可分别调整，从略\nestimators = [ \n    ('rf',RandomForestClassifier(random_state=1,n_estimators=20)),\n    ('svc',SVC(kernel='rbf', probability=True,random_state=1)),\n    ('knc',KNeighborsClassifier()),\n    ('abc',AdaBoostClassifier(base_estimator=DecisionTreeClassifier() ,n_estimators=20,random_state=1)),\n    ('lr',LogisticRegression(random_state=1)) \n]\n#硬投票 参数设置\nvc = VotingClassifier(estimators=estimators, voting='hard')\nvc.fit(ttextdataemx_train,ttextdataemy_train)\nprint(f\"Embedding HardVoting Classifier Accuracy: {vc.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\nprint(f\"Embedding HardVoting Classifier Precision score: {precision_score(ttextdataemy_test,vc.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding HardVoting Classifier Recall score: {recall_score(ttextdataemy_test,vc.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding HardVoting Classifier F1 score: {f1_score(ttextdataemy_test,vc.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )\n#输出单个方法准确率\nfor est,name in zip(vc.estimators_,vc.estimators):\n    est.fit(ttextdataemx_train,ttextdataemy_train)\n    print(name[0],f\"Accuracy: {est.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\n    print(name[0],f\"Precision score: {precision_score(ttextdataemy_test,est.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(name[0],f\"Recall score: {recall_score(ttextdataemy_test,est.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(name[0],f\"F1 score: {f1_score(ttextdataemy_test,est.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:15:56.779396Z","iopub.execute_input":"2021-05-29T06:15:56.779688Z","iopub.status.idle":"2021-05-29T06:16:19.922178Z","shell.execute_reply.started":"2021-05-29T06:15:56.779658Z","shell.execute_reply":"2021-05-29T06:16:19.921184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#基于各方法准确率进行软投票 权重可调，根据之前给出的各方法准确率可以微调，这里采取排序法，之前准确率越高权重越大\nvc = VotingClassifier(estimators=estimators, voting='soft', weights=[3,2,4,1,5])\nvc.fit(ttextdataemx_train,ttextdataemy_train)\nprint(f\"Embedding SoftVoting Classifier Accuracy: {vc.score(ttextdataemx_test, ttextdataemy_test) * 100:.3f}%\", )\nprint(f\"Embedding SoftVoting Classifier Precision score: {precision_score(ttextdataemy_test,vc.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding SoftVoting Classifier Recall score: {recall_score(ttextdataemy_test,vc.predict(ttextdataemx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"Embedding SoftVoting Classifier F1 score: {f1_score(ttextdataemy_test,vc.predict(ttextdataemx_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:19.926839Z","iopub.execute_input":"2021-05-29T06:16:19.929257Z","iopub.status.idle":"2021-05-29T06:16:31.68081Z","shell.execute_reply.started":"2021-05-29T06:16:19.929188Z","shell.execute_reply":"2021-05-29T06:16:31.679806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"软投票准确率超过了之前最高的lr,ensemble有效","metadata":{}},{"cell_type":"markdown","source":"2.TF-IDF 特征：文本分析中常用的特征，用词频信息对文本进行特征提取，对语言不统一的文本仍然生效甚至更具有分辨性。仍然用之前的方法进行调参和分析。","metadata":{}},{"cell_type":"code","source":"#TF-IDF模型\n#重新加载数据\n#超小测试样本及划分\ntoydata=totaldata[0:100]\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)\n#超小测试文本样本及划分\ntoytextdata=toydata[['title','label_group']]\nttextx_train,ttextx_test, ttexty_train, ttexty_test = train_test_split(toytextdata,toytextdata.label_group,test_size=0.3, random_state=0)\n\n#tiidf特征提取\ncount_vec = TfidfVectorizer(binary=False, decode_error='ignore', stop_words='english')\nresponse = count_vec.fit_transform(ttextx_train.title) # s must be string\ntrainfeature = response.toarray()\nresponse = count_vec.transform(ttextx_test.title) # s must be string\ntestfeature = response.toarray()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:31.682341Z","iopub.execute_input":"2021-05-29T06:16:31.682945Z","iopub.status.idle":"2021-05-29T06:16:31.724894Z","shell.execute_reply.started":"2021-05-29T06:16:31.682899Z","shell.execute_reply":"2021-05-29T06:16:31.723772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TF-IDF特征上做SVM预测\n# Set dual=False to speed up training, and it's not needed\nsvc = LinearSVC(random_state=1, dual=False, max_iter=10000)\nsvc.fit(trainfeature, ttexty_train)\nprint(f\"TF-IDF SVM Accuracy: {svc.score(testfeature, ttexty_test) * 100:.3f}%\", )\nprint(f\"TF-IDF SVM Precision score: {precision_score(ttexty_test,svc.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF SVM Recall score: {recall_score(ttexty_test,svc.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF SVM F1 score: {f1_score(ttexty_test,svc.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:31.726606Z","iopub.execute_input":"2021-05-29T06:16:31.727338Z","iopub.status.idle":"2021-05-29T06:16:31.833718Z","shell.execute_reply.started":"2021-05-29T06:16:31.727288Z","shell.execute_reply":"2021-05-29T06:16:31.832643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"准确率十分高","metadata":{}},{"cell_type":"code","source":"#TF-IDF特征上做knn分析\n#参数k可训练\nfor k in [3,4,5,6,7,8,9,10,11,12]:\n    print(\"k=\"+str(k))\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n    clf.fit(trainfeature, ttexty_train)\n    print(f\"TF-IDF KNN Accuracy: {clf.score(testfeature, ttexty_test) * 100:.3f}%\", )\n    print(f\"TF-IDF KNN Precision score: {precision_score(ttexty_test,clf.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"TF-IDF KNN Recall score: {recall_score(ttexty_test,clf.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"TF-IDF KNN F1 score: {f1_score(ttexty_test,clf.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:31.839688Z","iopub.execute_input":"2021-05-29T06:16:31.840487Z","iopub.status.idle":"2021-05-29T06:16:32.523162Z","shell.execute_reply.started":"2021-05-29T06:16:31.840428Z","shell.execute_reply":"2021-05-29T06:16:32.522134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时KNN算法的最佳参数为k=3","metadata":{}},{"cell_type":"code","source":"#基于TF-IDF决策树和随机森林\ndt = DecisionTreeClassifier(random_state=1)\ndt.fit(trainfeature, ttexty_train)\nprint(f\"TF-IDF DecisionTree Accuracy: {dt.score(testfeature, ttexty_test) * 100:.3f}%\", )\nprint(f\"TF-IDF DecisionTree Precision score: {precision_score(ttexty_test,dt.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF DecisionTree Recall score: {recall_score(ttexty_test,dt.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF DecisionTree F1 score: {f1_score(ttexty_test,dt.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )\n#n_estimators可调\nrf = RandomForestClassifier(random_state=1)\nrf.fit(trainfeature, ttexty_train)\nprint(f\"TF-IDF RandomForest Accuracy: {rf.score(testfeature, ttexty_test) * 100:.3f}%\", )\nprint(f\"TF-IDF RandomForest Precision score: {precision_score(ttexty_test,rf.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF RandomForest Recall score: {recall_score(ttexty_test,rf.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF RandomForest F1 score: {f1_score(ttexty_test,rf.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:32.526012Z","iopub.execute_input":"2021-05-29T06:16:32.526741Z","iopub.status.idle":"2021-05-29T06:16:33.012169Z","shell.execute_reply.started":"2021-05-29T06:16:32.526692Z","shell.execute_reply":"2021-05-29T06:16:33.011506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adaboost\n#base_estimator可调整,n_estimators可调,learning_rate可调\nfor l in [0.01,0.1,0.3,0.5,1]:\n    print(\"learning rate=\"+str(l))\n    ab = AdaBoostClassifier(learning_rate=l,base_estimator=DecisionTreeClassifier(),random_state=1)\n    ab.fit(trainfeature, ttexty_train)\n    print(f\"TF-IDF AdaBoost Accuracy: {ab.score(testfeature, ttexty_test) * 100:.3f}%\", )\n    print(f\"TF-IDF AdaBoost Precision score: {precision_score(ttexty_test,ab.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"TF-IDF AdaBoost Recall score: {recall_score(ttexty_test,ab.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"TF-IDF AdaBoost F1 score: {f1_score(ttexty_test,ab.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:33.013385Z","iopub.execute_input":"2021-05-29T06:16:33.013864Z","iopub.status.idle":"2021-05-29T06:16:33.281831Z","shell.execute_reply.started":"2021-05-29T06:16:33.013834Z","shell.execute_reply":"2021-05-29T06:16:33.28089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时AdaBoost的学习率不影响准确率","metadata":{}},{"cell_type":"code","source":"#梯度增强方法\nfor l in [0.01,0.03,0.1,0.3,0.5,1]:\n    print(\"learning rate=\"+str(l))\n    gbt = GradientBoostingRegressor(learning_rate=l,random_state=1)\n    gbt.fit(trainfeature, ttexty_train)\n    print(f\"TF-IDF GradientBoosting Accuracy: {gbt.score(testfeature, ttexty_test) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:33.284902Z","iopub.execute_input":"2021-05-29T06:16:33.285193Z","iopub.status.idle":"2021-05-29T06:16:35.830732Z","shell.execute_reply.started":"2021-05-29T06:16:33.285163Z","shell.execute_reply":"2021-05-29T06:16:35.829966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时梯度增强算法在学习率为0.5时效果最好","metadata":{}},{"cell_type":"code","source":"#Voting Classifier\n#各种估计方法ensemble\nestimators = [ \n    ('rf',RandomForestClassifier(random_state=1,n_estimators=20)),\n    ('svc',SVC(kernel='rbf', probability=True,random_state=1)),\n    ('knc',KNeighborsClassifier()),\n    ('abc',AdaBoostClassifier(base_estimator=DecisionTreeClassifier() ,n_estimators=20,random_state=1)),\n    ('lr',LogisticRegression(random_state=1)) \n]\n#硬投票 参数设置\nvc = VotingClassifier(estimators=estimators, voting='hard')\nvc.fit(trainfeature, ttexty_train)\nprint(f\"TF-IDF HardVoting Classifier Accuracy: {vc.score(testfeature, ttexty_test) * 100:.3f}%\", )\nprint(f\"TF-IDF HardVoting Classifier Precision score: {precision_score(ttexty_test,vc.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF HardVoting Classifier Recall score: {recall_score(ttexty_test,vc.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF HardVoting Classifier F1 score: {f1_score(ttexty_test,vc.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )\n#输出单个方法准确率\nfor est,name in zip(vc.estimators_,vc.estimators):\n    est.fit(trainfeature, ttexty_train)\n    print(name[0],f\"Accuracy: {est.score(testfeature, ttexty_test) * 100:.3f}%\", )\n    print(name[0],f\"Precision score: {precision_score(ttexty_test,est.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(name[0],f\"Recall score: {recall_score(ttexty_test,est.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(name[0],f\"SVM F1 score: {f1_score(ttexty_test,est.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:35.83188Z","iopub.execute_input":"2021-05-29T06:16:35.832276Z","iopub.status.idle":"2021-05-29T06:16:40.745894Z","shell.execute_reply.started":"2021-05-29T06:16:35.832234Z","shell.execute_reply":"2021-05-29T06:16:40.744657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#基于各方法准确率进行软投票 权重可调，根据之前给出的各方法准确率可以微调，这里采取排序法，之前准确率越高权重越大\nvc = VotingClassifier(estimators=estimators, voting='soft', weights=[5,2,3,4,1])\nvc.fit(trainfeature, ttexty_train)\nprint(f\"TF-IDF SoftVoting Classifier Accuracy: {vc.score(testfeature, ttexty_test) * 100:.3f}%\", )\nprint(f\"TF-IDF SoftVoting Classifier Precision score: {precision_score(ttexty_test,vc.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF SoftVoting Classifier Recall score: {recall_score(ttexty_test,vc.predict(testfeature) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"TF-IDF SoftVoting Classifier F1 score: {f1_score(ttexty_test,vc.predict(testfeature),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:40.747731Z","iopub.execute_input":"2021-05-29T06:16:40.749611Z","iopub.status.idle":"2021-05-29T06:16:43.361451Z","shell.execute_reply.started":"2021-05-29T06:16:40.749565Z","shell.execute_reply":"2021-05-29T06:16:43.35895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"软投票准确率超过了大部分分支分类器，比较稳健","metadata":{}},{"cell_type":"markdown","source":"3.spacy 中还有一个TextCategorizer方法，可以将文本进行分类，但需要设定语言，这里设定为英文进行测试","metadata":{}},{"cell_type":"code","source":"#spacy nlp方法 把标签转换为字符串，进行分类 TextCategorizer法\n#重新加载数据\n#超小测试样本及划分\ntoydata=totaldata[0:100]\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)\n#超小测试文本样本及划分\ntoytextdata=toydata[['title','label_group']]\nttextx_train,ttextx_test, ttexty_train, ttexty_test = train_test_split(toytextdata,toytextdata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:43.363064Z","iopub.execute_input":"2021-05-29T06:16:43.363499Z","iopub.status.idle":"2021-05-29T06:16:43.382543Z","shell.execute_reply.started":"2021-05-29T06:16:43.363456Z","shell.execute_reply":"2021-05-29T06:16:43.381473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#spacy nlp方法 把标签转换为字符串，进行分类 TextCategorizer法\nttextx_train=ttextx_train.astype('str')\nttextx_test=ttextx_test.astype('str')\nttexty_train=ttexty_train.astype('str')\nttexty_test==ttexty_test.astype('str')\n\n# Create an empty model，但文本不全是英文，可能有影响\nnlp = spacy.blank(\"en\")\n\n# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)\n#add label\nfor label in ttextx_train.label_group.unique():\n    textcat.add_label(label)\n#训练数据\ntrain =ttextx_train.apply(lambda row: (row['title'],row['label_group']), axis=1).tolist()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:43.384002Z","iopub.execute_input":"2021-05-29T06:16:43.384553Z","iopub.status.idle":"2021-05-29T06:16:44.445325Z","shell.execute_reply.started":"2021-05-29T06:16:43.384511Z","shell.execute_reply":"2021-05-29T06:16:44.444574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#加载数据\ndef load_data(train, split=0.8): \n\n    # Shuffle the data\n    random.shuffle(train)\n    texts, labels = zip(*train)\n    # get the categories for each review\n    categories = ttextx_train.label_group\n\n    cats = []\n    for y in labels:\n        cat = {category: 0 for category in categories}\n        cat[y] = 1\n        cats.append(cat)\n\n    # Splitting the training and evaluation data\n    split = int(len(train) * split)\n    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n\n# Calling the load_data() function \n(train_texts, train_cats), (dev_texts, dev_cats) = load_data(train)\n\n# Processing the final format of training data\ntrain_data = list(zip(train_texts,[{'cats': cats} for cats in train_cats]))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:44.446514Z","iopub.execute_input":"2021-05-29T06:16:44.447043Z","iopub.status.idle":"2021-05-29T06:16:44.477777Z","shell.execute_reply.started":"2021-05-29T06:16:44.447003Z","shell.execute_reply":"2021-05-29T06:16:44.476981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#准确率计算\ndef evaluate(tokenizer, textcat, texts, cats):\n    docs = (tokenizer(text) for text in texts)\n    tp = 0\n    for i, doc in enumerate(textcat.pipe(docs)):\n        #获取最大值对应的key\n        gold = max(cats[i], key=cats[i].get)\n        ds =  doc.cats.items()\n        h = {}\n        [h.update({k:v}) for k,v in ds]\n        predict = max(h, key=h.get)\n        if gold == predict:\n            tp += 1\n            \n    precision = tp / len(texts)\n    return precision\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:44.479003Z","iopub.execute_input":"2021-05-29T06:16:44.479559Z","iopub.status.idle":"2021-05-29T06:16:44.487916Z","shell.execute_reply.started":"2021-05-29T06:16:44.479517Z","shell.execute_reply":"2021-05-29T06:16:44.486843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#迭代训练，时间较长\nn_iter = 10\n# 禁用其他组件\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\nwith nlp.disable_pipes(*other_pipes):  # 只训练 textcat\n    optimizer = nlp.begin_training()\n\n    print(\"Training the model...\")\n    print('{:^5}\\t{:^5}'.format('LOSS', 'PRECISION'))\n\n    # 开始训练\n    for i in range(n_iter):\n        losses = {}\n        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n                      losses=losses)\n\n        with textcat.model.use_params(optimizer.averages):\n            score = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats) \n\n            print('{0:.3f}\\t{1:.3f}'.format(losses['textcat'], score))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:16:44.489223Z","iopub.execute_input":"2021-05-29T06:16:44.489778Z","iopub.status.idle":"2021-05-29T06:19:51.87534Z","shell.execute_reply.started":"2021-05-29T06:16:44.489736Z","shell.execute_reply":"2021-05-29T06:19:51.873302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#测试准确率\ntest =ttextx_test.apply(lambda row: (row['title'],row['label_group']), axis=1).tolist()\ntexts, labels = zip(*test)\ndocs = (nlp.tokenizer(text) for text in texts)\ncats = []\nfor y in labels:\n    cat = {category: 0 for category in ttextx_test.label_group}\n    cat[y] = 1\n    cats.append(cat)\ntp = 0\nfor i, doc in enumerate(textcat.pipe(docs)):\n    #获取最大值对应的key\n    gold = max(cats[i], key=cats[i].get)\n    ds =  doc.cats.items()\n    h = {}\n    [h.update({k:v}) for k,v in ds]\n    predict = max(h, key=h.get)\n    if gold == predict:\n        tp += 1\n                \nprecision = tp / len(ttextx_test)\n\nprint(f\"Spacy nlp Accuracy: {precision* 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:19:51.876579Z","iopub.execute_input":"2021-05-29T06:19:51.87685Z","iopub.status.idle":"2021-05-29T06:19:51.94061Z","shell.execute_reply.started":"2021-05-29T06:19:51.876822Z","shell.execute_reply":"2021-05-29T06:19:51.93957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现效果还是较好的","metadata":{}},{"cell_type":"markdown","source":"三、用图像信息进行分类预测","metadata":{}},{"cell_type":"markdown","source":"仍然在划分出的toydata数据集中进行训练和预测，除对image信息进行读取加工外，还可利用image_phash信息进行预测。处理image更常用的神经网络方法见notebook PCbighomework_network_hgz","metadata":{}},{"cell_type":"code","source":"#超小测试样本及划分\ntoydata=totaldata[0:100]\n#将toydata中所有标签的样本提取出来，这将大大提升准确率\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)\n#超小测试图像样本及划分\ntoyimagedata=toydata[['image','label_group']]\ntimagex_train,timagex_test, timagey_train, timagey_test = train_test_split(toyimagedata,toyimagedata.label_group,test_size=0.3, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:19:51.941893Z","iopub.execute_input":"2021-05-29T06:19:51.942271Z","iopub.status.idle":"2021-05-29T06:19:51.956351Z","shell.execute_reply.started":"2021-05-29T06:19:51.942239Z","shell.execute_reply":"2021-05-29T06:19:51.955479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.先对图像进行简单信息提取，直接将其转化为一维向量，之后可做KNN分析","metadata":{}},{"cell_type":"code","source":"#建立图像矩阵样本，将其向量化（一维信息）\ntoyimagearraydata=np.zeros((len(toyimagedata),512*512*3))\nfor i in range(len(toyimagedata)):\n    a = mpimg.imread('../input/shopee-product-matching/train_images/'+toyimagedata.image[toyimagedata.index[i]]) \n    toyimagearraydata[i] = np.resize(a,512*512*3)\n#样本划分\ntimagearrayx_train,timagearrayx_test, timagearrayy_train, timagearrayy_test = train_test_split(toyimagearraydata,toyimagedata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:19:51.957617Z","iopub.execute_input":"2021-05-29T06:19:51.957869Z","iopub.status.idle":"2021-05-29T06:20:03.442853Z","shell.execute_reply.started":"2021-05-29T06:19:51.957844Z","shell.execute_reply":"2021-05-29T06:20:03.442099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#在1维图像样本上做knn分析\n#参数k可训练\nfor k in [3,4,5,6,7,8,9,10,11,12]:\n    print(\"k=\"+str(k))\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n    clf.fit(timagearrayx_train, timagey_train.values)\n    Z = clf.predict(timagearrayx_test)\n    print(f\"1dimensionimage KNN Accuracy: {clf.score(timagearrayx_test,timagey_test.values) * 100:.3f}%\", )\n    print(f\"1dimensionimage KNN Precision score: {precision_score(timagey_test.values,clf.predict(timagearrayx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"1dimensionimage KNN Recall score: {recall_score(timagey_test.values,clf.predict(timagearrayx_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"1dimensionimage KNN F1 score: {f1_score(timagey_test.values,clf.predict(timagearrayx_test),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:20:03.444051Z","iopub.execute_input":"2021-05-29T06:20:03.444642Z","iopub.status.idle":"2021-05-29T06:22:03.93165Z","shell.execute_reply.started":"2021-05-29T06:20:03.444599Z","shell.execute_reply":"2021-05-29T06:22:03.930521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时KNN算法的最佳参数为k=3","metadata":{}},{"cell_type":"markdown","source":"可见一维样本的信息还是损失过多，准确率不高，做svm分析等的时间过长，在此不做展示","metadata":{}},{"cell_type":"markdown","source":"2.SIFT特征处理。使用opencv2中的SIFT相关函数可以提取出图像信息的关键点，并以此作为特征进行图像分类。","metadata":{}},{"cell_type":"code","source":"#SIFT处理图像\n#超小测试样本及划分/100可接受速度\ntoydata=totaldata[0:100]\n#将toydata中所有标签的样本提取出来，这将大大提升准确率\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\ntx_train,tx_test, ty_train, ty_test = train_test_split(toydata,toydata.label_group,test_size=0.3, random_state=0)\n#超小测试图像样本及划分\ntoyimagedata=toydata[['image','label_group']]\ntimagex_train,timagex_test, timagey_train, timagey_test = train_test_split(toyimagedata,toyimagedata.label_group,test_size=0.3, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:22:03.933346Z","iopub.execute_input":"2021-05-29T06:22:03.934Z","iopub.status.idle":"2021-05-29T06:22:03.953337Z","shell.execute_reply.started":"2021-05-29T06:22:03.933952Z","shell.execute_reply":"2021-05-29T06:22:03.952184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SIFT特征提取，时间较长\n\ndef calcSiftFeature(img):\n    #设置图像sift特征关键点最大为200\n    sift = cv2.SIFT_create()\n    #计算图片的特征点和特征点描述\n    keypoints, features = sift.detectAndCompute(img, None)\n    return features\n\n#计算词袋\ndef learnVocabulary(features):\n    wordCnt = 50\n    #criteria表示迭代停止的模式   eps---精度0.1，max_iter---满足超过最大迭代次数20\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.1)\n    #得到k-means聚类的初始中心点\n    flags = cv2.KMEANS_RANDOM_CENTERS\n    # 标签，中心 = kmeans(输入数据（特征)、聚类的个数K,预设标签，聚类停止条件、重复聚类次数、初始聚类中心点\n    compactness, labels, centers = cv2.kmeans(features, wordCnt, None,criteria, 20, flags)\n    return centers\n\ndef calcFeatVec(features, centers):\n    featVec = np.zeros((1, 50))\n    for i in range(0, features.shape[0]):\n        #第i张图片的特征点\n        fi = features[i]\n        diffMat = np.tile(fi, (50, 1)) - centers\n        #axis=1按行求和，即求特征到每个中心点的距离\n        sqSum = (diffMat**2).sum(axis=1)\n        dist = sqSum**0.5\n        #升序排序\n        sortedIndices = dist.argsort()\n        #取出最小的距离，即找到最近的中心点\n        idx = sortedIndices[0]\n        #该中心点对应+1\n        featVec[0][idx] += 1\n    return featVec\n\nfeatures = np.float32([]).reshape(0, 128)#存放训练集图片的特征\nfor i in range(len(toyimagedata)):\n    img = cv2.imread('../input/shopee-product-matching/train_images/'+toyimagedata.image[toyimagedata.index[i]])\n    #获取图片sift特征点\n    img_f = calcSiftFeature(img)\n    #特征点加入训练数据\n    features = np.append(features, img_f, axis=0)\n#训练集的词袋\ncenters = learnVocabulary(features)\n\ndata_vec = np.float32([]).reshape(0, 50)#存放训练集图片的特征\nlabels = np.float32([])\nfor i in range(len(toyimagedata)):\n    img = cv2.imread('../input/shopee-product-matching/train_images/'+toyimagedata.image[toyimagedata.index[i]])\n    img_f = calcSiftFeature(img)\n    img_vec = calcFeatVec(img_f, centers)\n    data_vec = np.append(data_vec,img_vec,axis=0)\n    labels = np.append(labels,toyimagedata.label_group[toyimagedata.index[i]])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:22:03.955269Z","iopub.execute_input":"2021-05-29T06:22:03.955974Z","iopub.status.idle":"2021-05-29T06:29:21.012223Z","shell.execute_reply.started":"2021-05-29T06:22:03.955928Z","shell.execute_reply":"2021-05-29T06:29:21.01125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#由于数据比较离散，进行Normalization处理,可调整\ntt=data_vec\ndata_vec = preprocessing.normalize(tt, norm='l2')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:21.01331Z","iopub.execute_input":"2021-05-29T06:29:21.013589Z","iopub.status.idle":"2021-05-29T06:29:21.018369Z","shell.execute_reply.started":"2021-05-29T06:29:21.013562Z","shell.execute_reply":"2021-05-29T06:29:21.017387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sift数据划分\ntsiftdatax_train, tsiftdatax_test, tsiftdatay_train, tsiftdatay_test = train_test_split(data_vec, labels,\n                                                    test_size=0.3, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:21.019884Z","iopub.execute_input":"2021-05-29T06:29:21.020297Z","iopub.status.idle":"2021-05-29T06:29:21.031544Z","shell.execute_reply.started":"2021-05-29T06:29:21.020254Z","shell.execute_reply":"2021-05-29T06:29:21.030606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SIFT变换后的数据又可以使用之前的各类方法进行分类","metadata":{}},{"cell_type":"code","source":"#sift上做SVM预测\nsvc = LinearSVC(random_state=1, dual=False, max_iter=10000)\nsvc.fit(tsiftdatax_train, tsiftdatay_train)\nprint(f\"SIFT SVM Accuracy: {svc.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\nprint(f\"SIFT SVM Precision score: {precision_score(tsiftdatay_test,svc.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT SVM Recall score: {recall_score(tsiftdatay_test,svc.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT SVM F1 score: {f1_score(tsiftdatay_test,svc.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:21.032914Z","iopub.execute_input":"2021-05-29T06:29:21.033338Z","iopub.status.idle":"2021-05-29T06:29:21.131806Z","shell.execute_reply.started":"2021-05-29T06:29:21.033296Z","shell.execute_reply":"2021-05-29T06:29:21.130542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sift上做knn分析\n#参数k可训练\nfor k in [3,4,5,6,7,8,9,10,11,12]:\n    print(\"k=\"+str(k))\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n    clf.fit(tsiftdatax_train, tsiftdatay_train)\n    Z = clf.predict(tsiftdatax_test)\n    print(f\"SIFT KNN Accuracy: {clf.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\n    print(f\"SIFT KNN Precision score: {precision_score(tsiftdatay_test,clf.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"SIFT KNN Recall score: {recall_score(tsiftdatay_test,clf.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"SIFT KNN F1 score: {f1_score(tsiftdatay_test,clf.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:21.133491Z","iopub.execute_input":"2021-05-29T06:29:21.133904Z","iopub.status.idle":"2021-05-29T06:29:21.799718Z","shell.execute_reply.started":"2021-05-29T06:29:21.133863Z","shell.execute_reply":"2021-05-29T06:29:21.798657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时KNN算法的最佳参数为k=7","metadata":{}},{"cell_type":"code","source":"#基于SIFT决策树和随机森林\ndt = DecisionTreeClassifier(random_state=1)\ndt.fit(tsiftdatax_train, tsiftdatay_train)\nprint(f\"SIFT DecisionTree Accuracy: {dt.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\nprint(f\"SIFT DecisionTree Precision score: {precision_score(tsiftdatay_test,dt.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT DecisionTree Recall score: {recall_score(tsiftdatay_test,dt.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT DecisionTree F1 score: {f1_score(tsiftdatay_test,dt.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )\nrf = RandomForestClassifier(random_state=1)\nrf.fit(tsiftdatax_train, tsiftdatay_train)\nprint(f\"SIFT RandomForest Accuracy: {rf.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\nprint(f\"SIFT RandomForest Precision score: {precision_score(tsiftdatay_test,rf.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT RandomForest Recall score: {recall_score(tsiftdatay_test,rf.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT RandomForest F1 score: {f1_score(tsiftdatay_test,rf.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:21.801476Z","iopub.execute_input":"2021-05-29T06:29:21.802088Z","iopub.status.idle":"2021-05-29T06:29:22.462258Z","shell.execute_reply.started":"2021-05-29T06:29:21.802041Z","shell.execute_reply":"2021-05-29T06:29:22.461273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adaboost\n#base_estimator可调整,n_estimators可调,learning_rate可调\nfor l in [0.01,0.1,0.3,0.5,1]:\n    print(\"learning rate=\"+str(l))\n    ab = AdaBoostClassifier(learning_rate=l,base_estimator=DecisionTreeClassifier(),random_state=1)\n    ab.fit(tsiftdatax_train, tsiftdatay_train)\n    print(f\"SIFT AdaBoost Accuracy: {ab.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\n    print(f\"SIFT AdaBoost Precision score: {precision_score(tsiftdatay_test,ab.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"SIFT AdaBoost Recall score: {recall_score(tsiftdatay_test,ab.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"SIFT AdaBoost F1 score: {f1_score(tsiftdatay_test,ab.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:22.463463Z","iopub.execute_input":"2021-05-29T06:29:22.463765Z","iopub.status.idle":"2021-05-29T06:29:22.71212Z","shell.execute_reply.started":"2021-05-29T06:29:22.463735Z","shell.execute_reply":"2021-05-29T06:29:22.711075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时AdaBoost的学习率不影响结果","metadata":{}},{"cell_type":"code","source":"#梯度增强方法\nfor l in [0.01,0.03,0.1,0.3,0.5,1]:\n    print(\"learning rate=\"+str(l))\n    gbt = GradientBoostingRegressor(learning_rate=l,random_state=1)\n    gbt.fit(tsiftdatax_train, tsiftdatay_train)\n    print(f\"SIFT GradientBoosting Accuracy: {gbt.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:22.713576Z","iopub.execute_input":"2021-05-29T06:29:22.71398Z","iopub.status.idle":"2021-05-29T06:29:25.109162Z","shell.execute_reply.started":"2021-05-29T06:29:22.713937Z","shell.execute_reply":"2021-05-29T06:29:25.108107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时梯度增强算法在学习率为0.1时效果最好","metadata":{}},{"cell_type":"code","source":"#Voting Classifier\n#各种估计方法ensemble\nestimators = [ \n    ('rf',RandomForestClassifier(random_state=1,n_estimators=20)),\n    ('svc',SVC(kernel='rbf', probability=True,random_state=1)),\n    ('knc',KNeighborsClassifier()),\n    ('abc',AdaBoostClassifier(base_estimator=DecisionTreeClassifier() ,n_estimators=20,random_state=1)),\n    ('lr',LogisticRegression(random_state=1)) \n]\n#硬投票 参数设置\nvc = VotingClassifier(estimators=estimators, voting='hard')\nvc.fit(tsiftdatax_train, tsiftdatay_train)\nprint(f\"SIFT HardVoting Classifier Accuracy: {vc.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\nprint(f\"SIFT HardVoting Classifier Precision score: {precision_score(tsiftdatay_test,vc.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT HardVoting Classifier Recall score: {recall_score(tsiftdatay_test,vc.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT HardVoting Classifier F1 score: {f1_score(tsiftdatay_test,vc.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )\n#输出单个方法准确率\nfor est,name in zip(vc.estimators_,vc.estimators):\n    est.fit(tsiftdatax_train, tsiftdatay_train)\n    print(name[0],f\"Accuracy: {est.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\n    print(name[0],f\"Precision score: {precision_score(tsiftdatay_test,est.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(name[0],f\"Recall score: {recall_score(tsiftdatay_test,est.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(name[0],f\"F1 score: {f1_score(tsiftdatay_test,est.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:25.110452Z","iopub.execute_input":"2021-05-29T06:29:25.110708Z","iopub.status.idle":"2021-05-29T06:29:26.744967Z","shell.execute_reply.started":"2021-05-29T06:29:25.11068Z","shell.execute_reply":"2021-05-29T06:29:26.743915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#基于各方法准确率进行软投票 权重可调，根据之前给出的各方法准确率可以微调，这里采取排序法，之前准确率越高权重越大\nvc = VotingClassifier(estimators=estimators, voting='soft', weights=[5,1,4,2,3])\nvc.fit(tsiftdatax_train, tsiftdatay_train)\nprint(f\"SIFT SoftVoting Classifier Accuracy: {vc.score(tsiftdatax_test, tsiftdatay_test) * 100:.3f}%\", )\nprint(f\"SIFT SoftVoting Classifier Precision score: {precision_score(tsiftdatay_test,vc.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT SoftVoting Classifier Recall score: {recall_score(tsiftdatay_test,vc.predict(tsiftdatax_test) ,average='macro',zero_division=0) * 100:.3f}%\", )\nprint(f\"SIFT SoftVoting Classifier F1 score: {f1_score(tsiftdatay_test,vc.predict(tsiftdatax_test),average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:26.746647Z","iopub.execute_input":"2021-05-29T06:29:26.747256Z","iopub.status.idle":"2021-05-29T06:29:27.784164Z","shell.execute_reply.started":"2021-05-29T06:29:26.747192Z","shell.execute_reply":"2021-05-29T06:29:27.783189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"软投票略超过各分支分类器，但整体准确率还是不高","metadata":{}},{"cell_type":"markdown","source":"3.用图像phash值做分析。训练集中给出了image_phash的值，这是一种图像哈希方式，可以通过定义新的度量汉明距离，用KNN方法进行样本分类","metadata":{}},{"cell_type":"code","source":"#超小测试样本及划分\ntoydata=totaldata[0:100]\n#将toydata中所有标签的样本提取出来，这将大大提升准确率\ntoytrickdata=totaldata.loc[totaldata.label_group.isin(toydata.label_group)]\ntoydata=toytrickdata\n#超小测试图像哈希样本及划分\ntoyphashdata=toydata[['image_phash','label_group']]\ntphashx_train,tphashx_test, tphashy_train, tphashy_test = train_test_split(toyphashdata,toyphashdata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:27.785785Z","iopub.execute_input":"2021-05-29T06:29:27.786405Z","iopub.status.idle":"2021-05-29T06:29:27.800898Z","shell.execute_reply.started":"2021-05-29T06:29:27.786357Z","shell.execute_reply":"2021-05-29T06:29:27.799882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#建立图像哈希样本\ntphasharraydata = []\nfor i in range(len(toyphashdata)): \n    tphasharraydata.append(np.array(list(toyphashdata['image_phash'][toyphashdata.index[i]])))\ntphasharraydata=np.array(tphasharraydata)\n#样本划分\ntphasharrayx_train,tphasharrayx_test, tphasharrayy_train, tphasharrayy_test = train_test_split(tphasharraydata,toyphashdata.label_group,test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:27.802696Z","iopub.execute_input":"2021-05-29T06:29:27.803298Z","iopub.status.idle":"2021-05-29T06:29:27.828687Z","shell.execute_reply.started":"2021-05-29T06:29:27.803254Z","shell.execute_reply":"2021-05-29T06:29:27.827629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#用图像哈希值计算汉明距离\ndef hanming(image_code, ref_code):\n    \"\"\"\n    calculate hanming distance between image and reference\n    Args:\n        image_code: list type\n        ref_code: list type\n    \"\"\"\n    assert len(image_code)== len(ref_code)\n    return sum(np.array(image_code)!=np.array(ref_code))/len(image_code)\n\n#自制knn\n\ndist = np.zeros([tphasharrayx_train.shape[0],tphasharrayx_test.shape[0]])\nfor i in range(tphasharrayx_train.shape[0]):\n    for j in range(tphasharrayx_test.shape[0]):\n        dist[i,j] = hanming(tphasharrayx_train[i], tphasharrayx_test[j])\n#参数k可训练\nfor k in [3,4,5,6,7,8,9,10,11,12]:\n    print(\"k=\"+str(k))\n    max_index = []\n    for j in range(len(tphasharrayx_test)):\n        list1 = dist[:,j]\n        list2 = sorted(list1)\n        max_num = list2[:k]\n        max_index.append([y for y,i in enumerate(list1) if i in max_num])\n    #分类\n    pre = [pd.value_counts(tphasharrayy_train.values[max_index[i]]).idxmax() for i in range(len(tphasharrayx_test))]\n \n    #查看结果\n    print(f\"ImagePhash KNN Accuracy: {sum(pre == tphasharrayy_test.values)/len(tphasharrayy_test)* 100:.3f}%\", )\n    print(f\"ImagePhash KNN Precision score: {precision_score(pre,tphasharrayy_test.values ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"ImagePhash KNN Recall score: {recall_score(pre,tphasharrayy_test.values ,average='macro',zero_division=0) * 100:.3f}%\", )\n    print(f\"ImagePhash KNN F1 score: {f1_score(pre,tphasharrayy_test.values,average='macro',zero_division=0) * 100:.3f}%\", )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:29:27.830292Z","iopub.execute_input":"2021-05-29T06:29:27.831043Z","iopub.status.idle":"2021-05-29T06:29:32.1155Z","shell.execute_reply.started":"2021-05-29T06:29:27.830996Z","shell.execute_reply":"2021-05-29T06:29:32.114645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"此时KNN的最佳参数为k=3","metadata":{}},{"cell_type":"markdown","source":"综上，我们从文本信息和图像信息分别提取特征并对商品标签进行了预测，总的来说还是文本信息的准确率更高，因为同标签商品的描述十分类似，但图像则较难分辨。PCbighomework_network_hgz用神经网络进一步对图像信息进行训练，得到了明显较好的结果；PCbighomework_mix_hgz试图整合文本和图像最优模型的信息，是综合文本图像信息产生新分类器的尝试。具体结果对照见实验报告。","metadata":{}}]}