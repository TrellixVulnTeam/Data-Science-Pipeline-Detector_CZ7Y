{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# First submission! Just submit this preliminary work to see if the scoreboard works ;)\n\nMore to come...\n\n## Shopee Project - Determine if two products are the same by their images\n\nThe general workflow is:\n\n### Image\n* Stacking two backbone models for transfer learning: ResNet50 pretrained on MS-COCO (downloaded from the Internet) + ResNet50 pretrained on ImageNet (from Keras) => \n* Supervised feature selection by ANOVA => \n* Agglomerative clustering by cosine similarity\n\n### Title\n* Tokenize => Indonesian Stemmer + WordNet Lemmatizer => \n* Calculate TF-IDF =>\n* Clustering\n\nMerge the results from the image cluster and title cluster","metadata":{"_uuid":"551b2a5d-d745-41f7-8679-898cadacc939","_cell_guid":"69a0d29c-9981-41f2-9b3f-407728fbaea9","trusted":true}},{"cell_type":"code","source":"from shutil import copytree\n#copytree('../input/zzxjoanw/hdbscan-0.8.27/hdbscan-0.8.27','./hdbscan')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd hdbscan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python setup.py bdist_wheel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd dist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install \"hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl\" --no-cache-dir --no-binary :all: --no-build-isolation\nimport hdbscan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from nltk.cluster.kmeans import KMeansClusterer\n# from nltk.cluster.util import cosine_distance","metadata":{"_uuid":"790269e3-79f6-4045-a368-c65a58cb4c23","_cell_guid":"76e0220b-aa70-4f6d-92da-cf545639988f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install \"../input/zzxjoanw/nltk-3.6.2-py3-none-any.whl\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os","metadata":{"_uuid":"ce13bb69-0b52-46d6-8c38-05298dcbc570","_cell_guid":"aff5aa72-7b09-43d8-9124-0fe64a896405","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import struct\n\n# Image tools\n#import imgaug\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Activation, Average, Concatenate, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\n\nimport scipy\nfrom sklearn import *\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# NLP tools\nfrom html import unescape\nfrom nltk.util import everygrams\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import TweetTokenizer","metadata":{"_uuid":"50afea74-0d25-4f24-81b8-cbbc326ce566","_cell_guid":"a9ae14d6-a31a-4b9c-b2bd-15f046f27b0b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input as ppi_vgg16, decode_predictions as dp_vgg16\nfrom keras.applications.resnet50 import ResNet50, preprocess_input as ppi_resnet50, decode_predictions as dp_resnet50\nfrom keras.utils import plot_model\n\nfrom joblib import load\n\n# from glob import glob\n# from shutil import copy2\nfrom gc import collect","metadata":{"_uuid":"efc3fd66-5163-4787-970e-87ae9f390757","_cell_guid":"1588194b-184b-40cc-8def-9a8077840d42","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\ndef preprocess(path):\n    #print(path)\n    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_RGB2BGR)\n\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    th, threshed = cv2.threshold(gray, 205, 255, cv2.THRESH_BINARY_INV)\n\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n\n    cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n\n    small1 = []\n    small2 = []\n    large1 = []\n    large2 = []\n\n    for cnt in cnts:\n        x,y,w,h = cv2.boundingRect(cnt)\n#         if w*h < 1000:\n#             continue\n        small1.append(y)\n        small2.append(x)\n        large1.append(y+h)\n        large2.append(x+w)\n\n    dst = img[np.min(small1):np.max(large1), np.min(small2):np.max(large2)]\n\n    s = max(dst.shape[0:2])\n\n    f = np.full((s,s,3),255,np.uint8)\n\n    ax,ay = (s - dst.shape[1])//2,(s - dst.shape[0])//2\n\n    f[ay:dst.shape[0]+ay,ax:ax+dst.shape[1]] = dst\n\n    f = cv2.resize(f, (300, 300))\n    \n    return f","metadata":{"_uuid":"50f6115d-e58c-4939-b50d-23e2fd0ffea5","_cell_guid":"47bb7513-fbb3-47da-be64-caccf73e9cb9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Indonesian stemmer\n\n!pip install '/kaggle/input/zzxjoanw/PySastrawi-1.2.0-py2.py3-none-any.whl'\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory","metadata":{"_uuid":"59913949-0ed9-4fee-86b7-42beb9bdb5a2","_cell_guid":"9eca6a5c-35bf-41b6-add1-6812a19b8ae2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"factory = StemmerFactory()\nstemmer = factory.create_stemmer()","metadata":{"_uuid":"4243c265-3517-49dc-893d-a08d4c754d04","_cell_guid":"58f87100-d5ec-4e65-9515-9db10e8a10ca","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df0 = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\n#df0.sort_values('label_group',inplace=True)","metadata":{"_uuid":"216ecd14-be8a-449b-83b8-c1432c47799c","_cell_guid":"318ccf0d-5e21-4aa2-8c12-10af5411c582","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testpaths = df0['image'].tolist()\ntitles = df0['title'].tolist()\ntextid = df0['posting_id'].tolist()","metadata":{"_uuid":"047c24e2-e4bb-48f9-a66a-8277e047be68","_cell_guid":"15b6004b-d9a7-40a3-b7ca-705162f09532","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cntvect = feature_extraction.text.CountVectorizer(stop_words = 'english', max_features = 20000)\ncntvect.fit(titles)\ntext_X = cntvect.transform(titles)\ntf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l2')\ntext_Xtf = tf_trans.fit_transform(text_X)\ntext_Xtf = text_Xtf.toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import *\nmul_batch_size = 1024\nmyMatching = []\nbatch_num =shape(text_Xtf)[0]//mul_batch_size  \nif shape(text_Xtf)[0]%mul_batch_size !=0: \n    batch_num += 1 \n\noverall_ind = 0\nprint(batch_num)\nfor batch_index in range(0, batch_num): \n    print(\"batch:\", batch_index)\n    start = batch_index * mul_batch_size\n    end = (batch_index+1) * mul_batch_size\n    if end >= shape(text_Xtf)[0]:\n        end = shape(text_Xtf)[0]\n    cur_similarity = matmul(text_Xtf, text_Xtf[start:end].T).T\n    for sample in cur_similarity:\n            cur_matching = []\n            for index,value in enumerate(sample):\n                if value > 0.7:\n                    cur_matching.append(textid[index])\n            #cur_matching = ' '.join(cur_matching)\n            myMatching.append(cur_matching)\n            overall_ind += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lsa = decomposition.TruncatedSVD(n_components=250, random_state=0)\n#lsa.fit(X_trainx[0:50000])\n#X_trainx = lsa.transform(X_trainx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.keras.applications.efficientnet import EfficientNetB3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget https://dord.mynetgear.com/modelSelection13.joblib\n#skb = load('/kaggle/input/zzxjoanw/goodman_1100.joblib')","metadata":{"_uuid":"ca2004bd-f1e8-41db-9992-3346c37bebb6","_cell_guid":"200e10bd-5b4f-407a-9444-38f8f70c53b0","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_b4_imagenet = EfficientNetB3(weights='/kaggle/input/zzxjoanw/b3_goodman_.h5', include_top=False, input_shape=(300,300,3))\ntt = model_b4_imagenet.get_layer('top_activation').output\navg_pool = GlobalAveragePooling2D(name='avg_pool')(tt)\n\nmodel = Model(inputs=model_b4_imagenet.input,\n          outputs=avg_pool)\n# print(model_b4_imagenet.summary())\nins = np.zeros((0,1536))\nbatch = []\n\nimages = np.zeros(shape=(1, 300, 300, 3))\n#img = preprocess(f'/kaggle/input/shopee-product-matching/train_images/{testpaths[0]}')\nimg = preprocess(f'/kaggle/input/shopee-product-matching/test_images/{testpaths[0]}') \n\nx_expand = np.expand_dims(img, axis=0)\nimages[0, :, :, :] = x_expand\n\nbatch.append(images)\nfor i, path in enumerate(testpaths[1:]):\n#     start = time.time()\n    images = np.zeros(shape=(1, 300, 300, 3))\n    img = preprocess(f'/kaggle/input/shopee-product-matching/test_images/{path}') \n    #img = preprocess(f'/kaggle/input/shopee-product-matching/test_images/{testpaths[path]}') \n    \n    x_expand = np.expand_dims(img, axis=0)\n    images[0, :, :, :] = x_expand\n    \n    batch.append(images)\n    if i % 64 == 0:\n        batch = np.vstack(batch)\n        images_features = model.predict(batch, batch_size=64)\n        batch = []\n        ins = np.vstack([ins,images_features])\nif i % 64 != 0:\n    batch = np.vstack(batch)\n    images_features = model.predict(batch, batch_size=i % 64)\n    batch = []\n    ins = np.vstack([ins,images_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ins = skb.transform(ins)","metadata":{"_uuid":"29855d0e-11f8-415d-95a4-a4f7fed7c957","_cell_guid":"1824767a-47e6-4b2d-8b31-361402242d79","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ins = np.hstack([ins,X_trainx]) \n\nss = preprocessing.StandardScaler()\nins = ss.fit_transform(ins)\nprint(shape(ins))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = decomposition.PCA(n_components=min(800, shape(ins)[0]))\nins = pca.fit_transform(ins)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelAc = hdbscan.HDBSCAN(min_cluster_size=2, cluster_selection_epsilon=11,core_dist_n_jobs=-1)#,approx_min_span_tree=True, cluster_selection_method='leaf')\nmodelAclabels_ = modelAc.fit_predict(ins)","metadata":{"_uuid":"b37ef5b8-29f1-4c09-8e1d-4299d2b64157","_cell_guid":"da744f66-956c-4d4c-b158-923b2b82fc58","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(modelAclabels_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_result_dict = {}\n\n#out = []\npostingids = np.array(df0['posting_id'])\n\nfor i in range(modelAclabels_.shape[0]):\n    outstring_list = []\n    #print(modelAclabels_)\n    if modelAc.labels_[i] == -1:\n        outstring_list.append(postingids[i])\n    else:\n        outstring_list = postingids[modelAclabels_ == modelAclabels_[i]]          #predictions == predictions[i]])\n    final_list = list(set(outstring_list).union(set(myMatching[i])))\n    if(len(final_list) > 50):\n        final_list = final_list[0:50]\n    final_list = \" \".join(final_list)\n    #out.append(final_list)\n    \n    sub_result_dict[postingids[i]] = []\n    sub_result_dict[postingids[i]].append(postingids[i])\n    sub_result_dict[postingids[i]].append(final_list)\n#print(out)\n    ","metadata":{"_uuid":"53a29333-8ba4-4c70-b2e0-8c2cb5fa6291","_cell_guid":"d00be50a-d3a4-4b52-a1d0-4299b267bfca","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_csv_kaggle_sub2(fname, result):\n    # fname = file name\n    # Y is a list/array with class entries\n    \n    # header\n    df = pd.DataFrame.from_dict(result, columns = ['posting_id', 'matches'], orient='index')\n    df.to_csv(path_or_buf = fname, index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df0.insert(1,'matches',out)","metadata":{"_uuid":"e9872d92-dec1-4f3d-aad4-f7ebfb2563ef","_cell_guid":"0438d1dc-5802-4e68-a36c-e86b6ddf4d76","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df0[['posting_id','matches']].to_csv('submission.csv',index=False)","metadata":{"_uuid":"eb45e349-1b7d-443e-9814-882730b4ddbc","_cell_guid":"ec91f799-edc6-4c04-a620-f6a5d524e4c2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"write_csv_kaggle_sub2(\"/kaggle/working/submission.csv\", sub_result_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}