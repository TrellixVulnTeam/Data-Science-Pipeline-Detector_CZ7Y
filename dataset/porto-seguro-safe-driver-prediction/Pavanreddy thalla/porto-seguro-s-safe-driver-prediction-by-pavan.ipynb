{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](http://)# Porto Seguroâ€™s Safe Driver Prediction\n## Predict if a driver will file an insurance claim next year.\n\n### Problem Statment: \n<ul>predict the probability that an auto insurance policy holder files a claim.<ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 65000)\n\nfrom scipy import stats\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n##Synthetic Minority Over-sampling Technique to overcome imbalanced dataset\n#from imblearn.over_sampling import SMOTE \n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, make_scorer\nscore_fun = make_scorer('roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/porto-seguro-safe-driver-prediction/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/porto-seguro-safe-driver-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace(-1, np.NAN)\ntest_data = test_data.replace(-1, np.NAN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test_data['id']\ntest_data.drop(columns='id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_per = df.isna().sum()/df.shape[0]*100\nmissing_values_per[missing_values_per>40]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns='ps_car_03_cat', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_id = df['id']\ny = df['target']\ndf.drop(columns=['id', 'target'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = df.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = []\nreg = []\nfor i in columns:\n    if 'cat' in i:\n        cat.append(i)\n    elif 'bin' in i:\n        cat.append(i)        \n    elif 'reg' in i:\n        reg.append(i)\n    elif 'ind' in i:\n        cat.append(i)\n    elif df[i].dtype=='float64':\n        reg.append(i)\n    else:\n        cat.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[reg] = df[reg].astype('float64')\ndf[cat] = df[cat].astype('O')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df[reg].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cat].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows, columns = df.shape\ndrop_nunique_col = []\nfor col in df.columns:\n    if df[col].nunique == rows or df[col].nunique == 1:\n        drop_nunique_col.append(col)\ndrop_nunique_col    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        X_train[col] = X_train[col].fillna(X_train[col].mode()[0])\n        X_test[col] = X_test[col].fillna(X_train[col].mode()[0])\n        test_data[col] = test_data[col].fillna(X_train[col].mode()[0])\n\n    else:\n        X_train[col] = X_train[col].fillna(X_train[col].mean())\n        X_test[col] = X_test[col].fillna(X_train[col].mean())\n        test_data[col] = test_data[col].fillna(X_train[col].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nprint(y_train.value_counts())\nprint(y_train.value_counts(normalize=True))\nprint(y_train.shape)\n\nsmort = SMOTE(sampling_strategy=0.3, k_neighbors=8)  ## SMOTE Parameters\nX_train, y_train = smort.fit_resample(X_train, y_train)\n\nprint(y_train.value_counts())\nprint(y_train.value_counts(normalize=True))\nprint(y_train.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing -Lable Encoding, MinMax Scaling, Chi2Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelEncoderExt(object):\n    def __init__(self):\n        \"\"\"\n        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n        \"\"\"\n        self.label_encoder = LabelEncoder()\n        # self.classes_ = self.label_encoder.classes_\n\n    def fit(self, data_list):\n        \"\"\"\n        This will fit the encoder for all the unique values and introduce unknown value\n        :param data_list: A list of string\n        :return: self\n        \"\"\"\n        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n        self.classes_ = self.label_encoder.classes_\n\n        return self\n\n    def transform(self, data_list):\n        \"\"\"\n        This will transform the data_list to id list where the new values get assigned to Unknown class\n        :param data_list:\n        :return:\n        \"\"\"\n        new_data_list = list(data_list)\n        for unique_item in np.unique(data_list):\n            if unique_item not in self.label_encoder.classes_:\n                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n\n        return self.label_encoder.transform(new_data_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Le = LabelEncoderExt()\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        Le.fit(X_train[col])\n        X_train[col] = Le.transform(X_train[col]).asdtype('int64')\n        X_test[col] = Le.transform(X_test[col]).asdtype('int64')\n        test_data[col] = Le.transform(test_data[col]).asdtype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mMs = MinMaxScaler()\nfor col in reg:\n        #mMs.fit([X_train[col]])\n        X_train[col] = mMs.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n        X_test[col] = mMs.transform(np.array(X_test[col]).reshape(-1, 1))\n        test_data[col] = mMs.transform(np.array(test_data[col]).reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ch2_Value = []\npValue = []\nfor col in cat:\n    ct = pd.crosstab(X_train[col], y_train)   \n    ch2_Value.append(stats.chi2_contingency(ct)[0])\n    pValue.append(stats.chi2_contingency(ct)[1])\n    \nch2_df = pd.DataFrame()\nch2_df['cat_columns'] = cat\nch2_df['ch2_value'] = ch2_Value\nch2_df['pValue'] = pValue\n\n\n\nprint(\"Before Feature Selection[Ch2_Test] No of Categorical Columns: =======>\", len(cat))\nch2_test_af_col = ch2_df[ch2_df['pValue']<0.06]['cat_columns'].tolist()\nprint(\"After Feature Selection[Ch2_Test] No of Categorical Columns: ========>\", len(ch2_test_af_col))\n\nfinal_col = reg + ch2_test_af_col     ## combing continous and ch2 test outcome columns \n\nX_train = X_train[final_col]\nX_test = X_test[final_col]\ntest_data = test_data[final_col]\n\n\nprint(\"Final Number of Columns : ========>\", len(final_col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfeatures_importance = rf.feature_importances_\nfeatures_importance[::-1].sort()\n\nfeature_imp_df = pd.DataFrame()\nfeature_imp = []\nfor i, col in enumerate(X_train.columns):\n    feature_imp.append(features_importance[i])\n    #print(\"{}. {} ({})\".format(i + 1, col, features_importance[i]))\nfeature_imp_df['cName'] = X_train.columns\nfeature_imp_df['feature_imp_Val'] = feature_imp\n\n#feature_imp_df\n\nplt.figure(figsize=(15, 15))\nplt.plot(np.arange(1, features_importance.shape[0]+1), np.cumsum(features_importance))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## HyperParameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_hyp = RandomForestClassifier(n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {\n    'n_estimators': [50, 75, 100],\n    'criterion' : ['gini', 'entropy'], \n    'max_depth' : [4, 5, 6, 7, 8], \n    'max_leaf_nodes': [20, 30, 40, 50],\n    'min_samples_leaf': [5, 10, 15, 20]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsCV = RandomizedSearchCV(estimator=rf_hyp, param_distributions=rf_params, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsCV.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = rsCV.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_best_Model = rsCV.best_estimator_ ## Choosing Best estimator with best parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_best_Model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cross_val_model(X,y, model, n_splits=3, n_folds=3):\n    'Do split dataset and calculate cross_score'\n    X = np.array(X)\n    y = np.array(y)\n    folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0).split(X, y))\n\n    for j, (train_idx, test_idx) in enumerate(folds):\n        X_train = X[train_idx]\n        y_train = y[train_idx]\n        X_holdout = X[test_idx]\n        y_holdout = y[test_idx]\n\n        print (\"Fit %s Split %d\" % (str(model).split('(')[0], j+1))\n        model.fit(X_train, y_train)\n        cross_score = cross_val_score(model, X_holdout, y_holdout, cv=n_folds, scoring='roc_auc')\n        print(\"         Mean cross_score of \",n_folds,\" Folds : =========:>\", cross_score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_model(X_train, y_train, rf_best_Model, n_splits=5, n_folds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = rf_best_Model.predict(X_test)\ny_predict_proba = rf_best_Model.predict_proba(X_test)[::,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_acc = rf_best_Model.score(X_train, y_train)    # Model Evaluation\ntest_acc =  rf_best_Model.score(X_test, y_test)\n\nrecallScore = recall_score(y_test, y_predict)\nprecisionScore = precision_score(y_test, y_predict)\n\nf1Score = f1_score(y_test, y_predict)\nauc = roc_auc_score(y_test, y_predict_proba)\nfpr, tpr, thrshould = roc_curve(y_test, y_predict_proba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\n\\n\")\nprint(\"Model Name: \", str(rf_best_Model).split(\"(\")[0])\nprint(\"ConfusionMatrix: \\n\", confusion_matrix(y_test, y_predict))    \nprint(\"TrainAcc: ====> {}\".format(train_acc))\nprint(\"TestAccuracy : ====> {}\".format(test_acc))\nprint(\"recall: ====> {}\".format(recallScore))\nprint(\"Precision: ====> {}\".format(precisionScore))\nprint(\"F1Score: ====> {}\".format(f1Score))\nprint(\"AUC: ====> {}\".format(auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.plot(fpr, tpr, label=\"Model Name: \"+str(rf_best_Model).split(\"(\")[0]+\"\\n\"+\"auc=\"+str(auc))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Area Under The Curve AUC-ROC')\n\nplt.legend(loc= 7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Submission ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.DataFrame(columns=['id', 'target'])\nresult_df['id'] = test_id\nresult_df['target'] = rf_best_Model.predict_proba(test_data)[::, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.to_csv(\"Porto Seguro_Submission.csv\", index=False, sep = ',', encoding = 'utf8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}