{"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"source":"#CSE627a Project 1 \n#Kai Wang\n#Kaggle competition: Porto Seguroâ€™s Safe Driver Prediction","metadata":{"_cell_guid":"c2ebbe9b-3445-4002-9d86-343b498a480e","_uuid":"921c385ac4b9637faef19bf5fd6fa84d527ceace"},"cell_type":"markdown"},{"source":"Load the packages","metadata":{"_cell_guid":"463d0f2f-ab40-4d5e-804a-88b2eb4b4666","_uuid":"c0010d1a44fbb7d52981630348ba286f4ad3fc2b"},"cell_type":"raw"},{"source":"import pandas as pd\nimport numpy as np\nfrom numpy import isnan\nfrom pandas import DataFrame\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier","outputs":[],"metadata":{"_cell_guid":"542fd1cf-0afa-4a56-959f-d64b0e495326","_uuid":"6f40db445bdd0a04bdadd6a90bd86ae392fab3aa","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Random Forest was the first algorithm that I used for this project","metadata":{"_cell_guid":"5df967e0-e12c-4fdc-86b8-1363d82309d0","_uuid":"905a73afa7601675cbb15812fafb452b10122420"},"cell_type":"raw"},{"source":"#read files \ntrain = pd.read_csv('../input/train.csv', na_values=-1)\ntest = pd.read_csv('../input/test.csv', na_values=-1)","outputs":[],"metadata":{"_cell_guid":"f35f2f14-98f2-448d-a328-59cab441a99c","_uuid":"a4f97758565a771f66eb61d88aaf0e7fc076b0a9","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print(train.shape, test.shape)","outputs":[],"metadata":{"_cell_guid":"962be4db-8fbe-43e3-84cb-ddbd6b95d028","_uuid":"5b5c1dff82be81050816cab35a670d5e7580df3d"},"execution_count":null,"cell_type":"code"},{"source":"#get the header title\nlist(train)","outputs":[],"metadata":{"_cell_guid":"11686d81-25fa-422a-8423-234b9520a7c7","_uuid":"43df1801b5f0d204e89e6462268bb967bcca10df"},"execution_count":null,"cell_type":"code"},{"source":"train.describe()","outputs":[],"metadata":{"_cell_guid":"4b2b05c2-4c3f-4c6d-8989-cdcd93bff758","_uuid":"a9d18f28035bacfb9f6e0ff6f21ffce34af3b1f8","scrolled":true},"execution_count":null,"cell_type":"code"},{"source":"#drop the id and target cols\nX = train.drop(['id', 'target'], axis=1)\nfeatures = X.columns\nX = X.values\ny = train['target'].values","outputs":[],"metadata":{"_cell_guid":"3bf425c6-8498-416b-b890-95e58cad9493","_uuid":"9585d9f58fb9aebb93910ff1edc8f151a2c4eeef"},"execution_count":null,"cell_type":"code"},{"source":"#get the test ids for results\nout = test['id'].to_frame()\nout['target'] = 0","outputs":[],"metadata":{"_cell_guid":"2ab4439d-fc18-4da2-b78d-713158b4126c","_uuid":"b1afacbe7fb4eedd1ae05d80d0f95a3a0f7df577","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#get the test data\ntest_X = test.drop(['id'],axis=1)\ntest_X = test_X.values","outputs":[],"metadata":{"_cell_guid":"a9dfa4e8-4467-4da8-b55d-9ff94ff954a9","_uuid":"a0b7a4b8c5175b26d764c090a24ed621011da744","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# there is a error message: \n#ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n# for solving this problem, I changed all NaN to 0\nwhnan = isnan(X)\nX[whnan] = 0\nwhnan = isnan(test_X)\ntest_X[whnan] = 0","outputs":[],"metadata":{"_cell_guid":"ac04b201-dbc9-46a6-825c-b5709ee34af7","_uuid":"9c24d84f038e3a9541d9655b341f968d64454c7a","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# train the model with 5-fold cross validation \nkfold = 5  # need to change to 5\nskf = StratifiedKFold(n_splits=kfold, random_state=0)\ntemp = np.zeros(shape=(len(test_X),2))\nfor train_index, test_index in skf.split(X, y):\n\tX_train, X_valid = X[train_index], X[test_index]\n\ty_train, y_valid = y[train_index], y[test_index]\n\n\tclf = RandomForestClassifier(max_depth=2, random_state=0)\n\tclf.fit(X_train, y_train)\n\tprob = clf.predict_proba(test_X)\n\ttemp = np.add(temp,prob)","outputs":[],"metadata":{"_cell_guid":"bf0e2dbe-b8c1-4761-8c04-ed322ab9e79d","_uuid":"4b6efaf29dbde04c8ca671bce54286b0a12d8d09","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#get the results\ntemp =temp / 5\nres = DataFrame(temp[:,1])\nout['target'] = res\nout.to_csv('sub.csv',index = False, float_format = '%.5f')","outputs":[],"metadata":{"_cell_guid":"41e7b893-32a6-48c6-97d1-772953bf33bc","_uuid":"f25c367c117317e7d0524400e8b45a335c190f06","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"After submission, the score is 0.219","metadata":{"_cell_guid":"81f88114-7112-4069-b2f0-70e25d51e5fe","_uuid":"a8646ba682e07c74221664f3b49fb7ead4ffff8c"},"cell_type":"raw"},{"source":"This random forest model is trained with default parameters, then I used different parameters to train the model","metadata":{"_cell_guid":"b61a7c9c-8b2d-477e-8d0e-06ca6893992d","_uuid":"20dc479bf1590a9cb9df9a9feaeee7b481ee2411"},"cell_type":"raw"},{"source":"for train_index, test_index in skf.split(X, y):\n\tX_train, X_valid = X[train_index], X[test_index]\n\ty_train, y_valid = y[train_index], y[test_index]\n\n\tclf = RandomForestClassifier(n_estimators=50, max_depth=2, max_features=\"log2\", random_state=0)\n\tclf.fit(X_train, y_train)\n\tprob = clf.predict_proba(test_X)\n\ttemp = np.add(temp,prob)","outputs":[],"metadata":{"_cell_guid":"ad402673-90e7-443b-8ba2-8d74ea7d5274","_uuid":"120678e2bc123e036f7a1a6c0c54e585f8158cbf","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#get the results\ntemp =temp / 5\nres = DataFrame(temp[:,1])\nout['target'] = res\nout.to_csv('sub.csv',index = False, float_format = '%.5f')","outputs":[],"metadata":{"_cell_guid":"54a425e8-2a96-4a1f-b035-559f0f4d436f","_uuid":"a015747b832e34b254fe6c1e54d19474230266a4","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"After the submission, the score is 0.231. the score improved a little.","metadata":{"_cell_guid":"f4bbb919-6a0f-41ee-887c-a5591f247039","_uuid":"54ca79993ccfacb54666f9f4fcc1f89223493c71"},"cell_type":"raw"},{"source":"#before do another training, \n#I want to analysis the feature importance of the training data\nimport matplotlib.pyplot as plt\nclf = RandomForestClassifier(n_estimators=50, max_depth=2, max_features=\"log2\", random_state=0)\nclf.fit(X,y)\nimportances = clf.feature_importances_","outputs":[],"metadata":{"_cell_guid":"f0190d04-e76f-4528-8c2f-7fefa748416d","_uuid":"314fe261cfb6f7a1f2588f859d147d5a40a25554","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"y_pos = np.arange(len(importances))\nplt.figure(figsize=(6,12))\nplt.title('Feature Importances')\nplt.barh(y_pos, importances, color='b')\nplt.yticks(y_pos,features)\nplt.xlabel('Relative Importance')\nplt.show()","outputs":[],"metadata":{"_cell_guid":"57146e6f-52dd-4325-8c23-a5f29c4333fe","_uuid":"737c5c840e5bdb0c9346ede1a4aed4049c7df67f"},"execution_count":null,"cell_type":"code"},{"source":"From the above figure, we can see that those \"ps_cals_*\" features is useless for training the model. So these features will be removed for further training.","metadata":{"_cell_guid":"515c2a2a-0340-4f0f-93a6-0aaebf055fcb","_uuid":"97589d98b6a089c4b2a56ff7f9c457dd58d89afc"},"cell_type":"raw"},{"source":"col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]","outputs":[],"metadata":{"_cell_guid":"4edbd40a-7892-4d3f-b358-035a03b813bf","_uuid":"8ee040973935e16d4eb933938bc83338e9b1f36d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"train = train.drop(col_to_drop, axis=1)  \ntest = test.drop(col_to_drop, axis=1)  ","outputs":[],"metadata":{"_cell_guid":"d56a4184-1eb4-4baa-8b4d-486584c0bddf","_uuid":"ac64650743fa6a5132f0a89bfe5c28264e005c1d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print(train.shape, test.shape)","outputs":[],"metadata":{"_cell_guid":"87d041ad-0676-44ec-b166-f02e18e5aa4a","_uuid":"29c3c0eca63681881e6ca2d031688e7ee64a285a"},"execution_count":null,"cell_type":"code"},{"source":"#without the \"ps_calc_*\" features model training\nX = train.drop(['id', 'target'], axis=1)\nfeatures = X.columns\nX = X.values\ny = train['target'].values\nout = test['id'].to_frame()\nout['target'] = 0\ntest_X = test.drop(['id'],axis=1)\ntest_X = test_X.values","outputs":[],"metadata":{"_cell_guid":"0f66d0b8-02ef-4e0f-88ec-ae15702ce262","_uuid":"69c0277f8cd6c3b5deea3aa8c5716bf3e21c6ffe","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"whnan = isnan(X)\nX[whnan] = 0\nwhnan = isnan(test_X)\ntest_X[whnan] = 0","outputs":[],"metadata":{"_cell_guid":"664a9487-ae00-41a9-bf6b-cd4e6a22eb75","_uuid":"201061dd3932162f140afda8eb7c508317a3d087","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"for train_index, test_index in skf.split(X, y):\n\tX_train, X_valid = X[train_index], X[test_index]\n\ty_train, y_valid = y[train_index], y[test_index]\n\n\tclf = RandomForestClassifier(n_estimators=50, max_depth=2, max_features=\"log2\", random_state=0)\n\tclf.fit(X_train, y_train)\n\tprob = clf.predict_proba(test_X)\n\ttemp = np.add(temp,prob)","outputs":[],"metadata":{"_cell_guid":"f1dcb1f4-608a-4a79-ab4b-d9ec23d10a5a","_uuid":"893618b19e56d54a4130699e2204c378c3b195c6","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#get the results\ntemp =temp / 5\nres = DataFrame(temp[:,1])\nout['target'] = res\nout.to_csv('/home/kaiwang/Desktop/project1/sub.csv',index = False, float_format = '%.5f')","outputs":[],"metadata":{"_cell_guid":"f1aa64a7-3b6f-46e1-8644-115628e1ce95","_uuid":"8e474da52c4a440f9fca38b924259eb98b3773b1","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"After submission, the score is 0.229. It decreased a little since fewer features are uesd in this training. I also trained the model with different n_estimator and max_features, but the scores did not improved too much. So I decided to try other algorithms. ","metadata":{"_cell_guid":"b216c412-a61f-4ef5-8dc3-fe51d0ab48f7","_uuid":"097aadc9ae4d5095ad59ee30c5009d0891fa8b98"},"cell_type":"raw"},{"source":"#try to use multiple layer perceptron\n#load packages\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom sklearn.model_selection import train_test_split","outputs":[],"metadata":{"_cell_guid":"1795aee1-8279-446f-bb9f-8054a672a311","_uuid":"8813a881562bde5819974c59b3b7638035bb7c5d"},"execution_count":null,"cell_type":"code"},{"source":"#split the data into training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","outputs":[],"metadata":{"_cell_guid":"98331d3b-fa37-4b4e-8bed-3d579bb6b02e","_uuid":"110710813e77080100b4b12b72e4e044ab2c0fab","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#define the model\nmodel = Sequential()\nmodel.add(Dense(512, input_dim=37, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1, activation='sigmoid'))","outputs":[],"metadata":{"_cell_guid":"2e6e3ecf-b2f1-4420-bc27-b3ee8c1d070e","_uuid":"28a17b2fd5c78765a27c1954551bb461356d3e1e","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","outputs":[],"metadata":{"_cell_guid":"315d9c39-f836-463b-97a2-8cfe16d6efa9","_uuid":"49a6ccfae3d7d979cdc9ced76c4e4ed1e41b5b2c","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Fit the model\nmodel.fit(X_train, y_train, epochs=3, batch_size=124)","outputs":[],"metadata":{"_cell_guid":"8d3f5e77-101b-45cf-9561-a7c47b259ba8","_uuid":"e36e4da48e9edd3c7d3368995b869973e1eff3e3"},"execution_count":null,"cell_type":"code"},{"source":"#evaluate the model\nscores = model.evaluate(X_test, y_test)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","outputs":[],"metadata":{"_cell_guid":"14229350-9f64-4793-b3fc-c0bbe260f2bf","_uuid":"f66606a641d6702ffb0d9d1e2e300b1d72e9d63d"},"execution_count":null,"cell_type":"code"},{"source":"#predict the test reuslts\npres = model.predict_proba(test_X,verbose = 0)\nres = DataFrame(pres)\nout['target'] = res\nout.to_csv('sub.csv', index=False, float_format='%.5f') ","outputs":[],"metadata":{"_cell_guid":"3cc4b9bc-789b-4122-94f0-635db57b08b0","_uuid":"210dcbf84f8c665096ee6d4c4627517fe382af1d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"After submission, the score is 0.232, it only improved 0.001 compared to the best score (0.233). Then I tried to do some feature engineering.","metadata":{"_cell_guid":"a28abb40-90c1-4ea2-93bf-2e55b7b2e284","_uuid":"4768a02d51f094b49bec632376047001387b46d7"},"cell_type":"raw"},{"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntwo_way = [('ps_car_13', 'ps_ind_17_bin'), ('ps_car_13', 'ps_ind_05_cat'),\n           ('ps_ind_05_cat', 'ps_reg_03'), ('ps_ind_05_cat', 'ps_ind_17_bin'),\n           ('ps_car_13', 'ps_reg_03'), ('ps_ind_17_bin', 'ps_reg_03')]\n\nthree_way = [('ps_car_13', 'ps_ind_05_cat', 'ps_ind_17_bin'),\n             ('ps_car_13', 'ps_ind_05_cat', 'ps_reg_03'),\n             ('ps_car_13', 'ps_car_13', 'ps_ind_17_bin'),\n             ('ps_ind_05_cat', 'ps_ind_17_bin', 'ps_reg_03'),\n             ('ps_car_13', 'ps_ind_17_bin', 'ps_reg_03'),\n             ('ps_car_13', 'ps_ind_04_cat', 'ps_ind_17_bin')]","outputs":[],"metadata":{"_cell_guid":"89ceebfd-7a0b-4982-8ee6-57331b7c6701","_uuid":"87a957d1f8a470f025b283dfdc506908bc37d671","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"for (x1, x2) in two_way:\n  train[x1 + '_' + x2] = train[x1] * train[x2]\n  test[x1 + '_' + x2] = test[x1] * test[x2]\n\nfor (x1, x2, x3) in three_way:\n  train[x1 + '_' + x2 + '_' + x3] = train[x1] * train[x2] * train[x3]\n  test[x1 + '_' + x2 + '_' + x3] = test[x1] * test[x2] * test[x3]","outputs":[],"metadata":{"_cell_guid":"bdd0bd62-9174-410d-a1f9-1b431bda41d0","_uuid":"f20dcdcb7677f8b03ac42a46d088f52744b99ddb","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print('Train shape:', train.shape)\nprint('Test shape:', test.shape)\n\nprint('Columns:', train.columns)","outputs":[],"metadata":{"_cell_guid":"c3654051-99f5-4653-8fc3-6d38ad95ff9c","_uuid":"ff36d048a9d28087b19b3b3734994f3f5126b9f9"},"execution_count":null,"cell_type":"code"},{"source":"y_train = train['target'].values\nid_train = train['id'].values\nid_test = test['id'].values\n\ntrain = train.drop(['target', 'id'], axis=1)\ntest = test.drop(['id'], axis=1)","outputs":[],"metadata":{"_cell_guid":"48ad57a8-9cef-4793-b0f7-a0bf884e4108","_uuid":"c552c6b5d77155e6dd297d208125a885f22c4eca","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"x_train = np.array(train)\nx_test = np.array(test)","outputs":[],"metadata":{"_cell_guid":"147cfd29-c422-494e-8f7d-e736854213b4","_uuid":"477a2b745db73b582bbff8fc4722cfb74f3a0625","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)","outputs":[],"metadata":{"_cell_guid":"56d5fb47-f5a4-4f22-9b86-3cd47b146a3a","_uuid":"72b0e4ac4b3e5f6f16fb30a76ee7cd97b1b0489b"},"execution_count":null,"cell_type":"code"},{"source":"#use cross validation for multiple layer perceptron training\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\nfrom keras.layers.normalization import BatchNormalization\n\nskf = StratifiedKFold(n_splits=5, random_state=0)\n\nntest = len(x_test)\n\noof_test = np.zeros((ntest,))\noof_test_kf = np.empty((5, ntest))\n\nfor i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n    print(i, ' of ', 5-1)\n    x_tr = x_train[train_index]\n    x_te = x_train[test_index]\n    \n    y_tr = np_utils.to_categorical(y_train[train_index])\n    y_te = np_utils.to_categorical(y_train[test_index])\n    \n    kfold_weight_path = 'nn' + str(i) + '.h5'\n    \n    model = Sequential()\n    model.add(Dense(518, activation = 'relu', input_shape=(x_tr.shape[1],)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Dense(256, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Dense(128, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Dense(2, activation='sigmoid'))\n    \n    model.compile(loss = 'binary_crossentropy',\n                  optimizer = Adam(),\n                  metrics=['accuracy'])\n    callback = [EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 1),\n                ModelCheckpoint(kfold_weight_path, monitor='val_loss', save_best_only=True, verbose=0),\n                ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 6, verbose = 1)]\n    model.fit(x_tr, y_tr,\n              batch_size=1024*2, \n              epochs=10000,\n              verbose=1,\n              validation_data=(x_te, y_te), \n              callbacks = callback)\n    oof_test_kf[i, :] = model.predict(x_test)[:, 1]","outputs":[],"metadata":{"_cell_guid":"5556948e-0993-4017-ade8-ced389b61234","_uuid":"e50bf65f4568c84f8827e596f32c99276f0cc790"},"execution_count":null,"cell_type":"code"},{"source":"#get the results\noof_test[:] = oof_test_kf.mean(axis=0)\npred = oof_test.reshape(-1, 1).ravel()","outputs":[],"metadata":{"_cell_guid":"9cbad136-06da-4378-baf9-37e8d19db644","_uuid":"ac966a6e483265d16006f912ef534a05567e47ad","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"sub = pd.DataFrame()\nsub['id'] = id_test\nsub['target'] = pred\nsub.to_csv('sub.csv', index=False, float_format='%.5f') ","outputs":[],"metadata":{"_cell_guid":"df6bcdc5-19ef-46dc-8be6-8018b3e6e763","_uuid":"2a841c9054012f2c432e987eb4af51bb25671d37","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"After the submission, the score is 0.262. It improved a lot comapred to previous submission. From other kernals, xgboost was proposed with a high score. So next I will try to use xgboost for this project.","metadata":{"_cell_guid":"5da7f0ad-1ece-42ee-a96c-6165e843eeb7","_uuid":"7cd66e23955832ff4b6fb0b4c51694c30214df01"},"cell_type":"raw"},{"source":"import xgboost as xgb\nx_train = np.array(train)\nx_test = np.array(test)\n\nd_test = xgb.DMatrix(np.array(x_test))","outputs":[],"metadata":{"_cell_guid":"b524886d-44dd-4ecd-92e5-704806252fee","_uuid":"2a8910b07baffcb52a52aad059d8ab8a6337d5a5","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#train the model\nfor i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n    print(i, ' of ', 5-1)\n    x_tr = x_train[train_index]\n    x_te = x_train[test_index]\n    \n    y_tr = y_train[train_index]\n    y_te = y_train[test_index]\n    \n    ratio = float(np.sum(y_tr == 1)) / np.sum(y_tr == 0)\n    \n    dtra = xgb.DMatrix(data = x_tr, label = y_tr)\n    dval = xgb.DMatrix(data = x_te, label = y_te) \n    \n    watchlist  = [(dtra,'train'), (dval,'eval')]\n\n    xgb_params = {\n        'min_child_weight': 4,\n        'eval_metric': 'auc',\n        'eta': 0.0125,\n        'colsample_bytree': 0.8,\n        'max_depth': 12,\n        'subsample': 0.8,\n        'alpha': 1,\n        'gamma': 1,\n        'silent': 1,\n        'seed': 0,\n        'nthread':-1,\n        'n_parallel_tree': 1\n    }\n\n    xgb_mod = xgb.train(xgb_params, \n                        dtra,\n                        10000, \n                        watchlist, \n                        early_stopping_rounds=100, \n                        maximize=True, \n                        verbose_eval=100)\n    oof_test_kf[i, :] = xgb_mod.predict(d_test, ntree_limit=xgb_mod.best_ntree_limit+50)\n    ","outputs":[],"metadata":{"_cell_guid":"eee3e409-f825-48b0-bf68-6e6159b1f802","_uuid":"9aae28d7aedae5ec5241add0e2e8e312dd858b05","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#get the results\noof_test[:] = oof_test_kf.mean(axis=0)\npred = oof_test.reshape(-1, 1).ravel()\n\nsub = pd.DataFrame()\nsub['id'] = id_test\nsub['target'] = pred\nsub.to_csv('sub.csv', index=False, float_format='%.5f') ","outputs":[],"metadata":{"_cell_guid":"e4d13e2e-3df6-4918-9d08-71754f47469e","_uuid":"4547066ed7f67de37ea2dbebc80e239a31ca98b4","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"After the submission, the score is 0.275. This is all for this project.","metadata":{"_cell_guid":"465cd663-ce8e-40c5-9a18-2dc9a626060f","_uuid":"a128d6e3dce7893e30b668b889cf4691371a5a47"},"cell_type":"raw"}],"nbformat":4}