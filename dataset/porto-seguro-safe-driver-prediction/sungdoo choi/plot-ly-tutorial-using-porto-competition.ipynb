{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport warnings\nfrom collections import Counter\nfrom sklearn.feature_selection import mutual_info_classif\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd5aa281e2f5cb2f5ce52df6badc57a82450c876"},"cell_type":"code","source":"rows = train.shape[0]\ncolumns = train.shape[1]\nprint(\"The train dataset contains {0} rows and {1} columns\".format(rows, columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e290254c218083130e3539a1363da80fcdba8d43"},"cell_type":"code","source":"train.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8764e3503f45637999d0f83237e5475d3eed989c"},"cell_type":"code","source":"train_copy = train\ntrain_copy = train_copy.replace(-1, np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca10e6cac8ba9377f3f0766b4c1a4a9f8e74c0ab"},"cell_type":"code","source":"import missingno as msno\nmsno.matrix(df=train_copy.iloc[:,2:39], figsize=(20, 14), color=(0.42, 0.1, 0.05))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad7e06defba87e8bfdc82cbce920038c7187ad62"},"cell_type":"code","source":"data = [go.Bar(\n            x = train[\"target\"].value_counts().index.values,\n            y = train[\"target\"].value_counts().values,\n            text='Distribution of target variable'\n    )]\n\nlayout = go.Layout(\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a090d2e8655a456f00fd0af7067f0fac6eced846"},"cell_type":"code","source":"Counter(train.dtypes.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"470e46ffbd09b61aa6eccd9cf45159db89e4e8ea"},"cell_type":"code","source":"train_float = train.select_dtypes(include=['float64'])\ntrain_int = train.select_dtypes(include=['int64'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f753f29c72ef39b9946e5258a7e9a72f20db275"},"cell_type":"code","source":"colormap = plt.cm.magma\nplt.figure(figsize=(16,12))\nplt.title('Pearson correlation of continuous features', y=1.05, size=15)\nsns.heatmap(train_float.corr(),linewidths=0.1,vmax=1.0, square=True, \n            cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2024ae873973c868eb2e3dcb83542fa69ad7a77f"},"cell_type":"code","source":"data = [\n    go.Heatmap(\n        z= train_int.corr().values,\n        x=train_int.columns.values,\n        y=train_int.columns.values,\n        colorscale='Viridis',\n        reversescale = False,\n       \n        opacity = 1.0 )\n]\n\nlayout = go.Layout(\n    title='Pearson Correlation of Integer-type features',\n    xaxis = dict(ticks='', nticks=36),\n    yaxis = dict(ticks='' ),\n    width = 900, height = 700)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='labelled-heatmap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"507755075b2e5d12878227e6e2f0d0d6c7cf0590"},"cell_type":"code","source":"mf = mutual_info_classif(train_float.values,train.target.values,n_neighbors=3, random_state=17 )\nprint(mf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b0028f487174a215abffcb3bcd392793b1c63aa"},"cell_type":"code","source":"bin_col = [col for col in train.columns if '_bin' in col]\nzero_list = []\none_list = []\nfor col in bin_col:\n    zero_list.append((train[col]==0).sum())\n    one_list.append((train[col]==1).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4118fa20a0bcf2806fd8447f69b94e6f034d307"},"cell_type":"code","source":"trace1 = go.Bar(\n    x=bin_col,\n    y=zero_list ,\n    name='Zero count'\n)\ntrace2 = go.Bar(\n    x=bin_col,\n    y=one_list,\n    name='One count'\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='stack',\n    title='Count of 1 and 0 in binary variables'\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8108ca96eaad8dd01b439f6ed0d28201d943c7df"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\nrf.fit(train.drop(['id', 'target'],axis=1), train.target)\nfeatures = train.drop(['id', 'target'],axis=1).columns.values\nprint(\"----- Training Done -----\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"211f3d4fa2b72e555c03a7cf63b42f147e1ee43a"},"cell_type":"code","source":"trace = go.Scatter(\n    y = rf.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        #size= rf.feature_importances_,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = rf.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Random Forest Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51fe26883223e5bff34845b54eb2722c525c8a08"},"cell_type":"code","source":"x, y = (list(x) for x in zip(*sorted(zip(rf.feature_importances_, features), \n                                                            reverse = False)))\ntrace2 = go.Bar(\n    x=x ,\n    y=y,\n    marker=dict(\n        color=x,\n        colorscale = 'Viridis',\n        reversescale = True\n    ),\n    name='Random Forest Feature importance',\n    orientation='h',\n)\n\nlayout = dict(\n    title='Barplot of Feature importances',\n     width = 900, height = 2000,\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=True,\n#         domain=[0, 0.85],\n    ))\n\nfig1 = go.Figure(data=[trace2])\nfig1['layout'].update(layout)\npy.iplot(fig1, filename='plots')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e2e9ef2744c194aaba2f61acf4cc0aaafa82852"},"cell_type":"code","source":"from sklearn import tree\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nimport re\n\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 3)\ndecision_tree.fit(train.drop(['id', 'target'],axis=1), train.target)\n\n# Export our trained model as a .dot file\nwith open(\"tree1.dot\", 'w') as f:\n     f = tree.export_graphviz(decision_tree,\n                              out_file=f,\n                              max_depth = 4,\n                              impurity = False,\n                              feature_names = train.drop(['id', 'target'],axis=1).columns.values,\n                              class_names = ['No', 'Yes'],\n                              rounded = True,\n                              filled= True )\n        \n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n\n# Annotating chart with PIL\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\",)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24c0b4f72a54f417c2d4877dc357b5e5df9bd7ae"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=100, max_depth=3, min_samples_leaf=4, max_features=0.2, random_state=0)\ngb.fit(train.drop(['id', 'target'],axis=1), train.target)\nfeatures = train.drop(['id', 'target'],axis=1).columns.values\nprint(\"----- Training Done -----\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7898a6b739d34f6fb147b6df5dffaf612abefe04"},"cell_type":"code","source":"trace = go.Scatter(\n    y = gb.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        #size= rf.feature_importances_,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = gb.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Gradient Boosting Machine Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08023df0f048e74a4f46492dbad788a2d7dae276"},"cell_type":"code","source":"x, y = (list(x) for x in zip(*sorted(zip(gb.feature_importances_, features), \n                                                            reverse = False)))\ntrace2 = go.Bar(\n    x=x ,\n    y=y,\n    marker=dict(\n        color=x,\n        colorscale = 'Viridis',\n        reversescale = True\n    ),\n    name='Gradient Boosting Classifer Feature importance',\n    orientation='h',\n)\n\nlayout = dict(\n    title='Barplot of Feature importances',\n     width = 900, height = 2000,\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=True,\n    ))\n\nfig1 = go.Figure(data=[trace2])\nfig1['layout'].update(layout)\npy.iplot(fig1, filename='plots')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75d11f72eab1ec39cc582ee03df3b7a99a7c7fc8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}