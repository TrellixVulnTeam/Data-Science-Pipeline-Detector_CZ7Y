{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# from sklearn.preprocessing import MinMaxScaler\n# from sklearn.model_selection import KFold, train_test_split\n# import seaborn as sns\n# import tensorflow as tf\n# from sklearn.utils import shuffle\n# from imblearn.under_sampling import RandomUnderSampler\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = pd.read_csv(\"/kaggle/input/submisson/submisson_cat.csv\")\nnn = pd.read_csv('/kaggle/input/submisson/submission_nn.csv')\nxg = pd.read_csv('/kaggle/input/submisson/submission_xg.csv')\nrf = pd.read_csv('/kaggle/input/submisson/submisson_Rf.csv')\nlg = pd.read_csv('/kaggle/input/submisson/submission_lgbm.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ex = 0.5*lg + 0.5 * cat\n#ex.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = 0.5*lg +0.4*cat + 0.005*rf + 0.005* xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['id'] = cat['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('final_sum.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# train = pd.read_csv('/kaggle/input/train-nova/train_nona.csv', index_col = 0)\n# test = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in train.columns:\n#     if 'calc' in col:\n#         train = train.drop(col, axis=1)\n        \n# for col in test.columns:\n#     if 'calc' in col:\n#         test = test.drop(col, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test = test.drop(['ps_car_03_cat','ps_car_05_cat'], axis=1)\n# for col in ['ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_car_01_cat','ps_car_02_cat','ps_car_07_cat','ps_car_09_cat']:\n#     test[col] = test[col].replace(-1,int(test[col].mode()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in train.columns:\n#     if 'cat' in col:\n#         train[col] = train[col].astype(str)\n\n# for col in test.columns:\n#     if 'cat' in col:\n#         test[col] = test[col].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = pd.get_dummies(train)\n# test = pd.get_dummies(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mmscaler = MinMaxScaler()\n# for col in train.drop(['id','target'],axis=1).columns:\n#     mmscaler.fit(np.array(train[col]).reshape(-1,1))\n#     train[col] = mmscaler.transform(np.array(train[col]).reshape(-1,1))\n\n# for col in test.drop(['id'],axis=1).columns:\n#     mmscaler.fit(np.array(test[col]).reshape(-1,1))\n#     test[col] = mmscaler.transform(np.array(test[col]).reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target = train['target']\n# train = train.drop(['id','target'], axis = 1)\n# test = test.drop(['id'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(train.shape)\n# print(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X, y = RandomUnderSampler(sampling_strategy= 0.4, random_state=42).fit_sample(train, target)\n# X = pd.DataFrame(X, columns = train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.test.is_gpu_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gpu_options = tf.GPUOptions(visible_device_list=\"0\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def to_tensor(data, target, batch_size):\n\n#     ind = pd.DataFrame()\n#     reg = pd.DataFrame()\n#     car = pd.DataFrame()\n#     for col in data.columns:\n#         if 'ind' in col:\n#             ind = pd.concat([ind, train[col]], axis =1)\n#         elif 'reg' in col:\n#             reg = pd.concat([reg, train[col]], axis =1)\n#         else:\n#             car = pd.concat([car, train[col]], axis =1)\n#     y = target\n    \n#     shuffle(ind, random_state =42)\n#     shuffle(reg, random_state =42)\n#     shuffle(car, random_state =42)\n#     shuffle(y, random_state =42)\n    \n#     length = len(ind)\n#     max_batch = length // batch_size +1\n#     index = 0\n#     i = 0\n    \n#     while index<length:\n#         try:\n#             batch_ind = ind.iloc[index : index + batch_size]\n#             batch_reg = reg.iloc[index : index + batch_size]\n#             batch_car = car.iloc[index : index + batch_size]\n#             batch_y = y[index : index + batch_size]\n#         except IndexError:\n#             batch_ind = ind.iloc[index:]\n#             batch_reg = reg.iloc[index:]\n#             batch_car = car.iloc[index:]\n#             batch_y = y[index:]\n    \n#         batch_ind = np.array(batch_ind)\n#         batch_reg = np.array(batch_reg)\n#         batch_car = np.array(batch_car)\n\n#         batch_y = np.array(batch_y).astype(int)\n#         batch_y = np.eye(2)[batch_y]\n\n#         index += batch_size\n#         left = length - index\n#         i += 1\n\n#         yield i, batch_ind, batch_reg, batch_car, batch_y, left, max_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def early_stopping_and_save_model(sess, saver, input_vali_loss, early_stopping_val_loss_list):\n\n#     if len(early_stopping_val_loss_list) != early_stopping_patience:\n#         early_stopping_val_loss_list = [99.99 for _ in range(early_stopping_patience)]\n\n#     early_stopping_val_loss_list.append(input_vali_loss)\n#     if input_vali_loss < min(early_stopping_val_loss_list[:-1]):\n#         saver.save(sess, os.getcwd()+'/model.ckpt')\n#         early_stopping_val_loss_list.pop(0)\n\n#         return True, early_stopping_val_loss_list\n\n#     elif early_stopping_val_loss_list.pop(0) < min(early_stopping_val_loss_list):\n#         return False, early_stopping_val_loss_list\n\n#     else:\n#         return True, early_stopping_val_loss_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropout_rate = 0.3\n# epoch_num = 20000\n# batch_size = 4096\n# learning_rate = 0.001\n# early_stopping_patience = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.reset_default_graph()\n# ind_data = tf.placeholder(tf.float32, [None, 28], name='ind_data')\n# reg_data = tf.placeholder(tf.float32, [None, 3], name='reg_data')\n# car_data = tf.placeholder(tf.float32, [None, 163], name='car_data')\n# y_data = tf.placeholder(tf.float32, [None, 2], name='y_data')\n# initializer = tf.contrib.layers.xavier_initializer()\n# # initializer = tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)\n\n# ind_w_1 = tf.get_variable('ind_data', [28,64], initializer = initializer)\n# ind_b_1 = tf.Variable(tf.zeros([64]), name='ind_b_1')\n# # fc_bn_1 = tf.layers.batch_normalization(tf.matmul(x_data, fc_w_1) + fc_b_1, name = 'bn_1')\n# # fc_z_1 = tf.nn.sigmoid(fc_bn_1, name='fc_z_1')\n# ind_z_1 = tf.nn.sigmoid(tf.matmul(ind_data, ind_w_1) + ind_b_1, name='ind_z_1')\n# ind_d_1 = tf.nn.dropout(ind_z_1, dropout_rate, name='ind_d_1')\n\n# reg_w_1 = tf.get_variable('reg_data', [3,64], initializer = initializer)\n# reg_b_1 = tf.Variable(tf.zeros([64]), name='reg_b_1')\n# # fc_bn_1 = tf.layers.batch_normalization(tf.matmul(x_data, fc_w_1) + fc_b_1, name = 'bn_1')\n# # fc_z_1 = tf.nn.sigmoid(fc_bn_1, name='fc_z_1')\n# reg_z_1 = tf.nn.sigmoid(tf.matmul(reg_data, reg_w_1) + reg_b_1, name='reg_z_1')\n# reg_d_1 = tf.nn.dropout(reg_z_1, dropout_rate, name='fc_d_1')\n\n# car_w_1 = tf.get_variable('car_data', [163,64], initializer = initializer)\n# car_b_1 = tf.Variable(tf.zeros([64]), name='fc_b_1')\n# # fc_bn_1 = tf.layers.batch_normalization(tf.matmul(x_data, fc_w_1) + fc_b_1, name = 'bn_1')\n# # fc_z_1 = tf.nn.sigmoid(fc_bn_1, name='fc_z_1')\n# car_z_1 = tf.nn.sigmoid(tf.matmul(car_data, car_w_1) + car_b_1, name='car_z_1')\n# car_d_1 = tf.nn.dropout(car_z_1, dropout_rate, name='fc_d_1')\n\n# combine = tf.concat([ind_d_1, reg_d_1], axis=1, name='combine')\n# combine = tf.concat([car_d_1, combine], axis=1, name='combine')\n\n# fc_w_2 = tf.get_variable('combine', [192, 256], initializer = initializer)\n# fc_b_2 = tf.Variable(tf.zeros([256]), name='fc_b_2')\n# # fc_bn_2 = tf.layers.batch_normalization(tf.matmul(fc_z_1, fc_w_2) + fc_b_2, name = 'bn_2')\n# # fc_z_2 = tf.nn.sigmoid(fc_bn_2, name='fc_z_2')\n# fc_z_2 = tf.nn.sigmoid(tf.matmul(combine, fc_w_2) + fc_b_2, name='fc_z_2')\n# fc_d_2 = tf.nn.dropout(fc_z_2, dropout_rate, name='fc_d_2')\n\n# fc_w_3 = tf.get_variable('fc_d_2', [256, 2], initializer = initializer)\n# fc_u_3 = tf.matmul(fc_d_2, fc_w_3, name='fc_u_3')\n\n# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=fc_u_3, labels=y_data), name='loss')\n# optimizer = tf.train.AdamOptimizer(learning_rate)\n# training = optimizer.minimize(loss)\n\n# pred_y = tf.nn.softmax(fc_u_3, name='pred_y')\n# pred = tf.equal(tf.argmax(pred_y, 1), tf.argmax(y_data, 1), name='pred')\n# acc = tf.reduce_mean(tf.cast(pred, tf.float32), name='acc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch_index_list = list(range(0, X_train.shape[0], batch_size))\n# vali_batch_list = list(range(0, X_vali.shape[0], batch_size))\n# train_loss_list, vali_loss_list = [], []\n# train_acc_list, vali_acc_list = [], []\n# saver = tf.train.Saver()\n# early_stopping_val_loss_list = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n#     sess.run(tf.global_variables_initializer())\n#     for epoch in range(epoch_num):\n#         total_loss, total_acc, vali_loss, vali_acc = 0, 0, 0, 0\n#         train_gen = to_tensor(X_train, y_train, batch_size)\n#         vali_gen = to_tensor(X_vali, y_vali, batch_size)\n\n#         for i, batch_ind, batch_reg, batch_car, batch_y, left, tot in train_gen:\n#             sess.run(training, feed_dict={ind_data: batch_ind, reg_data:batch_reg, car_data:batch_car, y_data: batch_y})\n#             loss_val, acc_val = sess.run([loss, acc], feed_dict={ind_data: batch_ind, reg_data:batch_reg, car_data:batch_car, y_data: batch_y})    \n#             total_loss += loss_val\n#             total_acc += acc_val\n        \n#         for i, vali_ind, batch_reg, batch_car, vali_y, left, tot in vali_gen:\n#             tmp_vali_loss, tmp_vali_acc, vali_pred_y = sess.run([loss, acc, pred_y],\n#                                                                         feed_dict={ind_data: batch_ind, reg_data:batch_reg, car_data:batch_car, y_data : vali_y})\n#             vali_loss += tmp_vali_loss\n#             vali_acc += tmp_vali_acc\n        \n#         train_loss_list.append(total_loss/len(batch_index_list))\n#         train_acc_list.append(total_acc/len(batch_index_list))\n#         vali_loss_list.append(vali_loss)\n#         vali_acc_list.append(vali_acc)\n        \n#         print('{} / {}'.format(np.argmax(vali_pred_y, axis=1).sum(), len(vali_pred_y)))\n#         print('\\n#%4d/%d' % (epoch + 1, epoch_num), end='  |  ')\n#         print('Avg_loss={:.4f} / Avg_acc={:.4f}'.format(total_loss/len(batch_index_list), total_acc/len(batch_index_list)), end='  |  ')\n#         print('vali_loss={:.4f} / vali_acc={:.4f}'.format(vali_loss/len(vali_batch_list), vali_acc/len(vali_batch_list)), end='  |  ')\n#         print('-'*100)\n        \n#         bool_continue, early_stopping_val_loss_list = early_stopping_and_save_model(sess, saver, vali_loss_list[-1], early_stopping_val_loss_list)\n#         if not bool_continue:\n#             print('{0}\\nstop epoch : {1}\\n{0}'.format('-' * 100, epoch - early_stopping_patience + 1))\n#             break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_test = test\n# y_test = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.reset_default_graph()\n# with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n#     sess.run(tf.global_variables_initializer())\n#     saver = tf.train.import_meta_graph(os.getcwd()+'/model.ckpt'+ '.meta')\n#     saver.restore(sess, os.getcwd()+'/model.ckpt')\n\n#     test_gen = to_tensor(X_test, y_test, batch_size)\n\n#     ind_data = tf.get_default_graph().get_tensor_by_name('ind_data:0')\n#     reg_data = tf.get_default_graph().get_tensor_by_name('reg_data:0')\n#     car_data = tf.get_default_graph().get_tensor_by_name('car_data:0')\n#     y_data = tf.get_default_graph().get_tensor_by_name('y_data:0')\n#     acc = tf.get_default_graph().get_tensor_by_name('acc:0')\n#     loss = tf.get_default_graph().get_tensor_by_name('loss:0')\n#     pred_y = tf.get_default_graph().get_tensor_by_name('pred_y:0')\n#     pred = np.array([])\n#     prob = np.array([])\n#     for i, test_ind, test_reg, test_car, test_y, left, tot in test_gen:\n#         test_loss, test_acc, test_pred_y, test_true_y = sess.run([loss, acc, pred_y, y_data],\n#                                                                  feed_dict={ind_data: test_ind, reg_data:test_reg, car_data:test_car,, y_data: test_y})\n\n#         y_prob = test_pred_y[:,1]\n# #         y_pred = np.argmax(test_pred_y, axis=1)\n# #         pred = np.append(pred, y_pred)\n#         prob = np.append(prob, y_prob)\n#     final_y = pd.DataFrame({'target' : prob})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub['target'] = prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}