{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Porto Seguro Safe Driver Prediction Competation\n\nhttps://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data\n\nIn this competition, we will predict the probability that an auto insurance policy holder files a claim.\n\nPlease read the overview and Evaluation process.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We already knew that the `target` columns signifies whether or not a claim was filed for that policy holder.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## In here first i am going to focus on the Imbalanced Class handling.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Library","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np  \nimport pandas as pd  \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set the label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LABELS = [\"No Claim Filed\", \"Claim Filed\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Load","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target / Class Exploration","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Get the count of target.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we already know that the proportion of records with `target` = 1 (Claim Filed) is far less than `target` = 0 (No Claim Filed). \n\nThis can lead to a model that has great accuracy but does have any added value in practice.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.target);\nplt.xlabel('Is Filed Claim?');\nplt.ylabel('Number of occurrences');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets visualize the same with more precise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count_classes = pd.value_counts(data['target'], sort = True)\n\ncount_classes.plot(kind = 'bar', rot = 0)\n\nplt.title(\"Claims Distribution\")\n\nplt.xticks(range(2), LABELS)\n\nplt.xlabel(\"Claims --> \")\n\nplt.ylabel(\"Frequency --> \")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Techniques to handle Class Imbalance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A widely adopted technique for dealing with highly unbalanced datasets is called resampling. \n\nIt consists of removing samples from the majority class (under sampling) and / or adding more examples from the minority class (over sampling).\n\nDespite the advantage of balancing classes, these techniques also have their weaknesses. \n\n* The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. \n* In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n\nTo implement this resampling techniques we are going to use Python imbalanced-learn module (`imblearn`). It is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n\nOther resampling techniques like SMOTE; SMOTETomek etc are also there, which will see below.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Before we start with handling, lets have X and y.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('target', axis = 1)\ny = data.target\n\ndata.shape, X.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_us.value_counts()[0] \n# X.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets have the counts in some kind of DataFrame to see the difference in a glance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_table = pd.DataFrame()\n\ndata_table['technique'] = ['Original Data']\ndata_table['X_Shape'] = [X.shape[0]]\ndata_table['y_Shape'] = [y.shape[0]]\ndata_table['target_0'] = [y.value_counts()[0]]\ndata_table['target_1'] = [y.value_counts()[1]]\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1: Under Sampling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1.1 Under Sampling using NearMiss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import NearMiss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nm = NearMiss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_us, y_us = nm.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape for Imbalanced Class :')\ndisplay(X.shape, y.shape)\nprint('Count of target : {} '.format(y.value_counts()))\n\n\nprint('Shape for Balanced Class :')\ndisplay(X_us.shape, y_us.shape)\nprint('Count of target : {} '.format(y_us.value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_row = {'technique': 'Under Sampling - NearMiss', 'X_Shape': X_us.shape[0], 'y_Shape':y_us.shape[0], 'target_0': y_us.value_counts()[0], 'target_1' : y_us.value_counts()[1]}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2 Under Sampling using RandomUnderSampler\n`RandomUnderSampler` is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. \n\nUnder-sample the majority class(es) by randomly picking samples with or without replacement.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rus = RandomUnderSampler(random_state=42, replacement=True)  \nX_rus, y_rus = rus.fit_resample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_row = {\n    'technique': 'Under Sampling - RandomUnderSampler', \n    'X_Shape': X_rus.shape[0], \n    'y_Shape':y_rus.shape[0], \n    'target_0': y_rus.value_counts()[0], \n    'target_1' : y_rus.value_counts()[1]\n}\n\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2: Over Sampling\nOne way to fight imbalance data is to generate new samples in the minority classes. The most naive strategy is to generate new samples by randomly sampling with replacement of the currently available samples. The `RandomOverSampler` offers such a scheme.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os = RandomOverSampler() # Default sampling_strategy='auto'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_os, y_os = os.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_row = {\n    'technique': 'Over Sampling - Auto', \n    'X_Shape': X_os.shape[0], \n    'y_Shape':y_os.shape[0], \n    'target_0': y_os.value_counts()[0], \n    'target_1' : y_os.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os2 = RandomOverSampler(sampling_strategy=0.5)\n\nX_os2, y_os2 = os2.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_row = {\n    'technique': 'Over Sampling - half', \n    'X_Shape': X_os2.shape[0], \n    'y_Shape':y_os2.shape[0], \n    'target_0': y_os2.value_counts()[0], \n    'target_1' : y_os2.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3: SMOTE\n`SMOTE` (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, based on those that already exist. It works randomly picingk a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n\nThis technique generates synthetic data for the minority class.\n\nhttps://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE(sampling_strategy = 'minority')\nX_smote, y_smote = smote.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_row = {\n    'technique': 'SMOTE - minority', \n    'X_Shape': X_smote.shape[0], \n    'y_Shape':y_smote.shape[0], \n    'target_0': y_smote.value_counts()[0], \n    'target_1' : y_smote.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are various other parameters such as `random_state`, `k_neighbors` etc which can be changed as well.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4: SMOTETomek\nIts a combination of over-sampling and under-sampling, using the SMOTE and Tomek links techniques.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smk = SMOTETomek(random_state=9)\nX_smk, y_smk = smk.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_row = {\n    'technique': 'SMOTETomek_9', \n    'X_Shape': X_smk.shape[0], \n    'y_Shape':y_smk.shape[0], \n    'target_0': y_smk.value_counts()[0], \n    'target_1' : y_smk.value_counts()[1]\n}\ndata_table = data_table.append(new_row,ignore_index=True)\n\ndata_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can try with various other random state.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Note: One can select any of the technique based on the problem, but make sure to use proper and correct evulation metrix.\n\nDont go with accuracy; score. \n\nSome of the metrics, which might works best with such imbalanced dataset are as below. Try considering them.\n1. Confusion Matrix\n2. Precision\n3. Recall\n4. F1-Score\n5. AUC-ROC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}