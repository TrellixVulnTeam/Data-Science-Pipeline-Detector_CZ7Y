{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\n\nimport seaborn as sns\nimport missingno as msno\n\nimport xgboost as xgb\nimport warnings\nsns.set(style='white', context = 'notebook', palette='deep')\nwarnings.filterwarnings(\"ignore\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"np.random.seed(1989)\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train.shape)\nprint(\"Test shape : \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55bdbfedb1bb6f392d9e7bfd793be67ae3d79b00"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52595b026978b6d2a84f678e9b2fa37f53249fa3"},"cell_type":"code","source":"print(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae47d1c62b08d4b36e52443c24166bffcb54d451"},"cell_type":"code","source":"print(test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d7af0e26b907bdf2f5b188782fcd6a43d2b6bba"},"cell_type":"code","source":"targets = train['target'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"880af4fbefbc7cd6ee571acf6d89145d2ea8945f"},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nax = sns.countplot(x=targets)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(targets)),\n               (p.get_x()+ 0.3, p.get_height()+10000))\nplt.title('Distribution of Target', fontsize = 20)\nplt.xlabel('Claim', fontsize =20)\nplt.ylabel('Frequency [%]', fontsize= 20)\nax.set_ylim(top = 700000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5cd4d36f744e83df8128ba58bc3b41639f2ef9c"},"cell_type":"markdown","source":"2.1 Data check"},{"metadata":{"trusted":true,"_uuid":"6a15372d3c46f306c2560621167bd2f7e5606315"},"cell_type":"code","source":"print('Id is unique.') if train.id.nunique() == train.shape[0] else print('Oh no')\nprint('Train and test sets are distinct.') if len(np.intersect1d(train.id.values, test.id.values)) == 0 else print('Oh no')\nprint('We do not need to worry about missing values.') if train.count().min() == train.shape[0] else print('Oh no')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34d038486f2e61ec65c5157558b83a17b76304d0"},"cell_type":"markdown","source":"2.2 Find Null data"},{"metadata":{"trusted":true,"_uuid":"efe1921b2be3735b75d2e15e0f415ea5407ff5a2"},"cell_type":"code","source":"import missingno as msno\n\ntrain_null = train\ntrain_null = train_null.replace(-1, np.NAN)\n\nmsno.matrix(df= train_null.iloc[:, :], figsize=(20,14), color=(0.8,0.5,0.2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"491979b727102327842907a243a3dcbd9db6d795"},"cell_type":"code","source":"test_null = test\ntest_null = test_null.replace(-1, np.NAN)\n\nmsno.matrix(df=test_null.iloc[:,:], figsize=(20,14), color=(0.8,0.5,0.2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ecc60fb336ef776ab5f9b97e152c383c983c266"},"cell_type":"code","source":"train_null = train_null.loc[:, train_null.isnull().any()]\ntest_null = test_null.loc[:, test_null.isnull().any()]\n\nprint(train_null.columns)\nprint(test_null.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc01e9168d2199d2ba3352e22a1999988bd60b53"},"cell_type":"code","source":"print('Columns \\t Number of NaN')\nfor column in train_null.columns:\n    print('{}: \\t {}'.format(column, len(train_null[column][np.isnan(train_null[column])])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c8ad599033e88e00523e6f5357cf482ae7d39a1"},"cell_type":"markdown","source":"Feature analysis"},{"metadata":{"trusted":true,"_uuid":"10420ce6382951c2bb026f6698a5fab57f402ad8"},"cell_type":"code","source":"#divides all features in to 'bin', 'cat' and 'etc' group.\n\nfeature_list = list(train.columns) # train의 컬럼들을 리스트화해서 feature_list에 넣음\ndef groupFeatures(features): # groupFeatures 함수 정의 파라미터로 features(리스트)를 받음\n    features_bin = [] # features_bin 리스트 생성\n    features_cat = [] # features_cat 리스트생성\n    features_etc = [] # features_etc 리스트 생성\n    for feature in features : # 파라미터로 받은 features 리스트를 하나씩 빼서 for문\n        if 'bin' in feature: # feature에 'bin' 이라는 단어가 들어가면\n            features_bin.append(feature) # features_bin 리스트에 feature를 추가\n        elif 'cat' in feature: # 또는 'cat'이라는 단어가 들어가면\n            features_cat.append(feature) #features_cat에 추가\n        elif 'id' in feature or 'target' in feature: #또는 feature에 'id' 또는 'target'이 들어가면\n            continue # 다음꺼 계속\n        else: # 그것도 아니면 features_etc에 추가\n            features_etc.append(feature)\n    return features_bin, features_cat, features_etc\n\nfeature_list_bin, feature_list_cat, feature_list_etc = groupFeatures(feature_list)\n\n#feature_list_bin, cat, etc 에 groupFeature 함수에 feature_list를 파라미터로 넣은 return 값들을 넣음\n\nprint(\"# of binary feature : \", len(feature_list_bin)) # 길이들을 출력\nprint(\"# of categorical feature : \", len(feature_list_cat))\nprint(\"# of other feature : \", len(feature_list_etc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff276156a75502a7a50c98030eddffac9fe814ff"},"cell_type":"code","source":"def TrainTestHistogram(train, test, feature):   # TrainTestHistogram 함수 정의 train, test, feature를 파라미터로 받음\n    fig, axes = plt.subplots(len(feature), 2, figsize=(10,40)) # feature길이 행 , 2열로 subplot 생성 크기 10,40 사이즈\n    fig.tight_layout() # 그래프랑 글자들끼리 겹치지 않게 딱 들어맞게 만들어줌\n    \n    left = 0\n    right = 0.9\n    bottom = 0.1\n    top = 0.9\n    wspace = 0.3\n    \n    hspace = 0.7\n    \n    plt.subplots_adjust(left=left, bottom = bottom, right=right, top = top, wspace=wspace, hspace=hspace)\n    # 그래프들의 간격을 조정\n    count = 0\n    \n    for i, ax in enumerate(axes.ravel()): # ravel 함수. numpy에 있는 함수로 여러 리스트로 되어있는 것을 하나로 만들어줌.\n        # enumerate는 리스트에 인덱스를 포함하게 만든다. 그래서 i에 인덱스 저장\n        # ax에 값 저장.\n        if i % 2 == 0 :  # i가 짝수이면.\n            title = 'Train : ' + feature[count] # title에 train + feature의 count 번째에 있는 값으로 title 정의\n            ax.hist(train[feature[count]], bins =30, normed = False)\n            # 히스토그램 그리기    bins = 30은 30개의 막대기로 구분한다는 뜻. 몇개의 막대기로 구분할 것인가.\n            #normed = false 는 확률밀도가 아니라 빈도를 표시한다는 뜻.\n            ax.set_title(title) # 제목 설정\n            \n        else: # i가 홀수이면\n            title = 'Test : ' + feature[count]\n            ax.hist(test[feature[count]], bins = 30, normed = False)\n            ax.set_title(title) # 제목설정\n            count = count + 1 # 카운트 증가","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f8a549bf33c25257642f004efd1fe57fb546cb0"},"cell_type":"code","source":"TrainTestHistogram(train,test,feature_list_bin)\n# TrainTestHistogram 함수에 train, test, feature_list_bin 을 넣음","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55ae149a43802b5c91a3ed000bf711f1e5588b20"},"cell_type":"code","source":"TrainTestHistogram(train, test, feature_list_cat)\n\n# TrainTestHistogram 함수에 train, test, feature_list_cat 을 넣음","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"803347d45dcad0b340a461c3057f867a9d05b136"},"cell_type":"code","source":"TrainTestHistogram(train, test, feature_list_etc)\n\n# TrainTestHistogram 함수에 train, test, feature_list_etc 을 넣음","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc4f821ee13dff92669c2a6245a16d0b5a5e1ba9"},"cell_type":"code","source":"left = 0\nright = 0.9\nbottom = 0.1\ntop = 0.9\nwspace = 0.3\n\nhspace = 0.7\n\nfig, axes = plt.subplots(13,2,figsize=(10,40))\n# plt.subplots 13행 2열 10 40사이즈 생성\nplt.subplots_adjust(left=left, bottom=bottom, right = right, top = top, wspace=wspace, hspace=hspace)\n\nfor i, ax in enumerate(axes.ravel()):\n    title = 'Train: ' + feature_list_etc[i] # title 변수에 'Train' + etc의 i번째에있는 값 더해서 title 정의\n    ax.hist(train[feature_list_etc[i]], bins=20,normed=True)\n    # normed = True는 정규분포의 확률밀도 함수로 나타낸다..\n    ax.set_title(title) # 제목 생성\n    ax.text(0, 1.2, train[feature_list_etc[i]].head(), horizontalalignment = 'left',\n           verticalalignment='top', style = 'italic', bbox={'facecolor': 'red', 'alpha':0.2, 'pad' : 10},\n           transform = ax.transAxes)\n    # https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.text.html 참고..\n    # 크기, 내용, text 위치들 , italic 채 , bbox 위에 사각형을 만듦 .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eedaac6afbdfbf14f43844c9a007d4114f5271d6"},"cell_type":"code","source":"etc_ordianal_features = ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01',\n                    'ps_reg_02', 'ps_car_11', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03',\n                    'ps_calc_04', 'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08',\n                    'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13',\n                    'ps_calc_14']\netc_continuous_features = ['ps_reg_03', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']\n\ntrain_null_columns = train_null.columns # train_null의 컬럼들을 저장\ntest_null_columns = test_null.columns # test_null의 컬럼들을 저장.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1975f7c9c8c99aec203fe2f27aacbfadd673529"},"cell_type":"code","source":"for feature in train_null_columns : # train_null_columns에 들어있는 컬럼들을 feature로 받아.\n    if 'cat' in feature or 'bin' in feature: # feature에 'cat' 또는 'bin'이 들어있으면\n        train_null[feature].fillna(train_null[feature].value_counts().idxmax(), inplace= True)\n        # train_null[feature]의 값들의 개수를 각각(예: 1이 3개 2가 2개 3이 4개...등) 센다음에 그 값들의 개수가 가장 큰 걸로 nan값을 채움.\n        #inplace = true 를 사용해야 train_null[feature]에 해당 내용이 반영된다.\n    elif feature in etc_continuous_features: # 또는 etc_continuous_features에 feature가 있으면\n        train_null[feature].fillna(train_null[feature].median(), inplace=True)\n        # nan 값을 중앙 값으로 채운다.\n    elif feature in etc_ordianal_features: # 또는 etc_rodianal_feature에 feature가 있으면.\n        train_null[feature].fillna(train_null[feature].value_counts().idxmax(), inplace=True)\n        # 맨위와 마찬가지\n    else :\n        print(feature)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe4739b203c0ddcd8861dbe8e0804ce086a4a0b2"},"cell_type":"code","source":"for feature in test_null_columns: # 테스트 마찬가지\n    if 'cat' in feature or 'bin' in feature:\n        # For categorical and binary features with postfix, substitue null values with the most frequent value to avoid float number.\n        test_null[feature].fillna(test_null[feature].value_counts().idxmax(), inplace=True)\n    elif feature in etc_continuous_features:\n        test_null[feature].fillna(test_null[feature].median(), inplace=True)\n    elif feature in etc_ordianal_features:\n        # For categorical and binary features which was assumed, substitue null values with the most frequent value to avoid float number.\n        test_null[feature].fillna(test_null[feature].value_counts().idxmax(), inplace=True)\n    else:\n        print(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9dd506e586a5f91b1883edbeb317985573d825c"},"cell_type":"code","source":"for feature in train_null_columns: # train_null_columns의 값들을 feature에 넣어\n    train[feature] = train_null[feature]\n   # train의 feature의 컬럼에   train_null 의 feature를 넣음\n# \n\nfor feature in test_null_columns:  \n    test[feature] = test_null[feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65302feb34ca700dc1d162da10ce724dee351066"},"cell_type":"code","source":"msno.matrix(df=train.iloc[:,:], figsize=(20,14), color=(0.3,0.6,0.3))\n\n# 널 값이 얼마나 들어있는지 볼수 있는 그래프 그림. 행열 처음부터 끝까지 크기, 색깔","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28f6f83ea366d1a897cd42af887bb962211c268f"},"cell_type":"code","source":"msno.matrix(df=test.iloc[:,:], figsize=(20,14), color = (0.2,0.3,0.8))\n\n# 널 값이 얼마나 들어있는지 볼수 있는 그래프 그림. 행열 처음부터 끝까지 크기, 색깔","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c62a0222e2fb6117511ecd138ccb5ef73d6c4642"},"cell_type":"code","source":"def oneHotEncode_dataframe(df, features):\n    for feature in features:\n        temp_onehot_encoded = pd.get_dummies(df[feature])\n        column_names = [\"{}_{}\".format(feature, x) for x in temp_onehot_encoded.columns]\n        temp_onehot_encoded.columns = column_names\n        df = df.drop(feature, axis= 1)\n        df = pd.concat([df, temp_onehot_encoded], axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4b0afad73d382cd5ec6a5a7637751822773549a"},"cell_type":"code","source":"train = oneHotEncode_dataframe(train, feature_list_cat)\ntest = oneHotEncode_dataframe(test, feature_list_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5e6a64aaf023e31a3858f60aba7fe6c40d728b5"},"cell_type":"code","source":"def gini(actual, pred, compcol = 0, sortcol = 1):\n    assert(len(actual) == len(pred))\n    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype = np.float)\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    totalLosses = all[:, 0].sum()\n    giniSum = all[:, 0].cumsum().sum() / totalLosses\n    \n    giniSum -= (len(actual) + 1) /2.\n    return giniSum / len(actual)\n\ndef gini_normalized(a, p):\n    return gini(a,p) / gini(a,a)\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"360189442bce31b69de838d70503d78ff928c28e"},"cell_type":"markdown","source":"3.1 Using stratified shuffle split"},{"metadata":{"trusted":true,"_uuid":"7c8bac540a1559d48ba1a655fd48bf17ccfd2853"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nn_split = 3\nSSS = StratifiedShuffleSplit(n_splits=3, test_size = 0.5, random_state = 1989)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fac6228d478e9036b4e812c516f34a2976ab021b"},"cell_type":"code","source":"params = {\n    'min_child_weight' : 10.0,\n    'max_depth' : 7,\n    'max_delta_step': 1.8,\n    'colsample_bytree' : 0.4,\n    'subsample' : 0.8,\n    'eta' : 0.025,\n    'gamma' : 0.65,\n    'num_boost_round' : 700\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d538bf260374ce6a059f51418239221e7d3370aa"},"cell_type":"code","source":"X = train.drop(['id', 'target'], axis = 1).values\ny = train.target.values\ntest_id = test.id.values\ntest = test.drop('id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b469ef7cfb0c1c0aa3c60de390596c6d5508db5f"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['id'] = test_id\nsub['target'] = np.zeros_like(test_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb7a3763e5337543db95928ed7cb923f4e721661"},"cell_type":"code","source":"SSS.get_n_splits(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d955bd5d58820690867f394fdf5544a0cefcb9a7"},"cell_type":"code","source":"print(SSS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d785e0235c52ee724a27e4a8927a32c373397a6c"},"cell_type":"code","source":"for train_index, test_index in SSS.split(X,y):\n    print(\"TRAIN: \", train_index, \"TEST: \", test_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ada31b242f8fd5e8fee0718c76199336e18c6d21"},"cell_type":"code","source":"for i, (train_index, test_index) in enumerate(SSS.split(X,y)):\n    print('--------# {} of {} shuffle split----------'.format(i + 1, n_split))\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = y[train_index], y[test_index]\n    \n    d_train = xgb.DMatrix(X_train, y_train)\n    d_valid = xgb.DMatrix(X_valid, y_valid)\n    d_test = xgb.DMatrix(test.values)\n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n    \n    model = xgb.train(params, d_train, 2000, watchlist,\n                     early_stopping_rounds=100, feval =gini_xgb, maximize = True, verbose_eval = 100)\n    \n    print('----- # {} of {} prediction-------'.format(i + 1, n_split))\n    \n    p_test = model.predict(d_test)\n    sub['target'] = sub['target'] + p_test/n_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8977b23f599db274a8cfa2f9930e1d7832ba6b9a"},"cell_type":"code","source":"# sub.to_csv('stratifiedShuffleSplit_xgboost.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed445111fac3ec2d0fda4a69373fdcf6f45bf269"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}