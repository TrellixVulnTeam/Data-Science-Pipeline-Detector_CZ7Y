{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\npd.set_option('display.max_rows', 1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\ndesired_apriori=0.05\n\n# Get the indices per target value\nidx_0 = train[train.target == 0].index\nidx_1 = train[train.target == 1].index\n\n# # Get original number of records per target value\nnb_0 = len(train.loc[idx_0])\nnb_1 = len(train.loc[idx_1])\n\n\n\n# # Calculate the undersampling rate and resulting number of records with target=0\nundersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\nundersampled_nb_0 = int(undersampling_rate*nb_0)\nprint('Rate to undersample records with target=0: {}'.format(undersampling_rate))\nprint('Number of records with target=0 after undersampling: {}'.format(undersampled_nb_0))\n\n# Randomly select records with target=0 to get at the desired a priori\nundersampled_idx = shuffle(idx_0, random_state=37, n_samples=undersampled_nb_0)\n\n# Construct list with remaining indices\nidx_list = list(undersampled_idx) + list(idx_1)\n\n# Return undersample data frame\ntrain = train.loc[idx_list].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat((train.loc[:,'ps_ind_01':'ps_calc_20_bin'], test.loc[:,'ps_ind_01':'ps_calc_20_bin']))\ndf = df.replace(-1, np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df.columns:\n    print(f\"{column}: {df[column].nunique()}\")\n    if df[column].nunique() < 10:\n        print(f\"{df[column].value_counts()}\")\n    print(\"====================================\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_details(df):\n    b = pd.DataFrame()\n    b['Missing value'] = df.isnull().sum()\n    b['N unique value'] = df.nunique()\n    b['dtype'] = df.dtypes\n    return b\nbasic_details(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Dropping the variables with too many missing values\nvars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\ndf.drop(vars_to_drop, inplace=True,  axis=1)\ncol_to_drop = df.columns[df.columns.str.startswith('ps_calc_')]\ndf.drop(col_to_drop, inplace=True, axis=1)\n\ndef missing_value(df):\n    col = df.columns\n    for i in col:\n        if df[i].isnull().sum()>0:\n            df[i].fillna(df[i].mode()[0],inplace=True)\n            \nmissing_value(df)\n\n# for c in df.select_dtypes(include=['float64']).columns:\n#     df[c]=df[c].astype(np.float32)\n    \n# for c in df.select_dtypes(include=['int64']).columns[2:]:\n#     df[c]=df[c].astype(np.int8)\n    \n\ndef category_type(df):\n    col = df.columns\n    for i in col:\n        if (df[i].nunique()<=104) and (df[i].nunique()>2) :\n            df[i] = df[i].astype('category')\ncategory_type(df)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tot_cat_col = list(df.select_dtypes(include=['category']).columns)\nnum_col = [c for c in df.columns if c not in tot_cat_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def descrictive_stat_feat(df):\n    df = pd.DataFrame(df)\n    dcol= [c for c in df.columns if df[c].nunique()>=10]\n    d_median = df[dcol].median(axis=0)\n    d_mean = df[dcol].mean(axis=0)\n    q1 = df[dcol].apply(np.float32).quantile(0.25)\n    q3 = df[dcol].apply(np.float32).quantile(0.75)\n    \n    #Add mean and median column to data set having more then 10 categories\n    for c in dcol:\n        df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n        df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n        df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n        df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n    return df\n\ndf = descrictive_stat_feat(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def OHE(df,column):\n    cat_col = column\n    len_df = df.shape[0]\n    c2,c3 = [],{}\n    \n    print('Categorical feature',len(column))\n    for c in cat_col:\n        if df[c].nunique()>2 :\n            c2.append(c)\n            c3[c] = 'ohe_'+c\n    \n    df = pd.get_dummies(df, prefix=c3, columns=c2, drop_first=True)\n    return df\ndf = OHE(df,tot_cat_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier(df,columns):\n    for i in columns:\n        quartile_1,quartile_3 = np.percentile(df[i],[25,75])\n        quartile_f,quartile_l = np.percentile(df[i],[1,99])\n        IQR = quartile_3-quartile_1\n        lower_bound = quartile_1 - (1.5*IQR)\n        upper_bound = quartile_3 + (1.5*IQR)\n        print(i,lower_bound,upper_bound,quartile_f,quartile_l)\n                \n        df[i].loc[df[i] < lower_bound] = quartile_f\n        df[i].loc[df[i] > upper_bound] = quartile_l\n        \noutlier(df,num_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating matrices for feature selection:\nX_train = df[:train.shape[0]]\nX_test_fin = df[train.shape[0]:]\ny = train.target\nX_train['Y'] = y\ndf = X_train\ndf.head() ## DF for Model training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Correlation with output variable\n# cor = df.corr()\n# cor_target = (cor['Y'])\n# #Selecting highly correlated features (8% level)\n# relevant_features = cor_target[(cor_target<=-0.00) | (cor_target>=0.00) ]\n# relevant_features.sort_values(ascending = False).head(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_memory_usage(df):\n    \"\"\" The function will reduce memory of dataframe\n    Note: Apply this function after removing missing value\"\"\"\n    intial_memory = df.memory_usage().sum()/1024**2\n    print('Intial memory usage:',intial_memory,'MB')\n    for col in df.columns:\n        mn = df[col].min()\n        mx = df[col].max()\n        if df[col].dtype != object:            \n            if df[col].dtype == int:\n                if mn >=0:\n                    if mx < np.iinfo(np.uint8).max:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < np.iinfo(np.uint16).max:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < np.iinfo(np.uint32).max:\n                        df[col] = df[col].astype(np.uint32)\n                    elif mx < np.iinfo(np.uint64).max:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)\n            if df[col].dtype == float:\n                df[col] =df[col].astype(np.float32)\n    \n    red_memory = df.memory_usage().sum()/1024**2\n    print('Memory usage after complition: ',red_memory,'MB')\n    \nreduce_memory_usage(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndef gini(y, pred):\n    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n    gs -= (len(y) + 1) / 2.\n    return gs / len(y)\n\ndef gini_xgb(pred, y):\n    y = y.get_label()\n    return 'gini', gini(y, pred) / gini(y, y)\n\nX = df.drop('Y', axis=1)\ny = df.Y\n\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=4242)\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nd_test = xgb.DMatrix(X_test_fin)\n\nparams = {\n        'objective':'binary:logistic',        \n        'max_depth':8,\n        'learning_rate':0.07,\n        'eval_metric':'auc',\n        'min_child_weight':6,\n        'subsample':0.8,\n        'colsample_bytree':0.8,\n        'seed':45,\n        'reg_lambda':1.3,\n        'reg_alpha':8,\n        'gamma':10,\n        'scale_pos_weight':1.6,\n        'nthread':-1\n}\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nnrounds=2000  # need to change to 2000\nmodel = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \n                          feval=gini_xgb, maximize=True, verbose_eval=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['ID'] = test['id']\nsub['target'] = model.predict(d_test)\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}