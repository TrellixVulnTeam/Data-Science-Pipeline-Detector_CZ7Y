{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"본 글은 Bert Carremans 님의 https://www.kaggle.com/bertcarremans/data-preparation-exploration 을 참조하였음을 밝힙니다. 좋은 커널 공유에 감사드립니다.\n\nThis page is originated from the masterwork of Bert Carremans (https://www.kaggle.com/bertcarremans/data-preparation-exploration). I'm honored to step on the giant's shoulder. I appreciate you, indeed.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# from sklearn.preprocessing import Imputer  # imputer 더 이상 지원안함.\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.utils import shuffle\nfrom sklearn.ensemble import RandomForestClassifier\n\npd.set_option('display.max_columns', 100)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T14:51:51.777783Z","iopub.execute_input":"2021-05-29T14:51:51.778219Z","iopub.status.idle":"2021-05-29T14:51:52.990434Z","shell.execute_reply.started":"2021-05-29T14:51:51.778126Z","shell.execute_reply":"2021-05-29T14:51:52.989614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Table of Contents\n1. [데이터의 전체적인 특징](#chapter1)\n2. [메타데이터프레임 만들기](#chapter2)\n3. [통계 분석](#chapter3)\n4. [데이터 전처리](#chapter4)\n5. [EDV(Exploratory Data Visualization)](#chapter5)\n6. [Feature Enginering](#chapter6)\n7. [Feature 고르기](#chapter7)\n8. [Feature 스케일링](#chapter8)","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/porto-seguro-safe-driver-prediction/train.csv\")\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:51:52.992058Z","iopub.execute_input":"2021-05-29T14:51:52.992437Z","iopub.status.idle":"2021-05-29T14:51:56.224883Z","shell.execute_reply.started":"2021-05-29T14:51:52.992382Z","shell.execute_reply":"2021-05-29T14:51:56.22393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/porto-seguro-safe-driver-prediction/test.csv\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:51:56.227177Z","iopub.execute_input":"2021-05-29T14:51:56.227741Z","iopub.status.idle":"2021-05-29T14:52:00.513583Z","shell.execute_reply.started":"2021-05-29T14:51:56.227697Z","shell.execute_reply":"2021-05-29T14:52:00.512728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 해당 데이터의 전체적 특징 <a class=\"anchor\" id=\"chapter1\"></a>\n대회를 수행하기 위해서 필요한 데이터 상세 내용의 전체 요약입니다.\n- 비슷한 그룹핑에 들어있는 피쳐는 다음과 같이 표시되어 있음. (ind, reg, car, calc ...)\n- bin 이라고 되어 있는 칼럼은 binary, cat은 고양이가 아니라 카테고리형 데이터이다.\n- 아무런 표시가 없는 데이터 칼럼은 연속적인 데이터이다.\n- 결측치는 NaN이 아니라 -1로 표시되어 있다.\n- Target 칼럼은 0이면 내년도에 보험에 들지 않았고, 1이면 보험을 들었다. ","metadata":{}},{"cell_type":"code","source":"train_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.515201Z","iopub.execute_input":"2021-05-29T14:52:00.515546Z","iopub.status.idle":"2021-05-29T14:52:00.548365Z","shell.execute_reply.started":"2021-05-29T14:52:00.515509Z","shell.execute_reply":"2021-05-29T14:52:00.547217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"앞으로 체크해야 할것\n- binary 변수들\n- 정수값으로 구성되어 있는 카테고리 변수들\n- 정수나 실수값으로 구성되어 있는 변수들\n- -1로 되어 있는 결측치\n- 타겟 변수와 id 변수","metadata":{}},{"cell_type":"markdown","source":"train_df 살펴보자","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.549867Z","iopub.execute_input":"2021-05-29T14:52:00.550253Z","iopub.status.idle":"2021-05-29T14:52:00.650137Z","shell.execute_reply.started":"2021-05-29T14:52:00.550215Z","shell.execute_reply":"2021-05-29T14:52:00.649207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"595212개의 행이 존재하고, 59개의 칼럼이 존재한다. 그중 실수 칼럼은 10개, 정수 칼럼은 49개이다.","metadata":{}},{"cell_type":"markdown","source":"테스트 데이터도 확인해보자.","metadata":{}},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.651379Z","iopub.execute_input":"2021-05-29T14:52:00.651893Z","iopub.status.idle":"2021-05-29T14:52:00.781492Z","shell.execute_reply.started":"2021-05-29T14:52:00.651851Z","shell.execute_reply":"2021-05-29T14:52:00.780438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"892816개의 행, 58개의 열로 구성되어 있다. test데이터셋은 target이 존재하지 않으므로 문제가 없어보인다.","metadata":{}},{"cell_type":"markdown","source":"### Metadata <a class=\"anchor\" id=\"chapter2\"></a>\n효과적으로 데이터프레임을 분석하기 위해서, 우리는 변수들에 관한 메타 정보들을 새롭게 저장할 것이다. 메타데이터는 우리가 상세한 분석이나 시각화, 모델링 등에 활용될 수 있다.\n아래는 데이터의 특성에 따라 4가지 항목으로 분류한 것이다. 영어로 적는게 더 편할 것 같아 따로 한글로 바꾸진 않았다,\n* role : input, ID, target\n* level : nominal, interval, ordinal, binary\n* keep : True or False\n* dtype : int, float, str","metadata":{}},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.782966Z","iopub.execute_input":"2021-05-29T14:52:00.783349Z","iopub.status.idle":"2021-05-29T14:52:00.790698Z","shell.execute_reply.started":"2021-05-29T14:52:00.783308Z","shell.execute_reply":"2021-05-29T14:52:00.789773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"아래는 metadata를 분류하는 작업이다. ","metadata":{}},{"cell_type":"code","source":"data = []\nfor f in train_df.columns :\n    # role 정의하기\n    if f == \"target\" :\n        role = \"target\"\n    elif f == \"id\" :\n        role = \"id\"\n    else :\n        role = \"input\"\n        \n    # level 정의하기\n    if (\"bin\" in f) or (f == \"target\") :\n        level = \"binary\"\n    elif (\"cat\" in f) or f ==\"id\" :\n        level = \"nominal\"\n    elif train_df[f].dtype == float :\n        level = \"interval\"\n    elif train_df[f].dtype == int :\n        level = \"ordinal\"\n        \n    # id값만 제외하고 모든 값들에 keep 을 True로 설정\n    keep = True\n    if f == \"id\" :\n        keep = False\n    \n    # 데이터타입을 정의\n    dtype = train_df[f].dtype\n    \n    # 위에서 구한 메타데이터를 하나의 딕셔너리로 담는다.\n    f_dict = {\n        \"varname\": f,\n        \"role\" : role,\n        \"level\" : level,\n        \"keep\" : keep,\n        \"dtype\" : dtype\n    }\n    data.append(f_dict)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.793803Z","iopub.execute_input":"2021-05-29T14:52:00.794535Z","iopub.status.idle":"2021-05-29T14:52:00.804173Z","shell.execute_reply.started":"2021-05-29T14:52:00.794497Z","shell.execute_reply":"2021-05-29T14:52:00.803211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"메타데이터를 데이터프레임에 저장한다.","metadata":{}},{"cell_type":"code","source":"meta = pd.DataFrame(data, columns=[\"varname\", \"role\", \"level\", \"keep\", \"dtype\"])\nmeta.set_index(\"varname\", inplace=True)\nmeta","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.806507Z","iopub.execute_input":"2021-05-29T14:52:00.806925Z","iopub.status.idle":"2021-05-29T14:52:00.836515Z","shell.execute_reply.started":"2021-05-29T14:52:00.806887Z","shell.execute_reply":"2021-05-29T14:52:00.835586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"예시로, 숫자 데이터가 포함되어 있고 dropped 되지 않은 열을 불러온다.","metadata":{}},{"cell_type":"code","source":"meta[(meta.level == \"nominal\") & (meta.keep)].index","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.839822Z","iopub.execute_input":"2021-05-29T14:52:00.840126Z","iopub.status.idle":"2021-05-29T14:52:00.851327Z","shell.execute_reply.started":"2021-05-29T14:52:00.840099Z","shell.execute_reply":"2021-05-29T14:52:00.850636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"아래는 role과 level이 총 몇개가 들어있는지에 대한 데이터프레임이다.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame({\"count\" : meta.groupby([\"role\", \"level\"])[\"role\"].count()})","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.852488Z","iopub.execute_input":"2021-05-29T14:52:00.852983Z","iopub.status.idle":"2021-05-29T14:52:00.867527Z","shell.execute_reply.started":"2021-05-29T14:52:00.852852Z","shell.execute_reply":"2021-05-29T14:52:00.866395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({\"count\" : meta.groupby([\"role\", \"level\"])[\"role\"].count()}).reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.868951Z","iopub.execute_input":"2021-05-29T14:52:00.869436Z","iopub.status.idle":"2021-05-29T14:52:00.886553Z","shell.execute_reply.started":"2021-05-29T14:52:00.8694Z","shell.execute_reply":"2021-05-29T14:52:00.885704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 통계 분석 <a class=\"anchor\" id=\"chapter3\"></a>\n\n보통 통계 분석을 할때는 describe()함수를 사용하지만, mean, std, 등을 카테고리나 id 값에 사용하는 것은 적절하지 않다. 우리는 그 대신 아까 구한 메타 데이터를 이용한다. 메타 데이터 덕분에 우리는 describe()를 사용하고 싶은 칼럼만 더 쉽게 구할 수 있다.","metadata":{}},{"cell_type":"markdown","source":"### 구간 값 변수","metadata":{}},{"cell_type":"code","source":"v = meta[ (meta.level == \"interval\") & (meta.keep)].index\nv\n# 구간값이 있는 칼럼의 이름만 구했다.","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.887893Z","iopub.execute_input":"2021-05-29T14:52:00.888199Z","iopub.status.idle":"2021-05-29T14:52:00.896753Z","shell.execute_reply.started":"2021-05-29T14:52:00.888173Z","shell.execute_reply":"2021-05-29T14:52:00.895659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 구한 칼럼들을 describe()함수에 넣는다.\ntrain_df[v].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:00.898399Z","iopub.execute_input":"2021-05-29T14:52:00.898825Z","iopub.status.idle":"2021-05-29T14:52:01.177731Z","shell.execute_reply.started":"2021-05-29T14:52:00.898788Z","shell.execute_reply":"2021-05-29T14:52:01.176777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* min을 잘 살펴보자.\n* min이 -1이 있는 칼럼을 나열한다.\n","metadata":{}},{"cell_type":"markdown","source":"### reg 변수\n- ps_reg_03가 결측치 포함\n- 각 변수들의 최소-최대값의 범위는 굉장히 다양하다. 정규화를 사용할 수 있지만, 정규화는 classifier에 달려있다.","metadata":{}},{"cell_type":"markdown","source":"### car 변수\n- ps_car_12, ps_car_14가 결측치를 포함한다.\n- 스케일링 사용할것임","metadata":{}},{"cell_type":"markdown","source":"### calc 변수\n- 결측치 없음.\n- 세 calc 최대값이 모두 0.9이다. \n- 세 calc 변수들은 비슷한 분포를 가지고 있다.","metadata":{}},{"cell_type":"markdown","source":"전체적으로, 범위 변수들의 범위가 상당히 작다. 아마도 로그화나 다른 데이터 변형 작업이 실행되었을 가능성이 있다 (개인정보 보호를 위해?)\n","metadata":{}},{"cell_type":"markdown","source":"### 순열 변수들","metadata":{}},{"cell_type":"code","source":"v = meta[ (meta.level == \"ordinal\") & (meta.keep) ].index\ntrain_df[v].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:01.179152Z","iopub.execute_input":"2021-05-29T14:52:01.179516Z","iopub.status.idle":"2021-05-29T14:52:01.60185Z","shell.execute_reply.started":"2021-05-29T14:52:01.179478Z","shell.execute_reply":"2021-05-29T14:52:01.600827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- ps_car_11에 결측치 포함\n- 이 값에 스케일링을 넣으면 표준화 가능","metadata":{}},{"cell_type":"markdown","source":"### 이진 변수들","metadata":{}},{"cell_type":"code","source":"v = meta[ (meta.level == \"binary\") & (meta.keep)].index\ntrain_df[v].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:01.60342Z","iopub.execute_input":"2021-05-29T14:52:01.604076Z","iopub.status.idle":"2021-05-29T14:52:02.0001Z","shell.execute_reply.started":"2021-05-29T14:52:01.604031Z","shell.execute_reply":"2021-05-29T14:52:01.997768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이진변수이므로 모두 0,1만 들어있다.\n- target이 포함되어있는 이진 변수들의 평균은 3.645%로, 매우 불균형적으로 구성되어 있다.\n- 낮은 평균을 고려해보면 대부분의 경우 대부분의 타겟값들은 0이라고 할 수 있다.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"### 불균형 클래스 조정하기 <a class=\"anchor\" id=\"chapter4\"></a>\n위에서 설명했듯, 타겟 칼럼이 1인 비율은 0인 비율에 비해 훨씬 낮은 것을 알 수 있다. 이 결론을 바탕으로 모델을 만들때 꽤 정확하게 예측하는 모델을 만들 수는 있지만, 다른 추가된 값을 실질적으로 포함할 수 있다. 이것을 바탕으로, 2개의 방법을 고려해볼수 있겠다.\n- target이 1인 항목을 oversampling 하는것.\n- target이 0인 항목을 undersampling 하는것.\n\n(그 외에도 다른 여러 방법들이 있다. [MachineLearningMastery.com](https://www.kaggleusercontent.com/kf/1676042/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..BpxnVrgBAuCqyykqSJ6rRg.sG9fZig1ih6alTOjfM8BU0n0yWwYUrDMWnn7gAWRUTIPvMBMYoj5yQY1vnnrGEvz5AzBC7BcY5WHrfrYinI9dKs2LGrCtKHzzJOxHn5yjaCIyQOTduufatzf-i-s4az0TBmjzwD_PsCDJ6bLYDB0pl3vc60cq3n_ffCmSnOiqwfGYJbk3dDGN-rSX38ZLPDfPxyIkMAHM2SAzzINip-uDk1PaxzzjkZ5ORN9WnirQOFONaKRnin9SRxJteTfl3wBdC9-1owwSrsSNJrlTUjGMP-bENnhuiZnUfURh5aibHmwm8oaccaREQriYQP3M4ldrdAAwORXoAmVVW1V2KWfpEfe6M0L4DqlXi1X3qcynHj8WBBlxqnLyhAL-PF0EGZeqB_jPkudXq0ZXGdHPbqwsPS_ZkbcUVSVdNhSx-NmwKL_bjlYHUAwrSU0kUdoDMYhye_xj6z4e5rqzxfTgXiiABdXYPCNOXX2lqTzQnnlHOLDhCM4SxbzGzdPklVi1L-LwAzVTz9kYDGzwNuomCn9bcGz6DZkNOVeMOfwzSpQuf8qMDM1-yjbZXdj-iDTDDApybgt8M-ukCLE5Z48K7SPY_rmWdWV75ads1RvRNuJY_i_OeciAZ0GyiruGfrMvXMQ0L2LsW6fREg2-WsIhk11Oc53-xyeOSmH6jl-8KRunbk.ZY90E-09ljdpHL8dqGb6_A/(https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n)\n- 현재 트레이닝 모델에 있는 데이터 셋이 많으므로, target이 0인 항목을 undersampling을 하는것으로 결정한다.","metadata":{}},{"cell_type":"code","source":"desired_apriori = 0.10\n\n# 타겟의 인덱스 구하기\nidx_0 = train_df.query(\"target == 0\").index\nidx_1 = train_df.query(\"target == 1\").index\n\nidx_0\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.001531Z","iopub.execute_input":"2021-05-29T14:52:02.004408Z","iopub.status.idle":"2021-05-29T14:52:02.191252Z","shell.execute_reply.started":"2021-05-29T14:52:02.004369Z","shell.execute_reply":"2021-05-29T14:52:02.190481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx_1","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.194878Z","iopub.execute_input":"2021-05-29T14:52:02.196787Z","iopub.status.idle":"2021-05-29T14:52:02.205894Z","shell.execute_reply.started":"2021-05-29T14:52:02.196741Z","shell.execute_reply":"2021-05-29T14:52:02.204897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"target이 0인 행이 573518개인 반면, target이 1인 행은 21694개 밖에 되지 않는다. ","metadata":{}},{"cell_type":"code","source":"# 각 행의 갯수 저장\nnb_0 = len(idx_0)\nnb_1 = len(idx_1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.209873Z","iopub.execute_input":"2021-05-29T14:52:02.211905Z","iopub.status.idle":"2021-05-29T14:52:02.217296Z","shell.execute_reply.started":"2021-05-29T14:52:02.211865Z","shell.execute_reply":"2021-05-29T14:52:02.216544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# undersampling을 할 비율\nundersample_rate = ((1-desired_apriori) *nb_1) / (nb_0 * desired_apriori)\nundersampled_nb_0 = int(undersample_rate * nb_0)\nprint(f\"언더샘플을 할 비율 : {undersample_rate}\")\nprint(f\"언더샘플 후에 target 0의 개수 : {undersampled_nb_0}\")\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.221216Z","iopub.execute_input":"2021-05-29T14:52:02.221709Z","iopub.status.idle":"2021-05-29T14:52:02.23203Z","shell.execute_reply.started":"2021-05-29T14:52:02.221668Z","shell.execute_reply":"2021-05-29T14:52:02.231262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 목표 priori에 도달하기 위해 언더샘플된 랜덤으로 target=0 행의 인덱스의 순서를 섞는다.\nundersampled_idx = shuffle(idx_0, random_state=37, n_samples=undersampled_nb_0)\n\n# 두 인덱스들을 합쳐 하나의 리스트로 저장\nidx_list = list(undersampled_idx) + list(idx_1) \n\n# undersample된 데이터프레임을 새롭게 저장한다.\ntrain_df = train_df.loc[idx_list].reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.233228Z","iopub.execute_input":"2021-05-29T14:52:02.234871Z","iopub.status.idle":"2021-05-29T14:52:02.588212Z","shell.execute_reply.started":"2021-05-29T14:52:02.234818Z","shell.execute_reply":"2021-05-29T14:52:02.587389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.5894Z","iopub.execute_input":"2021-05-29T14:52:02.589931Z","iopub.status.idle":"2021-05-29T14:52:02.600429Z","shell.execute_reply.started":"2021-05-29T14:52:02.589889Z","shell.execute_reply":"2021-05-29T14:52:02.599173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 전처리 <a class=\"anchor\" id=\"chapter4\"></a>","metadata":{}},{"cell_type":"markdown","source":"### 결측치 확인\n- 결측치는 -1로 저장되어 있다.","metadata":{}},{"cell_type":"code","source":"vars_with_missing = []\n\nfor f in train_df.columns :\n    missings = train_df[train_df[f] == -1][f].count()\n    if missings > 0 :\n        vars_with_missing.append(f)\n        missings_perc = missings/train_df.shape[0]\n        \n        print(f\"{f}칼럼은 {missings}개의 결측치가 있습니다. {missings_perc:.2%}\")\n        \n\nprint(f\"전체 {len(vars_with_missing)}개의 결측치가 있습니다.\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.606078Z","iopub.execute_input":"2021-05-29T14:52:02.606353Z","iopub.status.idle":"2021-05-29T14:52:02.755433Z","shell.execute_reply.started":"2021-05-29T14:52:02.606327Z","shell.execute_reply":"2021-05-29T14:52:02.754568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ps_car_03_cat와 ps_car_05_cat 는 결측치가 각각 69%, 44%로 너무 많다. 칼럼을 삭제하는게 더 좋을 것 같다.\n* 다른 카테고리형 칼럼들은 결측치가 매우 미소하므로 결측치 부분만 제거해주도록 하자.\n* ps_reg_03 카럼은 총 17%의 결측치가 있다. 이 칼럼은 연속적인 값이므로 평균을 구해서 채워넣도록 하자.\n* ps_car_11은 1개의 결측치가 있다. 평균값을 구해서 넣어주도록 하자.\n* ps_car_14는 전체의 7퍼센트가 결측치이고 연속값이므로 평균을 채워주도록 하자.","metadata":{}},{"cell_type":"code","source":"# ps_car_03_cat과 ps_car_05_cat 칼럼 제거\ntrain_df.drop([\"ps_car_03_cat\",\"ps_car_05_cat\" ], axis=1, inplace=True)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.757637Z","iopub.execute_input":"2021-05-29T14:52:02.758139Z","iopub.status.idle":"2021-05-29T14:52:02.818944Z","shell.execute_reply.started":"2021-05-29T14:52:02.758102Z","shell.execute_reply":"2021-05-29T14:52:02.817949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 메타 데이터프레임 업데이트\nmeta.loc[[\"ps_car_03_cat\",\"ps_car_05_cat\"], \"keep\"] = False\nmeta","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.820456Z","iopub.execute_input":"2021-05-29T14:52:02.820985Z","iopub.status.idle":"2021-05-29T14:52:02.847675Z","shell.execute_reply.started":"2021-05-29T14:52:02.820934Z","shell.execute_reply":"2021-05-29T14:52:02.846288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer as Imputer","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.849306Z","iopub.execute_input":"2021-05-29T14:52:02.849713Z","iopub.status.idle":"2021-05-29T14:52:02.861425Z","shell.execute_reply.started":"2021-05-29T14:52:02.849667Z","shell.execute_reply":"2021-05-29T14:52:02.860529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 임퓨팅 하기 0\nmean_imp = Imputer(missing_values = -1, strategy=\"mean\")\nmode_imp = Imputer(missing_values=-1, strategy=\"most_frequent\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.862791Z","iopub.execute_input":"2021-05-29T14:52:02.863262Z","iopub.status.idle":"2021-05-29T14:52:02.867729Z","shell.execute_reply.started":"2021-05-29T14:52:02.863208Z","shell.execute_reply":"2021-05-29T14:52:02.866593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 결측치 처리\ntrain_df[\"ps_reg_03\"] = mean_imp.fit_transform(train_df[[\"ps_reg_03\"]]).ravel()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.869368Z","iopub.execute_input":"2021-05-29T14:52:02.869903Z","iopub.status.idle":"2021-05-29T14:52:02.887329Z","shell.execute_reply.started":"2021-05-29T14:52:02.869863Z","shell.execute_reply":"2021-05-29T14:52:02.886603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"ps_reg_03\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.888561Z","iopub.execute_input":"2021-05-29T14:52:02.888959Z","iopub.status.idle":"2021-05-29T14:52:02.896162Z","shell.execute_reply.started":"2021-05-29T14:52:02.888922Z","shell.execute_reply":"2021-05-29T14:52:02.895292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"ps_car_14\"] = mean_imp.fit_transform(train_df[[\"ps_car_14\"]]).ravel()\ntrain_df[\"ps_car_12\"] = mean_imp.fit_transform(train_df[[\"ps_car_12\"]]).ravel()\ntrain_df[\"ps_car_11\"] = mean_imp.fit_transform(train_df[[\"ps_car_11\"]]).ravel()\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.897659Z","iopub.execute_input":"2021-05-29T14:52:02.898305Z","iopub.status.idle":"2021-05-29T14:52:02.990675Z","shell.execute_reply.started":"2021-05-29T14:52:02.898261Z","shell.execute_reply":"2021-05-29T14:52:02.989633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 결측치 다시 확인\nvars_with_missing = []\n\nfor f in train_df.columns :\n    missings = train_df[train_df[f] == -1][f].count()\n    if missings > 0 :\n        vars_with_missing.append(f)\n        missings_perc = missings/train_df.shape[0]\n        \n        print(f\"{f}칼럼은 {missings}개의 결측치가 있습니다. {missings_perc:.2%}\")\n        \n\nprint(f\"전체 {len(vars_with_missing)}개의 결측치가 있습니다.\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:02.992147Z","iopub.execute_input":"2021-05-29T14:52:02.992575Z","iopub.status.idle":"2021-05-29T14:52:03.073589Z","shell.execute_reply.started":"2021-05-29T14:52:02.992516Z","shell.execute_reply":"2021-05-29T14:52:03.07258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이제 categorical 데이터를 정제해준다.","metadata":{}},{"cell_type":"markdown","source":"### 카테고리형 변수 내의 cardinality(카테고리의 종류) 체크하기\ncardinality는 한 카테고리 내에 있는 다른 종류의 값의 개수입니다. 현재는 없지만 나중에 우리가 가짜 더미 변수들을 카테고리변수에서 가져와 만들건데, 그래서 카테고리 변수 내의 인자값이 얼마나 있는지를 알아야합니다. 각 변수들을 각각 처리해야하지 않으면 나중에 더미 데이터를 만들때 문제가 있을 수도 있습니다.","metadata":{}},{"cell_type":"code","source":"meta","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.074994Z","iopub.execute_input":"2021-05-29T14:52:03.075352Z","iopub.status.idle":"2021-05-29T14:52:03.097351Z","shell.execute_reply.started":"2021-05-29T14:52:03.075311Z","shell.execute_reply":"2021-05-29T14:52:03.096315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 메타 데이터프레임에서 카테고리형 데이터만 가져옴\nv = meta[(meta.level == \"nominal\") & (meta.keep)].index\nv","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.098732Z","iopub.execute_input":"2021-05-29T14:52:03.099127Z","iopub.status.idle":"2021-05-29T14:52:03.108764Z","shell.execute_reply.started":"2021-05-29T14:52:03.099091Z","shell.execute_reply":"2021-05-29T14:52:03.107966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for f in v : \n    # cardinality 구하기\n    dist_values = train_df[f].value_counts().shape[0]\n    print(f\"변수 {f}는 총 {dist_values}개의 종류로 되어 있습니다.\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.110223Z","iopub.execute_input":"2021-05-29T14:52:03.110619Z","iopub.status.idle":"2021-05-29T14:52:03.142559Z","shell.execute_reply.started":"2021-05-29T14:52:03.110583Z","shell.execute_reply":"2021-05-29T14:52:03.14163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ps_car_11_cat 변수가 104개의 값을 가지고 있는 것을 확인했습니다. 이제 이 타겟을 frequency encoding을 이용해서 인코딩 해줍니다.","metadata":{}},{"cell_type":"code","source":"# add_noise, 인코딩 함수 선언.\n\n\n# Script by https://www.kaggle.com/ogrellier\n# Code: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n\ndef add_noise(series, noise_level) :\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\ndef target_encode(train_series = None, test_series= None, target = None, \n                 min_samples_leaf = 1, smoothing = 1, noise_level=0) :\n    '''\n    Smoothing 과정은 Daniele Micchi-Barreca님의 글을 참조해서 만들었습니다.\n    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n    \n    train_series : pd.Series로 저장된 train의 카테고리형 칼럼\n    test_series : pd.Series로 저장된 test의 카테고리형 칼럼\n    target : pd.Series로 저장된 target 값\n    min_samplies_leaf (int) : 카테고리 평균을 고려한 최소 샘플 개수\n    smoothing (int) : 카테고리 평균과 prior 을 밸런싱하는 smoothing effect\n    '''\n    # asserting해준다. \n    assert len(train_series) == len(target)\n    assert train_series.name == test_series.name\n    temp = pd.concat([train_series, target], axis=1)\n    \n    # target 평균 계산하기\n    averages = temp.groupby(by=train_series.name)[target.name].agg([\"mean\", \"count\"])\n    \n    # smoothing 구하기\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing) )\n    \n    # average를 모든 타겟 데이타에 적용합니다.\n    prior = target.mean()\n    # count 값이 클 수록, full_avg는 적게 영향을 미칩니다.\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    \n    # 구한 averages를 통해 train_series와 test_series에 적용합니다.\n    ft_train_series = pd.merge(train_series.to_frame(train_series.name),\n                              averages.reset_index().rename(columns={\"index\" : target.name, \n                                                                    target.name : \"average\"}),\n                              on=train_series.name,\n                              how = \"left\")[\"average\"].rename(train_series.name + \"_mean\").fillna(prior)\n    # pd.merge는 인덱스를 저장하지 않으므로 인덱스를 다시 설정해주자.\n    ft_train_series.index = train_series.index\n    # fit test_series\n    ft_test_series = pd.merge(test_series.to_frame(test_series.name),\n                             averages.reset_index().rename(columns={\"index\" : target.name,\n                                                                   target.name : \"average\"}),\n                             on=test_series.name, \n                              how=\"left\")[\"average\"].rename(train_series.name + \"_mean\").fillna(prior)\n    # pd.merge는 인덱스를 저장하지 않으므로 인덱스를 다시 설정해주자.\n    ft_test_series.index = test_series.index\n    \n    return add_noise(ft_train_series, noise_level), add_noise(ft_test_series, noise_level)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.143805Z","iopub.execute_input":"2021-05-29T14:52:03.144173Z","iopub.status.idle":"2021-05-29T14:52:03.155902Z","shell.execute_reply.started":"2021-05-29T14:52:03.144137Z","shell.execute_reply":"2021-05-29T14:52:03.154716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 인코딩\ntrain_encoded, test_encoded = target_encode(train_df[\"ps_car_11_cat\"],\n                                           test_df[\"ps_car_11_cat\"],\n                                           target=train_df.target,\n                                           min_samples_leaf=100,\n                                           smoothing=10,\n                                           noise_level=0.01)\n\n# 인코딩 값 저장\ntrain_df[\"ps_car_11_cat_te\"] = train_encoded\ntrain_df.drop(\"ps_car_11_cat\", inplace=True, axis=1)\nmeta.loc[\"ps_car_11_cat\", \"keep\"] = False  # meta 데이터프레임 업데이트\ntest_df[\"ps_car_11_cat_te\"] = test_encoded\ntest_df.drop('ps_car_11_cat', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.157306Z","iopub.execute_input":"2021-05-29T14:52:03.157793Z","iopub.status.idle":"2021-05-29T14:52:03.530975Z","shell.execute_reply.started":"2021-05-29T14:52:03.157757Z","shell.execute_reply":"2021-05-29T14:52:03.530073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 확인작업\ntrain_df[\"ps_car_11_cat_te\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.533059Z","iopub.execute_input":"2021-05-29T14:52:03.533312Z","iopub.status.idle":"2021-05-29T14:52:03.544857Z","shell.execute_reply.started":"2021-05-29T14:52:03.533286Z","shell.execute_reply":"2021-05-29T14:52:03.54374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"카테고리 데이터가 잘 인코딩 되었다.","metadata":{}},{"cell_type":"markdown","source":"## EDV(Exploratory Data Visualization)  <a class=\"anchor\" id=\"chapter5\"></a>\n### 데이터 시각화 하기","metadata":{}},{"cell_type":"markdown","source":"### 카테고리형 변수\n카테고리형 변수들과 타겟이 1인 고객의 비율을 알아보자.","metadata":{}},{"cell_type":"code","source":"# 카테고리형 변수들 이름 가져오기\nv = meta[(meta.level == \"nominal\") & (meta.keep)].index\nv","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.546353Z","iopub.execute_input":"2021-05-29T14:52:03.547064Z","iopub.status.idle":"2021-05-29T14:52:03.554278Z","shell.execute_reply.started":"2021-05-29T14:52:03.547019Z","shell.execute_reply":"2021-05-29T14:52:03.553145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for f in v : \n    plt.figure()\n    fig, ax = plt.subplots(figsize = (20, 10))\n    \n    # category형 값 당 존재하는 타겟이 1인 항목의 비율 계산\n    cat_perc = train_df[[f, \"target\"]].groupby([f], as_index=False).mean()\n#     print(cat_perc)\n    # value 값으로 정렬\n    cat_perc.sort_values(by=\"target\", ascending=False, inplace=True)\n#     print(cat_perc)\n    \n    # 막대그래프 그리기\n    sns.barplot(ax = ax, x = f, y=\"target\", data=cat_perc, order=cat_perc[f])\n    plt.ylabel(\"% target\", fontsize=18)\n    plt.xlabel(f, fontsize=18)\n    plt.tick_params(axis=\"both\", which=\"major\", labelsize=18)\n    plt.title(f, fontsize=18)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:03.555997Z","iopub.execute_input":"2021-05-29T14:52:03.556752Z","iopub.status.idle":"2021-05-29T14:52:05.818397Z","shell.execute_reply.started":"2021-05-29T14:52:03.556708Z","shell.execute_reply":"2021-05-29T14:52:05.81758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"위에서 본 것과 같이 결측치가 많이 존재하는 변수들이 있다. 그렇기 떄문에 많은 결측치들을 별도의 카테고리 값으로 만드는것이 mode로 replace하는 것보다 더 바람직하다. 결측치를 가지고 있는 고객들은 더 많이 (물론 100%는 아니지만) 보험을 드는 경향이 있다. ","metadata":{}},{"cell_type":"markdown","source":"### 범위 변수들\n이제는 범위값을 가지고 있는 변수들의 상관관계를 확인해보도록 하자. 상관관계를 알아볼 때 가장 사용하기 좋은 것은 히트맵으로 시각화 하는 방법이다. [Michael Waskom 님의 글을 참조하였다.](http://seaborn.pydata.org/examples/many_pairwise_correlations.html)","metadata":{}},{"cell_type":"code","source":"# 히트맵 함수를 정의한다.\ndef corr_heatmap(v) :\n    correlations = train_df[v].corr()\n    \n    # 2개의 색을 가진 컬러맵 생성\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n    \n    fig, ax = plt.subplots(figsize=(10, 10))\n    sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt=\".2f\", square=True, \n                linewidths=0.5, annot=True, cbar_kws={\"shrink\": 0.75})\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:05.819674Z","iopub.execute_input":"2021-05-29T14:52:05.820021Z","iopub.status.idle":"2021-05-29T14:52:05.825938Z","shell.execute_reply.started":"2021-05-29T14:52:05.819982Z","shell.execute_reply":"2021-05-29T14:52:05.824742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# meta에서 interval인것을 추출\nv = meta[ (meta.level == \"interval\") & meta.keep].index\ncorr_heatmap(v)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:05.827117Z","iopub.execute_input":"2021-05-29T14:52:05.827798Z","iopub.status.idle":"2021-05-29T14:52:06.555226Z","shell.execute_reply.started":"2021-05-29T14:52:05.827763Z","shell.execute_reply":"2021-05-29T14:52:06.554406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- ps_reg_02와 ps_reg_03은 상관계수가 0.7로 높은 관계가 있다.\n- ps_car_12와 ps_car_13은 상관계수가 0.67\n- ps_car_12와 ps_car_14는 상관계수가 0.58\n- ps_car_13와 ps_car_15는 상관계수가 0.53이다.","metadata":{}},{"cell_type":"markdown","source":"Seaborn은 시각화하게 편리한 도구가 많아 변수들간의 관계(특히 선형관계)를 잘 확인할 수 있다. 그 중 하나인 pairplot을 사용하면 한눈에 변수들간의 관계를 확인할 수 있지만, 이미 우리가 히트맵에서 확인했듯이, 상관계수가 높은 카테고리를 이미 확인하였다. 그래서 우리는 바로 각각의 높은 상관계수를 가지고 있는 변수를 살펴보는게 좋겠다.","metadata":{}},{"cell_type":"markdown","source":"##### NOTE : 데이터 분석 과정 속도를 내기 위해서 train_data의 샘플을 사용하였다.","metadata":{}},{"cell_type":"code","source":"# 데이터의 10%를 랜덤하게 추출\ns = train_df.sample(frac=0.1)\ns","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:06.556454Z","iopub.execute_input":"2021-05-29T14:52:06.55683Z","iopub.status.idle":"2021-05-29T14:52:06.623776Z","shell.execute_reply.started":"2021-05-29T14:52:06.556791Z","shell.execute_reply":"2021-05-29T14:52:06.622839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ps_reg_02와 ps_reg_03의 상관관계 확인\n아래의 회귀선에서 보이듯, 두 변수들에 1차 함수 형태의 비례 관계가 있음을 알 수 있다. hue 파라미터 덕분에 우리는 target=0의 회귀선과 target=1의 회귀선이 같음을 알 수 있다.","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x=\"ps_reg_02\", y=\"ps_reg_03\", data=s, hue=\"target\", \n           palette=\"Set1\", scatter_kws={\"alpha\" : 0.3})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:06.625179Z","iopub.execute_input":"2021-05-29T14:52:06.625528Z","iopub.status.idle":"2021-05-29T14:52:08.345658Z","shell.execute_reply.started":"2021-05-29T14:52:06.625492Z","shell.execute_reply":"2021-05-29T14:52:08.344785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ps_car_12와 ps_car_13의 관계","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x=\"ps_car_12\", y=\"ps_car_13\", data=s, hue=\"target\",\n          palette=\"Set1\", scatter_kws={\"alpha\" : 0.3})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:08.346716Z","iopub.execute_input":"2021-05-29T14:52:08.347053Z","iopub.status.idle":"2021-05-29T14:52:09.981528Z","shell.execute_reply.started":"2021-05-29T14:52:08.34702Z","shell.execute_reply":"2021-05-29T14:52:09.980741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.4 ~ 0.6 사이에 값이 집중되어 있고 회귀선이 같음을 알 수 있다.","metadata":{}},{"cell_type":"markdown","source":"ps_car_12와 ps_car_14의 관계","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x=\"ps_car_12\", y=\"ps_car_14\", data=s, hue=\"target\", palette=\"Set1\",\n          scatter_kws={\"alpha\" : 0.3})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:09.98286Z","iopub.execute_input":"2021-05-29T14:52:09.983201Z","iopub.status.idle":"2021-05-29T14:52:11.634272Z","shell.execute_reply.started":"2021-05-29T14:52:09.983163Z","shell.execute_reply":"2021-05-29T14:52:11.633462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ps_car_13과 ps_car_15의 관계","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x=\"ps_car_15\", y=\"ps_car_13\", data=s, hue=\"target\", palette=\"Set1\",\n          scatter_kws={\"alpha\" :0.3})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:11.635598Z","iopub.execute_input":"2021-05-29T14:52:11.635944Z","iopub.status.idle":"2021-05-29T14:52:13.433129Z","shell.execute_reply.started":"2021-05-29T14:52:11.635908Z","shell.execute_reply":"2021-05-29T14:52:13.432353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"자, 이제 상관관계도 살펴보았다. 그러면 이제 상관관계가 있는 변수 중 어떤 것을 선택해야 할까? PCA(Principal Component Analysis)에 따르면 필요없는 변수들은 제거하여 차원을 줄여야 한다고 한다. 본래는 제거를 해야 마땅하지만 상관계수가 있는 항목이 많지 않으므로 모델에서 heavy-lifting을 사용하도록 하자.","metadata":{}},{"cell_type":"markdown","source":"### 순서형 데이터의 상관계수 확인하기","metadata":{}},{"cell_type":"code","source":"# 메타에서 ordinal인 것을 가져온다.\nv = meta[(meta.level == \"ordinal\") & (meta.keep)].index\n# 히트맵 \ncorr_heatmap(v)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:13.434361Z","iopub.execute_input":"2021-05-29T14:52:13.434747Z","iopub.status.idle":"2021-05-29T14:52:14.793321Z","shell.execute_reply.started":"2021-05-29T14:52:13.434706Z","shell.execute_reply":"2021-05-29T14:52:14.792508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"상관계수가 있는 변수들이 많아 보이지 않는다. 그렇다면, 나중에 target값을 기준으로 grouping 했을 때 분포가 어떤지 살펴보면 되겠다.","metadata":{}},{"cell_type":"markdown","source":"## Feature Enginering <a class=\"anchor\" id=\"chapter6\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### Dummy 값 생성하기\n카테고리의 값은 그저 다른 상태라는 것만을 알려주지, 서로간의 어떤 순서나 배수 관계가 아니다. 예를 들자면, 카테고리 값이 2라고 해서 그게 카테고리 값 1인 값의 2배가 아니라는 것이다. 그렇기 때문에, 이런 관계를 이용해서 우리는 더미 값을 만들 수 있다. 처음 생성된 더미 변수를 버린다. 왜냐하면 첫 더미 변수들은 순수한 변수들의 카테고리 값에서 만들어진 다른 더미 변수들에서 오기 떄문이다.","metadata":{}},{"cell_type":"code","source":"v = meta[(meta.level == \"nominal\") & (meta.keep)].index\nprint(f\"더미 만들기 작업 전 변수 개수 : {train_df.shape[1]} \")\ntrain_df = pd.get_dummies(train_df, columns=v, drop_first=True)\nprint(f\"더미 만들기 작업 후 변수 개수 : {train_df.shape[1]} \")\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:14.794623Z","iopub.execute_input":"2021-05-29T14:52:14.795003Z","iopub.status.idle":"2021-05-29T14:52:14.902812Z","shell.execute_reply.started":"2021-05-29T14:52:14.794972Z","shell.execute_reply":"2021-05-29T14:52:14.901885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"52개의 더미 칼럼이 추가 되었다!","metadata":{}},{"cell_type":"markdown","source":"### interaction(범위) 변수 생성하기","metadata":{}},{"cell_type":"code","source":"# level이 interval인 칼럼 가져오기\nv = meta[ (meta.level == \"interval\") & (meta.keep)].index\n\n# 차수가 2개인 Polynomial 값 추가하기\npoly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\ninteractions = pd.DataFrame(data=poly.fit_transform(train_df[v]), columns=poly.get_feature_names(v))\ninteractions","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:14.904152Z","iopub.execute_input":"2021-05-29T14:52:14.904776Z","iopub.status.idle":"2021-05-29T14:52:15.162239Z","shell.execute_reply.started":"2021-05-29T14:52:14.90473Z","shell.execute_reply":"2021-05-29T14:52:15.16123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 기존의 칼럼 제거하기\ninteractions.drop(v, inplace=True, axis=1)\nprint(f\"interactions 생성 전 칼럼 수 : {train_df.shape[1]}\")\ntrain_df = pd.concat([train_df, interactions], axis=1)\nprint(f\"interactions 생성 전 칼럼 수 : {train_df.shape[1]}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:15.163782Z","iopub.execute_input":"2021-05-29T14:52:15.16416Z","iopub.status.idle":"2021-05-29T14:52:15.304312Z","shell.execute_reply.started":"2021-05-29T14:52:15.16412Z","shell.execute_reply":"2021-05-29T14:52:15.303421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"추가 interaction 칼럼이 train 데이터에 추가되었다. get_feature_names 메소드 덕분에 우리는 칼럼 이름들을 새로운 변수에 집어넣을 수 있다.","metadata":{}},{"cell_type":"markdown","source":"### Feature 고르기 <a class=\"anchor\" id=\"chapter7\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### varience가 낮거나 0인 변수 제거하기","metadata":{}},{"cell_type":"markdown","source":"개인적으로, 나는 classifier 알고리즘이 알아서 어떤 피쳐값을 유지할 건지 선택하도록 하는걸 더 좋아하는데, 우리 스스로 할 수 있는게 하나 있다. 그건 바로 variance가 낮거나 0인 변수를 제거하는것이다. Sklearn은 VarianceThreshold 간편한 메소드를 가지고 있다. 기본적으로 VarianceThreshold 메소드는 variance가 0인 변수들을 지운다. 근데 이번 대회에서는 이것을 사용하지 않을 것이다 왜냐하면 앞 과정에서 variance가 0인 변수들을 찾을 수 없었기 때문이다. 근데 1% 미만인 variance를 삭제한다면 총 31개의 칼럼을 삭제하게 된다.","metadata":{}},{"cell_type":"code","source":"# VarienceThreshold 생성자 선언\nselector = VarianceThreshold(threshold=0.01)\n# id와 target 값 없이 학습 실행\nselector.fit(train_df.drop([\"id\", \"target\"], axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:15.305606Z","iopub.execute_input":"2021-05-29T14:52:15.305967Z","iopub.status.idle":"2021-05-29T14:52:15.97712Z","shell.execute_reply.started":"2021-05-29T14:52:15.305929Z","shell.execute_reply":"2021-05-29T14:52:15.97629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x를 not x로 만들어주는 벡터 \nf = np.vectorize(lambda x : not x)\n\nv= train_df.drop([\"id\", \"target\"], axis=1).columns[f(selector.get_support())]\nprint(f\"{len(v)}개의 칼럼의 variance가 매우 낮다.\")\nprint(f\"variance가 낮은 칼럼 :{list(v)}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:15.980946Z","iopub.execute_input":"2021-05-29T14:52:15.983074Z","iopub.status.idle":"2021-05-29T14:52:16.059893Z","shell.execute_reply.started":"2021-05-29T14:52:15.983036Z","shell.execute_reply":"2021-05-29T14:52:16.058918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"만약 variance로 변수를 선택한다면 꽤 많은 변수를 잃어야 한다. 하지만 현재 데이터 셋은 변수가 그렇게 많지 않으므로 classifier가 대신 선택하게 하자. 많은 변수가 있는 데이터 셋에는 classifier 만큼 시간을 절약할 수 있는게 없다. \n","metadata":{}},{"cell_type":"markdown","source":"Sklearn은 또한 다른 feature selection 메소드를 활용할 수 있는 툴이다. 그 중 하나인 SelectFromModel 메소드는 분류기로 하여금 최고의 피쳐를 자동으로 골라 그것들을 사용하게 한다. 아래서 SelectFromModel 메소드를 RandomForest와 함께 사용하는 방법을 소개한다 ","metadata":{}},{"cell_type":"markdown","source":"### 랜덤포레스트와 SelectFromModel을 이용해서 피쳐 선택하기","metadata":{}},{"cell_type":"markdown","source":"여기서 우리는 피쳐 선택을 랜덤포레스트의 feature importances를 이용해 할것이다. Sklearn의 SelectFromModel을 이용하면 얼마나 많은 변수들을 저장할 것인지 분류할 수 있게 된다. 피쳐 중요도를 수동으로 설정해서 한계를 정할 수 있다. 여기서는 간단하게 상위 50%만 고르도록 하자.\n    아래의 코드는 Sebastian Raschka님의 [깃허브 Repository](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch04/ch04.ipynb)에서 가져온 것이다. 파이썬 머신러닝의 샘플 코드가 예술이다.","metadata":{}},{"cell_type":"code","source":"X_train = train_df.drop([\"id\", \"target\"], axis=1)\ny_train = train_df[\"target\"]\n\nfeat_labels = X_train.columns\nfeat_labels","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:16.061156Z","iopub.execute_input":"2021-05-29T14:52:16.061496Z","iopub.status.idle":"2021-05-29T14:52:16.129615Z","shell.execute_reply.started":"2021-05-29T14:52:16.061459Z","shell.execute_reply":"2021-05-29T14:52:16.128672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 랜덤포레스트 객체 생성\nrf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:52:16.130879Z","iopub.execute_input":"2021-05-29T14:52:16.131234Z","iopub.status.idle":"2021-05-29T15:09:21.872239Z","shell.execute_reply.started":"2021-05-29T14:52:16.131199Z","shell.execute_reply":"2021-05-29T15:09:21.871432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = rf.feature_importances_","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:09:21.873381Z","iopub.execute_input":"2021-05-29T15:09:21.873767Z","iopub.status.idle":"2021-05-29T15:09:22.383339Z","shell.execute_reply.started":"2021-05-29T15:09:21.873726Z","shell.execute_reply":"2021-05-29T15:09:22.38238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:09:22.384714Z","iopub.execute_input":"2021-05-29T15:09:22.385084Z","iopub.status.idle":"2021-05-29T15:09:22.393297Z","shell.execute_reply.started":"2021-05-29T15:09:22.385047Z","shell.execute_reply":"2021-05-29T15:09:22.391939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nindices = np.argsort(rf.feature_importances_)[::-1]\nindices","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:09:22.394768Z","iopub.execute_input":"2021-05-29T15:09:22.395159Z","iopub.status.idle":"2021-05-29T15:09:22.915848Z","shell.execute_reply.started":"2021-05-29T15:09:22.395118Z","shell.execute_reply":"2021-05-29T15:09:22.915059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for f in range(X_train.shape[1]) :\n    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]], importances[indices[f]]))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:09:22.917011Z","iopub.execute_input":"2021-05-29T15:09:22.917379Z","iopub.status.idle":"2021-05-29T15:09:22.940981Z","shell.execute_reply.started":"2021-05-29T15:09:22.917337Z","shell.execute_reply":"2021-05-29T15:09:22.940297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SelectFromModel이 있으므로 우리는 어떤 종류의 분류기를 선택할것인지 정할 수 있고 피쳐 중요도에 대한 한계 구간을 구분할 수 있다. get_support 메소드는 그레사 train_data셋에 있는 변수의 개수를 제한할 수 있다. ","metadata":{}},{"cell_type":"code","source":"sfm = SelectFromModel(rf, threshold=\"median\", prefit=True)\nprint(f\"선별 전 피쳐의 개수 : {X_train.shape[1]}\")\nn_features = sfm.transform(X_train).shape[1]\nprint(f\"선별 후 피쳐의 개수 : {n_features}\")\nselected_vars = list(feat_labels[sfm.get_support()])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:09:22.943763Z","iopub.execute_input":"2021-05-29T15:09:22.944021Z","iopub.status.idle":"2021-05-29T15:09:25.112095Z","shell.execute_reply.started":"2021-05-29T15:09:22.943998Z","shell.execute_reply":"2021-05-29T15:09:25.110853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[selected_vars + [\"target\"]]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:13:46.38033Z","iopub.execute_input":"2021-05-29T15:13:46.380684Z","iopub.status.idle":"2021-05-29T15:13:46.431316Z","shell.execute_reply.started":"2021-05-29T15:13:46.38063Z","shell.execute_reply":"2021-05-29T15:13:46.430399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 피쳐 scaling <a class=\"anchor\" id=\"chapter8\"></a>","metadata":{}},{"cell_type":"markdown","source":"앞서 말했듯이, 우리는 standardScaling을 적용해서 스케일링을 할 수 있다. 몇 분류기들은 scaling을 사용 전과 후가 큰 차이가 나기도 한다.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit_transform(train_df.drop([\"target\"], axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:13:48.677222Z","iopub.execute_input":"2021-05-29T15:13:48.67757Z","iopub.status.idle":"2021-05-29T15:13:49.159485Z","shell.execute_reply.started":"2021-05-29T15:13:48.677538Z","shell.execute_reply":"2021-05-29T15:13:49.158421Z"},"trusted":true},"execution_count":null,"outputs":[]}]}