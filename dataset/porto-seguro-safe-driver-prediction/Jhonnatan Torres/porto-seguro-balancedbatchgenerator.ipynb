{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Adapted from https://imbalanced-learn.org/dev/auto_examples/applications/porto_seguro_keras_under_sampling.html","metadata":{}},{"cell_type":"code","source":"%matplotlib inline","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Porto Seguro: balancing samples in mini-batches with Keras\n\nThis example compares two strategies to train a neural-network on the Porto\nSeguro Kaggle data set [1]_. The data set is imbalanced and we show that\nbalancing each mini-batch allows to improve performance and reduce the training\ntime.\n\n## References\n\n.. [1] https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data\n","metadata":{}},{"cell_type":"markdown","source":"### Data loading\n\n","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nimport pandas as pd\nimport numpy as np","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:49:44.009065Z","iopub.execute_input":"2022-05-29T20:49:44.009564Z","iopub.status.idle":"2022-05-29T20:49:44.036042Z","shell.execute_reply.started":"2022-05-29T20:49:44.009462Z","shell.execute_reply":"2022-05-29T20:49:44.03507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, you should download the Porto Seguro data set from Kaggle. See the\nlink in the introduction.\n\n","metadata":{}},{"cell_type":"code","source":"training_data = pd.read_csv(\"../input/porto-seguro-safe-driver-prediction/train.csv\")\ntesting_data = pd.read_csv(\"../input/porto-seguro-safe-driver-prediction/test.csv\")\n\ny_train = training_data[[\"id\", \"target\"]].set_index(\"id\")\nX_train = training_data.drop([\"target\"], axis=1).set_index(\"id\")\nX_test = testing_data.set_index(\"id\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:50:42.470878Z","iopub.execute_input":"2022-05-29T20:50:42.471848Z","iopub.status.idle":"2022-05-29T20:50:56.378678Z","shell.execute_reply.started":"2022-05-29T20:50:42.471807Z","shell.execute_reply":"2022-05-29T20:50:56.377426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data set is imbalanced and it will have an effect on the fitting.\n\n","metadata":{}},{"cell_type":"code","source":"print(f\"The data set is imbalanced: {Counter(y_train['target'])}\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:51:03.845141Z","iopub.execute_input":"2022-05-29T20:51:03.846052Z","iopub.status.idle":"2022-05-29T20:51:03.960459Z","shell.execute_reply.started":"2022-05-29T20:51:03.846001Z","shell.execute_reply":"2022-05-29T20:51:03.959262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the pre-processing pipeline\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.impute import SimpleImputer\n\n\ndef convert_float64(X):\n    return X.astype(np.float64)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:51:16.91359Z","iopub.execute_input":"2022-05-29T20:51:16.914486Z","iopub.status.idle":"2022-05-29T20:51:18.453555Z","shell.execute_reply.started":"2022-05-29T20:51:16.914437Z","shell.execute_reply":"2022-05-29T20:51:18.452536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We want to standard scale the numerical features while we want to one-hot\nencode the categorical features. In this regard, we make use of the\n:class:`~sklearn.compose.ColumnTransformer`.\n\n","metadata":{}},{"cell_type":"code","source":"numerical_columns = [\n    name for name in X_train.columns if \"_calc_\" in name and \"_bin\" not in name\n]\nnumerical_pipeline = make_pipeline(\n    FunctionTransformer(func=convert_float64, validate=False), StandardScaler()\n)\n\ncategorical_columns = [name for name in X_train.columns if \"_cat\" in name]\ncategorical_pipeline = make_pipeline(\n    SimpleImputer(missing_values=-1, strategy=\"most_frequent\"),\n    OneHotEncoder(categories=\"auto\"),\n)\n\npreprocessor = ColumnTransformer(\n    [\n        (\"numerical_preprocessing\", numerical_pipeline, numerical_columns),\n        (\n            \"categorical_preprocessing\",\n            categorical_pipeline,\n            categorical_columns,\n        ),\n    ],\n    remainder=\"drop\",\n)\n\n# Create an environment variable to avoid using the GPU. This can be changed.\nimport os\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:51:45.210924Z","iopub.execute_input":"2022-05-29T20:51:45.211376Z","iopub.status.idle":"2022-05-29T20:51:45.220547Z","shell.execute_reply.started":"2022-05-29T20:51:45.21133Z","shell.execute_reply":"2022-05-29T20:51:45.219416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a neural-network\n\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Activation,\n    Dense,\n    Dropout,\n    BatchNormalization,\n)\n\n\ndef make_model(n_features):\n    model = Sequential()\n    model.add(Dense(200, input_shape=(n_features,), kernel_initializer=\"glorot_normal\"))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(100, kernel_initializer=\"glorot_normal\", use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.25))\n    model.add(Dense(50, kernel_initializer=\"glorot_normal\", use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.15))\n    model.add(Dense(25, kernel_initializer=\"glorot_normal\", use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation=\"sigmoid\"))\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n    return model","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:52:28.097024Z","iopub.execute_input":"2022-05-29T20:52:28.098099Z","iopub.status.idle":"2022-05-29T20:52:35.345881Z","shell.execute_reply.started":"2022-05-29T20:52:28.098064Z","shell.execute_reply":"2022-05-29T20:52:35.344941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a decorator to report the computation time\n\n","metadata":{}},{"cell_type":"code","source":"import time\nfrom functools import wraps\n\n\ndef timeit(f):\n    @wraps(f)\n    def wrapper(*args, **kwds):\n        start_time = time.time()\n        result = f(*args, **kwds)\n        elapsed_time = time.time() - start_time\n        print(f\"Elapsed computation time: {elapsed_time:.3f} secs\")\n        return (elapsed_time, result)\n\n    return wrapper","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:52:35.347337Z","iopub.execute_input":"2022-05-29T20:52:35.348145Z","iopub.status.idle":"2022-05-29T20:52:35.354597Z","shell.execute_reply.started":"2022-05-29T20:52:35.34811Z","shell.execute_reply":"2022-05-29T20:52:35.353608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first model will be trained using the ``fit`` method and with imbalanced\nmini-batches.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n\n@timeit\ndef fit_predict_imbalanced_model(X_train, y_train, X_test, y_test):\n    model = make_model(X_train.shape[1])\n    model.fit(X_train, y_train, epochs=2, verbose=1, batch_size=1000)\n    y_pred = model.predict(X_test, batch_size=1000)\n    return roc_auc_score(y_test, y_pred)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:55:02.725779Z","iopub.execute_input":"2022-05-29T20:55:02.726224Z","iopub.status.idle":"2022-05-29T20:55:02.732599Z","shell.execute_reply.started":"2022-05-29T20:55:02.72619Z","shell.execute_reply":"2022-05-29T20:55:02.731725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the contrary, we will use imbalanced-learn to create a generator of\nmini-batches which will yield balanced mini-batches.\n\n","metadata":{}},{"cell_type":"code","source":"from imblearn.keras import BalancedBatchGenerator\n\n\n@timeit\ndef fit_predict_balanced_model(X_train, y_train, X_test, y_test):\n    model = make_model(X_train.shape[1])\n    training_generator = BalancedBatchGenerator(\n        X_train, y_train, batch_size=1000, random_state=42\n    )\n    model.fit(training_generator, epochs=5, verbose=1)\n    y_pred = model.predict(X_test, batch_size=1000)\n    return roc_auc_score(y_test, y_pred)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:55:04.233186Z","iopub.execute_input":"2022-05-29T20:55:04.233614Z","iopub.status.idle":"2022-05-29T20:55:04.240366Z","shell.execute_reply.started":"2022-05-29T20:55:04.23358Z","shell.execute_reply":"2022-05-29T20:55:04.239505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification loop\n\n","metadata":{}},{"cell_type":"markdown","source":"We will perform a 10-fold cross-validation and train the neural-network with\nthe two different strategies previously presented.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=10)\n\ncv_results_imbalanced = []\ncv_time_imbalanced = []\ncv_results_balanced = []\ncv_time_balanced = []\nfor train_idx, valid_idx in skf.split(X_train, y_train):\n    X_local_train = preprocessor.fit_transform(X_train.iloc[train_idx])\n    y_local_train = y_train.iloc[train_idx].values.ravel()\n    X_local_test = preprocessor.transform(X_train.iloc[valid_idx])\n    y_local_test = y_train.iloc[valid_idx].values.ravel()\n\n    elapsed_time, roc_auc = fit_predict_imbalanced_model(\n        X_local_train, y_local_train, X_local_test, y_local_test\n    )\n    cv_time_imbalanced.append(elapsed_time)\n    cv_results_imbalanced.append(roc_auc)\n\n    elapsed_time, roc_auc = fit_predict_balanced_model(\n        X_local_train, y_local_train, X_local_test, y_local_test\n    )\n    cv_time_balanced.append(elapsed_time)\n    cv_results_balanced.append(roc_auc)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T20:55:05.935762Z","iopub.execute_input":"2022-05-29T20:55:05.936331Z","iopub.status.idle":"2022-05-29T21:04:30.728903Z","shell.execute_reply.started":"2022-05-29T20:55:05.936297Z","shell.execute_reply":"2022-05-29T21:04:30.727517Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot of the results and computation time\n\n","metadata":{}},{"cell_type":"code","source":"df_results = pd.DataFrame(\n    {\n        \"Balanced model\": cv_results_balanced,\n        \"Imbalanced model\": cv_results_imbalanced,\n    }\n)\ndf_results = df_results.unstack().reset_index()\n\ndf_time = pd.DataFrame(\n    {\"Balanced model\": cv_time_balanced, \"Imbalanced model\": cv_time_imbalanced}\n)\ndf_time = df_time.unstack().reset_index()\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure()\nsns.boxplot(y=\"level_0\", x=0, data=df_time)\nsns.despine(top=True, right=True, left=True)\nplt.xlabel(\"time [s]\")\nplt.ylabel(\"\")\nplt.title(\"Computation time difference using a random under-sampling\")\n\nplt.figure()\nsns.boxplot(y=\"level_0\", x=0, data=df_results, whis=10.0)\nsns.despine(top=True, right=True, left=True)\nax = plt.gca()\nax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: \"%i%%\" % (100 * x)))\nplt.xlabel(\"ROC-AUC\")\nplt.ylabel(\"\")\nplt.title(\"Difference in terms of ROC-AUC using a random under-sampling\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-29T21:06:23.737317Z","iopub.execute_input":"2022-05-29T21:06:23.738438Z","iopub.status.idle":"2022-05-29T21:06:24.295537Z","shell.execute_reply.started":"2022-05-29T21:06:23.738382Z","shell.execute_reply":"2022-05-29T21:06:24.294712Z"},"trusted":true},"execution_count":null,"outputs":[]}]}