{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport gc\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFECV\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dirname = '/kaggle/input/porto-seguro-safe-driver-prediction'\ntrain = pd.read_csv(os.path.join(dirname, 'train.csv'))\ntest = pd.read_csv(os.path.join(dirname, 'test.csv'))\n\nprint(f'shape of train: {train.shape}')\nprint(f'shape of test: {test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having huge class imbalance between positive & negative target values."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [c for c in train.columns if c.endswith('_cat')]\nbin_cols = [c for c in train.columns if c.endswith('_bin')]\nother_cols = [c for c in train.columns if c not in cat_cols+bin_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperating columns as \"categorical\", \"binary\" & other types for better understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in cat_cols:\n    neg_val = train.loc[train[c] < 0].shape[0]\n    if(neg_val > 0):\n        print(f'Missing value with -1 inserted in categorical columns {c}: {neg_val} -- {(neg_val * 100)/len(train):.2f}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As mentioned in data -1 was inserted if there is no value, which means it was a null value.\nSo here we found the missing values in training set categorical columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in other_cols:\n    neg_val = train.loc[train[c] < 0].shape[0]\n    if(neg_val > 0):\n        print(f'Missing value with -1 inserted in numeric columns {c}: {neg_val} -- {(neg_val * 100)/len(train):.2f}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values & there percentage in columns other than category & binary."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [c for c in cat_cols if c not in ('ps_car_03_cat','ps_car_05_cat')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing columns with ~50% & above of missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full = pd.concat([train,test], axis=0)\ndf_full = df_full[cat_cols+other_cols+bin_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenating \"train\" & \"test\" set for doing cleanup and scaling process"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_miss_cols = ['ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat',\n                 'ps_car_01_cat','ps_car_02_cat','ps_car_07_cat','ps_car_09_cat']\noth_miss_cols = ['ps_car_11','ps_car_12','ps_car_14','ps_reg_03']\n\nfor i in cat_miss_cols:\n    df_full.loc[df_full[i] < 0, i] = df_full[i].mode()[0]\nfor j in oth_miss_cols:\n    df_full.loc[df_full[j] < 0, j] = df_full[j].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing missing values in categorical columns with mode function.\nImputing missing values in numerical columns with mean function."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ind_cols = [c for c in df_full.columns if re.search(r'(\\_ind)', c)]\nreg_cols = [c for c in df_full.columns if re.search(r'(\\_reg)',c)]\ncar_cols = [c for c in df_full.columns if re.search(r'(\\_car)',c)]\ncalc_cols = [c for c in df_full.columns if re.search(r'(\\_calc)',c)]\n\n#ind cols\nind_cat_cols = [ic for ic in ind_cols if re.search(r'_cat', ic)]\nind_bin_cols = [ib for ib in ind_cols if re.search(r'_bin', ib)]\nind_oth_cols = [io for io in ind_cols if io not in ind_cat_cols+ind_bin_cols]\n\n#reg cols\nreg_oth_cols = reg_cols\n\n#car cols\ncar_cat_cols = [cc for cc in car_cols if re.search(r'_cat', cc)]\ncar_oth_cols = [co for co in car_cols if co not in car_cat_cols]\n\n#calc cols\ncalc_bin_cols = [clb for clb in calc_cols if re.search(r'_bin', clb)]\ncalc_oth_cols = [clo for clo in calc_cols if clo not in calc_bin_cols]\n\n#Fuction to calculate sum of related columns, as a feature engineering \ndef createSum(newcol, cols):\n    df_full[newcol] = np.zeros(df_full.shape[0])\n    for c in cols:\n        df_full[newcol] += df_full[c]\n    return df_full[newcol]\n\ncreateSum('ps_ind_all_cat_sum', ind_cat_cols)\ncreateSum('ps_ind_all_bin_sum', ind_bin_cols)\ncreateSum('ps_ind_all_oth_sum', ind_oth_cols)\ncreateSum('ps_reg_all_oth_sum', reg_oth_cols)\ncreateSum('ps_car_all_cat_sum', car_cat_cols)\ncreateSum('ps_car_all_oth_sum', car_oth_cols)\ncreateSum('ps_calc_all_bin_sum', calc_bin_cols)\ncreateSum('ps_calc_all_oth_sum', calc_oth_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Further seperating columns based on column name like \"_ind\", \"_reg\", \"_car\" & \"_calc\".\n2. In the above group we are further seperating as \"category\", \"binary\" & \"other\".\n3. Using this group we are creating a new column with sum of all the columns in relevant groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_add_cols = ['ps_ind_all_cat_sum','ps_ind_all_bin_sum','ps_ind_all_oth_sum','ps_reg_all_oth_sum',\n               'ps_car_all_cat_sum','ps_car_all_oth_sum','ps_calc_all_bin_sum','ps_calc_all_oth_sum']\ntarget = ['target']\ndf_full_new = df_full[ind_cat_cols + \n                  ind_bin_cols + \n                  ind_oth_cols +\n                  reg_oth_cols +\n                  car_cat_cols +\n                  car_oth_cols +\n                  calc_bin_cols +\n                  calc_oth_cols + \n                  new_add_cols + target]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selecting all the group of columns with newly added columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_full_new[:595212]\ndf_test = df_full_new[595212:]\n\ndf_train = df_train.sample(frac=1)\ntrain_new_0 = df_train.loc[df_train['target'] == 0][:21694]\ntrain_new_1 = df_train.loc[df_train['target'] == 1]\ntrain_new = pd.concat([train_new_0,train_new_1])\ndf_train = train_new.sample(frac=1, random_state=42).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Spliting the full concatenated dataset as train & test.\n2. Let us do a shuffle of training data using dataframe \"sample\".\n3. To handle class imbalance, we may undersample majority class manually to make equal count of both positive & negative class."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have equal count of positive & negative class."},{"metadata":{"trusted":true},"cell_type":"code","source":"def createDensityPlot(df, cols):\n    fig = plt.figure(figsize=(18,14))\n    for i,j in enumerate(cols):\n        fig.add_subplot(3,2,i+1)\n        sns.kdeplot(df.loc[df['target'] == 0, j], label=\"Target==0\")\n        sns.kdeplot(df.loc[df['target'] == 1, j], label=\"Target==1\")\n        plt.xlabel(j)\n        plt.ylabel('Density')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_oth_cols1 = ['ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14','ps_car_15',\n                'ps_ind_01']\nall_oth_cols2 = ['ps_ind_03', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', \n                'ps_reg_03', 'ps_calc_01']\nall_oth_cols3 = ['ps_calc_02', 'ps_calc_03', 'ps_calc_04',\n                'ps_calc_05', 'ps_calc_06', 'ps_calc_07']\nall_oth_cols4 = ['ps_calc_08', 'ps_calc_09', 'ps_calc_10', \n                 'ps_calc_11', 'ps_calc_12', 'ps_calc_13']\nall_oth_cols5 = ['ps_calc_14','ps_car_11_cat']\n\ncreateDensityPlot(df_train, all_oth_cols1)\ncreateDensityPlot(df_train, all_oth_cols2)\ncreateDensityPlot(df_train, all_oth_cols3)\ncreateDensityPlot(df_train, all_oth_cols4)\ncreateDensityPlot(df_train, all_oth_cols5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Using density plot we can an idea about how discrete & continuous value columns shows any pattern in explaining poisitive & negative classes.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_oth_cols = ['ps_car_12','ps_car_13','ps_car_14','ps_car_15','ps_ind_01',\n                    'ps_ind_03', 'ps_ind_15','ps_reg_01', 'ps_reg_02', 'ps_reg_03','ps_car_11_cat']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the density plot we choose these columns have more details between the 2 classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"def createCountPlot(df, cols):\n    fig = plt.figure(figsize=(15,10))\n    for i,j in enumerate(cols):\n        fig.add_subplot(3,2,i+1)\n        sns.countplot(x=j, data=df, hue='target')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_cat_col1 = ['ps_car_01_cat','ps_car_02_cat','ps_car_04_cat','ps_car_06_cat','ps_car_07_cat','ps_car_08_cat']\nall_cat_col2 = ['ps_car_09_cat','ps_car_10_cat','ps_car_11_cat','ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat']\n\ncreateCountPlot(df_train, all_cat_col1)\ncreateCountPlot(df_train, all_cat_col2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here creating count plot on \"categorical\" columns for better understanding the class difference on these columns. "},{"metadata":{"trusted":true},"cell_type":"code","source":"all_bin_cols1 = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin']\nall_bin_cols2 = ['ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin']\nall_bin_cols3 = ['ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n\ncreateCountPlot(df_train, all_bin_cols1)\ncreateCountPlot(df_train, all_bin_cols2)\ncreateCountPlot(df_train, all_bin_cols3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here creating count plot on \"binary\" columns for understanding the class difference on these columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_cat_cols = ['ps_car_01_cat','ps_car_02_cat','ps_car_04_cat','ps_car_06_cat','ps_car_09_cat','ps_ind_04_cat','ps_ind_05_cat']\nselected_bin_cols = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin','ps_ind_16_bin', 'ps_ind_17_bin']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selected the columns which are having difference between the classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_new=pd.get_dummies(data=df_train, columns=selected_cat_cols, drop_first=True)\ndf_test_new=pd.get_dummies(data=df_test, columns=selected_cat_cols, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encoding the categorical columns as a standard procedure for training & test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = df_train_new.drop(['target'], axis=1).corr()\nupper = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(np.bool))\nto_drop = [col for col in upper.columns if any (upper[col].abs() > 0.9)]\nprint(f'collinear columns count: {len(to_drop)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking inter collinearity between columns, by fixing the threshold of greater than 0.9"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ndf_cols = df_train_new.columns\ndf_labels = df_train_new['target']\ndf_cols = [c for c in df_cols if c not in ['id','target','ps_reg_all_oth_sum','ps_car_all_cat_sum']]\ndf_scaled = scaler.fit_transform(df_train_new[df_cols])\ndf_new = pd.DataFrame(df_scaled, columns=df_cols).reset_index(drop=True)\ndf_new['target'] = df_labels.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling the traing data as a standard step. "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_new = scaler.transform(df_test_new[df_cols])\ndf_new_test = pd.DataFrame(test_new, columns=df_cols).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transforming the test set based on training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_new.drop('target', axis=1)\ny = df_new['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperating the training data as 'X' & 'y'."},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\ndel df_full\ndel df_scaled\ndel df_new\ndel df_train\ndel train_new_0\ndel train_new_1\ndel train_new\ndel test_new\ndel train\ndel test\ndel df_train_new\ndel df_test_new\ndel correlation\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nrfecv = RFECV(estimator=log_reg, step=1, cv=StratifiedKFold(5), scoring='roc_auc')\nrfecv.fit(X, y)\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using sklearns \"Recursive feature elimination\" to select optimal useful columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.drop(X.columns[np.where(rfecv.support_ == False)[0]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Drop the less feature importance columns to reduce dimension of our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits= 10, shuffle=True, random_state=1001)\n\nlgb_cla = LGBMClassifier(nthread=4,\n                         n_estimators=10000,\n                         learning_rate=0.01,\n                         num_leaves=34,\n                         colsample_bytree=0.9497036,\n                         subsample=0.8715623,\n                         max_depth=8,\n                         reg_alpha=0.041545473,\n                         reg_lambda=0.0735294,\n                         min_split_gain=0.0222415,\n                         min_child_weight=39.3259775,\n                         silent=-1,\n                         verbose=-1, )\n\n# Create arrays and dataframes to store results\noof_preds = np.zeros(X.shape[0])\nsub_preds = np.zeros(df_new_test.shape[0])\nfeature_importance_df = pd.DataFrame()\n\nfeats = X.columns   \n\nfor n_fold, (train_idx, test_idx) in enumerate(folds.split(X, y)):\n    train_x, train_y = X.iloc[train_idx], y.iloc[train_idx]\n    test_x, test_y = X.iloc[test_idx], y.iloc[test_idx]\n\nlgb_cla.fit(train_x, train_y, eval_set=[(train_x, train_y), (test_x, test_y)],\n            eval_metric= 'auc', verbose= 200, early_stopping_rounds= 500)\n\noof_preds[test_idx] = lgb_cla.predict_proba(test_x, num_iteration=lgb_cla.best_iteration_)[:, 1]\nsub_preds += lgb_cla.predict_proba(df_new_test[feats], num_iteration=lgb_cla.best_iteration_)[:, 1] / folds.n_splits\n\nfold_importance_df = pd.DataFrame()\nfold_importance_df[\"feature\"] = feats\nfold_importance_df[\"importance\"] = lgb_cla.feature_importances_\nfold_importance_df[\"fold\"] = n_fold + 1\nfeature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\nprint('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(test_y, oof_preds[test_idx])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(os.path.join(dirname, 'test.csv'))\ntest['target'] = sub_preds\ntest[['id','target']].to_csv('submission_02.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}