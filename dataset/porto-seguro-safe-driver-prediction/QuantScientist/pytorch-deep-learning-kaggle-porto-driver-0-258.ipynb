{"cells":[{"metadata":{"_uuid":"c88c132dac3908aa10d39ca408da3eea29decf76","slideshow":{"slide_type":"slide"},"_cell_guid":"556a42c3-1263-446e-8c1e-65cd1901f611"},"cell_type":"markdown","source":"# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n\n#### Shlomo Kashani \n\n\n## 69-PyTorch-Kaggle-porto-driver\n\nWeb: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n\nNotebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n\n*Shlomo Kashani*\n\n\n### Data\n- Download from Kaggle\n\n### Epochs\nI set epochs=500 because in Kaggle this runs on a CPU, change to 5000 for better results on a GPU"},{"metadata":{"_uuid":"00f69110481df8e5dc2f6b22f85ed57252defeeb","slideshow":{"slide_type":"slide"},"collapsed":true,"_cell_guid":"f2a22c11-4867-4706-b45e-e3b26f37bf38"},"cell_type":"markdown","source":"# PyTorch Imports\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"641a00a35bed67714404fbb76c835907f067a87f","slideshow":{"slide_type":"-"},"collapsed":true,"_cell_guid":"3c437ee6-22a3-4826-9cb5-2a48ee95471d"},"source":"% reset -f\nimport torch\nimport sys\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\nfrom sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n\nprint('__Python VERSION:', sys.version)\nprint('__pyTorch VERSION:', torch.__version__)\n\nimport numpy\nimport numpy as np\n\nuse_cuda = torch.cuda.is_available()\nFloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\nTensor = FloatTensor\n\nimport pandas\nimport pandas as pd\n\nimport logging\nhandler=logging.basicConfig(level=logging.INFO)\nlgr = logging.getLogger(__name__)\n%matplotlib inline\n\n# !pip install psutil\nimport psutil\nimport os\ndef cpuStats():\n        print(sys.version)\n        print(psutil.cpu_percent())\n        print(psutil.virtual_memory())  # physical memory usage\n        pid = os.getpid()\n        py = psutil.Process(pid)\n        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n        print('memory GB:', memoryUse)\n\ncpuStats()","outputs":[]},{"metadata":{"_uuid":"68215cb0cc4621aa263706009ab028b2dc7a6eb2","slideshow":{"slide_type":"slide"},"collapsed":true,"_cell_guid":"fb941080-db5e-4a5b-a777-9eeb8a617234"},"cell_type":"markdown","source":"#  Global params"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6c6507ce66c8fa3dbd7d37fce6c4ff2d379ead39","collapsed":true,"_cell_guid":"b8dfa887-cf7b-4caa-bf6a-ec3534ab2067"},"source":"# fix seed\nseed=17*19\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif use_cuda:\n    torch.cuda.manual_seed(seed)    \n# ! dir    ","outputs":[]},{"metadata":{"_uuid":"8cb0c2510660f94ddaa1a405f94b4d434dc5a0bd","slideshow":{"slide_type":"slide"},"collapsed":true,"_cell_guid":"426a5a63-32a5-4ad3-88e0-0ebe08774d16"},"cell_type":"markdown","source":"\n#  View the Data"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"013281b3b441e2f21927f2c89837cbbfb23def6a","collapsed":true,"_cell_guid":"40a56f8e-7e3d-493a-ad91-8b549dabbb8a"},"source":"import gc; gc.enable()\n# !pip install xgboost\nimport xgboost as xgb\n# http://www.lfd.uci.edu/~gohlke/pythonlibs/#xgboost\nimport pandas as pd\nimport numpy as np\nfrom sklearn import *\nimport sklearn\n\n# Data params\nTARGET_VAR= 'target'\nBASE_FOLDER = '../input/'\n\n# Read in our input data\ndf_train = pd.read_csv(BASE_FOLDER + '/train.csv')\ndf_test = pd.read_csv(BASE_FOLDER + '/test.csv')\n# This prints out (rows, columns) in each dataframe\nprint('Train shape:', df_train.shape)\nprint('Test shape:', df_test.shape)\n\nprint('Columns:', df_train.columns)\n\ny_train = df_train['target'].values\nid_train = df_train['id'].values\nid_test = df_test['id'].values\ndf_train.head()","outputs":[]},{"metadata":{"_uuid":"1446cf549e1f3b5247763bbe1c67b076ab2fc57b","slideshow":{"slide_type":"slide"},"collapsed":true,"_cell_guid":"78c7c4bc-2a85-4a24-a9c1-dfd15a5a9036"},"cell_type":"markdown","source":"#  Train / Validation / Test Split"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"4f4b3bb860aa2fefda962b02db898a90d6f81766","collapsed":true,"_cell_guid":"961fe1a3-4c06-4353-91f4-6b551bdfe7e7"},"source":"x_train = df_train.drop(['target', 'id'], axis=1)\nx_test = df_test.drop(['id'], axis=1)\n\n# Take a random 20% of the dataset as validation data\ntrainX, valX, trainY, valY = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\nprint('Train samples: {} Validation samples: {}'.format(len(trainX), len(valX)))\n\nN_FEATURES=trainX.shape[1]","outputs":[]},{"metadata":{"_uuid":"83e367e376ac2e04c9431ba15f7bc0fbf5c2ba56","slideshow":{"slide_type":"slide"},"collapsed":true,"_cell_guid":"9e4d1d88-94a9-4723-a80e-ac477654579d"},"cell_type":"markdown","source":"#  From Numpy to PyTorch GPU tensors"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"aaa1cb6a0b3bc888a9314997f88f03c171257667","collapsed":true,"_cell_guid":"441ae82a-ca40-4bd6-b9fc-5aa62d10ce3a"},"source":"use_cuda = torch.cuda.is_available()\n# use_cuda = False\n\n\n# Convert the np arrays into the correct dimention and type\n# Note that BCEloss requires Float in X as well as in y\ndef XnumpyToTensor(x_data_np):\n    x_data_np = np.array(x_data_np, dtype=np.float32)        \n    print(x_data_np.shape)\n    print(type(x_data_np))\n\n    if use_cuda:\n        lgr.info (\"Using the GPU\")    \n        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n    else:\n        lgr.info (\"Using the CPU\")\n        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n    \n    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'            \n    print((X_tensor.data.shape)) # torch.Size([108405, 29])\n    return X_tensor\n\n\n# Convert the np arrays into the correct dimention and type\n# Note that BCEloss requires Float in X as well as in y\ndef YnumpyToTensor(y_data_np):    \n    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n    print(y_data_np.shape)\n    print(type(y_data_np))\n\n    if use_cuda:\n        lgr.info (\"Using the GPU\")            \n    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n    else:\n        lgr.info (\"Using the CPU\")        \n    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n\n    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n    print(y_data_np.shape)\n    print(type(y_data_np))    \n    return Y_tensor","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"915c7a22b4b02a7e66c6005221ca0612ca365e2e","collapsed":true,"_cell_guid":"033868d8-e25f-4a03-a921-ff44c12fb569"},"source":"# class ConvRes(nn.Module):\n#     def __init__(self, insize, outsize):\n#         super(ConvRes, self).__init__()\n#         drate = .3\n#         self.math = nn.Sequential(\n#             nn.BatchNorm1d(insize),            \n#             torch.nn.Conv1d(insize, outsize, kernel_size=2, padding=2),\n#             nn.PReLU(),\n#         )\n#     def forward(self, x):\n#         return self.math(x)\n\n# class ConvCNN(nn.Module):\n#     def __init__(self, insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n#         super(ConvCNN, self).__init__()\n#         self.avg = avg\n#         self.math = torch.nn.Sequential(\n#             torch.nn.Conv1d(insize, outsize, kernel_size=kernel_size, padding=padding),\n#             torch.nn.BatchNorm1d(outsize),\n#             torch.nn.LeakyReLU(),\n#             torch.nn.MaxPool1d(pool),\n#         )        \n#     def forward(self, x):\n#         x = self.math(x)        \n#         return x\n\n# class SimpleNet(nn.Module):\n#     def __init__(self):\n#         super(SimpleNet, self).__init__()        \n\n#         self.cnn1 = ConvCNN(N_FEATURES, 64, kernel_size=7, pool=4, avg=False)\n#         self.cnn2 = ConvCNN(64, 64, kernel_size=5, pool=2, avg=True)\n#         self.cnn3 = ConvCNN(64, 32, kernel_size=5, pool=2, avg=True)\n#         self.res1 = ConvRes(32, 64)\n\n#         self.features = nn.Sequential(\n#             self.cnn1,\n# #             self.cnn2,\n# #             self.cnn3,\n# #             self.res1,\n#         )\n\n#         self.classifier = torch.nn.Sequential(\n#             nn.Linear(1024, 1),\n#         )\n#         self.sig = nn.Sigmoid()\n\n#     def forward(self, x):\n#         x = self.features(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.classifier(x)\n#         x = self.sig(x)\n#         return x\n    \n    \nX_tensor_train= XnumpyToTensor(trainX) # default order is NBC for a 3d tensor, but we have a 2d tensor\nX_shape=X_tensor_train.data.size()\n\n\nn_mult_factor=9\nn_input= trainX.shape[1]\nn_hidden= n_input * n_mult_factor\nn_output=1\nn_input_rows=trainX.shape[0]\nn_cnn_kernel=7\nn_padding=4\nn_max_pool1d=2\n\nDEBUG_ON=True\ndef debug(msg, x):\n    if DEBUG_ON:\n        print (msg + ', (size():' + str (x.size()))\n    \nclass CNNNumerAI(nn.Module):    \n    def __init__(self, n_input, n_hidden, n_output,n_cnn_kernel, n_mult_factor, n_padding,n_max_pool1d):\n        super(CNNNumerAI, self).__init__()    \n        self.n_input=n_input\n        self.n_hidden=n_hidden\n        self.n_output= n_output \n        self.n_cnn_kernel=n_cnn_kernel\n        self.n_mult_factor=n_mult_factor\n        self.n_padding=n_padding\n        self.n_max_pool1d=n_max_pool1d\n        self.n_l1=int((n_mult_factor * self.n_input) * (n_padding + 1) / n_max_pool1d)\n                    \n        self.features = nn.Sequential(  \n            torch.nn.Conv1d(self.n_input, self.n_hidden,kernel_size=(self.n_cnn_kernel,), stride=(1,), padding=(self.n_padding,)),                                             \n            torch.nn.LeakyReLU(),            \n            torch.nn.MaxPool1d(kernel_size=self.n_max_pool1d),\n                                    \n        )                        \n                \n        linear4=torch.nn.Linear(int(self.n_hidden), 1)\n        torch.nn.init.xavier_uniform(linear4.weight)        \n        \n        self.classifier = torch.nn.Sequential\n                                 (\n                                    linear4\n                                  )                                 \n        self.sig=nn.Sigmoid()\n                \n        \n    def forward(self, x):\n        varSize=x.data.shape[0] # must be calculated here in forward() since its is a dynamic size                          \n        # for CNN  \n        x=x.contiguous() \n        x = x.view(varSize,self.n_input,1)\n        debug('after view',x)   \n        x=self.features(x)\n        debug('after CNN',x)           \n        x = x.view(varSize,int(self.n_hidden)) \n        debug('after 2nd view',x)                  \n        x=self.classifier(x)   \n        debug('after self.out',x)   \n        x=self.sig(x)\n        return x\n\nnet = CNNNumerAI(n_input, n_hidden, n_output,n_cnn_kernel, n_mult_factor, n_padding, n_max_pool1d)    \nprint(net)\n\nif use_cuda:\n    net=net.cuda() \nb = net(X_tensor_train)\n\nprint ('(b.size():' + str (b.size()))    \n\nLR = 0.005\n\noptimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\nloss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n\nif use_cuda:\n    lgr.info (\"Using the GPU\")    \n    net.cuda()\n    loss_func.cuda()\n#     cudnn.benchmark = True\n\nlgr.info (optimizer)\nlgr.info (loss_func)","outputs":[]},{"metadata":{"_uuid":"5924485871c7b4a5433bfb54fedff46c7e23abed","_cell_guid":"82efda03-9e61-4901-8f8d-97bf4a36b9da"},"cell_type":"markdown","source":"# Training set"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f9057e5181309d3c1e7340c70fbe750d87f10af2","collapsed":true,"_cell_guid":"658daa90-6dda-44f1-b858-9a1de7f47c47"},"source":"from __future__ import division\n\nimport time\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\nfrom sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n\n# for windows\ntorch.backends.cudnn.enabled=False\n\nstart_time = time.time()    \nepochs=1500 # change to 5000 for better results\ndiv_factor=100\nall_losses = []\nloss_arr =[]\nDEBUG_ON=False\n\nprint (net)\n\nX_tensor_train= XnumpyToTensor(trainX)\nY_tensor_train= YnumpyToTensor(trainY)\nprint(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n\n# CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n# X_tensor_train=X_tensor_train.contiguous()\n# Y_tensor_train=Y_tensor_train.contiguous()\n                \n# From here onwards, we must only use PyTorch Tensors\nfor step in range(epochs):    \n    out = net(X_tensor_train)                 # input x and predict based on x\n    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n\n    optimizer.zero_grad()   # clear gradients for next train\n    cost.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n                   \n        \n    if step % div_factor == 0:        \n        loss = cost.data[0]\n        all_losses.append(loss)\n        print(step, cost.data.cpu().numpy())\n        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n        # Use .cpu() to move the tensor to host memory first.        \n        prediction = (net(X_tensor_train).data).float() # probabilities         \n#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n#         pred_y = prediction.data.numpy().squeeze()            \n        pred_y = prediction.cpu().numpy().squeeze()\n        target_y = Y_tensor_train.cpu().data.numpy()\n                        \n        tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ), 2*roc_auc_score(target_y,pred_y ) - 1)\n        print ('LOG_LOSS={}, ROC_AUC={}, GINI={}'.format(*tu))  \n        \n        loss_arr.append(cost.cpu().data.numpy()[0])\n                \nend_time = time.time()\nprint ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.plot(all_losses)\nplt.show()\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.title('GINI:' + str(2*roc_auc_score(target_y,pred_y ) - 1))\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([-0.1, 1.2])\nplt.ylim([-0.1, 1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0ab3b7d76fe6a7961f11a3b67537bf210f502732","collapsed":true,"_cell_guid":"65efa106-b2fd-490a-bd07-b5aaa276e760"},"source":"net.eval()\n# Validation data\nprint (valX.shape)\nprint (valY.shape)\n\nX_tensor_val= XnumpyToTensor(valX)\nY_tensor_val= YnumpyToTensor(valY)\n\n\nprint(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n\npredicted_val = (net(X_tensor_val).data).float() # probabilities \n# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\npred_y = predicted_val.cpu().numpy()\ntarget_y = Y_tensor_val.cpu().data.numpy()                \n\nprint (type(pred_y))\nprint (type(target_y))\n\n\nprint ('\\n')\ntu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ), 2*roc_auc_score(target_y,pred_y ) - 1)\nprint ('LOG_LOSS={}, ROC_AUC={}, GINI={}'.format(*tu))  \n        \nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.title('GINI=' + str(2*roc_auc_score(target_y,pred_y ) - 1))\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([-0.1, 1.2])\nplt.ylim([-0.1, 1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# print (pred_y)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a4fae8b85d5470eabe18894a5f92b05f15a3abec","slideshow":{"slide_type":"slide"},"collapsed":true,"_cell_guid":"374999bf-3efe-4c64-91d8-4397e02d9363"},"source":"# Submission","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2d965577d79bc18da96e37f60c7ab5c8366bf0a3","collapsed":true,"_cell_guid":"550b1ed8-b9bd-492f-8659-e0e31ff8a8cf"},"source":"# X_df_test = pd.read_csv(BASE_FOLDER + '/test.csv')\n# print('Test shape:', X_df_test.shape)\n# print('Columns:', X_df_test.columns)\n# id_test = X_df_test['id'].values\n# X_df_test=X_df_test.apply(lambda x: pandas.to_numeric(x, errors='ignore'))\n\n\n# print (X_df_test.shape)\n# columns = ['id', 'target']\n# df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n\n\n# for index, row in X_df_test.iterrows():\n#     rwo_no_id=row.drop('id')    \n# #     print (rwo_no_id.values)    \n#     x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n#     if use_cuda:\n#         X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n#     else:\n#         X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n                    \n#     X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n#     predicted_val = (net(X_tensor_test).data).float() # probabilities     \n#     p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n    \n#     df_pred = df_pred.append({'id':row['id'], 'target':p_test},ignore_index=True)\n# #     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n\n# df_pred.head(5)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"74026ada9da4f2f650347f6dd2f3ddb2a659dcdc","collapsed":true,"_cell_guid":"1e7cb91b-92e5-4be0-b6a5-0dff8742fa67"},"source":"# df_pred.id=df_pred.id.astype(int)\n\n# def savePred(df_pred, loss):\n# #     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n#     csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n#     df_pred.to_csv(csv_path, columns=('id', 'target'), index=None)\n#     print (csv_path)\n    \n# savePred (df_pred, str(2*roc_auc_score(target_y,pred_y ) - 1))","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"563253e9bcb548c417b519f1fcde92eafbe8274b","collapsed":true,"_cell_guid":"b701d421-10a8-46c0-83a0-fb87a9787d0e"},"source":"","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"be87f3dc85f6c4cc8c17e137326c7370ec38fe19","collapsed":true,"_cell_guid":"d6bb0ef6-4ade-4df6-99fc-721b95080430"},"source":"","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"48da4017ccbde49ce469ec49b275637636dc4856","collapsed":true,"_cell_guid":"63ac94b1-1ffd-4f8d-8831-7ac949dfb6d9"},"source":"","outputs":[]}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.3"},"livereveal":{"controls":"true","start_slideshow_at":"selected","progress":"true","scroll":"true","history":"true","mouseWheel":"true","overview":"true"},"anaconda-cloud":{},"celltoolbar":"Slideshow"}}