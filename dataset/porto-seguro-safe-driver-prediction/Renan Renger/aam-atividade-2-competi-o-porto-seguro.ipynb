{"cells":[{"metadata":{"_uuid":"9742a115258b897057483257df69c83f80bd5d84"},"cell_type":"markdown","source":"## Pré-processamento é provavelmente a parte mais importante de ciência dos dados\n\nTer dados representativos sem atributos faltantes é provavelmente o pote de ouro em ciência dos dados. É muito incomum que os dados do mundo real não apresentem anomalias seja da própria natureza ou sejam anomalias introduzidas no processo de medição e registro da observação (amostra).\n\nEsse notebook é voltado para como tratar dados mais complexos e transformar todas as informações em números que façam sentido para que o modelo seja capaz de traçar a relação entre atributos e classes. A seguir é oferecida uma pequena parcela de um conjunto de dados da empresa Porto Seguro, no qual uma competição foi aberta e os competidores foram desafiados a criar um modelo para prever se uma apólice teria um sinistro registrado ou não, indicando o uso do serviço.\n\nAlgumas características sobre o nome das features:\n- O nome dos atributos indica o grupo ao qual pertence (ind, reg, car);\n- Os prefixos bin e cat indicam atributos binários e categóricos, respectivamente;\n- Atributos sem os prefixos citados podem ser ordinais ou contínuos;\n- Atributos com -1 indicam dado faltante (missing); e\n- A coluna 'target' indica se houve sinistro para apólice ou não."},{"metadata":{"trusted":true,"_uuid":"1a7654aaf347e25084cbe7356064efadc9fcc25a"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7418c7b14b9e66afe65c1acbf34c8603edb80a4f"},"cell_type":"code","source":"dfTreino = pd.read_csv('../input/train.csv')\ndfTeste = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0e5054224eea44262988e984f16a3f3182558f1"},"cell_type":"code","source":"# Podemos usar a coluna \"id\" como o índice dos Datasets, sem nenhum prejuizo\ndfTreino.set_index('id', inplace=True)\ndfTeste.set_index('id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17c7b96681c5b098d4bc1ecd862b9f54ec39f843"},"cell_type":"code","source":"headNumber = 5\nprint(f'Dataset de treino - Primeiras {headNumber} linhas')\ndisplay(dfTreino.head(headNumber))\n\nprint(f'Dataset de teste - Primeiras {headNumber} linhas')\ndisplay(dfTeste.head(headNumber))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3c620fc418e9e13abea019149eaf2a3d612711b"},"cell_type":"code","source":"print('Dataset de treino - Estatistica descritiva')\ndisplay(dfTreino.describe())\n\nprint('Dataset de teste - Estatistica descritiva')\ndisplay(dfTeste.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ad44f081a392c74953f8030d6288d0f3d04b8db"},"cell_type":"code","source":"print('Dataset de treino - Sumário das Features')\nprint(dfTreino.info())\nprint('---')\nprint('Dataset de treino - Sumário das Features')\nprint(dfTeste.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d62630365986dbf806707c1805f9fe5ab752555e"},"cell_type":"code","source":"print(f'Dataset de treino tem {dfTreino.shape[0]} linhas por {dfTreino.shape[1]} colunas ({dfTreino.shape[0] * dfTreino.shape[1]} celulas)')\nprint(f'Dataset de teste tem {dfTeste.shape[0]} linhas por {dfTeste.shape[1]} colunas ({dfTeste.shape[0] * dfTeste.shape[1]} celulas)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c56e7d35db35ec6076f38a9aa7d2c8892ee2f1c7"},"cell_type":"code","source":"nonUsed, used = dfTreino.groupby('target').size()\nprint(f'Das {dfTreino.shape[0]} entradas no dataset, {nonUsed} foram de casos onde não foi acionado o seguro e {used} foram caso onde houve acionamento')\nprint(f'Temos assim {round((used/nonUsed) * 100,6)}% de ocorrencias em que o resultado (1 ou \"houve acionamento\") desejamos prever')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f55ba8dea6d0f9c706be2c2f6f3ddc1c1cc7d190"},"cell_type":"markdown","source":"## Observação\nCom base nas analises acima, podemos perceber algumas coisas:\n\n1 -  Os valores estão desnormalizados, variando tanto de tipo (numéricos discretos e continuos, categoricos e binários);\n\n2 - Faltando dados em ambos os datasets (marcados como -1 nos datasets);\n\n3 - **Temos um enorme desbalanço no que tange a ocorrencias cujo valor é desejado (\"houve acionamento\") vs ocorrencias sem acionamento**\n\n---"},{"metadata":{"trusted":true,"_uuid":"1a759114a85164dffd7e8bc22634aaede327e174"},"cell_type":"code","source":"print(f'Antes - Treino tem {dfTreino.shape[0]} linhas por {dfTreino.shape[1]} colunas ({dfTreino.shape[0] * dfTreino.shape[1]} celulas)')\ndfTreino.drop_duplicates()\nprint(f'Depois - Treino tem {dfTreino.shape[0]} linhas por {dfTreino.shape[1]} colunas ({dfTreino.shape[0] * dfTreino.shape[1]} celulas)')\nprint('---')\nprint(f'Antes - Teste tem {dfTeste.shape[0]} linhas por {dfTeste.shape[1]} colunas ({dfTeste.shape[0] * dfTeste.shape[1]} celulas)')\ndfTeste.drop_duplicates()\nprint(f'Depois - Teste tem {dfTeste.shape[0]} linhas por {dfTeste.shape[1]} colunas ({dfTeste.shape[0] * dfTeste.shape[1]} celulas)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50f2facc45a1b3d17f43b4b93dda2d1a5f44453d"},"cell_type":"markdown","source":"Ao trabalhar com as colunas (atributos), é interessante ter uma organização de que tipo de dado determinado atributo é, e para quais propósitos determinado atributo pode ser usado. Nesse sentido, seguindo o trabalho de https://www.kaggle.com/bertcarremans/data-preparation-exploration, vamos criar metadados para esse conjunto."},{"metadata":{"trusted":true,"_uuid":"bdc7d1048a6ea454e4432a125353e0f2279fdd83"},"cell_type":"code","source":"def generateMetadata(dfInput):\n    data = []\n    for f in dfInput.columns:\n        # definindo o uso (entre rótulo, id e atributos)\n        if f == 'target':\n            role = 'target' # rótulo\n        elif f == 'id':\n            role = 'id'\n        else:\n            role = 'input' # atributos\n\n        # definindo o tipo do dado\n        if 'bin' in f or f == 'target':\n            level = 'binary'\n        elif 'cat' in f or f == 'id':\n            level = 'nominal'\n        elif dfInput[f].dtype == np.float64:\n            level = 'interval'\n        elif dfInput[f].dtype == np.int64:\n            level = 'ordinal'\n\n        # mantem keep como verdadeiro pra tudo, exceto id\n        keep = True\n        if f == 'id':\n            keep = False\n\n        # cria o tipo de dado\n        dtype = dfInput[f].dtype\n\n        # cria dicionário de metadados\n        f_dict = {\n            'varname': f,\n            'role': role,\n            'level': level,\n            'keep': keep,\n            'dtype': dtype\n        }\n        data.append(f_dict)\n\n    meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n    meta.set_index('varname', inplace=True)\n    \n    return meta","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da06f97ec6126ddbfcbb301405a54bfdeb7e880f"},"cell_type":"markdown","source":"Para visualizar o atributo e todos seus metadados, basta mostrar a variável meta:"},{"metadata":{"trusted":true,"_uuid":"ab6e9dfb59b12eedad5391391f49ca49951a7b9b"},"cell_type":"code","source":"meta_train = generateMetadata(dfTreino)\nmeta_test = generateMetadata(dfTeste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5293d760cb438834c71c46d8dbcfe14ec8e1b4b9"},"cell_type":"code","source":"display(meta_train)\ndisplay(meta_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33c425bf85c4e5da38b843bfda69cc2af543fa7b"},"cell_type":"markdown","source":"Com essa estrutura de metadados, fica fácil consultar quais colunas quer se manter e que são nominais, por exemplo:"},{"metadata":{"trusted":true,"_uuid":"e606fff15cbdd9e93a1b26fa8c81dc5c7a474b84"},"cell_type":"code","source":"print('Metadados categoricos da base de treino')\nprint(meta_train[(meta_train.level == 'nominal') & (meta_train.keep)].index)\nprint('---')\nprint('Metadados categoricos da base de teste')\nprint(meta_test[(meta_test.level == 'nominal') & (meta_test.keep)].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95ccf6aea89a0e49563a7650888586f0db52378a"},"cell_type":"markdown","source":"Da mesma forma, seria possível contar os atributos por tipo de uso e dado:"},{"metadata":{"trusted":true,"_uuid":"10e8d89f5e57830447940a9f318bf57c627523a2"},"cell_type":"code","source":"print('Tipos e quantidade de features do dataset de treino')\ndisplay(pd.DataFrame({'count' : meta_train.groupby(['role', 'level'])['role'].size()}).reset_index())\n\nprint('Tipos e quantidade de features do dataset de teste')\ndisplay(pd.DataFrame({'count' : meta_test.groupby(['role', 'level'])['role'].size()}).reset_index())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b2922f3d904bcd30aade510d3fbd43b6b4664d9"},"cell_type":"markdown","source":"## Valores faltantes\n\nConforme já mencionado, os valores faltantes são indicados por -1, então é importante saber quais colunas têm valores faltantes e em qual proporção."},{"metadata":{"trusted":true,"_uuid":"00213ba7f718ceb850a063964abc5aca64ec1dda"},"cell_type":"code","source":"def getMissingAttributes(dfInput):\n    atributos_missing = []\n    return_missing = []\n\n    for f in dfInput.columns:\n        missings = dfInput[dfInput[f] == -1][f].count()\n        if missings > 0:\n            atributos_missing.append(f)\n            missings_perc = missings/dfInput.shape[0]\n            \n            return_missing.append([f, missings, missings_perc])\n\n            print('Atributo {} tem {} amostras ({:.2%}) com valores faltantes'.format(f, missings, missings_perc))\n            \n\n    print('No total, há {} atributos com valores faltantes'.format(len(atributos_missing)))\n    \n    return pd.DataFrame(return_missing).rename(index=str, columns={0: \"column_name\", 1: \"column_nulls\", 2: \"column_percentage\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c70e52f178ddcc54242b5249184bba079aafc54"},"cell_type":"code","source":"missing_Train = getMissingAttributes(dfTreino)\ndisplay(missing_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d83e821557596fe58c02c83c4b366b9b6d99c336"},"cell_type":"code","source":"missing_Test = getMissingAttributes(dfTeste)\ndisplay(missing_Test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcd12a496b8fba471f22f6684e273df4bea5643d"},"cell_type":"markdown","source":"Duas estratégias podem ser optadas aqui: simplesmente remover o atributo ou tentar preenchê-lo de forma sintética. Preencher de forma sintética pode gerar uma falsa distribuição quando o número de atributos faltantes é muito alto. Quando este for o caso, é sempre seguro optar por remover o atributo inteiro. Também é importante lembrar que a estratégia de preenchimento deve ser coerente com o tipo de dado, por exemplo: **dados ordinais não devem ser preenchidos com média, nem dados contínuos com moda.**"},{"metadata":{"trusted":true,"_uuid":"e9ea753249d796c495bcff97739b511d87233eeb"},"cell_type":"code","source":"# limiar de remoção - 42.5% de nulos\nremove_threshold = 0.425","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69559f3ede8d31cb5959c5b58575716dba2c74cd"},"cell_type":"code","source":"columns_to_remove = np.array(missing_Train.column_name[(missing_Train.column_percentage >= remove_threshold)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06ed2b6f78fa9e39444358f17b9547afdb847b80"},"cell_type":"code","source":"# removendo as colunas que tem muitos valores faltantes\ndfTreino = dfTreino.drop(columns_to_remove, axis=1)\ndfTeste = dfTeste.drop(columns_to_remove, axis=1)\n\n# atualiza os metadados para ter como referência\nmeta_train.loc[(columns_to_remove),'keep'] = False  \nmeta_test.loc[(columns_to_remove),'keep'] = False\n\n# remove do frame de colunas com falta de dados as colunas que foram dropadas\nmissing_Train.drop(missing_Train[(np.isin(missing_Train.column_name, columns_to_remove))].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"805b5d3bb4a13fe039bc29de0630e46701623ed6"},"cell_type":"code","source":"# Usa ou moda ou média para preencher os valores \"vazios\" que nosso dataset contem, baseado nos metadados do mesmo\ndef fillNullNumbers(dfInput, dfMetadata, dfMissing, missing_default, label):\n\n    from sklearn.impute import SimpleImputer\n\n    media_imp = SimpleImputer(missing_values=missing_default, strategy='mean')\n    moda_imp = SimpleImputer(missing_values=missing_default, strategy='most_frequent')\n\n    for index,row in dfMissing.iterrows():\n        columnName = row['column_name']\n        columnType = dfMetadata.level[(dfMetadata.index == columnName)][0]\n\n        if (columnType == 'interval'):\n            imputerToUse = media_imp\n            imputerString = 'media_imp'\n        elif (columnType == 'ordinal'):\n            imputerToUse = moda_imp\n            imputerString = 'moda_imp'\n        else:\n            imputerToUse = None\n            imputerString = None\n\n        if (imputerToUse != None):\n            dfInput[columnName] = imputerToUse.fit_transform(dfInput[[columnName]]).ravel()\n            print(f\"{label} - Preenchida coluna {columnName}, cujo tipo é {columnType}, usando o Imputer {imputerString}\")\n\n    return dfInput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d77312312941f0919691fb1c8647870e5b24ed2"},"cell_type":"code","source":"dfTreino = fillNullNumbers(dfTreino, meta_train, missing_Train, -1, 'Treino')\nprint('---')\ndfTeste = fillNullNumbers(dfTeste, meta_test, missing_Train, -1, 'Teste')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0921473df8a574071b09435212756f6c8fc41084"},"cell_type":"markdown","source":"Os atributos categóricos podem ser mantidos porque o número de valores faltantes não é expressivo. Inclusive, a estratégia de preenchimento dos **atributos categóricos** é sempre mais complexa. Esses atributos **não se beneficiam de medidas estatísticas** como moda e média, portanto essas medidas não servem para preenchê-los de forma sintética.\n\n---\n\n## One-hot encoding (ou dummy variables)\n\nDepois de ter tratado os dados faltantes, é importante que os dados ordinais tenham representação apropriada para o problema tratado. Se o dado não tem distância ou rankamento entre eles, cada valor de um atributo deve ser representado por um conjunto de atributos de mesma distância. *(Verificar slides desse encontro para que isso fique mais claro)*\n\nOs dados que precisam ser separados em mais dimensões já foram identificados como nominais no pré-processamento. É importante verificar se esses dados têm grande variedade de valores ou não, e aplicar essa separação apenas se for viável. Por exemplo, se um determinado atributo tem 300 valores, isso geraria 300 colunas novas. Isso só se justificaria se fosse uma base realmente grande e se houvesse uma correlação muito alta entre essa variedade de valores e a classe."},{"metadata":{"trusted":true,"_uuid":"8d33f93e1d121e292dda2040ea2b9b183bf09942"},"cell_type":"code","source":"def performOneHotEncoding(dfTrain, dfTest, meta_generic):\n    v = meta_generic[(meta_generic.level == 'nominal') & (meta_generic.keep)].index\n\n    for f in v:\n        dist_values = dfTrain[f].value_counts().shape[0]\n        print('Atributo {} tem {} valores distintos'.format(f, dist_values))\n        \n    print('Antes do one-hot encoding tinha-se {} atributos'.format(dfTrain.shape[1]))\n    dfTrain = pd.get_dummies(dfTrain, columns=v, drop_first=True)\n    print('Depois do one-hot encoding tem-se {} atributos'.format(dfTrain.shape[1]))\n\n    dfTest = pd.get_dummies(dfTest, columns=v, drop_first=True)\n    missing_cols = set( dfTrain.columns ) - set( dfTest.columns )\n    for c in missing_cols:\n        dfTest[c] = 0\n\n    dfTrain, dfTest = dfTrain.align(dfTest, axis=1)\n    \n    return dfTrain, dfTest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d6b5fafda4ec24b89a66a46d7ecdca49afbfe5b"},"cell_type":"markdown","source":"Vamos optar por manter todos atributos e, portanto, gerar o conjunto de atributos que os mantêm à mesma distância:"},{"metadata":{"trusted":true,"_uuid":"acf4c6866c9c00d07b0855349f194a3cbd36076c"},"cell_type":"code","source":"dfTreino, dfTeste = performOneHotEncoding(dfTreino, dfTeste, meta_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a925c09396f626bfab0ddca2b42022244ac9bbc"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nmin_max_scaler = MinMaxScaler()\n\ndfTreino[dfTreino.columns] = min_max_scaler.fit_transform(dfTreino[dfTreino.columns])\ndfTeste[dfTeste.columns] = min_max_scaler.fit_transform(dfTeste[dfTeste.columns])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5785c81b877363b0a86be4b5da3faf85c9d8c5cc"},"cell_type":"markdown","source":"## Depois de todo pré-processamento...\n\nÉ hora de verificar se tanto treino como teste têm o mesmo tamanho/formato, e aplicar um modelo de classificação já que esse é um problema desse tipo. Vale lembrar que o tamanho do treino e teste pode variar quando você estiver participando de outras competições ou explorando outros conjuntos de dados.\n\nIsso porque na maioria das competições não se tem o *target* do test. Estima-se uma resposta e submete ao Kaggle, por exemplo, para que ele verifique qual foi o resultado final. Então esse tamanho pode variar em 1 entre treino e teste. No nosso caso, como todos os dados vêm de uma mesma fonte para experimentos, é esperado que tenham a mesma quantidade de atributos ou colunas."},{"metadata":{"trusted":true,"_uuid":"9f22786e9d4edbeed8bbb9ac998306f68ee1ef32"},"cell_type":"code","source":"print(dfTreino.shape)\nprint(dfTeste.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38598331e1c03264c019cb1198b9ab7c7bcd7e6c"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = dfTreino.drop(['id', 'target'], axis=1)\ny = dfTreino['target']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2874f507980a038d60bcdbeb2c8e3acfbc03894a"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nmodel = LogisticRegression(solver='lbfgs')\n\nmodel.fit(X_train, y_train)\ny_pred_class = model.predict(X_val)\ny_pred_proba = model.predict_proba(X_val)\n\nrecall = recall_score(y_val, y_pred_class)\naccuracy = accuracy_score(y_val, y_pred_class)\nlogloss = log_loss(y_val, y_pred_proba)\nprecision =  precision_score(y_val, y_pred_class)\nf1 = f1_score(y_val, y_pred_class)\n\nprint(f'Regressão Logistica / Baseline')\nprint('---')\nprint(f'Acurácia: {round(accuracy, 6)}%')\nprint(f'Recall: {round(recall, 6)}%')\nprint(f'Precisão: {round(precision, 6)}%')\nprint(f'Log Loss: {round(logloss, 6)}')\nprint(f'F1 Score: {round(f1, 6)}')\n\nprint('---')\nprint('Matriz de Confusão')\ndisplay(pd.DataFrame(confusion_matrix(y_val, y_pred_class)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23b1c0b7a0e9be42d0a2ac498318ae4cfee3c338"},"cell_type":"markdown","source":"## Exercícios\n\n1. A partir desse ponto, verifique a distribuição das classes e analise qual métrica seria mais interessante para estimar o resultado de forma justa.\n2. Utilize um método de classificação da sua escolha e aplique hiperparametrização.\n3. Verifique qual o resultado que se tem utilizando validação cruzada."},{"metadata":{"trusted":true,"_uuid":"746b003f5f5792bbcae8753073b0c3e9527d8ef0"},"cell_type":"markdown","source":"## Primeira Classe de Categorizadores -  Arvore (Decision Tree e Random Forest)"},{"metadata":{"trusted":true,"_uuid":"2bb8ace49dc9897b71f07e48e8b35f2d561e7981","scrolled":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nclf = DecisionTreeClassifier(max_depth=80,min_samples_leaf=1)\nclf.fit(X_train, y_train)\n\ny_pred_class = clf.predict(X_val)\ny_pred_proba = clf.predict_proba(X_val)\n\nrecall = recall_score(y_val, y_pred_class)\naccuracy = accuracy_score(y_val, y_pred_class)\nlogloss = log_loss(y_val, y_pred_proba)\nprecision =  precision_score(y_val, y_pred_class)\nf1 = f1_score(y_val, y_pred_class)\n\nprint(f'Decision Tree with 80 layers and at least 1 leaves')\nprint('---')\nprint(f'Acurácia: {round(accuracy, 6)}%')\nprint(f'Recall: {round(recall, 6)}%')\nprint(f'Precisão: {round(precision, 6)}%')\nprint(f'Log Loss: {round(logloss, 6)}')\nprint(f'F1 Score: {round(f1, 6)}')\n\nprint('---')\nprint('Matriz de Confusão')\ndisplay(pd.DataFrame(confusion_matrix(y_val, y_pred_class)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2387b4f09ba8f031785f4e003e42e7bb45dbb49c"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nclf = RandomForestClassifier(n_estimators=1, max_depth=80, min_samples_leaf=1, random_state=0)\nclf.fit(X_train, y_train)\n\ny_pred_class = clf.predict(X_val)\ny_pred_proba = clf.predict_proba(X_val)\n\nrecall = recall_score(y_val, y_pred_class)\naccuracy = accuracy_score(y_val, y_pred_class)\nlogloss = log_loss(y_val, y_pred_proba)\nprecision =  precision_score(y_val, y_pred_class)\nf1 = f1_score(y_val, y_pred_class)\n\nprint(f'Random Forest with 1 estimator, 80 layers and at least 1 leaf per layer')\nprint('---')\nprint(f'Acurácia: {round(accuracy, 6)}%')\nprint(f'Recall: {round(recall, 6)}%')\nprint(f'Precisão: {round(precision, 6)}%')\nprint(f'Log Loss: {round(logloss, 6)}')\nprint(f'F1 Score: {round(f1, 6)}')\n\nprint('---')\nprint('Matriz de Confusão')\ndisplay(pd.DataFrame(confusion_matrix(y_val, y_pred_class)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9a6a5e92f3479f1bfcccc0d01e4d9d5a540024f"},"cell_type":"code","source":"'''\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, ShuffleSplit\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nsvm = LinearSVC()\nclf = CalibratedClassifierCV(svm, cv=ShuffleSplit())\nclf.fit(X_train, y_train)\n\ny_pred_class = clf.predict(X_val)\ny_pred_proba = clf.predict_proba(X_val)\n\nrecall = recall_score(y_val, y_pred_class)\naccuracy = accuracy_score(y_val, y_pred_class)\nlogloss = log_loss(y_val, y_pred_proba)\nprecision =  precision_score(y_val, y_pred_class)\nf1 = f1_score(y_val, y_pred_class)\n\nprint(f'Regressão Logistica / Baseline')\nprint('---')\nprint(f'Acurácia: {round(accuracy, 6)}%')\nprint(f'Recall: {round(recall, 6)}%')\nprint(f'Precisão: {round(precision, 6)}%')\nprint(f'Log Loss: {round(logloss, 6)}')\nprint(f'F1 Score: {round(f1, 6)}')\n\nprint('---')\nprint('Matriz de Confusão')\ndisplay(pd.DataFrame(confusion_matrix(y_val, y_pred_class)))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30fd87d37f57347302b3cf6efd606dd0ea10aa95"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nclf = SGDClassifier(loss='modified_huber', shuffle=True, random_state=0, max_iter=1000, tol=1e-3)\nclf.fit(X_train, y_train)\n\ny_pred_class = clf.predict(X_val)\ny_pred_proba = clf.predict_proba(X_val)\n\nrecall = recall_score(y_val, y_pred_class)\naccuracy = accuracy_score(y_val, y_pred_class)\nlogloss = log_loss(y_val, y_pred_proba)\nprecision =  precision_score(y_val, y_pred_class)\nf1 = f1_score(y_val, y_pred_class)\n\nprint(f'Regressão Logistica / Baseline')\nprint('---')\nprint(f'Acurácia: {round(accuracy, 6)}%')\nprint(f'Recall: {round(recall, 6)}%')\nprint(f'Precisão: {round(precision, 6)}%')\nprint(f'Log Loss: {round(logloss, 6)}')\nprint(f'F1 Score: {round(f1, 6)}')\n\nprint('---')\nprint('Matriz de Confusão')\ndisplay(pd.DataFrame(confusion_matrix(y_val, y_pred_class)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf925fdfd667e3991ae890296eb430a07c04e62d"},"cell_type":"code","source":"# Rodar depois, fora do Kaggle - Provavel que vá demorar 6h+\n'''\nfrom sklearn.svm import SVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, ShuffleSplit\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nsvm = SVC(gamma=2, C=1)\nclf = CalibratedClassifierCV(svm, cv=ShuffleSplit())\nclf.fit(X_train, y_train)\n\ny_pred_class = clf.predict(X_val)\ny_pred_proba = clf.predict_proba(X_val)\n\nrecall = recall_score(y_val, y_pred_class)\naccuracy = accuracy_score(y_val, y_pred_class)\nlogloss = log_loss(y_val, y_pred_proba)\nprecision =  precision_score(y_val, y_pred_class)\nf1 = f1_score(y_val, y_pred_class)\n\nprint(f'Regressão Logistica / Baseline')\nprint('---')\nprint(f'Acurácia: {round(accuracy, 6)}%')\nprint(f'Recall: {round(recall, 6)}%')\nprint(f'Precisão: {round(precision, 6)}%')\nprint(f'Log Loss: {round(logloss, 6)}')\nprint(f'F1 Score: {round(f1, 6)}')\n\nprint('---')\nprint('Matriz de Confusão')\ndisplay(pd.DataFrame(confusion_matrix(y_val, y_pred_class)))\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}