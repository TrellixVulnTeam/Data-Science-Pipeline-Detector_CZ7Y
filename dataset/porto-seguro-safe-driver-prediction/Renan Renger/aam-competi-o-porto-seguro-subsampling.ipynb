{"cells":[{"metadata":{"_uuid":"140ab0533aa6ce88d9e126ba2fc60758b282cddc"},"cell_type":"markdown","source":"## AAM / Machine Learning - Atividade 02 - Competição Porto Seguro\n\n**Equipe**:\n\n*Ciro Mora* - RA: 111310\n\n*José Diniz* - RA: 183134\n\n*Renan Renger* - RA: 183148\n\n*Roberto Rodrigues* -  RA: 060235\n\n**Projeto**\n\nPredição de acionamento ou não de sinistro de seguro baseado em dataset liberado pela competição.\n\n**Observação**\n\nBoa parte dos comentário do notebook são proveniente de um notebook base fornecido em sala com a descrição da atividade serão mantidos por comodidade.\n"},{"metadata":{"_uuid":"9742a115258b897057483257df69c83f80bd5d84"},"cell_type":"markdown","source":"## Pré-processamento é provavelmente a parte mais importante de ciência dos dados\n\nTer dados representativos sem atributos faltantes é provavelmente o pote de ouro em ciência dos dados. É muito incomum que os dados do mundo real não apresentem anomalias seja da própria natureza ou sejam anomalias introduzidas no processo de medição e registro da observação (amostra).\n\nEsse notebook é voltado para como tratar dados mais complexos e transformar todas as informações em números que façam sentido para que o modelo seja capaz de traçar a relação entre atributos e classes. A seguir é oferecida uma pequena parcela de um conjunto de dados da empresa Porto Seguro, no qual uma competição foi aberta e os competidores foram desafiados a criar um modelo para prever se uma apólice teria um sinistro registrado ou não, indicando o uso do serviço.\n\nAlgumas características sobre o nome das features:\n- O nome dos atributos indica o grupo ao qual pertence (ind, reg, car);\n- Os prefixos bin e cat indicam atributos binários e categóricos, respectivamente;\n- Atributos sem os prefixos citados podem ser ordinais ou contínuos;\n- Atributos com -1 indicam dado faltante (missing); e\n- A coluna 'target' indica se houve sinistro para apólice ou não."},{"metadata":{"_uuid":"1a7654aaf347e25084cbe7356064efadc9fcc25a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom numba import jit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83d9b39ce027ba5018349eb0633fc7c80f8638cb"},"cell_type":"code","source":"@jit\ndef eval_gini(y_true, y_prob):\n    \"\"\"\n    Original author CPMP : https://www.kaggle.com/cpmpml\n    In kernel : https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0\n    delta = 0\n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n    return gini","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7418c7b14b9e66afe65c1acbf34c8603edb80a4f","trusted":true},"cell_type":"code","source":"dfTreino = pd.read_csv('../input/train.csv')\ndfTeste = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0e5054224eea44262988e984f16a3f3182558f1","trusted":true},"cell_type":"code","source":"# Podemos usar a coluna \"id\" como o índice dos Datasets, sem nenhum prejuizo\ndfTreino.set_index('id', inplace=True)\ndfTeste.set_index('id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17c7b96681c5b098d4bc1ecd862b9f54ec39f843","trusted":true},"cell_type":"code","source":"headNumber = 5\nprint(f'Dataset de treino - Primeiras {headNumber} linhas')\ndisplay(dfTreino.head(headNumber))\n\nprint(f'Dataset de teste - Primeiras {headNumber} linhas')\ndisplay(dfTeste.head(headNumber))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3c620fc418e9e13abea019149eaf2a3d612711b","trusted":true},"cell_type":"code","source":"print('Dataset de treino - Estatistica descritiva')\ndisplay(dfTreino.describe())\n\nprint('Dataset de teste - Estatistica descritiva')\ndisplay(dfTeste.describe())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ad44f081a392c74953f8030d6288d0f3d04b8db","trusted":true},"cell_type":"code","source":"print('Dataset de treino - Sumário das Features')\nprint(dfTreino.info())\nprint('---')\nprint('Dataset de treino - Sumário das Features')\nprint(dfTeste.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62630365986dbf806707c1805f9fe5ab752555e","trusted":true},"cell_type":"code","source":"print(f'Dataset de treino tem {dfTreino.shape[0]} linhas por {dfTreino.shape[1]} colunas ({dfTreino.shape[0] * dfTreino.shape[1]} celulas)')\nprint(f'Dataset de teste tem {dfTeste.shape[0]} linhas por {dfTeste.shape[1]} colunas ({dfTeste.shape[0] * dfTeste.shape[1]} celulas)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c56e7d35db35ec6076f38a9aa7d2c8892ee2f1c7","trusted":true},"cell_type":"code","source":"nonUsed, used = dfTreino.groupby('target').size()\nprint(f'Das {dfTreino.shape[0]} entradas no dataset, {nonUsed} foram de casos onde não foi acionado o seguro e {used} foram caso onde houve acionamento')\nprint(f'Temos assim {round((used/nonUsed) * 100,6)}% de ocorrencias em que o resultado (1 ou \"houve acionamento\") desejamos prever')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f55ba8dea6d0f9c706be2c2f6f3ddc1c1cc7d190"},"cell_type":"markdown","source":"## Observação\nCom base nas analises acima, podemos perceber algumas coisas:\n\n1 -  Os valores estão desnormalizados, variando tanto de tipo (numéricos discretos e continuos, categoricos e binários);\n\n2 - Faltando dados em ambos os datasets (marcados como -1 nos datasets);\n\n3 - **Temos um enorme desbalanço no que tange a ocorrencias cujo valor é desejado (\"houve acionamento\") vs ocorrencias sem acionamento**\n\n---"},{"metadata":{"_uuid":"1a759114a85164dffd7e8bc22634aaede327e174","trusted":true},"cell_type":"code","source":"print(f'Antes - Treino tem {dfTreino.shape[0]} linhas por {dfTreino.shape[1]} colunas ({dfTreino.shape[0] * dfTreino.shape[1]} celulas)')\ndfTreino.drop_duplicates()\nprint(f'Depois - Treino tem {dfTreino.shape[0]} linhas por {dfTreino.shape[1]} colunas ({dfTreino.shape[0] * dfTreino.shape[1]} celulas)')\nprint('---')\nprint(f'Antes - Teste tem {dfTeste.shape[0]} linhas por {dfTeste.shape[1]} colunas ({dfTeste.shape[0] * dfTeste.shape[1]} celulas)')\ndfTeste.drop_duplicates()\nprint(f'Depois - Teste tem {dfTeste.shape[0]} linhas por {dfTeste.shape[1]} colunas ({dfTeste.shape[0] * dfTeste.shape[1]} celulas)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50f2facc45a1b3d17f43b4b93dda2d1a5f44453d"},"cell_type":"markdown","source":"Ao trabalhar com as colunas (atributos), é interessante ter uma organização de que tipo de dado determinado atributo é, e para quais propósitos determinado atributo pode ser usado. Nesse sentido, seguindo o trabalho de https://www.kaggle.com/bertcarremans/data-preparation-exploration, vamos criar metadados para esse conjunto."},{"metadata":{"_uuid":"bdc7d1048a6ea454e4432a125353e0f2279fdd83","trusted":true},"cell_type":"code","source":"def generateMetadata(dfInput):\n    data = []\n    for f in dfInput.columns:\n        # definindo o uso (entre rótulo, id e atributos)\n        if f == 'target':\n            role = 'target' # rótulo\n        elif f == 'id':\n            role = 'id'\n        else:\n            role = 'input' # atributos\n\n        # definindo o tipo do dado\n        if 'bin' in f or f == 'target':\n            level = 'binary'\n        elif 'cat' in f or f == 'id':\n            level = 'nominal'\n        elif dfInput[f].dtype == float or dfInput[f].dtype == np.float64:\n            level = 'interval'\n        elif dfInput[f].dtype == int or dfInput[f].dtype == np.int64:\n            level = 'ordinal'\n            \n        # mantem keep como verdadeiro pra tudo, exceto id\n        keep = True\n        if f == 'id':\n            keep = False\n\n        # cria o tipo de dado\n        dtype = dfInput[f].dtype\n\n        # cria dicionário de metadados\n        f_dict = {\n            'varname': f,\n            'role': role,\n            'level': level,\n            'keep': keep,\n            'dtype': dtype\n        }\n        data.append(f_dict)\n\n    meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n    meta.set_index('varname', inplace=True)\n    \n    return meta","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da06f97ec6126ddbfcbb301405a54bfdeb7e880f"},"cell_type":"markdown","source":"Para visualizar o atributo e todos seus metadados, basta mostrar a variável meta:"},{"metadata":{"_uuid":"ab6e9dfb59b12eedad5391391f49ca49951a7b9b","trusted":true},"cell_type":"code","source":"meta_train = generateMetadata(dfTreino)\nmeta_test = generateMetadata(dfTeste)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5293d760cb438834c71c46d8dbcfe14ec8e1b4b9","trusted":true},"cell_type":"code","source":"display(meta_train)\ndisplay(meta_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33c425bf85c4e5da38b843bfda69cc2af543fa7b"},"cell_type":"markdown","source":"Com essa estrutura de metadados, fica fácil consultar quais colunas quer se manter e que são nominais, por exemplo:"},{"metadata":{"_uuid":"e606fff15cbdd9e93a1b26fa8c81dc5c7a474b84","trusted":true},"cell_type":"code","source":"print('Metadados categoricos da base de treino')\nprint(meta_train[(meta_train.level == 'nominal') & (meta_train.keep)].index)\nprint('---')\nprint('Metadados categoricos da base de teste')\nprint(meta_test[(meta_test.level == 'nominal') & (meta_test.keep)].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95ccf6aea89a0e49563a7650888586f0db52378a"},"cell_type":"markdown","source":"Da mesma forma, seria possível contar os atributos por tipo de uso e dado:"},{"metadata":{"_uuid":"10e8d89f5e57830447940a9f318bf57c627523a2","trusted":true},"cell_type":"code","source":"print('Tipos e quantidade de features do dataset de treino')\ndisplay(pd.DataFrame({'count' : meta_train.groupby(['role', 'level'])['role'].size()}).reset_index())\n\nprint('Tipos e quantidade de features do dataset de teste')\ndisplay(pd.DataFrame({'count' : meta_test.groupby(['role', 'level'])['role'].size()}).reset_index())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b2922f3d904bcd30aade510d3fbd43b6b4664d9"},"cell_type":"markdown","source":"## Valores faltantes\n\nConforme já mencionado, os valores faltantes são indicados por -1, então é importante saber quais colunas têm valores faltantes e em qual proporção."},{"metadata":{"_uuid":"00213ba7f718ceb850a063964abc5aca64ec1dda","trusted":true},"cell_type":"code","source":"def getMissingAttributes(dfInput):\n    atributos_missing = []\n    return_missing = []\n\n    for f in dfInput.columns:\n        missings = dfInput[dfInput[f] == -1][f].count()\n        if missings > 0:\n            atributos_missing.append(f)\n            missings_perc = missings/dfInput.shape[0]\n            \n            return_missing.append([f, missings, missings_perc])\n\n            print('Atributo {} tem {} amostras ({:.2%}) com valores faltantes'.format(f, missings, missings_perc))\n            \n\n    print('No total, há {} atributos com valores faltantes'.format(len(atributos_missing)))\n    \n    return pd.DataFrame(return_missing).rename(index=str, columns={0: \"column_name\", 1: \"column_nulls\", 2: \"column_percentage\"})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c70e52f178ddcc54242b5249184bba079aafc54","trusted":true},"cell_type":"code","source":"missing_Train = getMissingAttributes(dfTreino)\ndisplay(missing_Train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d83e821557596fe58c02c83c4b366b9b6d99c336","trusted":true},"cell_type":"code","source":"missing_Test = getMissingAttributes(dfTeste)\ndisplay(missing_Test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcd12a496b8fba471f22f6684e273df4bea5643d"},"cell_type":"markdown","source":"Duas estratégias podem ser optadas aqui: simplesmente remover o atributo ou tentar preenchê-lo de forma sintética. Preencher de forma sintética pode gerar uma falsa distribuição quando o número de atributos faltantes é muito alto. Quando este for o caso, é sempre seguro optar por remover o atributo inteiro. Também é importante lembrar que a estratégia de preenchimento deve ser coerente com o tipo de dado, por exemplo: **dados ordinais não devem ser preenchidos com média, nem dados contínuos com moda.**"},{"metadata":{"_uuid":"e9ea753249d796c495bcff97739b511d87233eeb","trusted":true},"cell_type":"code","source":"# limiar de remoção - 42.5% de nulos\nremove_threshold = 0.425","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69559f3ede8d31cb5959c5b58575716dba2c74cd","trusted":true},"cell_type":"code","source":"columns_to_remove = np.array(missing_Train.column_name[(missing_Train.column_percentage >= remove_threshold)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06ed2b6f78fa9e39444358f17b9547afdb847b80","trusted":true},"cell_type":"code","source":"# removendo as colunas que tem muitos valores faltantes\ndfTreino = dfTreino.drop(columns_to_remove, axis=1)\ndfTeste = dfTeste.drop(columns_to_remove, axis=1)\n\n# atualiza os metadados para ter como referência\nmeta_train.loc[(columns_to_remove),'keep'] = False  \nmeta_test.loc[(columns_to_remove),'keep'] = False\n\n# remove do frame de colunas com falta de dados as colunas que foram dropadas\nmissing_Train.drop(missing_Train[(np.isin(missing_Train.column_name, columns_to_remove))].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"805b5d3bb4a13fe039bc29de0630e46701623ed6","trusted":true},"cell_type":"code","source":"# Usa ou moda ou média para preencher os valores \"vazios\" que nosso dataset contem, baseado nos metadados do mesmo\ndef fillNullNumbers(dfInput, dfMetadata, dfMissing, missing_default, label):\n\n    from sklearn.impute import SimpleImputer\n\n    media_imp = SimpleImputer(missing_values=missing_default, strategy='mean')\n    moda_imp = SimpleImputer(missing_values=missing_default, strategy='most_frequent')\n\n    for index,row in dfMissing.iterrows():\n        columnName = row['column_name']\n        columnType = dfMetadata.level[(dfMetadata.index == columnName)][0]\n\n        if (columnType == 'interval'):\n            imputerToUse = media_imp\n            imputerString = 'media_imp'\n        elif (columnType == 'ordinal'):\n            imputerToUse = moda_imp\n            imputerString = 'moda_imp'\n        else:\n            imputerToUse = None\n            imputerString = None\n\n        if (imputerToUse != None):\n            dfInput[columnName] = imputerToUse.fit_transform(dfInput[[columnName]]).ravel()\n            print(f\"{label} - Preenchida coluna {columnName}, cujo tipo é {columnType}, usando o Imputer {imputerString}\")\n\n    return dfInput","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d77312312941f0919691fb1c8647870e5b24ed2","trusted":true},"cell_type":"code","source":"dfTreino = fillNullNumbers(dfTreino, meta_train, missing_Train, -1, 'Treino')\nprint('---')\ndfTeste = fillNullNumbers(dfTeste, meta_test, missing_Train, -1, 'Teste')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0921473df8a574071b09435212756f6c8fc41084"},"cell_type":"markdown","source":"Os atributos categóricos podem ser mantidos porque o número de valores faltantes não é expressivo. Inclusive, a estratégia de preenchimento dos **atributos categóricos** é sempre mais complexa. Esses atributos **não se beneficiam de medidas estatísticas** como moda e média, portanto essas medidas não servem para preenchê-los de forma sintética.\n\n---\n\n## One-hot encoding (ou dummy variables)\n\nDepois de ter tratado os dados faltantes, é importante que os dados ordinais tenham representação apropriada para o problema tratado. Se o dado não tem distância ou rankamento entre eles, cada valor de um atributo deve ser representado por um conjunto de atributos de mesma distância. *(Verificar slides desse encontro para que isso fique mais claro)*\n\nOs dados que precisam ser separados em mais dimensões já foram identificados como nominais no pré-processamento. É importante verificar se esses dados têm grande variedade de valores ou não, e aplicar essa separação apenas se for viável. Por exemplo, se um determinado atributo tem 300 valores, isso geraria 300 colunas novas. Isso só se justificaria se fosse uma base realmente grande e se houvesse uma correlação muito alta entre essa variedade de valores e a classe."},{"metadata":{"_uuid":"8d33f93e1d121e292dda2040ea2b9b183bf09942","trusted":true},"cell_type":"code","source":"def performOneHotEncoding(dfTrain, dfTest, meta_generic, dist_limit):\n    v = meta_generic[(meta_generic.level == 'nominal') & (meta_generic.keep)].index\n    display(v)\n    for f in v:\n        dist_values = dfTrain[f].value_counts().shape[0]\n        print('Atributo {} tem {} valores distintos'.format(f, dist_values))\n        if (dist_values > dist_limit):\n            print('Atributo {} tem mais de {} valores distintos e por isso será ignorado'.format(f, dist_limit))\n            dfTrain.drop([f], axis=1)\n            v = v.drop([f])\n        \n    print('Antes do one-hot encoding tinha-se {} atributos'.format(dfTrain.shape[1]))\n    dfTrain = pd.get_dummies(dfTrain, columns=v, drop_first=True)\n    print('Depois do one-hot encoding tem-se {} atributos'.format(dfTrain.shape[1]))\n\n    dfTest = pd.get_dummies(dfTest, columns=v, drop_first=True)\n    missing_cols = set( dfTrain.columns ) - set( dfTest.columns )\n    for c in missing_cols:\n        dfTest[c] = 0\n\n    dfTrain, dfTest = dfTrain.align(dfTest, axis=1)\n    \n    return dfTrain, dfTest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d6b5fafda4ec24b89a66a46d7ecdca49afbfe5b"},"cell_type":"markdown","source":"Vamos optar por manter todos atributos e, portanto, gerar o conjunto de atributos que os mantêm à mesma distância:"},{"metadata":{"_uuid":"acf4c6866c9c00d07b0855349f194a3cbd36076c","trusted":true},"cell_type":"code","source":"dfTreino, dfTeste = performOneHotEncoding(dfTreino, dfTeste, meta_train, 200)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a925c09396f626bfab0ddca2b42022244ac9bbc","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nmin_max_scaler = MinMaxScaler()\n\ndfTreino[dfTreino.columns] = min_max_scaler.fit_transform(dfTreino[dfTreino.columns])\ndfTeste[dfTeste.columns] = min_max_scaler.fit_transform(dfTeste[dfTeste.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da247c61f494d4c4f3fed0c45068b19cdbd5508c"},"cell_type":"code","source":"dfTeste.drop(['target'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5785c81b877363b0a86be4b5da3faf85c9d8c5cc"},"cell_type":"markdown","source":"## Depois de todo pré-processamento...\n\nÉ hora de verificar se tanto treino como teste têm o mesmo tamanho/formato, e aplicar um modelo de classificação já que esse é um problema desse tipo. Vale lembrar que o tamanho do treino e teste pode variar quando você estiver participando de outras competições ou explorando outros conjuntos de dados.\n\nIsso porque na maioria das competições não se tem o *target* do test. Estima-se uma resposta e submete ao Kaggle, por exemplo, para que ele verifique qual foi o resultado final. Então esse tamanho pode variar em 1 entre treino e teste. No nosso caso, como todos os dados vêm de uma mesma fonte para experimentos, é esperado que tenham a mesma quantidade de atributos ou colunas."},{"metadata":{"trusted":true,"_uuid":"3e0804251395cef399517f8b29c87a73e5704105"},"cell_type":"code","source":"# Models\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\n# Feature Selection\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, ShuffleSplit\n\n# Auxiliary Scores\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edc481aab1df0be1076a243f15ad38bbd9ba01ce","trusted":true},"cell_type":"code","source":"def showDistribution(val_classes):\n    nonUsed, used = pd.DataFrame(val_classes).groupby('target').size()\n    print('---')\n    print(f'Das {pd.DataFrame(val_classes).shape[0]} entradas no dataset, {nonUsed} foram de casos onde não foi acionado o seguro e {used} foram caso onde houve acionamento')\n    print(f'Temos assim {round((used/len(val_classes)) * 100,6)}% de ocorrencias em que o resultado (1 ou \"houve acionamento\") desejamos prever')\n    print('---')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2874f507980a038d60bcdbeb2c8e3acfbc03894a","trusted":true},"cell_type":"code","source":"def logisticRegression(X_Train, y_Train, X_Val, y_Val):\n\n    model = LogisticRegression(solver='lbfgs')\n\n    model.fit(X_Train, y_Train)\n\n    y_pred_class = model.predict(X_Val)\n    y_pred_proba = model.predict_proba(X_Val)\n\n    recall = recall_score(y_Val, y_pred_class)\n    accuracy = accuracy_score(y_Val, y_pred_class)\n    logloss = log_loss(y_Val, y_pred_proba)\n    precision =  precision_score(y_Val, y_pred_class)\n    f1 = f1_score(y_Val, y_pred_class)\n    gini = eval_gini(y_Val, y_pred_class)\n\n    print(f'Baseline - Regressão Logistica')\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n    print(f'Gini: {round(gini, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n    print('---')\n    \n    return model, 'Baseline - Regressão Logistica'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"add33086c01d42b3543fa1fa44913cebe33f9a08","trusted":true},"cell_type":"code","source":"# n_estimators=20, learning_rate = 0.5, max_features=2, max_depth = 70, random_state = 0 - Recall: 0.057621%\n\ndef xGBClassifier(X_Train, y_Train, X_Val, y_Val, modelName, modelParams):\n\n    if (modelParams == None):\n        clf = XGBClassifier()\n    else:\n        clf = XGBClassifier(**modelParams)  \n        modelName = modelName + ' - Parameters: ' + str(modelParams)\n    \n    clf.fit(X_Train, y_Train)\n\n    y_pred_class = clf.predict(X_Val)\n    y_pred_proba = clf.predict_proba(X_Val)\n\n    recall = recall_score(y_Val, y_pred_class)\n    accuracy = accuracy_score(y_Val, y_pred_class)\n    logloss = log_loss(y_Val, y_pred_proba)\n    gini = eval_gini(y_Val, y_pred_class)\n    precision =  precision_score(y_Val, y_pred_class)\n    f1 = f1_score(y_Val, y_pred_class)\n\n    print(modelName)\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n    print(f'Gini: {round(gini, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n    print('---')\n    \n    return clf, modelName","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8bea94e697d9ac6708a0502db46dcd8e0bf15f4","trusted":true},"cell_type":"code","source":"def decisionTreeClassifier(X_Train, y_Train, X_Val, y_Val):\n\n    clf = DecisionTreeClassifier()\n\n    clf.fit(X_Train, y_Train)\n\n    y_pred_class = clf.predict(X_Val)\n    y_pred_proba = clf.predict_proba(X_Val)\n\n    recall = recall_score(y_Val, y_pred_class)\n    accuracy = accuracy_score(y_Val, y_pred_class)\n    gini = eval_gini(y_Val, y_pred_class)\n    logloss = log_loss(y_Val, y_pred_proba)\n    precision =  precision_score(y_Val, y_pred_class)\n    f1 = f1_score(y_Val, y_pred_class)\n\n    print(f'Decision Tree - Default Parameters')\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n    print(f'Gini: {round(gini, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n    print('---')\n    \n    return clf, f'Decision Tree - Default Parameters'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78fd822ef4b6e374245c98ed637ed0ac248ddef3"},"cell_type":"code","source":"def gridSearchKNN(X_Train, y_Train, X_Val, y_Val, k_range):\n    clf=KNeighborsClassifier()\n    param_grid=dict(n_neighbors=k_range)\n    scores = ['f1']\n    for sc in scores:\n        grid=GridSearchCV(clf,param_grid,cv=4,scoring=sc,n_jobs=-1)\n        print(\"K-Nearest Neighbors - Tuning hyper-parameters for %s\" % sc)\n        \n        grid.fit(X_Train,y_Train)\n        \n        print(grid.best_params_)\n        print(np.round(grid.best_score_,3))\n        \n        y_pred_class = grid.predict(X_Val)\n        y_pred_proba = grid.predict_proba(X_Val)\n\n        recall = recall_score(y_Val, y_pred_class)\n        accuracy = accuracy_score(y_Val, y_pred_class)\n        gini = eval_gini(y_Val, y_pred_class)\n        logloss = log_loss(y_Val, y_pred_proba)\n        precision =  precision_score(y_Val, y_pred_class)\n        f1 = f1_score(y_Val, y_pred_class)\n\n        print(f'KNN with recall-maxing hyperparameters - {grid.best_params_}')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'Log Loss: {round(logloss, 6)}')\n        print(f'F1 Score: {round(f1, 6)}')\n        print(f'Gini: {round(gini, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n        print('---')\n        \n        return grid, f'KNN with recall-maxing hyperparameters - {grid.best_params_}'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e4c46819eefe201b29e56f47996f9bdef69c9ff"},"cell_type":"code","source":"def gridSearchSVC(X_Train, y_Train, X_Val, y_Val):\n    svc=SVC()\n    param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],'C': [1, 10, 100, 1000]},\n                  {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n    scores = ['f1']\n    for sc in scores:\n        grid=GridSearchCV(svc,param_grid,cv=4,scoring=sc,n_jobs=-1)\n        \n        print(\"Support Vector Classifier - Tuning hyper-parameters for %s\" % sc)\n        \n        grid.fit(X_Train,y_Train)\n        print(grid.best_params_)\n        print(np.round(grid.best_score_,3))\n        \n        y_pred_class = grid.predict(X_Val)\n\n        recall = recall_score(y_Val, y_pred_class)\n        accuracy = accuracy_score(y_Val, y_pred_class)\n        gini = eval_gini(y_Val, y_pred_class)\n        precision =  precision_score(y_Val, y_pred_class)\n        f1 = f1_score(y_Val, y_pred_class)\n\n        print(f'SVC with recall-maxing hyperparameters - {grid.best_params_}')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'F1 Score: {round(f1, 6)}')\n        print(f'Gini: {round(gini, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n        print('---')\n        \n        return grid, f'SVC with recall-maxing hyperparameters - {grid.best_params_}'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85d7d66d12116da708643f8f912e02c99ff01dc0"},"cell_type":"code","source":"def gridSearchXGB(X_Train, y_Train, X_Val, y_Val, score):\n    xgb=XGBClassifier(random_state = 0)\n    param_grid = [{'n_estimators': [100, 200, 300, 400], 'learning_rate': [0.1, 0.25, 0.5, 0.75],'max_depth': [25, 50, 75, 100], 'gamma': [0, 3, 6, 9]}]\n    scores = [score]\n    for sc in scores:\n        grid=GridSearchCV(xgb,param_grid,cv=2,scoring=sc,n_jobs=-1)\n        \n        print(\"XGBoost - Tuning hyper-parameters for %s\" % sc)\n        \n        grid.fit(X_Train,y_Train)\n        print(grid.best_params_)\n        print(np.round(grid.best_score_,3))\n        \n        y_pred_class = grid.predict(X_Val)\n\n        recall = recall_score(y_Val, y_pred_class)\n        accuracy = accuracy_score(y_Val, y_pred_class)\n        gini = eval_gini(y_Val, y_pred_class)\n        precision =  precision_score(y_Val, y_pred_class)\n        f1 = f1_score(y_Val, y_pred_class)\n\n        print(f'XGBoost with {sc}-maxing hyperparameters - {grid.best_params_}')\n        print('---')\n        print(f'Acurácia: {round(accuracy, 6)}%')\n        print(f'Recall: {round(recall, 6)}%')\n        print(f'Precisão: {round(precision, 6)}%')\n        print(f'F1 Score: {round(f1, 6)}')\n        print(f'Gini: {round(gini, 6)}')\n\n        print('---')\n        print('Matriz de Confusão')\n        display(pd.DataFrame(confusion_matrix(y_Val, y_pred_class)))\n        print('---')\n        \n        return grid, f'XGBoost with {sc}-maxing hyperparameters - {grid.best_params_}'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"664dad7a496fecae1568255ed928fb8ff290d502"},"cell_type":"code","source":"def predictTestDataset(X_Test, y_Test, clfModel, clfName):\n    y_pred_class = clfModel.predict(X_Test)\n    y_pred_proba = clfModel.predict_proba(X_Test)\n\n    recall = recall_score(y_Test, y_pred_class)\n    accuracy = accuracy_score(y_Test, y_pred_class)\n    gini = eval_gini(y_Test, y_pred_class)\n    logloss = log_loss(y_Test, y_pred_proba)\n    precision =  precision_score(y_Test, y_pred_class)\n    f1 = f1_score(y_Test, y_pred_class)\n\n    print(clfName)\n    print('---')\n    print(f'Acurácia: {round(accuracy, 6)}%')\n    print(f'Recall: {round(recall, 6)}%')\n    print(f'Precisão: {round(precision, 6)}%')\n    print(f'Log Loss: {round(logloss, 6)}')\n    print(f'F1 Score: {round(f1, 6)}')\n    print(f'Gini: {round(gini, 6)}')\n\n    print('---')\n    print('Matriz de Confusão')\n    display(pd.DataFrame(confusion_matrix(y_Test, y_pred_class)))\n    print('---')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bfd1cdf51867b7084ed64a59044cd9aa909384c"},"cell_type":"code","source":"def predictContestDataset(X_Test, clfModel, clfName):\n    \n    print(clfName)\n    print('---')\n    \n    y_pred_class = clfModel.predict(X_Test)\n    y_pred_proba = clfModel.predict_proba(X_Test)\n    \n    pd_prediction = pd.DataFrame(y_pred_class)\n    pd_prediction.columns = ['target']\n    showDistribution(pd_prediction)\n\n    return y_pred_class, y_pred_proba","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f22786e9d4edbeed8bbb9ac998306f68ee1ef32","trusted":true},"cell_type":"code","source":"print(dfTreino.shape)\nprint(dfTeste.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54b468a436e21ad2a6f03eeb43dcc676f8c7285f"},"cell_type":"code","source":"sample_size = 10000\ninactive_sample_size = int(sample_size * 1)\n\nactivated_indices = dfTreino[dfTreino.target == 1].index\nactivated = dfTreino.loc[np.random.choice(activated_indices, sample_size, replace=False)]\n\ninactive_indices = dfTreino[dfTreino.target == 0].index\ninactive = dfTreino.loc[np.random.choice(inactive_indices, inactive_sample_size, replace=False)]\n\nsubsampled = pd.concat([activated, inactive])\n\nsubsampled.sort_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0318036e906b1314a1ab0761fdaf21398d3ab9c8","trusted":true},"cell_type":"code","source":"X = subsampled.drop(['target'], axis=1)\ny = subsampled['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82038554148315e487fb1d566c7f1265b0636922"},"cell_type":"code","source":"X_supersampled = dfTreino.drop(X.index).drop(['target'], axis=1)\ny_supersampled = dfTreino.drop(X.index)['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a26a84b956ece5a2f9234d55200e9d9dd28e169"},"cell_type":"code","source":"print(X_supersampled.shape)\nprint(y_supersampled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2013e5e222489b8edf880ce3c6a997715a2aed"},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6407c00eb0a43aacbfcff7e2a78b9d5fc83090d8","scrolled":true},"cell_type":"code","source":"showDistribution(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c5bb69b1455a499366359945f2c9ed39adb7aad","scrolled":false},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n\nshowDistribution(y_train)\nlogRegModel, logRegName = logisticRegression(X_train, y_train, X_val, y_val)\nxgbPureModel, xgbPureName = xGBClassifier(X_train, y_train, X_val, y_val, 'XGBoost - Base',None)\n#xgbPresetModel, xgbPresetName = xGBClassifier(X_train, y_train, X_val, y_val, 'XGBoost - Preset', {'n_estimator':400, 'learning_rate' : 0.5,'random_state' : 0,'max_depth':70,'objective':\"binary:logistic\",'subsample':.8,'min_child_weig':6,'colsample_bytr':.8,'scale_pos_weight':1.6, 'gamma':10, 'reg_alph':8, 'reg_lambda':1})\nxgbHyperParametrizedModel, xgbHyperParametrizedName = xGBClassifier(X_train, y_train, X_val, y_val, 'XGBoost - Hyperparametrized',{'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 16, 'n_estimators': 100, 'subsample': 1.0})\n#decTreeModel, decTreeName = decisionTreeClassifier(X_train, y_train, X_val, y_val)\n#knnModel, knnName = gridSearchKNN(X_train, y_train, X_val, y_val, list(range(1,20)))\n#svcModel, svcName = gridSearchSVC(X_train, y_train, X_val, y_val)\n\nshowDistribution(y_supersampled)\npredictTestDataset(X_supersampled, y_supersampled, logRegModel, logRegName)\npredictTestDataset(X_supersampled, y_supersampled, xgbPureModel, xgbPureName)\n#predictTestDataset(X_supersampled, y_supersampled, xgbPresetModel, xgbPresetName)\npredictTestDataset(X_supersampled, y_supersampled, xgbHyperParametrizedModel, xgbHyperParametrizedName)\n#predictTestDataset(X_supersampled, y_supersampled, decTreeModel, decTreeName)\n#predictTestDataset(X_supersampled, y_supersampled, knnModel, knnName)\n#predictTestDataset(X_supersampled, y_supersampled, svcModel, svcName)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b13ef90490e839c8d270d0eb033b322dbc11b78"},"cell_type":"code","source":"#showDistribution(y_train)\n#xgbGridSearchModel, xgbGridSearchName = gridSearchXGB(X_train, y_train, X_val, y_val, 'f1')\n\n#showDistribution(y_supersampled)\n#predictTestDataset(X_supersampled, y_supersampled, xgbGridSearchModel, xgbGridSearchName)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f2bce379e596670b3472ee8660f4202874373d7"},"cell_type":"code","source":"contest_prediction, contest_prediction_probability = predictContestDataset(dfTeste, xgbHyperParametrizedModel, xgbHyperParametrizedName)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6cc9262f13a48a6d629f8deffef7bf891cbc293a"},"cell_type":"code","source":"sample    = pd.read_csv('../input/sample_submission.csv', low_memory=False)\nsample.target = contest_prediction_probability\nsample.target = 1 - sample.target\nsample.to_csv(\"submission.csv\", float_format='%.6f', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}