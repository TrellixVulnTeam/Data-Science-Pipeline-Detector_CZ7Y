{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 성능개선 2 : XGBoost 모델","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T11:41:02.404783Z","iopub.execute_input":"2022-06-01T11:41:02.405193Z","iopub.status.idle":"2022-06-01T11:41:02.435107Z","shell.execute_reply.started":"2022-06-01T11:41:02.405112Z","shell.execute_reply":"2022-06-01T11:41:02.434365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터 경로\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n\ntrain = pd.read_csv(data_path + 'train.csv', index_col='id')\ntest = pd.read_csv(data_path + 'test.csv', index_col='id')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:02.436324Z","iopub.execute_input":"2022-06-01T11:41:02.436884Z","iopub.status.idle":"2022-06-01T11:41:13.158241Z","shell.execute_reply.started":"2022-06-01T11:41:02.436853Z","shell.execute_reply":"2022-06-01T11:41:13.157273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 피처 엔지니어링","metadata":{}},{"cell_type":"markdown","source":"### 데이터 합치기","metadata":{"execution":{"iopub.status.busy":"2022-05-30T09:08:25.683191Z","iopub.execute_input":"2022-05-30T09:08:25.685512Z","iopub.status.idle":"2022-05-30T09:08:25.729466Z","shell.execute_reply.started":"2022-05-30T09:08:25.68543Z","shell.execute_reply":"2022-05-30T09:08:25.728614Z"}}},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1)  # 타깃값 제거\n\nall_features = all_data.columns  # 전체 피처\nall_features","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:13.15999Z","iopub.execute_input":"2022-06-01T11:41:13.160342Z","iopub.status.idle":"2022-06-01T11:41:14.51194Z","shell.execute_reply.started":"2022-06-01T11:41:13.160314Z","shell.execute_reply":"2022-06-01T11:41:14.510835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 명목형 피처 원-핫 인코딩\n\n모든 명목형 피처에 원-핫 인코딩을 적용\n\n명목형 데이터에는 고윳값별 순서가 따로 없음\n\n'cat' 이 포함된 피처가 명목형 피처임","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:14.513329Z","iopub.execute_input":"2022-06-01T11:41:14.513788Z","iopub.status.idle":"2022-06-01T11:41:15.60344Z","shell.execute_reply.started":"2022-06-01T11:41:14.513744Z","shell.execute_reply":"2022-06-01T11:41:15.60261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처 추출\ncat_features = [feature for feature in all_features if 'cat' in feature]\n\nonehot_encoder = OneHotEncoder()  # 원-핫 인코더 객체 생성\n\n# 인코딩\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])\n\nencoded_cat_matrix","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:15.605761Z","iopub.execute_input":"2022-06-01T11:41:15.606453Z","iopub.status.idle":"2022-06-01T11:41:17.87516Z","shell.execute_reply.started":"2022-06-01T11:41:15.606406Z","shell.execute_reply":"2022-06-01T11:41:17.874247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 파생 피처 추가\n\n1. 한 데이터가 가진 결측값 개수를 파생 피처로 만들자! -1 이 결측값이었으니 결측값 개수를 구하려면 -1 개수를 구하면 됨","metadata":{}},{"cell_type":"code","source":"# '데이터 하나당 결측값 개수'를 파생 피처로 추가\nall_data['num_missing'] = (all_data == -1).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:17.878234Z","iopub.execute_input":"2022-06-01T11:41:17.878579Z","iopub.status.idle":"2022-06-01T11:41:18.103177Z","shell.execute_reply.started":"2022-06-01T11:41:17.878549Z","shell.execute_reply":"2022-06-01T11:41:18.10206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 명목형 피처, calc 분류의 피처를 제외한 피처\nremaining_features = [feature for feature in all_features if ('cat' not in feature and 'calc' not in feature)]\n\n# num_missing 을 remaining_features 에 추가\nremaining_features.append('num_missing')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:18.104818Z","iopub.execute_input":"2022-06-01T11:41:18.105165Z","iopub.status.idle":"2022-06-01T11:41:18.110047Z","shell.execute_reply.started":"2022-06-01T11:41:18.105128Z","shell.execute_reply":"2022-06-01T11:41:18.109085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. ind 분류의 피처들을 살펴보자. 모든 ind 피처 값을 연결해서 새로운 피처를 만들려고 함\n    - 예를 들어, ps_ind_01, ps_ind_02_cat, ps_ind_03 의 값이 각각 2, 2, 5라면 모든 값을 연결해 2_2_5_ 로 만듦\n    - ind 피처가 총 18개이므로 18개 값이 연결된 새로운 피처를 만들고, 이 피처명을 'mix_ind' 라고 함","metadata":{}},{"cell_type":"markdown","source":"> 왜 이런 파생 피처들을 만들까?\n> 이 파생 피처들은 타깃값 예측에 어떤 도움이 되는걸까? 사실 처음부터 파생 피처가 타깃값 예측에 도움이 되는지 알기는 쉽지 않음. 사칙연산도 해보고, 통계도 내보고, 문자열 연결도 해보는 등 갖은 방법으로 피처 엔지니어링을 해볼 수 있음. 실제로 많은 상위권 캐글러도 여러 피처 엔지니어링을 시도함. 그중 성능 향상에 도움되는 피처를 선별함. 앞의 결측값 개수나 뒤에서 만들 '명목형 피처의 고윳값별 개수' 피처도 어떤 이유에서 타깃값 예측에 도움을 주는지 단번에 알기는 어려움. 이런 방법도 있음을 기억해두고 다른 문제를 풀 때 응용해보자","metadata":{}},{"cell_type":"code","source":"# 분류가 ind 인 피처\nind_features = [feature for feature in all_features if 'ind' in feature]\n\nis_first_feature = True\nfor ind_feature in ind_features:\n    if is_first_feature:\n        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n        is_first_feature = False\n    else:\n        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:18.111147Z","iopub.execute_input":"2022-06-01T11:41:18.111553Z","iopub.status.idle":"2022-06-01T11:41:39.745959Z","shell.execute_reply.started":"2022-06-01T11:41:18.111526Z","shell.execute_reply":"2022-06-01T11:41:39.744797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data['mix_ind']","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:39.747233Z","iopub.execute_input":"2022-06-01T11:41:39.747529Z","iopub.status.idle":"2022-06-01T11:41:39.754945Z","shell.execute_reply.started":"2022-06-01T11:41:39.747504Z","shell.execute_reply":"2022-06-01T11:41:39.753935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 새로 만든 mix_ind 가 들쑥날쑥하게 한 칸씩 들여 써진 것처럼 보일 겁니다. 실제로 들여 써진건 아니고 all_data['mix_ind'] 를 호출하면 값을 오른쪽 정렬하기 때문에 그렇게 보이는 것임","metadata":{}},{"cell_type":"markdown","source":"3. 명목형 피처의 고윳값별 개수를 새로운 피처로 추가\n    - 고윳값별 개수는 value_counts() 로 구함","metadata":{}},{"cell_type":"code","source":"all_data['ps_ind_02_cat'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:39.756379Z","iopub.execute_input":"2022-06-01T11:41:39.756687Z","iopub.status.idle":"2022-06-01T11:41:39.779637Z","shell.execute_reply.started":"2022-06-01T11:41:39.756644Z","shell.execute_reply":"2022-06-01T11:41:39.778989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data['ps_ind_02_cat'].value_counts().to_dict()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:39.781808Z","iopub.execute_input":"2022-06-01T11:41:39.782273Z","iopub.status.idle":"2022-06-01T11:41:39.80457Z","shell.execute_reply.started":"2022-06-01T11:41:39.78224Z","shell.execute_reply":"2022-06-01T11:41:39.803399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 명목형 피처의 고윳값별 개수를 파생 피처로 만들자. cat 분류에 속하는 피처들(cat_features)과 mix_ind 피처를 모두 명목형 피처로 간주","metadata":{}},{"cell_type":"code","source":"cat_count_features = []\nfor feature in cat_features + ['mix_ind']:\n    val_counts_dict = all_data[feature].value_counts().to_dict()\n    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: val_counts_dict[x])\n    cat_count_features.append(f'{feature}_count')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:39.806928Z","iopub.execute_input":"2022-06-01T11:41:39.807412Z","iopub.status.idle":"2022-06-01T11:41:48.328667Z","shell.execute_reply.started":"2022-06-01T11:41:39.807365Z","shell.execute_reply":"2022-06-01T11:41:48.327666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_count_features","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:48.330204Z","iopub.execute_input":"2022-06-01T11:41:48.330646Z","iopub.status.idle":"2022-06-01T11:41:48.337029Z","shell.execute_reply.started":"2022-06-01T11:41:48.330605Z","shell.execute_reply":"2022-06-01T11:41:48.33609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 필요 없는 피처 제거\n\n지금까지 만든 피처는 다음과 같음\n\n- encoded_cat_matrix: 원-핫 인코딩된 명목형 피처\n- remaining_features: 명목형 피처와 calc 분류의 피처를 제외한 피처들 (+ num_missing)\n- cat_count_features: mix_ind 를 포함한 명목형 피처의 고윳값별 개수 파생 피처\n\n제거해야 할 피처\n\n- 이진 피처 : ps_ind_10_bin ~ ps_ind_13_bin, ps_calc_15_bin ~ ps_calc_20_bin\n- 순서형 피처 : ps_ind_14, ps_calc_04 ~ ps_calc_14\n- 연속형 피처 : ps_calc_01 ~ ps_calc_03, ps_car_14","metadata":{"execution":{"iopub.status.busy":"2022-05-30T09:13:28.2941Z","iopub.execute_input":"2022-05-30T09:13:28.294549Z","iopub.status.idle":"2022-05-30T09:13:30.757733Z","shell.execute_reply.started":"2022-05-30T09:13:28.2945Z","shell.execute_reply":"2022-05-30T09:13:30.75623Z"}}},{"cell_type":"code","source":"# 추가로 제거할 피처\ndrop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n\n# remaining_features, cat_count_features 에서 drop_features 를 제거한 데이터\nall_data_remaining = all_data[remaining_features + cat_count_features].drop(drop_features, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:48.338561Z","iopub.execute_input":"2022-06-01T11:41:48.339168Z","iopub.status.idle":"2022-06-01T11:41:49.281485Z","shell.execute_reply.started":"2022-06-01T11:41:48.339125Z","shell.execute_reply":"2022-06-01T11:41:49.28075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import sparse","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:49.282561Z","iopub.execute_input":"2022-06-01T11:41:49.282926Z","iopub.status.idle":"2022-06-01T11:41:49.289555Z","shell.execute_reply.started":"2022-06-01T11:41:49.282893Z","shell.execute_reply":"2022-06-01T11:41:49.288623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터 합치기\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n                               encoded_cat_matrix],\n                              format='csr')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:49.290863Z","iopub.execute_input":"2022-06-01T11:41:49.291478Z","iopub.status.idle":"2022-06-01T11:41:53.854963Z","shell.execute_reply.started":"2022-06-01T11:41:49.29144Z","shell.execute_reply":"2022-06-01T11:41:53.853903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"지금까지 한 작업\n\n1. 명목형 피처에 원-핫 인코딩을 적용\n2. 데이터 하나당 가지고 있는 결측값 개수를 새로운 피처로 추가\n3. 모든 ind 피처 값을 연결해서 새로운 명목형 피처를 만듦(직접 사용하진 않고, 4에서 활용하기 위해 만듦)\n4. 명목형 피처의 고윳값별 개수를 새로운 피처로 추가\n5. 필요 없는 피처를 제거(drop_features 와 calc 분류의 피처들)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T09:23:08.855708Z","iopub.execute_input":"2022-05-30T09:23:08.856114Z","iopub.status.idle":"2022-05-30T09:23:08.868265Z","shell.execute_reply.started":"2022-05-30T09:23:08.856083Z","shell.execute_reply":"2022-05-30T09:23:08.866817Z"}}},{"cell_type":"markdown","source":"### 데이터 나누기","metadata":{}},{"cell_type":"code","source":"num_train = len(train)  # 훈련 데이터 개수\n\n# 훈련 데이터와 테스트 데이터 나누기\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:53.856215Z","iopub.execute_input":"2022-06-01T11:41:53.856554Z","iopub.status.idle":"2022-06-01T11:41:54.787359Z","shell.execute_reply.started":"2022-06-01T11:41:53.856526Z","shell.execute_reply":"2022-06-01T11:41:54.786455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 평가지표 계산 함수 작성\n\n### 지니계수란?\n\n원래 경제학에서 쓰는 용어로 소득 불평등 정도를 나타내는 지표임\n\n지니계수가 작을수록 소득 수준이 평등하고, 클수록 불평등함을 의미\n\n지니계수는 로렌츠 곡선을 이용해 계산하고 로렌츠 곡선을 그리려면 모든 경제인구를 소득 순서대로 나열한 후에 가로축은 인구 누적 비율, 세로축은 소득 누적 점유율로 설정\n\n인구 누적 비율과 해당 소득 누적 점유율을 연결한 선을 로렌츠 곡선이라고 함\n\n<img src=https://t1.daumcdn.net/cfile/blog/224431355845363417>\n\n지니계수는 A 영역 넓이를 삼각형 전체 넓이로 나눈 값을 의미\n\nA 영역이 좁을수록(로렌츠 곡선이 대각선과 가까워질수록) 소득 수준은 평등\n\n반대로 A 영역이 넓을수록(로렌츠 곡선이 대각선과 멀어질수록) 소득 수준은 불평등\n\n머신러닝에서 지니계수는 모델의 예측 성능을 측정하는데 쓰임\n\n예측값을 크기순으로 정렬해서 로렌츠 곡선을 구함\n\n> 지니계수 값은 (2 x ROC AUC - 1)과 같음. 그렇기 때문에 평가지표가 지니계수이면 평가지표가 ROC AUC 인 상황과 거의 비슷하긴 함\n\n### 정규화 지니계수 계산 함수\n\n정규화란 값의 범위를 0~1 사이로 조정한다는 뜻이므로, 정규화 지니계수는 값이 0에 가까울수록 성능이 나쁘고, 1에 가까울수록 성능이 좋다는 의미\n\n$$정규화 지니계수 = \\frac{예측 값에 대한 지니계수}{예측이 완벽할 떄의 지니계수}$$\n\n'예측 값에 대한 지니계수' 는 예측값과 실제값으로 구한 지니계수\n\n'예측이 완벽할 때의 지니계수' 는 실젯값과 실젯값으로 구한 지니계수를 뜻함","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:54.788715Z","iopub.execute_input":"2022-06-01T11:41:54.789091Z","iopub.status.idle":"2022-06-01T11:41:54.792491Z","shell.execute_reply.started":"2022-06-01T11:41:54.789063Z","shell.execute_reply":"2022-06-01T11:41:54.791907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_gini(y_true, y_pred):\n    # 실젯값과 예측값의 크기가 서로 같은지 확인 (값이 다르면 오류 발생)\n    assert y_true.shape == y_pred.shape\n    \n    n_samples = y_true.shape[0]  # 데이터 개수\n    L_mid = np.linspace(1 / n_samples, 1, n_samples)  # 대각선 값\n    \n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()]  # y_pred 크기순으로 y_true 값 정렬\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order)  # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred)  # 예측값에 대한 지니계수\n    \n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()]  # y_true 크기순으로 y_true 값 정렬\n    L_true = np.cumsum(true_order) / np.sum(true_order)  # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true)  # 예측이 완벽할 때 지니계수\n    \n    # 정규화된 지니계수\n    return G_pred / G_true","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:54.793726Z","iopub.execute_input":"2022-06-01T11:41:54.79419Z","iopub.status.idle":"2022-06-01T11:41:54.807071Z","shell.execute_reply.started":"2022-06-01T11:41:54.794122Z","shell.execute_reply":"2022-06-01T11:41:54.806143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 로직을 간단히만 설명해보자면 로렌츠 곡선 상단 넓이를 삼각형 넓이로 나눈 값이 지니계수임. 정규화 지니계수는 '예측값에 대한 지니계수'를 '예측이 완벽할 때의 지니계수'로 나눈 값임. 결국 로렌츠 곡선 상단 넓이를 구할 수 있으면 정규화 지니계수도 구할 수 있음","metadata":{}},{"cell_type":"code","source":"# XGBoost 용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds)  # 반환값(평가지표 이름, 평가 점수)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:54.808444Z","iopub.execute_input":"2022-06-01T11:41:54.809232Z","iopub.status.idle":"2022-06-01T11:41:54.819136Z","shell.execute_reply.started":"2022-06-01T11:41:54.809174Z","shell.execute_reply":"2022-06-01T11:41:54.818482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 하이퍼파라미터 최적화\n\n베이지안 최적화 기법을 활용해 하이퍼파라미터를 조정\n\n그리드서치보다 더 빠르고 효율적이며, 코드도 직관적이어서 사용하기도 편리함","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:54.820127Z","iopub.execute_input":"2022-06-01T11:41:54.821007Z","iopub.status.idle":"2022-06-01T11:41:55.050481Z","shell.execute_reply.started":"2022-06-01T11:41:54.820959Z","shell.execute_reply":"2022-06-01T11:41:55.049562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# 베이지안 최적화용 데이터셋\nbayes_dtrain = xgb.DMatrix(X_train, y_train)\nbayes_dvalid = xgb.DMatrix(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:55.051502Z","iopub.execute_input":"2022-06-01T11:41:55.051813Z","iopub.status.idle":"2022-06-01T11:41:55.590846Z","shell.execute_reply.started":"2022-06-01T11:41:55.051787Z","shell.execute_reply":"2022-06-01T11:41:55.589869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 하이퍼파라미터 범위 설정\n\n1. 하이퍼파라미터 범위를 점점 좁히는 방법\n    - 예컨대 0 ~ 1 범위의 하이퍼파라미터가 있다면 처음에는 범위를 0 ~ 1 전체로 잡고 베이지안 최적화를 수행\n    - 0.5 를 최적하이퍼파라미터로 찾았다면 다시 0.5 주변으로 범위를 잡음\n    - 가령 0.4 ~ 0.6 정도로 좁히는 방식을 반복하여 하이퍼파라미터 범위를 찾아줄 수 있음\n    \n2. 다른 상위권 캐글러가 설정한 하이퍼파라미터를 참고하는 방법\n    - 공유된 코드를 참고해서 하이퍼파라미터 범위를 설정\n    - 여러 차례 연습하다 보면 하이퍼파라미터에 대한 대략적인 감이 잡힘","metadata":{}},{"cell_type":"code","source":"# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {'max_depth': (4, 8),\n                'subsample': (0.6, 0.9),\n                'colsample_bytree': (0.7, 1.0),\n                'min_child_weight': (5, 7),\n                'gamma': (8, 11),\n                'reg_alpha': (7, 9),\n                'reg_lambda': (1.1, 1.5),\n                'scale_pos_weight': (1.4, 1.6),\n               }\n\n# 값이 고정된 하이퍼파라미터\nfixed_params = {'objective': 'binary:logistic',\n                'learning_rate': 0.02,\n                'random_state': 1991,\n               }","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:55.592131Z","iopub.execute_input":"2022-06-01T11:41:55.592779Z","iopub.status.idle":"2022-06-01T11:41:55.598571Z","shell.execute_reply.started":"2022-06-01T11:41:55.592745Z","shell.execute_reply":"2022-06-01T11:41:55.597922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### (베이지안 최적화용) 평가지표 계산 함수 작성\n\nLightGBM 용 eval_function() 과 유사하지만 다른점\n\n1. 하이퍼파라미터명\n2. train() 메서드 내 검증 데이터 전달 방식\n3. train() 메서드 내 maximize 파라미터\n4. predict() 메서드에 DMatrix 타입을 전달하는 점","metadata":{}},{"cell_type":"code","source":"def eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n                  reg_alpha, gamma, reg_lambda, scale_pos_weight):\n    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n    \n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {'max_depth': int(round(max_depth)),\n              'subsample': subsample,\n              'colsample_bytree': colsample_bytree,\n              'min_child_weight': min_child_weight,\n              'gamma': gamma,\n              'reg_alpha': reg_alpha,\n              'reg_lambda': reg_lambda,\n              'scale_pos_weight': scale_pos_weight,\n             }\n    \n    # 고정된 하이퍼파라미터도 추가\n    params.update(fixed_params)\n    \n    print('하이퍼파라미터:', params)\n    \n    # LightGBM 모델 훈련\n    xgb_model = xgb.train(params=params,\n                          dtrain=bayes_dtrain,\n                          num_boost_round=2000,\n                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=False,\n                         )\n    \n    best_iter = xgb_model.best_iteration  # 최적 반복 횟수\n    \n    # 검증 데이터로 예측 수행\n    preds = xgb_model.predict(bayes_dvalid,\n                              iteration_range=(0, best_iter))\n\n    # 지니계수 계산\n    gini_score = eval_gini(y_valid, preds)\n    print(f'지니계수 : {gini_score}\\n')\n    \n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:55.599452Z","iopub.execute_input":"2022-06-01T11:41:55.60006Z","iopub.status.idle":"2022-06-01T11:41:55.612967Z","shell.execute_reply.started":"2022-06-01T11:41:55.600028Z","shell.execute_reply":"2022-06-01T11:41:55.612054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 최적화 수행","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:26:03.850724Z","iopub.execute_input":"2022-05-30T11:26:03.851149Z","iopub.status.idle":"2022-05-30T11:26:04.92457Z","shell.execute_reply.started":"2022-05-30T11:26:03.851114Z","shell.execute_reply":"2022-05-30T11:26:04.923578Z"}}},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:55.616415Z","iopub.execute_input":"2022-06-01T11:41:55.616814Z","iopub.status.idle":"2022-06-01T11:41:55.651643Z","shell.execute_reply.started":"2022-06-01T11:41:55.616776Z","shell.execute_reply":"2022-06-01T11:41:55.65084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 베이지안 최적화 객체 생성\noptimizer = BayesianOptimization(f=eval_function,  # 평가지표 계산 함수\n                                 pbounds=param_bounds,  # 하이퍼파라미터 범위\n                                 random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:55.65266Z","iopub.execute_input":"2022-06-01T11:41:55.653351Z","iopub.status.idle":"2022-06-01T11:41:55.658172Z","shell.execute_reply.started":"2022-06-01T11:41:55.653321Z","shell.execute_reply":"2022-06-01T11:41:55.657311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 베이지안 최적화 수행\noptimizer.maximize(init_points=3, n_iter=6)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:41:55.659431Z","iopub.execute_input":"2022-06-01T11:41:55.660033Z","iopub.status.idle":"2022-06-01T14:08:34.891575Z","shell.execute_reply.started":"2022-06-01T11:41:55.659999Z","shell.execute_reply":"2022-06-01T14:08:34.888965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 결과 확인","metadata":{}},{"cell_type":"code","source":"# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max['params']\nmax_params","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:08:34.895473Z","iopub.execute_input":"2022-06-01T14:08:34.896102Z","iopub.status.idle":"2022-06-01T14:08:34.908661Z","shell.execute_reply.started":"2022-06-01T14:08:34.89604Z","shell.execute_reply":"2022-06-01T14:08:34.907735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"num_leaves 와 min_child_samples 는 원래 정수형 하이퍼파라미터이므로 정수형으로 변환하여 다시 저장","metadata":{}},{"cell_type":"code","source":"# 정수형 하이퍼파라미터 변환\nmax_params['max_depth'] = int(round(max_params['max_depth']))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:08:34.915602Z","iopub.execute_input":"2022-06-01T14:08:34.916306Z","iopub.status.idle":"2022-06-01T14:08:34.930069Z","shell.execute_reply.started":"2022-06-01T14:08:34.916259Z","shell.execute_reply":"2022-06-01T14:08:34.929063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 여기에 고정된 하이퍼파라미터 추가\nmax_params.update(fixed_params)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:08:34.931329Z","iopub.execute_input":"2022-06-01T14:08:34.932346Z","iopub.status.idle":"2022-06-01T14:08:34.948575Z","shell.execute_reply.started":"2022-06-01T14:08:34.932292Z","shell.execute_reply":"2022-06-01T14:08:34.94717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_params","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:08:34.949848Z","iopub.execute_input":"2022-06-01T14:08:34.95017Z","iopub.status.idle":"2022-06-01T14:08:34.964666Z","shell.execute_reply.started":"2022-06-01T14:08:34.950144Z","shell.execute_reply":"2022-06-01T14:08:34.963661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 모델 훈련 및 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:08:34.966306Z","iopub.execute_input":"2022-06-01T14:08:34.967397Z","iopub.status.idle":"2022-06-01T14:08:34.978224Z","shell.execute_reply.started":"2022-06-01T14:08:34.967352Z","shell.execute_reply":"2022-06-01T14:08:34.977359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 층화 K 폴드 교차 검증기 생성\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n\n# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0])\n# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0])\n\n# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    # 각 폴드를 구분하는 문구 출력\n    print('#' * 40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#' * 40)\n    \n    # 훈련용 데이터, 검증용 데이터 설정\n    X_train, y_train = X[train_idx], y[train_idx]  # 훈련용 데이터\n    X_valid, y_valid = X[valid_idx], y[valid_idx]  # 검증용 데이터\n    \n    # LightGBM 전용 데이터셋 생성\n    dtrain = xgb.DMatrix(X_train, y_train)  # LightGBM 전용 훈련 데이터셋\n    dvalid = xgb.DMatrix(X_valid, y_valid)  # LightGBM 전용 검증 \n    dtest = xgb.DMatrix(X_test)\n    \n    # LightGBM 전용 데이터셋 생성\n    xgb_model = xgb.train(params=max_params,  # 최적 하이퍼파라미터\n                          dtrain=dtrain,  # 훈련 데이터셋\n                          num_boost_round=2000,  # 부스팅 반복 횟수\n                          evals=[(dvalid, 'valid')],  # 성능 평가용 검증 데이터셋\n                          maximize=True,\n                          feval=gini,  # 검증용 평가지표\n                          early_stopping_rounds=200,  # 조기종료 조건\n                          verbose_eval=100,  # 100번째마다 점수 출력\n                         )\n    \n    # 모델 성능이 가장 좋을 떄의 부스팅 반복 횟수 저장\n    best_iter = xgb_model.best_iteration\n    \n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += xgb_model.predict(dtest,\n                                        iteration_range=(0, best_iter)) / folds.n_splits\n    \n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n    oof_val_preds[valid_idx] += xgb_model.predict(dvalid,\n                                                  iteration_range=(0, best_iter))\n    \n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:52:04.77679Z","iopub.execute_input":"2022-06-01T14:52:04.777163Z","iopub.status.idle":"2022-06-01T15:05:22.481535Z","shell.execute_reply.started":"2022-06-01T14:52:04.777135Z","shell.execute_reply":"2022-06-01T15:05:22.480466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:05:22.483363Z","iopub.execute_input":"2022-06-01T15:05:22.484975Z","iopub.status.idle":"2022-06-01T15:05:22.605574Z","shell.execute_reply.started":"2022-06-01T15:05:22.484938Z","shell.execute_reply":"2022-06-01T15:05:22.604364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:05:22.607465Z","iopub.execute_input":"2022-06-01T15:05:22.608366Z","iopub.status.idle":"2022-06-01T15:05:24.850258Z","shell.execute_reply.started":"2022-06-01T15:05:22.608309Z","shell.execute_reply":"2022-06-01T15:05:24.849182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}