{"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","version":"3.6.3","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"Hello everyone! In this kernel is represented 1 dimensional convolutional neural network. The idea is simple, without tuning of model's hyperparameters. The submission file is provided.","metadata":{"_cell_guid":"102ad684-34c1-4813-a0e3-71e74b7ce003","_uuid":"f3c80af0b8b741961fb9971aa18ba5f30c42654a"}},{"cell_type":"markdown","source":"Feature binarization and scaling created by our team","metadata":{"_cell_guid":"af3ff81c-15a1-40ef-bf86-e57284969503","_uuid":"54b2acb02e5f5b4b5efd15e3eab50c4f70da9f98"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nSEED = 42\nnp.random.seed(SEED)\n\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\n\n#binarization of features\nclass FeatureBinarizatorAndScaler:\n    \"\"\" This class needed for scales and factorize features\n    \"\"\"\n    NUMERICAL_FEATURES = list()\n    CATEGORICAL_FEATURES = list()\n    BIN_FEATURES = list()\n    binarizers = dict()\n    scalers = dict()\n\n    def __init__(self, numerical=list(), categorical=list(), binfeatures = list(), binarizers=dict(), scalers=dict()):\n        self.NUMERICAL_FEATURES = numerical\n        self.CATEGORICAL_FEATURES = categorical\n        self.BIN_FEATURES = binfeatures\n        self.binarizers = binarizers\n        self.scalers = scalers\n\n    def fit(self, train_set):\n        for feature in train_set.columns:\n\n            if feature.split('_')[-1] == 'cat':\n                self.CATEGORICAL_FEATURES.append(feature)\n            elif feature.split('_')[-1] != 'bin':\n                self.NUMERICAL_FEATURES.append(feature)\n            else:\n                self.BIN_FEATURES.append(feature)\n        for feature in self.NUMERICAL_FEATURES:\n            scaler = StandardScaler()\n            self.scalers[feature] = scaler.fit(np.float64(train_set[feature]).reshape((len(train_set[feature]), 1)))\n        for feature in self.CATEGORICAL_FEATURES:\n            binarizer = LabelBinarizer()\n            self.binarizers[feature] = binarizer.fit(train_set[feature])\n\n    def transform(self, data):\n        binarizedAndScaledFeatures = np.empty((0, 0))\n        for feature in self.NUMERICAL_FEATURES:\n            if feature == self.NUMERICAL_FEATURES[0]:\n                binarizedAndScaledFeatures = self.scalers[feature].transform(np.float64(data[feature]).reshape(\n                    (len(data[feature]), 1)))\n            else:\n                binarizedAndScaledFeatures = np.concatenate((\n                    binarizedAndScaledFeatures,\n                    self.scalers[feature].transform(np.float64(data[feature]).reshape((len(data[feature]),\n                                                                                       1)))), axis=1)\n        for feature in self.CATEGORICAL_FEATURES:\n\n            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures,\n                                                         self.binarizers[feature].transform(data[feature])), axis=1)\n\n        for feature in self.BIN_FEATURES:\n            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures, np.array(data[feature]).reshape((len(data[feature]),\n                                                                                       1))), axis=1)\n\n        print(binarizedAndScaledFeatures.shape )\n\n        return binarizedAndScaledFeatures","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_cell_guid":"834f3ba4-cc8b-4d39-b1ec-0bbce6c611f4","collapsed":true,"_uuid":"1ace9b30137cf105e07400e29cfaca02cb24badc"}},{"cell_type":"markdown","source":"Convolutional Neural Network implementation","metadata":{"_cell_guid":"af20eeb1-0f0a-4e5a-8a1c-b4b3db00d5b8","_uuid":"5633409604267f6b9568d0b178bf069c15c27bce"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Convolution1D, Dropout\nfrom keras.optimizers import SGD\nfrom keras.initializers import random_uniform\n\nimport pandas as pd\n\nX_train = pd.read_csv('../input/train.csv')\ny_train = X_train['target']\nX_test = pd.read_csv('../input/test.csv')\ntest_id = X_test['id']\nX_test = X_test.drop(['id'], axis=1)\nX_train = X_train.drop(['id', 'target'], axis = 1)\ny_train1 = abs(-1+y_train)\ny_train = pd.concat([y_train, y_train1], axis=1)\nbinarizerandscaler = FeatureBinarizatorAndScaler()\nbinarizerandscaler.fit(X_train)\nX_train = binarizerandscaler.transform(X_train)\nX_test = binarizerandscaler.transform(X_test)\ny_train = y_train.as_matrix()\n\n\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n\n#hyperparameters\ninput_dimension = 226\nlearning_rate = 0.0025\nmomentum = 0.85\nhidden_initializer = random_uniform(seed=SEED)\ndropout_rate = 0.2\n\n\n# create model\nmodel = Sequential()\nmodel.add(Convolution1D(nb_filter=32, filter_length=3, input_shape=X_train.shape[1:3], activation='relu'))\nmodel.add(Convolution1D(nb_filter=16, filter_length=1, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(128, input_dim=input_dimension, kernel_initializer=hidden_initializer, activation='relu'))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(64, kernel_initializer=hidden_initializer, activation='relu'))\nmodel.add(Dense(2, kernel_initializer=hidden_initializer, activation='softmax'))\n\nsgd = SGD(lr=learning_rate, momentum=momentum)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\nmodel.fit(X_train, y_train, epochs=5, batch_size=128)\npredictions = model.predict_proba(X_test)\n\nans = pd.DataFrame(predictions)\nans = ans[0]","metadata":{"collapsed":true,"_cell_guid":"cab4f87c-521d-4779-b598-42971064c240","_uuid":"74271b30c7e41968023d919803285c2fe9649472"}},{"outputs":[],"execution_count":null,"cell_type":"code","source":"# Create submission file\nsub = pd.DataFrame()\nsub['id'] = test_id\nsub['target'] = ans\nsub.to_csv('submission.csv', float_format='%.6f', index=False)\n","metadata":{"collapsed":true,"_cell_guid":"cdb1e843-5dc0-41b1-9aa2-0886bb6ebfb2","_uuid":"deb477943486f87cc6939b0895b409a3e381369b"}}]}