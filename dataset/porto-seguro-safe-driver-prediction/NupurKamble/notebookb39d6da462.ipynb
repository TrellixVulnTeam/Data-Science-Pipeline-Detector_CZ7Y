{"cells":[{"metadata":{"_cell_guid":"ae9ba5eb-27c3-4773-849d-46c990c90c10","_uuid":"d7a7a7227819a8ff57d62c621a1385bf713c0ed1","scrolled":true},"execution_count":null,"source":"import csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import StratifiedKFold \nimport matplotlib as plt\nfrom sklearn.model_selection import ShuffleSplit\ntrain =  pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint('Test and Train files loaded')\nprint(\"train shape: %s\", str(train.shape))\nprint(\"test shape: %s\", str(test.shape))","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a681fc91-f294-4926-bbd4-2223fc83948c","_uuid":"d5c320bc0e5a8439aabe9663cd111d44c66f048e","collapsed":true},"execution_count":null,"source":"target = train.target.values\ntrain = train.drop('target',axis=1)\ntrain = train.drop('id',axis=1)\ntest = test.drop('id',axis=1)\nprint('train '+str(train.shape))\nprint('test '+str(test.shape))\nprint(train.columns.values == test.columns.values)\nprint(train.columns.values)\nprint(test.columns.values)\nprint(target.shape)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"079ee380-6c7f-4116-a341-a97c23be132e","scrolled":true,"_uuid":"51415ce7737c81e21c7e9e75b422adcee9d0022c","collapsed":true},"execution_count":null,"source":"\ntrain_df = train\ntrain_df['label'] = 'train'\nscore_df = test\nscore_df['label'] = 'score'\nconcat_df = pd.concat([train_df , score_df])\nl=[]\nfor i in concat_df.values:\n    if 'cat' in i:\n        l.append(i)\nfor i in l:\n    concat_df[i] = concat_df[i].astype(object)\n\n# Create your dummies\nfeatures_df = pd.get_dummies(concat_df, columns=l)\n# Split your data\ntrain_df = features_df[features_df['label'] == 'train']\ntest_df = features_df[features_df['label'] == 'score']\nfeatures_df.shape\nprint(train_df.shape)\nprint(score_df.shape)\ntrain_df.head(3)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"44445d5a-89cb-44ef-94ba-9a78786886df","_uuid":"1523d03a680dff1739dada1e730d6d6539334333","collapsed":true},"execution_count":null,"source":"train = train_df.drop('label',axis=1)\ntest = score_df.drop('label',axis=1)\nprint(train.shape)\nprint(test.shape)\ntest.head(4)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c055f72c-a08d-4cf9-80a6-48ef5afb2829","_uuid":"4ceb160926060021924ef6a03b08e76b93007ee7","collapsed":true},"execution_count":null,"source":"#python3.5\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import StratifiedKFold \nimport matplotlib as plt\nfrom sklearn.model_selection import ShuffleSplit\ny=target\nX=train.values\ntest = test.values\nprint(X.shape)\nprint(target.shape)\n","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"aed40a09-7920-4784-9bf9-ad481968c5f0","_uuid":"335257546df68c141b1fb8237764736bb13b3d58","collapsed":true},"execution_count":null,"source":"n_folds = 4                                    \nskf = StratifiedKFold(y, n_folds, shuffle = False, random_state = 14)\nprint(test.shape)\nprint(target)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"eb7bb1c9-8bad-4543-9c8f-806576138b92","_uuid":"9a169f008c32dff0c5cd3528cc89695c9a809b6f","collapsed":true},"execution_count":null,"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n#We pass X and y as numpyarray\ndef stacking(X,y,clfs,test,clf_names):\n    '''Inputs: X:numpy array of features of training set excluding label or response or target\n               y:numpy array of labels or response or target\n               clfs: classifier list \n               test: test set without labels and only features set\n       Output:List of [blend_train:metafeatures, blend_test:meta predictions of test, y:label, test:test'''\n    \n    clf_length = (len(clfs))\n    x_rows = (X.shape[0])\n    test_rows = int(test.shape[0])\n    blend_train = np.zeros((x_rows,clf_length))#construct a 2d list containing rows=len of X and no of columns=len(classifier list) \n    blend_test = np.zeros((test_rows,clf_length),dtype = float)#construct a 2d list containing rows = len of test and no of columns = len(classifier list)\n    \n    a=clf_names\n    for i, clf in enumerate(clfs):#iterate over classifiers from list\n        blend_test_j = np.zeros((test.shape[0], len(skf)))#we take mean of all entries in each row blend_test_j and store it in blend_test\n        print('classifier: %s'%(a[i]))\n        for j, (train,cv) in enumerate(skf):\n            xtrain = X[train]\n            ytrain = y[train]\n            xtest = X[cv]\n            ytest = y[cv]\n            clf.fit(xtrain,ytrain)\n            accuracy = accuracy_score(ytest,clf.predict(xtest))\n            logloss = log_loss(ytest,clf.predict_proba(xtest))\n            blend_train[cv,i] = clf.predict_proba(xtest)[:,1]#collect meta features(predictions over cross validation indices)\n            blend_test_j[:,j] =clf.predict_proba(test)[:,1]#predict the test set and take mean every time once for loop exits.  \n            print('fold= %s and logloss is %s and accuracy is %s'%(str(j),str(logloss),str(accuracy))) \n        #print blend_test_j\n        blend_test[:,i] = blend_test_j.mean(1)#Calculate mean of each row of predictions. \n    return [blend_train,blend_test,y,test]","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"1bca6119-83b8-4cac-a2f8-488b255b14e9","_uuid":"cfac46942b4c8e2f4e149bc98f9131027a3349ac","collapsed":true},"execution_count":null,"source":"from sklearn.metrics import log_loss\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import GridSearchCV\nclfs = [RandomForestClassifier(n_estimators=500, n_jobs=-1, criterion='gini'),\n            RandomForestClassifier(n_estimators=500, n_jobs=-1, criterion='entropy'),\n            ExtraTreesClassifier(n_estimators=500, n_jobs=-1, criterion='gini'),\n            ExtraTreesClassifier(n_estimators=500, n_jobs=-1, criterion='entropy'),\n            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=300)]\nstack = stacking(X,y,clfs,test,['rf1','rf2','et1','et2','gb'])","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c878cb12-2984-4352-8132-a4160812deb5","_uuid":"045f17fb9b2a990c4a674169063af5fd8216f9d8","collapsed":true},"execution_count":null,"source":"#So, far we have blend_train,y and blend_test\n#Now, training is done on bend_train,y and predictions are made on blend_test\nblend_train = stack[0]\nprint(blend_train)\nprint('Shape of blend_train is: %s'%(str(blend_train.shape)))\n\nblend_test = stack[1]\nprint(blend_test)\nprint('Shape of blend_test is: %s'%(str(blend_test.shape)))\n\n#Now, we train on blend_train as meta features on LogisticRegression.You can use SVM too\nprint('Blending Procedure')\nclf = LogisticRegression()\nclf.fit(blend_train, y)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"81dcada6-dfec-47e8-8cfb-70938d212a26","_uuid":"4d768852274b3b899f13311f0d665c0537ea9096","collapsed":true},"execution_count":null,"source":"y_submission = clf.predict_proba(blend_test)[:,1]#save first column or column of your choice in submission\nprint(\"Linear stretch of predictions to [0,1]\")# we scale the probabilities between 0 to 1 \ny_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())#we can also use X-mean/Xdev to normalize\nprint(\"Saving Results.\")","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"376a3817-921e-4f41-8a96-7cb45b8f86fc","_uuid":"6f16009c354da00e34af4d44b482526b10a61bd4","collapsed":true},"execution_count":null,"source":"idc = pd.read_csv('test.csv')\nidc = idc.iloc[:,0].values\nidc","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5bb6a940-0f26-4da4-97ed-a4161714b9fe","_uuid":"b53db46919ccf27aa92a5ec1faeef839b2836721","collapsed":true},"execution_count":null,"source":"tmp = np.vstack([idc, y_submission]).T#transpose the horizontal to vertical\nnp.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f',\n               header='id,target', comments='')","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"7e84e987-ffc4-4b42-8941-45216515fb2d","_uuid":"d1a565896696eb541ff1efe9c5a9fd441c15f96f","collapsed":true},"execution_count":null,"source":"","cell_type":"code","outputs":[]}],"nbformat":4,"metadata":{"anaconda-cloud":{},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","file_extension":".py","name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1}