{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# 훈련 데이터, 테스트 데이터를 읽어온다\ntrn = pd.read_csv('../input/train.csv', na_values=['-1', '-1.0'])\ntst = pd.read_csv('../input/test.csv', na_values=['-1', '-1.0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터의 크기를 확인한다\nprint(trn.shape, tst.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터 첫 5줄을 확인한다\ntrn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터프레임에 대한 메타 정보를 확인한다\ntrn.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 타겟 변수의 고유값과 타겟==1의 비율을 계산한다\nnp.unique(trn['target'])\n1.0 * sum(trn['target']/trn.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 그 외 기초 통계 기법\n\n# 변수의 최대값, 최소값 등을 확인한다\ntrn.describe()\n\n# 변수의 결측값을 확인한다\ntrn.isnull().sum(axis=0)\ntst.isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 훈련 데이터와 테스트 데이터를 통합한다\ntst['target'] = np.nan\ndf = pd.concat([trn, tst], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 시각화 관련 라이브러리를 불러온다\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 시각화 관련 함수를 미리 정의한다\ndef bar_plot(col, data, hue=None):\n    f, ax = plt.subplots(figsize=(10, 5))\n    sns.countplot(x=col, hue=hue, data=data, alpha=0.5)\n    plt.show()\n    \ndef dist_plot(col, data):\n    f, ax = plt.subplots(figsize=(10, 5))\n    sns.distplot(data[col].dropna(), kde=False, bins=10)\n    plt.show()\n    \ndef bar_plot_ci(col, data):\n    f, ax = plt.subplots(figsize=(10, 5))\n    sns.barplot(x=col, y='target', data=data)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 분석의 편의를 위해 변수 유형별로 구분한다\n# 이진 변수\nbinary = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n          'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_calc_15_bin', \n          'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n# 범주형 변수\ncategory = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', \n            'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', \n            'ps_car_10_cat', 'ps_car_11_cat']\n# 정수형 변수\ninteger = ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06', \n           'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', \n           'ps_calc_14', 'ps_car_11']\n# 소수형 변수\nfloats = ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_car_12', 'ps_car_13',\n          'ps_car_14', 'ps_car_15']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#이진 변수, 범주형 변수 그리고 정수형 변수를 시각화 한다.\nfor col in binary + category + integer:\n    bar_plot(col, df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 소수형 변수를 시각화 한다.\nfor col in floats:\n    dist_plot(col, df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 전체 데이터에 대한 상관관계 HeatMap 시각화\ncorr = df.corr()\ncmap = sns.color_palette(\"Blues\")\nf, ax = plt.subplots(figsize=(10, 7))\nsns.heatmap(corr, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 일부 변수만 선별\nfeatures = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', \n          'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin',\n          'ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', \n          'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', \n          'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_car_11',\n          'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_12', 'ps_car_13',\n          'ps_car_14', 'ps_car_15']\n\ncorr_sub = df[features].corr()\nf, ax = plt.subplots(figsize=(10, 7))\nsns.heatmap(corr_sub, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in (binary + category + integer):\n    bar_plot_ci(col, df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['is_tst'] = df['target'].isnull()\nfor col in binary + category + integer:\n    bar_plot(col, df, 'is_tst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 훈련/테스트 데이터를 읽어온다\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain_label = train['target']\ntrain_id = train['id']\ndel train['target'], train['id']\n\ntest = pd.read_csv(\"../input/test.csv\")\ntest_id = test['id']\ndel test['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 파생 변수 01 : 결측값을 의미하는 “-1”의 개수를 센다\ntrain['missing'] = (train==-1).sum(axis=1).astype(float)\ntest['missing'] = (test==-1).sum(axis=1).astype(float)\n\n# 파생 변수 02 : 이진 변수의 합\nbin_features = [c for c in train.columns if 'bin' in c]\ntrain['bin_sum'] = train[bin_features].sum(axis=1)\ntest['bin_sum'] = test[bin_features].sum(axis=1)\n\n# 파생 변수 03 : 단일변수 타겟 비율 분석으로 선정한 변수를 기반으로 Target Encoding을 수행한다. Target Encoding은 교차 검증 과정에서 진행한다.\nfeatures = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_15', 'ps_car_11']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 모델 학습에 필요한 라이브러리\nimport lightgbm as lgbm\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM 모델의 설정값이다.\nnum_boost_round = 10000\nparams = {\"objective\": \"binary\",\n          \"boosting_type\": \"gbdt\",\n          \"learning_rate\": 0.1,\n          \"num_leaves\": 15,\n          \"max_bin\": 256,\n          \"feature_fraction\": 0.6,\n          \"verbosity\": 0,\n          \"drop_rate\": 0.1,\n          \"is_unbalance\": False,\n          \"max_drop\": 50,\n          \"min_child_samples\": 10,\n          \"min_child_weight\": 150,\n          \"min_split_gain\": 0,\n          \"subsample\": 0.9,\n          \"seed\": 2018\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Gini(y_true, y_pred):\n    # 정답과 예측값의 개수가 동일한지 확인한다\n    assert y_true.shape == y_pred.shape\n    n_samples = y_true.shape[0]\n\n    # 예측값(y_pred)를 오름차순으로 정렬한다\n    arr = np.array([y_true, y_pred]).transpose()\n    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n\n    # Lorenz curves를 계산한다\n    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n\n    # Gini 계수를 계산한다\n    G_true = np.sum(L_ones - L_true)\n    G_pred = np.sum(L_ones - L_pred)\n\n    # Gini 계수를 정규화한다\n    return G_pred * 1. / G_true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM 모델 학습 과정에서 평가 함수로 사용한다\ndef evalerror(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', Gini(labels, preds), True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stratified 5-Fold 내부 교차 검증을 준비한다\nNFOLDS = 5\nkfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\nkf = kfold.split(train, train_label)\n\ncv_train = np.zeros(len(train_label))\ncv_pred = np.zeros(len(test_id))    \nbest_trees = []\nfold_scores = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, (train_fold, validate) in enumerate(kf):\n    # 훈련/검증 데이터를 분리한다\n    X_train, X_validate, label_train, label_validate = train.iloc[train_fold, :], train.iloc[validate, :], train_label[train_fold], train_label[validate]\n    \n    # target encoding 피쳐 엔지니어링을 수행한다\n    for feature in features:\n        # 훈련 데이터에서 feature 고유값별 타겟 변수의 평균을 구한다\n        map_dic = pd.DataFrame([X_train[feature], label_train]).T.groupby(feature).agg('mean')\n        map_dic = map_dic.to_dict()['target']\n        # 훈련/검증/테스트 데이터에 평균값을 매핑한다\n        X_train[feature + '_target_enc'] = X_train[feature].apply(lambda x: map_dic.get(x, 0))\n        X_validate[feature + '_target_enc'] = X_validate[feature].apply(lambda x: map_dic.get(x, 0))\n        test[feature + '_target_enc'] = test[feature].apply(lambda x: map_dic.get(x, 0))\n\n    dtrain = lgbm.Dataset(X_train, label_train)\n    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n    # 훈련 데이터를 학습하고, evalerror() 함수를 통해 검증 데이터에 대한 정규화 Gini 계수 점수를 기준으로 최적의 트리 개수를 찾는다.\n    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100, early_stopping_rounds=100)\n    best_trees.append(bst.best_iteration)\n    # 테스트 데이터에 대한 예측값을 cv_pred에 더한다.\n    cv_pred += bst.predict(test, num_iteration=bst.best_iteration)\n    cv_train[validate] += bst.predict(X_validate)\n\n    # 검증 데이터에 대한 평가 점수를 출력한다.\n    score = Gini(label_validate, cv_train[validate])\n    print(score)\n    fold_scores.append(score)\n\ncv_pred /= NFOLDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 시드값별로 교차 검증 점수를 출력한다.\nprint(\"cv score:\")\nprint(Gini(train_label, cv_train))\nprint(fold_scores)\nprint(best_trees, np.mean(best_trees))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 테스트 데이터에 대한 결과물을 저장한다.\npd.DataFrame({'id': test_id, 'target': cv_pred}).to_csv('../lgbm_baseline.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}