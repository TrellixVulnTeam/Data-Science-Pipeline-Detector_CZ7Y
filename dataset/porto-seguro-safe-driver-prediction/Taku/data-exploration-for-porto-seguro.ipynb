{"cells":[{"metadata":{"collapsed":true,"_uuid":"9277cb3b94da3735557839787d050199f295692f"},"cell_type":"markdown","source":"# **Porto Seguro's Safe Driver Prediction**\n\nHello, this kernel will do some data exploration on the Porto Seguro Safe Driver Prediction dataset. Any helpful feedback would be appreciated :)"},{"metadata":{"_uuid":"45240e9f36a15b556943916583447d28baf74a13"},"cell_type":"markdown","source":"Let's start by loading in some useful packages..."},{"metadata":{"trusted":true,"_uuid":"7f95d83a3a8bca8152c414a1dcc5b3ea0e93a5ee"},"cell_type":"code","source":"####Loading useful packages\n\n#For data manipulation\nimport numpy as np\nimport pandas as pd\n\n#For plotting\nimport matplotlib.pyplot as pp\nimport seaborn as sns\n\n#This just ensures that our plots appear\n%matplotlib inline                   \n\n\n#For surpressing warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"829d97dd796558bfb75aa1b8e6c9843b57c4a790"},"cell_type":"markdown","source":"Next, let's load in the data and take at the training data..."},{"metadata":{"trusted":true,"_uuid":"ac41b9b3d6bd6b67da5dd79d5ea8ede3d1be5db2"},"cell_type":"code","source":"#loading in the data\ntrain_data = pd.read_csv(\"../input/test23/train.csv\")\ntest_data = pd.read_csv(\"../input/test22/test.csv\")\n\n#Let's take a look at our training data\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"882265f8ef59cc50afbc1b4ca1c563929c722557"},"cell_type":"code","source":"#Let's take a look at our testing data\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa0d79843976c2a7b937cfa7fe20b3dfde848262"},"cell_type":"code","source":"#What's the shape of the data like ?\nprint(\"Training data dimenstions: \",train_data.shape)\nprint(\"Testing data dimenstions: \",test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e4841ed9acdda1d6ab6eba7eea4f942c26901e8"},"cell_type":"markdown","source":"As we'd expect, the training data has one more column than the testing data. Let's take a look at one of the observations...."},{"metadata":{"trusted":true,"_uuid":"f2d0de39fa023cccee597734a9ab968a8b50bfd0"},"cell_type":"code","source":"#Having a closer look at one of the customers.....\ntrain_data.iloc[1,]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f86a570d7045c98bfce05dbbc20b979d3abeb680"},"cell_type":"markdown","source":"Great,nothing seems out of place there! Let's view how our target variable, whether a driver claims or not, is distributed...."},{"metadata":{"trusted":true,"_uuid":"dd843160fdce932ea52addb17cb0ce9bb0dbce08"},"cell_type":"code","source":"#Let's look at the distribution of the target variable\npp.hist(train_data.loc[:,'target'])\npp.xlabel(\"target\")\npp.ylabel(\"frequency\")\npp.title(\"Distribution of target variable\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"431c32dd796d84e17ef0a1b0980347129e82fd2e"},"cell_type":"markdown","source":"Look's like we have an imbalanced class problem, we'll deal with that later. Let's examine the data types of our training data...\n"},{"metadata":{"trusted":false,"_uuid":"bf576da600dc92f5377e0b04aba2c5a9c3ee8ec1"},"cell_type":"code","source":"#Let's check the data type of each of the variables\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1316be9dec4d27ffcba54d515872e73fcac9dee"},"cell_type":"markdown","source":"All of our variables are numerical, fantastic! This means no encoding is needed. Let's put our variables into the groups that are specified:categorical, binary, interval and ordinal variables..."},{"metadata":{"trusted":true,"_uuid":"ca40832e833934965892d589706c12f897351e5f"},"cell_type":"code","source":"#Making's lists on variables which belong to each group\n\ncategorical_variables = [train_data.columns[i] for i in range(len(train_data.columns)) if 'cat' in train_data.columns[i]]\n\nbinary_variables = [train_data.columns[i] for i in range(len(train_data.columns)) if 'bin' in train_data.columns[i]]\n\ninterval_variables = [train_data.columns[i] for i in range(len(train_data.columns)) if (train_data.loc[:,train_data.columns[i]].dtype==float and 'cat' not in train_data.columns[i] and 'bin' not in train_data.columns[i])]\n\nordinal_variables = [train_data.columns[i] for i in range(len(train_data.columns)) if (train_data.loc[:,train_data.columns[i]].dtype == 'int64' and 'cat' not in train_data.columns[i] and 'bin' not in train_data.columns[i])][2:]\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"845e2cc6c6c3879323c13a4155f82a3c474caeec"},"cell_type":"markdown","source":"Before we proceed to examine each category of variables, let's check if we have any missing values...."},{"metadata":{"trusted":true,"_uuid":"b63c97d01600617963d9a5d5cee70af3f1cd5e97"},"cell_type":"code","source":"pd.Series(train_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"721e768d4fcefab374711cb8d63aeb5b81b4bf0a"},"cell_type":"markdown","source":"Hmmm, this looks suspicious. Let's try visualize this and see if we get the same outcome..."},{"metadata":{"trusted":true,"_uuid":"98d9146f7b593c21fd172603654d0db8a71418d2"},"cell_type":"code","source":"#Categorical Variables\nfor i in categorical_variables:\n    train_data.loc[:,i].value_counts(dropna=False).plot.bar()\n    pp.xlabel(i)\n    pp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac2e6e157f2fd207374e4c4e4c6b80303fb3b4b4"},"cell_type":"code","source":"#Binary variables\nfor i in binary_variables:\n    train_data.loc[:,i].value_counts(dropna=False).plot.bar()\n    pp.xlabel(i)\n    pp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62149f3856519d034580a85ac43e19116b7ac8c8"},"cell_type":"code","source":"#Interval variables\nfor i in interval_variables:\n    train_data.loc[:,i].value_counts(dropna=False).plot.hist()\n    pp.xlabel(i)\n    pp.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da7ef474f5fddb5f21f51e9a8652809f5f5369a7"},"cell_type":"code","source":"#Ordinal variables\nfor i in ordinal_variables:\n    train_data.loc[:,i].value_counts(dropna=False).plot.bar()\n    pp.xlabel(i)\n    pp.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad3cbee57a8f37dae0f71aa3c32561bd47766f29"},"cell_type":"markdown","source":"Okay, that confirms that there are no missing values. Let's now look at the summary statistics for each group of variables...\n"},{"metadata":{"trusted":true,"_uuid":"72a259d143c1e5fbec1e01425978ca34af629ce1"},"cell_type":"code","source":"#Categorical variables\ntrain_data.loc[:,categorical_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7a8202dc325d25c4801867549be20059ff046ae"},"cell_type":"code","source":"#Binary Variables\ntrain_data.loc[:,binary_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"259153981ba844f6cb1ffe82becb0444303bcc3e"},"cell_type":"code","source":"#Interval variables\ntrain_data.loc[:,interval_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69465086c3b16855b1db924b2ae9def148f64059"},"cell_type":"code","source":"#Ordinal variables\ntrain_data.loc[:,ordinal_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f92efb721415862f5cc9cb8d8a1915e12329300"},"cell_type":"markdown","source":"Now, let's look at the testing data"},{"metadata":{"trusted":true,"_uuid":"3ba9b2cbd6a875429ced59b2bcd161bf7efb57d8"},"cell_type":"code","source":"#Categorial Variables\ntest_data.loc[:,categorical_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a62df85457adc536e9bf0eb88bf95af9d9334b34"},"cell_type":"code","source":"#Binary variables\ntest_data.loc[:,binary_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3ea73997505cf9ab2938fca19064f0327977e36"},"cell_type":"code","source":"#Interval variables\ntest_data.loc[:,interval_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32e8b721eb8c4a04cff1fbab94699a37d627301f"},"cell_type":"code","source":"#Ordinal Variables\ntest_data.loc[:,ordinal_variables].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04c7d1b5ab25a6bfec9c35667d2ec866ee820af6"},"cell_type":"markdown","source":"Everything seems okay. Let's dive deeper into interval and continous variables using box and whisker plots..."},{"metadata":{"trusted":true,"_uuid":"af3daff38aa5e0f9ea4804ebe973994f7c5f9e95"},"cell_type":"code","source":"#Interval Variables\nfor i in interval_variables:\n    sns.boxplot(train_data.loc[:,i],showfliers=True)\n    pp.xlabel(i)\n    pp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0c8b78703c3d54625c0c491c76f42c254a2eb2"},"cell_type":"code","source":"#Ordinal variables\nfor i in ordinal_variables:\n    sns.boxplot(train_data.loc[:,i],showfliers=True)\n    pp.xlabel(i)\n    pp.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91c0b78435f09e35f5589dcea46fdbd00846ba12"},"cell_type":"markdown","source":"There seems to be quite a few variables with outliers! Let's examine these outliers a little bit closer....."},{"metadata":{"_uuid":"4b40d6c9bb49c27dfb6ec66167469c301f81deec"},"cell_type":"markdown","source":"First, we are going find the interquartile-range(IQR)......"},{"metadata":{"trusted":true,"_uuid":"cd6a9de502e825031bcf37f438c1e095b1427223"},"cell_type":"code","source":"#Finding the interquartile range\nQ1 = train_data.quantile(0.25)\nQ3 = train_data.quantile(0.75)\nIQR = Q3 - Q1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bf70fc018b4c640f81988cdc94b44fb52726f9a"},"cell_type":"markdown","source":"Next, let's make two list of interval and ordinal variables that had a significant number of outliers, based on the graphs."},{"metadata":{"trusted":true,"_uuid":"46405d9228ad69b0dde43019cb5282e8eaa8e56a"},"cell_type":"code","source":"int_var = ['ps_reg_02','ps_reg_03','ps_car_12','ps_car_13','ps_car_14','ps_car_15']\nod_var = ['ps_ind_14','ps_calc_04','ps_calc_06','ps_calc_07','ps_calc_08','ps_calc_10','ps_calc_11','ps_calc_12','ps_calc_13','ps_calc_14']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"114b78fe381459c49c066e80cd055b95bad636f0"},"cell_type":"markdown","source":"Next,let's separate the outlier data from the non-outlier data"},{"metadata":{"trusted":true,"_uuid":"a157d8e7a5e1bfb6f1e434b3a04de08dbeddbf02"},"cell_type":"code","source":"#Separating the outliers from the non-outliers\noutliers = train_data[(train_data > (Q3 + 1.5 * IQR))|(train_data < (Q1 - 1.5 * IQR))].drop(labels='target',axis=1)\noutliers['target'] = train_data['target']\nnon_outliers = train_data[(train_data <= (Q3 + 1.5 * IQR))&(train_data >= (Q1 - 1.5 * IQR))].drop(labels='target',axis=1)\nnon_outliers['target'] = train_data['target']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb2950e23c448d87cce6498470bf92a6a600ec8b"},"cell_type":"code","source":"#for ordinal variables\nfor i in od_var:\n    print(\"{} outliers have \".format(i),outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[1,0]/outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"ones\")\n    print(\"{} outliers have \".format(i),outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[0,0]/outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"zeroes\")\n    print(\"{} non-outliers have \".format(i),non_outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[1,0]/non_outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"ones\")\n    print(\"{} non-outliers have \".format(i),non_outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[0,0]/non_outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"zeroes\")\n    print(\"\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad8c8c034bbc574f2f22637763b320a3b2cb4be0"},"cell_type":"code","source":"#For interval variables\nfor i in int_var:\n    print(\"{} outliers have \".format(i),outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[1,0]/outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"ones\")\n    print(\"{} outliers have \".format(i),outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[0,0]/outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"zeroes\")\n    print(\"{} non-outliers have \".format(i),non_outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[1,0]/non_outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"ones\")\n    print(\"{} non-outliers have \".format(i),non_outliers[['target',i]].dropna(axis=0).groupby('target').count().iloc[0,0]/non_outliers[['target',i]].dropna(axis=0).groupby('target').count().sum(axis=0)[0],\"zeroes\")\n    print(\"\")\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43a3df0c37174d1c7913b727d6f9a1933a3138f0"},"cell_type":"markdown","source":"Great! The outliers seem not to have any effect on claming. Let's examine the correlations next...."},{"metadata":{"trusted":true,"_uuid":"8273b2b75d1cc23e41a9cb480a5bb61848e13cc9"},"cell_type":"code","source":"#Let's look at the correlation of the features with the response\ntarget_correlations = train_data.corr().iloc[:,1]\ntarget_correlations = target_correlations.iloc[2:]\ntarget_correlations.abs().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91434aab50e7e9d417050ea99a8d3892fc5b64c2"},"cell_type":"markdown","source":"Let's check for collinearity....."},{"metadata":{"trusted":true,"_uuid":"60c6e7dc3fcf63209f37e9c1333769d372459b03"},"cell_type":"code","source":"#Checking for collinearity\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor  \n\nvif_train_data = train_data.drop(['target','id'],axis = 1)\ncolnames = train_data.columns.drop(['target','id'])\nvif_table = pd.DataFrame()\n\nfor i in colnames:\n    a = vif_train_data.columns.get_loc(i)\n    vif = variance_inflation_factor(np.array(vif_train_data),exog_idx=a)\n    vif_table.loc[0,i] = vif","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e50d3d846c513cb6930dced0dd3bd31359f086fa"},"cell_type":"markdown","source":"Let's check for factors with a VIF > 5 ...."},{"metadata":{"trusted":true,"_uuid":"c47629baa62260407364e8c8d62a0653dc2dbe71"},"cell_type":"code","source":"vif_table.loc[:,vif_table.loc[0,:] > 5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d80300fef268800fff50f8a034c1c0b8042fe55d"},"cell_type":"code","source":"target_correlations.abs().sort_values(ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f58a2772c8605a2b8f1ac6b21274402a95fcca13"},"cell_type":"markdown","source":"Ahhh, our top variable,ps_car_13, has a VIF over 5. Although I want to drop variables which show high collinearity, but because ps_car_13 has the strongest relationship  with target and also because it's only marginally over 5,  I am going to keep ps_car_13 in my top 5 variables and use those 5 variables going forward'"},{"metadata":{"_uuid":"45e68a52c2c4770827dabe6ea69865faae9fccb3"},"cell_type":"markdown","source":"Let's extract the data for the top 5 features....."},{"metadata":{"trusted":true,"_uuid":"5a256f0d46e7737cabc89503e4c77289a63230be"},"cell_type":"code","source":"#Let's put the top 5 \nft_top5 = train_data.loc[:,['target','ps_car_13','ps_car_12','ps_ind_17_bin','ps_car_07_cat','ps_reg_02']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f122438d6e56448cf727efd1487b0ebca561e46f"},"cell_type":"markdown","source":"Let's examine the relationship between the top 5 features and the target variable"},{"metadata":{"trusted":true,"_uuid":"9edb15cc8551f1a4036f046667c5cfb568a29d96"},"cell_type":"code","source":"#Let's examine the relationship between target and our top variables\nfor i in range(5):\n#Kernal density plot of claims that did happen\n    sns.kdeplot(train_data.loc[train_data.loc[:,'target'] == 0,target_correlations.abs().sort_values(ascending=False).index[i]], label = 'target ==0')\n    sns.kdeplot(train_data.loc[train_data.loc[:,'target'] == 1,target_correlations.abs().sort_values(ascending=False).index[i]], label = 'target ==1')\n    pp.xlabel('ps_car_13'); pp.ylabel('Density');pp.title('Distribution of {}'.format(target_correlations.abs().sort_values(ascending=False).index[i]))\n    pp.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b3fa19c07e3c7899474925ace3c75f6bd61e2e6"},"cell_type":"markdown","source":"There doesn't seem to any significant differences in density for when target= 0 and for when target=1."},{"metadata":{"_uuid":"ad4ac1c2004070f297a2e90540e4daff695e521a"},"cell_type":"markdown","source":"Let's try making new features using the top 5 features , polynomial method up to degree three and check  if the correlation improves...."},{"metadata":{"trusted":true,"_uuid":"df8361901c9c1b84311954cd0e386267fe3bb763"},"cell_type":"code","source":"#Make a new dataframe for polynomial feature\npoly_features = ft_top5\npoly_features = poly_features.loc[:,['ps_car_13','ps_car_12','ps_ind_17_bin','ps_car_07_cat','ps_reg_02']]\npoly_features_test = ft_top5.loc[:,['ps_car_13','ps_car_12','ps_ind_17_bin','ps_car_07_cat','ps_reg_02']]\n\nfrom sklearn.preprocessing import PolynomialFeatures\n#train the features\npoly_transformer = PolynomialFeatures(degree =3)\npoly_transformer.fit(poly_features)\n\n#Transform the features\npoly_features = poly_transformer.transform(poly_features)\npoly_features_test = poly_transformer.transform(poly_features_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a78ffd9087871f57401211b9c3f089d107a5793b"},"cell_type":"code","source":"poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(input_features=['ps_car_13','ps_car_12','ps_ind_17_bin','ps_car_07_cat','ps_reg_02']))\npoly_features['target'] = train_data.loc[:,'target']\npoly_corrs = poly_features.corr()['target'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9cf12d9f8d08e622e18310eb0cd2182e92aec7a"},"cell_type":"code","source":"poly_corrs.abs().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ff28b2f9a6fbe605fd635157bc5a1b193c8b392"},"cell_type":"markdown","source":"There doesn't seem to be any different combinations of variables different from our top 5 that seem to have a stronger correlation."},{"metadata":{"_uuid":"a3672b4fa9aa864407cf82bc5f6dfe908f812633"},"cell_type":"markdown","source":"I will dive into feature engineering in a future kernel :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}