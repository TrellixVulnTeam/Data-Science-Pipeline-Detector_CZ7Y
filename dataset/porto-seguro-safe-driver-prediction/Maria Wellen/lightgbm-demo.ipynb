{"cells":[{"metadata":{},"cell_type":"markdown","source":"> Inspired by this blog post https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629#latest-583153, We tried to recreate https://www.kaggle.com/mjahrer solution using LightGBM."},{"metadata":{},"cell_type":"markdown","source":"Here we import the necessary libraries for the analysis: numpy, pandas,sklearn and lightgbm. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import metrics\n\n#Light GBM\nimport lightgbm as lgb\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this step we read the training and testing databases using pandas."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the competition data description, missing data is represented by -1. We replaced -1 by numpy missing data code in both the train and testing datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace -1 for missing\n\nfor col in train.columns: \n    train.loc[train[col] == -1, col] = np.nan \n\nfor col in test.columns: \n    test.loc[test[col] == -1, col] = np.nan     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We set the parameters for the LightGBM algorithm, according with the discussion post. We set the seed to 42 to make the results reproducible."},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 42\n\nparam = {'num_leaves': 31,\n        'boosting_type': 'gbdt',\n        'learning_rate': 0.01,\n        'max_bin': 255,\n        'min_data_in_leaf': 1500,\n        'feature_fraction': 0.7,\n        'bagging_freq': 1,\n        'bagging_fraction': 0.7,\n        'lambda_l1': 1, \n        'lambda_l2': 1, \n        'save_binary': True,\n        'seed': seed,\n        'feature_fraction_seed': seed,\n        'bagging_seed': seed,\n        'drop_seed': seed,\n        'data_random_seed': seed,\n        'objective': 'binary',  \n        'verbose': 1,\n        'metric': 'binary_logloss',\n        'is_unbalance': False, \n        'boost_from_average': True\n    }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the code below we do one hot encoding of the categorical variables in both the train and test databases."},{"metadata":{"trusted":true},"cell_type":"code","source":"#one-hot encoding of categorical variables\n\ncat_names = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat',\n             'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat',\n             'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', \n             'ps_car_10_cat', 'ps_car_11_cat']\n\ntrain = pd.get_dummies(train, columns = cat_names)\ntest = pd.get_dummies(test, columns = cat_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the code below we remove the calculated features, according to the discussion posts and to reduce the computational complexity of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove calc featutes\ncalc_names = ['ps_calc_01',    'ps_calc_02',    'ps_calc_03',    'ps_calc_04',\n              'ps_calc_05',    'ps_calc_06',    'ps_calc_07',   'ps_calc_08',\n              'ps_calc_09',    'ps_calc_10',    'ps_calc_11',    'ps_calc_12',\n              'ps_calc_13',    'ps_calc_14',    'ps_calc_15_bin','ps_calc_16_bin',\n              'ps_calc_17_bin','ps_calc_18_bin','ps_calc_19_bin',\n              'ps_calc_20_bin']\n\ntrain.drop(columns = calc_names, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create a list of predictors using the colums of the train database, we remove 'id' and 'target' from this list."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors = list(train.columns)\npredictors.remove('id')\npredictors.remove('target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we create a 5-fold cross-validation split of the dataset, and create vectors oof, and predictions, to store the results of each validation set, and the predictions of the test set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"nfold = 5\ntarget = 'target'\nskf = KFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here for each of the 5-folds, we train a LightGBM model, save the oof predictions of each set and accumulate the predictions of the test set. The test set has 5 predictions that get averaged."},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 1\nfor train_index, valid_index in skf.split(train, train.target.values):\n    print(\"\\nfold {}\".format(i))\n    \n    #Train data\n    t=train.iloc[train_index]\n        \n    xg_train = lgb.Dataset(t[predictors].values,\n                           label=t[target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    \n    xg_valid = lgb.Dataset(train.iloc[valid_index][predictors].values,\n                           label=train.iloc[valid_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    num_rounds = 1400\n    clf = lgb.train(param, xg_train, num_rounds, valid_sets = [xg_train, xg_valid], \n                    verbose_eval=2000, early_stopping_rounds = 1000) \n    oof[valid_index] = clf.predict(train.iloc[valid_index][predictors].values, num_iteration=clf.best_iteration) \n    \n    predictions += clf.predict(test[predictors], num_iteration=clf.best_iteration) / nfold\n    i = i + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we print the cross-valdiated results of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"\\n\\nCV AUC: {:<0.5f}\".format(metrics.roc_auc_score(train.target.values, oof)))\nprint(\"\\n\\nCV log loss: {:<0.5f}\".format(metrics.log_loss(train.target.values, oof)))\nprint(\"\\n\\nCV Gini: {:<0.5f}\".format(2 * metrics.roc_auc_score(train.target.values, oof) -1))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we create the submission file."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/sample_submission.csv')\nsub_df[\"target\"] = predictions\nsub_df[:10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"lightgbm.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we submit the results to the competition, we get scores consistent with the results reported by https://www.kaggle.com/mjahrer"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}