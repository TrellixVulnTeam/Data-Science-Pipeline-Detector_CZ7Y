{"nbformat":4,"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","version":"3.6.3","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":1,"cells":[{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"b861f05d-c424-4744-9210-e8f9da819067","_uuid":"814e05b9899965c78f26deec949eadfa542011fc"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nSEED = 42\nnp.random.seed(SEED)\n\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\n\n\n#binarization of features\nclass FeatureBinarizatorAndScaler:\n    \"\"\" This class needed for scales and factorize features\n    \"\"\"\n    NUMERICAL_FEATURES = list()\n    CATEGORICAL_FEATURES = list()\n    BIN_FEATURES = list()\n    binarizers = dict()\n    scalers = dict()\n\n    def __init__(self, numerical=list(), categorical=list(), binfeatures = list(), binarizers=dict(), scalers=dict()):\n        self.NUMERICAL_FEATURES = numerical\n        self.CATEGORICAL_FEATURES = categorical\n        self.BIN_FEATURES = binfeatures\n        self.binarizers = binarizers\n        self.scalers = scalers\n\n    def fit(self, train_set):\n        for feature in train_set.columns:\n\n            if feature.split('_')[-1] == 'cat':\n                self.CATEGORICAL_FEATURES.append(feature)\n            elif feature.split('_')[-1] != 'bin':\n                self.NUMERICAL_FEATURES.append(feature)\n            else:\n                self.BIN_FEATURES.append(feature)\n        for feature in self.NUMERICAL_FEATURES:\n            scaler = StandardScaler()\n            self.scalers[feature] = scaler.fit(np.float64(train_set[feature]).reshape((len(train_set[feature]), 1)))\n        for feature in self.CATEGORICAL_FEATURES:\n            binarizer = LabelBinarizer()\n            self.binarizers[feature] = binarizer.fit(train_set[feature])\n\n\n    def transform(self, data):\n        binarizedAndScaledFeatures = np.empty((0, 0))\n        for feature in self.NUMERICAL_FEATURES:\n            if feature == self.NUMERICAL_FEATURES[0]:\n                binarizedAndScaledFeatures = self.scalers[feature].transform(np.float64(data[feature]).reshape(\n                    (len(data[feature]), 1)))\n            else:\n                binarizedAndScaledFeatures = np.concatenate((\n                    binarizedAndScaledFeatures,\n                    self.scalers[feature].transform(np.float64(data[feature]).reshape((len(data[feature]),\n                                                                                       1)))), axis=1)\n        for feature in self.CATEGORICAL_FEATURES:\n\n            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures,\n                                                         self.binarizers[feature].transform(data[feature])), axis=1)\n\n        for feature in self.BIN_FEATURES:\n            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures, np.array(data[feature]).reshape((len(data[feature]),\n                                                                                       1))), axis=1)\n\n        print(binarizedAndScaledFeatures.shape )\n\n        return binarizedAndScaledFeatures\n    \n    from keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Convolution1D, Dropout\nfrom keras.optimizers import SGD\nfrom keras.initializers import random_uniform\n\nimport pandas as pd\n\nX_train = pd.read_csv('../input/train.csv')\ny_train = X_train['target']\nX_test = pd.read_csv('../input/test.csv')\ntest_id = X_test['id']\nX_test = X_test.drop(['id'], axis=1)\nX_train = X_train.drop(['id', 'target'], axis = 1)\ny_train1 = abs(-1+y_train)\ny_train = pd.concat([y_train, y_train1], axis=1)\nbinarizerandscaler = FeatureBinarizatorAndScaler()\nbinarizerandscaler.fit(X_train)\nX_train = binarizerandscaler.transform(X_train)\nX_test = binarizerandscaler.transform(X_test)\ny_train = y_train.as_matrix()\n\n\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n\n#hyperparameters\ninput_dimension = 226\nlearning_rate = 0.0025\nmomentum = 0.85\nhidden_initializer = random_uniform(seed=SEED)\ndropout_rate = 0.2\n\n\n# create model\nmodel = Sequential()\nmodel.add(Convolution1D(nb_filter=32, filter_length=3, input_shape=X_train.shape[1:3], activation='relu'))\nmodel.add(Convolution1D(nb_filter=16, filter_length=1, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(128, input_dim=input_dimension, kernel_initializer=hidden_initializer, activation='relu'))\nmodel.add(Dropout(dropout_rate))\nmodel.add(Dense(64, kernel_initializer=hidden_initializer, activation='relu'))\nmodel.add(Dense(2, kernel_initializer=hidden_initializer, activation='softmax'))\n\nsgd = SGD(lr=learning_rate, momentum=momentum)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\nmodel.fit(X_train, y_train, epochs=5, batch_size=128)\npredictions = model.predict_proba(X_test)\n\nans = pd.DataFrame(predictions)\nans = ans[0]"}]}