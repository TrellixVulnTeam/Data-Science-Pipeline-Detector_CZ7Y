{"cells":[{"metadata":{"trusted":true,"_uuid":"fcca8f227b3e4303c0f4047919de6195abf7abb3"},"cell_type":"code","source":"#Atividade 2 - Aprendizado de Máquina - FACENS\n#Bruno Silva\n#Denise Leite\n#Milena Rocha","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":false},"cell_type":"code","source":"#Importando o arquivo de treino\ndf_train = pd.read_csv('../input/train.csv')\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a11978b205796d3d23342086b11656b8ba691258"},"cell_type":"code","source":"#Verificando se existem dados duplicados\nprint('Antes:', df_train.shape)\ndf_train.drop_duplicates()\nprint('Depois:', df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"438a4b40e79065691eb06ad4afc2446796377f45","trusted":false},"cell_type":"code","source":"#Importante o arquivo de teste\ndf_test = pd.read_csv('../input/test.csv')\ndf_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f2090708e4d5031c299f52b69ef5fd58dd788afe"},"cell_type":"code","source":"#Verificando se existem dados duplicados\nprint('Antes:', df_test.shape)\ndf_test.drop_duplicates()\nprint('Depois:', df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64efaf7d27b5d4e07351c5def62435a68d08bfb5","trusted":false},"cell_type":"code","source":"#Verificando o tamanho do dataset de treino e teste\nprint('Train: ', df_train.shape)\nprint('Test:  ', df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2884abe83be4305b27e71ff8ad109a0f61c428a0","trusted":false},"cell_type":"code","source":"#Separando os dataset de treino para criar o ds meta dos dados\ndata = []\nfor f in df_train.columns:\n    # definindo o uso (entre rótulo, id e atributos)\n    if f == 'target':\n        role = 'target' # rótulo\n    elif f == 'id':\n        role = 'id'\n    else:\n        role = 'input' # atributos\n         \n    # definindo o tipo do dado\n    if 'bin' in f or f == 'target':\n        level = 'binary'\n    elif 'cat' in f or f == 'id':\n        level = 'nominal'\n    elif df_train[f].dtype == float:\n        level = 'interval'\n    elif df_train[f].dtype == int:\n        level = 'ordinal'\n        \n    # mantem keep como verdadeiro pra tudo, exceto id\n    keep = True\n    if f == 'id':\n        keep = False\n    \n    # cria o tipo de dado\n    dtype = df_train[f].dtype\n    \n    # cria dicionário de metadados\n    f_dict = {\n        'varname': f,\n        'role': role,\n        'level': level,\n        'keep': keep,\n        'dtype': dtype\n    }\n    data.append(f_dict)\n    \nmeta_train = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\nmeta_train.set_index('varname', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35df4d431286c3c88300b0a7a16e55191eb89d13","trusted":false},"cell_type":"code","source":"#Visualizando o meta de treino\nmeta_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c74db84b527585d4a77bcd23440db9006e7cd88b","trusted":false},"cell_type":"code","source":"#Separando os dataset de teste para criar o ds meta dos dados\ndata = []\nfor f in df_test.columns:\n    # definindo o uso (entre rótulo, id e atributos)\n    if f == 'target':\n        role = 'target' # rótulo\n    elif f == 'id':\n        role = 'id'\n    else:\n        role = 'input' # atributos\n         \n    # definindo o tipo do dado\n    if 'bin' in f or f == 'target':\n        level = 'binary'\n    elif 'cat' in f or f == 'id':\n        level = 'nominal'\n    elif df_test[f].dtype == float:\n        level = 'interval'\n    elif df_test[f].dtype == int:\n        level = 'ordinal'\n        \n    # mantem keep como verdadeiro pra tudo, exceto id\n    keep = True\n    if f == 'id':\n        keep = False\n    \n    # cria o tipo de dado\n    dtype = df_test[f].dtype\n    \n    # cria dicionário de metadados\n    f_dict = {\n        'varname': f,\n        'role': role,\n        'level': level,\n        'keep': keep,\n        'dtype': dtype\n    }\n    data.append(f_dict)\n    \nmeta_test = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\nmeta_test.set_index('varname', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c6dabefea9104969b0296c06fd43dac942e7f7b","trusted":false},"cell_type":"code","source":"meta_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fde925466eeb08ac39c257b7ff06bbda5e1fe8d6"},"cell_type":"markdown","source":"## Eliminando Campos e Igualando os Datasets"},{"metadata":{"_uuid":"b1ba5201a96cf7b8624e7ea8118227259816eebd","trusted":false},"cell_type":"code","source":"#Filtrando as variáveis a serem mantidas DS de Treino\nmeta_train[(meta_train.level == 'nominal') & (meta_train.keep)].index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"819918a3294568e370a0eaf7a383c68857ae3417","trusted":false},"cell_type":"code","source":"#Filtrando as variáveis a serem mantidas DS Teste\nmeta_test[(meta_test.level == 'nominal') & (meta_test.keep)].index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b286de238b3c3418e0940dcded23480663faec73"},"cell_type":"markdown","source":"## Visualizando as varáveis por tipo nos datasets"},{"metadata":{"_uuid":"4c45950cd2c9e6431247ab2895bdac7788c4224f","trusted":false},"cell_type":"code","source":"#Dataset de Treino\npd.DataFrame({'count' : meta_train.groupby(['role', 'level'])['role'].size()}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08cda62a03386566e469edcf2ae627c4adf7597f","trusted":false},"cell_type":"code","source":"#Datast de Teste\npd.DataFrame({'count' : meta_test.groupby(['role', 'level'])['role'].size()}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac7d6def6efc26692cdebb075731e6927594b5ab"},"cell_type":"markdown","source":"## Eliminando campos faltantes"},{"metadata":{"_uuid":"767dffc6e765e2cd5f6c6072fe9eed7ddb688df1","trusted":false},"cell_type":"code","source":"#Analisando o Dataset de Treino\natributos_missing = []\n\nfor f in df_train.columns:\n    missings = df_train[df_train[f] == -1][f].count()\n    if missings > 0:\n        atributos_missing.append(f)\n        missings_perc = missings/df_train.shape[0]\n        \n        print('Atributo {} tem {} amostras ({:.2%}) com valores faltantes'.format(f, missings, missings_perc))\n        \nprint('No total, há {} atributos com valores faltantes'.format(len(atributos_missing)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d703d5ad209ac5797ade17d7a048ff3dae822ea","trusted":false},"cell_type":"code","source":"#Analisando o Dataset de Teste\natributos_missing_test = []\n\nfor f in df_test.columns:\n    missings_test = df_test[df_test[f] == -1][f].count()\n    if missings_test > 0:\n        atributos_missing_test.append(f)\n        missings_perc_test = missings_test/df_test.shape[0]\n        \n        print('Atributo {} tem {} amostras ({:.2%}) com valores faltantes'.format(f, missings_test, missings_perc_test))\n        \nprint('No total, há {} atributos com valores faltantes'.format(len(atributos_missing_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f53dc16d21f2185371884b9ddae74b715edce4e5","trusted":false},"cell_type":"code","source":"# removendo ps_car_03_cat e ps_car_05_cat que tem muitos valores faltantes\nvars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\ntrain = df_train.drop(vars_to_drop, axis=1)\ntest = df_test.drop(vars_to_drop, axis=1)\nmeta_train.loc[(vars_to_drop),'keep'] = False  # atualiza os metadados para ter como referência (processar o test depois)\nmeta_test.loc[(vars_to_drop),'keep'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1b1184b383dc38cfbb3d0a06061a42dcd90484ee"},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\n\nmedia_imp = Imputer(missing_values=-1, strategy='mean', axis=0)\nmoda_imp = Imputer(missing_values=-1, strategy='most_frequent', axis=0)\ntrain['ps_reg_03'] = media_imp.fit_transform(train[['ps_reg_03']]).ravel()\ntrain['ps_car_12'] = media_imp.fit_transform(train[['ps_car_12']]).ravel()\ntrain['ps_car_14'] = media_imp.fit_transform(train[['ps_car_14']]).ravel()\ntrain['ps_car_11'] = moda_imp.fit_transform(train[['ps_car_11']]).ravel()\n\ntest['ps_reg_03'] = media_imp.fit_transform(test[['ps_reg_03']]).ravel()\ntest['ps_car_12'] = media_imp.fit_transform(test[['ps_car_12']]).ravel()\ntest['ps_car_14'] = media_imp.fit_transform(test[['ps_car_14']]).ravel()\ntest['ps_car_11'] = moda_imp.fit_transform(test[['ps_car_11']]).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"da5657d258767b7f9cfc02e4c804bf026b075ad7"},"cell_type":"code","source":"v = meta_train[(meta_train.level == 'nominal') & (meta_train.keep)].index\n\nfor f in v:\n    dist_values = train[f].value_counts().shape[0]\n    print('Atributo {} tem {} valores distintos'.format(f, dist_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b0ed321f817f701e1c8da52f664c40f6e68c6e3d"},"cell_type":"code","source":"v = meta_test[(meta_test.level == 'nominal') & (meta_test.keep)].index\n\nfor f in v:\n    dist_values = train[f].value_counts().shape[0]\n    print('Atributo {} tem {} valores distintos'.format(f, dist_values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9c0b215723616cc802f446386d8b3d5d7b273831"},"cell_type":"code","source":"v = meta_train[(meta_train.level == 'nominal') & (meta_train.keep)].index\nprint('Antes do one-hot encoding tinha-se {} atributos'.format(train.shape[1]))\ntrain = pd.get_dummies(train, columns=v, drop_first=True)\nprint('Depois do one-hot encoding tem-se {} atributos'.format(train.shape[1]))\n\nprint('Antes do one-hot encoding tinha-se {} atributos'.format(test.shape[1]))\ntest = pd.get_dummies(test, columns=v, drop_first=True)\nprint('Depois do one-hot encoding tem-se {} atributos'.format(test.shape[1]))\n\nmissing_cols = set( train.columns ) - set( test.columns )\n\nprint(missing_cols)\nfor c in missing_cols:\n    test[c] = 0\n    \ntrain, test = train.align(test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a749493b11b153439499ddd1cae2fd07b2232642"},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"78d00a214d9d5fe3426873d6661d9d02f512add5"},"cell_type":"code","source":"X_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']\n\nX_test  = test.drop(['id', 'target'], axis=1)\ny_test  = test['target']\n\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(class_weight='balanced')\n\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"af0f3afa411870c364f32cb207b0ef878c0e3936"},"cell_type":"code","source":"#Creating Submission file\ny_pred = model.predict(X_test)\nsubmit = pd.DataFrame({'id':test['id'],'target':y_pred})\n#submit.head() \nsubmit.to_csv('submission_log.csv',index=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b8ee5a40dc650bd9a0851409370a7c24ccad909e"},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn import metrics\n\nmodel = linear_model.LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1])\nmodel.fit(X_train, y_train)\n\nerro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', erro_treino)\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', erro_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"037c4f493051957d1baeb81fb3bcd69e19a39971"},"cell_type":"code","source":"#Creating Submission file\ny_pred = model.predict(X_test)\nsubmit = pd.DataFrame({'id':test['id'],'target':y_pred})\n#submit.head() \nsubmit.to_csv('submission_lin.csv',index=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e7a0c19b585cb3a6e4ce95d0a6ca06643bb39be2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}