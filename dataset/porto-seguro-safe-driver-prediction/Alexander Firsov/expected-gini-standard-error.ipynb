{"nbformat_minor":1,"cells":[{"source":"This notebook is an attempt to answer of how gini standard error depends on the percent of the data used for calculation. For example, if one selected 10% of train data for validation, what gini error could be expected? Or what would be gini deviation for public leaderboard comparing to private one?","cell_type":"markdown","metadata":{"_uuid":"518893e5accea20e610fe20f6be06ff77d66ab03","_cell_guid":"6f56c54d-a508-4716-b1c3-206285cdb603"}},{"source":"It is not possible to calculate gini directly on test data, therefore test data is created from 50% of train data (and increased using  random sampling with replacement to correspond test size in this competition), other 50% is used for training. Note that  goal here is not any specific model or exact gini value, but only behavior of gini standard deviation.","cell_type":"markdown","metadata":{"_uuid":"8cb5ebe2478b904b0fadc99e4ce2ef3d1215529c","_cell_guid":"d9c49043-2330-458c-990d-343513d28e0b"}},{"source":"import pandas as pd\nimport numpy as np\nfrom numba import jit\nfrom sklearn.model_selection import train_test_split\n\n# obligatory part of any kernel\n# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n@jit\ndef eval_gini(y_true, y_prob):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0.0\n    delta = 0\n    n = len(y_true)\n    for i in range(n - 1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini / (1.0 * ntrue * (n - ntrue))\n    return gini\n\n\nseed = 1685\ntrain_original = pd.read_csv('../input/train.csv', dtype={'target': np.int8, 'id': np.int32})\ntest_original = pd.read_csv('../input/test.csv', dtype={'id': np.int32})\ntest_set_size = len(test_original.index)\ntrain_set_size = len(train_original)\n\ntrain, test_source = train_test_split(train_original, random_state=seed, train_size=0.5, test_size=0.5)\ntest = test_source.sample(n=test_set_size, replace=True)\n\ndel train_original, test_original, test_source","outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_uuid":"f7953fc7844e9e2a6c7b51c35d44820c5926cd59","_cell_guid":"330dd9f3-a7ca-45b7-8651-63be31429938"},"execution_count":1},{"source":"Fit some model and make prediction on test","cell_type":"markdown","metadata":{"_uuid":"41d86599cdb533a5af0b5fba596ad00d7dbe63fc","_cell_guid":"e7c0aa1e-1cb2-4c59-817d-e327e180c839"}},{"source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(\n    n_jobs=4,\n    random_state=seed,\n    n_estimators=100,\n    max_depth=4,\n    objective='binary:logistic',\n    learning_rate=0.1,\n)\n\nfit_model = model.fit(train.drop(['id', 'target'], axis=1), train['target'])\n\nprediction = fit_model.predict_proba(test.drop(['id', 'target'], axis=1))[:, 1]\ngini_total = eval_gini(test['target'], prediction)\ntarget_and_prediction = pd.DataFrame({\n    'prediction': prediction,\n    'target' : test['target']\n})","outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_uuid":"1484c92c25b228be7c5b41cffb4b344ef21f8673","_cell_guid":"5f08db03-941c-4fc9-8156-b903c1e7dba8"},"execution_count":2},{"source":"Check what gini would be for randomly selected 5%, 10%, 15%, etc of test data","cell_type":"markdown","metadata":{"_uuid":"e951156be6cd6c49f5c86e51e82052a395a59500","_cell_guid":"fffe3166-a0f9-49f4-8986-43a5df69a040"}},{"source":"step = 5\nnum_rounds = 200\nx = []\nmean = []\nstd = []\nmins=[]\nmaxs=[]\n\ntest_target = test['target']\npercents = range(step, 100 + step, step)\nfor part_size in percents:\n    ginis = []\n    for i in range(num_rounds):\n        iteration_seed = (seed + num_rounds * part_size + i)\n        part = target_and_prediction.sample(frac=part_size / 100, random_state=iteration_seed)\n        gini = eval_gini(part['target'], part['prediction'])\n        ginis.append(gini)\n    x.append(part_size)\n    mean.append(np.mean(ginis))\n    std.append(np.std(ginis))\n    mins.append(np.min(ginis))\n    maxs.append(np.max(ginis))","outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_uuid":"e3ecaf986d3750ee67229f47bbee3e1e5b1b83db","_cell_guid":"279dd69c-16bc-4acc-a902-9f9afc46e981"},"execution_count":null},{"source":"import matplotlib.pyplot as plt\n% matplotlib inline\n\nhigh = [x + y for x, y in zip(mean, std)]\nlow = [x - y for x, y in zip(mean, std)]\n\nplt.figure(1, figsize=(12, 12))\nplt.axis([0, 100, 0.255, 0.29])\n\nplt.fill_between(x, maxs, mins, interpolate=True, color='#F0F0F0')\nplt.fill_between(x, high, low, interpolate=True, color='silver')\nplt.plot(x, [gini_total] * len(x), 'r--', x, mean, '-o')\n\npublic_index = 30 // step - 1\npublic_label = mean[public_index] + std[public_index]\nplt.annotate('Public leaderboard,\\n30%, std = {:8.5f}'.format(std[public_index]),\n             xy=(30, public_label + 0.001),\n             xytext=(30, public_label + 0.005),\n             arrowprops=dict(facecolor='black', shrink=0.05),\n             )\n\nprivate_index = 70 // step - 1\nprivate_label = mean[private_index] + std[private_index]\nplt.annotate('Private leaderboard,\\n70%, std = {:8.5f}'.format(std[private_index]),\n             xy=(70, private_label + 0.001),\n             xytext=(70, private_label + 0.005),\n             arrowprops=dict(facecolor='black', shrink=0.05),\n             )\nplt.title('Gini deviation vs data size')\nplt.xlabel('Percent of test data used for gini calculation')\nplt.ylabel('Gini mean value and deviation')\nplt.show()","outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_uuid":"4b4f03c2494b971311b808e6e8f26afee856debd","_cell_guid":"811e3f45-07b1-4bd8-b6c0-f50f60cfe620"},"execution_count":null},{"source":"On plot above, gini was calculated 200 times on randomly selected samples of each size.\nLight grey area - gini min/max, grey area - gini within standard deviation, blue - mean value, and red - gini value calculated on full data set.\n\nModel here has gini about 0.27 on full test set, but public leaderboard may vary within 0.265 - 0.275, and private leaderboard may have range 0.268 - 0.272.","cell_type":"markdown","metadata":{"_uuid":"e69cc171168c97a442843f8d0619fc9d4aa04f39","_cell_guid":"92e6e881-74b9-45f5-b847-6f674d5d86c8"}},{"source":"results = pd.DataFrame()\nresults['test, %'] = percents\nresults['train, %'] = results['test, %'] * test_set_size / train_set_size\nresults['std'] = std\nresults['min'] = mins\nresults['mean'] = mean\nresults['max'] = maxs\n\nresults","outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_uuid":"51cc60e77b82b2630e5f1982980144bd75a55138","_cell_guid":"eb59cdb0-04eb-4f60-a819-fd3ddfa72154"},"execution_count":null},{"source":"Table above shows that standard error of public leaderboard is about 0.005 and if one use 15% validation set from train data, standard deviation would be about 0.01.\n\nNote sure I can draw conclusions like this, but If we assume that top of the public leaderboard overfits to 30% of test data, then potential winners have public gini  within 0.281 - 0.291, that is about 2000 teams, and winning solution has gini about 0.286.\n\nThe question is how you deal with such a big standard error? ","cell_type":"markdown","metadata":{"_uuid":"b2596d7103efba3657609d47daecbf7b16f0a2df","_cell_guid":"276eb835-2fad-4050-a870-872f561e21f9"}}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","version":"3.6.3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4}