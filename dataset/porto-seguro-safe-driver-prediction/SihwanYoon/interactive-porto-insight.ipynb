{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 노트북 소개\n해당 노트북은 Interactive Porto Insights - A Plot.ly Tutorial(https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial)의 한글 번역본입니다!\n\n필사를 하며 개인적으로 느꼈던 점과 활용한 방법들도 기재가 되어있습니다.\n오역과 의역이 다수 있으니 잘못된 점 알려주시면 수정하도록 하겠습니다.\n\n# Introduction\n브라질에서 세번째로 큰 보험 회사인 Porto Seguro에 의해 주최된 이 경쟁은 운전자가 내년에 보험 청구를 할 가능성에 대해 예측하는 작업을 진행합니다.\n\n이 노트북은 파이썬의 시각화 도구인 Plot.ly를 활용하여 상호관계적 차트를 만들고 데이터를 분석하는 하는데 목적을 두고 있습니다. Plot.ly는 통계적 시각화에 특화된 라이브러리로 파이썬뿐만 아니라 다른 프로그래밍 언어에서도 사용하고 있습니다.\n\n우리는 Plot.ly를 통하여 편리하게 다양한 그래프들을 만들어볼 수 있습니다.\n1. Simple Horizontal bar plot : 단순 수평 막대그래프 \n2. Correlation Heatmap plot : 상관관계 히트맵\n3. Scatter Plot : 산점도\n4. Vertical Bar plot : 수직 막대그래프트\n5. 3D Scatter Plot : 3D 산점도\n\n이 노트북의 테마는 다음과 같이 정리 가능합니다:\n1. 데이터 품질 점검 - 결측값을 시각화하고 평가합니다.\n2. Feature 점검과 필터링 - 상관관계와 상호의존정보를 활용합니다. Binary, Categorical 그리고 다른 변수들을 점검합니다.\n3. 학습한 모델을 활용한 Feature 중요도 랭킹 산정 - Random Forest와 Gradient Boosting 을 활용하여 모델을 만들고 학습 과정에 기반하여 Feature들의 중요도 순위를 산정합니다.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom collections import Counter\nfrom sklearn.feature_selection import mutual_info_classif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plotly.offline : 만들어진 그래프를 시각화합니다.\n\nplotly.graph_objs : 그래프를 선택하고 데이터와 레이아웃을 설정합니다.\n\nplotly.tools : 이번 노트북에서 사용하지 않습니다.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/porto-seguro-safe-driver-prediction/train.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train 데이터의 행과 열의 갯수를 확인합니다\nrows = train.shape[0]\ncolumns = train.shape[1]\n\nprint('Train dataset contains {0} rows and {1} columns.'.format(rows, columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Quality checks\n결측값을 찾아봅니다.","metadata":{}},{"cell_type":"code","source":"# 1. 데이터 퀄리티 체크\n\n# 방법 1 any().any() 활용\nprint(train.isnull().any().any())\n\n# 방법 2 sum().sum() 활용\nprint(train.isnull().sum().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"원본 작성자는 any().any()를 활용했지만, 개인적으로는 sum().sum()이 더 낫다고 생각해서 두 개 다 넣어놨습니다.\n\n결측값이 전혀 없는 듯하지만 데이터 설명에 따르면 결측값은 -1로 처리가되어있음을 알 수 있습니다. 따라서 -1 값을 NaN 값으로 치환해보도록 하겠습니다.","metadata":{}},{"cell_type":"code","source":"train_copy = train\ntrain_copy = train_copy.replace(-1, np.NaN)\n\ncount_null = train_copy.isnull().sum().sum()\nprint('치환된 Null값의 갯수는 {}개입니다'.format(count_null))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"치환된 Null값의 개수를 확인했습니다.\n\n이제 Missingno 패키지를 활용하여 결측값을 확인해보도록 하겠습니다.","metadata":{}},{"cell_type":"code","source":"# missingno 를 활용하여 Null값 확인하기\nimport missingno as msno\nmsno.matrix(df=train_copy.iloc[:, 2:39],\n           figsize=(20,14), color=(0.42, 0.1, 0.05))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"와인색 부분은 데이터가 온전히 보존된 부분이고 흰색 부분은 데이터가 유실된 부분을 나타냅니다. \n\n이를 통해 우리는 59개의 Feature들 중 7개의 Feature에 결측값이 있음을 확인할 수 있습니다. 하지만 엄밀히 따지면 총 13개의 Feature에 결측값이 있습니다. Missingno 매트릭스는 대략 40개의 Feature들에 맞추어져 있기 때문에 제외된 Feature들에서 결측값을 지닌 남은 5개의 Feature들이 발견됐을 것입니다.\n\n우리가 발견한 7개의 칼럼은 다음과 같습니다.\n\n**ps_ind_05_cat | ps_reg_03 | ps_car_03_cat | ps_car_05_cat | ps_car_07_cat | ps_car_09_cat | ps_car_14**\n\n많은 결측값을 가진 칼럼은 '_cat'이라는 접미사를 가지고 있습니다. 원본 노트북에는 없지만 결측값의 비율을 한 번 확인해봅시다.","metadata":{}},{"cell_type":"code","source":"# Null값의 퍼센트 비율을 확인\nfor col in train_copy :\n    if train_copy[col].isnull().sum() > 0 :\n        print('{} contains {} Null values ({:.2f}%)'.format(col, train_copy[col].isnull().sum(),\n                                                                               train_copy[col].isnull().sum()/len(train_copy[col])))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"앞서 언급했듯이 13개의 칼럼들이 존재함을 알 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"**Target 변수 검사**\n\n표준화된 검사 과정엔 Target Variable에 대한 검사가 수행됩니다. 이번 데이터의 경우에는 이미 Target Variable이 'target'이라는 이름으로 지정되어 있습니다. 이 Target Variable은 class/label/correct라는 별칭으로 불리기도 하며 이를 바탕으로 새로운 데이터 값이 주어졌을 때 미지의 값을 예측하게 됩니다.","metadata":{}},{"cell_type":"code","source":"# 타겟 변수를 확인\n\ndata = [go.Bar(x=train['target'].value_counts().index,\n               y=train['target'].value_counts().values,\n               text='Distribution of target variable'\n              )]\n\nlayout = go.Layout(title='Target variable distribution')\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"matplotlib과 seaborn이 아닌 **Plot.ly**로 그래프를 그려봤습니다.\n\n과정은 다음과 같이 진행됐습니다.\n\n1. go.Bar를 활용하여 x축과 y축 데이터를 지정해줍니다. text는 그래프에 마우스를 올렸을 때 나타나는 텍스트를 의미합니다.\n2. go.Layout을 활용하여 그래프의 제목을 지정해줍니다.\n3. go.Figure를 활용하여 fig에 그래프를 할당해줍니다.\n4. py.iplot을 활용하여 그래프를 시각화해줍니다.\n\n여기서 go는 plotly.graphic_objs, iplot은 plotly.offline이었습니다. 기억해두도록 합시다.","metadata":{}},{"cell_type":"markdown","source":"시각화된 데이터를 보니 레이블값이 매우 불균형함을 알 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"**Datatype check**\n\n이 과정을 통해 훈련 데이터가 어떤 데이터들로 구성되어 있는지 확인해봅니다. 정수인지, 문자인지, 실수인지 확인함으로써 데이터에 대해 더 나은 전반적인 이해를 얻을 수 있습니다. Collections 모듈의 Counter를 활용하여 확인해보도록 합니다.","metadata":{}},{"cell_type":"code","source":"# 훈련 데이터의 타입 확인 (방법 1)\ntrain.dtypes.value_counts().to_frame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"개인적으로 저는 굳이 Collections의 Counter를 사용할 이유를 못느껴 value_counts를 frame으로 만들어 확인했습니다.","metadata":{}},{"cell_type":"code","source":"# 훈련 데이터의 타입 확인 (방법 2)\nCounter(train.dtypes.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"59개로 이루어진 칼럼들은 39개의 int, 20개의 float으로 구성되어 있습니다.\n\n각 데이터들은 '_bin', '_cat', '_reg'라는 접미사를 가지고 있습니다. 각각의 접미사들은 뜻을 가지고 있는데, '_bin'은 binary, '_cat'은 categorical, '_reg'는 Continious 이거나 Ordianl 데이터를 말합니다.\n\n이제 단순히 float values(Continious Feature)와 integer values(Binary, Categorical, Ordinal)으로 데이터를 나눠보도록 합시다.","metadata":{}},{"cell_type":"code","source":"# float과 int를 select_dtypes를 활용하여 구분\ntrain_float = train.select_dtypes(include=['float64'])\ntrain_int = train.select_dtypes(include=['int64'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation plots\n변수들의 선형 상관관계 그래프를 확인해봄으로써 인사이트를 얻어보도록 하겠습니다. 일단 seaborn 라이브러리를 활용하여 히트맵을 그려보도록 합시다. 편리하게 판다스의 corr()을 사용하여 피어슨 상관계수를 계산해준 뒤, seaborn의 heatmap을 사용해보도록 합시다.","metadata":{}},{"cell_type":"markdown","source":"**float features들의 상관관계**","metadata":{}},{"cell_type":"code","source":"# seaborn을 활용하여 float 데이터의 히트맵 생성\ncolormap = plt.cm.magma\nplt.figure(figsize=(16,12))\nplt.title('Pearson correlation of continuous features', y=1.05, size=15)\nsns.heatmap(train_float.corr(),linewidths=0.1,vmax=1.0, square=True, \n            cmap=colormap, linecolor='white', annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"히트맵을 통해 대다수의 Featurese들이 0이거나 다른 변수들과 상관관계가 거의 없음을 확인 가능합니다. 이것은 추가로 할 조사에 흥미로운 관찰 결과를 말해줍니다. 지금 당장에는, 양의 상관관계를 보이는 변수들은 다음과 같습니다.\n\n**(ps_reg_01, ps_reg_03)**\n\n**(ps_reg_02, ps_reg_03)**\n\n**(ps_car_12, ps_car_13)**\n\n**(ps_car_13, ps_car_15)** ","metadata":{}},{"cell_type":"markdown","source":"**Integer Features들의 상관관계**\n\n이번에는 seaborn 대신 plotly를 사용해보도록 하겠습니다.\n간단하게 'go.Heatmap'을 사용하면 됩니다. x축과 y축에는 각 칼럼의 이름들을 기입해주고 z축에는 상관관계 값을 기입해주도록 합시다.","metadata":{}},{"cell_type":"code","source":"data = [\n    go.Heatmap(\n        z=train_int.corr().values,\n        x=train_int.columns.values,\n        y=train_int.columns.values,\n        colorscale='Viridis',\n        reversescale=False,\n        opacity=1.0)\n]\n\nlayout = go.Layout(\n        title='Peason corr of Integer-type Features',\n        xaxis=dict(ticks='', nticks=36),\n        yaxis=dict(ticks=''),\n        width=900, height=700)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"비슷하게, 대다수의 칼럼들이 상관관계를 가지고 있지 않거나 0임을 확인 가능합니다. 이 정보는 만약 우리가 주성분 분석(PCA)과 같이 차원 축소를 진행하는 경우에 매우 유용한 정보가 될 수 있습니다. \n\n우리에게 흥미로운 칼럼은 다음과 같습니다\n\n\n**음의 상관관계를 가지는 Features: ps_ind_06_bin, ps_ind_07_bin, ps_ind_08_bin, ps_ind_09_bin**\n\n또 다른 흥미로운 측면은 우리가 결측값 분석에서 많은 결측값을 지녔던 ps_car_03_cat과 ps_car_05_cat에서 찾아볼 수 있습니다. 우리는 이 둘이 강력한 양의 상관을 가지고 있어도 놀라울 일이 아니지만 데이터에 대한 근본적인 진실을 제대로 반영하지 못하고 있을 수 있습니다. ","metadata":{}},{"cell_type":"markdown","source":"### Mutual Information plots\n상호의존정보는 Target과 변수들 간의 상호 정보를 검사할 수 있는 유용한 도구입니다. 분류 문제에서, 우리는 sklearn의 mutual_info_classif 메소드로 손쉽게 이를 측정할 수 있습니다. 0일 경우 랜덤한 변수이 서로 독립적이라는 것을 의미하며, 값이 높아질수록 약간의 독립성을 나타냅니다. 이 기능을 통해 Feature 내부에 target에 대한 정보가 얼마나 담겨있는지 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"#상호의존정보 확인\nmf = mutual_info_classif(train_float.values,\n                        train['target'].values,\n                        n_neighbors=3,\n                        random_state=17)\n\nprint(mf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Binary features inspection\n다음으로는 0과 1, 두 개의 값만을 가지고 있는 binary columns들에 대한 검사를 시작합니다. 모든 binary 칼럼을 호출하여 0과 1의 비율을 그래프로 나타내보도록 합시다.","metadata":{}},{"cell_type":"code","source":"bin_col = []\nfor col in train.columns :\n    if '_bin' in col :\n        bin_col.append(col)\n        \nzero_list = []\none_list = []\n\nfor col in bin_col :\n    zero_list.append((train[col]==0).sum())\n    one_list.append((train[col]==1).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace1 = go.Bar(\n        x=bin_col,\n        y=zero_list,\n        name='Zero count')\n\ntrace2 = go.Bar(\n        x=bin_col,\n        y=one_list,\n        name='One Count')\n\ndata=[trace1, trace2]\n\nlayout = go.Layout(\n        barmode='stack',\n        title='Count of 1 and 0 in binary variables')\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*ps_ind_10_bin, ps_ind_11_bin, ps_ind_12_bin, ps_ind_13_bin* 이 네 개의 칼럼은 거의 완벽히 0에게 지배당했습니다. 이를 통해 target에 대한 정보가 거의 담기지 않았음을 유추할 수 있을 것입니다.","metadata":{}},{"cell_type":"markdown","source":"### 랜덤 포레스트를 활용한 Featrue importance 확인\n\n\n이제 랜덤 포레스트 분류기로 훈련 데이터를 fit 시키고, 모델이 훈련을 마친 후 특징의 순위를 살펴보는 랜덤 포레스트 모델을 구현하도록 합니다. 이것은 유용한 Feature importance를 얻는 데 많은 하이퍼 파라미터 튜닝이 필요하지 않고 목표 불균형을 파악하는 데도 매우 강력한 앙상블 모델을 사용하는 빠른 방법입니다.","metadata":{}},{"cell_type":"code","source":"# Random Forest를 활용한 Feature 중요도 확인\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=150,\n                           max_depth=8,\n                            min_samples_leaf=4,\n                            max_features=0.2,\n                            n_jobs=-1,\n                            random_state=0)\n\nX_train = train.drop(['target', 'id'], axis=1)\ny_train = train['target']\n\nrf.fit(X_train, y_train)\n\nfeatures = train.drop(['target' , 'id'], axis=1).columns.values\n\nprint('Training Done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot.ly Scatter Plot**\n\n훈련된 랜덤 포레스트 모델은 \"feature_importances_\"로 값을 불러올 수 있습니다. 그렇다면 plotly의 Scatter plot으로 이를 확인해보도록 합시다. 한가지 주의해야 할 점은 scatter plot의 Marker 속성입니다. 이를 통해 사이즈, 색상, 스케일 등을 조정할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"trace = go.Scatter(\n    y = rf.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        #size= rf.feature_importances_,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = rf.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Random Forest Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"막대 그래프 형태로도 살펴보도록 합시다.","metadata":{}},{"cell_type":"code","source":"x, y = (list(x) for x in zip(*sorted(zip(rf.feature_importances_, features), \n                                                            reverse = False)))\ntrace2 = go.Bar(\n    x=x ,\n    y=y,\n    marker=dict(\n        color=x,\n        colorscale = 'Viridis',\n        reversescale = True\n    ),\n    name='Random Forest Feature importance',\n    orientation='h',\n)\n\nlayout = dict(\n    title='Barplot of Feature importances',\n     width = 900, height = 2000,\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=True,\n#         domain=[0, 0.85],\n    ))\n\nfig1 = go.Figure(data=[trace2])\nfig1['layout'].update(layout)\npy.iplot(fig1, filename='plots')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boosting을 통한 Featrue importance 확인\n\n다른 모델을 활용하여 Feature importances를 얻어보도록 합시다.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=100,\n                                max_depth=3,\n                               min_samples_leaf=4,\n                               max_features=0.2,\n                               random_state=0)\n\ngb.fit(X_train, y_train)\n\nprint('Training Done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace = go.Scatter(\n    y = gb.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        color = gb.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Gradient Boosting Machine Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = (list(x) for x in zip(*sorted(zip(gb.feature_importances_, features), \n                                                            reverse = False)))\ntrace2 = go.Bar(\n    x=x ,\n    y=y,\n    marker=dict(\n        color=x,\n        colorscale = 'Viridis',\n        reversescale = True\n    ),\n    name='Random Forest Feature importance',\n    orientation='h',\n)\n\nlayout = dict(\n    title='Barplot of Feature importances',\n     width = 900, height = 2000,\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=True,\n#         domain=[0, 0.85],\n    ))\n\nfig1 = go.Figure(data=[trace2])\nfig1['layout'].update(layout)\npy.iplot(fig1, filename='plots')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"흥미롭게도 두 모델 모두에게서 **ps_car_13**이 제일 중요한 칼럼임을 확인할 수 있었습니다.","metadata":{}}]}