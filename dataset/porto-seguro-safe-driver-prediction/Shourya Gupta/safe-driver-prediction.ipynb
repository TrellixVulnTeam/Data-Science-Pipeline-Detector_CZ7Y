{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style = \"darkgrid\")\n# !pip install datawig\n# import datawig # impute missing values \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T06:51:56.826253Z","iopub.execute_input":"2021-11-29T06:51:56.826568Z","iopub.status.idle":"2021-11-29T06:51:56.838031Z","shell.execute_reply.started":"2021-11-29T06:51:56.826534Z","shell.execute_reply":"2021-11-29T06:51:56.837454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/porto-seguro-safe-driver-prediction/train.csv\"\ndata = pd.read_csv(path)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:51:56.839502Z","iopub.execute_input":"2021-11-29T06:51:56.839982Z","iopub.status.idle":"2021-11-29T06:52:00.224355Z","shell.execute_reply.started":"2021-11-29T06:51:56.839949Z","shell.execute_reply":"2021-11-29T06:52:00.223518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10) # display top 10 rows","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:52:00.225524Z","iopub.execute_input":"2021-11-29T06:52:00.225749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(['id'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of rows and columns in dataset\nrows = data.shape[0]\ncolumns = data.shape[1]\nprint(\"Data has {} rows, {} columns\".format(rows, columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA PREPROCESSING","metadata":{}},{"cell_type":"markdown","source":"## HANDLE NULLS","metadata":{}},{"cell_type":"code","source":"# number of nulls in dataset\nnulls = (data.isna().sum()/rows)*100\nnulls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"IT IS MENTIONED IN DATA DESCRIPTION THAT -1 REPRESENTS MISSING VALUES","metadata":{}},{"cell_type":"code","source":"# replace -1 with NaN\ndata = data.replace(to_replace = -1, value = np.nan)\n# calculate nulls count\nnulls = (data.isna().sum()/rows)*100\nnulls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# threshold value for nulls %\nnull_threshold = 15\n# columns to drop with nulls % greater than threshold\ndrop_nulls = []\n# columns with null % less than threshold (to be imputed)\nretain_nulls = []\n\nprint(\"Columns with nulls more than threshold :\\n\")\nfor i in nulls.index:\n    if(nulls[i]>null_threshold):\n        print(i, nulls[i])\n        drop_nulls.append(i)\n    elif(nulls[i]>0):\n        retain_nulls.append(i)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(drop_nulls, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SPLIT INTO TRAIN & VALIDATION PARTS","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# dependent variables\nX = data.drop(['target'], axis = 1)\n# independent variable\ny = data['target']\n\n# split data into train and validation part\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"markdown","source":"## HANDLE CATEGORICAL VARIABLES","metadata":{}},{"cell_type":"code","source":"# categorical columns\ncat_columns = []\n\nfor i in X_train.columns:\n    if('cat' in i):\n        cat_columns.append(i)\n\ncat_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert list to np.array\ncat_columns = np.array(cat_columns)\n\n# not using the following columns since they are of binary nature thus no need to encode\ncat_columns = cat_columns[(cat_columns!='ps_ind_04_cat') & (cat_columns!='ps_car_02_cat') & \n           (cat_columns!='ps_car_07_cat') & (cat_columns!='ps_car_08_cat')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode categorical variable using LeaveOneOutEncoding technique\n# !pip install category_encoders\nfrom category_encoders import LeaveOneOutEncoder\n\n# intialise encoder\nencoder = LeaveOneOutEncoder(cols = cat_columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit and encode data\nX_train = encoder.fit_transform(X_train, y_train)\nX_val = encoder.transform(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# columns to use as input to imputer\nimputer_columns = []\n\nfor i in X_train.columns:\n    if(i not in retain_nulls):\n        imputer_columns.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datawig\nimport datawig\n\ndef ImputeNulls(train, val, imputer_columns, output_column):\n    ''' \n    Replaces nulls in output_column\n    \n    Args:\n        train, val (DataFrame) : Training and validation datasets\n    \n    Returns:\n        tuple : train and validation datasets with imputed values\n    '''\n#     intialise imputer\n    imputer = datawig.SimpleImputer(\n        input_columns=imputer_columns,\n        output_column=output_column\n        )\n#     fit \n    imputer.fit(train_df = train)\n#     impute missing values\n#     imputer = datawig.SimpleImputer.load('./ps_car_14')\n    train = imputer.predict(train)\n    val = imputer.predict(val)\n    return (train, val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# map columns with imputed values to fill against nulls\nfill_nulls = {}\n\nfor i in retain_nulls[:-1]:\n    fill_nulls[i] = X_train[i].median()\n    X_train[i] = X_train[i].fillna(value=fill_nulls[i])\n    X_val[i] = X_val[i].fillna(value=fill_nulls[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val = ImputeNulls(X_train, X_val, imputer_columns, retain_nulls[-1])\nX_train = X_train.drop(['ps_car_14'], axis = 1)\nX_val = X_val.drop(['ps_car_14'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def handleOutliers(data, to_return = False):\n    ''' \n    Removes outliers from each column and reports the data loss\n    \n    Args:\n        data (DataFrame) : The DataFrame to remove outliers from\n        to_return (bool) :  - Default value False\n                            - Whether to return the DataFrame after removing outliers\n    \n    Returns:\n        DataFrame : data free from outliers\n    '''\n#     calculate first quantile\n    Q1 = data.quantile(0.25)\n#     calculate third quantile\n    Q3 = data.quantile(0.75)\n#     calculate inter quartile range\n    IQR1 = Q3-Q1\n\n#     initialise data w/o outliers (drop outliers)\n    data_c = data[~((data < (Q1-1.5*IQR1))|(data > (Q3+1.5*IQR1))).any(axis = 1)] \n    \n#     report data loss\n    print('Data loss is {}%'.format(((len(data) - len(data_c))/len(data))*100))\n    \n    if(to_return):\n        return data_c.reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"handleOutliers(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def countOutliers(data, column):\n    ''' \n    Calculates the number of outliers in given column\n    \n    Args:\n        data (DataFrame) : The dataset in form of Pandas DataFrame\n        column (string) : The column to report number of outliers in\n    \n    Returns:\n        int : percentage of outliers in column\n    '''\n#     calculate first quantile\n    Q1 = data[column].quantile(0.25)\n#     calculate third quantile\n    Q3 = data[column].quantile(0.75)\n#     calculate inter quartile range\n    IQR1 = Q3-Q1\n    \n#     % of outliers in the column\n    return (len(data[((data[column] < (Q1-1.5*IQR1))|(data[column] > (Q3+1.5*IQR1)))])/len(data))*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# percentage of outliers in each column\noutliers = {}\n\nfor column in X_train.columns:\n    outliers[column] = countOutliers(X_train, column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sort in decreasing order\noutliers = dict(sorted(outliers.items(), key=lambda item: item[1], reverse = True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def OutliersInfo(threshold_outliers, outliers):\n    '''\n    Finds number of columns in data with more than threshold percentage of outliers\n    \n    Args:\n        thershold_outliers (int) : maximum percentage of outliers acceptable in dataset\n        outliers (dict) : map of columns with number of outliers in each\n    \n    Returns:\n        list : Columns with more than thershold percent of outliers\n    '''\n\n#     remove columns with more than threshold\n    to_drop_outliers = []\n\n    for i in outliers:\n        if(outliers[i] <= threshold_outliers):\n            break\n        elif(i != 'target'):\n            to_drop_outliers.append(i)\n            \n    return to_drop_outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# thersholds to check\nthresholds_outliers = [i for i in range(21)]\n# number of columns for each threshold\nthreshold_outliers_values = []\n\nfor i in thresholds_outliers:\n    threshold_outliers_values.append(len(OutliersInfo(i, outliers)))\n    \n# plot\nsns.lineplot(x=thresholds_outliers, y=threshold_outliers_values)\nplt.xlabel(\"Thresholds\")\nplt.ylabel(\"Columns\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_outliers = 4\n\n# columns with more than threshold of outliers\ndrop_outliers = OutliersInfo(threshold_outliers, outliers)\n\nprint(\"Columns with more than {}% of values as Outliers are {}\".format(threshold_outliers, len(drop_outliers)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop outliers\nX_train = X_train.drop(drop_outliers, axis = 1)\nX_val = X_val.drop(drop_outliers, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handle Constant Valued columns","metadata":{}},{"cell_type":"code","source":"#columns with constant value\ndrop_constant_valued = ['ps_ind_02_cat', 'ps_ind_10_bin', 'ps_ind_11_bin'\n                       , 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14']\n\nX_train = X_train.drop(drop_constant_valued, axis=1)\nX_val = X_val.drop(drop_constant_valued, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = handleOutliers(X_train, True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install dataprep\nfrom dataprep.eda import plot\nplot(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}