{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # 다차원 배열 처리를 지원하는 라이브러리\nimport pandas as pd \nimport matplotlib.pyplot as plt # 시각화\nimport matplotlib\n%matplotlib inline\n\nimport seaborn as sns # 시각화\nimport missingno as msno # 누락 데이터 시각화 라이브러리\n\nimport xgboost as xgb # Gradient Boosting\nimport warnings\nsns.set(style='white', context='notebook', palette='deep')\n\n# 기본 라이브러리 추가","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"np.random.seed(1989)\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train.shape) # 행, 열\nprint(\"Test shape : \", test.shape )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1afaf0f0a9597b47ea896b679cae335887e0e34"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea35bba7b8b9413af8f98c0d4bfef08c06782d51"},"cell_type":"code","source":"print(train.info()) # 트레인 셋의 각 행의 속성","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de45ed909d5073051c2d8d451db41e87e8717314"},"cell_type":"code","source":"print(test.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45c957ebc4d4c8f9f3fba23e1854911b3e9457db"},"cell_type":"markdown","source":"각 데이터의 수는 57개이나, 각각이 무엇을 의미하는 지는 알 수 없음"},{"metadata":{"trusted":true,"_uuid":"0edbced071a44beb092c73958be65c3f02d0a0f4"},"cell_type":"code","source":"targets = train['target'].values # 타겟 행의 값을 따로 변수로 지정","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"751e8df7f777608e6e845efed2cd74398f1bdd4e"},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nax = sns.countplot(x = targets)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(targets)), (p.get_x()+ 0.3, p.get_height()+10000))\nplt.title('Distribution of Target', fontsize=20)\nplt.xlabel('Claim', fontsize=20)\nplt.ylabel('Frequency [%]', fontsize=20)\nax.set_ylim(top=700000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a204dad032edcc601817e35d53cde2205a792db"},"cell_type":"markdown","source":"0이 너무 많아서 단순히 분할하여 훈력을 진행한다면 불공정한 결과가 나올 수 있다. 때문에 반드시 표본추출을 행하여 함."},{"metadata":{"trusted":true,"_uuid":"e4f1e9eb9167589ec546d516333d08903b23f26d"},"cell_type":"code","source":"print('Id is unique.') if train.id.nunique() == train.shape[0] else print('Oh no')\nprint('Train and test sets are distinct.') if len(np.intersect1d(train.id.values, test.id.values)) == 0 else print('Oh no')\nprint('We do not need to worry about missing values.') if train.count().min() == train.shape[0] else print('Oh no')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3bf5129fec6f4f30e5e2caba807acb69e4beab7c"},"cell_type":"code","source":"# null값 확인\ntrain_null = train\ntrain_null = train_null.replace(-1, np.NaN) # -1값을 누락값으로 간주하여 null값으로 대체\n\nmsno.matrix(df=train_null.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"674e9be2238c42c656dec8d7a5ef73944883e393"},"cell_type":"code","source":"test_null = test\ntest_null = test_null.replace(-1, np.NaN)\n\nmsno.matrix(df=test_null.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2158eeaedcc5463792557a28bb785e2faaa1544"},"cell_type":"code","source":"# 널값의 데이터를 포함한 행 추출\ntrain_null = train_null.loc[:, train_null.isnull().any()]\ntest_null = test_null.loc[:, test_null.isnull().any()]\n\nprint(train_null.columns)\nprint(test_null.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa8ed4dcedd087b8f1d8ba6646a560dacc886351"},"cell_type":"code","source":"print('Columns \\t Number of NaN')\nfor column in train_null.columns:\n    print('{}:\\t {}'.format(column,len(train_null[column][np.isnan(train_null[column])])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"580029e94a6f83f082c94d7af4557679b795af73"},"cell_type":"markdown","source":"많은 특징들이 존재함으로 개별적으로 분석해야함"},{"metadata":{"trusted":true,"_uuid":"c3fb1079308fa02f4d95c1e1c9c42dae5dde8816"},"cell_type":"code","source":"# divides all features in to 'bin', 'cat' and 'etc' group.\n\nfeature_list = list(train.columns) #컬럼들을 리스트화함\ndef groupFeatures(features): # groupFeatures함수 정의\n    features_bin = []\n    features_cat = []\n    features_etc = []\n    for feature in features: # 각 특정에 맞는 리스트에 해당 컬럼을 추가하는 과정\n        if 'bin' in feature:\n            features_bin.append(feature)\n        elif 'cat' in feature:\n            features_cat.append(feature)\n        elif 'id' in feature or 'target' in feature:\n            continue\n        else:\n            features_etc.append(feature)\n    return features_bin, features_cat, features_etc\n\nfeature_list_bin, feature_list_cat, feature_list_etc = groupFeatures(feature_list)\n# 리턴 값을 받아옴\n\nprint(\"# of binary feature : \", len(feature_list_bin))\nprint(\"# of categorical feature : \", len(feature_list_cat))\nprint(\"# of other feature : \", len(feature_list_etc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ad521892165e6e637f3e1558097b5642115ec4c"},"cell_type":"code","source":"def TrainTestHistogram(train, test, feature): # TrainTestHistogram 함수 정의. 히스토그램 생성 함수\n    fig, axes = plt.subplots(len(feature), 2, figsize=(10, 40))\n    fig.tight_layout() # 글자 안 겹치게\n\n    left  = 0  \n    right = 0.9   \n    bottom = 0.1   \n    top = 0.9     \n    wspace = 0.3 \n    hspace = 0.7 \n\n    plt.subplots_adjust(left=left, bottom=bottom, right=right, \n                        top=top, wspace=wspace, hspace=hspace)\n    # 간격 조정\n    \n    count = 0\n    for i, ax in enumerate(axes.ravel()):\n        # ravel : 다차원의 배열을 1차원의 배열로 만들어주는 함수\n        if i % 2 == 0:\n            title = 'Train: ' + feature[count]\n            ax.hist(train[feature[count]], bins=30, normed=False)\n            ax.set_title(title)\n            # \"bis=30\"30개의 막대로 구분, \"normed=False\" 확률밀도가 아닌 빈도로 표시\n        else:\n            title = 'Test: ' + feature[count]\n            ax.hist(test[feature[count]], bins=30, normed=False)\n            ax.set_title(title)\n            count = count + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"766cbb2c4bbf455508c645b5d2020da5c93ee7ba"},"cell_type":"code","source":"TrainTestHistogram(train, test, feature_list_bin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"803d46fdd09d2c189b0e308fa97f1e0a68742ef9"},"cell_type":"code","source":"TrainTestHistogram(train, test, feature_list_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1883bf34bab1f7536a1e87a0445c39d3b2b17f90"},"cell_type":"code","source":"TrainTestHistogram(train, test, feature_list_etc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41a6c741ea9bcf0537e583596720e585205245da"},"cell_type":"markdown","source":"추측 가능한 정보\n    1. train, test 데이터들은 이진접이나 범주형 데이터와 유한 분포를 가짐.\n    2. 각 특정은 train, test가 유사하나 약간의 차이를 가짐\n    \n아래는 특정에 대해 더 자세히 살펴보는 과정이다."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"51d702533aeeaabd1a50e4db67fbe5011bf48e69"},"cell_type":"code","source":"left  = 0  \nright = 0.9    \nbottom = 0.1\ntop = 0.9      \nwspace = 0.3   \nhspace = 0.7\n\nfig, axes = plt.subplots(13, 2, figsize=(10, 40))\nplt.subplots_adjust(left=left, bottom=bottom, right=right, \n                    top=top, wspace=wspace, hspace=hspace)\n\nfor i, ax in enumerate(axes.ravel()):\n    title = 'Train: ' + feature_list_etc[i]\n    ax.hist(train[feature_list_etc[i]], bins=20, normed=True)\n    ax.set_title(title)\n    ax.text(0, 1.2, train[feature_list_etc[i]].head(), horizontalalignment='left',\n            verticalalignment='top', style='italic',\n       bbox={'facecolor':'red', 'alpha':0.2, 'pad':10}, transform=ax.transAxes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1f65a31e805971c8555a2473bb6e961a503c66e"},"cell_type":"markdown","source":"위 그래프들을 보고 연속형 그룹과 이산형 그룹으로 나눌 수 있음"},{"metadata":{"_uuid":"188d309342402fce4aa05cfca5986f564004ddf9"},"cell_type":"markdown","source":"null값 대체"},{"metadata":{"trusted":true,"_uuid":"811274927f052ff768617104b6d4d03c0de10251"},"cell_type":"code","source":"etc_ordianal_features = ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01',\n                    'ps_reg_02', 'ps_car_11', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03',\n                    'ps_calc_04', 'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08',\n                    'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13',\n                    'ps_calc_14']\n\netc_continuous_features = ['ps_reg_03', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']\n\ntrain_null_columns = train_null.columns\ntest_null_columns = test_null.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf5f89915fd3faeaadf561514e48d2c8666c516d"},"cell_type":"code","source":"for feature in train_null_columns:\n    if 'cat' in feature or 'bin' in feature:\n        train_null[feature].fillna(train_null[feature].value_counts().idxmax(), inplace=True)\n        # 사용빈도가 가장 높은 수로 대체, 실수형 데이터가 안 나오게 할라고\n    elif feature in etc_continuous_features:\n        train_null[feature].fillna(train_null[feature].median(), inplace=True)\n        # 중앙값으로 대체\n    elif feature in etc_ordianal_features:\n        train_null[feature].fillna(train_null[feature].value_counts().idxmax(), inplace=True)\n    else:\n        print(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bec82cb7227f6d8cd29512af0666b5196391f9e5"},"cell_type":"code","source":"for feature in test_null_columns:\n    if 'cat' in feature or 'bin' in feature:\n        test_null[feature].fillna(test_null[feature].value_counts().idxmax(), inplace=True)\n    elif feature in etc_continuous_features:\n        test_null[feature].fillna(test_null[feature].median(), inplace=True)\n    elif feature in etc_ordianal_features:\n        test_null[feature].fillna(test_null[feature].value_counts().idxmax(), inplace=True)\n    else:\n        print(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c897f790e9db842a883e07027fdbf2c968bc369"},"cell_type":"code","source":"msno.matrix(df=train.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))\n# null값이 없어짐~","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d3924cbd8595440643213d3cd8ab18ac1ae6b32"},"cell_type":"code","source":"msno.matrix(df=train.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))\n# null값이 없어짐~","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2932b393fb53248253a9d2cba59bcbb30e91f9e3"},"cell_type":"markdown","source":"범주형 데이터를 위해 pd.get_dummy() 함수를 이용하여 One-hot encoding을 진행한다. 가변수화 한다고도 함.\n\n**One-hot encoding**\n \n     범주형 데이터를 기계가 이해할 수 있는 형태의 뎅터로 변환해 주는 것으로, 해당되는 하나의 데이터만 1로 변경해주고 나머지 데이터는 0으로 채워주는 것을 의미한다.\n \n     예를 들어 과일 데이터에 사과, 배, 사과가 있다고 하면 각각의 과일을 컬럼으로 만드어주고 해당되는 과일만 1로 표기해 주는 것을 말한다.\n    <ex>\n    before                    after\n      과일                       과일 |사과 | 배\n      ----                      ---------------  \n      사과                       사과 | 1  | 0\n      ____                      ---------------\n       배                         배  | 0  | 1\n      ----                      ---------------\n      사과                       사과 | 1  | 0\n     \n    \n    \nget_dummy()는 위와 같은 One-hot encoding을 해주는 함수이다\n    "},{"metadata":{"trusted":true,"_uuid":"fda613c2c118489923cd36a2efa9109da48e990c"},"cell_type":"code","source":"def oneHotEncode_dataframe (df, features): \n    # oneHotEncode_dataframe 함수 정의\n    for feature in features:\n        temp_onehot_encoded = pd.get_dummies(df[feature])\n        # df 데이터의 feature 행을 One-hot encoding 한다.\n        column_names = [\"{}_{}\".format(feature, x) for x in temp_onehot_encoded.columns]\n        # 컬럼의 이름을 feature_x의 형식으로 지정하는 데,이때 x는 temp_onehot_encoded.columns에 따른다.\n        temp_onehot_encoded.columns = column_names\n        # 컬럼명을 변경한다.\n        df = df.drop(feature, axis=1)\n        df = pd.concat([df, temp_onehot_encoded], axis=1) \n        # 기존에 있던 특성 행을 지우고 세분화한 정보를 붙인다.\n        # 세분화된 정보를 붙였기떄문에 기본의 특성을 필요없음\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de4e1d860139c76adcf145c384c52c4f5823c5ab"},"cell_type":"code","source":"train = oneHotEncode_dataframe(train, feature_list_cat)\ntest = oneHotEncode_dataframe(test, feature_list_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"808dd21d895dd9b23b1d0940022fb002fcb89386"},"cell_type":"code","source":"train.head()\n#아래의 데이터를 확인해보면 \"ps_car_11_cat_70\" 과 같이 인코딩된 행들을 찾아볼 수 있음","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c01f4203283ac2028869cf43ec923ab47a763fba"},"cell_type":"markdown","source":"[](http://)Prediction with xgboost"},{"metadata":{"trusted":true,"_uuid":"ba60c80a8aabc5382db55eca29929c12656cc517"},"cell_type":"code","source":"def gini(actual, pred, cmpcol = 0, sortcol = 1):\n    # 의사결정트리에서 엔트로피 대신 트리를 생성하는 기준으로 사용하는 지니계수에 대한 함수\n    # 지니계수 : 전체 중에서 특정 class에 속하는 관측치의 비율을 모두 제외한 값으로 불순도를 나타냄\n    assert( len(actual) == len(pred) )\n    # 예측값과 실측값의 길이가 같지않다면 AsertionError를 발생시킴\n    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n    # asarray(a, dtype, order) : 입력을 배열 형태로 변환해주는 함수\n    # a: 배열로 변환할 수 있는 데이터. 이때의 np.c_는 actual와 pred, actual 길이를 균등하게 나눈 값을 세로로 붙여서 이차원 배열을 만든다.\n    # array함수와 유사하나 입력 데이터가 이미 배열 형태라면 새로운 배열을 생성하지 않는 것이 특징.\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    # all[:,2](np.arange(len(actual)))을 기본 정렬 기준으로, all[:,1](pred)을 보조 정렬 기준으로. 이떄 all[:,1]는 내림차순\n    totalLosses = all[:,0].sum()\n    # 실측값을 모두 더함\n    giniSum = all[:,0].cumsum().sum() / totalLosses\n    # 식츨값의 누적합의 합을 실측값의 합으로 나눔\n    \n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n \ndef gini_normalized(a, p): # 지니계수 정규화 함수\n    return gini(a, p) / gini(a, a)\n\ndef gini_xgb(preds, dtrain): \n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10b04a74ef28e7f0ef4fd9308b6e32eaad8205d9"},"cell_type":"markdown","source":"stratified shuffle split\n\nstratified shuffle split은 train, test 세트의 분할 데이터들의 인덱스를 제공한다. 각 분할등급의 빈도수는 모든 데이터 세트의 분배와 동일한 비율을 가진다. 이 방법을 사용하면 train, test 시 불균형 표본 추출 문제(해당 데이터에서는 Target 값이 불균형했음)를 방지할 수 있다. \n\n과정\n\n    1. 분류자 선택. 이 커널의 경우 xgboost 사용\n    2. 매개변수 설정 > 이때 좋은 결과를 위해서는 최적화 작업 필요 \n    3. 각 분류자를 이용하여 stratified shuffle split를 수행한다.\n    4. 예측값의 평균을 얻는다\n   \n참고 : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShu"},{"metadata":{"trusted":true,"_uuid":"f9162eb27363dd24cdc4b573dd4ed49381c69487"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit # 추가 해야됨\nn_split = 3\nSSS = StratifiedShuffleSplit(n_splits=3, test_size=0.5, random_state=1989)\n# n_split : 반복횟수, random_state : 난 수 생성 시드 설정","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b19f2a0f1940a7930ae23c9eac49ffc3c95b6e4c"},"cell_type":"code","source":"# 매개변수를 최적화함\nparams = {\n    'min_child_weight': 10.0,\n    'max_depth': 7,\n    'max_delta_step': 1.8,\n    'colsample_bytree': 0.4,\n    'subsample': 0.8,\n    'eta': 0.025,\n    'gamma': 0.65,\n    'num_boost_round' : 700\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f5f777dba4c801cadd1ab51b4bb1c365187aee9"},"cell_type":"code","source":"X = train.drop(['id', 'target'], axis = 1).values\ny = train.target.values\ntest_id = test.id.values\ntest = test.drop('id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a384404a5c7ba5cf06bff33670756d2134983214"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['id'] = test_id\nsub['target'] = np.zeros_like(test_id)\n# zeros_like : 지정된 배열과 동일한 모양과 유형으로 0 배열 반환.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"792348370746607577046d02a7ded3aa78256b71"},"cell_type":"code","source":"SSS.get_n_splits(X, y)\nprint(SSS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90cad1cf8eb71f22706537ced08a8318f4b69e5e"},"cell_type":"code","source":"for train_index, test_index in SSS.split(X, y):\n    print(\"TRAIN: \", train_index, \"TEST: \", test_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"09d1208f67cba35af4339590df5d4f00e9aff01d"},"cell_type":"code","source":"for i, (train_index, test_index) in enumerate(SSS.split(X, y)):\n    print('------# {} of {} shuffle split------'.format(i + 1, n_split))\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = y[train_index], y[test_index]\n    \n    #분할된 데이터를 XGBost 형식으로 변환\n    d_train = xgb.DMatrix(X_train, y_train)\n    d_valid = xgb.DMatrix(X_valid, y_valid)\n    d_test = xgb.DMatrix(test.values)\n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\n    # Train the model! \n    model = xgb.train(params, d_train, 2000, watchlist, \n                      early_stopping_rounds=100, feval=gini_xgb, maximize=True, verbose_eval=100)\n    # d_train : 학습 데이터의 레이블\n    # 2000 : 반복횟수\n    # watchlist : 훈련 중에 검증 성능으로 평가되는 목록\n    # verbose_eval : 검증 세트의 평가 지횩 주어진 단계마다 출력됨\n    # 참고 : https://xgboost.readthedocs.io/en/latest/python/python_api.html\n    \n    print('------# {} of {} prediction------'.format(i + 1, n_split))\n    # Predict on our test data\n    p_test = model.predict(d_test)\n    sub['target'] = sub['target'] + p_test/n_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98cd2c52da15fa2374acaf106d8faa09f731eaee"},"cell_type":"code","source":"sub.to_csv('stratifiedShuffleSplit_xgboost.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd8ba2549cb5ce0d07a1488b37d17b4aa469d7cb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}