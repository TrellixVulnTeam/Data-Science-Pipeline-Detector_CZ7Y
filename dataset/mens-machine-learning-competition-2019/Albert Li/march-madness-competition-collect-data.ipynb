{"cells":[{"metadata":{"_uuid":"209ed7d36781a0fc2d868777b199910c5239741a"},"cell_type":"markdown","source":"**Getting Data**\n\nWe will first utilize the data provided by Kaggle. \n\nDetailed data descriptions can be found here:\n\nhttps://www.kaggle.com/c/mens-machine-learning-competition-2019/data\n\nLet's first load the necessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n# Importing useful packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa535fde210fd1660ea602761ffccd6ecfcc4bf3"},"cell_type":"markdown","source":"Input data files are available in the \"../input/\" directory. \n\nThe list of files can be found also on the right side panel, under \"Draft Environment\""},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e0aa97d197e116e384bdf680cf2adca20c284289"},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# List the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7adb1603901300c73195d7cf34f1a6ca2f9c08f2"},"cell_type":"markdown","source":"Many files are in .zip format, however, Kaggle kernel will read the csv directly from the zip files.\n\nLet's read a couple files into Pandas DataFrame, a popular data strucutre for analytics. Use the built in .head() function to examine the first few records."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"# Use function .read_csv to read CSV files into DataFrame\n\n# Read game results since 1985\ndf_compact = pd.read_csv('../input/datafiles/RegularSeasonCompactResults.csv')\ndf_compact.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5fbae12433056b81ead75dab573753788ed0b9e6"},"cell_type":"code","source":"# Read team info\ndf_teams = pd.read_csv('../input/datafiles/Teams.csv')\ndf_teams['TeamName'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc7d2fc08732a11b2911b8fa69cc2fe95d74aa7a","scrolled":true},"cell_type":"code","source":"# Read play by play data for year 2018\nplay2018 = pd.read_csv('../input/playbyplay_2018/Events_2018.csv')\nplay2018.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5abbcc75e312c1a093a80f080aa3aeceae522e8"},"cell_type":"code","source":"# Read tournament seed data\ndf_seeds = pd.read_csv('../input/datafiles/NCAATourneySeeds.csv')\ndf_seeds.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef04c0b00cd5d72deb43e3c49fdf25dfa4566ceb"},"cell_type":"markdown","source":"Feel free to load additional data and check out what they contain\n"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d1cfe0eaf8e6e11cab842852f9680e6533098102"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb74c719c0ab4868b5b0240ccea0587292779a98"},"cell_type":"markdown","source":"Here are some useful ways to inspect the data\n\n .shape  # review the number of rows and columns for the dataframe\n\n.dtypes  # review the data type for each column\n\n.nunique()  # get the unique count of a variable\n"},{"metadata":{"trusted":true,"_uuid":"5b38e9bed302e998dc087a6f9aaf9d1522bcb751"},"cell_type":"code","source":"# Check the data size for the dataframe for teams\ndf_teams.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75918ca6e1a0ea9f693efca525f147a4c4dda427"},"cell_type":"code","source":"# Check the data type for each columns in teams data\ndf_teams.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"515edd0e087f9f66b163bb78cea4092ebec9fedd"},"cell_type":"code","source":"# Count of unique values of each columns in the teams data. One can see that there are 366 unique teams\ndf_teams.nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e09909c68f17c759b84049e243052c068fb403f3"},"cell_type":"markdown","source":"Sometimes there exist files that share the same naming conventions and it's ideal to load these files into a single table. For the Play by Play data, it's easy to see that in each year's data there are two csv files: Events and Players. And the naming convention is very structured with only the year that updates. We can utilize the following scripts to reach file and concatenate them into a single table."},{"metadata":{"trusted":true,"_uuid":"c1a3f6e1a25f4f41930d8e8a825214e793842b1d","scrolled":false},"cell_type":"code","source":"df_pbp = pd.DataFrame()\nfor i in range(8):\n    df = pd.read_csv('../input/playbyplay_201' + str(i) + '/Events_201' + str(i) + '.csv')\n    df_pbp = df_pbp.append(df)\n    print(\"Cumulative data size for year 201\" + str(i) + \": \" + str(df_pbp.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea08e0f2548ba2502b7d70f5c6f44526f4c89be0"},"cell_type":"markdown","source":"**Data Wrangling**\n\n"},{"metadata":{"_uuid":"04690533ba286c6ce258a9e2244edc2fd22ea4b8"},"cell_type":"markdown","source":"Now we want to prepare the data in a way that we can build a naive model with. The seed number or ranking in the tournament region seems to be a good predictor for how likely the team will win. So let's start preparing the data with the seed number in mind.\n\nThe first thing we need is to clean the seed column. In the original data, the \"Seed\" column has a \"W\" attached to the front of the actual seed number. We can run the following script to remove the \"W\" character and convert the seed data into integers. "},{"metadata":{"trusted":true,"_uuid":"9615b1e4eb55b257ed184aca129be0b16bc11e13"},"cell_type":"code","source":"df_seeds['seed_int'] = df_seeds['Seed'].apply(lambda x: int(x[1:3]))\ndf_winseeds = df_seeds.loc[:, ['TeamID', 'Season', 'seed_int']].rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\ndf_lossseeds = df_seeds.loc[:, ['TeamID', 'Season', 'seed_int']].rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\ndf_temp = pd.merge(left=df_compact, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\ndf_concat = pd.merge(left=df_temp, right=df_lossseeds, on=['Season', 'LTeamID'])\n\ndf_concat.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da79376679eca99bc6d099468cb0b017c9f83245"},"cell_type":"markdown","source":"Then we want to create a calculated field named \"SeedDiff\", which is the difference between winning team's seed number and losing team's seed number"},{"metadata":{"trusted":true,"_uuid":"59e0f50dff2a98dee17483d887aa300db60f75d1"},"cell_type":"code","source":"df_concat['SeedDiff'] = df_concat.WSeed - df_concat.LSeed\ndf_concat.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef6993ad98267e5e30e7f1095cc1060fb44806e5"},"cell_type":"markdown","source":"Lastly, we need to create our target variable for this naive model. Here we seperate the wins and losses, then assign 1 to wins and 0 to losses."},{"metadata":{"trusted":true,"_uuid":"a0372d61eab67250c3a26e5ce972da0e72c101ac","scrolled":true},"cell_type":"code","source":"df_wins = pd.DataFrame()\ndf_wins['SeedDiff'] = df_concat['SeedDiff']\ndf_wins['Result'] = 1\n\ndf_losses = pd.DataFrame()\ndf_losses['SeedDiff'] = -df_concat['SeedDiff']\ndf_losses['Result'] = 0\n\ndf_predictions = pd.concat((df_wins, df_losses))\ndf_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfc299983913194ff187fc2eecfe249932c9b3f6"},"cell_type":"markdown","source":"Use shuffle function from sklearn to construct the training data"},{"metadata":{"trusted":true,"_uuid":"4450da9acce2b268b9e1337f4098a077681421aa"},"cell_type":"code","source":"X_train = df_predictions.SeedDiff.values.reshape(-1,1)\ny_train = df_predictions.Result.values\nX_train, y_train = shuffle(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d44ce4a1e1bc3449c2435291612778560df0f9d"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fa4a578f3e112031cc04fec95bd615501dced99"},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"625a80e3634c644d24579b0b99a40def18b33c14"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}