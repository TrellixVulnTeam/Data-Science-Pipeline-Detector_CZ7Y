{"cells":[{"metadata":{"_uuid":"17ffdcd092ac283a89f50f39254b1df39ae12b5a"},"cell_type":"markdown","source":"# Overview ##\n\nThis notebook creates numerous models, and will choose the best model for predicting MM brackets. The models are trained on the seed differences between teams and season average metric differences (e.g., FG%, PPG, Opp. PPG) between teams. \n\nNote that the model is trained entirely on data from 2003-2018 and their known outcomes. The resulting classifier is then used on 2019 data to generate predictions for this year's tournament on March 11."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import svm\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2c836f60f53b1f0b64453cadf1e96f03cd98a67"},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/datafiles\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67ce5510921041eea2ae326bb4d6d5ede23604d3"},"cell_type":"markdown","source":"## Load the training data ##\nWe're keeping it relatively simple & using only a handful of files for this model: the tourney seeds, tourney results, and a detailed results dataset to calculate our other features."},{"metadata":{"trusted":true,"_uuid":"b7e4fb85b937d5850b0a18f8b253488c32c29a5d"},"cell_type":"code","source":"data_dir = '../input/datafiles/'\ndf_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\ndf_tour = pd.read_csv(data_dir + 'NCAATourneyCompactResults.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16741e2d16cca9eb10509a02464844f45f536424"},"cell_type":"code","source":"#Identify the seeds of the winning and losing teams\ndf_seeds['WTeamID'] = df_seeds['TeamID']\ndf_seeds['LTeamID'] = df_seeds['TeamID']\n\ndf_tour = pd.merge(df_tour, df_seeds.loc[:,['Season','Seed','WTeamID']], how = 'left', on = ['Season','WTeamID'])\ndf_tour = df_tour.rename(index=str, columns = {'Seed':'WSeed'})\ndf_tour = pd.merge(df_tour, df_seeds.loc[:,['Season','Seed','LTeamID']], how = 'left', on = ['Season','LTeamID'])\ndf_tour = df_tour.rename(index=str, columns = {'Seed':'LSeed'})\n\n#Get the seed number from the Seed columns\ndef remove_region(row):\n    return int(row[1:3])\n\ndf_tour['WSeedRank'] = df_tour['WSeed'].apply(remove_region)\ndf_tour['LSeedRank'] = df_tour['LSeed'].apply(remove_region)\n\n#Find upsets, defined as a seed difference of greater than 4\ndf_tour['SeedDiff'] = df_tour['LSeedRank'] - df_tour['WSeedRank']\ndf_tour['Upset'] = False\ndf_tour.loc[(df_tour['SeedDiff'] < -4),'Upset'] = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"945d0e434af0b657ee98069bd9562ec3bf729970"},"cell_type":"code","source":"#Determine the probability of each type of upset occuring\n#First, find the counts of the upsets that have occured in previous seasons\nupset_freqs = df_tour.loc[(df_tour['Upset'] == True),['WSeedRank',\n                                       'LSeedRank',\n                                       'SeedDiff',\n                                       'Upset']].groupby(['WSeedRank',\n                                       'LSeedRank',\n                                       'SeedDiff']).count().sort_values('Upset',\n                                                                       ascending = False).reset_index()\n#Divide upset counts by number of seasons x days x regions to ger probability\nupset_freqs['Upset_prob'] = upset_freqs['Upset']/(len(df_tour['Season'].unique()) * len(df_tour['DayNum'].unique())*4)\n\n#Add upset information to df_tour\ndf_tour = pd.merge(df_tour, upset_freqs, how = 'left', on = ['WSeedRank',\n                                                            'LSeedRank',\n                                                            'SeedDiff'])\ndf_tour = df_tour.drop(['Upset_x','Upset_y'], axis = 1)\ndf_tour['Upset_prob'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ff4dd7a8f247ec64de6dd8824ea675dd0db405a"},"cell_type":"code","source":"upset_freqs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0971c949ac558e99a6715f140d136e10eba7c81"},"cell_type":"code","source":"df_tour.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06d5f8a2c47f63aa6b32019e5a358308bb5fb886"},"cell_type":"code","source":"#Investigating score differences for upsets - not sure this information is useful\n#df_tour['Score_Diff'] = df_tour['WScore'] - df_tour['LScore']\n#df_tour.loc[(df_tour['Upset_prob']>0),['WSeedRank',\n#                                      'LSeedRank',\n#                                      'SeedDiff',\n#                                      'Upset_prob',\n#                                      'Score_Diff']].groupby([\n#                                      'WSeedRank',\n#                                      'LSeedRank',\n#                                      'SeedDiff',\n#                                      'Upset_prob']).agg(['min',\n#                                                          'max',\n#                                                          'mean',\n#                                                          'std']).sort_values('Upset_prob',\n#                                                                        ascending = False).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab1b18791586f06c3565b2cb3be42a8c8cb8fa41"},"cell_type":"code","source":"# We load detailed season data to calculate season average statistics for each team\ndf_reg_season_detailed = pd.read_csv(data_dir + 'RegularSeasonDetailedResults.csv')\ndf_reg_season_detailed.drop(labels=['WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WDR', 'WAst', \n               'WStl', 'WBlk', 'WPF', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LDR', \n                'LAst', 'LStl', 'LBlk', 'LPF', 'WLoc', 'NumOT', 'WOR', 'LOR'], \n                            inplace=True, axis=1)\ndf_reg_season_detailed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"877f2a2a2ed70b145c76bb77b2d3809161b32473"},"cell_type":"markdown","source":"## Create a new data frame with season average metrics ##\nWe are creating a new data frame with season average statistics for each team for use as features in our machine learning algorithm."},{"metadata":{"trusted":true,"_uuid":"ce1f93be3a1c685c03d9914a6a4c3b9eb8e57c6c"},"cell_type":"code","source":"yearList = range(2003,2019) #2003 is the first year we have detailed data for\nteams_pd = pd.read_csv(data_dir + 'Teams.csv')\nteamIDs = teams_pd['TeamID'].tolist()\n\nrows = list()\n\nfor year in yearList:\n    for team in teamIDs:\n        df_curr_season = df_reg_season_detailed[df_reg_season_detailed.Season == year]       \n\n        df_curr_team_wins = df_curr_season[df_curr_season.WTeamID == team]\n        df_curr_team_losses = df_curr_season[df_curr_season.LTeamID == team]\n        \n        # no games played by them this year.. skip (current team didn't win or lose any games)\n        if df_curr_team_wins.shape[0] == 0 and df_curr_team_losses.shape[0] == 0:\n            continue;\n        \n        df_winteam = df_curr_team_wins.rename(columns={'WTeamID':'TeamID', 'WFGM':'FGM', \n                    'WFGA':'FGA', 'WTO':'TO', 'WScore':'Score', 'LScore':'OppScore'})\n        \n        # drop all columns except the ones we are using\n        df_winteam = df_winteam[['TeamID', 'FGM', 'FGA', 'TO', 'Score', 'OppScore']]\n\n        df_loseteam = df_curr_team_losses.rename(columns={'LTeamID':'TeamID', 'LFGM':'FGM',\n                    'LFGA':'FGA', 'LTO':'TO', 'LScore':'Score', 'WScore':'OppScore'})\n        # drop all columns except the ones we are using\n        df_loseteam = df_loseteam[['TeamID', 'FGM', 'FGA', 'TO', 'Score', 'OppScore']] \n\n        # dataframe w/ all relevant stats from current year for current team\n        df_curr_team = pd.concat((df_winteam, df_loseteam)) \n\n        wins = df_winteam.shape[0]\n        FGPercent = df_curr_team['FGM'].sum() / df_curr_team['FGA'].sum()\n        TurnoverAvg = df_curr_team['TO'].sum() / len(df_curr_team['TO'].values)\n        PPG = df_curr_team['Score'].sum() / len(df_curr_team['Score'].values)\n        OppPPG = df_curr_team['OppScore'].sum() / len(df_curr_team['OppScore'].values)\n\n        # collect all data in rows list first for effeciency\n        rows.append([year, team, wins, FGPercent, TurnoverAvg, PPG, OppPPG])\n\ndf_training_data = pd.DataFrame(rows, columns=['Season', 'TeamID', 'Wins', 'FGPercent', \n                                               'TOAvg', 'PPG', 'OppPPG'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50e969f4ebc60b19bf1ad6f7c089407869bfc1e4"},"cell_type":"markdown","source":"Here we show the contents of our seeding and tournament results data frames. These, combined with the stats calculated above (df_training_data) will form the final X_train matrix."},{"metadata":{"trusted":true,"_uuid":"0d5e175e4fa3b742a47c4e82e7dbf0aae75f739f"},"cell_type":"code","source":"df_seeds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bebec521f0803ad33c8396825c21e2780ff10a5"},"cell_type":"code","source":"df_tour.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"529ee0c46da964e2257c0c2988bbb5203ba3fa68"},"cell_type":"markdown","source":"First, we'll simplify the datasets to remove the columns we won't be using and convert the seedings to the needed format (stripping the regional abbreviation in front of the seed)."},{"metadata":{"trusted":true,"_uuid":"a79fdc52b33075a00ba41aaebcaba245e8c2dfe2"},"cell_type":"code","source":"def seed_to_int(seed):\n    #Get just the digits from the seeding. Return as int\n    s_int = int(seed[1:3])\n    return s_int\ndf_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\ndf_seeds.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\ndf_seeds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3fc3fcb729f0bef03a5213150ed0e2cadeee72a"},"cell_type":"code","source":"df_tour.drop(labels=['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], inplace=True, axis=1)\ndf_tour.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2f63f6cbd5571567b1121fb86bb542465336e57"},"cell_type":"markdown","source":"Merge seed for each team\nMerge the Seeds with their corresponding TeamIDs in the compact results dataframe."},{"metadata":{"trusted":true,"_uuid":"e7c89d97043cff5f11402097a5f4330260faf2a3"},"cell_type":"code","source":"df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\ndf_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\ndf_dummy = pd.merge(left=df_tour, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\ndf_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'LTeamID'])\ndf_concat['SeedDiff'] = df_concat.WSeed - df_concat.LSeed\ndf_concat.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c60ea99eb413669af6c56f7a6a60602e944fe617"},"cell_type":"markdown","source":"Now we'll combine our advanced season statistics and merge them into the df_concat data frame."},{"metadata":{"trusted":true,"_uuid":"dc14f3f615ffad7a3f099b3933c48b9da4adc0eb"},"cell_type":"code","source":"df_winstats = df_training_data.rename(columns={'TeamID':'WTeamID', 'FGPercent':'WFGPercent', \n                            'TOAvg':'WTOAvg', 'PPG':'WPPG', 'OppPPG':'WOppPPG', 'Wins':'WWins'})\ndf_lossstats = df_training_data.rename(columns={'TeamID':'LTeamID', 'FGPercent':'LFGPercent',\n                            'TOAvg':'LTOAvg', 'PPG':'LPPG', 'OppPPG':'LOppPPG', 'Wins':'LWins'})\ndf_dummy = pd.merge(left=df_concat, right=df_winstats, on=['Season', 'WTeamID'])\ndf_concat = pd.merge(left=df_dummy, right=df_lossstats, on=['Season', 'LTeamID'])\ndf_concat['FGPercentDiff'] = df_concat.WFGPercent - df_concat.LFGPercent\ndf_concat['TOAvgDiff'] = df_concat.WTOAvg - df_concat.LTOAvg\ndf_concat['PPGDiff'] = df_concat.WPPG - df_concat.LPPG\ndf_concat['OppPPGDiff'] = df_concat.WOppPPG - df_concat.LOppPPG\ndf_concat['WWinMargin'] = df_concat.WPPG - df_concat.WOppPPG\ndf_concat['LWinMargin'] = df_concat.LPPG - df_concat.LOppPPG\ndf_concat['WinMarginDiff'] = df_concat.WWinMargin - df_concat.LWinMargin\ndf_concat['WinDiff'] = df_concat.WWins - df_concat.LWins\n # drop all columns except the ones we are using\ndf_concat = df_concat[['Season', 'WTeamID', 'LTeamID', 'SeedDiff', 'FGPercentDiff', \n                       'TOAvgDiff', 'PPGDiff', 'OppPPGDiff', 'WinMarginDiff', 'WinDiff']]\n\n# Note: We can have SeedDiff == 0 due to the First Four (68 teams)! Also Final Four onwards!\n# Note: Pandas merges tossed out data from before 2003!\ndf_concat.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46cfd3a0ccbe84b1fb9cf37da84bbed1c840863a"},"cell_type":"markdown","source":"Now we'll create a dataframe that summarizes wins & losses along with their corresponding seed differences, FG% differences, and turnover differences. This is the meat of what we'll be creating our model on."},{"metadata":{"trusted":true,"_uuid":"5d5def76178737b47951ad8da8dc5d999f11a3f8"},"cell_type":"code","source":"# We create positive and negative versions of the data so the \n# supervised learning algorithm has sample data of each class to classify\n\ndf_wins = pd.DataFrame()\ndf_wins['SeedDiff'] = df_concat['SeedDiff']\ndf_wins['FGPercentDiff'] = df_concat['FGPercentDiff']\ndf_wins['TOAvgDiff'] = df_concat['TOAvgDiff']\ndf_wins['PPGDiff'] = df_concat['PPGDiff']\ndf_wins['OppPPGDiff'] = df_concat['OppPPGDiff']\ndf_wins['WinMarginDiff'] = df_concat['WinMarginDiff']\ndf_wins['WinDiff'] = df_concat['WinDiff']\ndf_wins['Result'] = 1\n\ndf_losses = pd.DataFrame()\ndf_losses['SeedDiff'] = -df_concat['SeedDiff']\ndf_losses['FGPercentDiff'] = -df_concat['FGPercentDiff']\ndf_losses['TOAvgDiff'] = -df_concat['TOAvgDiff']\ndf_losses['PPGDiff'] = -df_concat['PPGDiff']\ndf_losses['OppPPGDiff'] = -df_concat['OppPPGDiff']\ndf_losses['WinMarginDiff'] = -df_concat['WinMarginDiff']\ndf_losses['WinDiff'] = -df_concat['WinDiff']\ndf_losses['Result'] = 0\n\ndf_predictions = pd.concat((df_wins, df_losses))\ndf_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4b1510d9cd31ba749e57907df9143982b5ee2d2"},"cell_type":"code","source":"X_train = [list(a) for a in zip(df_predictions.SeedDiff.values, df_predictions.FGPercentDiff.values, \n                                df_predictions.TOAvgDiff.values, df_predictions.PPGDiff.values,\n                                df_predictions.OppPPGDiff.values, df_predictions.WinMarginDiff.values,\n                                df_predictions.WinDiff.values)]\nX_train = np.array(X_train)\ny_train = df_predictions.Result.values\nX_train, y_train = shuffle(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0fc3a9e6e6b0df61f32bad62d0acb8b0655efb6"},"cell_type":"markdown","source":"Train the model\nTrain the a variety of models. Tune the hyperparameters for each algorithm and perform cross validation. Logistic regression and SVC perform the best."},{"metadata":{"trusted":true,"_uuid":"1bede1e8452b323d5eb7b9cc6072398db02663dc"},"cell_type":"code","source":"# Neural Network\n# params = {'hidden_layer_sizes': [(256,), (512,), (128, 256, 128,)]}\n# mlp = MLPClassifier(learning_rate='adaptive')\n# clf = GridSearchCV(mlp, params, scoring='neg_log_loss', cv = 5)\n# clf.fit(X_train, y_train)\n# print('Best log_loss Multi Layer Perceptron Classifier: {}'.format(clf.best_score_))\n\n# Gradient Boosted Classifier\nGBC = GradientBoostingClassifier()\nparam_grid_GBC = {\n    \"n_estimators\" : [100],\n    \"learning_rate\" : [0.1, 0.05, 0.02, 0.01],\n    \"max_depth\" : [1,2,3],\n    \"min_samples_leaf\" : [1,3,5],\n    \"max_features\" : [1.0, 0.3, 0.1]\n}\nclf = GridSearchCV(GBC, param_grid_GBC, scoring='neg_log_loss', cv = 3)\nclf.fit(X_train, y_train)\nprint('Best log_loss Gradient Boosting Classifier: {}'.format(clf.best_score_))\n\n# Random Forest Classifier\nRFC = RandomForestClassifier()\nparam_grid_RFC = { \n    'n_estimators': [60, 120, 240],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\nclf = GridSearchCV(RFC, param_grid_RFC, scoring='neg_log_loss', cv = 3)\nclf.fit(X_train, y_train)\nprint('Best log_loss Random Forest Classifier: {}'.format(clf.best_score_))\n\n# K Nearest Neighbors Classifier\nknn = KNeighborsClassifier()\nk = np.arange(80)+1\nparameters = {'n_neighbors': k}\nclf = GridSearchCV(knn, parameters, scoring='neg_log_loss', cv = 3)\nclf.fit(X_train, y_train)\nprint('Best log_loss K-Nearest Neighbors Classifier: {}'.format(clf.best_score_))\n\n# SVC\nSVC = svm.SVC(probability=True)\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\ntuned_parameters_preselected = [{'kernel': ['linear'], 'C': [10]}]\nclf = GridSearchCV(SVC, tuned_parameters_preselected, scoring='neg_log_loss', cv = 3)\nclf.fit(X_train, y_train)\nprint('Best log_loss Support Vector Classification: {}'.format(clf.best_score_))\n\n# Logistic Regression\nlogreg = LogisticRegression(solver = 'lbfgs')\nparams = {'C': np.logspace(start=-15, stop=15, num=31)} # {C: array[1^-15 , 1^-14, ... 1^15] }\nclf = GridSearchCV(logreg, params, scoring='neg_log_loss', refit=True, cv = 3) #sklearn model selection\nclf.fit(X_train, y_train)\nprint('Best log_loss Logistic Regression: {}, with best C: {}'.format(clf.best_score_, \n                                                                      clf.best_params_['C']))\n\n# Logistic Regression is typically the top-performer. We compute it last, and use \n# this classifier to make future predictions.\n\n# SVC is typically a close second. Comment out Logistic Regression to use \n# the SVC classifier instead to make future predictions\n\n# Keep in mind, the provided values are a single representation of our classifier's\n# success! Depending on how the data is shuffled, each run of the program may yield\n# a slightly different classifier (and thus different predictions/success rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15e4ba3376abaeadd89a891d2e99cb53c0a58a7c"},"cell_type":"code","source":"# Create training data with the seeds varying from -10, 10\n# All other features are zeroed out so the plot only shows\n# the relationship between seed and P(team1 wins)\nX1 = np.arange(-10, 10)\nX2 = np.zeros(20, dtype=np.int)\nX = [list(a) for a in zip(X1, X2, X2, X2, X2, X2, X2)]\nX = np.array(X)\n\npreds = clf.predict_proba(X)[:,1]\n\nplt.plot(X1, preds)\nplt.xlabel('Team1 seed - Team2 seed')\nplt.ylabel('P(Team1 will win)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23a085f14be29dd283afc85e6bc12d47b3fa6ae0"},"cell_type":"code","source":"print(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c20617da9fd930f88e0af71e10d52862585dfe7e"},"cell_type":"code","source":"df_sample_sub = pd.read_csv(\"../input/\" + 'SampleSubmissionStage1.csv')\nn_test_games = len(df_sample_sub)\n\ndef get_year_t1_t2(ID):\n    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n    return (int(x) for x in ID.split('_'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70ad893c4c22de88af9170b8f2230fc5bcfdb6b3"},"cell_type":"code","source":"df_sample_sub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0974ebd960ad7d162922b5e6df263dd490c65425"},"cell_type":"markdown","source":"Now we create our X_test matrix with the expected dimensions for the Kaggle contest and fill it with zeroes. Then we loop over the sample submission, and initialize X_test with the correct features for 2018 teams. This X_test matrix is our test set for our previously trained classifier to make predictions about this year's tournament."},{"metadata":{"trusted":true,"_uuid":"5e3b91682bdb722644e37637c406ffe15bbc84a0"},"cell_type":"code","source":"X_test = np.zeros(shape=(n_test_games, 7))\n\nfor ii, row in df_sample_sub.iterrows():\n    year, t1, t2 = get_year_t1_t2(row.ID)\n    t1_seed = df_seeds[(df_seeds.TeamID == t1) & (df_seeds.Season == year)].seed_int.values[0]\n    t2_seed = df_seeds[(df_seeds.TeamID == t2) & (df_seeds.Season == year)].seed_int.values[0]\n    diff_seed = t1_seed - t2_seed\n    X_test[ii, 0] = diff_seed\n    \n    t1_FGPercent = df_training_data[(df_training_data.TeamID == t1) & \n                                    (df_training_data.Season == year)].FGPercent.values[0]\n    t2_FGPercent = df_training_data[(df_training_data.TeamID == t2) & \n                                    (df_training_data.Season == year)].FGPercent.values[0]\n    diff_FGPercent = t1_FGPercent - t2_FGPercent\n    X_test[ii, 1] = diff_FGPercent\n    \n    t1_TOAvg = df_training_data[(df_training_data.TeamID == t1) & \n                                (df_training_data.Season == year)].TOAvg.values[0]\n    t2_TOAvg = df_training_data[(df_training_data.TeamID == t2) & \n                                (df_training_data.Season == year)].TOAvg.values[0]\n    diff_TOAvg = t1_TOAvg - t2_TOAvg\n    X_test[ii, 2] = diff_TOAvg\n    \n    t1_PPG = df_training_data[(df_training_data.TeamID == t1) & \n                              (df_training_data.Season == year)].PPG.values[0]\n    t2_PPG = df_training_data[(df_training_data.TeamID == t2) & \n                              (df_training_data.Season == year)].PPG.values[0]\n    diff_PPG = t1_PPG - t2_PPG\n    X_test[ii, 3] = diff_PPG\n    \n    t1_OppPPG = df_training_data[(df_training_data.TeamID == t1) & \n                                 (df_training_data.Season == year)].OppPPG.values[0]\n    t2_OppPPG = df_training_data[(df_training_data.TeamID == t2) & \n                                 (df_training_data.Season == year)].OppPPG.values[0]\n    diff_OppPPG = t1_OppPPG - t2_OppPPG\n    X_test[ii, 4] = diff_OppPPG\n    \n    X_test[ii, 5] = diff_PPG - diff_OppPPG # Win Margin\n    \n    t1_Wins = df_training_data[(df_training_data.TeamID == t1) & \n                                 (df_training_data.Season == year)].Wins.values[0]\n    t2_Wins = df_training_data[(df_training_data.TeamID == t2) & \n                                 (df_training_data.Season == year)].Wins.values[0]\n    X_test[ii, 6] = t1_Wins - t2_Wins","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70e33cd04a7aeaa4a37c1db4ec7f0aafeabe55af"},"cell_type":"markdown","source":"Make Predictions\nCreate predictions using the logistic regression model we trained."},{"metadata":{"trusted":true,"_uuid":"d773b5e1aecb043685e8835997f8f611c2b7fb05"},"cell_type":"code","source":"preds = clf.predict_proba(X_test)[:,1]\n\nclipped_preds = np.clip(preds, 0.05, 0.95)\ndf_sample_sub.Pred = clipped_preds\ndf_sample_sub.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c62350c0b35d9ca005a824047e5d704031c9cad"},"cell_type":"code","source":" ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}