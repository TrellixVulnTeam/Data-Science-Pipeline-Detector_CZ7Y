{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport os\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nimport warnings\nfrom xgboost import XGBClassifier\nwarnings.filterwarnings(\"ignore\")\nfrom tpot import TPOTClassifier\nimport glob\nprint(os.listdir('../input/daily-rpi-2019'))","execution_count":8,"outputs":[{"output_type":"stream","text":"['WK_Col_02_25_2019.csv', 'WK_Col_03_15_2019.csv', 'WK_Col_02_24_2019.csv', 'WK_Col_02_16_2019.csv', 'WK_Col_03_18_2019.csv', 'WK_Col_03_17_2019.csv', 'WK_Col_02_15_2019.csv', 'WK_Col_03_08_2019.csv', 'WK_Col_02_17_2019.csv', 'WK_Col_03_11_2019.csv', 'WK_Col_03_05_2019.csv', 'full_team_crosswalk.csv', 'WK_Col_02_19_2019.csv', 'teams_to_rpi_teams.csv', 'WK_Col_Aggregate.csv', 'WK_Col_03_12_2019.csv', 'train_master.csv', 'WK_Col_03_04_2019.csv', 'WK_Col_03_14_2019.csv', 'test_stage1_Prepped.csv', 'WK_Col_01_28_2019.csv', 'reg_season_tourney_output_all.csv', 'WK_Col_02_28_2019.csv', 'WK_Col_02_20_2019.csv', 'SampSubmishStage1.csv', 'WK_Col_03_06_2019.csv', 'WK_Col_03_07_2019.csv', 'Stage2_LR_AYX_Predictions.csv', 'WK_Col_02_13_2019.csv', 'WK_Col_03_01_2019.csv', 'WK_Col_03_02_2019.csv', 'WK_Col_02_26_2019.csv', 'WK_Col_03_13_2019.csv', 'train_stage2.csv', 'WK_Col_02_27_2019.csv', 'WK_Col_02_22_2019.csv', 'SampSubmishStage1_Prepped.csv', 'WK_Col_02_23_2019.csv', 'train_stage1_Prepped.csv', 'WK_Col_02_18_2019.csv', 'test_stage2.csv', 'WK_Col_02_01_2019.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Previously (during stage 1) prepped data for using a variety of model evaluation techniques. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"st1_tr =  pd.read_csv(\"../input/daily-rpi-2019/train_stage1_Prepped.csv\")\nst1_tr.head()\nst1_tt =  pd.read_csv(\"../input/daily-rpi-2019/test_stage1_Prepped.csv\")\nst1_tt.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"       PPG_1     OPPG_1   PPG_diff   ...    TOPG_diff  FG3_PCT_diff  target\n0  72.166667  60.722222   0.666667   ...     1.812500      0.065256       0\n1  72.166667  60.722222 -10.083333   ...     1.312500      0.032962       1\n2  67.500000  54.350000  -7.884615   ...     5.950000      0.007948       0\n3  74.400000  56.966667  -3.488889   ...    -0.700000     -0.044865       1\n4  74.400000  56.966667   4.214815   ...     0.485185      0.018812       1\n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PPG_1</th>\n      <th>OPPG_1</th>\n      <th>PPG_diff</th>\n      <th>TOPG_1</th>\n      <th>FG3_PCT_1</th>\n      <th>AOE_1</th>\n      <th>ADE_1</th>\n      <th>AEE_1</th>\n      <th>PPG_2</th>\n      <th>OPPG_2</th>\n      <th>TOPG_2</th>\n      <th>FG3_PCT_2</th>\n      <th>AOE_2</th>\n      <th>ADE_2</th>\n      <th>AEE_2</th>\n      <th>seed_diff</th>\n      <th>OPPG_diff</th>\n      <th>AOE_diff</th>\n      <th>ADE_diff</th>\n      <th>AEE_diff</th>\n      <th>TOPG_diff</th>\n      <th>FG3_PCT_diff</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>72.166667</td>\n      <td>60.722222</td>\n      <td>0.666667</td>\n      <td>13.00</td>\n      <td>0.434109</td>\n      <td>1.158064</td>\n      <td>1.030348</td>\n      <td>2.188413</td>\n      <td>71.500000</td>\n      <td>57.687500</td>\n      <td>11.187500</td>\n      <td>0.368852</td>\n      <td>1.160307</td>\n      <td>1.063350</td>\n      <td>2.223656</td>\n      <td>15</td>\n      <td>3.034722</td>\n      <td>-0.002242</td>\n      <td>-0.033001</td>\n      <td>-0.035243</td>\n      <td>1.812500</td>\n      <td>0.065256</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72.166667</td>\n      <td>60.722222</td>\n      <td>-10.083333</td>\n      <td>13.00</td>\n      <td>0.434109</td>\n      <td>1.158064</td>\n      <td>1.030348</td>\n      <td>2.188413</td>\n      <td>82.250000</td>\n      <td>72.562500</td>\n      <td>11.687500</td>\n      <td>0.401146</td>\n      <td>1.210949</td>\n      <td>0.932917</td>\n      <td>2.143866</td>\n      <td>0</td>\n      <td>-11.840278</td>\n      <td>-0.052884</td>\n      <td>0.097431</td>\n      <td>0.044547</td>\n      <td>1.312500</td>\n      <td>0.032962</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.500000</td>\n      <td>54.350000</td>\n      <td>-7.884615</td>\n      <td>13.95</td>\n      <td>0.398058</td>\n      <td>1.120207</td>\n      <td>1.098966</td>\n      <td>2.219174</td>\n      <td>75.384615</td>\n      <td>62.076923</td>\n      <td>8.000000</td>\n      <td>0.390110</td>\n      <td>1.226225</td>\n      <td>0.992088</td>\n      <td>2.218313</td>\n      <td>13</td>\n      <td>-7.726923</td>\n      <td>-0.106017</td>\n      <td>0.106878</td>\n      <td>0.000861</td>\n      <td>5.950000</td>\n      <td>0.007948</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>74.400000</td>\n      <td>56.966667</td>\n      <td>-3.488889</td>\n      <td>10.30</td>\n      <td>0.366292</td>\n      <td>1.187905</td>\n      <td>1.094870</td>\n      <td>2.282775</td>\n      <td>77.888889</td>\n      <td>62.592593</td>\n      <td>11.000000</td>\n      <td>0.411157</td>\n      <td>1.200499</td>\n      <td>1.035152</td>\n      <td>2.235651</td>\n      <td>-7</td>\n      <td>-5.625926</td>\n      <td>-0.012594</td>\n      <td>0.059719</td>\n      <td>0.047125</td>\n      <td>-0.700000</td>\n      <td>-0.044865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>74.400000</td>\n      <td>56.966667</td>\n      <td>4.214815</td>\n      <td>10.30</td>\n      <td>0.366292</td>\n      <td>1.187905</td>\n      <td>1.094870</td>\n      <td>2.282775</td>\n      <td>70.185185</td>\n      <td>56.814815</td>\n      <td>9.814815</td>\n      <td>0.347480</td>\n      <td>1.120725</td>\n      <td>1.090824</td>\n      <td>2.211548</td>\n      <td>-3</td>\n      <td>0.151852</td>\n      <td>0.067181</td>\n      <td>0.004046</td>\n      <td>0.071227</td>\n      <td>0.485185</td>\n      <td>0.018812</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Processed data for Stage 2 - both the training file of historical tournament data for the period of 2014-2018 containing all NCAA results. And the \"test\" file which is this year's Stage 2 submission file with the processed team level data ready to be predicted on. "},{"metadata":{"trusted":true},"cell_type":"code","source":"st2_tr =  pd.read_csv(\"../input/daily-rpi-2019/train_stage2.csv\")\nst2_tr.head()\n\n\n","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   seed_diff   PPG_diff  OPPG_diff   ...    TOPG_diff  FG3_PCT_diff  target\n0          3  -0.744118  -1.370588   ...     2.258824     -0.032315       1\n1         -8   7.721739   4.615652   ...     0.017391     -0.018063       0\n2         -1   0.678261   5.398261   ...     0.278261      0.007224       1\n3         -4   4.427273   3.010909   ...     1.709091     -0.026811       0\n4        -15  14.410526   9.183158   ...     1.326316     -0.000630       0\n\n[5 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed_diff</th>\n      <th>PPG_diff</th>\n      <th>OPPG_diff</th>\n      <th>AOE_diff</th>\n      <th>ADE_diff</th>\n      <th>AEE_diff</th>\n      <th>TOPG_diff</th>\n      <th>FG3_PCT_diff</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>-0.744118</td>\n      <td>-1.370588</td>\n      <td>-0.041326</td>\n      <td>0.045585</td>\n      <td>0.004259</td>\n      <td>2.258824</td>\n      <td>-0.032315</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-8</td>\n      <td>7.721739</td>\n      <td>4.615652</td>\n      <td>-0.002560</td>\n      <td>0.020684</td>\n      <td>0.018124</td>\n      <td>0.017391</td>\n      <td>-0.018063</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1</td>\n      <td>0.678261</td>\n      <td>5.398261</td>\n      <td>-0.026397</td>\n      <td>-0.049631</td>\n      <td>-0.076028</td>\n      <td>0.278261</td>\n      <td>0.007224</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-4</td>\n      <td>4.427273</td>\n      <td>3.010909</td>\n      <td>0.007776</td>\n      <td>-0.000814</td>\n      <td>0.006962</td>\n      <td>1.709091</td>\n      <td>-0.026811</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-15</td>\n      <td>14.410526</td>\n      <td>9.183158</td>\n      <td>0.031702</td>\n      <td>0.007947</td>\n      <td>0.039649</td>\n      <td>1.326316</td>\n      <td>-0.000630</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"st2_tt =  pd.read_csv(\"../input/daily-rpi-2019/test_stage2.csv\")\nst2_tt.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"               ID  Team1      ...      TOPG_diff  FG3_PCT_diff\n0  2019_1101_1113   1101      ...       -1.93858      0.042035\n1  2019_1101_1120   1101      ...       -0.49189      0.002446\n2  2019_1113_1120   1113      ...        1.44669     -0.039589\n3  2019_1101_1124   1101      ...       -1.62608      0.043639\n4  2019_1113_1124   1113      ...        0.31250      0.001604\n\n[5 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Team1</th>\n      <th>T1_RPI</th>\n      <th>Seed_1</th>\n      <th>Team2</th>\n      <th>T2_RPI</th>\n      <th>Seed_2</th>\n      <th>seed_diff</th>\n      <th>PPG_diff</th>\n      <th>OPPG_diff</th>\n      <th>AOE_diff</th>\n      <th>ADE_diff</th>\n      <th>AEE_diff</th>\n      <th>TOPG_diff</th>\n      <th>FG3_PCT_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019_1101_1113</td>\n      <td>1101</td>\n      <td>ABL CHRISTIAN</td>\n      <td>15</td>\n      <td>1113</td>\n      <td>ARIZONA ST</td>\n      <td>11</td>\n      <td>4</td>\n      <td>-6.08836</td>\n      <td>-8.16595</td>\n      <td>0.003957</td>\n      <td>0.033703</td>\n      <td>0.037660</td>\n      <td>-1.93858</td>\n      <td>0.042035</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019_1101_1120</td>\n      <td>1101</td>\n      <td>ABL CHRISTIAN</td>\n      <td>15</td>\n      <td>1120</td>\n      <td>AUBURN</td>\n      <td>5</td>\n      <td>10</td>\n      <td>-7.15821</td>\n      <td>-3.69168</td>\n      <td>-0.058369</td>\n      <td>0.012063</td>\n      <td>-0.046306</td>\n      <td>-0.49189</td>\n      <td>0.002446</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019_1113_1120</td>\n      <td>1113</td>\n      <td>ARIZONA ST</td>\n      <td>11</td>\n      <td>1120</td>\n      <td>AUBURN</td>\n      <td>5</td>\n      <td>6</td>\n      <td>-1.06985</td>\n      <td>4.47427</td>\n      <td>-0.062326</td>\n      <td>-0.021640</td>\n      <td>-0.083966</td>\n      <td>1.44669</td>\n      <td>-0.039589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019_1101_1124</td>\n      <td>1101</td>\n      <td>ABL CHRISTIAN</td>\n      <td>15</td>\n      <td>1124</td>\n      <td>BAYLOR</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0.06789</td>\n      <td>-2.29095</td>\n      <td>-0.000515</td>\n      <td>0.036455</td>\n      <td>0.035940</td>\n      <td>-1.62608</td>\n      <td>0.043639</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019_1113_1124</td>\n      <td>1113</td>\n      <td>ARIZONA ST</td>\n      <td>11</td>\n      <td>1124</td>\n      <td>BAYLOR</td>\n      <td>9</td>\n      <td>2</td>\n      <td>6.15625</td>\n      <td>5.87500</td>\n      <td>-0.004472</td>\n      <td>0.002752</td>\n      <td>-0.001720</td>\n      <td>0.31250</td>\n      <td>0.001604</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now let's try to find a good model for evaluating this training data. Let's first separate the features (predictor variables) from the target (outcome or dependent) variable. Let's also prepare an autoML library for analyzing this data. And let's also split the model for train and test data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['seed_diff', 'PPG_diff', 'OPPG_diff', 'AOE_diff', 'ADE_diff', 'AEE_diff', 'TOPG_diff', 'FG3_PCT_diff']\nX = st2_tr[features]\ny = st2_tr['target']\n\n# split model for train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=7)\n\n#pipeline_optimizer = TPOTClassifier()\n#pipeline_optimizer = TPOTClassifier(generations=25, population_size=250, scoring='neg_log_loss', cv=8,\n#                                    random_state=42, verbosity=2)\n#pipeline_optimizer.fit(X_train, y_train)\n#print(pipeline_optimizer.score(X_test, y_test))\n# 0.7099236641221374\n#pipeline_optimizer.export('tpot_exported_pipeline.py')\n\n# Best pipeline according to above iteration of TPOT: LogisticRegression(LinearSVC(input_matrix, C=5.0, dual=True, loss=hinge, penalty=l2, tol=0.001), C=10.0, dual=False, penalty=l1)\n\n#pipeline_optimizer = TPOTClassifier()\n#pipeline_optimizer = TPOTClassifier(generations=100, population_size=100, scoring=\"neg_log_loss\", cv=5,\n#                                    random_state=42, verbosity=2)\n#pipeline_optimizer.fit(X_train, y_train)\n#print(pipeline_optimizer.score(X_test, y_test))\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.linear_model import LogisticRegression\n\n#LogisticRegression(LinearSVC(input_matrix, C=5.0, dual=True, loss=hinge, penalty=l2, tol=0.001), C=10.0, dual=False, penalty=l1)\n\n# Get your LinearSVC model parameterized and trained first \nlsvc = LinearSVC(C=5.0, dual=True, loss='hinge', penalty='l2', tol=0.001)\nlsvc2 = CalibratedClassifierCV(lsvc)\nlsvc2.fit(X_train, y_train)\npred1 = lsvc2.predict(X_train)\npred1 = pd.DataFrame(data=pred1, columns=['target'])\nprint(pred1)\ny_pred = lsvc2.predict_proba(X_train)\ny_pred = pd.DataFrame(data=y_pred, columns=['Pred2', 'Pred']) # Pred is target prediction\ny_pred = y_pred.drop(['Pred2'], axis=1)\nprint(y_pred)\nprint(y_test)\n# Now use the outputs of the LinearSVC model to train the logistic regresion model \nlr = LogisticRegression(C=10.0, dual=False, penalty='l1')\nlr.fit(y_pred, y_train)\n# After you've fitted the logistic regression model you still must predict on the training data for it \nytr_pred = lr.predict(y_pred)\ny_train2 = pd.DataFrame(data=ytr_pred, columns=['y_pred'])\n# Now turn those predictions into predictive probabilities for each team \nytr_pred_probs = lr.predict_proba(y_train2)\nytr_pred_probs = pd.DataFrame(data=ytr_pred_probs, columns=['Pred2', 'Pred1'])\n# Drop the second team which isn't on the Team 1 line anyway \nytr_pred_probs = ytr_pred_probs.drop(['Pred2'], axis=1)\nprint(ytr_pred_probs)\n# Validate the score of your predictive probabilities against the labeled training data \nlr.score(ytr_pred_probs, y_train)\n##################################\n# Now let's see how it works against the hold out test data before we decide whether this is worth doing on the final submission file.... ? ? ? \nyt_pred = lsvc2.predict_proba(X_test)\nyt_pred = pd.DataFrame(data=yt_pred, columns=['Pred2', 'Pred']) # Pred is target prediction\nyt_pred = yt_pred.drop(['Pred2'], axis=1)\n# Now use the outputs of the LinearSVC model to train the logistic regression model \nyt_pred2 = lr.predict(yt_pred)\nyt_test2 = pd.DataFrame(data=yt_pred2, columns=['y_pred'])\n# Now turn those predictions into predictive probabilities for each team \nyt_pred_probs = lr.predict_proba(yt_test2)\nyt_pred_probs = pd.DataFrame(data=yt_pred_probs, columns=['Pred2', 'Pred1'])\n# Drop the second team which isn't on the Team 1 line anyway \nyt_pred_probs = yt_pred_probs.drop(['Pred2'], axis=1)\nprint(yt_pred_probs)\n# Validate the score of your predictive probabilities against the labeled training data \nlr.score(yt_pred_probs, y_test)\n\n\n#Generation 5 - Current best internal CV score: -0.5377470801591799\n# Best pipeline: LogisticRegression(LogisticRegression(FastICA(input_matrix, tol=0.25), C=25.0, dual=True, penalty=l2), C=15.0, dual=False, penalty=l2)\n\n# 25 Generations # 250 population size  scoring='neg_log_loss', cv=8,\n# Generation 25 - Current best internal CV score: -0.5397767537100093\n# Best pipeline: LogisticRegression(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), C=25.0, dual=False, penalty=l2)\n#-0.554315389839604\n\n","execution_count":13,"outputs":[{"output_type":"stream","text":"      target\n0          1\n1          1\n2          0\n3          1\n4          1\n5          0\n6          0\n7          1\n8          1\n9          0\n10         1\n11         1\n12         1\n13         0\n14         1\n15         1\n16         1\n17         0\n18         1\n19         1\n20         1\n21         0\n22         0\n23         1\n24         1\n25         0\n26         0\n27         0\n28         1\n29         0\n...      ...\n1542       1\n1543       1\n1544       0\n1545       1\n1546       0\n1547       1\n1548       0\n1549       1\n1550       1\n1551       0\n1552       1\n1553       1\n1554       0\n1555       0\n1556       1\n1557       1\n1558       0\n1559       1\n1560       1\n1561       1\n1562       1\n1563       1\n1564       1\n1565       0\n1566       0\n1567       0\n1568       0\n1569       1\n1570       1\n1571       0\n\n[1572 rows x 1 columns]\n          Pred\n0     0.520368\n1     0.695297\n2     0.191900\n3     0.919545\n4     0.509495\n5     0.073535\n6     0.427578\n7     0.613776\n8     0.562690\n9     0.197339\n10    0.655375\n11    0.841807\n12    0.602234\n13    0.474433\n14    0.750279\n15    0.625719\n16    0.713708\n17    0.350096\n18    0.904010\n19    0.522996\n20    0.675204\n21    0.425235\n22    0.182991\n23    0.564260\n24    0.666816\n25    0.459942\n26    0.397143\n27    0.147885\n28    0.776477\n29    0.489177\n...        ...\n1542  0.742423\n1543  0.548139\n1544  0.224780\n1545  0.563497\n1546  0.281981\n1547  0.848885\n1548  0.098307\n1549  0.774013\n1550  0.521763\n1551  0.341252\n1552  0.504744\n1553  0.645752\n1554  0.420639\n1555  0.282030\n1556  0.792890\n1557  0.898118\n1558  0.295771\n1559  0.577663\n1560  0.611613\n1561  0.533871\n1562  0.696043\n1563  0.625223\n1564  0.547427\n1565  0.435896\n1566  0.261563\n1567  0.294193\n1568  0.303755\n1569  0.653666\n1570  0.950649\n1571  0.364478\n\n[1572 rows x 1 columns]\n1205    0\n1931    0\n1223    0\n1676    1\n1072    1\n1538    1\n1592    0\n1471    1\n1680    1\n590     1\n556     1\n347     1\n438     0\n2042    0\n1487    0\n1939    0\n299     0\n595     0\n1070    1\n2038    1\n1595    1\n514     1\n1513    0\n1042    0\n643     1\n2019    0\n1589    1\n423     0\n1974    0\n758     0\n       ..\n1132    1\n43      0\n1164    0\n9       0\n1426    1\n147     1\n1726    1\n13      1\n389     0\n1751    0\n688     0\n1964    1\n1044    0\n717     0\n700     1\n94      0\n1276    0\n1739    0\n1050    0\n1158    1\n1431    0\n1810    1\n501     0\n702     1\n2043    1\n1455    1\n1818    0\n729     0\n25      1\n1548    1\nName: target, Length: 524, dtype: int64\n         Pred1\n0     0.932523\n1     0.932523\n2     0.067561\n3     0.932523\n4     0.932523\n5     0.067561\n6     0.067561\n7     0.932523\n8     0.932523\n9     0.067561\n10    0.932523\n11    0.932523\n12    0.932523\n13    0.067561\n14    0.932523\n15    0.932523\n16    0.932523\n17    0.067561\n18    0.932523\n19    0.932523\n20    0.932523\n21    0.067561\n22    0.067561\n23    0.932523\n24    0.932523\n25    0.067561\n26    0.067561\n27    0.067561\n28    0.932523\n29    0.067561\n...        ...\n1542  0.932523\n1543  0.932523\n1544  0.067561\n1545  0.932523\n1546  0.067561\n1547  0.932523\n1548  0.067561\n1549  0.932523\n1550  0.932523\n1551  0.067561\n1552  0.932523\n1553  0.932523\n1554  0.067561\n1555  0.067561\n1556  0.932523\n1557  0.932523\n1558  0.067561\n1559  0.932523\n1560  0.932523\n1561  0.932523\n1562  0.932523\n1563  0.932523\n1564  0.932523\n1565  0.067561\n1566  0.067561\n1567  0.067561\n1568  0.067561\n1569  0.932523\n1570  0.932523\n1571  0.067561\n\n[1572 rows x 1 columns]\n        Pred1\n0    0.067561\n1    0.067561\n2    0.067561\n3    0.932523\n4    0.932523\n5    0.932523\n6    0.067561\n7    0.932523\n8    0.067561\n9    0.932523\n10   0.067561\n11   0.067561\n12   0.932523\n13   0.067561\n14   0.932523\n15   0.067561\n16   0.067561\n17   0.067561\n18   0.932523\n19   0.932523\n20   0.067561\n21   0.932523\n22   0.067561\n23   0.067561\n24   0.932523\n25   0.067561\n26   0.932523\n27   0.067561\n28   0.067561\n29   0.932523\n..        ...\n494  0.932523\n495  0.067561\n496  0.067561\n497  0.932523\n498  0.067561\n499  0.932523\n500  0.932523\n501  0.932523\n502  0.067561\n503  0.067561\n504  0.067561\n505  0.067561\n506  0.067561\n507  0.932523\n508  0.932523\n509  0.067561\n510  0.932523\n511  0.067561\n512  0.067561\n513  0.067561\n514  0.932523\n515  0.932523\n516  0.067561\n517  0.932523\n518  0.067561\n519  0.932523\n520  0.067561\n521  0.067561\n522  0.067561\n523  0.932523\n\n[524 rows x 1 columns]\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.7061068702290076"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"After After testing the model on our hold out data, we can take the trained model and apply it to this year's NCAA Tournament Submission File that we've created "},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['seed_diff', 'PPG_diff', 'OPPG_diff', 'AOE_diff', 'ADE_diff', 'AEE_diff', 'TOPG_diff', 'FG3_PCT_diff']\nID = st2_tt['ID']\nX2 = st2_tt[features]\nprint(st2_tt.shape)\n\n# Now let's see how it works against the hold out test data before we decide whether this is worth doing on the final submission file.... ? ? ? \ny2_pred = lsvc2.predict_proba(X2)\ny2_pred = pd.DataFrame(data=y2_pred, columns=['Pred2', 'Pred']) # Pred is target prediction\ny2_pred = y2_pred.drop(['Pred2'], axis=1)\n# Now use the outputs of the LinearSVC model to train the logistic regression model \ny2_pred2 = lr.predict(y2_pred)\ny2_test2 = pd.DataFrame(data=y2_pred2, columns=['y_pred'])\n# Now turn those predictions into predictive probabilities for each team \ny2_pred_probs = lr.predict_proba(y2_test2)\ny2_pred_probs = pd.DataFrame(data=y2_pred_probs, columns=['Pred2', 'Pred1'])\n# Drop the second team which isn't on the Team 1 line anyway \ny2_pred_probs = y2_pred_probs.drop(['Pred2'], axis=1)\nprint(y2_pred_probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's convert this exercise into the final submission file !"},{"metadata":{"trusted":true},"cell_type":"code","source":"ID = pd.DataFrame(data=ID, columns=['ID'])\nID['Pred'] = y2_pred_probs['Pred1']\nID.head()\nID[['ID', 'Pred']].to_csv('submission_SVM_LR_Ensemble.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}