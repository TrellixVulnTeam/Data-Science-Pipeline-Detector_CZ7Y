{"cells":[{"metadata":{"_uuid":"e2f624d6b5ab08b652e600fad1b90ae7045e5b9b"},"cell_type":"markdown","source":"# Introduction\nMassey Ordinals is a compilation of ranking systems. In this notebook we compare those systems in terms of their performance. In other words, we get a ranking of rankings. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.figsize'] = (15, 9)\n\nseason_df = pd.read_csv('../input/datafiles/RegularSeasonCompactResults.csv')\ntourney_df = pd.read_csv('../input/datafiles/NCAATourneyCompactResults.csv')\nordinals_df = pd.read_csv('../input/masseyordinals/MasseyOrdinals.csv')\\\n                .rename(columns={'RankingDayNum':'DayNum'})\n# Get the last available data from each system previous to the tournament\nordinals_df = ordinals_df.groupby(['SystemName','Season','TeamID']).last().reset_index()\nordinals_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Merge game and ordinal data"},{"metadata":{"trusted":true,"_uuid":"d047750861a973b8cde034922d11a76359dad4d8"},"cell_type":"code","source":"# Add winner's ordinals\ngames_df = tourney_df.merge(ordinals_df,left_on=['Season','WTeamID'],\n                          right_on=['Season','TeamID'])\ngames_df.head()\n# Then add losser's ordinals\ngames_df = games_df.merge(ordinals_df,left_on=['Season','LTeamID','SystemName'],\n                          right_on=['Season','TeamID','SystemName'],\n                          suffixes = ['W','L'])\ngames_df.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53a6a84135fe1709baddbb85adc1cab8bbb3869a"},"cell_type":"markdown","source":"## How accurate are the different systems?\nHere we evaluate the accuracy of each system (i.e. the percentage of times in which the result agrees with the ranking difference) and plot the top 50 systems. "},{"metadata":{"trusted":true,"_uuid":"7b1d7a5ab6749161607f7bba753eb6f9d62e6200"},"cell_type":"code","source":"## Add column with 1 if result is correct\ngames_df = games_df.drop(labels=['TeamIDW','TeamIDL'],axis=1)\ngames_df['prediction'] = (games_df.OrdinalRankW<games_df.OrdinalRankL).astype(int)\nresults_by_system = games_df.groupby('SystemName').agg({'prediction':('mean','count')})\nresults_by_system['prediction']['mean'].sort_values(ascending=False)[:50].plot.bar(ylim=[.7,.8])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26df85d5d8f753be7f1014ce8548aa5344e2c6a0"},"cell_type":"markdown","source":"This figure does not take into account the consistency of the accuracy, i.e. the length of the track record evaluated. To account for that, we show the accuracy together with the sample size for each system"},{"metadata":{"trusted":true,"_uuid":"31d01365550611337e3747cd3ac1eda1dc2664b5"},"cell_type":"code","source":"results_by_system['prediction'].sort_values('mean',ascending=False)[:50]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a834e7928a11a063cf90cb4749ff2e2cf5e1574"},"cell_type":"markdown","source":"## Evaluation of predictions based on the competition's metrics\nOk, we have measured the accuracy, but how are the systems ranked according to the log-loss?\n\nTo do that,  we transform the rank into an elo-like rating given the following formula (see this [post](https://www.kaggle.com/c/march-machine-learning-mania-2014/discussion/6777) by Jeff Sonas):\n\nRating = 100 - 4*LN(rank+1) - rank/22\n\nAnd then compute the probability of team A beating team B is:\n\nprob = 1/(1+POWER(10,-RatingDiff/15))\n\nWe focus on the four last seasons, so that the metrics computed should be in agreement with the leaderboard score."},{"metadata":{"trusted":true,"_uuid":"9ef73db1509864450fc5c14690bd62694cc40140"},"cell_type":"code","source":"games_df['Wrating'] = 100-4*np.log(games_df['OrdinalRankW']+1)-games_df['OrdinalRankW']/22\ngames_df['Lrating'] = 100-4*np.log(games_df['OrdinalRankL']+1)-games_df['OrdinalRankL']/22\ngames_df['prob'] = 1/(1+10**((games_df['Lrating']-games_df['Wrating'])/15))\nloss_results = games_df[games_df.Season>=2015].groupby('SystemName')['prob'].agg([('loss',lambda p: -np.mean(np.log(p))),('count','count')])\nloss_results['loss'].sort_values()[:50].plot.bar(ylim=[.4,.6])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de7d29053eb47f370ca266ddca3e3690ae6f658e"},"cell_type":"markdown","source":"## Let us choose a system and generate a submission"},{"metadata":{"trusted":true,"_uuid":"0d9c7bff83541f686619b7237eb87af3dae7a0b3"},"cell_type":"code","source":"ref_system = 'POM'\nordinals_df['Rating']= 100-4*np.log(ordinals_df['OrdinalRank']+1)-ordinals_df['OrdinalRank']/22\nordinals_df = ordinals_df[ordinals_df.SystemName==ref_system]\n# Get submission file\nsubmission_df = pd.read_csv('../input/SampleSubmissionStage1.csv')\n\nsubmission_df['Season'] = submission_df['ID'].map(lambda x: int(x.split('_')[0]))\nsubmission_df['Team1'] = submission_df['ID'].map(lambda x: int(x.split('_')[1]))\nsubmission_df['Team2'] = submission_df['ID'].map(lambda x: int(x.split('_')[2]))\nsubmission_df = submission_df.merge(ordinals_df[['Season','TeamID','Rating']],how='left',\n                                    left_on = ['Season','Team1'], right_on = ['Season','TeamID'])\nsubmission_df = submission_df.merge(ordinals_df[['Season','TeamID','Rating']],how='left',\n                                    left_on = ['Season','Team2'], right_on = ['Season','TeamID'],\n                                   suffixes=['W','L'])\nsubmission_df['Pred'] = 1/(1+10**((submission_df['RatingL']-submission_df['RatingW'])/15))\nsubmission_df[['ID', 'Pred']].to_csv('submission.csv', index=False)\nsubmission_df[['ID', 'Pred']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79351428832d866d564f099fbc6e1b8f94d65f78"},"cell_type":"code","source":"submission_df.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}