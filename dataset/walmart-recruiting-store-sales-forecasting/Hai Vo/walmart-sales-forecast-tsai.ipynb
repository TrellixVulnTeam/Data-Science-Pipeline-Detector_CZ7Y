{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\n\nimport math\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n\nfrom sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.feature_selection import RFE\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:22:05.908011Z","iopub.execute_input":"2021-05-28T04:22:05.908537Z","iopub.status.idle":"2021-05-28T04:22:06.518702Z","shell.execute_reply.started":"2021-05-28T04:22:05.908421Z","shell.execute_reply":"2021-05-28T04:22:06.517618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 100)\npd.set_option('display.width', 256)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:22:07.881816Z","iopub.execute_input":"2021-05-28T04:22:07.882215Z","iopub.status.idle":"2021-05-28T04:22:07.888614Z","shell.execute_reply.started":"2021-05-28T04:22:07.882185Z","shell.execute_reply":"2021-05-28T04:22:07.886159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Loading**","metadata":{}},{"cell_type":"code","source":"data_root = '../input/walmart-recruiting-store-sales-forecasting'\ndatasets = dict()\nfor ds in ['train', 'test']:\n    dataset = pd.read_csv(f\"{data_root}/{ds}.csv.zip\", sep=',', header=0,\n                          names=['Store', 'Dept', 'Date', 'weeklySales', 'isHoliday'] if ds=='train'\n                           else ['Store', 'Dept', 'Date', 'isHoliday'])\n    features = pd.read_csv(f\"{data_root}/features.csv.zip\", sep=',', header=0,\n                           names=['Store', 'Date', 'Temperature', 'Fuel_Price', \n                                  'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', \n                                  'CPI', 'Unemployment', 'IsHoliday']).drop(columns=['IsHoliday'])\n    stores = pd.read_csv(f\"{data_root}/stores.csv\", names=['Store', 'Type', 'Size'], sep=',', header=0)\n    dataset = dataset.merge(stores, how='left').merge(features, how='left')\n\n    dataset['Date'] = pd.to_datetime(dataset['Date'])\n    # dataset[\"isTomorrowHoliday\"] = dataset[\"isHoliday\"].shift(-1).fillna(False)\n    display(dataset.head())\n    \n    datasets[ds] = dataset","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-05-28T04:22:11.058507Z","iopub.execute_input":"2021-05-28T04:22:11.058924Z","iopub.status.idle":"2021-05-28T04:22:11.841492Z","shell.execute_reply.started":"2021-05-28T04:22:11.058889Z","shell.execute_reply":"2021-05-28T04:22:11.840368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets['train'][datasets['train'].weeklySales<=0]","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:22:15.282247Z","iopub.execute_input":"2021-05-28T04:22:15.282644Z","iopub.status.idle":"2021-05-28T04:22:15.366193Z","shell.execute_reply.started":"2021-05-28T04:22:15.282606Z","shell.execute_reply":"2021-05-28T04:22:15.365056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets['train'].dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:22:17.131056Z","iopub.execute_input":"2021-05-28T04:22:17.13148Z","iopub.status.idle":"2021-05-28T04:22:17.140087Z","shell.execute_reply.started":"2021-05-28T04:22:17.13143Z","shell.execute_reply":"2021-05-28T04:22:17.138711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def describe_missing_values(df: pd.DataFrame):\n    miss_val = df.isnull().sum()\n    miss_val_percent = 100 * df.isnull().sum() / len(df)\n    miss_val_table = pd.concat([miss_val, miss_val_percent], axis=1)\n    miss_val_table_ren_columns = miss_val_table.rename(\n        columns = {0: 'Missing Values', \n                   1: '% of Total Values',}\n    )\n    miss_val_table_ren_columns = miss_val_table_ren_columns[\n        miss_val_table_ren_columns.iloc[:,1] != 0\n    ].sort_values('% of Total Values', ascending=False).round(1)\n    \n    print(f\"Dataframe has {df.shape[1]} columns,\")\n    print(f\"\\t\\t {miss_val_table_ren_columns.shape[0]} columns that have missing values.\")\n\n    return miss_val_table_ren_columns\n\n\ndef visualize_distribution_of_missing_values(df: pd.DataFrame):\n    df_nan_check = df.isna().sum().sort_values()\n    df_nan_check = df_nan_check.to_dict()\n    df_not_nan = []\n\n    nan_cols = 0\n\n    for key, value in df_nan_check.items():\n        df_nan_check[key] = int(value/len(df)*100)\n        if df_nan_check[key] >= 80:\n            nan_cols += 1\n        else:\n            df_not_nan.append(key)\n\n    # Visualize\n    plt.figure(figsize=(9, 6))\n    plt.suptitle('Distribution of Empty Values', fontsize=19)\n    plt.bar(df_nan_check.keys(), df_nan_check.values())\n    plt.xticks(rotation=69)\n    plt.show()\n    \n\nfor ds in ['train', 'test']:\n    print(f'\\n\\n{ds}-set:')\n    print(describe_missing_values(datasets[ds]))\n    # visualize_distribution_of_missing_values(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:22:19.067541Z","iopub.execute_input":"2021-05-28T04:22:19.067954Z","iopub.status.idle":"2021-05-28T04:22:19.236123Z","shell.execute_reply.started":"2021-05-28T04:22:19.067918Z","shell.execute_reply":"2021-05-28T04:22:19.234998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Exploration**","metadata":{"_uuid":"53ed17a3087c8d1b282d852e55a4843e23136ec6"}},{"cell_type":"code","source":"def scatter(dataset, column):\n    plt.figure()\n    plt.scatter(dataset[column] , dataset['weeklySales'], alpha=0.169)\n    plt.ylabel('weeklySales')\n    plt.xlabel(column)","metadata":{"_uuid":"d5d0f48bb70f7676dc1268eadcfac31703a852ea","execution":{"iopub.status.busy":"2021-05-28T04:22:21.738904Z","iopub.execute_input":"2021-05-28T04:22:21.739291Z","iopub.status.idle":"2021-05-28T04:22:21.745018Z","shell.execute_reply.started":"2021-05-28T04:22:21.739261Z","shell.execute_reply":"2021-05-28T04:22:21.74377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['Fuel_Price', 'Size', 'CPI', 'Type', 'isHoliday', 'Unemployment', 'Temperature', 'Store', 'Dept']:\n    scatter(datasets['train'], col)","metadata":{"_uuid":"24f3db6eaa3103816f2316c3c52480124a888a96","execution":{"iopub.status.busy":"2021-05-28T04:22:23.274866Z","iopub.execute_input":"2021-05-28T04:22:23.275275Z","iopub.status.idle":"2021-05-28T04:22:31.724396Z","shell.execute_reply.started":"2021-05-28T04:22:23.275242Z","shell.execute_reply":"2021-05-28T04:22:31.722958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(18, 14))\ncorr = datasets['train'].corr()\nc = plt.pcolor(corr)\nplt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\nplt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns, rotation=45)\nfig.colorbar(c)","metadata":{"_uuid":"7de400728cdc665aefedd7ba506cffbbf6dfe87d","execution":{"iopub.status.busy":"2021-05-28T04:22:31.726078Z","iopub.execute_input":"2021-05-28T04:22:31.726443Z","iopub.status.idle":"2021-05-28T04:22:32.306277Z","shell.execute_reply.started":"2021-05-28T04:22:31.726407Z","shell.execute_reply":"2021-05-28T04:22:32.305175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Manipulation**","metadata":{"_uuid":"45bb9a93aa88a169dae9dc805525a1f56f2afeec"}},{"cell_type":"code","source":"for ds in datasets.keys():\n    # make holidays more specific\n    datasets[ds]['Holiday_Type'] = None\n    datasets[ds].loc[(datasets[ds]['isHoliday']==True) & \n                     (datasets[ds]['Date'].dt.month==2), 'Holiday_Type'] = 'Super_Bowl'\n    datasets[ds].loc[(datasets[ds]['isHoliday']==True) & \n                     (datasets[ds]['Date'].dt.month==9), 'Holiday_Type'] = 'Labor_Day'\n    datasets[ds].loc[(datasets[ds]['isHoliday']==True) & \n                     (datasets[ds]['Date'].dt.month==11), 'Holiday_Type'] = 'Thanksgiving' \n    datasets[ds].loc[(datasets[ds]['isHoliday']==True) & \n                     (datasets[ds]['Date'].dt.month==12), 'Holiday_Type'] = 'Christmax'\n    datasets[ds].drop(columns=['isHoliday'], inplace=True)\n    \n    # 1-hot encoding for categorical features\n    datasets[ds] = pd.get_dummies(datasets[ds], columns=[\"Type\", \"Holiday_Type\"])\n    \n    # data imputation\n    datasets[ds].fillna(value=0, inplace=True)\n    display(datasets[ds].head())","metadata":{"_uuid":"1586a44ad77b30ff62ac07810796b391bc1096de","execution":{"iopub.status.busy":"2021-05-28T04:22:32.308069Z","iopub.execute_input":"2021-05-28T04:22:32.308387Z","iopub.status.idle":"2021-05-28T04:22:32.900403Z","shell.execute_reply.started":"2021-05-28T04:22:32.308355Z","shell.execute_reply":"2021-05-28T04:22:32.899566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in datasets['train'].columns:\n    if col in ['Store', 'Dept', 'Date']:\n        continue\n    if col not in list(datasets['test'].columns):\n        datasets['test'][col] = 0\n\ndatasets['train'].rename(columns={'weeklySales': 'Weekly_Sales'}, inplace=True)\n# datasets['train']['Weekly_Sales'][datasets['train']['Weekly_Sales']<0] = 0\ndatasets['train']['Previous_Sales'] = datasets['train'].Weekly_Sales.shift(1)\n\nfeature_names = [col for col in datasets['train'] if col not in ['Previous_Sales', 'Weekly_Sales']]\ndatasets['train'] = datasets['train'][feature_names+['Previous_Sales', 'Weekly_Sales']]\ndatasets['test'] = datasets['test'][feature_names]\n        \ndisplay(datasets['train'].head())\ndisplay(datasets['test'].head())","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:23:21.077548Z","iopub.execute_input":"2021-05-28T04:23:21.078152Z","iopub.status.idle":"2021-05-28T04:23:21.159151Z","shell.execute_reply.started":"2021-05-28T04:23:21.078115Z","shell.execute_reply":"2021-05-28T04:23:21.158345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats = datasets['train'].groupby([\"Store\", \"Dept\"])['Date'].agg(['count']).value_counts(sort=False)\nstats = stats.to_frame('#(store, dept)')\ndisplay(stats)\nstats.reset_index(drop=True, inplace=True)\nplt.plot(stats.index, stats.values)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:24:02.965773Z","iopub.execute_input":"2021-05-28T04:24:02.966211Z","iopub.status.idle":"2021-05-28T04:24:03.16899Z","shell.execute_reply.started":"2021-05-28T04:24:02.966172Z","shell.execute_reply":"2021-05-28T04:24:03.167556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train, data_test = datasets['train'].copy(), datasets['test'].copy()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:24:08.045794Z","iopub.execute_input":"2021-05-28T04:24:08.046188Z","iopub.status.idle":"2021-05-28T04:24:08.072437Z","shell.execute_reply.started":"2021-05-28T04:24:08.046154Z","shell.execute_reply":"2021-05-28T04:24:08.071319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"window_size = 12\nstride = 1\nX_all, y_all = [], []\nfor name, group in data_train.groupby([\"Store\", \"Dept\"]):\n    data_group = group.sort_values(by=['Date'], ascending=True)\n    data_group = data_group.drop(columns=[\"Store\", \"Dept\", \"Date\"]).to_numpy()\n    if data_group.shape[0] < window_size/3:\n        continue\n\n    # Padding\n    n_samples = (len(data_group) - window_size) / stride\n    if n_samples != int(n_samples):\n        n_pads = (math.ceil(n_samples) - n_samples) * stride\n        if abs(n_pads-round(n_pads)) > 1e-7:\n            raise ValueError(f\"n_pads={n_pads} must be INT\")\n        n_pads = int(n_pads)\n        \n        data_padded = np.zeros(shape=(len(data_group)+n_pads, data_group.shape[1]))\n        data_padded[-data_group.shape[0]:, :] = data_group\n        data_group = data_padded\n    \n    X_group = data_group[:, :-1]\n    y_group = data_group[:, -1]\n\n    n_samples = int((len(data_group) - window_size) / stride)\n    for s in range(n_samples):\n        s_start = s * stride\n        X_sample = X_group[s_start:s_start+window_size, :]\n        y_sample = y_group[s_start+window_size]\n        X_all.append(X_sample.T)\n        y_all.append(y_sample.T)\n        \nX_all, y_all = np.array(X_all), np.array(y_all)\nprint('Total samples:\\t\\t', X_all.shape, y_all.shape)\n\nML_max_samples = 70_000\nif len(X_all) > ML_max_samples:\n    X_ml, _, y_ml, _ = train_test_split(X_all, y_all, train_size=ML_max_samples, random_state=20_03_21, shuffle=True)\nelse:\n    X_ml, y_ml = X_all, y_all\nprint('Samples for ML model:\\t', X_ml.shape, y_ml.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:24:21.781629Z","iopub.execute_input":"2021-05-28T04:24:21.782051Z","iopub.status.idle":"2021-05-28T04:24:28.592201Z","shell.execute_reply.started":"2021-05-28T04:24:21.782015Z","shell.execute_reply":"2021-05-28T04:24:28.590952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(y_all)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:24:44.204769Z","iopub.execute_input":"2021-05-28T04:24:44.205159Z","iopub.status.idle":"2021-05-28T04:24:46.063241Z","shell.execute_reply.started":"2021-05-28T04:24:44.205127Z","shell.execute_reply":"2021-05-28T04:24:46.062257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_SALES = 100_000\nsns.distplot(np.where(y_all>MAX_SALES, MAX_SALES, y_all))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:24:54.547464Z","iopub.execute_input":"2021-05-28T04:24:54.548274Z","iopub.status.idle":"2021-05-28T04:24:56.748553Z","shell.execute_reply.started":"2021-05-28T04:24:54.548216Z","shell.execute_reply":"2021-05-28T04:24:56.747407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_all = y_all / MAX_SALES\n# sns.distplot(y_all)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test[['Previous_Sales', 'Weekly_Sales']] = None\ndata_group_extended = dict()\nN_features = len(datasets['test'].columns) - 3\n\nfor name, test_group in data_test.groupby([\"Store\", \"Dept\"]):\n    \n    train_group = data_train[(data_train.Store==name[0]) & (data_train.Dept==name[1])]\n\n    ######################################################\n    # Concatenate train-set & test-set per (store, dept) #\n    ######################################################\n    data_group = pd.concat([train_group, test_group]) if len(train_group) > 0 else test_group\n    data_group.sort_values(by=['Date'], ascending=True, inplace=True)\n    # print(data_group[['Date', 'Size', 'Temperature', 'Weekly_Sales']].to_string())\n    # if data_group.duplicated(subset=['Store', 'Dept', 'Date'], keep=False).sum() > 0:\n    #     print(name)\n    data_group.reset_index(drop=True, inplace=True)\n    # display(data_group[data_group.Weekly_Sales.isna()])\n    \n    data_group_extended[name] = data_group\n    continue\n\n    ######################################\n    # Build batch samples for prediction #\n    ######################################\n    predict_indices = list(data_group[data_group.Weekly_Sales.isna()].index)\n    if len(predict_indices) == 0:\n        continue\n    features = data_group.to_numpy()[:, 3:-1]\n\n    # Padding\n    if len(train_group) < window_size:\n        n_pads = window_size - len(train_group)\n        features = np.vstack([np.zeros(shape=(n_pads, N_features)), features])\n        predict_indices = [i+n_pads for i in predict_indices]\n\n    # Sample by batch\n    X_predict = np.empty(shape=(len(predict_indices), N_features, window_size))\n    for j, idx in enumerate(predict_indices):\n        X_predict[j, ...] = features[idx-window_size:idx, :].T\n\n    data_group_extended[name] = [data_group[[\"Store\", \"Dept\", \"Date\", \"Weekly_Sales\"]][data_group.Weekly_Sales.isna()], \n                                 predict_indices, \n                                 X_predict]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check size of predictions per (store, dept)\nfor name, (data_group, indices, X_group) in data_group_extended.items():\n    sum_1 = data_group.Weekly_Sales.isna().sum()\n    sum_2 = len(indices)\n    sum_3 = X_group.shape[0]\n    if (sum_1 != sum_2) or (sum_2 != sum_3):\n        print(name, data_group.Weekly_Sales.isna().sum(), len(indices), X_group.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling**","metadata":{"_uuid":"352d8fad9967d928067c9623ff8cb73f20748689"}},{"cell_type":"markdown","source":"## **Input Shape**: (N_samples, N_features, Max_seq_len)","metadata":{}},{"cell_type":"code","source":"!pip install --ignore-installed tsai","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tsai.all import *\n\nimport torch\n\ndef torch2np(tensor: torch.Tensor) -> np.array:\n    if torch.cuda.is_available():\n        tensor = tensor.cpu()\n    return tensor.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scorer = make_scorer(MSE, greater_is_better=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MiniRocket","metadata":{}},{"cell_type":"code","source":"# Machine-Learning models\nML_models = [\n    # (RocketClassifier, {'num_kernels': 10_000}),\n    (MiniRocketClassifier, {'num_features': 10_000, 'max_dilations_per_kernel': 32}),\n    (MiniRocketVotingClassifier, {'num_features': 10_000, 'max_dilations_per_kernel': 32, 'n_estimators': 3}),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_ml, y_ml, \n                                                  train_size=0.69 if len(X_ml) < ML_max_samples else ML_max_samples//2, \n                                                  random_state=4_10_20, \n                                                  shuffle=True)\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = MiniRocketRegressor(num_features=10_000, \n#                             max_dilations_per_kernel=window_size,\n#                             normalize_features=False,\n#                             verbose=True,\n#                             scoring=scorer)\n\n# print(\"Training MiniRocket ...\")\n# timer.start(False)\n# model.fit(X_train, y_train)\n# t = timer.stop()\n# print(f\"\\t ... in {t}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = model.predict(X_val)\n# error = MSE(y_val, y_pred, squared=False) # Root-MSE\n# print(f'Val Error: {error:.5f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results = []\n# for name, (data_group, indices, X_test) in data_group_extended.items():\n#     if len(data_group) != X_test.shape[0]:\n#         raise ValueError(f\"{name} - {len(data_group)} != {X_test.shape[0]}\")\n#     else:\n#         y_pred = model.predict(X_test)\n#         data_group.Weekly_Sales = y_pred\n#         data_group['Date'] = pd.to_datetime(data_group.Date, format='%Y-%m-%d %H:%M:%S')\n#         data_group['Id'] = data_group['Store'].astype(int).apply(str) + '_' \\\n#                           + data_group['Dept'].astype(int).apply(str) + '_' \\\n#                           + data_group['Date'].dt.strftime('%Y-%m-%d')\n#         results.append(data_group[['Id', 'Weekly_Sales']])\n        \n# results = pd.concat(results)\n# results.Weekly_Sales = results.Weekly_Sales.apply(np.exp)\n# results.to_csv('submission_MiniRocket.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not os.path.isdir('models'):\n#     os.mkdir('models')\n# model.save('MiniRocket')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deep Learning","metadata":{}},{"cell_type":"code","source":"# Deep-Learning models\nDL_models = {\n    \"InceptionTime\": (InceptionTime, {'nf': 32, 'ks': window_size}), \n    \"InceptionTimePlus\": (InceptionTimePlus, {'nf': 32, 'ks': window_size, 'bottleneck': True, 'depth': 6, 'dilation': 1, 'stride': 1}), \n    \"TSTransformer\": (TST, {'max_seq_len': window_size, 'd_model': 32, 'd_ff': 16, 'n_layers': 2, 'n_heads': 4, }), \n    \"TSTransformerPlus\": (TSTPlus, {'max_seq_len': window_size, 'd_model': 32, 'd_ff': 16, 'n_layers': 2, 'n_heads': 4, }), \n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, \n                                                  train_size=0.69, \n                                                  random_state=4_10_20, \n                                                  shuffle=True)\nX_dl, y_dl, splits = combine_split_data([X_train, X_val], [y_train, y_val])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformations = [None, [TSRegression()]]\nbatch_transformations = [TSStandardize(by_sample=True, by_var=True)]\ndsets = TSDatasets(X_dl, y_dl, splits=splits, tfms=transformations, inplace=True)\ndloaders = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 32], batch_tfms=batch_transformations, num_workers=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = 'TSTransformer'\nmodel, model_params = DL_models[MODEL_NAME]\nmodel = create_model(model, dls=dloaders, **model_params)\nlearner = Learner(dls=dloaders, model=model, metrics=[mae, rmse], opt_func=Adam)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_min, lr_steepest = learner.lr_find(start_lr=1e-7, end_lr=1e0, num_it=1_000)\nlr_min, lr_steepest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner.fit_one_cycle(n_epoch=50, lr_max=lr_min)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# valid_probas, valid_targets, valid_preds = learner.get_preds(dl=dloaders.valid, with_decoded=True)\n# acc = torch2np((valid_targets==valid_preds).float().mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.parameters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pandas==1.1.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresults = []\nfor name, (data_group, indices, X_test) in data_group_extended.items():\n    if len(data_group) != X_test.shape[0]:\n        raise ValueError(f\"{name} - {len(data_group)} != {X_test.shape[0]}\")\n    else:\n        X_test = torch.Tensor(X_test).to(device)\n        y_pred = model(X_test)\n        y_pred = torch2np(y_pred.detach())\n        data_group.Weekly_Sales = y_pred \n        data_group['Date'] = pd.to_datetime(data_group.Date, format='%Y-%m-%d %H:%M:%S')\n        data_group['Id'] = data_group['Store'].astype(int).apply(str) + '_' \\\n                          + data_group['Dept'].astype(int).apply(str) + '_' \\\n                          + data_group['Date'].dt.strftime('%Y-%m-%d')\n        results.append(data_group[['Id', 'Weekly_Sales']])\n        \nresults = pd.concat(results)\nresults.Weekly_Sales = results.Weekly_Sales * MAX_SALES\nresults.to_csv(f'submission_{MODEL_NAME}.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}