{"cells":[{"metadata":{},"cell_type":"markdown","source":"# version15 変更点\n・ずれの大きいDept72 & WEEK47のデータのみ、store毎に1年前の値に置き換えてみる\n\n# version14 変更点\n・Hiliday *5をやめて戻す。　＝単純にRMSE→MAEの効果\n\n# version13 変更点\n・RMSE　→　MAE　に変更\n\n# version12 変更点\n・Holidayのweight * 5 を反映するために、学習・予測時にholidayは売上*5を行い、最後に5で割り戻す処理を追加\n\n# version11 変更点\n・validでずれの大きい Dept72 & WEEK47　のフラグを立ててみる。\n\n# version10 変更点\n・validの値を、最後のモデルでの全データ予測　→　各foldでのvalidの予測値を格納、に変更  \n・グラフ化して考察\n\n# version9 変更点\n・validationで予測と実際のズレが大きいデータにどんな特徴があるかを見る\n\n# version8 変更点\n・light GBMの試行回数を10000まで増やしてどこがいいかを見る\n\n# version7 変更点\n・2012年クリスマスの修正をbest kernel からパクる  \n>https://www.kaggle.com/avelinocaio/walmart-store-sales-forecasting\n\n# version6 変更点\n・isholidayの修正をbest kernel からパクる（Easter）  \n>https://www.kaggle.com/avelinocaio/walmart-store-sales-forecasting\n\n# version5 変更点\n・Markdwon、temp、CPI、unEmpolyment　をdropする  \n・ハイパーパラメータを省略　（前回チューニングした値で固定）  \n　　best param: max_depth=16, num_leaves=8,min_data_in_leaf=2  \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\n%matplotlib inline\n\n# 小数第4位まで表示\n%precision 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/features.csv.zip')\ntrain = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/train.csv.zip')\nstores = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/stores.csv')\ntest = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/test.csv.zip')\nholidays = pd.read_csv('../input/holidays/holidays.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 型の変換\nholidays[\"Date\"]=pd.to_datetime(holidays[\"Date\"])\nfeatures[\"IsHoliday\"] = np.where(features[\"IsHoliday\"]==True,1,0)\nfeatures[\"Date\"] = pd.to_datetime(features[\"Date\"])\ntrain[\"Date\"] = pd.to_datetime(train[\"Date\"])\ntest[\"Date\"] = pd.to_datetime(test[\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"category\"] = \"train\"\ntest[\"category\"] = \"test\"\ndata_join = pd.concat([train,test])\ndata_join = pd.merge(data_join, features, on=[\"Store\",\"Date\", \"IsHoliday\"], how= \"left\")\ndata_join = pd.merge(data_join, stores, on=\"Store\", how= \"inner\")\ndata_join = pd.merge(data_join, holidays, on=\"Date\", how= \"left\")\ndata_join[\"IsHoliday\"] = data_join[\"IsHoliday\"].astype(int)\ndata_join.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_join[\"YEAR\"] = data_join[\"Date\"].dt.year\ndata_join[\"MONTH\"] = data_join[\"Date\"].dt.month\ndata_join[\"WEEK\"] = data_join[\"Date\"].dt.week\ndata_join","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 特徴量作成：一年前の売上\ndata_sales = data_join[[\"Dept\",\"Store\",\"YEAR\",\"WEEK\",\"Weekly_Sales\"]]\ndata_sales = data_sales.rename(columns={\"Weekly_Sales\":\"Weekly_Sale_before\"})\ndata_sales[\"YEAR\"] = data_sales[\"YEAR\"] + 1\ndata_join2 = pd.merge(data_join, data_sales, on=[\"Dept\",\"Store\",\"YEAR\",\"WEEK\"], how=\"left\")\ndata_join2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"version 11 追記  \nDept72 & WEEK47 のフラグを立てる","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 特徴量作成：Dept72 & WEEK47 のフラグを立てる\ndata_join2[\"FLAG_D72&W47\"] = np.where((data_join2[\"Dept\"]==72) & (data_join2[\"WEEK\"]==47),1,0)\ndata_join2[data_join2[\"FLAG_D72&W47\"] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_join2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_join2[\"Weekly_Sale_before\"] = data_join2[\"Weekly_Sale_before\"].fillna(0)\ndata_join2[\"Weekly_Sale_before\"] = np.where(data_join2[\"Weekly_Sale_before\"]==0,data_join2[\"Weekly_Sales\"],data_join2[\"Weekly_Sale_before\"])\ndata_join2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"・version5で追記。\nMarkdwon、Fuel temp、CPI、unEmpolyment　をdropする","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_join2.drop(columns=[\"Temperature\",\"Fuel_Price\",\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\",\"CPI\",\"Unemployment\"],axis=1,inplace=True)\ndata_join2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"version 6で追記  \nIsHolidayの修正","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_join2.loc[(data_join2.YEAR==2010) & (data_join2.WEEK==13), 'IsHoliday'] = True\ndata_join2.loc[(data_join2.YEAR==2011) & (data_join2.WEEK==16), 'IsHoliday'] = True\ndata_join2.loc[(data_join2.YEAR==2012) & (data_join2.WEEK==14), 'IsHoliday'] = True\ndata_join2.loc[(data_join2.YEAR==2013) & (data_join2.WEEK==13), 'IsHoliday'] = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Version14で落とす\n#Version12 追記  \n#・Holidayのweight * 5 を反映するために、学習・予測時にholidayは売上*5を行い、最後に5で割り戻す処理を追加","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_join2[\"Weekly_Sales\"] = np.where(data_join2[\"IsHoliday\"]==1,data_join2[\"Weekly_Sales\"]*5,data_join2[\"Weekly_Sales\"])\n# data_join2[\"Weekly_Sale_before\"] = np.where(data_join2[\"IsHoliday\"]==1,data_join2[\"Weekly_Sale_before\"]*5,data_join2[\"Weekly_Sale_before\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# baseline\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\n# 参考HP\n# https://rin-effort.com/2019/12/29/machine-learning-6/\n# https://www.codexa.net/lightgbm-beginner/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data_join2[data_join2[\"category\"]==\"train\"]\ndata_test = data_join2[data_join2[\"category\"]==\"test\"]\n\ntrain_x = data_train.drop(columns=['Date', 'Weekly_Sales', 'category'])\ntrain_y = data_train['Weekly_Sales']\ntest_x = data_test.drop(columns=['Date', 'Weekly_Sales', 'category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LightGBM\n\n・欠損値はそのままでOK\n\n・ラベルは数値にする必要あり→label encoding　だが、label encodingは欠損値がNG　→　NAという文字列に変換しておく","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_col = [col for col in train_x.columns if train_x[col].dtype == 'O']\nobj_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x[obj_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nfor c in obj_col:\n    le = LabelEncoder()\n    le.fit(train_x[c].fillna('NA'))\n\n    train_x[c] = le.transform(train_x[c].fillna('NA'))\n    test_x[c] = le.transform(test_x[c].fillna('NA'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x[obj_col].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ハイパーパラメータチューニング\nクロスバリデーション計算時間短縮のために\n* 3fold\n* num_boost_round=1000\n\nとする","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import itertools\n\n# param_space = {\n#     'max_depth': [8, 12, 16],\n#     \"num_leaves\": [8, 12, 16],\n#     \"min_data_in_leaf\":[2, 6,10] \n# }\n\n# param_combinations = itertools.product(param_space['max_depth'], param_space['num_leaves'],param_space['min_data_in_leaf'])\n\n# for i,j,k in param_combinations:\n#     print(f'max_depth:{i}, num_leaves:{j}, min_data_in_leaf:{k}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #イテレータは一度for文を回すと再実行しても最初から回ってくれない。上でfor文を回してしまったので、改めてイテレータを発行する。\n# param_combinations = itertools.product(param_space['max_depth'], param_space['num_leaves'],param_space['min_data_in_leaf'])\n\n# #•パラメータの組ごとにそのパラメータとスコアを保存するリストを用意\n# params_list = []\n# scores_list = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"グリッドサーチの実行。実行時間長いので注意（約30分）","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# version13 追記　：　MAE\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# for max_depth,num_leaves,min_data_in_leaf in param_combinations:\n#     kf = KFold(n_splits=3, shuffle=True, random_state=72)\n#     train_scores = []\n#     valid_scores = []\n#     print(f'param: max_depth={max_depth}, num_leaves={num_leaves},min_data_in_leaf={min_data_in_leaf} ')\n\n#     # ハイパーパラメータ\n#     params = {\"metric\": \"rmse\",\n#               \"max_depth\" : max_depth,\n#               \"num_leaves\": num_leaves,\n#               \"min_data_in_leaf\":min_data_in_leaf}\n    \n#     for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n#         tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n#         tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n#         lgb_train = lgb.Dataset(tr_x, tr_y)\n#         lgb_eval = lgb.Dataset(va_x, va_y)\n\n#         gbm = lgb.train(params,lgb_train,valid_sets=lgb_eval,num_boost_round=1000,early_stopping_rounds=100,verbose_eval=500)\n\n#         tr_pred = gbm.predict(tr_x)\n#         va_pred = gbm.predict(va_x)\n\n#         train_RMSE = np.sqrt(mean_squared_error(tr_y,tr_pred))\n#         valid_RMSE = np.sqrt(mean_squared_error(va_y,va_pred))\n\n#         train_scores.append(train_RMSE)\n#         valid_scores.append(valid_RMSE)\n\n#         print(f'fold{i}:  train_RMSE={train_RMSE}  valid_RMSE={valid_RMSE}')\n\n#     mean_train_scores = np.mean(train_scores)\n#     mean_valid_scores = np.mean(valid_scores)\n#     params_list.append((max_depth,num_leaves,min_data_in_leaf))\n#     scores_list.append(mean_valid_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_idx = np.argsort(scores_list)[-1]\n# best_param = params_list[best_idx]\n# print(f'best param: max_depth={best_param[0]}, num_leaves={best_param[1]},min_data_in_leaf={best_param[2]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best param: max_depth=16, num_leaves=8,min_data_in_leaf=2\nbest_param = [16,8,2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# クロスバリデーション\n5 kfold ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ハイパーパラメータ\n# チューニングで決定したbest_paramの値を代入\nparams = {\"metric\": \"mae\",\n          \"max_depth\":best_param[0],\n          \"num_leaves\":best_param[1],\n          \"min_data_in_leaf\":best_param[2]\n         }\n\n# 初期値\ntrain_scores = []\nvalid_scores = []\npred = np.zeros(test_x.shape[0])\npred_valid = np.zeros(train_x.shape[0])\n\n# 5kfold クロスバリデーション\n\nkf = KFold(n_splits = 5, shuffle = True, random_state=0)\n\nfor i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n    lgb_train = lgb.Dataset(tr_x, tr_y)\n    lgb_eval = lgb.Dataset(va_x, va_y)\n\n    gbm = lgb.train(params,lgb_train,valid_sets=lgb_eval,num_boost_round=10000,early_stopping_rounds=100,verbose_eval=500)\n    \n    tr_pred = gbm.predict(tr_x)\n    va_pred = gbm.predict(va_x)\n    pred += gbm.predict(test_x) / 5\n    \n    # version9 追記 各varid時に予測値を求めておく\n    pred_valid[va_idx] =  va_pred\n\n    train_MAE = mean_absolute_error(tr_y,tr_pred)\n    valid_MAE = mean_absolute_error(va_y,va_pred)\n\n    train_scores.append(train_MAE)\n    valid_scores.append(valid_MAE)\n                       \n    print(f'fold{i}:  train_MAE={train_MAE}  valid_MAE={valid_MAE}')\n\nmean_train_scores = np.mean(train_scores)\nmean_valid_scores = np.mean(valid_scores)\n\nprint(f'mean train MAE={mean_train_scores}  mean valid MAE={mean_valid_scores}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#予測値と正解値を描写する関数\ndef True_Pred_map(true,pred):\n    R2 = r2_score(true, pred) \n    plt.figure(figsize=(10,6))\n    ax = plt.subplot(111)\n    ax.scatter(x=true,y=pred)\n    ax.set_xlabel('True Value', fontsize=15)\n    ax.set_ylabel('Pred Value', fontsize=15)\n    ax.set_xlim(true.min()-0.1 , true.max()+0.1)\n    ax.set_ylim(pred.min()-0.1 , pred.max()+0.1)\n    x = np.linspace(true.min()-0.1, true.max()+0.1, 2)\n    y = x\n    ax.plot(x,y,'r-')\n    plt.text(0.1, 0.8, 'R^2 = {}'.format(str(round(R2, 5))), transform=ax.transAxes, fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"True_Pred_map(tr_y,tr_pred)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"True_Pred_map(va_y,va_pred)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Feature_importance\nlgb.plot_importance(gbm, importance_type=\"gain\",height=0.5, figsize=(8,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)ほぼWeekly_Sale_beforeで決めている。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# from graphviz import Digraph\n# lgb.create_tree_digraph(gbm) # figsize=(20,12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"version9 追記  \ntrainデータで予測値と正解のずれが大きいレコードを抽出し、ズレを補正する方法を探る","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tmp = train_x.copy()\ntrain_tmp[\"Weekly_Sales\"] = train_y\ntrain_tmp[\"pred\"] = pred_valid\ntrain_tmp[\"pred_diff\"] = train_tmp['Weekly_Sales']-train_tmp[\"pred\"]\ntrain_tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tmp[\"pred_diff\"].hist(bins=50).set_yscale(\"log\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tmp[(train_tmp[\"pred_diff\"]<-200000) | (train_tmp[\"pred_diff\"]>200000)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"week47 & dept72 がおおい。　←　isHoliday = 1なので、 重み5倍。これを修正するのが効きそう。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainとtestの各Deptのレコード数\ntmp = data_join2.pivot_table(index=\"Dept\",columns=\"category\",values=\"Type\",aggfunc=\"count\")\ntmp.plot(kind=\"bar\",figsize=(20,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainとtestの各Storeのレコード数\ntmp = data_join2.pivot_table(index=\"Store\",columns=\"category\",values=\"Type\",aggfunc=\"count\")\ntmp.plot(kind=\"bar\",figsize=(20,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 時系列的に並べてみる\nplt.figure(figsize=(20,5))\nsns.lineplot(x=\"WEEK\", y=\"Weekly_Sales\", data=data_join2[data_join2[\"Dept\"]==72],hue=\"YEAR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Week47の各deptでの反応の違い\nplt.figure(figsize=(20,5))\nsns.barplot(x=\"Dept\", y=\"Weekly_Sales\", data=data_join2[(data_join2[\"WEEK\"]==46) | (data_join2[\"WEEK\"]==47)],hue=\"WEEK\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dept72でのみ、WEEK47(＝ThanksgivingDay) の跳ね上がりが甚大。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# WEEKとHolidayが年によってずれていってないか？\ndata_join2[(data_join2[\"Store\"] == 1) & (data_join2[\"Dept\"] == 1) & (data_join2[\"Holiday_name\"].notnull())]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"WEEKはずれていない。OK","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store毎のDept72 & WEEK47　の反応の違い\nplt.figure(figsize=(20,5))\nsns.barplot(x=\"Store\", y=\"Weekly_Sales\", data=data_join2[(data_join2[\"Dept\"]==72) & ((data_join2[\"WEEK\"]==46) | (data_join2[\"WEEK\"]==47))],hue=\"WEEK\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data = data_join2[((data_join2[\"Dept\"]==72)|(data_join2[\"Dept\"]==92)) & (data_join2[\"WEEK\"]==47)],x=\"Weekly_Sale_before\",y=\"Weekly_Sales\",hue=\"YEAR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# もう一度、ズレ量の各パラメータ依存性を見返してみる\nfig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(20, 15))\nsns.scatterplot(data=train_tmp,x=\"Store\",y=\"pred_diff\",hue=\"YEAR\",ax=ax1,palette=\"Set2\")\nsns.scatterplot(data=train_tmp,x=\"Dept\",y=\"pred_diff\",hue=\"YEAR\",ax=ax2,palette=\"Set2\")\nsns.scatterplot(data=train_tmp,x=\"WEEK\",y=\"pred_diff\",hue=\"YEAR\",ax=ax3,palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dept72, WEEK47が目立つ。　その中でもYEAR 2011が少し外れ気味か？","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(20, 15))\nsns.scatterplot(data=train_tmp,x=\"Store\",y=\"pred_diff\",hue=\"Holiday_name\",ax=ax1,palette=\"Set2\")\nsns.scatterplot(data=train_tmp,x=\"Dept\",y=\"pred_diff\",hue=\"Holiday_name\",ax=ax2,palette=\"Set2\")\nsns.scatterplot(data=train_tmp,x=\"YEAR\",y=\"pred_diff\",hue=\"Holiday_name\",ax=ax3,palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Holiday_name=4 = WEEK47 = Thanksgivingday　が顕著。\nそこで特に1年前データとのずれが大きいということか？","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.scatterplot(data = train_tmp, x=\"Weekly_Sale_before\",y=\"pred_diff\", hue=\"Holiday_name\",palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(20, 15))\nsns.barplot(data=train_tmp[(train_tmp[\"Dept\"]==72) & (train_tmp[\"WEEK\"]==47)],x=\"Store\",y=\"pred_diff\",hue=\"YEAR\",ax=ax1,palette=\"Set2\")\nsns.barplot(data=train_tmp[(train_tmp[\"Dept\"]==72) & (train_tmp[\"WEEK\"]==47)],x=\"Store\",y=\"Weekly_Sales\",hue=\"YEAR\",ax=ax2,palette=\"Set2\")\nsns.barplot(data=train_tmp[(train_tmp[\"Dept\"]==72) & (train_tmp[\"WEEK\"]==47)],x=\"Store\",y=\"Weekly_Sale_before\",hue=\"YEAR\",ax=ax3,palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ずれの大きいDept72 & WEEK 47でも、前年の売上と相関大。なぜこれで大きくずれてしまう？  \n ・この特殊な条件だけのフラグを一つ作ってみる。  \n ・（この特殊な条件だけ、別のモデルで予測する？） ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Submission Fileの作成","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test_pred = test.copy(deep=True)\ntest_pred[\"Weekly_Sales\"] = pred\ntest_pred[['Store', 'Dept', 'Date']] = test_pred[['Store', 'Dept', 'Date']].astype(str)\ntest_pred[\"id\"] = test_pred[\"Store\"] + \"_\" + test_pred[\"Dept\"] + \"_\" + test_pred[\"Date\"]\n\n# test_pred = test_pred[[\"id\",\"Weekly_Sales\"]]\n# test_pred.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"version7で追記　\n2012年クリスマスの修正をbest kernel からパクる。  \nYEAR==2012, WEEK==52 かつ　last_sales > 2xWeekly_Sales　だったらlast week x 2.5/7を足す\nというのをstore, dept　ごとに判断して実行する","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# YEARとWEEKをtestデータで再度作る\ntest_pred[\"Date\"] = pd.to_datetime(test_pred[\"Date\"])\ntest_pred[\"YEAR\"] = test_pred[\"Date\"].dt.year\ntest_pred[\"MONTH\"] = test_pred[\"Date\"].dt.month\ntest_pred[\"WEEK\"] = test_pred[\"Date\"].dt.week\ntest_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Version15更新：Dept72 & WEEK47は、一年前の売上で置換\n# 先に作っていた 1年前の売上が入ったdata_salesをマージして、置換\n\n# 先程idづくりのためにstrにしていたのでintに戻す\ntest_pred[['Store', 'Dept']] = test_pred[['Store', 'Dept']].astype(int)\n\ntest_pred_bef = pd.merge(test_pred, data_sales, on=[\"Dept\",\"Store\",\"YEAR\",\"WEEK\"], how=\"left\")\ntest_pred_bef[(test_pred_bef[\"Dept\"] == 72) & (test_pred_bef[\"WEEK\"] == 47)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_bef[\"Weekly_Sales\"] = np.where((test_pred_bef[\"Dept\"] == 72) & (test_pred_bef[\"WEEK\"] == 47),  test_pred_bef[\"Weekly_Sale_before\"], test_pred_bef[\"Weekly_Sales\"])\ntest_pred_bef[(test_pred_bef[\"Dept\"] == 72) & (test_pred_bef[\"WEEK\"] == 47)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred2 = test_pred_bef.copy()\ntest_pred2[\"Weekly_Sales\"] = np.where((test_pred2[\"YEAR\"]==2012)&(test_pred2[\"WEEK\"]==52)&(test_pred2[\"Weekly_Sales\"].shift(1) > 2*test_pred2[\"Weekly_Sales\"])\\\n                                     ,test_pred2[\"Weekly_Sales\"]+test_pred2[\"Weekly_Sales\"].shift(1)*2.5/7, test_pred2[\"Weekly_Sales\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Version14で落とす\n#Version12 追記  \n#・**Holidayのweight * 5 を反映するために、学習・予測時にholidayは売上*5を行い、**最後に5で割り戻す処理を追加","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_pred2[\"Weekly_Sales\"] = np.where(test_pred2[\"IsHoliday\"]==1,test_pred2[\"Weekly_Sales\"]/5,test_pred2[\"Weekly_Sales\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred3 = test_pred2[[\"id\",\"Weekly_Sales\"]]\ntest_pred3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test_pred3[[\"id\",\"Weekly_Sales\"]]\nsubmission.to_csv('submission15.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}