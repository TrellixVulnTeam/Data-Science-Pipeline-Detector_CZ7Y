{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-09T02:35:25.884694Z","iopub.execute_input":"2022-05-09T02:35:25.884948Z","iopub.status.idle":"2022-05-09T02:35:25.89949Z","shell.execute_reply.started":"2022-05-09T02:35:25.88492Z","shell.execute_reply":"2022-05-09T02:35:25.898729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Descomprimindo para torna-los csv","metadata":{}},{"cell_type":"code","source":"import zipfile\n\ndef extract_func(zipped_data_path: str, unzipped_directory: str) -> None:\n    with zipfile.ZipFile(zipped_data_path, 'r') as zip_ref:\n        zip_ref.extractall(unzipped_directory)\n\nfiles = ['features.csv.zip', 'sampleSubmission.csv.zip', 'test.csv.zip', 'train.csv.zip']\n\ndata_path = '../input/walmart-recruiting-store-sales-forecasting/'\ndirectory_to_extract_to = 'unzip/'\n\n[\n    extract_func(\n        zipped_data_path=data_path+file,\n        unzipped_directory=directory_to_extract_to\n    )\n    for file in files\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:35:28.514741Z","iopub.execute_input":"2022-05-09T02:35:28.515014Z","iopub.status.idle":"2022-05-09T02:35:28.63821Z","shell.execute_reply.started":"2022-05-09T02:35:28.514986Z","shell.execute_reply":"2022-05-09T02:35:28.637343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Depois de descomprimir comecei uma análise exploratoria para entender meu dataset e como usa-lo","metadata":{}},{"cell_type":"code","source":"raw_data = pd.read_csv('unzip/train.csv')\nraw_data.tail(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:35:31.298869Z","iopub.execute_input":"2022-05-09T02:35:31.29916Z","iopub.status.idle":"2022-05-09T02:35:31.597458Z","shell.execute_reply.started":"2022-05-09T02:35:31.29913Z","shell.execute_reply":"2022-05-09T02:35:31.59597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Verificando se o tamanho da loja é relacionado com o tipo dela, aparentemente podemos dizer que sim","metadata":{}},{"cell_type":"code","source":"stores = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/stores.csv')\nstores = stores.sort_values(by='Size',ascending=True)\n\navg_size_store_per_type = stores[['Type','Size']].groupby(['Type']).median()\nsns.barplot(x=avg_size_store_per_type.index,y=avg_size_store_per_type.Size)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:35:35.063362Z","iopub.execute_input":"2022-05-09T02:35:35.063718Z","iopub.status.idle":"2022-05-09T02:35:35.238966Z","shell.execute_reply.started":"2022-05-09T02:35:35.063655Z","shell.execute_reply":"2022-05-09T02:35:35.237799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Verificando abaixo, se a quantidade dos dados sobre as lojas está bem distribuida ao longo do tempo, e se não existe um \"gap\" em alguma parte da série temporal","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nraw_data.sort_values(by=['Date'],ascending=True)\nregisters_per_day = raw_data[['Store','Dept','Date']].groupby(['Date']).count()\nregisters_per_day\nraw_data[raw_data.Date == '2010-02-05']\n\nsns.barplot(x=registers_per_day.index,y=registers_per_day.Store)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:35:37.33382Z","iopub.execute_input":"2022-05-09T02:35:37.334087Z","iopub.status.idle":"2022-05-09T02:35:40.34057Z","shell.execute_reply.started":"2022-05-09T02:35:37.33406Z","shell.execute_reply":"2022-05-09T02:35:40.339749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\nLabor Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\nThanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\nChristmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13","metadata":{}},{"cell_type":"markdown","source":"Feriados tem sim um maior volume de vendas que semana sem feriados, porem essa diferença é menor que o esperado","metadata":{}},{"cell_type":"code","source":"holiday_evaluation = raw_data[['Weekly_Sales','IsHoliday']].groupby(['IsHoliday']).median()\nholiday_evaluation\nsns.barplot(x=holiday_evaluation.index,y=holiday_evaluation.Weekly_Sales)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:35:46.557254Z","iopub.execute_input":"2022-05-09T02:35:46.558638Z","iopub.status.idle":"2022-05-09T02:35:46.732432Z","shell.execute_reply.started":"2022-05-09T02:35:46.558568Z","shell.execute_reply":"2022-05-09T02:35:46.73178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Selecione algumas lojas para conseguir ver o comportamento de cada uma, para entender tendencias e discrepancias entre elas","metadata":{}},{"cell_type":"code","source":"selected_stores = raw_data[raw_data.Store > 20]\nselected_stores = selected_stores[selected_stores.Store < 40]\n\nselected_stores['Year'] = pd.to_datetime(selected_stores.Date).dt.isocalendar().year\nselected_stores['Week'] = pd.to_datetime(selected_stores.Date).dt.isocalendar().week\n\ng = sns.FacetGrid(selected_stores, col=\"Store\", col_wrap=5)\ng.map(sns.lineplot, \"Week\", \"Weekly_Sales\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:35:48.816434Z","iopub.execute_input":"2022-05-09T02:35:48.817214Z","iopub.status.idle":"2022-05-09T02:36:22.799801Z","shell.execute_reply.started":"2022-05-09T02:35:48.817181Z","shell.execute_reply":"2022-05-09T02:36:22.798439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maioria das lojas tem o mesmo pico de vendas no fim do ano, mas algumas lojas não possuem essa variabilidade, provavelmente atrelada ao tipo de loja que estamos falando, mas que precisa ser validada pelos dados","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(selected_stores, col=\"Year\", col_wrap=5)\ng.map(sns.lineplot, \"Week\", \"Weekly_Sales\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:37:30.436435Z","iopub.execute_input":"2022-05-09T02:37:30.436727Z","iopub.status.idle":"2022-05-09T02:37:39.302937Z","shell.execute_reply.started":"2022-05-09T02:37:30.436692Z","shell.execute_reply":"2022-05-09T02:37:39.302155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mesmo tendo 4 feriados no conjunto de dados, podemos ver que existem dois picos muito maiores no fim do ano, ou seja, alguns feriados possuem mais importancia que outras quando falamos de venda.\nUma hipotese, é que os descontos tambem sejam maiores por volta dessas datas.\nOu seja, esses feriados de fim de ano podem ser usados ao nosso favor quando modelando, fazendo assim que eles se tornem uma feature do modelo","metadata":{}},{"cell_type":"code","source":"end_of_the_year = selected_stores[selected_stores.Week > 45]\n\ng = sns.FacetGrid(end_of_the_year, col=\"Year\", col_wrap=5)\ng.map(sns.lineplot, \"Week\", \"Weekly_Sales\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:37:46.120197Z","iopub.execute_input":"2022-05-09T02:37:46.120848Z","iopub.status.idle":"2022-05-09T02:37:47.321962Z","shell.execute_reply.started":"2022-05-09T02:37:46.120806Z","shell.execute_reply":"2022-05-09T02:37:47.320422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vemos dois pontos que se destacam, são eles Natal e Dia de Ação de Graças, que tem uma importancia na venda ainda maior que os outros feriados observados","metadata":{}},{"cell_type":"markdown","source":"Abaixo estou tentando olhar para os indicatores que o desafio oferece, vendo se algum deles trás alguma informação sobre minha váriavel alvo","metadata":{}},{"cell_type":"code","source":"additional_features = pd.read_csv('unzip/features.csv')\nadditional_features['Year'] = pd.to_datetime(additional_features.Date).dt.isocalendar().year\nadditional_features['Week'] = pd.to_datetime(additional_features.Date).dt.isocalendar().week\n\nraw_data['Year'] = pd.to_datetime(raw_data.Date).dt.isocalendar().year\nraw_data['Week'] = pd.to_datetime(raw_data.Date).dt.isocalendar().week\n\nFuel_vs_Sales = pd.merge(\n    left=raw_data,\n    right=additional_features,\n    how='left',\n    left_on=['Store', 'Year', 'Week'],\n    right_on=['Store', 'Year', 'Week']\n)\n\nsns.lineplot(x=Fuel_vs_Sales.Fuel_Price,y=Fuel_vs_Sales.Weekly_Sales)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:37:51.341929Z","iopub.execute_input":"2022-05-09T02:37:51.342189Z","iopub.status.idle":"2022-05-09T02:38:26.372062Z","shell.execute_reply.started":"2022-05-09T02:37:51.34216Z","shell.execute_reply":"2022-05-09T02:38:26.371145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preço do combustivel não se mostrou uma variavel ","metadata":{}},{"cell_type":"code","source":"sns.lineplot(x=Fuel_vs_Sales.Unemployment,y=Fuel_vs_Sales.Weekly_Sales)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:38:43.516693Z","iopub.execute_input":"2022-05-09T02:38:43.51699Z","iopub.status.idle":"2022-05-09T02:39:03.461807Z","shell.execute_reply.started":"2022-05-09T02:38:43.516959Z","shell.execute_reply":"2022-05-09T02:39:03.460746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Desemprego não mostra uma correlação tão \"limpa\" com as vendas, porem pode existir algo ali no meio que possa potencializar isso, porem precisaria de mais tempo investigando essa variável para achar a maneira correta de utilizar no modelo","metadata":{}},{"cell_type":"code","source":"experimentation_set = pd.read_csv('unzip/train.csv')\nstores = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/stores.csv')\n\nfull_set = pd.merge(\n    left=experimentation_set,\n    right=stores,\n    how='left',\n    left_on='Store',\n    right_on='Store'\n)\n\nfull_set['Week'] = pd.to_datetime(full_set.Date).dt.isocalendar().week\nfull_set['Year'] = pd.to_datetime(full_set.Date).dt.isocalendar().year\nfull_set['Date'] = pd.to_datetime(full_set.Date)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:39:18.042292Z","iopub.execute_input":"2022-05-09T02:39:18.042585Z","iopub.status.idle":"2022-05-09T02:39:19.209426Z","shell.execute_reply.started":"2022-05-09T02:39:18.042552Z","shell.execute_reply":"2022-05-09T02:39:19.208263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation_set = pd.read_csv('unzip/test.csv')\n\nadditional_features.dropna()\nadditional_features.sort_values(by='Date',ascending=False)\n\ng = sns.FacetGrid(additional_features, col=\"Year\")\ng.map(sns.lineplot, \"Week\", \"MarkDown1\")\n\ng = sns.FacetGrid(full_set, col=\"Year\")\ng.map(sns.lineplot, \"Week\", \"Weekly_Sales\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:39:32.189635Z","iopub.execute_input":"2022-05-09T02:39:32.189926Z","iopub.status.idle":"2022-05-09T02:39:55.049836Z","shell.execute_reply.started":"2022-05-09T02:39:32.189889Z","shell.execute_reply":"2022-05-09T02:39:55.047717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Os markdowns são the categorias diferentes, ou seja, cada um provavelmente tem sua peculiaridade e relação com as vendas finais da semana\nAssumindo que as venda são uma série temporal e o comportamento passado se assemelha ao do futuro, decidi tentar modelar esse markdown como uma porcentagem, ou seja, olhando para o passado, em relação ao periodo de uma ano, qual a porcentagem de markdown normalmente acontece naquele período do ano em relação ao maximo de markdown possivel.","metadata":{}},{"cell_type":"code","source":"markdowns = [\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\",\"Week\"]\n\nenginnered_markdown = additional_features[markdowns].groupby(by=\"Week\").median()\nenginnered_markdown = enginnered_markdown/enginnered_markdown.max()\nenginnered_markdown = enginnered_markdown.fillna(0)\n\nenginnered_markdown","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:02.24191Z","iopub.execute_input":"2022-05-09T02:40:02.242196Z","iopub.status.idle":"2022-05-09T02:40:02.2784Z","shell.execute_reply.started":"2022-05-09T02:40:02.242167Z","shell.execute_reply":"2022-05-09T02:40:02.27712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Após modelar o MarkDown, decidi adicionar as features relacionadas as descobertas de maiores vendas no natal e na época de acão de graças","metadata":{}},{"cell_type":"code","source":"full_set = pd.merge(\n    left=full_set,\n    right=enginnered_markdown,\n    how=\"left\",\n    left_on=\"Week\",\n    right_on=\"Week\"\n)\n\nfull_set['IsChristmas'] = full_set['Week'].apply(lambda x: 1 if x == 51 else 0)\n\nfull_set['IsThanksgiving'] = full_set['Week'].apply(lambda x: 1 if x == 47 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:06.027754Z","iopub.execute_input":"2022-05-09T02:40:06.028031Z","iopub.status.idle":"2022-05-09T02:40:06.786552Z","shell.execute_reply.started":"2022-05-09T02:40:06.028Z","shell.execute_reply":"2022-05-09T02:40:06.784916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_set","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:09.53481Z","iopub.execute_input":"2022-05-09T02:40:09.535103Z","iopub.status.idle":"2022-05-09T02:40:09.567204Z","shell.execute_reply.started":"2022-05-09T02:40:09.535071Z","shell.execute_reply":"2022-05-09T02:40:09.566519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Essa é uma simples alteração, fazendo com que as categorias virem número para que possam alimentar o modelo. Poderia ter feito um one hot encoding aqui, mas como elas tem uma relação de ordem entre elas, ou seja, uma maior que a outra, preferi essa solução para preservar esta propriedade","metadata":{}},{"cell_type":"code","source":"def categories_to_ordinal(categorie: str):\n    if categorie == 'A':\n        return 1\n    if categorie == 'B':\n        return 2\n    return 3\n\nfull_set['ModType'] = full_set['Type'].apply(lambda categorie: categories_to_ordinal(categorie)) ","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:15.319745Z","iopub.execute_input":"2022-05-09T02:40:15.320145Z","iopub.status.idle":"2022-05-09T02:40:15.680118Z","shell.execute_reply.started":"2022-05-09T02:40:15.320115Z","shell.execute_reply":"2022-05-09T02:40:15.679018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como os dados aqui são limitados, selecione para o meu conjunto de treino tudo que não é 2011, e para teste o ano todo de 2011. Fiz isso para que conseguisse ter confiança em todas as partes do ano que estou realizando a predição. Preservando uma série histórica toda para a validação","metadata":{}},{"cell_type":"code","source":"train_set = full_set[full_set.Year != 2011]\ntest_set = full_set[full_set.Year == 2011]\n\nfeatures = ['Store','Dept','Week','IsHoliday','ModType', 'IsChristmas','IsThanksgiving', 'MarkDown1' ,'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\ntarget = 'Weekly_Sales'\n\nX_train = train_set[features]\ny_train = train_set[target]\n\nX_test = test_set[features]\ny_real = test_set[target]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:17.4656Z","iopub.execute_input":"2022-05-09T02:40:17.465902Z","iopub.status.idle":"2022-05-09T02:40:17.574746Z","shell.execute_reply.started":"2022-05-09T02:40:17.465871Z","shell.execute_reply":"2022-05-09T02:40:17.573334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Esse abaixo é o codigo para conseguir observar o erro ponderado dos modelos treinados, aproximando a performance segundo o que foi dito no desafio","metadata":{}},{"cell_type":"code","source":"def WMAE(dataset, real, predicted):\n    weights = dataset.IsHoliday.apply(lambda weight: 5 if weight else 1)\n    return np.round(np.sum(weights*abs(real-predicted))/(np.sum(weights)), 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:21.232981Z","iopub.execute_input":"2022-05-09T02:40:21.233254Z","iopub.status.idle":"2022-05-09T02:40:21.238897Z","shell.execute_reply.started":"2022-05-09T02:40:21.233223Z","shell.execute_reply":"2022-05-09T02:40:21.237901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O primeiro modelo testado foi o random forest, com uma variação no parametro de profundidade.\nAté 25 ele mostra uma melhora, depois se torna insignificante ou até pior.\nResolvi começar por random forest pois estava com medo dos resultados dos dias de feriado, acreditava que esse modelo pudesse contornar isso, visto que ele lida bem com esses *outliers*","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nmax_depth_options = list(range(20,25))\n\nfor depth in max_depth_options:\n    regr = RandomForestRegressor(max_depth=depth, random_state=0)\n    regr.fit(X_train, y_train)\n    y_predicted = regr.predict(X_test)\n    print(f\"Depth {depth}: \" + str(WMAE(X_test, y_real, y_predicted)))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T21:38:20.458275Z","iopub.execute_input":"2022-05-07T21:38:20.458598Z","iopub.status.idle":"2022-05-07T21:47:19.12721Z","shell.execute_reply.started":"2022-05-07T21:38:20.458566Z","shell.execute_reply":"2022-05-07T21:47:19.126269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x=test_set.Date,y=y_real)\nsns.lineplot(x=test_set.Date,y=y_predicted)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T21:48:45.726268Z","iopub.execute_input":"2022-05-07T21:48:45.726647Z","iopub.status.idle":"2022-05-07T21:48:51.647647Z","shell.execute_reply.started":"2022-05-07T21:48:45.726612Z","shell.execute_reply":"2022-05-07T21:48:51.646624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Depois de testar esse primeiro modelo, resolvi ir para o xgboost.\nAmbos fazem uso de ensamble learning (combinação de dois ou mais modelos para obter um melhor) e decision trees mas agora usando gradient boosting (combina os modelos sequencialmente) e não bagging (primeiro se criam varios subsets das amostras do dataset de treino, se treinam modelos nessas amostras, por fim uma média é criada para gerar uma estimativa mais assertiva) como no modelo de random forest.","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\nregressor = xgb.XGBRegressor(\n    n_estimators=120,\n    reg_lambda=1,\n    gamma=0,\n    max_depth=25\n)\n\nX_train['Week'] = X_train['Week'].astype('int')\n\nregressor.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:40:31.912228Z","iopub.execute_input":"2022-05-09T02:40:31.912858Z","iopub.status.idle":"2022-05-09T02:42:34.509387Z","shell.execute_reply.started":"2022-05-09T02:40:31.912823Z","shell.execute_reply":"2022-05-09T02:42:34.508641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test['Week'] = X_test['Week'].astype('int')\n\ny_pred = regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:43:24.057152Z","iopub.execute_input":"2022-05-09T02:43:24.057535Z","iopub.status.idle":"2022-05-09T02:43:27.322445Z","shell.execute_reply.started":"2022-05-09T02:43:24.057501Z","shell.execute_reply":"2022-05-09T02:43:27.321813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x=test_set.Date,y=y_real)\nsns.lineplot(x=test_set.Date,y=y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:43:37.103031Z","iopub.execute_input":"2022-05-09T02:43:37.103978Z","iopub.status.idle":"2022-05-09T02:43:47.881564Z","shell.execute_reply.started":"2022-05-09T02:43:37.103944Z","shell.execute_reply":"2022-05-09T02:43:47.880552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WMAE(X_test, y_real, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T02:43:51.608073Z","iopub.execute_input":"2022-05-09T02:43:51.608356Z","iopub.status.idle":"2022-05-09T02:43:51.715896Z","shell.execute_reply.started":"2022-05-09T02:43:51.608326Z","shell.execute_reply":"2022-05-09T02:43:51.715027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A diferença entre eles ficou bem baixa, então para mim a escolha ficaria a cargo de performance de treino/escalabilidade, sendo assim acredito que para um ambinete de produção usar o XGBoost seria melhor devido a implementação da biblioteca","metadata":{}}]}