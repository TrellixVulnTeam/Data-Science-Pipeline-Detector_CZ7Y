{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Acknowledgements**\n#### This kernel uses such good kernels:\n   - https://www.kaggle.com/ayushikaushik/eda-modelling-cross-validation\n   - https://www.kaggle.com/yepp2411/walmart-prediction-1-eda-with-time-and-space\n   - https://www.kaggle.com/avelinocaio/walmart-store-sales-forecasting","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n## **Table of Contents**\n1. [Import libraries](#1)\n2. [Download datasets](#2)\n3. [EDA](#3)\n4. [Preparing to modeling](#4)\n5. [Prediction](#5)","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"1\"></a>\n## 1. Import libraries \n##### [Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.special import boxcox1p\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pandasql import sqldf\npysqldf = lambda q: sqldf(q, globals())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"2\"></a>\n## 2. Download datasets \n##### [Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/features.csv.zip')\ntrain = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/train.csv.zip')\nstores = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/stores.csv')\ntest = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/test.csv.zip')\nsample_submission = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/sampleSubmission.csv.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stores.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_feat = features.merge(stores, how='inner', on='Store')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_feat.head(5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"3\"></a>\n## 3. EDA\n##### [Back to Table of Contents](#0.1)\n\n","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(full_feat.dtypes, columns=['Type'])\nfull_feat.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'Type_Train': train.dtypes, 'Type_Test': test.dtypes})","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train info\\n\")\ntrain.info()\nprint(\"***\"*16,\"\\ntest info\\n\")\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_feat.Date = pd.to_datetime(full_feat.Date)\ntrain.Date = pd.to_datetime(train.Date)\ntest.Date = pd.to_datetime(test.Date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_feat['Week'] = full_feat.Date.dt.isocalendar().week\nfull_feat['Year'] = full_feat.Date.dt.isocalendar().year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_feat.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detail = train.merge(full_feat, \n                           how='inner',\n                           on=['Store','Date','IsHoliday']).sort_values(by=['Store',\n                                                                            'Dept',\n                                                                            'Date']).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_detail = test.merge(full_feat, \n                           how='inner',\n                           on=['Store','Date','IsHoliday']).sort_values(by=['Store',\n                                                                            'Dept',\n                                                                            'Date']).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detail.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_detail.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_null = (train_detail.isnull().sum()/len(train_detail)).sort_values(ascending = False)\ntr_null2 = train_detail.isnull().sum()\nnull_data = pd.concat([tr_null,tr_null2],axis = 1).rename(columns = {0:\"% of Null\", \n                                                                     1:\"# of Null\"})\nnull_data = null_data[null_data['# of Null']>1]\nnull_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pysqldf(\"\"\"\nSELECT\n    T.*,\n    case\n        when ROW_NUMBER() OVER(partition by Year order by week) = 1 then 'Super Bowl'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 2 then 'Labor Day'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 3 then 'Thanksgiving'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 4 then 'Christmas'\n    end as Holyday,\n    case\n        when ROW_NUMBER() OVER(partition by Year order by week) = 1 then 'Sunday'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 2 then 'Monday'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 3 then 'Thursday'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 4 and Year = 2010 then 'Saturday'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 4 and Year = 2011 then 'Sunday'\n        when ROW_NUMBER() OVER(partition by Year order by week) = 4 and Year = 2012 then 'Tuesday'\n    end as Day\n    from(\n        SELECT DISTINCT\n            Year,\n            Week,\n            case \n                when Date <= '2012-11-01' then 'Train Data' else 'Test Data' \n            end as Data_type\n        FROM full_feat\n        WHERE IsHoliday = True) as T\"\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_sales_2010 = train_detail[train_detail.Year==2010]['Weekly_Sales'].groupby(train_detail['Week']).mean()\nweekly_sales_2011 = train_detail[train_detail.Year==2011]['Weekly_Sales'].groupby(train_detail['Week']).mean()\nweekly_sales_2012 = train_detail[train_detail.Year==2012]['Weekly_Sales'].groupby(train_detail['Week']).mean()\nplt.figure(figsize=(20,8))\nsns.lineplot(weekly_sales_2010.index, weekly_sales_2010.values)\nsns.lineplot(weekly_sales_2011.index, weekly_sales_2011.values)\nsns.lineplot(weekly_sales_2012.index, weekly_sales_2012.values)\nplt.grid()\nplt.xticks(np.arange(1, 53, step=1))\nplt.legend(['2010', '2011', '2012'], loc='best', fontsize=16)\nplt.title('Average Weekly Sales - Per Year', fontsize=18)\nplt.ylabel('Sales', fontsize=16)\nplt.xlabel('Week', fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detail.loc[(train_detail.Year==2010) & (train_detail.Week==13), 'IsHoliday'] = True\ntrain_detail.loc[(train_detail.Year==2011) & (train_detail.Week==16), 'IsHoliday'] = True\ntrain_detail.loc[(train_detail.Year==2012) & (train_detail.Week==14), 'IsHoliday'] = True\ntest_detail.loc[(test_detail.Year==2013) & (test_detail.Week==13), 'IsHoliday'] = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_sales_mean = train_detail['Weekly_Sales'].groupby(train_detail['Date']).mean()\nweekly_sales_median = train_detail['Weekly_Sales'].groupby(train_detail['Date']).median()\nplt.figure(figsize=(20,8))\nsns.lineplot(weekly_sales_mean.index, weekly_sales_mean.values)\nsns.lineplot(weekly_sales_median.index, weekly_sales_median.values)\nplt.grid()\nplt.legend(['Mean', 'Median'], loc='best', fontsize=16)\nplt.title('Weekly Sales - Mean and Median', fontsize=18)\nplt.ylabel('Sales', fontsize=16)\nplt.xlabel('Date', fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_sales = train_detail['Weekly_Sales'].groupby(train_detail['Store']).mean()\nplt.figure(figsize=(20,8))\nsns.barplot(weekly_sales.index, weekly_sales.values, palette='dark')\nplt.grid()\nplt.title('Average Sales - per Store', fontsize=18)\nplt.ylabel('Sales', fontsize=16)\nplt.xlabel('Store', fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekly_sales = train_detail['Weekly_Sales'].groupby(train_detail['Dept']).mean()\nplt.figure(figsize=(25,8))\nsns.barplot(weekly_sales.index, weekly_sales.values, palette='dark')\nplt.grid()\nplt.title('Average Sales - per Dept', fontsize=18)\nplt.ylabel('Sales', fontsize=16)\nplt.xlabel('Dept', fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"white\")\n\ncorr = train_detail.corr()\n\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\nf, ax = plt.subplots(figsize=(20, 15))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nplt.title('Correlation Matrix', fontsize=18)\n\nsns.heatmap(corr, mask=mask, cmap='summer', vmax=.3, center=0,\n            square=True, linewidths=.5, \n            cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detail = train_detail.drop(columns=\n                                 ['Fuel_Price','MarkDown1',\n                                  'MarkDown2','MarkDown3',\n                                  'MarkDown4','MarkDown5'])\ntest_detail = test_detail.drop(columns=\n                               ['Fuel_Price','MarkDown1',\n                                'MarkDown2','MarkDown3',\n                                'MarkDown4','MarkDown5'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discrete_plot(feature):\n    fig = plt.figure(figsize=(20,8))\n    gs = GridSpec(1,2)\n    sns.boxplot(y=train_detail.Weekly_Sales, x=train_detail[feature], ax=fig.add_subplot(gs[0,0]))\n    plt.ylabel('Sales', fontsize=16)\n    plt.xlabel(feature, fontsize=16)\n    sns.stripplot(y=train_detail.Weekly_Sales, x=train_detail[feature], ax=fig.add_subplot(gs[0,1]))\n    plt.ylabel('Sales', fontsize=16)\n    plt.xlabel(feature, fontsize=16)\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_continuous_plot(feature):\n    \n    fig = plt.figure(figsize=(18,8))\n    gs = GridSpec(1,2)\n    \n    j = sns.distplot(train_detail[feature], ax=fig.add_subplot(gs[0,1]), color = 'green')\n\n    plt.title('Distribution\\n')\n    \n    j = sns.scatterplot(y=train_detail['Weekly_Sales'], \n                        x=train_detail[feature], ax=fig.add_subplot(gs[0,0]), color = 'red')\n\n    plt.title('Linear\\n' + 'Corr: ' + str(np.round(train_detail['Weekly_Sales']\\\n                                                   .corr(train_detail[feature]),2)) + ', Skew: ' + \n               str(np.round(stats.skew(train_detail[feature], nan_policy='omit'),2)))\n    \n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_discrete_plot('IsHoliday')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_discrete_plot('Type')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = stores.Type.value_counts().index.tolist()\nsizes = stores.Type.value_counts().values.tolist()\nexplode = (0.05, 0.02, 0)\nplt.figure(figsize=(5,5))\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', startangle=60,\n        textprops={'fontsize': 18},colors=['#f538cc','#fa5282','#facc69'])\nplt.title('Different types of stores');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detail.Type.replace({'A':1,'B':2,'C':3}, inplace = True)\ntest_detail.Type.replace({'A':1,'B':2,'C':3}, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_continuous_plot('Temperature')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_continuous_plot('CPI')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_continuous_plot('Unemployment')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_continuous_plot('Size')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detail = train_detail.drop(columns=['Temperature','Unemployment','CPI'])\ntest_detail = test_detail.drop(columns=['Temperature','Unemployment','CPI'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4\"></a>\n## 4. Preparing to modeling\n##### [Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"train_detail.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_detail[['Store','Dept','IsHoliday','Size','Week','Type','Year']]\nY_train = train_detail['Weekly_Sales']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"5\"></a>\n## 5. Prediction\n##### [Back to Table of Contents](#0.1)\n","metadata":{}},{"cell_type":"code","source":"RF = RandomForestRegressor(n_estimators=58, max_depth=27, max_features=6, min_samples_split=3, min_samples_leaf=1)\nRF.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,12))\nplot_tree(RF.estimators_[0], filled=True, rounded=True,feature_names=X_train.columns) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_detail[['Store', 'Dept', 'IsHoliday', 'Size', 'Week', 'Type', 'Year']]\npredict = RF.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Final = X_test[['Store', 'Dept', 'Week']]\nFinal['Weekly_Sales'] = predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Final_adj = pysqldf(\"\"\"\n    SELECT\n        Store,\n        Dept,\n        Week,\n        Weekly_Sales,\n        case \n            when Week = 52 and last_sales > 2*Weekly_Sales then Weekly_Sales+(3/7)*last_sales\n            else Weekly_Sales \n        end as Weekly_Sales_Adjusted\n    from(\n        SELECT\n            Store, \n            Dept, \n            Week, \n            Weekly_Sales,\n            case \n                when Week = 52 then lag(Weekly_Sales) over(partition by Store, Dept) \n            end as last_sales\n        from Final)\"\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['Weekly_Sales'] = Final_adj['Weekly_Sales_Adjusted']\nsample_submission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}