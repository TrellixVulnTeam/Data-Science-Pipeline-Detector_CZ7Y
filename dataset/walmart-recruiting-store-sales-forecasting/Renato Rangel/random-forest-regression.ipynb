{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nimport seaborn as sns\nsns.set(style=\"ticks\", palette=\"pastel\")\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# got this code from here https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n\ndef plot_learning_curve(estimator, \n                        title, \n                        X, \n                        y,\n                        scorer,\n                        ylim=None, \n                        cv=None,\n                        n_jobs=None, \n                        train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(estimator,\n                                                            X,\n                                                            y,\n                                                            cv=cv,\n                                                            scoring=scorer,\n                                                            n_jobs=n_jobs,\n                                                            train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_error(test_y, predicted, weights):\n    return mean_absolute_error(test_y, predicted, sample_weight=weights)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparação dos dados"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"features = pd.read_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip')\nstores = pd.read_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/stores.csv')\ntrain = pd.read_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nstores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(train, features, on=['Store','Date','IsHoliday'], how='inner')\ndf = pd.merge(df, stores, on='Store', how='inner')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.merge(test, features, on=['Store','Date','IsHoliday'], how='inner')\ntest = pd.merge(test, stores, on='Store', how='inner')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])\ndf['year'] = df['Date'].dt.year\ndf['week'] = df['Date'].dt.week\n\ntest_id = test[\"Store\"].astype(str) + \"_\" + test[\"Dept\"].astype(str) + \"_\" + test[\"Date\"].astype(str)\n\ntest['Date'] = pd.to_datetime(test['Date'])\ntest['year'] = test['Date'].dt.year\ntest['week'] = test['Date'].dt.week","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análise Exploratória"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Date\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Date\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.lineplot(x=\"Date\", hue=\"year\", y=\"Weekly_Sales\", data=df)\nplt.xticks(rotation=15)\nplt.title('Vendas de cada ano por semana')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pelo gráfico acima, é possível perceber que existe um aumento das vendas em alguns períodos do ano, sazonalidade."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nsns.boxplot(x=\"IsHoliday\", \n            y=\"Weekly_Sales\",\n#             orient=\"h\",\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As vendas nas semanas de feriados apresentam valores semanais maiores que as semanas sem feriados "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.boxplot(x=\"Dept\", \n            y=\"Weekly_Sales\",\n#             orient=\"h\",\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.boxplot(x=\"Store\", \n            y=\"Weekly_Sales\",\n#             orient=\"h\",\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As vendas por departamento apresentaram uma diferença de valor vendido maior do que as vendas por loja. Acredito que a feature departamento possa ser um bom preditor das vendas semanais."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nsns.boxplot(x=\"Type\", \n            y=\"Weekly_Sales\",\n            data=df)\nsns.despine(offset=10, trim=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nsns.scatterplot(x=\"Type\", y=\"Size\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os tipos (A, B, C) tem relação com a variável tamanho."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nsns.scatterplot(x=\"Size\", y=\"Weekly_Sales\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nsns.scatterplot(x=\"year\",\n                y=\"Fuel_Price\",\n                data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extração de features"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['Date']\ndel test[\"Date\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_type = LabelEncoder()\ndf['Type'] = lb_type.fit_transform(df['Type'])\ntest['Type'] = lb_type.transform(test['Type'])\n\nlb_is_holiday = LabelEncoder()\ndf['IsHoliday'] = lb_is_holiday.fit_transform(df['IsHoliday'])\ntest['IsHoliday'] = lb_is_holiday.transform(test['IsHoliday'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"si = SimpleImputer()\nsi.fit(df[[\"CPI\"]]) \ntest[\"CPI\"] = si.transform(test[[\"CPI\"]])\n\nsi = SimpleImputer()\nsi.fit(df[[\"Unemployment\"]]) \ntest[\"Unemployment\"] = si.transform(test[[\"Unemployment\"]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seleção de features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = df.corr().round(decimals=2)\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(12, 10))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dados faltantes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().mean() * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=[\"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\"], inplace=True)\ntest.drop(columns=[\"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\"], inplace=True)\n\ndf.drop(columns=[\"Type\"], inplace=True)\ntest.drop(columns=[\"Type\"], inplace=True)\n\ndf.drop(columns=[\"Fuel_Price\"], inplace=True)\ntest.drop(columns=[\"Fuel_Price\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As variáveis do tipo Markdown apresentaram em torno de 70% de dados faltantes e uma correlação muito fraca com o target, portanto serão retiradas do treinamento.\n\nAs variáveis \"Size\" e \"Type\" apresentaram uma correlação muito alta entre si, portanto será removida a variável \"Type\" por ter menor correlação com o target. Isso também ocorre entre a variável \"Fuel_Price\" e \"Year\". \"Fuel_Price\" será removida.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Modelagem"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, validation = train_test_split(df, test_size=.3, random_state=1)\n\ndef prepare_data(train):\n    X_train = train.drop('Weekly_Sales', axis=1)\n    y_train = train['Weekly_Sales']\n    X_train.loc[:, \"extra\"] = X_train['IsHoliday'].replace(1, 5).replace(0, 1)\n    return X_train, y_train\n\nX_train, y_train = prepare_data(train)\nX_validation, y_validation = prepare_data(validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, validation, si, df, corr, features, stores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_regression = LinearRegression()\ndecision_tree = DecisionTreeRegressor()\n\nlinear_regression.fit(X_train.drop(columns=[\"extra\"]), y_train)\npredicted = linear_regression.predict(X_validation.drop(columns=[\"extra\"]))\nprint(calculate_error(y_validation, predicted, X_validation[\"extra\"]))\n\ndecision_tree.fit(X_train.drop(columns=[\"extra\"]), y_train)\npredicted = decision_tree.predict(X_validation.drop(columns=[\"extra\"]))\nprint(calculate_error(y_validation, predicted, X_validation[\"extra\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Foram testadas duas abordagens de modelos preditivos: Regressão Linear (linear) e Árvore de decisão (não-linear tree-based). A árvore de decisão apresentou um resultado melhor então a solução proposta nessa modelagem será uma Random Forest por estar na mesma família da Árvore de decisão e ser um modelo mais robusto."},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_scorer(estimator, X, y, sample_weight=None):\n    return calculate_error(y, estimator.predict(X), X[\"extra\"])\n    \ndef remove_extra(X):\n    return X.drop(columns=[\"extra\"])\n\npipe = Pipeline(steps=[(\"preprocessing\", FunctionTransformer(remove_extra, validate=False)),\n                      (\"regressor\", RandomForestRegressor())])\n\nsearch_space = {\"regressor\": [RandomForestRegressor()],\n                 \"regressor__n_estimators\": [100, 200, 300, 600],\n                 \"regressor__max_depth\": [10, 20, 30, 40, 50, 60, 70, 80],\n                 \"regressor__min_samples_leaf\": [1, 2, 4],\n                 \"regressor__min_samples_split\": [2, 8, 12]}\n\n\nrf_random = RandomizedSearchCV(estimator=pipe, \n                               param_distributions=search_space, \n                               n_iter = 1, \n                               cv = 3, \n                               verbose=2, \n                               random_state=42, \n                               n_jobs = -1,\n                               scoring=new_scorer)\n\n# Fit the random search model\nrf_random.fit(X_train, y_train)\n\nmodel = rf_random.best_estimator_\n\nprint(rf_random.best_estimator_)\nprint(rf_random.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = \"Learning Curves Random Forest\"\n\nlc_svm = plot_learning_curve(model, title, X_train, y_train, scorer=new_scorer, ylim=(0.0, 4000.0), cv=3, n_jobs=-1)\nlc_svm.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculate_error(model.predict(X_train), y_train, X_train[\"extra\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculate_error(model.predict(X_validation), y_validation, X_validation[\"extra\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submissão"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[:, \"extra\"] = test['IsHoliday'].replace(1, 5).replace(0, 1)\n\npredicted = model.predict(test)\ntest[\"Id\"] = test_id\ntest[\"Weekly_Sales\"] = predicted\ntest[[\"Id\", \"Weekly_Sales\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}