{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip\n!unzip /kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip\n!unzip /kaggle/input/walmart-recruiting-store-sales-forecasting/sampleSubmission.csv.zip\n!unzip /kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/working/train.csv\", parse_dates=['Date'], names=['Store','Dept','Date','weeklySales','isHoliday'],sep=',', header=0)\nfeatures = pd.read_csv(\"/kaggle/working/features.csv\", parse_dates=['Date'], sep=',', header=0,\n                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\nstores = pd.read_csv(\"../input/walmart-recruiting-store-sales-forecasting/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\ndataset = dataset.merge(stores, how='left').merge(features, how='left')\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\nimport matplotlib.pyplot as plt\n\ndef scatter(dataset, column):\n    plt.figure()\n    plt.scatter(dataset[column] , dataset['weeklySales'])\n    plt.ylabel('weeklySales')\n    plt.xlabel(column)\n\nscatter(dataset, 'Fuel_Price')\nscatter(dataset, 'Size')\nscatter(dataset, 'CPI')\nscatter(dataset, 'Type')\nscatter(dataset, 'isHoliday')\nscatter(dataset, 'Unemployment')\nscatter(dataset, 'Temperature')\nscatter(dataset, 'Store')\nscatter(dataset, 'Dept')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18, 14))\ncorr = dataset.corr()\nc = plt.pcolor(corr)\nplt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\nplt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns)\nfig.colorbar(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset, columns=[\"Type\"])\ndataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\ndataset['dow'] = pd.to_datetime(dataset['Date']).dt.dayofweek\ndataset['day'] = pd.to_datetime(dataset['Date']).dt.day\ndataset['month'] = pd.to_datetime(dataset['Date']).dt.month\ndataset['year'] = pd.to_datetime(dataset['Date']).dt.year\ndataset['week'] = pd.to_datetime(dataset['Date']).dt.week\n\nfrom datetime import datetime as dt\n\ndataset.loc[(dataset[\"Date\"] >= dt(2010, 2, 5)) & (dataset[\"Date\"] <= dt(2010, 2, 13)),\"Special_day\"] = 1\ndataset.loc[(dataset[\"Date\"] >= dt(2010, 7, 5)) & (dataset[\"Date\"] <= dt(2010, 7, 14)),\"Special_day\"] = 1\ndataset.loc[(dataset[\"Date\"] >= dt(2010, 11, 9)) & (dataset[\"Date\"] <= dt(2010, 11, 29)),\"Special_day\"] = 1\ndataset.loc[(dataset[\"Date\"] >= dt(2010, 12, 10)) & (dataset[\"Date\"] <= dt(2010, 12, 31)),\"Special_day\"] = 1\ndataset[\"Special_day\"] = dataset[\"Special_day\"].fillna(0)\ndataset = dataset.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extraTreesRegressor():\n    clf = ExtraTreesRegressor(n_estimators=100,max_features='auto', verbose=1, n_jobs=1)\n    return clf\n\ndef predict_(m, test_x):\n    return pd.Series(m.predict(test_x))\n\ndef model_():\n#     return knn()\n    return extraTreesRegressor()\n#     return svm()\n#     return nn()\n#     return randomForestRegressor()    \n\ndef train_(train_x, train_y):\n    m = model_()\n    m.fit(train_x, train_y)\n    return m\n\ndef train_and_predict(train_x, train_y, test_x):\n    m = train_(train_x, train_y)\n    return predict_(m, test_x), m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_error(test_y, predicted, weights):\n    return mean_absolute_error(test_y, predicted, sample_weight=weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5)\nsplited = []\n# dataset2 = dataset.copy()\nfor name, group in dataset.groupby([\"Store\", \"Dept\"]):\n    group = group.reset_index(drop=True)\n    trains_x = []\n    trains_y = []\n    tests_x = []\n    tests_y = []\n    if group.shape[0] <= 5:\n        f = np.array(range(5))\n        np.random.shuffle(f)\n        group['fold'] = f[:group.shape[0]]\n        continue\n    fold = 0\n    for train_index, test_index in kf.split(group):\n        group.loc[test_index, 'fold'] = fold\n        fold += 1\n    splited.append(group)\n\nsplited = pd.concat(splited).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = None\nerror_cv = 0\nbest_error = np.iinfo(np.int32).max\nfor fold in range(5):\n    dataset_train = splited.loc[splited['fold'] != fold]\n    dataset_test = splited.loc[splited['fold'] == fold]\n    train_y = dataset_train['weeklySales']\n    train_x = dataset_train.drop(columns=['weeklySales', 'fold'])\n    test_y = dataset_test['weeklySales']\n    test_x = dataset_test.drop(columns=['weeklySales', 'fold'])\n    print(dataset_train.shape, dataset_test.shape)\n    predicted, model = train_and_predict(train_x, train_y, test_x)\n    weights = test_x['isHoliday'].replace(True, 5).replace(False, 1)\n    error = calculate_error(test_y, predicted, weights)\n    error_cv += error\n    print(fold, error)\n    if error < best_error:\n        print('Find best model')\n        best_error = error\n        best_model = model\nerror_cv /= 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test = pd.read_csv(\"/kaggle/working/test.csv\",  parse_dates=['Date'], names=['Store','Dept','Date','isHoliday'],sep=',', header=0)\nfeatures = pd.read_csv(\"/kaggle/working/features.csv\", parse_dates=['Date'], sep=',', header=0,\n                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\nstores = pd.read_csv(\"../input/walmart-recruiting-store-sales-forecasting/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\ndataset_test = dataset_test.merge(stores, how='left').merge(features, how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test = pd.get_dummies(dataset_test, columns=[\"Type\"])\ndataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\ndataset_test = dataset_test.fillna(0)\ncolumn_date = dataset_test['Date']\ndataset_test['dow'] = pd.to_datetime(dataset_test['Date']).dt.dayofweek\ndataset_test['day'] = pd.to_datetime(dataset_test['Date']).dt.day\ndataset_test['month'] = pd.to_datetime(dataset_test['Date']).dt.month\ndataset_test['year'] = pd.to_datetime(dataset_test['Date']).dt.year\ndataset_test['week'] = pd.to_datetime(dataset_test['Date']).dt.week\n\ndataset_test.loc[(dataset_test[\"Date\"] >= dt(2010, 2, 5)) & (dataset_test[\"Date\"] <= dt(2010, 2, 13)),\"Special_day\"] = 1\ndataset_test.loc[(dataset_test[\"Date\"] >= dt(2010, 7, 5)) & (dataset_test[\"Date\"] <= dt(2010, 7, 14)),\"Special_day\"] = 1\ndataset_test.loc[(dataset_test[\"Date\"] >= dt(2010, 11, 9)) & (dataset_test[\"Date\"] <= dt(2010, 11, 29)),\"Special_day\"] = 1\ndataset_test.loc[(dataset_test[\"Date\"] >= dt(2010, 12, 10)) & (dataset_test[\"Date\"] <= dt(2010, 12, 31)),\"Special_day\"] = 1\ndataset_test[\"Special_day\"] = dataset_test[\"Special_day\"].fillna(0)\ndataset_test = dataset_test.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\ndataset_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_test = best_model.predict(dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test['weeklySales'] = predicted_test\ndataset_test['Date'] = column_date\ndataset_test['id'] = dataset_test['Store'].astype(str) + '_' +  dataset_test['Dept'].astype(str) + '_' +  dataset_test['Date'].astype(str)\ndataset_test = dataset_test[['id', 'weeklySales']]\ndataset_test = dataset_test.rename(columns={'id': 'Id', 'weeklySales': 'Weekly_Sales'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test.to_csv('submission_walmart.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}