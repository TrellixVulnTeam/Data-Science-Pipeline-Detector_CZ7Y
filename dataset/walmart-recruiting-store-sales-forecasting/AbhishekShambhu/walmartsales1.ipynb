{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor \nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn import linear_model\nfrom sklearn.feature_selection import RFE\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/train.csv\", names=['Store','Dept','Date','weeklySales','isHoliday'],sep=',', header=0)\nfeatures = pd.read_csv(\"../input/features.csv\",sep=',', header=0,\n                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\nstores = pd.read_csv(\"../input/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\ndataset = dataset.merge(stores, how='left').merge(features, how='left')\n\n# dataset[\"nextWeekHoliday\"] = dataset[\"isHoliday\"].shift(-1).fillna(False)\n# dataset[\"next2WeekHoliday\"] = dataset[\"isHoliday\"].shift(-2).fillna(False)\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter(dataset, column):\n    plt.figure()\n    plt.scatter(dataset[column] , dataset['weeklySales'])\n    plt.ylabel('weeklySales')\n    plt.xlabel(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter(dataset, 'Fuel_Price')\nscatter(dataset, 'Size')\nscatter(dataset, 'CPI')\nscatter(dataset, 'Type')\nscatter(dataset, 'isHoliday')\nscatter(dataset, 'Unemployment')\nscatter(dataset, 'Temperature')\nscatter(dataset, 'Store')\nscatter(dataset, 'Dept')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18, 14))\ncorr = dataset.corr()\nc = plt.pcolor(corr)\nplt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\nplt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns)\nfig.colorbar(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset, vars=['weeklySales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset.fillna(0), vars=['weeklySales', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, group in dataset.groupby([\"Store\", \"Dept\"]):\n    plt.title(name)\n    plt.scatter(range(len(group)), group[\"weeklySales\"])\n    plt.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset, columns=[\"Type\"])\ndataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\ndataset['Month'] = pd.to_datetime(dataset['Date']).dt.month\ndataset = dataset.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown4'])\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def knn():\n    knn = KNeighborsRegressor(n_neighbors=10)\n    return knn\n\ndef extraTreesRegressor():\n    clf = ExtraTreesRegressor(n_estimators=100,max_features='auto', verbose=1, n_jobs=1)\n    return clf\n\ndef randomForestRegressor():\n    clf = RandomForestRegressor(n_estimators=100,max_features='log2', verbose=1)\n    return clf\n\ndef svm():\n    clf = SVR(kernel='rbf', gamma='auto')\n    return clf\n\ndef nn():\n    clf = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', verbose=3)\n    return clf\n\ndef lm():\n    clf = linear_model.LinearRegression(normalize=True)\n    return clf\n\ndef gbr():\n    clf = GradientBoostingRegressor(loss=\"huber\")\n    return clf\n\ndef elasticNet():\n    clf = linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True)\n    return clf\n\ndef predict_(m, test_x):\n    return pd.Series(m.predict(test_x))\n\ndef model_():\n#     return knn()\n     return extraTreesRegressor()\n#     return svm()\n#     return nn()\n#     return randomForestRegressor()\n#     return lm()\n#     return gbr()\n#     return elasticNet()\n\ndef train_(train_x, train_y):\n    m = model_()\n    m.fit(train_x, train_y)\n    return m\n\ndef train_and_predict(train_x, train_y, test_x):\n    m = train_(train_x, train_y)\n    return predict_(m, test_x), m\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_error(test_y, predicted, weights):\n    return mean_absolute_error(test_y, predicted, sample_weight=weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5)\nsplited = []\n# dataset2 = dataset.copy()\nfor name, group in dataset.groupby([\"Store\", \"Dept\"]):\n    group = group.reset_index(drop=True)\n    trains_x = []\n    trains_y = []\n    tests_x = []\n    tests_y = []\n    if group.shape[0] <= 5:\n        f = np.array(range(5))\n        np.random.shuffle(f)\n        group['fold'] = f[:group.shape[0]]\n        continue\n    fold = 0\n    for train_index, test_index in kf.split(group):\n        group.loc[test_index, 'fold'] = fold\n        fold += 1\n    splited.append(group)\n\nsplited = pd.concat(splited).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splited","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = None\nerror_cv = 0\nbest_error = np.iinfo(np.int32).max\nfor fold in range(5):\n    dataset_train = splited.loc[splited['fold'] != fold]\n    dataset_test = splited.loc[splited['fold'] == fold]\n    train_y = dataset_train['weeklySales']\n    train_x = dataset_train.drop(columns=['weeklySales', 'fold'])\n    test_y = dataset_test['weeklySales']\n    test_x = dataset_test.drop(columns=['weeklySales', 'fold'])\n    print(dataset_train.shape, dataset_test.shape)\n    predicted, model = train_and_predict(train_x, train_y, test_x)\n    weights = test_x['isHoliday'].replace(True, 5).replace(False, 1)\n    error = calculate_error(test_y, predicted, weights)\n    error_cv += error\n    print(fold, error)\n    if error < best_error:\n        print('Find best model')\n        best_error = error\n        best_model = model\nerror_cv /= 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test = pd.read_csv(\"../input/test.csv\", names=['Store','Dept','Date','isHoliday'],sep=',', header=0)\nfeatures = pd.read_csv(\"../input/features.csv\",sep=',', header=0,\n                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\nstores = pd.read_csv(\"../input/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\ndataset_test = dataset_test.merge(stores, how='left').merge(features, how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test = pd.get_dummies(dataset_test, columns=[\"Type\"])\ndataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\ndataset_test = dataset_test.fillna(0)\ncolumn_date = dataset_test['Date']\ndataset_test['Month'] = pd.to_datetime(dataset_test['Date']).dt.month\ndataset_test = dataset_test.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\ndataset_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_test = best_model.predict(dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test['weeklySales'] = predicted_test\ndataset_test['Date'] = column_date\ndataset_test['id'] = dataset_test['Store'].astype(str) + '_' +  dataset_test['Dept'].astype(str) + '_' +  dataset_test['Date'].astype(str)\ndataset_test = dataset_test[['id', 'weeklySales']]\ndataset_test = dataset_test.rename(columns={'id': 'Id', 'weeklySales': 'Weekly_Sales'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test.to_csv('output.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}