{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://cdn.corporate.walmart.com/dims4/WMT/0b04aa6/2147483647/strip/true/crop/2400x1260+0+0/resize/1200x630!/quality/90/?url=https%3A%2F%2Fcdn.corporate.walmart.com%2F6f%2Fd3%2Ff3f5a16f44a88d88b8059defd0a9%2Foption-signage.jpg)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport plotly.figure_factory as ff\nimport warnings \nwarnings.filterwarnings('ignore')\n%matplotlib inline\nplt.rcParams['font.size'] = 12\nplt.rcParams['figure.figsize'] = (15, 10)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:23:56.999067Z","iopub.execute_input":"2022-07-05T12:23:56.999415Z","iopub.status.idle":"2022-07-05T12:23:59.673498Z","shell.execute_reply.started":"2022-07-05T12:23:56.999327Z","shell.execute_reply":"2022-07-05T12:23:59.672548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import RFECV","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:23:59.675839Z","iopub.execute_input":"2022-07-05T12:23:59.676297Z","iopub.status.idle":"2022-07-05T12:23:59.691559Z","shell.execute_reply.started":"2022-07-05T12:23:59.676247Z","shell.execute_reply":"2022-07-05T12:23:59.690452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_df  = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/features.csv.zip')\ntrain_df  = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/train.csv.zip')\nstores_df  = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/stores.csv')\ntest_df  = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/test.csv.zip')\nsample_submission = pd.read_csv('../input/walmart-recruiting-store-sales-forecasting/sampleSubmission.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:23:59.693395Z","iopub.execute_input":"2022-07-05T12:23:59.693844Z","iopub.status.idle":"2022-07-05T12:24:00.106204Z","shell.execute_reply.started":"2022-07-05T12:23:59.693764Z","shell.execute_reply":"2022-07-05T12:24:00.105213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging the data\nWe have merged the data in order to take into account the features and the stores data as well which will help our model become more robust in predicting the sales.","metadata":{}},{"cell_type":"code","source":"merged_train_df = train_df.merge(stores_df, how='left').merge(features_df, how='left')\nmerged_test_df = test_df.merge(stores_df, how='left').merge(features_df, how='left')","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:00.474621Z","iopub.execute_input":"2022-07-05T12:24:00.475246Z","iopub.status.idle":"2022-07-05T12:24:00.740063Z","shell.execute_reply.started":"2022-07-05T12:24:00.475211Z","shell.execute_reply":"2022-07-05T12:24:00.739072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Knowing the value counts and Data Types of our columns\nmerged_train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:00.741956Z","iopub.execute_input":"2022-07-05T12:24:00.742302Z","iopub.status.idle":"2022-07-05T12:24:00.851004Z","shell.execute_reply.started":"2022-07-05T12:24:00.742254Z","shell.execute_reply":"2022-07-05T12:24:00.849903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:00.853244Z","iopub.execute_input":"2022-07-05T12:24:00.853495Z","iopub.status.idle":"2022-07-05T12:24:00.896241Z","shell.execute_reply.started":"2022-07-05T12:24:00.853447Z","shell.execute_reply":"2022-07-05T12:24:00.895124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:01.017244Z","iopub.execute_input":"2022-07-05T12:24:01.017556Z","iopub.status.idle":"2022-07-05T12:24:01.218821Z","shell.execute_reply.started":"2022-07-05T12:24:01.017519Z","shell.execute_reply":"2022-07-05T12:24:01.217567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:01.856689Z","iopub.execute_input":"2022-07-05T12:24:01.856979Z","iopub.status.idle":"2022-07-05T12:24:02.009119Z","shell.execute_reply.started":"2022-07-05T12:24:01.856946Z","shell.execute_reply":"2022-07-05T12:24:02.007919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis\nExploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.","metadata":{}},{"cell_type":"code","source":"sales_df = merged_train_df.sample(frac=0.1)\nhist_data = [sales_df.Weekly_Sales]\ngroup_labels = ['Weekly Sales']\nfig = ff.create_distplot(hist_data, group_labels, show_hist=False)\nfig.update_layout(title_text='Weekly Sales Distplot')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:02.386982Z","iopub.execute_input":"2022-07-05T12:24:02.387613Z","iopub.status.idle":"2022-07-05T12:24:03.163078Z","shell.execute_reply.started":"2022-07-05T12:24:02.387578Z","shell.execute_reply":"2022-07-05T12:24:03.16225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_df","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:03.164599Z","iopub.execute_input":"2022-07-05T12:24:03.164857Z","iopub.status.idle":"2022-07-05T12:24:03.214227Z","shell.execute_reply.started":"2022-07-05T12:24:03.164819Z","shell.execute_reply":"2022-07-05T12:24:03.213386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Dept Wise Sales\")\nplt.xlabel('Dept')\nsns.histplot(x=sales_df.Dept, y= sales_df.Weekly_Sales);","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:03.215925Z","iopub.execute_input":"2022-07-05T12:24:03.216574Z","iopub.status.idle":"2022-07-05T12:24:03.569444Z","shell.execute_reply.started":"2022-07-05T12:24:03.216533Z","shell.execute_reply":"2022-07-05T12:24:03.568436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The store number 10 and 35 have the highest sales\n\nLets with the help of heatmap try to understand a correlation between the columns in our `merged_train_df`","metadata":{}},{"cell_type":"code","source":"corr = sales_df.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nf, ax = plt.subplots(figsize=(25,20))\ncmap = sns.diverging_palette(220, 20, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, annot=True,square=True, linewidths=.5, cbar_kws={'shrink': .5})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:04.171236Z","iopub.execute_input":"2022-07-05T12:24:04.173423Z","iopub.status.idle":"2022-07-05T12:24:05.151655Z","shell.execute_reply.started":"2022-07-05T12:24:04.173387Z","shell.execute_reply":"2022-07-05T12:24:05.150429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(sales_df, x='Temperature', y ='Weekly_Sales', color='IsHoliday', marginal='box', title ='Affect of Store Temperature on Sales')\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)','paper_bgcolor': 'rgba(0, 0, 0, 0)'})","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:05.154224Z","iopub.execute_input":"2022-07-05T12:24:05.154909Z","iopub.status.idle":"2022-07-05T12:24:05.701258Z","shell.execute_reply.started":"2022-07-05T12:24:05.154865Z","shell.execute_reply":"2022-07-05T12:24:05.700449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.title('Relation between Store size and sales')\nsns.lineplot ( data = sales_df, x = 'Size', y =  'Weekly_Sales', hue = 'IsHoliday');","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:05.7026Z","iopub.execute_input":"2022-07-05T12:24:05.703413Z","iopub.status.idle":"2022-07-05T12:24:09.729281Z","shell.execute_reply.started":"2022-07-05T12:24:05.703369Z","shell.execute_reply":"2022-07-05T12:24:09.728137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph we can say, the store size somewhat increases the sales upto a point but after that it most likely won't have much impact on the sales of a store.","metadata":{}},{"cell_type":"markdown","source":"## Outlier Detection\n*Wikipedia definition,*\n\n\"In statistics, an outlier is an observation point that is distant from other observations.\"\n\nThe above definition suggests that outlier is something which is separate/different from the crowd.\n\nFinding outliers by looking at the data could be easy but it may be a quite challenging task when you have got thousands or even millions of datapoints. We have used IQR (Inter-Quartlie Range) to find out the outliers and then took them away so our model doesn't perform poor.","metadata":{}},{"cell_type":"code","source":"#Outlier Detection and removing the outliers\ndataset = sorted(merged_train_df.Weekly_Sales)\nq1, q3 = np.percentile(dataset,[25,75])\niqr = q3-q1\nlower_fence = q1-(1.5*iqr)\nupper_fence = q3+(1.5*iqr)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:09.731588Z","iopub.execute_input":"2022-07-05T12:24:09.732676Z","iopub.status.idle":"2022-07-05T12:24:09.943475Z","shell.execute_reply.started":"2022-07-05T12:24:09.732628Z","shell.execute_reply":"2022-07-05T12:24:09.942466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_df= merged_train_df[merged_train_df.Weekly_Sales < upper_fence]\nmerged_train_df","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:09.94538Z","iopub.execute_input":"2022-07-05T12:24:09.945828Z","iopub.status.idle":"2022-07-05T12:24:10.014244Z","shell.execute_reply.started":"2022-07-05T12:24:09.94578Z","shell.execute_reply":"2022-07-05T12:24:10.013227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(x=merged_train_df[\"Weekly_Sales\"], y=merged_train_df[\"IsHoliday\"], palette=\"Set2\", orient=\"h\");","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:10.01575Z","iopub.execute_input":"2022-07-05T12:24:10.016634Z","iopub.status.idle":"2022-07-05T12:24:10.397394Z","shell.execute_reply.started":"2022-07-05T12:24:10.016586Z","shell.execute_reply":"2022-07-05T12:24:10.396402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-processing\nIn this section, we are gonna be cleaning up our data and getting it prepared for the model. We would be dealing with the missing values, categorical data and dropping any other unnecessary columns in the dataset.","metadata":{}},{"cell_type":"code","source":"# Splitting Date Column\ndef split_date(df):\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Year'] = df.Date.dt.year\n    df['Month'] = df.Date.dt.month\n    df['Day'] = df.Date.dt.day\n    df['WeekOfYear'] = df.Date.dt.isocalendar().week","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:10.648282Z","iopub.execute_input":"2022-07-05T12:24:10.649131Z","iopub.status.idle":"2022-07-05T12:24:10.655569Z","shell.execute_reply.started":"2022-07-05T12:24:10.649085Z","shell.execute_reply":"2022-07-05T12:24:10.654323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_date(merged_train_df)\nsplit_date(merged_test_df)\nsplit_date(sales_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:10.713004Z","iopub.execute_input":"2022-07-05T12:24:10.713396Z","iopub.status.idle":"2022-07-05T12:24:11.199425Z","shell.execute_reply.started":"2022-07-05T12:24:10.713359Z","shell.execute_reply":"2022-07-05T12:24:11.198373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_df = merged_train_df.drop(['Date'], axis=1)\nmerged_test_df = merged_test_df.drop(['Date'], axis=1)\nsales_df = sales_df.drop(['Date'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:11.201715Z","iopub.execute_input":"2022-07-05T12:24:11.20203Z","iopub.status.idle":"2022-07-05T12:24:11.257113Z","shell.execute_reply.started":"2022-07-05T12:24:11.201983Z","shell.execute_reply":"2022-07-05T12:24:11.255986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:12.874658Z","iopub.execute_input":"2022-07-05T12:24:12.875476Z","iopub.status.idle":"2022-07-05T12:24:13.000827Z","shell.execute_reply.started":"2022-07-05T12:24:12.875422Z","shell.execute_reply":"2022-07-05T12:24:12.99953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:13.588884Z","iopub.execute_input":"2022-07-05T12:24:13.589171Z","iopub.status.idle":"2022-07-05T12:24:13.616315Z","shell.execute_reply.started":"2022-07-05T12:24:13.589138Z","shell.execute_reply":"2022-07-05T12:24:13.615022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:17.286569Z","iopub.execute_input":"2022-07-05T12:24:17.287074Z","iopub.status.idle":"2022-07-05T12:24:17.305991Z","shell.execute_reply.started":"2022-07-05T12:24:17.287031Z","shell.execute_reply":"2022-07-05T12:24:17.30475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding and Imputing the values\nSince ML algorithms can work with only numerical data, it is empirical for us to\n\n- encode - Turning into a numerical value\n- Impute - Required since there are NaNvalues in our data and dropping the rows that contain those values might not be such a good idea.","metadata":{}},{"cell_type":"code","source":"inputs_df = sales_df.copy()\ncategorical_cols = inputs_df.select_dtypes(include=['object']).columns.tolist()\ncategorical_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:53.044898Z","iopub.execute_input":"2022-07-05T12:24:53.045212Z","iopub.status.idle":"2022-07-05T12:24:53.058896Z","shell.execute_reply.started":"2022-07-05T12:24:53.045178Z","shell.execute_reply":"2022-07-05T12:24:53.057478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OneHotEncoding\n\nFor categorical variables where no such ordinal relationship exists, the integer encoding is not enough. In fact, using this encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\n\nIn this case, a one-hot encoding can be applied to the integer representation. This is where the integer encoded variable is removed and a new binary variable is added for each unique integer value.\n\n![](https://i.imgur.com/n8GuiOO.png)\n\nRead More on Encoding data https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/","metadata":{}},{"cell_type":"code","source":"inputs_df","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:53.780066Z","iopub.execute_input":"2022-07-05T12:24:53.781707Z","iopub.status.idle":"2022-07-05T12:24:53.821581Z","shell.execute_reply.started":"2022-07-05T12:24:53.781642Z","shell.execute_reply":"2022-07-05T12:24:53.820537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\nencoder.fit(inputs_df[categorical_cols])\nencoded_cols = list(encoder.get_feature_names_out(categorical_cols))\ninputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:53.997011Z","iopub.execute_input":"2022-07-05T12:24:53.997282Z","iopub.status.idle":"2022-07-05T12:24:54.024773Z","shell.execute_reply.started":"2022-07-05T12:24:53.99725Z","shell.execute_reply":"2022-07-05T12:24:54.023823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_df = merged_test_df.copy()\ncategorical_cols1 = Test_df.select_dtypes(include=['object']).columns.tolist()\nencoded_cols1 = list(encoder.get_feature_names_out(categorical_cols1))\nTest_df[encoded_cols1] = encoder.transform(Test_df[categorical_cols1])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:55.172006Z","iopub.execute_input":"2022-07-05T12:24:55.173017Z","iopub.status.idle":"2022-07-05T12:24:55.228998Z","shell.execute_reply.started":"2022-07-05T12:24:55.172971Z","shell.execute_reply":"2022-07-05T12:24:55.22805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also need to encode `IsHoliday` into a numerical value since this column is also a categorical data. We will use LabelEncoder() for this purpose.","metadata":{}},{"cell_type":"code","source":"encoder1 = LabelEncoder()\nencoder1.fit(inputs_df['IsHoliday'])\ninputs_df['IsHoliday'] = encoder1.transform(inputs_df['IsHoliday'])\nTest_df['IsHoliday'] = encoder1.transform(Test_df['IsHoliday'])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:55.709389Z","iopub.execute_input":"2022-07-05T12:24:55.709703Z","iopub.status.idle":"2022-07-05T12:24:55.721311Z","shell.execute_reply.started":"2022-07-05T12:24:55.709671Z","shell.execute_reply":"2022-07-05T12:24:55.720201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping Unnecessary columns\n","metadata":{}},{"cell_type":"code","source":"target_col = merged_train_df.columns[2]\ntargets_df = sales_df['Weekly_Sales']\ninputs_df.drop([ 'Type'], axis=1, inplace = True)\nTest_df.drop(['Type'], axis=1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:55.870707Z","iopub.execute_input":"2022-07-05T12:24:55.870947Z","iopub.status.idle":"2022-07-05T12:24:55.900432Z","shell.execute_reply.started":"2022-07-05T12:24:55.870916Z","shell.execute_reply":"2022-07-05T12:24:55.899459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imputation\n\nImputation is the process of replacing missing data with substituted values. Below are some of the imputation techniques\n![](https://vitalflux.com/wp-content/uploads/2018/10/Missing-Data-Imputation-Techniques.png)","metadata":{}},{"cell_type":"code","source":"numeric_cols = inputs_df.columns[0:17].tolist()\nnumeric_cols1 = Test_df.columns[0:17].tolist()\nimputer = SimpleImputer(strategy = 'mean')\nimputer.fit(inputs_df[numeric_cols])\ninputs_df[numeric_cols] = imputer.transform(inputs_df[numeric_cols])\nTest_df[numeric_cols1] = imputer.transform(Test_df[numeric_cols1])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:24:58.107805Z","iopub.execute_input":"2022-07-05T12:24:58.108142Z","iopub.status.idle":"2022-07-05T12:24:58.291905Z","shell.execute_reply.started":"2022-07-05T12:24:58.108109Z","shell.execute_reply":"2022-07-05T12:24:58.290847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Selection\n\nRFE is a transformer estimator, which means it follows the familiar fit/transform pattern of Sklearn. It is a popular algorithm due to its easy configurable nature and robust performance. As the name suggests, it removes features one at a time based on the weights given by a model of our choice in each iteration.\n\nGiven an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features.\n\nThat procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n\nMore here :- https://www.kaggle.com/code/bhatnagardaksh/how-to-feature-selection-a-tutorial-updated","metadata":{}},{"cell_type":"code","source":"estimator = LinearRegression()\nselector = RFE(estimator, n_features_to_select=10, step=1)\nselector = selector.fit(inputs_df, targets_df)\nRanking = pd.DataFrame(data= selector.feature_names_in_, columns=['Features'])\nRanking['Feature Selected'] = selector.support_\nRanking[Ranking['Feature Selected'].eq(True)]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:25:04.792141Z","iopub.execute_input":"2022-07-05T12:25:04.794625Z","iopub.status.idle":"2022-07-05T12:25:05.058501Z","shell.execute_reply.started":"2022-07-05T12:25:04.794587Z","shell.execute_reply":"2022-07-05T12:25:05.057368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs_df1 = inputs_df[Ranking[Ranking['Feature Selected'].eq(True)]['Features'].values.tolist()]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:25:05.554749Z","iopub.execute_input":"2022-07-05T12:25:05.555059Z","iopub.status.idle":"2022-07-05T12:25:05.566999Z","shell.execute_reply.started":"2022-07-05T12:25:05.555025Z","shell.execute_reply":"2022-07-05T12:25:05.565813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spliting Data and Training model\n\nSince we have been working with a fraction of the data, we will use that data to see an initial impression of which models are looking better for us on the sample. We will for now go ahead and train the data on the sample data and later on use the entire data.\n\nRead more here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html","metadata":{}},{"cell_type":"code","source":"train_inputs, val_inputs, train_targets, val_targets = train_test_split(inputs_df1, targets_df, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:25:06.289205Z","iopub.execute_input":"2022-07-05T12:25:06.289544Z","iopub.status.idle":"2022-07-05T12:25:06.30527Z","shell.execute_reply.started":"2022-07-05T12:25:06.289478Z","shell.execute_reply":"2022-07-05T12:25:06.304142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = ['Linear Regression', \"KNN\", \"Linear SVM\", \"Random Forest\",'Ridge', 'Lasso']\nregressors = [\n    LinearRegression(),\n    KNeighborsRegressor(n_neighbors=3),\n    SVR(kernel=\"rbf\", C=1.0),\n    RandomForestRegressor(max_depth=5, n_estimators=100),\n    Ridge(alpha=1.0),\n    Lasso(alpha=1.0)]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:25:06.568611Z","iopub.execute_input":"2022-07-05T12:25:06.569219Z","iopub.status.idle":"2022-07-05T12:25:06.578389Z","shell.execute_reply.started":"2022-07-05T12:25:06.569181Z","shell.execute_reply":"2022-07-05T12:25:06.577268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\nfor name, clf in zip(names, regressors):\n    clf.fit(train_inputs, train_targets)\n    score = clf.score(val_inputs, val_targets)\n    scores.append(score)\nscores_df = pd.DataFrame()\nscores_df['name'] = names\nscores_df['score'] = scores\nscores_df.sort_values('score', ascending= False)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:25:06.985617Z","iopub.execute_input":"2022-07-05T12:25:06.985913Z","iopub.status.idle":"2022-07-05T12:26:31.243404Z","shell.execute_reply.started":"2022-07-05T12:25:06.985879Z","shell.execute_reply":"2022-07-05T12:26:31.242313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining a function to transform the whole dataset and align it as per the requirements","metadata":{}},{"cell_type":"code","source":"def transformer(df):\n    imputer = SimpleImputer(strategy = 'mean')\n    imputer.fit(df[df.select_dtypes(include=['float64', 'int32','UInt32']).columns.tolist()])\n    df[df.select_dtypes(include=['float64', 'int32','UInt32']).columns.tolist()] = imputer.transform(df[df.select_dtypes(include=['float64', 'int32','UInt32']).columns.tolist()])\n    categorical_cols = df.select_dtypes(include=['object','bool']).columns.tolist()\n    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n    encoder.fit(df[categorical_cols])\n    encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n    df[encoded_cols] = encoder.transform(df[categorical_cols])\n    df.drop(['Type', 'IsHoliday'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:26:52.566948Z","iopub.execute_input":"2022-07-05T12:26:52.56727Z","iopub.status.idle":"2022-07-05T12:26:52.57759Z","shell.execute_reply.started":"2022-07-05T12:26:52.567236Z","shell.execute_reply":"2022-07-05T12:26:52.575682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer(merged_train_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:26:56.504388Z","iopub.execute_input":"2022-07-05T12:26:56.504736Z","iopub.status.idle":"2022-07-05T12:26:57.693933Z","shell.execute_reply.started":"2022-07-05T12:26:56.504693Z","shell.execute_reply":"2022-07-05T12:26:57.69287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_df","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:26:57.695936Z","iopub.execute_input":"2022-07-05T12:26:57.6963Z","iopub.status.idle":"2022-07-05T12:26:57.837881Z","shell.execute_reply.started":"2022-07-05T12:26:57.696254Z","shell.execute_reply":"2022-07-05T12:26:57.836892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking if the values have been imputed/filled or not.","metadata":{}},{"cell_type":"code","source":"merged_train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:27:01.180486Z","iopub.execute_input":"2022-07-05T12:27:01.180835Z","iopub.status.idle":"2022-07-05T12:27:01.209251Z","shell.execute_reply.started":"2022-07-05T12:27:01.180801Z","shell.execute_reply":"2022-07-05T12:27:01.208195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets_df","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:27:05.322915Z","iopub.execute_input":"2022-07-05T12:27:05.323243Z","iopub.status.idle":"2022-07-05T12:27:05.335214Z","shell.execute_reply.started":"2022-07-05T12:27:05.323211Z","shell.execute_reply":"2022-07-05T12:27:05.331948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets_df = merged_train_df['Weekly_Sales']\nestimator = LinearRegression()\nselector = RFECV(estimator, step=1, cv=5, min_features_to_select=10)\nselector = selector.fit(merged_train_df, targets_df)\nRanking = pd.DataFrame(data= selector.feature_names_in_, columns=['Features'])\nRanking['Feature Selected'] = selector.support_\nRanking[Ranking['Feature Selected'].eq(True)]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:27:12.696803Z","iopub.execute_input":"2022-07-05T12:27:12.697099Z","iopub.status.idle":"2022-07-05T12:27:31.522356Z","shell.execute_reply.started":"2022-07-05T12:27:12.697065Z","shell.execute_reply":"2022-07-05T12:27:31.520965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs_df = merged_train_df[Ranking[Ranking['Feature Selected'].eq(True)]['Features'].values.tolist()]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:27:31.524581Z","iopub.execute_input":"2022-07-05T12:27:31.527129Z","iopub.status.idle":"2022-07-05T12:27:31.563456Z","shell.execute_reply.started":"2022-07-05T12:27:31.527079Z","shell.execute_reply":"2022-07-05T12:27:31.562466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs, val_inputs, train_targets, val_targets = train_test_split(inputs_df, \n                                                                        targets_df, \n                                                                        test_size=0.25, \n                                                                        random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:30:03.931053Z","iopub.execute_input":"2022-07-05T12:30:03.931385Z","iopub.status.idle":"2022-07-05T12:30:04.004918Z","shell.execute_reply.started":"2022-07-05T12:30:03.931351Z","shell.execute_reply":"2022-07-05T12:30:04.003882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#names = ['Linear Regression', \"KNN\", \"Linear SVM\", \"Random Forest\",'Ridge', 'Lasso']\n#regressors = [LinearRegression(), KNeighborsRegressor(n_neighbors=3),SVR(kernel=\"rbf\", C=1.0),RandomForestRegressor(max_depth=5, n_estimators=100),Ridge(alpha=1.0),Lasso(alpha=1.0)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(train_inputs, train_targets)\nprint(\"The Validation Score of Lin Reg Model is %0.2f\" % (model.score(val_inputs, val_targets)))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:30:09.047363Z","iopub.execute_input":"2022-07-05T12:30:09.047997Z","iopub.status.idle":"2022-07-05T12:30:09.147844Z","shell.execute_reply.started":"2022-07-05T12:30:09.04796Z","shell.execute_reply":"2022-07-05T12:30:09.146567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KNeighborsRegressor(n_neighbors=3)\nmodel.fit(train_inputs, train_targets)\nprint(\"The Validation Score of KNN Model is %0.2f\" % (model.score(val_inputs, val_targets)))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:30:12.167476Z","iopub.execute_input":"2022-07-05T12:30:12.167851Z","iopub.status.idle":"2022-07-05T12:30:13.82556Z","shell.execute_reply.started":"2022-07-05T12:30:12.167819Z","shell.execute_reply":"2022-07-05T12:30:13.824508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestRegressor(n_jobs=-1, random_state=42)\nmodel.fit(train_inputs, train_targets)\nprint(\"The Validation Score of Random Forest Model is %0.2f\" % (model.score(val_inputs, val_targets)))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T12:30:54.499666Z","iopub.execute_input":"2022-07-05T12:30:54.500793Z","iopub.status.idle":"2022-07-05T12:32:54.997321Z","shell.execute_reply.started":"2022-07-05T12:30:54.500738Z","shell.execute_reply":"2022-07-05T12:32:54.996248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter Tuning \n\nhyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\n\nThe same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. \n\nHyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data. The objective function takes a tuple of hyperparameters and returns the associated loss. Cross-validation is often used to estimate this generalization performance.\n\n![](https://i.imgur.com/EJCrSZw.png)\n","metadata":{}},{"cell_type":"code","source":"sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test_df = Test_df.drop(['MarkDown2','MarkDown5','IsHoliday','Type_C', 'Year'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample_submission['Weekly_Sales'] = rf_test_preds\n#sample_submission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Future Work and references\n\nAs we can see the Random Forest model has given us the lowest RMSE so the best model in this case should be the Random Forest model.\n\nReferences:-\n- https://www.kaggle.com/maxdiazbattan/wallmart-sales-eda-feat-eng-future-update\n- https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting\n- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n\nFuture Work may include trying out some more algorithms like Support Vector Machines (SVM), Lasso Regression, Ridge Regression, Gausian Regression etc. and see which one can further reduce the RMSE and give us even better results.","metadata":{}}]}