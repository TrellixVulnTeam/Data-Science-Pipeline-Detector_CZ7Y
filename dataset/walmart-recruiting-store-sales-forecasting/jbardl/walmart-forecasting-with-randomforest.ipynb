{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T00:22:44.305229Z","iopub.execute_input":"2022-05-13T00:22:44.305582Z","iopub.status.idle":"2022-05-13T00:22:44.316126Z","shell.execute_reply.started":"2022-05-13T00:22:44.305547Z","shell.execute_reply":"2022-05-13T00:22:44.315356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Walmart Sales Forecasting\n\nFor this notebook, I train a Random Forest Regressor using only the train dataset and information about holidays - no other features included.","metadata":{}},{"cell_type":"code","source":"# loading used libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:22:44.321222Z","iopub.execute_input":"2022-05-13T00:22:44.321545Z","iopub.status.idle":"2022-05-13T00:22:45.876388Z","shell.execute_reply.started":"2022-05-13T00:22:44.321511Z","shell.execute_reply":"2022-05-13T00:22:45.875587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load both datasets\n\ntrain = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip\")\ntest = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:22:45.877716Z","iopub.execute_input":"2022-05-13T00:22:45.878089Z","iopub.status.idle":"2022-05-13T00:22:46.250787Z","shell.execute_reply.started":"2022-05-13T00:22:45.878061Z","shell.execute_reply":"2022-05-13T00:22:46.249632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:22:46.252173Z","iopub.execute_input":"2022-05-13T00:22:46.252788Z","iopub.status.idle":"2022-05-13T00:22:46.26726Z","shell.execute_reply.started":"2022-05-13T00:22:46.252736Z","shell.execute_reply":"2022-05-13T00:22:46.266114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Brief analysis of the impact of holidays\n\nFrom the data I know which observations happened on a holiday. However, what I don't know is how each holiday affect the sales.\n\nThe different holidays which we know are the following:\n\n- Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n- Labor Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n- Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n- Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n\nTo look at this, I aggregate sales on each store per observed date, and plot them together with holidays.","metadata":{}},{"cell_type":"code","source":"print(f\"Train data go from {train.Date.min()} to {train.Date.max()}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:24:58.997214Z","iopub.execute_input":"2022-05-13T00:24:58.997533Z","iopub.status.idle":"2022-05-13T00:24:59.132606Z","shell.execute_reply.started":"2022-05-13T00:24:58.997502Z","shell.execute_reply":"2022-05-13T00:24:59.131574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that some holidays are out of the bounds of our train dataset. For plotting sake, I keep only those holidays which happened during the time for which he have observed data.","metadata":{}},{"cell_type":"code","source":"train_plot = train.copy()\ntrain_plot['Date'] = pd.to_datetime(train_plot['Date'])\n\n# prepare sales aggregation by store\ntrain_plot = train_plot.groupby([\"Date\", \"Store\"])['Weekly_Sales'].sum().reset_index()\n\n# holiday dates and colos to differentiate them in plot\nspecial_dates = {\n    'Super bowl': ['2010-02-12', '2011-02-11', '2012-02-10'],\n    'Labor day': ['2010-09-10', '2011-09-09', '2012-09-07'],\n    'Thanksgiving': ['2010-11-26', '2011-11-25'],\n    'Christmas': ['2010-12-31', '2011-12-30']\n}\ncolors = ['blue', 'red', 'green', 'yellow']\n\nplt.figure(figsize=(20,9))\nsns.lineplot(x='Date', y='Weekly_Sales', hue='Store', data=train_plot)\n\n# min and max values for vertical lines\nmax_val = train_plot.Weekly_Sales.max()\nmin_val = train_plot.Weekly_Sales.min()\n\nfor ix, event in enumerate(special_dates.keys()):\n    \n    plt.vlines(x      = special_dates[event], \n               colors = colors[ix],\n               ymin   = min_val, \n               ymax   = max_val, \n               label  = event)\n    \nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:28:26.621787Z","iopub.execute_input":"2022-05-13T00:28:26.622657Z","iopub.status.idle":"2022-05-13T00:28:27.932765Z","shell.execute_reply.started":"2022-05-13T00:28:26.622617Z","shell.execute_reply":"2022-05-13T00:28:27.931848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's clear from the plot that Thanksgiving and Christmas are the holidays in which sales at Store level rise higher. Super bowl also correlates to some rise in the sales, but not as high as the previous two holidays. As for Labor day, this holiday correlates to high sales in some store, but not all of them.\n\nThe conclusion here is that having a representation of which holiday is it that takes place for each observation is relevant to predict the amount of sales. For that, I generate a one-hot-encoding of the holidays and merge it to de train data.","metadata":{}},{"cell_type":"code","source":"def generate_holidays_dummies(df):\n\n    holidays_dates = {\n        'super_bowl': ['2010-02-12', '2011-02-11', '2012-02-10', '2013-02-08'],\n        'labor_day': ['2010-09-10', '2011-09-09', '2012-09-07', '2013-09-06'],\n        'thanksgiving': ['2010-11-26', '2011-11-25', '2012-11-23', '2013-11-29'],\n        'christmas': ['2010-12-31', '2011-12-30', '2012-12-28', '2013-12-27']\n    }\n    # create Series with each holiday and its dates\n    holidays_df = pd.DataFrame(holidays_dates).melt().set_index('value')\n    \n    # merge previous Series to a temporal dataframe\n    # observations which aren't holidays will remain NaN\n    temp_df = df.merge(holidays_df, how='left', left_on='Date', right_index=True)\n    \n    # merge one-hot-encoded holidays to dataset\n    df = pd.concat([df, pd.get_dummies(temp_df.variable)], axis=1)\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apart from that, the only remaining features available from the data are those related to date.","metadata":{}},{"cell_type":"code","source":"def process_date(df):\n    \n    df['Date'] = pd.to_datetime(df.Date)\n    df['year'] = df.Date.dt.year\n    df['month'] = df.Date.dt.month\n    df['week'] = df.Date.dt.week\n    df['day'] = df.Date.dt.day\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:37:22.171795Z","iopub.execute_input":"2022-05-13T00:37:22.17212Z","iopub.status.idle":"2022-05-13T00:37:22.17887Z","shell.execute_reply.started":"2022-05-13T00:37:22.172085Z","shell.execute_reply":"2022-05-13T00:37:22.177889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, I define a function to consolidate all of data processing for simplicity.","metadata":{}},{"cell_type":"code","source":"def process_data(df):\n    \n    # holidays processing\n    df = generate_holidays_dummies(df)\n#     df.drop('IsHoliday', axis=1, inplace=True)\n    df['IsHoliday'] = df.IsHoliday.map({True: 1, False: 0})\n    \n    # date processing\n    df = process_date(df)\n    df.drop('Date', axis=1, inplace=True)\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"train = process_data(train)\n\nfeatures = train.drop('Weekly_Sales', axis=1)\ntarget = train['Weekly_Sales']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel = RandomForestRegressor(n_estimators=300, random_state=24)\nmodel.fit(features, target)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"test_processed = process_data(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since labor day doesn't occur in test set, we manually add a column for ","metadata":{}},{"cell_type":"code","source":"test_processed.insert(4, 'labor_day', 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_processed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing submission","metadata":{}},{"cell_type":"code","source":"preds_series = pd.Series(preds)\n\nid_col = test.Store.astype(str) + \"_\" + test.Dept.astype(str) + \"_\" + test.Date.astype(str)\ndf_submission = pd.concat([id_col, preds_series], axis=1)\ndf_submission.columns = [\"Id\", \"Weekly_Sales\"]\n\ndf_submission.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}