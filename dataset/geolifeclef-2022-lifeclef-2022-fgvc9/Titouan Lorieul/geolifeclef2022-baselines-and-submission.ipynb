{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook presents some code to compute some basic baselines.\n\nIn particular, it shows how to:\n1. Use the provided validation set\n2. Compute the top-30 metric\n3. Save the predictions on the test in the right format for submission","metadata":{}},{"cell_type":"code","source":"%pylab inline --no-import-all\n\nimport os\nfrom pathlib import Path\n\nimport pandas as pd\n\n\n# Change this path to adapt to where you downloaded the data\nDATA_PATH = Path(\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\")\n\n# Create the path to save submission files\nSUBMISSION_PATH = Path(\"submissions\")\nos.makedirs(SUBMISSION_PATH, exist_ok=True)\n\n# Clone the GitHub repository\n!rm -rf GLC\n!git clone https://github.com/maximiliense/GLC","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:34.825855Z","start_time":"2022-02-15T15:34:33.902797Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:26.656789Z","iopub.execute_input":"2022-02-23T11:28:26.657188Z","iopub.status.idle":"2022-02-23T11:28:28.478796Z","shell.execute_reply.started":"2022-02-23T11:28:26.657089Z","shell.execute_reply":"2022-02-23T11:28:28.47795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also load the official metric, top-30 error rate, for which we provide efficient implementations:","metadata":{}},{"cell_type":"code","source":"from GLC.metrics import top_30_error_rate\nhelp(top_30_error_rate)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:34.831795Z","start_time":"2022-02-15T15:34:34.827913Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:28.480457Z","iopub.execute_input":"2022-02-23T11:28:28.480963Z","iopub.status.idle":"2022-02-23T11:28:28.491005Z","shell.execute_reply.started":"2022-02-23T11:28:28.480929Z","shell.execute_reply":"2022-02-23T11:28:28.490245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from GLC.metrics import top_k_error_rate_from_sets\nhelp(top_k_error_rate_from_sets)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:34.840459Z","start_time":"2022-02-15T15:34:34.833489Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:28.492573Z","iopub.execute_input":"2022-02-23T11:28:28.493142Z","iopub.status.idle":"2022-02-23T11:28:28.498206Z","shell.execute_reply.started":"2022-02-23T11:28:28.493109Z","shell.execute_reply":"2022-02-23T11:28:28.497592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For submissions, we will also need to predict the top-30 sets for which we also provide an efficient implementation:","metadata":{}},{"cell_type":"code","source":"from GLC.metrics import predict_top_30_set\nhelp(predict_top_30_set)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:34.850192Z","start_time":"2022-02-15T15:34:34.843048Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:28.499961Z","iopub.execute_input":"2022-02-23T11:28:28.500445Z","iopub.status.idle":"2022-02-23T11:28:28.510326Z","shell.execute_reply.started":"2022-02-23T11:28:28.500414Z","shell.execute_reply":"2022-02-23T11:28:28.509465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also provide an utility function to generate submission files in the right format:","metadata":{}},{"cell_type":"code","source":"from GLC.submission import generate_submission_file\nhelp(generate_submission_file)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T11:28:28.511141Z","iopub.execute_input":"2022-02-23T11:28:28.511727Z","iopub.status.idle":"2022-02-23T11:28:28.524727Z","shell.execute_reply.started":"2022-02-23T11:28:28.511701Z","shell.execute_reply":"2022-02-23T11:28:28.523988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observation data loading","metadata":{}},{"cell_type":"markdown","source":"We first need to load the observation data:","metadata":{}},{"cell_type":"code","source":"df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\ndf_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\ndf_obs = pd.concat((df_obs_fr, df_obs_us))","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:35.686811Z","start_time":"2022-02-15T15:34:34.851926Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:28.525731Z","iopub.execute_input":"2022-02-23T11:28:28.525913Z","iopub.status.idle":"2022-02-23T11:28:30.590668Z","shell.execute_reply.started":"2022-02-23T11:28:28.525885Z","shell.execute_reply":"2022-02-23T11:28:30.589873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we retrieve the train/val split provided:","metadata":{}},{"cell_type":"code","source":"obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\nobs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n\ny_train = df_obs.loc[obs_id_train][\"species_id\"].values\ny_val = df_obs.loc[obs_id_val][\"species_id\"].values\n\nn_val = len(obs_id_val)\nprint(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:36.13279Z","start_time":"2022-02-15T15:34:35.688156Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:30.591892Z","iopub.execute_input":"2022-02-23T11:28:30.593362Z","iopub.status.idle":"2022-02-23T11:28:31.468994Z","shell.execute_reply.started":"2022-02-23T11:28:30.593308Z","shell.execute_reply":"2022-02-23T11:28:31.467532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also load the observation data for the test set:","metadata":{}},{"cell_type":"code","source":"df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\ndf_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n\ndf_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n\nobs_id_test = df_obs_test.index.values\n\nprint(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n\ndf_obs_test.head()","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:36.16918Z","start_time":"2022-02-15T15:34:36.134721Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:31.470536Z","iopub.execute_input":"2022-02-23T11:28:31.47076Z","iopub.status.idle":"2022-02-23T11:28:31.543471Z","shell.execute_reply.started":"2022-02-23T11:28:31.470732Z","shell.execute_reply":"2022-02-23T11:28:31.542359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample submission file\n\nIn this section, we will demonstrate how to generate the sample submission file provided.\n\nTo do so, we will use the function `generate_submission_file` from `GLC.submission`.","metadata":{}},{"cell_type":"markdown","source":"The sample submission consists in always predicting the first 30 species for all the test observations:","metadata":{}},{"cell_type":"code","source":"first_30_species = np.arange(30)\ns_pred = np.tile(first_30_species[None], (len(df_obs_test), 1))","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:36.18507Z","start_time":"2022-02-15T15:34:36.176395Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:31.544516Z","iopub.execute_input":"2022-02-23T11:28:31.544727Z","iopub.status.idle":"2022-02-23T11:28:31.551598Z","shell.execute_reply.started":"2022-02-23T11:28:31.544702Z","shell.execute_reply":"2022-02-23T11:28:31.549768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can then generate the associated submission file using:","metadata":{}},{"cell_type":"code","source":"generate_submission_file(SUBMISSION_PATH / \"sample_submission.csv\", df_obs_test.index, s_pred)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:36.873681Z","start_time":"2022-02-15T15:34:36.188032Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:31.5551Z","iopub.execute_input":"2022-02-23T11:28:31.555527Z","iopub.status.idle":"2022-02-23T11:28:32.671815Z","shell.execute_reply.started":"2022-02-23T11:28:31.555491Z","shell.execute_reply":"2022-02-23T11:28:32.670977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Constant baseline: 30 most observed species\n\nThe first baseline consists in predicting the 30 most observed species on the train set which corresponds exactly to the \"Top-30 most present species\":","metadata":{}},{"cell_type":"code","source":"species_distribution = df_obs.loc[obs_id_train][\"species_id\"].value_counts(normalize=True)\ntop_30_most_observed = species_distribution.index.values[:30]","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:37.030364Z","start_time":"2022-02-15T15:34:36.875285Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:32.6731Z","iopub.execute_input":"2022-02-23T11:28:32.673508Z","iopub.status.idle":"2022-02-23T11:28:32.906951Z","shell.execute_reply.started":"2022-02-23T11:28:32.673471Z","shell.execute_reply":"2022-02-23T11:28:32.905689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, it does not perform very well on the validation set:","metadata":{}},{"cell_type":"code","source":"s_pred = np.tile(top_30_most_observed[None], (n_val, 1))\nscore = top_k_error_rate_from_sets(y_val, s_pred)\nprint(\"Top-30 error rate: {:.1%}\".format(score))","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:37.043069Z","start_time":"2022-02-15T15:34:37.032104Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:32.908107Z","iopub.execute_input":"2022-02-23T11:28:32.908317Z","iopub.status.idle":"2022-02-23T11:28:32.92115Z","shell.execute_reply.started":"2022-02-23T11:28:32.908288Z","shell.execute_reply":"2022-02-23T11:28:32.919924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will however generate the associated submission file on the test using:","metadata":{}},{"cell_type":"code","source":"# Compute baseline on the test set\nn_test = len(df_obs_test)\ns_pred = np.tile(top_30_most_observed[None], (n_test, 1))\n\n# Generate the submission file\ngenerate_submission_file(SUBMISSION_PATH / \"constant_top_30_most_present_species_baseline.csv\", df_obs_test.index, s_pred)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:37.762255Z","start_time":"2022-02-15T15:34:37.044524Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:32.922711Z","iopub.execute_input":"2022-02-23T11:28:32.922935Z","iopub.status.idle":"2022-02-23T11:28:34.081059Z","shell.execute_reply.started":"2022-02-23T11:28:32.922907Z","shell.execute_reply":"2022-02-23T11:28:34.080281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random forest on environmental vectors\n\nA classical approach in ecology is to train Random Forests on environmental vectors.\n\nWe show here how to do so using [scikit-learn](https://scikit-learn.org/).\n\nWe start by loading the environmental vectors:","metadata":{}},{"cell_type":"code","source":"df_env = pd.read_csv(DATA_PATH / \"pre-extracted\" / \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n\nX_train = df_env.loc[obs_id_train].values\nX_val = df_env.loc[obs_id_val].values\nX_test = df_env.loc[obs_id_test].values","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:45.731902Z","start_time":"2022-02-15T15:34:37.764022Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:34.082231Z","iopub.execute_input":"2022-02-23T11:28:34.082493Z","iopub.status.idle":"2022-02-23T11:28:42.051146Z","shell.execute_reply.started":"2022-02-23T11:28:34.082454Z","shell.execute_reply":"2022-02-23T11:28:42.050056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we need to handle properly the missing values.\n\nFor instance, using `SimpleImputer`:","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(\n    missing_values=np.nan,\n    strategy=\"constant\",\n    fill_value=np.finfo(np.float32).min,\n)\nimp.fit(X_train)\n\nX_train = imp.transform(X_train)\nX_val = imp.transform(X_val)\nX_test = imp.transform(X_test)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:34:46.705147Z","start_time":"2022-02-15T15:34:45.734104Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:42.052335Z","iopub.execute_input":"2022-02-23T11:28:42.05254Z","iopub.status.idle":"2022-02-23T11:28:44.014468Z","shell.execute_reply.started":"2022-02-23T11:28:42.052512Z","shell.execute_reply":"2022-02-23T11:28:44.013661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now start training our Random Forest (as there are a lot of observations, over 1.8M, this can take a while):","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nest = RandomForestClassifier(n_estimators=16, max_depth=10, n_jobs=-1)\nest.fit(X_train, y_train)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:37:23.045384Z","start_time":"2022-02-15T15:34:46.706534Z"},"execution":{"iopub.status.busy":"2022-02-23T11:28:44.015652Z","iopub.execute_input":"2022-02-23T11:28:44.015855Z","iopub.status.idle":"2022-02-23T11:34:16.43326Z","shell.execute_reply.started":"2022-02-23T11:28:44.015827Z","shell.execute_reply":"2022-02-23T11:34:16.432275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As there are a lot of classes (over 17K), we need to be cautious when predicting the scores of the model.\n\nThis can easily take more than 5Go on the validation set.\n\nFor this reason, we will be predict the top-30 sets by batches using the following generic function:","metadata":{}},{"cell_type":"code","source":"def batch_predict(predict_func, X, batch_size=1024):\n    res = predict_func(X[:1])\n    n_samples, n_outputs, dtype = X.shape[0], res.shape[1], res.dtype\n    \n    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n    \n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        preds[i:i+batch_size] = predict_func(X_batch)\n            \n    return preds","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:37:23.06365Z","start_time":"2022-02-15T15:37:23.051514Z"},"execution":{"iopub.status.busy":"2022-02-23T11:34:16.435207Z","iopub.execute_input":"2022-02-23T11:34:16.435747Z","iopub.status.idle":"2022-02-23T11:34:16.442911Z","shell.execute_reply.started":"2022-02-23T11:34:16.435713Z","shell.execute_reply":"2022-02-23T11:34:16.442211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can know compute the top-30 error rate on the validation set:","metadata":{}},{"cell_type":"code","source":"def predict_func(X):\n    y_score = est.predict_proba(X)\n    s_pred = predict_top_30_set(y_score)\n    return s_pred\n\ns_val = batch_predict(predict_func, X_val, batch_size=1024)\nscore_val = top_k_error_rate_from_sets(y_val, s_val)\nprint(\"Top-30 error rate: {:.1%}\".format(score_val))","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:38:04.919835Z","start_time":"2022-02-15T15:37:23.068792Z"},"execution":{"iopub.status.busy":"2022-02-23T11:34:16.444325Z","iopub.execute_input":"2022-02-23T11:34:16.444747Z","iopub.status.idle":"2022-02-23T11:34:39.282349Z","shell.execute_reply.started":"2022-02-23T11:34:16.444711Z","shell.execute_reply":"2022-02-23T11:34:39.281291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now predict the top-30 sets on the test data and save them in a submission file:","metadata":{}},{"cell_type":"code","source":"# Compute baseline on the test set\ns_pred = batch_predict(predict_func, X_test, batch_size=1024)\n\n# Generate the submission file\ngenerate_submission_file(SUBMISSION_PATH / \"random_forest_on_environmental_vectors.csv\", df_obs_test.index, s_pred)","metadata":{"ExecuteTime":{"end_time":"2022-02-15T15:38:44.086269Z","start_time":"2022-02-15T15:38:04.921407Z"},"execution":{"iopub.status.busy":"2022-02-23T11:34:39.283291Z","iopub.execute_input":"2022-02-23T11:34:39.28346Z","iopub.status.idle":"2022-02-23T11:35:01.554345Z","shell.execute_reply.started":"2022-02-23T11:34:39.283439Z","shell.execute_reply":"2022-02-23T11:35:01.553235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note that the baseline appearing on the leaderboard is a similar Random Forest of 100 trees and a max depth of 16.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}