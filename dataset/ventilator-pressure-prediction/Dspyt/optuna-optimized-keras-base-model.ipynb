{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport gc\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import *\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_absolute_error","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset creation\nTraining dataset is prepared with functions in the [feature engineering notebook](https://www.kaggle.com/mistag/ventilator-feature-engineering), which is based on [Improvement base on Tensor Bidirect LSTM](https://www.kaggle.com/kensit/improvement-base-on-tensor-bidirect-lstm-0-173/notebook) by [Ken Sit](https://www.kaggle.com/kensit).","metadata":{}},{"cell_type":"code","source":"def bvar(series):\n    series = abs(series).rolling(window=2).apply(np.prod, raw=True)\n    return np.sum(series)*((2/np.pi)**(-2))\n\ndef add_features(df):\n    df['400'] = (df.index.to_series() / 400).astype(int)\n    df['8000'] = (df.index.to_series() / 8000).astype(int)\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df[\"area_max\"] = df.groupby(\"breath_id\")[\"area\"].transform(\"max\")\n    df['area_w5_prod'] = abs(df.area).rolling(window=5).apply(np.prod, raw=True)\n\n    df[\"u_in_max\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")\n    df[\"u_in_sum\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"sum\")\n    df['u_in_bvar'] = df.groupby(\"breath_id\")[\"u_in\"].transform(bvar)\n    df[\"u_in_lag1\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(1)\n    df[\"u_in_lag2\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(2)\n    df[\"u_in_lag3\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(3)\n\n    df[\"u_in_cumsum\"] = df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n    df[\"u_in_cumsum_reverse\"] = df[\"u_in_sum\"] - df[\"u_in_cumsum\"]\n    \n    df[\"u_out_sum\"] = df.groupby(\"breath_id\")[\"u_out\"].transform(\"sum\")\n    df[\"u_out_cumsum\"] = df.groupby(\"breath_id\")[\"u_out\"].cumsum()\n    df[\"u_out_cumsum_reverse\"] = df[\"u_out_sum\"] - df[\"u_out_cumsum\"]\n    \n    df[\"time_passed\"] = df.groupby(\"breath_id\")[\"time_step\"].diff()\n    \n    df['RC'] = df[\"R\"] + df[\"C\"]\n    df['R-C']= df.R - df.C\n    df[\"RC_400_mean\"] = df.groupby(\"400\")[\"RC\"].transform(\"mean\")\n    df['R-C_8000_mean']= df.groupby(\"8000\")['R-C'].transform(\"mean\")\n    #df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df.drop(['id','breath_id','u_out','R','C','area',\"u_in\",'time_step','400','RC','u_in_sum',\"R-C\",'u_out_sum'],axis=1)\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ori = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntargets = train_ori['pressure'].to_numpy().reshape(-1, 80)\ntrain_ori.drop(labels='pressure', axis=1, inplace=True)\ntrain = add_features(train_ori)\n# normalise the dataset\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\n\n# Reshape to group 80 timesteps for each breath ID\ntrain = train.reshape(-1, 80, train.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:21:01.610286Z","iopub.execute_input":"2021-10-04T05:21:01.610861Z","iopub.status.idle":"2021-10-04T05:21:41.696623Z","shell.execute_reply.started":"2021-10-04T05:21:01.610812Z","shell.execute_reply":"2021-10-04T05:21:41.695625Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test set is created below, using the feature engineering function from the above mentioned notebook:","metadata":{}},{"cell_type":"code","source":"test_ori = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\ntest = add_features(test_ori)\ntest = RS.transform(test)\ntest = test.reshape(-1, 80, test.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:21:41.698502Z","iopub.execute_input":"2021-10-04T05:21:41.69892Z","iopub.status.idle":"2021-10-04T05:22:02.670754Z","shell.execute_reply.started":"2021-10-04T05:21:41.698877Z","shell.execute_reply":"2021-10-04T05:22:02.66972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model creation\nModel parameters are from [Keras model tuning with Optuna](https://www.kaggle.com/mistag/keras-model-tuning-with-optuna). (The \"optimal parameters\" will not be exactly the same every time the optimization study is run, so the parameters used below might differ from the model tuning notebook).","metadata":{}},{"cell_type":"code","source":"# model creation\ndef create_lstm_model():\n\n    x0 = tf.keras.layers.Input(shape=(train.shape[-2], train.shape[-1]))  \n\n    lstm_layers = 2 # number of LSTM layers\n    lstm_units = [320, 229]\n    lstm = Bidirectional(keras.layers.LSTM(lstm_units[0], return_sequences=True))(x0)\n    for i in range(lstm_layers-1):\n        lstm = Bidirectional(keras.layers.LSTM(lstm_units[i+1], return_sequences=True))(lstm)    \n    lstm = Dropout(0.01)(lstm)\n    lstm = Dense(100, activation='relu')(lstm)\n    lstm = Dense(1)(lstm)\n\n    model = keras.Model(inputs=x0, outputs=lstm)\n    model.compile(optimizer=\"adam\", loss=\"mae\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:22:07.041066Z","iopub.execute_input":"2021-10-04T05:22:07.041416Z","iopub.status.idle":"2021-10-04T05:22:07.050479Z","shell.execute_reply.started":"2021-10-04T05:22:07.041358Z","shell.execute_reply":"2021-10-04T05:22:07.049742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Function to get hardware strategy\ndef get_hardware_strategy():\n    try:\n        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n        # set: this is always the case on Kaggle.\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        tf.config.optimizer.set_jit(True)\n    else:\n        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n        strategy = tf.distribute.get_strategy()\n\n    return tpu, strategy\n\ntpu, strategy = get_hardware_strategy()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-04T05:22:08.88671Z","iopub.execute_input":"2021-10-04T05:22:08.887524Z","iopub.status.idle":"2021-10-04T05:22:14.755117Z","shell.execute_reply.started":"2021-10-04T05:22:08.887464Z","shell.execute_reply":"2021-10-04T05:22:14.754077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 350\nBATCH_SIZE = 512\nNFOLDS = 2\n\nwith strategy.scope():\n    kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=2021)\n    history = []\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = create_lstm_model()\n        model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n\n        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose=0)\n\n        history.append(model.fit(X_train, y_train, \n                                 validation_data=(X_valid, y_valid), \n                                 epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr]))\n        test_pred = model.predict(test).squeeze().reshape(-1, 1).squeeze()\n        test_preds.append(test_pred)    \n        \n        # save model\n        #model.save(\"lstm_model_fold_{}\".format(fold))\n        \n        del X_train, X_valid, y_train, y_valid, model\n        gc.collect()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-04T05:29:13.569896Z","iopub.execute_input":"2021-10-04T05:29:13.570488Z","iopub.status.idle":"2021-10-04T05:31:16.505381Z","shell.execute_reply.started":"2021-10-04T05:29:13.570448Z","shell.execute_reply":"2021-10-04T05:31:16.504044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\nsubmission[\"pressure\"] = sum(test_preds)/2\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T10:16:17.4267Z","iopub.execute_input":"2021-10-03T10:16:17.427026Z","iopub.status.idle":"2021-10-03T10:16:30.69901Z","shell.execute_reply.started":"2021-10-03T10:16:17.426996Z","shell.execute_reply":"2021-10-03T10:16:30.698315Z"},"trusted":true},"execution_count":null,"outputs":[]}]}