{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.layers import Conv1D, Input, Dense, Add, Multiply\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import models\nimport tensorflow_addons as tfa\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\nfrom tqdm.notebook import tqdm\n\n%matplotlib inline\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:30.928159Z","iopub.execute_input":"2021-10-16T01:12:30.928984Z","iopub.status.idle":"2021-10-16T01:12:37.812061Z","shell.execute_reply.started":"2021-10-16T01:12:30.928896Z","shell.execute_reply":"2021-10-16T01:12:37.811053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:37.816149Z","iopub.execute_input":"2021-10-16T01:12:37.816396Z","iopub.status.idle":"2021-10-16T01:12:37.826122Z","shell.execute_reply.started":"2021-10-16T01:12:37.816368Z","shell.execute_reply":"2021-10-16T01:12:37.825014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data and some statistics","metadata":{}},{"cell_type":"code","source":"train_ori = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest_ori = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:37.827721Z","iopub.execute_input":"2021-10-16T01:12:37.828827Z","iopub.status.idle":"2021-10-16T01:12:50.802184Z","shell.execute_reply.started":"2021-10-16T01:12:37.828778Z","shell.execute_reply":"2021-10-16T01:12:50.801192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ori","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:50.804193Z","iopub.execute_input":"2021-10-16T01:12:50.804809Z","iopub.status.idle":"2021-10-16T01:12:50.843658Z","shell.execute_reply.started":"2021-10-16T01:12:50.804778Z","shell.execute_reply":"2021-10-16T01:12:50.842545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Length of TRAIN dataset: {len(train_ori)}')\nprint(f'Length of TEST dataset: {len(test_ori)}')\nprint('')\nprint('Missing values in TRAIN dataset')\nfor i in train_ori.iloc[:, 0:-1].columns.tolist():\n    print(f'{i}: {train_ori[i].isna().sum()}')\nprint('')\nprint('Missing values in TEST dataset')\nfor i in test_ori.iloc[:, 0:-1].columns.tolist():\n    print(f'{i}: {test_ori[i].isna().sum()}')\nprint('')\nprint(f'Number of breaths in train dataset: {train_ori[\"breath_id\"].nunique()}')\nprint(f'Number of breaths in test dataset: {test_ori[\"breath_id\"].nunique()}')\nprint(f'The number of observations for each breath: {train_ori[\"breath_id\"].value_counts().reset_index()[\"breath_id\"].unique()[0]}')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:50.845391Z","iopub.execute_input":"2021-10-16T01:12:50.845728Z","iopub.status.idle":"2021-10-16T01:12:51.446965Z","shell.execute_reply.started":"2021-10-16T01:12:50.845687Z","shell.execute_reply":"2021-10-16T01:12:51.445027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_initial = train_ori[train_ori['time_step']==0]\ntrain_initial","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:51.449215Z","iopub.execute_input":"2021-10-16T01:12:51.44952Z","iopub.status.idle":"2021-10-16T01:12:51.511753Z","shell.execute_reply.started":"2021-10-16T01:12:51.449482Z","shell.execute_reply":"2021-10-16T01:12:51.510715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_mean = train_initial['pressure'].mean()\ntotal_std = train_initial['pressure'].std()\nprint('total mean: {}'.format(total_mean))\nprint('total std: {}'.format(total_std))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:51.513592Z","iopub.execute_input":"2021-10-16T01:12:51.513944Z","iopub.status.idle":"2021-10-16T01:12:51.522712Z","shell.execute_reply.started":"2021-10-16T01:12:51.513875Z","shell.execute_reply":"2021-10-16T01:12:51.521323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_stat_mean = train_initial.groupby(['R', 'C']).mean()\ninitial_stat_std = train_initial.groupby(['R', 'C']).std()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:51.525967Z","iopub.execute_input":"2021-10-16T01:12:51.526857Z","iopub.status.idle":"2021-10-16T01:12:51.554205Z","shell.execute_reply.started":"2021-10-16T01:12:51.526785Z","shell.execute_reply":"2021-10-16T01:12:51.553234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_stat = pd.DataFrame({'R': [5, 5, 5, 20, 20, 20, 50, 50, 50],\n                            'C': [10, 20, 50, 10, 20, 50, 10, 20, 50],\n                            'mean': initial_stat_mean['pressure'].values,\n                            'std': initial_stat_std['pressure'].values})\ninitial_stat","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:12:51.555822Z","iopub.execute_input":"2021-10-16T01:12:51.556172Z","iopub.status.idle":"2021-10-16T01:12:51.573172Z","shell.execute_reply.started":"2021-10-16T01:12:51.556133Z","shell.execute_reply":"2021-10-16T01:12:51.571801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add Features","metadata":{}},{"cell_type":"code","source":"def add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross1'] = df['u_in'] * (1 - df['u_out'])\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    print(\"Step-2...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-3...Completed\")\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n    df['u_in_lagback_diff3'] = df['u_in'] - df['u_in_lag_back3']\n    df['u_out_lagback_diff3'] = df['u_out'] - df['u_out_lag_back3']\n    df['u_in_lagback_diff4'] = df['u_in'] - df['u_in_lag_back4']\n    df['u_out_lagback_diff4'] = df['u_out'] - df['u_out_lag_back4']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    '''df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']'''\n    print(\"Step-5...Completed\")\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    \n    '''df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n                                                              .groupby('breath_id')['u_in']\\\n                                                              .rolling(window=15,min_periods=1)\\\n                                                              .agg({\"15_in_sum\":\"sum\",\n                                                                    \"15_in_min\":\"min\",\n                                                                    \"15_in_max\":\"max\",\n                                                                    \"15_in_mean\":\"mean\"\n                                                                    #\"15_in_std\":\"std\"\n                                                               })\\\n                                                               .reset_index(level=0,drop=True))'''\n    print(\"Step-6...Completed\")\n    \n    #df['u_in_diff_1_2'] = df['u_in_lag1'] - df['u_in_lag2']\n    #df['u_out_diff_1_2'] = df['u_out_lag1'] - df['u_out_lag2']\n    #df['u_in_lagback_diff_1_2'] = df['u_in_lag_back1'] - df['u_in_lag_back2']\n    #df['u_out_lagback_diff_1_2'] = df['u_out_lag_back1'] - df['u_out_lag_back2']\n    \n    df['u_in_diff1_lag'] = df.groupby('breath_id')['u_in_diff1'].shift(1)\n    df['u_in_diff2_lag'] = df.groupby('breath_id')['u_in_diff2'].shift(1)\n    df['u_in_diff3_lag'] = df.groupby('breath_id')['u_in_diff3'].shift(1)\n    df['u_in_diff4_lag'] = df.groupby('breath_id')['u_in_diff4'].shift(1)\n    df = df.fillna(0)\n    df['u_in_diff1_diff'] = df['u_in_diff1'] - df['u_in_diff1_lag']\n    df['u_in_diff2_diff'] = df['u_in_diff1'] - df['u_in_diff2_lag']\n    df['u_in_diff3_diff'] = df['u_in_diff1'] - df['u_in_diff3_lag']\n    df['u_in_diff4_diff'] = df['u_in_diff1'] - df['u_in_diff4_lag']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    print(\"Step-8...Completed\")\n    return df\n\ntrain = add_features(train_ori)\ntest = add_features(test_ori)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:20:21.747206Z","iopub.execute_input":"2021-10-16T01:20:21.747547Z","iopub.status.idle":"2021-10-16T01:22:13.897834Z","shell.execute_reply.started":"2021-10-16T01:20:21.747518Z","shell.execute_reply":"2021-10-16T01:22:13.896385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id', 'one', 'count', 'u_in_lag1','u_in_lag2','u_in_lag3','u_in_lag4',\n           'u_out_lag1','u_out_lag2','u_out_lag3','u_out_lag4','u_in_lag_back1','u_in_lag_back2','u_in_lag_back3','u_in_lag_back4',\n           'u_out_lag_back1','u_out_lag_back2','u_out_lag_back3','u_out_lag_back4','u_in_diff1_lag','u_in_diff2_lag','u_in_diff3_lag','u_in_diff4_lag'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id','one', 'count', 'u_in_lag1','u_in_lag2','u_in_lag3','u_in_lag4',\n           'u_out_lag1','u_out_lag2','u_out_lag3','u_out_lag4','u_in_lag_back1','u_in_lag_back2','u_in_lag_back3','u_in_lag_back4',\n           'u_out_lag_back1','u_out_lag_back2','u_out_lag_back3','u_out_lag_back4','u_in_diff1_lag','u_in_diff2_lag','u_in_diff3_lag','u_in_diff4_lag'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:05.927737Z","iopub.execute_input":"2021-10-16T01:25:05.928041Z","iopub.status.idle":"2021-10-16T01:25:11.807413Z","shell.execute_reply.started":"2021-10-16T01:25:05.928014Z","shell.execute_reply":"2021-10-16T01:25:11.806492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:14.526298Z","iopub.execute_input":"2021-10-16T01:25:14.527258Z","iopub.status.idle":"2021-10-16T01:25:14.540507Z","shell.execute_reply.started":"2021-10-16T01:25:14.527227Z","shell.execute_reply":"2021-10-16T01:25:14.539248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:31.817768Z","iopub.execute_input":"2021-10-16T01:25:31.818071Z","iopub.status.idle":"2021-10-16T01:25:43.539107Z","shell.execute_reply.started":"2021-10-16T01:25:31.818043Z","shell.execute_reply":"2021-10-16T01:25:43.538112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, test.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:43.541147Z","iopub.execute_input":"2021-10-16T01:25:43.541577Z","iopub.status.idle":"2021-10-16T01:25:43.547576Z","shell.execute_reply.started":"2021-10-16T01:25:43.541535Z","shell.execute_reply":"2021-10-16T01:25:43.546513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:43.549323Z","iopub.execute_input":"2021-10-16T01:25:43.549921Z","iopub.status.idle":"2021-10-16T01:25:43.563744Z","shell.execute_reply.started":"2021-10-16T01:25:43.54988Z","shell.execute_reply":"2021-10-16T01:25:43.562698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shape_ = train.shape[1:]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:43.566012Z","iopub.execute_input":"2021-10-16T01:25:43.568374Z","iopub.status.idle":"2021-10-16T01:25:43.574122Z","shell.execute_reply.started":"2021-10-16T01:25:43.568344Z","shell.execute_reply":"2021-10-16T01:25:43.572823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = targets[:,:,np.newaxis]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:43.575919Z","iopub.execute_input":"2021-10-16T01:25:43.576618Z","iopub.status.idle":"2021-10-16T01:25:43.585536Z","shell.execute_reply.started":"2021-10-16T01:25:43.576577Z","shell.execute_reply":"2021-10-16T01:25:43.584515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"EPOCH = 300\nBATCH_SIZE = 128\nLR = 1e-3","metadata":{"execution":{"iopub.status.busy":"2021-10-16T01:25:43.5873Z","iopub.execute_input":"2021-10-16T01:25:43.587986Z","iopub.status.idle":"2021-10-16T01:25:43.59679Z","shell.execute_reply.started":"2021-10-16T01:25:43.587934Z","shell.execute_reply":"2021-10-16T01:25:43.59584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model\n- https://github.com/stdereka/liverpool-ion-switching/blob/f44c57e88a3e7889720c88710135f2c7d31b416e/model/nn.py#L116","metadata":{}},{"cell_type":"code","source":"def conv_block(x: tf.Tensor, filters: int, kernel_size: int):\n    \"\"\"\n    Implements convolution block with residual connection.\n    :param x: Input tensor.\n    :param filters: Number of filters in convolution layer.\n    :param kernel_size: Filter size.\n    :return: Output tensor.\n    \"\"\"\n    x = Conv1D(filters=filters,\n               kernel_size=1,\n               padding='same')(x)\n    res_x = x\n    x = Conv1D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same', activation='relu')(x)\n    x = Conv1D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same', activation='relu')(x)\n    x = Conv1D(filters=filters,\n               kernel_size=kernel_size,\n               padding='same', activation='relu')(x)\n    res_x = Add()([res_x, x])\n    return res_x\n\ndef wave_block(x: tf.Tensor, filters: int, kernel_size: int, n: int):\n    \"\"\"\n    Implements wavenet block.\n    :param x: Input tensor.\n    :param filters: Number of kernels.\n    :param kernel_size: Filter size.\n    :param n: Number of dilation rates for convolutions.\n    :return: Output tensor.\n    \"\"\"\n    dilation_rates = [2 ** i for i in range(n)]\n    x = Conv1D(filters=filters,\n               kernel_size=1,\n               padding='same')(x)\n    res_x = x\n    for dilation_rate in dilation_rates:\n        tanh_out = Conv1D(filters=filters,\n                          kernel_size=kernel_size,\n                          padding='same',\n                          activation='tanh',\n                          dilation_rate=dilation_rate)(x)\n        sigm_out = Conv1D(filters=filters,\n                          kernel_size=kernel_size,\n                          padding='same',\n                          activation='sigmoid',\n                          dilation_rate=dilation_rate)(x)\n        x = Multiply()([tanh_out, sigm_out])\n        x = Conv1D(filters=filters,\n                   kernel_size=1,\n                   padding='same')(x)\n        res_x = Add()([res_x, x])\n    return res_x","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-16T01:25:43.598747Z","iopub.execute_input":"2021-10-16T01:25:43.599192Z","iopub.status.idle":"2021-10-16T01:25:43.615342Z","shell.execute_reply.started":"2021-10-16T01:25:43.59915Z","shell.execute_reply":"2021-10-16T01:25:43.61408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    inp = Input(shape_)\n    x = conv_block(inp, 16, 3)\n    x = wave_block(x, 16, 3, 12)\n    x = conv_block(x, 32, 3)\n    x = wave_block(x, 32, 3, 8)\n    x = conv_block(x, 64, 3)\n    x = wave_block(x, 64, 3, 4)\n    x = conv_block(x, 128, 3)\n    x = wave_block(x, 128, 3, 1)\n    x = keras.layers.Activation('swish')(x)\n    out = Dense(1, name='out')(x)\n    model = models.Model(inputs=inp, outputs=out)\n    opt = Adam(lr=LR)\n    opt = tfa.optimizers.SWA(opt)\n    model.compile(loss='mae', optimizer=opt)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-09T01:17:12.578629Z","iopub.execute_input":"2021-10-09T01:17:12.579316Z","iopub.status.idle":"2021-10-09T01:17:12.589951Z","shell.execute_reply.started":"2021-10-09T01:17:12.579282Z","shell.execute_reply":"2021-10-09T01:17:12.589291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"#submission_tmp = submission.copy()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T01:17:12.591671Z","iopub.execute_input":"2021-10-09T01:17:12.591884Z","iopub.status.idle":"2021-10-09T01:17:12.601142Z","shell.execute_reply.started":"2021-10-09T01:17:12.59186Z","shell.execute_reply":"2021-10-09T01:17:12.600455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n#with tpu_strategy.scope():\nkf = KFold(n_splits=5, shuffle=True, random_state=2021)\ntest_preds = []\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n    if (fold != 0) and (fold != 1):\n        continue\n    submission_tmp = submission.copy()\n    print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n    X_train, X_valid = train[train_idx], train[test_idx]\n    y_train, y_valid = targets[train_idx], targets[test_idx]\n    X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n    X_valid = tf.convert_to_tensor(X_valid, dtype=tf.float32)\n    y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n    y_valid = tf.convert_to_tensor(y_valid, dtype=tf.float32)\n    model = get_model()\n\n    scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n    lr = LearningRateScheduler(scheduler, verbose=1)\n\n    #es = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1, mode=\"min\", restore_best_weights=True)\n    sv = tf.keras.callbacks.ModelCheckpoint(\n    'fold-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='min', save_freq='epoch')\n\n    history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, sv])\n    model.load_weights('fold-%i.h5'%fold)\n    pred = model.predict(test).squeeze().reshape(-1, 1).squeeze()\n    submission_tmp['pressure'] = pred\n    submission_tmp.to_csv('submission_{}.csv'.format(fold), index=False)\n    test_preds.append(pred)\n    \n    plt.figure(figsize=(15, 5))\n    plt.plot(\n        np.arange(len(history.history[\"loss\"])),\n        history.history[\"loss\"],\n        \"-o\",\n        label=\"Train Loss\",\n        color=\"#2ca02c\")\n    plt.plot(\n        np.arange(len(history.history[\"loss\"])),\n        history.history[\"val_loss\"],\n        \"-o\",\n        label=\"Val Loss\",\n        color=\"#d62728\")\n    \n    x = np.argmin(history.history[\"val_loss\"])\n    y = np.min(history.history[\"val_loss\"])\n    x1 = np.argmin(history.history[\"loss\"])\n    y1 = np.min(history.history[\"loss\"])\n    \n    xdist = plt.xlim()[1] - plt.xlim()[0]\n    ydist = plt.ylim()[1] - plt.ylim()[0]\n\n    plt.scatter(x, y, s=200, color=\"#d62728\")\n    plt.text(x - 0.03 * xdist, y + 0.05 * ydist, \"min val_loss:{:.4f}\".format(y), size=14)\n    plt.scatter(x1, y1, s=200, color=\"#2ca02c\")\n    plt.text(x1 - 0.03 * xdist, y1 + 0.05 * ydist, \"min loss:{:.4f}\".format(y1), size=14)\n\n    plt.xlabel(\"Epoch\", size=14)\n    plt.ylabel(\"Loss\", size=14)\n\n    plt.legend()\n    plt.savefig(f\"fig{fold}.png\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T01:17:12.602473Z","iopub.execute_input":"2021-10-09T01:17:12.602931Z","iopub.status.idle":"2021-10-09T01:18:22.781471Z","shell.execute_reply.started":"2021-10-09T01:17:12.602896Z","shell.execute_reply":"2021-10-09T01:18:22.778601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"pressure\"] = sum(test_preds)/2\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}