{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\n\nimport os\n\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nimport torch.optim as optim \nimport torch.nn.init as init \nimport torch.nn.functional as F \nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom transformers import AdamW \nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T16:39:50.524422Z","iopub.execute_input":"2022-02-10T16:39:50.524915Z","iopub.status.idle":"2022-02-10T16:39:57.072862Z","shell.execute_reply.started":"2022-02-10T16:39:50.524821Z","shell.execute_reply":"2022-02-10T16:39:57.072116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bunch of useful links: \n# https://www.kaggle.com/theoviel/deep-learning-starter-simple-lstm\n# https://www.kaggle.com/yasufuminakama/ventilator-pressure-lstm-starter\n# https://www.kaggle.com/shujun717/1-solution-lstm-cnn-transformer-1-fold\n# https://www.kaggle.com/junkoda/pytorch-lstm-with-tensorflow-like-initialization\n# https://www.kaggle.com/sagarikajadon/simple-lstm-pytorch","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:39:57.074463Z","iopub.execute_input":"2022-02-10T16:39:57.074702Z","iopub.status.idle":"2022-02-10T16:39:57.078302Z","shell.execute_reply.started":"2022-02-10T16:39:57.074665Z","shell.execute_reply":"2022-02-10T16:39:57.077644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:39:57.079466Z","iopub.execute_input":"2022-02-10T16:39:57.080297Z","iopub.status.idle":"2022-02-10T16:39:57.091021Z","shell.execute_reply.started":"2022-02-10T16:39:57.08026Z","shell.execute_reply":"2022-02-10T16:39:57.090166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    competition='ventilator'\n    print_freq=100\n    apex=False\n    scheduler='CosineAnnealingLR' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    \n    batch_scheduler=False\n    epochs=10\n    num_workers=4\n    \n    dense_dim = 512\n    lstm_dim = 512\n    logit_dim = 512\n    num_classes = 1\n    \n    input_dim=4\n    matrix_dim=4\n    \n    hidden_size=64\n    lr=5e-3\n    min_lr=1e-6\n    batch_size=64\n    \n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    \n    train=True\n    inference=True\n    \n    device='cuda' if torch.cuda.is_available() else \"cpu\"\n    save_weights = True\n    \n    optimizer=\"Adam\"\n    loss='L1Loss'\n    \n    cate_seq_cols=['R', 'C']\n    cont_seq_cols=[ 'u_in', 'u_out']","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:39:57.093345Z","iopub.execute_input":"2022-02-10T16:39:57.093648Z","iopub.status.idle":"2022-02-10T16:39:57.139788Z","shell.execute_reply.started":"2022-02-10T16:39:57.093614Z","shell.execute_reply":"2022-02-10T16:39:57.139085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\ntest_ids = test['id'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:39:57.14108Z","iopub.execute_input":"2022-02-10T16:39:57.141515Z","iopub.status.idle":"2022-02-10T16:40:13.413418Z","shell.execute_reply.started":"2022-02-10T16:39:57.141477Z","shell.execute_reply":"2022-02-10T16:40:13.412675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = train.breath_id.values.reshape(-1, 80)[:, 0]\n\ntargets = train['pressure'].to_numpy().reshape(-1, 80)\ntrain.drop(['breath_id'], axis=1, inplace=True)\ntargets\n\nfrom sklearn.preprocessing import RobustScaler \nRS = RobustScaler()\ntrain = RS.fit_transform(train)\n\nnum_features = train.shape[-1]\ntrain = train.reshape(-1, 80, num_features)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:13.414636Z","iopub.execute_input":"2022-02-10T16:40:13.414893Z","iopub.status.idle":"2022-02-10T16:40:14.75665Z","shell.execute_reply.started":"2022-02-10T16:40:13.41486Z","shell.execute_reply":"2022-02-10T16:40:14.755907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load dataset \n# should not be used, error in dataloading\n# Inspired by https://www.kaggle.com/theoviel/deep-learning-starter-simple-lstm\n\nimport torch\nfrom torch.utils.data import Dataset\n\nclass VentilatorDataset(Dataset): \n    def __init__(self, df): \n        if 'pressure' not in df.columns: \n            df['pressure'] = 0\n        self.df = df.groupby('breath_id').agg(list).reset_index()\n        self.R = np.array(self.df['R'].values.tolist())\n        self.C = np.array(self.df['C'].values.tolist())\n        self.u_in = np.array(self.df['u_in'].values.tolist())\n        self.pressure = np.array(self.df['pressure'].values.tolist())\n        self.u_out = np.array(self.df['u_out'].values.tolist())\n        self.inputs = np.concatenate(\n            [self.R[:,None], self.C[:, None], self.u_in[:, None], self.u_out[:, None]], 1).transpose(0, 2, 1)\n        # self.u_out\n        # self.input\n    def __len__(self):\n        return len(self.df.shape[0])\n    \n    def __getitem__(self, idx):\n        data = {\n            'input': torch.tensor(self.inputs[idx], dtype=torch.float),\n            'u_out': torch.tensor(self.u_out[idx], dtype=torch.float),\n            'pressure': torch.tensor(self.pressure[idx], dtype=torch.float)\n        }\n        return data","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:14.757801Z","iopub.execute_input":"2022-02-10T16:40:14.758077Z","iopub.status.idle":"2022-02-10T16:40:14.770651Z","shell.execute_reply.started":"2022-02-10T16:40:14.758038Z","shell.execute_reply":"2022-02-10T16:40:14.769947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CusDataset(Dataset): \n    def __init__(self, data, target): \n        self.data = data\n        self.target = target\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        current_sample = self.data[idx, :, :]\n        current_target = self.target[idx, :]\n        \n        return torch.tensor(current_sample, dtype = torch.float), torch.tensor(current_target, dtype = torch.float)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:14.771769Z","iopub.execute_input":"2022-02-10T16:40:14.772126Z","iopub.status.idle":"2022-02-10T16:40:14.779939Z","shell.execute_reply.started":"2022-02-10T16:40:14.772087Z","shell.execute_reply":"2022-02-10T16:40:14.779299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = CusDataset(train, targets)\ndata[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:14.782698Z","iopub.execute_input":"2022-02-10T16:40:14.78289Z","iopub.status.idle":"2022-02-10T16:40:14.865016Z","shell.execute_reply.started":"2022-02-10T16:40:14.782856Z","shell.execute_reply":"2022-02-10T16:40:14.864238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#td = TrainDataset(train)\n#td[69]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:14.867452Z","iopub.execute_input":"2022-02-10T16:40:14.867752Z","iopub.status.idle":"2022-02-10T16:40:14.871049Z","shell.execute_reply.started":"2022-02-10T16:40:14.867716Z","shell.execute_reply":"2022-02-10T16:40:14.870252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset = VentilatorDataset(main_df)\n#dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:14.872186Z","iopub.execute_input":"2022-02-10T16:40:14.872476Z","iopub.status.idle":"2022-02-10T16:40:14.883887Z","shell.execute_reply.started":"2022-02-10T16:40:14.872442Z","shell.execute_reply":"2022-02-10T16:40:14.883099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass RNNModel(nn.Module): \n    def __init__(\n        self, CFG,\n        input_dim=CFG.input_dim,\n        lstm_dim=CFG.matrix_dim,\n        dense_dim=CFG.matrix_dim,\n        logit_dim=CFG.matrix_dim,\n        num_classes=1,\n    ):\n        \n        super().__init__()\n        self.CFG = CFG\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, dense_dim // 2),\n            nn.ReLU(),\n            nn.Linear(dense_dim // 2, dense_dim),\n            nn.ReLU(),\n        )\n        \n        self.lstm = nn.LSTM(dense_dim, lstm_dim, batch_first=True, bidirectional=True)\n        \n        self.output = nn.Sequential(\n            nn.Linear(lstm_dim * 2, logit_dim),\n            nn.ReLU(),\n            nn.Linear(logit_dim, num_classes),\n        )\n        \n    def forward(self, x):\n        features = self.mlp(x)\n    \n        features, _ = self.lstm(features)\n    \n        pred = self.logits(features)\n        return pred\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T16:40:14.884619Z","iopub.execute_input":"2022-02-10T16:40:14.8848Z","iopub.status.idle":"2022-02-10T16:40:14.897381Z","shell.execute_reply.started":"2022-02-10T16:40:14.884778Z","shell.execute_reply":"2022-02-10T16:40:14.896635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(RNNModel, self).__init__()\n        \n        hidden_dim= [400, 300, 200, 100]\n        self.bilstm1= nn.LSTM(input_dim, hidden_dim[0], batch_first= True, bidirectional= True)\n        self.norm1= nn.LayerNorm(hidden_dim[0]*2)\n        \n        self.bilstm2= nn.LSTM(hidden_dim[0]*2, hidden_dim[1], batch_first= True, bidirectional= True)\n        self.norm2= nn.LayerNorm(hidden_dim[1]*2)\n        \n        self.bilstm3= nn.LSTM(hidden_dim[1]*2, hidden_dim[2], batch_first= True, bidirectional= True)\n        self.norm3= nn.LayerNorm(hidden_dim[2]*2)\n        \n        self.bilstm4= nn.LSTM(hidden_dim[2]*2, hidden_dim[3], batch_first= True, bidirectional= True)\n        self.norm4= nn.LayerNorm(hidden_dim[3]*2)\n        \n        self.fc1= nn.Linear(hidden_dim[3]*2, 100)\n        self.fc2= nn.Linear(100, output_dim)\n\n        \n    def forward(self, X):\n        pred, _= self.bilstm1(X)\n        pred= self.norm1(pred)\n        \n        pred, _= self.bilstm2(pred)\n        pred= self.norm2(pred)\n        \n        pred, _= self.bilstm3(pred)\n        pred= self.norm3(pred)\n        \n        pred, _= self.bilstm4(pred)\n        pred= self.norm4(pred)\n        \n        pred= self.fc1(pred)\n        pred= F.selu(pred)\n        \n        pred= self.fc2(pred)\n        pred= pred.squeeze(dim= 2)\n        return pred","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:06:17.281088Z","iopub.execute_input":"2022-02-10T17:06:17.282009Z","iopub.status.idle":"2022-02-10T17:06:17.298132Z","shell.execute_reply.started":"2022-02-10T17:06:17.281945Z","shell.execute_reply":"2022-02-10T17:06:17.297073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 64\n\ngroup_kfold = GroupKFold(n_splits=CFG.n_fold)\n\nfor fold, (train_idx, valid_idx) in enumerate(group_kfold.split(train, targets, groups=groups)):\n    \n    print(\"Fold %d\" % fold)\n    \n    train_fold = train[train_idx]\n    val_fold = train[valid_idx]\n    train_target = targets[train_idx]\n    val_target = targets[valid_idx]\n\n    train_dataset = CusDataset(train_fold, train_target)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers,\n                              drop_last=False)\n    \n    valid_dataset = CusDataset(val_fold, val_target)\n    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers,\n                              drop_last=False)\n    \n    model = RNNModel(num_features, 1)\n    model.to(CFG.device)\n    model.train()\n    \n    criterion= nn.L1Loss()\n    criterion.to(CFG.device)\n    optimizer = AdamW(model.parameters(), lr=CFG.lr)\n    \n    for epoch in range(CFG.epochs): \n        running_loss = 0.0\n        \n        for i, (x,y) in enumerate(train_loader):\n            inputs = x.to(CFG.device)\n            labels = y.to(CFG.device)\n            \n            # Zero the parameter gradients\n            optimizer.zero_grad()\n            \n            # forward + backward + optimize \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            #print stats\n            running_loss += loss.item()\n            if i % 2000 == 0: \n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n                running_loss = 0.0\n                \n    print(\"Finished\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:12:20.628753Z","iopub.execute_input":"2022-02-10T17:12:20.629845Z","iopub.status.idle":"2022-02-10T17:12:51.916081Z","shell.execute_reply.started":"2022-02-10T17:12:20.629792Z","shell.execute_reply":"2022-02-10T17:12:51.914315Z"},"trusted":true},"execution_count":null,"outputs":[]}]}