{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# reference\n\n","metadata":{}},{"cell_type":"markdown","source":"# Specify library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n#from joypy import joyplot for matplotlib\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize, StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:34:33.496605Z","iopub.execute_input":"2021-10-24T01:34:33.496944Z","iopub.status.idle":"2021-10-24T01:34:33.504784Z","shell.execute_reply.started":"2021-10-24T01:34:33.496895Z","shell.execute_reply":"2021-10-24T01:34:33.5041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Settings","metadata":{}},{"cell_type":"code","source":"save_modified_data = True","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:34:33.506582Z","iopub.execute_input":"2021-10-24T01:34:33.507013Z","iopub.status.idle":"2021-10-24T01:34:33.520215Z","shell.execute_reply.started":"2021-10-24T01:34:33.506979Z","shell.execute_reply":"2021-10-24T01:34:33.519374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"path = '../input/ventilator-pressure-prediction'\ntrain = pd.read_csv(f\"{path}/train.csv\")\ntest = pd.read_csv(f\"{path}/test.csv\")\nsubmission = pd.read_csv(f'{path}/sample_submission.csv')\n\ntrain = train.astype({'time_step': float, 'pressure': float, 'u_in' : float})\ntest = test.astype({'time_step': float, 'u_in' : float})","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:34:33.521582Z","iopub.execute_input":"2021-10-24T01:34:33.522086Z","iopub.status.idle":"2021-10-24T01:34:43.499008Z","shell.execute_reply.started":"2021-10-24T01:34:33.522027Z","shell.execute_reply":"2021-10-24T01:34:43.498172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try and Error","metadata":{}},{"cell_type":"markdown","source":"# Utilitys","metadata":{}},{"cell_type":"code","source":"def data_clean(df):\n    ## pickup ignore breath id\n    ignore_breath_ids = set()\n    \n    time_step_diff_limit = 0.04\n    for k, grp in tqdm(df.groupby(\"breath_id\")):\n        \n        ## ignore non liner time_step data\n        diff_se = grp[\"time_step\"].diff()\n        diff_chk = diff_se[diff_se > time_step_diff_limit]\n        if len(diff_chk) != 0:\n            ignore_breath_ids.add(k)\n            \n        ## ignor negative pressure data\n        #mi = grp[\"pressure\"].min()\n        #if mi < 0:\n        #    ignore_breath_ids.add(k)\n            \n        ## ignore len(u_out == 0) =< 28 \n        u_out_0_len = len(grp[grp[\"u_out\"] == 0])\n        if u_out_0_len < 29:\n            ignore_breath_ids.add(k)\n            \n        ## ignore pressure max == 64.8209917386395\n        ma = grp[\"pressure\"].max()\n        if ma == 64.8209917386395:\n            ignore_breath_ids.add(k)\n    \n    df = df[~df[\"breath_id\"].isin(np.array(list(ignore_breath_ids)))]\n    return df\n\ndef change_type(df):\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    return df\n\ndef add_features(df):\n    df['u_in_cumsum'] = df.groupby('breath_id')[\"u_in\"].cumsum()\n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    #df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    #df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    #df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    #df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df = df.fillna(0)\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ndef tf_tpu_or_gpu_or_cpu():\n    tpu = None\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        return \"tpu\"\n\n    elif tf.test.is_gpu_available():\n        strategy = tf.distribute.get_strategy()\n        print('Running on GPU')\n        return \"gpu\"\n\n    else:\n        strategy = tf.distribute.get_strategy()\n        print('Running on CPU')\n        return \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:34:43.5072Z","iopub.execute_input":"2021-10-24T01:34:43.507406Z","iopub.status.idle":"2021-10-24T01:34:43.526756Z","shell.execute_reply.started":"2021-10-24T01:34:43.507381Z","shell.execute_reply":"2021-10-24T01:34:43.526092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pickup u_out == 0","metadata":{}},{"cell_type":"code","source":"def u_out_0_df(df):\n    grp_len = int(32)\n    new_df = pd.DataFrame()\n    for k, grp in tqdm(df.groupby(\"breath_id\")):\n        tmp_df = grp[grp[\"u_out\"] == 0]\n        rowno  = tmp_df.shape[0]\n        for i in range(grp_len - rowno):\n            row_df = tmp_df.tail(1).copy()\n            time_diff = tmp_df.tail(2).diff().tail(1)[\"time_step\"]\n            row_df[\"time_step\"] = row_df[\"time_step\"] + time_diff * (i + 1)\n            row_df[\"id\"] = row_df[\"id\"] + int(1)\n            tmp_df = tmp_df.append(row_df,ignore_index=True)\n        new_df = new_df.append(tmp_df,ignore_index=True)\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:34:43.527778Z","iopub.execute_input":"2021-10-24T01:34:43.528612Z","iopub.status.idle":"2021-10-24T01:34:43.543229Z","shell.execute_reply.started":"2021-10-24T01:34:43.528568Z","shell.execute_reply":"2021-10-24T01:34:43.542571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# apply utilitys for data","metadata":{}},{"cell_type":"code","source":"print(\"**Info : Data clean of train.\")\ntrain = data_clean(train)\nprint(\"**Info : pick up u_out == 0 of train.\")\ntrain = u_out_0_df(train)\ntrain.to_csv(\"./train_u_out_0.csv\")\nprint(\"**Info : add features of train.\")\ntrain = add_features(train)\n\nprint(\"**Info : pick up u_out == 0 of test.\")\ntest = u_out_0_df(test)\ntest.to_csv(\"./test_u_out_0.csv\")\nprint(\"**Info : add features of test.\")\ntest = add_features(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:34:43.544425Z","iopub.execute_input":"2021-10-24T01:34:43.545302Z","iopub.status.idle":"2021-10-24T01:37:07.713554Z","shell.execute_reply.started":"2021-10-24T01:34:43.545256Z","shell.execute_reply":"2021-10-24T01:37:07.712544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save modified train/test data","metadata":{}},{"cell_type":"code","source":"train.to_csv(\"./train_mod.csv\")\ntest.to_csv(\"./test_mod.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:37:07.715212Z","iopub.execute_input":"2021-10-24T01:37:07.715452Z","iopub.status.idle":"2021-10-24T01:37:20.528676Z","shell.execute_reply.started":"2021-10-24T01:37:07.715422Z","shell.execute_reply":"2021-10-24T01:37:20.528068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize original data u_in histgram for each time step id","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f\"{path}/train.csv\")\ntrain[\"time_step_id\"] = list(range(1,81,1)) * int(len(train)/80)\nrange_bins = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65,70,75,80,85,90,95,100]\nbins_name = ['~5', '~10', '~15','~20','~25', '~30', '~35', '~40','~45', '~50', '~55', '~60','~65','~70','~75','~80','~85','~90','~95','~100']\ntrain[\"u_in_range\"] = pd.cut(train[\"u_in\"],bins=range_bins,labels=bins_name)\ntmp_df = pd.DataFrame()\nfor k,grp in train.groupby(\"time_step_id\"):\n    tmp_df = tmp_df.append(grp[\"u_in_range\"].value_counts())\ntmp_df = tmp_df.reset_index(drop=True)\ntmp_df.columns = tmp_df.columns.astype(str)\ntmp_df = tmp_df.reindex(columns=bins_name)\nax = sns.heatmap(tmp_df)\nax.set_xlabel(\"u_in_range\", fontsize = 20)\nax.set_ylabel(\"time_step_id\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:37:20.529904Z","iopub.execute_input":"2021-10-24T01:37:20.530812Z","iopub.status.idle":"2021-10-24T01:37:31.036236Z","shell.execute_reply.started":"2021-10-24T01:37:20.530764Z","shell.execute_reply":"2021-10-24T01:37:31.035439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize original data pressure histgram for each time step id","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f\"{path}/train.csv\")\ntrain[\"time_step_id\"] = list(range(1,81,1)) * int(len(train)/80)\nrange_bins = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65]\nbins_name = ['~5', '~10', '~15','~20','~25', '~30', '~35', '~40','~45', '~50', '~55', '~60', '~65']\ntrain[\"pressure_range\"] = pd.cut(train[\"pressure\"],bins=range_bins,labels=bins_name)\ntmp_df = pd.DataFrame()\nfor k,grp in train.groupby(\"time_step_id\"):\n    tmp_df = tmp_df.append(grp[\"pressure_range\"].value_counts())\ntmp_df = tmp_df.reset_index(drop=True)\ntmp_df.columns = tmp_df.columns.astype(str)\ntmp_df = tmp_df.reindex(columns=bins_name)\nax = sns.heatmap(tmp_df)\nax.set_xlabel(\"pressure_range\", fontsize = 20)\nax.set_ylabel(\"time_step_id\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:37:31.037378Z","iopub.execute_input":"2021-10-24T01:37:31.037594Z","iopub.status.idle":"2021-10-24T01:37:41.254196Z","shell.execute_reply.started":"2021-10-24T01:37:31.037568Z","shell.execute_reply":"2021-10-24T01:37:41.253352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize u_in hist with StandardScaler() for each time step id","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f\"{path}/train.csv\")\ntrain = u_out_0_df(train)\ncolumns = train.columns\n#scaler = RobustScaler()\nscaler = StandardScaler()\ntrain = scaler.fit_transform(train)\ntrain = pd.DataFrame(train,columns= columns)\ntrain[\"time_step_id\"] = list(range(1,33,1)) * int(len(train)/32)\nrange_bins = [-1.8, -1.6, -1.4, -1.2, -1.0, -0.8, -0.6, -0.4,-0.2,0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8]\nbins_name = ['~-1.6', '~-1.4', '~-1.2','~-1.0','~-0.8','~-0.6','~-0.4','~-0.2','~0','~0.2','~0.4','~0.6','~0.8','~1.0','~1.2','~1.4','~1.6','~1.8']\n#train[\"pressure_range\"] = pd.cut(train[\"pressur\"],bins=range_bins,labels=bins_name)\ntrain[\"u_in_range\"] = pd.cut(train[\"u_in\"],bins=range_bins,labels=bins_name)\ntmp_df = pd.DataFrame()\nfor k,grp in train.groupby(\"time_step_id\"):\n    tmp_df = tmp_df.append(grp[\"u_in_range\"].value_counts())\ntmp_df = tmp_df.reset_index(drop=True)\ntmp_df.columns = tmp_df.columns.astype(str)\ntmp_df = tmp_df.reindex(columns=bins_name)\nax = sns.heatmap(tmp_df)\nax.set_xlabel(\"u_in_range\", fontsize = 20)\nax.set_ylabel(\"time_step_id\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:37:41.25569Z","iopub.execute_input":"2021-10-24T01:37:41.256011Z","iopub.status.idle":"2021-10-24T01:42:16.357273Z","shell.execute_reply.started":"2021-10-24T01:37:41.255969Z","shell.execute_reply":"2021-10-24T01:42:16.356091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize u_in hist with RobustScaler() for each time step id","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f\"{path}/train.csv\")\ntrain = u_out_0_df(train)\ncolumns = train.columns\nscaler = RobustScaler()\n#scaler = StandardScaler()\ntrain = scaler.fit_transform(train)\ntrain = pd.DataFrame(train,columns= columns)\ntrain[\"time_step_id\"] = list(range(1,33,1)) * int(len(train)/32)\nrange_bins = [-0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2,-0.1,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\nrange_bins = [-9, -8, -7, -6, -5, -4, -3, -2,-1,0,1,2,3,4,5,6,7,8,9,10]\nbins_name = ['~-8', '~-7','~-6','~-5','~-4','~-3','~-2','~-1','~0','~1','~2','~3','~4','~5','~6','~7','~8','~9','10']\n#train[\"pressure_range\"] = pd.cut(train[\"pressure\"],bins=range_bins,labels=bins_name)\ntrain[\"u_in_range\"] = pd.cut(train[\"u_in\"],bins=range_bins,labels=bins_name)\ntmp_df = pd.DataFrame()\nfor k,grp in train.groupby(\"time_step_id\"):\n    #tmp_df = tmp_df.append(grp[\"pressure_range\"].value_counts())\n    tmp_df = tmp_df.append(grp[\"u_in_range\"].value_counts())\ntmp_df = tmp_df.reset_index(drop=True)\ntmp_df.columns = tmp_df.columns.astype(str)\ntmp_df = tmp_df.reindex(columns=bins_name)\nax = sns.heatmap(tmp_df)\nax.set_xlabel(\"u_in_range\", fontsize = 20)\nax.set_ylabel(\"time_step_id\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:42:16.358424Z","iopub.status.idle":"2021-10-24T01:42:16.358738Z","shell.execute_reply.started":"2021-10-24T01:42:16.358576Z","shell.execute_reply":"2021-10-24T01:42:16.358592Z"},"trusted":true},"execution_count":null,"outputs":[]}]}