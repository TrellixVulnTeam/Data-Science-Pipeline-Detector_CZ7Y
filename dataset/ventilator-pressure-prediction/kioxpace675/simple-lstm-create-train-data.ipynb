{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NOTATION\n\nThis notebook is copy, train data making step of following notebook.<br>\nhttps://www.kaggle.com/tfukuda675/update-simple-lstm-simple-data<br>\n\nThe above notebook is huge, it is hard to run quickly.<br>\nSo, I picked up the data making step.\n\n<font color=\"red\">If you think this notebook is usefull, please push upvote botton.</font><br>\n\nThanks!","metadata":{}},{"cell_type":"markdown","source":"# Specify library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n#from joypy import joyplot for matplotlib\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize, StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\ntqdm.pandas()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-22T00:21:14.705271Z","iopub.execute_input":"2021-10-22T00:21:14.705671Z","iopub.status.idle":"2021-10-22T00:21:23.168577Z","shell.execute_reply.started":"2021-10-22T00:21:14.705543Z","shell.execute_reply":"2021-10-22T00:21:23.167576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Settings\n\ndebug_mode = [true|false] # when this option is true, reduse data size to debug_data_count size.<br>\nsave_modified_data = True # when this option is true, save output data in this notebook.","metadata":{}},{"cell_type":"code","source":"debug_mode = False\ndebug_data_count = int(1000)\nsave_modified_data = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"path = '../input/ventilator-pressure-prediction'\ntrain = pd.read_csv(f\"{path}/train.csv\")\ntest = pd.read_csv(f\"{path}/test.csv\")\nsubmission = pd.read_csv(f'{path}/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilitys","metadata":{}},{"cell_type":"code","source":"def data_clean(df):\n    ## pickup ignore breath id\n    ignore_breath_ids = set()\n    \n    time_step_diff_limit = 0.04\n    for k, grp in tqdm(df.groupby(\"breath_id\")):\n        \n        ## ignore non liner time_step data\n        diff_se = grp[\"time_step\"].diff()\n        diff_chk = diff_se[diff_se > time_step_diff_limit]\n        if len(diff_chk) != 0:\n            ignore_breath_ids.add(k)\n            \n        ## ignor negative pressure data\n        m = grp[\"pressure\"].min()\n        if m < 0:\n            ignore_breath_ids.add(k)\n    \n    df = df[~df[\"breath_id\"].isin(np.array(list(ignore_breath_ids)))]\n    return df\n\ndef change_type(df):\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    return df\n\ndef add_features(df):\n    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df = df.fillna(0)\n    return df\n\ndef tf_tpu_or_gpu_or_cpu():\n    tpu = None\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        return \"tpu\"\n\n    elif tf.test.is_gpu_available():\n        strategy = tf.distribute.get_strategy()\n        print('Running on GPU')\n        return \"gpu\"\n\n    else:\n        strategy = tf.distribute.get_strategy()\n        print('Running on CPU')\n        return \"cpu\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# reduce data size in debug_mode case","metadata":{}},{"cell_type":"code","source":"if debug_mode:\n    train = train[:80*debug_data_count]\n    test = test[:80*debug_data_count]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# apply utilitys for data","metadata":{}},{"cell_type":"code","source":"train = data_clean(train)\ntrain = add_features(train)\ntrain = change_type(train)\n\ntest = add_features(test)\ntest = change_type(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save modified train/test data","metadata":{}},{"cell_type":"code","source":"train.to_csv(\"./train_mod.csv\")\ntest.to_csv(\"./test_mod.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}}]}