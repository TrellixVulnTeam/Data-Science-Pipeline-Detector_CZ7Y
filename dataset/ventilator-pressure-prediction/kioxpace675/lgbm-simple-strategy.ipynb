{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Note\n\nThis Notebook specializes in finding hints to get better score with using simple data, strategy and visualize.\n\n## strategy of this notebook\n\nThere non liner time_step data and minus pressure data.\nI ignore these data and simplify data for finding low score reason.\n\nOverview:\n* ignore non liner time_step data\n* ignore minus pressure data\n* use puls shift lag data only. do not use future data. \n\n## refer to\nFor visualization<br>\nhttps://www.kaggle.com/tfukuda675/data-visualization-plotly-seaborn-matplot","metadata":{}},{"cell_type":"markdown","source":"# glossary\n\n### LGBMRegressor\nLGBM for regression<br>\n\nhttps://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n\n### LGBMClassifier\nLGBM for Classifier\n","metadata":{}},{"cell_type":"markdown","source":"# Read library","metadata":{}},{"cell_type":"code","source":"#!pip install joypy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n#from joypy import joyplot for matplotlib\nimport tensorflow as tf\nimport tqdm\nimport optuna\nimport time\nimport lightgbm as lgb\nfrom sklearn import metrics\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize, StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:59:03.679644Z","iopub.execute_input":"2021-10-16T10:59:03.67992Z","iopub.status.idle":"2021-10-16T10:59:03.70051Z","shell.execute_reply.started":"2021-10-16T10:59:03.679891Z","shell.execute_reply":"2021-10-16T10:59:03.699468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"path = '../input/ventilator-pressure-prediction'\ntrain = pd.read_csv(f\"{path}/train.csv\")\ntest = pd.read_csv(f\"{path}/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:43:44.309807Z","iopub.execute_input":"2021-10-16T10:43:44.310067Z","iopub.status.idle":"2021-10-16T10:43:59.118192Z","shell.execute_reply.started":"2021-10-16T10:43:44.310038Z","shell.execute_reply":"2021-10-16T10:43:59.117469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confirm linearity of time_step","metadata":{}},{"cell_type":"code","source":"time_step_diff_limit = 0.04\nnon_liner_timestep_breath_ids = list()\nfor k, grp in train.groupby(\"breath_id\"):\n    diff_se = grp[\"time_step\"].diff()\n    diff_chk = diff_se[diff_se > time_step_diff_limit]\n    if len(diff_chk) != 0:\n        non_liner_timestep_breath_ids.append(k)\n\n#print(non_liner_timestep_breath_ids)\n## results are following:\n## [803, 2327, 3178, 4199, 5830, 10277, 11502, 13238, 15803, 16315, 16634, 18117, 18600, 24127, 25397, 28189, 28942, 30181, 32296, 36128, 36175, 37711, 38237, 38415, 39045, 39722, 42317, 42988, 43344, 44245, 45197, 46324, 49849, 53877, 54129, 55244, 55851, 61454, 64662, 67422, 67748, 72104, 74766, 76037, 78768, 79105, 80375, 87127, 87776, 89084, 91883, 93186, 98677, 102063, 104001, 106034, 107067, 109693, 111439, 112027, 115588, 119689, 120878, 121135, 125136]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:43:59.120117Z","iopub.execute_input":"2021-10-16T10:43:59.120464Z","iopub.status.idle":"2021-10-16T10:44:31.593013Z","shell.execute_reply.started":"2021-10-16T10:43:59.12042Z","shell.execute_reply":"2021-10-16T10:44:31.592015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize NON linier \"time_step\"","metadata":{}},{"cell_type":"code","source":"non_liner_timestep_df = train[train[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\nfig = go.Figure()\nfor k,grp in non_liner_timestep_df.groupby(\"breath_id\"):\n    grp = grp.reset_index(drop=True)\n    fig.add_trace(go.Scatter(x=grp.index, y=grp[\"time_step\"], mode='lines', name=k))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:44:31.594779Z","iopub.execute_input":"2021-10-16T10:44:31.595014Z","iopub.status.idle":"2021-10-16T10:44:31.803962Z","shell.execute_reply.started":"2021-10-16T10:44:31.594983Z","shell.execute_reply":"2021-10-16T10:44:31.80272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize liner \"time_step\"\n\nThere are several gradient of \"time_step\",,,.","metadata":{}},{"cell_type":"code","source":"liner_timestep_df = train[~train[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\nfig = go.Figure()\nfor k,grp in liner_timestep_df[:80*10000].groupby(\"breath_id\"):\n    grp = grp.reset_index(drop=True)\n    fig.add_trace(go.Scatter(x=grp.index, y=grp[\"time_step\"], mode='lines', name=k))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:44:31.805783Z","iopub.execute_input":"2021-10-16T10:44:31.806106Z","iopub.status.idle":"2021-10-16T10:44:41.382237Z","shell.execute_reply.started":"2021-10-16T10:44:31.806064Z","shell.execute_reply":"2021-10-16T10:44:41.38069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n<br>\n\n# END Visualize\n\n<br>\n<br>","metadata":{}},{"cell_type":"markdown","source":"# Utilitys","metadata":{}},{"cell_type":"code","source":"def data_clean(df):\n    ## drop non liner time_step data.\n    time_step_diff_limit = 0.04\n    non_liner_timestep_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        diff_se = grp[\"time_step\"].diff()\n        diff_chk = diff_se[diff_se > time_step_diff_limit]\n        if len(diff_chk) != 0:\n            non_liner_timestep_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\n    \n    ## drop minus pressure data.\n    minus_pressure_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        m = grp[\"pressure\"].min()\n        if m < 0:\n            minus_pressure_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(minus_pressure_breath_ids)]   \n    \n    return df\n\ndef change_type(df):\n    df = df.merge(pd.get_dummies(df['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\n    df = df.merge(pd.get_dummies(df['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\n\n    return df\n\ndef add_features(df):\n    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n    df['u_in_lag1']   = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1']  = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag2']   = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2']  = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_diff1']  = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2']  = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:58:17.356253Z","iopub.execute_input":"2021-10-16T10:58:17.356552Z","iopub.status.idle":"2021-10-16T10:58:17.372255Z","shell.execute_reply.started":"2021-10-16T10:58:17.356522Z","shell.execute_reply":"2021-10-16T10:58:17.371329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data again and set config\n","metadata":{}},{"cell_type":"code","source":"path = '../input/ventilator-pressure-prediction'\ntrain = pd.read_csv(f\"{path}/train.csv\")\ntest = pd.read_csv(f\"{path}/test.csv\")\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\ndebug_mode = True","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:58:18.710607Z","iopub.execute_input":"2021-10-16T10:58:18.710901Z","iopub.status.idle":"2021-10-16T10:58:28.118411Z","shell.execute_reply.started":"2021-10-16T10:58:18.71087Z","shell.execute_reply":"2021-10-16T10:58:28.11767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# In Debug mode\n\nreduce data size","metadata":{}},{"cell_type":"code","source":"if debug_mode:\n    train = train[:80*1000]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:58:28.119607Z","iopub.execute_input":"2021-10-16T10:58:28.120396Z","iopub.status.idle":"2021-10-16T10:58:28.124606Z","shell.execute_reply.started":"2021-10-16T10:58:28.120356Z","shell.execute_reply":"2021-10-16T10:58:28.123672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# apply utilitys for data","metadata":{}},{"cell_type":"code","source":"train = data_clean(train)\ntrain = add_features(train)\ntrain = change_type(train)\n\ntest = add_features(test)\ntest = change_type(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:58:28.125975Z","iopub.execute_input":"2021-10-16T10:58:28.126209Z","iopub.status.idle":"2021-10-16T10:58:31.038581Z","shell.execute_reply.started":"2021-10-16T10:58:28.126182Z","shell.execute_reply":"2021-10-16T10:58:31.037939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data for LGBM","metadata":{}},{"cell_type":"code","source":"y = train[['pressure']]\nX = train.drop(['pressure', 'id', 'breath_id'], axis=1)\ntest_X = test.drop(['id', 'breath_id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:58:31.039978Z","iopub.execute_input":"2021-10-16T10:58:31.040445Z","iopub.status.idle":"2021-10-16T10:58:31.46503Z","shell.execute_reply.started":"2021-10-16T10:58:31.040408Z","shell.execute_reply":"2021-10-16T10:58:31.464147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\nmodels = []\nfeature_importance = pd.DataFrame()\nparams = {'objective': 'regression',\n          'learning_rate': 0.10,\n          \"boosting_type\": \"gbdt\",\n          'min_data_in_leaf':600,\n          'max_bin': 196,\n          #'device':'gpu',\n          'feature_fraction':0.4,\n          'lambda_l1':36, 'lambda_l2':80,\n          'max_depth':16,\n          'num_leaves':1000,\n          \"metric\": 'mae',\n          'n_jobs': -1\n         }\n\nfolds = GroupKFold(n_splits=5)\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = lgb.LGBMRegressor(**params, n_estimators=8000)\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            verbose=100, early_stopping_rounds=10)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)\n\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = X.columns.tolist()\n    fold_importance[\"importance\"] = model.feature_importances_\n    fold_importance[\"fold\"] = fold_n + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T10:59:34.631303Z","iopub.execute_input":"2021-10-16T10:59:34.631658Z","iopub.status.idle":"2021-10-16T10:59:54.119754Z","shell.execute_reply.started":"2021-10-16T10:59:34.631602Z","shell.execute_reply":"2021-10-16T10:59:54.118976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    submission['pressure'] += model.predict(test_X)\nsubmission['pressure'] /= 5\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}