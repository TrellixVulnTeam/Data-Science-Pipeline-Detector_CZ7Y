{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T21:52:22.89834Z","iopub.execute_input":"2021-10-11T21:52:22.898604Z","iopub.status.idle":"2021-10-11T21:52:22.908333Z","shell.execute_reply.started":"2021-10-11T21:52:22.898577Z","shell.execute_reply":"2021-10-11T21:52:22.907248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\nfrom torch import nn\nimport torch\n\nimport pytorch_lightning as pl\n\nprint(\"TORCH:\", torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T21:52:23.399099Z","iopub.execute_input":"2021-10-11T21:52:23.399336Z","iopub.status.idle":"2021-10-11T21:52:29.167287Z","shell.execute_reply.started":"2021-10-11T21:52:23.39931Z","shell.execute_reply":"2021-10-11T21:52:29.165978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2021-10-11T21:52:29.169395Z","iopub.execute_input":"2021-10-11T21:52:29.16966Z","iopub.status.idle":"2021-10-11T21:52:29.173606Z","shell.execute_reply.started":"2021-10-11T21:52:29.169623Z","shell.execute_reply":"2021-10-11T21:52:29.172881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom collections import OrderedDict, Counter\nfrom tqdm import tqdm\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-10-11T21:52:29.175209Z","iopub.execute_input":"2021-10-11T21:52:29.175562Z","iopub.status.idle":"2021-10-11T21:52:29.184145Z","shell.execute_reply.started":"2021-10-11T21:52:29.17553Z","shell.execute_reply":"2021-10-11T21:52:29.183452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for setting the seed\ndef set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():  # GPU operation have separate seed\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T21:52:29.186161Z","iopub.execute_input":"2021-10-11T21:52:29.186481Z","iopub.status.idle":"2021-10-11T21:52:29.240124Z","shell.execute_reply.started":"2021-10-11T21:52:29.186449Z","shell.execute_reply":"2021-10-11T21:52:29.239276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datapath = '../input/ventilator-pressure-prediction'\n\ntrain = pd.read_csv(datapath + '/train.csv')\ntest = pd.read_csv(datapath + '/test.csv')\n\nprint('Train Shape -> ', end='')\nprint(train.shape)\nprint(train.head())\n\nprint('\\nTest Shape -> ', end='')\nprint(test.shape)\nprint(test.head())\n\ncount = list(Counter(train.breath_id).values())\n\nN_TIME_STEPS_PER_EXAMPLE = max(count)\nassert N_TIME_STEPS_PER_EXAMPLE == min(count)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T21:52:29.242302Z","iopub.execute_input":"2021-10-11T21:52:29.242509Z","iopub.status.idle":"2021-10-11T21:52:42.421803Z","shell.execute_reply.started":"2021-10-11T21:52:29.242485Z","shell.execute_reply":"2021-10-11T21:52:42.420969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_diff(array: np.array, index: int = 0):\n    data = array.copy()\n    adding = np.zeros(data[:, :, index].shape)\n    adding[:, 1:] = data[:, :-1, index]\n    data[:, :, index] -= adding\n    return data\n\ndef pressure_log(array, index: int = 0):\n    data = np.zeros_like(array[:, :, index])\n    data[:, 1:] = array[:, :-1, index]\n    return data\n    \n\ndef featurize(dataframe: pd.DataFrame):\n    # Dropping unecessary columns\n    data = dataframe.copy().drop(columns=['id', 'breath_id'])\n    \n    # Nomalizing some features\n    data['norm_R'] = (data.R - data.R.min()) / (data.R.max() - data.R.min())\n    data['norm_C'] = (data.C - data.C.min()) / (data.C.max() - data.C.min())\n    \n    # Adding the difference between some features\n    data['time_step_diff'] = add_diff(data.time_step.to_numpy().reshape(-1, N_TIME_STEPS_PER_EXAMPLE, 1)).flatten()\n    data['u_in_diff'] = add_diff(data.u_in.to_numpy().reshape(-1, N_TIME_STEPS_PER_EXAMPLE, 1)).flatten()\n\n    # New cross features\n    data['time_cross_var'] = data.time_step * data.time_step_diff\n    data['u_in_cross_var_in_time'] = data.u_in * data.u_in_diff * data.time_cross_var\n    data['norm_R_C_time_cross_var'] = data.norm_R * data.norm_C * data.time_cross_var\n    data['u_in_norm_R_C'] = data.norm_R * data.norm_C * data.u_in\n    data['u_in_norm_R_C_time_cross_var'] = data.u_in_norm_R_C * data.time_cross_var \n    data['norm_R_C_u_in_cross_var'] = data.norm_R * data.norm_C * data.u_in_diff\n\n    # Dropping some features that I don't want to use\n    data = data.drop(columns=['R', 'C', 'time_step', 'norm_C', 'norm_R'])\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:01:06.955604Z","iopub.execute_input":"2021-10-12T00:01:06.955877Z","iopub.status.idle":"2021-10-12T00:01:06.968515Z","shell.execute_reply.started":"2021-10-12T00:01:06.955834Z","shell.execute_reply":"2021-10-12T00:01:06.967569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_features_dataframe = featurize(train.drop(columns='pressure'))\ntraining_targets_dataframe = train.pressure\ntraining_features_dataframe.head(7)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:01:07.517703Z","iopub.execute_input":"2021-10-12T00:01:07.51826Z","iopub.status.idle":"2021-10-12T00:01:09.197626Z","shell.execute_reply.started":"2021-10-12T00:01:07.518224Z","shell.execute_reply":"2021-10-12T00:01:09.196823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_targets_dataframe.head(7)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:01:09.891229Z","iopub.execute_input":"2021-10-12T00:01:09.891845Z","iopub.status.idle":"2021-10-12T00:01:09.898985Z","shell.execute_reply.started":"2021-10-12T00:01:09.891806Z","shell.execute_reply":"2021-10-12T00:01:09.898072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FEATURES = len(training_features_dataframe.columns)\n\ntraining_features = training_features_dataframe.to_numpy().reshape(-1, N_TIME_STEPS_PER_EXAMPLE, N_FEATURES)\ntraining_targets = training_targets_dataframe.to_numpy().reshape(-1, N_TIME_STEPS_PER_EXAMPLE)\n\nprint('Features Shape:', training_features.shape, 'Targets Shape:', training_targets.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:01:10.318317Z","iopub.execute_input":"2021-10-12T00:01:10.318554Z","iopub.status.idle":"2021-10-12T00:01:10.505374Z","shell.execute_reply.started":"2021-10-12T00:01:10.318529Z","shell.execute_reply":"2021-10-12T00:01:10.504612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_dev, y_train, y_dev = train_test_split(training_features, training_targets, test_size=0.2)\nX_dev, X_test, y_dev, y_test = train_test_split(X_dev, y_dev, test_size=0.5)\n\nprint('Train Shape:', X_train.shape, '\\nDev Shape:', X_dev.shape, '\\nTest shape:', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:01:11.273775Z","iopub.execute_input":"2021-10-12T00:01:11.274314Z","iopub.status.idle":"2021-10-12T00:01:11.531128Z","shell.execute_reply.started":"2021-10-12T00:01:11.274277Z","shell.execute_reply":"2021-10-12T00:01:11.530274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 50\n\ntrainset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ndevset = TensorDataset(torch.from_numpy(X_dev), torch.from_numpy(y_dev))\ntestset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n\ntrainLoader = DataLoader(trainset, BATCH_SIZE, shuffle=False)\ndevLoader = DataLoader(devset, BATCH_SIZE, shuffle=False)\ntestLoader = DataLoader(testset, BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:01:11.576113Z","iopub.execute_input":"2021-10-12T00:01:11.576317Z","iopub.status.idle":"2021-10-12T00:01:11.582663Z","shell.execute_reply.started":"2021-10-12T00:01:11.576293Z","shell.execute_reply":"2021-10-12T00:01:11.581955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hidden_block(x, y, activation: str = 'relu', drop: float = 0.05):\n    activations = nn.ModuleDict([\n        ['selu', nn.SELU()],\n        ['relu', nn.ReLU()],\n        ['lrelu', nn.LeakyReLU()],\n        ['none', nn.Identity()]\n    ])\n    return nn.Sequential(nn.Linear(x, y), nn.Dropout(drop), activations[activation])\n\n\nclass LongShortTermNetwork(pl.LightningModule):\n\n    def __init__(self, input_size: int, output_size: int, lstm_hidden_size: int, num_layers: int,\n        bidirectional: bool, lstm_drop: float = 0, linear_hidden_sizes: list = [256, 64], hidden_activation: str = 'selu') -> None:\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.in_size = input_size\n        self.out_size = output_size\n        self.lstm_hidden_size = lstm_hidden_size\n        self.num_layers = num_layers\n        self.bidirectional = bidirectional\n        self.n_stacks = 1 + int(self.bidirectional)\n        \n        self.lstm_layer = nn.LSTM(\n            input_size=self.in_size,\n            hidden_size=self.lstm_hidden_size,\n            num_layers=self.num_layers,\n            batch_first=True,\n            bidirectional=bidirectional,\n            dropout=lstm_drop\n        )\n\n        self.linear_sizes = [2 * self.lstm_hidden_size, *linear_hidden_sizes]\n        self.hidden_layer = nn.Sequential(OrderedDict([\n            (f'block_{i}', hidden_block(x, y, hidden_activation, 0.2))\n                for i, (x, y) in enumerate(zip(self.linear_sizes, self.linear_sizes[1:]), 1)\n        ]))\n\n        self.output = nn.Linear(self.linear_sizes[-1], self.out_size)\n        \n        \n    def init_hidden(self, n_samples: int):\n        total_layers = self.n_stacks * self.num_layers\n        weights = (\n            torch.zeros(total_layers, n_samples, self.lstm_hidden_size).float(),\n            torch.zeros(total_layers, n_samples, self.lstm_hidden_size).float()\n        )\n\n        if torch.cuda.is_available():\n            weights = tuple(each.cuda() for each in weights)\n\n        return weights\n\n    def forward(self, input_t: torch.TensorType, hidden=None, prev_pred=None):\n        if hidden is not None:\n            h_t, c_t = hidden\n        else:\n            h_t, c_t = self.init_hidden(input_t.size(0))\n        \n        out, (h_t, c_t) = self.lstm_layer(input_t, (h_t, c_t))\n        out = self.hidden_layer(out)\n        out = self.output(out)\n        \n        if hidden is not None:\n            return out, (h_t, c_t)\n        return out\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), 3e-3)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n    \n    def training_step(self, train_batch, batch_idx):\n        self.train()\n        x, y = train_batch\n\n        x = x.float()\n        y = y.float()\n\n        out = self(x)\n        loss = F.l1_loss(out.flatten(), y.flatten())\n\n        with torch.no_grad():\n            mse = F.mse_loss(out.flatten(), y.flatten())\n\n        self.log('loss', loss)\n        self.log('mse_loss', mse, prog_bar=True)\n        return loss\n    \n    def validation_step(self, val_batch, batch_idx):\n        self.eval()\n        with torch.no_grad():\n            x, y = val_batch\n            x = x.float()\n            y = y.float()\n            out = self(x)\n            loss = F.l1_loss(out.flatten(), y.flatten())\n            mse = F.mse_loss(out.flatten(), y.flatten())\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_mse_loss', mse, prog_bar=True)\n    \n    def training_epoch_end(self, outputs):\n        sch = self.lr_schedulers()\n\n        # If the selected scheduler is a ReduceLROnPlateau scheduler.\n        if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            sch.step(self.trainer.callback_metrics[\"val_loss\"])\n        else:\n            sch.step()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:06:58.861995Z","iopub.execute_input":"2021-10-12T00:06:58.862274Z","iopub.status.idle":"2021-10-12T00:06:58.890672Z","shell.execute_reply.started":"2021-10-12T00:06:58.862244Z","shell.execute_reply":"2021-10-12T00:06:58.889786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n#print(\"Device is:\", device, \"(CUDA is recommended for faster training!)\\n\")\n\nmodel = LongShortTermNetwork(N_FEATURES, 1, 256, 4, True, 0.2, [256, 128], 'none')\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:07:15.734076Z","iopub.execute_input":"2021-10-12T00:07:15.734591Z","iopub.status.idle":"2021-10-12T00:07:15.782437Z","shell.execute_reply.started":"2021-10-12T00:07:15.734557Z","shell.execute_reply":"2021-10-12T00:07:15.780723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"val_loss\",\n    dirpath=\"./checkpoints\",\n    filename=\"sample-pressure-model-{epoch:02d}-{val_loss:.3f}\",\n    save_top_k=3,\n    mode=\"min\",\n)\nlr_callback = pl.callbacks.LearningRateMonitor(logging_interval='epoch')","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:07:19.381905Z","iopub.execute_input":"2021-10-12T00:07:19.382462Z","iopub.status.idle":"2021-10-12T00:07:19.387469Z","shell.execute_reply.started":"2021-10-12T00:07:19.382426Z","shell.execute_reply":"2021-10-12T00:07:19.386575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(gpus=1, max_epochs=100, callbacks=[checkpoint_callback, lr_callback])\ntrainer.fit(model, trainLoader, devLoader)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:06:08.2635Z","iopub.execute_input":"2021-10-12T00:06:08.26374Z","iopub.status.idle":"2021-10-12T00:06:12.289139Z","shell.execute_reply.started":"2021-10-12T00:06:08.263714Z","shell.execute_reply":"2021-10-12T00:06:12.288438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best Score:', checkpoint_callback.best_model_score)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:20:45.084322Z","iopub.execute_input":"2021-10-11T22:20:45.08458Z","iopub.status.idle":"2021-10-11T22:20:45.106799Z","shell.execute_reply.started":"2021-10-11T22:20:45.084554Z","shell.execute_reply":"2021-10-11T22:20:45.105823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model_states = torch.load(checkpoint_callback.best_model_path)\nbest_model_states.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing the model with my test set","metadata":{}},{"cell_type":"code","source":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:22.453459Z","iopub.execute_input":"2021-10-11T23:26:22.453712Z","iopub.status.idle":"2021-10-11T23:26:22.457935Z","shell.execute_reply.started":"2021-10-11T23:26:22.453685Z","shell.execute_reply":"2021-10-11T23:26:22.45702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pressure_net = pressure_net.to(DEVICE)\nwith torch.no_grad():\n    pressure_net.eval()\n    losses = []\n    mse_losses = []\n    for batch in testLoader:\n        x, y = batch\n        x, y = x.to(DEVICE).float(), y.to(DEVICE).float()\n        \n        out = pressure_net(x)\n        \n        mae = F.l1_loss(out.flatten(), y.flatten())\n        mse = F.mse_loss(out.flatten(), y.flatten())\n        \n        losses.append(mae.item())\n        mse_losses.append(mse.item())\nmean_loss = np.mean(losses)\nmean_mse_loss = np.mean(mse_losses)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:24.791383Z","iopub.execute_input":"2021-10-11T23:26:24.791661Z","iopub.status.idle":"2021-10-11T23:26:28.505671Z","shell.execute_reply.started":"2021-10-11T23:26:24.791623Z","shell.execute_reply":"2021-10-11T23:26:28.50495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean Testing Loss (MAE): {mean_loss:.4f}...\")\nprint(f\"Mean Testing MSE Loss: {mean_mse_loss:.4f}...\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:28.50729Z","iopub.execute_input":"2021-10-11T23:26:28.507533Z","iopub.status.idle":"2021-10-11T23:26:28.51251Z","shell.execute_reply.started":"2021-10-11T23:26:28.507501Z","shell.execute_reply":"2021-10-11T23:26:28.511774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Last but one testing losses:\n\n > Mean Testing Loss (MAE): 0.2141...  \n > Mean Testing MSE Loss: 0.1239...\n \n","metadata":{}},{"cell_type":"code","source":"def predict(net: nn.Module, features, device: str = 'cpu', eval_batch: int = 200) -> np.array:\n    \"\"\"Return the predictions feedforwarding the features to the model.\"\"\"\n    with torch.no_grad():\n        net.eval()\n        net = net.to(device)\n        predictions = []\n        for i in range(0, features.size(0), eval_batch):\n            input_t = features[i:min(i+eval_batch, features.size(0))].to(device)\n            prediction = net(input_t.float())\n            predictions.append(prediction.cpu())\n    return torch.cat(predictions, dim=0).numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:38.372699Z","iopub.execute_input":"2021-10-11T23:26:38.372973Z","iopub.status.idle":"2021-10-11T23:26:38.379425Z","shell.execute_reply.started":"2021-10-11T23:26:38.372946Z","shell.execute_reply":"2021-10-11T23:26:38.378732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K = 1122\n\ny = y_test[K]\ny_hat = predictions[K]\n\nplt.plot(y)\nplt.plot(y_hat)\nplt.title(f'Constant showcase example n={K}')\nplt.legend(['Targets', 'Predictions'])\nplt.ylabel('Pressure')\nplt.show();\n\nprint('MSE: %.4f...' % mean_squared_error(y, y_hat))\nprint('MAE: %.4f...' % mean_absolute_error(y, y_hat))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:57.009382Z","iopub.execute_input":"2021-10-11T23:26:57.009655Z","iopub.status.idle":"2021-10-11T23:26:57.238046Z","shell.execute_reply.started":"2021-10-11T23:26:57.009627Z","shell.execute_reply":"2021-10-11T23:26:57.236911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = np.random.randint(0, predictions.shape[0])\n\ny = y_test[k]\ny_hat = predictions[k]\n\nplt.plot(y)\nplt.plot(y_hat)\nplt.title(f'Random Showcase example n={k}')\nplt.legend(['Targets', 'Predictions'])\nplt.ylabel('Pressure')\nplt.show();\n\nprint('MSE: %.4f...' % mean_squared_error(y, y_hat))\nprint('MAE: %.4f...' % mean_absolute_error(y, y_hat))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:27:09.035212Z","iopub.execute_input":"2021-10-11T23:27:09.035486Z","iopub.status.idle":"2021-10-11T23:27:09.256507Z","shell.execute_reply.started":"2021-10-11T23:27:09.035458Z","shell.execute_reply":"2021-10-11T23:27:09.255788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now the Testing data","metadata":{}},{"cell_type":"code","source":"testing_set_dataframe = featurize(test)\ntesting_set_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T18:23:28.776276Z","iopub.execute_input":"2021-10-10T18:23:28.776539Z","iopub.status.idle":"2021-10-10T18:23:29.101391Z","shell.execute_reply.started":"2021-10-10T18:23:28.776508Z","shell.execute_reply":"2021-10-10T18:23:29.100617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_set = testing_set_dataframe.to_numpy().reshape(-1, N_TIME_STEPS_PER_EXAMPLE, N_FEATURES)\ntest_predictions = predict(model, torch.from_numpy(testing_set), device='cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T18:23:42.913648Z","iopub.execute_input":"2021-10-10T18:23:42.914224Z","iopub.status.idle":"2021-10-10T18:23:48.062729Z","shell.execute_reply.started":"2021-10-10T18:23:42.914183Z","shell.execute_reply":"2021-10-10T18:23:48.062006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': np.arange(1, test_predictions.size+1),\n    'pressure': test_predictions.flatten()\n})\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T18:25:28.682901Z","iopub.execute_input":"2021-10-10T18:25:28.683576Z","iopub.status.idle":"2021-10-10T18:25:28.711565Z","shell.execute_reply.started":"2021-10-10T18:25:28.683536Z","shell.execute_reply":"2021-10-10T18:25:28.710708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T18:25:35.653417Z","iopub.execute_input":"2021-10-10T18:25:35.653683Z","iopub.status.idle":"2021-10-10T18:25:46.11471Z","shell.execute_reply.started":"2021-10-10T18:25:35.653654Z","shell.execute_reply":"2021-10-10T18:25:46.113911Z"},"trusted":true},"execution_count":null,"outputs":[]}]}