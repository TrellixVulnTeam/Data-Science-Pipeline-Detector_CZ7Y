{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### The issue of weighed ensemble in kaggle competitions is that weight are tuned according the test data in the public score. Therefore, one may get high score in the public leaderboard, but lose his/her position in the public one because of overfitting. It is much saver to not use test dataset in model at all and try various statistical techniques instead.\n\n*Upvote if useful!*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\n# public notebooks results\nsub_0 = pd.read_csv('../input/gb-vpp-whoppity-dub-dub/median_submission.csv')\nsub_1 = pd.read_csv('../input/gb-vpp-to-infinity-and-beyond/submission.csv')\nsub_2 = pd.read_csv('../input/pred-ventilator-lstm-model-0-149/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:16:34.313322Z","iopub.execute_input":"2021-10-17T07:16:34.313983Z","iopub.status.idle":"2021-10-17T07:16:39.249665Z","shell.execute_reply.started":"2021-10-17T07:16:34.313948Z","shell.execute_reply":"2021-10-17T07:16:39.248808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.array([np.array(sub_0['pressure'].values), np.array(sub_1['pressure'].values), np.array(sub_2['pressure'].values)])\npred","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:16:52.003393Z","iopub.execute_input":"2021-10-17T07:16:52.003686Z","iopub.status.idle":"2021-10-17T07:16:52.087666Z","shell.execute_reply.started":"2021-10-17T07:16:52.003655Z","shell.execute_reply":"2021-10-17T07:16:52.086877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we try 3 things. \n1. Find mean predictions of three notebooks. If the predictions are very scattered, this will not improve score much. \n1. Try is to use median, it will work well with scattered data. \n1. This is more experimental; standard deviation of the predictions will be calculated, data will be clipped with this range and average of clipped data calculated. It still uses mean, but it will eliminate data that are very far from average point and therefore should reduce sparce effect","metadata":{}},{"cell_type":"code","source":"# Finding statistical features\nmean = np.mean(pred, axis=0)\nmed = np.median(pred, axis=0)\nstd = np.std(pred, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:16:54.6671Z","iopub.execute_input":"2021-10-17T07:16:54.667413Z","iopub.status.idle":"2021-10-17T07:16:55.117115Z","shell.execute_reply.started":"2021-10-17T07:16:54.667367Z","shell.execute_reply":"2021-10-17T07:16:55.116418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean of values inside the standard mean\nclipped_pres = np.clip(np.vstack(pred), mean-std, mean+std)\nclipped_mean = np.mean(clipped_pres, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:17:00.266665Z","iopub.execute_input":"2021-10-17T07:17:00.266966Z","iopub.status.idle":"2021-10-17T07:17:00.455061Z","shell.execute_reply.started":"2021-10-17T07:17:00.266938Z","shell.execute_reply":"2021-10-17T07:17:00.454246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['pressure'] = mean\nsub.to_csv('submission_mean.csv', index=False)\nsub.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:17:03.467466Z","iopub.execute_input":"2021-10-17T07:17:03.467746Z","iopub.status.idle":"2021-10-17T07:17:12.509256Z","shell.execute_reply.started":"2021-10-17T07:17:03.467717Z","shell.execute_reply":"2021-10-17T07:17:12.508213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['pressure'] = med\nsub.to_csv('submission_median.csv', index=False)\nsub.to_csv('submission.csv', index=False)\nsub.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['pressure'] = clipped_mean\nsub.to_csv('submission_clipped_mean.csv', index=False)\nsub.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:17:23.789793Z","iopub.execute_input":"2021-10-17T07:17:23.790071Z","iopub.status.idle":"2021-10-17T07:17:32.896638Z","shell.execute_reply.started":"2021-10-17T07:17:23.790044Z","shell.execute_reply":"2021-10-17T07:17:32.895731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Score of mean on public leaderboard -> 0.144\n1. Score of median on public leaderboard -> 0.141\n1. Score ofclipped mean on public leaderboard -> 0.143\n\nThis shows that median method is best statistical approach among three and mean is the worst. However, in my opinion if larger number of predictions would be used, clipped mean would show same or better result as median","metadata":{}}]}