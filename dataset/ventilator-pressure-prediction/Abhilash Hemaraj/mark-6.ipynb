{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-26T21:09:18.995595Z","iopub.execute_input":"2021-09-26T21:09:18.995856Z","iopub.status.idle":"2021-09-26T21:09:19.103261Z","shell.execute_reply.started":"2021-09-26T21:09:18.995778Z","shell.execute_reply":"2021-09-26T21:09:19.102306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# libraries\nimport pandas as pd\nfrom tqdm.auto import tqdm\ntqdm.pandas()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport itertools\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingRegressor\n\nimport random\nrandom.seed(7)\ntf.random.set_seed(7)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:11:40.151001Z","iopub.execute_input":"2021-09-26T21:11:40.151675Z","iopub.status.idle":"2021-09-26T21:11:44.964636Z","shell.execute_reply.started":"2021-09-26T21:11:40.151636Z","shell.execute_reply":"2021-09-26T21:11:44.963836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directory = '../input/ventilator-pressure-prediction'\ntrain = pd.read_csv(os.path.join(directory, 'train.csv'))\ntest = pd.read_csv(os.path.join(directory, 'test.csv'))\nsub = pd.read_csv(os.path.join(directory, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:11:45.292899Z","iopub.execute_input":"2021-09-26T21:11:45.293454Z","iopub.status.idle":"2021-09-26T21:11:58.268551Z","shell.execute_reply.started":"2021-09-26T21:11:45.293417Z","shell.execute_reply":"2021-09-26T21:11:58.26784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['R', 'C', 'time_step', 'u_in', 'u_out']].values","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:11:59.160671Z","iopub.execute_input":"2021-09-26T21:11:59.161015Z","iopub.status.idle":"2021-09-26T21:11:59.375378Z","shell.execute_reply.started":"2021-09-26T21:11:59.160982Z","shell.execute_reply":"2021-09-26T21:11:59.374412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[['R', 'C', 'time_step', 'u_in', 'u_out']].values\nY = train.pressure.values\n\nsample_length = 80\ninput_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n  X, None, sequence_length=sample_length, sequence_stride=sample_length)\ntarget_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n  Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n\nfor batch in zip(input_dataset, target_dataset):\n  inputs, targets = batch\n  assert np.array_equal(inputs[0], X[:sample_length])\n\n  # second sample equals output timestamps 20-40\n  assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n  break","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:12:00.150907Z","iopub.execute_input":"2021-09-26T21:12:00.151182Z","iopub.status.idle":"2021-09-26T21:12:02.750985Z","shell.execute_reply.started":"2021-09-26T21:12:00.151156Z","shell.execute_reply":"2021-09-26T21:12:02.750248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingRegressor","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:12:08.481922Z","iopub.execute_input":"2021-09-26T21:12:08.482474Z","iopub.status.idle":"2021-09-26T21:12:08.488225Z","shell.execute_reply.started":"2021-09-26T21:12:08.482436Z","shell.execute_reply":"2021-09-26T21:12:08.487316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:12:10.256768Z","iopub.execute_input":"2021-09-26T21:12:10.257211Z","iopub.status.idle":"2021-09-26T21:12:10.263078Z","shell.execute_reply.started":"2021-09-26T21:12:10.257168Z","shell.execute_reply":"2021-09-26T21:12:10.262375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lstm_model():\n    # create model\n    model = Sequential()\n    model.add(Input(shape = (inputs.shape[1], inputs.shape[2])))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(Dense(160, activation = 'relu'))\n    #model.add(Dense(80, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    model.compile(loss='mae', optimizer='adam', metrics = [tensorflow.keras.metrics.RootMeanSquaredError()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:12:12.480742Z","iopub.execute_input":"2021-09-26T21:12:12.480997Z","iopub.status.idle":"2021-09-26T21:12:12.487436Z","shell.execute_reply.started":"2021-09-26T21:12:12.48097Z","shell.execute_reply":"2021-09-26T21:12:12.486668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bi_lstm_model():\n    # create model\n    model = Sequential()\n    model.add(Input(shape = (inputs.shape[1], inputs.shape[2])))\n    model.add(Bidirectional(LSTM(640, return_sequences=True)))\n    model.add(Bidirectional(LSTM(320, return_sequences=True)))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(LSTM(320, return_sequences=True))\n    model.add(Dense(320, activation = 'relu'))\n    model.add(Dense(160, activation = 'relu'))\n    #model.add(Dense(80, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    model.compile(loss='mae', optimizer='adam', metrics = [tensorflow.keras.metrics.RootMeanSquaredError()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:12:12.85266Z","iopub.execute_input":"2021-09-26T21:12:12.85327Z","iopub.status.idle":"2021-09-26T21:12:12.859834Z","shell.execute_reply.started":"2021-09-26T21:12:12.853236Z","shell.execute_reply":"2021-09-26T21:12:12.859151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cnn_lstm_model():\n    # create model\n\n    model = Sequential()\n    model.add(Input(shape = ( inputs.shape[1], inputs.shape[2])))\n    model.add(Conv1D(filters = 320, kernel_size = 3, strides = 1, padding = 'causal', activation = \"relu\" ))\n    model.add(LSTM(320, return_sequences=True, activation = 'tanh'))\n    model.add(LSTM(320, return_sequences=True, activation = 'tanh'))\n    model.add(Dense(160, activation = 'relu'))\n    #model.add(Dense(80, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    model.compile(loss='mae', optimizer = tensorflow.keras.optimizers.Adam(), metrics = [tensorflow.keras.metrics.RootMeanSquaredError()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-26T21:12:14.57667Z","iopub.execute_input":"2021-09-26T21:12:14.577255Z","iopub.status.idle":"2021-09-26T21:12:14.583926Z","shell.execute_reply.started":"2021-09-26T21:12:14.577204Z","shell.execute_reply":"2021-09-26T21:12:14.583137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the stages of the pipeline\npipeline = Pipeline(steps= [('model', KerasRegressor(build_fn=cnn_lstm_model, epochs=500, batch_size = 512, verbose=1))])\n\n# fit the pipeline model with the training data                            \npipeline.fit(inputs, targets)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-26T21:30:56.592326Z","iopub.execute_input":"2021-09-26T21:30:56.592581Z","iopub.status.idle":"2021-09-26T21:31:17.840261Z","shell.execute_reply.started":"2021-09-26T21:30:56.592554Z","shell.execute_reply":"2021-09-26T21:31:17.839628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"4024000/80","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:04.33825Z","iopub.execute_input":"2021-09-26T15:18:04.338549Z","iopub.status.idle":"2021-09-26T15:18:04.346011Z","shell.execute_reply.started":"2021-09-26T15:18:04.338506Z","shell.execute_reply":"2021-09-26T15:18:04.344767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_array = pipeline.predict(test[['R', 'C', 'time_step', 'u_in', 'u_out']].to_numpy().reshape(50300, 80, 5))\n#list(itertools.chain(*sub_array))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-26T21:14:37.001207Z","iopub.execute_input":"2021-09-26T21:14:37.001779Z","iopub.status.idle":"2021-09-26T21:15:16.625732Z","shell.execute_reply.started":"2021-09-26T21:14:37.00174Z","shell.execute_reply":"2021-09-26T21:15:16.625023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_array =list(itertools.chain(*sub_array))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:20:39.941758Z","iopub.execute_input":"2021-09-26T15:20:39.942283Z","iopub.status.idle":"2021-09-26T15:20:40.626509Z","shell.execute_reply.started":"2021-09-26T15:20:39.942234Z","shell.execute_reply":"2021-09-26T15:20:40.62535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sub_array = pipeline.predict(test[['R', 'C', 'time_step', 'u_in', 'u_out']])","metadata":{"execution":{"iopub.status.busy":"2021-09-23T15:36:36.791909Z","iopub.execute_input":"2021-09-23T15:36:36.793601Z","iopub.status.idle":"2021-09-23T15:36:42.662245Z","shell.execute_reply.started":"2021-09-23T15:36:36.793502Z","shell.execute_reply":"2021-09-23T15:36:42.660186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'id':test.id, 'pressure':sub_array}).to_csv('mark_5.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:19:02.248372Z","iopub.execute_input":"2021-09-26T07:19:02.248921Z","iopub.status.idle":"2021-09-26T07:19:16.352453Z","shell.execute_reply.started":"2021-09-26T07:19:02.248868Z","shell.execute_reply":"2021-09-26T07:19:16.351597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building from the top down: Implementation of deep-lstms","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}