{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ensemble Folds with MEDIAN - [0.153]\nThis notebook is a fork of [Zhangxin's][1] notebook [here][2]. The purpose of this notebook is to demonstrate using **median** (instead of mean) to ensemble fold model predictions. Additionally it demonstrates \"rounding\" predictions to match the discrete target distribution observed in train data.\n\nSince the [competition metric][3] is MAE, using **median** is best. If the competition metric were RSME, then **mean** would be best.\n\nThe original notebook ensembles its 10 fold models with **mean** (instead of median) and achieves **LB 0.157**. By using **median** we boost the LB by **+0.002** and by using \"rounding\", we boost LB by **+0.002** too. Both of these tricks together boost LB a total **+0.004**!\n\n[1]: https://www.kaggle.com/tenffe\n[2]: https://www.kaggle.com/tenffe/finetune-of-tensorflow-bidirectional-lstm\n[3]: https://www.kaggle.com/c/ventilator-pressure-prediction/overview/evaluation","metadata":{}},{"cell_type":"markdown","source":"# Train Targets are Discrete - EDA\nThe discovery that train targets are discrete was first published in discussion [here][1], then [here][2]\n\n[1]: https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/275897\n[2]: https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/276083","metadata":{}},{"cell_type":"code","source":"import cupy, cudf, matplotlib.pyplot as plt\ntrain_gf = cudf.read_csv('../input/ventilator-pressure-prediction/train.csv')\n\nplt.title('Histogram of Train Pressures',size=14)\nplt.hist(train_gf.sample(100_000).pressure.to_array(),bins=100)\nplt.show()\nprint('Max pressure =',train_gf.pressure.max(), 'Min pressure =',train_gf.pressure.min())","metadata":{"execution":{"iopub.status.busy":"2021-10-03T09:33:23.884475Z","iopub.execute_input":"2021-10-03T09:33:23.88503Z","iopub.status.idle":"2021-10-03T09:33:35.057351Z","shell.execute_reply.started":"2021-10-03T09:33:23.884894Z","shell.execute_reply":"2021-10-03T09:33:35.056128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pressure = cupy.sort( train_gf.pressure.unique().values )\nprint('The first 25 unique pressures...')\nPRESSURE_MIN = all_pressure[0].item()\nPRESSURE_MAX = all_pressure[-1].item()\nall_pressure[:25]","metadata":{"execution":{"iopub.status.busy":"2021-10-03T09:49:40.737439Z","iopub.execute_input":"2021-10-03T09:49:40.73775Z","iopub.status.idle":"2021-10-03T09:49:40.780342Z","shell.execute_reply.started":"2021-10-03T09:49:40.737695Z","shell.execute_reply":"2021-10-03T09:49:40.779448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The differences between first 25 pressures...')\nPRESSURE_STEP = ( all_pressure[1] - all_pressure[0] ).item()\nall_pressure[1:26] - all_pressure[:25]","metadata":{"execution":{"iopub.status.busy":"2021-10-03T09:49:43.049608Z","iopub.execute_input":"2021-10-03T09:49:43.050255Z","iopub.status.idle":"2021-10-03T09:49:43.058798Z","shell.execute_reply.started":"2021-10-03T09:49:43.050213Z","shell.execute_reply":"2021-10-03T09:49:43.05805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport os \nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717\n\nimport tensorflow as tf, gc\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\n\nDEBUG = False\nTRAIN_MODEL = False\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]","metadata":{"_uuid":"e331dbcc-0346-4019-9ff6-b890154a878b","_cell_guid":"3e5a0bd1-3e22-4b2c-a565-68985e55f95e","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-03T09:33:35.358275Z","iopub.execute_input":"2021-10-03T09:33:35.358566Z","iopub.status.idle":"2021-10-03T09:33:49.348465Z","shell.execute_reply.started":"2021-10-03T09:33:35.35853Z","shell.execute_reply":"2021-10-03T09:33:49.347675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Engineer Features","metadata":{}},{"cell_type":"code","source":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)\n\ntargets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"_uuid":"dc41dbf2-f199-4b9d-bbd9-bf6084162b47","_cell_guid":"13a36b46-7067-4b29-aad3-7e3b15e8415b","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-03T09:33:49.351754Z","iopub.execute_input":"2021-10-03T09:33:49.351972Z","iopub.status.idle":"2021-10-03T09:34:50.399314Z","shell.execute_reply.started":"2021-10-03T09:33:49.351947Z","shell.execute_reply":"2021-10-03T09:34:50.398497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test Data","metadata":{}},{"cell_type":"code","source":"EPOCH = 300\nBATCH_SIZE = 1024\nNUM_FOLDS = 10\n\ngpu_strategy = tf.distribute.get_strategy()\n\nwith gpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        K.clear_session()\n        \n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        \n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        if TRAIN_MODEL:\n            model = keras.models.Sequential([\n                keras.layers.Input(shape=train.shape[-2:]),\n                keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n                keras.layers.Dense(128, activation='selu'),\n                keras.layers.Dense(1),\n            ])\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n            lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n            es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n            sv = keras.callbacks.ModelCheckpoint(\n                checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n                save_weights_only=False, mode='auto', save_freq='epoch',\n                options=None\n            )\n            model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        else:\n            model = keras.models.load_model('../input/finetune-of-tensorflow-bidirectional-lstm/'+checkpoint_filepath)\n            \n        test_preds.append(model.predict(test, batch_size=BATCH_SIZE, verbose=2).squeeze().reshape(-1, 1).squeeze())\n        \n        del model, X_train, X_valid; gc.collect()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-03T09:35:33.91265Z","iopub.execute_input":"2021-10-03T09:35:33.913626Z","iopub.status.idle":"2021-10-03T09:42:49.204115Z","shell.execute_reply.started":"2021-10-03T09:35:33.913574Z","shell.execute_reply":"2021-10-03T09:42:49.20094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post Process with Median and Round","metadata":{}},{"cell_type":"code","source":"# ENSEMBLE FOLDS WITH MEAN\nsubmission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\nsubmission.to_csv('submission_mean_LB157.csv', index=False)\n\n# ENSEMBLE FOLDS WITH MEDIAN\nsubmission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\nsubmission.to_csv('submission_median_LB155.csv', index=False)\n\n# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\nsubmission[\"pressure\"] =\\\n    np.round( (submission.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\nsubmission.pressure = np.clip(submission.pressure, PRESSURE_MIN, PRESSURE_MAX)\nsubmission.to_csv('submission_median_round_LB153.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T09:50:00.849314Z","iopub.execute_input":"2021-10-03T09:50:00.850105Z","iopub.status.idle":"2021-10-03T09:50:34.654435Z","shell.execute_reply.started":"2021-10-03T09:50:00.850057Z","shell.execute_reply":"2021-10-03T09:50:34.653629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After PostProcess, Test Targets are Discrete - EDA","metadata":{}},{"cell_type":"code","source":"plt.title('Histogram of Test Pressures',size=14)\nplt.hist(submission.sample(10_000).pressure.values, bins=100)\nplt.show()\nprint('Max pressure =',submission.pressure.max(), 'Min pressure =',submission.pressure.min())","metadata":{"execution":{"iopub.status.busy":"2021-10-03T09:51:08.530458Z","iopub.execute_input":"2021-10-03T09:51:08.530776Z","iopub.status.idle":"2021-10-03T09:51:09.02273Z","shell.execute_reply.started":"2021-10-03T09:51:08.53074Z","shell.execute_reply":"2021-10-03T09:51:09.022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pressure = np.sort( submission.pressure.unique() )\nprint('The differences between first 25 test pressures...')\nall_pressure[1:26] - all_pressure[:25]","metadata":{"execution":{"iopub.status.busy":"2021-10-03T10:03:02.307533Z","iopub.execute_input":"2021-10-03T10:03:02.308136Z","iopub.status.idle":"2021-10-03T10:03:02.354719Z","shell.execute_reply.started":"2021-10-03T10:03:02.308093Z","shell.execute_reply":"2021-10-03T10:03:02.353793Z"},"trusted":true},"execution_count":null,"outputs":[]}]}