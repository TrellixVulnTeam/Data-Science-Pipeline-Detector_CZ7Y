{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\nimport gc","metadata":{"_uuid":"e331dbcc-0346-4019-9ff6-b890154a878b","_cell_guid":"3e5a0bd1-3e22-4b2c-a565-68985e55f95e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-26T18:23:11.366265Z","iopub.execute_input":"2021-10-26T18:23:11.366614Z","iopub.status.idle":"2021-10-26T18:23:18.527129Z","shell.execute_reply.started":"2021-10-26T18:23:11.366524Z","shell.execute_reply":"2021-10-26T18:23:18.526123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]","metadata":{"_uuid":"ca71d87d-6594-4f31-906d-0b53cd4c1374","_cell_guid":"89eb257e-0ed2-4f8b-94d6-462a5e995eb1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-26T18:23:18.529272Z","iopub.execute_input":"2021-10-26T18:23:18.529515Z","iopub.status.idle":"2021-10-26T18:23:34.196169Z","shell.execute_reply.started":"2021-10-26T18:23:18.529488Z","shell.execute_reply":"2021-10-26T18:23:34.195298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    print(\"Step-2...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-3...Completed\")\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    print(\"Step-5...Completed\")\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n                                                              .groupby('breath_id')['u_in']\\\n                                                              .rolling(window=15,min_periods=1)\\\n                                                              .agg({\"15_in_sum\":\"sum\",\n                                                                    \"15_in_min\":\"min\",\n                                                                    \"15_in_max\":\"max\",\n                                                                    \"15_in_mean\":\"mean\"})\\\n                                                               .reset_index(level=0,drop=True))\n    print(\"Step-6...Completed\")\n    \n    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n    \n    df['time_gap'] = df['time_step'] - df.shift(1).fillna(0)['time_step']\n    df['u_in_gap'] = df['u_in'] - df.shift(1).fillna(0)['u_in']\n    df['u_in_rate'] = df['u_in_gap'] / df['time_gap']\n\n    df.loc[list(range(0, len(df), 80)), 'time_gap'] = 0\n    df.loc[list(range(0, len(df), 80)), 'u_in_gap'] = 0\n    df.loc[list(range(0, len(df), 80)), 'u_in_rate'] = 0\n    \n    df['area'] = df['u_in'] * df['time_gap']\n    df['area_cumsum'] = (df['area']).groupby(df['breath_id']).cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['minus_one']=-1.0\n    df['plus_one']=1.0\n    df['exponent']=(df['minus_one']*df['time_step'])/(df['R']*df['C'])\n    df['factor']=np.exp(df['exponent'])\n    df['vf']=(df['u_in_cumsum']*df['R'])/df['factor']\n    df['vt']=0\n    df.loc[df['time_step'] != 0, 'vt']=df['area']/(df['C']*(df['minus_one']*df['factor']+df['plus_one']))\n    df['v']=df['vf']+df['vt']\n    \n    df['tmp'] = df['u_out']*(-1)+1 # inversion of u_out\n    df['u_in_half'] = df['tmp'] * df['u_in']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"_uuid":"dc41dbf2-f199-4b9d-bbd9-bf6084162b47","_cell_guid":"13a36b46-7067-4b29-aad3-7e3b15e8415b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-26T18:23:34.197397Z","iopub.execute_input":"2021-10-26T18:23:34.197596Z","iopub.status.idle":"2021-10-26T18:26:12.264829Z","shell.execute_reply.started":"2021-10-26T18:23:34.197572Z","shell.execute_reply":"2021-10-26T18:26:12.264202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:26:12.26635Z","iopub.execute_input":"2021-10-26T18:26:12.26668Z","iopub.status.idle":"2021-10-26T18:26:12.275537Z","shell.execute_reply.started":"2021-10-26T18:26:12.266652Z","shell.execute_reply":"2021-10-26T18:26:12.274635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure','id', 'breath_id','one','count',\n            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n            'breath_id_lag2same'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id','one','count',\n            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n            'breath_id_lag2same'], axis=1)","metadata":{"_uuid":"346bf2c0-96d2-4da5-8837-c0f820294a85","_cell_guid":"01328860-fa2a-421c-9e5f-ea0048246f98","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-26T18:26:12.276736Z","iopub.execute_input":"2021-10-26T18:26:12.277Z","iopub.status.idle":"2021-10-26T18:26:18.361017Z","shell.execute_reply.started":"2021-10-26T18:26:12.276971Z","shell.execute_reply":"2021-10-26T18:26:18.360363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COLS = train.columns.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:26:18.362682Z","iopub.execute_input":"2021-10-26T18:26:18.362984Z","iopub.status.idle":"2021-10-26T18:26:18.369062Z","shell.execute_reply.started":"2021-10-26T18:26:18.362946Z","shell.execute_reply":"2021-10-26T18:26:18.368265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:26:18.370627Z","iopub.execute_input":"2021-10-26T18:26:18.371093Z","iopub.status.idle":"2021-10-26T18:26:18.386494Z","shell.execute_reply.started":"2021-10-26T18:26:18.371052Z","shell.execute_reply":"2021-10-26T18:26:18.385761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:26:18.387876Z","iopub.execute_input":"2021-10-26T18:26:18.388388Z","iopub.status.idle":"2021-10-26T18:27:13.536918Z","shell.execute_reply.started":"2021-10-26T18:26:18.388347Z","shell.execute_reply":"2021-10-26T18:27:13.535588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:13.540138Z","iopub.execute_input":"2021-10-26T18:27:13.540396Z","iopub.status.idle":"2021-10-26T18:27:30.26478Z","shell.execute_reply.started":"2021-10-26T18:27:13.540368Z","shell.execute_reply":"2021-10-26T18:27:30.263814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:30.267107Z","iopub.execute_input":"2021-10-26T18:27:30.267353Z","iopub.status.idle":"2021-10-26T18:27:30.272445Z","shell.execute_reply.started":"2021-10-26T18:27:30.267327Z","shell.execute_reply":"2021-10-26T18:27:30.271545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nclass WarmupExponentialDecay(Callback):\n    def __init__(self,lr_base=0.0002,lr_min=0.0,decay=0,warmup_epochs=0):\n        self.num_passed_batchs = 0   #一个计数器\n        self.warmup_epochs=warmup_epochs  \n        self.lr=lr_base #learning_rate_base\n        self.lr_min=lr_min #最小的起始学习率,此代码尚未实现\n        self.decay=decay  #指数衰减率\n        self.steps_per_epoch=0 #也是一个计数器\n        \n    def on_batch_begin(self, batch, logs=None):\n        # params是模型自动传递给Callback的一些参数\n        if self.steps_per_epoch==0:\n            #防止跑验证集的时候呗更改了\n            if self.params['steps'] == None:\n                self.steps_per_epoch = np.ceil(1. * self.params['samples'] / self.params['batch_size'])\n            else:\n                self.steps_per_epoch = self.params['steps']\n        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*(self.num_passed_batchs + 1) / self.steps_per_epoch / self.warmup_epochs)\n        else:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*((1-self.decay)**(self.num_passed_batchs-self.steps_per_epoch*self.warmup_epochs)))\n        self.num_passed_batchs += 1\n        \n    def on_epoch_begin(self,epoch,logs=None):\n        #用来输出学习率的,可以删除\n        print(\"learning_rate:\",K.get_value(self.model.optimizer.lr))","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:30.273877Z","iopub.execute_input":"2021-10-26T18:27:30.274128Z","iopub.status.idle":"2021-10-26T18:27:30.289728Z","shell.execute_reply.started":"2021-10-26T18:27:30.274098Z","shell.execute_reply":"2021-10-26T18:27:30.288819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.layers import Concatenate, LSTM, GRU\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Bidirectional, Multiply\nfrom tensorflow.keras.layers import BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:30.290995Z","iopub.execute_input":"2021-10-26T18:27:30.291375Z","iopub.status.idle":"2021-10-26T18:27:30.3058Z","shell.execute_reply.started":"2021-10-26T18:27:30.291343Z","shell.execute_reply":"2021-10-26T18:27:30.304722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    inputs = keras.layers.Input(shape=train.shape[-2:])\n    \n#     x = keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=True))(inputs)\n    x = keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True))(inputs)\n    x1 = keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True))(x)\n    x2 = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x1)\n    \n#     z2 = keras.layers.Bidirectional(keras.layers.GRU(units=256, return_sequences=True))(x2)\n#     z3 = keras.layers.Bidirectional(keras.layers.GRU(units=128, return_sequences=True))(keras.layers.Add()([x2, z2]))\n    x3 = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    x4 = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x3)\n    \n    x5 = keras.layers.Dense(100, activation='selu')(x4)\n    x6 = keras.layers.Dense(100, activation='selu')(x5)\n    x7 = keras.layers.Dense(100, activation='selu')(x6)\n    x7 = tf.keras.layers.Concatenate(axis=2)([x7,x5])\n    outputs = keras.layers.Dense(1)(x7)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"lstm_model\")\n    return model\n\n# m = get_model()\n# print(m.summary())","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:30.307437Z","iopub.execute_input":"2021-10-26T18:27:30.307705Z","iopub.status.idle":"2021-10-26T18:27:30.326399Z","shell.execute_reply.started":"2021-10-26T18:27:30.307676Z","shell.execute_reply":"2021-10-26T18:27:30.325693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:30.327518Z","iopub.execute_input":"2021-10-26T18:27:30.327836Z","iopub.status.idle":"2021-10-26T18:27:35.338871Z","shell.execute_reply.started":"2021-10-26T18:27:30.327797Z","shell.execute_reply":"2021-10-26T18:27:35.337721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(\n    model, \n    to_file='Google_Brain_Keras_Model.png', \n    show_shapes=True,\n    show_layer_names=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:35.340399Z","iopub.execute_input":"2021-10-26T18:27:35.340675Z","iopub.status.idle":"2021-10-26T18:27:36.532256Z","shell.execute_reply.started":"2021-10-26T18:27:35.340642Z","shell.execute_reply":"2021-10-26T18:27:36.531309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 250\nBATCH_SIZE = 512\nNUM_FOLDS = 10\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        U_OUT_IDX = 0\n        y_weight = np.ones_like( y_train )\n        u_out_values = X_train[:,:,U_OUT_IDX]\n        y_weight[ u_out_values==1 ] = 0.1\n        model = get_model()\n        model.compile(optimizer=\"adam\", loss=\"mae\", sample_weight_mode=\"temporal\")\n\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n        es = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"min\", restore_best_weights=True)\n\n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        sv = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=False, mode='auto', save_freq='epoch',\n            options=None\n        )\n#         if fold < 1:\n#             model.load_weights(f\"../input/tf-lstm-resnet-like-ff-92e0df/folds{fold}.hdf5\")\n#             test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n#         else:\n        model.fit(X_train, y_train, sample_weight=y_weight.reshape((-1, 80, 1)), validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n\n        del X_train, X_valid, y_train, y_valid, model\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:32:58.41424Z","iopub.execute_input":"2021-10-26T18:32:58.415234Z","iopub.status.idle":"2021-10-27T01:11:37.952515Z","shell.execute_reply.started":"2021-10-26T18:32:58.415194Z","shell.execute_reply":"2021-10-27T01:11:37.949912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('sub.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T18:27:58.044891Z","iopub.status.idle":"2021-10-26T18:27:58.045638Z","shell.execute_reply.started":"2021-10-26T18:27:58.045407Z","shell.execute_reply":"2021-10-26T18:27:58.04544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}