{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T11:33:56.105711Z","iopub.execute_input":"2021-11-01T11:33:56.106031Z","iopub.status.idle":"2021-11-01T11:33:56.136431Z","shell.execute_reply.started":"2021-11-01T11:33:56.105951Z","shell.execute_reply":"2021-11-01T11:33:56.135255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0.Import libraries and CSV files","metadata":{}},{"cell_type":"code","source":"# Import helpful libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\n#Importing CSV files\nX_train_full=pd.read_csv(\"/kaggle/input/ventilator-pressure-prediction/train.csv\")\nX_test_full=pd.read_csv(\"/kaggle/input/ventilator-pressure-prediction/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:03.224634Z","iopub.execute_input":"2021-11-01T12:03:03.22511Z","iopub.status.idle":"2021-11-01T12:03:11.101969Z","shell.execute_reply.started":"2021-11-01T12:03:03.225077Z","shell.execute_reply":"2021-11-01T12:03:11.100881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.EDA\n- Here, we are simply checking for missing values.\n- Please refer to my other code for EDA.\nhttps://www.kaggle.com/shashimo/ventilator-very-simple-eda-for-starter","metadata":{}},{"cell_type":"code","source":"cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()]\nprint('Missing:',cols_with_missing)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:14.872377Z","iopub.execute_input":"2021-11-01T12:03:14.872651Z","iopub.status.idle":"2021-11-01T12:03:14.905924Z","shell.execute_reply.started":"2021-11-01T12:03:14.872624Z","shell.execute_reply":"2021-11-01T12:03:14.904721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Feature engeneering","metadata":{}},{"cell_type":"code","source":"def feature_eng(df):\n    df['u_in_first']  = df.groupby('breath_id')['u_in'].transform('first')\n    df['u_in_mean']   = df.groupby('breath_id')['u_in'].transform('mean')\n    df['u_in_median'] = df.groupby('breath_id')['u_in'].transform('median')\n    df['u_in_last']   = df.groupby('breath_id')['u_in'].transform('last')\n    df[\"RCRatio\"] = df.R/df.C\n    df['u_in_shifted'] = df.groupby('breath_id')['u_in'].shift(2).fillna(method=\"backfill\")\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df.drop(['id','breath_id'], axis=1, inplace=True)\n    return df\n\nX_train_full_fe=feature_eng(X_train_full)\nX_test_full_fe=feature_eng(X_test_full)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:17.494069Z","iopub.execute_input":"2021-11-01T12:03:17.49449Z","iopub.status.idle":"2021-11-01T12:03:20.457156Z","shell.execute_reply.started":"2021-11-01T12:03:17.494457Z","shell.execute_reply":"2021-11-01T12:03:20.45615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Data preparation for LSTM\n","metadata":{}},{"cell_type":"code","source":"y_train_full=X_train_full_fe[['pressure']].to_numpy().reshape(-1, 80)\nX_train_full_fe.drop(['pressure'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:36.717585Z","iopub.execute_input":"2021-11-01T12:03:36.717885Z","iopub.status.idle":"2021-11-01T12:03:36.97682Z","shell.execute_reply.started":"2021-11-01T12:03:36.717853Z","shell.execute_reply":"2021-11-01T12:03:36.975775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\nX_train_full_fe = RS.fit_transform(X_train_full_fe)\nX_test_full_fe = RS.transform(X_test_full_fe)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:38.913382Z","iopub.execute_input":"2021-11-01T12:03:38.914376Z","iopub.status.idle":"2021-11-01T12:03:41.332372Z","shell.execute_reply.started":"2021-11-01T12:03:38.91431Z","shell.execute_reply":"2021-11-01T12:03:41.331447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_full_fe = X_train_full_fe.reshape(-1, 80, X_train_full_fe.shape[-1])\nX_test_full_fe = X_test_full_fe.reshape(-1, 80, X_train_full_fe.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:43.177422Z","iopub.execute_input":"2021-11-01T12:03:43.177694Z","iopub.status.idle":"2021-11-01T12:03:43.18511Z","shell.execute_reply.started":"2021-11-01T12:03:43.177665Z","shell.execute_reply":"2021-11-01T12:03:43.183076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.LSTM","metadata":{}},{"cell_type":"code","source":"EPOCH = 100\nBATCH_SIZE = 1024\nN_SPLITS=3\n\nkf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=0)\ntest_preds = []\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_train_full_fe,y_train_full)):\n    print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n    X_train, X_valid = X_train_full_fe[train_idx],X_train_full_fe[test_idx]\n    y_train, y_valid = y_train_full[train_idx],y_train_full[test_idx]\n    model=keras.Sequential([\n        keras.layers.Input(shape=X_train_full_fe.shape[-2:]),\n        keras.layers.Bidirectional(keras.layers.LSTM(200, return_sequences=True)),\n        keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True)),\n        keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n        keras.layers.Dense(100, activation='relu'),\n        keras.layers.Dense(1), \n    ])\n    model.compile(optimizer='adam',loss='mae')\n    scheduler = ExponentialDecay(1e-3, 400*((len(X_train_full_fe)*0.8)/BATCH_SIZE), 1e-5)\n    lr = LearningRateScheduler(scheduler, verbose=1)\n    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr])\n    #model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE)\n    test_preds.append(model.predict(X_test_full_fe).squeeze().reshape(-1, 1).squeeze())","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:03:56.271117Z","iopub.execute_input":"2021-11-01T12:03:56.271423Z","iopub.status.idle":"2021-11-01T13:10:28.413785Z","shell.execute_reply.started":"2021-11-01T12:03:56.271381Z","shell.execute_reply":"2021-11-01T13:10:28.412754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.Make CSVfile","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\nsubmission[\"pressure\"] = sum(test_preds)/N_SPLITS\nsubmission.to_csv('submission.csv', index=False)\nprint('end')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:10:44.134235Z","iopub.execute_input":"2021-11-01T13:10:44.134608Z","iopub.status.idle":"2021-11-01T13:10:55.938596Z","shell.execute_reply.started":"2021-11-01T13:10:44.134562Z","shell.execute_reply":"2021-11-01T13:10:55.937498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}