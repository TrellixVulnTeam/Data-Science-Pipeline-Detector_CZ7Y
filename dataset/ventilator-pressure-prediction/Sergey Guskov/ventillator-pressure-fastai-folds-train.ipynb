{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Based on:\n* https://www.kaggle.com/dienhoa/ventillator-fastai-lb-0-168-no-kfolds-no-blend\n* https://www.kaggle.com/lucasmorin/spectral-analysis-feature-engineering  \n* https://www.kaggle.com/junkoda/pytorch-lstm-with-tensorflow-like-initialization/notebook\n\nSo, please upvote them first!\n\nChanges from original\n* Add more callbacks [EarlyStopping and SaveModelCallback]\n* More features\n* Add oof \n* Use folds \n* [L1Loss is MAE](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)","metadata":{}},{"cell_type":"markdown","source":"# Install FASTAI","metadata":{}},{"cell_type":"code","source":"!pip install -Uqq fastai","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:26:06.196329Z","iopub.execute_input":"2021-10-31T19:26:06.196699Z","iopub.status.idle":"2021-10-31T19:26:16.913921Z","shell.execute_reply.started":"2021-10-31T19:26:06.19661Z","shell.execute_reply":"2021-10-31T19:26:16.913005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport random\nimport numpy as np \nimport pandas as pd \n\n# Torch\nfrom torch.utils.data import Dataset\nimport torch\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\n\n# FASTAI\nfrom fastai.data.core import DataLoaders\nfrom fastai.learner import Learner\nfrom fastai.callback.progress import ProgressCallback\nfrom fastai.optimizer import OptimWrapper\nfrom torch import optim\nfrom fastai.losses import MSELossFlat, L1LossFlat,CrossEntropyLossFlat\nfrom fastai.callback.schedule import Learner\n# https://docs.fast.ai/callback.tracker.html\nfrom fastai.callback.tracker import EarlyStoppingCallback, ReduceLROnPlateau, SaveModelCallback\nfrom fastai.data.transforms import IndexSplitter\n\n#scipy for FFT\nimport scipy.signal as signal\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq\nfrom scipy.signal import hilbert, chirp\nfrom scipy.signal import blackman\n\n#sklearn\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-31T19:26:16.917802Z","iopub.execute_input":"2021-10-31T19:26:16.918433Z","iopub.status.idle":"2021-10-31T19:26:22.365033Z","shell.execute_reply.started":"2021-10-31T19:26:16.9184Z","shell.execute_reply":"2021-10-31T19:26:22.364017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(10000)\nRANDOM_STATE = 10000","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:26:22.376746Z","iopub.execute_input":"2021-10-31T19:26:22.376971Z","iopub.status.idle":"2021-10-31T19:26:22.385038Z","shell.execute_reply.started":"2021-10-31T19:26:22.376946Z","shell.execute_reply":"2021-10-31T19:26:22.384129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load source datasets","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/train.csv')\ndf_test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:26:22.389884Z","iopub.execute_input":"2021-10-31T19:26:22.390208Z","iopub.status.idle":"2021-10-31T19:26:34.88506Z","shell.execute_reply.started":"2021-10-31T19:26:22.390172Z","shell.execute_reply":"2021-10-31T19:26:34.884264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UTILS","metadata":{}},{"cell_type":"code","source":"%%time\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:26:34.887477Z","iopub.execute_input":"2021-10-31T19:26:34.887753Z","iopub.status.idle":"2021-10-31T19:26:34.901449Z","shell.execute_reply.started":"2021-10-31T19:26:34.887703Z","shell.execute_reply":"2021-10-31T19:26:34.900702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"\n\ndict_types = {\n'id': np.int32,\n'breath_id': np.int32,\n'R': np.int8,\n'C': np.int8,\n'time_step': np.float32,\n'u_in': np.float32,\n'u_out': np.int8, \n'pressure': np.float32,\n} \n\nall_pressure = np.sort(df.pressure.unique())\nPRESSURE_MIN = all_pressure[0]\nPRESSURE_MAX = all_pressure[-1]\nPRESSURE_STEP = (all_pressure[1] - all_pressure[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:26:34.902689Z","iopub.execute_input":"2021-10-31T19:26:34.903008Z","iopub.status.idle":"2021-10-31T19:26:34.980528Z","shell.execute_reply.started":"2021-10-31T19:26:34.902974Z","shell.execute_reply":"2021-10-31T19:26:34.979818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FFT features","metadata":{}},{"cell_type":"code","source":"%time\nffta = lambda x: np.abs(fft(np.append(x.values,x.values[0]))[:80])\nffta.__name__ = 'ffta'\n\nfftw = lambda x: np.abs(fft(np.append(x.values,x.values[0])*w)[:80])\nfftw.__name__ = 'fftw'\n\n\n\nN = 80\nw = blackman(N+1)\n\ndef fft_features(df):\n    print(\"Step FFT-features\")\n    df['fft_u_in'] = df.groupby('breath_id')['u_in'].transform(ffta)\n    df['fft_u_in_w'] = df.groupby('breath_id')['u_in'].transform(fftw)\n    df['analytical'] = df.groupby('breath_id')['u_in'].transform(hilbert)\n    df['envelope'] = np.abs(df['analytical'])\n    df['phase'] = np.angle(df['analytical'])\n    df['unwrapped_phase'] = df.groupby('breath_id')['phase'].transform(np.unwrap)\n    df['phase_shift1'] = df.groupby('breath_id')['unwrapped_phase'].shift(1).astype(np.float32)\n    df['IF'] = df['unwrapped_phase'] - df['phase_shift1'].astype(np.float32)\n    df = df.fillna(0)\n    print(\"Finish adding FFT-features\")\n    df = df.drop('analytical',axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:26:34.98237Z","iopub.execute_input":"2021-10-31T19:26:34.982861Z","iopub.status.idle":"2021-10-31T19:26:34.999156Z","shell.execute_reply.started":"2021-10-31T19:26:34.982828Z","shell.execute_reply":"2021-10-31T19:26:34.99834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main features","metadata":{}},{"cell_type":"code","source":"def add_features(df: pd.DataFrame): \n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n\n    df = df.fillna(0)\n    print(\"Step-1...Completed\")\n\n\n    gc.collect()\n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-2...Completed\")\n    gc.collect()\n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    \n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    \n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    \n    print(\"Step-3...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    print(\"Step-4...Completed\")\n    gc.collect()\n    \n    g = df.groupby('breath_id')['u_in']\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = g.ewm(halflife=9).mean().reset_index(level=0,drop=True)\n    df['ewm_u_in_std'] = g.ewm(halflife=10).std().reset_index(level=0,drop=True)\n    df['ewm_u_in_corr'] = g.ewm(halflife=10).corr().reset_index(level=0,drop=True)\n\n    # adding this make notebook allocate all memory\n    #df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (g.rolling(window=15,min_periods=1).agg({\"15_in_sum\":\"sum\",\"15_in_min\":\"min\",\"15_in_max\":\"max\",\"15_in_mean\":\"mean\"}).reset_index(level=0,drop=True))\n    \n    df['rolling_10_mean'] = g.rolling(window=10, min_periods=1).mean()\\\n                             .reset_index(level=0, drop=True)\n    df['rolling_10_max'] = g.rolling(window=10, min_periods=1).max()\\\n                            .reset_index(level=0, drop=True)\n    df['rolling_10_std'] = g.rolling(window=10, min_periods=1).std()\\\n                            .reset_index(level=0, drop=True)\n\n    df['expand_mean'] = g.expanding(2).mean()\\\n                         .reset_index(level=0, drop=True)\n    df['expand_max'] = g.expanding(2).max()\\\n                        .reset_index(level=0, drop=True)\n    df['expand_std'] = g.expanding(2).std()\\\n                        .reset_index(level=0, drop=True)\n    \n    print(\"Step-5...Completed\")\n    gc.collect()\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    print(\"Step-6...Completed\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:32:05.501548Z","iopub.execute_input":"2021-10-31T19:32:05.501976Z","iopub.status.idle":"2021-10-31T19:32:05.527782Z","shell.execute_reply.started":"2021-10-31T19:32:05.501937Z","shell.execute_reply":"2021-10-31T19:32:05.526764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train data...\\n\")\ntrain = add_features(df)\ntrain = fft_features(train)\nprint(\"Shape of train df\", train.shape)\ndel df\ngc.collect()\n\nprint(\"\\nTest data...\\n\")\ntest = add_features(df_test)\ntest = fft_features(test)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:32:11.263582Z","iopub.execute_input":"2021-10-31T19:32:11.264164Z","iopub.status.idle":"2021-10-31T19:42:28.734938Z","shell.execute_reply.started":"2021-10-31T19:32:11.264125Z","shell.execute_reply":"2021-10-31T19:42:28.734262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure','id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id','one','count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:42:35.390278Z","iopub.execute_input":"2021-10-31T19:42:35.391266Z","iopub.status.idle":"2021-10-31T19:42:36.709024Z","shell.execute_reply.started":"2021-10-31T19:42:35.391225Z","shell.execute_reply":"2021-10-31T19:42:36.708312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:42:42.422279Z","iopub.execute_input":"2021-10-31T19:42:42.422714Z","iopub.status.idle":"2021-10-31T19:43:07.958501Z","shell.execute_reply.started":"2021-10-31T19:42:42.422673Z","shell.execute_reply":"2021-10-31T19:43:07.957654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:07.960275Z","iopub.execute_input":"2021-10-31T19:43:07.961535Z","iopub.status.idle":"2021-10-31T19:43:39.499762Z","shell.execute_reply.started":"2021-10-31T19:43:07.961488Z","shell.execute_reply":"2021-10-31T19:43:39.499017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:39.501148Z","iopub.execute_input":"2021-10-31T19:43:39.501425Z","iopub.status.idle":"2021-10-31T19:43:39.506609Z","shell.execute_reply.started":"2021-10-31T19:43:39.50139Z","shell.execute_reply":"2021-10-31T19:43:39.505906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = list(range(len(train)))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:39.507796Z","iopub.execute_input":"2021-10-31T19:43:39.508332Z","iopub.status.idle":"2021-10-31T19:43:39.517544Z","shell.execute_reply.started":"2021-10-31T19:43:39.508297Z","shell.execute_reply":"2021-10-31T19:43:39.516793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape[-2:]","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:39.520902Z","iopub.execute_input":"2021-10-31T19:43:39.521122Z","iopub.status.idle":"2021-10-31T19:43:39.528419Z","shell.execute_reply.started":"2021-10-31T19:43:39.5211Z","shell.execute_reply":"2021-10-31T19:43:39.527643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class VentilatorDataset(Dataset):\n    def __init__(self, data, target):\n        self.data = torch.from_numpy(data).float()\n        if target is not None:\n            self.targets = torch.from_numpy(target).float()\n                \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if hasattr(self, 'targets'): return self.data[idx], self.targets[idx]\n        else: return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:39.53011Z","iopub.execute_input":"2021-10-31T19:43:39.530953Z","iopub.status.idle":"2021-10-31T19:43:39.538161Z","shell.execute_reply.started":"2021-10-31T19:43:39.530917Z","shell.execute_reply":"2021-10-31T19:43:39.537482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_size=64):\n        hidden = [400, 300, 200, 100]\n        super().__init__()\n        self.lstm1 = nn.LSTM(input_size, hidden[0],\n                             batch_first=True, bidirectional=True)\n        self.lstm2 = nn.LSTM(2 * hidden[0], hidden[1],\n                             batch_first=True, bidirectional=True)\n        self.lstm3 = nn.LSTM(2 * hidden[1], hidden[2],\n                             batch_first=True, bidirectional=True)\n        self.lstm4 = nn.LSTM(2 * hidden[2], hidden[3],\n                             batch_first=True, bidirectional=True)\n        self.fc1 = nn.Linear(2 * hidden[3], 50)\n        self.selu = nn.SELU()\n        self.fc2 = nn.Linear(50, 1)\n        self._reinitialize()\n\n    def _reinitialize(self):\n        \"\"\"\n        Tensorflow/Keras-like initialization\n        \"\"\"\n        for name, p in self.named_parameters():\n            if 'lstm' in name:\n                if 'weight_ih' in name:\n                    nn.init.xavier_uniform_(p.data)\n                elif 'weight_hh' in name:\n                    nn.init.orthogonal_(p.data)\n                elif 'bias_ih' in name:\n                    p.data.fill_(0)\n                    n = p.size(0)\n                    p.data[(n // 4):(n // 2)].fill_(1)\n                elif 'bias_hh' in name:\n                    p.data.fill_(0)\n            elif 'fc' in name:\n                if 'weight' in name:\n                    nn.init.xavier_uniform_(p.data)\n                elif 'bias' in name:\n                    p.data.fill_(0)\n\n    def forward(self, x):\n        x, _ = self.lstm1(x)\n        x, _ = self.lstm2(x)\n        x, _ = self.lstm3(x)\n        x, _ = self.lstm4(x)\n        x = self.fc1(x)\n        x = self.selu(x)\n        x = self.fc2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:39.539284Z","iopub.execute_input":"2021-10-31T19:43:39.539635Z","iopub.status.idle":"2021-10-31T19:43:39.554983Z","shell.execute_reply.started":"2021-10-31T19:43:39.539592Z","shell.execute_reply":"2021-10-31T19:43:39.554323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 1024\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\ntest_dataset = VentilatorDataset(test, None)\ntest_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:39.556241Z","iopub.execute_input":"2021-10-31T19:43:39.55688Z","iopub.status.idle":"2021-10-31T19:43:41.018517Z","shell.execute_reply.started":"2021-10-31T19:43:39.556843Z","shell.execute_reply":"2021-10-31T19:43:41.017728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True)\npreds_fold = []\noof_df = []\nfor fold, (train_index, valid_index) in enumerate(kf.split(idx)):\n    \n    preds = []\n    model = RNNModel(input_size=train.shape[-1]).to('cuda')\n    print(\"FOLD:\", fold)\n    print(train_index)\n    print(valid_index)\n\n    train_input, valid_input = train[train_index], train[valid_index]\n    train_targets, valid_targets = targets[train_index], targets[valid_index]\n\n    train_dataset = VentilatorDataset(train_input, train_targets)\n    valid_dataset = VentilatorDataset(valid_input, valid_targets)\n    \n    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=False)\n    valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle=False)\n    \n    dls = DataLoaders(train_loader, valid_loader)\n    learn = Learner(dls, model, loss_func=L1LossFlat())\n    callbacks = [SaveModelCallback(every_epoch=True, monitor='valid_loss',min_delta=0.1, fname=f\"fastai_fold{fold+1}.pth\"),\n                 ReduceLROnPlateau(monitor='valid_loss', min_delta=0.5, patience=5),\n                EarlyStoppingCallback(monitor='valid_loss', min_delta=0.0005, patience=5)]\n    learn.fit_one_cycle(120, lr_max=2e-3, cbs=callbacks)\n    \n    valid_oof_dataset = VentilatorDataset(valid_input, None)\n    valid_oof_loader = DataLoader(valid_oof_dataset, batch_size = batch_size, shuffle=False)\n    oof_pred = []\n    oof_sample = []\n    \n    with torch.no_grad():\n        for data in valid_oof_loader:\n            pred = model(data.to('cuda')).squeeze(-1).flatten()\n            oof_pred.extend(pred.detach().cpu().numpy())\n        oof_df.append({\n            'pred': oof_pred,\n            'target': valid_targets\n        })\n        for data in test_loader:\n            pred = model(data.to('cuda')).squeeze(-1).flatten()\n            preds.extend(pred.detach().cpu().numpy())\n    preds_fold.append(preds)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:48:48.774138Z","iopub.execute_input":"2021-10-31T19:48:48.774462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"code","source":"target = []\npred = []\nfor i in range(len(oof_df)):\n    target.extend(oof_df[i]['target'].flatten())\n    pred.extend(oof_df[i]['pred'])\nprint(len(target))    \nprint(len(pred))\nfrom sklearn.metrics import mean_absolute_error\nprint(mean_absolute_error(target,pred))\ntotal = pd.DataFrame(data={'pred': pred, 'target': target})\ntotal.to_csv('oof_score.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:41.036041Z","iopub.status.idle":"2021-10-31T19:43:41.036778Z","shell.execute_reply.started":"2021-10-31T19:43:41.036465Z","shell.execute_reply":"2021-10-31T19:43:41.036492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"preds_fold = np.array(preds_fold)\ndf_test['pressure'] = np.median(preds_fold, axis=0)\ndf_test[['id', 'pressure']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T19:43:41.038207Z","iopub.status.idle":"2021-10-31T19:43:41.039012Z","shell.execute_reply.started":"2021-10-31T19:43:41.038554Z","shell.execute_reply":"2021-10-31T19:43:41.038579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EOF","metadata":{}}]}