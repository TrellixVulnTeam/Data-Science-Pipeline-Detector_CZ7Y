{"cells":[{"cell_type":"markdown","metadata":{},"source":"<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/16/Closed_circuit_ventilators.gif\"/>\n<center>Image Source: Tabletop Whale: Explaining ventilators for COVID-19 http://tabletopwhale.com/2020/04/01/explaining-ventilators-for-covid-19.html</center>"},{"cell_type":"markdown","metadata":{},"source":"# About Competition\nMechanical ventilation is a clinician-intensive procedure that was prominently on display during the early days of the COVID-19 pandemic. Developing new methods for controlling mechanical ventilators is prohibitively expensive, even before reaching clinical trials. High-quality simulators could reduce this barrier.\n Current simulators are trained as an ensemble, where each model simulates a single lung setting. However, lungs and their attributes form a continuous space, so a parametric approach must be explored that would consider the differences in patient lungs.\n The team at Google Brain aims to grow the community around machine learning for mechanical ventilation control. They believe neural networks and deep learning can better generalize across lungs with varying characteristics.\n In this competition, youâ€™ll simulate a ventilator connected to a sedated patient's lung. The best submissions will take lung attributes compliance and resistance into account.Competition file is available [here](https://www.kaggle.com/c/ventilator-pressure-prediction)."},{"cell_type":"markdown","metadata":{},"source":"# Load Competition Dataset"},{"cell_type":"markdown","metadata":{},"source":"Competition dataset located in \"/kaggle/input\"; This path defined by Kaggle to access the competition file. We will list two files from this path as input files."},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        path=os.path.join(dirname, filename)\n        if 'train' in path:\n            __training_path=path\n        elif 'test' in path:\n            __test_path=path"},{"cell_type":"markdown","metadata":{},"source":"## Input Dataset"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"#loaded files\nprint(f'Training path:{__training_path}\\nTest path:{__test_path}')"},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":"True"},"outputs":[],"source":"# Kaggle Environment Prepration\n#update kaggle env\nimport sys\n#you may update the environment that allow you to run the whole code\n!{sys.executable} -m pip install --upgrade scikit-learn==\"0.24.2\""},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"#record this information if you need to run the Kernel internally\nimport sklearn; sklearn.show_versions()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{},"source":"# Input Dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false},"outputs":[],"source":"def __load__data(__training_path, __test_path, concat=False):\n\t\"\"\"load data as input dataset\n\tparams: __training_path: the training path of input dataset\n\tparams: __test_path: the path of test dataset\n\tparams: if it is True, then it will concatinate the training and test dataset as output\n\treturns: generate final loaded dataset as dataset, input and test\n\t\"\"\"\n\t# LOAD DATA\n\timport pandas as pd\n\t__train_dataset = pd.read_csv(__training_path, delimiter=',')\n\t__test_dataset = pd.read_csv(__test_path, delimiter=',')\n\treturn __train_dataset, __test_dataset\n__train_dataset, __test_dataset = __load__data(__training_path, __test_path, concat=True)\n__train_dataset.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false},"outputs":[],"source":"# STORE SUBMISSION RELEVANT COLUMNS\n__test_dataset_submission_columns = __test_dataset['id']"},{"cell_type":"markdown","metadata":{},"source":"### Discard Irrelevant Columns\nIn the given input dataset there are <b>1</b> column that can be removed as follows:* id *."},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false},"outputs":[],"source":"# DISCARD IRRELEVANT COLUMNS\n__train_dataset.drop(['id'], axis=1, inplace=True)\n__test_dataset.drop(['id'], axis=1, inplace=True)"},{"cell_type":"markdown","metadata":{},"source":"### Target Column\nThe target column is the value which we need to predict.\nTherefore, we need to detach the target columns in prediction.\nNote that if we don't drop this fields, it will generate a model with high accuracy on training and worst accuracy on test (because the value in test dataset is Null).\nHere is the list of *target column*: <b>pressure</b>"},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false},"outputs":[],"source":"# DETACH TARGET\n__feature_train = __train_dataset.drop(['pressure'], axis=1)\n__target_train =__train_dataset['pressure']\n__feature_test = __test_dataset"},{"cell_type":"markdown","metadata":{},"source":"# Training Model and Prediction\nFirst, we will train a model based on preprocessed values of training data set.\nSecond, let's predict test values based on the trained model."},{"cell_type":"markdown","metadata":{},"source":"## LightGBM Regressor\nWe will use *LightGBM Regressor* which is constructing a gradient boosting model. We will use *lightgbm* package.\nMore detail about *LightGBM Regressor* can be found [here](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html)."},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":true},"outputs":[],"source":"# MODEL\nimport numpy as np\nfrom lightgbm import LGBMRegressor\n__model = LGBMRegressor()\n__model.fit(__feature_train, __target_train) \n__y_pred = __model.predict(__feature_test)"},{"cell_type":"markdown","metadata":{},"source":"# Submission File\nWe have to maintain the target columns in \"submission.csv\" which will be submitted as our prediction results."},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false},"outputs":[],"source":"# SUBMISSION\nsubmission = pd.DataFrame(columns=['id'], data=__test_dataset_submission_columns)\nsubmission['pressure'] = __y_pred\nsubmission.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false},"outputs":[],"source":"# save submission file\nsubmission.to_csv(\"kaggle_submission.csv\", index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}