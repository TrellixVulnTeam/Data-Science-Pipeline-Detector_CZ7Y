{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-26T07:24:02.968152Z","iopub.execute_input":"2021-09-26T07:24:02.968443Z","iopub.status.idle":"2021-09-26T07:24:02.977058Z","shell.execute_reply.started":"2021-09-26T07:24:02.968415Z","shell.execute_reply":"2021-09-26T07:24:02.976144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchmetrics\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.model_selection import train_test_split\nfrom torchmetrics import MeanAbsoluteError\nfrom datetime import datetime\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:24:03.901699Z","iopub.execute_input":"2021-09-26T07:24:03.901957Z","iopub.status.idle":"2021-09-26T07:24:03.907685Z","shell.execute_reply.started":"2021-09-26T07:24:03.90193Z","shell.execute_reply":"2021-09-26T07:24:03.906364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1. Baseline LSTM Model without tuning, \n####    Because i misread the evaluation section i have modeled expiratory phase too, this version is modified for inspiratory phase only - modified custom loss function","metadata":{}},{"cell_type":"code","source":"X = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/train.csv')\nX_test = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/test.csv')\nX.pop('id')\nX_test.pop('id')\ny = X['pressure']\nX.pop('pressure')\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-26T07:29:37.207807Z","iopub.execute_input":"2021-09-26T07:29:37.208493Z","iopub.status.idle":"2021-09-26T07:29:44.244371Z","shell.execute_reply.started":"2021-09-26T07:29:37.208456Z","shell.execute_reply":"2021-09-26T07:29:44.243611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['u_in_cumsum'] = (X['u_in']).groupby(X['breath_id']).cumsum()\nX_test['u_in_cumsum']  = (X_test['u_in']).groupby(X_test['breath_id']).cumsum()\n# X['u_out_cumsum'] = (X['u_out']).groupby(X['breath_id']).cumsum()\n# X_test['u_out_cumsum']  = (X_test['u_out']).groupby(X_test['breath_id']).cumsum()\n# X['RC']= X['u_in']*(1-X['u_out'])*(1-np.exp(-X['time_step']/(1e-3*X['R']*X['C'])))\n# X_test['RC']= X_test['u_in']*(1-X_test['u_out'])*(1-np.exp(-X_test['time_step']/(X_test['R']*X_test['C'])))\n\nX.pop('breath_id')\nX_test.pop('breath_id')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-26T07:29:44.245751Z","iopub.execute_input":"2021-09-26T07:29:44.246075Z","iopub.status.idle":"2021-09-26T07:29:44.542934Z","shell.execute_reply.started":"2021-09-26T07:29:44.246038Z","shell.execute_reply":"2021-09-26T07:29:44.542119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_rows',100)\n# X.iloc[:100]","metadata":{"execution":{"iopub.status.busy":"2021-09-26T06:24:30.270786Z","iopub.execute_input":"2021-09-26T06:24:30.271142Z","iopub.status.idle":"2021-09-26T06:24:30.275846Z","shell.execute_reply.started":"2021-09-26T06:24:30.27107Z","shell.execute_reply":"2021-09-26T06:24:30.274477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_off=X.iloc[:400,:].copy()\n# y_off=y.iloc[:400].copy()\n# X=X.iloc[400:,:]\n# y=y.iloc[400:]","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:31:19.004462Z","iopub.execute_input":"2021-09-26T07:31:19.005039Z","iopub.status.idle":"2021-09-26T07:31:19.010328Z","shell.execute_reply.started":"2021-09-26T07:31:19.005002Z","shell.execute_reply":"2021-09-26T07:31:19.00944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tmp = X.iloc[:,4].copy()\nX_tmp_test = X_test.iloc[:,4].copy()\n# X_tmp_off = X_off.iloc[:,4].copy()\nst = StandardScaler()\nX = st.fit_transform(X)\nX_test = st.transform(X_test)\n# X_off = st.transform(X_off)\nX[:,4]=np.array(X_tmp)\nX_test[:,4]=np.array(X_tmp_test)\n# X_off[:,4]=np.array(X_tmp_off)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:32:30.308486Z","iopub.execute_input":"2021-09-26T07:32:30.308741Z","iopub.status.idle":"2021-09-26T07:32:31.642982Z","shell.execute_reply.started":"2021-09-26T07:32:30.308715Z","shell.execute_reply":"2021-09-26T07:32:31.642274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.float32(X).reshape(-1,80,6)\nX_test = np.float32(X_test).reshape(-1,80,6)\ny=np.float32(y).reshape(-1,80,1)\n\n# X_off=np.float32(X_off).reshape(-1,80,6)\n# y_off=np.float32(y_off).reshape(-1,80,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:33:08.719103Z","iopub.execute_input":"2021-09-26T07:33:08.719804Z","iopub.status.idle":"2021-09-26T07:33:08.828094Z","shell.execute_reply.started":"2021-09-26T07:33:08.719768Z","shell.execute_reply":"2021-09-26T07:33:08.827225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, n_dim, n_hdim=30, n_layers=1, v_dropout=0):\n        super().__init__()\n        self.n_dim = n_dim\n        self.n_hdim = n_hdim\n        self.n_layers = n_layers\n        self.v_dropout = v_dropout\n        self.lstm = nn.LSTM(\n        input_size=128,\n        hidden_size=self.n_hdim,\n        num_layers=self.n_layers,\n        dropout = self.v_dropout,\n        bidirectional=True,\n        batch_first=True)\n        self.inp = nn.Linear(self.n_dim,64)\n        self.inp2 = nn.Linear(64,128)\n        self.fc = nn.Linear(self.n_hdim*2,64)#2380 for 20\n        self.out = nn.Linear(64,1)\n\n\n        torch.nn.init.xavier_normal_(self.out.weight)\n        torch.nn.init.xavier_normal_(self.fc.weight)\n        torch.nn.init.xavier_normal_(self.inp.weight)\n        torch.nn.init.xavier_normal_(self.inp2.weight)\n\n\n    def forward(self, x):\n        x = F.relu(self.inp(x))\n        x = F.relu(self.inp2(x))\n        x, _ = self.lstm(x)\n\n        x = F.relu(self.fc(x))\n        x = F.relu(self.out(x))\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:33:12.239722Z","iopub.execute_input":"2021-09-26T07:33:12.239987Z","iopub.status.idle":"2021-09-26T07:33:12.251654Z","shell.execute_reply.started":"2021-09-26T07:33:12.239958Z","shell.execute_reply":"2021-09-26T07:33:12.249533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class L1Loss_masked(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, preds, y, u_out):\n\n\n        mask = 1 - u_out\n        mae = torch.abs(mask * (y - preds))\n        mae = torch.sum(mae) / torch.sum(mask)\n\n        return mae","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:33:14.0074Z","iopub.execute_input":"2021-09-26T07:33:14.008099Z","iopub.status.idle":"2021-09-26T07:33:14.01556Z","shell.execute_reply.started":"2021-09-26T07:33:14.008059Z","shell.execute_reply":"2021-09-26T07:33:14.014758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_gd(X, X_test, y, epochs, n_folds):\n\n\n    gc.collect()\n    kfold = KFold(n_splits = n_folds, random_state=42, shuffle=True)\n    y_pred = torch.zeros(4024000,1)\n\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n       # device = 'cpu'\n    print('Using {} device'.format(device))   \n    y_pred = y_pred.to(device)\n    xtest = torch.from_numpy(X_test)\n    test_loader = torch.utils.data.DataLoader(xtest, batch_size=32, shuffle=False)\n\n\n    for idx in kfold.split(X=X, y=y):\n        best_loss = 1e4\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X[train_idx]\n        ytrain = y[train_idx]\n        xval = X[val_idx]\n        yval = y[val_idx]\n        \n        ytrain = np.array(ytrain)\n        yval = np.array(yval)\n        xtrain = torch.from_numpy(xtrain)\n        xval = torch.from_numpy(xval)\n        ytrain = torch.from_numpy(ytrain)\n        yval = torch.from_numpy(yval)\n\n        \n        train_dataset = torch.utils.data.TensorDataset(xtrain,ytrain)\n        train_loader=torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4 )\n \n        val_dataset = torch.utils.data.TensorDataset(xval,yval)\n        val_loader=torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False , num_workers=4)\n        \n        model = LSTMModel(6,128,3)\n\n        criterion = L1Loss_masked()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.0008, eps=1e-08)\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n        model.to(device)\n        gc.collect()\n        for epoch in range(epochs):\n            model.train()\n            t0 = datetime.now()\n            train_loss = []\n            for inputs, targets in train_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(inputs)\n\n                loss = criterion(outputs, targets, inputs[:,:,4].reshape(-1,80,1))\n                loss.backward()\n                optimizer.step()\n                train_loss.append(loss.item())\n            train_loss = np.mean(train_loss) \n\n            model.eval()\n            with torch.no_grad():\n                val_loss = []\n                for inputs, targets in val_loader:\n                    inputs, targets = inputs.to(device), targets.to(device)\n                    outputs = model(inputs)\n                    loss = criterion(outputs, targets, inputs[:,:,4].reshape(-1,80,1))\n                    val_loss.append(loss.item())\n\n\n                val_loss = np.mean(val_loss)\n\n\n                if val_loss > 10:\n                    model.load_state_dict(torch.load('/kaggle/working/ckpt_pytorch_ep_1'))\n                    model.to(device)\n                elif val_loss < best_loss:\n                    best_loss = val_loss\n                    torch.save(model.state_dict(), '/kaggle/working/ckpt_pytorch')\n                if epoch==0:\n                    torch.save(model.state_dict(), '/kaggle/working/ckpt_pytorch_ep_1')\n        #         auc_roc = metric(outputs,targets.int()).compute()\n                dt = datetime.now() - t0\n                print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n          Val Loss: {val_loss:.4f} ,lowest loss {best_loss:.5f} ,    Duration: {dt}')\n\n\n        with torch.no_grad():\n            del model\n            del inputs\n            del targets\n            del xtrain\n            del xval\n            del ytrain\n            del yval\n            del train_dataset\n            del val_dataset\n            del train_loader\n            del val_loader\n            gc.collect()\n            with torch.cuda.device('cuda:0'):\n                torch.cuda.empty_cache()\n            model =LSTMModel(6,128,3)\n            model.load_state_dict(torch.load('/kaggle/working/ckpt_pytorch'))\n            model.to(device)\n            preds = []\n            model.eval()\n            for inputs in test_loader:\n                inputs = inputs.to(device)\n                preds.append(model(inputs).reshape(-1,1)/kfold.n_splits)\n            y_pred += torch.cat(preds,0)\n\n    return y_pred.cpu().numpy() \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-26T07:33:17.263043Z","iopub.execute_input":"2021-09-26T07:33:17.263586Z","iopub.status.idle":"2021-09-26T07:33:17.28768Z","shell.execute_reply.started":"2021-09-26T07:33:17.26355Z","shell.execute_reply":"2021-09-26T07:33:17.286958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_pred=batch_gd(X, X_test, y, epochs=120, n_folds=5)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T07:33:39.663119Z","iopub.execute_input":"2021-09-26T07:33:39.663786Z","iopub.status.idle":"2021-09-26T08:04:38.998515Z","shell.execute_reply.started":"2021-09-26T07:33:39.663754Z","shell.execute_reply":"2021-09-26T08:04:38.997728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsub = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/sample_submission.csv')\nsub.iloc[:,1]=y_pred\nsub=sub.set_index('id')\nsub.to_csv('baseline_pytorch_cv.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T06:58:03.23365Z","iopub.execute_input":"2021-09-26T06:58:03.233977Z","iopub.status.idle":"2021-09-26T06:58:22.191409Z","shell.execute_reply.started":"2021-09-26T06:58:03.233946Z","shell.execute_reply":"2021-09-26T06:58:22.190362Z"},"trusted":true},"execution_count":null,"outputs":[]}]}