{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/gdrive')\n# data_dir = 'gdrive/MyDrive/kaggle/ventilator-pressure-prediction/data'\n# SAVE_MODEL_PATH = 'gdrive/MyDrive/kaggle/ventilator-pressure-prediction/code/models/model_class28'\n\n\ndata_dir = '../input/ventilator-pressure-prediction'\nSAVE_MODEL_PATH = '/kaggle/working/'","metadata":{"executionInfo":{"elapsed":1008,"status":"ok","timestamp":1634252834113,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"NmbBLeXhm4oU","outputId":"2337d0d4-cf9c-4363-b119-9e214c04bee3","execution":{"iopub.status.busy":"2021-10-29T16:11:55.151081Z","iopub.execute_input":"2021-10-29T16:11:55.151451Z","iopub.status.idle":"2021-10-29T16:11:55.238973Z","shell.execute_reply.started":"2021-10-29T16:11:55.15136Z","shell.execute_reply":"2021-10-29T16:11:55.238217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install pandas --upgrade\n!pip install tez\n#!pip install Time2Vec-PyTorch","metadata":{"executionInfo":{"elapsed":3705,"status":"ok","timestamp":1634252838069,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"Ab1di-c2CU6E","outputId":"0d645d49-ac65-4df9-f1e5-423d06a283ab","execution":{"iopub.status.busy":"2021-10-29T16:11:55.24059Z","iopub.execute_input":"2021-10-29T16:11:55.241247Z","iopub.status.idle":"2021-10-29T16:12:02.847325Z","shell.execute_reply.started":"2021-10-29T16:11:55.241205Z","shell.execute_reply":"2021-10-29T16:12:02.846114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install transformers > /dev/null\n# !pip install git+https://github.com/rashmibanthia/tez.git@b81953fa2e5ae2f4ea8d560de35c3a857c5e59e6 > /dev/null","metadata":{"executionInfo":{"elapsed":16005,"status":"ok","timestamp":1634252854057,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"s-AUVB6RnGBY","outputId":"a931ca42-d3ab-4604-8c5c-ba650301bc24","execution":{"iopub.status.busy":"2021-10-29T16:12:02.849045Z","iopub.execute_input":"2021-10-29T16:12:02.849372Z","iopub.status.idle":"2021-10-29T16:12:02.856081Z","shell.execute_reply.started":"2021-10-29T16:12:02.849327Z","shell.execute_reply":"2021-10-29T16:12:02.855226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport tez\n\nimport random\nimport gc \n\nimport pandas as pd\nimport torch.nn as nn\nimport numpy as np\n\nfrom sklearn import metrics\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\n\nimport torch.nn.functional as F\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import get_cosine_schedule_with_warmup\nfrom tqdm.notebook import tqdm as tqdm\nfrom torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR,ReduceLROnPlateau,CosineAnnealingWarmRestarts\nfrom sklearn.preprocessing import RobustScaler","metadata":{"executionInfo":{"elapsed":14286,"status":"ok","timestamp":1634252868325,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"d7MNZArsnLMT","execution":{"iopub.status.busy":"2021-10-29T16:12:02.85865Z","iopub.execute_input":"2021-10-29T16:12:02.859206Z","iopub.status.idle":"2021-10-29T16:12:08.981417Z","shell.execute_reply.started":"2021-10-29T16:12:02.859161Z","shell.execute_reply":"2021-10-29T16:12:08.980585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed: int) -> None:\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1634252868330,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"L6xVC3xqnc9U","execution":{"iopub.status.busy":"2021-10-29T16:12:08.982751Z","iopub.execute_input":"2021-10-29T16:12:08.983011Z","iopub.status.idle":"2021-10-29T16:12:08.98883Z","shell.execute_reply.started":"2021-10-29T16:12:08.98298Z","shell.execute_reply":"2021-10-29T16:12:08.988143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1634252868330,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"fY2cJr2ttG49","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, X, y, w):\n        if y is None:\n            y = np.zeros(len(X), dtype=np.float32)\n\n        self.X = X.astype(np.float32)\n        self.y = y.astype(np.float32)\n        self.w = w.astype(np.float32)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, i):\n        return self.X[i], self.y[i], self.w[i]","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:08.990249Z","iopub.execute_input":"2021-10-29T16:12:08.990751Z","iopub.status.idle":"2021-10-29T16:12:09.001057Z","shell.execute_reply.started":"2021-10-29T16:12:08.990716Z","shell.execute_reply":"2021-10-29T16:12:09.00024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1634252868331,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"qv-0m3f1vz7G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change fold here\nclass args:\n    fold = 4\n    learning_rate = 2e-3  \n    batch_size = 1024\n    epochs = 300\n    accumulation_steps = 1\n    output_folder = SAVE_MODEL_PATH\n    fp16 = False\n\n    device = 'cuda'\n    input_dim = 13 #8 #5\n    dense_dim = 512\n    lstm_dim = 512\n    logit_dim = 512\n\n    EMBED_SIZE = 64\n    HIDDEN_SIZE = 256\n    \n#     ALL_FEATURES = ['u_in', 'u_out', 'time_step', 'u_in_cumsum', 'u_in_cummean', 'area', 'cross', 'cross2', 'R_cate', 'C_cate', 'RC_sum', 'RC_dot',\n#  'u_in_lag_1','u_in_lag_2','u_in_lag_3','u_in_lag_4', 'u_in_time1', 'u_in_time2' , 'u_in_time3', 'u_in_time4',\n# 'u_out_lag_1','u_out_lag_2','u_out_lag_3','u_out_lag_4']\n\n    ALL_FEATURES = ['time_step', 'u_in', 'u_out', \n       'area', 'u_in_cumsum', 'u_in_lag1', 'u_out_lag1', 'u_in_lag_back1',\n       'u_out_lag_back1', 'u_in_lag2', 'u_out_lag2', 'u_in_lag_back2',\n       'u_out_lag_back2', 'u_in_lag3', 'u_out_lag3', 'u_in_lag_back3',\n       'u_out_lag_back3', 'u_in_lag4', 'u_out_lag4', 'u_in_lag_back4',\n       'u_out_lag_back4', 'breath_id__u_in__max', 'breath_id__u_out__max',\n       'u_in_diff1', 'u_out_diff1', 'u_in_diff2', 'u_out_diff2',\n       'breath_id__u_in__diffmax', 'breath_id__u_in__diffmean', 'u_in_diff3',\n       'u_out_diff3', 'u_in_diff4', 'u_out_diff4', 'cross', 'cross2', 'R_20',\n       'R_5', 'R_50', 'C_10', 'C_20', 'C_50', 'R__C_20__10', 'R__C_20__20',\n       'R__C_20__50', 'R__C_50__10', 'R__C_50__20', 'R__C_50__50',\n       'R__C_5__10', 'R__C_5__20', 'R__C_5__50', \n       'u_in_1st_derivative', 'expand_mean_1sr_der', 'u_in_1st_der_mean10',\n       'time_diff', 'power', 'power_cumsum', 'ewm_u_in_mean', 'ewm_u_in_std',\n       'ewm_u_in_corr', 'delta_u_in', 'delta_u_in_exp',\n       'delta_rolling_10_mean', 'delta_rolling_10_max', 'work', 'work_roll_10',\n       'work_roll_15', 'u_in_rol_q0.1', 'u_in_rol_q0.25', 'u_in_rol_q0.5',\n       'u_in_rol_q0.75', 'u_in_rol_q0.9']\n\n    \nprint(len(args.ALL_FEATURES))","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1634252868331,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"nVXO3tgAonFp","outputId":"3ea4d709-892c-42b9-8fb8-073c4143388e","execution":{"iopub.status.busy":"2021-10-29T16:12:09.004275Z","iopub.execute_input":"2021-10-29T16:12:09.004549Z","iopub.status.idle":"2021-10-29T16:12:09.01733Z","shell.execute_reply.started":"2021-10-29T16:12:09.004511Z","shell.execute_reply":"2021-10-29T16:12:09.016384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp ../input/ventilator-train-classification-ce-pytorch-optim/*.csv /kaggle/working/\n# !cp ../input/ventilator-train-classification-ce-pytorch-optim/model_f0_r1.bin /kaggle/working/model_f0_split6.bin","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:09.018668Z","iopub.execute_input":"2021-10-29T16:12:09.019008Z","iopub.status.idle":"2021-10-29T16:12:13.605122Z","shell.execute_reply.started":"2021-10-29T16:12:09.01897Z","shell.execute_reply":"2021-10-29T16:12:13.604168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import model_selection\n#df=pd.read_csv('../input/ventilator-train-classification-ce-pytorch-optim/train_folds.csv')\n''' \ndf=pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ndf[\"kfold\"] = -1\ny = df.pressure.values\n\nkf = model_selection.GroupKFold(n_splits=7)\n\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y, groups=df.breath_id.values)):\n    df.loc[v_, \"kfold\"] = f\n\ndf.to_csv(\"train_folds.csv\", index=False)\n''' \n\ndf=pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ndf[\"kfold\"] = -1\ny = df.pressure.values\nkf = model_selection.GroupKFold(n_splits=7)\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y, groups=df.breath_id.values)):\n    df.loc[v_, \"kfold\"] = f\ndf.to_csv(\"train_folds7.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:13.608885Z","iopub.execute_input":"2021-10-29T16:12:13.609109Z","iopub.status.idle":"2021-10-29T16:12:18.975033Z","shell.execute_reply.started":"2021-10-29T16:12:13.609081Z","shell.execute_reply":"2021-10-29T16:12:18.974254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #df_uout_0=df[df.u_out==0].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:18.976578Z","iopub.execute_input":"2021-10-29T16:12:18.976928Z","iopub.status.idle":"2021-10-29T16:12:18.982044Z","shell.execute_reply.started":"2021-10-29T16:12:18.976874Z","shell.execute_reply":"2021-10-29T16:12:18.981127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df['cycle_last_ts']=df.groupby(['breath_id','u_out'])['time_step'].transform('max') \n#df['cycle_last_ts_diff']=df['cycle_last_ts']-df['time_step']","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:18.983506Z","iopub.execute_input":"2021-10-29T16:12:18.984372Z","iopub.status.idle":"2021-10-29T16:12:18.99498Z","shell.execute_reply.started":"2021-10-29T16:12:18.984329Z","shell.execute_reply":"2021-10-29T16:12:18.9941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df[(df.breath_id==1) & (df.u_out==0)]\ndf.iloc[:,2:5] ","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:18.996727Z","iopub.execute_input":"2021-10-29T16:12:18.997099Z","iopub.status.idle":"2021-10-29T16:12:19.071977Z","shell.execute_reply.started":"2021-10-29T16:12:18.997061Z","shell.execute_reply":"2021-10-29T16:12:19.071222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(42)\n\n# ====================================================\n# Data Loading\n# ====================================================\ntrain_df = df \n#test_df = pd.read_csv(f'{data_dir}/test.csv')\nsub = pd.read_csv(f'{data_dir}/sample_submission.csv')\n\nfor c in ['u_in']:\n    train_df[c] = np.log1p(train_df[c])\n    #test_df[c] = np.log1p(test_df[c])\n\n","metadata":{"executionInfo":{"elapsed":20079,"status":"ok","timestamp":1634252888394,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"Q395bBKyrEqx","outputId":"206ebece-c972-4e73-9099-751aa629172c","execution":{"iopub.status.busy":"2021-10-29T16:12:19.073249Z","iopub.execute_input":"2021-10-29T16:12:19.073623Z","iopub.status.idle":"2021-10-29T16:12:20.09247Z","shell.execute_reply.started":"2021-10-29T16:12:19.073583Z","shell.execute_reply":"2021-10-29T16:12:20.091646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = np.zeros(len(train_df)).astype('float32')\ntest_preds_lst = []\n\ntarget_dic = {v:i for i, v in enumerate(sorted(train_df['pressure'].astype('float32').unique().tolist()))}\ntarget_dic_inv = {v: k for k, v in target_dic.items()}\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.093862Z","iopub.execute_input":"2021-10-29T16:12:20.094136Z","iopub.status.idle":"2021-10-29T16:12:20.390977Z","shell.execute_reply.started":"2021-10-29T16:12:20.094092Z","shell.execute_reply":"2021-10-29T16:12:20.390058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df=df\n#target_dict_inv_array=np.zeros(len(target_dic_inv))\ntarget_dict_inv_array=np.array(list(target_dic_inv.values())).astype('float32')\ntarget_dict_inv_array.shape\ntarget_dict_inv_array=torch.tensor(target_dict_inv_array) \n\ndel target_dic_inv","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.392411Z","iopub.execute_input":"2021-10-29T16:12:20.392719Z","iopub.status.idle":"2021-10-29T16:12:20.397796Z","shell.execute_reply.started":"2021-10-29T16:12:20.392656Z","shell.execute_reply":"2021-10-29T16:12:20.397014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target_dict_inv_array[27] ,target_dic ","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.399058Z","iopub.execute_input":"2021-10-29T16:12:20.399531Z","iopub.status.idle":"2021-10-29T16:12:20.40883Z","shell.execute_reply.started":"2021-10-29T16:12:20.399492Z","shell.execute_reply":"2021-10-29T16:12:20.407782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['tc']=train_df['R']*(train_df['C']/1000)\n#test_df['tc']=test_df['R']*(test_df['C']/1000)\n\ntrain_df['id']=train_df.id.astype('int32')\ntrain_df['R']=train_df.R.astype('int32')\ntrain_df['C']=train_df.C.astype('int32')\ntrain_df['u_out']=train_df.u_out.astype('int32')\ntrain_df['time_step']=train_df.time_step.astype('float32')\ntrain_df['u_in']=train_df.u_in.astype('float32')\ntrain_df['pressure']=train_df.pressure.astype('float32')\ntrain_df['kfold']=train_df.kfold.astype('int8')","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.41029Z","iopub.execute_input":"2021-10-29T16:12:20.410625Z","iopub.status.idle":"2021-10-29T16:12:20.91439Z","shell.execute_reply.started":"2021-10-29T16:12:20.410588Z","shell.execute_reply":"2021-10-29T16:12:20.91355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import cudf","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.916048Z","iopub.execute_input":"2021-10-29T16:12:20.916376Z","iopub.status.idle":"2021-10-29T16:12:20.921142Z","shell.execute_reply.started":"2021-10-29T16:12:20.916337Z","shell.execute_reply":"2021-10-29T16:12:20.920398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df=cudf.DataFrame().from_pandas(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.922969Z","iopub.execute_input":"2021-10-29T16:12:20.92354Z","iopub.status.idle":"2021-10-29T16:12:20.930737Z","shell.execute_reply.started":"2021-10-29T16:12:20.923499Z","shell.execute_reply":"2021-10-29T16:12:20.929932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n\n#train_df.groupby(train_df['breath_id'])['u_in'].rolling(window=10, min_periods=1)#.fillna(0)#.quantile(0.9)#.reset_index(level=0,drop=True)     \n#train_df.groupby('breath_id')['u_in'].ewm(halflife=10).mean().reset_index(level=0,drop=True)    \n\n#train_df.groupby('breath_id')['u_in'].expanding(2).mean().reset_index(level=0,drop=True)\n#train_df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).mean().reset_index( drop=True) \nembedding_df=df.iloc[:,2:5]   ","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:12:20.932532Z","iopub.execute_input":"2021-10-29T16:12:20.933057Z","iopub.status.idle":"2021-10-29T16:12:21.161977Z","shell.execute_reply.started":"2021-10-29T16:12:20.933016Z","shell.execute_reply":"2021-10-29T16:12:21.161009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_feature(df):\n    df['time_delta'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['delta'] = df['time_delta'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['delta'].cumsum()\n    \n    #df = df.drop(['time_delta','delta'], axis=1)\n    df = df.drop(['delta'], axis=1)\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df[\"u_out_sum\"] = df.groupby(\"breath_id\")[\"u_out\"].transform(\"sum\").astype('int32')\n    df['cycle_last_ts']=df.groupby(['breath_id','u_out'])['time_step'].transform('max') \n    df['cycle_last_ts_diff']=df['cycle_last_ts']-df['time_step']\n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1).fillna(0).astype('float32')\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1).fillna(0).astype('float32')\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2).fillna(0).astype('float32')\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2).fillna(0).astype('float32')\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    #df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3).fillna(0).astype('float32')\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    #df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3).fillna(0).astype('float32')\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    #df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4).fillna(0).astype('float32')\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    #df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4).fillna(0).astype('float32')\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    #df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = (df['u_out'] - df['u_out_lag1']).fillna(0).astype('float32')\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = (df['u_out'] - df['u_out_lag2']).fillna(0).astype('float32')\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    #df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    #df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    #df['u_out_diff3'] = (df['u_out'] - df['u_out_lag3']).fillna(0).astype('float32')\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    #df['u_out_diff4'] = (df['u_out'] - df['u_out_lag4']).fillna(0).astype('float32')\n    #df['cross']= df['u_in']*df['u_out']\n    #df['cross2']= df['time_step']*df['u_out']\n\n\n    #https://www.kaggle.com/alexxanderlarko/lgbm-sel-feat-1\n    df['u_in_1st_derivative'] = (df['u_in'].diff().fillna(0) / df['time_step'].diff().fillna(0)).fillna(0)\n    df['expand_mean_1sr_der'] = df.groupby('breath_id')['u_in_1st_derivative'].expanding(2).mean().reset_index(level=0,drop=True)\n    #df['u_in_1st_der_mean10'] = df.groupby('breath_id')['u_in_1st_derivative'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True)\n    #df['time_diff'] = df['time_step']-df['time_step'].shift(1)\n    #df['power'] = df['time_diff']*df['u_in']\n    df['power']=df['time_delta']*df['u_in']\n    df['power_cumsum'] = df.groupby(['breath_id'])['power'].cumsum()\n    df['ewm_u_in_mean'] = df.groupby('breath_id')['u_in'].ewm(halflife=10).mean().reset_index(level=0,drop=True)\n    df['ewm_u_in_std'] = df.groupby('breath_id')['u_in'].ewm(halflife=10).std().reset_index(level=0,drop=True)\n    df['ewm_u_in_corr'] = df.groupby('breath_id')['u_in'].ewm(halflife=10).corr().reset_index(level=0,drop=True)\n    df['delta_u_in'] = abs(df.groupby(df['breath_id'])['u_in'].diff().fillna(0)).reset_index(level=0,drop=True)\n    #cudf\n     \n    df['u_in_1st_der_mean10'] = df.groupby('breath_id')['u_in_1st_derivative'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True)\n    \n    #df['delta_u_in_exp'] = df.groupby(df['breath_id'])['delta_u_in'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True)\n    df['delta_rolling_10_mean'] = df.groupby('breath_id')['delta_u_in'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True)\n    df['delta_rolling_10_max'] = df.groupby('breath_id')['delta_u_in'].rolling(window=10, min_periods=1).max().reset_index(level=0,drop=True)\n    #cudf end\n    df['work']=((df['u_in'] + df['u_in'].shift(1).fillna(0))/2 * df['time_step'].diff().fillna(0)).clip(0,)\n    df['work_roll_10']=df.groupby(df['breath_id'])['work'].rolling(window=10, min_periods=1).sum().reset_index(level=0,drop=True)\n    df['work_roll_15']=df.groupby(df['breath_id'])['work'].rolling(window=15, min_periods=1).sum().reset_index(level=0,drop=True)\n    \n    \n    df['u_in_rol_q0.1'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1).quantile(0.1).reset_index(level=0,drop=True)\n    df['u_in_rol_q0.25'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1).quantile(0.25).reset_index(level=0,drop=True)\n    df['u_in_rol_q0.5'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1).quantile(0.5).reset_index(level=0,drop=True)\n    df['u_in_rol_q0.75'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1).quantile(0.75).reset_index(level=0,drop=True)\n    df['u_in_rol_q0.9'] = df.groupby(df['breath_id'])['u_in'].rolling(window=10, min_periods=1).quantile(0.9).reset_index(level=0,drop=True)     \n    \n    #df['u_in_diff1_back'] = df['u_in'] - df['u_in_lag_back1']\n    #df['u_in_diff2_back'] = df['u_in'] - df['u_in_lag_back2']\n    #df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    #df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n\n    df = df.fillna(0)\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n\n    return df\n\n\ntrain_df = add_feature(train_df)\n#test_df = add_feature(test_df)\n\nids = train_df[['id']].values.reshape(-1, 80)\n#print(train_df.shape)\n\n#print(len(X_all))\n#ids.shape\n","metadata":{"executionInfo":{"elapsed":200419,"status":"ok","timestamp":1634253088800,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"StVYFPOZtj-x","execution":{"iopub.status.busy":"2021-10-29T16:12:21.164221Z","iopub.execute_input":"2021-10-29T16:12:21.164864Z","iopub.status.idle":"2021-10-29T16:18:47.502478Z","shell.execute_reply.started":"2021-10-29T16:12:21.164825Z","shell.execute_reply":"2021-10-29T16:18:47.50163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:18:47.504024Z","iopub.execute_input":"2021-10-29T16:18:47.504316Z","iopub.status.idle":"2021-10-29T16:18:47.517661Z","shell.execute_reply.started":"2021-10-29T16:18:47.504281Z","shell.execute_reply":"2021-10-29T16:18:47.516546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def add_feature(df):\n#     df['time_delta'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n#     df['delta'] = df['time_delta'] * df['u_in']\n#     df['area'] = df.groupby('breath_id')['delta'].cumsum()\n\n#     df = df.drop(['time_delta','delta'], axis=1)\n\n#     df['cross']= df['u_in']*df['u_out']\n#     df['cross2']= df['time_step']*df['u_out']\n    \n#     df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n#     df['one'] = 1\n#     df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n#     df['u_in_cummean'] =df['u_in_cumsum'] / df['count']\n    \n#     df = df.drop(['count','one'], axis=1)\n\n#     df['breath_id_lag1']=df['breath_id'].shift(1).fillna(0)\n#     df['breath_id_lag1same']=np.select([df['breath_id_lag1']==df['breath_id']], [1], 0)\n#     df['u_in_lag_1'] = df['u_in'].shift(1).fillna(0) * df[f'breath_id_lag1same']\n#     df['u_in_time1'] = df['u_in'] - df['u_in_lag_1']\n#     df['u_out_lag_1'] = df['u_out'].shift(1).fillna(0) * df['breath_id_lag1same']\n\n#     df['breath_id_lag2']=df['breath_id'].shift(1).fillna(0)\n#     df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']], [1], 0)\n#     df['u_in_lag_2'] = df['u_in'].shift(1).fillna(0) * df[f'breath_id_lag1same']\n#     df['u_in_time2'] = df['u_in'] - df['u_in_lag_2']\n#     df['u_out_lag_2'] = df['u_out'].shift(1).fillna(0) * df['breath_id_lag2same']\n\n#     df['breath_id_lag3']=df['breath_id'].shift(1).fillna(0)\n#     df['breath_id_lag3same']=np.select([df['breath_id_lag3']==df['breath_id']], [1], 0)\n#     df['u_in_lag_3'] = df['u_in'].shift(1).fillna(0) * df[f'breath_id_lag3same']\n#     df['u_in_time3'] = df['u_in'] - df['u_in_lag_3']\n#     df['u_out_lag_3'] = df['u_out'].shift(1).fillna(0) * df['breath_id_lag3same']\n\n#     df['breath_id_lag4']=df['breath_id'].shift(1).fillna(0)\n#     df['breath_id_lag4same']=np.select([df['breath_id_lag4']==df['breath_id']], [1], 0)\n#     df['u_in_lag_4'] = df['u_in'].shift(1).fillna(0) * df[f'breath_id_lag4same']\n#     df['u_in_time4'] = df['u_in'] - df['u_in_lag_4']\n#     df['u_out_lag_4'] = df['u_out'].shift(1).fillna(0) * df['breath_id_lag4same']\n\n#     drop_columns = ['breath_id_lag1', 'breath_id_lag2', 'breath_id_lag3', 'breath_id_lag4', \n#                     'breath_id_lag1same', 'breath_id_lag2same', 'breath_id_lag3same', 'breath_id_lag4same']\n\n#     df = df.drop(drop_columns, axis=1)\n\n#     c_dic = {10: 0, 20: 1, 50:2}\n#     r_dic = {5: 0, 20: 1, 50:2}\n#     rc_sum_dic = {v: i for i, v in enumerate([15, 25, 30, 40, 55, 60, 70, 100])}\n#     rc_dot_dic = {v: i for i, v in enumerate([50, 100, 200, 250, 400, 500, 2500, 1000])}    \n\n#     df['C_cate'] = df['C'].map(c_dic)\n#     df['R_cate'] = df['R'].map(r_dic)\n#     df['RC_sum'] = (df['R'] + df['C']).map(rc_sum_dic)\n#     df['RC_dot'] = (df['R'] * df['C']).map(rc_dot_dic)\n#     df = df.drop(['R','C'], axis=1)\n\n#     # fill na by zero\n#     df = df.fillna(0)\n\n#     return df\n\n\n# train_df = add_feature(train_df)\n# test_df = add_feature(test_df)\n\n\n","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1634253088801,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"UOFif_TGDTxp","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-29T16:18:47.519802Z","iopub.execute_input":"2021-10-29T16:18:47.520242Z","iopub.status.idle":"2021-10-29T16:18:47.526326Z","shell.execute_reply.started":"2021-10-29T16:18:47.5202Z","shell.execute_reply":"2021-10-29T16:18:47.525322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#targets = train_df[['pressure']].to_numpy().reshape(-1, 80)\n#u_outs = train_df[['u_out']].to_numpy().reshape(-1, 80)\n#u_outs = train_df['u_out'] \nkfolds = train_df[['kfold']] #.to_numpy().reshape(-1, 80)\ntrain_breathid = train_df.breath_id.values \n#test_breathid = test_df.breath_id.values\ntrain_ids = train_df.id.values\n#test_ids = test_df.id.values \n\ntrain_pressure = train_df.pressure.values\n# test_pressure = test.pressure.values \n\ntrain_df.drop(['pressure', 'id', 'breath_id', 'kfold'], axis=1, inplace=True)\n#test_df = test_df.drop(['id', 'breath_id'], axis=1)\n#train_df.shape, test_df.shape","metadata":{"executionInfo":{"elapsed":4106,"status":"ok","timestamp":1634253092902,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"EjbwXyXZDZvp","outputId":"497aa28d-fbfe-4abe-e985-9617d0ed7cb8","execution":{"iopub.status.busy":"2021-10-29T16:18:47.533475Z","iopub.execute_input":"2021-10-29T16:18:47.533695Z","iopub.status.idle":"2021-10-29T16:18:48.122604Z","shell.execute_reply.started":"2021-10-29T16:18:47.53367Z","shell.execute_reply":"2021-10-29T16:18:48.121824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ojus1/Time2Vec-PyTorch/ ","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:18:48.123906Z","iopub.execute_input":"2021-10-29T16:18:48.124203Z","iopub.status.idle":"2021-10-29T16:18:48.82966Z","shell.execute_reply.started":"2021-10-29T16:18:48.124166Z","shell.execute_reply":"2021-10-29T16:18:48.828333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nsys.path.append('/kaggle/working/Time2Vec-PyTorch/')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:18:48.831251Z","iopub.execute_input":"2021-10-29T16:18:48.831575Z","iopub.status.idle":"2021-10-29T16:18:48.837793Z","shell.execute_reply.started":"2021-10-29T16:18:48.831531Z","shell.execute_reply":"2021-10-29T16:18:48.837088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Model import *\nModel(\"sin\", 8)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:18:48.839121Z","iopub.execute_input":"2021-10-29T16:18:48.839403Z","iopub.status.idle":"2021-10-29T16:18:48.855612Z","shell.execute_reply.started":"2021-10-29T16:18:48.839368Z","shell.execute_reply":"2021-10-29T16:18:48.854984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traincols = train_df.columns\n\n#train_df['u_out_orig']=df['u_out'].values\n\nRS = RobustScaler()\ntrain_df = RS.fit_transform(train_df[traincols])\ntrain_df=train_df.astype('float32')\n\n#train_df.shape, test_df.shape,len(traincols),len(testcols)\n","metadata":{"executionInfo":{"elapsed":13039,"status":"ok","timestamp":1634253105938,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"joiL3h0oDaj1","outputId":"f46708ad-69f2-472b-aa57-96bfc0a5296d","execution":{"iopub.status.busy":"2021-10-29T16:18:48.856895Z","iopub.execute_input":"2021-10-29T16:18:48.857185Z","iopub.status.idle":"2021-10-29T16:19:02.509307Z","shell.execute_reply.started":"2021-10-29T16:18:48.857141Z","shell.execute_reply":"2021-10-29T16:19:02.505919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df=train_df.astype('float32')\nimport gc\ngc.collect()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.513228Z","iopub.execute_input":"2021-10-29T16:19:02.514079Z","iopub.status.idle":"2021-10-29T16:19:02.864638Z","shell.execute_reply.started":"2021-10-29T16:19:02.514043Z","shell.execute_reply":"2021-10-29T16:19:02.86361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dtype\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.866146Z","iopub.execute_input":"2021-10-29T16:19:02.86758Z","iopub.status.idle":"2021-10-29T16:19:02.880094Z","shell.execute_reply.started":"2021-10-29T16:19:02.867509Z","shell.execute_reply":"2021-10-29T16:19:02.879384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from periodic_activations import SineActivation , CosineActivation,t2v\nfrom Data import ToyDataset\nfrom torch import nn\nimport torch","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.881768Z","iopub.execute_input":"2021-10-29T16:19:02.882072Z","iopub.status.idle":"2021-10-29T16:19:02.889088Z","shell.execute_reply.started":"2021-10-29T16:19:02.882033Z","shell.execute_reply":"2021-10-29T16:19:02.888305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nclass SineActivation(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(SineActivation, self).__init__()\n        self.out_features = out_features\n        self.w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n        self.b0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n        self.w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n        self.b = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n        self.f = torch.sin\n\n    def forward(self, tau):\n        return t2v(tau, self.f, self.out_features, self.w, self.b, self.w0, self.b0)\n\n\ndef t2v1(tau, f, out_features, w, b, w0, b0, arg=None):\n    if arg:\n        v1 = f(torch.matmul(tau, w) + b, arg)\n    else:\n        #print(w.shape, tau.shape, b.shape)\n        v1 = f(torch.matmul(tau, w) + b)\n    v2 = torch.matmul(tau, w0) + b0\n    #print(v1.shape,v2.shape)\n    return torch.cat([v1, v2], -1)\nt2v=t2v1\n\nclass Model(nn.Module):\n    def __init__(self, activation, hiddem_dim):\n        super(Model, self).__init__()\n        if activation == \"sin\":\n            self.l1 = SineActivation(1, hiddem_dim)\n        elif activation == \"cos\":\n            self.l1 = CosineActivation(1, hiddem_dim)\n        \n        self.fc1 = nn.Linear(hiddem_dim, 2)\n    \n    def forward(self, x):\n        #x = x.unsqueeze(1)\n        x = self.l1(x)\n        x = self.fc1(x)\n        return x\nclass VPPModel(tez.Model):\n    \n    \n    def __init__(self, learning_rate):\n        hidden = [768, 512, 256, 128]\n        super().__init__()\n        self.learning_rate = learning_rate\n        # self.loss_fct = custom_ce_loss()\n        self.step_scheduler_after = \"batch\" #\"epoch\"\n        self.time_step=Model(\"sin\", 8)\n        self.u_in=Model(\"sin\", 8)\n        self.r=nn.Embedding(3,2)\n        self.c=nn.Embedding(3,2)\n\n        #self.lstm = nn.LSTM(len(args.ALL_FEATURES), args.HIDDEN_SIZE, batch_first=True, bidirectional=True, dropout=0.0, num_layers=4)\n        # self.head = nn.Linear(args.HIDDEN_SIZE * 2,950)\n        '''\n        self.head = nn.Sequential(\n            nn.Linear(args.HIDDEN_SIZE * 2, args.HIDDEN_SIZE * 2),\n            nn.LayerNorm(args.HIDDEN_SIZE * 2),\n            nn.ReLU(),\n            nn.Linear(args.HIDDEN_SIZE * 2, 950),\n        )\n        '''\n        \n        self.head = nn.Sequential(\n            nn.Linear( hidden[3] * 2, hidden[3] * 2),\n            nn.LayerNorm( hidden[3] * 2),\n            nn.ReLU(),\n            nn.Linear( hidden[3] * 2, 950),\n        )\n        \n        self.lstm1 = nn.LSTM( len(traincols)+1+2+2, hidden[0],\n                             batch_first=True, bidirectional=True)\n        self.gru = nn.LSTM(2 * hidden[0], hidden[0],\n                             batch_first=True, bidirectional=True)\n        self.lstm3 = nn.LSTM(2 * hidden[0], hidden[2],\n                             batch_first=True, bidirectional=True)\n        self.lstm4 = nn.LSTM(2 * hidden[2], hidden[3],\n                             batch_first=True, bidirectional=True)\n        \n        \n        self._reinitialize()\n        \n        '''\n        # LSTM\n        for n, m in self.named_modules():\n            if isinstance(m, nn.LSTM):\n                print(f'init {m}')\n                for param in m.parameters():\n                    if len(param.shape) >= 2:\n                        nn.init.orthogonal_(param.data)\n                    else:\n                        nn.init.normal_(param.data)\n        '''\n                        \n    def _reinitialize(self):\n        \"\"\"\n        Tensorflow/Keras-like initialization\n        \"\"\"\n        for name, p in self.named_parameters():\n            if 'lstm' in name:\n                if 'weight_ih' in name:\n                    nn.init.xavier_uniform_(p.data)\n                    #nn.init.orthogonal_(p.data)\n                elif 'weight_hh' in name:\n                    nn.init.orthogonal_(p.data)\n                elif 'bias_ih' in name:\n                    p.data.fill_(0)\n                    # Set forget-gate bias to 1\n                    n = p.size(0)\n                    p.data[(n // 4):(n // 2)].fill_(1)\n                elif 'bias_hh' in name:\n                    p.data.fill_(0)\n            elif 'fc' in name or 'conv1' in name:\n                if 'weight' in name:\n                    #nn.init.xavier_uniform_(p.data)\n                    nn.init.normal_(p.data)\n                elif 'bias' in name:\n                    p.data.fill_(0)\n\n    \n    \n    \n    def custom_ce_loss(self, logits=None, y=None, u_out=None):\n        criterion = nn.CrossEntropyLoss()\n\n        loss = criterion(logits.reshape(-1, 950), y.reshape(-1))\n\n        for lag, w in [(1, 0.4), (2, 0.2), (3, 0.1), (4, 0.1)]:\n            # negative lag loss\n            # if target < 0, target = 0\n            neg_lag_target = F.relu(y.reshape(-1) - lag)\n            neg_lag_target = neg_lag_target.long()\n            neg_lag_loss = criterion(logits.reshape(-1, 950), neg_lag_target)\n\n            # positive lag loss\n            # if target > 949, target = 949\n            pos_lag_target = 949 - F.relu((949 - (y.reshape(-1) + lag)))\n            pos_lag_target = pos_lag_target.long()\n            pos_lag_loss = criterion(logits.reshape(-1, 950), pos_lag_target)\n\n            loss += (neg_lag_loss + pos_lag_loss) * w\n\n        return loss\n\n    \n    def monitor_metrics(self, outputs, targets, real_pressure, loss, u_out):\n        w = 1 - u_out     \n        #out = torch.tensor([[target_dic_inv[j.item()] for j in i] for i in torch.argmax(outputs,axis=2)]).to(args.device)\n        out= target_dict_inv_array[torch.argmax(outputs,axis=2)].to(args.device) \n        mae = w * (real_pressure - out).abs()\n        mae = mae.sum(-1) / w.sum(-1) \n        \n        return {\"ce\": loss.item(), \"mae\":mae.mean().item()}\n\n    def fetch_scheduler(self):\n        # sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        #     self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        # )\n        \n        num_train_steps = int((len(train_dataset)/args.batch_size) * args.epochs)  #int(len(train_loader) * args.epochs)\n        num_warmup_steps = int(num_train_steps / 10)\n        #sch = get_cosine_schedule_with_warmup(self.optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n        if resume :\n             print('resume')\n            \n             sch=  torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                  self.optimizer, T_0=40, T_mult=1, eta_min=4e-6, last_epoch=-1\n              )\n        else:\n             sch=  torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n                  self.optimizer, T_0=40, T_mult=2, eta_min=8e-6, last_epoch=-1\n              )\n            \n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate,weight_decay=3e-5)\n        return opt\n\n    def forward(self, X, y=None,real_pressure=None, u_out=None,encod_R=None,encod_C=None):\n        bs = X.shape[0]\n        #print(X[:,:,0].unsqueeze(-1).shape)\n        x_ts=self.time_step(X[:,:,0].unsqueeze(-1) ) # we need (bs,seq len,feature )\n        r_emb=self.r(encod_R)\n        c_emb=self.c(encod_C)\n        #print('ts',X.shape,x_ts.shape)\n        X=torch.cat([x_ts,X[:,:,1:]],dim=-1)\n        #print('cat',X.shape)\n        X=torch.cat([X,r_emb,c_emb],dim=-1)\n        #print('lstm',X.shape)\n        x,_ =self.lstm1(X)\n        x,_=self.gru(x)\n        x, _ = self.lstm3(x)\n        \n        #print('dsl3',l3.size())\n        x, _ = self.lstm4(x)\n        \n        #out, _ = self.lstm(X, None) \n        logits = self.head(x)\n\n        if y is not None:\n            loss = self.custom_ce_loss(logits, y, u_out)\n            \n            # loss = self.loss_fct(\n            #     logits.reshape(-1, 950),\n            #     y.reshape(-1)\n            # ) \n\n            metrics = self.monitor_metrics(logits, y, real_pressure, loss, u_out)\n            # print(\"***\", metrics )\n            return logits, loss, metrics\n\n        return logits, 0, {}\n","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.89076Z","iopub.execute_input":"2021-10-29T16:19:02.891056Z","iopub.status.idle":"2021-10-29T16:19:02.929967Z","shell.execute_reply.started":"2021-10-29T16:19:02.891018Z","shell.execute_reply":"2021-10-29T16:19:02.929222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VPPDataset:    \n    def __init__(self, df, label_dic=None,feature_cols=traincols):\n        self.dfs = [_df for _, _df in df.groupby(\"breath_id\")]\n        self.label_dic = label_dic\n        self.features=feature_cols\n        #self.breath_id=df.groupby(\"breath_id\").index.values\n    def __len__(self):\n        return len(self.dfs)\n    \n    def __getitem__(self, item):\n        df = self.dfs[item]\n        #X = df[args.ALL_FEATURES].values     \n        X = df[self.features].values  \n        u_out = df['u_out'].values\n        encod_r=df['encod_R'].values\n        encod_c=df['encod_C'].values\n        if self.label_dic is None:\n            # label = None #[-1]\n            # real_pressure = [-1]\n            pass\n        else:\n            y = self.dfs[item]['pressure'].values\n            #label = [self.label_dic[i] for i in y]\n            label=list(map(lambda i: self.label_dic[i],y))\n            real_pressure = y\n\n        if self.label_dic is None:\n            d = {\n                \"X\": torch.tensor(X).float(),\n                \"u_out\" : torch.tensor(u_out).long(),\n            }            \n        else:\n            d = {\n                \"X\": torch.tensor(X).float(),\n                \"y\" : torch.tensor(label).long(),\n                \"real_pressure\": torch.tensor(real_pressure).float(),\n                \"u_out\" : torch.tensor(u_out).long(),\n                \"encod_R\":torch.tensor(encod_r).long(),\n                \"encod_C\":torch.tensor(encod_c).long()\n            }\n            #print(torch.tensor(u_out).long().sum())\n        \n        return d","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.931566Z","iopub.execute_input":"2021-10-29T16:19:02.931752Z","iopub.status.idle":"2021-10-29T16:19:02.944533Z","shell.execute_reply.started":"2021-10-29T16:19:02.931731Z","shell.execute_reply":"2021-10-29T16:19:02.943561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.945723Z","iopub.execute_input":"2021-10-29T16:19:02.946095Z","iopub.status.idle":"2021-10-29T16:19:02.957248Z","shell.execute_reply.started":"2021-10-29T16:19:02.946059Z","shell.execute_reply":"2021-10-29T16:19:02.95638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VentilatorLoss(nn.Module):\n    \"\"\"\n    Directly optimizes the competition metric\n    \"\"\"\n    def __call__(self, logits=None, y=None, u_out=None):\n        #w = 1 - u_out\n        #w=torch.ones(2,80) if u_out is None else u_out\n        #print(w.size(),y.size(),preds.size())\n        #print(w.sum(-1),preds,'preds')\n        #print(y)\n        #mae = w * (y - preds.squeeze(-1)).abs()\n        #mae = mae.sum(-1) / w.sum(-1)\n        criterion = nn.CrossEntropyLoss()\n\n        loss = criterion(logits.reshape(-1, 950), y.reshape(-1))\n\n        for lag, w in [(1, 0.4), (2, 0.2), (3, 0.1), (4, 0.1)]:\n            # negative lag loss\n            # if target < 0, target = 0\n            neg_lag_target = F.relu(y.reshape(-1) - lag)\n            neg_lag_target = neg_lag_target.long()\n            neg_lag_loss = criterion(logits.reshape(-1, 950), neg_lag_target)\n\n            # positive lag loss\n            # if target > 949, target = 949\n            pos_lag_target = 949 - F.relu((949 - (y.reshape(-1) + lag)))\n            pos_lag_target = pos_lag_target.long()\n            pos_lag_loss = criterion(logits.reshape(-1, 950), pos_lag_target)\n\n            loss += (neg_lag_loss + pos_lag_loss) * w\n\n        return loss\n\n        return mae","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.958804Z","iopub.execute_input":"2021-10-29T16:19:02.959407Z","iopub.status.idle":"2021-10-29T16:19:02.968395Z","shell.execute_reply.started":"2021-10-29T16:19:02.959371Z","shell.execute_reply":"2021-10-29T16:19:02.967429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VentilatorLoss_val(nn.Module):\n    \"\"\"\n    Directly optimizes the competition metric\n    \"\"\"\n    def __call__(self, preds, y, u_out=None):\n        #w = 1 - u_out\n        out = torch.tensor([[target_dic_inv[j.item()] for j in i] for i in torch.argmax(outputs,axis=2)]).to(args.device)\n         \n        w=torch.ones(2,80) if u_out is None else u_out\n        #print(w.size(),y.size(),preds.size())\n        #print(w.sum(-1),preds,'preds')\n        #print(y)\n        mae = w * (y - preds.squeeze(-1)).abs()\n        mae = mae.sum(-1) / w.sum(-1)\n\n        return mae","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.969896Z","iopub.execute_input":"2021-10-29T16:19:02.970413Z","iopub.status.idle":"2021-10-29T16:19:02.980189Z","shell.execute_reply.started":"2021-10-29T16:19:02.970377Z","shell.execute_reply":"2021-10-29T16:19:02.979438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def custom_ce_loss(self, logits=None, y=None, u_out=None):\n        criterion = nn.CrossEntropyLoss()\n\n        loss = criterion(logits.reshape(-1, 950), y.reshape(-1))\n\n        for lag, w in [(1, 0.4), (2, 0.2), (3, 0.1), (4, 0.1)]:\n            # negative lag loss\n            # if target < 0, target = 0\n            neg_lag_target = F.relu(y.reshape(-1) - lag)\n            neg_lag_target = neg_lag_target.long()\n            neg_lag_loss = criterion(logits.reshape(-1, 950), neg_lag_target)\n\n            # positive lag loss\n            # if target > 949, target = 949\n            pos_lag_target = 949 - F.relu((949 - (y.reshape(-1) + lag)))\n            pos_lag_target = pos_lag_target.long()\n            pos_lag_loss = criterion(logits.reshape(-1, 950), pos_lag_target)\n\n            loss += (neg_lag_loss + pos_lag_loss) * w\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.981712Z","iopub.execute_input":"2021-10-29T16:19:02.982297Z","iopub.status.idle":"2021-10-29T16:19:02.991281Z","shell.execute_reply.started":"2021-10-29T16:19:02.982258Z","shell.execute_reply":"2021-10-29T16:19:02.990515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#criterion = VentilatorLoss()\n#criterion_val= VentilatorLoss_val()\n#VentilatorLoss()\ndef evaluate(model, loader_val):\n    tb = time.time()\n    was_training = model.training\n    model.eval()\n\n    loss_sum = 0\n    score_sum = 0\n    n_sum = 0\n    y_pred_all = []\n    losses_val=AverageMeter()\n    for ibatch, (x, y, w) in enumerate(loader_val):\n        n = y.size(0)\n        x = x.to(device)\n        y = y.to(device)\n        w = w.to(device)\n\n        with torch.no_grad():\n            y_pred = model(x).squeeze()\n\n        #loss = criterion(y_pred, y)\n        loss = criterion_val(y_pred, y,w).mean()\n        losses_val.update(loss.item(),n)\n        n_sum += n\n        loss_sum += n*loss.item()\n        if ibatch % 10 == 0 or ibatch == (len(loader_val)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      #'Elapsed {remain:s} '\n                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                      #'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.6f}  '\n                      .format(\n                       iepoch+1, ibatch, len(loader_val),\n                       #remain=timeSince(start, float(step+1)/len(train_loader)),\n                       loss=losses_val,\n                       \n                       lr=1e-3,\n                       ))\n        \n        y_pred_all.append(y_pred.cpu().detach().numpy())\n\n    loss_val = loss_sum / n_sum\n\n    model.train(was_training)\n\n    d = {'loss': loss_val,\n         'time': time.time() - tb,\n         'y_pred': np.concatenate(y_pred_all, axis=0)}\n\n    return d\n","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:02.992573Z","iopub.execute_input":"2021-10-29T16:19:02.992939Z","iopub.status.idle":"2021-10-29T16:19:03.006344Z","shell.execute_reply.started":"2021-10-29T16:19:02.992812Z","shell.execute_reply":"2021-10-29T16:19:03.005378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm as tqdm\nfrom torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR,ReduceLROnPlateau,CosineAnnealingWarmRestarts","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.007444Z","iopub.execute_input":"2021-10-29T16:19:03.008174Z","iopub.status.idle":"2021-10-29T16:19:03.017756Z","shell.execute_reply.started":"2021-10-29T16:19:03.0081Z","shell.execute_reply":"2021-10-29T16:19:03.016757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ids = train[['id']].values.reshape(-1, 80)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.019145Z","iopub.execute_input":"2021-10-29T16:19:03.019655Z","iopub.status.idle":"2021-10-29T16:19:03.026686Z","shell.execute_reply.started":"2021-10-29T16:19:03.019615Z","shell.execute_reply":"2021-10-29T16:19:03.025879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\nnfold = 5\nkfold = KFold(n_splits=nfold, shuffle=True, random_state=228)\nepochs = 2 if debug else 292\nlr = 1e-3\nbatch_size = 768\nmax_grad_norm = 1000\nimport time\nlog = {}\noof_pred = []\noof_target = []\noof_ids=[]\nfor ifold, (idx_train, idx_val) in enumerate(kfold.split(X_all)):\n    \n    tb = time.time()\n    model = Model(input_size)\n    model.to(device)\n    model.train()\n    if ifold >=2: # due to time limit\n        continue\n    print('Fold %d' % ifold)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=3e-5)\n    #scheduler = ReduceLROnPlateau(optimizer, factor=0.55, patience=10,verbose=True)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, 28, 2,eta_min=3e-5)\n \n    X_train = X_all[idx_train]\n    y_train = y_all[idx_train]\n    w_train = w_all[idx_train]\n    ids_val=ids[idx_val]\n    X_val = X_all[idx_val]\n    y_val = y_all[idx_val]\n    w_val = w_all[idx_val]\n\n    dataset_train = Dataset(X_train, y_train, w_train)\n    dataset_val = Dataset(X_val, y_val, w_val)\n    loader_train = torch.utils.data.DataLoader(dataset_train, shuffle=False,\n                         batch_size=batch_size, drop_last=True)\n    loader_val = torch.utils.data.DataLoader(dataset_val, shuffle=False,\n                         batch_size=batch_size, drop_last=False)\n    \n     \n    scheduler1=OneCycleLR(optimizer, 1.5e-3, total_steps=len(loader_train)*batch_size\n                                 ,cycle_momentum=False, \n                                 pct_start=0.6, anneal_strategy='cos',\n                                 div_factor=30.0, final_div_factor=1,\n                                 last_epoch=-1, verbose=False)\n     \n    #scheduler = ReduceLROnPlateau(optimizer, factor=0.6, patience=10)\n    \n    losses_train = []\n    losses_val = []\n    lrs = []\n    time_val = 0\n    best_score = np.inf\n   \n    print('epoch loss_train loss_val lr time')\n    best_score=np.inf\n     \n    for iepoch in range(epochs):\n        loss_train = 0\n        n_sum = 0\n        losses = AverageMeter()\n        for ibatch, (x, y, w) in enumerate(tqdm(loader_train)):\n            n = y.size(0)\n            x = x.to(device)\n            y = y.to(device)\n            w = w.to(device)\n            optimizer.zero_grad()\n\n            y_pred = model(x).squeeze()\n            loss = criterion_val(y_pred,y )\n            #loss = criterion_val(y_pred, y,w).mean()\n            losses.update(loss.item(),n)\n            loss_train += n*loss.item()\n            n_sum += n\n\n            loss.backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n            if ibatch % 30 == 0 or ibatch == (len(loader_train)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      #'Elapsed {remain:s} '\n                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                      #'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.6f}  '\n                      .format(\n                       iepoch+1, ibatch, len(loader_train),\n                       #remain=timeSince(start, float(step+1)/len(train_loader)),\n                       loss=losses,\n                       \n                       #lr=1e-3,\n                       lr=scheduler.get_last_lr()[-1] \n                       ))\n\n            optimizer.step()\n            scheduler.step()\n        #scheduler.step()\n        val = evaluate(model, loader_val)\n        \n        loss_val = val['loss']\n        time_val += val['time']\n        if val['loss']<best_score:\n            best_score=val['loss']\n            \n            print('saving best wt',best_score)\n            time.sleep(1)\n            torch.save(model.state_dict(),f'fold_best{ifold}.pt')\n        losses_train.append(loss_train / n_sum)\n        losses_val.append(val['loss'])\n        lrs.append(optimizer.param_groups[0]['lr'])\n\n        print('%3d %9.6f %9.6f %7.3e %7.1f %6.1f' %\n              (iepoch + 1,\n               losses_train[-1], losses_val[-1], \n               lrs[-1], time.time() - tb, time_val))\n\n        #scheduler.step(losses_val[-1])\n        #capure oof\n        #oof_pred.append( val['y_pred'])\n        #oof_target.append(y_val)\n        #oof_ids.append(ids_val)\n     \n    print('generate fold',ifold ,' oofs')\n    model.load_state_dict(torch.load(f'/kaggle/working/fold_best{ifold}.pt'))\n    val = evaluate(model, loader_val)\n    oof_pred.append(val['y_pred'])\n    oof_target.append(y_val)\n    oof_ids.append(ids_val)\n    #oof_target=np.concatenate(oof_target)\n    #oof_ids=np.concatenate(oof_ids)\n    #ofilename = 'model%d.pth' % ifold\n    #torch.save(model.state_dict(), ofilename)\n    #print(ofilename, 'written')\n\n    log['fold%d' % ifold] = {\n        'loss_train': np.array(losses_train),\n        'loss_val': np.array(losses_val),\n        'learning_rate': np.array(lrs),\n        'y_pred': val['y_pred'],\n        'idx': idx_val\n    }\n'''","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-29T16:19:03.027892Z","iopub.execute_input":"2021-10-29T16:19:03.028439Z","iopub.status.idle":"2021-10-29T16:19:03.040315Z","shell.execute_reply.started":"2021-10-29T16:19:03.028401Z","shell.execute_reply":"2021-10-29T16:19:03.039543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df=train_df.astype('float32')\n#train_df.dtype","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.041583Z","iopub.execute_input":"2021-10-29T16:19:03.042217Z","iopub.status.idle":"2021-10-29T16:19:03.049744Z","shell.execute_reply.started":"2021-10-29T16:19:03.042178Z","shell.execute_reply":"2021-10-29T16:19:03.048961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(train_df,columns=traincols)\n#test_df = pd.DataFrame(test_df,columns=testcols)\ntest=False\nif test:\n    \n    testcols = test_df.columns\n    test_df = RS.transform(test_df[testcols])\n    test_df=test_df.astype('float32')\n    test_df['breath_id'] = test_breathid\n    test_df['id'] = test_ids\n    print(test_df.shape)\n\ntrain_df['breath_id'] = train_breathid\n#test_df['breath_id'] = test_breathid\ntrain_df['pressure'] = train_pressure\ntrain_df['id'] = train_ids\n\ntrain_df['kfold'] = kfolds.kfold\n\ntrain_df.shape","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1634253105939,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"243NfBFEDdEo","outputId":"f88ac1cb-93e1-4bff-fbfc-977fc3226ffe","execution":{"iopub.status.busy":"2021-10-29T16:19:03.051317Z","iopub.execute_input":"2021-10-29T16:19:03.051842Z","iopub.status.idle":"2021-10-29T16:19:03.090625Z","shell.execute_reply.started":"2021-10-29T16:19:03.051806Z","shell.execute_reply":"2021-10-29T16:19:03.089895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()\n\nr_mapping={5:0,20:1,50:2}\n\nc_mapping={10:0,20:1,50:2}\n\nembedding_df['encod_R']=embedding_df['R'].map(r_mapping)\nembedding_df['encod_C']=embedding_df['C'].map(c_mapping)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.092165Z","iopub.execute_input":"2021-10-29T16:19:03.09265Z","iopub.status.idle":"2021-10-29T16:19:03.279898Z","shell.execute_reply.started":"2021-10-29T16:19:03.092614Z","shell.execute_reply":"2021-10-29T16:19:03.279014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#r_mapping[20]","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.281765Z","iopub.execute_input":"2021-10-29T16:19:03.282311Z","iopub.status.idle":"2021-10-29T16:19:03.295608Z","shell.execute_reply.started":"2021-10-29T16:19:03.28227Z","shell.execute_reply":"2021-10-29T16:19:03.29495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#enc_cat_mapping={'time_step':0,'encod_R':1,'encod_C':2}\n#enc_cat_columns=['encod_R','encod_C','time_step']","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.29854Z","iopub.execute_input":"2021-10-29T16:19:03.29907Z","iopub.status.idle":"2021-10-29T16:19:03.307765Z","shell.execute_reply.started":"2021-10-29T16:19:03.299028Z","shell.execute_reply":"2021-10-29T16:19:03.306171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.concat([train_df,embedding_df.iloc[:,-2:]],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:03.310742Z","iopub.execute_input":"2021-10-29T16:19:03.311453Z","iopub.status.idle":"2021-10-29T16:19:04.974595Z","shell.execute_reply.started":"2021-10-29T16:19:03.311413Z","shell.execute_reply":"2021-10-29T16:19:04.97381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:19:04.976052Z","iopub.execute_input":"2021-10-29T16:19:04.976332Z","iopub.status.idle":"2021-10-29T16:19:04.984186Z","shell.execute_reply.started":"2021-10-29T16:19:04.976298Z","shell.execute_reply":"2021-10-29T16:19:04.983168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = train_df[train_df.kfold != args.fold].reset_index(drop=True)\ndf_valid = train_df[train_df.kfold == args.fold].reset_index(drop=True)\n\ntrain_dataset = VPPDataset(\n        df = df_train[list(traincols)+['breath_id','encod_R','encod_C' ,'pressure']],\n        label_dic = target_dic,\n        feature_cols=traincols\n    )\n\nvalid_dataset = VPPDataset(\n    df = df_valid[list(traincols)+['breath_id','encod_R','encod_C' ,'pressure']],\n    label_dic = target_dic,\n    feature_cols=traincols\n)\n\ndel train_df\ngc.collect()","metadata":{"executionInfo":{"elapsed":9601,"status":"ok","timestamp":1634253115526,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"KXobScFnskW2","execution":{"iopub.status.busy":"2021-10-29T16:21:39.742553Z","iopub.execute_input":"2021-10-29T16:21:39.743308Z","iopub.status.idle":"2021-10-29T16:21:47.134872Z","shell.execute_reply.started":"2021-10-29T16:21:39.743267Z","shell.execute_reply":"2021-10-29T16:21:47.134086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!cp ../input/ventilator-train-classification-ce-pytorch-optim/model_f0_r1.bin /kaggle/working/ \n\n#sample_data=train_dataset[0] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\nSineAct=SineActivation\nsineact = SineAct(1, 64)\ncosact = CosineActivation(1, 64)\n#print(torch.randn(2,80,1).shape)\nprint(sineact(torch.randn(2,80,1)).shape)\n#print(cosact(torch.Tensor([[7]])).shape)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:20:35.467938Z","iopub.execute_input":"2021-10-29T16:20:35.468246Z","iopub.status.idle":"2021-10-29T16:20:35.473947Z","shell.execute_reply.started":"2021-10-29T16:20:35.468212Z","shell.execute_reply":"2021-10-29T16:20:35.473137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del model\nresume=False\nif resume :\n    model=VPPModel(learning_rate = 7e-4)\n    #model.load_state_dict(torch.load('/kaggle/working/model_f0_r1.bin'))\n    #model.to(args.device)\n    #model.eval()\nelse:\n    model = VPPModel(learning_rate = args.learning_rate)\n\nes = EarlyStopping(\n    monitor= \"valid_mae\",\n    model_path=f\"{args.output_folder}/model_f{args.fold}.bin\",\n    patience=120,\n    mode=\"min\",\n    save_weights_only=True,\n    delta=0.0001\n)\ngc.collect()","metadata":{"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1634253117744,"user":{"displayName":"Rashmi Colab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17272521842766554838"},"user_tz":240},"id":"4zEDFHu6skA9","outputId":"6a5a6826-6721-412b-ce3c-76398b6eb6f0","execution":{"iopub.status.busy":"2021-10-29T16:22:14.39709Z","iopub.execute_input":"2021-10-29T16:22:14.397848Z","iopub.status.idle":"2021-10-29T16:22:15.524414Z","shell.execute_reply.started":"2021-10-29T16:22:14.39781Z","shell.execute_reply":"2021-10-29T16:22:15.523724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nX=sample_data['X'].unsqueeze(0)\ny=sample_data['y'].unsqueeze(0)\nu_out=sample_data['u_out'].unsqueeze(0)\nrp=sample_data['real_pressure'].unsqueeze(0)\neR=sample_data['encod_R'].unsqueeze(0)\neC=sample_data['encod_C'].unsqueeze(0)\nmodel(X,y,rp,u_out,eR,eC)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:22:32.746356Z","iopub.execute_input":"2021-10-29T16:22:32.747173Z","iopub.status.idle":"2021-10-29T16:22:33.340738Z","shell.execute_reply.started":"2021-10-29T16:22:32.74712Z","shell.execute_reply":"2021-10-29T16:22:33.339918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Fold:\",args.fold)\n\ntrain=True\nif train:\n\n    model.fit(\n        train_dataset,\n        valid_dataset=valid_dataset,\n        train_bs=args.batch_size,\n        valid_bs=3 * args.batch_size,\n        device=args.device,\n        epochs=180,\n        callbacks=[es],\n        fp16=args.fp16,\n        accumulation_steps=args.accumulation_steps,\n        n_jobs = 4\n    ) \n","metadata":{"id":"wxifUjsKsh5u","outputId":"ead258c3-166a-4c5c-cff4-491121478716","execution":{"iopub.status.busy":"2021-10-29T16:22:34.975992Z","iopub.execute_input":"2021-10-29T16:22:34.976608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# LSR scheduler\nimport torch\nfrom torch import optim\nfrom matplotlib import pyplot as plt\nmodel = torch.nn.Linear(10, 2)\noptimizer = optim.SGD(model.parameters(), lr=3e-3)\nsteps = 10\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 40, 2)\nlrs=[]\nfor epoch in range(300):\n    for idx in range(62):\n        None\n        #scheduler.step()\n        #print(scheduler.get_lr())\n        scheduler.step()\n        lrs.append(scheduler.get_lr())\n'''","metadata":{"id":"xxT9ni8_U8zU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.plot(lrs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{"id":"AncICxBsDyow"}},{"cell_type":"code","source":"try:\n    \n    del train_dataset\n    gc.collect()\n    gc.collect()\n\n    from tqdm.notebook import tqdm as tqdm\n    #model.load(f\"{args.output_folder}/model_f{args.fold}.bin\", device=\"cuda\", weights_only=True)\n    model.load(f\"{args.output_folder}/model_f{args.fold}.bin\", device=\"cuda\", weights_only=True)\n    valid_predictions = model.predict(valid_dataset, batch_size=args.batch_size, n_jobs=-1)\n\n    final_valid_predictions = []\n    for preds in tqdm(valid_predictions):\n       #out = [[target_dic_inv[j.item()] for j in i] for i in np.argmax(preds,axis=2)]\n        out= target_dict_inv_array[np.argmax(preds,axis=2)] \n        out=out.cpu().numpy()\n        final_valid_predictions.extend(np.array(out).flatten().tolist())\n\n    df_valid = df_valid[[\"id\", \"pressure\", \"u_out\"]]\n    df_valid[\"target\"] = final_valid_predictions \n\n    df_valid.to_csv(f\"{args.output_folder}/valid_predictions_f{args.fold}.csv\", index=False)\nexcept:\n    print('x')\n ","metadata":{"id":"d1Od2_lFX9uc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    df_valid=pd.read_csv(f\"{args.output_folder}/valid_predictions_f{args.fold}.csv\")\n    \n    df_valid['error']=np.abs(df_valid.pressure-df_valid.target)\n    print(df_valid[df_valid.u_out==-1].error.mean())\nexcept:\n    print('x')","metadata":{"id":"-roI3L-EfGUr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{"id":"g_PsP5_oCFHt"}},{"cell_type":"code","source":"'''\ndel train_dataset, valid_dataset\ngc.collect()\n\nsub = pd.read_csv(f'{data_dir}/sample_submission.csv')\n\ntest_dataset = VPPDataset(\n    df = test_df\n)\nmodel = VPPModel(learning_rate = args.learning_rate)\n\nmodel.load(f\"{args.output_folder}/model_f{args.fold}.bin\", device=\"cuda\", weights_only=True)\n\ndel train_df\ngc.collect()\n\ntest_predictions = model.predict(test_dataset, batch_size=args.batch_size, n_jobs=0)\nfinal_test_predictions = []\n\nfor preds in tqdm(test_predictions):\n    out = [[target_dic_inv[j.item()] for j in i] for i in np.argmax(preds,axis=2)]\n    final_test_predictions.extend(np.array(out).flatten().tolist())\n\nsub[\"pressure\"] = final_test_predictions\nsub.to_csv(f\"{args.output_folder}/test_predictions_f{args.fold}.csv\", index=False)\n'''","metadata":{"id":"2L6ZnbzCYHN5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm -rf /kaggle/working/Time2Vec-PyTorch","metadata":{"id":"FDvK8_N14rRP"},"execution_count":null,"outputs":[]}]}