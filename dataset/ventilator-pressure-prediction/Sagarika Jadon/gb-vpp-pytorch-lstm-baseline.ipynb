{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data \n\ntrain= pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest= pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\ntest_ids= test['id'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:42:10.270225Z","iopub.execute_input":"2021-10-27T06:42:10.270877Z","iopub.status.idle":"2021-10-27T06:42:27.858987Z","shell.execute_reply.started":"2021-10-27T06:42:10.270776Z","shell.execute_reply":"2021-10-27T06:42:27.858179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df):\n    dfr= pd.get_dummies(df['R'], prefix= \"R_\")\n    df= pd.concat([df, dfr], axis= 1)\n    dfc= pd.get_dummies(df['C'], prefix= \"C_\")\n    df= pd.concat([df, dfc], axis= 1)\n    df= df.drop(['R', 'C'], axis= 1)\n\n    df['u_in_cumsum']= df['u_in'].groupby(df['breath_id']).cumsum()\n    df['time_step_cumsum']= df['time_step'].groupby(df['breath_id']).cumsum()\n    \n    df['u_in_min']= df['u_in'].groupby(df['breath_id']).transform('min')\n    df['u_in_max']= df['u_in'].groupby(df['breath_id']).transform('max')\n    df['u_in_mean']= df['u_in'].groupby(df['breath_id']).transform('mean')\n   \n    df['u_in_lag2']= df['u_in'].groupby(df['breath_id']).shift(2)\n    df['u_in_lag1']= df['u_in'].groupby(df['breath_id']).shift(1)\n    df['u_in_lag-1']= df['u_in'].groupby(df['breath_id']).shift(-1)\n    df['u_in_lag-2']= df['u_in'].groupby(df['breath_id']).shift(-2)\n    df= df.fillna(0)\n\n    df['u_in_diff1']= df['u_in']- df['u_in_lag1']\n    df['u_in_diff2']= df['u_in']- df['u_in_lag2']\n    df['u_in_diff3']= df['u_in_max']- df['u_in']\n    df['u_in_diff4']= df['u_in_mean']- df['u_in']\n\n    df1= df[df['u_out'] == 0]\n    df['mean_inspiratory_uin']= df1['u_in'].groupby(df['breath_id']).transform('mean')\n\n    df2= df[df['u_out'] == 1]\n    df['mean_expiratory_uin']= df2['u_in'].groupby(df['breath_id']).transform('mean')\n    \n    df['u_in_diff5']= df['mean_inspiratory_uin']- df['u_in']\n    df['u_in_diff6']= df['mean_expiratory_uin']- df['u_in']\n    \n    df= df.fillna(0)\n    \n    df['delta_t']= df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['delta_uin']= df.groupby('breath_id')['u_in'].diff().fillna(0)\n    \n    df['area']= df['u_in']*df['delta_t']\n    df['area']= df.groupby('breath_id')['area'].cumsum()\n    df['slope']= (df['delta_uin']/df['delta_t']).fillna(0)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:42:27.860749Z","iopub.execute_input":"2021-10-27T06:42:27.860998Z","iopub.status.idle":"2021-10-27T06:42:27.875892Z","shell.execute_reply.started":"2021-10-27T06:42:27.860967Z","shell.execute_reply":"2021-10-27T06:42:27.874938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups= train.breath_id.values.reshape(-1, 80)[:, 0]\ngroups.shape\n\ntrain= preprocess(train)\ntargets= train['pressure'].to_numpy().reshape(-1, 80)\ntrain.drop(['id','pressure', \"breath_id\"], axis= 1, inplace= True)\n\ntest= preprocess(test)\ntest.drop(['id', \"breath_id\"], axis= 1, inplace= True)\ny_test= np.zeros(test.shape[0]).reshape(-1, 80)\n\nfrom sklearn.preprocessing import RobustScaler\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest  = RS.transform(test)\n\nnum_features= train.shape[-1]\ntrain= train.reshape(-1, 80, num_features)\ntest= test.reshape(-1, 80, num_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:42:27.877407Z","iopub.execute_input":"2021-10-27T06:42:27.878062Z","iopub.status.idle":"2021-10-27T06:43:46.487196Z","shell.execute_reply.started":"2021-10-27T06:42:27.878025Z","shell.execute_reply":"2021-10-27T06:43:46.486451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset:\n    def __init__(self, data, target):\n        self.data= data\n        self.target= target\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        current_sample= self.data[idx, :, :]\n        current_target= self.target[idx, :]\n        \n        return torch.tensor(current_sample, dtype= torch.float), torch.tensor(current_target, dtype= torch.float)\n     ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.489266Z","iopub.execute_input":"2021-10-27T06:43:46.489527Z","iopub.status.idle":"2021-10-27T06:43:46.495649Z","shell.execute_reply.started":"2021-10-27T06:43:46.489494Z","shell.execute_reply":"2021-10-27T06:43:46.49482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(RNNModel, self).__init__()\n        \n        hidden_dim= [400, 300, 200, 100]\n        self.bilstm1= nn.LSTM(input_dim, hidden_dim[0], batch_first= True, bidirectional= True)\n        self.norm1= nn.LayerNorm(hidden_dim[0]*2)\n        \n        self.bilstm2= nn.LSTM(hidden_dim[0]*2, hidden_dim[1], batch_first= True, bidirectional= True)\n        self.norm2= nn.LayerNorm(hidden_dim[1]*2)\n        \n        self.bilstm3= nn.LSTM(hidden_dim[1]*2, hidden_dim[2], batch_first= True, bidirectional= True)\n        self.norm3= nn.LayerNorm(hidden_dim[2]*2)\n        \n        self.bilstm4= nn.LSTM(hidden_dim[2]*2, hidden_dim[3], batch_first= True, bidirectional= True)\n        self.norm4= nn.LayerNorm(hidden_dim[3]*2)\n        \n        self.fc1= nn.Linear(hidden_dim[3]*2, 100)\n        self.fc2= nn.Linear(100, output_dim)\n\n        \n    def forward(self, X):\n        pred, _= self.bilstm1(X)\n        pred= self.norm1(pred)\n        \n        pred, _= self.bilstm2(pred)\n        pred= self.norm2(pred)\n        \n        pred, _= self.bilstm3(pred)\n        pred= self.norm3(pred)\n        \n        pred, _= self.bilstm4(pred)\n        pred= self.norm4(pred)\n        \n        pred= self.fc1(pred)\n        pred= F.selu(pred)\n        \n        pred= self.fc2(pred)\n        pred= pred.squeeze(dim= 2)\n        return pred","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.496835Z","iopub.execute_input":"2021-10-27T06:43:46.497216Z","iopub.status.idle":"2021-10-27T06:43:46.513155Z","shell.execute_reply.started":"2021-10-27T06:43:46.497172Z","shell.execute_reply":"2021-10-27T06:43:46.512484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_parameters(m):\n    if isinstance(m, nn.LSTM):\n        nn.init.orthogonal_(m.weight_ih_l0.data, gain= nn.init.calculate_gain('tanh'))\n        nn.init.orthogonal_(m.weight_hh_l0.data, gain= nn.init.calculate_gain('tanh'))\n        nn.init.orthogonal_(m.weight_ih_l0_reverse.data, gain= nn.init.calculate_gain('tanh'))\n        nn.init.orthogonal_(m.weight_hh_l0_reverse.data, gain= nn.init.calculate_gain('tanh'))\n        \n        nn.init.constant_(m.bias_ih_l0.data, 0)\n        nn.init.constant_(m.bias_hh_l0.data, 0)\n        nn.init.constant_(m.bias_ih_l0_reverse.data, 0)\n        nn.init.constant_(m.bias_hh_l0_reverse.data, 0)\n        \n    if isinstance(m, nn.Linear):\n        nn.init.xavier_normal_(m.weight.data)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.514357Z","iopub.execute_input":"2021-10-27T06:43:46.514668Z","iopub.status.idle":"2021-10-27T06:43:46.526567Z","shell.execute_reply.started":"2021-10-27T06:43:46.514632Z","shell.execute_reply":"2021-10-27T06:43:46.525822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device= \"cuda\" if torch.cuda.is_available() else 'cpu'\nINPUT_DIM= num_features\nOUTPUT_DIM= 1\nBATCH_SIZE= 1024","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.528159Z","iopub.execute_input":"2021-10-27T06:43:46.528722Z","iopub.status.idle":"2021-10-27T06:43:46.57754Z","shell.execute_reply.started":"2021-10-27T06:43:46.528685Z","shell.execute_reply":"2021-10-27T06:43:46.576821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(dataloader, model, criterion, optimizer):\n    size= len(dataloader.dataset)\n    model.train()\n    batches= len(dataloader)\n    train_loss= 0\n    \n    for batch_idx, (X, y) in enumerate(dataloader):\n        X, y= X.to(device), y.to(device)\n\n        scores= model(X)\n        loss= criterion(scores, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loss= loss.item()\n        train_loss += loss\n        \n    train_loss_avg= train_loss/batches\n    print(f\"avg. train loss: {train_loss_avg}\")\n    return train_loss_avg","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.578953Z","iopub.execute_input":"2021-10-27T06:43:46.579209Z","iopub.status.idle":"2021-10-27T06:43:46.594892Z","shell.execute_reply.started":"2021-10-27T06:43:46.579178Z","shell.execute_reply":"2021-10-27T06:43:46.594201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_model(dataloader, model, criterion):\n    \n    size= len(dataloader.dataset)\n    batches= len(dataloader)\n    model.eval()\n    test_loss= 0\n\n    with torch.no_grad():\n        for X, y in (dataloader):\n            X, y= X.to(device), y.to(device)\n      \n            scores= model(X)\n            test_loss += criterion(scores, y)\n\n    test_loss /= batches\n    print(f\"avg test loss : {test_loss}\")\n    return test_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.598158Z","iopub.execute_input":"2021-10-27T06:43:46.598931Z","iopub.status.idle":"2021-10-27T06:43:46.605428Z","shell.execute_reply.started":"2021-10-27T06:43:46.598895Z","shell.execute_reply":"2021-10-27T06:43:46.604674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_model(dataloader, model):\n    model.eval()\n    y_pred= np.array([])\n    \n    with torch.no_grad():\n        for X , y in dataloader:\n            X, y= X.to(device), y.to(device)\n            \n            preds= model(X)\n            preds= preds.flatten().cpu().numpy()\n            \n            y_pred= np.concatenate((y_pred, preds))\n            \n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.608178Z","iopub.execute_input":"2021-10-27T06:43:46.608499Z","iopub.status.idle":"2021-10-27T06:43:46.615358Z","shell.execute_reply.started":"2021-10-27T06:43:46.608469Z","shell.execute_reply":"2021-10-27T06:43:46.61477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\nkfold= GroupKFold(n_splits= 5)\nEPOCHS= 150\ncv_scores= []\npredictions= np.zeros(test_ids.shape[0])\n\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(train, targets, groups= groups)):\n    X_train, X_val= train[train_idx], train[val_idx]\n    y_train, y_val= targets[train_idx], targets[val_idx]\n    \n    train_dataset= CustomDataset(data= X_train, target= y_train)\n    val_dataset= CustomDataset(data= X_val, target= y_val)\n\n    train_loader= data.DataLoader(train_dataset, batch_size= BATCH_SIZE)\n    val_loader= data.DataLoader(val_dataset, batch_size= BATCH_SIZE)\n    \n    model= RNNModel(input_dim= INPUT_DIM, output_dim= OUTPUT_DIM).to(device)\n    model.apply(initialize_parameters)\n\n    criterion= nn.L1Loss()\n    criterion.to(device)\n\n    optimizer= optim.Adam(model.parameters(), lr= 0.001)\n    scheduler= optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor= 0.5, patience= 10, verbose= True)\n    \n    best_valid_loss= float('inf')\n    \n    avg_train_losses= []\n    avg_val_losses= []\n    \n    for t in range(EPOCHS):\n        print(f\"Epoch: {t+1}\")\n        train_loss= train_model(train_loader, model, criterion, optimizer)\n        val_loss= val_model(val_loader, model, criterion)\n        \n        avg_train_losses.append(train_loss)\n        avg_val_losses.append(val_loss)\n        \n        if (val_loss< best_valid_loss):\n            best_valid_loss= val_loss\n            ofilename = 'ventilator%d.pth' % fold\n            torch.save(model.state_dict(),  ofilename)\n        \n        scheduler.step(val_loss)\n    \n    cv_scores.append(best_valid_loss)\n    \n    test_dataset= CustomDataset(data= test, target= y_test)\n    test_loader= data.DataLoader(test_dataset, batch_size= BATCH_SIZE)\n                       \n    model.load_state_dict(torch.load('ventilator%d.pth' % fold, map_location=device))\n    predictions += (predict_model(test_loader, model)/5)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:43:46.617979Z","iopub.execute_input":"2021-10-27T06:43:46.61819Z","iopub.status.idle":"2021-10-27T06:50:28.660927Z","shell.execute_reply.started":"2021-10-27T06:43:46.618161Z","shell.execute_reply":"2021-10-27T06:50:28.659967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:50:28.671008Z","iopub.execute_input":"2021-10-27T06:50:28.672655Z","iopub.status.idle":"2021-10-27T06:50:28.692368Z","shell.execute_reply.started":"2021-10-27T06:50:28.672616Z","shell.execute_reply":"2021-10-27T06:50:28.691433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub= pd.DataFrame({'id': test_ids, 'pressure': predictions})\nsub.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:50:28.693918Z","iopub.execute_input":"2021-10-27T06:50:28.694205Z","iopub.status.idle":"2021-10-27T06:50:41.815283Z","shell.execute_reply.started":"2021-10-27T06:50:28.69417Z","shell.execute_reply":"2021-10-27T06:50:41.814515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_scores","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:50:41.816337Z","iopub.execute_input":"2021-10-27T06:50:41.816578Z","iopub.status.idle":"2021-10-27T06:50:41.848407Z","shell.execute_reply.started":"2021-10-27T06:50:41.816547Z","shell.execute_reply":"2021-10-27T06:50:41.847612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.plot(avg_train_losses)\n# plt.plot(avg_val_losses)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:50:41.849961Z","iopub.execute_input":"2021-10-27T06:50:41.850273Z","iopub.status.idle":"2021-10-27T06:50:41.854545Z","shell.execute_reply.started":"2021-10-27T06:50:41.850238Z","shell.execute_reply":"2021-10-27T06:50:41.853661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}}]}