{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler #whatever the scaling method you decide\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import GroupKFold #for balanced division of data\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, SequentialSampler","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:18:12.671Z","iopub.execute_input":"2021-10-16T04:18:12.671351Z","iopub.status.idle":"2021-10-16T04:18:12.678095Z","shell.execute_reply.started":"2021-10-16T04:18:12.671315Z","shell.execute_reply":"2021-10-16T04:18:12.67716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/ventilator-pressure-prediction/train.csv'\ntest_path = '../input/ventilator-pressure-prediction/test.csv'","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:18:15.193354Z","iopub.execute_input":"2021-10-16T04:18:15.193628Z","iopub.status.idle":"2021-10-16T04:18:15.197963Z","shell.execute_reply.started":"2021-10-16T04:18:15.193599Z","shell.execute_reply":"2021-10-16T04:18:15.197101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this piece of code is from one of the notebooks here in this competition\ndef difference_operator(df, feature):\n    col_name = f\"{feature}_diff\"\n    df[col_name] = (\n        df[feature].shift(-1).fillna(method=\"ffill\")\n        - df[feature].shift(1).fillna(method=\"bfill\")\n    ) / (\n        df[\"time_step\"].shift(-1).fillna(method=\"ffill\")\n        - df[\"time_step\"].shift(1).fillna(method=\"bfill\")\n    )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:18:52.393417Z","iopub.execute_input":"2021-10-16T04:18:52.393852Z","iopub.status.idle":"2021-10-16T04:18:52.401544Z","shell.execute_reply.started":"2021-10-16T04:18:52.393815Z","shell.execute_reply":"2021-10-16T04:18:52.400534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting some extra features from the main  \"u_in\" feature  MAY help our model!!! \n\ndef get_extra_features(df):   \n    df['state'] = df['R'].astype(str) + '_' + df['C'].astype(str)\n    df = df.merge(pd.get_dummies(df[\"state\"], prefix=\"state\"), left_index=True, right_index=True).drop([\"state\"], axis=1)\n    df['time_diff'] = df['time_step'].diff().fillna(0)\n    df['flow_diff'] = df['u_in'].diff().fillna(0)\n    df['flow_cum'] = df['u_in'].cumsum()\n        \n    df[\"flow_lag1\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(1).fillna(method=\"bfill\")\n    df[\"flow_back1\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-1).fillna(method=\"ffill\"))\n    df[\"flow_lag2\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(2).fillna(method=\"bfill\")\n    df[\"flow_back2\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-2).fillna(method=\"ffill\"))\n    df[\"flow_lag3\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(3).fillna(method=\"bfill\")\n    df[\"flow_back3\"] = (df.groupby(\"breath_id\")[\"u_in\"].shift(-3).fillna(method=\"ffill\"))\n    df[\"time_lag\"] = (df.groupby(\"breath_id\")[\"time_step\"].shift(1).fillna(method=\"bfill\"))\n    df[\"time_back\"] = (df.groupby(\"breath_id\")[\"time_step\"].shift(-1).fillna(method=\"ffill\"))\n\n    df[\"area\"] = df[\"time_back\"] * df[\"u_in\"]\n    df[\"segment\"] = (1-df[\"u_out\"])\n    df[\"area_cum\"] = df.groupby([\"breath_id\"])[\"area\"].cumsum()\n    \n    df['flow_diff2'] = df['u_in']-df['flow_lag1']\n    df['flow_diff3'] = df['u_in']-df['flow_lag2']\n    df['flow_diff4'] = df['u_in']-df['flow_lag3']\n    \n    difference_operator(df, \"u_in\")\n    difference_operator(df, \"u_in_diff\")\n    difference_operator(df, \"u_in_diff_diff\")\n    difference_operator(df, \"u_in_diff_diff_diff\")\n        \n    difference_operator(df, \"area\")\n    difference_operator(df, \"area_diff\")\n    difference_operator(df, \"area_diff_diff\")\n    difference_operator(df, \"area_diff_diff_diff\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:18:54.344342Z","iopub.execute_input":"2021-10-16T04:18:54.344644Z","iopub.status.idle":"2021-10-16T04:18:54.362069Z","shell.execute_reply.started":"2021-10-16T04:18:54.344614Z","shell.execute_reply":"2021-10-16T04:18:54.361141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting our data preprocessed , divided and grouped by 'breath_id'\ndef get_data(scaler= None):\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    train = get_extra_features(train)\n    test = get_extra_features(test)\n    feats = [ 'u_in', 'time_diff','flow_diff','flow_cum', 'flow_lag1', 'flow_back1', 'flow_lag2', 'flow_back2',\n            'flow_lag3', 'flow_back3', 'time_lag', 'time_back', 'area', 'area_cum', \n            'u_in_diff', 'u_in_diff_diff', 'u_in_diff_diff_diff', 'u_in_diff_diff_diff_diff',\n            'area_diff', 'area_diff_diff', 'area_diff_diff_diff', 'area_diff_diff_diff_diff',\n            'flow_diff2', 'flow_diff3', 'flow_diff4']\n    \n    test.loc[:, 'pressure'] = 0\n    test.loc[:, 'fold'] = -1\n    \n    not_to_scale = [ 'state_20_10', 'state_20_20', 'state_20_50', 'state_50_10',\n       'state_50_20', 'state_50_50', 'state_5_10', 'state_5_20', 'state_5_50','segment']\n                              \n    if scaler is not None :                          \n        trans = make_column_transformer((scaler, feats),remainder='passthrough',n_jobs=-1)\n    \n        train[feats] = trans.fit_transform(train[feats])\n        test[feats] = trans.transform(test[feats])\n    \n    Fold = GroupKFold(n_splits=10)   #whatever how many fold we want to split the data\n    \n    groups = train['breath_id'].values\n    for f, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n        train.loc[val_index, 'fold'] = int(f)\n    train['fold'] = train['fold'].astype(int)\n                              \n    train = train.groupby('breath_id').agg(list).reset_index(drop=True)\n    test = test.groupby('breath_id').agg(list).reset_index(drop=True)\n    train['fold'] = train['fold'].apply(lambda x: x[0])\n    test['fold'] = test['fold'].apply(lambda x: x[0])\n \n    train = train[feats + not_to_scale + ['pressure']+['fold']]\n    test = test[feats + not_to_scale + ['pressure']+['fold']]\n    \n    return {\n        'train' :train,\n        'test' : test,\n    }","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:18:56.155443Z","iopub.execute_input":"2021-10-16T04:18:56.155774Z","iopub.status.idle":"2021-10-16T04:18:56.170972Z","shell.execute_reply.started":"2021-10-16T04:18:56.155739Z","shell.execute_reply":"2021-10-16T04:18:56.169929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = get_data(scaler=MinMaxScaler()) #or whatever","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:18:58.020869Z","iopub.execute_input":"2021-10-16T04:18:58.021174Z","iopub.status.idle":"2021-10-16T04:24:58.974085Z","shell.execute_reply.started":"2021-10-16T04:18:58.021141Z","shell.execute_reply":"2021-10-16T04:24:58.971273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data['train']\ntest = data['test']\n#train.head()     #check your data","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:24:58.979669Z","iopub.execute_input":"2021-10-16T04:24:58.980171Z","iopub.status.idle":"2021-10-16T04:24:59.228606Z","shell.execute_reply.started":"2021-10-16T04:24:58.980113Z","shell.execute_reply":"2021-10-16T04:24:59.227827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we can save our preprocessed data if we want \nimport pickle\nwith open('preprocessed_data', 'wb') as handle:\n    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:26:07.672992Z","iopub.execute_input":"2021-10-16T04:26:07.673637Z","iopub.status.idle":"2021-10-16T04:26:40.426893Z","shell.execute_reply.started":"2021-10-16T04:26:07.673586Z","shell.execute_reply":"2021-10-16T04:26:40.425943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VentilatorData(Dataset):\n    def __init__(self, df, flip=0):\n        super().__init__()\n        self.df = df.values.tolist()\n        self.flip = flip              # percentage for data augmentation if we wish \n    def __getitem__(self, idx):\n        row = self.df[idx]\n        tensors = torch.as_tensor(row[:-2], dtype = torch.float)   #all rows except the ['fold', pressure]\n        segment = torch.as_tensor(row[-3], dtype=torch.long)    #thats the 'segment' or the 'u_out' row\n        target = torch.as_tensor(row[-2], dtype=torch.float)   #the 'pressure row'\n        \n        if np.random.rand() < self.flip:    #use it for sum augmentition\n            tensors = tensors.flip(-1)\n        return {\n            'tensors':tensors,\n            'segment':segment,\n            'target':target,\n        }\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:27:19.070901Z","iopub.execute_input":"2021-10-16T04:27:19.071212Z","iopub.status.idle":"2021-10-16T04:27:19.080675Z","shell.execute_reply.started":"2021-10-16T04:27:19.071179Z","shell.execute_reply":"2021-10-16T04:27:19.079757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loader = DataLoader(VentilatorData(train), 64)\nbatch = next(iter(loader))\nbatch['tensors'].shape, batch['target'].shape, batch['segment'].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-16T04:31:52.463332Z","iopub.execute_input":"2021-10-16T04:31:52.464005Z","iopub.status.idle":"2021-10-16T04:31:57.707687Z","shell.execute_reply.started":"2021-10-16T04:31:52.463958Z","shell.execute_reply":"2021-10-16T04:31:57.70688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we can start building our models ","metadata":{}},{"cell_type":"markdown","source":"# to be continued !\n","metadata":{}}]}