{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-09T12:58:44.349465Z","iopub.execute_input":"2021-11-09T12:58:44.350183Z","iopub.status.idle":"2021-11-09T12:58:44.401912Z","shell.execute_reply.started":"2021-11-09T12:58:44.350044Z","shell.execute_reply":"2021-11-09T12:58:44.401051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_absolute_error\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.layers import Concatenate, LSTM, GRU\nfrom tensorflow.keras.layers import Bidirectional, Multiply\n\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:58:45.04798Z","iopub.execute_input":"2021-11-09T12:58:45.048324Z","iopub.status.idle":"2021-11-09T12:58:52.288598Z","shell.execute_reply.started":"2021-11-09T12:58:45.048287Z","shell.execute_reply":"2021-11-09T12:58:52.287426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\nprint(f\"train_: {train_.shape}\")\ntrain_.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:58:52.290612Z","iopub.execute_input":"2021-11-09T12:58:52.291237Z","iopub.status.idle":"2021-11-09T12:59:02.168972Z","shell.execute_reply.started":"2021-11-09T12:58:52.291197Z","shell.execute_reply":"2021-11-09T12:59:02.168193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/ventilator-transformed-datasets/train_0.csv')\nprint(f\"train_df: {train_df.shape}\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:59:02.170026Z","iopub.execute_input":"2021-11-09T12:59:02.170294Z","iopub.status.idle":"2021-11-09T13:00:51.76847Z","shell.execute_reply.started":"2021-11-09T12:59:02.170264Z","shell.execute_reply":"2021-11-09T13:00:51.767504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train_[['pressure']].to_numpy().reshape(-1, 80)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:51.771189Z","iopub.execute_input":"2021-11-09T13:00:51.771558Z","iopub.status.idle":"2021-11-09T13:00:51.795997Z","shell.execute_reply.started":"2021-11-09T13:00:51.771504Z","shell.execute_reply":"2021-11-09T13:00:51.795217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_\ngc.collect()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:51.797031Z","iopub.execute_input":"2021-11-09T13:00:51.797693Z","iopub.status.idle":"2021-11-09T13:00:52.186963Z","shell.execute_reply.started":"2021-11-09T13:00:51.797647Z","shell.execute_reply":"2021-11-09T13:00:52.185991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_df.values\ndel train_df\ngc.collect()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:52.188394Z","iopub.execute_input":"2021-11-09T13:00:52.18865Z","iopub.status.idle":"2021-11-09T13:00:52.570813Z","shell.execute_reply.started":"2021-11-09T13:00:52.188621Z","shell.execute_reply":"2021-11-09T13:00:52.569786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\n\nprint(f\"train: {train.shape} \\ntargets: {targets.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:52.572311Z","iopub.execute_input":"2021-11-09T13:00:52.572656Z","iopub.status.idle":"2021-11-09T13:00:52.584921Z","shell.execute_reply.started":"2021-11-09T13:00:52.572613Z","shell.execute_reply":"2021-11-09T13:00:52.584145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pressure = targets.squeeze().reshape(-1,1).astype('float32')\n\nP_MIN = np.min(pressure)\nP_MAX = np.max(pressure)\nP_STEP = (pressure[1] - pressure[0])[0]\nprint('Min pressure: {}'.format(P_MIN))\nprint('Max pressure: {}'.format(P_MAX))\nprint('Pressure step: {}'.format(P_STEP))\nprint('Unique values:  {}'.format(np.unique(pressure).shape[0]))\n\ndel pressure\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:52.586439Z","iopub.execute_input":"2021-11-09T13:00:52.586805Z","iopub.status.idle":"2021-11-09T13:00:53.152843Z","shell.execute_reply.started":"2021-11-09T13:00:52.586773Z","shell.execute_reply":"2021-11-09T13:00:53.151863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n    print(\"Running on TPU:\", tpu.master())\n    print(f\"Batch Size: {BATCH_SIZE}\")\n    \nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE = 512\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    print(f\"Batch Size: {BATCH_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:53.154455Z","iopub.execute_input":"2021-11-09T13:00:53.154749Z","iopub.status.idle":"2021-11-09T13:00:59.035791Z","shell.execute_reply.started":"2021-11-09T13:00:53.154674Z","shell.execute_reply":"2021-11-09T13:00:59.034355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:59.04096Z","iopub.execute_input":"2021-11-09T13:00:59.041663Z","iopub.status.idle":"2021-11-09T13:00:59.050553Z","shell.execute_reply.started":"2021-11-09T13:00:59.041625Z","shell.execute_reply":"2021-11-09T13:00:59.04942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dnn_model():\n    \n    x_input = Input(shape=(train.shape[-2:]))\n    \n    x1 = Bidirectional(LSTM(units=768, return_sequences=True))(x_input)\n    x2 = Bidirectional(LSTM(units=512, return_sequences=True))(x1)\n    x3 = Bidirectional(LSTM(units=384, return_sequences=True))(x2)\n    x4 = Bidirectional(LSTM(units=256, return_sequences=True))(x3)\n    x5 = Bidirectional(LSTM(units=128, return_sequences=True))(x4)\n    \n    z2 = Bidirectional(GRU(units=384, return_sequences=True))(x2)\n    \n    z31 = Multiply()([x3, z2])\n    z31 = BatchNormalization()(z31)\n    z3 = Bidirectional(GRU(units=256, return_sequences=True))(z31)\n    \n    z41 = Multiply()([x4, z3])\n    z41 = BatchNormalization()(z41)\n    z4 = Bidirectional(GRU(units=128, return_sequences=True))(z41)\n    \n    z51 = Multiply()([x5, z4])\n    z51 = BatchNormalization()(z51)\n    z5 = Bidirectional(GRU(units=64, return_sequences=True))(z51)\n    \n    x = Concatenate(axis=2)([x5, z2, z3, z4, z5])\n    \n    x = Dense(units=128, activation='selu')(x)\n    \n    x_output = Dense(units=1)(x)\n\n    model = Model(inputs=x_input, outputs=x_output, \n                  name='DNN_Model')\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:59.051538Z","iopub.execute_input":"2021-11-09T13:00:59.051814Z","iopub.status.idle":"2021-11-09T13:00:59.072255Z","shell.execute_reply.started":"2021-11-09T13:00:59.051786Z","shell.execute_reply":"2021-11-09T13:00:59.071301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = dnn_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:00:59.073362Z","iopub.execute_input":"2021-11-09T13:00:59.073979Z","iopub.status.idle":"2021-11-09T13:01:08.854024Z","shell.execute_reply.started":"2021-11-09T13:00:59.073934Z","shell.execute_reply":"2021-11-09T13:01:08.852596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:32:13.590767Z","iopub.execute_input":"2021-11-09T12:32:13.591045Z","iopub.status.idle":"2021-11-09T12:35:40.216402Z","shell.execute_reply.started":"2021-11-09T12:32:13.591017Z","shell.execute_reply":"2021-11-09T12:35:40.215345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1024\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:35:40.218243Z","iopub.execute_input":"2021-11-09T12:35:40.218476Z","iopub.status.idle":"2021-11-09T12:38:06.861793Z","shell.execute_reply.started":"2021-11-09T12:35:40.21845Z","shell.execute_reply":"2021-11-09T12:38:06.860959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 2048\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:38:16.117576Z","iopub.execute_input":"2021-11-09T12:38:16.117886Z","iopub.status.idle":"2021-11-09T12:40:31.372024Z","shell.execute_reply.started":"2021-11-09T12:38:16.117852Z","shell.execute_reply":"2021-11-09T12:40:31.370964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4096\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:41:04.82482Z","iopub.execute_input":"2021-11-09T12:41:04.825122Z","iopub.status.idle":"2021-11-09T12:43:20.230544Z","shell.execute_reply.started":"2021-11-09T12:41:04.825091Z","shell.execute_reply":"2021-11-09T12:43:20.229531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 5000\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n        \n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:48:22.27719Z","iopub.execute_input":"2021-11-09T12:48:22.278386Z","iopub.status.idle":"2021-11-09T12:50:42.939928Z","shell.execute_reply.started":"2021-11-09T12:48:22.278337Z","shell.execute_reply":"2021-11-09T12:50:42.938586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 6000\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T12:54:29.788995Z","iopub.execute_input":"2021-11-09T12:54:29.789804Z","iopub.status.idle":"2021-11-09T12:56:41.93289Z","shell.execute_reply.started":"2021-11-09T12:54:29.789721Z","shell.execute_reply":"2021-11-09T12:56:41.931689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 6500\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:01:08.855588Z","iopub.execute_input":"2021-11-09T13:01:08.855847Z","iopub.status.idle":"2021-11-09T13:03:36.737784Z","shell.execute_reply.started":"2021-11-09T13:01:08.855818Z","shell.execute_reply":"2021-11-09T13:03:36.736614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 6800\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:04:47.598182Z","iopub.execute_input":"2021-11-09T13:04:47.599241Z","iopub.status.idle":"2021-11-09T13:07:01.336443Z","shell.execute_reply.started":"2021-11-09T13:04:47.599192Z","shell.execute_reply":"2021-11-09T13:07:01.33555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 7000\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:07:44.543376Z","iopub.execute_input":"2021-11-09T13:07:44.543702Z","iopub.status.idle":"2021-11-09T13:10:01.130132Z","shell.execute_reply.started":"2021-11-09T13:07:44.543674Z","shell.execute_reply":"2021-11-09T13:10:01.129361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 7100\n\nwith tpu_strategy.scope():\n    \n    VERBOSE = 1\n    test_preds = []\n    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        if fold == 0:\n            X_train, X_valid = train[train_idx], train[test_idx]\n            y_train, y_valid = targets[train_idx], targets[test_idx]\n\n            model = dnn_model()\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n\n            model.fit(X_train, y_train, \n                      validation_data=(X_valid, y_valid), \n                      epochs=3,\n                      verbose=VERBOSE,\n                      batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T13:16:28.975282Z","iopub.execute_input":"2021-11-09T13:16:28.975668Z","iopub.status.idle":"2021-11-09T13:16:30.556116Z","shell.execute_reply.started":"2021-11-09T13:16:28.975638Z","shell.execute_reply":"2021-11-09T13:16:30.554523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}