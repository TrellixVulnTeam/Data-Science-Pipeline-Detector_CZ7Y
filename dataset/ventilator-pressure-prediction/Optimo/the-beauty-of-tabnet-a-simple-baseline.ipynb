{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Simple and efficient TabNet approach\n\n## Why TabNet for time series?\n\nIn my opinion TabNet, as XGBoost or LGBM is NOT the best algorithm for time series.\n\nHowever, pytorch-tabnet natively implements multi regression which is handy to make a time serie prediction.\n\n\nThis notebook shows one elegant and simple way to work with time series with TabNet:\n- pick a \"memory size\" (here it's the entire serie size of 80 points) and give all the features as input to the model\n- pick a \"horizon time\" for prediction (here it's again the entire serie size) and give this as multi-regression targets\n\nIt would be really painful to use such an approach with XGBoost, since you'll need to have one model per time_step.\n\nThis is a very simple baseline, no feature was created, no preprocessing, nothing : just reformating.\n\n## Results\n\nThe results are quite good, competing with simple yet strong LSTM baseline like this one: https://www.kaggle.com/theoviel/deep-learning-starter-simple-lstm\n\nI find the simplicity and flexibility of tabnet really beautiful, I hope you'll like it too.\n\n## Pushing further\n\nIf you want to try to push this baseline further here is a list of things one could try:\n- play with the parameters\n- try pretraining on test set (might be quite heavy)\n- create as many features as you like\n\nI am sure the score can be improved, however I still doubt that it can compete with time series Deep Learning models like TCN or LSTM. It might be useful for ensembling however.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"! pip install --user pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:37:32.891665Z","iopub.execute_input":"2021-09-28T21:37:32.892358Z","iopub.status.idle":"2021-09-28T21:37:42.549272Z","shell.execute_reply.started":"2021-09-28T21:37:32.892252Z","shell.execute_reply":"2021-09-28T21:37:42.547779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:37:42.552104Z","iopub.execute_input":"2021-09-28T21:37:42.55251Z","iopub.status.idle":"2021-09-28T21:37:48.095339Z","shell.execute_reply.started":"2021-09-28T21:37:42.552453Z","shell.execute_reply":"2021-09-28T21:37:48.094291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\n\ntrain = pd.read_csv(\"../input/ventilator-pressure-prediction/train.csv\")\ntrain[\"date\"] = train.groupby(\"breath_id\").time_step.rank(axis=0).astype(np.int)\n\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\ntest[\"date\"] = test.groupby(\"breath_id\").time_step.rank(axis=0).astype(np.int)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:37:48.100802Z","iopub.execute_input":"2021-09-28T21:37:48.101115Z","iopub.status.idle":"2021-09-28T21:38:05.948017Z","shell.execute_reply.started":"2021-09-28T21:37:48.101076Z","shell.execute_reply":"2021-09-28T21:38:05.947018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_df(df, has_target = True):\n    \"\"\"\n        This switch from time step observation to full series\n    \"\"\"\n    features = [\"R\", \"C\",] + [f\"u_in_{n}\" for n in range(80)] + [f\"u_out_{n}\" for n in range(80)]\n    targets =  [f\"u_pressure_{n}\" for n in range(80)]\n    \n    if has_target:\n        values = np.hstack([df.R.unique(),\n                            df.C.unique(),\n                            df.u_in.values,\n                            df.u_out.values,\n                            df.pressure.values])\n        columns = features + targets\n    else:\n        values = np.hstack([df.R.unique(),\n                            df.C.unique(),\n                            df.u_in.values,\n                            df.u_out.values])\n        columns = features\n    \n    result_df = pd.Series({col: val for col, val in zip(columns, values)})\n    return result_df","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:38:05.950773Z","iopub.execute_input":"2021-09-28T21:38:05.951393Z","iopub.status.idle":"2021-09-28T21:38:05.96147Z","shell.execute_reply.started":"2021-09-28T21:38:05.951346Z","shell.execute_reply":"2021-09-28T21:38:05.960212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.groupby(\"breath_id\").apply(lambda df : flatten_df(df)).reset_index(drop=False)\nX_test = test.groupby(\"breath_id\").apply(lambda df : flatten_df(df, has_target=False)).reset_index(drop=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:38:05.964899Z","iopub.execute_input":"2021-09-28T21:38:05.965182Z","iopub.status.idle":"2021-09-28T21:40:28.230199Z","shell.execute_reply.started":"2021-09-28T21:38:05.965149Z","shell.execute_reply":"2021-09-28T21:40:28.229356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define features and targets\nfeatures = [\"R\", \"C\"] + [f\"u_in_{n}\" for n in range(80)] + [f\"u_out_{n}\" for n in range(80)]\ntargets =  [f\"u_pressure_{n}\" for n in range(80)]","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:40:28.231698Z","iopub.execute_input":"2021-09-28T21:40:28.231977Z","iopub.status.idle":"2021-09-28T21:40:28.236528Z","shell.execute_reply.started":"2021-09-28T21:40:28.231944Z","shell.execute_reply":"2021-09-28T21:40:28.235671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define TabNet params","metadata":{}},{"cell_type":"code","source":"cat_idxs = [] # R and C could be categorical\ncat_dims = []\n\n\nBS = 2**12\nvirtual_BS = 256\n\n# commented params\ntabnet_params = dict(\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=1,\n    n_d = 256, \n    n_a = 256, \n    n_steps = 5,\n    gamma = 1.5,\n    n_independent = 2,\n    n_shared = 2,\n    lambda_sparse = 1e-5,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type = \"entmax\",\n    seed = 42,\n    verbose = 5\n    \n)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:40:28.237713Z","iopub.execute_input":"2021-09-28T21:40:28.238253Z","iopub.status.idle":"2021-09-28T21:40:28.252012Z","shell.execute_reply.started":"2021-09-28T21:40:28.238215Z","shell.execute_reply":"2021-09-28T21:40:28.2512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure to comply with the competition metric\n# here we take advantage of the fact that pressure is positive\n\nfrom pytorch_tabnet.metrics import Metric\n\nclass filtered_MAE(Metric):\n        def __init__(self):\n            self._name = \"filtered_mae\"\n            self._maximize = False\n\n        def __call__(self, y_true, y_score):\n            weights = y_true >-1\n            mae = weights * np.abs(y_true - y_score)\n            mae = mae.sum() / weights.sum()\n            return mae\n        \ndef filtered_loss(y_pred, y_true):\n    weights = (y_true >-1)+0.\n    mae = weights * torch.abs(y_true - y_pred)\n    mae = torch.sum(mae) / torch.sum(weights)\n    return mae","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nimport copy\n\nN_SPLITS = 5\nkfold = GroupKFold(n_splits=N_SPLITS)\n\n# How many folds do you want to train?\nN_MODELS = 5\nassert(N_MODELS <= N_SPLITS)\nmax_epochs =  500\n\n# Create out of folds array\noof_predictions = np.zeros((X.shape[0], len(targets)))\ntest_preds = np.zeros((X_test.shape[0], len(targets)))\n\nfor fold, (trn_ind, val_ind) in enumerate(kfold.split(X, groups=X.breath_id)):\n    print(f'Training fold {fold + 1}')\n    X_train, X_val = X.loc[trn_ind][features].values, X.loc[val_ind][features].values\n    y_train, y_val = X.loc[trn_ind][targets].values, X.loc[val_ind][targets].values\n    \n    # mask unnecessary outputs with -1\n    y_train[X.loc[trn_ind, [c for c in X.columns if c.startswith(\"u_out\")]].values==1] = -1\n    y_val[X.loc[val_ind, [c for c in X.columns if c.startswith(\"u_out\")]].values==1]=-1\n    \n    \n    params = copy.deepcopy(tabnet_params)\n    params[\"scheduler_fn\"]=torch.optim.lr_scheduler.OneCycleLR\n    params[\"scheduler_params\"]={\"is_batch_level\":True,\n                                \"max_lr\":5e-2,\n                                \"steps_per_epoch\":int(X_train.shape[0] / BS)+1,\n                                \"epochs\":max_epochs}\n    \n\n    clf =  TabNetRegressor(**params)\n    clf.fit(\n      X_train, y_train,\n      eval_set=[(X_train, y_train), (X_val, y_val)],\n      eval_name=['train', 'val'],\n      max_epochs = max_epochs,\n      patience = 200,\n      batch_size = BS,  \n      virtual_batch_size = virtual_BS, \n      num_workers = 0,\n      drop_last = False, \n      eval_metric=[\"filtered_mae\"],\n      loss_fn=filtered_loss,\n      )\n    \n    del X_train\n      \n    oof_predictions[val_ind] = clf.predict(X_val)\n    \n    del X_val\n    \n    test_preds += clf.predict(X_test[features].values) / N_MODELS\n    if fold+1 >=N_MODELS:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-09-28T21:40:28.253186Z","iopub.execute_input":"2021-09-28T21:40:28.254101Z","iopub.status.idle":"2021-09-28T22:28:09.3799Z","shell.execute_reply.started":"2021-09-28T21:40:28.254053Z","shell.execute_reply":"2021-09-28T22:28:09.379095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Have a look at out of fold predictions","metadata":{}},{"cell_type":"code","source":"for serie_nb in range(50):\n    plt.plot(oof_predictions[serie_nb, :])\n    plt.plot(X.loc[serie_nb][targets].values, color=\"green\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T22:28:09.381381Z","iopub.execute_input":"2021-09-28T22:28:09.381689Z","iopub.status.idle":"2021-09-28T22:28:12.058431Z","shell.execute_reply.started":"2021-09-28T22:28:09.381654Z","shell.execute_reply":"2021-09-28T22:28:12.057677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/ventilator-pressure-prediction/sample_submission.csv\")\nsample_submission[\"pressure\"] = test_preds.reshape(-1, 1)\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T22:28:12.060715Z","iopub.execute_input":"2021-09-28T22:28:12.061099Z","iopub.status.idle":"2021-09-28T22:28:27.106578Z","shell.execute_reply.started":"2021-09-28T22:28:12.061059Z","shell.execute_reply":"2021-09-28T22:28:27.105744Z"},"trusted":true},"execution_count":null,"outputs":[]}]}