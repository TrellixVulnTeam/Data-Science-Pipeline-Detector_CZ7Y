{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Финальный проект по курсу Data Science\n![](https://gipermed.ru/upload/iblock/e3d/e3d6730be6efe6548610fc6d500c1e03.jpg)\n\nРеальный ноутбук к соревнованию **\"Google Brain - Ventilator Pressure Prediction\"**\n\n## Описание проекта\nСуть задачи заключается  в предсказании необходимого давления, создаваемого аппаратом для искусственной вентиляции лёгких, подключённого к находящемуся без сознания пациенту. Симуляция такого аппарата намного дешевле и безопаснее реальных клинических испытаний. В итоге алгоритм поможет в разработке аппаратов, более гибко адаптирующихся к конкретному пациенту. \n\nВ данном ноутбуке будут рассмотрены различные подходы к решению данной задачи, а также указаны результаты реальных сабмитов на соревнование. \n\n# 1. Подготовка к работе\n## 1.1 Импорт необходимых библиотек","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np  \nimport pandas as pd  \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,GroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingRegressor\n\nfrom catboost import CatBoostRegressor\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\n\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:01:41.501626Z","iopub.execute_input":"2021-11-03T06:01:41.502331Z","iopub.status.idle":"2021-11-03T06:01:43.076392Z","shell.execute_reply.started":"2021-11-03T06:01:41.502293Z","shell.execute_reply":"2021-11-03T06:01:43.075633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Зафиксируем random seed для воспроизводимости экспериментов\nrandom_seed = 42","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:01:46.058798Z","iopub.execute_input":"2021-11-03T06:01:46.059351Z","iopub.status.idle":"2021-11-03T06:01:46.063273Z","shell.execute_reply.started":"2021-11-03T06:01:46.059314Z","shell.execute_reply":"2021-11-03T06:01:46.062352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Определение функций","metadata":{}},{"cell_type":"code","source":"#Анализ датасетов на отсутствующие данные\ndef missing_values_table(df):\n        # Всего пустых позиций\n        mis_val = df.isnull().sum()\n        \n        # Процент пустых позиций\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Таблица с результатами\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Переименование колонок в таблице\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Сортировка таблицы по убыванию % отсутствующих данных\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Итоговая информация в виде текста\n        print (\"В изучаемом датасете \" + str(df.shape[1]) + \" столбцов.\\n\"      \n            \"Всего \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" столбцов содержат отсутствующие значения.\")\n        \n        # Таблица с результатами\n        return mis_val_table_ren_columns","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:22.122432Z","iopub.execute_input":"2021-11-03T04:30:22.123028Z","iopub.status.idle":"2021-11-03T04:30:22.135729Z","shell.execute_reply.started":"2021-11-03T04:30:22.122981Z","shell.execute_reply":"2021-11-03T04:30:22.134748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Анализ датасетов на уникальные данные\ndef unique_data(df, col):\n    unique_d = pd.DataFrame(columns=['Parameter', 'unique'])\n    for i in range(len(col)):\n        unique_d.loc[i] = [col[i], df[col[i]].nunique(dropna = True)]\n    return unique_d","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:22.137403Z","iopub.execute_input":"2021-11-03T04:30:22.13801Z","iopub.status.idle":"2021-11-03T04:30:22.151858Z","shell.execute_reply.started":"2021-11-03T04:30:22.137979Z","shell.execute_reply":"2021-11-03T04:30:22.151081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Поскольку в ноутбуке будет много разных моделей, построим функцию,составляющую статистическую таблицу результатов\ndef cumulated_res(data, model,description, sub):\n    l = len(data)\n    data.loc[l]= [model, description, sub]\n    return data\n#Датафрейм для добавления результатов\ndf_cum = pd.DataFrame(columns=['Модель', 'Описание', 'Submission'])","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:22.153057Z","iopub.execute_input":"2021-11-03T04:30:22.153289Z","iopub.status.idle":"2021-11-03T04:30:22.172345Z","shell.execute_reply.started":"2021-11-03T04:30:22.153262Z","shell.execute_reply":"2021-11-03T04:30:22.1714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Функция статистики\ndef statistic(df, col):\n    median = df[col].median()\n    IQR = df[col].quantile(0.75) - df[col].quantile(0.25)\n    perc25 = df[col].quantile(0.25)\n    perc75 = df[col].quantile(0.75)\n    l=perc25 - 1.5*IQR \n    r=perc75 + 1.5*IQR\n    print(\"Для {0} IQR: {1}, \".format(col,IQR),\"Границы выбросов: [{0}, {1}].\".format(l, r))\n    print('Всего {} выбросов'.format(df[df[col] > r][col].count()+df[df[col] < l][col].count()))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:22.173899Z","iopub.execute_input":"2021-11-03T04:30:22.174312Z","iopub.status.idle":"2021-11-03T04:30:22.189028Z","shell.execute_reply.started":"2021-11-03T04:30:22.17428Z","shell.execute_reply":"2021-11-03T04:30:22.188304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Функция гистограммы и ящика с усами\ndef graph_num(df, col, size = 6):\n    fig, (g1, g2) = plt.subplots(1, 2, figsize = (2*size,size))\n    fig.suptitle('Histogram and boxplot for {0} '.format(col), fontsize=20)\n    g1.hist(df[col], bins = 20, histtype = 'bar', align = 'mid', rwidth = 0.8, color = 'blue') # гистограмма\n    g2.boxplot(df[col], vert = False)  # выбросы\n    plt.figtext(0.5, 0, col, fontsize = 16)\n    plt.show","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:22.190212Z","iopub.execute_input":"2021-11-03T04:30:22.190773Z","iopub.status.idle":"2021-11-03T04:30:22.200996Z","shell.execute_reply.started":"2021-11-03T04:30:22.190732Z","shell.execute_reply":"2021-11-03T04:30:22.200419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Функция гистограммы для одного временного ряда, параметр по выбору\ndef graph_ts(df,param, value):\n    df_ts = df.loc[df['breath_id'] == value]\n    sns.histplot(df_ts[param], kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:22.20234Z","iopub.execute_input":"2021-11-03T04:30:22.202569Z","iopub.status.idle":"2021-11-03T04:30:22.21207Z","shell.execute_reply.started":"2021-11-03T04:30:22.202523Z","shell.execute_reply":"2021-11-03T04:30:22.211444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Импорт и обзор данных\nДанные представлены в виде двух выложенных на Kaggle тестового и тренировочного датасетов и шаблона для сабмитов. Известно, что в данных содержится следующая информация:\n\n**id** - Уникальный идентификатор каждого вдоха.   \n  **breath_id -** Уникальный идентификатор серии вдохов. Известно, что данные представлены в виде набора временных рядов, состоящих из одинакового количества вдохов.\n  **R** - параметр лёгких, показывающий органичения дыхания (в cmH2O/L/S). Физически это изменение давления в зависимости от изменения в потоке воздуха  (объём воздуха за определённое время). Интуитивно это можно представитькак попытку надуть шарик через соломинку. Параметр R можно изменить, меняя диаметр соломинки. Чем больше R, тем сложнее надувать.   \n  **C** - параметр лёгких, отражающий их \"податливость\"(в mL/cmH2O). Физически это изменения в объёме при изменении давления. Интуитивно это тот же самый пример с шариком. С можно изменить, изменяя толщину материала шарика. Чем выше С, тем тоньше стенка и тем легче надувать шарик.   \n  **time_step -** реальное время  \n  **u_in -** параметр входа на клапане от 0 (полностью закрыт, воздух не вдыхается) до 100.  \n  **u_out -** Параметр выхода на клапане. 0 клапан закрыт, пациент вдыхает или 1 - клапан открыт, пациент выдыхает.  \n  **pressure -** давление воздуха в cmH2O - целевой параметр.","metadata":{}},{"cell_type":"code","source":"#Выгрузим датасеты\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n\nprint(train.shape, test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:02:07.554056Z","iopub.execute_input":"2021-11-03T06:02:07.554659Z","iopub.status.idle":"2021-11-03T06:02:22.270882Z","shell.execute_reply.started":"2021-11-03T06:02:07.554619Z","shell.execute_reply":"2021-11-03T06:02:22.269933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:02:22.27252Z","iopub.execute_input":"2021-11-03T06:02:22.2728Z","iopub.status.idle":"2021-11-03T06:02:23.244335Z","shell.execute_reply.started":"2021-11-03T06:02:22.272767Z","shell.execute_reply":"2021-11-03T06:02:23.243457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 Предварительный обзор\nПрименить pandas_profiling не удалось из-за большого размера датасетов. Каждый раз процедура намертво зависала. ","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.117409Z","iopub.execute_input":"2021-11-03T04:30:37.117735Z","iopub.status.idle":"2021-11-03T04:30:37.141783Z","shell.execute_reply.started":"2021-11-03T04:30:37.117694Z","shell.execute_reply":"2021-11-03T04:30:37.140601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.143469Z","iopub.execute_input":"2021-11-03T04:30:37.14389Z","iopub.status.idle":"2021-11-03T04:30:37.167183Z","shell.execute_reply.started":"2021-11-03T04:30:37.143844Z","shell.execute_reply":"2021-11-03T04:30:37.166183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.168737Z","iopub.execute_input":"2021-11-03T04:30:37.169124Z","iopub.status.idle":"2021-11-03T04:30:37.183045Z","shell.execute_reply.started":"2021-11-03T04:30:37.169076Z","shell.execute_reply":"2021-11-03T04:30:37.182138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.184663Z","iopub.execute_input":"2021-11-03T04:30:37.185122Z","iopub.status.idle":"2021-11-03T04:30:37.199522Z","shell.execute_reply.started":"2021-11-03T04:30:37.184937Z","shell.execute_reply":"2021-11-03T04:30:37.19849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Перечень заголовков столбцов для каждого датасета\ncolumns_tr = list(train.columns)\ncolumns_te = list(test.columns)\nprint(\"train\", columns_tr)\nprint(\"test\", columns_te)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.200831Z","iopub.execute_input":"2021-11-03T04:30:37.201562Z","iopub.status.idle":"2021-11-03T04:30:37.212087Z","shell.execute_reply.started":"2021-11-03T04:30:37.201508Z","shell.execute_reply":"2021-11-03T04:30:37.211291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Поиск пустых значений для тренировочного датасета\nmissing_values_table(train)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.213284Z","iopub.execute_input":"2021-11-03T04:30:37.213494Z","iopub.status.idle":"2021-11-03T04:30:37.387744Z","shell.execute_reply.started":"2021-11-03T04:30:37.213461Z","shell.execute_reply":"2021-11-03T04:30:37.386952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Поиск пустых значений для тестового датасета\nmissing_values_table(test)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.388951Z","iopub.execute_input":"2021-11-03T04:30:37.389192Z","iopub.status.idle":"2021-11-03T04:30:37.486263Z","shell.execute_reply.started":"2021-11-03T04:30:37.389163Z","shell.execute_reply":"2021-11-03T04:30:37.485482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Проверим, встречаются ли одинаковые серии вдохов в тестовом и тренировочном датасетах\ntrain_breath_id = [x for x in (np.unique(train['breath_id']))]\ntest_breath_id = [x for x in (np.unique(test['breath_id']))]\nset(test_breath_id).intersection(train_breath_id)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.487396Z","iopub.execute_input":"2021-11-03T04:30:37.487661Z","iopub.status.idle":"2021-11-03T04:30:37.708873Z","shell.execute_reply.started":"2021-11-03T04:30:37.487633Z","shell.execute_reply":"2021-11-03T04:30:37.707956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Поиск уникальных значений для тренировочного датасета\nunique_data(train, columns_tr)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:37.710304Z","iopub.execute_input":"2021-11-03T04:30:37.710697Z","iopub.status.idle":"2021-11-03T04:30:40.251256Z","shell.execute_reply.started":"2021-11-03T04:30:37.710653Z","shell.execute_reply":"2021-11-03T04:30:40.25046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Поиск уникальных значений для тестового датасета\nunique_data(test, columns_te)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:40.25239Z","iopub.execute_input":"2021-11-03T04:30:40.252742Z","iopub.status.idle":"2021-11-03T04:30:41.699349Z","shell.execute_reply.started":"2021-11-03T04:30:40.252712Z","shell.execute_reply":"2021-11-03T04:30:41.698582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['id'].nunique()/train['breath_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:41.70261Z","iopub.execute_input":"2021-11-03T04:30:41.702823Z","iopub.status.idle":"2021-11-03T04:30:42.177205Z","shell.execute_reply.started":"2021-11-03T04:30:41.702796Z","shell.execute_reply":"2021-11-03T04:30:42.176359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['id'].nunique()/test['breath_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:42.178359Z","iopub.execute_input":"2021-11-03T04:30:42.178699Z","iopub.status.idle":"2021-11-03T04:30:42.524476Z","shell.execute_reply.started":"2021-11-03T04:30:42.178664Z","shell.execute_reply":"2021-11-03T04:30:42.523842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"breath_id\")[\"time_step\"].count()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:42.525449Z","iopub.execute_input":"2021-11-03T04:30:42.526128Z","iopub.status.idle":"2021-11-03T04:30:42.671747Z","shell.execute_reply.started":"2021-11-03T04:30:42.526095Z","shell.execute_reply":"2021-11-03T04:30:42.670806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.groupby(\"breath_id\")[\"time_step\"].count()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:42.672964Z","iopub.execute_input":"2021-11-03T04:30:42.673269Z","iopub.status.idle":"2021-11-03T04:30:42.764916Z","shell.execute_reply.started":"2021-11-03T04:30:42.673237Z","shell.execute_reply":"2021-11-03T04:30:42.764114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Поскольку нам известно,  что серии вдохов имеют одинаковый размер, будем в дальнейшем в качестве количества вдохов в ряду использовать  80.\n## 2.1 Посмотрим распределения и статистики","metadata":{}},{"cell_type":"code","source":"for c in columns_tr:\n    statistic(train, c)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:42.766339Z","iopub.execute_input":"2021-11-03T04:30:42.766716Z","iopub.status.idle":"2021-11-03T04:30:45.816724Z","shell.execute_reply.started":"2021-11-03T04:30:42.766681Z","shell.execute_reply":"2021-11-03T04:30:45.815682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in columns_tr:\n    graph_num(train, c)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:45.818054Z","iopub.execute_input":"2021-11-03T04:30:45.818616Z","iopub.status.idle":"2021-11-03T04:30:53.639378Z","shell.execute_reply.started":"2021-11-03T04:30:45.818578Z","shell.execute_reply":"2021-11-03T04:30:53.638748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in columns_te:\n    statistic(test, c)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:53.640313Z","iopub.execute_input":"2021-11-03T04:30:53.640607Z","iopub.status.idle":"2021-11-03T04:30:54.856521Z","shell.execute_reply.started":"2021-11-03T04:30:53.640575Z","shell.execute_reply":"2021-11-03T04:30:54.855675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in columns_te:\n    graph_num(test, c)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:54.862214Z","iopub.execute_input":"2021-11-03T04:30:54.862481Z","iopub.status.idle":"2021-11-03T04:30:59.634542Z","shell.execute_reply.started":"2021-11-03T04:30:54.862441Z","shell.execute_reply":"2021-11-03T04:30:59.633674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in ['R','C','u_out']:\n    print(i)\n    print(train[i].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:59.636065Z","iopub.execute_input":"2021-11-03T04:30:59.636376Z","iopub.status.idle":"2021-11-03T04:30:59.740291Z","shell.execute_reply.started":"2021-11-03T04:30:59.636334Z","shell.execute_reply":"2021-11-03T04:30:59.739317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Мы не видим ни одного нормального распределения. Также 3 параметра можно перевести в категориальные. \nПроверим корреляции.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train.corr(), vmin = -1, vmax = +1, annot = True, cmap = 'coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:30:59.741658Z","iopub.execute_input":"2021-11-03T04:30:59.741964Z","iopub.status.idle":"2021-11-03T04:31:01.816624Z","shell.execute_reply.started":"2021-11-03T04:30:59.74192Z","shell.execute_reply":"2021-11-03T04:31:01.815813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Более менее коррелируют только давление и параметр выхода на клапане, а также время выдоха. \nПосмотрим распределение давления в рамках одного дыхания.","metadata":{}},{"cell_type":"code","source":"graph_ts(train,'pressure', 18)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:01.818018Z","iopub.execute_input":"2021-11-03T04:31:01.818267Z","iopub.status.idle":"2021-11-03T04:31:02.0765Z","shell.execute_reply.started":"2021-11-03T04:31:01.818235Z","shell.execute_reply":"2021-11-03T04:31:02.075882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_ts(train, 'u_in',45008)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:02.077563Z","iopub.execute_input":"2021-11-03T04:31:02.077867Z","iopub.status.idle":"2021-11-03T04:31:02.389589Z","shell.execute_reply.started":"2021-11-03T04:31:02.07784Z","shell.execute_reply":"2021-11-03T04:31:02.388665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_ts(train,'R', 45094)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:02.390678Z","iopub.execute_input":"2021-11-03T04:31:02.390883Z","iopub.status.idle":"2021-11-03T04:31:02.62265Z","shell.execute_reply.started":"2021-11-03T04:31:02.390857Z","shell.execute_reply":"2021-11-03T04:31:02.621828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_ts(train, 'C', 18)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:02.623777Z","iopub.execute_input":"2021-11-03T04:31:02.624062Z","iopub.status.idle":"2021-11-03T04:31:02.863347Z","shell.execute_reply.started":"2021-11-03T04:31:02.624031Z","shell.execute_reply":"2021-11-03T04:31:02.862633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_ts(train,'u_out', 2)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:02.864541Z","iopub.execute_input":"2021-11-03T04:31:02.86475Z","iopub.status.idle":"2021-11-03T04:31:03.111193Z","shell.execute_reply.started":"2021-11-03T04:31:02.864724Z","shell.execute_reply":"2021-11-03T04:31:03.110375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Не самые говорящие графики. Попробуем другие варианты. Рассмотрим в рамках одной серии из тестового датасета. ","metadata":{}},{"cell_type":"code","source":"breath_id_1 = train[train['breath_id'] == 1]\nbreath_id_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:03.112748Z","iopub.execute_input":"2021-11-03T04:31:03.112984Z","iopub.status.idle":"2021-11-03T04:31:03.132384Z","shell.execute_reply.started":"2021-11-03T04:31:03.112956Z","shell.execute_reply":"2021-11-03T04:31:03.131519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize = (6, 4))\nax2 = ax1.twinx()\nax1.plot(breath_id_1['time_step'], breath_id_1['pressure'], 'm-', label='pressure')\nax1.plot(breath_id_1['time_step'], breath_id_1['u_in'], 'g-', label='u_in')\nax2.plot(breath_id_1['time_step'], breath_id_1['u_out'], 'b-', label='u_out')\n\nax1.set_xlabel('Timestep')\n\nR = breath_id_1['R'][0]\nC = breath_id_1['C'][0]\nax1.set_title(f'breath_id:{1}, R:{R}, C:{C}')\n\nax1.legend(loc=(1.1, 0.8))\nax2.legend(loc=(1.1, 0.7))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:03.133812Z","iopub.execute_input":"2021-11-03T04:31:03.134025Z","iopub.status.idle":"2021-11-03T04:31:03.660268Z","shell.execute_reply.started":"2021-11-03T04:31:03.133998Z","shell.execute_reply":"2021-11-03T04:31:03.659412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x = 'id',y='pressure',data=breath_id_1[breath_id_1['u_out']==0],color='green',label='inhale pressure');\nsns.lineplot(x = 'id',y='pressure',data=breath_id_1[breath_id_1['u_out']==1],color='orange',label='exhale pressure');\nsns.lineplot(x = 'id',y='u_in',data=breath_id_1,color='blue',label='valve pressure')\nplt.title(f\"Variation of Pressure and Input valve position during breath Id 1\");\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:03.661653Z","iopub.execute_input":"2021-11-03T04:31:03.661862Z","iopub.status.idle":"2021-11-03T04:31:03.973069Z","shell.execute_reply.started":"2021-11-03T04:31:03.661837Z","shell.execute_reply":"2021-11-03T04:31:03.972231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Учитывая размер датасетов, будем сразу удалять ненужные списки и датафреймы и оптимизировать память. ","metadata":{}},{"cell_type":"code","source":"del breath_id_1\ndel columns_tr\ndel columns_te\ndel train_breath_id\ndel test_breath_id\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:03.974286Z","iopub.execute_input":"2021-11-03T04:31:03.974525Z","iopub.status.idle":"2021-11-03T04:31:04.100606Z","shell.execute_reply.started":"2021-11-03T04:31:03.974497Z","shell.execute_reply":"2021-11-03T04:31:04.099758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Начнём собирать модели.\nДля начала отработаем на действующих признаках, не переводя их во временные ряды, затем сделаем преобразование имеющихся признаков, сформировав новые, затем добавим временные ряды. Что касается моделей, то в данном случае можно попробовать регрессии, ансамбли, нейросеть и поблендить результаты.   Для того, чтобы не выгружать заново датасеты, датафреймы будут преобразовываться из исходных train и test.\n# 3. Модели\n# 3.1 Регрессия на имеющихся признаках\nНичего не будем преобразовывать","metadata":{}},{"cell_type":"code","source":"X_n=train.drop(['pressure','id'], axis=1)\ny_n=train['pressure']\nid_test = test['id']\nX_n_t = test.drop(['id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:04.101862Z","iopub.execute_input":"2021-11-03T04:31:04.102308Z","iopub.status.idle":"2021-11-03T04:31:04.278575Z","shell.execute_reply.started":"2021-11-03T04:31:04.102268Z","shell.execute_reply":"2021-11-03T04:31:04.277575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n,y_n, test_size=0.2, random_state=random_seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:04.279999Z","iopub.execute_input":"2021-11-03T04:31:04.280224Z","iopub.status.idle":"2021-11-03T04:31:05.477193Z","shell.execute_reply.started":"2021-11-03T04:31:04.280198Z","shell.execute_reply":"2021-11-03T04:31:05.476264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost=CatBoostRegressor()\ngrid={'depth': [6,8,10],\n      'learning_rate' : [0.01, 0.05, 0.1],\n      'iterations'    : [30, 50, 100]}","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:05.478436Z","iopub.execute_input":"2021-11-03T04:31:05.479266Z","iopub.status.idle":"2021-11-03T04:31:05.488867Z","shell.execute_reply.started":"2021-11-03T04:31:05.479216Z","shell.execute_reply":"2021-11-03T04:31:05.487809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_catboost=GridSearchCV(estimator=catboost, param_grid = grid, cv = 2, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:05.49016Z","iopub.execute_input":"2021-11-03T04:31:05.4904Z","iopub.status.idle":"2021-11-03T04:31:05.501346Z","shell.execute_reply.started":"2021-11-03T04:31:05.490372Z","shell.execute_reply":"2021-11-03T04:31:05.500513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_catboost.fit(X_n_train,y_n_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:31:05.502973Z","iopub.execute_input":"2021-11-03T04:31:05.503685Z","iopub.status.idle":"2021-11-03T04:43:53.900731Z","shell.execute_reply.started":"2021-11-03T04:31:05.503635Z","shell.execute_reply":"2021-11-03T04:43:53.899622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_cb = grid_catboost.predict(X_n_t)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:43:53.902486Z","iopub.execute_input":"2021-11-03T04:43:53.902789Z","iopub.status.idle":"2021-11-03T04:43:55.104637Z","shell.execute_reply.started":"2021-11-03T04:43:53.902749Z","shell.execute_reply":"2021-11-03T04:43:55.103793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_cb","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:43:55.107648Z","iopub.execute_input":"2021-11-03T04:43:55.108027Z","iopub.status.idle":"2021-11-03T04:43:55.115659Z","shell.execute_reply.started":"2021-11-03T04:43:55.107982Z","shell.execute_reply":"2021-11-03T04:43:55.114868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_cb = submission\nsub_cb['pressure'] = preds_cb\nsub_cb.to_csv('submission_cb.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:43:55.117076Z","iopub.execute_input":"2021-11-03T04:43:55.117331Z","iopub.status.idle":"2021-11-03T04:44:09.716996Z","shell.execute_reply.started":"2021-11-03T04:43:55.117301Z","shell.execute_reply":"2021-11-03T04:44:09.716001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'CatBoost', 'без EDA', '4.2000')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:44:09.718966Z","iopub.execute_input":"2021-11-03T04:44:09.719296Z","iopub.status.idle":"2021-11-03T04:44:09.739331Z","shell.execute_reply.started":"2021-11-03T04:44:09.719252Z","shell.execute_reply":"2021-11-03T04:44:09.738484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del preds_cb\ndel X_n\ndel X_n_train\ndel X_n_test\ndel y_n\ndel y_n_train\ndel y_n_test\ndel X_n_t\ndel id_test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:44:09.740977Z","iopub.execute_input":"2021-11-03T04:44:09.741701Z","iopub.status.idle":"2021-11-03T04:44:10.002379Z","shell.execute_reply.started":"2021-11-03T04:44:09.74165Z","shell.execute_reply":"2021-11-03T04:44:10.001784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2 Регрессия на \"наивных\" признаках\n\nПреобразуем некоторые признаки в категориальные.","metadata":{}},{"cell_type":"code","source":"#\"Наивные\" датасеты\ndf_tr_naiv = train\ndf_te_naiv = test\ntype(df_tr_naiv)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:03:37.198462Z","iopub.execute_input":"2021-11-03T06:03:37.19939Z","iopub.status.idle":"2021-11-03T06:03:37.205248Z","shell.execute_reply.started":"2021-11-03T06:03:37.199342Z","shell.execute_reply":"2021-11-03T06:03:37.204671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr_naiv['R'] = df_tr_naiv['R'].astype(str)\ndf_tr_naiv['C'] = df_tr_naiv['C'].astype(str)\ndf_te_naiv['R'] = df_te_naiv['R'].astype(str)\ndf_te_naiv['C'] = df_te_naiv['C'].astype(str)\ndf_tr_naiv = pd.get_dummies(df_tr_naiv)\ndf_te_naiv = pd.get_dummies(df_te_naiv)\ndf_tr_naiv.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:03:37.81252Z","iopub.execute_input":"2021-11-03T06:03:37.812877Z","iopub.status.idle":"2021-11-03T06:04:07.666148Z","shell.execute_reply.started":"2021-11-03T06:03:37.81284Z","shell.execute_reply":"2021-11-03T06:04:07.66503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te_naiv.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:07.668266Z","iopub.execute_input":"2021-11-03T06:04:07.669125Z","iopub.status.idle":"2021-11-03T06:04:07.680108Z","shell.execute_reply.started":"2021-11-03T06:04:07.669073Z","shell.execute_reply":"2021-11-03T06:04:07.679148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_naiv = df_tr_naiv['pressure']\nid_test = df_te_naiv['id']","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:07.681781Z","iopub.execute_input":"2021-11-03T06:04:07.682605Z","iopub.status.idle":"2021-11-03T06:04:07.692141Z","shell.execute_reply.started":"2021-11-03T06:04:07.682554Z","shell.execute_reply":"2021-11-03T06:04:07.691265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_naiv = df_tr_naiv\nX_naiv.drop(['id', 'pressure', 'breath_id'], axis=1, inplace=True)\nX_s_naiv = df_te_naiv\nX_s_naiv.drop(['id', 'breath_id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:07.69408Z","iopub.execute_input":"2021-11-03T06:04:07.694571Z","iopub.status.idle":"2021-11-03T06:04:08.155394Z","shell.execute_reply.started":"2021-11-03T06:04:07.6945Z","shell.execute_reply":"2021-11-03T06:04:08.154634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_naiv.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:08.15738Z","iopub.execute_input":"2021-11-03T06:04:08.157633Z","iopub.status.idle":"2021-11-03T06:04:08.177275Z","shell.execute_reply.started":"2021-11-03T06:04:08.157605Z","shell.execute_reply":"2021-11-03T06:04:08.176467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_naiv.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:08.178384Z","iopub.execute_input":"2021-11-03T06:04:08.179035Z","iopub.status.idle":"2021-11-03T06:04:08.191226Z","shell.execute_reply.started":"2021-11-03T06:04:08.179001Z","shell.execute_reply":"2021-11-03T06:04:08.190252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_s_naiv.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:08.192389Z","iopub.execute_input":"2021-11-03T06:04:08.192634Z","iopub.status.idle":"2021-11-03T06:04:08.203107Z","shell.execute_reply.started":"2021-11-03T06:04:08.192606Z","shell.execute_reply":"2021-11-03T06:04:08.202303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_tr_naiv\ndel df_te_naiv\ndel id_test\n\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Обозначим модели\ndtr = DecisionTreeRegressor(random_state=random_seed)\nabr = AdaBoostRegressor(random_state=random_seed)\nbr = BaggingRegressor(random_state=random_seed)\nensemble =  VotingRegressor([('br', br), ('abr', abr), ('dtr', dtr)])","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:08.204609Z","iopub.execute_input":"2021-11-03T06:04:08.204929Z","iopub.status.idle":"2021-11-03T06:04:08.210277Z","shell.execute_reply.started":"2021-11-03T06:04:08.204898Z","shell.execute_reply":"2021-11-03T06:04:08.209458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds_dtr = []\ntest_preds_abr = []\ntest_preds_br = []\ntest_preds_ens = []","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:08.21148Z","iopub.execute_input":"2021-11-03T06:04:08.211821Z","iopub.status.idle":"2021-11-03T06:04:08.225659Z","shell.execute_reply.started":"2021-11-03T06:04:08.211787Z","shell.execute_reply":"2021-11-03T06:04:08.22473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Расчёты будут идти на 5 фолдах","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:08.228769Z","iopub.execute_input":"2021-11-03T06:04:08.229513Z","iopub.status.idle":"2021-11-03T06:04:08.237737Z","shell.execute_reply.started":"2021-11-03T06:04:08.229475Z","shell.execute_reply":"2021-11-03T06:04:08.236813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('DecisionTreeRegressor')\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_naiv, y_naiv)):\n    \n    print('fold->',fold+1)\n    X_naiv_train, X_Naivtest = X_naiv.loc[train_idx], X_naiv.loc[test_idx]\n    y_naiv_train, y_naiv_test = y_naiv.loc[train_idx], y_naiv.loc[test_idx]\n    dtr.fit(X_naiv_train, y_naiv_train)\n    test_preds_dtr.append(dtr.predict(X_s_naiv))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:44:42.164584Z","iopub.execute_input":"2021-11-03T04:44:42.165308Z","iopub.status.idle":"2021-11-03T04:49:11.962273Z","shell.execute_reply.started":"2021-11-03T04:44:42.165269Z","shell.execute_reply":"2021-11-03T04:49:11.961319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_dtr = submission\nsub_dtr['pressure'] = sum(test_preds_dtr)/5\nsub_dtr.to_csv('submission_dtr.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:49:11.963835Z","iopub.execute_input":"2021-11-03T04:49:11.96414Z","iopub.status.idle":"2021-11-03T04:49:27.258844Z","shell.execute_reply.started":"2021-11-03T04:49:11.964101Z","shell.execute_reply":"2021-11-03T04:49:27.257863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'DecisionTreeRegressor', 'наивный feature engineering', '4.1192')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:49:27.260207Z","iopub.execute_input":"2021-11-03T04:49:27.260712Z","iopub.status.idle":"2021-11-03T04:49:27.274931Z","shell.execute_reply.started":"2021-11-03T04:49:27.260673Z","shell.execute_reply":"2021-11-03T04:49:27.274084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_preds_dtr\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:49:27.276383Z","iopub.execute_input":"2021-11-03T04:49:27.276938Z","iopub.status.idle":"2021-11-03T04:49:27.426765Z","shell.execute_reply.started":"2021-11-03T04:49:27.276903Z","shell.execute_reply":"2021-11-03T04:49:27.425257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('AdaBoostRegressor')\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_naiv, y_naiv)):\n    \n    print('fold->',fold+1)\n    X_naiv_train, X_Naivtest = X_naiv.loc[train_idx], X_naiv.loc[test_idx]\n    y_naiv_train, y_naiv_test = y_naiv.loc[train_idx], y_naiv.loc[test_idx]\n    abr.fit(X_naiv_train, y_naiv_train)\n    test_preds_abr.append(abr.predict(X_s_naiv))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T04:49:27.427995Z","iopub.execute_input":"2021-11-03T04:49:27.428326Z","iopub.status.idle":"2021-11-03T05:11:10.789742Z","shell.execute_reply.started":"2021-11-03T04:49:27.428291Z","shell.execute_reply":"2021-11-03T05:11:10.788425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_abr = submission\nsub_abr['pressure'] = sum(test_preds_abr)/5\nsub_abr.to_csv('submission_abr.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:11:10.791888Z","iopub.execute_input":"2021-11-03T05:11:10.792195Z","iopub.status.idle":"2021-11-03T05:11:26.464187Z","shell.execute_reply.started":"2021-11-03T05:11:10.792152Z","shell.execute_reply":"2021-11-03T05:11:26.462791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'AdaBoostRegressor', 'наивный feature engineering', '6.9884')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:11:26.465835Z","iopub.execute_input":"2021-11-03T05:11:26.466292Z","iopub.status.idle":"2021-11-03T05:11:26.488689Z","shell.execute_reply.started":"2021-11-03T05:11:26.466255Z","shell.execute_reply":"2021-11-03T05:11:26.487096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_preds_abr\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:11:26.491557Z","iopub.execute_input":"2021-11-03T05:11:26.493343Z","iopub.status.idle":"2021-11-03T05:11:26.711723Z","shell.execute_reply.started":"2021-11-03T05:11:26.4933Z","shell.execute_reply":"2021-11-03T05:11:26.710832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('BaggingRegressor')\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_naiv, y_naiv)):\n    print('fold->',fold+1)\n    X_naiv_train, X_Naivtest = X_naiv.loc[train_idx], X_naiv.loc[test_idx]\n    y_naiv_train, y_naiv_test = y_naiv.loc[train_idx], y_naiv.loc[test_idx]\n    br.fit(X_naiv_train, y_naiv_train)\n    test_preds_br.append(br.predict(X_s_naiv))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:11:26.713177Z","iopub.execute_input":"2021-11-03T05:11:26.713509Z","iopub.status.idle":"2021-11-03T05:40:57.378089Z","shell.execute_reply.started":"2021-11-03T05:11:26.713468Z","shell.execute_reply":"2021-11-03T05:40:57.377176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_br = submission\nsub_br['pressure'] = sum(test_preds_br)/5\nsub_br.to_csv('submission_br.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:40:57.379845Z","iopub.execute_input":"2021-11-03T05:40:57.380302Z","iopub.status.idle":"2021-11-03T05:41:13.523578Z","shell.execute_reply.started":"2021-11-03T05:40:57.380256Z","shell.execute_reply":"2021-11-03T05:41:13.522615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'BaggingRegressor', 'наивный feature engineering', '3.7660')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:41:13.524891Z","iopub.execute_input":"2021-11-03T05:41:13.525108Z","iopub.status.idle":"2021-11-03T05:41:13.540455Z","shell.execute_reply.started":"2021-11-03T05:41:13.525082Z","shell.execute_reply":"2021-11-03T05:41:13.539686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_preds_br\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T05:41:13.541409Z","iopub.execute_input":"2021-11-03T05:41:13.541631Z","iopub.status.idle":"2021-11-03T05:41:13.728009Z","shell.execute_reply.started":"2021-11-03T05:41:13.541605Z","shell.execute_reply":"2021-11-03T05:41:13.72708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('VotingRegressor')\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_naiv, y_naiv)):\n    print('fold->',fold+1)\n    X_naiv_train, X_Naivtest = X_naiv.loc[train_idx], X_naiv.loc[test_idx]\n    y_naiv_train, y_naiv_test = y_naiv.loc[train_idx], y_naiv.loc[test_idx]\n    ensemble.fit(X_naiv_train, y_naiv_train)\n    test_preds_ens.append(ensemble.predict(X_s_naiv))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:04:11.457479Z","iopub.execute_input":"2021-11-03T06:04:11.457811Z","iopub.status.idle":"2021-11-03T07:00:36.87336Z","shell.execute_reply.started":"2021-11-03T06:04:11.457774Z","shell.execute_reply":"2021-11-03T07:00:36.87193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_naiv\ndel y_naiv\ndel X_s_naiv\n\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_ens = submission\nsub_ens['pressure'] = sum(test_preds_ens)/5\nsub_ens.to_csv('submission_ens.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:00:36.877714Z","iopub.execute_input":"2021-11-03T07:00:36.878013Z","iopub.status.idle":"2021-11-03T07:00:52.025975Z","shell.execute_reply.started":"2021-11-03T07:00:36.877962Z","shell.execute_reply":"2021-11-03T07:00:52.02494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'VotingRegressor', 'наивный feature engineering', '4.5196')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_preds_ens\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_blend = submission\nsub_blend['pressure'] = (sub_dtr['pressure'],+sub_abr['pressure']+ sub_br['pressure']+sub_ens['pressure']+ sub_cb['pressure'])/5\nsub_blend.to_csv('submission_blend.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del sub_cb\ndel sub_dtr\ndel sub_abr\ndel sub_br\ndel sub_ens\ndel sub_blend\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.3 Регрессия на доработанных признаках\nДобавим некоторые признаки. \n\nСоздадим датасеты для преобразования","metadata":{}},{"cell_type":"code","source":"df_tr = train\ndf_te = test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ndel test\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Последнее значение на выходном клапане last_value_u_in\nidxmax_time_step = df_tr.groupby('breath_id')['time_step'].idxmax()\nlast_value_u_in = df_tr.loc[idxmax_time_step, ['breath_id','u_in']]\nlast_value_u_in.columns = ['breath_id','last_value_u_in']\n\ndf_tr = df_tr.merge(last_value_u_in, on='breath_id')\n \nidxmax_time_step = df_te.groupby('breath_id')['time_step'].idxmax()\nlast_value_u_in = df_te.loc[idxmax_time_step, ['breath_id','u_in']]\nlast_value_u_in.columns = ['breath_id','last_value_u_in']\n\ndf_te = df_te.merge(last_value_u_in, on='breath_id')\ndf_te.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del idxmax_time_step\ndel last_value_u_in\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Среднее значение на входном клапане mean value u_in\nmean_u_in = df_tr.groupby('breath_id')['u_in'].mean().to_frame()\nmean_u_in.columns = ['mean_value_u_in']\ndf_tr = df_tr.merge(mean_u_in,on='breath_id')\n\nmean_u_in = df_te.groupby('breath_id')['u_in'].mean().to_frame()\nmean_u_in.columns = ['mean_value_u_in']\ndf_te = df_te.merge(mean_u_in,on='breath_id')\ndf_te.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Разница на входном клапане diff of value_u_in\ndf_tr['diff_u_in'] = df_tr.groupby('breath_id')['u_in'].diff()\ndf_tr = df_tr.fillna(0)\ndf_tr.head()\n\ndf_te['diff_u_in'] = df_te.groupby('breath_id')['u_in'].diff()\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Сумма на входном клапане накопительным итогом\ndf_tr['u_in_cumsum'] = (df_tr['u_in']).groupby(df_tr['breath_id']).cumsum()\ndf_te['u_in_cumsum'] = (df_te['u_in']).groupby(df_te['breath_id']).cumsum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Сумма на входном клапане обычная\nsum_u_in = df_tr.groupby('breath_id')['u_in'].sum().to_frame()\nsum_u_in.columns = ['sum_value_u_in']\ndf_tr = df_tr.merge(sum_u_in,on='breath_id')\n\nsum_u_in = df_te.groupby('breath_id')['u_in'].sum().to_frame()\nsum_u_in.columns = ['sum_value_u_in']\ndf_te = df_te.merge(sum_u_in,on='breath_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del sum_u_in\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Отношение накопительной суммы к обычной на входном клапане\ndf_tr[\"u_in_cumsum_rate\"] = df_tr[\"u_in_cumsum\"] / df_tr[\"sum_value_u_in\"]\ndf_te[\"u_in_cumsum_rate\"] = df_te[\"u_in_cumsum\"] / df_te[\"sum_value_u_in\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Если у вдоха нулевое значение на входном клапане\ndf_tr[df_tr[\"sum_value_u_in\"] == 0]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te[df_te[\"sum_value_u_in\"] == 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr = df_tr.fillna(0)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные входного клапана при сдвиге на один шаг\ndf_tr['lag_u_in'] = df_tr.groupby('breath_id')['u_in'].shift(1)\ndf_tr = df_tr.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te['lag_u_in'] = df_te.groupby('breath_id')['u_in'].shift(1)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные входного клапана при сдвиге на два шага\ndf_tr['lag_2_u_in'] = df_tr.groupby('breath_id')['u_in'].shift(2)\ndf_tr = df_tr.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te['lag_2_u_in'] = df_te.groupby('breath_id')['u_in'].shift(2)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные входного клапана при сдвиге на минус один шаг\ndf_tr['lag_-1_u_in'] = df_tr.groupby('breath_id')['u_in'].shift(-1)\ndf_tr = df_tr.fillna(0)\ndf_te['lag_-1_u_in'] = df_te.groupby('breath_id')['u_in'].shift(-1)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные входного клапана при сдвиге на минус два шага\ndf_tr['lag_-2_u_in'] = df_tr.groupby('breath_id')['u_in'].shift(-2)\ndf_tr = df_tr.fillna(0)\ndf_te['lag_-2_u_in'] = df_te.groupby('breath_id')['u_in'].shift(-2)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные входного клапана при сдвиге на минус три шага\ndf_tr['lag_-3_u_in'] = df_tr.groupby('breath_id')['u_in'].shift(-3)\ndf_tr = df_tr.fillna(0)\ndf_te['lag_-3_u_in'] = df_te.groupby('breath_id')['u_in'].shift(-3)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Данные входного клапана при сдвиге на три шага\ndf_tr['lag_3_u_in'] = df_tr.groupby('breath_id')['u_in'].shift(3)\ndf_tr = df_tr.fillna(0)\ndf_te['lag_3_u_in'] = df_te.groupby('breath_id')['u_in'].shift(3)\ndf_te = df_te.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Максимум по вдоху\ndf_tr[\"max_u_in_breathid\"] = df_tr.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")\ndf_te[\"max_u_in_breathid\"] = df_te.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Минимум по вдоху\ndf_tr['breath_id__u_in__min'] = df_tr.groupby(['breath_id'])['u_in'].transform('min')\ndf_te['breath_id__u_in__min'] = df_te.groupby(['breath_id'])['u_in'].transform('min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Произведение двух признаков\ndf_tr[\"R*C\"] = df_tr['R'] * df_tr['C']\ndf_te['R*C'] = df_te['R'] * df_te['C']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr['breath_id__u_in__diffmax'] = df_tr.groupby(['breath_id'])['u_in'].transform('max') - df_tr['u_in']\ndf_tr['breath_id__u_in__diffmean'] = df_tr.groupby(['breath_id'])['u_in'].transform('mean') - df_tr['u_in']\n\ndf_te['breath_id__u_in__diffmax'] = df_te.groupby(['breath_id'])['u_in'].transform('max') - df_te['u_in']\ndf_te['breath_id__u_in__diffmean'] = df_te.groupby(['breath_id'])['u_in'].transform('mean') - df_te['u_in']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr['breath_id__u_in__diffmax'] = df_tr.groupby(['breath_id'])['u_in'].transform('max') - df_tr['u_in']\ndf_tr['breath_id__u_in__diffmean'] = df_tr.groupby(['breath_id'])['u_in'].transform('mean') - df_tr['u_in']\n\ndf_te['breath_id__u_in__diffmax'] = df_te.groupby(['breath_id'])['u_in'].transform('max') - df_te['u_in']\ndf_te['breath_id__u_in__diffmean'] = df_te.groupby(['breath_id'])['u_in'].transform('mean') - df_te['u_in']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr['area'] = df_tr['time_step'] * df_tr['u_in']\ndf_tr['area'] = df_tr.groupby('breath_id')['area'].cumsum()\ndf_te['area'] = df_te['time_step'] * df_te['u_in']\ndf_te['area'] = df_te.groupby('breath_id')['area'].cumsum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Добавим категориальные переменные","metadata":{}},{"cell_type":"code","source":"df_tr[\"train_test\"] = \"train\"\ndf_te[\"train_test\"] = \"test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_all = pd.concat([df_tr,df_te],axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_tr\ndel df_te\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_all.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_all['R_C'] = [f'{r}_{c}' for r, c in zip(train_test_all['R'], train_test_all['C'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_all = pd.get_dummies(train_test_all,columns=[\"R_C\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_all.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_all['time_diff']=train_test_all.time_step.diff().fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tr = train_test_all[train_test_all[\"train_test\"] == \"train\"]\ndf_te = train_test_all[train_test_all[\"train_test\"] == \"test\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_test_all\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LM = True\nu_out_zero_only = False ## if train from only u_out=0 data ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train\nif(u_out_zero_only):\n    df_tr = df_tr[df_tr[\"u_out\"] == 0]\n    df_tr = df_tr.reset_index(drop=True)\nX_train = df_tr.drop([\"pressure\",\"breath_id\",\"train_test\"],axis=1)\ny_train = df_tr['pressure']\nX_test = df_te.drop([\"pressure\",\"breath_id\",\"train_test\"],axis=1)\n\nif(LM):\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    #print(scaler.mean_)\n\n    X_train_std = scaler.transform(X_train)\n\n\n    lr = LinearRegression().fit(X_train_std, y_train)\n    print(\"коэффициент детерминации = \",lr.score(X_train_std, y_train))\n\n\n    #test\n    X_test_std = scaler.transform(X_test)\n    sub_lr=submission\n    sub_lr['pressure'] = lr.predict(X_test_std)\n    sub_lr.to_csv(\"submission_lm.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'Linear Regression', 'feature engineering', '4.2873')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cum.to_csv('cum.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_tr\ndel df_te\ndel X_train\ndel y_train\ndel X_test\ndel X_train_std\ndel X_test_std\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.4 Нейросеть\n\nРазличные модели регрессии на данных, не разделённых на ряды по сету вдохов, дают не очень хороший результат. Попробуем прогнать данные через нейросеть. При этом подавать будем сетами по 80 шагов (на каждую серию вдохов).\nУчитывая, что для целей очистки памяти датафреймы удалялись, заново выгрузим данные и сделаем дополнительные признаки, а также сделаем решейпинг. ","metadata":{}},{"cell_type":"code","source":"train= pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest= pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\ntest_ids= test['id'].to_numpy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обернём составление признаков в функцию\ndef preprocess(df):\n    dfr= pd.get_dummies(df['R'], prefix= \"R_\")\n    df= pd.concat([df, dfr], axis= 1)\n    dfc= pd.get_dummies(df['C'], prefix= \"C_\")\n    df= pd.concat([df, dfc], axis= 1)\n    df= df.drop(['R', 'C'], axis= 1)\n\n    df['u_in_cumsum']= df['u_in'].groupby(df['breath_id']).cumsum()\n    df['time_step_cumsum']= df['time_step'].groupby(df['breath_id']).cumsum()\n    \n    df['u_in_min']= df['u_in'].groupby(df['breath_id']).transform('min')\n    df['u_in_max']= df['u_in'].groupby(df['breath_id']).transform('max')\n    df['u_in_mean']= df['u_in'].groupby(df['breath_id']).transform('mean')\n   \n    df['u_in_lag2']= df['u_in'].groupby(df['breath_id']).shift(2)\n    df['u_in_lag1']= df['u_in'].groupby(df['breath_id']).shift(1)\n    df['u_in_lag-1']= df['u_in'].groupby(df['breath_id']).shift(-1)\n    df['u_in_lag-2']= df['u_in'].groupby(df['breath_id']).shift(-2)\n    df= df.fillna(0)\n\n    df['u_in_diff1']= df['u_in']- df['u_in_lag1']\n    df['u_in_diff2']= df['u_in']- df['u_in_lag2']\n    df['u_in_diff3']= df['u_in_max']- df['u_in']\n    df['u_in_diff4']= df['u_in_mean']- df['u_in']\n\n    df1= df[df['u_out'] == 0]\n    df['mean_inspiratory_uin']= df1['u_in'].groupby(df['breath_id']).transform('mean')\n\n    df2= df[df['u_out'] == 1]\n    df['mean_expiratory_uin']= df2['u_in'].groupby(df['breath_id']).transform('mean')\n    \n    df['u_in_diff5']= df['mean_inspiratory_uin']- df['u_in']\n    df['u_in_diff6']= df['mean_expiratory_uin']- df['u_in']\n    \n    df= df.fillna(0)\n    \n    df['delta_t']= df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['delta_uin']= df.groupby('breath_id')['u_in'].diff().fillna(0)\n    \n    df['area']= df['u_in']*df['delta_t']\n    df['area']= df.groupby('breath_id')['area'].cumsum()\n    df['slope']= (df['delta_uin']/df['delta_t']).fillna(0)\n\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups= train.breath_id.values.reshape(-1, 80)[:, 0]\ngroups.shape\n\ntrain= preprocess(train)\ntargets= train['pressure'].to_numpy().reshape(-1, 80)\ntrain.drop(['id','pressure', \"breath_id\"], axis= 1, inplace= True)\n\ntest= preprocess(test)\ntest.drop(['id', \"breath_id\"], axis= 1, inplace= True)\ny_test= np.zeros(test.shape[0]).reshape(-1, 80)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest  = RS.transform(test)\n\nnum_features= train.shape[-1]\ntrain= train.reshape(-1, 80, num_features)\ntest= test.reshape(-1, 80, num_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset:\n    def __init__(self, data, target):\n        self.data= data\n        self.target= target\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        current_sample= self.data[idx, :, :]\n        current_target= self.target[idx, :]\n        \n        return torch.tensor(current_sample, dtype= torch.float), torch.tensor(current_target, dtype= torch.float)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(RNNModel, self).__init__()\n        \n        hidden_dim= [400, 300, 200, 100]\n        self.bilstm1= nn.LSTM(input_dim, hidden_dim[0], batch_first= True, bidirectional= True)\n        self.norm1= nn.LayerNorm(hidden_dim[0]*2)\n        \n        self.bilstm2= nn.LSTM(hidden_dim[0]*2, hidden_dim[1], batch_first= True, bidirectional= True)\n        self.norm2= nn.LayerNorm(hidden_dim[1]*2)\n        \n        self.bilstm3= nn.LSTM(hidden_dim[1]*2, hidden_dim[2], batch_first= True, bidirectional= True)\n        self.norm3= nn.LayerNorm(hidden_dim[2]*2)\n        \n        self.bilstm4= nn.LSTM(hidden_dim[2]*2, hidden_dim[3], batch_first= True, bidirectional= True)\n        self.norm4= nn.LayerNorm(hidden_dim[3]*2)\n        \n        self.fc1= nn.Linear(hidden_dim[3]*2, 100)\n        self.fc2= nn.Linear(100, output_dim)\n\n        \n    def forward(self, X):\n        pred, _= self.bilstm1(X)\n        pred= self.norm1(pred)\n        \n        pred, _= self.bilstm2(pred)\n        pred= self.norm2(pred)\n        \n        pred, _= self.bilstm3(pred)\n        pred= self.norm3(pred)\n        \n        pred, _= self.bilstm4(pred)\n        pred= self.norm4(pred)\n        \n        pred= self.fc1(pred)\n        pred= F.selu(pred)\n        \n        pred= self.fc2(pred)\n        pred= pred.squeeze(dim= 2)\n        return pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_parameters(m):\n    if isinstance(m, nn.LSTM):\n        nn.init.orthogonal_(m.weight_ih_l0.data, gain= nn.init.calculate_gain('tanh'))\n        nn.init.orthogonal_(m.weight_hh_l0.data, gain= nn.init.calculate_gain('tanh'))\n        nn.init.orthogonal_(m.weight_ih_l0_reverse.data, gain= nn.init.calculate_gain('tanh'))\n        nn.init.orthogonal_(m.weight_hh_l0_reverse.data, gain= nn.init.calculate_gain('tanh'))\n        \n        nn.init.constant_(m.bias_ih_l0.data, 0)\n        nn.init.constant_(m.bias_hh_l0.data, 0)\n        nn.init.constant_(m.bias_ih_l0_reverse.data, 0)\n        nn.init.constant_(m.bias_hh_l0_reverse.data, 0)\n        \n    if isinstance(m, nn.Linear):\n        nn.init.xavier_normal_(m.weight.data)\n        nn.init.constant_(m.bias.data, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Опишем признаки модели\ndevice= \"cuda\" if torch.cuda.is_available() else 'cpu'\nINPUT_DIM= num_features\nOUTPUT_DIM= 1\nBATCH_SIZE= 1024","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(dataloader, model, criterion, optimizer):\n    size= len(dataloader.dataset)\n    model.train()\n    batches= len(dataloader)\n    train_loss= 0\n    \n    for batch_idx, (X, y) in enumerate(dataloader):\n        X, y= X.to(device), y.to(device)\n\n        scores= model(X)\n        loss= criterion(scores, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loss= loss.item()\n        train_loss += loss\n        \n    train_loss_avg= train_loss/batches\n    print(f\"avg. train loss: {train_loss_avg}\")\n    return train_loss_avg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_model(dataloader, model, criterion):\n    \n    size= len(dataloader.dataset)\n    batches= len(dataloader)\n    model.eval()\n    test_loss= 0\n\n    with torch.no_grad():\n        for X, y in (dataloader):\n            X, y= X.to(device), y.to(device)\n      \n            scores= model(X)\n            test_loss += criterion(scores, y)\n\n    test_loss /= batches\n    print(f\"avg test loss : {test_loss}\")\n    return test_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_model(dataloader, model):\n    model.eval()\n    y_pred= np.array([])\n    \n    with torch.no_grad():\n        for X , y in dataloader:\n            X, y= X.to(device), y.to(device)\n            \n            preds= model(X)\n            preds= preds.flatten().cpu().numpy()\n            \n            y_pred= np.concatenate((y_pred, preds))\n            \n    return y_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold= GroupKFold(n_splits= 5)\nEPOCHS= 150\ncv_scores= []\npredictions= np.zeros(test_ids.shape[0])\n\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(train, targets, groups= groups)):\n    X_train, X_val= train[train_idx], train[val_idx]\n    y_train, y_val= targets[train_idx], targets[val_idx]\n    \n    train_dataset= CustomDataset(data= X_train, target= y_train)\n    val_dataset= CustomDataset(data= X_val, target= y_val)\n\n    train_loader= data.DataLoader(train_dataset, batch_size= BATCH_SIZE)\n    val_loader= data.DataLoader(val_dataset, batch_size= BATCH_SIZE)\n    \n    model= RNNModel(input_dim= INPUT_DIM, output_dim= OUTPUT_DIM).to(device)\n    model.apply(initialize_parameters)\n\n    criterion= nn.L1Loss()\n    criterion.to(device)\n\n    optimizer= optim.Adam(model.parameters(), lr= 0.001)\n    scheduler= optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor= 0.5, patience= 10, verbose= True)\n    \n    best_valid_loss= float('inf')\n    \n    avg_train_losses= []\n    avg_val_losses= []\n    \n    for t in range(EPOCHS):\n        print(f\"Epoch: {t+1}\")\n        train_loss= train_model(train_loader, model, criterion, optimizer)\n        val_loss= val_model(val_loader, model, criterion)\n        \n        avg_train_losses.append(train_loss)\n        avg_val_losses.append(val_loss)\n        \n        if (val_loss< best_valid_loss):\n            best_valid_loss= val_loss\n            ofilename = 'ventilator%d.pth' % fold\n            torch.save(model.state_dict(),  ofilename)\n        \n        scheduler.step(val_loss)\n    \n    cv_scores.append(best_valid_loss)\n    \n    test_dataset= CustomDataset(data= test, target= y_test)\n    test_loader= data.DataLoader(test_dataset, batch_size= BATCH_SIZE)\n                       \n    model.load_state_dict(torch.load('ventilator%d.pth' % fold, map_location=device))\n    predictions += (predict_model(test_loader, model)/5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_nn= pd.DataFrame({'id': test_ids, 'pressure': predictions})\nsub_nn.to_csv('submission.csv',index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cumulated_res(df_cum, 'LSTM', 'feature engineering', '0.2288')","metadata":{},"execution_count":null,"outputs":[]}]}