{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google Brain - Ventilator Pressure Prediction\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/29594/logos/header.png?t=2021-07-29-12-44-09&quot)","metadata":{}},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)","metadata":{}},{"cell_type":"markdown","source":"# Data description\nid - globally-unique time step identifier across an entire file\n\nbreath_id - globally-unique time step for breaths\n\nR - lung attribute indicating how restricted the airway is (in cmH2O/L/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n\nC - lung attribute indicating how compliant the lung is (in mL/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloonâ€™s latex, with higher C having thinner latex and easier to blow.\n\ntime_step - the actual time stamp.\n\nu_in - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n\nu_out - the control input for the exploratory solenoid valve. Either 0 or 1.\n\npressure - the airway pressure measured in the respiratory circuit, measured in cmH2O.","metadata":{}},{"cell_type":"markdown","source":"# Import packages","metadata":{}},{"cell_type":"code","source":"# Install packages\n# !pip install boostaroota","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:01:48.002792Z","iopub.execute_input":"2021-10-27T08:01:48.003283Z","iopub.status.idle":"2021-10-27T08:01:48.019063Z","shell.execute_reply.started":"2021-10-27T08:01:48.003212Z","shell.execute_reply":"2021-10-27T08:01:48.018432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\npyo.init_notebook_mode() # Set notebook mode to work in offline\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom sklearn import model_selection as sk_model_selection\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\nfrom sklearn import metrics\nimport optuna\n# from boostaroota import BoostARoota\nfrom sklearn.metrics import log_loss\nfrom optuna.samplers import TPESampler\nimport functools\nfrom functools import partial\nimport xgboost as xgb\nimport joblib\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport warnings \nwarnings.filterwarnings('ignore')\nimport torch.optim as optim\nimport time\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler, normalize\nimport gc\n\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:01:48.020816Z","iopub.execute_input":"2021-10-27T08:01:48.021143Z","iopub.status.idle":"2021-10-27T08:01:56.450785Z","shell.execute_reply.started":"2021-10-27T08:01:48.021107Z","shell.execute_reply":"2021-10-27T08:01:56.449947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\nsample_submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\ntest_data = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:01:56.454499Z","iopub.execute_input":"2021-10-27T08:01:56.454713Z","iopub.status.idle":"2021-10-27T08:02:09.959114Z","shell.execute_reply.started":"2021-10-27T08:01:56.454688Z","shell.execute_reply":"2021-10-27T08:02:09.95833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# u_in - 0 is completely closed and no air is let in and 100 is completely open\n# u_out - the exploratory valve is open (1) or closed (0) to let air out.\nprint(train_data.shape)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:09.961002Z","iopub.execute_input":"2021-10-27T08:02:09.961427Z","iopub.status.idle":"2021-10-27T08:02:09.984013Z","shell.execute_reply.started":"2021-10-27T08:02:09.961387Z","shell.execute_reply":"2021-10-27T08:02:09.983122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('# Breath IDs in train data:', train_data['breath_id'].nunique())\ntrain_data[train_data['breath_id']==1]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:09.986684Z","iopub.execute_input":"2021-10-27T08:02:09.986951Z","iopub.status.idle":"2021-10-27T08:02:10.065975Z","shell.execute_reply.started":"2021-10-27T08:02:09.986913Z","shell.execute_reply":"2021-10-27T08:02:10.065222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data['breath_id'].nunique())\ntrain_data[train_data['breath_id']==2]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:10.067432Z","iopub.execute_input":"2021-10-27T08:02:10.067896Z","iopub.status.idle":"2021-10-27T08:02:10.125621Z","shell.execute_reply.started":"2021-10-27T08:02:10.067859Z","shell.execute_reply":"2021-10-27T08:02:10.124892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data['breath_id'].nunique())\ntrain_data[train_data['breath_id']==3]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:10.127177Z","iopub.execute_input":"2021-10-27T08:02:10.127705Z","iopub.status.idle":"2021-10-27T08:02:10.187654Z","shell.execute_reply.started":"2021-10-27T08:02:10.127665Z","shell.execute_reply":"2021-10-27T08:02:10.186861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = train_data.groupby(['breath_id']).agg({'R':'nunique','C':'nunique'}).reset_index()\nprint('# Breath ids with >1 R or >1 C:', temp[(temp['R']>1) | (temp['C']>1)].shape[0])\ntemp.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:10.189116Z","iopub.execute_input":"2021-10-27T08:02:10.189377Z","iopub.status.idle":"2021-10-27T08:02:10.813321Z","shell.execute_reply.started":"2021-10-27T08:02:10.189343Z","shell.execute_reply":"2021-10-27T08:02:10.812535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['R'].unique(), train_data['C'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:10.814788Z","iopub.execute_input":"2021-10-27T08:02:10.815187Z","iopub.status.idle":"2021-10-27T08:02:10.882347Z","shell.execute_reply.started":"2021-10-27T08:02:10.815151Z","shell.execute_reply":"2021-10-27T08:02:10.881486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = train_data.groupby(['breath_id']).size().reset_index().rename(columns = {0:'# Entries'})\nprint(temp['# Entries'].unique())\ntemp","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:10.883805Z","iopub.execute_input":"2021-10-27T08:02:10.884064Z","iopub.status.idle":"2021-10-27T08:02:10.996647Z","shell.execute_reply.started":"2021-10-27T08:02:10.88403Z","shell.execute_reply":"2021-10-27T08:02:10.995811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data['id'].nunique(), train_data.shape)\ntrain_data[train_data['id']==1]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:10.998257Z","iopub.execute_input":"2021-10-27T08:02:10.998529Z","iopub.status.idle":"2021-10-27T08:02:11.396591Z","shell.execute_reply.started":"2021-10-27T08:02:10.998492Z","shell.execute_reply":"2021-10-27T08:02:11.395894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:11.398126Z","iopub.execute_input":"2021-10-27T08:02:11.39861Z","iopub.status.idle":"2021-10-27T08:02:12.473473Z","shell.execute_reply.started":"2021-10-27T08:02:11.398571Z","shell.execute_reply":"2021-10-27T08:02:12.47275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_submission.shape)\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:12.474759Z","iopub.execute_input":"2021-10-27T08:02:12.475429Z","iopub.status.idle":"2021-10-27T08:02:12.486809Z","shell.execute_reply.started":"2021-10-27T08:02:12.475361Z","shell.execute_reply":"2021-10-27T08:02:12.486025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_data.shape)\nprint('# Breath IDs in test data:', test_data['breath_id'].nunique())\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:12.491365Z","iopub.execute_input":"2021-10-27T08:02:12.491907Z","iopub.status.idle":"2021-10-27T08:02:12.5294Z","shell.execute_reply.started":"2021-10-27T08:02:12.491876Z","shell.execute_reply":"2021-10-27T08:02:12.528541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = test_data.groupby(['breath_id']).agg({'R':'nunique','C':'nunique'}).reset_index()\nprint('# Breath ids with >1 R or >1 C:', temp[(temp['R']>1) | (temp['C']>1)].shape[0])\ntemp.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:12.530789Z","iopub.execute_input":"2021-10-27T08:02:12.531197Z","iopub.status.idle":"2021-10-27T08:02:12.930543Z","shell.execute_reply.started":"2021-10-27T08:02:12.531144Z","shell.execute_reply":"2021-10-27T08:02:12.929646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['R'].unique(), test_data['C'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:12.931861Z","iopub.execute_input":"2021-10-27T08:02:12.932244Z","iopub.status.idle":"2021-10-27T08:02:12.980117Z","shell.execute_reply.started":"2021-10-27T08:02:12.932207Z","shell.execute_reply":"2021-10-27T08:02:12.979322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = test_data.groupby(['breath_id']).size().reset_index().rename(columns = {0:'# Entries'})\nprint(temp['# Entries'].unique())\ntemp","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:12.981377Z","iopub.execute_input":"2021-10-27T08:02:12.981707Z","iopub.status.idle":"2021-10-27T08:02:13.059841Z","shell.execute_reply.started":"2021-10-27T08:02:12.981663Z","shell.execute_reply":"2021-10-27T08:02:13.059013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data summaries","metadata":{}},{"cell_type":"code","source":"def interactive_line_chart(Breath_ID):\n    # Create traces\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(y=train_data[train_data['breath_id']==Breath_ID][\"pressure\"], \n                             x = train_data[train_data['breath_id']==Breath_ID]['time_step'],\n                        mode='lines',\n                        name='pressure'))\n    fig.add_trace(go.Scatter(y=train_data[train_data['breath_id']==Breath_ID][\"u_in\"], \n                             x = train_data[train_data['breath_id']==Breath_ID]['time_step'],\n                        mode='lines',\n                        name='u_in'))\n    fig.add_trace(go.Scatter(y=train_data[train_data['breath_id']==Breath_ID][\"u_out\"], \n                             x = train_data[train_data['breath_id']==Breath_ID]['time_step'],\n                        mode='lines',\n                        name='u_out'))\n\n    # Edit the layout\n    fig.update_layout(title='Variation by time step',\n                       xaxis_title='Time step',\n                       yaxis_title='Value')\n    fig.show()\n    \nw = widgets.interactive(interactive_line_chart, Breath_ID = train_data['breath_id'].unique().tolist())\ndisplay(w)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:13.061304Z","iopub.execute_input":"2021-10-27T08:02:13.061581Z","iopub.status.idle":"2021-10-27T08:02:13.721Z","shell.execute_reply.started":"2021-10-27T08:02:13.061544Z","shell.execute_reply":"2021-10-27T08:02:13.720345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(train_data.groupby(['breath_id']).agg({'pressure':'mean'}).reset_index(), x=\"pressure\", nbins=20)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:13.722291Z","iopub.execute_input":"2021-10-27T08:02:13.723089Z","iopub.status.idle":"2021-10-27T08:02:14.910788Z","shell.execute_reply.started":"2021-10-27T08:02:13.72305Z","shell.execute_reply":"2021-10-27T08:02:14.910135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pressure = np.sort(train_data.pressure.unique())\nPRESSURE_MIN = all_pressure[0].item()\nPRESSURE_MAX = all_pressure[-1].item()\nPRESSURE_STEP = ( all_pressure[1] - all_pressure[0] ).item()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:14.912073Z","iopub.execute_input":"2021-10-27T08:02:14.912803Z","iopub.status.idle":"2021-10-27T08:02:15.011217Z","shell.execute_reply.started":"2021-10-27T08:02:14.912764Z","shell.execute_reply":"2021-10-27T08:02:15.010399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Insights from EDA:\n\nThere are 80 entries for every breath_id. Hence we can consider a sequence of 80 steps to feed data into a LSTM model or we can build tree-based models/perceptron/other models by feeding 80 * features.\n\nR and C are constant for a breath id. Also, there are only 3 unique entries for R and C for all breath ids in train and test datasets.","metadata":{}},{"cell_type":"markdown","source":"# Pre-processing data for modelling","metadata":{}},{"cell_type":"code","source":"# Splitting into train and validation datasets\nbreath_id_list = train_data['breath_id'].unique().tolist()\ndf_train, df_valid = sk_model_selection.train_test_split(\n    breath_id_list, \n    test_size=0.2, \n    random_state=SEED)\n\ndf_train = train_data[train_data['breath_id'].isin(df_train)].reset_index(drop = True)\ndf_valid = train_data[train_data['breath_id'].isin(df_valid)].reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:15.012667Z","iopub.execute_input":"2021-10-27T08:02:15.012924Z","iopub.status.idle":"2021-10-27T08:02:15.761615Z","shell.execute_reply.started":"2021-10-27T08:02:15.012891Z","shell.execute_reply":"2021-10-27T08:02:15.760867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(df_train[['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:15.767103Z","iopub.execute_input":"2021-10-27T08:02:15.767725Z","iopub.status.idle":"2021-10-27T08:02:16.058614Z","shell.execute_reply.started":"2021-10-27T08:02:15.767676Z","shell.execute_reply":"2021-10-27T08:02:16.057924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From https://www.kaggle.com/dlaststark/gb-vpp-pulp-fiction\ndef add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    print(\"Step-2...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-3...Completed\")\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    print(\"Step-5...Completed\")\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n                                                              .groupby('breath_id')['u_in']\\\n                                                              .rolling(window=15,min_periods=1)\\\n                                                              .agg({\"15_in_sum\":\"sum\",\n                                                                    \"15_in_min\":\"min\",\n                                                                    \"15_in_max\":\"max\",\n                                                                    \"15_in_mean\":\"mean\"})\\\n                                                               .reset_index(level=0,drop=True))\n    print(\"Step-6...Completed\")\n    \n    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n    print(\"Step-7...Completed\")\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    print(\"Step-8...Completed\")\n    \n    return df\n\n\n# print(\"Train data...\\n\")\n# train = add_features(train_data)\n\n# print(\"\\nTest data...\\n\")\n# test = add_features(test_data)\n\n# del train_data\n# del test_data\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.060055Z","iopub.execute_input":"2021-10-27T08:02:16.060395Z","iopub.status.idle":"2021-10-27T08:02:16.09048Z","shell.execute_reply.started":"2021-10-27T08:02:16.060356Z","shell.execute_reply":"2021-10-27T08:02:16.089784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# targets = train[['pressure']].to_numpy()\n\n# train.drop(['id','one','count','pressure',\n#             'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n#             'breath_id_lag2same'], axis=1, inplace=True)\n\n# test = test.drop(['id','one','count','breath_id_lag',\n#                   'breath_id_lag2','breath_id_lagsame',\n#                   'breath_id_lag2same'], axis=1)\n\n# print(f\"train: {train.shape} \\ntest: {test.shape}\")\n\n# np.save('x_train.npy', train)\n# np.save('y_train.npy', targets)\n\n# np.save('x_test.npy', test)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.092057Z","iopub.execute_input":"2021-10-27T08:02:16.09262Z","iopub.status.idle":"2021-10-27T08:02:16.104621Z","shell.execute_reply.started":"2021-10-27T08:02:16.092576Z","shell.execute_reply":"2021-10-27T08:02:16.103972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = np.load('../input/ventilator_pressure_prediction_x_train/x_train.npy')\n# targets = np.load('../input/ventilator_pressure_prediction_y_train/y_train.npy')\n# test = np.load('../input/ventilator_pressure_prediction_x_test/x_test.npy')\n\n# scaler = RobustScaler()\n\n# cols = [x for x in train.columns if x!='breath_id']\n# train = scaler.fit_transform(train)\n# test = scaler.transform(test)\n\n# print(f\"train: {train.shape} \\ntest: {test.shape} \\ntargets: {targets.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.108065Z","iopub.execute_input":"2021-10-27T08:02:16.108506Z","iopub.status.idle":"2021-10-27T08:02:16.115434Z","shell.execute_reply.started":"2021-10-27T08:02:16.108463Z","shell.execute_reply":"2021-10-27T08:02:16.114691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(train.shape)\n# train[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.116713Z","iopub.execute_input":"2021-10-27T08:02:16.117057Z","iopub.status.idle":"2021-10-27T08:02:16.124897Z","shell.execute_reply.started":"2021-10-27T08:02:16.11702Z","shell.execute_reply":"2021-10-27T08:02:16.123801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, breath_id_list, train_flag):\n        self.breath_id_list = breath_id_list\n        self.train_flag = train_flag\n            \n    def __len__(self):\n        return len(self.breath_id_list)\n    \n    def __getitem__(self, index):\n        breath_id = self.breath_id_list[index]\n\n        formatted_train_data = pd.DataFrame(data = None)\n\n        if self.train_flag:\n            formatted_data = train_data[train_data['breath_id']==breath_id][['breath_id']].iloc[0:1,:].reset_index(drop = True)\n        else:\n            formatted_data = test_data[test_data['breath_id']==breath_id][['breath_id']].iloc[0:1,:].reset_index(drop = True)\n            formatted_data['pressure'] = 0\n            \n        for i in range(0, 80):\n            temp = formatted_data[formatted_data['breath_id']==breath_id][['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']].iloc[i:i+1,:].reset_index(drop = True)\n            temp = temp.sort_values(by = ['time_step'], ascending = True)\n            temp.columns = [temp.columns[j] + '_' + str(i+1) for j in range(0, len(temp.columns))]\n            formatted_data = pd.concat([formatted_data.reset_index(drop = True),temp.reset_index(drop = True)], axis = 1).reset_index(drop = True)\n            \n        formatted_train_data = pd.concat([formatted_train_data,formatted_data], axis = 0).reset_index(drop = True)\n#         cols = [x for x in formatted_train_data.columns if 'time_step_' in x] + [x for x in formatted_train_data.columns if 'R_' in x] + [x for x in formatted_train_data.columns if 'C_' in x] + [x for x in formatted_train_data.columns if 'u_in_' in x] + [x for x in formatted_train_data.columns if 'u_out_' in x]\n\n        X = torch.tensor(np.stack([formatted_train_data[[x for x in formatted_train_data.columns if 'time_step_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'R_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'C_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'u_in_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'u_out_' in x]].iloc[0]], axis = 1)).float()\n        \n        if (self.train_flag):\n            return {\"X\": X, \"y\": torch.tensor(formatted_train_data[[x for x in formatted_train_data.columns if 'pressure' in x]].iloc[0]).float()}\n        else:\n            return {\"X\": X, \"id\": breath_id}","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.126655Z","iopub.execute_input":"2021-10-27T08:02:16.126933Z","iopub.status.idle":"2021-10-27T08:02:16.144014Z","shell.execute_reply.started":"2021-10-27T08:02:16.126882Z","shell.execute_reply":"2021-10-27T08:02:16.143126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever_LSTM(torch_data.Dataset):\n    def __init__(self, breath_id_list, train_flag):\n        self.breath_id_list = breath_id_list\n        self.train_flag = train_flag\n            \n    def __len__(self):\n        return len(self.breath_id_list)\n    \n    def __getitem__(self, index):\n        breath_id = self.breath_id_list[index]\n\n        if self.train_flag:\n            formatted_data = train_data[train_data['breath_id']==breath_id].sort_values(by = ['time_step'], ascending = True)[['breath_id','R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']].reset_index(drop = True)\n        else:\n            formatted_data = test_data[test_data['breath_id']==breath_id].sort_values(by = ['time_step'], ascending = True)[['breath_id','R', 'C', 'time_step', 'u_in', 'u_out']].reset_index(drop = True)\n            formatted_data['pressure'] = 0\n        \n        # Scaling\n        formatted_data = pd.DataFrame(scaler.transform(formatted_data[['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']])).reset_index(drop = True)\n        formatted_data.columns = ['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']\n        \n        X = torch.tensor(np.stack([formatted_data['time_step'], formatted_data['R'], formatted_data['C'], formatted_data['u_in'], formatted_data['u_out']], axis = 1)).float()\n        \n        if (self.train_flag):\n            return {\"X\": X, \"y\": torch.tensor(formatted_data['pressure']).float()}\n        else:\n            return {\"X\": X, \"id\": breath_id}","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.145595Z","iopub.execute_input":"2021-10-27T08:02:16.145866Z","iopub.status.idle":"2021-10-27T08:02:16.160283Z","shell.execute_reply.started":"2021-10-27T08:02:16.145831Z","shell.execute_reply":"2021-10-27T08:02:16.159507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"formatted_train_data = pd.DataFrame(data = None)\nbreath_id_list = train_data['breath_id'].unique().tolist()[:10]\n\nfor breath_id in tqdm(breath_id_list):\n    formatted_data = train_data[train_data['breath_id']==breath_id][['breath_id']].iloc[0:1,:].reset_index(drop = True)\n    for i in range(0, 80):\n        temp = train_data[train_data['breath_id']==breath_id][['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']].iloc[i:i+1,:].reset_index(drop = True)\n        temp.columns = [temp.columns[j] + '_' + str(i+1) for j in range(0, len(temp.columns))]\n        formatted_data = pd.concat([formatted_data.reset_index(drop = True),temp.reset_index(drop = True)], axis = 1).reset_index(drop = True)\n    formatted_train_data = pd.concat([formatted_train_data,formatted_data], axis = 0).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:16.161577Z","iopub.execute_input":"2021-10-27T08:02:16.162014Z","iopub.status.idle":"2021-10-27T08:02:32.872027Z","shell.execute_reply.started":"2021-10-27T08:02:16.161979Z","shell.execute_reply":"2021-10-27T08:02:32.871254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"formatted_train_data = formatted_train_data[[x for x in formatted_train_data.columns if 'pressure' not in x] + [x for x in formatted_train_data.columns if 'pressure' in x]]\nformatted_train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:32.873712Z","iopub.execute_input":"2021-10-27T08:02:32.874279Z","iopub.status.idle":"2021-10-27T08:02:32.903741Z","shell.execute_reply.started":"2021-10-27T08:02:32.874239Z","shell.execute_reply":"2021-10-27T08:02:32.90283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tree-based model","metadata":{}},{"cell_type":"code","source":"# TBU","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:32.905551Z","iopub.execute_input":"2021-10-27T08:02:32.905844Z","iopub.status.idle":"2021-10-27T08:02:32.909642Z","shell.execute_reply.started":"2021-10-27T08:02:32.905792Z","shell.execute_reply":"2021-10-27T08:02:32.908708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Perceptron","metadata":{}},{"cell_type":"code","source":"# TBU","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:32.911481Z","iopub.execute_input":"2021-10-27T08:02:32.911779Z","iopub.status.idle":"2021-10-27T08:02:32.920335Z","shell.execute_reply.started":"2021-10-27T08:02:32.91174Z","shell.execute_reply":"2021-10-27T08:02:32.919343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML models - Logistic regression","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n        super(LSTMModel, self).__init__()\n\n        self.device = device\n        # Defining the number of layers and the nodes in each layer\n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n\n        # LSTM layers\n        self.lstm = nn.LSTM(\n            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n        )\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n#         self.relu = nn.ReLU()\n\n    def forward(self, x):\n        # Initializing hidden state for first input with zeros\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n        h0.to(self.device)\n\n        # Initializing cell state for first input with zeros\n        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n        c0.to(self.device)\n        \n        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n        # If we don't, we'll backprop all the way to the start even after going through another batch\n        # Forward propagation by passing in the input, hidden state, and cell state into the model\n        out, (hn, cn) = self.lstm(x, (h0.detach().to(self.device), c0.detach().to(self.device)))\n\n        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n        # so that it can fit into the fully connected layer\n        out = out[:, -1, :]\n\n        # Convert the final state to our desired output shape (batch_size, output_dim)\n        out = self.fc(out)\n        \n#         out = self.relu(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:32.921901Z","iopub.execute_input":"2021-10-27T08:02:32.92226Z","iopub.status.idle":"2021-10-27T08:02:32.936272Z","shell.execute_reply.started":"2021-10-27T08:02:32.922218Z","shell.execute_reply":"2021-10-27T08:02:32.935267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        train_loss_list = []\n        val_loss_list = []\n        train_mae_list = []\n        val_mae_list = []\n        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_mae, train_mse, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_mae, valid_mse, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, mae: {:.4f}, time: {:.4f} s            \",\n                n_epoch, train_loss, train_mae, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, mae: {:.4f}, time: {:.4f} s\",\n                n_epoch, valid_loss, valid_mae, valid_time\n            )\n\n            if self.best_valid_score > valid_loss: \n                self.info_message(\n                     \"Validation loss improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.save_model(n_epoch, save_path, valid_loss)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            train_loss_list.append(train_loss)\n            val_loss_list.append(valid_loss)\n            train_mae_list.append(train_mae)\n            val_mae_list.append(valid_mae)\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValidation loss didn't improve last {} epochs.\", patience)\n                break\n                \n        return {'train_loss':train_loss_list, 'val_loss':val_loss_list, 'train_mae':train_mae_list, 'val_mae':val_mae_list,'n_epoch':n_epoch}\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n        runnning_mae = 0\n        runnning_mse = 0\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            \n            outputs = self.model(X)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            error = ((torch.abs(outputs - targets).sum(axis = 1)/outputs.shape[1]).sum()/outputs.shape[0]).data\n            squared_error = (((((outputs - targets)*(outputs - targets)).sum(axis = 1))/outputs.shape[1]).sum()/(outputs.shape[0])).data\n            (torch.abs(outputs - targets).sum(axis = 1)/outputs.shape[1]).sum()/outputs.shape[0]\n            runnning_mae += error\n            runnning_mse += squared_error\n            \n            message = 'Train Step {}/{}, train_loss: {:.4f}, train_mae: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss/step, runnning_mae/step, end=\"\\r\")\n        \n        return sum_loss/len(train_loader), runnning_mae/len(train_loader), runnning_mse/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        runnning_mae = 0\n        runnning_mse = 0\n \n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n#                 y_all.extend(batch[\"y\"].tolist())\n\n                error = ((torch.abs(outputs - targets).sum(axis = 1)/outputs.shape[1]).sum()/outputs.shape[0]).data\n                squared_error = (((((outputs - targets)*(outputs - targets)).sum(axis = 1))/outputs.shape[1]).sum()/(outputs.shape[0])).data\n                runnning_mae += error\n                runnning_mse += squared_error\n\n            message = 'Valid Step {}/{}, valid_loss: {:.4f}, valid_mae: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss/step, runnning_mae/step, end=\"\\r\")\n            \n        return sum_loss/len(valid_loader), runnning_mae/len(train_loader), runnning_mse/len(train_loader), int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss):\n        self.lastmodel = f\"{save_path}\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:32.937945Z","iopub.execute_input":"2021-10-27T08:02:32.93832Z","iopub.status.idle":"2021-10-27T08:02:32.974602Z","shell.execute_reply.started":"2021-10-27T08:02:32.938215Z","shell.execute_reply":"2021-10-27T08:02:32.973905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ninput_dim = 5\noutput_dim = 80\nhidden_dim = 128\nlayer_dim = 3\nbatch_size = 128\ndropout = 0.02\nn_epochs = 30\npatient_epochs = 20\nlearning_rate = 1e-3\nweight_decay = 1e-6\n\nmodel_params = {'input_dim': input_dim,\n                'hidden_dim' : hidden_dim,\n                'layer_dim' : layer_dim,\n                'output_dim' : output_dim,\n                'dropout_prob' : dropout,\n                'device' : device}\n\nmodel = LSTMModel(**model_params)\n\nmodel.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\ncriterion = nn.L1Loss(reduction='mean')\n\n# train_data_retriever = DataRetriever_LSTM(\n#     df_train[\"breath_id\"].unique().tolist(),\n#     train_flag = True)\n\n# train_loader = torch_data.DataLoader(\n#     train_data_retriever,\n#     batch_size=batch_size,\n#     shuffle=True,\n#     num_workers=8,\n# )\n\n# valid_data_retriever = DataRetriever_LSTM(\n#     df_valid[\"breath_id\"].unique().tolist(),\n#     train_flag = True)\n\n# valid_loader = torch_data.DataLoader(\n#     valid_data_retriever,\n#     batch_size=batch_size,\n#     shuffle=False,\n#     num_workers=8,\n# )\n\n# trainer = Trainer(\n#     model, \n#     device, \n#     optimizer, \n#     criterion\n# )\n\n# history = trainer.fit(\n#     n_epochs, \n#     train_loader,\n#     valid_loader, \n#     f\"lstm_model.pth\",\n#     patient_epochs,\n# )","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:32.975616Z","iopub.execute_input":"2021-10-27T08:02:32.978349Z","iopub.status.idle":"2021-10-27T08:02:38.509455Z","shell.execute_reply.started":"2021-10-27T08:02:32.978305Z","shell.execute_reply":"2021-10-27T08:02:38.508416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = pd.DataFrame(data = {'Train loss':history['train_loss'],'Validation loss':history['val_loss']}, columns = ['Train loss', 'Validation loss'])\n# temp['epoch'] = temp.index + 1\n\n# # Create traces\n# fig = go.Figure()\n# fig.add_trace(go.Scatter(y=temp[\"Train loss\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Train loss'))\n# fig.add_trace(go.Scatter(y=temp[\"Validation loss\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Validation loss'))\n# # Edit the layout\n# fig.update_layout(title='Model loss',\n#                    xaxis_title='Epoch',\n#                    yaxis_title='Loss')\n# fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:38.51061Z","iopub.execute_input":"2021-10-27T08:02:38.510853Z","iopub.status.idle":"2021-10-27T08:02:38.514308Z","shell.execute_reply.started":"2021-10-27T08:02:38.510818Z","shell.execute_reply":"2021-10-27T08:02:38.513562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = pd.DataFrame(data = {'Train MAE':[x.cpu().numpy().item() for x in history['train_mae']],'Validation MAE':[x.cpu().numpy().item() for x in history['val_mae']]}, columns = ['Train MAE', 'Validation MAE'])\n# temp['epoch'] = temp.index + 1\n\n# # Create traces\n# fig = go.Figure()\n# fig.add_trace(go.Scatter(y=temp[\"Train MAE\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Train MAE'))\n# fig.add_trace(go.Scatter(y=temp[\"Validation MAE\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Validation MAE'))\n# # Edit the layout\n# fig.update_layout(title='Model accuracy',\n#                    xaxis_title='Epoch',\n#                    yaxis_title='MAE')\n# fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:38.516211Z","iopub.execute_input":"2021-10-27T08:02:38.516828Z","iopub.status.idle":"2021-10-27T08:02:38.538216Z","shell.execute_reply.started":"2021-10-27T08:02:38.516787Z","shell.execute_reply":"2021-10-27T08:02:38.535022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"# Load model\n\nmodel_params = {'input_dim': input_dim,\n                'hidden_dim' : hidden_dim,\n                'layer_dim' : layer_dim,\n                'output_dim' : output_dim,\n                'dropout_prob' : dropout,\n                'device' : device}\n\nmodel = LSTMModel(**model_params)\n\ncheckpoint = torch.load(f\"../input/ventilatorpressurepredictionlstmmodel/lstm_model.pth\")\nprint(checkpoint['best_valid_score'])\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.eval()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:38.539391Z","iopub.execute_input":"2021-10-27T08:02:38.539918Z","iopub.status.idle":"2021-10-27T08:02:38.683713Z","shell.execute_reply.started":"2021-10-27T08:02:38.539879Z","shell.execute_reply":"2021-10-27T08:02:38.683016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predictions on validation data\ny_pred = []\ny_true = []\n\nvalid_data_retriever = DataRetriever_LSTM(\n    df_valid[\"breath_id\"].unique().tolist(),\n    train_flag = True)\n\nvalid_loader = torch_data.DataLoader(\n    valid_data_retriever,\n    batch_size=batch_size*5,\n    shuffle=False,\n    num_workers=8,\n)\n\nfor e, batch in enumerate(valid_loader):\n    print(f\"{e}/{len(valid_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_res = (model(batch[\"X\"].to(device))).cpu().numpy()\n        temp = pd.DataFrame(np.vstack(batch[\"X\"].cpu().numpy()))\n        temp['predicted pressure'] = np.concatenate(tmp_res)\n        temp['actual pressure'] = np.concatenate(batch[\"y\"].numpy().tolist())\n        temp.columns = ['time_step','R', 'C','u_in', 'u_out','predicted pressure','actual pressure']\n        y_pred.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'predicted pressure']])).iloc[:,5].tolist())\n        y_true.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'actual pressure']])).iloc[:,5].tolist())","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:02:38.684852Z","iopub.execute_input":"2021-10-27T08:02:38.68567Z","iopub.status.idle":"2021-10-27T08:05:00.933107Z","shell.execute_reply.started":"2021-10-27T08:02:38.68563Z","shell.execute_reply":"2021-10-27T08:05:00.931934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = np.concatenate(y_pred)\ny_true = np.concatenate(y_true)\n\n# From https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153\n# y_pred = np.round((y_pred - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\n# y_pred = np.clip(y_pred, PRESSURE_MIN, PRESSURE_MAX)\n\nprint('MAE for validation data:', np.sum((np.abs((y_pred) - (y_true)).sum(axis = 0))/len(y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:09:31.683331Z","iopub.execute_input":"2021-10-27T08:09:31.683582Z","iopub.status.idle":"2021-10-27T08:09:31.69619Z","shell.execute_reply.started":"2021-10-27T08:09:31.683555Z","shell.execute_reply":"2021-10-27T08:09:31.695142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def interactive_line_chart_for_validation(Breath_ID):\n    data_retriever = DataRetriever_LSTM(\n    [Breath_ID],\n    train_flag = True)\n    y_pred = []\n    y_true = []\n    with torch.no_grad():\n        batch = np.expand_dims(data_retriever[0][\"X\"], axis = 0)\n        tmp_res = (model(torch.tensor(batch).float().to(device))).cpu().numpy()\n        temp = pd.DataFrame(np.vstack(batch))\n        temp['predicted pressure'] = np.concatenate(tmp_res)\n        temp['actual pressure'] = data_retriever[0][\"y\"].numpy().tolist()\n        temp.columns = ['time_step','R', 'C','u_in', 'u_out','predicted pressure','actual pressure']\n        y_pred.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'predicted pressure']])).iloc[:,5].tolist())\n        y_true.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'actual pressure']])).iloc[:,5].tolist())\n\n    # Create traces\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(y=temp[\"actual pressure\"], \n                             x = temp['time_step'],\n                        mode='lines',\n                        name='actual pressure'))\n    fig.add_trace(go.Scatter(y=temp[\"predicted pressure\"], \n                             x = temp['time_step'],\n                        mode='lines',\n                        name='predicted pressure'))\n\n    # Edit the layout\n    fig.update_layout(title='Variation by time step',\n                       xaxis_title='Time step',\n                       yaxis_title='Value')\n    fig.show()\n    \nw = widgets.interactive(interactive_line_chart_for_validation, Breath_ID = train_data['breath_id'].unique().tolist())\ndisplay(w)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:10:07.96909Z","iopub.execute_input":"2021-10-27T08:10:07.96967Z","iopub.status.idle":"2021-10-27T08:10:08.88213Z","shell.execute_reply.started":"2021-10-27T08:10:07.969626Z","shell.execute_reply":"2021-10-27T08:10:08.880813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n# Predictions on test data\ny_pred = []\nids = []\n\ntest_data_retriever = DataRetriever_LSTM(\n    test_data[\"breath_id\"].unique().tolist(),\n    train_flag = False)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=batch_size*5,\n    shuffle=False,\n    num_workers=8,\n)\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_res = (model(batch[\"X\"].to(device))).cpu().numpy()\n        temp = pd.DataFrame(np.vstack(batch[\"X\"].cpu().numpy()))\n        temp['predicted pressure'] = np.concatenate(tmp_res)\n        temp.columns = ['time_step','R', 'C','u_in', 'u_out','predicted pressure']\n        y_pred.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'predicted pressure']])).iloc[:,5].tolist())\n        ids.append(batch['id'])\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:10:21.548443Z","iopub.execute_input":"2021-10-27T08:10:21.548693Z","iopub.status.idle":"2021-10-27T08:16:45.164196Z","shell.execute_reply.started":"2021-10-27T08:10:21.548662Z","shell.execute_reply":"2021-10-27T08:16:45.163321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_output = sample_submission[['id']].sort_values(by = ['id'], ascending = True)\nfinal_output['pressure'] = np.concatenate(y_pred)\n\nfinal_output.to_csv('orig_submission.csv', index = False)\n\n# From https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153\nfinal_output['pressure'] = np.round((final_output.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\nfinal_output.pressure = np.clip(final_output.pressure, PRESSURE_MIN, PRESSURE_MAX)\n\nfinal_output.to_csv('clip_submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:24:22.75822Z","iopub.execute_input":"2021-10-27T08:24:22.758951Z","iopub.status.idle":"2021-10-27T08:24:49.379366Z","shell.execute_reply.started":"2021-10-27T08:24:22.758906Z","shell.execute_reply":"2021-10-27T08:24:49.378461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_output['breath_id'] = np.concatenate([np.concatenate([[i]*80 for i in x.numpy()]) for x in ids])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:24:49.382211Z","iopub.execute_input":"2021-10-27T08:24:49.382509Z","iopub.status.idle":"2021-10-27T08:24:50.140111Z","shell.execute_reply.started":"2021-10-27T08:24:49.382454Z","shell.execute_reply":"2021-10-27T08:24:50.139367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final_output.shape)\nfinal_output.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:24:50.1413Z","iopub.execute_input":"2021-10-27T08:24:50.143344Z","iopub.status.idle":"2021-10-27T08:24:50.164345Z","shell.execute_reply.started":"2021-10-27T08:24:50.143303Z","shell.execute_reply":"2021-10-27T08:24:50.163528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test data pressure values\\n')\ndisplay(final_output['pressure'].describe())\nprint('\\nTrain data pressure values\\n')\ndisplay(train_data['pressure'].describe())","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:24:50.166798Z","iopub.execute_input":"2021-10-27T08:24:50.16761Z","iopub.status.idle":"2021-10-27T08:24:50.499671Z","shell.execute_reply.started":"2021-10-27T08:24:50.167574Z","shell.execute_reply":"2021-10-27T08:24:50.498838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(final_output.groupby(['breath_id']).agg({'pressure':'mean'}).reset_index(), x=\"pressure\", nbins=20)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:24:50.501527Z","iopub.execute_input":"2021-10-27T08:24:50.502081Z","iopub.status.idle":"2021-10-27T08:24:51.159593Z","shell.execute_reply.started":"2021-10-27T08:24:50.502041Z","shell.execute_reply":"2021-10-27T08:24:51.158911Z"},"trusted":true},"execution_count":null,"outputs":[]}]}