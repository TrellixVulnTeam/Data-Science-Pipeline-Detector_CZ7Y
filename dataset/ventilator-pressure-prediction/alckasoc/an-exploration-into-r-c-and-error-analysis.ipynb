{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\nfrom sklearn.metrics import mean_absolute_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-10T02:52:04.345897Z","iopub.execute_input":"2021-10-10T02:52:04.346247Z","iopub.status.idle":"2021-10-10T02:52:10.639001Z","shell.execute_reply.started":"2021-10-10T02:52:04.346164Z","shell.execute_reply":"2021-10-10T02:52:10.638017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(r\"../input/ventilator-pressure-prediction/train.csv\")\ntest = pd.read_csv(r\"../input/ventilator-pressure-prediction/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:10.641504Z","iopub.execute_input":"2021-10-10T02:52:10.641874Z","iopub.status.idle":"2021-10-10T02:52:26.608143Z","shell.execute_reply.started":"2021-10-10T02:52:10.641831Z","shell.execute_reply":"2021-10-10T02:52:26.604929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.R.value_counts()), print(\"\"); display(train.C.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:26.611449Z","iopub.execute_input":"2021-10-10T02:52:26.612412Z","iopub.status.idle":"2021-10-10T02:52:26.711236Z","shell.execute_reply.started":"2021-10-10T02:52:26.6121Z","shell.execute_reply":"2021-10-10T02:52:26.710691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.corr().columns, train.corr().index","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:26.712829Z","iopub.execute_input":"2021-10-10T02:52:26.713156Z","iopub.status.idle":"2021-10-10T02:52:29.977702Z","shell.execute_reply.started":"2021-10-10T02:52:26.71313Z","shell.execute_reply":"2021-10-10T02:52:29.976759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = train.corr()\ncols = corr.columns\nnp.fill_diagonal(corr.values, 0)  # Remove diagonal.\n\nhm = plt.imshow(corr)\nplt.colorbar(hm)\nplt.xticks(ticks=np.arange(len(cols)),labels=cols,rotation=90)\nplt.yticks(ticks=np.arange(len(cols)),labels=cols)\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:29.979101Z","iopub.execute_input":"2021-10-10T02:52:29.979533Z","iopub.status.idle":"2021-10-10T02:52:32.022945Z","shell.execute_reply.started":"2021-10-10T02:52:29.979493Z","shell.execute_reply":"2021-10-10T02:52:32.02209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exclude the ID columns. Hmmm, analyzing this graph, I see weak negative (?) correlation between R and C. Everything seems to be centered around the bottom right corner. The time_step feature is somehow highly correlated with the u_out feature. This also seems to be the case with time_step and u_in and pressure in fact (negative correlation: as time progresses pressure decreases; that is a given). C and u_in have a weak positive correlation. u_in and u_out unsurprisingly are negatively correlated. u_in and u_out also correlate with pressure but they are on opposite sides of the spectrum. While u_in correlates to pressure (with medium strength), u_out correlates with pressure with stronger strength (but negatively instead of positively as with u_in). ","metadata":{}},{"cell_type":"code","source":"train.boxplot(column=\"pressure\", by=\"R\")","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:32.024254Z","iopub.execute_input":"2021-10-10T02:52:32.024576Z","iopub.status.idle":"2021-10-10T02:52:48.719016Z","shell.execute_reply.started":"2021-10-10T02:52:32.024538Z","shell.execute_reply":"2021-10-10T02:52:48.718044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_r50_c10 = train[(train.R == 50) & (train.C == 10)]\ntrain_r5_c10 = train[(train.R == 5) & (train.C == 10)]\ntrain_r20_c10 = train[(train.R == 20) & (train.C == 10)]\nprint(train_r50_c10.shape, train_r5_c10.shape, train_r20_c10.shape)\n\ntrain_r50_c50 = train[(train.R == 50) & (train.C == 50)]\ntrain_r5_c50 = train[(train.R == 5) & (train.C == 50)]\ntrain_r20_c50 = train[(train.R == 20) & (train.C == 50)]\nprint(train_r50_c50.shape, train_r5_c50.shape, train_r20_c50.shape)\n\ntrain_r50_c20 = train[(train.R == 50) & (train.C == 20)]\ntrain_r5_c20 = train[(train.R == 5) & (train.C == 20)]\ntrain_r20_c20 = train[(train.R == 20) & (train.C == 20)]\nprint(train_r50_c20.shape, train_r5_c20.shape, train_r20_c20.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:48.720574Z","iopub.execute_input":"2021-10-10T02:52:48.7208Z","iopub.status.idle":"2021-10-10T02:52:49.741997Z","shell.execute_reply.started":"2021-10-10T02:52:48.72077Z","shell.execute_reply":"2021-10-10T02:52:49.741088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hmm, looks like they are mostly even. R50 and C10 are by far the msot common. R20 and C10 and R20 and C20 seem like the least common. ","metadata":{"execution":{"iopub.status.busy":"2021-10-07T04:48:26.579121Z","iopub.execute_input":"2021-10-07T04:48:26.579719Z","iopub.status.idle":"2021-10-07T04:48:26.587174Z","shell.execute_reply.started":"2021-10-07T04:48:26.579681Z","shell.execute_reply":"2021-10-07T04:48:26.58612Z"}}},{"cell_type":"code","source":"print(train_r50_c10.pressure.mean(), train_r5_c10.pressure.mean(), train_r20_c10.pressure.mean())\nprint(train_r50_c50.pressure.mean(), train_r5_c50.pressure.mean(), train_r20_c50.pressure.mean())\nprint(train_r50_c20.pressure.mean(), train_r5_c20.pressure.mean(), train_r20_c20.pressure.mean())","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:49.743351Z","iopub.execute_input":"2021-10-10T02:52:49.743564Z","iopub.status.idle":"2021-10-10T02:52:49.767042Z","shell.execute_reply.started":"2021-10-10T02:52:49.743539Z","shell.execute_reply":"2021-10-10T02:52:49.766383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_r50_c10[train_r50_c10.u_out == 0].pressure.mean())\nprint(train_r5_c10[train_r5_c10.u_out == 0].pressure.mean())\nprint(train_r20_c10[train_r20_c10.u_out == 0].pressure.mean())\n\nprint(\"\")\n\nprint(train_r50_c50[train_r50_c50.u_out == 0].pressure.mean())\nprint(train_r5_c50[train_r5_c50.u_out == 0].pressure.mean())\nprint(train_r20_c50[train_r20_c50.u_out == 0].pressure.mean())\n\nprint(\"\")\n\nprint(train_r50_c20[train_r50_c20.u_out == 0].pressure.mean())\nprint(train_r5_c20[train_r5_c20.u_out == 0].pressure.mean())\nprint(train_r20_c20[train_r20_c20.u_out == 0].pressure.mean())","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:49.768286Z","iopub.execute_input":"2021-10-10T02:52:49.768896Z","iopub.status.idle":"2021-10-10T02:52:49.914095Z","shell.execute_reply.started":"2021-10-10T02:52:49.76885Z","shell.execute_reply":"2021-10-10T02:52:49.913193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\nfor _, df in train_r50_c10.groupby(\"breath_id\"):\n    plt.plot(df.time_step, df.pressure)\n    if cnt == 10: break\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:49.91681Z","iopub.execute_input":"2021-10-10T02:52:49.91705Z","iopub.status.idle":"2021-10-10T02:52:50.216036Z","shell.execute_reply.started":"2021-10-10T02:52:49.917023Z","shell.execute_reply":"2021-10-10T02:52:50.215134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\ncnt = 0\nfor _, df in train_r50_c50.groupby(\"breath_id\"):\n    ax.plot(df.time_step, df.pressure)\n    if cnt == 10: break\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:50.217337Z","iopub.execute_input":"2021-10-10T02:52:50.217679Z","iopub.status.idle":"2021-10-10T02:52:50.462231Z","shell.execute_reply.started":"2021-10-10T02:52:50.217616Z","shell.execute_reply":"2021-10-10T02:52:50.461267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\ncnt = 0\nfor breath_id, df in train_r50_c20.groupby(\"breath_id\"):\n    ax.plot(df.time_step, df.pressure, label=breath_id)\n    ax.legend()\n    if cnt == 10: break\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:50.463701Z","iopub.execute_input":"2021-10-10T02:52:50.464027Z","iopub.status.idle":"2021-10-10T02:52:50.83311Z","shell.execute_reply.started":"2021-10-10T02:52:50.463987Z","shell.execute_reply":"2021-10-10T02:52:50.832443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, before I just plot like 7 more of these, let's take a look at some of these graphs. Most of them start from the bottom and jump up and then begin to oscillate. There are some graphs that are smooth however. These need further investigation.\n\nEDIT: I added labels to the above graph.\n\nBreath_id 87.","metadata":{}},{"cell_type":"code","source":"plt.plot(train[train.breath_id == 87].time_step, train[train.breath_id == 87].pressure)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:50.834257Z","iopub.execute_input":"2021-10-10T02:52:50.834773Z","iopub.status.idle":"2021-10-10T02:52:51.009611Z","shell.execute_reply.started":"2021-10-10T02:52:50.83473Z","shell.execute_reply":"2021-10-10T02:52:51.008686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I wonder why this breath id curves? Could it be due to a previous breath id? What about its features?","metadata":{}},{"cell_type":"code","source":"train.breath_id.unique()[:90]  # There is no breath_id 86.\n# I wonder why the breath_ids are not consecutive. ","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.011031Z","iopub.execute_input":"2021-10-10T02:52:51.011337Z","iopub.status.idle":"2021-10-10T02:52:51.061782Z","shell.execute_reply.started":"2021-10-10T02:52:51.011297Z","shell.execute_reply":"2021-10-10T02:52:51.060952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bid_87 = train[train.breath_id == 87]","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.062946Z","iopub.execute_input":"2021-10-10T02:52:51.063184Z","iopub.status.idle":"2021-10-10T02:52:51.074912Z","shell.execute_reply.started":"2021-10-10T02:52:51.063159Z","shell.execute_reply":"2021-10-10T02:52:51.074261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bid_87","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.07635Z","iopub.execute_input":"2021-10-10T02:52:51.077366Z","iopub.status.idle":"2021-10-10T02:52:51.10243Z","shell.execute_reply.started":"2021-10-10T02:52:51.077321Z","shell.execute_reply":"2021-10-10T02:52:51.101617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bid_87_corr = bid_87.corr()\ncols = bid_87_corr.columns\nnp.fill_diagonal(bid_87_corr.values, 0)  # Remove diagonal.\nhm = plt.imshow(bid_87_corr)\nplt.colorbar(hm)\nplt.xticks(ticks=np.arange(len(cols)),labels=cols,rotation=90)\nplt.yticks(ticks=np.arange(len(cols)),labels=cols)\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.103641Z","iopub.execute_input":"2021-10-10T02:52:51.103864Z","iopub.status.idle":"2021-10-10T02:52:51.376508Z","shell.execute_reply.started":"2021-10-10T02:52:51.103836Z","shell.execute_reply":"2021-10-10T02:52:51.375935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks much like the first heatmap except the correlations are much stronger. ","metadata":{}},{"cell_type":"markdown","source":"# Let's Take a Look At Where Our Model is Falling Short","metadata":{}},{"cell_type":"code","source":"NUM_FOLDS = 10\nseed = 2021","metadata":{"execution":{"iopub.status.busy":"2021-10-10T03:48:29.571167Z","iopub.execute_input":"2021-10-10T03:48:29.571705Z","iopub.status.idle":"2021-10-10T03:48:29.576401Z","shell.execute_reply.started":"2021-10-10T03:48:29.57166Z","shell.execute_reply":"2021-10-10T03:48:29.575274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # models = []\n# # for p in glob(r\"../input/gvent-10-fold-ft-bilstm-models/*\"):\n# #     models.append(keras.models.load_model(p))\n\n# def add_features(df):\n#     df['area'] = df['time_step'] * df['u_in']\n#     df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n#     df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n#     df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n#     df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n#     df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n#     df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n#     df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n#     df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n#     df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n#     df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n#     df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n#     df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n#     df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n#     df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n#     df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n#     df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n#     df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n#     df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n#     df = df.fillna(0)\n    \n#     df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n#     df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n#     df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n#     df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n#     df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n#     df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n#     df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n#     df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n#     df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n#     df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n#     df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n#     df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n#     df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n#     df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n#     df['cross']= df['u_in']*df['u_out']\n#     df['cross2']= df['time_step']*df['u_out']\n    \n#     df['R'] = df['R'].astype(str)\n#     df['C'] = df['C'].astype(str)\n#     df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n#     df = pd.get_dummies(df)\n#     return df\n\n# train_tfm = add_features(train)\n# test_tfm = add_features(test)\n# targets = train_tfm[['pressure']].to_numpy().reshape(-1, 80)\n# train_ids = train_tfm[\"breath_id\"]\n# train_time_step = train_tfm[\"time_step\"]\n# train_u_out = train_tfm[\"u_out\"]\n# train_tfm.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n# test_ids = test_tfm[\"breath_id\"]\n# test_time_step = test_tfm[\"time_step\"]\n# test_u_out = test_tfm[\"u_out\"]\n# test_tfm = test_tfm.drop(['id', 'breath_id'], axis=1)\n\n# RS = RobustScaler()\n# train_tfm = RS.fit_transform(train_tfm)\n# test_tfm = RS.transform(test_tfm)\n\n# train_tfm = train_tfm.reshape(-1, 80, train_tfm.shape[-1])\n# test_tfm = test_tfm.reshape(-1, 80, train_tfm.shape[-1])\n\n# train_ids_reshaped = train_ids.values.reshape(-1, 80)\n# test_ids_reshaped = test_ids.values.reshape(-1, 80)\n\n# train_time_step_reshaped = train_time_step.values.reshape(-1, 80)\n# test_time_step_reshaped = test_time_step.values.reshape(-1, 80)\n\n# train_u_out_reshaped = train_u_out.values.reshape(-1, 80)\n# test_u_out_reshaped = test_u_out.values.reshape(-1, 80)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.377912Z","iopub.execute_input":"2021-10-10T02:52:51.378304Z","iopub.status.idle":"2021-10-10T02:52:51.384139Z","shell.execute_reply.started":"2021-10-10T02:52:51.378256Z","shell.execute_reply":"2021-10-10T02:52:51.383465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=seed)\n# test_preds = []\n\n# # model = models[0]  # Testing out just fold 0. \n\n# for fold, (train_idx, test_idx) in enumerate(kf.split(train_tfm, targets)):\n#     if fold == 0: continue\n#     if fold == 1: continue\n#     if fold == 2: continue\n#     if fold == 3: continue\n#     if fold == 4: continue\n#     if fold == 5: continue\n#     if fold == 6: continue\n#     if fold == 7: continue\n#     if fold == 8: continue\n    \n#     X_train_time_steps, X_valid_time_steps = train_time_step_reshaped[train_idx], train_time_step_reshaped[test_idx]\n#     X_train_u_out, X_valid_u_out = train_u_out_reshaped[train_idx], train_u_out_reshaped[test_idx]\n    \n#     # Predicting on entire fold 0 valid.  \n#     model = keras.models.load_model(f\"../input/gvent-10-fold-ft-bilstm-models/folds{fold}.hdf5\")\n    \n#     X_train_ids, X_valid_ids = train_ids_reshaped[train_idx], train_ids_reshaped[test_idx]\n    \n#     X_train, X_valid = train_tfm[train_idx], train_tfm[test_idx]\n#     y_train, y_valid = targets[train_idx], targets[test_idx]\n\n#     test_preds.append(model.predict(X_valid).squeeze().reshape(-1, 1).squeeze())\n    \n# #     np.save(f\"FT_bilstm_fold{fold}_preds.npy\", test_preds[0])\n# #     np.save(f\"FT_bilstm_fold{fold}_true.npy\", y_valid)\n# #     np.save(f\"FT_bilstm_fold{fold}_ids.npy\", X_valid_ids)\n# #     np.save(f\"FT_bilstm_fold{fold}_time_steps.npy\", X_valid_time_steps)\n# #     np.save(f\"FT_bilstm_fold{fold}_u_out.npy\", X_valid_u_out)\n    \n#     err_df = pd.DataFrame({\n#         \"ids\": X_valid_ids.flatten(),\n#         \"time_steps\": X_valid_time_steps.flatten(),\n#         \"u_out\": X_valid_u_out.flatten(),\n#         \"preds\": test_preds[0],\n#         \"true\": y_valid.flatten(),\n#     })\n#     err_df.to_csv(f\"fold{fold}_err.csv\", index=False)\n    \n#     del model\n#     break","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.385673Z","iopub.execute_input":"2021-10-10T02:52:51.386216Z","iopub.status.idle":"2021-10-10T02:52:51.401471Z","shell.execute_reply.started":"2021-10-10T02:52:51.386173Z","shell.execute_reply":"2021-10-10T02:52:51.400652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_err = {}\n\nfor fold in range(10):\n    tmp_df = pd.read_csv(f\"../input/ft-bilstm-model0-fold0-error-analysis/fold{fold}_err.csv\")\n    fold_err[fold] = tmp_df","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:52:51.402713Z","iopub.execute_input":"2021-10-10T02:52:51.403311Z","iopub.status.idle":"2021-10-10T02:52:58.015139Z","shell.execute_reply.started":"2021-10-10T02:52:51.403263Z","shell.execute_reply":"2021-10-10T02:52:58.014253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold0_err_bid_9 = fold_err[0][fold_err[0].ids == 9]\n\nplt.plot(fold0_err_bid_9.time_steps, fold0_err_bid_9.preds, label=\"preds\")\nplt.plot(fold0_err_bid_9.time_steps, fold0_err_bid_9.true, label=\"true\")\nplt.axvline(fold0_err_bid_9.time_steps[np.argmax(fold0_err_bid_9.u_out)], linestyle=\"--\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T02:54:30.907336Z","iopub.execute_input":"2021-10-10T02:54:30.907657Z","iopub.status.idle":"2021-10-10T02:54:31.085232Z","shell.execute_reply.started":"2021-10-10T02:54:30.90761Z","shell.execute_reply":"2021-10-10T02:54:31.084263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ventilation_mae_loss(y_true, y_pred, u_out):\n    w = 1 - u_out\n    mae = w * np.absolute(y_true - y_pred)\n    mae = mae.sum(-1) / w.sum(-1)\n\n    return mae","metadata":{"execution":{"iopub.status.busy":"2021-10-10T03:03:56.911165Z","iopub.execute_input":"2021-10-10T03:03:56.911758Z","iopub.status.idle":"2021-10-10T03:03:56.917027Z","shell.execute_reply.started":"2021-10-10T03:03:56.911715Z","shell.execute_reply":"2021-10-10T03:03:56.91601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seed = 2021  # We already initialized this.\nn = 25  # Number of graphs. Changing this number requires changing the amount of subplots.\n\ndef plot_fold_errors(fold, seed=None, shuffle=True):\n    \n    true = fold.true.values.reshape(-1, 80)\n    ids = fold.ids.values.reshape(-1, 80)[:, 0]\n    preds = fold.preds.values.reshape(-1, 80)\n    time_steps = fold.time_steps.values.reshape(-1, 80)\n    u_out = fold.u_out.values.reshape(-1, 80)\n    \n    if shuffle:\n        if seed:\n            np.random.seed(seed)  # Seed doesn't matter here unless you want the same n graphs.\n        \n        permutation = np.random.permutation(fold.ids.nunique())        \n    \n        true = true[permutation]\n        ids = ids[permutation]\n        preds = preds[permutation]\n        time_steps = time_steps[permutation]\n        u_out = u_out[permutation]\n\n    plt.figure(figsize=(20, 20))\n    for idx in range(1, n+1):\n        plt.subplot(5, 5, idx)\n        plt.plot(time_steps[idx-1], true[idx-1], label=\"y_valid\")\n        plt.plot(time_steps[idx-1], preds[idx-1], label=\"y_pred\")\n\n        vline = time_steps[idx-1][np.argmax(u_out[idx-1])]\n        plt.axvline(vline, linestyle=\"--\")\n\n        mae = ventilation_mae_loss(preds[idx-1], true[idx-1], u_out[idx-1])\n\n        plt.title(f\"b_id: {ids[idx-1]} | mae: {mae:.4f}\")\n        plt.legend()\n\n    plt.show()\n    \nplot_fold_errors(fold_err[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-10T05:45:15.195709Z","iopub.execute_input":"2021-10-10T05:45:15.196604Z","iopub.status.idle":"2021-10-10T05:45:19.040227Z","shell.execute_reply.started":"2021-10-10T05:45:15.196563Z","shell.execute_reply":"2021-10-10T05:45:19.039582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For model 0/fold 0, the model is performing quite well on the val fold (I'd presume it is doing as well as all the other 9 folds/models). Remember this is simply a snapshot of 25 breath_ids in the validaton data for fold0 for model0's predictions. The graph's match so well, I could barely tell there was even a blue line to begin with! For most out-of-fold predictions (val predictions for fold0), it predicts pretty well with < 0.1 MAE on u_out==0. Well, to be specific I simply set a range of 80 instead of the actual time step (which might distort how the graph is shaped but won't affect how MAE is calculated. However, there might be a slight problem with how i chose to calculate the MAE. I chose the first 30 time steps instead of all the time steps right before u_out==1 to calculate the MAE. To fix this we can save the time steps and the u_out to get a more accurate representation of the errors.","metadata":{}},{"cell_type":"markdown","source":"EDIT: Because the time_steps and u_out features are relevant to the accurate calculation of the MAE, I'll look towards including them. But first, I definitely want to get at least a *rough* estimate of where the MAE is scoring high. ","metadata":{}},{"cell_type":"markdown","source":"Hmmm, let's take a look with the seed so we can at least get a reference set of 25 pressure curves to get a feel of what a high MAE and a low MAE looks like. Breath_id 11546 got a high MAE (0.134) for some reason though it looks accurate visually. The other graphs perform extremely well with MAEs around 0.06. ","metadata":{}},{"cell_type":"markdown","source":"Anyways, let's compile a list of the best performing breath_ids and the worst performing breath_ids. ","metadata":{}},{"cell_type":"markdown","source":"LATEST EDIT: I just set everything up so now you can interactively plot a random assortment of 25 pressure curves for any of the 10 folds. I'll now go through all 10 folds and look at graphs with the highest MAE!","metadata":{}},{"cell_type":"code","source":"# NUM_FOLDS = 10  # We already initialized it.\n\ndef get_highest_maes(fold, threshold=0.16):\n    \n    true = fold.true.values.reshape(-1, 80)\n    ids = fold.ids.values.reshape(-1, 80)[:, 0]\n    preds = fold.preds.values.reshape(-1, 80)\n    time_steps = fold.time_steps.values.reshape(-1, 80)\n    u_out = fold.u_out.values.reshape(-1, 80)\n        \n    fold_maes = []\n    fold_ids = []\n        \n    for row in range(true.shape[0]):\n        mae = ventilation_mae_loss(preds[row], true[row], u_out[row])\n        fold_maes.append(mae)\n        fold_ids.append(ids[row])\n        \n    fold_maes = np.array(fold_maes)\n    fold_ids = np.array(fold_ids)\n    bool_arr = fold_maes > threshold\n    \n    return pd.DataFrame({\n        \"ids\": fold_ids[bool_arr],\n        \"mae\": fold_maes[bool_arr],\n    })\n\nall_fold_maes = {}  # A dictionary where each key is a fold, and the value\n# is the df with id and mae score.\n\nfor fold in range(NUM_FOLDS):\n    all_fold_maes[fold] = get_highest_maes(fold_err[fold])","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:02:33.895198Z","iopub.execute_input":"2021-10-10T04:02:33.895464Z","iopub.status.idle":"2021-10-10T04:02:35.092454Z","shell.execute_reply.started":"2021-10-10T04:02:33.895437Z","shell.execute_reply":"2021-10-10T04:02:35.091554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_fold_maes[0].mae.hist()\n\nplt.figure(figsize=(30, 20))\n#fig, axes = plt.subplots(2, 5)\n\nfor idx in range(1, NUM_FOLDS + 1):\n    plt.subplot(2, 5, idx)\n    plt.hist(all_fold_maes[idx-1].mae.values)\n    plt.title(f\"fold{idx-1}\")\n    plt.xlabel(\"MAE\")\n    plt.ylabel(\"Frequency\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T04:35:48.038904Z","iopub.execute_input":"2021-10-10T04:35:48.039936Z","iopub.status.idle":"2021-10-10T04:35:50.009588Z","shell.execute_reply.started":"2021-10-10T04:35:48.039893Z","shell.execute_reply":"2021-10-10T04:35:50.008773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like for all 10 folds and for breath_ids that score an MAE higher than 0.16, it seems like most of them are simply slightly over 0.16 (or at least between 0 and 1). These are all heavily skewed right distributions (THANKFULLY!) but there are some noticeable outliers here and there. For instance, fold3 has an outlier sitting at 10 MAE!","metadata":{}},{"cell_type":"code","source":"def get_outlier_maes(fold):\n    d = fold.describe()\n    Q1 = d.loc[\"25%\", \"mae\"]\n    Q3 = d.loc[\"75%\", \"mae\"]\n    IQR = Q3 - Q1\n    outlier_thr = Q3 + (1.5 * IQR)  # We don't check the lower end because the dist. is skewed right.\n    \n    bool_arr = fold.mae.values > outlier_thr\n    outliers = fold[bool_arr]\n    return outliers.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T05:19:58.520696Z","iopub.execute_input":"2021-10-10T05:19:58.520971Z","iopub.status.idle":"2021-10-10T05:19:58.529345Z","shell.execute_reply.started":"2021-10-10T05:19:58.520945Z","shell.execute_reply":"2021-10-10T05:19:58.528721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outlier_maes = {}\nfor fold in range(NUM_FOLDS):\n    outlier_maes[fold] = get_outlier_maes(all_fold_maes[fold])","metadata":{"execution":{"iopub.status.busy":"2021-10-10T05:19:58.70066Z","iopub.execute_input":"2021-10-10T05:19:58.701438Z","iopub.status.idle":"2021-10-10T05:19:58.764268Z","shell.execute_reply.started":"2021-10-10T05:19:58.701397Z","shell.execute_reply":"2021-10-10T05:19:58.76368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(NUM_FOLDS):\n    print(outlier_maes[fold].shape)  # Most of these folds have roughly 200 breath_ids where the performance\n    # is considered as an outlier performance!","metadata":{"execution":{"iopub.status.busy":"2021-10-10T05:21:50.92432Z","iopub.execute_input":"2021-10-10T05:21:50.924636Z","iopub.status.idle":"2021-10-10T05:21:50.931817Z","shell.execute_reply.started":"2021-10-10T05:21:50.92459Z","shell.execute_reply":"2021-10-10T05:21:50.930769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that's enough, let's plot these outliers!\n\nNote: So we can't plot all the outliers but we can plot some of them. These outliers are at the tip top of the pyramid and are considered greater than 1.5 IQRs from the upper quartile. Let's do some further preprocessing to select the *utmost* outlandish breath_ids. I made all these intermediate steps in the case anyone (including me) wants to toy with the other values. ","metadata":{}},{"cell_type":"code","source":"outlier_maes[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-10T05:40:07.467064Z","iopub.execute_input":"2021-10-10T05:40:07.467497Z","iopub.status.idle":"2021-10-10T05:40:07.479292Z","shell.execute_reply.started":"2021-10-10T05:40:07.467448Z","shell.execute_reply":"2021-10-10T05:40:07.478416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_k = 25  # Selecting the top 25 most outlandish/largest breath_id MAEs out of all the outliers for that fold. \n\ndef plot_outlier_maes(outlier_maes, fold_err, fold, top_k):\n    \n    plt.figure(figsize=(20, 20))\n    top_k_outliers = outlier_maes[fold].sort_values(ascending=False, by=\"mae\").iloc[:top_k]\n    fold_err_fold_top_k_outliers = fold_err[fold][fold_err[fold].ids.isin(top_k_outliers.ids.values)]\n    for idx, group_tmp_df in enumerate(fold_err_fold_top_k_outliers.groupby(\"ids\")):\n        group = group_tmp_df[0]\n        tmp_df = group_tmp_df[1]\n        preds = tmp_df.preds.values\n        true = tmp_df.true.values\n        time_steps = tmp_df.time_steps.values\n        u_out = tmp_df.u_out.values\n\n        plt.subplot(5, 5, idx+1)\n        plt.plot(time_steps, true, label=\"y_valid\")\n        plt.plot(time_steps, preds, label=\"y_pred\")\n\n        vline = time_steps[np.argmax(u_out)]\n        plt.axvline(vline, linestyle=\"--\")\n\n        mae = top_k_outliers[top_k_outliers.ids == group][\"mae\"].values[0]\n        plt.title(f\"b_id: {group} | mae: {mae:.4f}\")\n        plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T06:01:16.331925Z","iopub.execute_input":"2021-10-10T06:01:16.332208Z","iopub.status.idle":"2021-10-10T06:01:16.342529Z","shell.execute_reply.started":"2021-10-10T06:01:16.33218Z","shell.execute_reply":"2021-10-10T06:01:16.341576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_outlier_maes(outlier_maes, fold_err, fold=2, top_k=top_k)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T06:42:12.853268Z","iopub.execute_input":"2021-10-10T06:42:12.853904Z","iopub.status.idle":"2021-10-10T06:42:17.537193Z","shell.execute_reply.started":"2021-10-10T06:42:12.853854Z","shell.execute_reply":"2021-10-10T06:42:17.529701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, this is very interesting! If my code doesn't have any bug that is somehow offsetting this, then it seems very apparent that most of these outlier predictions ","metadata":{}},{"cell_type":"markdown","source":"To make sure we aren't messing up the code, I'll do a quick sanity check. ","metadata":{}},{"cell_type":"code","source":"plt.plot(train[train.breath_id == 112036].time_step, train[train.breath_id == 112036].pressure)\n\n# Okay, the y_valid graph makes sense. ","metadata":{"execution":{"iopub.status.busy":"2021-10-10T06:25:35.953331Z","iopub.execute_input":"2021-10-10T06:25:35.953779Z","iopub.status.idle":"2021-10-10T06:25:36.161556Z","shell.execute_reply.started":"2021-10-10T06:25:35.953735Z","shell.execute_reply":"2021-10-10T06:25:36.160768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(fold_err[1][fold_err[1].ids == 112036].time_steps, fold_err[1][fold_err[1].ids == 112036].preds)\nplt.plot(fold_err[1][fold_err[1].ids == 112036].time_steps, fold_err[1][fold_err[1].ids == 112036].true)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T06:41:26.207957Z","iopub.execute_input":"2021-10-10T06:41:26.208526Z","iopub.status.idle":"2021-10-10T06:41:26.429099Z","shell.execute_reply.started":"2021-10-10T06:41:26.208491Z","shell.execute_reply":"2021-10-10T06:41:26.428198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, assuming the preds are accurate (which I assume them to be), this does seem like an actual issue! 😬","metadata":{}},{"cell_type":"markdown","source":"Potential Fixes:\n\n1. Maybe we can try a model for the beginning part of the breath_id?\n2. Hmm, not sure what we can do to estimate the beginning climb. There isn't much to base on when inferring when the model only sees 1 point.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}