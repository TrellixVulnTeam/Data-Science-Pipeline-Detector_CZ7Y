{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Ventilator Pressure Prediction](https://www.kaggle.com/c/ventilator-pressure-prediction): \n# Temporal Convolutional Network using Keras-TCN\n\nIn this simple \"starter\" notebook we shall be using a **Temporal Convolutional Network** layer, thanks to the [Keras-TCN](https://github.com/philipperemy/keras-tcn) package written by Philippe RÃ©my, which is based on the work in the paper [\"*An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling*\"](https://arxiv.org/pdf/1803.01271.pdf).\n\n![](https://raw.githubusercontent.com/philipperemy/keras-tcn/master/misc/Dilated_Conv.png)\n\nFirstly, install `keras-tcn`:","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -q keras-tcn --no-dependencies\nfrom tcn import TCN, tcn_full_summary","metadata":{"execution":{"iopub.status.busy":"2021-09-29T18:01:45.369914Z","iopub.execute_input":"2021-09-29T18:01:45.371895Z","iopub.status.idle":"2021-09-29T18:01:53.07979Z","shell.execute_reply.started":"2021-09-29T18:01:45.37176Z","shell.execute_reply":"2021-09-29T18:01:53.079019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is heavily based on the following two LSTM notebooks:\n* [Tensorflow LSTM Baseline](https://www.kaggle.com/ryanbarretto/tensorflow-lstm-baseline), written by [Ryan Barretto](https://www.kaggle.com/ryanbarretto)\n* [Tensorflow Bidirectional LSTM (0.234)](https://www.kaggle.com/tolgadincer/tensorflow-bidirectional-lstm-0-234), by [Tolga Dincer](https://www.kaggle.com/tolgadincer)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy  as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom tensorflow import keras\nimport tensorflow as tf","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-29T21:40:58.516993Z","iopub.execute_input":"2021-09-29T21:40:58.517247Z","iopub.status.idle":"2021-09-29T21:41:03.492104Z","shell.execute_reply.started":"2021-09-29T21:40:58.51718Z","shell.execute_reply":"2021-09-29T21:41:03.491398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read in the data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest_data  = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:41:59.486643Z","iopub.execute_input":"2021-09-29T21:41:59.486918Z","iopub.status.idle":"2021-09-29T21:42:12.851822Z","shell.execute_reply.started":"2021-09-29T21:41:59.486889Z","shell.execute_reply":"2021-09-29T21:42:12.851045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some feature engineering\nThese ideas are from various sources, not all of them are necessarily useful and are just here for demonstration purposes:","metadata":{}},{"cell_type":"code","source":"for df in (train_data, test_data):\n    df['u_in_lag'] = df.groupby('breath_id')['u_in'].shift(2).fillna(method=\"backfill\")\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['last_value_u_in'] = df.groupby('breath_id')['u_in'].transform('last')\n    df['u_in_mean'] = df.groupby('breath_id')['u_in'].transform('mean')\n    df['u_in_median'] = df.groupby('breath_id')['u_in'].transform('median')\n    df['first_value_u_in'] = df.groupby('breath_id')['u_in'].transform('first')\n    df['u_in_min'] = df.groupby('breath_id')['u_in'].transform('min')\n    df['u_in_max'] = df.groupby('breath_id')['u_in'].transform('max')\n    df['u_in_delta'] = df['u_in_max'] - df['u_in_min']","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:42:16.299385Z","iopub.execute_input":"2021-09-29T21:42:16.299917Z","iopub.status.idle":"2021-09-29T21:42:18.366161Z","shell.execute_reply.started":"2021-09-29T21:42:16.299879Z","shell.execute_reply":"2021-09-29T21:42:18.365404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get things ready","metadata":{}},{"cell_type":"code","source":"targets = train_data[['pressure']].to_numpy().reshape(-1, 80)\n\n# drop the unwanted features\ntrain_data.drop(['pressure', 'id', 'breath_id', 'u_out'], axis=1, inplace=True)\ntest_data =  test_data.drop(['id', 'breath_id', 'u_out'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:42:22.118554Z","iopub.execute_input":"2021-09-29T21:42:22.118871Z","iopub.status.idle":"2021-09-29T21:42:23.224646Z","shell.execute_reply.started":"2021-09-29T21:42:22.118834Z","shell.execute_reply":"2021-09-29T21:42:23.223905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nRS = RobustScaler()\ntrain_data = RS.fit_transform(train_data)\ntest_data  = RS.transform(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:42:26.751418Z","iopub.execute_input":"2021-09-29T21:42:26.75214Z","iopub.status.idle":"2021-09-29T21:42:29.36752Z","shell.execute_reply.started":"2021-09-29T21:42:26.752098Z","shell.execute_reply":"2021-09-29T21:42:29.36677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_features = train_data.shape[-1]\n\ntrain_data = train_data.reshape(-1, 80, n_features)\ntest_data  = test_data.reshape(-1, 80, n_features)\n\nn_epochs = 50\nn_splits =  5","metadata":{"execution":{"iopub.status.busy":"2021-09-29T21:42:31.595365Z","iopub.execute_input":"2021-09-29T21:42:31.595654Z","iopub.status.idle":"2021-09-29T21:42:31.600662Z","shell.execute_reply.started":"2021-09-29T21:42:31.595627Z","shell.execute_reply":"2021-09-29T21:42:31.59969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculation","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=n_splits, shuffle=False)\ntest_preds = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train_data, targets)):\n    print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n    X_train, X_valid = train_data[train_idx], train_data[test_idx]\n    y_train, y_valid = targets[train_idx], targets[test_idx]\n    \n    scheduler = tf.keras.optimizers.schedules.ExponentialDecay(1e-3, 200*((len(test_data)*0.8)/1024), 1e-5)\n    \n    model = keras.models.Sequential([\n        TCN(input_shape=(80, n_features), nb_filters=256, return_sequences=True, dilations=[1, 2, 4, 8, 16, 32]),\n        keras.layers.Dense(1)\n    ])\n    \n    model.compile(optimizer=\"adam\", loss=\"mae\",\n                  metrics=keras.metrics.MeanAbsoluteError())\n    \n    history = model.fit(X_train, y_train, \n                        validation_data=(X_valid, y_valid), \n                        epochs=n_epochs, \n                        batch_size=1024, \n                        callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)])\n    \n    model.save(f'Fold{fold+1} weights')\n    test_preds.append(model.predict(test_data).squeeze().reshape(-1, 1).squeeze())","metadata":{"execution":{"iopub.status.busy":"2021-09-29T18:02:12.653177Z","iopub.execute_input":"2021-09-29T18:02:12.653657Z","iopub.status.idle":"2021-09-29T18:02:34.9457Z","shell.execute_reply.started":"2021-09-29T18:02:12.653621Z","shell.execute_reply":"2021-09-29T18:02:34.943621Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot a learning curve","metadata":{}},{"cell_type":"code","source":"logs = pd.DataFrame(history.history)\n\nplt.figure(figsize=(14, 4))\nplt.subplot(1, 2, 1)\nplt.plot(logs.loc[1:,\"loss\"], lw=2, label='training loss')\nplt.plot(logs.loc[1:,\"val_loss\"], lw=2, label='validation loss')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(logs.loc[1:,\"mean_absolute_error\"], lw=2, label='training MAE')\nplt.plot(logs.loc[1:,\"val_mean_absolute_error\"], lw=2, label='validation MAE')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MAE\")\nplt.legend(loc='upper right')\nplt.show()","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\nThe submission is created from the average over each fold","metadata":{}},{"cell_type":"code","source":"submission[\"pressure\"] = sum(test_preds)/n_splits\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T18:02:34.947262Z","iopub.status.idle":"2021-09-29T18:02:34.947931Z","shell.execute_reply.started":"2021-09-29T18:02:34.947662Z","shell.execute_reply":"2021-09-29T18:02:34.94769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Related kaggle notebooks\n* [\"Temporal CNN\"](https://www.kaggle.com/christofhenkel/temporal-cnn) by [Dieter](https://www.kaggle.com/christofhenkel)\n* [\"Temporal Convolutional Network\"](https://www.kaggle.com/christofhenkel/temporal-convolutional-network) by [Dieter](https://www.kaggle.com/christofhenkel)\n* [\"(PyTorch) Temporal Convolutional Networks\"](https://www.kaggle.com/ceshine/pytorch-temporal-convolutional-networks) by [Ceshine Lee](https://www.kaggle.com/ceshine)","metadata":{}}]}