{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 0. Introduction\n- Updated 10/13/21\n- This code is a baseline with Keras LSTM method.\n- Fisaish to submit\n\n### 0-1. Libarary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport gc\nimport glob\nimport time\nimport random\nimport pandas as pd\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import RobustScaler\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:07:25.581616Z","iopub.execute_input":"2021-10-09T18:07:25.582039Z","iopub.status.idle":"2021-10-09T18:07:31.291454Z","shell.execute_reply.started":"2021-10-09T18:07:25.582007Z","shell.execute_reply":"2021-10-09T18:07:31.289952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0-2. Debug","metadata":{}},{"cell_type":"code","source":"# For debug\nclass Config:\n    def __init__(self):\n        self.config = 0\n        self.debug_size = 754\n        self.data_dir = '../input/ventilator-pressure-prediction/'\n        self.post_processing = {\n                                'max_pressure': 64.82099173863948,\n                                'min_pressure': -1.8957442945646408,\n                                'diff_pressure': 0.07030215,\n                                }\n        \nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:08:14.06564Z","iopub.execute_input":"2021-10-09T18:08:14.065929Z","iopub.status.idle":"2021-10-09T18:08:14.071747Z","shell.execute_reply.started":"2021-10-09T18:08:14.065897Z","shell.execute_reply":"2021-10-09T18:08:14.070926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1 EDA & Preprocessing\n### 1-1. Train & Test data","metadata":{}},{"cell_type":"code","source":"# Dtype Changed for low size data\ndtypes = {'id': 'int32',\n          'breath_id': 'int32',\n          'R' : 'int8',\n          'C' : 'int8',\n          'time_step': 'float64',\n          'u_in': 'float64',\n          'u_out': 'int8',\n          'pressure': 'float64'}\n\n# Read train CSV data\ndef read_train():\n    train = pd.read_csv(config.data_dir + 'train.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_train = random.sample(set(train['breath_id'].unique()), config.config_size)\n        train_tmp = pd.DataFrame()\n        for i in lst_train:\n            train_tmp = pd.concat([train_tmp, train[train['breath_id'] == i]], axis=0)\n        train = train_tmp\n    train = train.astype(dtypes)\n    return train\n\n# Read test CSV data\ndef read_test():\n    test = pd.read_csv(config.data_dir + 'test.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_test = random.sample(set(test['breath_id'].unique()), config.config_size)\n        test_tmp = pd.DataFrame()\n        for i in lst_test:\n            test_tmp = pd.concat([test_tmp, test[test['breath_id'] == i]], axis=0)\n        test = test_tmp\n    test = test.astype(dtypes)\n    return test  \n\ntrain = read_train()   \ntrain.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:08:16.475021Z","iopub.execute_input":"2021-10-09T18:08:16.475752Z","iopub.status.idle":"2021-10-09T18:08:22.222743Z","shell.execute_reply.started":"2021-10-09T18:08:16.475712Z","shell.execute_reply":"2021-10-09T18:08:22.221831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-2. Exploratory Data Analysis\n### Feature\n- id - globally-unique time step identifier across an entire file\n- breath_id - globally-unique time step for breaths\n- R - lung attribute indicating how restricted the airway is (in cmH2O/L/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n- C - lung attribute indicating how compliant the lung is (in mL/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloonâ€™s latex, with higher C having thinner latex and easier to blow.\n- time_step - the actual time stamp.\n- u_in - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n- u_out - the control input for the exploratory solenoid valve. Either 0 or 1.\n- pressure - the airway pressure measured in the respiratory circuit, measured in cmH2O.","metadata":{}},{"cell_type":"code","source":"## Describe in exclude id columns\ntrain[train.columns[1:]].describe(include='all').round(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:08:30.376727Z","iopub.execute_input":"2021-10-09T18:08:30.377011Z","iopub.status.idle":"2021-10-09T18:08:31.585068Z","shell.execute_reply.started":"2021-10-09T18:08:30.376983Z","shell.execute_reply":"2021-10-09T18:08:31.584277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-3. Time series data(pressure/ u_in / u_out)\n- from [https://www.kaggle.com/kaitohonda/beginner-lgbm](https://www.kaggle.com/kaitohonda/beginner-lgbm)","metadata":{}},{"cell_type":"code","source":"if config.config:\n    fig, ax = plt.subplots(1, 3, figsize=(30, 6))\n    sns.set(font_scale=1.2)\n    for i, num in enumerate(random.sample(lst_train, 3)):\n        df = train[train['breath_id']==num]\n        ax2 = ax[i].twinx()\n\n        sns.lineplot(data=df, x='time_step', y='pressure', label='pressure', ax=ax[i])\n        sns.lineplot(data=df, x='time_step', y='u_in', label='u_in', ax=ax[i])\n        sns.lineplot(data=df, x='time_step', y='u_out', label='u_out', ax=ax2, color='r')\n\n        ax[i].set(xlabel='Timestep', ylabel='pressure, u_in', title=f'breath_id: {num}', xlim=(-0.2, 3.2), ylim=(-5, 105))\n        ax[i].legend(loc=(0.75, 0.7))\n        ax2.legend(loc=(0.75, 0.6))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:08:35.240684Z","iopub.execute_input":"2021-10-09T18:08:35.24098Z","iopub.status.idle":"2021-10-09T18:08:35.250876Z","shell.execute_reply.started":"2021-10-09T18:08:35.240947Z","shell.execute_reply":"2021-10-09T18:08:35.250023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-4. Preprocessing","metadata":{}},{"cell_type":"code","source":"def log_exp_return(series):\n    return np.exp(np.log1p(series).diff(1).fillna(0))\n\ndef preprocessing(df):\n    # time diff\n    df['time_diff'] = df['time_step'].groupby(df['breath_id']).diff(1).fillna(0)\n    \n    # basic parameter\n    df['u_in_ratio'] = df['u_in'].groupby(df['breath_id']).apply(log_exp_return)\n    df['area_unit'] = df['u_in'] * df['time_diff']  \n    df['area_ratio'] = df['area_unit'].groupby(df['breath_id']).apply(log_exp_return) \n\n    # Create Time Windows\n    def create_time_window(df, time_min, time_max, diff_time):\n        feature_dict = {\n                        'u_in': [np.std], \n                        'area_unit': [np.std], \n                        'u_in_ratio': [np.prod, np.std],\n                        'area_ratio': [np.prod, np.std]\n                        }\n        for time_stamp in np.arange(time_min, time_max, diff_time):\n            df_tmp = df[['time_step'] + list(feature_dict.keys())][(df['time_step'] >= time_stamp - diff_time) & (df['time_step'] < time_stamp)] \\\n                        .groupby(df['breath_id']).agg(feature_dict)\n            df_tmp.columns = ['_'.join(col) for col in df_tmp.columns]\n            df = pd.merge(df, df_tmp.add_suffix(f'_{time_stamp}_term').reset_index(), on='breath_id', how='left')\n            del df_tmp\n            gc.collect()\n            time.sleep(1)\n\n        return df\n    \n    df = create_time_window(df, 0.1, 0.6, 0.1)\n\n    for i in np.arange(1, 5, 1):\n        df[f'u_in_lag_fwrd{i}'] = df['u_in'].groupby(df['breath_id']).shift(i).fillna(0)\n        df[f'u_in_lag_back{i}'] = df['u_in'].groupby(df['breath_id']).shift(int(-i)).fillna(0)       \n        df[f'area_lag_fwrd{i}'] = df['time_diff'] * df[f'u_in_lag_fwrd{i}']\n        df[f'area_lag_back{i}'] = df['time_diff'] * df[f'u_in_lag_back{i}']\n\n    # u_in parameter\n    df['last_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('last')\n    df['first_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('first')\n    df['u_in_cumsum'] = df['u_in'].groupby(df['breath_id']).cumsum()  \n    \n    # u_in area\n    df['last_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('last')\n    df['first_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('first')\n    df['area_cumsum'] = df['area_unit'].groupby(df['breath_id']).cumsum()    \n        \n    df = df.fillna(0)\n    \n    # u_out parameter\n    df['u_out'] = df['u_out'].astype('str')\n\n    # R, C parameter\n    df['R'] = df['R'].astype('str')\n    df['C'] = df['C'].astype('str')\n    df = pd.get_dummies(df, drop_first=True)\n    \n    return df\n\n\ntarget = train[\"pressure\"].values\ntrain = train.drop([\"id\", \"pressure\"], axis=1)\ntrain = preprocessing(train)\ntrain = train.drop(['breath_id'], axis=1)\nfeature_column = train.columns.values\ntime.sleep(1)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:08:38.449325Z","iopub.execute_input":"2021-10-09T18:08:38.449974Z","iopub.status.idle":"2021-10-09T18:09:48.396002Z","shell.execute_reply.started":"2021-10-09T18:08:38.449936Z","shell.execute_reply":"2021-10-09T18:09:48.395134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-5. RobustScaler","metadata":{}},{"cell_type":"code","source":"rs = RobustScaler()\ntrain = rs.fit_transform(train)\nprint(f'train shape: {train.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:09:48.39796Z","iopub.execute_input":"2021-10-09T18:09:48.398267Z","iopub.status.idle":"2021-10-09T18:09:52.347704Z","shell.execute_reply.started":"2021-10-09T18:09:48.398229Z","shell.execute_reply":"2021-10-09T18:09:52.346559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Keras\n### 2-1. Reshape Data\n- Data Reshape for Keras","metadata":{}},{"cell_type":"code","source":"# Reshape (BreathID, Time_step)\ntarget = target.reshape(-1, 80)\n\n# Reshape (BreathID, Time_step, feature)\ntrain = train.reshape(-1, 80, train.shape[-1])\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:09:55.695163Z","iopub.execute_input":"2021-10-09T18:09:55.695631Z","iopub.status.idle":"2021-10-09T18:09:55.701551Z","shell.execute_reply.started":"2021-10-09T18:09:55.695596Z","shell.execute_reply":"2021-10-09T18:09:55.700668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-2. Keras Class","metadata":{}},{"cell_type":"code","source":"class Keras:\n    def __init__(self):\n        self.models = []\n        self.results = []\n        self.timeout = 28800\n        self.batch_size = 512\n        self.n_splits = 3\n        self.epoch = 200\n        self.es = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\", restore_best_weights=True)\n        self.lr = ReduceLROnPlateau(monitor=\"val_loss\", patience=2, verbose=0, factor=0.5, min_lr=1e-8)  \n        self.kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=2021)\n        \n    def create_model(self, n_layer, activation, mid_units, dropout_rate, train):\n        inputs = keras.layers.Input(shape=train.shape[-2:])\n        x = keras.layers.Bidirectional(keras.layers.LSTM(int(mid_units), return_sequences=True))(inputs)\n        for i in range(0, n_layer):\n            x = keras.layers.Bidirectional(keras.layers.LSTM(int(mid_units / (2**(i+1))), return_sequences=True))(x)\n#         x = keras.layers.Dropout(dropout_rate)(x)\n        x = keras.layers.Dense(int(mid_units / (2**(i+2))), activation=activation)(x)\n        output = keras.layers.Dense(1)(x)\n        model = keras.models.Model(inputs, output) \n        return model\n            \n    def keras_trial(self, params, train, target):        \n        for fold, (trn_idx, val_idx) in enumerate(self.kf.split(train, target)):\n            print(f'Fold {fold+1} started at {time.ctime()}')\n            model = self.create_model(params[\"n_layer\"], \n                                      params[\"activation\"],                                      \n                                      params[\"mid_units\"], \n                                      params[\"dropout_rate\"],\n                                      train)\n            model.compile(optimizer=params[\"optimizer\"], loss=\"mae\")\n            result = model.fit(x=train[trn_idx], \n                               y=target[trn_idx], \n                               batch_size=self.batch_size, \n                               epochs=self.epoch, \n                               verbose=1, \n                               callbacks=[self.lr, self.es], \n                               validation_data=(train[val_idx], target[val_idx])\n                              )\n            \n            self.results.append(result)\n            self.models.append(model)        \n            \n            del result, model\n            gc.collect()\n            time.sleep(1)   ","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:20:49.949574Z","iopub.execute_input":"2021-10-09T18:20:49.9502Z","iopub.status.idle":"2021-10-09T18:20:49.968256Z","shell.execute_reply.started":"2021-10-09T18:20:49.950159Z","shell.execute_reply":"2021-10-09T18:20:49.967488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-3. Keras Trial","metadata":{}},{"cell_type":"code","source":"keras_inst = Keras()\nparams = {'n_layer': 3, 'mid_units': 64, 'dropout_rate': 0.01, 'activation': 'selu', 'optimizer': 'adam'}\nkeras_inst.keras_trial(params, train, target)\ndel train, target\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T18:20:53.788327Z","iopub.execute_input":"2021-10-09T18:20:53.789017Z","iopub.status.idle":"2021-10-09T18:22:24.647432Z","shell.execute_reply.started":"2021-10-09T18:20:53.78897Z","shell.execute_reply":"2021-10-09T18:22:24.646458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-4. Loss & learning ratio","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, keras_inst.n_splits, figsize=(30, 10))\nfor i in range(keras_inst.n_splits):\n    ax2 = ax[i].twinx()\n    ax[i].plot(range(1, len(keras_inst.results[i].history['loss'])+1), np.log(keras_inst.results[i].history['loss']), label=\"train\")\n    ax[i].plot(range(1, len(keras_inst.results[i].history['val_loss'])+1), np.log(keras_inst.results[i].history['val_loss']), label=\"valid\")\n    ax2.plot(range(1, len(keras_inst.results[i].history['lr'])+1), [x * 1000 for x in keras_inst.results[i].history['lr']], label=\"lr\", color=\"r\", ls=\"--\")\n    ax[i].set(xlabel='Epochs', ylabel='Loss')\n    ax2.set(ylabel=\"lr [x1000]\")\n    ax[i].legend()\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T04:04:33.858184Z","iopub.execute_input":"2021-09-29T04:04:33.858534Z","iopub.status.idle":"2021-09-29T04:04:35.829623Z","shell.execute_reply.started":"2021-09-29T04:04:33.858498Z","shell.execute_reply":"2021-09-29T04:04:35.828843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Submission","metadata":{}},{"cell_type":"code","source":"# Test does not have \"pressure\" column\ndtypes.pop('pressure')\n\ntest = read_test()\ntest = preprocessing(test)\ntest = test.drop([\"id\", 'breath_id'], axis=1)\ntest = rs.transform(test)\ntest = test.reshape(-1, 80, test.shape[-1])\ntest_shape = test.shape\nprint(test.shape)\n\ntest_preds = []\nfor model in keras_inst.models:\n    test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n\ndel test\ngc.collect()\n\nsubmission = pd.read_csv(config.data_dir + \"sample_submission.csv\")[:test_shape[0] * test_shape[1]]\nsubmission[\"pressure\"] = sum(test_preds) / keras_inst.n_splits\nsubmission[\"pressure\"] = np.round((submission[\"pressure\"] - config.post_processing[\"min_pressure\"]) / config.post_processing[\"diff_pressure\"]) * config.post_processing[\"diff_pressure\"] + config.post_processing[\"min_pressure\"]\nsubmission[\"pressure\"] = np.clip(submission[\"pressure\"], config.post_processing[\"min_pressure\"], config.post_processing[\"max_pressure\"])\nsubmission.to_csv('submission_keras.csv', index=False)\nprint(submission.tail(2))","metadata":{"execution":{"iopub.status.busy":"2021-09-29T04:04:45.76293Z","iopub.execute_input":"2021-09-29T04:04:45.763581Z","iopub.status.idle":"2021-09-29T04:04:46.827926Z","shell.execute_reply.started":"2021-09-29T04:04:45.763529Z","shell.execute_reply":"2021-09-29T04:04:46.827013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}