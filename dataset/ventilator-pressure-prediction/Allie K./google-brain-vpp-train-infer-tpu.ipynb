{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport warnings\nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport tensorflow as tf, gc\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n%matplotlib inline\n\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\nseed_everything(56)\n\nclass config:\n    paths = {'train': '../input/ventilator-pressure-prediction/train.csv',\n             'test' : '../input/ventilator-pressure-prediction/test.csv',\n             'ss'   : '../input/ventilator-pressure-prediction/sample_submission.csv', }\n    \n    model_params = {'is_train':True, 'debug':False, 'EPOCH':300, 'BATCH_SIZE':1024, 'NUM_FOLDS':8,}\n    \n    post_processing = {'max_pressure': 64.82099173863948, 'min_pressure': -1.8957442945646408,\n                       'diff_pressure': 0.07030215, }\n\ntrain = pd.read_csv(config.paths[\"train\"])\ntest = pd.read_csv(config.paths[\"test\"])\nsubmission = pd.read_csv(config.paths[\"ss\"])\n\nif config.model_params[\"debug\"]:\n    print(\"[INFO] Debug Mode...\")\n    train = train[:80*1000]\n    config.model_params[\"EPOCH\"] = 20\n    config.model_params[\"BATCH_SIZE\"] = 128\n    config.model_params[\"NUM_FOLDS\"] = 5\n\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)\n\ntargets = train[['pressure']].to_numpy().reshape(-1, 80)\n\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])\n\ndef create_model(strategy):   \n    with strategy.scope():\n        model = Sequential([keras.layers.Input(shape=train.shape[-2:]),\n                            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n                            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n                            keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n                            keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n                            keras.layers.Dense(128, activation='selu'),\n                            #keras.layers.Dropout(0.1),\n                            keras.layers.Dense(1), ])\n        model.compile(optimizer='adam', loss='mae')\n    return model\n\ndef plot_hist(hist):\n    plt.plot(hist.history[\"loss\"])\n    plt.plot(hist.history[\"val_loss\"])\n    plt.title(\"model performance\")\n    plt.ylabel(\"mean_absolute_error\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.version.VERSION)\ntry: \n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError: \n    strategy = tf.distribute.MirroredStrategy() \n    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    tf.config.optimizer.set_jit(True) # XLA compilation\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n    print('Mixed precision enabled')\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=config.model_params[\"NUM_FOLDS\"], shuffle=True, random_state=56)\ntest_preds = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n    K.clear_session()\n    print(f\"\\nFOLD: {fold}\")\n    X_train, X_valid = train[train_idx], train[test_idx]\n    y_train, y_valid = targets[train_idx], targets[test_idx]\n    \n    checkpoint_filepath = f\"./folds_{fold}.hdf5\"\n    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=0)\n    es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=0, mode=\"min\", restore_best_weights=True)\n    sv = keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_loss', verbose=0, \n                                         save_best_only=True, save_weights_only=False, mode='auto',\n                                         save_freq='epoch')\n    \n    model = create_model(strategy)\n        \n    history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n                        epochs=config.model_params[\"EPOCH\"], batch_size=config.model_params[\"BATCH_SIZE\"], \n                        callbacks = [lr, es, sv])\n    \n    test_preds.append(model.predict(test, batch_size=config.model_params[\"BATCH_SIZE\"],\n                                    verbose=1).squeeze().reshape(-1, 1).squeeze())\n    plot_hist(history)\n    del X_train, X_valid, y_train, y_valid, model\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"pressure\"] = np.median(np.vstack(test_preds), axis=0)\nsubmission.to_csv('submission_raw.csv', index=False)\n#submission[\"pressure\"] = np.round((submission.pressure - config.post_processing[\"min_pressure\"])/config.post_processing[\"diff_pressure\"]) * config.post_processing[\"diff_pressure\"] + config.post_processing[\"min_pressure\"]\n#submission.pressure = np.clip(submission.pressure, config.post_processing[\"min_pressure\"], config.post_processing[\"max_pressure\"])\n#display(submission.head())\n#submission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}