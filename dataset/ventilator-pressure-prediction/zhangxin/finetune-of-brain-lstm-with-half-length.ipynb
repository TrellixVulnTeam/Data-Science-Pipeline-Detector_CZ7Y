{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In the previous [notebook](https://www.kaggle.com/tenffe/finetune-of-tensorflow-bidirectional-lstm), we use the length of 80 to train the LSTM model. But we know LSTM would not perform well when the length of sequence is too long.\n\nIn this notebook, we use the length of 40 to train the LSTM model. we hope the little change can get a better result.","metadata":{"execution":{"iopub.status.busy":"2021-10-17T00:46:07.032948Z","iopub.execute_input":"2021-10-17T00:46:07.03336Z","iopub.status.idle":"2021-10-17T00:46:07.065163Z","shell.execute_reply.started":"2021-10-17T00:46:07.033244Z","shell.execute_reply":"2021-10-17T00:46:07.063877Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\n\nimport pickle\nfrom joblib import dump, load","metadata":{"_uuid":"e331dbcc-0346-4019-9ff6-b890154a878b","_cell_guid":"3e5a0bd1-3e22-4b2c-a565-68985e55f95e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-17T00:50:20.211712Z","iopub.execute_input":"2021-10-17T00:50:20.212265Z","iopub.status.idle":"2021-10-17T00:50:27.607962Z","shell.execute_reply.started":"2021-10-17T00:50:20.212211Z","shell.execute_reply":"2021-10-17T00:50:27.606803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]","metadata":{"_uuid":"ca71d87d-6594-4f31-906d-0b53cd4c1374","_cell_guid":"89eb257e-0ed2-4f8b-94d6-462a5e995eb1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-17T00:51:32.38462Z","iopub.execute_input":"2021-10-17T00:51:32.385515Z","iopub.status.idle":"2021-10-17T00:51:48.653641Z","shell.execute_reply.started":"2021-10-17T00:51:32.385473Z","shell.execute_reply":"2021-10-17T00:51:48.652684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile AddFeatures.py\nimport numpy as np\nimport pandas as pd\n\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df","metadata":{"_uuid":"dc41dbf2-f199-4b9d-bbd9-bf6084162b47","_cell_guid":"13a36b46-7067-4b29-aad3-7e3b15e8415b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-17T00:52:09.263018Z","iopub.execute_input":"2021-10-17T00:52:09.263382Z","iopub.status.idle":"2021-10-17T00:52:09.272529Z","shell.execute_reply.started":"2021-10-17T00:52:09.263338Z","shell.execute_reply":"2021-10-17T00:52:09.271596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrom AddFeatures import add_features\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"_uuid":"346bf2c0-96d2-4da5-8837-c0f820294a85","_cell_guid":"01328860-fa2a-421c-9e5f-ea0048246f98","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-17T00:52:10.898089Z","iopub.execute_input":"2021-10-17T00:52:10.898924Z","iopub.status.idle":"2021-10-17T00:53:07.80004Z","shell.execute_reply.started":"2021-10-17T00:52:10.898874Z","shell.execute_reply":"2021-10-17T00:53:07.799145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])\n\ndump(RS, \"RS.gz\")","metadata":{"execution":{"iopub.status.busy":"2021-10-17T00:53:55.343174Z","iopub.execute_input":"2021-10-17T00:53:55.343534Z","iopub.status.idle":"2021-10-17T00:54:12.261633Z","shell.execute_reply.started":"2021-10-17T00:53:55.343502Z","shell.execute_reply":"2021-10-17T00:54:12.260745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##############3 use 40 length\ntrain = train.reshape(-1, 2, 40, train.shape[-1])\nprint(train.shape)\ngroups = np.zeros(shape=(train.shape[0], 2))\ngroups[:, 0] = np.array(list(range(1, train.shape[0]+1)))\ngroups[:, 1] = np.array(list(range(1, train.shape[0]+1)))\n\ntrain = train.reshape(-1, 40, train.shape[-1])\ngroups = groups.reshape(-1)\nprint(train.shape, groups.shape)\n\ntest = test.reshape(-1, 2, 40, train.shape[-1])\ntest = test.reshape(-1, 40, train.shape[-1])\nprint(test.shape)\n\ntargets = targets.reshape(-1, 2, 40)\ntargets = targets.reshape(-1, 40)\nprint(targets.shape)\n\ndump(train, \"train.gz\")\ndump(targets, \"targets.gz\")\ndump(groups, \"groups.gz\")","metadata":{"execution":{"iopub.status.busy":"2021-10-17T00:54:40.006747Z","iopub.execute_input":"2021-10-17T00:54:40.007846Z","iopub.status.idle":"2021-10-17T00:55:32.116Z","shell.execute_reply.started":"2021-10-17T00:54:40.007779Z","shell.execute_reply":"2021-10-17T00:55:32.114942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 360\nBATCH_SIZE = 1024\nNUM_FOLDS = 5 # 20的时候可以到0.6\nnum_select = 5\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = GroupKFold(n_splits=NUM_FOLDS)\n    test_preds = []\n    folds_dict = {}\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets, groups=groups)):  \n        folds_dict[fold] = (train_idx, val_idx)\n        \n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape=train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n            keras.layers.Dense(128, activation='selu'),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer=\"adam\", loss=\"mae\")\n\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=10, verbose=1)\n        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        sv = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=False, mode='auto', save_freq='epoch',\n            options=None\n        )\n\n        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-17T00:55:52.462188Z","iopub.execute_input":"2021-10-17T00:55:52.462558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dump(folds_dict, \"folds_dict.gz\")\n!ls ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n# ENSEMBLE FOLDS WITH MEDIAN\nsubmission[\"pressure\"] = np.median(np.vstack(test_preds), axis=0)\nsubmission.to_csv(\"./submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/ventilator-pressure-prediction/train.csv\")\ndf_sub = pd.read_csv(\"./submission.csv\")\n\nunique_pressures = df_train[\"pressure\"].unique()\nsorted_pressures = np.sort(unique_pressures)\n\ntotal_pressures_len = len(sorted_pressures)\n\ndef find_nearest(prediction):\n    insert_idx = np.searchsorted(sorted_pressures, prediction)\n    if prediction >= sorted_pressures[-1] or insert_idx == total_pressures_len:\n        # If the predicted value is bigger than the highest pressure in the train dataset,\n        # return the max value.\n        return sorted_pressures[-1]\n    elif prediction <= sorted_pressures[0] or insert_idx == 0:\n        # Same control but for the lower bound.\n        return sorted_pressures[0]\n    lower_val = sorted_pressures[insert_idx - 1]\n    upper_val = sorted_pressures[insert_idx]\n    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val\n\ndf_sub[\"pressure\"] = df_sub[\"pressure\"].apply(find_nearest)\ndf_sub.to_csv(\"./submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}