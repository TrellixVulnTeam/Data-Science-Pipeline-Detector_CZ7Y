{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T03:17:12.400217Z","iopub.execute_input":"2022-04-05T03:17:12.400521Z","iopub.status.idle":"2022-04-05T03:17:12.420527Z","shell.execute_reply.started":"2022-04-05T03:17:12.400489Z","shell.execute_reply":"2022-04-05T03:17:12.419889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%\nfrom tensorflow.python.keras import models\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.python.keras import activations\nfrom tensorflow.python.keras import callbacks\nfrom tensorflow.python.keras import initializers\nfrom tensorflow.python.keras import backend\nfrom tensorflow.python.keras import metrics\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras_tuner as kt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nimport copy","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:21.122251Z","iopub.execute_input":"2022-04-05T03:05:21.123028Z","iopub.status.idle":"2022-04-05T03:05:26.396745Z","shell.execute_reply.started":"2022-04-05T03:05:21.122992Z","shell.execute_reply":"2022-04-05T03:05:26.395919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x_rc = np.load('../input/ventilator-traindata/train_x_rc.npy')\ntrain_x_other = np.load('../input/ventilator-traindata/train_x_other.npy')\ntargets = np.load('../input/ventilator-traindata/target.npy')\nprint(train_x_other.shape)\nprint(train_x_rc.shape)\nprint(targets.shape)\ntrain_x_ = np.concatenate([train_x_other, train_x_rc], axis=-1)\ndel train_x_rc","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:26.399159Z","iopub.execute_input":"2022-04-05T03:05:26.39986Z","iopub.status.idle":"2022-04-05T03:05:37.056769Z","shell.execute_reply.started":"2022-04-05T03:05:26.399821Z","shell.execute_reply":"2022-04-05T03:05:37.056041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ExpandTileLayer(layers.Layer):\n    def __init__(self):\n        super(ExpandTileLayer, self).__init__()\n    def call(self, inputs, *args, **kwargs):\n        return backend.tile(backend.expand_dims(inputs, axis=-2), (1, 80, 1))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:37.058868Z","iopub.execute_input":"2022-04-05T03:05:37.059128Z","iopub.status.idle":"2022-04-05T03:05:37.064531Z","shell.execute_reply.started":"2022-04-05T03:05:37.059096Z","shell.execute_reply":"2022-04-05T03:05:37.063641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    rc_input = keras.Input(shape=(15, ),\n                           dtype='int32',\n                           name='rc_input_layer')\n    other_x_input = keras.Input(shape=(80, train_x_other.shape[-1]),\n                                dtype='float32',\n                                name='other_x_input')\n    rc_embedding_layer = layers.Dense(units=16,\n                                      use_bias=False, name='rc_embed_layer')\n    rc_embedding = rc_embedding_layer(rc_input)\n\n    # 维度拓展\n    rc_embedding = ExpandTileLayer()(rc_embedding)\n\n    x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n    conv1d_1 = layers.Conv1D(filters=256,\n                             kernel_size=5,\n                             padding='same',\n                             use_bias=False)(x_input)\n    conv1d_1 = layers.Activation(activations.selu)(conv1d_1)\n    conv1d_2 = layers.Conv1D(filters=128, use_bias=False,\n                             kernel_size=5, padding='same')(conv1d_1)\n    conv1d_output = layers.Activation(activations.selu)(conv1d_2)\n    ox = layers.Bidirectional(layers.LSTM(units=512,\n                                          return_sequences=True,\n                                          kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n                              merge_mode='concat')(conv1d_output)\n\n    ox = layers.Bidirectional(layers.LSTM(units=384,\n                                          return_sequences=True,\n                                          kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n                              merge_mode='concat')(ox)\n    ox = layers.Bidirectional(layers.LSTM(units=256,\n                                          return_sequences=True,\n                                          kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n                              merge_mode='concat')(ox)\n    ox = layers.Dense(units=128,\n                      kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n    lstm_output = layers.ELU()(ox)\n\n    output = layers.Concatenate(axis=-1)([lstm_output, conv1d_output])\n    output = layers.Dense(units=256,\n                          activation=activations.selu,\n                          kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n    output = layers.Dense(units=1,\n                          kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n    my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])\n    return my_model\nmodel = build_model()\nkeras.utils.plot_model(model, './model1.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:37.066074Z","iopub.execute_input":"2022-04-05T03:05:37.06635Z","iopub.status.idle":"2022-04-05T03:05:41.314338Z","shell.execute_reply.started":"2022-04-05T03:05:37.06632Z","shell.execute_reply":"2022-04-05T03:05:41.313557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_model():\n#     rc_input = keras.Input(shape=(15, ),\n#                            dtype='int32',\n#                            name='rc_input_layer')\n#     other_x_input = keras.Input(shape=(80, train_x_other.shape[-1]),\n#                                 dtype='float32',\n#                                 name='other_x_input')\n#     rc_embedding_layer = layers.Dense(units=10,\n#                                       use_bias=False, \n#                                       activation=activations.selu,\n#                                       name='rc_embed_layer')\n#     rc_embedding = rc_embedding_layer(rc_input)\n\n#     # 维度拓展\n#     rc_embedding = ExpandTileLayer()(rc_embedding)\n\n#     x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n#     conv1d_1 = layers.Conv1D(filters=256,\n#                              kernel_size=5,\n#                              padding='same')(x_input)\n#     conv1d_1 = layers.Activation(activations.relu)(conv1d_1)\n#     conv1d_1 = layers.BatchNormalization()(conv1d_1)\n#     conv1d_2 = layers.Conv1D(filters=192, \n#                              kernel_size=5,\n#                              padding='same')(conv1d_1)\n#     conv1d_output = layers.Activation(activations.relu)(conv1d_2)\n#     conv1d_output = layers.BatchNormalization()(conv1d_output)\n#     the_feature = layers.Concatenate()([conv1d_output, x_input])\n#     ox_1 = layers.Bidirectional(layers.LSTM(units=672,\n#                                           return_sequences=True,\n#                                           kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                               merge_mode='concat')(the_feature)\n#     ox_2 = layers.Bidirectional(layers.LSTM(units=512,\n#                                           return_sequences=True,\n#                                           kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                               merge_mode='concat')(ox_1)\n#     ox = layers.Bidirectional(layers.LSTM(units=384,\n#                                           return_sequences=True,\n#                                           kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                               merge_mode='concat')(ox_2)\n#     ox = layers.Bidirectional(layers.GRU(units=192,\n#                     return_sequences=True))(ox)\n#     output = layers.Concatenate(axis=-1)([ox, conv1d_output])\n#     output = layers.Dense(units=128,\n#                           activation=activations.selu,\n#                           kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n#     output = layers.Dense(units=1,\n#                           kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n#     my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])\n    \n#     return my_model","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:41.315804Z","iopub.execute_input":"2022-04-05T03:05:41.316023Z","iopub.status.idle":"2022-04-05T03:05:41.322924Z","shell.execute_reply.started":"2022-04-05T03:05:41.315997Z","shell.execute_reply":"2022-04-05T03:05:41.322061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# def build_model():\n#     rc_input = keras.Input(shape=(15, ),\n#                            dtype='int32',\n#                            name='rc_input_layer')\n#     other_x_input = keras.Input(shape=(80, train_x_other.shape[-1]),\n#                                 dtype='float32',\n#                                 name='other_x_input')\n#     rc_embed = layers.Dense(units=10, use_bias=False, name='rc_embed_layer')(rc_input)\n#     rc_embedding = ExpandTileLayer()(rc_embed)\n#     x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n#     conv_fea = layers.Conv1D(kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                              filters=128, kernel_size=5, padding='same')(x_input)\n#     conv_fea = layers.Activation(activations.selu)(conv_fea)\n\n#     x1 = layers.Bidirectional(layers.LSTM(units=640, return_sequences=True))(x_input)\n#     x2 = layers.Bidirectional(layers.LSTM(units=512, return_sequences=True))(x1)\n#     x3 = layers.Bidirectional(layers.LSTM(units=384, return_sequences=True))(x2)\n#     x4 = layers.Bidirectional(layers.LSTM(units=256, return_sequences=True))(x3)\n    \n#     xc = layers.Concatenate()([x2, conv_fea])\n#     z2 = layers.Bidirectional(layers.GRU(units=384, return_sequences=True))(x2)\n\n#     z31 = layers.Multiply()([x3, z2])\n#     z31 = layers.BatchNormalization()(z31)\n#     z3 = layers.Bidirectional(layers.GRU(units=256, return_sequences=True))(z31)\n\n#     z41 = layers.Multiply()([x4, z3])\n#     z41 = layers.BatchNormalization()(z41)\n#     z4 = layers.Bidirectional(layers.GRU(units=128, return_sequences=True))(z41)\n\n#     x = layers.Concatenate(axis=2)([x4, z2, z3, z4, conv_fea])\n\n#     x = layers.Dense(units=160, activation='selu')(x)\n\n#     x_output = layers.Dense(units=1, use_bias=False)(x)\n\n#     my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[x_output])\n#     return my_model\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:41.324368Z","iopub.execute_input":"2022-04-05T03:05:41.324869Z","iopub.status.idle":"2022-04-05T03:05:41.337556Z","shell.execute_reply.started":"2022-04-05T03:05:41.324835Z","shell.execute_reply":"2022-04-05T03:05:41.336727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_model():\n#     rc_input = keras.Input(shape=(15,),\n#                            dtype='int32',\n#                            name='rc_input_layer')\n#     other_x_input = keras.Input(shape=(80, train_x_other.shape[-1]),\n#                                 dtype='float32',\n#                                 name='other_x_input')\n#     rc_embedding_layer = layers.Dense(units=10,\n#                                       use_bias=False, name='rc_embed_layer')\n#     rc_embedding = rc_embedding_layer(rc_input)\n\n#     # 维度拓展\n#     rc_embedding = ExpandTileLayer()(rc_embedding)\n\n#     x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n#     conv1d_1 = layers.Conv1D(filters=256,\n#                              kernel_size=5,\n#                              padding='same',\n#                              use_bias=False)(x_input)\n#     conv1d_1 = layers.Activation(activations.selu)(conv1d_1)\n#     conv1d_2 = layers.Conv1D(filters=128,\n#                              kernel_size=5,\n#                              padding='same')(conv1d_1)\n#     conv1d_2 = layers.BatchNormalization()(conv1d_2)\n#     conv1d_output = layers.Activation(activations.selu)(conv1d_2)\n#     ox = layers.Bidirectional(layers.LSTM(units=784,\n#                                           return_sequences=True,\n#                                           kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                               merge_mode='concat')(conv1d_output)\n#     ox_1 = layers.Bidirectional(layers.LSTM(units=512,\n#                                             return_sequences=True,\n#                                             kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                                 merge_mode='concat')(ox)\n#     ox_2 = layers.Bidirectional(layers.LSTM(units=384,\n#                                             return_sequences=True,\n#                                             kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                                 merge_mode='concat')(ox_1)\n#     ox = layers.Bidirectional(layers.LSTM(units=128, return_sequences=True),\n#                              merge_mode='concat')(ox_2)\n    \n# #     z3 = layers.Bidirectional(layers.GRU(units=384, return_sequences=True),\n# #                              merge_mode='mul')(ox_1)\n# #     z4 = layers.Multiply()([ox_2, z3])\n# #     z4 = layers.BatchNormalization()(z4)\n# #     z4 = layers.Bidirectional(layers.LSTM(units=128, return_sequences=True),\n# #                              merge_mode='concat')(z4)\n#     feature_output = layers.Concatenate(axis=-1)([ox, x_input])\n#     output = layers.Dense(units=128, \n#                           activation=activations.selu,\n#                           kernel_initializer=initializers.initializers_v2.GlorotUniform())(feature_output)\n# #     output = layers.PReLU()(output)\n#     output = layers.Dense(units=1,\n#                           kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n#     my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])\n#     return my_model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:05:41.339077Z","iopub.execute_input":"2022-04-05T03:05:41.339441Z","iopub.status.idle":"2022-04-05T03:05:41.352882Z","shell.execute_reply.started":"2022-04-05T03:05:41.339408Z","shell.execute_reply":"2022-04-05T03:05:41.351924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPU训练","metadata":{}},{"cell_type":"code","source":"# 6折交叉验证\nkf = KFold(n_splits=7, shuffle=True, random_state=1143)\nfor fold, (train_ind, test_ind) in enumerate(kf.split(train_x_, targets)):\n    print('-------------------------------------------------------------------------------------------------')\n    train_x, test_x = train_x_[train_ind], train_x_[test_ind]\n    train_y, test_y = targets[train_ind], targets[test_ind]\n    train_x_rc = train_x[:, :, -15:][:, 0, :]\n    train_x_ox = train_x[:, :, :-15]\n    test_x_rc = test_x[:, :, -15:][:, 0, :]\n    test_x_ox = test_x[:, :, :-15]\n    train_y = train_y.reshape((-1, 80, 1))\n    test_y = test_y.reshape((-1, 80, 1))\n    \n    # 样本加权，区分呼气阶段和吸气阶段\n    y_weight = train_x_ox[:, :, 2] + 2\n    y_weight = y_weight.reshape((-1, 80, 1))\n    y_weight[y_weight == 2] = 0.9\n    test_weight = test_x_ox[:, :, 2] + 2\n    test_weight[test_weight == 2] = 0\n    test_weight = test_weight.reshape((-1, 80, 1))\n\n    my_model = build_model()\n    if fold == 0:\n        print(my_model.summary())\n\n    my_callbacks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.65, patience=10, verbose=1),\n                    callbacks.EarlyStopping(monitor='val_loss', patience=29, verbose=1, mode='min',\n                                            restore_best_weights=True)]\n    my_model.compile(loss=losses.MeanAbsoluteError(),\n                     optimizer=optimizers.Adam(clipnorm=0.9),\n                     sample_weight_mode=\"temporal\")\n    my_model.fit(x=[train_x_rc, train_x_ox], y=train_y,\n                 sample_weight=y_weight,\n                 validation_data=([test_x_rc, test_x_ox], test_y, test_weight),\n                 epochs=300,\n                 batch_size=512,\n                 validation_batch_size=4096,\n                 callbacks=my_callbacks,\n                 verbose=1)\n    my_model.save_weights(f'./model_{fold}.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:08:25.091103Z","iopub.execute_input":"2022-04-05T03:08:25.091411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU训练","metadata":{}},{"cell_type":"code","source":"\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# # instantiating the model in the strategy scope creates the model on the TPU\n# with tpu_strategy.scope():\n#     kf = KFold(n_splits=6, shuffle=True, random_state=1143)\n#     for fold, (train_ind, test_ind) in enumerate(kf.split(train_x_, targets)):\n#         print('-------------------------------------------------------------------------------------------------')\n#         train_x, test_x = train_x_[train_ind], train_x_[test_ind]\n#         train_y, test_y = targets[train_ind], targets[test_ind]\n#         train_x_rc = train_x[:, :, -15:][:, 0, :]\n#         train_x_ox = train_x[:, :, :-15]\n#         test_x_rc = test_x[:, :, -15:][:, 0, :]\n#         test_x_ox = test_x[:, :, :-15]\n#         train_y = train_y.reshape((-1, 80, 1))\n#         test_y = test_y.reshape((-1, 80, 1))\n\n#         y_weight = train_x_ox[:, :, 2] + 2\n#         y_weight = y_weight.reshape((-1, 80, 1))\n#         y_weight[y_weight == 2] = 0.9\n#         test_weight = test_x_ox[:, :, 2] + 2\n#         test_weight[test_weight == 2] = 0\n#         test_weight = test_weight.reshape((-1, 80, 1))\n\n#         my_model = build_model()\n#         if fold == 0:\n#             print(my_model.summary())\n            \n#         my_callbacks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.65, patience=10, verbose=1),\n#                         callbacks.EarlyStopping(monitor='val_loss', patience=29, verbose=1, mode='min',\n#                                                 restore_best_weights=True)]\n#         my_model.compile(loss=losses.MeanAbsoluteError(),\n#                          optimizer=optimizers.Adam(clipnorm=0.9),\n#                          sample_weight_mode=\"temporal\")\n#         my_model.fit(x=[train_x_rc, train_x_ox], y=train_y,\n#                      sample_weight=y_weight,\n#                      validation_data=([test_x_rc, test_x_ox], test_y, test_weight),\n#                      epochs=300,\n#                      batch_size=1024,\n#                      validation_batch_size=5120,\n#                      callbacks=my_callbacks,\n#                      verbose=1)\n#         save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n#         my_model.save_weights(f'./model_final_{fold}.h5', options=save_locally)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:06:30.901101Z","iopub.status.idle":"2022-04-05T03:06:30.901781Z","shell.execute_reply.started":"2022-04-05T03:06:30.901544Z","shell.execute_reply":"2022-04-05T03:06:30.901568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 生成提交文件","metadata":{}},{"cell_type":"code","source":"test_x_other = np.load('../input/ventilator-traindata/test_x_other.npy')\ntest_x_rc = np.load('../input/ventilator-traindata/test_x_rc.npy')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:17:18.127305Z","iopub.execute_input":"2022-04-05T03:17:18.127872Z","iopub.status.idle":"2022-04-05T03:17:22.367036Z","shell.execute_reply.started":"2022-04-05T03:17:18.127833Z","shell.execute_reply":"2022-04-05T03:17:22.366197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_pressure = []\nfor fold in range(7):\n    my_model.load_weights(f'./model_{fold}.h5')\n    pre_y_ = my_model.predict(x=[test_x_rc, test_x_other], batch_size=512)\n    pre_y = np.array(pre_y_).flatten()\n    pre_pressure.append(pre_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pressure_step = 0.07030248641967773\np_min = -1.7551400036622216\np_max = 64.82099173863328\nsub_medclip = np.median(np.vstack(pre_pressure), axis=0)\nsub_medclip = np.round((sub_medclip - p_min) / pressure_step) * pressure_step + p_min\nsub_medclip = np.vstack([np.arange(1, sub_medclip.shape[0] + 1), sub_medclip])\nsub_medclip = np.transpose(sub_medclip, axes=(1, 0))\nsub_medclip = pd.DataFrame(sub_medclip, columns=['id', 'pressure'])\nsub_medclip['id'] = sub_medclip['id'].astype('int32')\nsub_medclip['pressure'] = sub_medclip['pressure'].astype('float32')\nsub_medclip.to_csv('./submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}