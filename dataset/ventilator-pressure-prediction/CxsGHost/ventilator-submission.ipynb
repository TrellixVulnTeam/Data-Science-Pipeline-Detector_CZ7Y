{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-07T09:07:03.783077Z","iopub.execute_input":"2021-11-07T09:07:03.783953Z","iopub.status.idle":"2021-11-07T09:07:03.826977Z","shell.execute_reply.started":"2021-11-07T09:07:03.783848Z","shell.execute_reply":"2021-11-07T09:07:03.826297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# from tensorflow.python.keras import models\n# from tensorflow.keras import layers\n# from tensorflow.python.keras import losses\n# from tensorflow.keras import optimizers\n# from tensorflow.python.keras import activations\n# from tensorflow.python.keras import initializers\n# from tensorflow.python.keras import backend\n# from tensorflow.python.keras import metrics\n# from tensorflow.python import keras\n# import tensorflow as tf\n# import numpy as np\n# import pandas as pd\n# #%%\n\n# test_x_rc = np.load('../input/ventilator-testdata/test_x_rc.npy')\n# test_x_other = np.load('../input/ventilator-testdata/test_x_other.npy')\n\n# #%%\n\n\n# class ExpandTileLayer(layers.Layer):\n#     def __init__(self):\n#         super(ExpandTileLayer, self).__init__()\n#     def call(self, inputs, *args, **kwargs):\n#         return backend.tile(backend.expand_dims(inputs, axis=-2), (1, 80, 1))\n\n# #%%\n\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# # instantiating the model in the strategy scope creates the model on the TPU\n# with tpu_strategy.scope():\n\n\n#     #%%\n\n#     rc_input = keras.Input(shape=(test_x_rc.shape[-1], ),\n#                            dtype='int32',\n#                            name='rc_input_layer')\n#     other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                                 dtype='float32',\n#                                 name='other_x_input')\n#     rc_embedding_layer = layers.Dense(units=32,\n#                                       use_bias=False, name='rc_embed_layer')\n#     rc_embedding = rc_embedding_layer(rc_input)\n\n#     # 维度拓展\n#     rc_embedding = ExpandTileLayer()(rc_embedding)\n\n#     x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n#     ox = layers.Bidirectional(layers.LSTM(units=128,\n#                                           return_sequences=True,\n#                                           kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                               merge_mode='concat')(x_input)\n\n#     ox = layers.Bidirectional(layers.LSTM(units=64,\n#                                           return_sequences=True,\n#                                           kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                               merge_mode='concat')(ox)\n#     ox = layers.Dense(units=128,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n#     # if hp.Choice('d2_activation', ['prelu', 'elu']) == 'prelu':\n#     lstm_output = layers.ELU()(ox)\n#     # else:\n#     #     lstm_output = layers.ELU()(ox)\n\n#     conv1d_1 = layers.Conv1D(filters=256,\n#                              kernel_size=11,\n#                              padding='same', use_bias=False)(x_input)\n#     conv1d_1 = layers.BatchNormalization()(conv1d_1)\n#     conv1d_1 = layers.ReLU()(conv1d_1)\n#     conv1d_2 = layers.Conv1D(filters=128, padding='same', use_bias=False,\n#                              kernel_size=5)(conv1d_1)\n#     conv1d_2 = layers.BatchNormalization()(conv1d_2)\n#     conv1d_output = layers.ReLU()(conv1d_2)\n\n#     output = layers.Concatenate(axis=-1)([lstm_output, conv1d_output])\n#     output = layers.Dense(units=256,\n#                           activation=activations.relu,\n#                           kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n#     output = layers.Dense(units=1,\n#                           kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n#     my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])\n\n#     # my_callbacks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, verbose=1),\n#     #                 callbacks.EarlyStopping(monitor='val_loss', patience=46, verbose=1, mode='min', restore_best_weights=True)]\n#     my_model.compile(loss=losses.MeanAbsoluteError(),\n#                      optimizer=optimizers.Adam(),\n#                      metrics=[metrics.MeanAbsoluteError()])\n\n# #%%\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:07:03.828622Z","iopub.execute_input":"2021-11-07T09:07:03.829085Z","iopub.status.idle":"2021-11-07T09:07:03.835849Z","shell.execute_reply.started":"2021-11-07T09:07:03.829051Z","shell.execute_reply":"2021-11-07T09:07:03.834959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.keras import models\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.python.keras import activations\nfrom tensorflow.python.keras import initializers\nfrom tensorflow.python.keras import backend\nfrom tensorflow.python.keras import metrics\nfrom tensorflow.python import keras\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:12:16.300258Z","iopub.execute_input":"2021-11-07T09:12:16.300607Z","iopub.status.idle":"2021-11-07T09:12:16.307864Z","shell.execute_reply.started":"2021-11-07T09:12:16.300573Z","shell.execute_reply":"2021-11-07T09:12:16.306951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n#%%\n\n\ntest_x_rc = np.load('../input/more-feature-testdata/test_x_rc.npy')\ntest_x_other = np.load('../input/more-feature-testdata/test_x_other.npy')\nprint(test_x_other.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:12:18.470277Z","iopub.execute_input":"2021-11-07T09:12:18.471046Z","iopub.status.idle":"2021-11-07T09:12:25.18771Z","shell.execute_reply.started":"2021-11-07T09:12:18.471005Z","shell.execute_reply":"2021-11-07T09:12:25.186643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ExpandTileLayer(layers.Layer):\n    def __init__(self):\n        super(ExpandTileLayer, self).__init__()\n    def call(self, inputs, *args, **kwargs):\n        return backend.tile(backend.expand_dims(inputs, axis=-2), (1, 80, 1))","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.217672Z","iopub.execute_input":"2021-11-07T09:08:24.217937Z","iopub.status.idle":"2021-11-07T09:08:24.224875Z","shell.execute_reply.started":"2021-11-07T09:08:24.217908Z","shell.execute_reply":"2021-11-07T09:08:24.224181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# #%%\n\n\n\n# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embedding_layer = layers.Dense(units=16,\n#                                   use_bias=False, name='rc_embed_layer')\n# rc_embedding = rc_embedding_layer(rc_input)\n\n# # 维度拓展\n# rc_embedding = ExpandTileLayer()(rc_embedding)\n\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# ox = layers.Bidirectional(layers.LSTM(units=512,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(x_input)\n\n# ox = layers.Bidirectional(layers.LSTM(units=256,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Bidirectional(layers.LSTM(units=128,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Dense(units=128,\n#                   kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n# # if hp.Choice('d2_activation', ['prelu', 'elu']) == 'prelu':\n# lstm_output = layers.ELU()(ox)\n# # else:\n# #     lstm_output = layers.ELU()(ox)\n\n# conv1d_1 = layers.Conv1D(filters=256,\n#                          kernel_size=7,\n#                          padding='same', use_bias=False)(x_input)\n# conv1d_1 = layers.BatchNormalization()(conv1d_1)\n# conv1d_1 = layers.ReLU()(conv1d_1)\n# conv1d_2 = layers.Conv1D(filters=128, padding='same', use_bias=False,\n#                          kernel_size=5)(conv1d_1)\n# conv1d_2 = layers.BatchNormalization()(conv1d_2)\n# conv1d_output = layers.ReLU()(conv1d_2)\n\n# output = layers.Concatenate(axis=-1)([lstm_output, conv1d_output])\n# output = layers.Dense(units=256,\n#                       activation=activations.relu,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n# output = layers.Dense(units=1,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])\n\n\n# # my_callbacks = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, verbose=1),\n# #                 callbacks.EarlyStopping(monitor='val_loss', patience=46, verbose=1, mode='min', restore_best_weights=True)]\n# # my_model.compile(loss=losses.MeanAbsoluteError(),\n# #                  optimizer=optimizers.Adam(),\n# #                  metrics=[metrics.MeanAbsoluteError()])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.226333Z","iopub.execute_input":"2021-11-07T09:08:24.226981Z","iopub.status.idle":"2021-11-07T09:08:24.240217Z","shell.execute_reply.started":"2021-11-07T09:08:24.226949Z","shell.execute_reply":"2021-11-07T09:08:24.239122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embedding_layer = layers.Dense(units=16,\n#                                   use_bias=False, name='rc_embed_layer')\n# rc_embedding = rc_embedding_layer(rc_input)\n\n# # 维度拓展\n# rc_embedding = ExpandTileLayer()(rc_embedding)\n\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# conv1d_1 = layers.Conv1D(filters=256,\n#                          kernel_size=5,\n#                          padding='same',\n#                          use_bias=False)(x_input)\n# conv1d_1 = layers.Activation(activations.selu)(conv1d_1)\n# conv1d_2 = layers.Conv1D(filters=128, use_bias=False,\n#                          kernel_size=5, padding='same')(conv1d_1)\n# conv1d_output = layers.Activation(activations.selu)(conv1d_2)\n# ox = layers.Bidirectional(layers.LSTM(units=512,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(conv1d_output)\n\n# ox = layers.Bidirectional(layers.LSTM(units=384,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Bidirectional(layers.LSTM(units=256,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Dense(units=128,\n#                   kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n# lstm_output = layers.ELU()(ox)\n\n# output = layers.Concatenate(axis=-1)([lstm_output, conv1d_output])\n# output = layers.Dense(units=256,\n#                       activation=activations.selu,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n# output = layers.Dense(units=1,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.241784Z","iopub.execute_input":"2021-11-07T09:08:24.242438Z","iopub.status.idle":"2021-11-07T09:08:24.259141Z","shell.execute_reply.started":"2021-11-07T09:08:24.242395Z","shell.execute_reply":"2021-11-07T09:08:24.258143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, train_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embedding_layer = layers.Dense(units=16,\n#                                   use_bias=False, name='rc_embed_layer')\n# rc_embedding = rc_embedding_layer(rc_input)\n\n# # 维度拓展\n# rc_embedding = ExpandTileLayer()(rc_embedding)\n\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# conv1d_1 = layers.Conv1D(filters=256,\n#                          kernel_size=5,\n#                          kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                          padding='same',\n#                          use_bias=False)(x_input)\n# conv1d_1 = layers.Activation(activations.selu)(conv1d_1)\n# conv1d_2 = layers.Conv1D(filters=128,\n#                          use_bias=False,\n#                          kernel_size=5,\n#                          kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                          padding='same')(conv1d_1)\n# conv1d_output = layers.Activation(activations.selu)(conv1d_2)\n# the_feature = layers.Concatenate(axis=-1)([conv1d_output, x_input])\n# ox = layers.Bidirectional(layers.LSTM(units=512,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(the_feature)\n# ox = layers.Bidirectional(layers.LSTM(units=384,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Bidirectional(layers.LSTM(units=256,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# #     ox = layers.Dense(units=256,\n# #                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n# feature_output = layers.Concatenate(axis=-1)([ox, conv1d_output])\n# output = layers.Bidirectional(layers.GRU(units=256,\n#                                          return_sequences=True),\n#                               merge_mode='concat')(feature_output)\n# output = layers.Dense(units=128,\n#                       activation=activations.selu,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n# output = layers.Dense(units=1,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.260848Z","iopub.execute_input":"2021-11-07T09:08:24.261248Z","iopub.status.idle":"2021-11-07T09:08:24.277097Z","shell.execute_reply.started":"2021-11-07T09:08:24.261218Z","shell.execute_reply":"2021-11-07T09:08:24.276111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embedding_layer = layers.Dense(units=16,\n#                                   use_bias=False, name='rc_embed_layer')\n# rc_embedding = rc_embedding_layer(rc_input)\n\n# # 维度拓展\n# rc_embedding = ExpandTileLayer()(rc_embedding)\n\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# conv1d_1 = layers.Conv1D(filters=256,\n#                          kernel_size=5,\n#                          kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                          padding='same',\n#                          use_bias=False)(x_input)\n# conv1d_1 = layers.Activation(activations.selu)(conv1d_1)\n# conv1d_2 = layers.Conv1D(filters=128, \n#                          use_bias=False,\n#                          kernel_size=5, \n#                          kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                          padding='same')(conv1d_1)\n# conv1d_output = layers.Activation(activations.selu)(conv1d_2)\n# the_feature = layers.Concatenate(axis=-1)([conv1d_output, x_input])\n# ox_1 = layers.Bidirectional(layers.LSTM(units=512,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(the_feature)\n# ox_2 = layers.Bidirectional(layers.LSTM(units=384,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox_1)\n# ox = layers.Bidirectional(layers.LSTM(units=256,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox_2)\n# #     ox = layers.Dense(units=256,\n# #                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n# feature_output = layers.Concatenate(axis=-1)([ox, ox_2, conv1d_output])\n# output = layers.Bidirectional(layers.GRU(units=256,\n#                                          return_sequences=True),\n#                               merge_mode='concat')(feature_output)\n# output = layers.Dense(units=128,\n#                       activation=activations.selu,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n# output = layers.Dense(units=1,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.278752Z","iopub.execute_input":"2021-11-07T09:08:24.279011Z","iopub.status.idle":"2021-11-07T09:08:24.294475Z","shell.execute_reply.started":"2021-11-07T09:08:24.278973Z","shell.execute_reply":"2021-11-07T09:08:24.293509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embed = layers.Dense(units=8, use_bias=False, name='rc_embed_layer')(rc_input)\n# rc_embedding = ExpandTileLayer()(rc_embed)\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# conv_fea = layers.Conv1D(kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                          filters=128, kernel_size=5, padding='same')(x_input)\n# conv_fea = layers.BatchNormalization()(conv_fea)\n# conv_fea = layers.Activation(activations.selu)(conv_fea)\n# final_input = layers.Concatenate()([x_input, conv_fea])\n\n# x1 = layers.Bidirectional(layers.LSTM(units=640, return_sequences=True))(final_input)\n# x2 = layers.Bidirectional(layers.LSTM(units=512, return_sequences=True))(x1)\n# x3 = layers.Bidirectional(layers.LSTM(units=384, return_sequences=True))(x2)\n# x4 = layers.Bidirectional(layers.LSTM(units=256, return_sequences=True))(x3)\n\n# z2 = layers.Bidirectional(layers.GRU(units=384, return_sequences=True))(x2)\n\n# z31 = layers.Multiply()([x3, z2])\n# z31 = layers.BatchNormalization()(z31)\n# z3 = layers.Bidirectional(layers.GRU(units=256, return_sequences=True))(z31)\n\n# z41 = layers.Multiply()([x4, z3])\n# z41 = layers.BatchNormalization()(z41)\n# z4 = layers.Bidirectional(layers.GRU(units=128, return_sequences=True))(z41)\n\n# x = layers.Concatenate(axis=2)([x4, z2, z3, z4, conv_fea])\n\n# x = layers.Dense(units=160, activation='selu')(x)\n\n# x_output = layers.Dense(units=1)(x)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[x_output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.298286Z","iopub.execute_input":"2021-11-07T09:08:24.298677Z","iopub.status.idle":"2021-11-07T09:08:24.312172Z","shell.execute_reply.started":"2021-11-07T09:08:24.298627Z","shell.execute_reply":"2021-11-07T09:08:24.311431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embed = layers.Dense(units=8, use_bias=False, name='rc_embed_layer')(rc_input)\n# rc_embedding = ExpandTileLayer()(rc_embed)\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# conv_fea = layers.Conv1D(kernel_initializer=initializers.initializers_v2.LecunNormal(),\n#                          filters=128, kernel_size=5, padding='same')(x_input)\n# conv_fea = layers.BatchNormalization()(conv_fea)\n# conv_fea = layers.Activation(activations.selu)(conv_fea)\n# final_input = layers.Concatenate()([x_input, conv_fea])\n\n# x1 = layers.Bidirectional(layers.LSTM(units=640, return_sequences=True))(final_input)\n# x2 = layers.Bidirectional(layers.LSTM(units=512, return_sequences=True))(x1)\n# x3 = layers.Bidirectional(layers.LSTM(units=384, return_sequences=True))(x2)\n# x4 = layers.Bidirectional(layers.LSTM(units=256, return_sequences=True))(x3)\n\n# z2 = layers.Bidirectional(layers.GRU(units=384, return_sequences=True))(x2)\n\n# z31 = layers.Multiply()([x3, z2])\n# z31 = layers.BatchNormalization()(z31)\n# z3 = layers.Bidirectional(layers.GRU(units=256, return_sequences=True))(z31)\n\n# z41 = layers.Multiply()([x4, z3])\n# z41 = layers.BatchNormalization()(z41)\n# z4 = layers.Bidirectional(layers.GRU(units=128, return_sequences=True))(z41)\n\n# x = layers.Concatenate(axis=2)([x4, z2, z3, z4, conv_fea])\n\n# x = layers.Dense(units=160, activation='selu')(x)\n\n# x_output = layers.Dense(units=1)(x)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[x_output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.313359Z","iopub.execute_input":"2021-11-07T09:08:24.313651Z","iopub.status.idle":"2021-11-07T09:08:24.328504Z","shell.execute_reply.started":"2021-11-07T09:08:24.313621Z","shell.execute_reply":"2021-11-07T09:08:24.327448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rc_input = keras.Input(shape=(15, ),\n#                        dtype='int32',\n#                        name='rc_input_layer')\n# other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n#                             dtype='float32',\n#                             name='other_x_input')\n# rc_embedding_layer = layers.Dense(units=16,\n#                                   use_bias=False, name='rc_embed_layer')\n# rc_embedding = rc_embedding_layer(rc_input)\n\n# # 维度拓展\n# rc_embedding = ExpandTileLayer()(rc_embedding)\n\n# x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n# conv1d_1 = layers.Conv1D(filters=256,\n#                          kernel_size=5,\n#                          padding='same',\n#                          use_bias=False)(x_input)\n# conv1d_1 = layers.Activation(activations.selu)(conv1d_1)\n# conv1d_2 = layers.Conv1D(filters=128, use_bias=False,\n#                          kernel_size=5, padding='same')(conv1d_1)\n# conv1d_output = layers.Activation(activations.selu)(conv1d_2)\n# ox = layers.Bidirectional(layers.LSTM(units=512,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(conv1d_output)\n\n# ox = layers.Bidirectional(layers.LSTM(units=384,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Bidirectional(layers.LSTM(units=256,\n#                                       return_sequences=True,\n#                                       kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n#                           merge_mode='concat')(ox)\n# ox = layers.Dense(units=128,\n#                   kernel_initializer=initializers.initializers_v2.GlorotUniform())(ox)\n# lstm_output = layers.ELU()(ox)\n\n# output = layers.Concatenate(axis=-1)([lstm_output, conv1d_output])\n# output = layers.Dense(units=256,\n#                       activation=activations.selu,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n# output = layers.Dense(units=1,\n#                       kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n# my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.329774Z","iopub.execute_input":"2021-11-07T09:08:24.330049Z","iopub.status.idle":"2021-11-07T09:08:24.345911Z","shell.execute_reply.started":"2021-11-07T09:08:24.330018Z","shell.execute_reply":"2021-11-07T09:08:24.344995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n\n    rc_input = keras.Input(shape=(15, ),\n                           dtype='int32',\n                           name='rc_input_layer')\n    other_x_input = keras.Input(shape=(80, test_x_other.shape[-1]),\n                                dtype='float32',\n                                name='other_x_input')\n    rc_embedding_layer = layers.Dense(units=10,\n                                      use_bias=False, \n                                      activation=activations.selu,\n                                      name='rc_embed_layer')\n    rc_embedding = rc_embedding_layer(rc_input)\n\n    # 维度拓展\n    rc_embedding = ExpandTileLayer()(rc_embedding)\n\n    x_input = layers.Concatenate(axis=-1)([other_x_input, rc_embedding])\n    conv1d_1 = layers.Conv1D(filters=256,\n                             kernel_size=5,\n                             padding='same')(x_input)\n    conv1d_1 = layers.Activation(activations.relu)(conv1d_1)\n    conv1d_1 = layers.BatchNormalization()(conv1d_1)\n    conv1d_2 = layers.Conv1D(filters=192, \n                             kernel_size=5,\n                             padding='same')(conv1d_1)\n    conv1d_output = layers.Activation(activations.relu)(conv1d_2)\n    conv1d_output = layers.BatchNormalization()(conv1d_output)\n    the_feature = layers.Concatenate()([conv1d_output, x_input])\n    ox_1 = layers.Bidirectional(layers.LSTM(units=672,\n                                          return_sequences=True,\n                                          kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n                              merge_mode='concat')(the_feature)\n    ox_2 = layers.Bidirectional(layers.LSTM(units=512,\n                                          return_sequences=True,\n                                          kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n                              merge_mode='concat')(ox_1)\n    ox = layers.Bidirectional(layers.LSTM(units=384,\n                                          return_sequences=True,\n                                          kernel_initializer=initializers.initializers_v2.GlorotUniform()),\n                              merge_mode='concat')(ox_2)\n    ox = layers.Bidirectional(layers.GRU(units=192,\n                    return_sequences=True))(ox)\n    output = layers.Concatenate(axis=-1)([ox, conv1d_output])\n    output = layers.Dense(units=128,\n                          activation=activations.selu,\n                          kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n    output = layers.Dense(units=1,\n                          kernel_initializer=initializers.initializers_v2.GlorotUniform())(output)\n\n    my_model = models.Model(inputs=[rc_input, other_x_input], outputs=[output])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:24.347109Z","iopub.execute_input":"2021-11-07T09:08:24.347537Z","iopub.status.idle":"2021-11-07T09:08:47.708888Z","shell.execute_reply.started":"2021-11-07T09:08:24.347478Z","shell.execute_reply":"2021-11-07T09:08:47.708134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_pressure = []\nfor fold in range(1):\n    my_model.load_weights(f'../input/model-weights/model_final_{fold}.h5')\n    pre_y_ = my_model.predict(x=[test_x_rc, test_x_other], batch_size=4096)\n    pre_y = np.array(pre_y_).flatten()\n    pre_pressure.append(pre_y)\n# my_model.load_weights(f'../input/model-weights/model_final_6.h5')\n# pre_y_ = my_model.predict(x=[test_x_rc, test_x_other], batch_size=4096)\n# pre_y = np.array(pre_y_).flatten()\n# pre_pressure.append(pre_y)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:47.710046Z","iopub.execute_input":"2021-11-07T09:08:47.710295Z","iopub.status.idle":"2021-11-07T09:08:48.335558Z","shell.execute_reply.started":"2021-11-07T09:08:47.710265Z","shell.execute_reply":"2021-11-07T09:08:48.3343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npressure_step = 0.07030248641967773\np_min = -1.7551400036622216\np_max = 64.82099173863328\n# sub_medclip = np.median(np.vstack(pre_pressure), axis=0)\nsub_medclip = np.mean(np.vstack(pre_pressure), axis=0)\nsub_medclip = np.round((sub_medclip - p_min) / pressure_step) * pressure_step + p_min\nsub_medclip = np.vstack([np.arange(1, sub_medclip.shape[0] + 1), sub_medclip])\nsub_medclip = np.transpose(sub_medclip, axes=(1, 0))\nsub_medclip = pd.DataFrame(sub_medclip, columns=['id', 'pressure'])\nsub_medclip['id'] = sub_medclip['id'].astype('int32')\nsub_medclip['pressure'] = sub_medclip['pressure'].astype('float32')\nsub_medclip.to_csv('./submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T09:08:48.336437Z","iopub.status.idle":"2021-11-07T09:08:48.336779Z","shell.execute_reply.started":"2021-11-07T09:08:48.336611Z","shell.execute_reply":"2021-11-07T09:08:48.336627Z"},"trusted":true},"execution_count":null,"outputs":[]}]}