{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-28T11:13:57.497779Z","iopub.execute_input":"2021-09-28T11:13:57.498578Z","iopub.status.idle":"2021-09-28T11:13:57.5087Z","shell.execute_reply.started":"2021-09-28T11:13:57.498517Z","shell.execute_reply":"2021-09-28T11:13:57.507954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load CSV files\ntrain_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest_df = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:13:57.510482Z","iopub.execute_input":"2021-09-28T11:13:57.511313Z","iopub.status.idle":"2021-09-28T11:14:12.505536Z","shell.execute_reply.started":"2021-09-28T11:13:57.511264Z","shell.execute_reply":"2021-09-28T11:14:12.504469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of train and test dataset\nprint(\"Shape of training data : {}\".format(train_df.shape))\nprint(\"Shape of test data : {}\".format(test_df.shape))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-28T11:14:12.50724Z","iopub.execute_input":"2021-09-28T11:14:12.507516Z","iopub.status.idle":"2021-09-28T11:14:12.512749Z","shell.execute_reply.started":"2021-09-28T11:14:12.507483Z","shell.execute_reply":"2021-09-28T11:14:12.511965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set explanatory variable and Objective variable\ntrain_x = train_df.drop([\"id\", \"breath_id\", \"pressure\"], axis=1)\ntrain_y = train_df[\"pressure\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:14:12.51409Z","iopub.execute_input":"2021-09-28T11:14:12.514508Z","iopub.status.idle":"2021-09-28T11:14:12.666649Z","shell.execute_reply.started":"2021-09-28T11:14:12.514464Z","shell.execute_reply":"2021-09-28T11:14:12.665301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implement Optuna\nimport optuna\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nfrom statistics import mean\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:14:12.669137Z","iopub.execute_input":"2021-09-28T11:14:12.669384Z","iopub.status.idle":"2021-09-28T11:14:15.676802Z","shell.execute_reply.started":"2021-09-28T11:14:12.669356Z","shell.execute_reply":"2021-09-28T11:14:15.675724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimize hyperparameters\ndef objective(trial):\n    \n    # Split data into train and test data\n    x_train, x_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.2, random_state=1234, shuffle=False, stratify=None)\n    \n    params = {\n        'objective': 'regression',\n        'n_estimators': 1000,\n        'random_state': 42,\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n        'subsample': trial.suggest_loguniform('subsample', 0.4, 1.0),\n        'subsample_freq': trial.suggest_loguniform('subsample_freq', 0.4, 1.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 1.0),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'min_child_weight': trial.suggest_int('min_child_weight', 5, 256),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n    }\n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_eval = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n    \n    model_lgb = lgb.train(params,\n                         lgb_train,\n                         valid_sets=lgb_eval,\n                         num_boost_round=10000,\n                         early_stopping_rounds=100,\n                         verbose_eval=50)\n    \n    y_pred = model_lgb.predict(x_valid, num_iteration=model_lgb.best_iteration)\n    \n    score = mean_squared_error(y_valid, y_pred)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:14:15.678687Z","iopub.execute_input":"2021-09-28T11:14:15.679104Z","iopub.status.idle":"2021-09-28T11:14:15.693014Z","shell.execute_reply.started":"2021-09-28T11:14:15.679052Z","shell.execute_reply":"2021-09-28T11:14:15.691989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Get optimized parameters\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=10)\n# print(\"Number of finished trials: \", len(study.trials))\n# print(\"Best parameters: \", study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:14:15.69482Z","iopub.execute_input":"2021-09-28T11:14:15.695451Z","iopub.status.idle":"2021-09-28T11:14:15.709622Z","shell.execute_reply.started":"2021-09-28T11:14:15.695408Z","shell.execute_reply":"2021-09-28T11:14:15.708976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM\nfolds = 4   # Number of fold\nkf = KFold(n_splits=folds)\n\n# Set LGBM hyper parameters\nlgbm_params = {\n    'objective': 'regression',\n    'random_state': 42,\n    'learning_rate': 0.02,\n    'subsample': 0.9586980708213185,\n    'subsample_freq': 0.5886259785107316,\n    'colsample_bytree': 0.9982054887945049,\n    'reg_alpha': 0.021951494356699672,\n    'reg_lambda': 0.8902816396602072,\n    'min_child_weight': 60,\n    'min_child_samples': 23,\n    'bagging_fraction': 0.9024418505688159,\n    'bagging_freq': 7,\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:14:15.711521Z","iopub.execute_input":"2021-09-28T11:14:15.712201Z","iopub.status.idle":"2021-09-28T11:14:15.720892Z","shell.execute_reply.started":"2021-09-28T11:14:15.712154Z","shell.execute_reply":"2021-09-28T11:14:15.719947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model and predict\nmodels = []\nrmses = []\npreds = np.zeros(len(train_x))\n\nnum_boost_round = 10000\nearly_stopping_rounds = 1000\nverbose_eval = 100\n\nfor train_index, val_index in kf.split(train_x):\n    x_train = train_x.iloc[train_index]\n    x_valid = train_x.iloc[val_index]\n    y_train = train_y.iloc[train_index]\n    y_valid = train_y.iloc[val_index]\n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_eval = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n    \n    model_lgb = lgb.train(lgbm_params,\n                         lgb_train,\n                         valid_sets=lgb_eval,\n                         num_boost_round=num_boost_round,\n                         early_stopping_rounds=early_stopping_rounds,\n                         verbose_eval=verbose_eval)\n    \n    y_pred = model_lgb.predict(x_valid, num_iteration=model_lgb.best_iteration)\n    tmp_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n    print(tmp_rmse)\n    \n    models.append(model_lgb)\n    rmses.append(tmp_rmse)\n    preds[val_index] = y_pred\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T11:14:15.723062Z","iopub.execute_input":"2021-09-28T11:14:15.72365Z","iopub.status.idle":"2021-09-28T13:01:10.409858Z","shell.execute_reply.started":"2021-09-28T11:14:15.723525Z","shell.execute_reply":"2021-09-28T13:01:10.40758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate average of RMSE\nmean(rmses)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:01:10.41555Z","iopub.execute_input":"2021-09-28T13:01:10.416108Z","iopub.status.idle":"2021-09-28T13:01:10.42742Z","shell.execute_reply.started":"2021-09-28T13:01:10.416036Z","shell.execute_reply":"2021-09-28T13:01:10.426371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot actual and pred\nactual_pred_df = pd.DataFrame({\n    \"actual\" : train_y,\n    \"pred\" : preds\n})\n\nactual_pred_df.plot(xlim=[0,320])","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:01:10.429263Z","iopub.execute_input":"2021-09-28T13:01:10.429504Z","iopub.status.idle":"2021-09-28T13:01:19.565424Z","shell.execute_reply.started":"2021-09-28T13:01:10.429473Z","shell.execute_reply":"2021-09-28T13:01:19.564403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot variables importance\nfor model in models:\n    lgb.plot_importance(model, importance_type=\"gain\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:01:19.56706Z","iopub.execute_input":"2021-09-28T13:01:19.56777Z","iopub.status.idle":"2021-09-28T13:01:20.545846Z","shell.execute_reply.started":"2021-09-28T13:01:19.567734Z","shell.execute_reply":"2021-09-28T13:01:20.544703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submit data\ntest_x = test_df.drop([\"id\", \"breath_id\"], axis=1)\n\nsubmit_preds = []\n\nfor model in models:\n    submit_pred = model.predict(test_x)\n    submit_preds.append(submit_pred)\n\n# Calculate mean\npreds_array = np.array(submit_preds)\npreds_mean = np.mean(preds_array, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T13:01:20.547627Z","iopub.execute_input":"2021-09-28T13:01:20.547922Z","iopub.status.idle":"2021-09-28T14:07:14.378019Z","shell.execute_reply.started":"2021-09-28T13:01:20.547889Z","shell.execute_reply":"2021-09-28T14:07:14.376149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submit file\nsubmission[\"pressure\"] = preds_mean\nsubmission.to_csv(\"ventilator_submit01.csv\", index=False)\nprint(\"done\")","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:07:14.385239Z","iopub.execute_input":"2021-09-28T14:07:14.385547Z","iopub.status.idle":"2021-09-28T14:07:29.085277Z","shell.execute_reply.started":"2021-09-28T14:07:14.385513Z","shell.execute_reply":"2021-09-28T14:07:29.084244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}