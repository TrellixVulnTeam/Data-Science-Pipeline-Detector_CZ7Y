{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-01T17:36:28.265761Z","iopub.execute_input":"2021-10-01T17:36:28.266252Z","iopub.status.idle":"2021-10-01T17:36:28.301073Z","shell.execute_reply.started":"2021-10-01T17:36:28.266164Z","shell.execute_reply":"2021-10-01T17:36:28.300221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mlt\n# 前処理\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# XGBoost\nimport xgboost as xgb\n\n# LightGBM\nimport lightgbm as lgb\n\n# CatBoost\nimport catboost as  cb\nfrom catboost import CatBoost, Pool\n\n\n# 評価指標\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:36:30.464458Z","iopub.execute_input":"2021-10-01T17:36:30.464705Z","iopub.status.idle":"2021-10-01T17:36:32.961314Z","shell.execute_reply.started":"2021-10-01T17:36:30.464679Z","shell.execute_reply":"2021-10-01T17:36:32.960559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/ventilator-pressure-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/ventilator-pressure-prediction/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:36:34.772834Z","iopub.execute_input":"2021-10-01T17:36:34.773349Z","iopub.status.idle":"2021-10-01T17:36:47.954949Z","shell.execute_reply.started":"2021-10-01T17:36:34.773305Z","shell.execute_reply":"2021-10-01T17:36:47.954106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:40:26.564269Z","iopub.execute_input":"2021-10-01T17:40:26.564907Z","iopub.status.idle":"2021-10-01T17:40:26.584576Z","shell.execute_reply.started":"2021-10-01T17:40:26.564871Z","shell.execute_reply":"2021-10-01T17:40:26.584015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:38:08.967479Z","iopub.execute_input":"2021-10-01T17:38:08.967819Z","iopub.status.idle":"2021-10-01T17:38:08.994278Z","shell.execute_reply.started":"2021-10-01T17:38:08.967785Z","shell.execute_reply":"2021-10-01T17:38:08.993479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [\"id\",\"breath_id\",\"R\",\"C\",\"time_step\",\"u_in\",\"u_out\"]\nx_train=train[features]\ny_train=train[\"pressure\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:40:25.068983Z","iopub.execute_input":"2021-10-01T17:40:25.070681Z","iopub.status.idle":"2021-10-01T17:40:25.242298Z","shell.execute_reply.started":"2021-10-01T17:40:25.070582Z","shell.execute_reply":"2021-10-01T17:40:25.241336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfold = KFold(n_splits=5, shuffle=True, random_state=71)\ncv = list(fold.split(x_train,y_train))#もともとが generator なため明示的にlistに変換する","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:41:14.884593Z","iopub.execute_input":"2021-10-01T17:41:14.884924Z","iopub.status.idle":"2021-10-01T17:41:15.571595Z","shell.execute_reply.started":"2021-10-01T17:41:14.88489Z","shell.execute_reply":"2021-10-01T17:41:15.570758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:41:24.464805Z","iopub.execute_input":"2021-10-01T17:41:24.465082Z","iopub.status.idle":"2021-10-01T17:41:24.475189Z","shell.execute_reply.started":"2021-10-01T17:41:24.465055Z","shell.execute_reply":"2021-10-01T17:41:24.474418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### パラメータの設定\n- 評価指標は平均絶対誤差","metadata":{}},{"cell_type":"code","source":"params = {\n    'objective': \"regression\",\n    'metric': \"mae\",\n    \"verbosity\" :-1,\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:41:50.764358Z","iopub.execute_input":"2021-10-01T17:41:50.76463Z","iopub.status.idle":"2021-10-01T17:41:50.768895Z","shell.execute_reply.started":"2021-10-01T17:41:50.764595Z","shell.execute_reply":"2021-10-01T17:41:50.768253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nimport optuna.integration.lightgbm as lgb_o\n\ndef fit_lgbm(X, \n             y, \n             cv, \n             params: dict=None, \n             ):\n    \"\"\"lightGBM を CrossValidation の枠組みで学習を行なう function\"\"\"\n\n    # パラメータがないときは、空の dict で置き換える\n    if params is None:\n        params = {}\n    \n    scores = {}\n    models = []\n    # training data の target と同じだけのゼロ配列を用意\n    oof_pred = np.zeros_like(y, dtype=np.float)\n\n    evaluation_results = []\n    #cvした分のモデルのパラメータを保存 \n    #all_best_params=[]\n    for i, (idx_train, idx_valid) in enumerate(cv): #cvにはtrainとtestのindex番号がidx_trainとidx_validに入る\n        # この部分が交差検証のところです。データセットを cv instance によって分割します\n        # training data を trian/valid に分割\n        #array型から各cvでのインデックス番号を指定してtrainとtestを作る\n        x_train, y_train = X[idx_train], y[idx_train]#xはarray型でdataframe型ではない\n        x_valid, y_valid = X[idx_valid], y[idx_valid]\n\n        #lgbのデータセット作成\n        lgb_train=lgb.Dataset(x_train,y_train)\n        lgb_eval=lgb.Dataset(x_valid,y_valid)#valデータ\n        \n        #評価関数を保存する\n        evaluation_results_i = {} \n        #oputnaでパラメータを保存する\n        #best_params = {}\n\n        #学習\n        gbm = lgb.train(\n            params,\n            lgb_train,\n            num_boost_round=100,\n            valid_sets=[lgb_train,lgb_eval],#mseの推移を保存する\n            evals_result=evaluation_results_i,\n            valid_names=['train', 'valid'],\n            early_stopping_rounds=10,\n            )\n\n\n        #best_params = gbm.params\n        #all_best_params.append(best_params)\n    \n        #valデータに当てはめて推論\n        #pred_iはどんな型??\n        pred_i = gbm.predict(x_valid,num_iteration=gbm.best_iteration)#推論\n        \n        oof_pred[idx_valid] = pred_i#oof_pred(ゼロ配列)のcvした時のcvした時のテストデータのindex番号に予測値を入れる\n        models.append(gbm)#モデルをmodel配列に追加\n        evaluation_results.append(evaluation_results_i)\n        print(f'Fold {i} MAE: {mean_absolute_error(y_valid, pred_i) ** .5:.4f}')\n\n    scores = np.sqrt(mean_absolute_error(y,oof_pred))\n        \n    #score = mean_squared_error(y, oof_pred) ** .5\n    print('-' * 50)\n    print('FINISHED | Whole MAE: {:.4f}'.format(scores))\n    return oof_pred, models ,evaluation_results","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:42:22.064779Z","iopub.execute_input":"2021-10-01T17:42:22.065382Z","iopub.status.idle":"2021-10-01T17:42:22.626368Z","shell.execute_reply.started":"2021-10-01T17:42:22.065343Z","shell.execute_reply":"2021-10-01T17:42:22.625537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof, models ,evaluation_results= fit_lgbm(x_train.values,y_train.values,cv, params=params)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:43:26.766561Z","iopub.execute_input":"2021-10-01T17:43:26.766903Z","iopub.status.idle":"2021-10-01T17:44:52.070406Z","shell.execute_reply.started":"2021-10-01T17:43:26.766867Z","shell.execute_reply":"2021-10-01T17:44:52.069638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_importance(models, feat_train_df):\n    \"\"\"lightGBM の model 配列の feature importance を plot する\n    CVごとのブレを boxen plot として表現します.\n\n    args:\n        models:\n            List of lightGBM models\n        feat_train_df:\n            学習時に使った DataFrame\n    \"\"\"\n    feature_importance_df = pd.DataFrame()\n    for i, model in enumerate(models):\n        _df = pd.DataFrame()\n        _df['feature_importance'] = model.feature_importance()\n        _df['column'] = feat_train_df.columns\n        _df['fold'] = i + 1\n        feature_importance_df = pd.concat([feature_importance_df, _df], \n                                          axis=0, ignore_index=True)\n\n    order = feature_importance_df.groupby('column')\\\n        .sum()[['feature_importance']]\\\n        .sort_values('feature_importance', ascending=False).index[:50]#50行目まで抽出\n\n    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n    sns.boxenplot(data=feature_importance_df, \n                  x='feature_importance', \n                  y='column', \n                  order=order, \n                  ax=ax,\n                  palette='viridis', \n                  orient='h')\n    ax.tick_params(axis='x', rotation=90)\n    ax.set_title('Importance')\n    ax.grid()\n    fig.tight_layout()\n    return fig, ax\n\nfig, ax = visualize_importance(models, x_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T17:45:39.323528Z","iopub.execute_input":"2021-10-01T17:45:39.323859Z","iopub.status.idle":"2021-10-01T17:45:39.781414Z","shell.execute_reply.started":"2021-10-01T17:45:39.323828Z","shell.execute_reply":"2021-10-01T17:45:39.780637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = 0\nfor i in range(5):\n    pred += (models[0].predict(test))/5","metadata":{"execution":{"iopub.status.busy":"2021-10-01T18:01:06.307553Z","iopub.execute_input":"2021-10-01T18:01:06.308097Z","iopub.status.idle":"2021-10-01T18:01:32.516822Z","shell.execute_reply.started":"2021-10-01T18:01:06.308053Z","shell.execute_reply":"2021-10-01T18:01:32.516178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"id\":test[\"id\"],\"pressure\":pred})","metadata":{"execution":{"iopub.status.busy":"2021-10-01T18:03:06.919369Z","iopub.execute_input":"2021-10-01T18:03:06.919845Z","iopub.status.idle":"2021-10-01T18:03:06.943823Z","shell.execute_reply.started":"2021-10-01T18:03:06.919802Z","shell.execute_reply":"2021-10-01T18:03:06.943188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T18:05:08.763097Z","iopub.execute_input":"2021-10-01T18:05:08.763327Z","iopub.status.idle":"2021-10-01T18:05:21.808499Z","shell.execute_reply.started":"2021-10-01T18:05:08.763303Z","shell.execute_reply":"2021-10-01T18:05:21.80766Z"},"trusted":true},"execution_count":null,"outputs":[]}]}