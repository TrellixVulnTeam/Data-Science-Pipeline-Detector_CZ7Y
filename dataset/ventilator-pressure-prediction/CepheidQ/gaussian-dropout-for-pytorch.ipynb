{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport torch\nimport torch.nn as nn\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:40:27.489885Z","iopub.execute_input":"2021-10-12T00:40:27.490216Z","iopub.status.idle":"2021-10-12T00:40:27.498834Z","shell.execute_reply.started":"2021-10-12T00:40:27.490182Z","shell.execute_reply":"2021-10-12T00:40:27.497875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gaussian Dropout for Pytorch","metadata":{}},{"cell_type":"markdown","source":"Gaussian dropout multiplies a normal distributed noise with **all** your hidden embeddings dimensions instead of setting some dimensions to 0. So hidden_embedding*normal_noise.\nThis means, that the mean of your outputs will stay the same, although the standard deviation and variance changes. It might make train/inference performance more stable for regression task than normal dropout.\nThe noise used here, is similar to the [paper proposing it](https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf) N(1, (1/(1-p)). We use (1/(1-p)) here instead the reverse, because the noise \nwill grow with p, instead the other way around.\nSee also [discussion here](https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/277155).\nThanks to [Allohvk](https://www.kaggle.com/allohvk) for suggesting it in the first place.","metadata":{}},{"cell_type":"code","source":"class GaussianDropout(nn.Module):\n\n    def __init__(self, p: float):\n        \"\"\"\n        Multiplicative Gaussian Noise dropout with N(1, p/(1-p))\n        It is NOT (1-p)/p like in the paper, because here the\n        noise actually increases with p. (It can create the same\n        noise as the paper, but with reversed p values)\n\n        Source:\n        Dropout: A Simple Way to Prevent Neural Networks from Overfitting\n        https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\n\n        :param p: float - determines the the standard deviation of the\n        gaussian noise, where sigma = p/(1-p).\n        \"\"\"\n        super().__init__()\n        assert 0 <= p < 1\n        self.t_mean = torch.ones((0,))\n        self.shape = ()\n        self.p = p\n        self.t_std = self.compute_std()\n\n    def compute_std(self):\n        return self.p / (1 - self.p)\n\n    def forward(self, t_hidden):\n        if self.training and self.p > 0.:\n            if self.t_mean.shape != t_hidden.shape:\n                self.t_mean = torch.ones_like(input=t_hidden\n                                              , dtype=t_hidden.dtype\n                                              , device=t_hidden.device)\n            elif self.t_mean.device != t_hidden.device:\n                self.t_mean = self.t_mean.to(device=t_hidden.device, dtype=t_hidden.dtype)\n\n            t_gaussian_noise = torch.normal(self.t_mean, self.t_std)\n            t_hidden = t_hidden.mul(t_gaussian_noise)\n        return t_hidden","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:40:30.300758Z","iopub.execute_input":"2021-10-12T00:40:30.301087Z","iopub.status.idle":"2021-10-12T00:40:30.31068Z","shell.execute_reply.started":"2021-10-12T00:40:30.301052Z","shell.execute_reply":"2021-10-12T00:40:30.310051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test-Network","metadata":{}},{"cell_type":"code","source":"class TestNetwork(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(8, 16)\n        self.dropout = GaussianDropout(p=0.2)\n        self.linear2 = nn.Linear(16, 8)\n        \n    def forward(self, t_input):\n        t_hidden = self.linear(t_input)\n        t_hidden = self.dropout(t_hidden)\n        t_hidden = self.linear2(t_hidden)\n        return t_hidden","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:50.841877Z","iopub.execute_input":"2021-10-12T00:43:50.842203Z","iopub.status.idle":"2021-10-12T00:43:50.849297Z","shell.execute_reply.started":"2021-10-12T00:43:50.842173Z","shell.execute_reply":"2021-10-12T00:43:50.848094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network = TestNetwork()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:56.145359Z","iopub.execute_input":"2021-10-12T00:43:56.14563Z","iopub.status.idle":"2021-10-12T00:43:56.178673Z","shell.execute_reply.started":"2021-10-12T00:43:56.145603Z","shell.execute_reply":"2021-10-12T00:43:56.177891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_input = torch.randn((64, 80, 8))\nt_output = network(t_input)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:44:43.427657Z","iopub.execute_input":"2021-10-12T00:44:43.428329Z","iopub.status.idle":"2021-10-12T00:44:43.43614Z","shell.execute_reply.started":"2021-10-12T00:44:43.428294Z","shell.execute_reply":"2021-10-12T00:44:43.435349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_output.shape, t_output","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:45:34.043898Z","iopub.execute_input":"2021-10-12T00:45:34.044209Z","iopub.status.idle":"2021-10-12T00:45:34.05541Z","shell.execute_reply.started":"2021-10-12T00:45:34.044182Z","shell.execute_reply":"2021-10-12T00:45:34.05458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Maybe it helps you to improve your score :)**","metadata":{}}]}