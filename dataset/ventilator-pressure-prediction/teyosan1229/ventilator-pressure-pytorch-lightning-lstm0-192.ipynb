{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## About this notebook\n\n+ using PyTorch Lightning\n+ wandb\n    + However, I don't know how to hide the API KEY, so I commented it out.\n+ Can be run on kaggle, google colab, local machine\n+ I'm using the features of a private dataset, but I've output the data :)\n+ my LOCAL CV\n  + fold0:0.2326\n  + fold1:0.221\n  + fold2:0.2289\n  + fold3:0.2295\n  + fold4:0.2263\n  + Ensemble Folds with MEDIAN:0.192\n  \n### sorry. You may get a cpu memory error\n\nIt may be solved by not making oof","metadata":{}},{"cell_type":"markdown","source":"### reference\n\nThank you for publishing a very educational notebook\n\n+ https://www.kaggle.com/yasufuminakama/ventilator-pressure-lstm-starter\n+ https://www.kaggle.com/hirayukis/pytorch-lstm-cv-0-1942-lb-0-193\n+ https://www.kaggle.com/artgor/ventilator-pressure-prediction-eda-fe-and-models\n+ https://www.kaggle.com/theoviel/deep-learning-starter-simple-lstm\n+ https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153","metadata":{}},{"cell_type":"markdown","source":"## Get env","metadata":{"papermill":{"duration":0.023992,"end_time":"2021-10-10T14:10:35.582574","exception":false,"start_time":"2021-10-10T14:10:35.558582","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"papermill":{"duration":0.886454,"end_time":"2021-10-10T14:10:36.540204","exception":false,"start_time":"2021-10-10T14:10:35.65375","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:17.621041Z","iopub.execute_input":"2021-10-14T02:26:17.621536Z","iopub.status.idle":"2021-10-14T02:26:18.454706Z","shell.execute_reply.started":"2021-10-14T02:26:17.621425Z","shell.execute_reply":"2021-10-14T02:26:18.453879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nIN_COLAB = 'google.colab' in sys.modules\nIN_KAGGLE = 'kaggle_web_client' in sys.modules\nLOCAL = not (IN_KAGGLE or IN_COLAB)\nprint(f'IN_COLAB:{IN_COLAB}, IN_KAGGLE:{IN_KAGGLE}, LOCAL:{LOCAL}')","metadata":{"papermill":{"duration":0.052348,"end_time":"2021-10-10T14:10:36.635927","exception":false,"start_time":"2021-10-10T14:10:36.583579","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:18.456334Z","iopub.execute_input":"2021-10-14T02:26:18.456578Z","iopub.status.idle":"2021-10-14T02:26:18.467056Z","shell.execute_reply.started":"2021-10-14T02:26:18.456539Z","shell.execute_reply":"2021-10-14T02:26:18.466294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # For Colab Download some datasets\n# # ================================\n# if IN_COLAB:\n#     # mount googledrive\n#     from google.colab import drive\n#     drive.mount('/content/drive')\n#     # copy kaggle.json from googledrive\n#     ! pip install --upgrade --force-reinstall --no-deps  kaggle > /dev/null\n#     ! mkdir ~/.kaggle\n#     ! cp \"/content/drive/MyDrive/kaggle/kaggle.json\" ~/.kaggle/\n#     ! chmod 600 ~/.kaggle/kaggle.json\n    \n#     if not os.path.exists(\"/content/input/\"):\n#         !mkdir input\n#         !mkdir input/features\n#         !kaggle datasets download -d teyosan1229/ventilator-pressure\n#         !unzip /content/ventilator-pressure.zip -d input/features\n#         !kaggle competitions download -c ventilator-pressure-prediction\n#         !unzip /content/ventilator-pressure-prediction.zip -d input","metadata":{"papermill":{"duration":0.082141,"end_time":"2021-10-10T14:10:36.757772","exception":false,"start_time":"2021-10-10T14:10:36.675631","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:18.467998Z","iopub.execute_input":"2021-10-14T02:26:18.468233Z","iopub.status.idle":"2021-10-14T02:26:18.473762Z","shell.execute_reply.started":"2021-10-14T02:26:18.468211Z","shell.execute_reply":"2021-10-14T02:26:18.473002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IN_KAGGLE or IN_COLAB:\n    !pip install --upgrade -q wandb\n    !pip install -q pytorch-lightning\n    !pip install torch_optimizer","metadata":{"papermill":{"duration":25.497049,"end_time":"2021-10-10T14:11:02.294522","exception":false,"start_time":"2021-10-10T14:10:36.797473","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:18.476302Z","iopub.execute_input":"2021-10-14T02:26:18.476554Z","iopub.status.idle":"2021-10-14T02:26:43.921593Z","shell.execute_reply.started":"2021-10-14T02:26:18.47652Z","shell.execute_reply":"2021-10-14T02:26:43.920779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"papermill":{"duration":0.026235,"end_time":"2021-10-10T14:11:02.349081","exception":false,"start_time":"2021-10-10T14:11:02.322846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Hide Warning\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Python Libraries\nimport os\nimport math\nimport random\nimport glob\nimport pickle\nfrom collections import defaultdict\nfrom pathlib import Path\n\n# Third party\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n# Utilities and Metrics\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import RobustScaler, normalize, QuantileTransformer\nfrom sklearn.metrics import mean_absolute_error #[roc_auc_score, accuracy_score]\n\n# Pytorch \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.optim.optimizer import Optimizer, required\nimport torch_optimizer as optim\n\n# Pytorch Lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Callback, seed_everything\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger, CSVLogger\n\n# Weights and Biases Tool\nimport wandb\n#os.environ[\"WANDB_API_KEY\"]='hoge'\n#wandb.login()","metadata":{"papermill":{"duration":9.351358,"end_time":"2021-10-10T14:11:11.72687","exception":false,"start_time":"2021-10-10T14:11:02.375512","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:43.925054Z","iopub.execute_input":"2021-10-14T02:26:43.92529Z","iopub.status.idle":"2021-10-14T02:26:52.372119Z","shell.execute_reply.started":"2021-10-14T02:26:43.925263Z","shell.execute_reply":"2021-10-14T02:26:52.37119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{"papermill":{"duration":0.026502,"end_time":"2021-10-10T14:11:11.781572","exception":false,"start_time":"2021-10-10T14:11:11.75507","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CFG:\n    debug = False\n    competition='ventilator'\n    exp_name = \"public\"\n    seed = 29\n    \n    # data\n    target_col = 'pressure'\n    target_size = 1\n    \n    # optimizer\n    optimizer_name = 'RAdam'#['RAdam', 'sgd']\n    lr = 5e-3\n    weight_decay = 1e-5\n    amsgrad = False\n    \n    # scheduler\n    epochs = 300\n    scheduler = 'CosineAnnealingLR'\n    T_max = 300\n    min_lr = 1e-5\n    # criterion\n    # u_out = 1 を考慮しないLoss\n    criterion_name = 'CustomLoss1'\n    \n    # training\n    train = True\n    inference = True\n    n_fold = 5\n    trn_fold = [0]\n    precision = 16 #[16, 32, 64]\n    grad_acc = 1\n    # DataLoader\n    loader = {\n        \"train\": {\n            \"batch_size\": 1024,\n            \"num_workers\": 0,\n            \"shuffle\": True,\n            \"pin_memory\": True,\n            \"drop_last\": True\n        },\n        \"valid\": {\n            \"batch_size\": 1024,\n            \"num_workers\": 0,\n            \"shuffle\": False,\n            \"pin_memory\": True,\n            \"drop_last\": False\n        }\n    }\n    # pl\n    trainer = {\n        'gpus': 1,\n        'progress_bar_refresh_rate': 1,\n        'benchmark': False,\n        'deterministic': True,\n        }\n    # LSTM\n    num_layers = 4\n\n    cate_cols = ['u_out'] + \\\n                ['u_out_lag','u_out_lag2','u_out_lag3','u_out_lag_back','u_out_lag_back2','u_out_lag_back3'] + \\\n                ['R_20', 'R_5', 'R_50', 'C_10', 'C_20', 'C_50', 'RC_2010', 'RC_2020', 'RC_2050', 'RC_5010', 'RC_5020', 'RC_5050', 'RC_510', 'RC_520', 'RC_550']\n\n    cont_cols =['time_step', 'u_in'] + ['area'] + ['cross', 'cross2'] + ['u_in_cumsum', 'u_in_cummean'] + \\\n               ['u_in_lag','u_in_lag2','u_in_lag3','u_in_lag_back','u_in_lag_back2','u_in_lag_back3'] + \\\n               ['breath_time', 'u_in_time'] + ['u_out0_mean', 'u_out0_max', 'u_out0_std', 'u_out1_mean', 'u_out1_max', 'u_out1_std'] + \\\n               ['u_in_lag1_diff', 'u_in_lag2_diff','u_in_lag3_diff', 'u_in_lag4_diff'] + \\\n               ['u_in_rolling_mean2', 'u_in_rolling_mean4','u_in_rolling_mean10', 'u_in_rolling_max2', 'u_in_rolling_max4', 'u_in_rolling_max10',\n                'u_in_rolling_min2', 'u_in_rolling_min4', 'u_in_rolling_min10', 'u_in_rolling_std2', 'u_in_rolling_std4', 'u_in_rolling_std10'] + \\\n               ['breath_id__u_in__max', 'breath_id__u_out__max']\n\n    feature_cols = cate_cols + cont_cols\n    dense_dim = 512\n    hidden_size = 512\n    logit_dim = 512\n    \nseed_everything(CFG.seed)\nif not LOCAL:\n    CFG.loader[\"train\"][\"num_workers\"] = 4\n    CFG.loader[\"valid\"][\"num_workers\"] = 4","metadata":{"papermill":{"duration":0.045203,"end_time":"2021-10-10T14:11:11.855807","exception":false,"start_time":"2021-10-10T14:11:11.810604","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:52.373751Z","iopub.execute_input":"2021-10-14T02:26:52.374028Z","iopub.status.idle":"2021-10-14T02:26:52.394017Z","shell.execute_reply.started":"2021-10-14T02:26:52.373991Z","shell.execute_reply":"2021-10-14T02:26:52.393316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(CFG.feature_cols),CFG.loader[\"train\"][\"num_workers\"]","metadata":{"papermill":{"duration":0.034967,"end_time":"2021-10-10T14:11:11.917909","exception":false,"start_time":"2021-10-10T14:11:11.882942","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:52.395511Z","iopub.execute_input":"2021-10-14T02:26:52.395746Z","iopub.status.idle":"2021-10-14T02:26:52.407522Z","shell.execute_reply.started":"2021-10-14T02:26:52.395723Z","shell.execute_reply":"2021-10-14T02:26:52.406811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Directory & LoadData","metadata":{"papermill":{"duration":0.027746,"end_time":"2021-10-10T14:11:11.972913","exception":false,"start_time":"2021-10-10T14:11:11.945167","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if IN_KAGGLE:\n    INPUT_DIR = Path('../input/ventilator-pressure-prediction')\n    FEAT_DIR = Path('../input/ventilator-pressure')\n    OUTPUT_DIR = './'\nelif IN_COLAB:\n    INPUT_DIR = Path('/content/input/')\n    FEAT_DIR = Path('/content/input/features/')\n    OUTPUT_DIR = f'/content/drive/MyDrive/kaggle/Ventilator Pressure/{CFG.exp_name}/'\nif LOCAL:\n    INPUT_DIR = Path(\"F:/Kaggle/ventilator-pressure-prediction/data/input/\")\n    FEAT_DIR = Path(\"F:/Kaggle/ventilator-pressure-prediction/data/input/features/\")\n    OUTPUT_DIR = f'F:/Kaggle/ventilator-pressure-prediction/data/output/{CFG.exp_name}/'\n    \ndef load_datasets(feats):\n    dfs = [pd.read_feather(FEAT_DIR / f'{f}_train.ftr') for f in feats]\n    X_train = pd.concat(dfs, axis=1)\n    dfs = [pd.read_feather(FEAT_DIR / f'{f}_test.ftr') for f in feats]\n    X_test = pd.concat(dfs, axis=1)\n    return X_train, X_test\n\n\n# you can use own feature engineeringed data\nfeats = ['Base', 'Area', 'Cross', 'U_in_cumsum_mean', 'U_in_Lag', 'U_out_Lag', 'RC_OHE', 'U_out_stat', 'Time', 'U_in_Lag_Diff', 'U_in_Rolling', 'U_inout_max']\ndf_train, df_test = load_datasets(feats)\ndf_oof = df_train[[\"id\",\"breath_id\",\"u_out\", \"pressure\", \"fold\"]].copy()\n\nsubmission = pd.read_csv(INPUT_DIR / \"sample_submission.csv\")\ndisplay(df_train.head())\ndisplay(df_test.head())\n\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nif CFG.debug:\n    CFG.epochs = 5\n    #CFG.inference = False\n    #df_train = df_train.head(240000)","metadata":{"papermill":{"duration":22.139304,"end_time":"2021-10-10T14:11:34.139144","exception":false,"start_time":"2021-10-10T14:11:11.99984","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:26:52.410462Z","iopub.execute_input":"2021-10-14T02:26:52.410664Z","iopub.status.idle":"2021-10-14T02:27:37.966496Z","shell.execute_reply.started":"2021-10-14T02:26:52.410638Z","shell.execute_reply":"2021-10-14T02:27:37.96584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv('train.csv',index=False)\ndf_test.to_csv('test.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:27:37.96776Z","iopub.execute_input":"2021-10-14T02:27:37.96802Z","iopub.status.idle":"2021-10-14T02:39:59.239626Z","shell.execute_reply.started":"2021-10-14T02:27:37.967987Z","shell.execute_reply":"2021-10-14T02:39:59.238871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"papermill":{"duration":0.028359,"end_time":"2021-10-10T14:11:34.198588","exception":false,"start_time":"2021-10-10T14:11:34.170229","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # LINEに通知\n# import requests\n# def send_line_notification(message):\n#     env = \"\"\n#     if IN_COLAB: env = \"colab\"\n#     elif IN_KAGGLE: env = \"kaggle\"\n#     elif LOCAL: env = \"local\"\n        \n#     line_token = 'hoge'\n#     endpoint = 'https://notify-api.line.me/api/notify'\n#     message = f\"[{env}]{message}\"\n#     payload = {'message': message}\n#     headers = {'Authorization': 'Bearer {}'.format(line_token)}\n#     requests.post(endpoint, data=payload, headers=headers)","metadata":{"papermill":{"duration":0.036677,"end_time":"2021-10-10T14:11:34.263991","exception":false,"start_time":"2021-10-10T14:11:34.227314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:39:59.242431Z","iopub.execute_input":"2021-10-14T02:39:59.242769Z","iopub.status.idle":"2021-10-14T02:39:59.246599Z","shell.execute_reply.started":"2021-10-14T02:39:59.242733Z","shell.execute_reply":"2021-10-14T02:39:59.245817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV Split","metadata":{"papermill":{"duration":0.028039,"end_time":"2021-10-10T14:11:34.320298","exception":false,"start_time":"2021-10-10T14:11:34.292259","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# df_train[\"fold\"] = -1\n# Fold = GroupKFold(n_splits=CFG.n_fold)\n# for n, (train_index, val_index) in enumerate(Fold.split(df_train, df_train[CFG.target_col], groups=df_train.breath_id.values)):\n#      df_train.loc[val_index, 'fold'] = int(n)\n# df_train['fold'] = df_train['fold'].astype(int)\n# df_oof = df_train[[\"id\",\"breath_id\",\"u_out\", \"pressure\", \"fold\"]].copy()\n# print(df_train.groupby(['fold', 'breath_id']).size())","metadata":{"papermill":{"duration":0.46413,"end_time":"2021-10-10T14:11:34.812685","exception":false,"start_time":"2021-10-10T14:11:34.348555","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:39:59.247719Z","iopub.execute_input":"2021-10-14T02:39:59.248053Z","iopub.status.idle":"2021-10-14T02:39:59.259701Z","shell.execute_reply.started":"2021-10-14T02:39:59.248015Z","shell.execute_reply":"2021-10-14T02:39:59.258947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transforms","metadata":{"papermill":{"duration":0.058435,"end_time":"2021-10-10T14:11:34.934397","exception":false,"start_time":"2021-10-10T14:11:34.875962","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Dataset","metadata":{"papermill":{"duration":0.055648,"end_time":"2021-10-10T14:11:35.044608","exception":false,"start_time":"2021-10-10T14:11:34.98896","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n        self.u_out = self.X[:,:,2]\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        x = torch.FloatTensor(self.X[idx])\n        u_out = torch.LongTensor(self.u_out[idx])\n        label = torch.FloatTensor(self.y[idx]).squeeze(1)\n        return x, u_out, label\n    \nclass TestDataset(Dataset):\n    def __init__(self, X):\n        self.X = X\n        self.u_out = self.X[:,:,2]\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return torch.FloatTensor(self.X[idx])","metadata":{"papermill":{"duration":0.072841,"end_time":"2021-10-10T14:11:35.17362","exception":false,"start_time":"2021-10-10T14:11:35.100779","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:39:59.261041Z","iopub.execute_input":"2021-10-14T02:39:59.261514Z","iopub.status.idle":"2021-10-14T02:39:59.271288Z","shell.execute_reply.started":"2021-10-14T02:39:59.261478Z","shell.execute_reply":"2021-10-14T02:39:59.270577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rankgauss & Reshape\npandas.DataFrameからnumpyに変換、シーケンス分をまとめる","metadata":{"papermill":{"duration":0.032684,"end_time":"2021-10-10T14:11:35.250612","exception":false,"start_time":"2021-10-10T14:11:35.217928","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for col in tqdm(CFG.cont_cols):\n    qt = QuantileTransformer(random_state=0, output_distribution='normal')\n    df_train[[col]] = qt.fit_transform(df_train[[col]])\n    df_test[[col]] = qt.transform(df_test[[col]])\n#display(df_train.head())\n#display(df_test.head())\n#df_train.describe().T","metadata":{"papermill":{"duration":92.669575,"end_time":"2021-10-10T14:13:09.667443","exception":false,"start_time":"2021-10-10T14:11:36.997868","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:39:59.272475Z","iopub.execute_input":"2021-10-14T02:39:59.272815Z","iopub.status.idle":"2021-10-14T02:42:44.889574Z","shell.execute_reply.started":"2021-10-14T02:39:59.27278Z","shell.execute_reply":"2021-10-14T02:42:44.888842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.float32(df_train[CFG.feature_cols]).reshape(-1, 80, len(CFG.feature_cols))\ntest_X = np.float32(df_test[CFG.feature_cols]).reshape(-1, 80, len(CFG.feature_cols))\ny = np.float32(df_train[\"pressure\"]).reshape(-1, 80, 1)\nFold = np.int16(df_train[\"fold\"]).reshape(-1, 80, 1)\nFold = Fold.mean(axis=1).flatten()\nprint(X.shape, y.shape, test_X.shape, Fold.shape)","metadata":{"papermill":{"duration":3.173407,"end_time":"2021-10-10T14:13:13.061375","exception":false,"start_time":"2021-10-10T14:13:09.887968","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:44.892036Z","iopub.execute_input":"2021-10-14T02:42:44.892611Z","iopub.status.idle":"2021-10-14T02:42:55.589097Z","shell.execute_reply.started":"2021-10-14T02:42:44.892569Z","shell.execute_reply":"2021-10-14T02:42:55.588342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X, u_out, y になっているか確認\nds = TrainDataset(X,y)\nfor i in range(3):\n    print(\"=\"*50)\n    print(ds[0][i])\ndel ds","metadata":{"papermill":{"duration":0.118878,"end_time":"2021-10-10T14:13:13.2132","exception":false,"start_time":"2021-10-10T14:13:13.094322","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:55.590425Z","iopub.execute_input":"2021-10-14T02:42:55.590853Z","iopub.status.idle":"2021-10-14T02:42:55.691313Z","shell.execute_reply.started":"2021-10-14T02:42:55.590807Z","shell.execute_reply":"2021-10-14T02:42:55.690619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DataModule","metadata":{"papermill":{"duration":0.033224,"end_time":"2021-10-10T14:13:13.281013","exception":false,"start_time":"2021-10-10T14:13:13.247789","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n    \"\"\"\n    numpy arrayで受け取る\n    \"\"\"\n    def __init__(self, tr_X, tr_y, val_X, val_y, test_X, cfg):\n        super().__init__()\n        self.train_data = tr_X\n        self.train_label = tr_y\n        self.valid_data = val_X\n        self.valid_label = val_y\n        self.test_data = test_X\n        self.cfg = cfg\n        \n    def setup(self, stage=None):\n        self.train_dataset = TrainDataset(self.train_data, self.train_label)\n        self.valid_dataset = TrainDataset(self.valid_data, self.valid_label)\n        self.test_dataset = TestDataset(self.test_data)\n        \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, **self.cfg.loader['train'])\n\n    def val_dataloader(self):\n        return DataLoader(self.valid_dataset, **self.cfg.loader['valid'])\n\n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, **self.cfg.loader['valid'])","metadata":{"papermill":{"duration":0.044149,"end_time":"2021-10-10T14:13:13.358782","exception":false,"start_time":"2021-10-10T14:13:13.314633","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:55.692508Z","iopub.execute_input":"2021-10-14T02:42:55.692761Z","iopub.status.idle":"2021-10-14T02:42:55.703017Z","shell.execute_reply.started":"2021-10-14T02:42:55.692729Z","shell.execute_reply":"2021-10-14T02:42:55.701457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch Lightning Module","metadata":{"papermill":{"duration":0.033141,"end_time":"2021-10-10T14:13:13.498034","exception":false,"start_time":"2021-10-10T14:13:13.464893","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.dense_dim = cfg.dense_dim\n        self.hidden_size = cfg.hidden_size\n        self.num_layers = cfg.num_layers\n        self.logit_dim = cfg.logit_dim\n        self.mlp = nn.Sequential(\n            nn.Linear(len(cfg.feature_cols), self.dense_dim // 2),\n            nn.ReLU(),\n            #nn.Dropout(0.2),\n            nn.Linear(self.dense_dim // 2, self.dense_dim),\n            nn.ReLU(),\n        )\n        self.lstm1 = nn.LSTM(self.dense_dim, self.dense_dim,\n                            dropout=0., batch_first=True, bidirectional=True)\n        self.lstm2 = nn.LSTM(self.dense_dim * 2, self.dense_dim//2,\n                            dropout=0., batch_first=True, bidirectional=True)\n        self.lstm3 = nn.LSTM(self.dense_dim//2 * 2, self.dense_dim//4,\n                            dropout=0., batch_first=True, bidirectional=True)\n        self.lstm4 = nn.LSTM(self.dense_dim//4 * 2, self.dense_dim//8,\n                            dropout=0., batch_first=True, bidirectional=True)\n        self.head = nn.Sequential(\n            nn.LayerNorm(self.hidden_size//8 * 2),\n            nn.GELU(),\n            nn.Linear(self.hidden_size//8 * 2, 1),\n        )\n        # LSTMやGRUは直交行列に初期化する\n        for n, m in self.named_modules():\n            if isinstance(m, nn.LSTM):\n                print(f'init {m}')\n                for param in m.parameters():\n                    if len(param.shape) >= 2:\n                        nn.init.orthogonal_(param.data)\n                    else:\n                        nn.init.normal_(param.data)\n            elif isinstance(m, nn.GRU):\n                print(f\"init {m}\")\n                for param in m.parameters():\n                    if len(param.shape) >= 2:\n                        nn.init.orthogonal_(param.data)\n                    else:\n                        nn.init.normal_(param.data)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.mlp(x)\n        features, _ = self.lstm1(features)\n        features, _ = self.lstm2(features)\n        features, _ = self.lstm3(features)\n        features, _ = self.lstm4(features)\n        output = self.head(features).view(bs, -1)\n        return output\n    \ndef get_model(cfg):\n    model = CustomModel(cfg)\n    return model\n\n# ====================================================\n# criterion\n# ====================================================\ndef compute_metric(df, preds):\n    \"\"\"\n    Metric for the problem, as I understood it.\n    \"\"\"\n    \n    y = np.array(df['pressure'].values.tolist())\n    w = 1 - np.array(df['u_out'].values.tolist())\n    \n    assert y.shape == preds.shape and w.shape == y.shape, (y.shape, preds.shape, w.shape)\n    \n    mae = w * np.abs(y - preds)\n    mae = mae.sum() / w.sum()\n    \n    return mae\n\n\nclass VentilatorLoss(nn.Module):\n    \"\"\"\n    Directly optimizes the competition metric\n    \"\"\"\n    def __call__(self, preds, y, u_out):\n        w = 1 - u_out\n        mae = w * (y - preds).abs()\n        mae = mae.sum(-1) / w.sum(-1)\n\n        return mae\n\ndef get_criterion():\n    if CFG.criterion_name == 'BCEWithLogitsLoss':\n        criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n    if CFG.criterion_name == 'CrossEntropyLoss':\n        criterion = nn.CrossEntropyLoss()\n    if CFG.criterion_name == 'CustomLoss1':\n        # [reference]https://www.kaggle.com/theoviel/deep-learning-starter-simple-lstm\n        criterion = VentilatorLoss()\n    else:\n        raise NotImplementedError\n    return criterion\n# ====================================================\n# optimizer\n# ====================================================\ndef get_optimizer(model: nn.Module, config: dict):\n    \"\"\"\n    input:\n    model:model\n    config:optimizer_nameやlrが入ったものを渡す\n    \n    output:optimizer\n    \"\"\"\n    optimizer_name = config.optimizer_name\n    if 'Adam' == optimizer_name:\n        return Adam(model.parameters(),\n                    lr=config.lr,\n                    weight_decay=config.weight_decay,\n                    amsgrad=config.amsgrad)\n    elif 'RAdam' == optimizer_name:\n        return optim.RAdam(model.parameters(),\n                           lr=config.lr,\n                           weight_decay=config.weight_decay)\n    elif 'sgd' == optimizer_name:\n        return SGD(model.parameters(),\n                   lr=config.lr,\n                   momentum=0.9,\n                   nesterov=True,\n                   weight_decay=config.weight_decay,)\n    else:\n        raise NotImplementedError\n\n# ====================================================\n# scheduler\n# ====================================================\ndef get_scheduler(optimizer):\n    if CFG.scheduler=='ReduceLROnPlateau':\n        \"\"\"\n        factor : 学習率の減衰率\n        patience : 何ステップ向上しなければ減衰するかの値\n        eps : nanとかInf回避用の微小数\n        \"\"\"\n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n    elif CFG.scheduler=='CosineAnnealingLR':\n        \"\"\"\n        T_max : 1 半周期のステップサイズ\n        eta_min : 最小学習率(極小値)\n        \"\"\"\n        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n        \"\"\"\n        T_0 : 初期の繰りかえし回数\n        T_mult : サイクルのスケール倍率\n        \"\"\"\n        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n    else:\n        raise NotImplementedError\n    return scheduler","metadata":{"papermill":{"duration":0.087765,"end_time":"2021-10-10T14:13:13.619331","exception":false,"start_time":"2021-10-10T14:13:13.531566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:55.704535Z","iopub.execute_input":"2021-10-14T02:42:55.704964Z","iopub.status.idle":"2021-10-14T02:42:55.736935Z","shell.execute_reply.started":"2021-10-14T02:42:55.704928Z","shell.execute_reply":"2021-10-14T02:42:55.736103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.model = get_model(cfg)\n        self.criterion = get_criterion()\n    \n    def forward(self, x):\n        output = self.model(x)\n        return output\n    \n    def training_step(self, batch, batch_idx):\n        x, u_out, y = batch\n        output = self.forward(x)\n        labels = y\n        loss = self.criterion(output, labels ,u_out).mean()\n        \n        self.log('train_loss', loss, on_step=True, prog_bar=True, logger=True)\n        return {\"loss\": loss, \"predictions\": output, \"labels\": labels}\n    \n    def training_epoch_end(self, outputs):\n        self.log(\"lr\", self.optimizer.param_groups[0]['lr'], prog_bar=True, logger=True)\n    \n    def validation_step(self, batch, batch_idx):\n        x, u_out, y = batch\n        output = self.forward(x)\n        labels = y\n        loss = self.criterion(output,labels ,u_out).mean()\n        self.log('val_loss', loss, on_step= True, prog_bar=True, logger=True)\n        return {\"predictions\": output,\n                \"labels\": labels,\n                \"loss\": loss.item()}\n    \n    def validation_epoch_end(self, outputs):\n        preds = []\n        labels = []\n        loss = 0\n        for output in outputs:\n            preds += output['predictions']\n            labels += output['labels']\n            loss += output['loss']\n\n        labels = torch.stack(labels)\n        preds = torch.stack(preds)\n        loss = loss/len(outputs)\n        \n        self.log(\"val_loss_epoch\", loss, prog_bar=True, logger=True)\n        \n    def predict_step(self, batch, batch_idx):\n        x = batch\n        output = self.forward(x)\n        return output\n        \n    def test_step(self, batch, batch_idx):\n        x = batch       \n        output = self.forward(x)\n        return output\n    \n    def configure_optimizers(self):\n        self.optimizer = get_optimizer(self, self.cfg)\n        self.scheduler = {'scheduler': get_scheduler(self.optimizer),\n                          'interval': 'step', # or 'epoch'\n                          'frequency': 1}\n        return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}","metadata":{"papermill":{"duration":0.334427,"end_time":"2021-10-10T14:13:14.258293","exception":false,"start_time":"2021-10-10T14:13:13.923866","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:55.738892Z","iopub.execute_input":"2021-10-14T02:42:55.739122Z","iopub.status.idle":"2021-10-14T02:42:55.752379Z","shell.execute_reply.started":"2021-10-14T02:42:55.739093Z","shell.execute_reply":"2021-10-14T02:42:55.751443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"papermill":{"duration":0.037985,"end_time":"2021-10-10T14:13:14.335234","exception":false,"start_time":"2021-10-10T14:13:14.297249","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train() -> None:\n    for fold in range(CFG.n_fold):\n        if not fold in CFG.trn_fold:\n            continue\n        print(f\"{'='*38} Fold: {fold} {'='*38}\")\n        # Logger\n        #======================================================\n        lr_monitor = LearningRateMonitor(logging_interval='step')\n        \n        loss_checkpoint = ModelCheckpoint(\n            dirpath=OUTPUT_DIR,\n            filename=f\"best_loss_fold{fold}\",\n            monitor=\"val_loss\",\n            save_last=True,\n            save_top_k=1,\n            save_weights_only=True,\n            mode=\"min\",\n        )\n        \n#         wandb_logger = WandbLogger(\n#             project=f'{CFG.competition}',\n#             group= f'{CFG.exp_name}',\n#             name = f'Fold{fold}',\n#             save_dir=OUTPUT_DIR\n#         )\n        data_module = DataModule(X[Fold!=fold], y[Fold!=fold],\n                                 X[Fold==fold], y[Fold==fold],\n                                 test_X,\n                                 CFG\n                                )\n        data_module.setup()\n        \n        CFG.T_max = int(math.ceil(len(data_module.train_dataloader())/CFG.grad_acc)*CFG.epochs)\n        print(f\"set schedular T_max {CFG.T_max}\")\n        #early_stopping_callback = EarlyStopping(monitor='val_loss_epoch',mode=\"min\", patience=5)\n        \n        trainer = pl.Trainer(\n#             logger=wandb_logger,\n            callbacks=[loss_checkpoint],#lr_monitor,early_stopping_callback\n            default_root_dir=OUTPUT_DIR,\n            accumulate_grad_batches=CFG.grad_acc,\n            max_epochs=CFG.epochs,\n            precision=CFG.precision,\n            **CFG.trainer\n        )\n        # 学習\n        model = Trainer(CFG)\n        trainer.fit(model, data_module)\n        torch.save(model.model.state_dict(),OUTPUT_DIR + '/' + f'{CFG.exp_name}_fold{fold}.pth')\n        \n        del model, data_module\n        \n        if CFG.inference:\n            data_module = DataModule(X[0:1], y[0:1], X[0:1], y[0:1], test_X, CFG)\n            data_module.setup()\n            # Road best loss model\n            best_model = Trainer.load_from_checkpoint(cfg=CFG,checkpoint_path=loss_checkpoint.best_model_path)\n            predictions = trainer.predict(best_model, data_module.test_dataloader())\n            preds = []\n            for p in predictions:\n                preds += p\n            preds = torch.stack(preds).flatten()\n            submission['pressure'] = preds.to('cpu').detach().numpy()\n            submission.to_csv(OUTPUT_DIR + '/' + f'submission_fold{fold}.csv',index=False)\n            \n            # oof\n            data_module = DataModule(X[0:1], y[0:1], X[0:1], y[0:1], X[Fold==fold], CFG)\n            data_module.setup()\n            predictions = trainer.predict(best_model, data_module.test_dataloader())\n            preds = []\n            for p in predictions:\n                preds += p\n            preds = torch.stack(preds).flatten()\n            df_oof.loc[df_oof[\"fold\"] == fold, ['pred']] = preds.to('cpu').detach().numpy()\n            df_oof.to_csv(OUTPUT_DIR + '/' + f'oof.csv',index=False)\n        \n        wandb.finish()\n\n        ","metadata":{"papermill":{"duration":0.049586,"end_time":"2021-10-10T14:13:14.423877","exception":false,"start_time":"2021-10-10T14:13:14.374291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:55.753963Z","iopub.execute_input":"2021-10-14T02:42:55.754418Z","iopub.status.idle":"2021-10-14T02:42:55.772241Z","shell.execute_reply.started":"2021-10-14T02:42:55.754382Z","shell.execute_reply":"2021-10-14T02:42:55.771405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()\n#send_line_notification(\"finished\")\nwandb.finish()","metadata":{"papermill":{"duration":5433.35757,"end_time":"2021-10-10T15:43:47.81628","exception":false,"start_time":"2021-10-10T14:13:14.45871","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:42:55.773378Z","iopub.execute_input":"2021-10-14T02:42:55.773901Z","iopub.status.idle":"2021-10-14T02:47:15.993944Z","shell.execute_reply.started":"2021-10-14T02:42:55.773864Z","shell.execute_reply":"2021-10-14T02:47:15.992186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oof = pd.read_csv(OUTPUT_DIR + 'oof.csv')\n# cv = compute_metric(oof,oof[\"pred\"])\n# print(f\"cv:{cv}\")","metadata":{"papermill":{"duration":0.152895,"end_time":"2021-10-10T15:43:48.216026","exception":false,"start_time":"2021-10-10T15:43:48.063131","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T02:47:15.995426Z","iopub.status.idle":"2021-10-14T02:47:15.995835Z","shell.execute_reply.started":"2021-10-14T02:47:15.995614Z","shell.execute_reply":"2021-10-14T02:47:15.995639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # median\n# submission = pd.read_csv(INPUT_DIR / \"sample_submission.csv\")\n# preds = [pd.read_csv(f'./exp037sub_fold{i}.csv') for i in range(5)]\n# print(preds[0].pressure[0],preds[1].pressure[0],preds[2].pressure[0],preds[3].pressure[0],preds[4].pressure[0])\n# submission['pressure'] = np.median([preds[0].pressure,preds[1].pressure,preds[2].pressure,preds[3].pressure,preds[4].pressure],axis=0)\n# submission.to_csv('./exp037_5fold_median.csv',index=False)\n# submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T02:47:15.997968Z","iopub.status.idle":"2021-10-14T02:47:15.998513Z","shell.execute_reply.started":"2021-10-14T02:47:15.998271Z","shell.execute_reply":"2021-10-14T02:47:15.998295Z"},"trusted":true},"execution_count":null,"outputs":[]}]}