{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\nimport gc","metadata":{"_uuid":"e331dbcc-0346-4019-9ff6-b890154a878b","_cell_guid":"3e5a0bd1-3e22-4b2c-a565-68985e55f95e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-27T12:13:37.014355Z","iopub.execute_input":"2021-10-27T12:13:37.014801Z","iopub.status.idle":"2021-10-27T12:13:44.012465Z","shell.execute_reply.started":"2021-10-27T12:13:37.014691Z","shell.execute_reply":"2021-10-27T12:13:44.011673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:13:44.014266Z","iopub.execute_input":"2021-10-27T12:13:44.014481Z","iopub.status.idle":"2021-10-27T12:13:44.095447Z","shell.execute_reply.started":"2021-10-27T12:13:44.014456Z","shell.execute_reply":"2021-10-27T12:13:44.094546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 300\nBATCH_SIZE = 512\nNUM_FOLDS = 10","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:13:44.096647Z","iopub.execute_input":"2021-10-27T12:13:44.096901Z","iopub.status.idle":"2021-10-27T12:13:44.101195Z","shell.execute_reply.started":"2021-10-27T12:13:44.096871Z","shell.execute_reply":"2021-10-27T12:13:44.100433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]\n    EPOCH = 100\n    BATCH_SIZE = 128\n    NUM_FOLDS = 5","metadata":{"_uuid":"ca71d87d-6594-4f31-906d-0b53cd4c1374","_cell_guid":"89eb257e-0ed2-4f8b-94d6-462a5e995eb1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-27T12:13:44.102864Z","iopub.execute_input":"2021-10-27T12:13:44.103384Z","iopub.status.idle":"2021-10-27T12:13:58.755421Z","shell.execute_reply.started":"2021-10-27T12:13:44.103345Z","shell.execute_reply":"2021-10-27T12:13:58.754584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    print(\"Step-2...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-3...Completed\")\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    print(\"Step-5...Completed\")\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    df[[\"30_in_sum\",\"30_in_min\",\"30_in_max\",\"30_in_mean\"]] = (df\\\n                                                              .groupby('breath_id')['u_in']\\\n                                                              .rolling(window=30,min_periods=1)\\\n                                                              .agg({\"30_in_sum\":\"sum\",\n                                                                    \"30_in_min\":\"min\",\n                                                                    \"30_in_max\":\"max\",\n                                                                    \"30_in_mean\":\"mean\"})\\\n                                                               .reset_index(level=0,drop=True))\n    print(\"Step-6...Completed\")\n    \n    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n    \n    print(\"Step-7...Completed\")\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"_uuid":"dc41dbf2-f199-4b9d-bbd9-bf6084162b47","_cell_guid":"13a36b46-7067-4b29-aad3-7e3b15e8415b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-27T12:13:58.757951Z","iopub.execute_input":"2021-10-27T12:13:58.758284Z","iopub.status.idle":"2021-10-27T12:17:59.396971Z","shell.execute_reply.started":"2021-10-27T12:13:58.758244Z","shell.execute_reply":"2021-10-27T12:17:59.395917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:17:59.398668Z","iopub.execute_input":"2021-10-27T12:17:59.398953Z","iopub.status.idle":"2021-10-27T12:17:59.40867Z","shell.execute_reply.started":"2021-10-27T12:17:59.398914Z","shell.execute_reply":"2021-10-27T12:17:59.408011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure','id', 'breath_id','one','count',\n            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n            'breath_id_lag2same'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id','one','count',\n            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n            'breath_id_lag2same'], axis=1)","metadata":{"_uuid":"346bf2c0-96d2-4da5-8837-c0f820294a85","_cell_guid":"01328860-fa2a-421c-9e5f-ea0048246f98","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-27T12:17:59.410843Z","iopub.execute_input":"2021-10-27T12:17:59.411074Z","iopub.status.idle":"2021-10-27T12:18:06.059982Z","shell.execute_reply.started":"2021-10-27T12:17:59.411049Z","shell.execute_reply":"2021-10-27T12:18:06.059127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COLS = train.columns.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:18:06.061332Z","iopub.execute_input":"2021-10-27T12:18:06.061602Z","iopub.status.idle":"2021-10-27T12:18:06.0655Z","shell.execute_reply.started":"2021-10-27T12:18:06.061574Z","shell.execute_reply":"2021-10-27T12:18:06.064662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:18:06.06668Z","iopub.execute_input":"2021-10-27T12:18:06.067372Z","iopub.status.idle":"2021-10-27T12:18:06.082133Z","shell.execute_reply.started":"2021-10-27T12:18:06.06734Z","shell.execute_reply":"2021-10-27T12:18:06.081478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:18:06.083157Z","iopub.execute_input":"2021-10-27T12:18:06.083467Z","iopub.status.idle":"2021-10-27T12:19:11.728198Z","shell.execute_reply.started":"2021-10-27T12:18:06.083442Z","shell.execute_reply":"2021-10-27T12:19:11.727392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:19:11.729378Z","iopub.execute_input":"2021-10-27T12:19:11.729594Z","iopub.status.idle":"2021-10-27T12:19:30.052326Z","shell.execute_reply.started":"2021-10-27T12:19:11.729569Z","shell.execute_reply":"2021-10-27T12:19:30.051377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:19:30.053658Z","iopub.execute_input":"2021-10-27T12:19:30.053897Z","iopub.status.idle":"2021-10-27T12:19:30.058273Z","shell.execute_reply.started":"2021-10-27T12:19:30.05387Z","shell.execute_reply":"2021-10-27T12:19:30.057711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nclass WarmupExponentialDecay(Callback):\n    def __init__(self,lr_base=0.0002,lr_min=0.0,decay=0,warmup_epochs=0):\n        self.num_passed_batchs = 0   #一个计数器\n        self.warmup_epochs=warmup_epochs  \n        self.lr=lr_base #learning_rate_base\n        self.lr_min=lr_min #最小的起始学习率,此代码尚未实现\n        self.decay=decay  #指数衰减率\n        self.steps_per_epoch=0 #也是一个计数器\n        \n    def on_batch_begin(self, batch, logs=None):\n        # params是模型自动传递给Callback的一些参数\n        if self.steps_per_epoch==0:\n            #防止跑验证集的时候呗更改了\n            if self.params['steps'] == None:\n                self.steps_per_epoch = np.ceil(1. * self.params['samples'] / self.params['batch_size'])\n            else:\n                self.steps_per_epoch = self.params['steps']\n        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*(self.num_passed_batchs + 1) / self.steps_per_epoch / self.warmup_epochs)\n        else:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*((1-self.decay)**(self.num_passed_batchs-self.steps_per_epoch*self.warmup_epochs)))\n        self.num_passed_batchs += 1\n        \n    def on_epoch_begin(self,epoch,logs=None):\n        #用来输出学习率的,可以删除\n        print(\"learning_rate:\",K.get_value(self.model.optimizer.lr))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:19:30.059259Z","iopub.execute_input":"2021-10-27T12:19:30.059721Z","iopub.status.idle":"2021-10-27T12:19:30.072793Z","shell.execute_reply.started":"2021-10-27T12:19:30.059689Z","shell.execute_reply":"2021-10-27T12:19:30.072028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    inputs = keras.layers.Input(shape=train.shape[-2:])\n    \n    x = keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True))(inputs)\n    x1 = keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True))(x)\n    x2 = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x1)\n    \n    x3 = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    x4 = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x3)\n    \n    x5 = keras.layers.Dense(100, activation='selu')(x4)\n    x6 = keras.layers.Dense(100, activation='selu')(x5)\n    x7 = keras.layers.Dense(100, activation='selu')(x6)\n    x7 = tf.keras.layers.Concatenate(axis=2)([x7,x5])\n    outputs = keras.layers.Dense(1)(x7)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"lstm_model\")\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:19:30.076282Z","iopub.execute_input":"2021-10-27T12:19:30.076547Z","iopub.status.idle":"2021-10-27T12:19:30.089264Z","shell.execute_reply.started":"2021-10-27T12:19:30.076519Z","shell.execute_reply":"2021-10-27T12:19:30.08859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        U_OUT_IDX = 3\n        y_weight = np.ones_like( y_train )\n        u_out_values = X_train[:,:,U_OUT_IDX]\n        y_weight[ u_out_values==1 ] = 0.1\n        model = get_model()\n        model.compile(optimizer=\"adam\", loss=\"mae\", sample_weight_mode=\"temporal\")\n\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n        es = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, mode=\"min\", restore_best_weights=True)\n\n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        sv = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=False, mode='auto', save_freq='epoch',\n            options=None\n        )\n\n    #         if fold < 9:\n    #             model.load_weights(f\"../input/tf-lstm-resnet-like-ff-92e0df/folds{fold}.hdf5\")\n    #             test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n    #         else:\n        model.fit(X_train, y_train, sample_weight=y_weight.reshape((-1, 80, 1)), validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n\n        del X_train, X_valid, y_train, y_valid, model\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:19:30.0904Z","iopub.execute_input":"2021-10-27T12:19:30.09102Z","iopub.status.idle":"2021-10-27T13:07:04.125959Z","shell.execute_reply.started":"2021-10-27T12:19:30.090992Z","shell.execute_reply":"2021-10-27T13:07:04.123294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gf = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\nall_pressure = sorted(train_gf.pressure.unique())\nPRESSURE_MIN = all_pressure[0]\nPRESSURE_MAX = all_pressure[-1]\nPRESSURE_STEP = (all_pressure[1] - all_pressure[0])\nsubmission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\nsubmission[\"pressure\"] =np.round( (submission.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\nsubmission.pressure = np.clip(submission.pressure, PRESSURE_MIN, PRESSURE_MAX)\npressure_unique = np.array(sorted(train_gf['pressure'].unique()))\nsubmission['pressure'] = submission['pressure'].map(lambda x: pressure_unique[np.abs(pressure_unique-x).argmin()])\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-10-27T13:07:04.127786Z","iopub.status.idle":"2021-10-27T13:07:04.128816Z","shell.execute_reply.started":"2021-10-27T13:07:04.128498Z","shell.execute_reply":"2021-10-27T13:07:04.12853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T13:07:04.130277Z","iopub.status.idle":"2021-10-27T13:07:04.131468Z","shell.execute_reply.started":"2021-10-27T13:07:04.131148Z","shell.execute_reply":"2021-10-27T13:07:04.131179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}