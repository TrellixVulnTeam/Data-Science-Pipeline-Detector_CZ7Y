{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### The purpose of this notebook is to demonstrate the use of custom callbacks, validation only on `u_out==0`, custom discretization (with extrapolation) and some new features.\n\n##### Many thanks to [Chris Deotte](https://www.kaggle.com/cdeotte), [DLastStark](https://www.kaggle.com/dlaststark), [Zhangxin](https://www.kaggle.com/tenffe), [Niwashi](https://www.kaggle.com/marutama), [Carl McBride Ellis](https://www.kaggle.com/carlmcbrideellis) and many others for their ideas, discussions, models, features, etc.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import math\nimport os\nfrom pathlib import Path\nimport random\nimport gc\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GroupKFold, KFold\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import *\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras import mixed_precision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-02T11:15:22.257994Z","iopub.status.idle":"2021-11-02T11:15:22.258786Z","shell.execute_reply.started":"2021-11-02T11:15:22.2585Z","shell.execute_reply":"2021-11-02T11:15:22.258527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:26.014928Z","iopub.execute_input":"2021-11-02T09:31:26.015304Z","iopub.status.idle":"2021-11-02T09:31:26.02358Z","shell.execute_reply.started":"2021-11-02T09:31:26.015269Z","shell.execute_reply":"2021-11-02T09:31:26.022744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Constants","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCHS = 300\nFOLD_NUM = 5 # Total number of folds\nFOLDS = [0] # List of folds to run\nSEED = 23\n\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:27.25524Z","iopub.execute_input":"2021-11-02T09:31:27.255836Z","iopub.status.idle":"2021-11-02T09:31:27.260336Z","shell.execute_reply.started":"2021-11-02T09:31:27.255794Z","shell.execute_reply":"2021-11-02T09:31:27.25923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU Config","metadata":{}},{"cell_type":"code","source":"# Function to get hardware strategy\ndef get_hardware_strategy():\n    try:\n        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n        # set: this is always the case on Kaggle.\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        tf.config.optimizer.set_jit(True)\n    else:\n        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n        strategy = tf.distribute.get_strategy()\n    \n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n    return tpu, strategy\n\ntpu, strategy = get_hardware_strategy()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:29.328743Z","iopub.execute_input":"2021-11-02T09:31:29.329612Z","iopub.status.idle":"2021-11-02T09:31:29.338154Z","shell.execute_reply.started":"2021-11-02T09:31:29.329559Z","shell.execute_reply":"2021-11-02T09:31:29.337297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"REPLICAS = strategy.num_replicas_in_sync\nif tpu:\n    BATCH_SIZE = strategy.num_replicas_in_sync * BATCH_SIZE\nelse:\n    BATCH_SIZE = 8 * BATCH_SIZE\nprint('BATCH_SIZE:', BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:30.588329Z","iopub.execute_input":"2021-11-02T09:31:30.588658Z","iopub.status.idle":"2021-11-02T09:31:30.594937Z","shell.execute_reply.started":"2021-11-02T09:31:30.588624Z","shell.execute_reply":"2021-11-02T09:31:30.594254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Output files","metadata":{}},{"cell_type":"code","source":"MODELS = Path(\"models\")\nMODELS.mkdir(exist_ok=True)\n\nPREDS = Path(\"preds\")\nPREDS.mkdir(exist_ok=True)\n\nHISTORY = Path(\"history\")\nHISTORY.mkdir(exist_ok=True)\n\nINDICES = Path(\"indices\")\nINDICES.mkdir(exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:31.795785Z","iopub.execute_input":"2021-11-02T09:31:31.7966Z","iopub.status.idle":"2021-11-02T09:31:31.803209Z","shell.execute_reply.started":"2021-11-02T09:31:31.796555Z","shell.execute_reply":"2021-11-02T09:31:31.802162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seeding","metadata":{}},{"cell_type":"code","source":"def set_seed(seed: int):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nset_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:33.059177Z","iopub.execute_input":"2021-11-02T09:31:33.059571Z","iopub.status.idle":"2021-11-02T09:31:33.071103Z","shell.execute_reply.started":"2021-11-02T09:31:33.059528Z","shell.execute_reply":"2021-11-02T09:31:33.070095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/ventilator-pressure-prediction/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/ventilator-pressure-prediction/test.csv\")\n\npressure_values = np.array(sorted(train_df[\"pressure\"].unique().tolist()))\n\nif DEBUG:\n    train_df = train_df[:80*10000]\n    test_df = test_df[:80*10000]\n\nsub = test_df[[\"id\"]]    \n    \npressure_values.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:35.188007Z","iopub.execute_input":"2021-11-02T09:31:35.188796Z","iopub.status.idle":"2021-11-02T09:31:42.166693Z","shell.execute_reply.started":"2021-11-02T09:31:35.188755Z","shell.execute_reply":"2021-11-02T09:31:42.165898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"code","source":"def generate_shift(df, columns, windows):\n    for col in columns:\n        for window in windows:    \n            df[col + '_shift_pos_' + str(window)] = df.groupby('breath_id')[col].shift(window)\n            df[col + '_shift_neg_' + str(window)] = df.groupby('breath_id')[col].shift(-1 * window)\n            df[col + '_shift_diff_pos_' + str(window)] = df[col] - df[col + '_shift_pos_' + str(window)]\n            df[col + '_shift_diff_neg_' + str(window)] = df[col] - df[col + '_shift_neg_' + str(window)]\n            df.fillna(0, inplace=True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:42.168692Z","iopub.execute_input":"2021-11-02T09:31:42.16899Z","iopub.status.idle":"2021-11-02T09:31:42.177995Z","shell.execute_reply.started":"2021-11-02T09:31:42.168952Z","shell.execute_reply":"2021-11-02T09:31:42.17715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_rolling(df, columns, windows):\n    for col in columns:\n        for window in windows:    \n            df[col + '_rolling_mean_' + str(window)] = df.groupby('breath_id')[col].rolling(window).mean().reset_index(drop=True)\n            df[col + '_rolling_min_' + str(window)] = df.groupby('breath_id')[col].rolling(window).min().reset_index(drop=True)\n            df[col + '_rolling_max_' + str(window)] = df.groupby('breath_id')[col].rolling(window).max().reset_index(drop=True)\n            df[col + '_rolling_std_' + str(window)] = df.groupby('breath_id')[col].rolling(window).std().reset_index(drop=True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:42.179098Z","iopub.execute_input":"2021-11-02T09:31:42.179831Z","iopub.status.idle":"2021-11-02T09:31:42.189807Z","shell.execute_reply.started":"2021-11-02T09:31:42.179769Z","shell.execute_reply":"2021-11-02T09:31:42.188822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    cols = ['u_in']\n    windows = [1, 2, 4]\n    df = generate_shift(df, cols, windows)\n    print(\"Step-2...Completed\")\n    \n    windows = [8, 16]\n    df = generate_shift(df, cols, windows)\n    print(\"Step-3...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] = df['u_in_cumsum'] /df['count']\n    df.drop(['one', 'count'], axis=1, inplace=True)\n    \n    df['breath_id_lag'] = df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2'] = df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame'] = np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same'] = np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    df.drop(['breath_id_lag', 'breath_id_lag2', 'breath_id_lagsame', 'breath_id_lag2same'], axis=1, inplace=True)\n    print(\"Step-5...Completed\")\n\n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    print(\"Step-6...Completed\")\n        \n    df['time_gap'] = df['time_step'] - df.shift(1).fillna(0)['time_step']\n    df['u_in_rate'] = df['u_in_shift_pos_1'] / df['time_gap']\n\n    df.loc[list(range(0, len(df), 80)), 'time_gap'] = 0\n    df.loc[list(range(0, len(df), 80)), 'u_in_rate'] = 0\n    \n    df['area_1'] = df['u_in'] * df['time_gap']\n    df['area_cumsum_1'] = (df['area_1']).groupby(df['breath_id']).cumsum()\n    \n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    \n    print(\"Step-7...Completed\")\n    \n    df['u_in_2'] = df['u_in'] ** 2\n    df['u_in_3'] = df['u_in'] ** 3\n    df['R_2'] = df['R'] ** 2\n    df['C_2'] = df['C'] ** 2\n\n    df['R_2__mul__u_in_2'] = df['R_2'] * df['u_in_2']\n    df['C_2__div__R_2'] = df['C_2'] / df['R_2']\n    df['R__mul__u_in_2'] = df['R'] * df['u_in_2']\n    df['C__div__u_in_2'] = df['C'] / df['u_in_2']\n    df['C_2__div__u_in_2'] = df['C_2'] / df['u_in_2']\n    df['R_2__div__u_in_2'] = df['R_2'] / df['u_in_2']\n    \n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df = df.fillna(0)\n    df = pd.get_dummies(df)\n    print(\"Step-8...Completed\")\n\n    gc.collect()\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:42.193129Z","iopub.execute_input":"2021-11-02T09:31:42.19513Z","iopub.status.idle":"2021-11-02T09:31:42.219634Z","shell.execute_reply.started":"2021-11-02T09:31:42.195093Z","shell.execute_reply":"2021-11-02T09:31:42.218925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npreprocessed_train_df = add_features(train_df)\ndel train_df\ngc.collect()\n\npreprocessed_test_df = add_features(test_df)\ndel test_df\ngc.collect()\n\npreprocessed_train_df.shape, preprocessed_test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:31:42.221141Z","iopub.execute_input":"2021-11-02T09:31:42.221408Z","iopub.status.idle":"2021-11-02T09:34:50.674379Z","shell.execute_reply.started":"2021-11-02T09:31:42.221377Z","shell.execute_reply":"2021-11-02T09:34:50.673616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"u_out_0 = preprocessed_train_df['u_out'].to_numpy().reshape(-1, 80)\ntest_indices = preprocessed_test_df.index","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:34:50.676315Z","iopub.execute_input":"2021-11-02T09:34:50.676785Z","iopub.status.idle":"2021-11-02T09:34:50.683781Z","shell.execute_reply.started":"2021-11-02T09:34:50.676745Z","shell.execute_reply":"2021-11-02T09:34:50.682966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = preprocessed_train_df[['pressure']].to_numpy().reshape(-1, 80)\n\nto_drop = ['id', 'breath_id']\ntrain = preprocessed_train_df.drop(['pressure'] + to_drop, axis=1)\ntest = preprocessed_test_df.drop(to_drop, axis=1)\n\ndel preprocessed_train_df\ndel preprocessed_test_df\ngc.collect()\n\ntargets.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:34:50.686204Z","iopub.execute_input":"2021-11-02T09:34:50.686458Z","iopub.status.idle":"2021-11-02T09:34:56.027823Z","shell.execute_reply.started":"2021-11-02T09:34:50.686427Z","shell.execute_reply":"2021-11-02T09:34:56.027104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:35:08.615799Z","iopub.execute_input":"2021-11-02T09:35:08.616659Z","iopub.status.idle":"2021-11-02T09:35:08.628535Z","shell.execute_reply.started":"2021-11-02T09:35:08.616605Z","shell.execute_reply":"2021-11-02T09:35:08.627733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:35:09.460598Z","iopub.execute_input":"2021-11-02T09:35:09.461131Z","iopub.status.idle":"2021-11-02T09:35:45.632692Z","shell.execute_reply.started":"2021-11-02T09:35:09.461089Z","shell.execute_reply":"2021-11-02T09:35:45.631891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = RobustScaler(copy=False)\ntrain = scaler.fit_transform(train)\ntest = scaler.transform(test)\n\ndel scaler\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:35:45.634288Z","iopub.execute_input":"2021-11-02T09:35:45.635348Z","iopub.status.idle":"2021-11-02T09:35:55.75823Z","shell.execute_reply.started":"2021-11-02T09:35:45.635306Z","shell.execute_reply":"2021-11-02T09:35:55.757293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])\n\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:35:55.759512Z","iopub.execute_input":"2021-11-02T09:35:55.759866Z","iopub.status.idle":"2021-11-02T09:35:55.766777Z","shell.execute_reply.started":"2021-11-02T09:35:55.759828Z","shell.execute_reply":"2021-11-02T09:35:55.76605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def build_model(*metrics):\n\n    input_shape = train.shape[-2:]\n    x_input = Input(shape=input_shape)\n\n    x1 = Bidirectional(LSTM(units=512, return_sequences=True))(x_input)\n    x2 = Bidirectional(LSTM(units=256, return_sequences=True))(x1)\n    x3 = Bidirectional(LSTM(units=128, return_sequences=True))(x2)\n    x4 = Bidirectional(LSTM(units=64, return_sequences=True))(x3)\n    \n    z2 = Bidirectional(GRU(units=128, return_sequences=True))(x2)\n    \n    z31 = Multiply()([x3, z2])\n    z31 = BatchNormalization()(z31)\n    z3 = Bidirectional(GRU(units=64, return_sequences=True))(z31)\n    \n    z41 = Multiply()([x4, z3])\n    z41 = BatchNormalization()(z41)\n    z4 = Bidirectional(GRU(units=32, return_sequences=True))(z41)\n        \n    x = Concatenate(axis=2)([x4, z2, z3, z4])\n    \n    x = Dense(units=128, activation='selu')(x)\n\n    x_output = Dense(units=1)(x)\n    \n    model = Model(inputs=x_input, outputs=x_output)\n        \n    opt = Adam(learning_rate=1e-3)\n    \n    loss = MeanAbsoluteError()\n    model.compile(optimizer=opt, loss=loss, metrics=list(metrics))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:26:47.731113Z","iopub.execute_input":"2021-11-02T11:26:47.731579Z","iopub.status.idle":"2021-11-02T11:26:47.743728Z","shell.execute_reply.started":"2021-11-02T11:26:47.731541Z","shell.execute_reply":"2021-11-02T11:26:47.741712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nplot_model(model, to_file='ventilator_keras_model.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:26:48.279143Z","iopub.execute_input":"2021-11-02T11:26:48.27993Z","iopub.status.idle":"2021-11-02T11:26:52.508026Z","shell.execute_reply.started":"2021-11-02T11:26:48.27989Z","shell.execute_reply":"2021-11-02T11:26:52.507099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:26:52.510316Z","iopub.execute_input":"2021-11-02T11:26:52.510842Z","iopub.status.idle":"2021-11-02T11:26:54.261807Z","shell.execute_reply.started":"2021-11-02T11:26:52.5108Z","shell.execute_reply":"2021-11-02T11:26:54.261082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Discretization","metadata":{}},{"cell_type":"code","source":"diff = np.diff(pressure_values)\nstep = np.median(diff)\nstep","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:36:01.989394Z","iopub.execute_input":"2021-11-02T09:36:01.98966Z","iopub.status.idle":"2021-11-02T09:36:01.997104Z","shell.execute_reply.started":"2021-11-02T09:36:01.989627Z","shell.execute_reply":"2021-11-02T09:36:01.996272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXTRAPOLATE_KNOTS = 100\n\nleft_pressure_extrapolate = np.arange(pressure_values[0] - EXTRAPOLATE_KNOTS* step, pressure_values[0] - step, step)\nright_pressure_extrapolate = np.arange(pressure_values[-1] + step, pressure_values[-1] + EXTRAPOLATE_KNOTS* step, step)\n\npressure_values_extra = np.concatenate([left_pressure_extrapolate, pressure_values, right_pressure_extrapolate])\npressure_values_extra.shape\n\npressure_values_extra_mid_points = (pressure_values_extra[1:] + pressure_values_extra[:-1]) / 2\npressure_values_extra_mid_points.shape\n\ndel diff\ndel left_pressure_extrapolate\ndel right_pressure_extrapolate\ndel pressure_values\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:36:01.998378Z","iopub.execute_input":"2021-11-02T09:36:01.999248Z","iopub.status.idle":"2021-11-02T09:36:02.16691Z","shell.execute_reply.started":"2021-11-02T09:36:01.999209Z","shell.execute_reply":"2021-11-02T09:36:02.166227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretize_np(y_discr, y_midpoints, y_cont):\n    indices = np.searchsorted(y_midpoints, y_cont, side=\"left\")\n    result = y_discr[indices]\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:36:02.167992Z","iopub.execute_input":"2021-11-02T09:36:02.168283Z","iopub.status.idle":"2021-11-02T09:36:02.172774Z","shell.execute_reply.started":"2021-11-02T09:36:02.168246Z","shell.execute_reply":"2021-11-02T09:36:02.171844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Early Stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStoppingAtMinMAE(Callback):\n\n    def __init__(self, model, inputs, targets, indices, epochs, patience=0, fold=0):\n        super(EarlyStoppingAtMinMAE, self).__init__()\n\n        self.model = model\n        self.inputs = inputs\n        self.targets = targets\n        self.indices = indices\n        self.patience = patience\n        self.fold = fold\n\n        self.best_weights = None\n        self.last_epoch = epochs - 1\n\n    def on_train_begin(self, logs=None):\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.best = np.Inf\n\n    def on_epoch_end(self, epoch, logs=None):\n        pred = self.model.predict(self.inputs)\n        pred_flat = pred.ravel()\n        pred_flat_discrete = discretize_np(pressure_values_extra, pressure_values_extra_mid_points, pred_flat)\n\n        current_score = mean_absolute_error(self.targets[self.indices], pred_flat[self.indices])\n        current_score_discrete = mean_absolute_error(self.targets[self.indices], pred_flat_discrete[self.indices])\n#         current_score_all = mean_absolute_error(self.targets, pred_flat)\n#         current_score_all_discrete = mean_absolute_error(self.targets, pred_flat_discrete)\n        print(f'MAE score (discrete, u_out==0): {current_score_discrete:.6f}, MAE score (non-discrete, u_out==0): {current_score:.6f}\\n')\n#         print(f'MAE score (discrete, all indices): {current_score_all_discrete:.4f}, MAE score (non-discrete, all indices): {current_score_all:.4f}, \\n')\n\n        if np.less(current_score_discrete, self.best):\n            self.best = current_score_discrete\n            self.wait = 0\n            self.best_weights = self.model.get_weights()\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n                self.model.stop_training = True\n                print('Restoring model weights from the end of the best epoch.')\n                self.model.set_weights(self.best_weights)\n        if epoch == self.last_epoch:\n            self.model.set_weights(self.best_weights)\n            \n        del pred\n        del pred_flat\n        del pred_flat_discrete\n        gc.collect()\n\n    def on_train_end(self, logs=None):\n        if self.stopped_epoch > 0:\n            print(f'Epoch {self.stopped_epoch + 1}: early stopping. Best MAE: {self.best:.6f}')\n        self.model.save_weights(f\"{MODELS}/fold_{self.fold}.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:36:02.175464Z","iopub.execute_input":"2021-11-02T09:36:02.175753Z","iopub.status.idle":"2021-11-02T09:36:02.190963Z","shell.execute_reply.started":"2021-11-02T09:36:02.1757Z","shell.execute_reply":"2021-11-02T09:36:02.190105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"k_fold = KFold(n_splits=FOLD_NUM, shuffle=True, random_state=SEED)\n\noof_preds = []\noof_preds_discrete = []\noof_targets = []\n\ntest_preds = []\ntest_preds_discrete = []\nfor fold, (train_idx, val_idx) in enumerate(k_fold.split(train, targets)):\n    if fold not in FOLDS: continue\n    \n    K.clear_session()\n        \n    print(f\"FOLD={fold} started\")\n    \n    np.save(INDICES / f\"train_{fold}\", train_idx)\n    np.save(INDICES / f\"val_{fold}\", val_idx)\n\n    X_train, X_val = train[train_idx], train[val_idx]\n    y_train, y_val = targets[train_idx], targets[val_idx]\n    \n    u_out_0_val = u_out_0[val_idx]    \n    u_out_0_val_flat = u_out_0_val.ravel()\n    u_out_0_val_flat = list(map(bool, u_out_0_val_flat))\n    u_out_0_val_flat = ~np.array(u_out_0_val_flat)\n    \n    y_val_flat = y_val.ravel()\n\n    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.75, patience=10, verbose=1)\n    \n    with strategy.scope():\n        model = build_model()\n    \n#     es = EarlyStopping(monitor='val_loss',mode='min', patience=100, verbose=1, restore_best_weights=True)\n    es = EarlyStoppingAtMinMAE(model, X_val, y_val_flat, u_out_0_val_flat, EPOCHS, patience=75, fold=fold)\n    \n    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[es, lr])\n    \n    print(f\"FOLD={fold} started train prediction\")\n    train_pred = model.predict(X_train).ravel()\n    np.save(PREDS / f\"train_pred_fold_{fold}\", train_pred)\n    train_pred_discrete = discretize_np(pressure_values_extra, pressure_values_extra_mid_points, train_pred)\n    np.save(PREDS / f\"train_pred_fold_{fold}_discrete\", train_pred_discrete)\n    del train_pred\n    del train_pred_discrete\n    \n    print(f\"FOLD={fold} started validation prediction\")\n    val_pred = model.predict(X_val).ravel()\n    np.save(PREDS / f\"val_pred_fold_{fold}\", val_pred)\n    oof_preds.append(val_pred[u_out_0_val_flat].tolist())\n    val_pred_discrete = discretize_np(pressure_values_extra, pressure_values_extra_mid_points, val_pred)\n    np.save(PREDS / f\"val_pred_fold_{fold}_discrete\", val_pred_discrete)\n    oof_preds_discrete.append(val_pred_discrete[u_out_0_val_flat])\n    oof_targets.append(y_val_flat[u_out_0_val_flat])\n    val_mae = mean_absolute_error(y_val_flat[u_out_0_val_flat], val_pred[u_out_0_val_flat])\n    val_mae_discrete = mean_absolute_error(y_val_flat[u_out_0_val_flat], val_pred_discrete[u_out_0_val_flat])\n    print(f\"FOLD={fold} | MAE score (discrete, u_out==0): {val_mae_discrete:.6f},  MAE score (non-discrete, u_out==0): {val_mae:.6f}\")\n    del val_pred\n    del val_pred_discrete\n\n    print(f\"FOLD={fold} started test prediction\")\n    test_pred = model.predict(test).ravel()\n    np.save(PREDS / f\"test_pred_fold_{fold}\", test_pred)\n    test_preds.append(test_pred)\n    test_pred_discrete = discretize_np(pressure_values_extra, pressure_values_extra_mid_points, test_pred)\n    np.save(PREDS / f\"test_pred_fold_{fold}_discrete\", test_pred_discrete)\n    test_preds_discrete.append(test_pred_discrete)\n    del test_pred\n    del test_pred_discrete\n    \n    history_df = pd.DataFrame(history.history)\n    history_df.to_csv(HISTORY / f\"history_{fold}.csv\", index=False)\n    del history_df\n    \n    del X_train\n    del X_val\n    del y_train\n    del y_val\n    del u_out_0_val  \n    del u_out_0_val_flat\n    del y_val_flat\n    gc.collect()\n\n    print(f\"FOLD={fold} finished\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:28:46.046568Z","iopub.execute_input":"2021-11-02T11:28:46.046895Z","iopub.status.idle":"2021-11-02T11:33:12.163756Z","shell.execute_reply.started":"2021-11-02T11:28:46.046859Z","shell.execute_reply":"2021-11-02T11:33:12.162374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_preds = np.hstack(oof_preds)\noof_preds_discrete = np.hstack(oof_preds_discrete)\noof_targets = np.hstack(oof_targets)\n\noof_mae = mean_absolute_error(oof_targets, oof_preds)\noof_mae_discrete = mean_absolute_error(oof_targets, oof_preds_discrete)\nprint(f\"OOF | MAE score (discrete, u_out==0): {oof_mae_discrete:.6f},  MAE score (non-discrete, u_out==0): {oof_mae:.6f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['pressure'] = 0\n\n# ENSEMBLE FOLDS WITH MEAN\nsub.loc[test_indices, 'pressure'] = sum(test_preds) / len(test_preds)\nsub[[\"id\", \"pressure\"]].to_csv(\"submission_mean.csv\", index=False)\n\n# ENSEMBLE FOLDS WITH MEDIAN\nsub.loc[test_indices, 'pressure'] = np.median(np.vstack(test_preds),axis=0)\nsub[[\"id\", \"pressure\"]].to_csv(\"submission_median.csv\", index=False)\nsub[[\"id\", \"pressure\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ENSEMBLE FOLDS WITH MEAN\nsub.loc[test_indices, 'pressure'] = sum(test_preds_discrete) / len(test_preds_discrete)\nsub[[\"id\", \"pressure\"]].to_csv(\"submission_mean_discrete.csv\", index=False)\n\n# ENSEMBLE FOLDS WITH MEDIAN\nsub.loc[test_indices, 'pressure'] = np.median(np.vstack(test_preds_discrete),axis=0)\nsub[[\"id\", \"pressure\"]].to_csv(\"submission_median_discrete.csv\", index=False)\nsub[[\"id\", \"pressure\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}