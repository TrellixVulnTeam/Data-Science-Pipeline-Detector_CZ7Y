{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport copy\nimport glob\nimport random\nfrom random import random as rd\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-03T12:31:36.366521Z","iopub.execute_input":"2021-11-03T12:31:36.366921Z","iopub.status.idle":"2021-11-03T12:31:36.392261Z","shell.execute_reply.started":"2021-11-03T12:31:36.366826Z","shell.execute_reply":"2021-11-03T12:31:36.391641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference: \n* https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153 by Chris Deotte\n* https://www.kaggle.com/snnclsr/a-dummy-approach-to-improve-your-score-postprocess by Sinan Calisir\n* Public notebooks with score less than 0.158","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/ventilator-pressure-prediction/train.csv\")\nunique_pressures = df_train[\"pressure\"].unique()\nsorted_pressures = np.sort(unique_pressures)\ntotal_pressures_len = len(sorted_pressures)\n\ndef find_nearest(prediction):\n    insert_idx = np.searchsorted(sorted_pressures, prediction)\n    if insert_idx == total_pressures_len:\n        return sorted_pressures[-1]\n    elif insert_idx == 0:\n        return sorted_pressures[0]\n    lower_val = sorted_pressures[insert_idx - 1]\n    upper_val = sorted_pressures[insert_idx]\n    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val\n\ndef set_seed(seed = 2021):\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\ndef wc(input_list):\n    l = []\n    allow = [1336,1579]\n    for i in range(len(input_list)):\n        public_lb_score = int(input_list[i].split(\"/\")[-1].split(\".\")[1].split(\" \")[0]) \n#         public_lb_score = int(input_list[i].split(\"/\")[-1].split(\"_\")[1].split(\".\")[0])\n        if public_lb_score in allow:\n            print(public_lb_score)\n            l.append(public_lb_score)\n            input_list[i] = (pd.read_csv(input_list[i]).pressure).ravel()\n        else:\n            continue\n    output = 0\n    l_sum = sum(l)\n    if len(input_list) == 1:\n        output = input_list[0]\n    else:\n        weight1 = (l[1] / l_sum) + 0.1\n        weight2= 1 - weight1\n        output += input_list[0] * weight1 + input_list[1] * weight2\n    return output\n\ndef g(dp):\n# input: the dataset path of the prediction result files\n# file name format: public lb score or pulbic lb score + name, e.g., 0.335 LSTM baseline\n\n    # get all the files to blend\n    l = []\n    allow = [1336,1579]\n    for i in glob.iglob(f'{dp}/*'):\n        file_lb = int(i.split(\"/\")[-1].split(\".\")[1].split(\" \")[0])\n        if file_lb in allow:\n            l.append(i)\n        else:\n            continue\n    file_count = len(l)\n#     loop_time = 500 // file_count\n    loop_time = 125\n    # calculate the number of files in the input dataset\n    # and split them 2 by 2\n#     splits = file_count // 2\n    splits = 2\n    # sort the file based on their public lb score\n    l.sort()\n    flist = []\n    # create a file list\n    # append the 2 by 2 files as one element\n    # in the last loop, append all the files which are not necessarily 2 files\n    for i in range(splits):\n        if i == splits - 1:\n            flist.append(l[i * round(len(l) / splits): ])\n        else:\n            flist.append(l[i * round(len(l) / splits): (i + 1) * round(len(l) / splits)])\n    # transfrom each element in the file list into one blended prediction\n    for i in range(len(flist)):   \n        flist[i] = wc(flist[i])\n    pred_list = []\n    # loop a large number of times\n    # to converge the result into a stable expected value\n    for i in range(loop_time):      \n        weight = []        \n        set_seed(i)\n        # create a weight list with the same length as the file list\n        for i in range(len(flist)):\n            weight.append(rd())  \n        weight_sum = sum(weight)\n        # normalize the weights\n        for i in range(len(weight)):\n            weight[i] /= weight_sum\n        weight.sort(reverse = True)\n        temp = 0\n        # assign each weights to each blended prediction\n        for i in range(len(flist)):\n            temp += flist[i] * weight[i]\n        pred_list.append(temp)\n        del temp\n        gc.collect()\n    output = pd.read_csv(\"../input/ventilator-pressure-prediction/sample_submission.csv\")\n    output.pressure = np.median(np.vstack(pred_list), axis = 0)\n    output[\"pressure\"] = output[\"pressure\"].apply(find_nearest)\n    output.to_csv(f'rwb {loop_time} loops.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T12:31:38.271963Z","iopub.execute_input":"2021-11-03T12:31:38.272249Z","iopub.status.idle":"2021-11-03T12:31:47.643315Z","shell.execute_reply.started":"2021-11-03T12:31:38.272216Z","shell.execute_reply":"2021-11-03T12:31:47.642307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g('../input/ventilator-pressure-high-score-submissions')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T12:31:55.966049Z","iopub.execute_input":"2021-11-03T12:31:55.966339Z","iopub.status.idle":"2021-11-03T12:33:11.679933Z","shell.execute_reply.started":"2021-11-03T12:31:55.966311Z","shell.execute_reply":"2021-11-03T12:33:11.679176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:57:52.049701Z","iopub.execute_input":"2021-11-03T11:57:52.05005Z","iopub.status.idle":"2021-11-03T11:57:56.871096Z","shell.execute_reply.started":"2021-11-03T11:57:52.050021Z","shell.execute_reply":"2021-11-03T11:57:56.870386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testpreds = []\n# preds0 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds0.npy')\n# preds1 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds1.npy')\n# preds2 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds2.npy')\n# preds3 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds3.npy')\n# preds4 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds4.npy')\n# preds5 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds5.npy')\n# preds6 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds6.npy')\n# preds7 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds7.npy')\n# preds8 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds8.npy')\n# preds9 = np.load('../input/spectral-10folds-fastai-preds/train_10folds_preds9.npy')\n\n# testpreds.append(preds0)\n# testpreds.append(preds1)\n# testpreds.append(preds2)\n# testpreds.append(preds3)\n# testpreds.append(preds4)\n# testpreds.append(preds5)\n# testpreds.append(preds6)\n# testpreds.append(preds7)\n# testpreds.append(preds8)\n# testpreds.append(preds9)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:58:01.478079Z","iopub.execute_input":"2021-11-03T11:58:01.47837Z","iopub.status.idle":"2021-11-03T11:58:05.026955Z","shell.execute_reply.started":"2021-11-03T11:58:01.478342Z","shell.execute_reply":"2021-11-03T11:58:05.026149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds_fold = np.array(testpreds)\n# df_test['pressure'] = np.median(preds_fold, axis=0)\n# df_test[['id', 'pressure']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:58:07.876399Z","iopub.execute_input":"2021-11-03T11:58:07.876918Z","iopub.status.idle":"2021-11-03T11:58:21.03116Z","shell.execute_reply.started":"2021-11-03T11:58:07.876866Z","shell.execute_reply":"2021-11-03T11:58:21.03019Z"},"trusted":true},"execution_count":null,"outputs":[]}]}