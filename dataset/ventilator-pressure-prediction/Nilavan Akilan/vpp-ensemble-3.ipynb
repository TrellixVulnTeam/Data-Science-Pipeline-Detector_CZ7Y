{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transformer + Public submissions Ensemble\n## Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n\nVER = 84\nFIRST_FOLD_ONLY = True\nTRAIN_MODEL = False\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-17T02:45:51.748522Z","iopub.execute_input":"2021-11-17T02:45:51.748823Z","iopub.status.idle":"2021-11-17T02:45:57.207991Z","shell.execute_reply.started":"2021-11-17T02:45:51.748746Z","shell.execute_reply":"2021-11-17T02:45:57.207276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:45:57.210566Z","iopub.execute_input":"2021-11-17T02:45:57.210995Z","iopub.status.idle":"2021-11-17T02:46:10.980439Z","shell.execute_reply.started":"2021-11-17T02:45:57.210956Z","shell.execute_reply":"2021-11-17T02:46:10.979578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering\n\n> Reference: https://www.kaggle.com/dlaststark/gb-vpp-pulp-fiction","metadata":{}},{"cell_type":"code","source":"def add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    print(\"Step-2...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n\n    print(\"Step-3...Completed\")\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    print(\"Step-5...Completed\")\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n                                                              .groupby('breath_id')['u_in']\\\n                                                              .rolling(window=15,min_periods=1)\\\n                                                              .agg({\"15_in_sum\":\"sum\",\n                                                                    \"15_in_min\":\"min\",\n                                                                    \"15_in_max\":\"max\",\n                                                                    \"15_in_mean\":\"mean\"\n                                                                    #\"15_in_std\":\"std\"\n                                                               })\\\n                                                               .reset_index(level=0,drop=True))\n    print(\"Step-6...Completed\")\n        \n    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n    print(\"Step-7...Completed\")\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    print(\"Step-8...Completed\")\n    \n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:46:10.981967Z","iopub.execute_input":"2021-11-17T02:46:10.982246Z","iopub.status.idle":"2021-11-17T02:48:14.902174Z","shell.execute_reply.started":"2021-11-17T02:46:10.982191Z","shell.execute_reply":"2021-11-17T02:48:14.901392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train shape:', train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:14.904329Z","iopub.execute_input":"2021-11-17T02:48:14.904739Z","iopub.status.idle":"2021-11-17T02:48:14.93164Z","shell.execute_reply.started":"2021-11-17T02:48:14.9047Z","shell.execute_reply":"2021-11-17T02:48:14.930952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pressure_diff'] = train.groupby('breath_id').pressure.diff().fillna(0)\ntrain['pressure_integral'] = train.groupby('breath_id').pressure.cumsum()/200\ntargets = train[['pressure','pressure_diff','pressure_integral']].to_numpy().reshape(-1, 80, 3)\n\ntrain.drop(['pressure','pressure_diff','pressure_integral','id', 'breath_id','one','count',\n            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n            'breath_id_lag2same'], axis=1, inplace=True)\n\ntest.drop(['id', 'breath_id','one','count','breath_id_lag',\n            'breath_id_lag2','breath_id_lagsame',\n            'breath_id_lag2same'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:14.93284Z","iopub.execute_input":"2021-11-17T02:48:14.934374Z","iopub.status.idle":"2021-11-17T02:48:33.175631Z","shell.execute_reply.started":"2021-11-17T02:48:14.934333Z","shell.execute_reply":"2021-11-17T02:48:33.174805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COL_ORDER = list(train.columns[:3]) + list(train.columns[-15:]) + list(train.columns[3:-15])\ntrain = train[COL_ORDER]\ntest = test[COL_ORDER]\n\nprint('Train columns:')\nnp.array( COL_ORDER )","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:33.17711Z","iopub.execute_input":"2021-11-17T02:48:33.177405Z","iopub.status.idle":"2021-11-17T02:48:34.676751Z","shell.execute_reply.started":"2021-11-17T02:48:33.177367Z","shell.execute_reply":"2021-11-17T02:48:34.675996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalize features","metadata":{}},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train.astype('float32'))\ntest = RS.transform(test.astype('float32'))\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:34.678079Z","iopub.execute_input":"2021-11-17T02:48:34.678838Z","iopub.status.idle":"2021-11-17T02:48:45.871485Z","shell.execute_reply.started":"2021-11-17T02:48:34.678797Z","shell.execute_reply":"2021-11-17T02:48:45.870699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"U_OUT_IDX = 2\ny_weight = np.ones_like( targets )\nu_out_values = train[:,:,U_OUT_IDX]\ny_weight[ u_out_values==0 ] = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:45.872695Z","iopub.execute_input":"2021-11-17T02:48:45.872972Z","iopub.status.idle":"2021-11-17T02:48:45.982448Z","shell.execute_reply.started":"2021-11-17T02:48:45.872934Z","shell.execute_reply":"2021-11-17T02:48:45.981718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup GPU","metadata":{}},{"cell_type":"code","source":"# USE MULTIPLE GPUS\nif os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n    gpu_strategy = tf.distribute.get_strategy()\n    print('single strategy')\nelse:\n    gpu_strategy = tf.distribute.MirroredStrategy()\n    print('multiple strategy')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:45.983605Z","iopub.execute_input":"2021-11-17T02:48:45.983916Z","iopub.status.idle":"2021-11-17T02:48:46.004436Z","shell.execute_reply.started":"2021-11-17T02:48:45.983873Z","shell.execute_reply":"2021-11-17T02:48:46.003768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:46.007196Z","iopub.execute_input":"2021-11-17T02:48:46.007461Z","iopub.status.idle":"2021-11-17T02:48:46.014058Z","shell.execute_reply.started":"2021-11-17T02:48:46.007421Z","shell.execute_reply":"2021-11-17T02:48:46.013295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformer model","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"gelu\"), layers.Dense(feat_dim),]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:46.015476Z","iopub.execute_input":"2021-11-17T02:48:46.015816Z","iopub.status.idle":"2021-11-17T02:48:46.026153Z","shell.execute_reply.started":"2021-11-17T02:48:46.015733Z","shell.execute_reply":"2021-11-17T02:48:46.02523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_dim = train.shape[-1] + 32\nembed_dim = 64 \nnum_heads = 8 \nff_dim = 128  \ndropout_rate = 0.0\nnum_blocks = 12\n\ndef build_model():\n    inputs = layers.Input(shape=train.shape[-2:])\n    x = layers.Dense(feat_dim)(inputs)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    for k in range(num_blocks):\n        x_old = x\n        transformer_block = TransformerBlock(embed_dim, feat_dim, num_heads, ff_dim, dropout_rate)\n        x = transformer_block(x)\n        x = 0.7*x + 0.3*x_old\n    x = layers.Dense(128, activation=\"selu\")(x)\n    x = layers.Dropout(dropout_rate)(x)\n    outputs = layers.Dense(3, activation=\"linear\")(x)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:46.027613Z","iopub.execute_input":"2021-11-17T02:48:46.02842Z","iopub.status.idle":"2021-11-17T02:48:46.038839Z","shell.execute_reply.started":"2021-11-17T02:48:46.028385Z","shell.execute_reply":"2021-11-17T02:48:46.038062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Learning rate schedule","metadata":{}},{"cell_type":"code","source":"import math \nimport matplotlib.pyplot as plt\n\nLR_START = 1e-6\nLR_MAX = 6e-4\nLR_MIN = 1e-6\nLR_RAMPUP_EPOCHS = 0\nLR_SUSTAIN_EPOCHS = 0\nEPOCHS = 420\nSTEPS = [60,120,240]\n\n\ndef lrfn(epoch):\n    if epoch<STEPS[0]:\n        epoch2 = epoch\n        EPOCHS2 = STEPS[0]\n    elif epoch<STEPS[0]+STEPS[1]:\n        epoch2 = epoch-STEPS[0]\n        EPOCHS2 = STEPS[1]\n    elif epoch<STEPS[0]+STEPS[1]+STEPS[2]:\n        epoch2 = epoch-STEPS[0]-STEPS[1]\n        EPOCHS2 = STEPS[2]\n    \n    if epoch2 < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch2 + LR_START\n    elif epoch2 < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        decay_total_epochs = EPOCHS2 - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n        decay_epoch_index = epoch2 - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        phase = math.pi * decay_epoch_index / decay_total_epochs\n        cosine_decay = 0.5 * (1 + math.cos(phase))\n        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n    return lr\n\nrng = [i for i in range(EPOCHS)]\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, lr_y, '-o')\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\". \\\n          format(lr_y[0], max(lr_y), lr_y[-1]))\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\nplt.xlabel('Epoch',size=14)\nplt.ylabel('Learning Rate',size=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:46.040109Z","iopub.execute_input":"2021-11-17T02:48:46.040589Z","iopub.status.idle":"2021-11-17T02:48:46.270717Z","shell.execute_reply.started":"2021-11-17T02:48:46.040555Z","shell.execute_reply":"2021-11-17T02:48:46.270053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"EPOCH = EPOCHS\nBATCH_SIZE = 64\nNUM_FOLDS = 11\nSEED = 42\nVERBOSE = 1\n\nwith gpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n    \n    test_preds = []\n    oof_preds = []\n    oof_true = []\n    all_mask = []\n    test_folds = []\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        test_folds.append(test_idx)\n                \n        checkpoint_filepath = f\"folds{fold}_{VER}.hdf5\"\n\n        model = build_model()\n        opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n        model.compile(optimizer=opt, loss=\"mae\", sample_weight_mode=\"temporal\")\n\n        sv = keras.callbacks.ModelCheckpoint(\n                checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n                save_weights_only=True, mode='auto', save_freq='epoch',\n                options=None\n        )\n        if TRAIN_MODEL:\n            history = model.fit(X_train, y_train, verbose=VERBOSE,\n                                validation_data=(X_valid, y_valid, y_weight[test_idx,:,:1]), \n                                epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr_callback, sv], \n                                sample_weight=y_weight[train_idx,:,:1])\n        else:\n            model.load_weights(f'../input/vent-tranformer/folds{fold}_{VER}.hdf5')\n       \n        # PREDICT TEST\n        print('Predicting Test...')\n        test_preds.append(model.predict(test, batch_size=BATCH_SIZE, verbose=VERBOSE)[:,:,0]\\\n                          .squeeze().reshape(-1, 1).squeeze())\n        \n        # PREDICT OOF\n        print('Predicting OOF...')\n        oof_preds.append( model.predict(X_valid, verbose=VERBOSE)[:,:,0].squeeze().reshape(-1, 1) )\n        oof_true.append( y_valid[:,:,0].squeeze().reshape(-1, 1) )\n        score = mean_absolute_error(oof_true[-1], oof_preds[-1])\n        print(f\"Fold-{fold+1} | OOF all u_out Score: {score}\")\n        \n        mask = np.where( X_valid[:,:,2].reshape((-1,1))==-1 )[0]\n        mask_score = mean_absolute_error(oof_true[-1][mask], oof_preds[-1][mask])\n        print(f\"Fold-{fold+1} | OOF u_out=0 Score: {mask_score}\")\n        all_mask.append(mask)\n        \n        np.save(f'oof_v{VER}_trans',oof_preds)\n        #np.save(f'oof_true_v{VER}_trans',oof_true)\n        \n        if FIRST_FOLD_ONLY: break","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:48:46.272014Z","iopub.execute_input":"2021-11-17T02:48:46.272285Z","iopub.status.idle":"2021-11-17T02:49:46.771743Z","shell.execute_reply.started":"2021-11-17T02:48:46.27225Z","shell.execute_reply":"2021-11-17T02:49:46.770924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV Score after post process rounding","metadata":{}},{"cell_type":"code","source":"if FIRST_FOLD_ONLY: \n    NUM_FOLDS=1\n    \nt = 0\nfor k in range(NUM_FOLDS):\n    oof = oof_preds[k].copy()\n    oof2 = np.round( (oof+1.895744294564641)/0.07030214545121005 ) * 0.07030214545121005 -1.895744294564641\n    mae = np.mean(np.abs( oof2.flatten()[mask] - oof_true[k].reshape(-1, 1).squeeze()[mask] ))\n    t += mae\n    print('Fold',k,'has u_out MAE with PP =',mae)\nprint('Overall CV MAE with PP =',t/NUM_FOLDS)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:49:46.773008Z","iopub.execute_input":"2021-11-17T02:49:46.773323Z","iopub.status.idle":"2021-11-17T02:49:46.790532Z","shell.execute_reply.started":"2021-11-17T02:49:46.773283Z","shell.execute_reply":"2021-11-17T02:49:46.789498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\nsub_1 = pd.read_csv('../input/ventilator-public-submissions/1336_submission.csv')\nsub_2 = pd.read_csv('../input/ventilator-public-submissions/1348_submission.csv')\nsub_3 = pd.read_csv('../input/gb-vpp-pulp-fiction2/median_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:50:44.732118Z","iopub.execute_input":"2021-11-17T02:50:44.73268Z","iopub.status.idle":"2021-11-17T02:50:55.579549Z","shell.execute_reply.started":"2021-11-17T02:50:44.73264Z","shell.execute_reply":"2021-11-17T02:50:55.578729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.array([np.array(sub_1['pressure'].values), np.array(sub_2['pressure'].values), np.array(sub_3['pressure'].values), np.array(submission['pressure'].values)])\npred","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:50:56.027858Z","iopub.execute_input":"2021-11-17T02:50:56.028674Z","iopub.status.idle":"2021-11-17T02:50:56.104347Z","shell.execute_reply.started":"2021-11-17T02:50:56.028631Z","shell.execute_reply":"2021-11-17T02:50:56.103521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_pressures = train[\"pressure\"].unique()\nsorted_pressures = np.sort(unique_pressures)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:51:00.958028Z","iopub.execute_input":"2021-11-17T02:51:00.958737Z","iopub.status.idle":"2021-11-17T02:51:01.022155Z","shell.execute_reply.started":"2021-11-17T02:51:00.958688Z","shell.execute_reply":"2021-11-17T02:51:01.021451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_pressures_len = len(sorted_pressures)\n\ndef find_nearest(prediction):\n    insert_idx = np.searchsorted(sorted_pressures, prediction)\n    if insert_idx == total_pressures_len:\n        return sorted_pressures[-1]\n    elif insert_idx == 0:\n        return sorted_pressures[0]\n    lower_val = sorted_pressures[insert_idx - 1]\n    upper_val = sorted_pressures[insert_idx]\n    return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val\n\ndef better_than_median(inputs, axis):\n    spread = inputs.max(axis=axis) - inputs.min(axis=axis) \n    spread_lim = 0.45\n    print(f\"Inliers:  {(spread < spread_lim).sum():7} -> compute mean\")\n    print(f\"Outliers: {(spread >= spread_lim).sum():7} -> compute median\")\n    return np.where(spread < spread_lim,\n                    np.mean(inputs, axis=axis),\n                    np.median(inputs, axis=axis))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:52:25.658484Z","iopub.execute_input":"2021-11-17T02:52:25.659032Z","iopub.status.idle":"2021-11-17T02:52:25.666658Z","shell.execute_reply.started":"2021-11-17T02:52:25.658991Z","shell.execute_reply":"2021-11-17T02:52:25.665896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"pressure\"] = better_than_median(pred, axis=0)\nsubmission[\"pressure\"] = submission[\"pressure\"].apply(find_nearest)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:52:29.3451Z","iopub.execute_input":"2021-11-17T02:52:29.345683Z","iopub.status.idle":"2021-11-17T02:53:10.653877Z","shell.execute_reply.started":"2021-11-17T02:52:29.34564Z","shell.execute_reply":"2021-11-17T02:53:10.653165Z"},"trusted":true},"execution_count":null,"outputs":[]}]}