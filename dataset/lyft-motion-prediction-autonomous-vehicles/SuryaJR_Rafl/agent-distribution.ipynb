{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n\n#l5kit imports  \nfrom l5kit.data import ChunkedDataset, LocalDataManager\nfrom l5kit.dataset import EgoDataset, AgentDataset\nfrom l5kit.rasterization import build_rasterizer\nfrom l5kit.configs import load_config_data\nfrom l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\nfrom l5kit.geometry import transform_points\nfrom l5kit.data import PERCEPTION_LABELS\nimport os\n\nimport torch\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = {\n    'format_version': 4,\n    'data_path': \"../input/lyft-motion-prediction-autonomous-vehicles/\",\n    'model_params': {\n        'model_architecture': 'resnet18',\n        'history_num_frames': 10,\n        'history_step_size': 1,\n        'history_delta_time': 0.1,\n        'future_num_frames': 50,\n        'future_step_size': 1,\n        'future_delta_time': 0.1,\n    },\n\n    'raster_params': {\n        'raster_size': [224, 224],\n        'pixel_size': [0.5, 0.5],\n        'ego_center': [0.25, 0.5],\n        'map_type': 'py_semantic',\n        'satellite_map_key': 'aerial_map/aerial_map.png',\n        'semantic_map_key': 'semantic_map/semantic_map.pb',\n        'dataset_meta_key': 'meta.json',\n        'filter_agents_threshold': 0.5\n    },\n\n    'sample_data_loader': {\n        'key': 'scenes/sample.zarr',\n        'batch_size': 16,\n        'shuffle': False,\n        'num_workers': 4\n    },\n    'train_data_loader': {\n        'key': 'scenes/train.zarr',\n        'batch_size': 16,\n        'shuffle': True,\n        'num_workers': 4\n    },\n    \n    'val_data_loader': {\n        'key': 'scenes/validate.zarr',\n        'batch_size': 16,\n        'shuffle': False,\n        'num_workers': 4\n    },\n    \n    'test_data_loader': {\n        'key': 'scenes/test.zarr',\n        'batch_size': 32,\n        'shuffle': False,\n        'num_workers': 4\n    },\n\n    'train_params': {\n        'max_num_steps': 12000,\n        'checkpoint_every_n_steps': 500,\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading CUDA device"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f'device {device}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = cfg[\"data_path\"]\nos.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\ndm = LocalDataManager(None)\nrasterizer = build_rasterizer(cfg, dm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nThe agents['label_probabilities'] cannot be loaded entirely into kaggle memory\nHence dividing the dataset into batches and summing up at the end\n\nUsing GPU to run argmax improves runtime massively\n\"\"\"\n\ndef count_Agentlabels_zarr(data_loader_key):\n    dataset_path = dm.require(cfg[data_loader_key][\"key\"])\n    zarr_dataset = ChunkedDataset(dataset_path).open()\n    \n    # get agents from dataset\n    agents = zarr_dataset.agents\n    no_batches = 8\n    batch_len = round(len(agents) / no_batches )\n    total_count = []\n\n    for i in range(no_batches):\n        probabilities = torch.from_numpy(agents[i * batch_len : (i+1) * batch_len][\"label_probabilities\"]).to(device)\n        labels_indexes = torch.argmax(probabilities, dim=1)\n\n        counts = []\n        for idx_label, label in enumerate(PERCEPTION_LABELS):\n            counts.append(torch.sum(labels_indexes == idx_label))\n        counts = [x.cpu().numpy().item() for x in counts]\n        print(f'{i} batch result = {counts}')\n        total_count.append(counts)\n        del(probabilities)\n\n    agent_count =  np.sum(total_count, axis = 0).tolist()\n    print(f'Agents distribution for {data_loader_key} is ', agent_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\"\"\" Uncomment following lines to run the code \"\"\"\n#train_counts = count_Agentlabels_zarr(\"train_data_loader\")\n#val_counts = count_Agentlabels_zarr(\"val_data_loader\")\n#test_counts = count_Agentlabels_zarr(\"test_data_loader\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results for Agent distribution in differnt datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_counts = [0, 214185074, 0, 96737892, 0, 0, 0, 0, 0, 0, 0, 0, 1667331, 0, 7534327, 0, 0]\nval_counts   = [0, 209417891, 0, 94918785, 0, 0, 0, 0, 0, 0, 0, 0, 1574639, 0, 6706572, 0, 0]\ntest_counts  = [0, 58143776, 0, 27888998, 0, 0, 0, 0, 0, 0, 0, 0, 486857, 0, 2075290, 0, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"LABELS\" : PERCEPTION_LABELS, \n                   \"train_counts\" : train_counts, \n                   \"val_counts\" : val_counts,\n                   \"test_counts\" : test_counts\n                  })\n\ndf = df.set_index('LABELS')\n\n# selecting only necessary rows\ndf = df[(df.T != 0).any()]\ndf = df.drop('PERCEPTION_LABEL_UNKNOWN')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalising to percentages\nfor dataset in ['train_counts', 'val_counts', 'test_counts']:\n    df[dataset] = df[dataset] / df[dataset].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\n> ### 1. Distribution of different agents is equal for all the three datasets, which is very crucial for consistent results across training, validation and test sets. \n  \n> ### 2. Percentages of Pedestrian is around 7%, so increasing the pixel resolution might have will most likely have impact in max 7% increase (decisive for top kagglers, less for entry-level people). So, decision on pixel resolution can be decided based on tradeoff between resource and performance objective\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}