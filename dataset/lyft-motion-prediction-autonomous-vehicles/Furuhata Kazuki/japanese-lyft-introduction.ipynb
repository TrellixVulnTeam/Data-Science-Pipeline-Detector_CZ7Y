{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What's this\n- このNotebookは本コンペのルールの翻訳など、参加する前に読んでおくと良さそうなことをまとめていきます\n- 誤訳・誤解などが発生する可能性もありますので、予めご了承ください"},{"metadata":{},"cell_type":"markdown","source":"# 基本的なルール\n参加者1人につき1アカウント\n- 複数のアカウントからKaggleにサインアップすることはできませんので、複数のアカウントから投稿することはできません。\n\nチーム外でのプライベート共有はできません。\n- チーム外でコードやデータを個人的に共有することは禁止されています。\n- フォーラムで参加者全員が利用できるようにしておけば、コードを共有しても問題ありません。\n\nチームの合併\n- チームの合併は認められており、チームリーダーが行うことができます。\n- 合併するためには、結合されたチームの総投稿数が合併期限の時点で認められている最大投稿数以下でなければなりません。\n- 認められている上限は、1日あたりの提出数に大会開催日数を乗じたものです。\n\nチームの制限\n- チームサイズは最大5名までとさせていただきます。\n\n提出制限\n- 1日5作品まで応募できます。\n- 審査のために最終的な応募作品を2点まで選ぶことができます。\n\nコンテストタイムライン\n- 開始日 2020年8月24日\n- 合併期限 2020年11月18日まで\n- エントリー締め切り 2020年11月18日まで\n- 終了日（最終提出期限） 2020年11月25日 11:59 PM UTC\n\nコンテストタイトル：Lyft Level 5 - 自動運転車の動作予測\n\nコンテストスポンサー：Lyft, Inc.\n\nコンテストスポンサー住所：185 ベリーストリート、スイート5000、サンフランシスコCA 94107\n\nコンテストウェブサイト: https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles\n\n取得可能な賞品の合計: $30,000 USD\n\n- 第1位：$12,000\n\n- 第2位：$8,000\n\n- 第3位：$6,000\n\n- 第4位：$4,000\n\n主催者の判断により、主催者は、受賞チームの中から優秀なパフォーマーを招いて、ライブストリーミングによるウェビナーで発表してもらうことがあります"},{"metadata":{},"cell_type":"markdown","source":"# 本コンペの意義\n自律走行車（AV）は、交通機関の未来を劇的に再定義することが期待されています。しかし、自律走行車のメリットを完全に実現するためには、解決しなければならない重要な工学的課題が残っています。そのような課題の1つは、AVの周囲にいる自動車、自転車、歩行者などの交通エージェントの動きを確実に予測するモデルを構築することです。\n\nライドシェアリング企業のLyftは、この自動運転に挑戦し、完全な自動運転システムを構築するために、レベル5を開始しました（彼らは採用しています！）。彼らの以前のコンペでは、参加者に3Dオブジェクトを識別することを課題としていましたが、これは動きを検知する前の重要なステップでした。今回は、交通エージェントの動きを予測することに挑戦しています。\n\nこのコンテストでは、データサイエンスのスキルを応用して、自動運転車の動き予測モデルを構築します。あなたのモデルを訓練しテストするために、これまでにリリースされた最大の予測データセットにアクセスすることができます。あなたの機械学習の知識は、その後、車、自転車、歩行者がAVの環境でどのように動くかを予測するために必要とされます。\n\nLyftの使命は、世界最高の交通手段で人々の生活を改善することです。彼らは、自律走行車が交通機関をより安全で、環境に優しく、誰もがより利用しやすいものにする未来を信じています。彼らの目標は、研究者とデータを共有することで、業界全体の開発を加速させることです。あなたの参加の結果、業界を前進させ、世界中の人々がより早く自律走行車の恩恵を受けられるようにするために、あなたの手を貸すことができます。"},{"metadata":{},"cell_type":"markdown","source":"# データについて\nLyftの自律走行車の動き予測コンテストは、データ的にはかなりユニークなものです。このコンテストでは、非常に大量のデータが提供され、様々な方法で使用することができます。データを読み取るのも複雑です - LyftのL5Kitモジュールとサンプルノートブックを参照して、データを適切にロードしてトレーニングに使用してください。Kaggleに特化したサンプルノートブックについては、近日中にご紹介します。\n\nまた、このコンテストでは、投稿はカーネルから行う必要があり、投稿カーネルではインターネットをオフにしておく必要があります。便利なように、Lyft の l5kit モジュールは kaggle_l5kit というユーティリティスクリプトで提供されています。これをカーネルにアタッチするだけで、最新バージョンのl5kitとすべての依存関係が利用できるようになります。\n\n## どのようなファイルが必要ですか？\ntrain.zarrとtest.zarrだけで十分です。他のファイルはオプションですが、おそらく役に立つでしょう。データセットをロードして反復処理する方法については、サンプルノートブックを参照してください。\n\n## データフォーマットはどのようなものを期待すればいいのでしょうか？\n注: 詳細は L5Kit のデータフォーマットのページを参照してください。\n\nデータは .zarr ファイルにパッケージ化されています。これらは zarr Python モジュールを使用してロードされ、l5kit によってネイティブにロードされます。各 .zarr ファイルには、以下のセットが含まれています。\n\n- scenes: 指定された車両から取得した走行エピソード。\n- frames: 車両のポーズの時間内のスナップショット。\n- agents： 車両のセンサーによってキャプチャされた一般的なエンティティ。このデータセットでは、17個のエージェントlabel_probabilitiesのうち4個しか存在しないことに注意してください。\n- agents_mask: (訓練と検証のために)訓練に有用でないオブジェクトをマスクするマスク。テストでは、このマスク(mask.npzとしてファイルで提供される)は、予測が必要でないテストオブジェクトをマスクアウトします。\n- traffic_light_faces: 信号機の情報。\n\n## 何を予測しているのか？\n与えられたシーン内のオブジェクトの動きを予測しています。テストのために、周りに移動するオブジェクトの99フレームを使用でき、次の50フレームで自分の場所を予測するように求められます。\n\n## ファイル\n- aerial_map - モード \"py_satellite \"でラスタライズを行う際に利用される空中マップ．\n- semantic_map - モード \"py_semantic \"でラスタライズを行う際に使用される高定義のセマンティックマップです。\n- sample.zarr - 探索用に設計された小さなサンプルセット\n- train.zarr - .zarr形式のトレーニングセット．\n- validate.zarr - 検証セット（訓練のサイズに近いもの）．\n- test.csv - .zarr形式のテストセット．\n- mask.npz - テストセット用のブール値のマスクです。マスクに含まれるすべてのエージェントのみが提出されなければなりません。\n- *sample_submission.csv - 2つのサンプル送信、1つはマルチモードフォーマット、もう1つはシングルモードです。\n\n## 追加ファイル\ntrain_full.csv - 完全なトレーニングセット。別のデータセットに格納されており、Kaggleではここに、Lyftではここにホストされています（登録が必要です）。"},{"metadata":{},"cell_type":"markdown","source":"# コード規則\nこれはコードコンペティションです。\n本大会への投稿は、必ずノートから行ってください。本大会では、Notebooksでのトレーニングは必要ありませんのでご注意ください。\n\nコミット後に「大会への投稿」ボタンがアクティブになるためには、以下の条件を満たす必要があります。\n\n- CPUノートブック <= ランタイム 9 時間\n- GPUノートブック <= ランタイム 9 時間\n- TPUは本大会のトレーニングのみで使用可能となります。\n- TPUノートブック <= ランタイム 3 [](http://)時間\n- 事前に訓練されたモデルを含む、自由に利用可能な外部データの公開が許可されています。\n- 提出ファイルの名前は submission.csv である必要があります。\n\n応募方法については、[コードコンペティションFAQ](https://www.kaggle.com/docs/competitions#kernels-only-FAQ)をご覧ください。"},{"metadata":{},"cell_type":"markdown","source":"# 提出ファイル\n注意: L5Kitを使用している場合、予測（シングルおよびマルチモーダル）を有効なCSVに直接変換する機能を提供しています。\n\n各エージェントはそのtrack_idとタイムスタンプで識別されます。各軌跡は50個の2次元(X,Y)予測値を保持しています。<br>\nテストセット内の各エージェントに対して、最大3つの軌跡を予測することができます。<br>\nフォーマットはCSVファイルなので、予測がシングルモーダルであっても、3つの軌跡フィールドはすべて値を持っていなければなりません。<br>\nしかし、3つの軌跡のそれぞれにはそれ自身の信頼度があり、評価中に1つ以上の軌跡を完全に無視するために0に設定することができます。<br>\n3つの信頼度の合計は1でなければなりません。\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}