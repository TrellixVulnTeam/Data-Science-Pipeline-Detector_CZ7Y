{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports #"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parsing TFRecords #"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_descriptions = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'target_positions': tf.io.FixedLenFeature([], tf.string),\n    'target_yaws': tf.io.FixedLenFeature([], tf.string),\n    'target_availabilities': tf.io.FixedLenFeature([], tf.string),\n    'history_positions': tf.io.FixedLenFeature([], tf.string),\n    'history_yaws': tf.io.FixedLenFeature([], tf.string),\n    'history_availabilities': tf.io.FixedLenFeature([], tf.string),\n    'world_to_image': tf.io.FixedLenFeature([], tf.string),\n    'track_id': tf.io.FixedLenFeature([], tf.string),\n    'timestamp': tf.io.FixedLenFeature([], tf.string),\n    'centroid': tf.io.FixedLenFeature([], tf.string),\n    'yaw': tf.io.FixedLenFeature([], tf.string),\n    'extent': tf.io.FixedLenFeature([], tf.string),\n}\n\nfeature_dtypes = {\n    'image': tf.float32,\n    'target_positions': tf.float32,\n    'target_yaws': tf.float32,\n    'target_availabilities': tf.float32,\n    'history_positions': tf.float32,\n    'history_yaws': tf.float32,\n    'history_availabilities': tf.float32,\n    'world_to_image': tf.float64,\n    'track_id': tf.int64,\n    'timestamp': tf.int64,\n    'centroid': tf.float64,\n    'yaw': tf.float64,\n    'extent': tf.float32,\n}\n\ndef make_decoder(descriptions, dtypes):\n    def decode_example(example):\n        example_1 = tf.io.parse_single_example(example, descriptions)\n        example_2 = []\n        for key in dtypes.keys():\n            example_2.append(\n                tf.io.parse_tensor(example_1[key], dtypes[key])\n            )\n        return example_2\n    return decode_example\n\ndecoder = make_decoder(feature_descriptions, feature_dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pipeline #"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = Path('../input/lyft-motion-prediction-tfrecords')\n\ntrain_files = tf.io.gfile.glob(str(DATA_DIR / 'training' / 'training' / '*.tfrecord'))\nvalid_files = tf.io.gfile.glob(str(DATA_DIR / 'validation' / 'validation' / '*.tfrecord'))\n\nds_train = (\n    tf.data.TFRecordDataset(train_files)\n    .map(decoder)\n    # etc\n)\n\nds_valid = (\n    tf.data.TFRecordDataset(valid_files)\n    .map(decoder)\n    # etc\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examine Data #"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for batch in ds_train.take(1):\n    image_0 = batch[0][0]\n    pos_0 = batch[0][1]\n    plt.figure(figsize=(16, 8))\n    for channel in range(5):\n        plt.subplot(2, 5, channel+1)\n        plt.imshow(image_0[channel], cmap='gray')\n        plt.subplot(2, 5, channel+1+5)\n        plt.imshow(pos_0[channel], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for batch in ds_valid.take(1):\n    image_0 = batch[0][0]\n    pos_0 = batch[0][1]\n    plt.figure(figsize=(16, 8))\n    for channel in range(5):\n        plt.subplot(2, 5, channel+1)\n        plt.imshow(image_0[channel], cmap='gray')\n        plt.subplot(2, 5, channel+1+5)\n        plt.imshow(pos_0[channel], cmap='gray')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}