{"cells":[{"metadata":{"trusted":true,"_uuid":"41acfc55aa3c0fe58333040bcea6692001514a23"},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport torch\nfrom sklearn import preprocessing\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils import weight_norm\nfrom random import shuffle\nimport os\n\nfrom torch.autograd import Variable\nimport torch.optim as optim\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b5e99008b8ff8b00dc77ff67a992f4bd448db62"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7529622a3fc544217fa301948d9f05fee0f072e"},"cell_type":"code","source":"class Chomp1d(nn.Module):\n    def __init__(self, chomp_size):\n        super(Chomp1d, self).__init__()\n        self.chomp_size = chomp_size\n\n    def forward(self, x):\n        return x[:, :, :-self.chomp_size].contiguous()\n\n\nclass TemporalBlock(nn.Module):\n    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n        super(TemporalBlock, self).__init__()\n        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n                                           stride=stride, padding=padding, dilation=dilation))\n        self.chomp1 = Chomp1d(padding)\n        self.relu1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(dropout)\n\n        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n                                           stride=stride, padding=padding, dilation=dilation))\n        self.chomp2 = Chomp1d(padding)\n        self.relu2 = nn.ReLU()\n        self.dropout2 = nn.Dropout(dropout)\n\n        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n        self.relu = nn.ReLU()\n        self.init_weights()\n\n    def init_weights(self):\n        self.conv1.weight.data.normal_(0, 0.01)\n        self.conv2.weight.data.normal_(0, 0.01)\n        if self.downsample is not None:\n            self.downsample.weight.data.normal_(0, 0.01)\n\n    def forward(self, x):\n        out = self.net(x)\n        res = x if self.downsample is None else self.downsample(x)\n        return self.relu(out + res)\n\n\nclass TemporalConvNet(nn.Module):\n    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n        super(TemporalConvNet, self).__init__()\n        layers = []\n        num_levels = len(num_channels)\n        for i in range(num_levels):\n            dilation_size = 2 ** i\n            in_channels = num_inputs if i == 0 else num_channels[i-1]\n            out_channels = num_channels[i]\n            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n\n        self.network = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.network(x)\n    \nclass TCN(nn.Module):\n    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n        super(TCN, self).__init__()\n        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n        self.linear = nn.Linear(num_channels[-1], output_size)\n        self.sig = nn.Sigmoid()\n\n    def forward(self, x):\n        # x needs to have dimension (N, C, L) in order to be passed into CNN\n        output = self.tcn(x.transpose(1, 2)).transpose(1, 2)\n        output = self.linear(output).double()\n        return self.sig(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7612ef20a2d3c9e345f5d5472b0ab7d03dd19fdc"},"cell_type":"code","source":"def prepare_prediction_data(market_data, news_data, asset_code):\n\n    df_market = market_data[market_data['assetCode']==asset_code]\n    \n    if df_market.shape[0] == 0:\n        return None\n        \n    asset_name = df_market.iloc[0]['assetName']\n    df_market['time'] = df_market['time'].apply(lambda x: x.date())\n    \n    df_news = news_data[news_data['assetName']==asset_name]\n    df_news['time'] = df_news['time'].apply(lambda x: x.date())\n    df_news =  df_news.groupby('time').mean()\n    df_news ['time'] = df_news.index\n\n    \n    market_columns = ['time', 'volume', 'close', 'open', \n                    'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1', \n                    'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', \n                    'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n    df_market = df_market[market_columns]\n\n    \n    news_columns = ['time', 'urgency', 'takeSequence', 'bodySize', \n                    'sentenceCount', 'wordCount', 'firstMentionSentence', 'relevance', \n                    'sentimentClass', 'sentimentNegative', 'sentimentNeutral', 'sentimentPositive', \n                    'sentimentWordCount']\n    df_news = df_news[news_columns]\n    \n    if df_news.shape[0] == 0:\n        df_news.ix[0] = [0] * df_news.shape[1]\n\n    df_merged = pd.merge(df_market, df_news, how='left', on=['time']) #, validate='many_to_one')\n    \n    df_merged = df_merged.fillna(0)\n    df_merged = df_merged.drop('time', axis=1)\n\n    \n    data_array = preprocessing.scale(np.array(df_merged, dtype=\"float32\"))\n    X = torch.tensor(data_array)\n\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"973cf4bc8a5d9380d42459ee89fdb3515ac47e18"},"cell_type":"code","source":"'''Main Part'''\n\nstate_dict = \"../input/tcn-twosigma-training/TwoSigma_ModelDict\"\nmodel_name = \"../input/tcn-twosigma-training/TwoSigma_Model.pt\"\n\n\nargs_dropout = 0.25\nargs_kernel_size = 4\nargs_lr = 1e-3\nargs_levels = 5\nargs_nhid = 120\nargs_optim = 'Adam'\nargs_cuda = False\n\ninput_size = 23\noutput_size = 1\nn_channels = [args_nhid] * args_levels\nkernel_size = args_kernel_size\nmodel = TCN(input_size, output_size, n_channels, args_kernel_size, dropout=args_dropout)\nif args_cuda:\n    model.cuda()\noptimizer = getattr(optim, args_optim)(model.parameters(), lr=args_lr)\n    \nmodel = torch.load(model_name, map_location='cpu')\ncheckpoint = torch.load(state_dict, map_location='cpu')\nmodel.load_state_dict(checkpoint['model_state'])\noptimizer.load_state_dict(checkpoint['optim_state'])\nlr = checkpoint['lr']\nprint('Model loaded')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cf4128f7b9f35da67f64ef64120f2825f082623"},"cell_type":"code","source":"if (\"twosigma-prediction\" in os.listdir(\"../input/\") and \"X_Dict\" in os.listdir(\"../input/twosigma-prediction/\")):\n    X_dict = torch.load(\"../input/twosigma-prediction/X_Dict\", map_location='cpu')\n    torch.save(X_dict, \"X_Dict\")\n    print('X Dict loaded')\nelse:\n    X_dict = {}\n    asset_codes = market_train_df['assetCode'].unique()\n    for asset_code in asset_codes:\n        X = prepare_prediction_data(market_train_df, news_train_df, asset_code)\n        X_dict[asset_code] = X\n    torch.save(X_dict, \"X_Dict\")\n    print('X Dict saved')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5446d9b2478cee3fc285e594d10971f65bbd2251"},"cell_type":"code","source":"input_path = \"../input/twosigma-prediction/\"\n\nif  \"predictions\" in os.listdir(input_path):\n    predictions_dict = torch.load(input_path+\"predictions\")\n    torch.save(predictions_dict, \"predictions\")\n    print('Predictions loaded...')\nelse:\n    predictions_dict = {}\n    print('Predictions initialized') \n\ndays = env.get_prediction_days()\ncnt=1\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    print('Day ', cnt)    \n    if cnt in predictions_dict.keys():\n        predictions_df = predictions_dict[cnt]\n    elif cnt > 3:\n        predictions_df = predictions_template_df\n    else:\n        predictions_df = predictions_template_df\n        asset_codes = market_obs_df['assetCode'].unique()\n\n        for asset_code in asset_codes:\n            X_new = prepare_prediction_data(market_obs_df, news_obs_df, asset_code)\n            if asset_code in X_dict.keys():\n                X_train = X_dict[asset_code] \n                X_prediction = torch.cat((X_train, X_new), 0)      \n            else:\n                X_prediction = X_new\n            X_dict[asset_code] = X_prediction\n            \n            if args_cuda:\n                X_prediction = X_prediction.cuda()\n            output = model(X_prediction.unsqueeze(0)).squeeze(0)\n            prediction = output[-1,:].item()\n            predictions_df.loc[predictions_df['assetCode'] == asset_code,'confidenceValue'] = prediction\n        predictions_dict[cnt] = predictions_df\n        torch.save(predictions_dict, \"predictions\")\n        \n    env.predict(predictions_df)\n    cnt += 1\n    print('Done...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"365f8460ad709e56e273c8ebd1cc4a49916a209b"},"cell_type":"code","source":"\n#env.write_submission_file() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b4201a2b419b58933191e004436f9f473c27325"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"614b785fb51a56ee59f72889f115b56b18f68f23"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}