{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da934484b44263eaa44a4cd13221596736b079e"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cb268cceba741228fc77630ebfbff5fb43ad8ee"},"cell_type":"code","source":"from datetime import datetime, date\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics.scorer import make_scorer\nfrom sklearn.metrics import recall_score\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38980cc649e79fa95b35c22d31768724b93865aa"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"509b37b685f3ff79316e2b08fa97cd31d39c019f"},"cell_type":"code","source":"data = []\n#market_train_df['close'] = market_train_df['close'] / 20\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['close'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['close'].values,\n        name = f'{i} quantile',\n    ))\nlayout = go.Layout(dict(title = \"Trends of closing prices by quantiles\",\n                        xaxis = dict(),\n                        yaxis = dict(title = 'Price (USD)')),\n                   legend=dict(orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c51e6a044973570f03827787fb2eb41753207900"},"cell_type":"markdown","source":"I am able to see how markets fall and rise again.\n\nYou could also notice that higher quantile prices have increased with time and lower quantile prices decreased. Maybe the gap between poor and rich increases... on the other hand maybe more \"little\" companies are ready to go to market and prices of their shares isn't very high.\n\nNext, we are going to see how those price drops"},{"metadata":{"trusted":true,"_uuid":"c4e4b3dc7a222cf0fdae55ce140b50968f940e7e"},"cell_type":"code","source":"print(market_train_df['open'].describe().apply(lambda x: format(x, 'f')))\nprint(market_train_df['close'].describe().apply(lambda x: format(x, 'f')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0376bf25381c2b07109d7a09b3cbb594fb05947"},"cell_type":"code","source":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby('time').agg({'price_diff': ['std', 'min']}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e004127483ad3cda33c6481b06dfcf88e03514b4"},"cell_type":"code","source":"g = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * g['price_diff']['min']).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values,\n        color = g['price_diff']['std'].values,\n        colorscale='Viridis',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 biggest volatility of daily price',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff_std',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85244304f2b812f9a29bd115171041205f6b85bc"},"cell_type":"markdown","source":"We can see huge price fluctiations when market crashed. Just think about it... But this is wrong! There was no huge crash on January 2010... Let's dive into the data!"},{"metadata":{"trusted":true,"_uuid":"45acf1edf8131d30f206775c5257350db7d38ff0"},"cell_type":"code","source":"market_train_df.sort_values('price_diff')[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"769c343be9995d85bb1f4b9d555f21ee2ad06053"},"cell_type":"markdown","source":"So price of \"Towers Watson & Co\" shares was almost 10k... I think this is simply an error in data.\n\n"},{"metadata":{"trusted":true,"_uuid":"f3c39c8a8809557e9c3ed2ab2679f38df16178a3"},"cell_type":"code","source":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] / market_train_df['open'])\n\n\nprint(f\"In {(market_train_df['close_to_open'] >= 2).sum()} lines price increased by 100% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.5).sum()} lines price decreased by 50% or more.\")\n\n\nmarket_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.1].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e60c6ddbdeabb38dc068a98ed08124b858199fec"},"cell_type":"code","source":"# after replacing the wired open and close price, we see them again\nprint(market_train_df['open'].describe().apply(lambda x: format(x, 'f')))\nprint(market_train_df['close'].describe().apply(lambda x: format(x, 'f')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc65bcba929c537f698af2a07cbc856b44f790e8"},"cell_type":"code","source":"# maybe do not need this part\n\n\nmarket_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby(['time']).agg({'price_diff': ['std', 'min']}).reset_index()\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * np.round(g['price_diff']['min'], 2)).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values * 5,\n        color = g['price_diff']['std'].values,\n        colorscale='Viridis',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 biggest volatility of daily price',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d83f2966d1a4b7539202043b0c904fbdd245c88a"},"cell_type":"markdown","source":"I would like to choose data after 2010-01-01, since the big recession in 2008 influence a lot and it is a very rare situation. "},{"metadata":{"trusted":true,"_uuid":"d2de6bcaad235ce9dae2fc5881c6d151a40ad76c"},"cell_type":"code","source":"market_train_df = market_train_df.loc[market_train_df['time'].dt.date >=date(2010, 1, 1)]\n\nnews_train_df = news_train_df.loc[news_train_df['time'].dt.date >=date(2010, 1, 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84b86daf6ffa0f07ad60fc720e72037a3ce5cddc"},"cell_type":"code","source":"print(market_train_df.shape)\nprint(news_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0370835a8ba566883e8c5863083594528719689d"},"cell_type":"markdown","source":"**ASSETCODE and ASSETNAME **"},{"metadata":{"trusted":true,"_uuid":"f6f7328e6059b2c7d522ad6c51bf5b588e5beced"},"cell_type":"code","source":"print(market_train_df['assetCode'].nunique())\nprint(market_train_df['assetName'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0511b62e0fe2fea99d1b7f3b3911ac3350562fd0"},"cell_type":"code","source":"a = market_train_df[market_train_df.assetName == 'Unknown'].size \nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e174713af6727262424086250e5186b2b8cb27d"},"cell_type":"markdown","source":"\nUnknown assetName exist in market_train_df"},{"metadata":{"_uuid":"ea6e7fe09d451f3106d355961eadd8194433da0c"},"cell_type":"markdown","source":"**VOLUME**"},{"metadata":{"trusted":true,"_uuid":"e0e1f6c0569dbe7a2e06808cf60264802b2e3b3a"},"cell_type":"code","source":"print(market_train_df['volume'].describe().apply(lambda x: format(x, 'f')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e7fc3d4778a108ac4ae262244ee309038032bc7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a7dcf72ade35b11353bb19fe72f7b2c90049a31"},"cell_type":"code","source":"# plot the volumn to see any pattern \nx = (market_train_df['volume'] - np.mean(market_train_df['volume']))/np.std(market_train_df['volume'])\ny = (market_train_df['close'] - np.mean(market_train_df['close']))/np.std(market_train_df['close'])\nwith sns.axes_style(\"white\"):\n    sns.jointplot(x=x, y=y, kind=\"hex\", color=\"k\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f50a219c7902aa3a3e7d795ca18a686af399a33e"},"cell_type":"markdown","source":"Check and impute Missing values in **RETURN** variables"},{"metadata":{"trusted":true,"_uuid":"0ad19f36522e85dd8442fb38e9986204a7336069"},"cell_type":"code","source":"# plot the missing percentage\npercent = (100 * market_train_df.isnull().mean()).sort_values(ascending=False)\npercent.plot(kind=\"bar\", figsize = (8,6), fontsize = 10)\nplt.xlabel(\"Columns\", fontsize = 10)\nplt.ylabel(\"Value Percent(%)\", fontsize = 10)\nplt.title(\"Total Missing Value by market_train_df\", fontsize = 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d69c23d91cbe0c8388ea2ab835f20fbc6a62763f"},"cell_type":"markdown","source":"**The types of missing values are the same, but the percentage is slightly different.**\n\n1. market_train_df : { returnsOpenPrevMktres10 : 2.284680 , returnsClosePrevMktres10 : 2.283599, returnsOpenPrevMktres1 : 0.392540 , returnsClosePrevMktres1 : 0.392344 }\n\n"},{"metadata":{"trusted":true,"_uuid":"0d9737a65f77552654f01a9e023f1a1da5b950b5"},"cell_type":"code","source":"def mis_impute(data):\n    for i in data.columns:\n        #if data[i].dtype == \"object\":\n            #data[i] = data[i].fillna(\"other\")\n        if (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data\n\nmarket_train_df = mis_impute(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"550098073fd1dc853066a71ae698ece330eaccaa"},"cell_type":"code","source":"# checking missing\nmarket_train_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9dbf7f27af80fea0b4b8abae394b1f8550cb10a"},"cell_type":"markdown","source":"**Exploring the 'target' varibale**"},{"metadata":{"trusted":true,"_uuid":"6a13bf79b4950f08a69787b2f1e7d388c8f1ddd1"},"cell_type":"code","source":"# plot the target variable \n\ndata = []\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']\n\nprice_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].mean().reset_index()\n\ndata.append(go.Scatter(\n    x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = price_df['returnsOpenNextMktres10'].values,\n    name = f'{i} quantile'\n))\nlayout = go.Layout(dict(title = \"Trend of returnsOpenNextMktres10 \",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Value'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb62c18de317e053ab469cd19fb4862d580ae293"},"cell_type":"markdown","source":"Fluctuations seem to be high, but in fact they are lower that 8 percent. In fact it looks like a random noise..."},{"metadata":{"_uuid":"e0eca539c33290b374878449220c9a1fd9d6e802"},"cell_type":"markdown","source":"**Correlation between all kinds of RETURNS**"},{"metadata":{"trusted":true,"_uuid":"472135c4be231b3f0a394a62c8d4d45dbfab1a2a"},"cell_type":"code","source":"corr = market_train_df[['returnsClosePrevRaw1','returnsClosePrevMktres1','returnsClosePrevRaw10','returnsClosePrevMktres10',\n                        'returnsOpenPrevRaw1','returnsOpenPrevMktres1','returnsOpenPrevRaw10','returnsOpenPrevMktres10',\n                        'returnsOpenNextMktres10']].corr()\n\ncorr.style.background_gradient().set_precision(2)\nf,ax = plt.subplots(figsize=(10,8))\nsns.heatmap(corr, annot=True, linewidths=.2, fmt= '.3f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16bb001b21cef69c3f74fd5dca8d5d20fc9bc445"},"cell_type":"markdown","source":"**Exploring the news_train_df dataset**"},{"metadata":{"trusted":true,"_uuid":"b2bedc247ba7cec0b695a54947ed5e5d1b99ac40"},"cell_type":"code","source":"# '' convert to NA\nnews_train_df['headlineTag'] = news_train_df['headlineTag'].replace('', np.nan)  \nnews_train_df['headline'] = news_train_df['headline'].replace('', np.nan)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7388eefa76f1313121fe161405f08fc3fa46a63"},"cell_type":"code","source":"text=news_train_df.headline.values[:100000]\nwc= WordCloud(background_color=\"white\",max_words=2000,stopwords=STOPWORDS)\nwc.generate(\" \".join(text))\nplt.figure(figsize=(20,20))\nplt.axis(\"off\")\nplt.title(\"Words could of Headlines\", fontsize=30)\nplt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b223fc28b9ac3b54d570f3d1e62ce5a262b7076"},"cell_type":"code","source":"percent = (100 * news_train_df.isnull().mean()).sort_values(ascending=False)\npercent.plot(kind=\"bar\", figsize = (8,6), fontsize = 10)\nplt.xlabel(\"Columns\", fontsize = 10)\nplt.ylabel(\"Value Percent(%)\", fontsize = 10)\nplt.title(\"Total Missing Value by news_train_df\", fontsize = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13a162a0549aeea4e2c8ebaaa6ca392fb5916d32"},"cell_type":"code","source":"print(news_train_df['headlineTag'].value_counts(dropna=False))\n\n# most news do not have tags","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af355790031320b086fed1b374ac6bbac30e62da"},"cell_type":"markdown","source":"**SOURCETIMESTAMP**"},{"metadata":{"trusted":true,"_uuid":"e65e69515379bcfc796b3eb7064354e415ec8706","scrolled":true},"cell_type":"code","source":"\nnews_train_df.loc[news_train_df['time'] == news_train_df['sourceTimestamp']].shape[0]/len(news_train_df['time'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e90c1656edf806ebcd0e3ba2bfe445190cda2a00"},"cell_type":"markdown","source":"0.7801438328721768"},{"metadata":{"_uuid":"6cb1f3e4c6079d9c2955823960541eb43dea0764"},"cell_type":"markdown","source":"**FIRSTCREATED**"},{"metadata":{"trusted":true,"_uuid":"93c6b93cea73d701058ac9476a9cc039025d9c10"},"cell_type":"code","source":"\nnews_train_df.loc[news_train_df['time'] == news_train_df['firstCreated']].shape[0]/len(news_train_df['time'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1af0c7666fbafd472589b69f692b2d0803fe0a28"},"cell_type":"markdown","source":"0.4973234451922393"},{"metadata":{"_uuid":"dcb8dd1157b3e2f787ba84255e5260f861165c87"},"cell_type":"markdown","source":"**SOURCEID**"},{"metadata":{"trusted":true,"_uuid":"28d39d2b89422bf2d18a0a47b142505954943ae2"},"cell_type":"code","source":"news_train_df['sourceId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d35f4e7905c23aab9194e618943171c1a9c2bc55"},"cell_type":"markdown","source":"this id is unique for each news, so there are many repeated news"},{"metadata":{"_uuid":"2254c3ae8c55f4ff6afd2ba379557dfbb34c59c9"},"cell_type":"markdown","source":"**URGENCY**"},{"metadata":{"trusted":true,"_uuid":"42cd6bc5971858c501aa21809ef204dad44e69e3"},"cell_type":"code","source":"news_train_df['urgency'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37e151857184ecc19859ed1414abf868715c959c"},"cell_type":"markdown","source":"urgency 2 only has 25 news. Does it make sence to keep this category?"},{"metadata":{"_uuid":"7226fd75585b305608567ffacdc5d9bc674f8e58"},"cell_type":"markdown","source":"**Data Description: **\n**takeSequence(int16)** - the take sequence number of the news item, starting at 1. For a given story, alerts and articles have separate sequences."},{"metadata":{"trusted":true,"_uuid":"39a88cd102ff4b591910c7f86eb8f4ae207122f3"},"cell_type":"code","source":"news_train_df['takeSequence'].value_counts(dropna = False)\nsns.distplot(news_train_df['takeSequence'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7795008cf287ea771a28b45a93d3fd915c0efa1"},"cell_type":"code","source":"news_train_df['provider'].value_counts(dropna = False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bae6742dc80a011c39a317f856b6fe3f0ed6070"},"cell_type":"markdown","source":"**subjects(category) **- topic codes and company identifiers that relate to this news item. Topic codes describe the news item's subject matter. These can cover asset classes, geographies, events, industries/sectors, and other types."},{"metadata":{"trusted":true,"_uuid":"fd25819f150b55bcf973f9e552238fe410927c8a"},"cell_type":"code","source":"news_train_df['subjects'].value_counts(dropna = False) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2014898a9c78760f716f80399c529dc0fa305fb9"},"cell_type":"markdown","source":"**audiences(category)** - identifies which desktop news product(s) the news item belongs to. They are typically tailored to specific audiences. (e.g. \"M\" for Money International News Service and \"FB\" for French General News Service)"},{"metadata":{"trusted":true,"_uuid":"d391c30dfd5aa556686ffc1b2d1d9b878fba1122"},"cell_type":"code","source":"news_train_df['audiences'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7f939f814eb6d01366c601a3791e1f768e6edb9"},"cell_type":"code","source":"# I noticed that there three columns have similar meaning\ncorr = news_train_df[['bodySize','wordCount','sentenceCount']].corr()\ncorr.style.background_gradient().set_precision(2)\n\nf,ax = plt.subplots(figsize=(4,2))\nsns.heatmap(corr, annot=True, linewidths=.1, fmt= '.3f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"661ebf0aa47eeca568eebad06d6639f207210eb1"},"cell_type":"code","source":"sns.distplot(news_train_df.companyCount)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fad2ba5f03601751c0c0efa64df40000c5ea3c9"},"cell_type":"code","source":"news_train_df['marketCommentary'].value_counts()\nnews_train_df['marketCommentary'] = news_train_df['marketCommentary'] *1\nnews_train_df['marketCommentary'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a952eb892ab1c097ac6a8d4d675c630b059be6"},"cell_type":"code","source":"print(news_train_df['assetName'].nunique())\nprint(news_train_df['assetName'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9bb63a855c19d112c53f400a48e2a18d07ad55b"},"cell_type":"code","source":"b = news_train_df[news_train_df.assetName == 'Unknown'].size \nprint(b)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de78d71f4f95207f95e658aae81b0533d65279c1"},"cell_type":"markdown","source":"Unknown assetName does not exist in news_train_df"},{"metadata":{"trusted":true,"_uuid":"32f61cc768633ea731cd0f29375ae6e9b2a687f8"},"cell_type":"code","source":"news_train_df['relevance'].describe().apply(lambda x: format(x, 'f'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffe5efa01bc800fa92fbdb40ab4a1a66e6e30b50"},"cell_type":"code","source":"news_train_df['firstMentionSentence'].describe().apply(lambda x: format(x, 'f'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5b43ac3c570bc8ce24dbbb4fd8dc4ad1a2a53a0"},"cell_type":"code","source":"\nnews_train_df['sentimentClass'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e8a141d72f5696a4832e1a2eb10111a943f843e"},"cell_type":"code","source":"news_train_df['sentimentWordCount'].describe().apply(lambda x: format(x, 'f'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"616e7a4587318a818f0141890b332d1e68a87d45"},"cell_type":"code","source":"news_train_df['sentimentrelated'] = news_train_df['sentimentWordCount']/news_train_df['wordCount']\nnews_train_df['sentimentrelated'].describe().apply(lambda x: format(x, 'f'))\nnews_train_df['sentimentrelated'].corr(news_train_df['relevance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8e241f4fa521b62a93bb71e98d6e21f7b4ab761"},"cell_type":"code","source":"corr = news_train_df[['noveltyCount12H','noveltyCount24H','noveltyCount3D','noveltyCount5D','noveltyCount7D']].corr()\ncorr.style.background_gradient().set_precision(2)\n\nf,ax = plt.subplots(figsize=(4,3))\nsns.heatmap(corr, annot=True, linewidths=.1, fmt= '.3f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93689f0d153ecaf840b987661dcb2665ad2cf6ce"},"cell_type":"code","source":"corr = news_train_df[['volumeCounts12H','volumeCounts24H','volumeCounts3D','volumeCounts5D','volumeCounts7D']].corr()\ncorr.style.background_gradient().set_precision(2)\n\nf,ax = plt.subplots(figsize=(4,3))\nsns.heatmap(corr, annot=True, linewidths=.1, fmt= '.3f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94089077eab1644e0a9a917786757058b7da4c2c"},"cell_type":"markdown","source":"**Preparing data**"},{"metadata":{"trusted":true,"_uuid":"8c407e8adcd3c154064dd6eb38bdd666044adcff"},"cell_type":"code","source":"def prepare_market_data(market_df):\n    market_df['time'] = market_df['time'].dt.date\n    market_df['average'] = (market_df['close'] + market_df['open'])/2\n    market_df['beta'] = market_df['close_to_open']\n    droplist = ['assetName','assetName_mean_open','assetName_mean_close','price_diff',\n                'returnsClosePrevRaw1','returnsOpenPrevRaw1',\n                'returnsClosePrevMktres1','returnsOpenPrevMktres1',\n                'returnsClosePrevRaw10','returnsOpenPrevRaw10','close_to_open','close','open']\n    market_df.drop(droplist, axis=1, inplace=True)\n\n    \n\n    return market_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ec44df0cfe580d7e8168ea26b134c1eff62206f"},"cell_type":"code","source":"def prepare_news_data(news_df):\n    news_df['position'] = news_df['firstMentionSentence'] / news_df['sentenceCount']\n\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline',\n                'takeSequence','provider','firstMentionSentence',\n                'sentenceCount','bodySize','headlineTag','marketCommentary',\n                'subjects','audiences','sentimentClass',\n                'assetName', 'urgency','wordCount','sentimentWordCount']\n    news_df.drop(droplist, axis=1, inplace=True)\n    news_df['time'] = news_df['time'].dt.date\n\n    # create a mapping between 'assetCode' to 'news_index'\n    assets = []\n    indices = []\n    for i, values in news_df['assetCodes'].iteritems():\n        assetCodes = eval(values)\n        assets.extend(assetCodes)\n        indices.extend([i]*len(assetCodes))\n    mapping_df = pd.DataFrame({'news_index': indices, 'assetCode': assets})\n    del assets, indices\n    \n    # join 'news_train_df' and 'mapping_df' (effectivly duplicating news entries)\n    news_df['news_index'] = news_df.index.copy()\n    expanded_news_df = mapping_df.merge(news_df, how='left', on='news_index')\n    del mapping_df, news_df\n    \n    expanded_news_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return expanded_news_df.groupby(['time', 'assetCode']).mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d0e451a8068f3659ca8a64159d2331706727091"},"cell_type":"code","source":"market = market_train_df.copy()\nnews = news_train_df.copy()\nmarket_df = prepare_market_data(market)\nnews_df = prepare_news_data(news)\nmerged_df = market_df.merge(news_df, how='left', on=['assetCode', 'time']).fillna(0)\nmerged_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58b2a5d6c72fa061efa68c3cf0f15c02f8d1e742"},"cell_type":"code","source":"# join news_df to market_df using ['assetCode', 'time']\nmerged_df = market_df.merge(news_df, how='left', on=['assetCode', 'time']).fillna(0)\nmerged_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c839a031fc26e7377a8fb570345dfe1c7c2e856"},"cell_type":"code","source":"merged_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"409da37f824a85d5f35309056e81252b74bef9bf"},"cell_type":"markdown","source":"**Building Models**"},{"metadata":{"trusted":true,"_uuid":"178c2c284e04a48b5bbee45d8f9abfe54b8999d3","scrolled":false},"cell_type":"code","source":"col = [x for x in merged_df.columns if x not in ['assetCode', 'time', 'returnsOpenNextMktres10','universe']]\n\nX = merged_df[col].values\n\ny = (merged_df.returnsOpenNextMktres10 >= 0).astype(int).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e43f9ee610117d85febc79c0a635e52d270206a"},"cell_type":"code","source":"print(len(col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9552ba4d2086670a3bc28225b7192d55fc75acbe"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfe69bfbbd2c6335e2abb0bc2d04205135f6277e"},"cell_type":"markdown","source":"LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n        importance_type='split', learning_rate=0.01, max_depth=50,\n        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n        n_estimators=200, n_jobs=-1, num_leaves=300, objective=None,\n        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=False,\n        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"},{"metadata":{"trusted":true,"_uuid":"e648fb6699e2da2d392925c7330fca70b9a7ddfb"},"cell_type":"code","source":"import lightgbm as lgb\nd_train = lgb.Dataset(X_train, label=y_train)\nparams = {'learning_rate': 0.01, \n          'max_depth': 12, \n          'boosting': 'gbdt', \n          'objective': 'binary', \n          'metric': 'binary_logloss', \n          'is_training_metric': True, \n          'seed': 42}\nmodel = lgb.train(params, d_train, \n                  num_boost_round = 2000,\n                  #valid_sets = [d_train, lgb.Dataset(X_test, label=y_test)],\n                  verbose_eval = 100, \n                  #early_stopping_rounds = 100\n                 )\n\ny_pred=model.predict(X_test)\ny_pred[y_pred >= 0.5] = 1\ny_pred[y_pred < 0.5] = 0\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\naccuracy=accuracy_score(y_pred,y_test)\nf1 = f1_score(y_pred,y_test)\nrecall = recall_score(y_pred,y_test)\nprint(accuracy,f1,recall)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e54fa10ac2b09e9e914c87ecb790119b625181fa"},"cell_type":"markdown","source":"0.5415720423247385 0.5752815488804071 0.5411853506409923  with 50 \n\n0.5416385565065123 0.5752357998072845 0.6137589288350705  this is without universe\n\n0.5415910463766739 0.5755713774012932 0.6146662407490423\n\n"},{"metadata":{"trusted":true,"_uuid":"046ee79b8fb4ef853c92c540a29f8f8bf3f36e79"},"cell_type":"code","source":"importances = pd.DataFrame({'feature': list(merged_df[col].columns), 'importance': list(model.feature_importance())})\nimportances = importances.sort_values('importance',ascending = False)\nprint(importances)\n\n# importances.plot.bar()\n\nplt.rcdefaults()\nfig, ax = plt.subplots()\n\n# Example data\nfeature = importances.feature\ny_pos = np.arange(len(feature))\nimportance = importances.importance\n\n\nax.barh(y_pos, importance, align='center',\n        color='red', ecolor='black')\nax.set_yticks(y_pos)\nax.set_yticklabels(feature)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Importances')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75cbd71182fd7c9c0e3bfcbd4449aeba5474f257"},"cell_type":"markdown","source":"**Explore the XGBClassifier**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"97cb3bc65d3b836144ad6600267e8a251099452c"},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier(n_jobs = 4, n_estimators = 200, max_depth = 8, eta = 0.1)\nxgb.fit(X_train,y_train)\n\naccuracy = accuracy_score(xgb.predict(X_test),y_test)\nf1 = f1_score(xgb.predict(X_test),y_test)\nrecall = recall_score(xgb.predict(X_test),y_test)\n\nprint(accuracy,f1,recall)\n  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ebc5f6f88a824cce2d7f2117278e017c074d280"},"cell_type":"markdown","source":"0.5415693274601763 0.5738222723068206 0.6103122173038877   this is result without universe\n\n"},{"metadata":{"trusted":true,"_uuid":"08e51e5379f3809a24dc576869ea8b300d111cd8"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, xgb.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3137ea27d073e7fce92942f7a4ae5209bbbc0005"},"cell_type":"code","source":"importances = pd.DataFrame({'feature': list(merged_df[col].columns), 'importance': xgb.feature_importances_})\nimportances = importances.sort_values('importance',ascending = False)\nprint(importances)\n\n# importances.plot.bar()\n\nplt.rcdefaults()\nfig, ax = plt.subplots()\n\n# Example data\nfeature = importances.feature\ny_pos = np.arange(len(feature))\nimportance = importances.importance\n\n\nax.barh(y_pos, importance, align='center',\n        color='red', ecolor='black')\nax.set_yticks(y_pos)\nax.set_yticklabels(feature)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Importances')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c4663fabbef1d5ba820455e4feb32a3f71eb205"},"cell_type":"markdown","source":"**New TRY ----with only 10000 rows**"},{"metadata":{"trusted":true,"_uuid":"c45b6d792f5c3a85daa0956aadc10086e20f5b51"},"cell_type":"code","source":"from pandas.tools.plotting import scatter_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56f8a8c5d6d588652c5bf0fea84ea48b89a0fd21","scrolled":true},"cell_type":"code","source":"# Set the number of folds to 10\nnum_folds = 10\nscoring = 'accuarcy'\n# Append the models to the models list\nmodels = []\nmodels.append(('LR' , LogisticRegression()))\nmodels.append(('LDA' , LinearDiscriminantAnalysis()))\nmodels.append(('KNN' , KNeighborsClassifier()))\nmodels.append(('CART' , DecisionTreeClassifier()))\nmodels.append(('NB' , GaussianNB()))\nmodels.append(('SVM' , SVC()))\nmodels.append(('RF' , RandomForestClassifier(n_estimators=50)))\n\n# Evaluate each algorithm for accuracy\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=42)\n    cv_results = cross_val_score(model, X_train[:10000], y_train[:10000], cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1b39a484fa1778a28228d83389a7c21bfab2e6a"},"cell_type":"markdown","source":"LR: 0.497300 (0.020953)\n\nLDA: 0.533300 (0.017607)\n\nKNN: 0.495600 (0.021228)\n\nCART: 0.506200 (0.013006)\n\nNB: 0.505100 (0.019562)\n\nSVM: 0.494500 (0.020963)\n\nRF: 0.513500 (0.025390)"},{"metadata":{"trusted":true,"_uuid":"2ced12108d18c8beee06988939a30684af6dadeb"},"cell_type":"code","source":"# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c25ad439b795b9cd824c62a5fdfe44add4abb88"},"cell_type":"markdown","source":"**LDA   ----- since it have the best performace( better than QDA) **"},{"metadata":{"trusted":true,"_uuid":"36eee26275c8885b26d562645e2265796ca60791"},"cell_type":"code","source":"# prepare the model LDA\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nmodel_lda = LinearDiscriminantAnalysis()\nmodel_lda.fit(rescaledX, y_train)\n# estimate accuracy on validation dataset\nrescaledValidationX = scaler.transform(X_test)\npredictions = model_lda.predict(rescaledValidationX)\n\naccuracy = accuracy_score(predictions,y_test)\nf1 = f1_score(predictions,y_test)\nprecision = precision_score(predictions,y_test)\n\nprint(accuracy,f1,precision)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fa2aa4c9edffab6a43a3faa9e68f26e61afd872"},"cell_type":"markdown","source":"0.5390132824748706 0.5873468356153064 0.6487682838114617\n\n0.5390268567976815 0.5873930793157077 0.6488729736476891   this is the result from model without universe\n\n0.5241629733196685 0.5182453864294785 0.5061270397740847  this is the result from QDA"},{"metadata":{"_uuid":"7ac694f332beaa7af9409b8f0641d30b7c24c1d9"},"cell_type":"markdown","source":"**Try the cat **"},{"metadata":{"trusted":true,"_uuid":"b6753fdd93bcce2a736ed97be07e60da4d5f0abf"},"cell_type":"code","source":"\nfrom catboost import CatBoostClassifier\nimport time\n\nprint('Training XGBoost')\nt = time.time()\ncatb = CatBoostClassifier(thread_count=4, \n                          n_estimators=200, \n                          max_depth=8, eta=0.1, \n                          loss_function='Logloss', \n                          verbose=10)\ncatb.fit(X_train, y_train)\n\naccuracy = accuracy_score(catb.predict(X_test),y_test)\nf1 = f1_score(catb.predict(X_test),y_test)\nrecall = recall_score(catb.predict(X_test),y_test)\n\nprint(accuracy,f1,recall)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c58fadd4b7b76c907d2e4085f5fec542ad9997ad"},"cell_type":"markdown","source":"0.5414865240910294 0.5765660962046644 0.540863196664056"},{"metadata":{"trusted":true,"_uuid":"61d596d582f88754191fa1bc4ec4cb97bf568a46"},"cell_type":"code","source":"importances = pd.DataFrame({'feature': list(merged_df[col].columns), 'importance': catb.feature_importances_})\nimportances = importances.sort_values('importance',ascending = False)\nprint(importances)\n\n# importances.plot.bar()\n\nplt.rcdefaults()\nfig, ax = plt.subplots()\n\n# Example data\nfeature = importances.feature\ny_pos = np.arange(len(feature))\nimportance = importances.importance\n\n\nax.barh(y_pos, importance, align='center',\n        color='red', ecolor='black')\nax.set_yticks(y_pos)\nax.set_yticklabels(feature)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Importances')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ce76669044f1f60150c33926c3578b2bdef9e9c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daac88775bc9715d75ddb0995db80c252ae693d7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b2085ad60a1ea1a93036f9ce2b3f933cab0b3a6"},"cell_type":"code","source":"import dask \nfrom dask_ml.xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81e02cb3c37a4739967564df966b6b17bf06400c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ef75688f55c556f2fe857c802a901b5dbdb084f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b65e76c38d996d30c18cb9335d648735f20eea92"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1b69dede640a80d03561e8bbdfc08b4db910931"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97d80c38764e3dbc6b43c9855ece88816ec29fc4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}