{"cells":[{"metadata":{"_uuid":"512d64e04ad0533dd72ca6bcbca4882a7f289956"},"cell_type":"markdown","source":"# Market Data Only Baseline (XGBRegressor)\n\n\nThis is a fit of market data only (no news data used) showing relatively good results. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom kaggle.competitions import twosigmanews\nfrom collections import Counter\nfrom sklearn import linear_model\nfrom xgboost import XGBRegressor\nimport scipy\nimport lightgbm as lgb\nimport itertools\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint, truncnorm, uniform\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\n\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"env = twosigmanews.make_env()\n(market_train, _) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f51d00dc43857b446ae4a24b3718753f09040fd5"},"cell_type":"markdown","source":"# Data Visu"},{"metadata":{"trusted":true,"_uuid":"3cbf0bcb416d8df37585241d0985ad42ee226488"},"cell_type":"code","source":"market_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ea5b5d3b16334b736f526d26dfa89647058bb03"},"cell_type":"code","source":"market_train[\"time\"] = market_train[\"time\"].apply(lambda x: pd.Timestamp(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04ad20ff733c55249de51a0edbb66dd59f474bf4"},"cell_type":"code","source":"# first date\nmin_time = np.min(market_train[\"time\"])\nprint(min_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59516c98d91a3cf83d38e7e10c6b2169b39a5528"},"cell_type":"code","source":"# last date\nmax_time = np.max(market_train[\"time\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a285f21ffdda7193fa1dd622daff5d03e9e30567"},"cell_type":"code","source":"def get_score(df_):\n    assert \"pred\" in df_.columns\n    df_[\"score\"] = df_[\"returnsOpenNextMktres10\"] * \\\n        df_[\"pred\"] * df_[\"universe\"]\n    x_t_sum = df_.groupby(\"time\").sum()[\"score\"]\n    score = x_t_sum.mean() / x_t_sum.std()\n    return score\n\ndef sigma_score_lgb_f(preds, valid_data, df_valid_):\n    df_valid_[\"pred\"] = preds\n    score = get_score(df_valid_)\n    \n    return 'sigma_score', score, True\n\ndef get_market_X(df_,\n                 X_columns=['volume',\n                            'close',\n                            'open',\n                            'returnsClosePrevRaw1',\n                            'returnsOpenPrevRaw1',\n                            'returnsClosePrevMktres1',\n                            'returnsOpenPrevMktres1',\n                            'returnsClosePrevRaw10',\n                            'returnsOpenPrevRaw10',\n                            'returnsClosePrevMktres10',\n                            'returnsOpenPrevMktres10'],\n                 fillna_value=-1000):\n\n    X = df_[X_columns]\n    X.fillna(fillna_value, inplace=True)\n    X = X.values\n    return X\n\n\ndef get_lgb_dataset(df_,\n                    X_columns=['volume',\n                            'close',\n                            'open',\n                            'returnsClosePrevRaw1',\n                            'returnsOpenPrevRaw1',\n                            'returnsClosePrevMktres1',\n                            'returnsOpenPrevMktres1',\n                            'returnsClosePrevRaw10',\n                            'returnsOpenPrevRaw10',\n                            'returnsClosePrevMktres10',\n                            'returnsOpenPrevMktres10']):\n    \n\n    X = get_market_X(df_)\n    y = df_['returnsOpenNextMktres10'].clip(-1, 1)\n    return lgb.Dataset(X, y, feature_name=X_columns, free_raw_data=False)\n\n\n\n\ndef get_trained_model_and_score(train_beginning,\n                                train_end,\n                                valid_beginning,\n                                valid_end,\n                                base_df,\n                                model):\n    # Selecting time\n\n    df_train = base_df.loc[(base_df[\"time\"] > pd.Timestamp(train_beginning, tz='UTC')) & (base_df[\"time\"] < pd.Timestamp(train_end, tz='UTC'))]\n    df_valid = base_df.loc[(base_df[\"time\"] > pd.Timestamp(valid_beginning, tz='UTC')) & (base_df[\"time\"] < pd.Timestamp(valid_end, tz='UTC'))]\n\n    # Creating X and y arrays\n\n    X_train = get_market_X(df_train)\n    y_train = df_train[['returnsOpenNextMktres10']].values\n    X_valid = get_market_X(df_valid)\n\n    # Training the model, storing the prediction, and getting score\n    model.fit(X_train, y_train)\n    df_valid[\"pred\"] = np.clip(model.predict(X_valid), -1, 1)\n    score = get_score(df_valid)\n\n    return model, score\n\n\ndef get_trained_model_and_score_lgb(train_beginning,\n                                    train_end,\n                                    valid_beginning,\n                                    valid_end,\n                                    base_df,\n                                    lgb_params_):\n    # Selecting time\n\n    df_train = base_df.loc[(base_df[\"time\"] > pd.Timestamp(train_beginning, tz='UTC')) & (base_df[\"time\"] < pd.Timestamp(train_end, tz='UTC'))]\n    df_valid = base_df.loc[(base_df[\"time\"] > pd.Timestamp(valid_beginning, tz='UTC')) & (base_df[\"time\"] < pd.Timestamp(valid_end, tz='UTC'))]\n    \n    sigma_score_lgb = lambda x,y: sigma_score_lgb_f(x,y,df_valid)\n    \n    lgb_train =  get_lgb_dataset(df_train)\n    lgb_valid =  get_lgb_dataset(df_valid)\n\n    evals_result = {}\n    model = lgb.train(lgb_params_,\n                      lgb_train,\n                      num_boost_round=1000,\n                      valid_sets=(lgb_valid,),\n                      valid_names=('valid',),\n                      verbose_eval=25,\n                      early_stopping_rounds=100,\n                      feval=sigma_score_lgb,\n                      evals_result=evals_result)\n\n    score = np.max(evals_result['valid']['sigma_score'])\n\n    return model, score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e51b118adb78948bd9f56e27ef3ba709711977e7"},"cell_type":"code","source":"# lgb_params = dict(\n#     objective = 'regression_l1',\n#     learning_rate = 0.1,\n#     num_leaves = 10,\n#     max_depth = -1,\n# #     min_data_in_leaf = 1000,\n# #     min_sum_hessian_in_leaf = 10,\n#     bagging_fraction = 0.75,\n#     bagging_freq = 2,\n#     feature_fraction = 0.5,\n#     lambda_l1 = 0.0,\n#     lambda_l2 = 1.0,\n#     metric = 'None', # This will ignore the loss objetive and use sigma_score instead,\n#     seed = 42 # Change for better luck! :)\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80e8cc718b4124a06c9ba6abc4cc0ef2fe14ab27"},"cell_type":"code","source":"# year = 2008\n# train_beginning=\"{}-01-01\".format(year)\n# train_end=\"{}-01-01\".format(year+1)\n# valid_beginning=\"{}-01-01\".format(year+1)\n# valid_end=\"{}-01-01\".format(year+2)\n\n# get_trained_model_and_score_lgb(train_beginning=train_beginning,\n#                                     train_end=train_end,\n#                                     valid_beginning=valid_beginning,\n#                                     valid_end=valid_end,\n#                                     base_df=market_train,\n#                                     lgb_params_=lgb_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"443926cb2d927e610301e5b4f85ef245e60e8828"},"cell_type":"code","source":"# year = 2012\n# train_beginning=\"{}-01-01\".format(year)\n# train_end=\"{}-01-01\".format(year+1)\n# valid_beginning=\"{}-01-01\".format(year+1)\n# valid_end=\"{}-01-01\".format(year+2)\n\n# m0,score = get_trained_model_and_score_lgb(train_beginning=train_beginning,\n#                                     train_end=train_end,\n#                                     valid_beginning=valid_beginning,\n#                                     valid_end=valid_end,\n#                                     base_df=market_train,\n#                                     lgb_params_=lgb_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcbc785855f69f1684e9ed5f7b64e05527dfc894"},"cell_type":"code","source":"last_valid_df = market_train.loc[(market_train[\"time\"] > pd.Timestamp(\"2016-01-01\", tz='UTC')) & (market_train[\"time\"] < pd.Timestamp(\"2017-01-01\", tz='UTC'))]\nX_valid_last = get_market_X(last_valid_df) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0c7581cf713c0818ae643f1d2a690a7fe731f2b"},"cell_type":"markdown","source":"# making predictions and writting submissions"},{"metadata":{"trusted":true,"_uuid":"f5fa0dc2dda7696636a06209b392263edf3c8a08"},"cell_type":"code","source":"def predict_market_using_model(market_obs_df_, predictions_template_df_, model_):\n    X = get_market_X(market_obs_df_)\n    market_obs_df_[\"pred\"] = np.clip(model_.predict(X), -1, 1)\n    pred_dict = (market_obs_df_.set_index(\"assetCode\")[\"pred\"]).to_dict()\n    pred_dict_f = lambda x: pred_dict[x] if x in pred_dict else 0.0 \n    predictions_template_df_[\"confidenceValue\"] = predictions_template_df_[\"assetCode\"].apply(pred_dict_f)\n    return predictions_template_df_\n\ndef write_sub_using_model(model_):\n    days = env.get_prediction_days()\n    for (market_obs_df, _ , predictions_template_df) in days:\n        predictions_template_df_pred = predict_market_using_model(market_obs_df, predictions_template_df, model_)\n        env.predict(predictions_template_df_pred)\n    env.write_submission_file()\n    print('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74e92a891afdb0bcd05430440aa97c3284e7e762"},"cell_type":"markdown","source":"1. ## training different models XGBRegressor"},{"metadata":{"trusted":true,"_uuid":"c6d750a73e1c5e7470a52b1f6a26bb0ab358f706"},"cell_type":"code","source":"years = range(2007, 2016)\n\nall_XGB_models = []\nall_XGB_scores = []\n\nfor year in years:\n    lmodel = XGBRegressor()\n    train_beginning=\"{}-01-01\".format(year)\n    train_end=\"{}-01-01\".format(year+1)\n    valid_beginning=\"{}-01-01\".format(year+1)\n    valid_end=\"{}-01-01\".format(year+2)\n    model, score = get_trained_model_and_score(train_beginning=train_beginning,\n                                               train_end=train_end,\n                                               valid_beginning=valid_beginning,\n                                               valid_end=valid_end,\n                                               base_df=market_train,\n                                               model=lmodel)\n    all_XGB_models.append(model)\n    all_XGB_scores.append(score)\n    print(\"train: {}   -- {}\".format(train_beginning, train_end))\n    print(\"valid: {}   -- {}\".format(valid_beginning, valid_end))\n\n    print(\"valid score = {:.5f}\".format(score))\n    print()\n    \nprint(\"mean score = {:.5f}\".format(np.mean(all_XGB_scores)))\nprint(\"std score = {:.5f}\".format(np.std(all_XGB_scores)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80517fe96a37a83c70a10da050acfee3655ee26d"},"cell_type":"markdown","source":"## training different models lightgbm"},{"metadata":{"trusted":true,"_uuid":"7dedc34ff65294f4ecd4afe68cf24b708ed8f34d"},"cell_type":"code","source":"years = range(2007, 2016)\n\nall_lgb_models = []\nall_lgb_scores = []\n\nlgb_params = dict(\n    objective = 'regression_l1',\n    learning_rate = 0.1,\n    num_leaves = 10,\n    max_depth = -1,\n#     min_data_in_leaf = 1000,\n#     min_sum_hessian_in_leaf = 10,\n    bagging_fraction = 0.75,\n    bagging_freq = 2,\n    feature_fraction = 0.5,\n    lambda_l1 = 0.0,\n    lambda_l2 = 1.0,\n    metric = 'None', # This will ignore the loss objetive and use sigma_score instead,\n    seed = 42 # Change for better luck! :)\n)\n\n\nfor year in years:\n    train_beginning=\"{}-01-01\".format(year)\n    train_end=\"{}-01-01\".format(year+1)\n    valid_beginning=\"{}-01-01\".format(year+1)\n    valid_end=\"{}-01-01\".format(year+2)\n    model, score = get_trained_model_and_score_lgb(train_beginning=train_beginning,\n                                                   train_end=train_end,\n                                                   valid_beginning=valid_beginning,\n                                                   valid_end=valid_end,\n                                                   base_df=market_train,\n                                                   lgb_params_=lgb_params)\n\n    all_lgb_models.append(model)\n    all_lgb_scores.append(score)\n    print(\"train: {}   -- {}\".format(train_beginning, train_end))\n    print(\"valid: {}   -- {}\".format(valid_beginning, valid_end))\n\n    print(\"valid score = {:.5f}\".format(score))\n    print()\n    \nprint(\"mean score = {:.5f}\".format(np.mean(all_lgb_scores)))\nprint(\"std score = {:.5f}\".format(np.std(all_lgb_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23b22753f138c4024ec52010c203a96df7c467d2"},"cell_type":"code","source":"print(all_XGB_scores)\nprint(\"mean score = {:.5f}\".format(np.mean(all_XGB_scores)))\nprint(\"std score = {:.5f}\".format(np.std(all_XGB_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cca4957fffab3b5cc20cd88d637c1aac0530f862"},"cell_type":"code","source":"print(all_lgb_scores)\nprint(\"mean score = {:.5f}\".format(np.mean(all_lgb_scores)))\nprint(\"std score = {:.5f}\".format(np.std(all_lgb_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03549cc1527552b200c7842a9e437012fbe00439"},"cell_type":"code","source":"class CombinedModel:\n    def __init__(self, model_list, weigths=None):\n        self.model_list = model_list\n        if weigths is None:\n            weigths = np.random.randint(1,100,len(model_list))\n            self.weigths = weigths / np.sum(weigths)\n        else:\n            self.weigths =  weigths\n\n    \n    def predict(self, X):\n        pred = np.zeros((X.shape[0],))\n        for model, weigth in zip(self.model_list,  self.weigths):\n            pred += model.predict(X) *  weigth\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21b394bcbee5172083a05a4c1a944b81937928c0"},"cell_type":"code","source":"model2score ={}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d2dba31067d8124a6a2fbdec65ba23f8ed705b2"},"cell_type":"code","source":"w = np.clip(all_lgb_scores, 0, float(\"inf\"))\nw = w * 10\n\ncombined_lgb = CombinedModel(all_lgb_models, weigths=w)\n\nlast_valid_df[\"pred\"] = np.clip(combined_lgb.predict(X_valid_last), -1, 1)\nscore = get_score(last_valid_df)\nprint(score)\nmodel2score[\"combined_lgb\"] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4580a58e0eeffa63adb1b3b835100d4f23e48766"},"cell_type":"code","source":"w = np.clip(all_XGB_scores, 0, float(\"inf\"))\nw = w * 10\n\ncombined_XGB = CombinedModel(all_XGB_models, weigths=w)\n\nlast_valid_df[\"pred\"] = np.clip(combined_XGB.predict(X_valid_last), -1, 1)\nscore = get_score(last_valid_df)\nprint(score)\nmodel2score[\"combined_XGB\"] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f902db4e0feadd02a1f569b6e6db8f855648aab5"},"cell_type":"code","source":"w = np.array([np.mean(all_lgb_scores), np.mean(all_XGB_scores)])\nw = w * 10\n# w = [1,1]\nw = w / np.sum(w)\n\ncombined_list = [combined_lgb, combined_XGB]\n\n\ncombined_m = CombinedModel(combined_list, weigths=w)\nlast_valid_df[\"pred\"] = np.clip(combined_m.predict(X_valid_last), -1, 1)\nscore = get_score(last_valid_df)\nprint(score)\nmodel2score[\"combined_m\"] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85e9bdd2daad39d9ead846e7f790daf71f64357d"},"cell_type":"code","source":"lmodel = XGBRegressor(n_jobs=4, n_estimators=374, max_depth=7, eta=0.51, reg_lambda=5.0, gamma=0.127)\ntrain_beginning=\"2007-01-01\"\ntrain_end=\"2016-01-01\"\nvalid_beginning=\"2016-01-01\"\nvalid_end=\"2017-01-01\"\n\nXGBRmodel_all, score = get_trained_model_and_score(train_beginning=train_beginning,\n                                                   train_end=train_end,\n                                                   valid_beginning=valid_beginning,\n                                                   valid_end=valid_end,\n                                                   base_df=market_train,\n                                                   model=lmodel)\n\nprint(\"train: {}   -- {}\".format(train_beginning, train_end))\nprint(\"valid: {}   -- {}\".format(valid_beginning, valid_end))\n\nprint(\"valid score = {:.5f}\".format(score))\nprint()\nlast_valid_df[\"pred\"] = np.clip(XGBRmodel_all.predict(X_valid_last), -1, 1)\nscore = get_score(last_valid_df)\nprint(score)\nmodel2score[\"XGBRmodel_all\"] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1e0e5456684d367876b26401a4c03faf8ec9c96"},"cell_type":"code","source":"train_beginning=\"2007-01-01\"\ntrain_end=\"2016-01-01\"\nvalid_beginning=\"2016-01-01\"\nvalid_end=\"2017-01-01\"\n\nlgbmodel_all, score = get_trained_model_and_score_lgb(train_beginning=train_beginning,\n                                               train_end=train_end,\n                                               valid_beginning=valid_beginning,\n                                               valid_end=valid_end,\n                                               base_df=market_train,\n                                               lgb_params_=lgb_params)\n\nprint(\"train: {}   -- {}\".format(train_beginning, train_end))\nprint(\"valid: {}   -- {}\".format(valid_beginning, valid_end))\n\nprint(\"valid score = {:.5f}\".format(score))\nprint()\nlast_valid_df[\"pred\"] = np.clip(lgbmodel_all.predict(X_valid_last), -1, 1)\nscore = get_score(last_valid_df)\nprint(score)\nmodel2score[\"lgbmodel_all\"] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8a414fa970c08a62bba058f9372c53b1dd4bb59"},"cell_type":"code","source":"lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n\ndef prep_data(market_data):\n    # add asset code representation as int (as in previous kernels)\n    market_data['assetCodeT'] = market_data['assetCode'].map(lbl)\n    market_col = ['assetCodeT', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1', \n                        'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10', \n                        'returnsOpenPrevMktres10']\n    # select relevant columns, fillna with zeros (where dropped in previous kernels that I saw)\n    # getting rid of time, assetCode (keep int representation assetCodeT), assetName, universe\n    #market_data = market_data[market_data['universe'] == True]\n    X = market_data[market_col].fillna(0).values\n    if \"returnsOpenNextMktres10\" in list(market_data.columns):#if training data\n        up = (market_data.returnsOpenNextMktres10 >= 0).values\n        r = market_data.returnsOpenNextMktres10.values\n        universe = market_data.universe\n        day = market_data.time.dt.date\n        assert X.shape[0] == up.shape[0] == r.shape[0] == universe.shape[0] == day.shape[0]\n    else:#observation data without labels\n        up = []\n        r = []\n        universe = []\n        day = []\n    return X, up, r, universe, day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"245f043780fff4e6033edd45ce5bff59a6640d5b"},"cell_type":"code","source":"train_beginning=\"2007-01-01\"\ntrain_end=\"2016-01-01\"\ntrain_df = market_train.loc[(market_train[\"time\"] > pd.Timestamp(train_beginning, tz='UTC')) & (market_train[\"time\"] < pd.Timestamp(train_end, tz='UTC'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64bde31139679dc367b157c2a3156ceb2ee7b7f1"},"cell_type":"code","source":"X, up, r, universe, day = prep_data(train_df)\n\n# r, u and d are used to calculate the scoring metric on test\nX_train, X_test, up_train, up_test, _, r_test, _, u_test, _, d_test = \\\ntrain_test_split(X, up, r, universe, day, test_size=0.25, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ba6a4757694b5a5d767d179acc04e5e0b7f49d9"},"cell_type":"code","source":"xgb_market = XGBClassifier(n_jobs=4, n_estimators=374, max_depth=7, eta=0.51, reg_lambda=5.0, gamma=0.127)\nt = time.time()\nprint('Fitting Up')\nxgb_market.fit(X_train,up_train)\nprint(f'Done, time = {time.time() - t}s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe557a1041b82584ab6dcda14a14336fde9bdbb8"},"cell_type":"code","source":"def gen_conf(prediction_probs):\n    new_conf  = np.empty([prediction_probs.shape[0]])\n    for i in range(prediction_probs.shape[0]):\n        if abs(prediction_probs[i][0] - prediction_probs[i][1]) < 0.01:\n            new_conf[i] = 0\n        elif prediction_probs[i][0] > prediction_probs[i][1]:\n            new_conf[i] = - 1\n        else:\n            new_conf[i] = 1\n    return new_conf\n\nclass ClassificationModel:\n    def __init__(self, model):\n        self.model = model\n    \n    def predict(self, X):\n        pred = gen_conf(self.model.predict_proba(X))\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb84b1245c3290673ca53b637fd79ee7b8146d65"},"cell_type":"code","source":"xgb_classification =  ClassificationModel(model=xgb_market)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab78f47cc0787035964a996804bbbd8e32088446"},"cell_type":"code","source":"X, up, r, universe, day = prep_data(last_valid_df)\n\nlast_valid_df[\"pred\"] = np.clip(xgb_classification.predict(X), -1, 1)\nscore = get_score(last_valid_df)\nprint(score)\nmodel2score[\"xgb_classification\"] = score\nlast_valid_df[\"xgb_classification\"] = last_valid_df[\"pred\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57764908fc7b2464a022138a4ba91310a3162a22"},"cell_type":"code","source":"for i,m in enumerate(all_XGB_models):\n    name = \"XGB_model_{}\".format(i) \n    last_valid_df[\"pred\"] = np.clip(m.predict(X_valid_last), -1, 1)\n    score = get_score(last_valid_df)    \n    last_valid_df[name] = last_valid_df[\"pred\"]\n    model2score[name] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fac274917f83e4612de7711def478ba5b17bf37"},"cell_type":"code","source":"for i,m in enumerate(all_lgb_models):\n    name = \"lgb_model_{}\".format(i) \n    last_valid_df[\"pred\"] = np.clip(m.predict(X_valid_last), -1, 1)\n    score = get_score(last_valid_df)    \n    last_valid_df[name] = last_valid_df[\"pred\"]\n    model2score[name] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc18de73320b48163ad3aefb59f9daaac488d699"},"cell_type":"code","source":"model2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc83968a7d22ae0991c765db97fa706a05862c38"},"cell_type":"code","source":"last_valid_df[\"combined_lgb\"] = np.clip(combined_lgb.predict(X_valid_last), -1, 1)\nlast_valid_df[\"combined_m\"] = np.clip(combined_m.predict(X_valid_last), -1, 1)\nlast_valid_df[\"XGBRmodel_all\"] = np.clip(XGBRmodel_all.predict(X_valid_last), -1, 1)\nlast_valid_df[\"lgbmodel_all\"] = np.clip(lgbmodel_all.predict(X_valid_last), -1, 1)\nlast_valid_df[\"combined_XGB\"] = np.clip(combined_XGB.predict(X_valid_last), -1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c734a3d91c3e8b4807f8dc315568025ff967cf2"},"cell_type":"code","source":"select = list(model2score.keys())\nselect = [m for m in select if model2score[m] > 0.4]\nlast_valid_df_simple = last_valid_df[select]\npred_corr = last_valid_df_simple.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99743494208a571da12806dcb2bd6f2f59b7659e"},"cell_type":"code","source":"def plot_corr(names_,\n              corr_,\n              title,\n              cmap=plt.cm.Oranges,\n              figsize=(9, 9)):\n    \"\"\"\n    Plot a correlation matrix.\n    \n    cmap reference:\n    https://matplotlib.org/examples/color/colormaps_reference.html\n    \n    :param names_: row/collum names\n    :type names_: [str]\n    :param corr_: matrix with correlations\n    :type corr_: np.array\n    :param title: image title\n    :type title: str\n    :param cmap: plt color map\n    :type cmap: plt.cm\n    :param figsize: plot's size\n    :type figsize: tuple\n    \"\"\"\n    plt.figure(figsize=figsize)\n    plt.imshow(corr_, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=24, fontweight='bold')\n    plt.colorbar()\n    tick_marks = np.arange(len(names_))\n    plt.xticks(tick_marks, names_, rotation=45)\n    plt.yticks(tick_marks, names_)\n    thresh = corr_.max() / 2.\n    for i, j in itertools.product(range(corr_.shape[0]), range(corr_.shape[1])):\n        plt.text(j, i, format(corr_[i, j], '.2f'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if corr_[i, j] > thresh else \"black\")\n\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84b5708d08d42de4f40a3301eca1b85fc2313ed2"},"cell_type":"code","source":"for m in select:\n    print(m, model2score[m])\n\nplot_corr(pred_corr.columns,\n           pred_corr.values,\n           \"correlation between models\\n(all above 0.4)\",\n           cmap=plt.cm.Oranges,\n           figsize=(10, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74bae8724ab9e53f2601f48d03e1e7b5b7c7dc63"},"cell_type":"code","source":"# w = np.array([np.mean(all_lgb_scores), np.mean(all_XGB_scores)])\n# w = w * 10\nw = [1,1]\nw = w / np.sum(w)\n\ncombined_list = [xgb_classification, all_lgb_models[2]]\n\nXclass , _, _, _, _ = prep_data(last_valid_df)\n\nlast_valid_df[\"pred\"] = (np.clip(xgb_classification.predict(Xclass), -1, 1) + np.clip(all_lgb_models[2].predict(X_valid_last), -1, 1)) / 2 \nscore = get_score(last_valid_df)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76c44f2a871ac436b15f27837c7ecdfd6fac3f09"},"cell_type":"code","source":"def write_sub_using_class_and_ref_models(class_model, reg_model):\n    days = env.get_prediction_days()\n    for (market_obs_df, _ , predictions_template_df) in days:\n        Xreg = get_market_X(market_obs_df)\n        Xclass , _, _, _, _ = prep_data(market_obs_df)\n        market_obs_df[\"pred\"] = (np.clip(class_model.predict(Xclass), -1, 1) + np.clip(reg_model.predict(Xreg), -1, 1)) / 2 \n        pred_dict = (market_obs_df.set_index(\"assetCode\")[\"pred\"]).to_dict()\n        pred_dict_f = lambda x: pred_dict[x] if x in pred_dict else 0.0 \n        predictions_template_df[\"confidenceValue\"] = predictions_template_df[\"assetCode\"].apply(pred_dict_f)\n        env.predict(predictions_template_df)\n    env.write_submission_file()\n    print('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96372ecc5bbd2880c16fcfd8d798a73bb5d91958"},"cell_type":"code","source":"write_sub_using_class_and_ref_models(class_model=xgb_classification, reg_model=all_lgb_models[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d5583a3ff6e2f249539e8a149a2a33971151011"},"cell_type":"code","source":"# write_sub_using_model(model_=combined_XGB)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"631f9932c248299e94291cd6c331391ebbe209a7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}