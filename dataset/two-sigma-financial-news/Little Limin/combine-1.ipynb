{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization\nfrom keras.losses import binary_crossentropy, mse\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dropout\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0924a5b4a1408939e51db8f9ed88c4f829d710b0"},"cell_type":"code","source":"(marketdf, newsdf) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de0667096acc93253a26bf0a7f78468f7bb5bdd6"},"cell_type":"code","source":"\ndef preprocess(marketdf, newsdf,encode=None):\n\n    news=newsdf.drop(['sourceTimestamp', 'firstCreated', 'sourceId', 'headline','takeSequence','provider', 'subjects', 'audiences', 'headlineTag'],axis=1)\n\n    news['sentiment_v']=(abs(news['sentimentNegative']-news['sentimentPositive']))*news['sentimentWordCount']/news['wordCount']\n\n    news_1=news[['time', 'urgency','companyCount','assetName','relevance', 'sentimentClass','sentiment_v','noveltyCount12H', 'noveltyCount24H',\n           'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n           'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D', 'volumeCounts7D']]\n\n    news_1['time'] = (news_1['time'] - np.timedelta64(22,'h')).dt.ceil('1D')\n    marketdf['time'] = marketdf['time'].dt.floor('1D')\n    # use how = left to aviod vanish of some company without news\n    com=pd.merge(marketdf, news_1, how='left', on=['time', 'assetName'])\n    com_1=com.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()\n    com_1=com_1.fillna(0)\n    if encode==None:\n        encode={name:id_asset for id_asset,name in enumerate(com_1.assetCode.astype(str).unique())}\n\n    com_2=com_1.assetCode.apply(lambda x :get_encoder(name=x,encode=encode))   # encoded series\n    com_1.assetCode=com_2\n    return com_1,encode\n\ndef get_encoder(name,encode):\n    if name in encode.keys():\n        return encode[name]\n    else:\n        return 5\n\ncom_1,encode = preprocess(marketdf, newsdf)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce56e00e3a7f01b2fbba7211af61aea7638e7090"},"cell_type":"code","source":"\ncol=[i for i in com_1.columns if i not in ['returnsOpenNextMktres10','universe']]\ntarget='returnsOpenNextMktres10'\n\n# use all data to train the model\ntrain_r=com_1[target]\ntrain_data=com_1[col]\n\n\ntrain_r=np.clip(train_r,a_min=-1,a_max=1)\n\ndef get_train_x(train_data):\n    x=dict()\n    x['Code']=train_data['assetCode']\n    x['num']=train_data.iloc[:,2:].values\n    return x\n\nX=get_train_x(train_data)       \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b958b52b2e01f6fec250504e3981430723fa270a"},"cell_type":"code","source":"import copy\n\ndef create_multi(r_train):\n    y=copy.deepcopy(r_train)\n    y1=pd.Series(copy.deepcopy(y))\n    z=pd.Series([0]*len(y))\n    z[(y<y1.quantile(0.1)).tolist()]=1\n    z[((y1.quantile(0.1)<=y)&(y<y1.quantile(0.2))).tolist()]=2\n    z[((y1.quantile(0.2)<=y)&(y<y1.quantile(0.3))).tolist()]=3\n    z[((y1.quantile(0.3)<=y)&(y<y1.quantile(0.4))).tolist()]=4\n    z[((y1.quantile(0.4)<=y)&(y<y1.quantile(0.5))).tolist()]=5\n    z[((y1.quantile(0.5)<=y)&(y<y1.quantile(0.6))).tolist()]=6\n    z[((y1.quantile(0.6)<=y)&(y<y1.quantile(0.7))).tolist()]=7\n    z[((y1.quantile(0.7)<=y)&(y<y1.quantile(0.8))).tolist()]=8\n    z[((y1.quantile(0.8)<=y)&(y<y1.quantile(0.9))).tolist()]=9\n    z[(y1.quantile(0.9)<=y).tolist()]=10\n    return z\n\ncata_train_r=create_multi(train_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e1dae7b305aa3fe3db3d368f12cf31c873d93a"},"cell_type":"code","source":"# one-hot encoding the label 1-6\nfrom keras.utils import to_categorical\nencoded_z = to_categorical(cata_train_r)\nencoded_z=encoded_z[:,1:]\n#encoded_z_valid=to_categorical(z_valid)[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"572fdfed78134ab2698869b3e8a32994436379f5"},"cell_type":"code","source":"cata_input=Input(shape=[1], name='Code')\nembed=Embedding(input_dim=len(encode.keys()), output_dim=30, input_length=1)(cata_input)\ncategorical_logits = Flatten()(embed)\ncategorical_logits = Dense(32,activation='relu')(categorical_logits)\n\nnumerical_inputs = Input(shape=(26,), name='num')\nnumerical_logits = numerical_inputs\nnumerical_logits = BatchNormalization()(numerical_logits)\n\nnumerical_logits = Dense(128,activation='relu')(numerical_logits)\nnumerical_logits = Dense(64,activation='relu')(numerical_logits)\nnumerical_logits=Dropout(0.5)(numerical_logits)\nnumerical_logits = Dense(32,activation='relu')(numerical_logits)\n\n\nlogits = Concatenate()([numerical_logits,categorical_logits])\nlogits = Dense(64,activation='relu')(logits)\nlogits=Dropout(0.5)(logits)\nlogits = Dense(32,activation='relu')(logits)\nlogits=Dropout(0.5)(logits)\nlogits = Dense(16,activation='relu')(logits)\nout = Dense(10,activation='sigmoid')(logits)  \n\nmodel = Model(inputs = [cata_input] + [numerical_inputs], outputs=out)\nmodel.compile(optimizer='adam',loss=binary_crossentropy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8c1eb64d6d9c9a6bf7a581fcf9f5bc6e476fb19"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5f4f303110ac989b764a56f8edd20d9c6bfeb52"},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\ncheck_point = ModelCheckpoint('model.hdf_4p',verbose=True, save_best_only=True)\nearly_stop = EarlyStopping(patience=5,verbose=True)\n\nmodel.fit(X,encoded_z,\n          epochs=2,\n          verbose=True,\n          callbacks=[early_stop,check_point]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1cc8210a4b337d07133bdff530be97528ed1969"},"cell_type":"code","source":"# model.fit(X,encoded_z,\n#           epochs=1,\n#           verbose=True,\n#           callbacks=[early_stop,check_point]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf4ecbc420fc383a84fbf41cbc934a112753a01"},"cell_type":"code","source":"#model.predict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59e1d2ea8e94a2c79a55ea75fc6931e13f99f391"},"cell_type":"code","source":"y=pd.Series(copy.deepcopy(train_r))\na=y.quantile(np.arange(0.1,1,0.1).tolist())\n\ndef decode_pre(d1):\n    decode_z_valid_pre=[np.argmax(d1[i,:])+1 for i in range(d1.shape[0])]\n\n    q_list=[]\n    for i in range(len(a)+1):\n        if i==0:\n            tmp=(a.iloc[0]-a.iloc[1])/2+a.iloc[0]\n        elif i==(len(a)):\n            tmp=(a.iloc[-1]-a.iloc[-2])/2+a.iloc[-1]\n        else:\n            tmp=(a.iloc[i-1]+a.iloc[i])/2\n        q_list.append(tmp)\n    pre=pd.Series(decode_z_valid_pre)\n    pre=pre.replace([i+1 for i in range(len(a)+1)],q_list)\n    return pre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b601e7145c2f3c5163c3caf12fbacde5ca49c6d0"},"cell_type":"code","source":"#p=model.predict({'Code': train_data['assetCode'][:100],'num': train_data.iloc[:100,2:].values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a9a808c946bd2f253d8deca6302f31084232ef3"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4013c269cfa56d2b3eecebbb5fffe77e1117776"},"cell_type":"code","source":"#(market_obs_df, news_obs_df, predictions_template_df) = next(days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c552ee75a45766e312adb3f4be0470af05023d1"},"cell_type":"code","source":"\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    com,_=preprocess(market_obs_df, news_obs_df,encode=encode)\n    X=get_train_x(com[col])\n    y=model.predict(X)\n    pre=decode_pre(y)\n    predictions_template_df.confidenceValue=pre\n    env.predict(predictions_template_df)\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c932cd6b667403a793b8ae22b33e652476c19e88"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}