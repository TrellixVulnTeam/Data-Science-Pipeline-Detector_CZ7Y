{"cells":[{"metadata":{"_uuid":"50bc29d151fa6192be326cbc343ce0b6e40405b4"},"cell_type":"markdown","source":"# Import packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport lightgbm as lgb\nimport pandas as pd\nfrom kaggle.competitions import twosigmanews\nimport matplotlib.pyplot as plt\nimport random\nfrom datetime import datetime, date\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\nimport sklearn\nfrom sklearn.metrics import accuracy_score, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true,"_uuid":"2a60d768ec157469fe0512b86356dace3c41233a"},"cell_type":"code","source":"env = twosigmanews.make_env()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59372bcf5fd43a7aa8b2b261cb516a3292d54f02"},"cell_type":"code","source":"\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df = market_train_df.tail(3000000)\nnews_train_df = news_train_df.tail(6000000)\n\nmarket_train, news_train = market_train_df.copy(), news_train_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51d904e9fd57dc968c9808e0f86c43d553afc5ed"},"cell_type":"markdown","source":"# Data prep"},{"metadata":{"trusted":true,"_uuid":"944548f80a4d961c8cb95124cd71d0832d02906c"},"cell_type":"code","source":"from itertools import chain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6eb395c38ab2b54b924a630527dd749a11d86b03"},"cell_type":"code","source":"news_cols_agg = {\n    'urgency': ['min', 'count'],\n    'takeSequence': ['max'],\n    'bodySize': ['min', 'max', 'mean', 'std'],\n    'wordCount': ['min', 'max', 'mean', 'std'],\n    'sentenceCount': ['min', 'max', 'mean', 'std'],\n    'companyCount': ['min', 'max', 'mean', 'std'],\n    'marketCommentary': ['min', 'max', 'mean', 'std'],\n    'relevance': ['min', 'max', 'mean', 'std'],\n    'sentimentNegative': ['min', 'max', 'mean', 'std'],\n    'sentimentNeutral': ['min', 'max', 'mean', 'std'],\n    'sentimentPositive': ['min', 'max', 'mean', 'std'],\n    'sentimentWordCount': ['min', 'max', 'mean', 'std'],\n    'noveltyCount12H': ['min', 'max', 'mean', 'std'],\n    'noveltyCount24H': ['min', 'max', 'mean', 'std'],\n    'noveltyCount3D': ['min', 'max', 'mean', 'std'],\n    'noveltyCount5D': ['min', 'max', 'mean', 'std'],\n    'noveltyCount7D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts12H': ['min', 'max', 'mean', 'std'],\n    'volumeCounts24H': ['min', 'max', 'mean', 'std'],\n    'volumeCounts3D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts5D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts7D': ['min', 'max', 'mean', 'std']\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d87aca3334891248058960aa1ec1daabcdb4cc4"},"cell_type":"code","source":"def join_market_news(market_train_df, news_train_df):\n    # Fix asset codes (str -> list)\n    news_train_df['assetCodes'] = news_train_df['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")    \n    \n    # Expand assetCodes\n    assetCodes_expanded = list(chain(*news_train_df['assetCodes']))\n    assetCodes_index = news_train_df.index.repeat( news_train_df['assetCodes'].apply(len) )\n\n    assert len(assetCodes_index) == len(assetCodes_expanded)\n    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n\n    # Create expandaded news (will repeat every assetCodes' row)\n    news_cols = ['time', 'assetCodes'] + sorted(news_cols_agg.keys())\n    news_train_df_expanded = pd.merge(df_assetCodes, news_train_df[news_cols], left_on='level_0', right_index=True, suffixes=(['','_old']))\n\n    # Free memory\n    del news_train_df, df_assetCodes\n\n    # Aggregate numerical news features\n    news_train_df_aggregated = news_train_df_expanded.groupby(['time', 'assetCode']).agg(news_cols_agg)\n    \n    # Free memory\n    del news_train_df_expanded\n\n    # Convert to float32 to save memory\n    news_train_df_aggregated = news_train_df_aggregated.apply(np.float32)\n\n    # Flat columns\n    news_train_df_aggregated.columns = ['_'.join(col).strip() for col in news_train_df_aggregated.columns.values]\n\n    # Join with train\n    market_train_df = market_train_df.join(news_train_df_aggregated, on=['time', 'assetCode'])\n\n    # Free memory\n    del news_train_df_aggregated\n    \n    return market_train_df\n\ndef get_x(market_train_df, news_train_df, le=None):\n    # Split date into before and after 22h (the time used in train data)\n    # E.g: 2007-03-07 23:26:39+00:00 -> 2007-03-08 00:00:00+00:00 (next day)\n    #      2009-02-25 21:00:50+00:00 -> 2009-02-25 00:00:00+00:00 (current day)\n    news_train_df['time'] = (news_train_df['time'] - np.timedelta64(22,'h')).dt.ceil('1D')\n\n    # Round time of market_train_df to 0h of curret day\n    market_train_df['time'] = market_train_df['time'].dt.floor('1D')\n\n    # Join market and news\n    x = join_market_news(market_train_df, news_train_df)\n    \n    # If not label-encoder... encode assetCode\n    \"\"\"\n    if le is None:\n        le_assetCode = label_encode(x['assetCode'], min_count=10)\n        le_assetName = label_encode(x['assetName'], min_count=5)\n    else:\n        # 'unpack' label encoders\n        le_assetCode, le_assetName = le\n    x['assetCode'] = x['assetCode'].map(le_assetCode).fillna(-1).astype(int)\n    x['assetName'] = x['assetName'].map(le_assetName).fillna(-1).astype(int)\n    \n    try:\n        x.drop(columns=['returnsOpenNextMktres10'], inplace=True)\n    except:\n        pass\n    try:\n        x.drop(columns=['universe'], inplace=True)\n    except:\n        pass\n    x['dayofweek'], x['month'] = x.time.dt.dayofweek, x.time.dt.month\n    x.drop(columns='time', inplace=True)\n#    x.fillna(-1000,inplace=True)\n\n    # Fix some mixed-type columns\n    for bogus_col in ['marketCommentary_min', 'marketCommentary_max']:\n        x[bogus_col] = x[bogus_col].astype(float)\n    \"\"\" \n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd3600639bd504b250f67985080d4715924705be"},"cell_type":"code","source":"#market_train = get_x(market_train_df, news_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4856c0a87ba664a6040bcda5b90caa15006b4b1"},"cell_type":"code","source":"def mis_impute(data):\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"other\")\n        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data\n\nmarket_train_df = mis_impute(market_train_df)\n\ndef data_prep(market_train):\n    market_train.time = market_train.time.dt.date\n    lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n    market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n    \n    market_train = market_train.dropna(axis=0)\n    \n    return market_train\n\nmarket_train = data_prep(market_train_df)\n\n# check the shape\nprint(market_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"886507a9c0384f0919b922b5ff8e2764c9575e0c"},"cell_type":"code","source":"market_train = market_train.loc[market_train['time']>=date(2009, 1, 1)]\nup = market_train.returnsOpenNextMktres10 >= 0\nfcol = [c for c in market_train if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\n# It is good to keep these scaling values for later\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)\n\n# Sanity check\nassert X.shape[0] == up.shape[0] == r.shape[0]\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\n\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.25, random_state=99)\n\ntrain_data = lgb.Dataset(X_train, label=up_train.astype(int))\ntest_data = lgb.Dataset(X_test, label=up_test.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d49a70d9691361dcd2e06513fe44e83604f03ec2"},"cell_type":"markdown","source":"# Tuning hyper-params with skopt"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"647493abe54d31de0e8662a46c51ff6f800d11e5"},"cell_type":"code","source":"'''\n# use this section if you want to customize optimization\n\n# define blackbox function\ndef f(x):\n    print(x)\n    params = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x[0],\n        'num_leaves': x[1],\n        'min_data_in_leaf': x[2],\n        'num_iteration': x[3],\n        'max_bin': x[4],\n        'verbose': 1\n    }\n    \n    gbm = lgb.train(params,\n            train_data,\n            num_boost_round=100,\n            valid_sets=test_data,\n            early_stopping_rounds=5)\n            \n    print(type(gbm.predict(X_test, num_iteration=gbm.best_iteration)[0]),type(up_test.astype(int)[0]))\n    \n    print('score: ', mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float)))\n    \n    return mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float))\n\n# optimize params in these ranges\nspaces = [\n    (0.19, 0.20), #learning_rate\n    (2450, 2600), #num_leaves\n    (210, 230), #min_data_in_leaf\n    (310, 330), #num_iteration\n    (200, 220) #max_bin\n    ]\n\n# run optimization\nfrom skopt import gp_minimize\nres = gp_minimize(\n    f, spaces,\n    acq_func=\"EI\",\n    n_calls=10) # increase n_calls for more performance\n\n# print tuned params\nprint(res.x)\n\n# plot tuning process\nfrom skopt.plots import plot_convergence\nplot_convergence(res)\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45c99e6b4fb86f54d020723d13031a923c8d3808"},"cell_type":"markdown","source":"# Training with tuned params"},{"metadata":{"trusted":true,"_uuid":"b6ac689319157951828d4e4a713ae688ea5e618c"},"cell_type":"code","source":"# these are tuned params I found\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\nx_2 = [0.19016805202090095, 2583, 213, 312, 220]\n\nparams_1 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n        'num_iteration': x_1[3],\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\nparams_2 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_2[0],\n        'num_leaves': x_2[1],\n        'min_data_in_leaf': x_2[2],\n        'num_iteration': x_2[3],\n        'max_bin': x_2[4],\n        'verbose': 1\n    }\n\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)\n        \ngbm_2 = lgb.train(params_2,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)\n        \n\n#prediction\ndays = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    t = time.time()\n    market_obs_df = data_prep(market_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n    prediction_time += time.time() -t\n    \n    t = time.time()\n\n    confidence = lp\n    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()\nsub  = pd.read_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7376622bed44ed4f009c47ed1d5acf177720f857"},"cell_type":"code","source":"def training_accuracy(X, y):\n    y_pred = []\n    y_true = []\n    y_true = y\n    y_pred = (gbm_1.predict(X) + gbm_2.predict(X))/2\n    MSE = sklearn.metrics.mean_squared_error(y_true, y_pred)\n    accuracy = accuracy_score(np.array(y_true)>0,np.array(y_pred)>0)\n    plt.hist(y_true, bins=np.linspace(-0.15,0.15,150), alpha=0.3)\n    plt.hist(y_pred, bins=np.linspace(-0.15,0.15,150), alpha=0.3, color='darkorange')\n    plt.legend(['Ground truth', 'Predicted'])\n    plt.xlabel(\"Confidence\")\n    plt.ylabel(\"Count\")\n    plt.title(\"predicted confidence\")\n    plt.show()\n    return MSE, accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dba3a318c3307b494b6298a9a0a20ad2ef3c1136"},"cell_type":"code","source":"test_mse, test_accuracy = training_accuracy(X_test, r_test)\nprint (\"Test MSE = \" + str(test_mse) + \", Test Accuracy = \" + str(test_accuracy))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}