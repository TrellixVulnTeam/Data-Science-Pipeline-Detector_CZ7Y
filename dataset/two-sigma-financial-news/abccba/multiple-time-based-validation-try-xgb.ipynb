{"cells":[{"metadata":{"trusted":true,"_uuid":"ecb27f7868edd557dcb52f0569c9d1024c09e85e"},"cell_type":"code","source":"import gc\nfrom kaggle.competitions import twosigmanews\n# call it only once\n# making the enviornment\nenv=twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4410c4936d4078c5a548147458354c251282acbb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgbm\nimport xgboost as xgb\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e906e9c1bcab496073d6c6713d2c28a551a83fd"},"cell_type":"code","source":"market_data,news_data=env.get_training_data()\n\nprint(market_data.shape,news_data.shape)\n\n# converting universe to int\nmarket_data['universe']=market_data['universe'].astype(int)\n\ndisplay(market_data.head())\ndisplay(news_data.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5adacbac303c717da03b8a37fb6101903e18ab6e"},"cell_type":"markdown","source":"## MARKET DATA"},{"metadata":{"trusted":true,"_uuid":"a993138b4f43f844da2660798f80a85f8b05f71f"},"cell_type":"code","source":"about=pd.DataFrame(index=market_data.columns)\nabout['types']=market_data.dtypes.values\nabout['unique_values']=market_data.nunique().values\nabout['missing_values']=market_data.isnull().sum().values\nabout['missing_values_percentage']=about['missing_values']/market_data.shape[0]\n\nabout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3624a0f319ed24f095f3aad21e6f53728759cd3","scrolled":true},"cell_type":"code","source":"print(\"Training data starts at\",market_data['time'].dt.date.min(),\n              \"and it ends at\",market_data['time'].dt.date.max())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff6a9fda6e8d8db0aadfca933f6005dad764e8f3"},"cell_type":"markdown","source":"So it starts at 2nd feb 2007 and ends at 30 december 2016."},{"metadata":{"_uuid":"11426fb29a7f4566d7aa65acc3cea9d899637a17"},"cell_type":"markdown","source":"## REMOVING 2007 AND 2008 DATA"},{"metadata":{"trusted":true,"_uuid":"ba7c86b7d19f2c3009a7f19cdd46fa0388b764b0"},"cell_type":"code","source":"# removing the data from news and market\nmarket_data=market_data.loc[market_data['time'].dt.date>=pd.datetime(2009,1,1).date()]\nnews_data=news_data.loc[news_data['time'].dt.date>=pd.datetime(2009,1,1).date()]\nprint(market_data.shape,news_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc1f7c843227aab411ad83e4d536f211b28d6cda"},"cell_type":"markdown","source":"## LABEL ENCODERS BEFORE SPLITTING THE DATA INTO TRAIN AND VALID\n\nBefore splitting I am making a global label encoders for asset name and asset code. Actually there can be more asset code in test data. "},{"metadata":{"trusted":true,"_uuid":"2fba5e0cfb573908c4911615014903cdd1e3990c"},"cell_type":"code","source":"gblabel_encoder_asset_code={name:idx for idx,name in enumerate(market_data['assetCode'].unique())}\ngblabel_encoder_asset_name={name:idx for idx,name in enumerate(market_data['assetName'].unique())}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75456a388388d0ebfa3c626deda2ab574fb20451"},"cell_type":"code","source":"def make_the_dataframe(df,assetcode_encoder,assetname_encoder,is_train):\n        \n    # label encoding for asset code\n    unique_values_asset_code=df['assetCode'].unique()\n    for name in unique_values_asset_code:\n        if name not in assetcode_encoder.keys():\n            # so this asset code is not there in the given train data, so we will add new mapping for this\n#             print(\"New asset code is added and the name is\",name)\n            assetcode_encoder[name]=max(assetcode_encoder.values())+1\n            \n    df['assetCode_encoding']=df['assetCode'].map(assetcode_encoder)\n    \n    # label encoding for asset name\n    unique_values_asset_name=df['assetName'].unique()\n    for name in unique_values_asset_name:\n        if name not in assetname_encoder.keys():\n            # so this asset name is not there in the given train data\n#             print(\"New asset name added and the name is\",name)\n            assetname_encoder[name]=max(assetname_encoder.values())+1\n    \n    df['assetName_encoding']=df['assetName'].map(assetname_encoder)\n\n    # deriving time features\n    df['weekofyear']=df['time'].dt.weekofyear\n    df['dayofweek']=df['time'].dt.dayofweek\n#     df['isleapyear']=df['time'].dt.is_leap_year.astype(int)\n#     df['isquarterstart']=df['time'].dt.is_quarter_start.astype(int)\n    \n    # other features\n    df['close_to_open_ratio']=df['close']/df['open']\n#     df['number_of_stocks*price']=df['volume']*(df['close']+df['open'])/2\n#     df['mrktres_retu_raw_retu1']=df['returnsClosePrevMktres1']-df['returnsClosePrevRaw1']\n#     df['mrktres_retu_raw_retu10']=df['returnsClosePrevMktres10']-df['returnsClosePrevRaw10']\n    \n    if is_train:\n        # creating the label (only for train or validation and not for test data)\n        df['label']=(df['returnsOpenNextMktres10']>0).astype(int)\n\n        # changing time to date\n        df['time']=df['time'].dt.date\n    \n        necessary_df=df[['time','assetCode','assetName','returnsOpenNextMktres10','universe']].copy()\n    \n        # dropping off unnecessary columns for training we are using asset name/code encoding\n        df.drop(columns=['time','assetName','assetCode','returnsOpenNextMktres10','universe'],inplace=True)\n    \n        return df,necessary_df\n    else:\n        # universe is not given in the test data\n        df.drop(columns=['time','assetName','assetCode'],inplace=True)\n        return df\n\n# making the numpy array  \ndef make_the_numpy_array(market_data_train,market_data_val):\n    X_train=market_data_train.iloc[:,:-1].values\n    X_val=market_data_val.iloc[:,:-1].values\n\n    y_train=market_data_train.iloc[:,-1].values\n    y_val=market_data_val.iloc[:,-1].values\n        \n    return X_train,X_val,y_train,y_val\n\ndef competitoin_metric(extract,probs):\n    extract['confidence']=2*probs-1\n    \n    extract['score']=extract['universe']*extract['returnsOpenNextMktres10']*extract['confidence']\n    \n    x=extract.groupby('time')['score'].sum().values\n    \n    return np.mean(x)/np.std(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aaa60dcfdb3d6fd68bd07d2d81389320e0d6c6f8","scrolled":false},"cell_type":"code","source":"splits=[2012,2013,2014,2015]\nmodels=[]\nfor idx,year in enumerate(splits):\n    print(\"Year = \",year)\n    \n    yr,mo,dte=year,1,1\n    #there must be minimum 10 day gap between validation and train to ensure there is no overlap of target variable\n    print(\"Splitting the data with respect to time\")\n    market_data_val=market_data.loc[(market_data['time'].dt.date>=pd.datetime(yr,mo+2,dte).date())]\n    market_data_train=market_data.loc[market_data['time'].dt.date<pd.datetime(yr,mo,dte).date()]\n    \n    market_data_train,extract_train=make_the_dataframe(market_data_train.copy(),gblabel_encoder_asset_code.copy(),\n                                            gblabel_encoder_asset_name.copy(),is_train=True)\n\n    market_data_val,extract_val=make_the_dataframe(market_data_val.copy(),gblabel_encoder_asset_code.copy(),\n                                            gblabel_encoder_asset_name.copy(),is_train=True)\n    \n    X_train,X_val,y_train,y_val=make_the_numpy_array(market_data_train,market_data_val)\n    \n    print(\"The training data shape is\",X_train.shape,y_train.shape)\n    print(\"The validation data shape is\",X_val.shape,y_val.shape)\n    \n    gc.enable()\n    del market_data_train,market_data_val    \n    gc.collect()\n    \n    clf=xgb.XGBClassifier(n_jobs=4,max_depth=7)\n    clf.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],eval_metric='logloss',\n            early_stopping_rounds=25,verbose=10)\n    \n    print(\"The Training Competition metric is:\",competitoin_metric(extract_train,\n                             clf.predict_proba(X_train)[:,1]))\n    print(\"The validation competition metric is:\",competitoin_metric(extract_val,\n                             clf.predict_proba(X_val)[:,1]))    \n    models.append(clf)\n    \n    gc.enable()\n    del X_train,X_val,y_train,y_val\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b5c9e3132b118ce72d9a25fb4fbfb479a83045f3"},"cell_type":"code","source":"# # cross check code\n# for idx,year in enumerate(splits):\n#     print(\"Year = \",year)\n    \n#     yr,mo,dte=year,1,1\n#     #there must be minimum 10 day gap between validation and train to ensure there is no overlap of target variable\n#     print(\"Splitting the data with respect to time\")\n#     market_data_val=market_data.loc[(market_data['time'].dt.date>=pd.datetime(yr,mo+2,dte).date())]\n#     market_data_train=market_data.loc[market_data['time'].dt.date<pd.datetime(yr,mo,dte).date()]\n    \n#     market_data_train,extract_train=make_the_dataframe(market_data_train.copy(),gblabel_encoder_asset_code.copy(),\n#                                             gblabel_encoder_asset_name.copy(),is_train=True)\n\n#     market_data_val,extract_val=make_the_dataframe(market_data_val.copy(),gblabel_encoder_asset_code.copy(),\n#                                             gblabel_encoder_asset_name.copy(),is_train=True)\n    \n#     X_train,X_val,y_train,y_val=make_the_numpy_array(market_data_train,market_data_val)\n    \n#     print(\"The training data shape is\",X_train.shape,y_train.shape)\n#     print(\"The validation data shape is\",X_val.shape,y_val.shape)\n    \n#     gc.enable()\n#     del market_data_train,market_data_val    \n#     gc.collect()\n    \n#     clf=models[idx]\n    \n#     print(\"The Training Competition metric is:\",competitoin_metric(extract_train,\n#                          clf.predict_proba(X_train,num_iteration=clf.best_iteration_)[:,1]))\n#     print(\"The validation competition metric is:\",competitoin_metric(extract_val,\n#                          clf.predict_proba(X_val,num_iteration=clf.best_iteration_)[:,1]))\n    \n#     models.append(clf)\n    \n#     gc.enable()\n#     del X_train,X_val,y_train,y_val\n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe8a1cbfaecf8e162771c52754dcb569afeb2216"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bf2fdb5126e4e92fdb538e73808a6b12361b7c5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad25273cfee9d73999f7b3c9aeec045426ae6f80"},"cell_type":"markdown","source":"## MAKING THE PREDICTIONS "},{"metadata":{"trusted":true,"_uuid":"c9ec1614fe18e88e40d4bacea10e1c96e9c5372e"},"cell_type":"code","source":"def make_the_predictions(models,test_market_data,test_news_data,predictions_template_df):\n    test=make_the_dataframe(test_market_data,gblabel_encoder_asset_code.copy(),\n                             gblabel_encoder_asset_name.copy(),is_train=False)\n    \n    X_test=test.iloc[:,:].values\n    \n    gc.enable()\n    del test\n    gc.collect()\n    \n    # making inital predictions to zeros\n    \n    predictions_template_df['confidenceValue']=0\n    \n    for clf in models:\n        confidences=2*clf.predict_proba(X_test)[:,1]-1\n        predictions_template_df['confidenceValue']=predictions_template_df['confidenceValue']+confidences\n        \n    predictions_template_df['confidenceValue']=predictions_template_df['confidenceValue']/len(models)\n    \n    return predictions_template_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0a7a3ee328dc2ccaa87d6578462ff4952298c9e","scrolled":true},"cell_type":"code","source":"for day,(market_obs_df, news_obs_df, predictions_template_df) in enumerate(env.get_prediction_days()):\n    if(day==0):\n        print(\"The columns of market are\",market_obs_df.columns)\n    \n    predictions=make_the_predictions(models,market_obs_df, news_obs_df, predictions_template_df)\n    env.predict(predictions)\n    \n    if((day+1)%20==0):\n        print(\"Predictions for\",day+1,\"days done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56d8a6959d87d7c3f55cd5764a0e731da83fe8e7"},"cell_type":"code","source":"# writing the submission file\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9a803e7a7c7f17a3152ec2e6b6a2e663c66c365"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77f65d25dcd5cd9e4385bb316d02f94ca9a9c87e"},"cell_type":"code","source":"# a={'a':0,'b':1,'c':2,'d':3}\n\n# def test(di):\n#     cols=['d','e','a','e','f']\n#     for name in cols:\n#         if name not in di.keys():\n#             di[name]=max(di.values())+1\n    \n#     return di\n\n# new=test(a.copy())\n# new1=test(a.copy())\n# print(a)\n# print(new)\n# print(new1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f35be9c399caf11891d24e4a5c5d56ff49f2970f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49ac0f42057c32d7df6ce3cc358084d9378d230d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"898b20b0bb3786f313330fd7d9b5368d7bc0950c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5033f490e0d7dc60f9bcfc895710591967e135b8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}