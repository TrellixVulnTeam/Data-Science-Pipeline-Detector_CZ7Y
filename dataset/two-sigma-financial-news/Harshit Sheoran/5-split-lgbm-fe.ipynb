{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom datetime import datetime, date\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport time\nimport lightgbm as lgb\nfrom kaggle.competitions import twosigmanews","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"env = twosigmanews.make_env()\n\n(market_train, news_train) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b538a1c7822b9b7526cc3b361c3e376a0ff72bdc"},"cell_type":"code","source":"for col in market_train.columns:\n    if (market_train[col].dtype == \"int64\" or market_train[col].dtype == \"float64\"):\n        market_train[col] = market_train[col].fillna(market_train[col].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a0fe062c0fc5fe807d742ad286e9044aac31097"},"cell_type":"code","source":"market_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f89649b21c6a44f63e1bda7bf3efd40afbf7b8c"},"cell_type":"code","source":"market_train['time'] = market_train.time.dt.date\nmarket_train = market_train.loc[market_train['time'] >= date(2010, 1, 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fee01ff5a5535a55f742635289ef20238a709a30"},"cell_type":"code","source":"asset_code_dict = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\ncolumns_news = ['firstCreated','relevance','sentimentClass','sentimentNegative','sentimentNeutral',\n               'sentimentPositive','noveltyCount24H','noveltyCount7D','volumeCounts24H','volumeCounts7D','assetCodes','sourceTimestamp',\n               'assetName','audiences', 'urgency', 'takeSequence', 'bodySize', 'companyCount', \n               'sentenceCount', 'firstMentionSentence','time']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6222c0916cfd105e44d37ca48ca0d0941cd4cec"},"cell_type":"code","source":"def feature_engineering(df):\n    df['date'] = df['time']\n    df['price_diff'] = df['close'] - df['open']\n    df['close_to_open'] =  np.abs(df['close'] / df['open'])\n    df['assetName_mean_open'] = df.groupby('assetName')['open'].transform('mean')\n    df['assetName_mean_close'] = df.groupby('assetName')['close'].transform('mean')\n#    market_df.drop(['time'], axis=1, inplace=True)\n    \n#    news_df = news_df[columns_news]\n#    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n#    news_df['firstCreated'] = news_df.firstCreated.dt.date\n#    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n#    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n#    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n#    news_df['len_audiences'] = news_train['audiences'].map(lambda x: len(eval(x)))\n#    kcol = ['firstCreated', 'assetCodes']\n#    news_df = news_df.groupby(kcol, as_index=False).mean()\n#    market_df = pd.merge(market_df, news_df, how='left', left_on=['date', 'assetCode'], \n#                            right_on=['firstCreated', 'assetCodes'])\n#    del news_df\n    df['assetCodeT'] = df['assetCode'].map(asset_code_dict)\n\n    return df\n\ndf = feature_engineering(market_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af30f73c6d6ad59ae9ff8ee3b4480cefe740af25"},"cell_type":"code","source":"def reduce_mem_usage(df):\n    for col in df.columns:\n        if df[col].dtype == np.float64 or df[col].dtype == np.float32:\n            df[col] = df[col].astype(np.float16)\n    return df\n\ndf = reduce_mem_usage(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f8f689902f0d7608f2c0782b1a23e9e4cd004dc"},"cell_type":"code","source":"for col in df.columns:\n    if df[col].dtype == \"int64\" or df[col].dtype == \"float16\":\n        df[col] = df[col].fillna(df[col].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cd95626fd9a24733670da95cdf73f5f5dc42a51"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a1b120b763cc1fdb27132854285e9883643d574"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d23038ef99fdf865efb62abb76ecfadbc2a62e84"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nfrom datetime import datetime, date\n\nup = df['returnsOpenNextMktres10'] >= 0\n\nuniverse = df['universe'].values\nd = df['date']\n\nfcol = [c for c in df if c not in ['date', 'assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\nprint(\"Creating X\")\nX = df[fcol].values\nprint(\"Creating up\")\nup = up.values\nprint(\"Creating r\")\nr = df.returnsOpenNextMktres10.values\n\n# Scaling of X values\n# It is good to keep these scaling values for later\n\n#f = df[fcol]\n#print(f.info())\n\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nprint(\"Reshaping X\")\nX = 1 - ((maxs - X) / rng)\nprint(\"Rehaped and asseting\")\n# Sanity check\nassert X.shape[0] == up.shape[0] == r.shape[0]\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\n\n# X_train, X_test, up_train, up_test, r_train, r_test,u_train,u_test,d_train,d_test = model_selection.train_test_split(X, up, r,universe,d, test_size=0.25, random_state=99)\n\ndf['time'] = pd.to_datetime(df['date'])\n\nte = df['time']>date(2015, 1, 1)\n\nprint(\"Getting index values\")\n\ntt = 0\nfor tt,i in enumerate(te.values):\n    if i:\n        idx = tt\n        print(i,tt)\n        break\nprint(idx)\n# for ind_tr, ind_te in tscv.split(X):\n#     print(ind_tr)\n\nprint(\"Creating X_train, X_test\")\n\nX_train, X_test = X[:idx],X[idx:]\n\nprint(\"Creating up_train, up_test\")\nup_train, up_test = up[:idx],up[idx:]\nprint(\"Creating r_train, r_test\")\nr_train, r_test = r[:idx],r[idx:]\nprint(\"Creating u_train, u_test\")\nu_train,u_test = universe[:idx],universe[idx:]\nprint(\"Creating d_train, d_test\")\nd_train,d_test = d[:idx],d[idx:]\nprint(\"Creating Train Dataset\")\ntrain_data = lgb.Dataset(X_train, label=up_train.astype(int))\n# train_data = lgb.Dataset(X, label=up.astype(int))\nprint(\"Creating Test Dataset\")\ntest_data = lgb.Dataset(X_test, label=up_test.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e202dd31092f9e2bed28ce9c4421a8796b3c7921","scrolled":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nDATA_SPLIT_SEED = 2018\n\nsplits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=DATA_SPLIT_SEED).split(X, up))\nfor idx, (train_idx, valid_idx) in enumerate(splits):\n    X_train = X[train_idx]\n    y_train = up[train_idx]\n    X_val = X[valid_idx]\n    y_val = up[valid_idx]\n    \n    train_data = lgb.Dataset(X_train, label=y_train)\n    test_data = lgb.Dataset(X_val, label=y_val)\n    \n    x_1 = [0.19000424246380565, 2452, 212, 328, 202]\n    x_2 = [0.19016805202090095, 2583, 213, 312, 220]\n\n    def exp_loss(p,y):\n        y = y.get_label()\n#        p = p.get_label()\n        grad = -y*(1.0-1.0/(1.0+np.exp(-y*p)))\n        hess = -(np.exp(y*p)*(y*p-1)-1)/((np.exp(y*p)+1)**2)\n    \n        return grad,hess\n\n    params_1 = {\n            'task': 'train',\n            'boosting_type': 'gbdt',\n            'objective': 'binary',\n#            'objective': 'regression',\n            'learning_rate': x_1[0],\n            'num_leaves': x_1[1],\n            'min_data_in_leaf': x_1[2],\n#            'num_iteration': x_1[3],\n            'num_iteration': 239,\n            'max_bin': x_1[4],\n            'verbose': 1\n    }\n\n    params_2 = {\n            'task': 'train',\n            'boosting_type': 'gbdt',\n            'objective': 'binary',\n#            'objective': 'regression',\n            'learning_rate': x_2[0],\n            'num_leaves': x_2[1],\n            'min_data_in_leaf': x_2[2],\n#            'num_iteration': x_2[3],\n            'num_iteration': 172,\n            'max_bin': x_2[4],\n            'verbose': 1\n    }\n\n    gbm_1 = lgb.train(params_1,\n            train_data,\n            num_boost_round=100,\n            valid_sets=test_data,\n            early_stopping_rounds=5,\n#            fobj=exp_loss,\n        )\n\n    gbm_2 = lgb.train(params_2,\n            train_data,\n            num_boost_round=100,\n            valid_sets=test_data,\n            early_stopping_rounds=5,\n#            fobj=exp_loss,\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"315a6268c0cd5eab08f24cf00a2e8001bd1d31b1"},"cell_type":"code","source":"confidence_test = (gbm_1.predict(X_test) + gbm_2.predict(X_test))/2\nconfidence_test = (confidence_test-confidence_test.min())/(confidence_test.max()-confidence_test.min())\nconfidence_test = confidence_test*2-1\nprint(max(confidence_test),min(confidence_test))\n\n# calculation of actual metric that is used to calculate final score\nr_test = r_test.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = confidence_test * r_test * u_test\ndata = {'day' : d_test, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_test = mean / std\nprint(score_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d71d724e45738c38d04c5032f7a308679f68f8d"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfeat_importance = pd.DataFrame()\nfeat_importance[\"feature\"] = fcol\nfeat_importance[\"gain\"] = gbm_1.feature_importance(importance_type='gain')\nfeat_importance.sort_values(by='gain', ascending=False, inplace=True)\nplt.figure(figsize=(8,10))\nax = sns.barplot(y=\"feature\", x=\"gain\", data=feat_importance)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b81618fa8c75ed579966aec767e58f0030630462"},"cell_type":"code","source":"days = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76ac78c19e33192779fe69b8d0f2c321d7dc78ee"},"cell_type":"code","source":"def post_scaling(df):\n    mean, std = np.mean(df), np.std(df)\n    df = (df - mean)/ (std * 8)\n    return np.clip(df,-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94c3aa5035c006a4635fc78e9935a4d90dfdbc93"},"cell_type":"code","source":"for (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    for col in market_obs_df.columns:\n        if (market_obs_df[col].dtype == \"int64\" or market_obs_df[col].dtype == \"float64\"):\n            market_obs_df[col] = market_obs_df[col].fillna(market_obs_df[col].mean())\n    \n    for col in market_obs_df.columns:\n        if (market_obs_df[col].dtype == \"int64\" or market_obs_df[col].dtype == \"float64\"):\n            market_obs_df[col] = market_obs_df[col].fillna(market_obs_df[col].mean())\n            \n    market_obs_df = feature_engineering(market_obs_df)\n    \n    fcol = [c for c in market_obs_df if c not in ['date', 'assetCode', 'time', 'returnsOpenNextMktres10', 'universe', 'assetName', 'Unnamed: 0']]\n    \n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n#    X_live = 1 - ((maxs - X_live) / rng)\n    \n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n    \n\n    confidence = lp\n#    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence': post_scaling(confidence)})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e0885b1f901e8feb6c26927e107ec9d7a7ff446"},"cell_type":"code","source":"env.write_submission_file()\nsub  = pd.read_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"911e0c0a6c377109707324a41de41782a2be8826"},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eabf8fee382b401425981c2ea8f894c3061f373"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d949db4fdd3f79f5b831345a0214785fcdf7497"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}