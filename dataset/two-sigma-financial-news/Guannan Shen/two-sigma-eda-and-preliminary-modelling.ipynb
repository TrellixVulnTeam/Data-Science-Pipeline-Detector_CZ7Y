{"cells":[{"metadata":{"_uuid":"6a976d40fbd3348295a377afcf696d5a76024c16"},"cell_type":"markdown","source":"# Two Sigma: Using News to Predict Stock Movements\nAt the stage 1, incorporate News data  provided by Thomson Reuters into Market data provided by Intrinio to \"predict\" historical stock movements.  \nTo evaluate the predictive ability of the model, I should submit a signed confidence value, $\\hat{y}_{ti} \\in [-1, 1]$. This is to say, if you expect a stock to have a large positive return--compared to the broad market--over the next ten days, you might assign it a large, positive confidence value (near 1.0), and vice versa. If unsure, you might assign it a value near zero.  \nTo simply this problem, I started with one stock with no missing values and the outcome as close stock price.  "},{"metadata":{"_uuid":"8f94d3ae9e44e5e957ba02e5e9b33c95f3d59dab"},"cell_type":"markdown","source":"## Packages for Market data and News data\n### A Python rookie, using references\n>1. [Andrew Lukyanenko](https://www.kaggle.com/artgor/eda-feature-engineering-and-everything)  \n>2. [duvallwh](https://www.kaggle.com/duvallwh/finding-and-removing-bad-open-values)\n>3. [Bruno G. do Amaral](https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data)  \n>4. [Peter](https://www.kaggle.com/pestipeti/simple-eda-two-sigma)  \n>5. [Ashish Patel(阿希什)](https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach) \n>6. [Aguiar](https://www.kaggle.com/jsaguiar/baseline-with-news)  \n>7. [skmisc.loess.loess](https://has2k1.github.io/scikit-misc/generated/skmisc.loess.loess.html)\n>8. [Locally Weighted Linear Regression (Loess)](https://xavierbourretsicotte.github.io/loess.html)"},{"metadata":{"trusted":true,"_uuid":"e33d2493734e020a3dacf1b9c9578b4e4bfe9df8"},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom datetime import datetime, timedelta\nimport lightgbm as lgb \nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\n\n# interactive plot by plotly\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n# for news data\nfrom wordcloud import WordCloud\n\n# loess/lowess \n# from skmisc import loess as skmloess\nfrom scipy.interpolate import interp1d\nimport statsmodels.api as sm\n\n## try pyGAM\n\n# not fully understand all packages yet\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\n\n# We've got a submission file!\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0597e9caf16e57f02cc1ece02b4946f075a6f2f3"},"cell_type":"markdown","source":"## Import data, Get Market and News training dataset "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"159d44af7df33a289d4e535e6222c18060e28512"},"cell_type":"markdown","source":"## EDA and Preliminary Model Fitting\n"},{"metadata":{"_uuid":"5cd0d7e99385859e7b3afcc7d8a00b7eadd10c0a"},"cell_type":"markdown","source":"### Market Data\n#### Introduction of Market Data\nThis dataset contains stock market performance over the past decade, including open/close price, volume on that day and etc.  \nAccording to the data description:\n> The data is stored and retrieved as Pandas dataframes in the Kernels environment. Columns types are optimized to minimize space in memory.  \n> The `returnsOpenNextMktres10` (float64): the next 10 days, **market-residualized** return, meaning that the movement of the market as a whole has been accounted for, leaving only movements inherent to the instrument. This is the target variable used in competition scoring.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Get the market data\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f24284f6b196a3b3065856db025991249f6df24"},"cell_type":"markdown","source":"#### Descriptive of Market Data"},{"metadata":{"trusted":true,"_uuid":"650b08c35fc980ddc7ed5586063c864c107f81ef"},"cell_type":"code","source":"# variables Market\nprint(\"Within Market data: time is always 22:00 UTC \\n assetCode is the unique ID \\n assetName is not unique and can be Unknown \\n \")\nprint(f'{market_train_df.shape[0]} samples and {market_train_df.shape[1]} features in the training market dataset.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a53e0e70d75ed570c4b8d7b0842021f37f12a85"},"cell_type":"code","source":"# summary statistics of market data\nmarket_train_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08ffdcbbff762ae8cb2ceecbd37d128f9fd932d5"},"cell_type":"code","source":"# missing data\nmarket_train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a802ba700480a5558881f68b10569154f3ef88d4"},"cell_type":"markdown","source":"`returnsOpenNextMktres10` has been  filtered such that it is always not null.  \nThis variable is directly associated with the outcome, the next 10 days **confidenceValue**, taking market residuals. "},{"metadata":{"trusted":true,"_uuid":"f33e53cdfe115618d22608d4109fc7efeeab75d4"},"cell_type":"code","source":"# Summary of raw target variable.\ntarget = market_train_df['returnsOpenNextMktres10']\nprint(f'The range of target: {target.min()}, {target.max()} ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9935a2749ef9bdf085fcce102b633f2e4c13a868"},"cell_type":"markdown","source":"#### Take a glimpse of \"close price\"\n20 stocks were chosen randomly by the assetCode. "},{"metadata":{"trusted":true,"_uuid":"f91bb62c70c3dcaf8e5adecab0bafb4837638d3b"},"cell_type":"code","source":"# \nnp.random.seed(1024)\n# count all unique assetName\nprint(market_train_df['assetName'].value_counts().head() )\n# whole unique name series 3511 \nprint(market_train_df['assetName'].nunique())\nprint(market_train_df['assetCode'].nunique())\n\n# 20 random stocks from market data\nprint(\"Assets once appeared in News must have assetName, Unknown means may not have News\")\n# names of stocks in pilot data\npilot = np.random.choice(market_train_df['assetCode'].unique(), 20)\nprint(pilot) # numpy.ndarray\n\n# select big company pilot, based on quantiles of volume and close price \n# .groupby('a')['b'].mean()\n# market_train_df['assetName'].unique()\n# [market_train_df.groupby('assetName')['close'].mean() >=50]\nprint(\"groupby assetName has dimension1 3780\")\npilot_df = market_train_df[(market_train_df['assetCode'].isin(pilot))]\n\n# setup empty df to save pilot data\ndata = []\ndata_big = []\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"728977a44ff66420ec40f6dde04af275aa5d9104"},"cell_type":"markdown","source":"##### Plot the closing price of 20 random stocks. "},{"metadata":{"trusted":true,"_uuid":"b62865ddbe0912a93478776e347161fc7ae10f05"},"cell_type":"code","source":"# create trace plot for big company \n\n# create trace plot for whole pilot \nfor asset in pilot:\n    asset_df = market_train_df[(market_train_df['assetCode'] == asset)]\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 20 random assets\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"379d57445657e14d4a617364df2463e96b7d3481"},"cell_type":"markdown","source":"#### Missingness in the Market Data\n1. Drop-out:  instruments leave this subset of data.   \n2. Left-censoring:  instruments enter this subset of data. \n3. Smooth lines for `MTD.N` and `ARTC.O`, which are abnormal. Intermittent missing data? Instruments entered, left and entered again. \n4. Might exist a lot of changes in instruments around 2008 to 2009.  \n5. Choose HES.N, because it does not have obvious missing values \n"},{"metadata":{"trusted":true,"_uuid":"bc683cd19c2df59f192c1ab3bf4d5f2018601bc1"},"cell_type":"code","source":"# how many days in total in this dataset\nprint(market_train_df['time'].nunique())\nprint(\"2498 days of market data\")\n\n# check MTD.N, ARTC.O\nMTDN = market_train_df[(market_train_df['assetCode'] == 'MTD.N')]['time']\nprint(MTDN.size)\nprint(MTDN.nunique())\nprint(MTDN[0])\nprint(MTDN[(MTDN.nunique() -1)]) \n# for ARTCO\nARTCO = market_train_df[(market_train_df['assetCode'] == 'ARTC.O')]['time']\nprint(ARTCO.size)\nprint(ARTCO.nunique())\nprint(ARTCO[0])\nprint(ARTCO[(ARTCO.nunique() -1)]) \n\n# this is what I mentioned as 3. Intermittent missing data\n\n# check the missing of HES.N\nHESN = market_train_df[(market_train_df['assetCode'] == 'HES.N')]['time']\nprint(HESN.size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e607e4d0067394dc4116c05dd8bd19595ed2a18d"},"cell_type":"markdown","source":"#### Model a stock close price with LOESS\n![HESS](https://i.ibb.co/yyjhPc2/hess.jpg)\nLocally-weighted polynomial regression (LOESS) to fit the HES.N   \n>1. LOESS uses a **kd tree** to divide the box (also called the initial cell or bucket) enclosing all the predictor data points into rectangular cells. The vertices of these cells are the points at which local least squares fitting is done.   \n>2. The default of LOESS is using **least-squares fitting** for **Gaussian** distribution of residuals,  \n>3. **frac** is the tuning parameter, the smoothing factor, as a fraction of the number of points to take into account. Should be in the range (0, 1]. The stock is about 10-year data. The smoothing factor 1/20 was chosen, indicating that about half a year of data was used to fitting one dot. (Compared with 1/5, 1/10, 1/40)\n>4. By default,  **locally-quadratic fitting**, the polynomial up to 2 at most.\n>5. **p** is the number of features. For this implementation in Python, p = 1.  \n>6. Features should be numerical.\n"},{"metadata":{"trusted":true,"_uuid":"1ab55757f81413873283c4b1fdf885eca99b8c87"},"cell_type":"code","source":"# a class of loess in skmisc\nx_hess = range(HESN.size)\ny_hess = market_train_df[(market_train_df['assetCode'] == 'HES.N')]['close']\nloess_sm = sm.nonparametric.lowess\n# hess_loess = loess_sm(y_hess, x_hess,frac=1/20)\nhess_loess_1 = loess_sm(y_hess, x_hess,frac=1/5, it = 3, return_sorted = False)\nhess_loess_2 = loess_sm(y_hess, x_hess,frac=1/10, it = 3, return_sorted = False)\nhess_loess_3 = loess_sm(y_hess, x_hess,frac=1/20, it = 3, return_sorted = False)\nhess_loess_4 = loess_sm(y_hess, x_hess,frac=1/40, it = 3, return_sorted = False)\n# TRY TO MAKE prediction with loess\n# unpack the lowess smoothed points to their values\n## lowess_x = list(zip(*hess_loess))[0]\n### lowess_y = list(zip(*hess_loess))[1]\n\n# run scipy's interpolation. There is also extrapolation I believe\n## f = interp1d(lowess_x, lowess_y, bounds_error=False)\n## x_hess_new = range(HESN.size, (HESN.size + 10))\n## y_hess_new = f(xnew)\n\n# plot the loess fitting\nplt.figure(figsize=(12,6))\nplt.scatter(x_hess,y_hess, facecolors = 'none', edgecolor = 'lightblue', label = 'HESS Close Price')\nplt.plot(x_hess,hess_loess_1,color = 'magenta', label = 'Loess, 0.2: statsmodel')\nplt.plot(x_hess,hess_loess_2,color = 'green', label = 'Loess, 0.1: statsmodel')\nplt.plot(x_hess,hess_loess_3,color = 'red', label = 'Loess, 0.05: statsmodel')\nplt.plot(x_hess,hess_loess_4,color = 'darkblue', label = 'Loess, 0.025: statsmodel')\n## plt.plot(xnew, ynew, color = 'red', label = 'Loess: Prediction')\nplt.legend()\nplt.title('HESS STOCK 2007 - 2016: Loess Regression')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d124ad4e48b56851697a1013c5b526d241e825b6"},"cell_type":"code","source":"### loess with skmloess\n## hess_loess_skm = skmloess.loess(x_hess, y_hess, weights = None, p = 1, family='gaussian', span = 0.1, degree=2)\n# hess_loess_fit = skmloess.loess.fit(hess_loess_skm)\n# print(hess_loess_skm)\n# plot\n# plt.figure(figsize=(12,6))\n# plt.scatter(x_hess,y_hess, facecolors = 'none', edgecolor = 'lightblue', label = 'HESS Close Price')\n# plt.plot(x_hess,hess_loess_fit,color = 'magenta', label = 'Loess: statsmodel')\n# plt.legend()\n# plt.title('HESS STOCK 2007 - 2016: Loess regression comparisons')\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"100ef2dcb33588b10a6f157b61fafb11326f6cb2"},"cell_type":"code","source":"# outliers in Market data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"433deee9e0d682aae2bf2f85cad7287ede20f0cc"},"cell_type":"code","source":"# choose ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec39bff1f35e391858de0885a7497a995a47049a"},"cell_type":"markdown","source":"### News data\n#### Introduction of News Data\nThe news data contains information at both the news article level and asset level (in other words, the table is intentionally not normalized), including timestamps, news id, headline, urgency, companyCount, assetCodes, assetName, relevance (a decimal number indicating the relevance of the news item to the asset. It ranges from 0 to 1.), sentimentClass (-1, 0, 1), sentimentNegative, sentimentNeutral and sentimentPositive. "},{"metadata":{"trusted":true,"_uuid":"b75889147f49912fe85adce8677c7641060d8551"},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53050f489ba8244c07061f5569102cbeed58b1ad"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"54b2ddaeb93270c6f8c2a006a73c421ed3ce5481"},"cell_type":"code","source":"news_train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7be8ed45e5ee66b6fd096c5cdff20f41f7dd62e7"},"cell_type":"code","source":"print(f'{news_train_df.shape[0]} samples and {news_train_df.shape[1]} features in the training news dataset.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e9885f3f0fbeadeff470144d5a4d5a2a4a3b6fb"},"cell_type":"markdown","source":"#### Word cloud of headlines of News Data\nThe file is too huge to work with text directly.  \n100,000 out of 9,328,750 headlines were chosen randomly.  \nI am still learning to figure out why this plot is not reproducible. "},{"metadata":{"trusted":true,"_uuid":"369329d7dc71ba366e41b2cc8a577b1fec3cdf7d"},"cell_type":"code","source":"# variables News\n# The file is too huge to work with text directly\nstop = set(stopwords.words('english'))\nnp.random.seed(1024)\n# \ntext = ' '.join(np.random.choice(news_train_df['headline'], 100000))\n# text = ' '.join(news_train_df['headline'].str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size=None, stopwords=stop, background_color='white',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in random selected headline')\nplt.axis(\"off\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d27d0b3e0fc164fe97805a9c357f652f1b646ac"},"cell_type":"markdown","source":"#### Missing Data in News Data"},{"metadata":{"trusted":true,"_uuid":"9172146a1044df9751b0ae71964bd07ae0b1dc1b"},"cell_type":"code","source":"# missing data, no missing data\nnews_train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39d6ac8283a6d14c5eef5129151ec2abb1d6c108"},"cell_type":"markdown","source":"Chose asset code from the first few rows and test if these could be matched to the market data. "},{"metadata":{"trusted":true,"_uuid":"bc5f43bc1efcaf1e15694b3db12656881ae3a653"},"cell_type":"code","source":"# Check match of news data and market data\nprint(\"CHDN.OQ\" in market_train_df['assetCode'])\nprint(\"0857.HK\" in market_train_df['assetCode'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a08ac80e85690dd7b38284623914b9acae7326ba"},"cell_type":"markdown","source":"It looks like there was no missing data in News data. However, we all know that there cannot be News reported on everyday for each asset.  In addition, asset codes in News Data did not match with the Market Data totally.  \nIntuitively, the news data should be very important to make the prediction. However, by reviewing the baseline results of others, the features from news were shown to be much less important than the previous trend of the stock. This indicates we might need to impute the news data, since no news is good news. If there was no news, the opinoins on this stock are likely to be neutral.  "},{"metadata":{"_uuid":"b0500ce6c825a968567ef01c0bf86d91d86dda40"},"cell_type":"markdown","source":"#### Process the News Data and Merge it to the Market Data\nRemove some columns.  \nUnstacking news. We need to merge with market data which has individual asset codes. Therefore, we are going to unstack each asset code and save the original index.  \nThere can be many News on a single date for the same asset, so we need to group this data.  "},{"metadata":{"trusted":true,"_uuid":"f37ecb69f6c2935d6a8f3eab4f783be9a8126c2c"},"cell_type":"code","source":"# transform the date\nnews_test = news_train_df\nnews_test['date'] = news_test.time.dt.date  # Add date column\nprint(news_test.head(3))\n\n## check unique days of news data\nprint(news_test['date'].nunique())\n\n## check days of news for one asset\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41e5177c41fd1220ea1519f6f8c30c8ec623d967"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}