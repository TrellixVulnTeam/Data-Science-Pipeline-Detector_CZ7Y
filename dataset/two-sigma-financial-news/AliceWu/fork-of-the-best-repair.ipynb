{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5363c3301fe77aeac413f57975e1759c5a6ae125"},"cell_type":"code","source":"import numpy as np\nimport lightgbm as lgb\nimport pandas as pd\nfrom kaggle.competitions import twosigmanews\nimport matplotlib.pyplot as plt\nimport random\nfrom datetime import datetime, date\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\npd.options.mode.chained_assignment = None\nfrom datetime import timedelta\n%matplotlib inline\nimport cufflinks as cf\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\ncf.go_offline()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"# official way to get the data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"079b1d2474f911283fc1b04e552f421af763fdad"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()\nprint(market_train_df['time'].head)\nprint(market_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a5f2fbd071df4c2a86b408fd1e8a719757ae4e6"},"cell_type":"code","source":"#import datetime as dt\n#from time import strftime\n#market_train_df['date'] = market_train_df['time'].dt.strftime('%Y-%m-%d')\n#import pytz\n#print(date(2010, 1, 1))\n\nmarket_train_df['date'] = market_train_df['time'].dt.strftime('%Y-%m-%d')\n#market_train_df['date'] = market_train_df['time'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\nprint(market_train_df['time'].dtype) \nprint(market_train_df['date'].dtype) \nmarket_train_df['time'] = market_train_df['time'].dt.date\nmarket_train_df = market_train_df.loc[market_train_df['time']>=date(2010, 1, 1)]\nprint(market_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d32557ee2362c74c025d50ded58985fac9635790"},"cell_type":"code","source":"#异常值修复\ndef sampleAssetData(assetCode, date, numDays):\n    d = datetime.strptime(date,'%Y-%m-%d')\n    start = d - timedelta(days=numDays)\n    end = d + timedelta(days=numDays)\n    return market_train_df[(market_train_df['assetCode'] == assetCode)\n                             & (market_train_df['time'] >= start.date())\n                             & (market_train_df['time'] <= end.date())].copy()\n\ndef updateRawReturns(assetData, indices):\n    rowsToUpdate1 = assetData[(assetData.index >= indices[0][0]) & (assetData.index <= indices[0][1])]\n    for index, row in rowsToUpdate1.iterrows():\n        market_train_df.loc[[index],['returnsClosePrevRaw1']] = assetData['close'].pct_change()\n        market_train_df.loc[[index],['returnsOpenPrevRaw1']] = assetData['open'].pct_change()\n    rowsToUpdate2 = assetData[(assetData.index >= indices[1][0]) & (assetData.index <= indices[1][1])]\n    for index, row in rowsToUpdate2.iterrows():\n        market_train_df.loc[[index],['returnsClosePrevRaw10']] = assetData['close'].pct_change(periods=10)\n        market_train_df.loc[[index],['returnsOpenPrevRaw10']] = assetData['open'].pct_change(periods=10)\n\ndef estimateMktresReturn(sampleData, mktresCol, index):\n    sampleData['ones'] = 1\n    sampleData.dropna(inplace=True)\n    rawCol = mktresCol.replace('Mktres','Raw')\n    A = sampleData[[rawCol,'ones']]\n    y = sampleData[mktresCol]\n    m, c = np.linalg.lstsq(A,y,rcond=-1)[0]\n    return c + m * market_train_df.loc[index,rawCol]\n\ndef updateMktresReturns(assetCode, assetData, indices):\n    # update range of values for returnsClosePrevMktres1 & returnsOpenPrevMktres1\n    sample1 = assetData[(assetData.index < indices[2][0]) | (assetData.index > indices[2][1])]\n    rowsToUpdate1 = assetData[(assetData.index >= indices[2][0]) & (assetData.index <= indices[2][1])]\n    for index, row in rowsToUpdate1.iterrows():\n        market_train_df.loc[[index],['returnsClosePrevMktres1']] = estimateMktresReturn(sample1,'returnsClosePrevMktres1',index)\n        market_train_df.loc[[index],['returnsOpenPrevMktres1']] = estimateMktresReturn(sample1,'returnsOpenPrevMktres1',index)\n    # update range of values for returnsClosePrevMktres10 & returnsOpenPrevMktres10\n    sample2 = assetData[(assetData.index < indices[3][0]) | (assetData.index > indices[3][1])]\n    rowsToUpdate2 = assetData[(assetData.index >= indices[3][0]) & (assetData.index <= indices[3][1])]\n    l = []\n    for index, row in rowsToUpdate2.iterrows():\n        market_train_df.loc[[index],['returnsClosePrevMktres10']] = estimateMktresReturn(sample2,'returnsClosePrevMktres10',index)\n        est = estimateMktresReturn(sample2,'returnsOpenPrevMktres10',index)\n        l.append(est)\n        market_train_df.loc[[index],['returnsOpenPrevMktres10']] = est\n    # update range of values for returnsOpenNextMktres10\n    rowsToUpdate3 = assetData[(assetData.index >= indices[4][0]) & (assetData.index <= indices[4][1])]\n    i = 0\n    for index, row in rowsToUpdate3.iterrows():\n        market_train_df.loc[[index],['returnsOpenNextMktres10']] = l[i]\n        i += 1\n        \ndef fixBadReturnData(assetCode, badDate, badIndex, badReturnDataRanges, dayWindow):\n    # store copy of bad data window\n    badDataWindow = sampleAssetData(assetCode,badDate,dayWindow)\n    badDataWindow.reset_index(inplace=True)\n    # store indices needed to update raw and mktres return data\n    newIdx = badDataWindow[badDataWindow['index'] == badIndex].index[0]\n    indices = [\n        # range of bad data for... returnsClosePrevRaw1 & returnsOpenPrevRaw1\n        [badIndex,badDataWindow.loc[newIdx+badReturnDataRanges[0],'index']],\n        # returnsClosePrevRaw10 & returnsOpenPrevRaw10\n        [badIndex,badDataWindow.loc[newIdx+badReturnDataRanges[1],'index']],\n        # returnsClosePrevMktres1 & returnsOpenPrevMktres1\n        [badIndex,badDataWindow.loc[newIdx+badReturnDataRanges[2],'index']],\n        # returnsClosePrevMktres10 & returnsOpenPrevMktres10\n        [badIndex,badDataWindow.loc[newIdx+badReturnDataRanges[3],'index']],\n        # returnsOpenNextMktres10\n        [badDataWindow.loc[newIdx+badReturnDataRanges[4],'index'],badDataWindow.loc[newIdx+badReturnDataRanges[5],'index']]\n    ]\n    badDataWindow.set_index('index',inplace=True)\n    # correct bad raw return data\n    updateRawReturns(badDataWindow,indices)\n    # estimate affected mktres return data\n    updateMktresReturns(assetCode,badDataWindow,indices)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"772a95bf98eee982778b8900922eb088fe6e0ea7","scrolled":true},"cell_type":"code","source":"# bad volume, open, and close for ZNGA.O on 2016-07-06\nassetCode = 'ZNGA.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 19213100\nmarket_train_df.loc[[badIndex],['open']] = 2.64\nmarket_train_df.loc[[badIndex],['close']] = 2.75\n# ranges of affected return data\n#   integers specify how many rows of data need to be updated for different return columns, in reference to \"badDate\" row\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for FLEX.O on 2016-07-06\nassetCode = 'FLEX.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 5406600\nmarket_train_df.loc[[badIndex],['open']] = 11.580\nmarket_train_df.loc[[badIndex],['close']] = 11.750\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for SHLD.O on 2016-07-06\nassetCode = 'SHLD.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 279300\nmarket_train_df.loc[[badIndex],['open']] = 12.8900\nmarket_train_df.loc[[badIndex],['close']] = 13.1400\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for MAT.O on 2016-07-06\nassetCode = 'MAT.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 3242100\nmarket_train_df.loc[[badIndex],['open']] = 32.13\nmarket_train_df.loc[[badIndex],['close']] = 31.52\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for BBBY.O on 2016-07-06\nassetCode = 'BBBY.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 4205500\nmarket_train_df.loc[[badIndex],['open']] = 42.23\nmarket_train_df.loc[[badIndex],['close']] = 43.55\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for DISH.O on 2016-07-06\nassetCode = 'DISH.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 2303300\nmarket_train_df.loc[[badIndex],['open']] = 50.06\nmarket_train_df.loc[[badIndex],['close']] = 51.33\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for NDAQ.O on 2016-07-06\nassetCode = 'NDAQ.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 733400\nmarket_train_df.loc[[badIndex],['open']] = 64.64\nmarket_train_df.loc[[badIndex],['close']] = 64.74\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for PCAR.O on 2016-07-06\nassetCode = 'PCAR.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 2394300\nmarket_train_df.loc[[badIndex],['open']] = 50.16\nmarket_train_df.loc[[badIndex],['close']] = 50.79\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)\n\n# bad volume, open, and close for PZZA.O on 2016-07-06\nassetCode = 'PZZA.O'\nbadDate = '2016-07-06'\nbadIndex = market_train_df[(market_train_df['assetCode'] == assetCode) & (market_train_df['date'] == badDate)].index[0]\n# correct bad data\nmarket_train_df.loc[[badIndex],['volume']] = 185100\nmarket_train_df.loc[[badIndex],['open']] = 67.86\nmarket_train_df.loc[[badIndex],['close']] = 67.91\n# ranges of affected return data\nbadReturnDataRanges = [1,10,20,20,-11,9]\n# sample data window (on either side of \"badDate\")\nsampleWindow = 45\n# fix bad return data in market_train_df\nfixBadReturnData(assetCode,badDate,badIndex,badReturnDataRanges,sampleWindow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9ea69c145a398493207e35c37b722512e70b5ad"},"cell_type":"code","source":"#排异\n#market_train_df = market_train_df[market_train_df.assetName !='Unknown']\nmarket_train_df = market_train_df[market_train_df.assetCode != 'PGN.N']\nmarket_train_df = market_train_df[market_train_df.assetCode != 'EBRYY.OB']\nprint(market_train_df.shape)\n#market_train_df = market_train_df[market_train_df.assetCode != 'TW.N']\nprint(market_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54bc00fc4d70ec3adb5a87bccb95ceeb25d48bd3"},"cell_type":"markdown","source":"#数据增强——缩放\nprint(market_train_df.columns.values.tolist())\nprint(market_train_df.shape)\nmarket_enhance_df = market_train_df[['open','close','time', 'assetCode','assetName', 'universe','volume' ]].sample(frac=0.5).copy()\n#print(market_enhance_df.dtype)\nprint(market_enhance_df['assetCode'].dtype)\nf = lambda x: x+\".E\"\n#df['browse_nodes'] = df['browse_nodes'].map(f)\nmarket_enhance_df['assetCode'] = market_enhance_df['assetCode'].map(f)\nprint(market_enhance_df['assetCode'].head())\n#market_enhance_df['assetCode'] = [ 'E. % s' % i for i in market_train_df['assetCode']]\n#market_enhance_df['assetCode']+\".E\"\nmarket_enhance_df['open'] = market_enhance_df['open'].map(lambda x: x/2)\n#market_enhance_df['open']/2\nmarket_enhance_df['close'] = market_enhance_df['open'].map(lambda x: x/2)\n#market_enhance_df['close']/2\nmarket_enhance_df['returnsClosePrevRaw1'] = market_enhance_df['close'].pct_change()\nmarket_enhance_df['returnsOpenPrevRaw1'] = market_enhance_df['open'].pct_change()\nmarket_enhance_df['returnsClosePrevRaw1'] = market_enhance_df['close'].pct_change(periods=10)\nmarket_enhance_df['returnsOpenPrevRaw1'] = market_enhance_df['open'].pct_change(periods=10)\nmarket_enhance_df['returnsClosePrevMktres1'] = 0\n# market_enhance_df['returnsOpenPrevMktres1'].fillna(0)\n# market_enhance_df['returnsClosePrevMktres10'].fillna(0)\n# market_enhance_df['returnsOpenPrevMktres10'].fillna(0)\n# market_enhance_df['returnsOpenNextMktres10'].fillna(0)\nprint(market_enhance_df.shape)\nmarket_train_df = market_train_df.append(market_enhance_df)\n\n\n# def estimateMktresReturn(sampleData, mktresCol, index):\n#     sampleData['ones'] = 1\n#     sampleData.dropna(inplace=True)\n#     rawCol = mktresCol.replace('Mktres','Raw')\n#     A = sampleData[[rawCol,'ones']]\n#     y = sampleData[mktresCol]\n#     m, c = np.linalg.lstsq(A,y,rcond=-1)[0]\n#     return c + m * market_train_df.loc[index,rawCol]\n\n# def updateMktresReturns(assetCode, assetData, indices):\n#     # update range of values for returnsClosePrevMktres1 & returnsOpenPrevMktres1\n#     sample1 = assetData[(assetData.index < indices[2][0]) | (assetData.index > indices[2][1])]\n#     rowsToUpdate1 = assetData[(assetData.index >= indices[2][0]) & (assetData.index <= indices[2][1])]\n#     for index, row in rowsToUpdate1.iterrows():\n#         market_train_df.loc[[index],['returnsClosePrevMktres1']] = estimateMktresReturn(sample1,'returnsClosePrevMktres1',index)\n#         market_train_df.loc[[index],['returnsOpenPrevMktres1']] = estimateMktresReturn(sample1,'returnsOpenPrevMktres1',index)\n#     # update range of values for returnsClosePrevMktres10 & returnsOpenPrevMktres10\n#     sample2 = assetData[(assetData.index < indices[3][0]) | (assetData.index > indices[3][1])]\n#     rowsToUpdate2 = assetData[(assetData.index >= indices[3][0]) & (assetData.index <= indices[3][1])]\n#     l = []\n#     for index, row in rowsToUpdate2.iterrows():\n#         market_train_df.loc[[index],['returnsClosePrevMktres10']] = estimateMktresReturn(sample2,'returnsClosePrevMktres10',index)\n#         est = estimateMktresReturn(sample2,'returnsOpenPrevMktres10',index)\n#         l.append(est)\n#         market_train_df.loc[[index],['returnsOpenPrevMktres10']] = est\n#     # update range of values for returnsOpenNextMktres10\n#     rowsToUpdate3 = assetData[(assetData.index >= indices[4][0]) & (assetData.index <= indices[4][1])]\n#     i = 0\n#     for index, row in rowsToUpdate3.iterrows():\n#         market_train_df.loc[[index],['returnsOpenNextMktres10']] = l[i]\n#         i += 1\n        "},{"metadata":{"trusted":true,"_uuid":"6cb3cfb24232319fcbfaf8fc3fc61ddb026d5668"},"cell_type":"code","source":"print(market_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9bbbeb3756a124f401e8df6549c27c1b4fbd55f"},"cell_type":"markdown","source":"#quant EDA\ndef generate_quant_df(market_train_df):\n    #EDA\n    market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open'] \n    #grouped = market_train_df.groupby('time').agg({'price_diff': ['std', 'min']}).reset_index()\n    #print(market_train_df.sort_values('price_diff')[:10])\n    \n    #Moving average\n    market_train_df['MA_7MA'] = market_train_df['close'].rolling(window=7).mean()\n    market_train_df['MA_15MA'] = market_train_df['close'].rolling(window=15).mean()\n    market_train_df['MA_30MA'] = market_train_df['close'].rolling(window=30).mean()\n    market_train_df['MA_60MA'] = market_train_df['close'].rolling(window=60).mean()\n\n    #Exponential Moving Average\n    ewma = pd.Series.ewm\n    market_train_df['close_30EMA'] = ewma(market_train_df[\"close\"], span=30).mean()\n\n    #MACD\n    market_train_df['close_26EMA'] = ewma(market_train_df[\"close\"], span=26).mean()\n    market_train_df['close_12EMA'] = ewma(market_train_df[\"close\"], span=12).mean()\n    market_train_df['MACD'] = market_train_df['close_12EMA'] - market_train_df['close_26EMA']\n    #market_train_df.drop(columns=['close_26EMA', 'close_12EMA'])\n    \n    #Bollinger Band\n    no_of_std = 2\n    #market_train_df['MA_7MA'] = market_train_df['close'].rolling(window=7).mean()\n    market_train_df['MA_7MA_std'] = market_train_df['close'].rolling(window=7).std() \n    market_train_df['MA_7MA_BB_high'] = market_train_df['MA_7MA'] + no_of_std * market_train_df['MA_7MA_std']\n    market_train_df['MA_7MA_BB_low'] = market_train_df['MA_7MA'] - no_of_std * market_train_df['MA_7MA_std']\n    #market_train_df.drop(columns=['MA_7MA_std'])\n    \n    market_train_df['MA_15MA_std'] = market_train_df['close'].rolling(window=15).std() \n    market_train_df['MA_15MA_BB_high'] = market_train_df['MA_15MA'] + no_of_std * market_train_df['MA_15MA_std']\n    market_train_df['MA_15MA_BB_low'] = market_train_df['MA_15MA'] - no_of_std * market_train_df['MA_15MA_std']\n\n    market_train_df['MA_30MA_std'] = market_train_df['close'].rolling(window=30).std() \n    market_train_df['MA_30MA_BB_high'] = market_train_df['MA_30MA'] + no_of_std * market_train_df['MA_30MA_std']\n    market_train_df['MA_30MA_BB_low'] = market_train_df['MA_30MA'] - no_of_std * market_train_df['MA_30MA_std']\n\n\n    #RSI\n    def rsiFunc(prices, n=14):\n        deltas = np.diff(prices)\n        seed = deltas[:n+1]\n        up = seed[seed>=0].sum()/n\n        down = -seed[seed<0].sum()/n\n        rs = up/down\n        rsi = np.zeros_like(prices)\n        rsi[:n] = 100. - 100./(1.+rs)\n\n        for i in range(n, len(prices)):\n            delta = deltas[i-1] # cause the diff is 1 shorter\n\n            if delta>0:\n                upval = delta\n                downval = 0.\n            else:\n                upval = 0.\n                downval = -delta\n\n            up = (up*(n-1) + upval)/n\n            down = (down*(n-1) + downval)/n\n\n            rs = up/down\n            rsi[i] = 100. - 100./(1.+rs)\n\n        return rsi\n    print(rsiFunc(market_train_df['close'].values, 6).dtype)\n    market_train_df['rsi_6'] = rsiFunc(market_train_df['close'].values, 6)\n    market_train_df['rsi_14'] = rsiFunc(market_train_df['close'].values, 14)\n    market_train_df['rsi_20'] = rsiFunc(market_train_df['close'].values, 20)\n\n    #Volume moving avreage\n    market_train_df['VMA_7MA'] = market_train_df['volume'].rolling(window=7).mean()\n    market_train_df['VMA_15MA'] = market_train_df['volume'].rolling(window=15).mean()\n    market_train_df['VMA_30MA'] = market_train_df['volume'].rolling(window=30).mean()\n    market_train_df['VMA_60MA'] = market_train_df['volume'].rolling(window=60).mean()\n    \n#generate_quant_df(market_train_df)"},{"metadata":{"trusted":true,"_uuid":"ae10d6a84619658ee14c3ed8c0ed25717e55f0f5"},"cell_type":"code","source":"from multiprocessing import Pool\n\ndef create_lag(df_code,n_lag=[3,7,14,],shift_size=1):\n    code = df_code['assetCode'].unique()\n    \n    for col in return_features:\n        for window in n_lag:\n            rolled = df_code[col].shift(shift_size).rolling(window=window)\n            lag_mean = rolled.mean()\n            lag_max = rolled.max()\n            lag_min = rolled.min()\n            lag_std = rolled.std()\n            df_code['%s_lag_%s_mean'%(col,window)] = lag_mean\n            df_code['%s_lag_%s_max'%(col,window)] = lag_max\n            df_code['%s_lag_%s_min'%(col,window)] = lag_min\n#             df_code['%s_lag_%s_std'%(col,window)] = lag_std\n    return df_code.fillna(-1)\n\ndef generate_lag_features(df,n_lag = [3,7,14]):\n    features = ['time', 'assetCode', 'assetName', 'volume', 'close', 'open',\n       'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n       'returnsOpenNextMktres10', 'universe']\n    \n    assetCodes = df['assetCode'].unique()\n    print(assetCodes)\n    all_df = []\n    df_codes = df.groupby('assetCode')\n    df_codes = [df_code[1][['time','assetCode']+return_features] for df_code in df_codes]\n    print('total %s df'%len(df_codes))\n    \n    pool = Pool(4)\n    all_df = pool.map(create_lag, df_codes)\n    \n    new_df = pd.concat(all_df)  \n    new_df.drop(return_features,axis=1,inplace=True)\n    pool.close()\n    \n    return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bd4c3ddba90f4b23e324eefabb98272689ac0ce"},"cell_type":"code","source":"# return_features = ['close']\n# new_df = generate_lag_features(market_train_df,n_lag = 5)\n# market_train_df = pd.merge(market_train_df,new_df,how='left',on=['time','assetCode'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d80bb484853e216761cf2e7e08c0e9b093c08505"},"cell_type":"code","source":"return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\nn_lag = [3,7,14]\nnew_df = generate_lag_features(market_train_df,n_lag=n_lag)\n#generate_quant_df(market_train_df)\nmarket_train_df = pd.merge(market_train_df,new_df,how='left',on=['time','assetCode'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b67955bcf92b534e101be7b8b6aa697869fb7db"},"cell_type":"code","source":"print(market_train_df.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc53bf017273aa8c59a0f2dabf80c70eeb20108b"},"cell_type":"code","source":"# return_features = ['open']\n# new_df = generate_lag_features(market_train_df,n_lag=[3,7,14])\n# market_train_df = pd.merge(market_train_df,new_df,how='left',on=['time','assetCode'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4681d35d83bf94c0b9e95904124902ef2153e3bc"},"cell_type":"code","source":"def mis_impute(data):\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"other\")\n        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data\n\nmarket_train_df = mis_impute(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b9aa2e280d60a66c006af63f78700861ef90698"},"cell_type":"code","source":"def data_prep(market_train):\n    lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n    market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n    market_train = market_train.dropna(axis=0)\n    return market_train\n\nmarket_train_df = data_prep(market_train_df)\n# # check the shape\nprint(market_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f947d36b6b6c986fcba9a7ccb4a71fd5e58021d0"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nup = market_train_df['returnsOpenNextMktres10'] >= 0\n\n\nuniverse = market_train_df['universe'].values\nd = market_train_df['time']\n\nfcol = [c for c in market_train_df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'date' , 'universe','sourceTimestamp']]\n\nX = market_train_df[fcol].values\nup = up.values\nr = market_train_df.returnsOpenNextMktres10.values\n\n# Scaling of X values\n# It is good to keep these scaling values for later\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)\n\n# Sanity check\nassert X.shape[0] == up.shape[0] == r.shape[0]\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\n\nX_train, X_test, up_train, up_test, r_train, r_test,u_train,u_test,d_train,d_test = model_selection.train_test_split(X, up, r,universe,d, test_size=0.25, random_state=99)\n\n\n# te = market_train_df['time']>date(2015, 1, 1)\n\n# tt = 0\n# for tt,i in enumerate(te.values):\n#     if i:\n#         idx = tt\n#         print(i,tt)\n#         break\n# print(idx)\n# # for ind_tr, ind_te in tscv.split(X):\n# #     print(ind_tr)\n# X_train, X_test = X[:idx],X[idx:]\n\n# up_train, up_test = up[:idx],up[idx:]\n# r_train, r_test = r[:idx],r[idx:]\n# u_train,u_test = universe[:idx],universe[idx:]\n# d_train,d_test = d[:idx],d[idx:]\n\n# train_data = lgb.Dataset(X_train, label=up_train.astype(int))\ntrain_data = lgb.Dataset(X, label=up.astype(int))\ntest_data = lgb.Dataset(X_test, label=up_test.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0f9657c977e8556be91af02d04b84afd4fb460f"},"cell_type":"code","source":"# these are tuned params I found\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\nx_2 = [0.19016805202090095, 2583, 213, 312, 220]\nprint(up_train)\ndef exp_loss(p,y):\n    y = y.get_label()\n#     p = p.get_label()\n    grad = -y*(1.0-1.0/(1.0+np.exp(-y*p)))\n    hess = -(np.exp(y*p)*(y*p-1)-1)/((np.exp(y*p)+1)**2)\n    \n    return grad,hess\n\nparams_1 = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n#         'objective': 'regression',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n#         'num_iteration': x_1[3],\n        'num_iteration': 239,\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\nparams_2 = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n#         'objective': 'regression',\n        'learning_rate': x_2[0],\n        'num_leaves': x_2[1],\n        'min_data_in_leaf': x_2[2],\n#         'num_iteration': x_2[3],\n        'num_iteration': 172,\n        'max_bin': x_2[4],\n        'verbose': 1\n    }\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5,\n#         fobj=exp_loss,\n        )\n\ngbm_2 = lgb.train(params_2,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5,\n#         fobj=exp_loss,\n        )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57f90489c498f068d2dc0a0bd7e8e8c138899ae0"},"cell_type":"code","source":"confidence_test = (gbm_1.predict(X_test) + gbm_2.predict(X_test))/2\nconfidence_test = (confidence_test-confidence_test.min())/(confidence_test.max()-confidence_test.min())\nconfidence_test = confidence_test*2-1\nprint(max(confidence_test),min(confidence_test))\n\n# calculation of actual metric that is used to calculate final score\nr_test = r_test.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = confidence_test * r_test * u_test\ndata = {'day' : d_test, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_test = mean / std\nprint(score_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cd0e0e8c5724f660e3095c6e2a3e8459afc7d6c"},"cell_type":"code","source":"import gc\ndel X_train,X_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ba5794894665dfc9ee492c60268bf073ca18c05"},"cell_type":"code","source":"#prediction\ndays = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\ntotal_market_obs_df = []\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    t = time.time()\n    market_obs_df['time'] = market_obs_df['time'].dt.date\n    \n    return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\n    total_market_obs_df.append(market_obs_df)\n    if len(total_market_obs_df)==1:\n        history_df = total_market_obs_df[0]\n    else:\n        history_df = pd.concat(total_market_obs_df[-(np.max(n_lag)+1):])\n    print(history_df)\n    \n    new_df = generate_lag_features(history_df,n_lag=[3,7,14])\n   #generate_quant_df(market_obs_df)\n    market_obs_df = pd.merge(market_obs_df,new_df,how='left',on=['time','assetCode'])\n    \n#     return_features = ['open']\n#     new_df = generate_lag_features(market_obs_df,n_lag=[3,7,14])\n#     market_obs_df = pd.merge(market_obs_df,new_df,how='left',on=['time','assetCode'])\n    \n    market_obs_df = mis_impute(market_obs_df)\n    \n    market_obs_df = data_prep(market_obs_df)\n    \n#     market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    \n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    \n    confidence = lp\n    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    \n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()\nsub  = pd.read_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}