{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# SOURCE: https://www.kaggle.com/rabaman/0-64-in-100-lines","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom kaggle.competitions import twosigmanews\nimport datetime\nimport time\n\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9a9948ee4506514d3a60f326a240d5385fa375a"},"cell_type":"code","source":"def prepare_market_data(market_df):\n    market_df['ratio'] = market_df['close'] / market_df['open']\n    market_df['average'] = (market_df['close'] + market_df['open'])/2\n    market_df['pricevolume'] = market_df['volume'] * market_df['close']\n\n    market_df.drop(['assetName', 'volume'], axis=1, inplace=True)\n\n    return market_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31a0bb989936aa84ee04a5c1875b002434d01e5d"},"cell_type":"code","source":"def prepare_news_data(news_df):\n    news_df['position'] = news_df['firstMentionSentence'] / news_df['sentenceCount']\n    news_df['coverage'] = news_df['sentimentWordCount'] / news_df['wordCount']\n\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence',\n                'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass',\n                'assetName', 'urgency','wordCount','sentimentWordCount']\n    news_df.drop(droplist, axis=1, inplace=True)\n\n    # create a mapping between 'assetCode' to 'news_index'\n    assets = []\n    indices = []\n    for i, values in news_df['assetCodes'].iteritems():\n        assetCodes = eval(values)\n        assets.extend(assetCodes)\n        indices.extend([i]*len(assetCodes))\n    mapping_df = pd.DataFrame({'news_index': indices, 'assetCode': assets})\n    del assets, indices\n    \n    # join 'news_train_df' and 'mapping_df' (effectivly duplicating news entries)\n    news_df['news_index'] = news_df.index.copy()\n    expanded_news_df = mapping_df.merge(news_df, how='left', on='news_index')\n    del mapping_df, news_df\n    \n    expanded_news_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return expanded_news_df.groupby(['time', 'assetCode']).mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc3429ea86c9b2b6461aaa577470bb9f9d3001df"},"cell_type":"code","source":"def prepare_data(market_df, news_df, start=None):\n    market_df['time'] = market_df['time'].dt.date\n    news_df['time'] = news_df['time'].dt.date\n    if start is not None:\n        market_df = market_df[market_df['time'] >= start].reset_index(drop=True)\n        news_df = news_df[news_df['time'] >= start].reset_index(drop=True)\n\n    market_df = prepare_market_data(market_df)\n    news_df = prepare_news_data(news_df)\n\n    # join news_df to market_df using ['assetCode', 'time']\n    return market_df.merge(news_df, how='left', on=['assetCode', 'time']).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52cbd905a6cf7e2a76efe39253cda26ae758cbe2"},"cell_type":"code","source":"(market_df, news_df) = env.get_training_data()\n\n# # TODO: remove this\n# market_df = market_df.tail(1_000_000)\n# news_df = news_df.tail(3_000_000)\n\nprint('preparing data...')\nstart = datetime.date(2009,1,1)\nmerged_df = prepare_data(market_df, news_df, start)\nprint('Ready!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95196a96b02667b4116333cf33e27917b3ae49b9"},"cell_type":"code","source":"train_columns = [x for x in merged_df.columns if x not in ['assetCode', 'time', 'returnsOpenNextMktres10']]\nX = merged_df[train_columns].values\ny = (merged_df.returnsOpenNextMktres10 >= 0).astype(int).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95680aa5ab0616bd6010afa64a1c952eeced5a4f"},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true,"_uuid":"78e986be35467a48d133625c46338635c64e277b"},"cell_type":"code","source":"import lightgbm as lgb\nimport random\nfrom sklearn.metrics import mean_squared_error\n\nt = time.time()\nprint ('Tune hyperparameters for lightgbm')\n\ntrain_set, val_set = lgb.Dataset(X_train, y_train), lgb.Dataset(X_test, y_test)\n\n# best_params = None\n# best_loss = 100\n# for _ in range(25):\n#     # generate params\n#     params = {\"objective\" : \"binary\",\n#           \"metric\" : \"binary_logloss\",\n#           \"num_leaves\" : random.choice([10, 25, 60, 75, 100]),\n#           \"max_depth\": -1,\n#           \"learning_rate\" : random.choice([0.1, 0.01, 0.08, 0.05, 0.001, 0.003]),\n#           \"bagging_fraction\" : random.choice([0.7, 0.8, 0.9, 0.95]),  # subsample\n#           \"feature_fraction\" : random.choice([0.7, 0.8, 0.9, 0.95]),  # colsample_bytree\n#           \"bagging_freq\" : 5,        # subsample_freq\n#           \"bagging_seed\" : 2018,\n#           \"verbosity\" : -1 }\n    \n#     lgbm_model = lgb.train(params, train_set, 2000, valid_sets=[train_set, val_set], early_stopping_rounds=100, verbose_eval=False)\n#     loss = mean_squared_error(lgbm_model.predict(X_test, num_iteration=lgbm_model.best_iteration), y_test.astype(float))\n\n#     if loss < best_loss:\n#         best_params = params\n#         best_loss = loss\n\nbest_params = {\n    'objective': 'binary', \n    'metric': 'binary_logloss', \n    'num_leaves': 75, \n    'max_depth': -1, \n    'learning_rate': 0.05, \n    'bagging_fraction': 0.9, \n    'feature_fraction': 0.9, \n    'bagging_freq': 5, \n    'bagging_seed': 2018, \n    'verbosity': -1\n}\n\nprint(f'Train again with the best params: {best_params}s')\nlgbm_model = lgb.train(best_params, train_set, 2000, valid_sets=[train_set, val_set], early_stopping_rounds=100, verbose_eval=2000)\n\nprint(f'Done, time = {time.time() - t}s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0275019aa470277eff9e9a6659fad50d92790d8a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfeat_importance = pd.DataFrame()\nfeat_importance[\"feature\"] = train_columns\nfeat_importance[\"gain\"] = lgbm_model.feature_importance(importance_type='gain')\nfeat_importance.sort_values(by='gain', ascending=False, inplace=True)\nplt.figure(figsize=(8,10))\nax = sns.barplot(y=\"feature\", x=\"gain\", data=feat_importance)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"928259cd8f084b567a2e8a862a068ef01e776a5e"},"cell_type":"markdown","source":"## Predict"},{"metadata":{"trusted":true,"_uuid":"fd08fc381b89b00faa003a49323df35cfe2f14ee"},"cell_type":"code","source":"print(\"generating predictions...\")\n\nfor market_df, news_df, pred_template_df in env.get_prediction_days():\n    test_df = prepare_data(market_df, news_df, start)\n    test_columns = [x for x in test_df.columns if x not in ['assetCode', 'time', 'returnsOpenNextMktres10']]\n    X_test = test_df[test_columns].values\n    preds = lgbm_model.predict(X_test, num_iteration=lgbm_model.best_iteration) * 2 - 1\n    preds_df = pd.DataFrame({'assetCode':test_df['assetCode'],'confidenceValue':preds})\n    env.predict(preds_df)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2f0eb67b231b5604cdc851e5e5ab20f559b07aa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}