{"cells":[{"metadata":{"_uuid":"5ffb21374c7cf4b98e7239045ef9bf312effee25"},"cell_type":"markdown","source":"# Using Market State and Financial News to Predict Stocks Movement\n## 1.  Introduction\nIn this [kaggle competition](https://www.kaggle.com/c/two-sigma-financial-news) we will predict how stocks will change based on the market state and news articles.  We will loop through a long series of trading days; for each day, we'll receive an updated state of the market, and a series of news articles which were published since the last trading day, along with impacted stocks and sentiment analysis.  We'll use this information to predict whether each stock will have increased or decreased ten trading days into the future.  \n\n**Evaluation details**: we must predict a signed confidence value,$\\hat{y}_{ti} \\in [-1,1]$, which is multiplied by the market-adjusted return of a given assetCode over a ten day window. If we expect a stock to have a large positive return--compared to the broad market--over the next ten days, we might assign it a large, positive confidenceValue (near 1.0). If we expect a stock to have a negative return, you might assign it a large, negative confidenceValue (near -1.0). If unsure, you might assign it a value near zero.\n\n$$x_t = \\sum_i \\hat{y}_{ti}  r_{ti}  u_{ti},$$\n\nwhere $r_{ti}$ is the 10-day market-adjusted leading return for day t for instrument i, and $u_{ti}$ is a 0/1 universe variable that controls whether a particular asset is included in scoring on a particular day.\n\nThe submission score is then calculated as the mean divided by the standard deviation of your daily xt values:\n$$\\text{score} = \\frac{\\bar{x}_t}{\\sigma(x_t)}.$$\nIf the standard deviation of predictions is 0, the score is defined as 0.\n\n"},{"metadata":{"_uuid":"225708f447eee93041881f9d6c3a3e890cb16718"},"cell_type":"markdown","source":"## 2. Load and explore the data \nFirst let's import the module and create an environment. According to the compition rules we must use custom kaggle.competitions.twosigmerfanews Python module to import the market and news data."},{"metadata":{"trusted":true,"_uuid":"a7bb41db36c1b0b03ec991d28f49cff171cb8515"},"cell_type":"code","source":"#Improt all the needed pacakges\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e2c60082acd1320883b6f3544cbb34b362e37fb"},"cell_type":"markdown","source":"## Import and explore the training data\nIn accordance with the competition rule we import the data with the custom module \"twosigmanews\". There are 4,072,956 rows and 16 columns in the maket training set and 9,328,750 rows with 35 columns in the news training set."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"78b1eb046eed1d32a3d51554c64fd8963415d3e4"},"cell_type":"code","source":"market_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7bacc97fb2115f16dd2616eff696c702c3ecce04"},"cell_type":"code","source":"news_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c639d07f69418010659ddf17fd0b30a532e8d0b7"},"cell_type":"code","source":"print(market_train_df.time.min())\nmarket_train_df_5years=market_train_df[market_train_df.time>'2011-12-30 22:00:00+0000']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20899c7239a40effe7dd9ab4dd17beeeb2bcd8cb"},"cell_type":"code","source":"market_train_df_5years.to_csv(\"market_2011_2016.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"873ee6d1c0c8f149e09abdf57022d7d36cd25f13"},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17fd0fa566b29c9e0f55e86954d2607fb7a11e80"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inlinemarket_train_df.info()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b42c6fa6f2ea28627d5ff00a7ae2331ca763aa6"},"cell_type":"markdown","source":"Check with the missing values. There are 4 features with missing values."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3f83e13aa4ff442261b0acfa5c7bf21823d67b8b"},"cell_type":"code","source":"#Deal with the missing number,fill the missing values as mean values,\nmissing_cols=['returnsClosePrevMktres1',\n              'returnsOpenPrevMktres1',\n              'returnsClosePrevMktres10',\n              'returnsOpenPrevMktres10']\n\nfor col in missing_cols:\n    market_train_df[col]=market_train_df[col].fillna(market_train_df[col].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f83518789298c74286d884edecf1006f9618274"},"cell_type":"code","source":"import datetimeprint(f'The market data start from {market_train_df[\"time\"].min()}, and end on {market_train_df[\"time\"].max()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"2895f504fdf488ffee910a9161768e1b5cab6226"},"cell_type":"code","source":"#Explore the data related to returns.\n#data = []\nreturn_terms=[\n             \"returnsClosePrevRaw1\",\n             \"returnsOpenPrevRaw1\",\n             \"returnsClosePrevMktres1\",\n             \"returnsOpenPrevMktres1\",\n             \"returnsClosePrevRaw10\",\n             \"returnsOpenPrevRaw10\",\n             \"returnsClosePrevMktres10\",\n             \"returnsOpenPrevMktres10\",\n             \"returnsOpenNextMktres10\"\n             ] \nfor  return_term in return_terms:\n    market_train_df[return_term]=market_train_df[return_term].clip(-1,1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9e06eb1e0c3f0fa7b0fb189136f573d746fcacd"},"cell_type":"markdown","source":"There are 9328750 rows with 35 features in the news train set."},{"metadata":{"_uuid":"a9194d649cfd2111038cfe710042b24d5e367b4a"},"cell_type":"markdown","source":"Find if there are any missing value in news_train_df. We are lucky that no missing value is found in news trainning data."},{"metadata":{"trusted":true,"_uuid":"e7c29bd86f7a20f6066b3f03b0402822d8303d0e"},"cell_type":"code","source":"print(f'The news data start from {news_train_df[\"time\"].min()}, and end on {news_train_df[\"time\"].max()}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"135e45c70617db5854f14aa46b7988197429f462"},"cell_type":"code","source":"headlineTag_dic = {k: v for v, k in enumerate(news_train_df['headlineTag'].unique())}\nprovider_dic = {k: v for v, k in enumerate(news_train_df['provider'].unique())}\nmarketCommentary_map = {False:0,True:1}\nnews_drop_col=['time','sourceTimestamp','assetName','headline','subjects','audiences']\n#news_train_df=news_train_df.sample(6000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f56bc3a72b4f1cad7475585af43fb929c70104b"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n#This function expands a row in to multiple rows from the list of assetcodes.\ndef expand(df, expand_column):\n    lens = []\n    d = {}\n    expands_list=[]\n    for i,item in df[expand_column].items():\n        expand=list(item[2:-2].split(\"\\', \\'\"))\n        lens.append(len(expand))\n        expands_list.extend(expand)        \n    d[expand_column] = expands_list\n    \n    #print(len(d[expand_column]))\n    #print(np.mean(lens))\n    for col in df.columns.values:\n        if col != expand_column:\n             d[col] = np.repeat(df[col].values, lens)\n    return pd.DataFrame(d)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34c393555fe254f72598be94ae4991f7f36c50fc"},"cell_type":"markdown","source":"## 2. Build a model without the content of the news as the baseline. "},{"metadata":{"_uuid":"81d5ed3838b2bc52613a73097af6531e85180716"},"cell_type":"markdown","source":"**2.1  Feature engineering**"},{"metadata":{"trusted":true,"_uuid":"35bc695b7e3fbaa6600911e7eee9aed4fddfe94c"},"cell_type":"code","source":"def prep_market(market_df):    \n    #print(\"Deal with the market data\")\n    market_df=market_df.drop(['assetName'],axis=1)\n    market_df[\"time\"]=pd.to_datetime(market_df[\"time\"])\n    market_df['time'] = market_df.time.dt.date\n    market_df['close_to_open'] = market_df['close'] / market_df['open'] \n    #print(f'The shape of market data is {market_df.shape}')\n    return market_df\n    \ndef prep_news(news_df):    \n    #print(\"Deal with the news data\")    \n    news_df['firstCreated']=pd.to_datetime(news_df['firstCreated'])\n    news_df=news_df.drop(news_drop_col,axis=1)\n    news_df['headlineTagT'] = news_df['headlineTag'].map(headlineTag_dic)    \n    news_df['provider'] = news_df['provider'].map(provider_dic)    \n    news_df['marketCommentary'] = news_df['marketCommentary'].map(marketCommentary_map)\n    #print('expand')\n    news_df=expand(news_df, \"assetCodes\")\n    #print('group')\n    #news_df = news_df.groupby(['firstCreated', 'assetCodes'], as_index=False).mean()\n    #print(f'The shape of news data is {news_df.shape}')\n    return news_df\n\ndef group_news(news_df):\n    #print('group')\n    news_df['firstCreated']=news_df['firstCreated'].dt.date\n    news_df = news_df.groupby(['firstCreated', 'assetCodes'], as_index=False).mean()\n    return news_df\n\ndef merge_market_news(market_df,news_df):    \n    market_and_news_df = pd.merge(market_df, news_df, left_on=['time', 'assetCode'], right_on=['firstCreated', 'assetCodes'])   \n    return market_and_news_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bff7964a6baefbb2ee790c30d1b4615801224e4"},"cell_type":"markdown","source":"**2.2  Traning and testing date splitting**"},{"metadata":{"trusted":true,"_uuid":"37ecd2bd2e7faf3bff4f32834f348d84b641ab65"},"cell_type":"code","source":"\nnews_train_df=prep_news(news_train_df)\nnews1=news_train_df[news_train_df['firstCreated']<=\"2009-12-31\"]\nnews2=news_train_df[(news_train_df['firstCreated']<=\"2012-12-31\")&(news_train_df['firstCreated']>\"2009-12-31\")]\nnews3=news_train_df[news_train_df['firstCreated']>\"2012-12-31\"]\ndel(news_train_df)\nnews1=group_news(news1)\nnews2=group_news(news2)\nnews3=group_news(news3)\nnews_train_df=pd.concat([news1,news2,news3],sort='False')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d408042cc72823123d995af1557b104202f6b90"},"cell_type":"code","source":"market_train_df=prep_market(market_train_df)\nmarket_news_train_df = merge_market_news(market_train_df, news_train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcb104cccfe99fc52862f06ecd5fccade9be6456"},"cell_type":"code","source":"features_col=['volume', 'close', 'open', 'returnsClosePrevRaw1','returnsOpenPrevRaw1', \n              'returnsClosePrevMktres1','returnsOpenPrevMktres1', 'returnsClosePrevRaw10',\n              'returnsOpenPrevRaw10', 'returnsClosePrevMktres10','returnsOpenPrevMktres10', \n              'close_to_open', 'urgency', 'takeSequence', 'provider',\n              'bodySize', 'companyCount', 'marketCommentary', 'sentenceCount','wordCount', \n              'firstMentionSentence', 'relevance', 'sentimentClass','sentimentNegative', \n              'sentimentNeutral', 'sentimentPositive','sentimentWordCount', 'noveltyCount12H', \n              'noveltyCount24H','noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n              'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D', 'volumeCounts7D','headlineTagT']\n\nfeatures_col_market=['volume', 'close', 'open', 'returnsClosePrevRaw1','returnsOpenPrevRaw1', \n                     'returnsClosePrevMktres1','returnsOpenPrevMktres1', 'returnsClosePrevRaw10',\n                     'returnsOpenPrevRaw10', 'returnsClosePrevMktres10','returnsOpenPrevMktres10', 'close_to_open']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbeaefc5e99f3c90ce40a473f2bd193e716062e4","trusted":true},"cell_type":"code","source":"UpOrDown = market_news_train_df.returnsOpenNextMktres10 >= 0\nUpOrDown = UpOrDown.values\nreturns = market_news_train_df.returnsOpenNextMktres10.values\nX=market_news_train_df[features_col].values\nmins_X = np.min(X, axis=0)\nmaxs_X = np.max(X, axis=0)\nrange_X = maxs_X - mins_X\nX = 1 - ((maxs_X - X) / range_X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d95a69d48f5d782cd2788abff65c439258006ea7"},"cell_type":"code","source":"UpOrDown_market = market_train_df.returnsOpenNextMktres10 >= 0\nUpOrDown_market = UpOrDown_market.values\nreturns_market = market_train_df.returnsOpenNextMktres10.values\nX_market=market_train_df[features_col_market].values\nmins_X_market = np.min(X_market, axis=0)\nmaxs_X_market = np.max(X_market, axis=0)\nrange_X_market = maxs_X_market - mins_X_market\nX_market = 1 - ((maxs_X_market - X_market) / range_X_market)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85ce22126110afcbbadcc959a8b6ace3371e3530"},"cell_type":"markdown","source":"**2.3  Buiding estimator with market and news data**"},{"metadata":{"trusted":true,"_uuid":"7ac8a9ff78427c5052addd9724f389fb0b0647d6"},"cell_type":"code","source":"import lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, UpOrDown_train, UpOrDown_test, returns_train, returns_test = model_selection.train_test_split(X, UpOrDown, returns, test_size=0.1, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2da23c35a260e17f1ea1896f76a7ee9b8e04d59d"},"cell_type":"code","source":"params = {'learning_rate': 0.05, 'max_depth': 5, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=UpOrDown_train), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train, label=UpOrDown_train), lgb.Dataset(X_test, label=UpOrDown_test)],\n                  verbose_eval=50, early_stopping_rounds=30)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e340c72ed4c62912d15ad862d2ed39378572e9c"},"cell_type":"markdown","source":"**2.3  Buiding estimator with only market data **"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"5eb1154fcd53355ef85a3502977a6396b600c1aa"},"cell_type":"code","source":"X_train_market, X_test_market, UpOrDown_train_market, UpOrDown_test_market, returns_train_market, returns_test_market = model_selection.train_test_split(X_market, UpOrDown_market, returns_market, test_size=0.1, random_state=99)\n\nparams = {'learning_rate': 0.05, 'max_depth': 5, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel_market = lgb.train(params, train_set=lgb.Dataset(X_train_market, label=UpOrDown_train_market), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train_market, label=UpOrDown_train_market), lgb.Dataset(X_test_market, label=UpOrDown_test_market)],\n                  verbose_eval=50, early_stopping_rounds=30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ebba2fb21dccd03b13d2d21a58597292bbcbd1b","trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'imp': model.feature_importance(), 'col':features_col})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndf.plot.bar(x='col',y='imp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e90e25341ac0a459ab5a56e6c043182fa98194e0"},"cell_type":"code","source":"df_market = pd.DataFrame({'imp': model_market.feature_importance(), 'col':features_col_market})\ndf_market = df_market.sort_values(['imp','col'], ascending=[True, False])\ndf_market.plot.bar(x='col',y='imp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"461de38cadd23b57802210ff4dd767e2b321c51c"},"cell_type":"code","source":"#Predect only use market data\n'''\ndays = env.get_prediction_days()\nimport time\nn_days = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')    \n    market_obs_df=prep_market(market_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live_market=market_obs_df[features_col_market].values\n    X_live_market=1-((maxs_X_market - X_live_market) / range_X_market)\n    lp_market = model_market.predict(X_live_market)\n    confidence_market = 2 * lp_market -1\n    preds_market= pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence_market})\n    predictions_template_df = predictions_template_df.merge(preds_market,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n\nenv.write_submission_file()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90f64669c0094e9c0c160d64f3616bf47e041a18"},"cell_type":"code","source":"\ndays = env.get_prediction_days()\nimport time\n\nn_days = 0\n\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    market_obs_df=prep_market(market_obs_df)\n\n    news_obs_df=prep_news(news_obs_df)\n    news_obs_df=group_news(news_obs_df)\n    market_news_obs_df = merge_market_news(market_obs_df, news_obs_df)\n    assetcode_set=set(market_news_obs_df['assetCode'].values)\n    X_live = market_news_obs_df[features_col].values\n    X_live = 1 - ((maxs_X - X_live) / range_X)        \n    lp = model.predict(X_live)\n    confidence = 2 * lp -1\n    preds = pd.DataFrame({'assetCode':market_news_obs_df['assetCode'],'confidence':confidence})\n    \n    market_only_obs_df=market_obs_df[~market_obs_df['assetCode'].isin(assetcode_set)]\n    X_live_market_only=market_only_obs_df[features_col_market].values\n    X_live_market_only=1-((maxs_X_market - X_live_market_only) / range_X_market)\n    lp_market_only = model_market.predict(X_live_market_only)\n    confidence_market_only = 2 * lp_market_only -1\n    preds_market_only= pd.DataFrame({'assetCode':market_only_obs_df['assetCode'],'confidence':confidence_market_only})\n    \n    preds_all=pd.concat([preds,preds_market_only],sort='False')\n    \n    predictions_template_df = predictions_template_df.merge(preds_all,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    \nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d38aa8a67cad3f0c105db7e764ec9b805db39ceb"},"cell_type":"code","source":"# We've got a submission file!\nimport os\nprint([filename for filename in os.listdir('.') if '.csv' in filename])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb5a471ff0ad67727858ce82ef97a746d325d0ef"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}