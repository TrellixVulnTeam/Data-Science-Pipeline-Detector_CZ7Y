{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom kaggle.competitions import twosigmanews\n\nenv = twosigmanews.make_env()\n(market_train, _) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.__version__","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"cat_cols = ['assetCode']\nnum_cols = ['volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1',\n                    'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10',\n                    'returnsOpenPrevMktres10']\n\nfrom sklearn.model_selection import train_test_split\n#train_indices, val_indices = train_test_split(market_train.index.values,test_size=0.95)\n#train_indices, val_indices = train_test_split(market_train.index.values,test_size=0.25)\ntrain_indices, val_indices = train_test_split(market_train.index.values,test_size=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74c9f5b9c0b1c27b815dd7dd29b2aaef49565e03"},"cell_type":"code","source":"# handle cat features\ndef encode(encoder, x):\n    len_encoder = len(encoder)\n    try:\n        ind = encoder[x]\n    except KeyError:\n        ind = len_encoder\n    return ind\n\nencoders = [{} for cat in cat_cols]\n\nfor i, cat in enumerate(cat_cols):\n    print('encoding %s'%cat, end='\\n')\n    encoders[i] = {l:ind for ind, l in enumerate(market_train[cat].unique())}\n    market_train[cat] = market_train[cat].apply(lambda x:encode(encoders[i],x))\n    \nembed_sizes = [len(encoder) + 1 for encoder in encoders]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6591bcb38de75fe4a57c4b73d161e79ec94be2c3"},"cell_type":"code","source":"# handle num features\nfrom sklearn.preprocessing import StandardScaler\nmarket_train[num_cols] = market_train[num_cols].fillna(0)\nscaler = StandardScaler()\nmarket_train[num_cols] = scaler.fit_transform(market_train[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fa4534866774c64728ba1c006097e9fe77c4848"},"cell_type":"code","source":"# Define NN\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization,LeakyReLU,Dropout,Average\nfrom keras.losses import binary_crossentropy, mse, mae\n\ncat_inputs = []\nfor cat in cat_cols:\n    cat_inputs.append(Input(shape=[1], name=cat))\n    \ncat_embs = []\nfor i,cat in enumerate(cat_cols):\n    cat_embs.append(Embedding(embed_sizes[i], 10)(cat_inputs[i]))\n\n#cat_logits = Concatenate()([Flatten()(cat_emb) for cat_emb in cat_embs])\ncat_logits = Flatten()(cat_embs[0])\ncat_logits = Dense(32)(cat_logits)\ncat_logits = LeakyReLU(0.1)(cat_logits)\ncat_logits = Dropout(0.5)(cat_logits)\nnum_input = Input(shape = (len(num_cols),), name='num')\nnum_logits = num_input\nnum_logits = BatchNormalization()(num_logits)\nnum_logits = Dense(32)(num_logits)\nnum_logits = LeakyReLU(0.1)(num_logits)\nnum_logits = Dropout(0.5)(num_logits)\nall_logits = Concatenate()([num_logits, cat_logits])\nlogits = Dense(128, activation='relu')(all_logits)\nlogits = Dropout(0.5)(logits)\nlogits = Dense(64, activation='relu')(logits)\nlogits = Dropout(0.5)(logits)\nout = Dense(1, activation='tanh')(logits)\n\n\nmodel = Model(inputs = cat_inputs+[num_input],outputs=out)\n#model.summary()\nmodel.compile(optimizer='adam', loss=mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"509c9cd57ce8d34313b18ba63e7ccd83a99ac329"},"cell_type":"code","source":"def get_input(market_train, indices):\n    X_num = market_train.loc[indices, num_cols].values\n    X = {'num':X_num}\n    for cat in cat_cols:\n        X[cat] = market_train.loc[indices, cat].values\n    market_train.loc[indices, 'returnsOpenNextMktres10'] = market_train.loc[indices, 'returnsOpenNextMktres10'].apply(lambda x: 0 if x < -0.3 or x > 0.3else x)\n    market_train.loc[indices, 'returnsOpenNextMktres10'] = market_train.loc[indices, 'returnsOpenNextMktres10'].apply(lambda x: -1 if x < 0 else x)\n    market_train.loc[indices, 'returnsOpenNextMktres10'] = market_train.loc[indices, 'returnsOpenNextMktres10'].apply(lambda x: 1 if x > 0 else x)\n    y = market_train.loc[indices, 'returnsOpenNextMktres10']\n    #y = market_train.loc[indices, 'returnsOpenNextMktres10'].apply(lambda x: 0 if x > 0.3 or x < -0.3 else x)\n    #y = y.apply(lambda x: (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))/0.3\n    y = y.values\n    r = market_train.loc[indices,'returnsOpenNextMktres10'].values\n    u = market_train.loc[indices, 'universe']\n    d = market_train.loc[indices, 'time'].dt.date\n    return X,y,r,u,d\n\n# r, u and d are used to calculate the scoring metric\nX_train,y_train,r_train,u_train,d_train = get_input(market_train, train_indices)\nX_valid,y_valid,r_valid,u_valid,d_valid = get_input(market_train, val_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b72f9d2eb951170033e516d177b948b7de20850e","scrolled":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\ncheck_point = ModelCheckpoint('model.hdf5', verbose=True, save_best_only=True)\nearly_stop= EarlyStopping(patience=2, verbose=True)\nmodel.fit(X_train, y_train,\n         validation_data = (X_valid, y_valid),\n         epochs = 4,\n         verbose = True,\n         callbacks=[check_point, early_stop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6ca05e0c11fa0cb8dc25f531408fc10ff8bf34e"},"cell_type":"markdown","source":"confidence_valid = model.predict(X_valid)[:,0]\n#r_valid = pd.Series(r_valid)\n#r_valid = r_valid.map(lambda x: 1 if x > 0 else -1)\n#r_valid = r_valid.values\nr_valid = r_valid.clip(-1,1)\nx_t_i = confidence_valid*r_valid*u_valid\ndata = {'day':d_valid, \n       'x_t_i':x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nprint('sr:',mean/std)"},{"metadata":{"trusted":true,"_uuid":"b136ef51a1223f5655f2293c93d4149ba44fe26e"},"cell_type":"code","source":"# Prediction\ndays = env.get_prediction_days()\n\nn_days = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days += 1\n    if n_days % 10 == 0:\n        print(n_days,end='\\n')\n    # num features\n    market_obs_df[num_cols] = market_obs_df[num_cols].fillna(0)\n    market_obs_df[num_cols] = scaler.transform(market_obs_df[num_cols])\n    X_num_test = market_obs_df[num_cols].values\n    X_test = {'num':X_num_test}\n    test_cat_cols = []\n    for i in range(len(cat_cols)):\n        market_obs_df[cat_cols[i]+'_encoded'] = market_obs_df[cat_cols[i]].astype(str).apply(lambda x: encode(encoders[i], x))\n        X_test[cat_cols[i]] = market_obs_df[cat_cols[i]+'_encoded']\n    market_prediction = model.predict(X_test)\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'], 'confidence':market_prediction.reshape(-1)})\n    predictions_template_df = predictions_template_df.merge(preds, how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\nenv.write_submission_file()\nprint('Done!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}