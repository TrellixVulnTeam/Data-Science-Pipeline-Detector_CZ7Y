{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Import some libraries\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # graphing\nimport os\nfrom datetime import datetime, timedelta # Used to subtract days from a date\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.\n\n# Import environment\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import training dataset\n(market_train_df, news_train_df) = env.get_training_data()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2cfcf7f70eaecc5d2e274e5b85e78f14df0b456"},"cell_type":"code","source":"# Process news data function\ndef process_news_date(news_train_df):\n    # Define which columns I don't want - I just used my intuition to select these columns\n    news_columns_to_drop = ['firstCreated','sourceId','headline','takeSequence','provider','subjects','audiences','bodySize','companyCount','headlineTag','sentenceCount','assetCodes','firstMentionSentence','noveltyCount12H','noveltyCount24H','noveltyCount3D','noveltyCount5D','noveltyCount7D','volumeCounts12H','volumeCounts24H','volumeCounts3D','volumeCounts5D','volumeCounts7D']\n    # Drop the columns chosen from above\n    news_train_df.drop(columns=news_columns_to_drop,inplace=True)\n    # Create sentiment word ratio from sentimentWordCount and wordCount <- i think this feature is helpful.\n    news_train_df['sentimentWordRatio'] = news_train_df['sentimentWordCount']/news_train_df['wordCount']\n    # Drop sentimentWordCount and wordCount since they are incorporated into the new column sentimentWordRatio now\n    news_columns_to_drop = ['wordCount','sentimentWordCount']\n    news_train_df=news_train_df.drop(columns=news_columns_to_drop)\n    #return the news dataframe\n    return news_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7836bca34da50d4478eacafde04bb62efc68725c"},"cell_type":"code","source":"# Separate 'date' into year,month, and day. Then, add year,month, and day to the 'assetName'.\n# Performing this will allow me to merge news & market data with this new 'combined_index' column\ndef combined_index(df):\n    df['combined_index'] = (df['time'].dt.year).astype(str)+(df['time'].dt.month).astype(str)+(df['time'].dt.day).astype(str)+(df['assetName']).astype(str)\n    return df\n\n# mergy market & news data by 'combined_index'\ndef merge_market_news(market_df,news_df):\n    # By having .mean(), it will take average of numeric values if there are duplicate news for the same 'combined_index'\n    news_df = news_df.groupby('combined_index').mean()\n    # merge news data to market data using the 'combined_index' we created\n    market_df=market_df.merge(news_df,how='left',on='combined_index')\n    # since there are more items in market data, ther are lots of rows with NaNs, and we fill them with 0 for training purposes.\n    fill_na_columns = ['urgency','marketCommentary','relevance','sentimentClass','sentimentNegative','sentimentNeutral','sentimentPositive','sentimentWordRatio']\n    market_df[fill_na_columns]=market_df[fill_na_columns].fillna(0)\n    return market_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68119642649da77ba42bb10ad7491eabb03ad539"},"cell_type":"code","source":"# Process news data\nnews_train_df=process_news_date(news_train_df)\n# Create 'combined_index' for news dataframe\nnews_train_df=combined_index(news_train_df).copy()\n# Create 'combined_index' for market dataframe\nmarket_train_df=combined_index(market_train_df).copy()\n# Merge market & news data\nmarket_train_df=merge_market_news(market_train_df,news_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6171ceff2e65d8a7998922afda1560036f6b1c7d"},"cell_type":"code","source":"# Pre-processes market data for training\ndef pre_process_market_data(market_train_df):\n    # Let's remove outliers based on our EDA. Remove anything outside [-1,1] for 'returnsOpenNextMktres10'\n    market_train_df = (market_train_df[(market_train_df['returnsOpenNextMktres10']<1) & (market_train_df['returnsOpenNextMktres10']>-1)]).copy()\n    # Let's choose our features\n    features = ['time','universe','volume','returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevRaw10','returnsOpenPrevRaw10','urgency','marketCommentary','relevance','sentimentClass','sentimentNegative','sentimentNeutral','sentimentPositive','sentimentWordRatio']\n    x = market_train_df[features].copy()\n    y = market_train_df[['returnsOpenNextMktres10','universe','time']].copy()\n    return x,y\n\n# Pre-processes market data for prediction for actual scoring. We are not provided with 'returnsOpenNextMktres10', hence no outlier removal is needed and we don't need to output target data.\ndef pre_process_market_data_actual_competition(market_train_df):\n    # Let's choose our features\n    features = ['volume','returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevRaw10','returnsOpenPrevRaw10','urgency','marketCommentary','relevance','sentimentClass','sentimentNegative','sentimentNeutral','sentimentPositive','sentimentWordRatio']\n    x = market_train_df[features]\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc0ed88b5bde83be684a70b4055845e03dd863fe"},"cell_type":"code","source":"x,y=pre_process_market_data(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d06bbc81bfb5905857f5392e33e48b23d812631f"},"cell_type":"code","source":"# Splits data for training. Takes out 30 days worth of data between training and validation set to prevent data leakage\ndef split_train_test_and_time(x,y,test_size):    \n    # Splits data as specified test_size and creates a gap of 30 days between train and test. This helps data leakage so that the model doesn't know the future when training\n    X_train = x[x['time']<(x['time'][int(len(x)*(1-test_size))]-timedelta(days=30))]\n    y_train = y[y['time']<(y['time'][int(len(x)*(1-test_size))]-timedelta(days=30))]\n    X_test = x[x['time']>x['time'][int(len(x)*(1-test_size))]]\n    y_test = y[y['time']>y['time'][int(len(y)*(1-test_size))]]   \n    # Features to be used\n    features_no_universe = ['volume','returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevRaw10','returnsOpenPrevRaw10','urgency','marketCommentary','relevance','sentimentClass','sentimentNegative','sentimentNeutral','sentimentPositive','sentimentWordRatio']\n    # Filters out data with universe==0\n    # X_train = X_train[X_train.universe==1]\n    # y_train = y_train[y_train.universe==1]  \n    # Save time for calculating score later. It is used to group and sum x_t values each day\n    train_time = X_train['time']\n    X_train = X_train[features_no_universe]\n    y_train = y_train['returnsOpenNextMktres10']    \n    # Filters out data with universe==0 for accurate scoring\n    X_test = X_test[X_test.universe==1]\n    y_test = y_test[y_test.universe==1]\n    # Save time for calculating score later. It is used to group and sum x_t values each day\n    test_time = X_test['time']\n    X_test = X_test[features_no_universe]\n    y_test = y_test['returnsOpenNextMktres10']   \n    return X_train,X_test,y_train,y_test,train_time,test_time\n\n# Draw graph of train vs eval scores. Visualize training process once it's done\ndef draw_train_eval_graph(evals_result,params):\n    x_axix = range(1,len(evals_result['train']['sigma_score'])+1)\n    train_sigma_score = evals_result['train']['sigma_score']\n    eval_sigma_score = evals_result['eval']['sigma_score']\n\n    plt.plot(x_axix,train_sigma_score,label='Train')\n    plt.plot(x_axix,eval_sigma_score,label='Eval')\n    plt.legend()\n    print(\"eta: \",params['eta'],\", max_depth: \",params['max_depth'])\n\n# This will display real target vs predictions. Kind of a sanity check..\ndef compare_real_target_with_pred(x,y):\n    # Compare predict and actual nextMKTres side by side\n    input_for_pred = xgb.DMatrix(x.values)\n    y_pred = bst.predict(input_for_pred,ntree_limit = bst.best_ntree_limit)\n    data  = {'y_real':y.values, 'y_pred': y_pred}\n    print(pd.DataFrame(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31e1273855597ed63320bd50f2f5aba4119bc3dc"},"cell_type":"code","source":"# sigma_score function is considered as a custom evaluation metric for xgboost\n# example of how custom evaluation function is incorporated into xgboost's training can be found here : https://github.com/dmlc/xgboost/blob/master/demo/guide-python/custom_objective.py\ndef sigma_score(preds,dval):\n    # get y_target values\n    labels = dval.get_label()\n    # call time parameter to be used for grouping, so that we can add x_t values for each day\n    df_time = dval.params['extra_time']\n    # instead of making any prediction above 0 as 1, I chose anything above the mean of predictions (I call it market average) to be 1\n    preds[preds>preds.mean()]=1\n    # anything between market average(prediction mean) and 0 were given 0. \n    preds[(preds<=preds.mean())&(preds>=0)]=0\n    # any asset giving negative return...... -1 \n    preds[preds<0]=-1\n    # I assume you can take below approach too\n    #preds[preds>0]=1\n    #preds[preds<=0]=-1\n    \n    #calculate x_t and score as specified by the competition\n    x_t = pd.Series(preds*labels)\n    x_t_sum = x_t.groupby(df_time).sum()    \n    score = (x_t_sum.mean())/(x_t_sum.std())\n    return 'sigma_score', round(score,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1af854b998b9d6851cedc6e99712340c2163a657"},"cell_type":"code","source":"import xgboost as xgb\n\n# remember, this is not train_test_split from sklearn. This is my own function. It devides data with 30 days gap and doesn't allow the model to look into the future.\nX_train,X_val,y_train,y_val,train_time,val_time=split_train_test_and_time(x,y,test_size=0.2)\n\n# Define datasets that xgboost accepts\nxgtrain = xgb.DMatrix(X_train.values,y_train.values)\nxgval = xgb.DMatrix(X_val.values,y_val.values)\n\n# We will 'inject' an extra parameter in order to have access to df_valid['time'] inside sigma_score without globals\nxgtrain.params = {'extra_time': train_time.factorize()[0]}\nxgval.params = {'extra_time': val_time.factorize()[0]}\n\n# define parameters. I found learning rate of 0.3 and max_depth of 6 to be suitable.\nparams ={'eta':0.5, 'max_depth':5,'objective':'reg:linear','silent':1,'eval_metric':'rmse'}\n# this allows cross validation. Make sure eval data is the latter one, so that the model will do an early stopping if eval data's sigma score doesn't increase.\n# We want the training to stop when eval data's sigma score doesn't increase so that we don't overfit our model to the training data\nevallist = [(xgtrain,'train'),(xgval,'eval')]\n# Save evaluation metric scores for displaying later\nevals_result = {}\n# perform 400 rounds at maximum if early stopping doesn't happen\nnum_round = 400\n# here, one thing to note is that our custom evaluation function 'sigma_score' is passed into 'feval'.\nbst = xgb.train(params,xgtrain,num_round,evallist,evals_result=evals_result,feval=sigma_score,maximize=True,early_stopping_rounds=50,verbose_eval=10)\n# # If early stopping is enabled during training, you can get predictions from the best iteration by using this-> y_test_pred = bst.predict(xgtest,ntree_limit = bst.best_ntree_limit)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90e079a35a79067c90edf79efad3fce8dbf4657f"},"cell_type":"code","source":"# Compare predict and actual nextMKTres side by side\ncompare_real_target_with_pred(X_val,y_val)\n\n# Compare predict and actual nextMKTres side by side\ncompare_real_target_with_pred(X_train,y_train)\n\ndraw_train_eval_graph(evals_result,params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceba89381c5a7041211ae9e8802f33ef627e9d7a"},"cell_type":"code","source":"# Use functions defined previously to process data for the final submission\ndef make_my_confidence_predictions(market_obs_df,predictions_template_df):#, news_obs_df, predictions_template_df):\n    x=pre_process_market_data_actual_competition(market_obs_df).copy()\n    x = xgb.DMatrix(x.values)\n    predictions_template_df.confidenceValue = bst.predict(x,ntree_limit = bst.best_ntree_limit)\n    predictions_template_df.confidenceValue[predictions_template_df.confidenceValue>predictions_template_df.confidenceValue.mean()]=1\n    predictions_template_df.confidenceValue[(predictions_template_df.confidenceValue<=predictions_template_df.confidenceValue.mean())&(predictions_template_df.confidenceValue>=0)]=0\n    predictions_template_df.confidenceValue[predictions_template_df.confidenceValue<0]=-1\n    return predictions_template_df\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days():    \n    # Process news data\n    news_obs_df=process_news_date(news_obs_df)\n    # Truncate date so that both news and market can be combined\n    news_obs_df=combined_index(news_obs_df).copy()\n    # Truncate date so that both news and market can be combined\n    market_obs_df=combined_index(market_obs_df).copy()\n    market_obs_df=merge_market_news(market_obs_df,news_obs_df)\n    market_obs_df=pre_process_market_data_actual_competition(market_obs_df)\n    \n    predictions_df = make_my_confidence_predictions(market_obs_df, predictions_template_df)\n    env.predict(predictions_df)\nprint('Done!')\n# Write submission file    \nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}