{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nfrom kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"034e7ec6f8990f8b360b79e52b790fc5eb900869"},"cell_type":"markdown","source":"Pre process market data"},{"metadata":{"trusted":true,"_uuid":"5bb5e18c0d882dc6c76ec6cb580decadd9db5a76"},"cell_type":"code","source":"def market_process(market_train_df):\n    \n    market_train_df['time'] = market_train_df.time.dt.date\n    market_train_df['bartrend'] = market_train_df['close'] / market_train_df['open']\n    market_train_df['average'] = (market_train_df['close'] + market_train_df['open'])/2\n    market_train_df['pricevolume'] = market_train_df['volume'] * market_train_df['close']\n    \n    # drop nans or not?\n    market_train_df.dropna(axis=0, inplace=True)\n    market_train_df.drop('assetName', axis=1, inplace=True)\n    \n    #market_train_df.columns = pd.Index([\"{}_{}\".format(e[0], e[1]) for e in market_train_df.columns.tolist()])\n    #market_train_df.reset_index(inplace=True)\n    # Set datatype to float32\n    float_cols = {c: 'float32' for c in market_train_df.columns if c not in ['assetCode', 'time','assetName']}\n    \n    return market_train_df.astype(float_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d61fbad2a95f3f7e1b67ec77353b1728df5e66f4"},"cell_type":"code","source":"    market_train_df = market_process(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10f2f0120466af547bbaa16e18310a0f2f50353c"},"cell_type":"markdown","source":"Add new features to market data"},{"metadata":{"trusted":true,"_uuid":"e7492a4c35d6e04795304d799e95353855ba88be"},"cell_type":"code","source":"def analysis_get_features(market_data, byday=False, trainInfo=None):\n    # for full training set feature creation\n    if(not byday):\n        # assign uids to each asset \n        uAssestCode = pd.unique(market_data.assetCode)    \n        uidList     = np.linspace(1.0, uAssestCode.shape[0], num=uAssestCode.shape[0])\n\n        # feature 0 - map from assetCode to uid    \n        uidMap = {}\n        for A, B in zip(uAssestCode, uidList):\n            uidMap[A] = B\n\n        aUID = np.zeros(market_data.shape[0])\n        for i, item in enumerate(market_data.assetCode):\n            aUID[i] = uidMap[item]\n\n        # feature 1, 2 - gain, gainb    \n        gain  = market_data.close - market_data.open    \n        gainb = np.zeros(gain.shape[0])\n        # classify\n        gainb[gain > 0] = 1\n\n        # feature 3 - volumeb\n        v   = market_data.volume\n        npv = np.array(v)    \n        vbins, ved = np.histogram(v, bins=20)\n        volumeb    = np.zeros(v.shape[0])\n\n        # create classes for bins\n        for i in range(1, ved.shape[0] - 1): \n            volumeb[np.logical_and(ved[i] < npv, npv < ved[i+1])] = i\n\n        # features to dataframe\n        #Xdict = {1: aUID, 2: gain, 3: gainb, 4: volumeb}\n        Xdict = {1: gain, 2: gainb, 3: volumeb}\n        X     = pd.DataFrame(Xdict)\n        \n        # save off training information\n        trainInfo = (uidList, uidMap, ved)\n        \n    # for one off feature creation\n    else:                \n        # feature 0\n        auid = np.zeros(market_data.assetCode.shape[0])\n        for i, assetCode in enumerate(market_data.assetCode):\n            # look for uid\n            if assetCode in trainInfo[1]:\n                uid = trainInfo[1][assetCode]\n            else:\n                # if its a new asset code create a new uid\n                newUID = trainInfo[0].max() + 1\n                np.append(trainInfo[0], newUID)\n                \n                # update dict\n                trainInfo[1][assetCode] = newUID\n                uid = newUID\n                \n            # set uid\n            auid[i] = uid\n        \n        # feature 1, 2 - gain, gainb\n        gain  = market_data.close - market_data.open    \n        gainb = np.zeros(gain.shape[0])\n        # classify\n        gainb[gain > 0] = 1\n        \n        # feature 3 - volumeb\n        v   = market_data.volume\n        npv = np.array(v)    \n        # TODO consider using the same bin alignment as the training data\n        # it may be better to leave it as-is; it would be proportionate\n        # ved = trainInfo[2][i]\n        vbins, ved = np.histogram(v, bins=20)\n        volumeb    = np.zeros(v.shape[0])\n\n        # create classes for bins\n        for i in range(1, ved.shape[0] - 1): \n            volumeb[np.logical_and(ved[i] < npv, npv < ved[i+1])] = i\n                \n        # features to dataframe\n        #Xdict = {1: auid, 2: gain, 3: gainb, 4: volumeb}\n        Xdict = {1: gain, 2: gainb, 3: volumeb}\n        X     = pd.DataFrame(Xdict)\n    \n    return X, trainInfo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dd9b1eb9393f3ce4c55d8fcea3413ac7cc2ffb7"},"cell_type":"code","source":"features, trainInfo = analysis_get_features(market_train_df)\n#features.shape: (3979902, 3)\n#3 new features created from the existing data\n#start looking at Andrew's code from Training function","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a387a4ce4ecfeacf2e223e8734436b1f60386150"},"cell_type":"markdown","source":"Merge the new features to market_train_df"},{"metadata":{"trusted":true,"_uuid":"f579c259ecdd26edfa3e2d782ae44a2289451aa3"},"cell_type":"code","source":"#New column names to be gain gainb volumeb\nmarket_train_df = market_train_df.assign(gain=features[1].values, gainb = features[2].values, volumeb = features[3].values)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2954791687761ee1a9ab96e8bcbb7c9b53d632ea"},"cell_type":"markdown","source":"Pre processing news data"},{"metadata":{"trusted":true,"_uuid":"74f39b65d093cf026e60ffa8eb448668bed8d85b"},"cell_type":"code","source":"def news_process(news_train_df):\n    \n    news_train_df['time'] = news_train_df.time.dt.date\n    news_train_df['position'] = news_train_df['firstMentionSentence'] / news_train_df['sentenceCount']\n    news_train_df['coverage'] = news_train_df['sentimentWordCount'] / news_train_df['wordCount']\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',\n            'firstMentionSentence','headlineTag','marketCommentary','subjects','audiences',\n            'assetName','noveltyCount12H','noveltyCount24H','noveltyCount3D','noveltyCount5D',\n            'noveltyCount7D','urgency','sentimentClass']\n    news_train_df.drop(droplist, axis=1, inplace=True)\n    \n    # Factorize categorical columns\n#     for col in ['headlineTag', 'provider', 'sourceId']:\n#         news_train[col], uniques = pd.factorize(news_train[col])\n#         del uniques\n    \n    # Remove {} and '' from assetCodes column\n    news_train_df['assetCodes'] = news_train_df['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n    return news_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfd8ca32c642913808f6b00e5a32c04423156d8e"},"cell_type":"code","source":"news_train_df = news_process(news_train_df)\n#news_train_df.shape(9328750, 35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff597fa172e7baf4a2d62dd2931df02abd223eda"},"cell_type":"code","source":"def unstack_asset_codes(news_train_df):\n    codes = []\n    indexes = []\n    for i, values in news_train_df['assetCodes'].iteritems():\n        explode = values.split(\", \")\n        codes.extend(explode)\n        repeat_index = [int(i)]*len(explode)\n        indexes.extend(repeat_index)\n    index_df = pd.DataFrame({'news_index': indexes, 'assetCode': codes})\n    del codes, indexes\n    gc.collect()\n    return index_df\n\nindex_df = unstack_asset_codes(news_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d134a2fa48d287f5fdec3fe1c8d38c313e2fab65"},"cell_type":"code","source":"def merge_news_on_index(news_train_df, index_df):\n    news_train_df['news_index'] = news_train_df.index.copy()\n\n    # Merge news on unstacked assets\n    news_unstack_df = index_df.merge(news_train_df, how='left', on='news_index')\n    news_unstack_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return news_unstack_df\n\nnews_unstack_df = merge_news_on_index(news_train_df, index_df)\ndel news_train_df, index_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb46090cf965908d7393aa257714dae9325a8f3"},"cell_type":"code","source":"news_unstack_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96bae035eccf974c074a7c4f4fc0fdaec109c6cd"},"cell_type":"code","source":"def group_news(news_frame):\n    \n    aggregations = ['mean']\n    gp = news_frame.groupby(['assetCode', 'time']).agg(aggregations)\n    gp.columns = pd.Index([\"{}_{}\".format(e[0], e[1]) for e in gp.columns.tolist()])\n    gp.reset_index(inplace=True)\n    # Set datatype to float32\n    float_cols = {c: 'float32' for c in gp.columns if c not in ['assetCode', 'time']}\n    return gp.astype(float_cols)\n\nnews_agg_df = group_news(news_unstack_df)\ndel news_unstack_df; gc.collect()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff9c308970c24fef12c9421bebf8316d56d6316c"},"cell_type":"code","source":"def merge(market_train_df,news_agg_df):\n    \n    df = market_train_df.merge(news_agg_df, how='left', on=['time','assetCode'])\n    # drop nans or not?\n    df.dropna(axis=0, inplace=True)\n    \n    del market_train_df, news_agg_df\n    return df\n\ndf = merge(market_train_df,news_agg_df)\ngc.collect()\n#df.shape (1121521, 37)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7049abf5fef34548f26f525de9e194aca3401f8f"},"cell_type":"code","source":"time = df.time\nnum_target = df.returnsOpenNextMktres10.astype('float32')\nbin_target = (df.returnsOpenNextMktres10 >= 0).astype('int8')\nuniverse = df.universe.astype('int8')\n# Drop columns that are not features\ndf.drop(['returnsOpenNextMktres10', 'universe', 'assetCode', 'time'], axis=1, inplace=True)\ngc.collect()\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f21e77714259c648098ec3dae465b77d43f1f14"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(df, bin_target, test_size = 0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eba40f1d413680f394e7e48c02b7a41e6c8f5e33"},"cell_type":"code","source":"from mlxtend.feature_selection import ColumnSelector\n\n# col_selector = ColumnSelector(cols=('gain','gainb','volumeb'))\n# col_selector.fit(X) # optional, does not do anything\n# col_selector.transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"554aa58dd06059bea9b2cee9c7b12319e44e52a6"},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn import svm\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nclf1 = LogisticRegression(random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6375f644f173cd42f2c8020914f85f6c56d20bfb"},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nclf2 = LGBMClassifier(\n    objective='binary',\n    boosting='gbdt',\n    learning_rate = 0.05,\n    max_depth = 8,\n    num_leaves = 80,\n    n_estimators = 400,\n    bagging_fraction = 0.8,\n    feature_fraction = 0.9)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41d84faa33f56d94c8eddb9f40391c04d9cbba58"},"cell_type":"code","source":"# svc linear \npipe3 = make_pipeline(ColumnSelector(cols=('gain','gainb','volumeb')), MinMaxScaler(),\n                      svm.LinearSVC())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c85336c18d3280828e3d943c8463b848e0af05b5"},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19315aa9feb38920982e2ddbede9d8a91e58fa00"},"cell_type":"code","source":"# for clf in (clf1, clf2):\n#     print(\"Model fit start\")\n#     clf.fit(X_train, y_train)\n#     print(\"Model fitted\")\n#     print(\"------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7b3814462ef878be28ecf836a1860c17772c912"},"cell_type":"code","source":"print(\"Model fit start\")\nclf1.fit(X_train, y_train)\nprint(\"Model fitted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e80d7738cb7fa2a523f42b84d3bb254daed7b9"},"cell_type":"code","source":"y1_pred = clf1.predict(X_test)\nprint('accuracy Logistic Regression:', np.mean(y_test == y1_pred))\nscore_1 = f1_score(y1_pred, y_test)\nprint('f score Logistic Regression:{}'.format(score_1))\n# accuracy Logistic Regression: 0.5121909899467243\n# f score Logistic Regression:0.5141512366235957","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62ef1f2fe4ea99efe615c6d5b540e055f0a94eaa"},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y1_pred)\n\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Logistic Regression classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bab7d809d3aaf292d17fabd643f8ecdc0afc2ad7"},"cell_type":"code","source":"print(\"Model fit start\")\npipe3.fit(X_train, y_train)\nprint(\"Model fitted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75309aa16116eb7e3a652b3893ca24fd027b3348"},"cell_type":"code","source":"pipe3_pred = pipe3.predict(X_test)\nprint('accuracy SVC Linear:', np.mean(y_test == pipe3_pred))\nscore_2 = f1_score(pipe3_pred, y_test)\nprint('f score SVC Linear:{}'.format(score_2))\n\n# accuracy SVC Linear: 0.5095472682285281\n# f score SVC Linear:0.6558187409856991","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7bb06ccbaf21f446302fc6035d78993a77426f9"},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, pipe3_pred)\n\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for SVC Linear classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40cfd029ad36bd70f518d59e57703080bdb07c6e"},"cell_type":"code","source":"# Train and Test DF without new extracted features\nX_train_temp = X_train.loc[:, X_train.columns != 'gain']\nX_train_temp = X_train_temp.loc[:, X_train_temp.columns != 'gainb']\nX_train_temp = X_train_temp.loc[:, X_train_temp.columns != 'volumeb']\n# X_train_temp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1915088b3fa1b0a622385d9f69ed42219dad9a8"},"cell_type":"code","source":"# Train and Test DF without new extracted features\nX_test_temp = X_test.loc[:, X_test.columns != 'gain']\nX_test_temp = X_test_temp.loc[:, X_test_temp.columns != 'gainb']\nX_test_temp = X_test_temp.loc[:, X_test_temp.columns != 'volumeb']\n# X_test_temp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89c6d37f18af7cebc798fb495d9cee0377c3783c"},"cell_type":"code","source":"print(\"Model fit start\")\nclf2.fit(X_train, y_train)\nprint(\"Model fitted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"827f4223ac8c15e80078a7193b1cd1268b4842b6"},"cell_type":"code","source":"y2_pred = clf2.predict(X_test)\nprint('accuracy LGBM:', np.mean(y_test == y2_pred))\nscore_2 = f1_score(y2_pred, y_test)\nprint('f score LGBM:{}'.format(score_2))\n# accuracy LGBM: 0.5495374601547001\n# f score LGBM:0.5739453100293057","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"153f5b9593e7328bc7449e29387ac99cb4e9b65d"},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y2_pred)\n\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for LGBM classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df606c41948d52fb3bccbe6805bbd2ba73a2ffd8"},"cell_type":"code","source":"from mlxtend.classifier import EnsembleVoteClassifier\nimport copy\neclf = EnsembleVoteClassifier(clfs=[clf1, pipe3, clf2], weights=[1,2,2], refit = False)\n\nlabels = ['Logistic Regression', 'SVC Linear', 'LGBM', 'Ensemble']\n\neclf.fit(X_train, y_train)\neclfY = eclf.predict(X_test)\nprint('accuracy ECLF:', np.mean(y_test == eclfY))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56752a452fd76a0edbb3d29de0fb9b148e03a103"},"cell_type":"code","source":"score_eclf = f1_score(eclfY, y_test)\nprint('f score ECLF:{}'.format(score_eclf))\n# LR SVC Ensemble Weight[1,1]\n# accuracy ECLF: 0.5128062236686655\n# f score ECLF:0.4826296503205159\n\n# LR SVC Ensemble Weight[1,2]\n# accuracy ECLF: 0.5095472682285281\n# f score ECLF:0.6558187409856991\n\n# LR SVC LGBM Weight[1,2,1]\n# accuracy ECLF: 0.5335681326764896\n# f score ECLF:0.6030406623134683\n\n# LR SVC LGBM Weight[1,2,2]\n# accuracy ECLF: 0.5359666525489847\n# f score ECLF:0.6137059511217503","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"909f9f2f8a16135f878d17d3938fcc9e005fe190"},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, eclfY)\n\nplt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for ECLF classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}