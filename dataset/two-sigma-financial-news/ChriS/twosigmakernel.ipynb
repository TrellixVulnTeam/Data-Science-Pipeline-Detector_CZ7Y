{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import *\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n(market_train, news_train) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5a0348ae9f79ab46e6a436ecbba888af09e50ec"},"cell_type":"code","source":"market_train = market_train[market_train.returnsOpenNextMktres10<1][market_train.returnsOpenNextMktres10>-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bc467b42c332f8bd118ebd94af4659a0426432f"},"cell_type":"code","source":"def calcRsi(series, period = 14):\n    \n    \"\"\"\n    Calculate the RSI of a data series \n    \n    Parameters\n    ----------\n    series : pandas series\n        Candle sticks dataset\n    period : int\n        Period of each calculation\n        \n    Returns\n    -------\n    rsi : float\n        the calculated rsi\n    \"\"\"\n    try:\n        delta = series.diff().dropna()\n        u = delta * 0\n        d = u.copy()\n        u[delta > 0] = delta[delta > 0]\n        d[delta < 0] = -delta[delta < 0]\n        u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n        u = u.drop(u.index[:(period-1)])\n        d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n        d = d.drop(d.index[:(period-1)])\n\n        rs = u.ewm(com=period-1, adjust=False).mean() \\\n            / d.ewm(com=period-1, adjust=False).mean()\n        \n        rsi = 100 - 100 / (1 + rs)\n    except IndexError:\n        rsi = 0\n    \n    return rsi\n\ndef addBollinger(df, period=20, col='close'):\n    \"\"\"\n    Add the simple moving average column to dataframe \n\n    Parameters\n    ----------\n    df : pandas dataframe\n        Candle sticks dataset\n    period : int\n        Period of each calculation\n\n    Returns\n    -------\n    None\n    \"\"\"\n    bbmid_series = df[col].rolling(window=period).mean()\n    series_stdev = df[col].rolling(window=period).std()\n    df['BBUpperBand'] = bbmid_series + 2*series_stdev\n    df['BBLowerBand'] = bbmid_series - 2*series_stdev\n    df['BBBandwidth'] = df['BBUpperBand'] - df['BBLowerBand']  \n    df['BBMiddleBand'] = bbmid_series\n    return df\n\ndef addMACD(df):\n    ema_fast = df['close'].ewm(span=12).mean()\n    ema_slow = df['close'].ewm(span=26).mean()\n    signal_line = df['close'].ewm(span=9).mean()\n    df['macd'] = ema_fast - ema_slow\n    df['macd_signal'] = df.macd.ewm(span=9, adjust=False).mean()\n    df['macdh'] = df['macd'] - df['macd_signal']\n    return df\n\ndef allindicator(market_train):\n    market_train['RSI'] = calcRsi(market_train['close'], 14)\n    market_train = addBollinger(market_train)\n    market_train = addMACD(market_train)\n    return market_train\n\ndef EMA(df):\n    df = df.groupby('time')\n    EMA_7 = df['close'].ewm(span=7).mean()\n    return df\n\nfrom multiprocessing import Pool\n\ndef groupAsset(market_train):\n    all_df = []\n    df_codes = market_train.groupby('assetCode')\n    df_codes = [df_code[1] for df_code in df_codes]\n    pool = Pool(4)\n    all_df = pool.map(allindicator, df_codes)\n    new_df = pd.concat(all_df)  \n    pool.close()\n    del all_df, df_codes, market_train\n    return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e8589f72bf9233ff5ecb996a2b8d4680bb77753"},"cell_type":"code","source":"def data_prep(market_train,news_train):\n    \n    #market_train = groupAsset(market_train)\n    \n    market_train['formatdate']=market_train['time'].dt.date\n    news_train['formatdate'] = news_train.firstCreated.dt.date\n    \n    for col_cat in ['headlineTag', 'provider', 'sourceId']:\n        news_train[col_cat], uniques = pd.factorize(news_train[col_cat])\n        del uniques\n    \n    news_train_sim = news_train.drop(columns=['time','sourceTimestamp','firstCreated','headline','subjects','audiences','assetCodes'])\n    news_train_1 = news_train_sim.groupby(by=['assetName','formatdate'],as_index=False,observed=True).mean().add_suffix('_mean')\n    news_train_1.rename(columns={'assetName_mean': 'assetName', 'formatdate_mean': 'formatdate'}, inplace=True)\n    #news_train_2 = news_train_sim.groupby(by=['assetName','formatdate'],as_index=False,observed=True).sum().add_suffix('_sum')\n    #news_train_2.rename(columns={'assetName_sum': 'assetName', 'formatdate_sum': 'formatdate'}, inplace=True)\n    #news_train_3 = news_train_sim.groupby(by=['assetName','formatdate'],as_index=False,observed=True).var()\n    #news_train_group = pd.merge(news_train_1,news_train_2.iloc[:, np.r_[0,1,2:3]],on=['assetName','formatdate'])\n    #,news_train_3,on=['assetName','formatdate'])\n    merge_train = pd.merge(market_train, news_train_1, how='left', left_on=['formatdate', 'assetName'], \n                                right_on=['formatdate', 'assetName'])\n    #merge_train.fillna(0,inplace=True)\n    #merge_train.drop(['marketCommentary_sum','noveltyCount24H_mean','noveltyCount3D_mean','marketCommentary_mean','urgency_sum',\n    #                 'urgency_mean','noveltyCount5D_mean','bodySize_sum','noveltyCount12H_mean','provider_sum','sentimentClass_mean',\n    #                 'takeSequence_sum','volumeCounts12H_mean','headlineTag_mean','wordCount_sum','headlineTag_sum'],1,inplace=True)\n    del market_train, news_train_sim, news_train_1\n    \n    #merge_train.apply(lambda x: x.fillna(x.mean()),axis=0)\n    \n    \n    \n    return merge_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8548d6a766bd6ca4a9bc7a340769fdbfe387b9be"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"316a9daf2f39edc5da7eb83c43847c776ca99bef"},"cell_type":"code","source":"\n#testabc['change']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c2841de1e7920fc786161f38a34274c5b5ea603"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60223f9c60507f00997ae3e458d3ac0d45943720"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"316caf72e991d0965a6389a9920749b27336bd9c"},"cell_type":"code","source":"merge_train = data_prep(market_train,news_train)\n\ndf_main = merge_train[['time','assetCode','close']]\ndf_main = groupAsset(df_main)\nmerge_train  = pd.merge(merge_train, df_main, how='left',on=['time','assetCode','close'])\ndf_main = df_main[['time','assetCode','close']]\n\ntest123 = merge_train[['time','close','volume']]\ntest123['cap']=test123['close']*test123['volume']\ntestabc = test123.groupby('time').sum()\ntestabc['wholemarket_index']=testabc['cap']/testabc['volume']\ntestabc.reset_index(inplace=True)\nfor i in range (len(testabc)-1):\n    testabc.loc[i+1,'changeWMI'] = (testabc.loc[i+1,'wholemarket_index']-testabc.loc[i,'wholemarket_index'])/(testabc.loc[i,'wholemarket_index'])\ntestabc = testabc[['time','changeWMI']]\nmerge_train  = pd.merge(merge_train, testabc, how='left',on=['time'])\ntest123 = merge_train[['time','close','volume']]\n\nmerge_train.fillna(0,inplace=True)\n\nup = merge_train.returnsOpenNextMktres10 >= 0\nup = up.values\n\nfcol = [c for c in merge_train.columns if c not in ['assetCode','assetName','time',\n                                             'returnsOpenNextMktres10', 'formatdate', 'universe','close','open']]\nX = merge_train[fcol].values\nr = merge_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fe57843c4992f2cbe97993db59782f87d6cbb10"},"cell_type":"code","source":"test123","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2de35b689c0f8387cfb09869ef608fc6cd882c8"},"cell_type":"code","source":"X_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=99)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a12388cbfcd159d1d3a9b26418447b59b97e398b"},"cell_type":"code","source":"import lightgbm as lgb\nparams = {'learning_rate': 0.15, 'max_depth': 20, 'num_leaves':512, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=up_train), num_boost_round=100,\n                  valid_sets=[lgb.Dataset(X_train, label=up_train), lgb.Dataset(X_test, label=up_test)],\n                  verbose_eval=50, early_stopping_rounds=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cb983dd12382b49804744063e21c87c3851a418"},"cell_type":"code","source":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\ndef generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: np.random.randint(0, 255), range(3)))\n    return color\n\ndf = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndata = [df]\nfor dd in data:  \n    colors = []\n    for i in range(len(dd)):\n         colors.append(generate_color())\n\n    data = [\n        go.Bar(\n        orientation = 'h',\n        x=dd.imp,\n        y=dd.col,\n        name='Features',\n        textfont=dict(size=20),\n            marker=dict(\n            color= colors,\n            line=dict(\n                color='#000000',\n                width=0.5\n            ),\n            opacity = 0.87\n        )\n    )\n    ]\n    layout= go.Layout(\n        title= 'Feature Importance of LGB',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis=dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n\n    py.iplot(dict(data=data,layout=layout), filename='horizontal-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6334aa3f9abfc497eee0ba68bbdb221f1a6c84d5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e5032263f041e91548d082b7eb0bb7c85ef5e85"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ea4f4646166894f7f24b6cc00af4c64c4c5db6c4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79f62cf2e540494a15bb390d2969eb41a1cc4688"},"cell_type":"code","source":"df_main = df_main[df_main.time>'2016-12-01']\nn_days = 0 \nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days():\n    n_days +=1\n    if n_days % 2 == 0:\n        print(n_days,end=' ')\n    market_obs_df = data_prep(market_obs_df, news_obs_df)\n    \n    df_days = market_obs_df[['time','assetCode','close']]\n    df_main = df_main.append(df_days)\n    df_main.sort_values(by=['time'],inplace=True)\n    df_main.reset_index(inplace=True,drop=True)\n    df_main = groupAsset(df_main)\n    market_obs_df  = pd.merge(market_obs_df, df_main, how='left',on=['time','assetCode','close'])\n    df_main = df_main[['time','assetCode','close']]\n    \n    test456 = market_obs_df[['time','close','volume']]\n    test123 = test123.append(test456)\n    test123['cap']=test123['close']*test123['volume']\n    testabc = test123.groupby('time').sum()\n    testabc['wholemarket_index']=testabc['cap']/testabc['volume']\n    testabc.reset_index(inplace=True)\n    for i in range (len(testabc)-1):\n        testabc.loc[i+1,'changeWMI'] = (testabc.loc[i+1,'wholemarket_index']-testabc.loc[i,'wholemarket_index'])/(testabc.loc[i,'wholemarket_index'])\n    testabc = testabc[['time','changeWMI']]\n    market_obs_df  = pd.merge(market_obs_df, testabc, how='left',on=['time'])\n    test123 = test123[['time','close','volume']]\n    \n    market_obs_df.fillna(0,inplace=True)\n    \n    X_live = market_obs_df[fcol].values\n    \n    # Scaling of X values\n    #mins = np.min(X_live, axis=0)\n    #maxs = np.max(X_live, axis=0)\n    #rng = maxs - mins\n    X_live = 1 - ((maxs - X_live) / rng)\n    \n    \n    \n    \n    lp = model.predict(X_live)\n    \n    confidence = 2 * lp -1\n      \n    #market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dee79afa16d1cc2e5196e0a02a9cbd1810b0f9a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c181617badac5c184ce1770e7f5b043f4af3760e"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"367ca87ea1ab9d73658718842afceb126965bab4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}