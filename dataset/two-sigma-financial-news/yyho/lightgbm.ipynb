{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom kaggle.competitions import twosigmanews\npd.set_option('max_columns', 50)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"env = twosigmanews.make_env()\nmarket_train_df, news_train = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99acf065401ba9c9da53d62852a9834283915fe"},"cell_type":"code","source":"for column in market_train_df.select_dtypes(include='float64').columns:\n    market_train_df[column] = market_train_df[column].astype('float16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f50e4d3d1cf34d3370a6a83e3c09a30f64ae0ac8"},"cell_type":"code","source":"start = datetime(2010, 1, 1, 0, 0, 0).date()\nmarket_train = market_train_df.loc[market_train_df['time'].dt.date >= start].reset_index(drop=True)\nnews_train = news_train.loc[news_train['time'].dt.date >= start].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03dd48c018bef8b217c0e19cd69af683671788f1"},"cell_type":"code","source":"def preprocess_news(news_train):\n    drop_list = [\n        'audiences', 'subjects', 'assetName',\n        'headline', 'firstCreated', 'sourceTimestamp',\n    ]\n    news_train.drop(drop_list, axis=1, inplace=True)\n    \n    # Factorize categorical columns\n    for col in ['headlineTag', 'provider', 'sourceId']:\n        news_train[col], uniques = pd.factorize(news_train[col])\n        del uniques\n    \n    # Remove {} and '' from assetCodes column\n    news_train['assetCodes'] = news_train['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n    return news_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80d545fe3e7dd3d8c068a6c679172e38ea1669af"},"cell_type":"code","source":"news_train = preprocess_news(news_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14f3c4bc81e7b03bb07c8ef20d4b43b94411b6bd"},"cell_type":"code","source":"def unstack_asset_codes(news_train):\n    codes = []\n    indexes = []\n    for i, values in news_train['assetCodes'].iteritems():\n        explode = values.split(\", \")\n        codes.extend(explode)\n        repeat_index = [int(i)]*len(explode)\n        indexes.extend(repeat_index)\n    index_df = pd.DataFrame({'news_index': indexes, 'assetCode': codes})\n    del codes, indexes\n    gc.collect()\n    return index_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28ec4168d58123d84d5eaaf5366d1635c05844a4"},"cell_type":"code","source":"index_df = unstack_asset_codes(news_train)\nindex_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4975a1ab3d342986ee090432a9b69a8a7e7dc52f"},"cell_type":"code","source":"def merge_news_on_index(news_train, index_df):\n    news_train['news_index'] = news_train.index.copy()\n\n    # Merge news on unstacked assets\n    news_unstack = index_df.merge(news_train, how='left', on='news_index')\n    news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return news_unstack","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb1967ed3cd97f496832c2f19a47e29622397421"},"cell_type":"code","source":"news_unstack = merge_news_on_index(news_train, index_df)\ndel news_train, index_df\ngc.collect()\nnews_unstack.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0119728d6946ea731e7dbc87c2ddc0b8f3fd938e"},"cell_type":"code","source":"def group_news(news_frame):\n    news_frame['date'] = news_frame.time.dt.date  # Add date column\n    \n    aggregations = ['mean']\n    gp = news_frame.groupby(['assetCode', 'date']).agg(aggregations)\n    gp.columns = pd.Index([\"{}_{}\".format(e[0], e[1]) for e in gp.columns.tolist()])\n    gp.reset_index(inplace=True)\n    gp.drop(['sourceId_mean'],axis=1, inplace=True)\n    # Set datatype to float32\n    float_cols = {c: 'float32' for c in gp.columns if c not in ['assetCode', 'date']}\n    return gp.astype(float_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df3c440eb17c1440245f68824534453a02e90887"},"cell_type":"code","source":"news_agg = group_news(news_unstack)\ndel news_unstack; gc.collect()\nnews_agg.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b3ed8e738279eeb02de380eefff3d3f36169241"},"cell_type":"code","source":"def process_date(df):\n    df['date'] = df['time'].dt.date\n    df['month'] = df['time'].dt.month\n    df['dayofweek'] = df['time'].dt.dayofweek\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5866de66693f2eee1ef53dd0a07e2a7c51b0756a"},"cell_type":"code","source":"def process_ma(df,columns=['open','close','volume'], windows=[10, 20, 60]):\n    ma_columns = []\n    ma_dev_columns = []\n    drop_list = []\n    for col in columns:\n        for window in windows:\n            ma_column = 'ma_{0}_{1}'.format(col,window)\n            ma_dev_column = 'ma_dev_{0}_{1}'.format(col,window)\n            ma_lag_column = 'ma_lag_{0}_{1}'.format(col,window)\n            ma_lag_rate_column = 'ma_lag_rate_{0}_{1}'.format(col,window)\n            std_column = 'std_{0}_{1}'.format(col,window)\n            ma_columns.append(ma_column)\n            ma_dev_columns.append(ma_dev_column)\n            # calc moving average\n            df[ma_column] = df.groupby('assetCode')[col].apply(lambda x: x.rolling(window).mean())\n            # calc rate of deviation from moving average\n            df[ma_dev_column] = df[col] / df[ma_column] - 1\n            # calc moving std\n            df[std_column] = df.groupby('assetCode')[col].apply(lambda x: x.rolling(window).std())\n            \n            df[ma_lag_column] = df.groupby('assetCode')[ma_column].shift()\n            df[ma_lag_rate_column] = (df[ma_column] - df[ma_lag_column]) / df[ma_lag_column]\n            \n            drop_list.append(ma_column)\n            drop_list.append(ma_lag_column)\n            \n    df.drop(drop_list,axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d735f3d3519a808f024928650d42c65058cff00"},"cell_type":"code","source":"market_train = process_date(market_train)\nmarket_train = process_ma(market_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d6992dbe0bc8775e20660d2c43aa0233c5384f0"},"cell_type":"code","source":"df = market_train.merge(news_agg, how='left', on=['assetCode', 'date'])\ndel market_train, news_agg\ngc.collect()\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4e22f683af90abb05ead00a47c09918ad0917b0"},"cell_type":"code","source":"for column in df.select_dtypes(include='float64').columns:\n    df[column] = df[column].astype('float16')\n\nfor column in df.select_dtypes(include='int64').columns:\n    df[column] = df[column].astype('int16')\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04ad34d399984469f9e063f0b70cd2b42f3382bc"},"cell_type":"code","source":"def custom_metric(date, pred_proba, num_target, universe):\n    y = pred_proba*2 - 1\n    r = num_target.clip(-1,1) # get rid of outliers\n    x = y * r * universe\n    result = pd.DataFrame({'day' : date, 'x' : x})\n    x_t = result.groupby('day').sum().values\n    return np.mean(x_t) / np.std(x_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f506f5925d8dbd842e8fadd215b867d2afbfe33"},"cell_type":"code","source":"date = df.date\nnum_target = df.returnsOpenNextMktres10.astype('float32')\nbin_target = (df.returnsOpenNextMktres10 >= 0).astype('int8')\nuniverse = df.universe.astype('int8')\n# Drop columns that are not features\ndf.drop(['returnsOpenNextMktres10', 'date', 'universe', 'assetCode', 'assetName', 'time'], \n        axis=1, inplace=True)\ndf = df.astype('float32')  # Set all remaining columns to float32 datatype\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e9a27b01d73978bad66c977cb639c5c595f8ba5"},"cell_type":"code","source":"train_index, test_index = train_test_split(df.index.values, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"980547b13c6cd53ddd66e1aa5c2ecc6960b51f0c"},"cell_type":"code","source":"best_params = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'learning_rate': 0.05,\n    'num_leaves': 63,\n    'n_estimators': 1000,\n    'min_child_samples': 20,\n    'colsample_bytree': 1,\n    'subsample': 1.0,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0.8,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d986c9db7a41548a6e074e793533ccd23407bd2"},"cell_type":"code","source":"lgb_train = lgb.Dataset(df.iloc[train_index], bin_target.iloc[train_index])\nlgb_eval = lgb.Dataset(df.iloc[test_index], bin_target.iloc[test_index], reference=lgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8bee55fb395d935b46cf0bba7eb00b546a563cc"},"cell_type":"code","source":"clf = lgb.train(\n            best_params,\n            lgb_train,\n            valid_sets=lgb_eval,\n            early_stopping_rounds=5\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aeac11662289437aef4372ed9c957bdd4d5f6f2d"},"cell_type":"code","source":"pred_y = clf.predict(df.iloc[test_index])\npred_y[pred_y >= 0.5] = 1\npred_y[pred_y < 0.5] = 0\nprint((pred_y == bin_target.iloc[test_index]).sum() / len(pred_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e7dbf4d130e913c81fc8f28e10a5dfb11256551"},"cell_type":"code","source":"test_df_columns = ['time', 'assetCode', 'assetName', 'volume', 'close', 'open',\n                   'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n                   'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n                   'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n                   'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\nbase_df = market_train_df[market_train_df['time'] >= '2016-10-01']\nbase_df = base_df[test_df_columns]\nbase_df['id'] = -1\nbase_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cfa279e41180adc6c4d50d5e8d479f9a30f481a"},"cell_type":"code","source":"def calc_target(df):\n    df['open_next10'] = df.groupby('assetCode')['open'].shift(-10)\n    df['return_next10'] = df['open_next10'] / df['open'] - 1.0\n    df['target'] = (df.return_next10 >= 0).astype('int8')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5769fee2aa6eea095697571427c487d0f4bb1cbc"},"cell_type":"code","source":"target_test_df = calc_target(market_train_df)\ntarget_test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c57a15d3718c998028fe62dae4f7275d1475798"},"cell_type":"code","source":"def online_train(model, df, train_day_id, feats):\n    best_params = {\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'learning_rate': 0.05,\n        'num_leaves': 63,\n        'n_estimators': 1000,\n        'min_child_samples': 20,\n        'colsample_bytree': 1,\n        'subsample': 1.0,\n        'reg_alpha': 0.1,\n        'reg_lambda': 0.8,\n    }\n    \n    train_df = calc_target(df)\n    train_df = train_df[train_df['id'] == train_day_id]\n    train_df.reset_index(drop=True)\n    target_df = train_df[['target']]\n    train_df = train_df[feats]\n    \n    model.refit(train_df, target_df['target'])\n    return model\n    \"\"\"\n    train_index, test_index = train_test_split(train_df.index.values, test_size=0.1)\n    lgb_train = lgb.Dataset(train_df.iloc[train_index], target_df.iloc[train_index])\n    lgb_eval = lgb.Dataset(train_df.iloc[test_index], target_df.iloc[test_index], reference=lgb_train)\n    return lgb.train(\n            best_params,\n            lgb_train,\n            init_model=model,\n            learning_rates=lambda iter: 0.05 * (0.99 ** iter),\n            valid_sets=lgb_eval,\n            early_stopping_rounds=5\n    )\n    \"\"\"\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec5064f3a5e81d267b7128ff0c90920d872c4b44"},"cell_type":"code","source":"def write_submission(model, env):\n    days = env.get_prediction_days()\n    day_id = 0\n    market_obs_df_append = None\n    online_train_df_append = None\n    for (market_obs_df, news_obs_df, predictions_template_df) in days:\n        news_obs_df = preprocess_news(news_obs_df)\n        # Unstack news\n        index_df = unstack_asset_codes(news_obs_df)\n        news_unstack = merge_news_on_index(news_obs_df, index_df)\n        # Group and and get aggregations (mean)\n        news_obs_agg = group_news(news_unstack)\n\n        market_obs_df['id'] = day_id\n        if market_obs_df_append is None:\n            market_obs_df_append = base_df\n            \n        market_obs_df_append = pd.concat([market_obs_df_append,market_obs_df],\n                                         ignore_index=True,\n                                         sort=False)\n        \n        market_obs_process = process_date(market_obs_df_append)\n        market_obs_process = process_ma(market_obs_process)\n        market_obs_df = market_obs_process[market_obs_process['id']==day_id]\n        # Join market and news frames\n        obs_df = market_obs_df.merge(news_obs_agg, how='left', on=['assetCode', 'date'])\n        del market_obs_df, news_obs_agg, news_obs_df, news_unstack, index_df\n        gc.collect()\n        obs_df = obs_df[obs_df.assetCode.isin(predictions_template_df.assetCode)]\n        \n        # Drop cols that are not features\n        feats = [c for c in obs_df.columns if c not in ['date', 'assetCode', 'assetName', 'time', 'id']]\n        \n        # pile obs_df for online training\n        if online_train_df_append is None:\n            online_train_df_append = obs_df\n        else:\n            online_train_df_append = pd.concat([online_train_df_append, obs_df],\n                                                ignore_index=True,\n                                                sort=False)\n        \n        # online training\n        if day_id >= 10:\n            model = online_train(model, online_train_df_append, day_id - 10, feats)\n        \n        #preds = model.predict_proba(obs_df[feats])[:, 1] * 2 - 1\n        preds = model.predict(obs_df[feats]) * 2 - 1\n        sub = pd.DataFrame({'assetCode': obs_df['assetCode'], 'confidence': preds})\n        predictions_template_df = predictions_template_df.merge(sub, how='left').drop(\n            'confidenceValue', axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n        \n        env.predict(predictions_template_df)\n        if day_id == 59:\n            market_obs_df_append.drop(\n                market_obs_df_append.index[market_obs_df_append['id']==-1],\n                inplace=True)\n        elif day_id >= 60:\n            market_obs_df_append.drop(\n                market_obs_df_append.index[market_obs_df_append['id']==day_id-60],\n                inplace=True)\n        day_id += 1\n        del obs_df, predictions_template_df, preds, sub\n        gc.collect()\n    env.write_submission_file()\n    print('day_count',day_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c6148f433dc9b07e373dc5a45b7625f2eef6191"},"cell_type":"code","source":"write_submission(clf, env)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ba133ee465353a42270b48ef4b3d790e9bf967"},"cell_type":"code","source":"feat_importance = pd.DataFrame()\nfeat_importance[\"feature\"] = df.columns\nfeat_importance[\"gain\"] = clf.feature_importance(importance_type='gain')\nfeat_importance.sort_values(by='gain', ascending=False, inplace=True)\nplt.figure(figsize=(8,10))\nax = sns.barplot(y=\"feature\", x=\"gain\", data=feat_importance)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}