{"cells":[{"metadata":{"_uuid":"c49c4f47379d81cd7fc50faf2f482938e441dec5"},"cell_type":"markdown","source":"## General information\n\nTwo Sigma Financial News Competition is a unique competitions: not only it is a Kernel-only competition, but we aren't supposed to download data and during stage two our solutions will be used to predict future real data.\n\nI'll try to do an extensive EDA for this competition and try to find some interesting things about the data.\n\nP. S. I'l learning to use plotly, so there will be interactive charts at last!\n\n*The work is in progress.*"},{"metadata":{"_uuid":"6daa1434e9a463cb819f93bb08b41602e4b1f64b"},"cell_type":"markdown","source":"![](http://fintechnews.ch/wp-content/uploads/2016/11/Deutsche-Bank-Survey-87-of-Financial-Market-Participants-Say-Blockchain-Will-Disrupt-The-Industry-1440x564_c.jpg)"},{"metadata":{"_uuid":"896f2b18bf4f32ec7dfb0196e3d718a7ae991b6a"},"cell_type":"markdown","source":"### Getting data and importing libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# official way to get the data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ee6824cf41c4fd03be113d54e6975cf3574c06f"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56d475175477feee4b5672285e8bccd663b5c4c6"},"cell_type":"markdown","source":"We have two datasets, let's explore them separately."},{"metadata":{"_uuid":"a21a4bd4a0be55614fcdcbc8f1812b5994dabb19"},"cell_type":"markdown","source":"## Market data\n\nWe have a really interesting dataset which contains stock prices for many companies over a decade!\n\nFor now let's have a look at the data itself and not think about the competition. We can see long-term trends, appearing and declining companies and many other things."},{"metadata":{"trusted":true,"_uuid":"cca04f17e12924251a4ea85f1ea63a81e4c1c4eb"},"cell_type":"code","source":"print(f'{market_train_df.shape[0]} samples and {market_train_df.shape[1]} features in the training market dataset.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a10641e3f980559a25ebc3ab83082443ce344de8","scrolled":true},"cell_type":"code","source":"market_train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68399eec91a6c1e773c9534969949ca40f04f290"},"cell_type":"markdown","source":"At first let's take 10 random assets and plot them."},{"metadata":{"_uuid":"cb26ae98a1c16bb8f6a52c58467eadf274c6ab9d"},"cell_type":"markdown","source":"隨機選出10家公司，展示他們的資產收盤價趨勢圖"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e49f9296ce4c92adc8b82bc4e96fe05d1a1845d7","scrolled":false},"cell_type":"code","source":"data = []\nfor asset in np.random.choice(market_train_df['assetName'].unique(), 10):\n    asset_df = market_train_df[(market_train_df['assetName'] == asset)]\n#     print(asset_df)\n#     print()\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dae9a9525d26e61fc597f6c107e3a0680df2384d"},"cell_type":"markdown","source":"I plot data for all periods because I'd like to show long-term trends.\nAssets are sampled randomly, but you should see that some companies' stocks started trading later, some dissappeared. Disappearence could be due to bankruptcy, acquisition or other reasons."},{"metadata":{"trusted":true,"_uuid":"95acb79ce639b7dca8520b069f25093dff03b69d"},"cell_type":"code","source":"dd= market_train_df.groupby('time')['close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62ccdf6ee7c3371c8a2079c4261b5527fac0a72d"},"cell_type":"markdown","source":"Well, these were some random companies. But it would be more interesting to see general trends of prices."},{"metadata":{"_uuid":"2249d57c914076c19532cc0acd046083d78b0385"},"cell_type":"markdown","source":"將市場資料的收盤價，以時間分群為7個主要區間\n並列出這7個區間的趨勢圖\n"},{"metadata":{"_uuid":"968a5a7eb18766912505fad8c69730a4b68af494"},"cell_type":"markdown","source":"Collapse of Lehman Brothers : 2008年9月15日，在美國財政部、美國銀行以及英國巴克萊銀行相繼放棄收購談判後，雷曼兄弟公司宣佈申請破產保護\nBlack Monday :\n黑色星期一指股市大跌經常出現在星期一的現象。最著名的黑色星期一是1987年10月19日美國股市發生的大跌，當日道瓊斯指數下跌了22%。道瓊斯工業平均指數下跌至508點。黑色星期一，是最令人難以置信的一天。因為那兒沒有市場，被稱作“自由下跌”。自由下跌，簡單地說就是價格一直下跌，沒有任何買家。僅僅一天道瓊斯喪失其價值的23%，數百億美元消失了。裝了特殊程序的計算機不停地在賣，任何試圖使其穩定下來的努力都失敗了。\n\n　　對黑色星期一現象的一種解釋是因為周末容易公佈一些重大負面新聞，所以周一開盤後投資者會有劇烈反應。但歷史上許多黑色星期一之前的周末並沒有出現什麼重大消息，所以，很多情況下是由於市場謠言引發的恐慌性拋盤。事實上，全球歷史上的股市大跌幾乎在周一至週五都有發生。如果投資者在無實質性利空下爆發的恐慌性下跌中能保持理性，通常會獲得極佳的買入機會，如美國87年股災後1年多時間就收復失地。\n\nAnother crisis 另一場金融海嘯\nOil prices crash 油價暴跌"},{"metadata":{"trusted":true,"_uuid":"9dcc6697091aebcef13fabd12843018970a6fd77"},"cell_type":"code","source":"price_df = market_train_df.groupby('time')['close'].quantile(0.95).reset_index()\nx = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values\nlen(x)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"066d58a619d40beaf565c02064f2d1351fa717a8"},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['close'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['close'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of closing prices by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),\n    annotations=[\n        dict(\n            x='2008-09-01 22:00:00+0000',\n            y=82,\n            xref='x',\n            yref='y',\n            text='Collapse of Lehman Brothers',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        ),\n        dict(\n            x='2011-08-01 22:00:00+0000',\n            y=85,\n            xref='x',\n            yref='y',\n            text='Black Monday',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        ),\n        dict(\n            x='2014-10-01 22:00:00+0000',\n            y=120,\n            xref='x',\n            yref='y',\n            text='Another crisis',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=-20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        ),\n        dict(\n            x='2016-01-01 22:00:00+0000',\n            y=120,\n            xref='x',\n            yref='y',\n            text='Oil prices crash',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        )\n    ])\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7620510c704631bb04200c6a47ff01b0025befbd"},"cell_type":"markdown","source":"It is cool to be able to see how markets fall and rise again.\nI have shown 4 events when there were serious stock price drops on the market.\nYou could also notice that higher quantile prices have increased with time and lower quantile prices decreased.\nMaybe the gap between poor and rich increases... on the other hand maybe more \"little\" companies are ready to go to market and prices of their shares isn't very high."},{"metadata":{"_uuid":"19a6cf416e4b7d88b1dcdf5ef37565307ce5d3ce"},"cell_type":"markdown","source":"Now, let's look at these price drops in details."},{"metadata":{"_uuid":"97a7aab8ba5b38acf53fa16a599f7acef5b86333"},"cell_type":"markdown","source":"計算price_diff (Feature)為 收盤價減開盤價\n並以時間分群，計算股價差異的std(標準平均) 以及 min (最小值)"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8ca5182693d1826b459101b54dd23f6d7bf69b3d"},"cell_type":"code","source":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby('time').agg({'price_diff': ['std', 'min']}).reset_index()\ngrouped.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a21c4b16636acb7cc98caa354bb06ea989d6373f","_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"print(f\"Average standard deviation of price change within a day in {grouped['price_diff']['std'].mean():.4f}.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f512f76f7b3f75979ae77f08de44c67fca8e032"},"cell_type":"markdown","source":"取前10個股價標準差差異最大的資產公司，以圓點圖展示差異大小"},{"metadata":{"trusted":true,"_uuid":"9b85270e4197670fb5d7cca44509a5e75c3b705c"},"cell_type":"code","source":"g = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * g['price_diff']['min']).astype(str)\ng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4be3e4c4cc550f67bb77eea9f42a935f6574d48b"},"cell_type":"code","source":"g = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * g['price_diff']['min']).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7e55d1b2db816c00d5cc66f373949ec010c0494"},"cell_type":"markdown","source":"We can see huge price fluctiations when market crashed. Just think about it... **But this is wrong!** There was no huge crash on January 2010... Let's dive into the data!"},{"metadata":{"_uuid":"f4c43e1d3dc085b540af9736043089f5fb386f6b"},"cell_type":"markdown","source":"### Possible data errors\n\nAt first let's simply sort data by the difference between open and close prices."},{"metadata":{"_uuid":"c8af4f78dc2ad94d511398d2e4fb997feba21e07"},"cell_type":"markdown","source":"找出前10筆收開盤價差最大的資產公司"},{"metadata":{"trusted":true,"_uuid":"fd332dac81171201abbefcf3a42cc0a2c315d895","scrolled":true},"cell_type":"code","source":"aa = market_train_df.sort_values('price_diff')[:10]\n\naa[['assetCode','assetName','close','open','time','price_diff']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"409b5a614ff8c5efd13d9a69a81a6f0b81acf3ce"},"cell_type":"markdown","source":"So price of \"Towers Watson & Co\" shares was almost 10k... I think this is simply an error in data.\n\nBut what about Bank of New York Mellon Corp?\n\nLet's see data by Yahoo:"},{"metadata":{"_uuid":"79fba7ac9a4162cc5d6ac93c7b366ffba2d350a0"},"cell_type":"markdown","source":"![](https://i.imgur.com/C3COWfe.png)"},{"metadata":{"_uuid":"e2c1089b0ba6c7dce00d398ebf5702262f98e2de"},"cell_type":"markdown","source":"There were no spikes."},{"metadata":{"trusted":true,"_uuid":"143157631b3ecefbbf8c227c7c9b5bd522df2812"},"cell_type":"markdown","source":"Another case is with cost equal to 999, such numbers are usually suspicious. Let's look at Archrock Inc - no spikes there as well.\n\n![](https://i.imgur.com/KYZKkSd.png)"},{"metadata":{"trusted":true,"_uuid":"9fb49e6cf41f70872a78276403f3fe4d9ed87ae4"},"cell_type":"markdown","source":"So, let's try to find strange cases."},{"metadata":{"_uuid":"3646f941c90c6baf571b991965e6d3d0a175fab6"},"cell_type":"markdown","source":"計算收盤價與開盤價之比值"},{"metadata":{"trusted":true,"_uuid":"04fe6a44a65a7b66fa128f24acf6717eda1f6e20"},"cell_type":"code","source":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] / market_train_df['open'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efb50f5f854139a116b2a59ea02e863a0aaad37a"},"cell_type":"code","source":"aa = market_train_df.sort_values('close_to_open',ascending=False)[:10]\n\naa[['assetCode','assetName','close','open','time','price_diff','close_to_open']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"124f9d12cae5bc64b996da976ada7c817e5893be"},"cell_type":"code","source":"print(f\"{1+1}\") #內部運算","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39bf65e0c1a6fac123f5af29a76248c21c458747"},"cell_type":"code","source":"print(f\"In {(market_train_df['close_to_open'] >= 1.2).sum()} lines price increased by 20% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.8).sum()} lines price decreased by 20% or more.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"549aabe483a6f62dd7946020d3d8e60be89919d3"},"cell_type":"markdown","source":"Well, this isn't much considering we have more than 4 million lines and a lot of these cases are due to price falls during market crash. Well just need to deal with outliers."},{"metadata":{"trusted":true,"_uuid":"47fcd3e5635e68ea9681626bfb3bc9583b76fb00"},"cell_type":"code","source":"print(f\"In {(market_train_df['close_to_open'] >= 2).sum()} lines price increased by 100% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.5).sum()} lines price decreased by 100% or more.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78b680921bead3d610d3ba35f6cefa98778edeff"},"cell_type":"markdown","source":"For a quick fix I'll replace outliers in these lines with mean open or close price of this company.\n處理outliers值的方式是用 \"以資產名稱\"分群將開盤價與收盤價轉為資產平均值"},{"metadata":{"trusted":true,"_uuid":"bfdb68ea6cb6c303b00f8cef2d08f305aee591f1"},"cell_type":"code","source":"bb = market_train_df.groupby('assetName')['open'].transform('mean')\nbb = bb.sort_values(ascending=False)\nbb.reset_index()\nbb.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":true,"_uuid":"19ef8496d92912fd56dce27ea0548c8a42c92212"},"cell_type":"code","source":"market_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\n# 定位到那些收開盤比例值過大的dataframe值\n# 若(均開-開) > (均收-收): \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n# 定位到那些收開盤比例值過小的dataframe值        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3f8287435af9eecb41e7d054ec52283a3cf40eb"},"cell_type":"markdown","source":"Now let's try to build that graph again."},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":false,"_uuid":"ca35be72e7329e2265b885c2846cac73c68e0c5f"},"cell_type":"code","source":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby(['time']).agg({'price_diff': ['std', 'min']}).reset_index()\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * np.round(g['price_diff']['min'], 2)).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values * 5,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6451f892eb30e9ed887e3fc3bba0e4577af87655"},"cell_type":"markdown","source":"Now the graph is much more reasonable."},{"metadata":{"trusted":true,"_uuid":"ba7e227d09cb2954e1339aab21a4c49fbe53a90e"},"cell_type":"markdown","source":"Now let's take a look at out target variable."},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":false,"_uuid":"fc11eb700da57c528111c751f83bb1fc67446489"},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['returnsOpenNextMktres10'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 by quantiles\",\n                  xaxis = dict(title = '     Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"414894c26558ba77cb7e0963fba2a31c5f0d5d87"},"cell_type":"markdown","source":"We can see that quantiles have a high deviation, but mean value doesn't change much.\n\nNow I think it is time to throw an old part of dataset. Let's leave only data since 2010 year, this way we will get rid of the data of the biggest crisis."},{"metadata":{"_uuid":"29454b6967e6d8fe0c5441435a41d31d70048a1a"},"cell_type":"markdown","source":"Let's look at the target variable now.\n將歷史回報率過濾掉2010以前的紀錄"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"3d45a734741f7bdea69432e09a3f63c9e14132a6"},"cell_type":"code","source":"data = []\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']\n\nprice_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].mean().reset_index()\n\ndata.append(go.Scatter(\n    x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = price_df['returnsOpenNextMktres10'].values,\n    name = f'{i} quantile'\n))\nlayout = go.Layout(dict(title = \"Treand of returnsOpenNextMktres10 mean\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed1d2c559c69fb4f628e29423134f7e610cf3df9"},"cell_type":"markdown","source":"波動似乎很高，但實際上它們比8%要低。事實上，它看起來像一個隨機的噪音……"},{"metadata":{"_uuid":"7a3bc153d0005c67122c7835f30bbaff9002ca9f"},"cell_type":"markdown","source":"Now let's remember the description:\n```\nThe marketdata contains a variety of returns calculated over different timespans. All of the returns in this set of marketdata have these properties:\n\n    Returns are always calculated either open-to-open (from the opening time of one trading day to the open of another) or close-to-close (from the closing time of one trading day to the open of another).\n    Returns are either raw, meaning that the data is not adjusted against any benchmark, or market-residualized (Mktres), meaning that the movement of the market as a whole has been accounted for, leaving only movements inherent to the instrument.\n    Returns can be calculated over any arbitrary interval. Provided here are 1 day and 10 day horizons.\n    Returns are tagged with 'Prev' if they are backwards looking in time, or 'Next' if forwards looking.\n```\n\nLet's have a look at means of these variables."},{"metadata":{"trusted":true,"_uuid":"71abf4301d4c4cc18a5e300e7d20319560d49df1","_kg_hide-input":true},"cell_type":"code","source":"data = []\nfor col in ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n       'returnsOpenNextMktres10']:\n    df = market_train_df.groupby('time')[col].mean().reset_index()\n    data.append(go.Scatter(\n        x = df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = df[col].values,\n        name = col\n    ))\n    \nlayout = go.Layout(dict(title = \"Treand of mean values\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0e73c3ca9cae28623fb77eeb1ef4e0c5c22303d"},"cell_type":"markdown","source":"Well, for me it is difficult to interpret this, but it seems that returns for previous 10 days fluctuate the most.\n似乎前10天的回報率波動最大。"},{"metadata":{"_uuid":"7ce3cdada9c4560b8777dbbf3db5c67d1032caf0"},"cell_type":"markdown","source":"### News data"},{"metadata":{"trusted":true,"_uuid":"ba97b5f5630b0cf80e47b7bdf05fb8dd5ebee870"},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ef2c4e2e4fb9d8723267d46da7b0a418d2fc5e"},"cell_type":"code","source":"show_df = news_train_df[news_train_df.columns[:10]]\nshow_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"746a676f5c99038eaa2675f1c829056f8a7eba71"},"cell_type":"code","source":"print(f'{news_train_df.shape[0]} samples and {news_train_df.shape[1]} features in the training news dataset.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d999bbf073b48992439ad1ed45e4f22c6c676ef9"},"cell_type":"markdown","source":"The file is too huge to work with text directly, so let's see a wordcloud of the last 100000 headlines."},{"metadata":{"_uuid":"b9886f8da4dec2e1ad6b76ef15df2fde815dfcb1"},"cell_type":"markdown","source":"列出所有新聞頭條"},{"metadata":{"trusted":true,"_uuid":"523d6e0df4caf45372c794d7ce1706877c271b72"},"cell_type":"code","source":"len(show_df['headline'].str.lower().values)\nlen(show_df['headline'])\nlen(show_df['headline'].str.lower().values[-1000000:]) # 取後面1000000筆的headline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe755aae9cf82fd8eb687d3df7b0db1bcec622b"},"cell_type":"code","source":"# 將後面1000000筆的headline文字串聯以生成文字雲\ntext = ' '.join(news_train_df['headline'].str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size=None, stopwords=stop, background_color='white',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in headline')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"141ccfc6aa372c86c901e517f5fe26f2199c037d"},"cell_type":"code","source":"# Let's also limit the time period\nnews_train_df = news_train_df.loc[news_train_df['time'] >= '2010-01-01 22:00:00+0000']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5045c1af99f0fcf45ffe679467c62c8e3c862d90"},"cell_type":"code","source":"news_train_df['urgency'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69d7f02b9412c157bd15a7197955c9e4b68df21a"},"cell_type":"markdown","source":"列出文章類型所有統計數量"},{"metadata":{"trusted":true,"_uuid":"4fd2fa4fddc287426bad197666b5788006bab8b4"},"cell_type":"code","source":"(news_train_df['urgency'].value_counts() / 1000000).plot('bar');\nplt.xticks(rotation=0);\nplt.title('Urgency counts (mln)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"676e3a99d8decf96d38a3a0807e10cd5b647be2d"},"cell_type":"markdown","source":"* Well, it seems that in fact urgency \"2\" is almost never used."},{"metadata":{"_uuid":"eaecc0201acd21736844814731a4b391684aa18d"},"cell_type":"raw","source":"計算句子中的文字數量，並劃出能代表分布的盒方圖"},{"metadata":{"trusted":true,"_uuid":"097754e62d9a905805b132d4a6bab123855154f1"},"cell_type":"code","source":"news_train_df['sentence_word_count'] =  news_train_df['wordCount'] / news_train_df['sentenceCount']\nplt.boxplot(news_train_df['sentence_word_count'][news_train_df['sentence_word_count'] < 40]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ef900e74b1be3651e1252fd5eb9a4d408d1d523"},"cell_type":"code","source":"# \nee = news_train_df['sentence_word_count'].head()\nee.sort_values(ascending=False).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bee51d1409836a1d61a269a66b5bbe3ffc6c6539"},"cell_type":"code","source":"dd = news_train_df[['wordCount','sentenceCount','sentence_word_count']]\ndd.sort_values('sentence_word_count',ascending=False).head()\n# dd.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ada478042b03c13217820e4f1bfa7343affd241c"},"cell_type":"markdown","source":"There are some big outliers, but sentences mostly have 15-25 words in them.\n有一些大的離群值，但是句子大多有15-25個單詞。"},{"metadata":{"trusted":true,"_uuid":"a06cf9147c8093acbac7d123432587e5d32410b2","scrolled":true},"cell_type":"code","source":"# 列出各個新聞提供者數量\nnews_train_df['provider'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19b0aeeb5a37e7de6d75d456aecb98514da77d29"},"cell_type":"markdown","source":"It isn't surprising that Reuters is the most common provider :)"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e5a4a909c53ec5a421551a57ef708db986ac214d"},"cell_type":"code","source":"# 列出各個新聞頭條標籤數量\nee = news_train_df['headlineTag'].value_counts()[:10]\nee.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d700f29e213413d5fe3acecd9bfc9605895bca60"},"cell_type":"code","source":"# 列出各個新聞頭條標籤數量，並畫出值方圖\n(news_train_df['headlineTag'].value_counts() / 1000)[:10].plot('barh');\nplt.title('headlineTag counts (thousands)');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc2cad235a461e096f0076b58b913fb5abd0d31c"},"cell_type":"markdown","source":"Well, most news are tagless.\n大多數新聞都是無標籤的。"},{"metadata":{"trusted":true,"_uuid":"570fc228ce6bf016df2c7966f35ec54bd79416da"},"cell_type":"code","source":"news_train_df['sentimentClass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81c132598b64437c94bbf86a41a49e1527c25848","_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"# 將這些資產公司名稱依情緒分類為[負評,自然,正評]\nfor i, j in zip([-1, 0, 1], ['negative', 'neutral', 'positive']):\n#     print(\"{} , {}\".format(i,j)) ZIP將兩個List中的item包成元組\n    df_sentiment = news_train_df.loc[news_train_df['sentimentClass'] == i, 'assetName']\n    print(f'Top mentioned companies for {j} sentiment are:')\n    print(df_sentiment.value_counts().head(5))\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d1cab6278c7fdf3b70edab0e9db751a64484690"},"cell_type":"markdown","source":"I think it is quite funny that Apple is a company with most both negative and positive sentiments.\n我認為蘋果公司是一家既有消極情緒又有積極情緒的公司，這很有趣。"},{"metadata":{"_uuid":"6a79b9cba0ccf3d18554411cbf368305f3ba38e3"},"cell_type":"markdown","source":"At first I was sad that we don't have access to the texts of the news, but I have realized that we won't be able to use them anyway due to kernel memory limitations."},{"metadata":{"_uuid":"8e784d89a6731a06bc75b5c0ded3730ec6d43701"},"cell_type":"markdown","source":"## Modelling\n\nIt's time to build a model!\nI think that in this case we should build a binary classifier - we will simply predict whether the target goes up or down."},{"metadata":{"trusted":true,"_uuid":"3912a9d211fa28bf8afa7d2b7fbbfa240380227e"},"cell_type":"code","source":"#%%time\n# code mostly takes from this kernel: https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-xgb\n\ndef data_prep(market_df,news_df):\n    market_df['time'] = market_df.time.dt.date\n    market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] / market_df['volume']\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df['volume_to_mean'] = market_df['volume'] / market_df['volume'].mean()\n    \n    news_df['time'] = news_df.time.dt.hour\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['headlineLen'] = news_df['headline'].apply(lambda x: len(x))\n    news_df['assetCodesLen'] = news_df['assetCodes'].apply(lambda x: len(x))\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['asset_sentence_mean'] = news_df.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    lbl = {k: v for v, k in enumerate(news_df['headlineTag'].unique())} # 建立headlineTag中唯一的Key pair\n    news_df['headlineTagT'] = news_df['headlineTag'].map(lbl) # headlineTagT為headlineTag對應的數字\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean() # 將新聞以日期和建立日期為分群，將各column值做平均\n\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n\n    lbl = {k: v for v, k in enumerate(market_df['assetCode'].unique())}\n    market_df['assetCodeT'] = market_df['assetCode'].map(lbl)\n    \n    market_df = market_df.dropna(axis=0)\n    \n    return market_df\n\nmarket_train_df.drop(['price_diff', 'assetName_mean_open', 'assetName_mean_close'], axis=1, inplace=True)\nmarket_train = data_prep(market_train_df, news_train_df)\nprint(market_train.shape)\nup = market_train.returnsOpenNextMktres10 >= 0\n\nfcol = [c for c in market_train.columns if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'assetCodeT', 'volume_to_mean', 'sentence_word_count',\n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', 'returnsOpenPrevRaw1_to_volume',\n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values # X :整體訓練資料焦點column的值\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\nmins = np.min(X, axis=0) # 歸一最小vector\nmaxs = np.max(X, axis=0) # 歸一最大vector\nrng = maxs - mins # 歸一最小最大差值範圍vector\nX = 1 - ((maxs - X) / rng) # 整體訓練資料歸一化","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"171b329d82131d0337c1e7f5b14579b1aad46255"},"cell_type":"code","source":"# fcol\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a87cd064aa7cc6d196f53bc995e97cc0231bfcc9"},"cell_type":"code","source":"df = news_train_df[['assetCodes','assetCodesLen','headline','headlineLen','headlineTag','headlineTagT']].reset_index()\ndf[df['headlineTag']!=''].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f55f3f0fd6daf63a742c5872eb3bb462f2cb8b"},"cell_type":"code","source":"df = news_train_df[['assetName','sentimentClass','asset_sentiment_count']].sort_values('assetName')\ndf.drop_duplicates()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de4d1c860730acb573075e3f17230a8ec71d24da"},"cell_type":"code","source":"df = news_train_df[['assetName','sentenceCount','asset_sentence_mean']].sort_values('assetName')\ndf.drop_duplicates()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff28e3d139eefc3d82a6eae12c0acfb57daeff17"},"cell_type":"code","source":"market_train[fcol].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9695eface6eee79f079e168d97ced1835e868436"},"cell_type":"code","source":"X_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=99)\n\n# xgb_up = XGBClassifier(n_jobs=4,\n#                        n_estimators=300,\n#                        max_depth=3,\n#                        eta=0.15,\n#                        random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d21c956770c03ff9c5f0cc0653d3bf272869252"},"cell_type":"markdown","source":"http://lightgbm.apachecn.org/cn/latest/Parameters.html\n* LightBGM是一個可以找出最佳類別特徵切割的決策樹，即many-vs-many的切分方式。并且最优分割的查找的时间复杂度可以在线性时间完成，和原来的one-vs-other的复杂度几乎一致\n* boosting : gbdt, 傳統的梯度提升決策樹\n* objective(損失函數) : binary, binary log loss classification application\n* metric(度量參數) : AUC (Area under the curve) 比較曲線下面積做為模型優劣的指標。 https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF\n* is_training_metric 如果你需要輸出訓練的度量結果則設置 true\n* seed : 學習數據分隔中的隨機種子"},{"metadata":{"_uuid":"56969d08da9a7fc7fd2ac8d58d197c7b1b43791d"},"cell_type":"markdown","source":"Training and Valid http://lightgbm.apachecn.org/cn/latest/Python-Intro.html#id4\n* train_set : 加载 numpy 数组到 Dataset 中\n* valid_sets\n* early_stopping_rounds : 提前停止找到最佳数量的 boosting rounds（梯度次数）\n* num_boost_round (int, optional (default=100)) – Number of boosting iterations\n* verbose_eval : 每次經過幾個跌代就印出訓練的準確率結果(valid_0's : Test auc\t, valid_1's: Valid auc)"},{"metadata":{"trusted":true,"_uuid":"5190fffb5a49859564ac76fcd5cbace09fce50da"},"cell_type":"code","source":"params = {'learning_rate': 0.05, 'max_depth': 5, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=up_train), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train, label=up_train), lgb.Dataset(X_test, label=up_test)],\n                  verbose_eval=50, early_stopping_rounds=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0c968d65d7b8cf853c8e82fab48f0e2e70d6034"},"cell_type":"code","source":"df = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3cf7dff65149e68f8abb055509a4c97ee024bae"},"cell_type":"code","source":"model.feature_importance()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b5b48c148b13ccaac68f6415e8da6ca4d3a9d21","_kg_hide-input":true},"cell_type":"code","source":"def generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: np.random.randint(0, 255), range(3)))\n    return color\n\ndf = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndata = [df]\nfor dd in data:  \n    colors = []\n    for i in range(len(dd)):\n         colors.append(generate_color())\n\n    data = [\n        go.Bar(\n        orientation = 'h',\n        x=dd.imp,\n        y=dd.col,\n        name='Features',\n        textfont=dict(size=20),\n            marker=dict(\n            color= colors,\n            line=dict(\n                color='#000000',\n                width=0.5\n            ),\n            opacity = 0.87\n        )\n    )\n    ]\n    layout= go.Layout(\n        title= 'Feature Importance of LGB',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis=dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n\n    py.iplot(dict(data=data,layout=layout), filename='horizontal-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7b548b08eb281b4a341d235cbeea8b7e1201a36"},"cell_type":"code","source":"days = env.get_prediction_days()\nimport time\n\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    temp_market_obs_df = market_obs_df # 暫存識別\n    temp_news_obs_df = news_obs_df  # 暫存識別\n    temp_predictions_template_df = predictions_template_df  # 暫存識別\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n    \n    t = time.time()\n    market_obs_df = data_prep(market_obs_df, news_obs_df)  # 重新整併預測天數的預訓練df資料\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values # X_live :預測天數中整體訓練資料焦點column的值\n    X_live = 1 - ((maxs - X_live) / rng) # 預測天數中整體訓練資料歸一化\n    prep_time += time.time() - t # 累加預測資料前處理時間\n    \n    t = time.time()\n    lp = model.predict(X_live) # 以模型預測未來天數並更新\n    prediction_time += time.time() -t # 累加預測資料預測時間\n    \n    t = time.time()\n    confidence = 2 * lp -1 # 將歸一化還原為信心值\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence}) # preds : 整併預測的信心值和其assetCode\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n#     predictions_template_df 與 preds 進行left join並丟棄舊有的confidenceValue，將merge得到的confidence命名為新的confidenceValue column\n    env.predict(predictions_template_df) # 由原生環境預測未來的信心值\n    packaging_time += time.time() - t\n    \nenv.write_submission_file() # 將整體預測的信心值寫入提交檔","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1332a90de2fa5122666fee6f5720ed9f51fbc0b"},"cell_type":"code","source":"# 識別預測天數資料df\n# temp_market_obs_df.head()\n# temp_news_obs_df.head()\n# # 查看預測日的信心值\n# predictions_template_df[predictions_template_df.confidenceValue!=0.0].head()\n# lp\n# preds.head()\npredictions_template_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"419700f300c62c24659713042d049118031087ac"},"cell_type":"code","source":"# 尋找市場資料中assetCode的值有出現在predictions_template_df的assetCode裡\n# isin() 選擇某列等於多個數值或者字符串時\nmarket_obs_df.assetCode.isin(predictions_template_df.assetCode).head()\n# market_obs_df.assetCode\n# market_obs_df.head()\n# n_days #639","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}