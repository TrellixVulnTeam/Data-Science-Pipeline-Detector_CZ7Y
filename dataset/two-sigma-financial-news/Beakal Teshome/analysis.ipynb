{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.layers import BatchNormalization,Activation\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential, Model\nimport seaborn as sns\nfrom datetime import datetime\nfrom datetime import timedelta\nimport numpy as np\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport random\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09859fe7345bee9b9a6acd22fc7f0b1262a94c48"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75bb7de3b608c8d7cf259f8e7d1904e691b33773"},"cell_type":"code","source":"data = []\nfor asset in np.random.choice(market_train_df['assetName'].unique(), 10):\n    curr_asset = market_train_df[market_train_df['assetName'] == asset]\n    data.append(go.Scatter(\n        x = curr_asset['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = curr_asset['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\n\ninit_notebook_mode(connected=True)\niplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9584846200efa934789bfe1b9a648a4a778ef73"},"cell_type":"code","source":"#numer of assetNames\nmarket_train_df[\"assetName\"].unique().size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c41cb5440da94b2a24c2105b8c0d1a7979e4cc27"},"cell_type":"code","source":"market_train_df[market_train_df['returnsClosePrevRaw1'] > 1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92c5090b89d5e219e402209fb1578cd5e7ef550"},"cell_type":"code","source":"def sampleAssetData(assetCode, date, numDays):\n    d = datetime.strptime(date,'%Y-%m-%d')\n    start = d - timedelta(days=numDays)\n    end = d + timedelta(days=numDays)\n    return market_train_df[(market_train_df['assetCode'] == assetCode)\n                             & (market_train_df['time'] >= start.strftime('%Y-%m-%d'))\n                             & (market_train_df['time'] <= end.strftime('%Y-%m-%d'))].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36bc63cb403dc1fe0871f07d8a5a4bedcf6e427e"},"cell_type":"code","source":"sampleAssetData('EBR.N', '2016-10-13', 5)\n#We can see the ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c83eec5f612e6e0866baa4b05576b78a91bf1e2c"},"cell_type":"code","source":"#check market data\nmarket_train_df[market_train_df['assetCode'] == 'EBR.N'].head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52d1d8099c563e6752585f869dff6b64f146546e"},"cell_type":"code","source":"#lets only use the stock market values after 2009\nmarket_train_df = market_train_df[market_train_df.time > '2009'].reset_index()\nlen(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b48081bdc8ec5ca5b3215042022c393685664b29","scrolled":false},"cell_type":"code","source":"df = market_train_df[market_train_df['assetCode'] == 'EBR.N']\nmarket_train_df.iloc[df.index].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ffa1c78dbcd9719df1e61f1af87481ec7d5ba23"},"cell_type":"code","source":"pd.options.mode.chained_assignment = None\nclass preprocess_market:\n    def __init__(self, df, is_test = False):\n        self.data = df.copy()\n        self.scaler = MinMaxScaler()\n        self.is_test = is_test\n        if not is_test:\n            self.y = self.data['returnsOpenNextMktres10']\n    encode = []\n        \n    catagorical = ['assetCode']\n    \n#     numerical = ['volume', 'close', 'open',\n#        'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n#        'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n#        'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n#        'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n#        'returnsOpenNextMktres10', 'universe']\n        \n    def transform(self):\n        if self.is_test:\n            Mktres = ['returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n                     'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n        else:\n            Mktres = ['returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n             'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n              'returnsOpenNextMktres10']\n        self.data[Mktres] = self.data[Mktres].clip(-1, 1)\n        self.data['assetCode'] = self.data['assetCode'].apply(lambda x : x.split('.')[0])\n       #drop the traget column \n        self.data['volume'] = self.data['volume'] / self.data['volume'].mean()\n       #add a feauture\n        self.data['close/open'] = self.data['close'] / self.data['open']\n#        self.data['ema_diff'] = self.data[['open']].ewm(span = 20, adjust = False).mean(\n#        ) - self.data[['open']].ewm(span = 50, adjust = False).mean()\n       #drop other unnecessary columns\n        self.data.drop(['close_to_open', 'mean_close'], axis = 1, inplace = True)\n    \n        #\n    def get_y(self, idx = None):\n        if type(idx) == type(None):\n           return self.y\n        else:\n           return self.y.iloc[idx.index]\n        \n    \n    def adjust_time(self):\n        self.data['month'] = self.data['time'].dt.month\n        self.data['dayofweek'] = self.data['time'].dt.dayofweek\n        self.data['time'] = self.data['time'].dt.date #index\n        \n        #drop the time columns\n    \n    #get back the dataframe\n    def get_data(self):\n        return self.data\n\n    \n    def get_scaler(self):\n        return scaler\n    \n    \n    #replace data with abnormal change in close to open ratio\n    #taken from https://www.kaggle.com/artgor/eda-feature-engineering-and-everything\n    def remove_variance(self):\n        #percentage of change in close to open price\n        self.data['close_to_open'] =  np.abs(self.data['close'] / self.data['open'])\n        #add the mean of the opening and closing price as a feature\n        self.data['mean_open'] = self.data.groupby('assetName')['open'].transform('mean')\n        self.data['mean_close'] = self.data.groupby('assetName')['close'].transform('mean')\n        \n        \n        for i, row in self.data.loc[self.data['close_to_open'] >= 2].iterrows():\n            if np.abs(row['mean_open'] - row['open']) > np.abs(row['mean_close'] - row['close']):\n                self.data.iloc[i,6] = row['mean_open']\n            else:\n                self.data.iloc[i,5] = row['mean_close']\n        \n        for i, row in self.data.loc[self.data['close_to_open'] <= 0.5].iterrows():\n            if np.abs(row['mean_open'] - row['open']) > np.abs(row['mean_close'] - row['close']):\n                self.data.iloc[i,6] = row['mean_open']\n            else:\n                self.data.iloc[i,5] = row['mean_close']\n                \n    def fit(self):\n        self.adjust_time()\n        self.remove_variance()\n        self.transform()\n#         self.normalize()\n        \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa4875dfcb86560a6de80fc68dfb8ae3e1d99597"},"cell_type":"code","source":"market = preprocess_market(market_train_df)\nmarket.fit()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd5845824c85f2191eea969c57b0727239548817"},"cell_type":"code","source":"market_train = market.get_data()\nlen(market_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c9853dd02560d5984b0cef48751c7a48951f4ad"},"cell_type":"code","source":"# free up some space\ndel market_train_df\nmarket_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f6057b42a0a2c35a2d42d00f8a978552db4361a"},"cell_type":"code","source":"#lots of report by reuters likely to drop this feature\nplt.figure(figsize = (10, 5))\n(news_train_df['provider'].value_counts()/100)[:10].plot('bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41876209cfc1bb20657c344e9e17434ee3a41473"},"cell_type":"code","source":"#sentiment_class\n\nplt.figure(figsize = (10, 5))\nnews_train_df['sentimentClass'].value_counts().plot('bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c109464b9cf2fb5b195e393e71d7e89699ab55e0"},"cell_type":"code","source":"#urgency_class\n#one or three\nnews_train_df['urgency'].value_counts().plot('bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa098e082839a9c5119a5344cc1eceeb056def09"},"cell_type":"code","source":"#most articles generally have high relevance\nsns.distplot(news_train_df['relevance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9009324126cb7e3b36ce61c15531b8cdcfb00b9c"},"cell_type":"code","source":"news_cols_numeric = ['urgency', 'takeSequence', 'wordCount', 'sentenceCount', 'companyCount',\n                         'marketCommentary', 'relevance', 'sentimentNegative', 'sentimentNeutral',\n                         'sentimentPositive', 'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n                         'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n                         'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D', 'volumeCounts7D']\nflg, ax = plt.subplots(figsize = (10, 10))\ncorr = news_train_df[news_cols_numeric].corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d77d8a8f7977967dfd1875a451feb54b76d797a"},"cell_type":"code","source":"class process_news:\n    def __init__(self, news_df):\n        self.data = news_df.copy()\n\n       \n    def transform(self):\n                \n        dublet =  ['urgency', 'marketCommentary','relevance', 'sentimentClass',\n       'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n       'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n       'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n       'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D',\n       'volumeCounts7D']\n        #replace null values with zero\n     \n        self.data['firstCreated'] = self.data['firstCreated'].dt.date\n        self.data['assetCodes'] = self.data['assetCodes'].apply(lambda x: list(eval(x))[0]).apply(lambda x : x.split('.')[0])\n        self.data[dublet] = self.data.groupby(['firstCreated', 'assetCodes'])[dublet].transform('mean')\n        return self.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3d4fe6f394443f8c8e923281ed4104985b91e8c"},"cell_type":"code","source":"news = process_news(news_train_df)\nnews_data = news.transform()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be6a5677eb29cf8692d4626785e57d2239e3bc01","scrolled":false},"cell_type":"code","source":"# # news_train_df['firstCreated'].dt.date\ndel news_train_df\ndel process_news","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"347098fd81f91387510a2ec3697536b7e6f2c55d"},"cell_type":"code","source":"news_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61465112a4c38c653eb03a23ff275c9786acd222"},"cell_type":"code","source":"def combine_sub(market_data, news_data, is_test = False):\n    feature_cols = ['assetCode', 'volume', 'open', \n        'returnsOpenPrevRaw1', 'returnsOpenPrevMktres1', 'returnsOpenPrevRaw10',\n        'returnsOpenPrevMktres10', \n        'month', 'close/open', 'urgency',\n       'marketCommentary',\n        'relevance', 'sentimentClass',\n       'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n       'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n       'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n       'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D',\n       'volumeCounts7D']\n    \n    if not is_test:\n        feature_cols.append('returnsOpenNextMktres10')\n    if not is_test:\n        market = pd.merge(market_data, news_data, how='left', left_on=['time', 'assetCode'], \n                                right_on=['firstCreated', 'assetCodes'])\n    else:\n        market = pd.merge(market_data, news_data, how='left', left_on=['assetCode'], \n                                right_on=['assetCodes'])\n    #enumerate asset code\n    lbl = {k: v for v, k in enumerate(market['assetCode'].unique())}\n    market['assetCode'] = market['assetCode'].map(lbl)\n        \n    market = market[feature_cols]\n    market = market.drop_duplicates()\n    \n    target = None\n    if not is_test:\n        market.dropna(0, inplace = True)\n        target = market['returnsOpenNextMktres10']\n        market.drop(['returnsOpenNextMktres10'], axis = 1, inplace = True)\n       \n    else:\n        market.fillna(0, inplace = True)\n                      \n    return market, target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5f25c3997c8d91c2222a5e0af68ad81b9856831"},"cell_type":"code","source":"market, label = combine_sub(market_train, news_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70e54cdb4f632ceaae994d60dea320244992067f"},"cell_type":"code","source":"#write to csv file\n# market.to_csv('train_modified', sep=',')\n# label.to_csv('train_label', sep = ',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84abec7f3a6a039313b806e7101ff66e2ce2ef22"},"cell_type":"code","source":"label = label.apply(lambda x : 1 if x > 0 else -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27ec9b21e1a5ac08db722f96fa474a4cabd4bef2"},"cell_type":"code","source":"#build graph\n\ndef build_graph(num_feat):\n    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    model = Sequential()\n    model.add(BatchNormalization())\n    model.add(Dense(26, input_dim=num_feat, kernel_initializer='uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, kernel_initializer='uniform', activation='tanh'))\n\n    model.compile(loss = 'mean_squared_error',\n                 optimizer = optimizer, \n                 metrics = ['mse'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"119921aef1af3934003e4ca743a24d086d942bf0","scrolled":true},"cell_type":"code","source":"num_feat = market.shape[1]\nfilepath=\"weights1.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\nmodel = build_graph(num_feat)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dcc20d0f01c9eda36c54dcdda98032c2acd2678","scrolled":true},"cell_type":"code","source":"history = model.fit(market.values, label.values, validation_split=0.20, epochs=40, batch_size=256, callbacks=callbacks_list, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c549837720a13d1afb1e13601fb2b984abb0b609"},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ab95a0931bef6ca6deb8ccffa150bcbc368312"},"cell_type":"code","source":"class process_news_test:\n    def __init__(self, news_df):\n        self.data = news_df.copy()\n\n       \n    def transform(self):\n                \n        dublet =  ['urgency', 'marketCommentary','relevance', 'sentimentClass',\n       'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n       'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n       'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n       'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D',\n       'volumeCounts7D']\n        #replace null values with zero\n     \n        self.data['firstCreated'] = self.data['firstCreated'].dt.date\n        self.data['assetCodes'] = self.data['assetCodes'].apply(lambda x: list(eval(x))[0]).apply(lambda x : x.split('.')[0])\n        self.data[dublet] = self.data.groupby(['assetCodes'])[dublet].transform('mean')\n        return self.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"257fcb9b9ed999f6e41042f4a6eb07596ecaeb34"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52c124f2f6792947f981b0e92be8bfcc942cedc3"},"cell_type":"code","source":"model.load_weights(\"weights1.best.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9120d1cb89b77c10e54a2c83927acc093565cfee"},"cell_type":"code","source":"for (market_obs_df, news_obs_df, predictions_template_df) in days:\n        \n    market = preprocess_market(market_obs_df, is_test = True)\n    market.fit()\n    market_test = market.get_data()\n    \n    news = process_news_test(news_obs_df)\n    news_test = news.transform()\n    \n    market_news, label = combine_sub(market_test, news_test, is_test = True)\n    \n    predictions_template_df.confidenceValue = model.predict(market_news.values)\n    env.predict(predictions_template_df)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"776b85cd720007c2e3f77dfbcb4c5fce8c6618c6"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71cc7ae5695743edc22169113510e34639846ad5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}