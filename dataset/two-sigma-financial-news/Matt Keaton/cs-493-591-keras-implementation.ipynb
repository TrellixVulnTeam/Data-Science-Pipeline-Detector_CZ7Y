{"cells":[{"metadata":{"_uuid":"7b6e603b43eef47c413f0abc2b81c24d4d9b1d0b"},"cell_type":"markdown","source":"This implementation will be heavily based on the Keras library. Certain aspects, such as developing the testing structure, will be taken from scikit-learn in order to test the results of the Keras implementation to our scikit-learn implementation."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n# Import environment\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import training dataset\n(market_train_df, _) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d557eeaff0f8cfe3745c6b47859bb0689066c39"},"cell_type":"markdown","source":"<font size = 5>**Data Pre-Processing**</font>"},{"metadata":{"trusted":true,"_uuid":"56c6ea7af2a4701b94688540f19509ddd916850b"},"cell_type":"code","source":"# process data\ndef process_merged_data(df):\n    # Drop rows with NaN values\n    df = df.dropna()\n    # Let's choose our features\n    features = ['time','returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10','returnsOpenPrevMktres10','returnsOpenNextMktres10']\n    X = df[features]\n    return X\n\nmarket_data_no_outlier = process_merged_data(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe1d934efc5f3e4e8286407e41a18e03ddfff615"},"cell_type":"markdown","source":"Removing outliers - **MAY REMOVE LATER**"},{"metadata":{"trusted":true,"_uuid":"b373227957b24180d8d410a7fe97eeacbbc9d316","scrolled":true},"cell_type":"code","source":"def remove_outlier(df,column_list,lower_percentile,upper_percentile):\n    for i in range(len(column_list)):\n        df = (df[(df[column_list[i]]<np.percentile(df[column_list[i]],upper_percentile)) & (df[column_list[i]]>np.percentile(df[column_list[i]],lower_percentile))])\n    return df\noutlier_removal_list = [ 'returnsClosePrevRaw1',\n                         'returnsOpenPrevRaw1',\n                         'returnsClosePrevRaw10',\n                         'returnsOpenPrevRaw10']\nmarket_data_no_outlier = remove_outlier(market_data_no_outlier,outlier_removal_list,2,98)\nprint(\"Number of data decreased from \",len(market_train_df['returnsOpenNextMktres10']),\" to \",len(market_data_no_outlier['returnsOpenNextMktres10']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5f547b00ea79336838dae7d97edcbc803d0a2ab"},"cell_type":"markdown","source":"Dropping rows containing NaN values from Market Data"},{"metadata":{"trusted":true,"_uuid":"47564e9b202a5a5ff400d24c7fda1ee62bb8787a","scrolled":true},"cell_type":"code","source":"# Test\nmarket_data_no_outlier.columns.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caaed0a67a8276891dd4a857b995efa6bce722f8"},"cell_type":"markdown","source":"Final Feature Selection"},{"metadata":{"trusted":true,"_uuid":"e863a5121bff2e657cf2f0812f5ad9002044014d"},"cell_type":"code","source":"X = market_data_no_outlier[['returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10']].copy()\ny = market_data_no_outlier[['returnsOpenNextMktres10']].copy()\ntime = market_data_no_outlier[['time']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b5cf479d83136d0224d0cd19f2169f0735f2490"},"cell_type":"code","source":"X.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfae8930dccebbbe39c9a457dc76ec09a34dfcb2"},"cell_type":"code","source":"y.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4d8e0afe2704fc13eb3ef9a1a19306edafdde6c"},"cell_type":"code","source":"time.columns.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d2f1d4c3ab2cbd85a23bb0331cc4cb6eb0a692e"},"cell_type":"markdown","source":"Standardize Data"},{"metadata":{"trusted":true,"_uuid":"bc8684bb3d25ddf84d7e73fcd94e1912a0524365"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef scale_data(df,features):\n    scaler = StandardScaler()\n    df[features]=scaler.fit_transform(df[features])\n    return df\nmarket_data_no_outlier_scaled = scale_data(market_data_no_outlier,X.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"303ab6272ae907011d5c3f6ad3e15fff1a075b7c"},"cell_type":"markdown","source":"Splitting Data into Training and Validation - Cross-validation using k-fold testing"},{"metadata":{"trusted":true,"_uuid":"678ef5c7001c7a6c6b6515f7103e568ecfcd284b"},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5) # Define the split - into 5 folds \nprint(kf) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9819e8646dd0afaea51d64a1c116822600b18842"},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64fc522393a4591aae483ce9d10e891df9179c4e"},"cell_type":"markdown","source":"<font size=\"6\">**Run Neural Network: **</font>  \n<font size=\"6\"></font>"},{"metadata":{"_uuid":"3d0b2dca4d3f7bc6a795eab03927876b77ba8352"},"cell_type":"markdown","source":"Network Definition"},{"metadata":{"trusted":true,"_uuid":"8603e0b2b2cb8505ac9e7817595f2653b4d45d14"},"cell_type":"code","source":"# Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,BatchNormalization,Input\nfrom keras.optimizers import Adam\n\n# Initialize Model\nmodel = Sequential()\n# Input layer & hidden layer\nmodel.add(Dense(5, input_shape=(X.shape[1],), activation='relu'))\nmodel.add(Dense(5,activation='relu'))\n# Output layer\nmodel.add(Dense(1))\n# Compile the architecture and view summary\noptimizer = Adam(lr=0.001)\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f15369dbb8fe343b0b01a645eac33034e6a0cd4e"},"cell_type":"markdown","source":"*- Try to understand early stopping and callbacks"},{"metadata":{"trusted":true,"_uuid":"6944496c0ce7d849ae6020d39eab201aa280eff1","scrolled":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint,EarlyStopping\n\n# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_acc', verbose = 1, save_best_only = True, mode ='auto')\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto',restore_best_weights=True)\ncallbacks_list = [early_stopping]\n# callbacks_list = [checkpoint,early_stopping]\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    train_time, test_time = time.iloc[train_index], time.iloc[test_index]\n# Change epoch number: for testing purposes\n    model.fit(x=X_train.values,y=y_train.values, epochs=5,shuffle=True,validation_data=(X_test.values, y_test.values), callbacks=callbacks_list)# validation_split=0.2)#) #, callbacks=callbacks_list)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94e3bc6c6ce324701d27566e97f8d2f745bbe290"},"cell_type":"markdown","source":"Sanity Checking:"},{"metadata":{"trusted":true,"_uuid":"530ea7a79369574206a0620ae609591c027d0d73"},"cell_type":"code","source":"data = {'y_real':y_test[:1],'y_pred':(model.predict(X_test.values[:1])).reshape(1,-1)[0]}\npd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6432554fff1d4c704fde30413be8651a7667af64"},"cell_type":"markdown","source":"Confidence Value creation:"},{"metadata":{"trusted":true,"_uuid":"7f10f294392f38f911e4afc744e517ee03853729"},"cell_type":"code","source":"import time\nstart_time = time.time()\nmy_pred_test = model.predict(X_test).reshape(1,-1)[0]\npositive_pred = my_pred_test[my_pred_test>=0]\nnegative_pred = my_pred_test[my_pred_test<0]\npos_min = positive_pred.min()\npos_max = positive_pred.max()\nneg_min = negative_pred.min()\nneg_max = negative_pred.max()\n\nfor i in range(len(positive_pred)):\n    positive_pred[i] = (positive_pred[i]-pos_min)/(pos_max - pos_min)\nfor m in range(len(negative_pred)):\n    negative_pred[m] = -1 + (negative_pred[m]-neg_min)/(neg_max-neg_min)\nelapsed_time = time.time() - start_time\nprint('It took', elapsed_time/60, 'minutes make predictions and scale them to confidence interval')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"819d51bc8c037d2c88497b407fff9dddd350beb6"},"cell_type":"code","source":"# def make_my_prediction(x):\n#     my_pred = (model.predict(x)).reshape(1,-1)[0]\n#     my_pred[my_pred>0]=1\n#     my_pred[my_pred<0]=-1\n#     return my_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"262148e78bfcfa1e2106e00ea99bcad7919876c4"},"cell_type":"code","source":"# my_pred_test = make_my_prediction(X_test)\n# my_pred_train = make_my_prediction(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c5531910c8c38df154c61ba688ff36a8419b653"},"cell_type":"code","source":"np.reshape(my_pred_test, (-1, 1))\nprint(my_pred_test.shape, \",\", y_test.values.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2769f06ac08408b5dd9dc6c7ee29aa823a044d25","scrolled":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndata = pd.DataFrame({'y_real':y_test.iloc[:,0],'y_predicted':my_pred_test})\ny_real = data.iloc[:,0]\nsample_y = y_real[0:100]\nsample_pred = data.iloc[0:100, 1]\nscaled_pred = sample_pred*50 - 0.2\ndiff = (sample_y)-(scaled_pred)\nt = range(0,100)\nplt.plot(t, scaled_pred)\nplt.plot(t, data.iloc[0:100, 0])\nplt.legend()\nplt.title('Real Return Values vs. Predicted\\nReturn Values for Keras Neural Network')\nplt.xlabel('Time (Days)')\nplt.ylabel('10 Day Leading Market Adjusted Return')\n\nplt.savefig('KerasPlot.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f101763832884680d174baa40a41684fe50e358"},"cell_type":"markdown","source":"Statistics:"},{"metadata":{"trusted":true,"_uuid":"d64b5a4bcff8f2961374b3c0e46f37be02ecc48d"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, explained_variance_score\nfrom sklearn.metrics import median_absolute_error, r2_score\nfrom sklearn.metrics import mean_absolute_error\n\nprint('mean_absolute_error is', mean_absolute_error(sample_y, sample_pred))\nprint('mean_squared_error is', mean_squared_error(sample_y, sample_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0440f49d3bbabaecafbc6e9d9a2d2e2c27ee5de3"},"cell_type":"markdown","source":"Sigma Score:"},{"metadata":{"trusted":true,"_uuid":"00c8bd3bb3f4a8cfd70b2c68261a96f47cdd1842"},"cell_type":"code","source":"# # sigma_score function is considered as a custom evaluation metric for xgboost\n# # example of how custom evaluation function is incorporated into xgboost's training can be found here : https://github.com/dmlc/xgboost/blob/master/demo/guide-python/custom_objective.py\n# def sigma_score(preds,dval,df):\n    \n#     # get y_target values\n#     labels = dval\n#     # call time parameter to be used for grouping, so that we can add x_t values for each day\n#     df_time = df\n    \n#     #calculate x_t and score as specified by the competition\n#     x_t = pd.Series(preds*labels)\n#     x_t_sum = x_t.groupby(df_time).sum()    \n#     score = (x_t_sum.mean())/(x_t_sum.std())\n#     return 'sigma_score', round(score,5)\n\n# print(\"Testing......\\n\")\n# my_pred_test = make_my_prediction(X_test.values)\n# print(\"test : \",sigma_score(my_pred_test,y_test,test_time))\n\n# my_pred_train = make_my_prediction(X_train.values)\n# print(\"train : \",sigma_score(my_pred_train,y_train,train_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dea0f1dcd679953044e7e259278e5053bd493f7"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}