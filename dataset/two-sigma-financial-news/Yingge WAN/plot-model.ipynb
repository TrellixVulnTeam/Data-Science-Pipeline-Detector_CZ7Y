{"cells":[{"metadata":{"_uuid":"512d64e04ad0533dd72ca6bcbca4882a7f289956"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom datetime import date, datetime, timedelta\nfrom sklearn.metrics import accuracy_score\nfrom kaggle.competitions import twosigmanews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11247d0cd2871de1b9551b7a511a9381c6375b4b"},"cell_type":"code","source":"env = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8d8dd40919f2270d5332427eb43f57f0df2e452"},"cell_type":"markdown","source":"# Merge & clean data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"start_date = date(2015,1,1)\n\n# (market_train, _) = env.get_training_data()\n(market_train_orig, news_train_orig) = env.get_training_data()\nmarket_train_df = market_train_orig.copy()\nnews_train_df = news_train_orig.copy()\nprint('Market train shape: ',market_train_df.shape)\nprint('News train shape: ', news_train_df.shape)\n\n# Sort data\nmarket_train_df = market_train_df.sort_values('time')\nmarket_train_df['date'] = market_train_df['time'].dt.date\n\n# Fill nan\nmarket_train_fill = market_train_df\ncolumn_market = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolumn_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\nfor i in range(len(column_raw)):\n    market_train_fill[column_market[i]] = market_train_fill[column_market[i]].fillna(market_train_fill[column_raw[i]])\nmarket_train_orig = market_train_orig.sort_values('time')\nnews_train_orig = news_train_orig.sort_values('time')\nmarket_train_df = market_train_orig.copy()\nnews_train_df = news_train_orig.copy()\ndel market_train_orig\ndel news_train_orig\nmarket_train_df = market_train_df.loc[market_train_df['time'].dt.date>=start_date]\nnews_train_df = news_train_df.loc[news_train_df['time'].dt.date>=start_date]\nmarket_train_df['close_open_ratio'] = np.abs(market_train_df['close']/market_train_df['open'])\nthreshold = 0.5\nprint('In %i lines price increases by 50%% or more in a day' %(market_train_df['close_open_ratio']>=1.5).sum())\nprint('In %i lines price decreases by 50%% or more in a day' %(market_train_df['close_open_ratio']<=0.5).sum())\nmarket_train_df = market_train_df.loc[market_train_df['close_open_ratio'] < 1.5]\nmarket_train_df = market_train_df.loc[market_train_df['close_open_ratio'] > 0.5]\nmarket_train_df = market_train_df.drop(columns=['close_open_ratio'])\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom nltk.corpus import stopwords\ncolumn_market = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolumn_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\n#the top hundred words.\nvectorizer = CountVectorizer(max_features=1000, stop_words={\"english\"})\n#we do this with TF-IDF.\nX = vectorizer.fit_transform(news_train_df['headline'].values)\ntf_transformer = TfidfTransformer(use_idf=False).fit(X)\nX_train_tf = tf_transformer.transform(X)\nX_train_vals = X_train_tf.mean(axis=1)\n\n\ndel vectorizer\ndel X\ndel X_train_tf\n\n#mean tf-idf score for news article.\nd = pd.DataFrame(data=X_train_vals)\nnews_train_df['tf_score'] = d\n\nmarket_train_df = market_train_df.loc[market_train_df['time'].dt.date>=start_date]\nnews_train_df = news_train_df.loc[news_train_df['time'].dt.date>=start_date]\n\n#add indicator features\nmarket_train_df['rolling_average_close_mean'] = market_train_df.groupby('assetCode')['close'].transform('mean')\nmarket_train_df['rolling_average_vol_mean'] = market_train_df.groupby('assetCode')['volume'].transform('mean')\nmarket_train_df['rolling_average_close_std'] = market_train_df.groupby('assetCode')['close'].transform('std')\nmarket_train_df['rolling_average_vol_std'] = market_train_df.groupby('assetCode')['volume'].transform('std')\n#some more refined instruments\nmarket_train_df['moving_average_7_day'] = market_train_df.groupby('assetCode')['close'].transform(lambda x: x.rolling(window=7).mean())\newma = pd.Series.ewm\nmarket_train_df['ewma'] =  market_train_df.groupby('assetCode')['close'].transform(lambda x : ewma(x, span=30).mean())\nmarket_train_df['moving_average_7_day'] = market_train_df['moving_average_7_day'].fillna(0)\nmarket_train_df['ewma'] = market_train_df['ewma'].fillna(0)\nfor i in range(len(column_raw)):\n    market_train_df[column_market[i]] = market_train_df[column_market[i]].fillna(market_train_df[column_raw[i]])\n    print('Removing outliers ...')\ncolumn_return = column_market + column_raw + ['returnsOpenNextMktres10']\norig_len = market_train_df.shape[0]\nfor column in column_return:\n    market_train_df = market_train_df.loc[market_train_df[column]>=-2]\n    market_train_df = market_train_df.loc[market_train_df[column]<=2]\nnew_len = market_train_df.shape[0]\nrmv_len = np.abs(orig_len-new_len)\nprint('There were %i lines removed' %rmv_len)\nprint('Removing strange data ...')\norig_len = market_train_df.shape[0]\nmarket_train_df = market_train_df[~market_train_df['assetCode'].isin(['PGN.N','EBRYY.OB'])]\n#market_train_df = market_train_df[~market_train_df['assetName'].isin(['Unknown'])]\nnew_len = market_train_df.shape[0]\nrmv_len = np.abs(orig_len-new_len)\nprint('There were %i lines removed' %rmv_len)\n# Function to remove outliers\ndef remove_outliers(data_frame, column_list, low=0.02, high=0.98):\n    for column in column_list:\n        this_column = data_frame[column]\n        quant_df = this_column.quantile([low,high])\n        low_limit = quant_df[low]\n        high_limit = quant_df[high]\n        data_frame[column] = data_frame[column].clip(lower=low_limit, upper=high_limit)\n    return data_frame\ncolumns_outlier = ['takeSequence', 'bodySize', 'sentenceCount', 'wordCount', 'sentimentWordCount', 'firstMentionSentence','noveltyCount12H',\\\n                  'noveltyCount24H', 'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H', 'volumeCounts24H',\\\n                  'volumeCounts3D','volumeCounts5D','volumeCounts7D']\nprint('Clipping news outliers ...')\nnews_train_df = remove_outliers(news_train_df, columns_outlier)\nasset_code_dict = {k: v for v, k in enumerate(market_train_df['assetCode'].unique())}\ndrop_columns = [col for col in news_train_df.columns if col not in ['sourceTimestamp', 'urgency', 'takeSequence', 'bodySize', 'companyCount', \n               'sentenceCount', 'firstMentionSentence', 'relevance','firstCreated', 'assetCodes']]\ncolumns_news = ['firstCreated','relevance','sentimentClass','sentimentNegative','sentimentNeutral',\n               'sentimentPositive','noveltyCount24H','noveltyCount7D','volumeCounts24H','volumeCounts7D','assetCodes','sourceTimestamp',\n               'assetName','audiences', 'urgency', 'takeSequence', 'bodySize', 'companyCount', \n               'sentenceCount', 'firstMentionSentence','time', 'tf_score']\ndef data_prep(market_df,news_df):\n    market_df['date'] = market_df.time.dt.date\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df.drop(['time'], axis=1, inplace=True)\n    \n    news_df = news_df[columns_news]\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['len_audiences'] = news_train_df['audiences'].map(lambda x: len(eval(x)))\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['date', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n    del news_df\n#     market_df['assetCodeT'] = market_df['assetCode'].map(asset_code_dict)\n    market_df = market_df.drop(columns = ['firstCreated','assetCodes','assetName']).fillna(0) \n#     print(market_df.count)\n    return market_df\nprint('Merging data ...')\nmarket_train_df = data_prep(market_train_df, news_train_df)\nmarket_train_df = market_train_df.loc[market_train_df['date']>=start_date]\nmarket_train = market_train_df\n\ndel market_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f7dec87a5f584037d01bd19ed066f5fd944aaf"},"cell_type":"code","source":"market_train.describe().round(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7be6288dd6462e2d0b7d5eae2fa70d748a82a1b"},"cell_type":"markdown","source":"# Prepare model"},{"metadata":{"trusted":true,"_uuid":"5dfa1843dfece6fccfca91896ef85a332b55e3e6"},"cell_type":"code","source":"# cat_cols = ['assetCode']\n# num_cols = ['volume',\n#             'close',\n#             'open',\n#             'returnsClosePrevRaw1',\n#             'returnsOpenPrevRaw1',\n#             'returnsClosePrevMktres1',\n#             'returnsOpenPrevMktres1',\n#             'returnsClosePrevRaw10',\n#             'returnsOpenPrevRaw10',\n#             'returnsClosePrevMktres10',\n#             'returnsOpenPrevMktres10']\ncat_cols = ['assetCodeT']\nnum_cols = ['volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', \n               'returnsClosePrevMktres10', 'returnsOpenPrevMktres10', 'close_to_open', 'rolling_average_close_mean', 'rolling_average_vol_mean', 'rolling_average_close_std', 'ewma', 'rolling_average_close_std', 'sourceTimestamp', 'urgency', 'companyCount', 'takeSequence', 'bodySize', 'sentenceCount',\n               'moving_average_7_day','relevance', 'sentimentClass', 'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n               'noveltyCount24H','noveltyCount7D','volumeCounts24H','volumeCounts7D','assetCodesLen', 'asset_sentiment_count', 'len_audiences', 'tf_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e108339134e95473b4a983237d58adb64c3ef64a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_indices, val_indices = train_test_split(market_train.index.values,\n                                              test_size=0.25,\n                                              random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f51d00dc43857b446ae4a24b3718753f09040fd5"},"cell_type":"markdown","source":"# Handling categorical variables"},{"metadata":{"trusted":true,"_uuid":"301a65b834d8614a914883d49be1860550174f06"},"cell_type":"code","source":"def encode(encoder, x):\n    len_encoder = len(encoder)\n    try:\n        id = encoder[x]\n    except KeyError:\n        id = len_encoder\n    return id\n\nencoders = [{} for cat in cat_cols]\n\n\n# for i, cat in enumerate(cat_cols):\n#     print('encoding %s ...' % cat, end=' ')\n#     encoders[i] = {l: id for id, l in enumerate(market_train.loc[train_indices, cat].astype(str).unique())}\n#     market_train[cat] = market_train[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n#     print('Done')\n\nmarket_train['assetCodeT'] = market_train['assetCode'].astype(str).apply(lambda x: encode(encoders[0], x))\nembed_sizes = [len(encoder) + 1 for encoder in encoders] #+1 for possible unknown assets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eae09951757845ad5bdf08e004e6477513ed739a"},"cell_type":"markdown","source":"# Define NN Architecture"},{"metadata":{"trusted":true,"_uuid":"f8661c00b3363e610d2ed00fdb86b507a71a41c3"},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization, Dropout\nfrom keras.losses import binary_crossentropy\n\ncategorical_inputs = []\nfor cat in cat_cols:\n    categorical_inputs.append(Input(shape=[1], name=cat))\n\ncategorical_embeddings = []\nfor i, cat in enumerate(cat_cols):\n    categorical_embeddings.append(Embedding(embed_sizes[i], 10)(categorical_inputs[i]))\n\n#categorical_logits = Concatenate()([Flatten()(cat_emb) for cat_emb in categorical_embeddings])\ncategorical_logits = Flatten()(categorical_embeddings[0])\ncategorical_logits = Dense(32,activation='relu')(categorical_logits)\ncategorical_logits = Dropout(0.5)(categorical_logits)\ncategorical_logits = BatchNormalization()(categorical_logits)\ncategorical_logits = Dense(32,activation='relu')(categorical_logits)\n\nnumerical_inputs = Input(shape=(len(num_cols),), name='num')\nnumerical_logits = numerical_inputs\nnumerical_logits = BatchNormalization()(numerical_logits)\nnumerical_logits = Dense(128,activation='relu')(numerical_logits)\n\nnumerical_logits = Dropout(0.5)(numerical_logits)\nnumerical_logits = BatchNormalization()(numerical_logits)\nnumerical_logits = Dense(128,activation='relu')(numerical_logits)\nnumerical_logits = Dense(64,activation='relu')(numerical_logits)\n\nlogits = Concatenate()([numerical_logits,categorical_logits])\nlogits = Dense(64,activation='relu')(logits)\nout = Dense(1, activation='sigmoid')(logits)\n\nmodel = Model(inputs = categorical_inputs + [numerical_inputs], outputs=out)\nmodel.compile(optimizer='adam',loss=binary_crossentropy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd6ac097d55ae74d4b7e660958c3bb00e8bc5569"},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fecfb9cfcf401170cc8e010d38ff08c11d7387bb"},"cell_type":"code","source":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}