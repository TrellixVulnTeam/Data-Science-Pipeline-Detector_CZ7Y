{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.ar_model import AR\nfrom kaggle.competitions import twosigmanews\n\nrandom.seed(42)\nnp.random.seed(42)\n\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"market_train_df, news_train_df = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fa7d6be4bfd3f1db2ec5f286d9e7a6e71ebfe47"},"cell_type":"code","source":"market_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"717308f11a76966a4092c489435fc261eff40f9c"},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b274ed0a495576f4ca4d020efe02132f0442d65"},"cell_type":"code","source":"market_train_df.assetCode.unique().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"639edd2c720f561cfb6e47e889100df770e4d4f3"},"cell_type":"code","source":"market_train_df[market_train_df.assetCode == 'AAPL.O'].plot(x='time', y='returnsOpenNextMktres10', figsize=(10, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5370c5969a57680943991379d447e79c99c9709"},"cell_type":"code","source":"plot_acf(market_train_df[market_train_df.assetCode == 'AAPL.O'].returnsOpenNextMktres10, lags=30);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ce6e7b2b0e9ec0f69239e1321f90f1c95b83a25"},"cell_type":"code","source":"plot_pacf(market_train_df[market_train_df.assetCode == 'AAPL.O'].returnsOpenNextMktres10, lags=30);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c69be8cb51c912bb858716cb10d2470e5acff7b2"},"cell_type":"markdown","source":"We should restructure our dataset so we can train a multivariate ARIMA.\nUnfortunately, `pd.get_dummies()` kills kernel, so we'll have to gather features ourselves :("},{"metadata":{"trusted":true,"_uuid":"739b21a98a8db65ad2919ef1387d9179934157b9"},"cell_type":"code","source":"from tqdm import tqdm\n\nassets = market_train_df.assetCode.unique()\ngroups = market_train_df.groupby('assetCode').groups\n# df = pd.DataFrame(index=market_train_df.time.unique())\ndf = {}\n\nfor asset in tqdm(assets):\n    #df[asset] = market_train_df.iloc[groups[asset]].set_index('time').returnsOpenNextMktres10\n    df[asset] = market_train_df.iloc[groups[asset]].returnsOpenNextMktres10.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d390824b8d466822619f808efe0e2ac8292d7470"},"cell_type":"code","source":"for asset in assets:\n    df[asset] = df[asset][~np.isnan(df[asset])]\n    df[asset] = df[asset][-250:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"608786a457092cc81066c231ca86e0f5d89df5bf"},"cell_type":"code","source":"lens = [len(df[asset]) for asset in assets]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c912b7b9183a3c9a3f55e2a557fba5f0596a3fd"},"cell_type":"code","source":"plt.hist(lens);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e79fdbf51bbbbab1cc09736a2ed186d89fefd15"},"cell_type":"code","source":"min(lens)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fec260505f972e28339fd0fcbf428e1e5fee254"},"cell_type":"markdown","source":"Finding best hp via cross validation"},{"metadata":{"trusted":true,"_uuid":"f14f9131d0106b89780851cc674250b0113eba2f"},"cell_type":"code","source":"import warnings; warnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1e821a2c1d68e8b1f50c553ae55e04e36ca3531"},"cell_type":"markdown","source":"Unfortunately ARIMA model is too slow to train, that's why we'll use AR model"},{"metadata":{"trusted":true,"_uuid":"55309d0e33d59b38b7603a829d22d4ef2ef001b8"},"cell_type":"code","source":"# from tqdm import tqdm\n# from sklearn.metrics import mean_squared_error\n\n# targets = [df[asset][-1] for asset in assets]\n# scores = []\n# hps = []\n\n# NUM_ASSETS_FOR_VAL = 100\n# assets_to_use = random.sample(list(assets), NUM_ASSETS_FOR_VAL)\n# targets_to_use = [t for t,a in zip(targets, assets) if a in set(assets_to_use)]\n\n# for history_size in [250, 100, 50]:\n#     for p in [5, 3, 1]:\n#         for d in [1, 0]:\n#             for q in [3, 1]:\n#                 order = (p, d, q)\n\n#                 predictions = []\n\n#                 for asset in tqdm(assets_to_use):\n#                     train = df[asset][-history_size:-1]\n\n#                     try:\n#                         model = ARIMA(train, order).fit()\n#                         pred = model.forecast()[0][0]\n#                         if np.isnan(pred): pred = 0.\n#                         predictions.append(pred)\n#                     except ValueError:\n#                         predictions.append(0.)\n#                     except np.linalg.LinAlgError:\n#                         predictions.append(0.)\n\n#                 scores.append(mean_squared_error(targets_to_use, predictions))\n#                 hps.append([history_size, order])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e42c02a63a19d904bfdd6e86f63aca8950de75ea"},"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\n\ntargets = [df[asset][-1] for asset in assets]\nscores = []\nhps = []\n\nfor history_size in [500, 250, 100, 50]:\n    predictions = []\n\n    for asset in tqdm(assets):\n        train = df[asset][-history_size:-1]\n\n        try:\n            model = AR(train).fit()\n            pred = model.predict()[-1]\n            if np.isnan(pred): pred = 0.\n            predictions.append(pred)\n        except ValueError:\n            predictions.append(0.)\n        except np.linalg.LinAlgError:\n            predictions.append(0.)\n\n    scores.append(mean_squared_error(targets, predictions))\n    hps.append(history_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1191b0128742a314364a99bc037333d1ec40fb0f"},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86cc8fed37c675aec2c3badbf295c6ccd09f8de4"},"cell_type":"code","source":"print('Best found hp:', hps[np.argmin(scores)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32dea4196994be5fc490b34ca3520b88a07ac11f"},"cell_type":"markdown","source":"Interestingly, but using history of size only 100 works much better, then using history of size 500!"},{"metadata":{"trusted":true,"_uuid":"ac715bcba42a809641e28233dd472071e3cbd41d"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e94609e778c5bc0285bb0127ab4eca530b601c3"},"cell_type":"code","source":"# env.predict(predictions.reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec094568e4376313c4d17934883ee5122b9db1a8"},"cell_type":"code","source":"# order = (1, 1, 3)\nhistory_size = 100\n\nfor (obs, _, predictions) in tqdm(days):\n    predictions.set_index('assetCode', inplace=True)\n    obs_dict = {row.assetCode: row.returnsOpenPrevMktres10 for row in obs.itertuples()}\n\n    for asset in obs_dict:\n        if asset in df:\n            df[asset] = np.concatenate([[obs_dict[asset]], df[asset]])\n            df[asset] = df[asset][~np.isnan(df[asset])]\n            df[asset] = df[asset][-history_size:]\n        else:\n            df[asset] = np.array([obs_dict[asset]])\n\n    for asset in obs_dict:\n        try:\n            #model = ARIMA(df[asset], order).fit(maxiter=50)\n            #pred = model.forecast()[0][0]\n            model = AR(df[asset]).fit()\n            pred = model.predict()[-1]\n            if np.isnan(pred): pred = 0.\n        except ValueError:\n            pred = 0.\n        except np.linalg.LinAlgError:\n            pred = 0.\n        \n        predictions.ix[asset, 'confidenceValue'] = pred\n    \n    #predictions = pd.DataFrame(predictions)\n    predictions.confidenceValue.clip(-1, 1, inplace=True)\n    env.predict(predictions.reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ecb78f309e4f59e2b9ab127335ae6da0513e9b9"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}