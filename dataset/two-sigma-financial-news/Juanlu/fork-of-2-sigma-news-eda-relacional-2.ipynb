{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thanks to all the contributors with kernels to this competition!\n\nSpecially, to the ones that provided code and comments that inspired us making this and other kernels we developed in the context of this competition:\n\nhttps://www.kaggle.com/dmdm02/complete-eda-voting-lightgbm\n\nhttps://www.kaggle.com/chocozzz/two-sigma-news-simple-eda-prophet-nlp\n\nhttps://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach\n\nhttps://www.kaggle.com/jsaguiar/baseline-with-news\n\nhttps://www.kaggle.com/artgor/eda-feature-engineering-and-everything\n\nhttps://www.kaggle.com/christofhenkel/market-data-nn-baseline\n\nhttps://www.kaggle.com/smasar/tutorial-timeseriesapproach\n\nhttps://www.kaggle.com/rabaman/0-64-in-100-lines\n\nhttps://www.kaggle.com/guowenrui/market-nn-if-you-like-you-can-use-it-and-upvote/notebook\n\nhttps://www.kaggle.com/smasar/eda-preprocessing-processing-evaluation"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"Importar librerías"},{"metadata":{"_uuid":"e2524e66838667e802b1fe2a999502b6554f4b8f","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nplt.style.use('seaborn')\nsns.set(font_scale=2)\n\nimport random\ndef generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: random.randint(0, 255), range(3)))\n    return color\n\nimport warnings \nwarnings.filterwarnings('ignore')\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdd83f326e1787df94e1a11e7a3bfa3e23dd32ac"},"cell_type":"markdown","source":"Crear entorno"},{"metadata":{"_uuid":"a99c0e803afb4d179d0c33f7bb73b4458fe3b43d","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e08403c881b7963f4ad31a9a1ac31daca547125b"},"cell_type":"markdown","source":"Carga de los datos de training"},{"metadata":{"_uuid":"048583ec640b32ca30a238ca81b5660fe0dbff59","trusted":true},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bacce382ae10b3cf53cda4f94062912208477a4"},"cell_type":"markdown","source":"Dadas las características del proyecto, de cara a poder medir la accuracy, simplemente consultamos las características de los ficheros de test... pero no vamos a usarlos en lo sucesivo, sino que vamos a coger un subconjunto de los ficheros de train, que tengan las mismas características: los datos de mercados del último día y los datos del fichero de noticias posteriores a las 22h del penúltimo día (más todos los del último día). "},{"metadata":{"_uuid":"6e6015669efb4c966c23b47b251dcd6d6d5e5468","trusted":true},"cell_type":"code","source":"#del market_test_df, news_test_df\n\nsplit = '2016-12-29 22:00:00+00:00'\n\nmarket_test_df = market_train_df.loc[market_train_df['time'] > split]\nnews_test_df = news_train_df.loc[news_train_df['time'] > split]\n\nmarket_train_df = market_train_df.loc[market_train_df['time'] <= split].reset_index(drop=True)\nnews_train_df = news_train_df.loc[news_train_df['time'] <= split].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"In market_train_df: \", market_train_df.shape);print(\"In market_test_df: \", market_test_df.shape);\nprint(\"In news_train_df: \", news_train_df.shape);print(\"In news_test_df: \", news_test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.1.3 Análisis relacional entre variables\n\nAntes de nada, vamos a ver las matrices de correlación entre las variables de cada uno de los ficheros, como punto de partida para plantearnos evaluar relaciones cruzadas entre variables.\n\nPrimero, la del fichero de mercados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sólo mirando la matriz de correlación del fichero de mercados, se pueden extraer varias conclusiones:\n\n- hay una altísima correlación entre las variables \"open\" y \"close\". Lo cuál parece bastante lógico, ya que no debería ser muy frecuente variaciones muy fuertes en la cotización dentro de una misma sesión.\n- hay también muy altas correlaciones entre las variables \"Raw\" y las variables \"Mktres\" correspondientes. Esto también parece bastante lógico, pues debería estar bastante relacionado: el rendimiento interdiario al cierre en crudo, con el rendimiento interdiario al cierre ajustado al mercado, el rendimiento inter-diez-días al cierre en crudo, con el rendimiento inter-diez-días al cierre ajustado al mercado, ... y así para todas las \"Raw\"/\"Mktres\".\n- hay algunas relaciones también significativas, aunque no tan altas, entre:\n    a. returnClosePrevRaw1 y returnClosePrevRaw10\n    b. returnClosePrevRaw1 y returnClosePrevMktres10\n    c. returnClosePrevMktres1 y returnClosePrevRaw10\n    d. returnClosePrevMktres1 y returnClosePrevMktres10\n  lo cuál también tiene una cierta lógica también, ya que lo \"normal\" sería que los rendimientos a un día y a 10 días estén relacionados.\n- esas mismas relaciones significativas, no se presentan entre las variables \"Open\".\n- y, sobre todo, llama la atención que no hay ninguna relación significativa entre la variable objetivo y ninguna otra variable.\n\n\nLa conclusión sobre la baja correlación de la variable objetivo con el resto de variables nos preocupa, así que decidimos hacer una prueba para ver si podemos detectar alguna relación significativa que no se detecte a primera vista.\n\nTeniendo en cuenta de lo que estamos hablando, mercados... y del horizonte temporal que estamos manejando, desde 2007... pensamos que el periodo de la crisis financiera puede estar causando cierta distorsión.\n\nVeamos la evolución temporal de las cotizaciones al cierre, por cuantiles:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\n#market_train_df['close'] = market_train_df['close'] / 20\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['close'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['close'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of closing prices by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo primero que llama la atención, efectivamente, es la caída de las cotizaciones entre 2008 y 2009.\n\nSe pueden apreciar más bajadas significativas (principipalmente se ven 4)... pero lo que se aprecia entre 2008 y 2009, como ya sabíamos previamente, es realmente algo sin parangón.\n\n\nOtro dato curioso es que se aprecia cómo lo cuantiles altos tienen una clara tendencia a la alza (desde 2010), mientras que cuantiles bajos no.\n\nPodría deberse a la entrada de más compañías pequeñas en el mercado, cuyo precio por acción es más bajo que el de las grandes compañías más asentadas.\n\n\nAhondemos más en el efecto de la crisis, echándole un vistazo a la variable objetivo"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['returnsOpenNextMktres10'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Returns (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver como, a pesar de haber muchas fluctuaciones... lo que era de esperar, las fluctuaciones en 2009 son algo fuera de lo común.\n\nEliminemos todo lo anterior a 2010 y volvamos a ver la evolución de la variable objetivo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']\n\nprice_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].mean().reset_index()\n\ndata.append(go.Scatter(\n    x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = price_df['returnsOpenNextMktres10'].values,\n    name = f'{i} quantile'\n))\nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 mean\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Returns (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aunque sigue habiendo muchas fluctuaciones, como obviamente ocurre en los mercados, se trata de un conjunto de datos con un comportamiento mucho más estable.\n\nEsto nos hace plantearnos la siguiente pregunta:\n- deberíamos conservar todos los datos de los que disponemos, para el posterior análisis?\n- o deberíamos quedarnos con el conjunto de datos más estable... y predecible?\n\nNo hay una respuesta buena, pero para decidir lo condicionamos a lo siguiente...\ncreemos que vamos a predecir un periodo de las características de la crisis financiera?\n\nLa verdad es que no... con lo que decidimos que, en adelante, vamos a quedarnos únicamente con los datos desde 2010.\n\n\nYa tenemos filtrado el fichero de mercados, así que... antes de que se nos olvide, vamos a filtrar también el fichero de noticias... aunque, en este caso, tomaremos los datos desde el final de la sesión anterior... esto es, desde las 22h del último día de 2009."},{"metadata":{"trusted":true},"cell_type":"code","source":"news_train_df = news_train_df.loc[news_train_df['time'] >= '2009-12-31 22:00:00+0000']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volviendo al fichero de mercados, veamos nuevamente la matriz de correlación... una vez eliminados los datos de la crisis de 2007-2009."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora, la matriz de correlación del fichero de mercados muestra mayores correlaciones:\n\n- sigue viéndose una altísima correlación entre las variables \"open\" y \"close\".\n- siguen viéndose muy altas correlaciones entre las variables \"Raw\" y las variables \"Mktres\" correspondientes. De hecho, incluso aumentan.\n- se mantienen relaciones también significativas, aunque no tan altas, entre:\n    a. returnClosePrevRaw1 y returnClosePrevRaw10\n    b. returnClosePrevRaw1 y returnClosePrevMktres10\n    c. returnClosePrevMktres1 y returnClosePrevRaw10\n    d. returnClosePrevMktres1 y returnClosePrevMktres10\n- pero esas correlaciones son aún más significativas entre las variables \"Open\":\n    a. returnOpenPrevRaw1 y returnOpenPrevRaw10\n    b. returnOpenPrevRaw1 y returnOpenPrevMktres10\n    c. returnOpenPrevMktres1 y returnOpenPrevRaw10\n    d. returnOpenPrevMktres1 y returnOpenPrevMktres10\n- e incluso aparece alguna correlación significativa entre variable \"Close\" y \"Open\".\n- y, sobre todo, llama la atención que aparecen algunas correlaciones superiores al 10% entre la variable objetivo y las variables \"Open\": returnOpenPrevRaw1, returnOpenPrevRaw10, returnOpenPrevMktres1 y returnOpenPrevMktres10.\n\nEsto nos reafirma en que el subconjunto de datos seleccionado es más apropiado y nos va a permitir realizar mejores predicciones.\n\n\nAhora, a modo ilustrativo, vamos a seleccionar un único activo y a ver la matriz de correlaciones para ese único activo.\n\nPara ello, vamos a comprobar la lista de activos con mayor volúmen de cotización y seleccionar de este modo uno que resulte significativo."},{"metadata":{"trusted":true},"cell_type":"code","source":"assetCode_df = market_train_df.groupby('assetCode')['volume'].sum().sort_values(ascending=False)\nassetCode_df[:15].plot.barh()\nplt.ylabel('assetCode')\nplt.xlabel('Trading volume')\nplt.title('Top 15 asset code by volume')\nplt.gca().invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para que resulte más inteligible, probaremos por el nombre:"},{"metadata":{"trusted":true},"cell_type":"code","source":"assetName_Volume = market_train_df.groupby('assetName')['volume'].sum().sort_values(ascending=False)\nassetName_Volume[:15].plot.barh()\nplt.ylabel('assetName')\nplt.xlabel('Trading volume')\nplt.title('Top 15 asset name by volume')\nplt.gca().invert_yaxis()\ndel assetName_Volume","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De la lista, podríamos escoger cualquiera, pero escogeremos las 5 primeras, que además corresponden a distintos sectores y por ello parecen bastante representativas.\n\nPara cada uno de ellos repetiremos la matriz de correlacción del fichero de mercados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"assetName = 'Bank of America Corp'\nsel_market_train_df = market_train_df[market_train_df['assetName']==assetName].sort_values(by='time',ascending=True) \n# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(sel_market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assetName = 'Ford Motor Co'\nsel_market_train_df = market_train_df[market_train_df['assetName']==assetName].sort_values(by='time',ascending=True) \n# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(sel_market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assetName = 'General Electric Co'\nsel_market_train_df = market_train_df[market_train_df['assetName']==assetName].sort_values(by='time',ascending=True) \n# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(sel_market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assetName = 'Microsoft Corp'\nsel_market_train_df = market_train_df[market_train_df['assetName']==assetName].sort_values(by='time',ascending=True) \n# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(sel_market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assetName = 'Intel Corp'\nsel_market_train_df = market_train_df[market_train_df['assetName']==assetName].sort_values(by='time',ascending=True) \n# Plot correlation\ncolumns_corr = ['returnsOpenNextMktres10', 'volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n           'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(sel_market_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('market_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que con cada compañía la matriz es diferente:\n- Siempre se puede comprobar la relación entre las variables \"Raw\" y \"Mktres\" correspondiente\n- pero, en cuanto a las variables que se presentan como significativas para la variable objetivo:\n    a. en un caso la más significativa parece el volúmen de cotización\n    b. en otro caso parecen ser las cotizaciones a la apertura y al cierre\n    c. en los otros tres casos parecen ser los retornos en los últimos 10 días (tanto \"Open\" como \"Close\", \"Raw\" y \"Mktres\") \n\nLo cuál ya nos da una primera conclusión...\npodría tener sentido hacer un modelo por cada compañía y probablemente la capacidad de predicción sea mucho mejor.\n\nNo obstante, aún es un poco pronto para pronunciarnos al respecto, pues el propósito fundamental de esta competición es el uso de las noticias para la predicción y, aún estamos únicamente con el fichero de mercados.\n\n\nPor otro lado, parece que puede resultar interesante abundar en las relaciones detectadas hasta el momento, centrándonos en:\n- relaciones entre variables \"Raw\" y \"Mktres\"\n- y, sobre todo, en relaciones entre la variable objetivo y el resto de variables."},{"metadata":{},"cell_type":"markdown","source":"Al comenzar a hacer estas comparaciones, nos damos cuenta de que aparecen ciertos atípicos en los retornos, que no permiten ver bien la relación entre las variables...\n\nEntonces recordamos aquellos valores atípicos que se habían detectado en la variable, open...\ny, dado que los retornos se calculan en base a variaciones en los valores open y close entre sesiones, decidimos hacer primero un análisis de la relación entre las variables:\n- open\n- close"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['close'], market_train_df['open'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('close')\nplt.ylabel('open')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos, efectivamente, cómo hay ciertos valores de open que no parecen lógicos... el valor al inicio de la sesión y al cierre, dentro de que varíen, lo normal es que se asemejen bastante.\n\nIntentemos calcularlo numéricamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby('time').agg({'price_diff': ['std', 'min']}).reset_index()\nprint(f\"Average standard deviation of price change within a day in {grouped['price_diff']['std'].mean():.4f}.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Efectivamente, la desviación estandar media de la diferencia de precio dentro de un día, vemos que es del 0.9916.\n\nAhora, intentemos detectar esas variaciones en el precio durante un día que no parecen realistas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] / market_train_df['open'])\n\nprint(f\"In {(market_train_df['close_to_open'] >= 1.2).sum()} lines price increased by 20% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.8).sum()} lines price decreased by 20% or more.\")\n\nprint(f\"In {(market_train_df['close_to_open'] >= 2).sum()} lines price increased by 100% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.5).sum()} lines price decreased by 100% or more.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que en muy pocos casos la variación es superior al 20%...\ny que en menos de 10 casos la variación es de más del 100%.\n\nDecidimos eliminar esos 9 casos antes de seguir adelante."},{"metadata":{"trusted":true},"cell_type":"code","source":"market_train_df = market_train_df.loc[market_train_df['close_to_open'] > 0.5]\nmarket_train_df = market_train_df.loc[market_train_df['close_to_open'] < 2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos nuevamente la relación entre open y close:"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['close'], market_train_df['open'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('close')\nplt.ylabel('open')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y ahora, tras haber eliminado esos atípicos...\nprocedamos a ver la relación entre los pares:\n- \"Raw\" rendimientos en crudo\n- \"Mktres\" rendimientos ajustados al mercado\n... tanto para las variables \"Open\" como \"Close\", tanto interdiarias como a 10 días:"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsClosePrevRaw1'], market_train_df['returnsClosePrevMktres1'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsClosePrevRaw1')\nplt.ylabel('returnsClosePrevMktres1')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsClosePrevRaw10'], market_train_df['returnsClosePrevMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsClosePrevRaw10')\nplt.ylabel('returnsClosePrevMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsOpenPrevRaw1'], market_train_df['returnsOpenPrevMktres1'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsOpenPrevRaw1')\nplt.ylabel('returnsOpenPrevMktres1')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsOpenPrevRaw10'], market_train_df['returnsOpenPrevMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsOpenPrevRaw10')\nplt.ylabel('returnsOpenPrevMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos lo que ya apuntaba la matriz de correlaciones, cuando mostraba aquellas diagonales de altas correlaciones entre cada variable de rendimientos en crudo y su correspondiente variable de rendimientos ajustados al mercado.\n\n\nAhora, centrémonos en la variable objetivo y en la correlación del resto de variables con ella:"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['volume'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('volume')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['close'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('close')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['open'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('open')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsClosePrevRaw1'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsClosePrevRaw1')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsOpenPrevRaw1'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsOpenPrevRaw1')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsClosePrevRaw10'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsClosePrevRaw10')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsOpenPrevRaw10'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsOpenPrevRaw10')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsClosePrevMktres1'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsClosePrevMktres1')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsOpenPrevMktres1'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsOpenPrevMktres1')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsClosePrevMktres10'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsClosePrevMktres10')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = (0,0,0)\narea = np.pi*3\nplt.scatter(market_train_df['returnsOpenPrevMktres10'], market_train_df['returnsOpenNextMktres10'], s=area, c=colors, alpha=0.5)\nplt.title('Scatter plot')\nplt.xlabel('returnsOpenPrevMktres10')\nplt.ylabel('returnsOpenNextMktres10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y ahora, la del fichero de noticias:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot correlation\ncolumns_corr = ['urgency', 'takeSequence', 'companyCount','marketCommentary','sentenceCount',\\\n           'firstMentionSentence','relevance','sentimentClass','sentimentWordCount','noveltyCount24H',\\\n           'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D','volumeCounts24H','volumeCounts3D',\\\n           'volumeCounts5D','volumeCounts7D']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(29,27))\nsns.heatmap(news_train_df[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('news_train_df correlation matrix')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c092b89d83d86df2f3efb1ea345c38ad3446e016"},"cell_type":"markdown","source":"Las conclusiones de la matriz de correlación del fichero de noticias son:\n\n● Existen correlaciones obvias entre las variables que se distinguen entre sí sólo por el horizonte temporal hacia el pasado que contemplan (novelty count y volume count), mientras más cerca en el tiempo más correlación entre ellas.\n\n● Otras correlaciones tienen que ver con los volúmenes de la noticia (contadores de número de sentencias, contadores de sentimiento, contadores de número de veces que se menciona un activo), que tienen un relativamente alto nivel de correlación entre sí.\n\n● Es natural que a más larga la noticia, más probable sea que sea relevante para el activo sea y más tokens relevantes se encuentren, y más noticias urgentes haya. No quiere decir esto, sin embargo, que sea relevante para el precio de la cotización, esto se verá cuando analicemos los modelos.\n\n● También se encuentra relación inversa entre los indicadores de número de secuencia con la relevancia. Esto es, a medida que se avanza en la historia la relevancia es menor.\n\n● Hay algunas variables con correlación con la variable de rendimiento objetivo particularmente baja y según el análisis exploratorio previo tampoco parecen conceptualmente muy relevantes, o bien están incluidas en variables nuevas, o bien son redundantes. Esto se tendrá en cuenta a la hora de simplificar el modelo eliminando variables. Estas variables son: bodysize, companycount, sentencecount, wordcount, noveltycountxH/D, headlineTag.\n\nEn definitiva, hay algunas correlaciones que recomendarían eliminar algunas variables para modelos lineales: aquellas que se relacionan entre sí por ser la misma variable, pero con distinto horizonte temporal."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}