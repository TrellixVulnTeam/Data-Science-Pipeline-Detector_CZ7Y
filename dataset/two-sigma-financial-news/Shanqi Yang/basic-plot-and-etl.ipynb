{"cells":[{"metadata":{"_uuid":"50617d51c31c5319fb22a5753e5a3da65c2665c2"},"cell_type":"markdown","source":"refer to\nhttps://www.kaggle.com/artgor/eda-feature-engineering-and-everything"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96a937742a730c59b65223fcf212b634541957b9"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5a7fa3391f2c9e47f57346192b71575e10f4539"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f17687274c7612318528e8ef160ebb5f39f4858"},"cell_type":"code","source":"market_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4020af774eeefb0cca5dd6b78676f085d4e81385"},"cell_type":"code","source":"data = []\nfor asset in np.random.choice(market_train_df[\"assetName\"].unique(), 10):\n    asset_df = market_train_df[(market_train_df[\"assetName\"] == asset)]\n    \n    data.append(go.Scatter(\n        x = asset_df[\"time\"].dt.strftime(date_format = \"%Y-%m-%d\").values,\n        y = asset_df[\"close\"].values,\n        name = asset        \n    ))\n    \nlayout = go.Layout(dict(title = \"closing prices of 10 random assets\",\n                       xaxis = dict(title = \"month\"),\n                       yaxis = dict(title = 'price USD'),\n                       ),legend=dict(orientation=\"h\"))\npy.iplot(dict(data = data, layout = layout), filename = \"basic-line\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7e5b9c46d0c13013a00932a249a3cfe21cb2e1a"},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby(\"time\")[\"close\"].quantile(i).reset_index()\n    \n    data.append(go.Scatter(\n        x = price_df[\"time\"].dt.strftime(date_format = \"%Y-%m-%d\").values,\n        y = price_df[\"close\"].values,\n        name = f'{i}quantile'\n    ))\n    \nlayout = go.Layout(dict(title = \"trends of closing prices by quantiles\",\n                       xaxis = dict(title = \"Month\"),\n                       yaxis = dict(title = \"Price(USD)\"),\n                       ),legend = dict(orientation = \"h\"))\n\npy.iplot(dict (data=data, layout = layout), filename = \"basic-line\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12eeafd31f8840086225896d7f012ea89da7c5a3"},"cell_type":"code","source":"market_train_df[\"price_diff\"] = market_train_df[\"close\"] - market_train_df[\"open\"]\ngrouped = market_train_df.groupby(\"time\").agg({\"price_diff\": [\"std\", \"min\"]}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d54f73ebea0d1c4ce99e547d9d3f712cbc26725c"},"cell_type":"code","source":"grouped.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ab87de96fbc867611b06ea1fe916be19def3f33"},"cell_type":"code","source":"print (f\"average standard deviation of price change within a day in { grouped['price_diff']['std'].mean():.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"388ca260afe83c90633f9339855b17312018affb"},"cell_type":"code","source":"g = grouped.sort_values(('price_diff', 'std'), ascending = False)[:10]\ng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5c475643f06a98d666b8f9e584f3d289bb818cd"},"cell_type":"code","source":"g['min_text'] = 'Maximum price drop: ' + (-1 * g['price_diff']['min']).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2dec068ca1d6bd0024c6d791468913d5d599075"},"cell_type":"code","source":"market_train_df.sort_values('price_diff')[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9be435cdc469bef4612ac7c0a2285ca233fb329"},"cell_type":"markdown","source":"try to find the strange case"},{"metadata":{"trusted":true,"_uuid":"b904b9fd2fca1b074fd2f68df73df2152373c0ce"},"cell_type":"code","source":"market_train_df['close_to_open'] = np.abs(market_train_df['close']/market_train_df['open'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bbdcb2c59b39d7b0dc4818ceb36844240030003"},"cell_type":"code","source":"print(f\"In {(market_train_df['close_to_open'] >= 1.2).sum()} lines price increased by 20% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.8).sum()} lines price decreased by 20% or more.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7174584bc2cea441ea5d86efa10eb30fde7119ca"},"cell_type":"code","source":"print(f\"In {(market_train_df['close_to_open'] >= 2).sum()} lines price increased by 100% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.5).sum()} lines price decreased by 100% or more.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"882dd16a939b8b537bbd712a7cf8ada752b7f5c1"},"cell_type":"markdown","source":"replacethe outlier with mean open orclose of this company"},{"metadata":{"trusted":true,"_uuid":"7cbc29034c1cb5994b0029d07cf2705d44696da6"},"cell_type":"code","source":"market_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"002c560c6140d09f2cc257a1e7a32dead19bc66e"},"cell_type":"code","source":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby(['time']).agg({'price_diff': ['std', 'min']}).reset_index()\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * np.round(g['price_diff']['min'], 2)).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values * 5,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ded2dea3cd3f7ee290131a54ed216f8172ad83b2"},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['returnsOpenNextMktres10'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbd73e59f7110e96397e9bea20dfabf511ef09b7"},"cell_type":"markdown","source":"We can see that quantiles have a high deviation, but mean value doesn't change much.\n\nNow I think it is time to throw an old part of dataset. Let's leave only data since 2010 year, this way we will get rid of the data of the biggest crisis.\n\nLet's look at the target variable now."},{"metadata":{"trusted":true,"_uuid":"07399c7aae6f773a10f38213e9443114133ed473"},"cell_type":"code","source":"data = []\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']\n\nprice_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].mean().reset_index()\n\ndata.append(go.Scatter(\n    x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = price_df['returnsOpenNextMktres10'].values,\n    name = f'{i} quantile'\n))\nlayout = go.Layout(dict(title = \"Treand of returnsOpenNextMktres10 mean\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d16d06196552ecfffcbdd665b75daaadad45adf"},"cell_type":"markdown","source":"Fluctuations seem to be high, but in fact they are lower that 8 percent. In fact it looks like a random noise...\n\nNow let's remember the description:\n\nThe marketdata contains a variety of returns calculated over different timespans. All of the returns in this set of marketdata have these properties:\n\n    Returns are always calculated either open-to-opebn (from the opening time of one trading day to the open of another) or close-to-close (from the closing time of one trading day to the open of another).\n    Returns are either raw, meaning that the data is not adjusted against any benchmark, or market-residualized (Mktres), meaning that the movement of the market as a whole has been accounted for, leaving only movements inherent to the instrument.\n    Returns can be calculated over any arbitrary interval. Provided here are 1 day and 10 day horizons.\n    Returns are tagged with 'Prev' if they are backwards looking in time, or 'Next' if forwards looking."},{"metadata":{"trusted":true,"_uuid":"34e2a61e08b006039e390129bd8d4b3719d0249c"},"cell_type":"code","source":"data = []\nfor col in ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n       'returnsOpenNextMktres10']:\n    df = market_train_df.groupby('time')[col].mean().reset_index()\n    data.append(go.Scatter(\n        x = df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = df[col].values,\n        name = col\n    ))\n    \nlayout = go.Layout(dict(title = \"Treand of mean values\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82f64cbf4bb6110f2df3562c2eb69bf72191100f"},"cell_type":"markdown","source":"## news data"},{"metadata":{"trusted":true,"_uuid":"2f6a15aabb689a22a2a1a3d20cf0b3c5a3eed9b5"},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dad9117238a8e547fe7e4c8c19f7c92778d11d1f"},"cell_type":"code","source":"print(f'{news_train_df.shape[0]} samples and {news_train_df.shape[1]} features in the training news dataset.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d814bb76a6f0d2df9b04f1f0652ad6d753c109dc"},"cell_type":"code","source":"text = \" \".join(news_train_df[\"headline\"].str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size = None, stopwords = stop, background_color = \"white\",\n                     width = 1200, height = 1000).generate(text)\n\nplt.figure(figsize = (12, 8))\nplt.imshow(wordcloud)\nplt.title(\"top words in headline\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e2fd6d098fce7b5540e1b3ce7efd75e8fc32948"},"cell_type":"code","source":"news_train_df = news_train_df.loc[news_train_df[\"time\"] >= \"2010-01-01 22:00:00+0000\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2de34bcaf23d5324dbc2a9461228ef9369e4eed2"},"cell_type":"code","source":"(news_train_df['urgency'].value_counts() / 1000000).plot('bar');\nplt.xticks(rotation=30);\nplt.title('Urgency counts (mln)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"619733e3ef7ddc34f7279e2ba9f80e6f1603d1d2"},"cell_type":"code","source":"news_train_df['sentence_word_count'] =  news_train_df['wordCount'] / news_train_df['sentenceCount']\nplt.boxplot(news_train_df['sentence_word_count'][news_train_df['sentence_word_count'] < 40]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88001852583af74adadff972bf5d417059e3363a"},"cell_type":"markdown","source":"There are some big outliers, but sentences mostly have 15-25 words in them."},{"metadata":{"trusted":true,"_uuid":"2898307a383eb0641a71e292de0a4c13dc882d25"},"cell_type":"code","source":"news_train_df['provider'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bb5f81a17d646aea2af16f88467e4f563ca8cd9"},"cell_type":"code","source":"(news_train_df['headlineTag'].value_counts() / 1000)[:10].plot('barh');\nplt.title('headlineTag counts (thousands)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6965933246c4ac45561a41eb207953a9339423d"},"cell_type":"code","source":"for i, j in zip([-1, 0, 1], ['negative', 'neutral', 'positive']):\n    df_sentiment = news_train_df.loc[news_train_df['sentimentClass'] == i, 'assetName']\n    print(f'Top mentioned companies for {j} sentiment are:')\n    print(df_sentiment.value_counts().head(5))\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"547c4fb0060adab40bc9d2d4065cdd9bf2a8d35a"},"cell_type":"markdown","source":" think it is quite funny that Apple is a company with most both negative and positive sentiments.\n\nAt first I was sad that we don't have access to the texts of the news, but I have realized that we won't be able to use them anyway due to kernel memory limitations."},{"metadata":{"_uuid":"c19440fb931a45373b75502cdea2746a7d62dd95"},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true,"_uuid":"ba2d828332c24515f0b0dc4a27763417ff3acdbe"},"cell_type":"code","source":"#%%time\n# code mostly takes from this kernel: https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-xgb\n\ndef data_prep(market_df,news_df):\n    market_df['time'] = market_df.time.dt.date\n    market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] / market_df['volume']\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df['volume_to_mean'] = market_df['volume'] / market_df['volume'].mean()\n    news_df['sentence_word_count'] =  news_df['wordCount'] / news_df['sentenceCount']\n    news_df['time'] = news_df.time.dt.hour\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['headlineLen'] = news_df['headline'].apply(lambda x: len(x))\n    news_df['assetCodesLen'] = news_df['assetCodes'].apply(lambda x: len(x))\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['asset_sentence_mean'] = news_df.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    lbl = {k: v for v, k in enumerate(news_df['headlineTag'].unique())}\n    news_df['headlineTagT'] = news_df['headlineTag'].map(lbl)\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n\n    lbl = {k: v for v, k in enumerate(market_df['assetCode'].unique())}\n    market_df['assetCodeT'] = market_df['assetCode'].map(lbl)\n    \n    market_df = market_df.dropna(axis=0)\n    \n    return market_df\n\nmarket_train_df.drop(['price_diff', 'assetName_mean_open', 'assetName_mean_close'], axis=1, inplace=True)\nmarket_train = data_prep(market_train_df, news_train_df)\nprint(market_train.shape)\nup = market_train.returnsOpenNextMktres10 >= 0\n\nfcol = [c for c in market_train.columns if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'assetCodeT',\n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider',\n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54a5a82918f13c10e16317050862ac646d08d096"},"cell_type":"code","source":"X_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fe05523c6a0298afbef9c924727d0f033d53863"},"cell_type":"code","source":"# xgb_up = XGBClassifier(n_jobs=4,\n#                        n_estimators=300,\n#                        max_depth=3,\n#                        eta=0.15,\n#                        random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfb4b8e04320871a9f90555d2a8c8c84ad101ca"},"cell_type":"code","source":"params = {'learning_rate': 0.01, 'max_depth': 12, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=up_train), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train, label=up_train), lgb.Dataset(X_test, label=up_test)],\n                  verbose_eval=100, early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29349bc3dd42d9371833617ba92a470a909d2a89"},"cell_type":"code","source":"def generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: np.random.randint(0, 255), range(3)))\n    return color\n\ndf = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndata = [df]\nfor dd in data:  \n    colors = []\n    for i in range(len(dd)):\n         colors.append(generate_color())\n\n    data = [\n        go.Bar(\n        orientation = 'h',\n        x=dd.imp,\n        y=dd.col,\n        name='Features',\n        textfont=dict(size=20),\n            marker=dict(\n            color= colors,\n            line=dict(\n                color='#000000',\n                width=0.5\n            ),\n            opacity = 0.87\n        )\n    )\n    ]\n    layout= go.Layout(\n        title= 'Feature Importance of LGB',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis=dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n\n    py.iplot(dict(data=data,layout=layout), filename='horizontal-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1623a1471ceda838bc89c9785ae639c08a47b81"},"cell_type":"code","source":"days = env.get_prediction_days()\nimport time\n\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n    \n    t = time.time()\n    market_obs_df = data_prep(market_obs_df, news_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = model.predict(X_live)\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    confidence = 2 * lp -1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}