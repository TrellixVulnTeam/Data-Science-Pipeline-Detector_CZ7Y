{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom kaggle.competitions import twosigmanews\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom datetime import date\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nenv = twosigmanews.make_env()\nstock_list = ['MSFT','AAPL','AMZN','BRK.B','JNJ','JPM','FB','GOOG','XOM','PFE','AMD', 'FLS', 'HCA', 'PKI', 'ILMN', 'GLW', 'IQV', 'WCG', 'VRTX', 'QCOM', 'ARNC', 'UAL', 'NKTR', 'LLY', 'ORLY', 'RCL', 'BLL', 'CA', 'AAP', 'XLNX', 'CF', 'LUV', 'WBA','CI','ESRX']\n(market_train_df, news_train_df) = env.get_training_data()\nreal_market = pd.DataFrame(columns=market_train_df.columns.values)\nnews_train_df = news_train_df.iloc[955479:1255479,]\n#real_market = market_train_df\nfor a in range(0,len(stock_list)):\n    substring = stock_list[a]\n    asset_check = market_train_df.loc[market_train_df['assetCode'].str.contains(substring)]\n  #  if any(substring in asset_check for substring in stock_list):\n    real_market = real_market.append(asset_check,sort=False)\n    print(a)\nreal_news = pd.DataFrame(columns=news_train_df.columns.values)\nfor b in range(0,len(stock_list)):\n    substring = stock_list[b]\n    asset_check = news_train_df.loc[news_train_df['assetCodes'].str.contains(substring)]\n  #  if any(substring in asset_check for substring in stock_list):\n    real_news = real_news.append(asset_check,sort=False)\n    print(b)\nmarket_train_df = real_market\nmarket_train_df['time'] = market_train_df['time'].apply(lambda x: date.toordinal(x))\nprint('news done')\nprovider_keys = []\nproviderInt = []        \nfor x in real_news['provider']:\n    if(x not in provider_keys):\n        provider_keys.append(x)\n    providerInt.append(provider_keys.index(x))\nreal_news.insert(35, 'ProviderInt', providerInt)\nprint('provider done')\nnews_train_df, news_test_df = train_test_split(real_news)\nmanipulate = news_train_df\nmanipulate = manipulate.drop(['time','sourceTimestamp','firstCreated','sourceId','headline','subjects','audiences','headlineTag','marketCommentary','assetCodes','assetName','provider'],axis=1)\nSC = KMeans(n_clusters=3)\nprint('k means done')\ntrain = manipulate\nstd_scale = StandardScaler()\ntrain = std_scale.fit_transform(train)\ntrain_predict = SC.fit_predict(train)\ntrain_trans = SC.transform(train)\nprincipal = PCA(n_components=6)\ntrain_pca = principal.fit_transform(train)\nplt.scatter(train_pca[:,0], train_pca[:,1], c=SC.labels_.astype(float))\nplt.xlabel('First PCA')\nplt.ylabel('Second PCA')\nplt.title('Training Data 2 Dimensional PCA With Cluster Coloring')\nnews_train_df['time'] = news_train_df['time'].apply(lambda x: date.toordinal(x))\nnews_test_df['time'] = news_test_df['time'].apply(lambda x: date.toordinal(x))\nmarket_train_df = market_train_df.loc[market_train_df['time'] <= np.max(news_train_df['time'].astype(float).values.reshape(-1,1))]\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= np.min(news_train_df['time'].astype(float).values.reshape(-1,1))]\ncol_list = list(market_train_df.columns.values)\ncol_list.append('PCA1')\ncol_list.append('PCA2')\ncol_list.append('PCA3')\ncol_list.append('PCA4')\ncol_list.append('PCA5')\ncol_list.append('PCA6')\nnews_train_df = news_train_df.assign(PCA1=train_pca[:,0])\nnews_train_df = news_train_df.assign(PCA2=train_pca[:,1])\nnews_train_df = news_train_df.assign(PCA3=train_pca[:,2])\nnews_train_df = news_train_df.assign(PCA4=train_pca[:,3])\nnews_train_df = news_train_df.assign(PCA5=train_pca[:,4])\nnews_train_df = news_train_df.assign(PCA6=train_pca[:,5])\nreturns_test = pd.DataFrame(columns=market_train_df.columns.values)\nreturns_train = pd.DataFrame(columns=market_train_df.columns.values)\nsize = 0\nunique_dates = news_train_df['time'].unique()\nfor i in range(0,len(unique_dates)):\n    date = unique_dates[i]\n    row_news = news_train_df.loc[news_train_df['time']==date,:]\n    market_rows = market_train_df.loc[(market_train_df['time']==date),:]\n    subjects = row_news['assetCodes']\n    pca1 = row_news['PCA1']\n    pca2 = row_news['PCA2']\n    pca3 = row_news['PCA3']\n    pca4 = row_news['PCA4']\n    pca5 = row_news['PCA5']\n    pca6 = row_news['PCA6']\n    for j in range(0,len(subjects)):\n        subject = subjects.iloc[j].split()[0]\n        train_pca1 = pca1.iloc[j]\n        train_pca2 = pca2.iloc[j]\n        train_pca3 = pca3.iloc[j]\n        train_pca4 = pca4.iloc[j]\n        train_pca5 = pca5.iloc[j]\n        train_pca6 = pca6.iloc[j]\n        subject_start = subject.find(\"'\")\n        subject_end = subject.find(\".\")\n        subject = subject[(subject_start+1):subject_end]\n        market_row = market_rows.loc[market_rows['assetCode'].str.contains(subject)]\n        if (market_row.shape[0] != 0):\n            market_row.insert(0, 'PCA1', train_pca1)\n            market_row.insert(0, 'PCA2', train_pca2)\n            market_row.insert(0, 'PCA3', train_pca3)\n            market_row.insert(0, 'PCA4', train_pca4)\n            market_row.insert(0, 'PCA5', train_pca5)\n            market_row.insert(0, 'PCA6', train_pca6)\n            returns_train = returns_train.append(market_row,sort=False)\n    print(i)\nprint('training done')\nmanipulate = news_test_df\nmanipulate = manipulate.drop(['time','sourceTimestamp','firstCreated','sourceId','headline','subjects','audiences','headlineTag','marketCommentary','assetCodes','assetName','provider'],axis=1)\ntest = manipulate\ntest = std_scale.fit_transform(test)\ntest_predict = SC.predict(test)\ntest_trans = SC.transform(test)\ntest_pca = principal.transform(test)\ncol_list = list(market_train_df.columns.values)\ncol_list.append('PCA1')\ncol_list.append('PCA2')\ncol_list.append('PCA3')\ncol_list.append('PCA4')\ncol_list.append('PCA5')\ncol_list.append('PCA6')\nnews_test_df = news_test_df.assign(PCA1=test_pca[:,0])\nnews_test_df = news_test_df.assign(PCA2=test_pca[:,1])\nnews_test_df = news_test_df.assign(PCA3=test_pca[:,2])\nnews_test_df = news_test_df.assign(PCA4=test_pca[:,3])\nnews_test_df = news_test_df.assign(PCA5=test_pca[:,4])\nnews_test_df = news_test_df.assign(PCA6=test_pca[:,5])\nsize = 0\nunique_dates = news_test_df['time'].unique()\nfor i in range(0,len(unique_dates)):\n    date = unique_dates[i]\n    row_news = news_test_df.loc[news_test_df['time']==date,:]\n    market_rows = market_train_df.loc[(market_train_df['time']==date),:]\n    subjects = row_news['assetCodes']\n    pca1 = row_news['PCA1']\n    pca2 = row_news['PCA2']\n    pca3 = row_news['PCA3']\n    pca4 = row_news['PCA4']\n    pca5 = row_news['PCA5']\n    pca6 = row_news['PCA6']\n    for j in range(0,len(subjects)):\n        subject = subjects.iloc[j].split()[0]\n        train_pca1 = pca1.iloc[j]\n        train_pca2 = pca2.iloc[j]\n        train_pca3 = pca3.iloc[j]\n        train_pca4 = pca4.iloc[j]\n        train_pca5 = pca5.iloc[j]\n        train_pca6 = pca6.iloc[j]\n        subject_start = subject.find(\"'\")\n        subject_end = subject.find(\".\")\n        subject = subject[(subject_start+1):subject_end]\n        market_row = market_rows.loc[market_rows['assetCode'].str.contains(subject)]\n        if (market_row.shape[0] != 0):\n            market_row.insert(0, 'PCA1', train_pca1)\n            market_row.insert(0, 'PCA2', train_pca2)\n            market_row.insert(0, 'PCA3', train_pca3)\n            market_row.insert(0, 'PCA4', train_pca4)\n            market_row.insert(0, 'PCA5', train_pca5)\n            market_row.insert(0, 'PCA6', train_pca6)\n            returns_test = returns_test.append(market_row,sort=False)\n    print(i)\nreturns_train = returns_train.reset_index()\nreturns_test = returns_test.reset_index()\nscaler = MinMaxScaler(feature_range=(-1,1))  \nreturns_train['returnsOpenNextMktres10'] = scaler.fit_transform(returns_train['returnsOpenNextMktres10'].astype(float).values.reshape(-1, 1))\nreturns_test['returnsOpenNextMktres10'] = scaler.fit_transform(returns_test['returnsOpenNextMktres10'].astype(float).values.reshape(-1, 1))\n# Any results you write to the current directory are saved as output.\nreturns_train.to_csv('returns_train.csv',index=False)\nreturns_test.to_csv('returns_test.csv',index=False)\nmarket_train_df.to_csv('market_train_df.csv',index=False)\nnews_train_df.to_csv('news_train_df.csv',index=False)\nnews_test_df.to_csv('news_test_df.csv',index=False)\n\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA\n\ndef function(x_test,x_train,y_test,y_train,model):\n        if(model == \"linear\"):\n                lin = LinearRegression()\n                lin.fit(x_train,y_train)\n                return lin.predict(x_test)\n        elif(model == \"logistic\"):\n                logit = LogisticRegression()\n                logit.fit(x_train,y_train)\n                return logit.predict(x_test)\n        elif(model == \"svc\"):\n                model3 = SVC(gamma='scale')\n                model3.fit(x_train,y_train)\n                return model3.predict(x_test)\n        elif(model == \"svr\"):\n                model3 = SVR(gamma='scale')\n                model3.fit(x_train,y_train)\n                return model3.predict(x_test)\n        elif(model == \"lda\"):\n                model4 = LDA()\n                model4.fit(x_train,y_train)\n                return model4.predict(x_test)\n        elif(model == \"qda\"):\n                model5 = QDA(reg_param=0.05)\n                model5.fit(x_train,y_train)\n                return model5.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"418c6c1a47d5207c73f7f12273bbdb55749f98ba"},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nreturns_test = returns_test.dropna()\nreturns_train = returns_train.dropna()\nlab_enc = preprocessing.LabelEncoder()\ny_train = lab_enc.fit_transform(returns_train['returnsOpenNextMktres10'])\nlab_enc = preprocessing.LabelEncoder()\ny_test = lab_enc.fit_transform(returns_test['returnsOpenNextMktres10'])\ny_train_nolab = returns_train['returnsOpenNextMktres10']\ny_test_nolab = returns_train['returnsOpenNextMktres10']\ny_train = y_train_nolab*100000\ny_train = y_train.astype('int')\ny_test = y_test_nolab*100000\ny_test = y_test.astype('int')\nlm_results_nolab = function(returns_test.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),returns_train.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),y_test_nolab,y_train_nolab,\"linear\")\nlm_results = function(returns_test.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),returns_train.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),y_test,y_train,\"linear\")\nlg_results = function(returns_test.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),returns_train.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),y_test,y_train,\"logistic\")\nsvm_results = function(returns_test.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),returns_train.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),y_test,y_train,\"svc\")\nsvr_results = function(returns_test.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),returns_train.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),y_test,y_train,\"svr\")\nlda_results = function(returns_test.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),returns_train.drop(['returnsOpenNextMktres10','time','assetCode','assetName'],axis=1),y_test,y_train,\"lda\")\nlm_results = scaler.fit_transform(lm_results.reshape(-1, 1))\nlg_results = scaler.fit_transform(lg_results.reshape(-1, 1))\nsvm_results = scaler.fit_transform(svm_results.reshape(-1, 1))\nsvr_results = scaler.fit_transform(svr_results.reshape(-1, 1))\nlda_results = scaler.fit_transform(lda_results.reshape(-1, 1))\nlm_mse_nolab = mean_squared_error(returns_test['returnsOpenNextMktres10'],lm_results_nolab)\nlm_mse = mean_squared_error(returns_test['returnsOpenNextMktres10'],lm_results)\nlg_mse = mean_squared_error(returns_test['returnsOpenNextMktres10'],lg_results)\nsvm_mse = mean_squared_error(returns_test['returnsOpenNextMktres10'],svm_results)\nsvr_mse = mean_squared_error(returns_test['returnsOpenNextMktres10'],svr_results)\nlda_mse = mean_squared_error(returns_test['returnsOpenNextMktres10'],lda_results)\nsvm_plot = returns_test['returnsOpenNextMktres10'].astype(float).values.reshape(-1,1) - svm_results\nplt.plot(svm_plot[0:1000])\nplt.xlabel('Test Instance Number')\nplt.ylabel('Real - SVM Prediction')\nplt.title('SVM Prediction Compared to Real')\nlist_mse = [lm_mse,lg_mse,svm_mse,lda_mse]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0969ef1ee47b15c228dfc7c51394687511d02a12"},"cell_type":"code","source":"\nplt.bar(x=[0,10,20,30,40,50],height=[lm_mse,lm_mse_nolab,lg_mse,svm_mse,svr_mse,lda_mse],tick_label=['LM MSE','LM NO LAB MSE','LG MSE','SVC MSE','SVR MSE','LDA MSE'])\nplt.xlabel('Model')\nplt.ylabel('MSE')\nplt.title('MSE of Various Models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e97323435d94c823cf47d2d73c0ce976870439e7"},"cell_type":"code","source":"lda_plot = returns_test['returnsOpenNextMktres10'].astype(float).values.reshape(-1,1) - lda_results\nplt.plot(lda_plot[0:1000])\nplt.xlabel('Test Instance Number')\nplt.ylabel('Real - SVM Prediction')\nplt.title('LDA Prediction Compared to Real')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b0590c331239deaae2cae64d73d4b014fab9cf2"},"cell_type":"code","source":"returns_test = returns_test.assign(LM=lm_results)\nreturns_test = returns_test.assign(LM_NoLab = lm_results_nolab)\nreturns_test = returns_test.assign(LG = lg_results)\nreturns_test = returns_test.assign(SVC = svm_results)\nreturns_test = returns_test.assign(SVR = svr_results)\nreturns_test = returns_test.assign(LDA = lda_results)\nlm_list = []\nlm_list_nolab = []\nlg_list = []\nsvm_list = []\nsvr_list = []\nlda_list = []\nunique_dates = returns_test['time'].unique()\nfor i in range(0,len(unique_dates)):\n    date = unique_dates[i]\n    rows = returns_test.loc[returns_test['time']==date,]\n    lm_list.append(rows['LM'].multiply(rows['returnsOpenPrevMktres10']).sum())\n    lg_list.append(rows['LG'].multiply(rows['returnsOpenPrevMktres10']).sum())\n    lm_list_nolab.append(rows['LM_NoLab'].multiply(rows['returnsOpenPrevMktres10']).sum())\n    svm_list.append(rows['SVC'].multiply(rows['returnsOpenPrevMktres10']).sum())\n    svr_list.append(rows['SVR'].multiply(rows['returnsOpenPrevMktres10']).sum())\n    lda_list.append(rows['LDA'].multiply(rows['returnsOpenPrevMktres10']).sum())\nlm_score = np.mean(lm_list)/np.std(lm_list)\nlm_nolab_score = np.mean(lm_list)/np.std(lm_list_nolab)  \nlg_score = np.mean(lg_list)/np.std(lg_list)  \nsvm_score = np.mean(svm_list)/np.std(svm_list)  \nsvr_score = np.mean(svr_list)/np.std(svr_list)  \nlda_score = np.mean(lda_list)/np.std(lda_list)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}