{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.cm as cm\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nfrom copy import deepcopy\nfrom scipy import stats\nimport keras as k\nfrom keras.layers import Dense, Conv1D, Flatten, Dropout, LSTM, GlobalAveragePooling1D, MaxPooling1D\nfrom keras.models import Sequential\nfrom sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, RobustScaler, StandardScaler\nfrom sklearn.mixture import  BayesianGaussianMixture, GaussianMixture\nfrom sklearn.impute import SimpleImputer\nimport lightgbm as lgb\npd.options.mode.chained_assignment = None  # default='warn'\n%config IPCompleter.greedy=True\n%load_ext line_profiler\nfrom sklearn import model_selection\n\nplt.rcParams['figure.figsize'] = [20, 10]\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c20fa6deeac9d374c98774abd90bdc76b023ee63","scrolled":false},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75a13f3ef468661294f6acd2860ae48ddf160e8d"},"cell_type":"code","source":"# GMM is trained for two features Raw and Mktres\n# All prevClose and prevOpen for both 1 and 10 days are placed under the respective feature\n# because all of these are expected to follow the same distribution dispite different window length (1 and 10)\n# Five clusters in each group\n\nkeys=['returnsOpenPrevRaw1','returnsClosePrevRaw1','returnsOpenPrevMktres1', 'returnsClosePrevMktres1', 'returnsClosePrevRaw10','returnsOpenPrevRaw10','returnsClosePrevMktres10','returnsOpenPrevMktres10','returnsOpenNextMktres10']\nkeysRaw = []\nkeysMktres = []\ntemp_df = deepcopy(market_train_df)\nmarket_train_df[keys] = market_train_df[keys].fillna(10000) # fill NaNs with very large number, this will indicate that something wasn't right\ngmmRaw = GaussianMixture(5, reg_covar=1e-6, covariance_type='diag')\ngmmMktres = GaussianMixture(5, reg_covar=1e-3, covariance_type='diag')\n\nfor key in keys:\n    if 'Raw' in key:\n        keysRaw.append(key)\n    else:\n        keysMktres.append(key)\n    \n\nvaluesRaw = np.reshape(market_train_df[keysRaw].values, (-1,1))\nvaluesMktres = np.reshape(market_train_df[keysMktres].values, (-1,1))\n\n# predict cluster for each sample\npredsRaw = gmmRaw.fit_predict(valuesRaw)\npredsMktres = gmmMktres.fit_predict(valuesMktres)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2e40b11e54f8adab8c9203107be9781175cff4a"},"cell_type":"code","source":"# These are the properties of the five clusters: weights, covariances, etc. so that we don't have to rerun training each time\n\n'''\ngmmRaw.weights_ =np.array( [6.83865690e-01, 1.16851905e-02, 1.22760963e-07, 3.04427095e-01, 2.19020444e-05]).reshape(-1)\ngmmRaw.means_ = np.array([1.54566863e-03,3.72870021e-02,9.29550000e+03,4.39326020e-03,1.56379609e+02]).reshape(-1,1)\ngmmRaw.covariances_ = np.array([5.49162779e-04, 8.51465015e-02, 7.48225000e+03, 8.13615109e-03, 6.43230001e+05]).reshape(-1,1)\ngmmRaw.precisions_ = np.array( [1.82095371e+03,1.17444637e+01,1.33649637e-04,1.22908239e+02, 1.55465386e-06]).reshape(-1,1)\ngmmRaw.precisions_cholesky_ = np.array([4.26726342e+01, 3.42701966e+00,1.15606936e-02,1.10863988e+01, 1.24685759e-03]).reshape(-1,1)\ngmmRaw.converged_ = True\ngmmRaw.n_iter_ = 28\ngmmRaw.lower_bound_ = 1.6266292098825175\ngmmRaw.n_components = 5\n\ngmmMktres.weights_ = np.array([9.64128858e-01, 1.07063273e-02, 8.69301996e-06, 2.50708018e-02, 8.53200247e-05]).reshape(-1)\ngmmMktres.means_ = np.array([3.86348381e-04,1.00000000e+04, 6.57471356e+02, 2.92204453e-02, 1.28427948e+01]).reshape(-1,1)\ngmmMktres.covariances_ = np.array([2.86978130e-03, 1.00078976e-03, 3.05273209e+06, 4.92966900e-02, 2.67858820e+03]).reshape(-1,1)\ngmmMktres.precisions_ = np.array([3.48458609e+02, 9.99210862e+02, 3.27575421e-07, 2.02853376e+01, 3.73330995e-04]).reshape(-1,1)\ngmmMktres.precisions_cholesky_ = np.array([1.86670461e+01, 3.16102968e+01,  5.72342049e-04,  4.50392469e+00, 1.93217752e-02]).reshape(-1,1)\ngmmMktres.converged_ = True\ngmmMktres.n_iter_ = 9\ngmmMktres.lower_bound_ = 1.5250902820890222\ngmmMktres.n_components = 5\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f63ea71dd77a4af002c2cd65343cdf085ca0efa2"},"cell_type":"code","source":"# perform outlier removal with the trained GMM\n\nkeysRaw = []\nkeysMktres = []\n\nfor key in keys:\n    if 'Raw' in key:\n        keysRaw.append(key)\n    else:\n        keysMktres.append(key)\n\nmax_val = 1 # cluster is judged as anomalous if either mean or covariances exceed 1\n\n#valuesRaw = np.reshape(market_train_df[keysRaw].values, (-1,1))\n#valuesMktres = np.reshape(market_train_df[keysMktres].values, (-1,1))\n\n#predsRaw = gmmRaw.predict(valuesRaw)\n#predsMktres = gmmMktres.predict(valuesMktres)\n\n# Mask to tell which clusters are anomalous\nmaskRaw = [not ((abs(gmmRaw.means_[i]) < max_val) and (gmmRaw.covariances_[i] < max_val))[0] for i in range(len(gmmRaw.weights_))]\nmaskMktres = [not ((abs(gmmMktres.means_[i]) < max_val) and (gmmMktres.covariances_[i] < max_val))[0] for i in range(len(gmmMktres.weights_))]\n\nreplaceIndicesMktres = [maskMktres[x] for x in predsMktres]\nreplaceIndicesRaw = [maskRaw[x] for x in predsRaw]\n\n# Replace anomalous values with the mean of the cluster with the largest weight, where the most data resides\nvaluesRaw[replaceIndicesRaw] = gmmRaw.means_[np.argmax(gmmRaw.weights_)][0]\nvaluesMktres[replaceIndicesMktres] = gmmMktres.means_[np.argmax(gmmMktres.weights_)][0]\n\nmarket_train_df[keysRaw] = np.reshape(valuesRaw, (-1, len(keysRaw)))\nmarket_train_df[keysMktres] = np.reshape(valuesMktres, (-1, len(keysMktres)))\n\nmarket_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"160d700fbf2ef01a5266632ef2f02a540d9b594b"},"cell_type":"code","source":"# Some features\nmarket_train_df['returnsClosePrevRaw1_1day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(1).reset_index(drop=True)\nmarket_train_df['returnsOpenPrevRaw1_1day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(1).reset_index(drop=True)\n\nmarket_train_df['returnsClosePrevRaw1_3day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(3).reset_index(drop=True)\nmarket_train_df['returnsOpenPrevRaw1_3day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(3).reset_index(drop=True)\n\nmarket_train_df['returnsClosePrevRaw1_5day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(5).reset_index(drop=True)\nmarket_train_df['returnsOpenPrevRaw1_5day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(5).reset_index(drop=True)\n\nmarket_train_df['returnsClosePrevRaw1_10day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(10).reset_index(drop=True)\nmarket_train_df['returnsOpenPrevRaw1_10day_lag'] = market_train_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(10).reset_index(drop=True)\n\nkeys = ['returnsClosePrevRaw1_1day_lag','returnsOpenPrevRaw1_1day_lag','returnsClosePrevRaw1_3day_lag','returnsOpenPrevRaw1_3day_lag','returnsClosePrevRaw1_5day_lag','returnsOpenPrevRaw1_5day_lag', 'returnsClosePrevRaw1_10day_lag', 'returnsOpenPrevRaw1_10day_lag'] + keys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7935b143c0acf6da60c03b62c93ef87dedf5b87"},"cell_type":"code","source":"st_date = pd.Timestamp(year=2014, month=1, day=15, hour=22, tz='UTC')\nend_date = pd.Timestamp(year=2018, month=1, day=14, hour=22, tz='UTC')\ntime = market_train_df[(market_train_df['time'] >= st_date) & (market_train_df['time'] < (end_date))]['time'].values \ndata = market_train_df[(market_train_df['time'] >= st_date) & (market_train_df['time'] < (end_date))][keys[:-1]].values \nr = market_train_df[(market_train_df['time'] >= st_date) & (market_train_df['time'] < (end_date))][keys[-1]].values\nlabels = market_train_df[(market_train_df['time'] >= st_date) & (market_train_df['time'] < (end_date))][keys[-1]].values\n\n# Custom labels for regression\nlabels = ((labels > 0.001).astype(int) - (labels < -0.001).astype(int))*0.1 + 0.25*((labels > 0.01).astype(int) - (labels < -0.01).astype(int)) + 0.6*((labels > 0.1).astype(int) - (labels < -0.1).astype(int))\n\nuniverse = market_train_df[(market_train_df['time'] >= st_date) & (market_train_df['time'] < (end_date))]['universe'].values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8b3c8ff9c292484280d8756090891de84f24eb9"},"cell_type":"code","source":"train_data, test_data, train_labels, test_labels, train_time, test_time, train_universe, test_universe, train_r, test_r = model_selection.train_test_split(data, labels, time, universe, r, test_size=0.50, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8f445315762fa2fe9167d519348d1012a8ed010"},"cell_type":"code","source":"data_scaler = RobustScaler()\nlabels_scaler = MinMaxScaler()\n\ndata_scaled = data_scaler.fit_transform(data)\ntest_data_scaled = data_scaler.transform(test_data)\n\nlabels_scaled = labels_scaler.fit_transform(labels.reshape(-1, 1))\ntest_labels_scaled = labels_scaler.transform(test_labels.reshape(-1, 1))\n\nprint(data_scaled.shape)\nprint(test_data_scaled.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1a85da25dcbb4340942b4707523a2bbc394680c"},"cell_type":"code","source":"lgb_train = lgb.Dataset(train_data, train_labels)\nlgb_test = lgb.Dataset(test_data, test_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17e99ee9121ace98d802939b5a192ce620c0919d"},"cell_type":"code","source":"params = {\n        'objective':'mae',\n        'num_iterations':500,\n        'learning_rate':0.01,\n        'n_estimators':200,\n        'early_stopping_rounds':20,\n        'num_leaves':2000\n    }\n\nlgbm_model = lgb.train(params, train_set = lgb_train, valid_sets = lgb_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e284b1f649246b87cfeb5ef059ff4e523ae1970"},"cell_type":"code","source":"pred = lgbm_model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d149e730992d92529fc9836f63e5ae27f2f4049"},"cell_type":"code","source":"conf_data = pd.DataFrame()\nconf_data['time'] = test_time\n\nconf_data['conf_pred'] = pred*test_universe*test_r\nconfidence_value = conf_data.groupby(conf_data.time)['conf_pred'].sum()\n\nconf = np.mean(confidence_value)/np.std(confidence_value)\nprint(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08ff3a9d348d0698d57f1c06b9f95a3e1e8f6505"},"cell_type":"code","source":"pred = lgbm_model.predict(train_data)\nconf_data = pd.DataFrame()\nconf_data['time'] = train_time\n\nconf_data['conf_pred'] = pred*train_universe*train_r\nconfidence_value = conf_data.groupby(conf_data.time)['conf_pred'].sum()\n\nconf = np.mean(confidence_value)/np.std(confidence_value)\nprint(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec8ee4ba050a790a06b224e26bc8b6d05fc041ca"},"cell_type":"code","source":"import warnings\nimport seaborn as sns\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(lgbm_model.feature_importance(),keys)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"724c38149860c8e9058474ac9045c2301e8a20da"},"cell_type":"code","source":"# You can only iterate through a result from `get_prediction_days()` once\n# so be careful not to lose it once you start iterating.\ndays = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c83e8349ed0406fe857a471e7a8de242a1e460da"},"cell_type":"code","source":"# Check and replace anomalous values\ndef fix_anomalies(df, keysRaw, keysMktres, maskRaw, maskMktres,  gmmMktres, gmmRaw):\n    df[keysRaw] = df[keysRaw].fillna(10000) \n    df[keysMktres] = df[keysMktres].fillna(10000) \n    valuesRaw = np.reshape(df[keysRaw].values, (-1,1))\n    valuesMktres = np.reshape(df[keysMktres].values, (-1,1))\n\n    predsRaw = gmmRaw.predict(valuesRaw)\n    predsMktres = gmmMktres.predict(valuesMktres)\n    \n    replaceIndicesMktres = [maskMktres[x] for x in predsMktres]\n    replaceIndicesRaw = [maskRaw[x] for x in predsRaw]\n\n    valuesRaw[replaceIndicesRaw] = gmmRaw.means_[np.argmax(gmmRaw.weights_)][0]\n    valuesMktres[replaceIndicesMktres] = gmmMktres.means_[np.argmax(gmmMktres.weights_)][0]\n\n    df[keysRaw] = np.reshape(valuesRaw, (-1, len(keysRaw)))\n    df[keysMktres] = np.reshape(valuesMktres, (-1, len(keysMktres)))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb031e35d7cfd78805e8bb38b347c76e9bc3d51f"},"cell_type":"code","source":"new_df = pd.DataFrame()\noffset = 20\n\n# Trimmed df for fast lag computation, because we don't need all values, just few last ones\ntemp_dates = market_train_df['time'].unique()[-offset:]\n\nst_date = temp_dates[0]\nend_date = temp_dates[-1]\n\ntemp_df = market_train_df[(market_train_df['time'] >= st_date) & (market_train_df['time'] <= (end_date))] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef60bc52a8a228e5a2ce18e4bd416f1f1f25aeae"},"cell_type":"code","source":"for (market_obs_df, news_obs_df, predictions_template_df) in days:\n    market_obs_df = fix_anomalies(market_obs_df, keysRaw, keysMktres[:-1], maskRaw, maskMktres,  gmmMktres, gmmRaw)\n    market_obs_df['pred'] = np.zeros_like(market_obs_df['time'])\n    #market_obs_df['log_volume_day_avg'] = market_obs_df.groupby('time', as_index=False)['volume'].transform(np.mean).transform(np.log).reset_index(drop=True)\n    #market_obs_df['pred_nn'] = np.zeros_like(market_obs_df['time'])\n    \n    temp_df = temp_df.append(market_obs_df, sort=False, ignore_index=True)\n    \n    # Make lagged features\n    temp_df['returnsClosePrevRaw1_1day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(1).reset_index(drop=True)\n    temp_df['returnsOpenPrevRaw1_1day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(1).reset_index(drop=True)\n    temp_df['returnsClosePrevRaw1_3day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(3).reset_index(drop=True)\n    temp_df['returnsOpenPrevRaw1_3day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(3).reset_index(drop=True)\n    temp_df['returnsClosePrevRaw1_5day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(5).reset_index(drop=True)\n    temp_df['returnsOpenPrevRaw1_5day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(5).reset_index(drop=True)\n    temp_df['returnsClosePrevRaw1_10day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsClosePrevRaw1'].shift(10).reset_index(drop=True)\n    temp_df['returnsOpenPrevRaw1_10day_lag'] = temp_df.groupby('assetCode', as_index=False)['returnsOpenPrevRaw1'].shift(10).reset_index(drop=True)\n    \n    # Put lags to market_obs_df\n    market_obs_df['returnsClosePrevRaw1_1day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsClosePrevRaw1_1day_lag'].reset_index(drop=True)\n    market_obs_df['returnsOpenPrevRaw1_1day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsOpenPrevRaw1_1day_lag'].reset_index(drop=True)\n    market_obs_df['returnsClosePrevRaw1_3day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsClosePrevRaw1_3day_lag'].reset_index(drop=True)\n    market_obs_df['returnsOpenPrevRaw1_3day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsOpenPrevRaw1_3day_lag'].reset_index(drop=True)\n    market_obs_df['returnsClosePrevRaw1_5day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsClosePrevRaw1_5day_lag'].reset_index(drop=True)\n    market_obs_df['returnsOpenPrevRaw1_5day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsOpenPrevRaw1_5day_lag'].reset_index(drop=True)\n    market_obs_df['returnsClosePrevRaw1_10day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsClosePrevRaw1_10day_lag'].reset_index(drop=True)\n    market_obs_df['returnsOpenPrevRaw1_10day_lag'] = temp_df[temp_df.assetCode.isin(market_obs_df.assetCode) & (temp_df.time == market_obs_df.time[0])]['returnsOpenPrevRaw1_10day_lag'].reset_index(drop=True)\n    \n    market_obs_df[keys[:-1]] = market_obs_df[keys[:-1]].fillna(0)\n    \n    obs_data = market_obs_df[market_obs_df['assetCode'].isin(predictions_template_df.assetCode)][keys[0:-1]]\n    pred = lgbm_model.predict(obs_data)\n    pred = np.clip(pred, -1, 1)\n    #pred_nn = model_nn.predict(obs_data)\n    market_obs_df['pred'] = pred\n    #market_obs_df['pred_nn'] = pred_nn.astype(np.float64).reshape(-1,)\n    new_df = new_df.append(market_obs_df, sort=True)\n    \n    # Trim df to last #offset values\n    temp_dates = temp_df['time'].unique()[-offset:]\n\n    st_date = temp_dates[0]\n    end_date = temp_dates[-1]\n    \n    temp_df = temp_df[(temp_df['time'] >= st_date) & (temp_df['time'] <= (end_date))]\n    \n    predictions_template_df.confidenceValue = pred\n    env.predict(predictions_template_df)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e1bf69b49502a3daa694b8974c52668956688b1"},"cell_type":"code","source":"#stored_new_df = deepcopy(new_df)\n#new_df = deepcopy(stored_new_df)\n\nnew_df.returnsOpenPrevMktres10 = new_df.groupby('assetCode').returnsOpenPrevMktres10.shift(-11)\nnew_df.returnsOpenPrevMktres10 = new_df.returnsOpenPrevMktres10.fillna(0)\n\nnew_df['conf_pred'] = new_df['pred'] * new_df.returnsOpenPrevMktres10  \nconfidence_value = new_df.groupby(new_df.time)['conf_pred'].sum()\n\nconf = np.mean(confidence_value)/np.std(confidence_value)\nprint(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c8ed34ffb2c47c6e124530ec798c0b4eb01ddd5"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d38aa8a67cad3f0c105db7e764ec9b805db39ceb"},"cell_type":"code","source":"# We've got a submission file!\nimport os\nprint([filename for filename in os.listdir('.') if '.csv' in filename])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe340df64260d47302bc1358e71fc62be9a76ae6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}