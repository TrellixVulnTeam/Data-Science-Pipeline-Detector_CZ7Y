{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n#import\nfrom kaggle.competitions import twosigmanews\nfrom datetime import datetime, date\nimport numpy as np\nfrom sklearn import model_selection\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"env = twosigmanews.make_env()\n(market_train_orig, news_train_orig) = env.get_training_data()\nmarket_train_df = market_train_orig.copy()\nnews_train_df = news_train_orig.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57d52f9e6a2e52c0e35e5defd9f9c434a6be812a"},"cell_type":"code","source":"market_train_df['time'] = market_train_df['time'].dt.date\nmarket_train_df = market_train_df.loc[market_train_df['time']>=date(2009, 1, 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad38ad6fa8b2f645bca112d3098168abcd16e17c"},"cell_type":"code","source":"news_train_df['time'] = news_train_df['time'].dt.date\nnews_train_df = news_train_df.loc[news_train_df['time']>=date(2009, 1, 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b42932c6c732f1a7a37f9bd3980dd87ebe1e526c"},"cell_type":"code","source":"del market_train_orig\ndel news_train_orig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de00e5d77de24c4c9800a7b22f6ba4c108011b6f"},"cell_type":"code","source":"from multiprocessing import Pool\n\ndef create_lag(df_code,n_lag=[3,7,14,],shift_size=1):\n    code = df_code['assetCode'].unique()\n    \n    for col in return_features:\n        for window in n_lag:\n            rolled = df_code[col].shift(shift_size).rolling(window=window)\n            lag_mean = rolled.mean()\n            lag_max = rolled.max()\n            lag_min = rolled.min()\n            lag_std = rolled.std()\n            df_code['%s_lag_%s_mean'%(col,window)] = lag_mean\n            df_code['%s_lag_%s_max'%(col,window)] = lag_max\n            df_code['%s_lag_%s_min'%(col,window)] = lag_min\n#             df_code['%s_lag_%s_std'%(col,window)] = lag_std\n    return df_code.fillna(-1)\n\ndef generate_lag_features(df,n_lag = [3,7,14]):\n    features = ['time', 'assetCode', 'assetName', 'volume', 'close', 'open',\n       'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n       'returnsOpenNextMktres10', 'universe']\n    \n    assetCodes = df['assetCode'].unique()\n    print(assetCodes)\n    all_df = []\n    df_codes = df.groupby('assetCode')\n    df_codes = [df_code[1][['time','assetCode']+return_features] for df_code in df_codes]\n    print('total %s df'%len(df_codes))\n    \n    pool = Pool(4)\n    all_df = pool.map(create_lag, df_codes)\n    \n    new_df = pd.concat(all_df)  \n    new_df.drop(return_features,axis=1,inplace=True)\n    pool.close()\n    \n    return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"090dfd653891416579996a231cb6cadf0d8d6580"},"cell_type":"code","source":"return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\nn_lag = [3,7,14]\nnew_df = generate_lag_features(market_train_df,n_lag=n_lag)\nmarket_train_df = pd.merge(market_train_df,new_df,how='left',on=['time','assetCode'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c7b0e34ab2dce7c65bd6fefa6608dd9edf8929b"},"cell_type":"code","source":"del new_df\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a69009003d117e68951b62f642058c09ec9b7b4"},"cell_type":"code","source":"print(market_train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a21f278dfd43cfa20489e40226e396a89ff4aba8"},"cell_type":"code","source":"def prepare_news_data(news_df):\n    news_df['position'] = news_df['firstMentionSentence'] / news_df['sentenceCount']\n    news_df['coverage'] = news_df['sentimentWordCount'] / news_df['wordCount']\n\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence',\n                'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass',\n                'assetName', 'urgency','wordCount','noveltyCount12H','sentimentWordCount','noveltyCount24H','noveltyCount3D','noveltyCount5D','noveltyCount7D','volumeCounts12H','volumeCounts24H','volumeCounts3D','volumeCounts5D','volumeCounts7D',]\n    news_df.drop(droplist, axis=1, inplace=True)\n\n    # create a mapping between 'assetCode' to 'news_index'\n    assets = []\n    indices = []\n    for i, values in news_df['assetCodes'].iteritems():\n        assetCodes = eval(values)\n        assets.extend(assetCodes)\n        indices.extend([i]*len(assetCodes))\n    mapping_df = pd.DataFrame({'news_index': indices, 'assetCode': assets})\n    del assets, indices\n    \n    # join 'news_train_df' and 'mapping_df' (effectivly duplicating news entries)\n    news_df['news_index'] = news_df.index.copy()\n    expanded_news_df = mapping_df.merge(news_df, how='left', on='news_index')\n    del mapping_df, news_df\n    \n    expanded_news_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n    return expanded_news_df.groupby(['time', 'assetCode']).mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69a0323af5625844ca2cf4471c35865f5dec7133"},"cell_type":"code","source":"news_train_df = prepare_news_data(news_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6727a2f32b9dc701e1b37cb5c09bd629b69f63d3"},"cell_type":"code","source":"market_train_df = market_train_df.merge(news_train_df, how='left', on=['assetCode', 'time'])\nmarket_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87be0883523d060d9e7bd303bca254586817c653","scrolled":true},"cell_type":"code","source":"del news_train_df\ngc.collect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4949c6df5d31f91ede9241bcd088f78dcac897a"},"cell_type":"code","source":"def fill_in(data):\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"\")\n        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data\n\nmarket_train_df = fill_in(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe14ecce405b4a4c8e3bf6f552b7e4b8b2995c11"},"cell_type":"code","source":"def data_other(market_train_df):\n    #market_train_df.time = market_train_df.time.dt.date\n    lbl = {k: v for v, k in enumerate(market_train_df['assetCode'].unique())}\n    market_train_df['assetCodeT'] = market_train_df['assetCode'].map(lbl)\n    \n    market_train_df = market_train_df.dropna(axis=0)\n    \n    return market_train_df\n\nmarket_train_df = data_other(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b9b932f170bcb691c69496d741d52eecff10d5e"},"cell_type":"code","source":"market_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3061fbd0d841f72cc1a2dbb9f17df53f600277fe"},"cell_type":"code","source":"green = market_train_df.returnsOpenNextMktres10 > 0\ngreen = green.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a83ad5392fb0e4bda94fc57eac1b140c9c2b2f8b"},"cell_type":"code","source":"fcol = [c for c in market_train_df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7badc2c454856599bc44e1f24e89fe3f7039aaa5"},"cell_type":"code","source":"X = market_train_df[fcol].values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4af04e69a487697369770df1f35ab6296e56ad90"},"cell_type":"code","source":"all_10day = market_train_df.returnsOpenNextMktres10.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfe0e95cf66ac341e5dabb6bb8f5370d0951912d"},"cell_type":"code","source":"X_train, X_test, green_train, green_test, all_train, all_test = model_selection.train_test_split(\n    X, green, all_10day, test_size=0.20, random_state=59)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fd36b95bd08067ed72fd49ea4edb40a69d521a6"},"cell_type":"code","source":"import lightgbm as lgb\ntrain_data = lgb.Dataset(X_train, label=green_train.astype(int))\ntest_data = lgb.Dataset(X_test, label=green_test.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81059922cfd4a2b67e6e97fa7b5a8c3d2451b2c1"},"cell_type":"code","source":"# these are tuned params I found\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\nx_2 = [0.19016805202090095, 2583, 213, 312, 220]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a5aa4d51fc76abf1237da4d146f280a0cca9d8f"},"cell_type":"code","source":"params_1 = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n        'num_iteration': x_1[3],\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\nparams_2 = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'learning_rate': x_2[0],\n        'num_leaves': x_2[1],\n        'min_data_in_leaf': x_2[2],\n        'num_iteration': x_2[3],\n        'max_bin': x_2[4],\n        'verbose': 1\n    }\n\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=1000,\n        valid_sets=test_data,\n        early_stopping_rounds=100)\n        \ngbm_2 = lgb.train(params_2,\n        train_data,\n        num_boost_round=1000,\n        valid_sets=test_data,\n        early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c95ad3ca284813fa6f42d9b73b2a3f9b8ab7616"},"cell_type":"code","source":"confidence_test = (gbm_1.predict(X_test) + gbm_2.predict(X_test))/2\nconfidence_test = (confidence_test-confidence_test.min())/(confidence_test.max()-confidence_test.min())\nconfidence_test = confidence_test*2-1\nprint(max(confidence_test),min(confidence_test))\n\n# calculation of actual metric that is used to calculate final score\nr_test = r_test.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = confidence_test * r_test * u_test\ndata = {'day' : d_test, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_test = mean / std\nprint(score_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e88a3a0f9886d638c4f11849df8c1b436e6cdf46"},"cell_type":"code","source":"days = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\ntotal_market_obs_df = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"381399559180bd9e2cf71547bcb9340a6ae6b720"},"cell_type":"code","source":"fcol1 = [c for c in market_train_df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp','companyCount','relevance','sentimentNegative','sentimentNeutral','sentimentPositive','position','coverage']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbc02042409373c9f2ae16ca73a6f07ee6499b7c"},"cell_type":"code","source":"X = market_train_df[fcol1].values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ef25f1c91d38696225abb9516bee1c39f781717"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn import preprocessing\nimport time\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    t = time.time()\n    market_obs_df['time'] = market_obs_df['time'].dt.date\n    \n    return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\n    total_market_obs_df.append(market_obs_df)\n    if len(total_market_obs_df)==1:\n        history_df = total_market_obs_df[0]\n    else:\n        history_df = pd.concat(total_market_obs_df[-(np.max(n_lag)+1):])\n    print(history_df)\n    \n    new_df = generate_lag_features(history_df,n_lag=[3,7,14])\n    market_obs_df = pd.merge(market_obs_df,new_df,how='left',on=['time','assetCode'])\n    \n    #news_obs_df = prepare_news_data(news_obs_df)\n    #market_obs_df = market_obs_df.merge(news_obs_df, how='left', on=['assetCode', 'time'])\n    \n#     return_features = ['open']\n#     new_df = generate_lag_features(market_obs_df,n_lag=[3,7,14])\n#     market_obs_df = pd.merge(market_obs_df,new_df,how='left',on=['time','assetCode'])\n    \n    market_obs_df = fill_in(market_obs_df)\n    \n    market_obs_df = data_other(market_obs_df)\n    \n#     market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    \n    X_live = market_obs_df[fcol1].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    \n    confidence = lp\n    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    \n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    \n#     predictions_template_df.set_index('assetCode')\n#     x = predictions_template_df[['confidenceValue']].values.astype(float)\n    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n#     np_scaled = min_max_scaler.fit_transform(x)\n#     df_normalized = pd.DataFrame(np_scaled,columns=predictions_template_df[['confidenceValue']])\n#     df_normalized['assetCode'] = df_normalized.index\n    \n    predictions_template_df[['confidenceValue']] = min_max_scaler.fit_transform(predictions_template_df[['confidenceValue']])\n    \n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2639cc66bcbdf824ebb701905e597aa64b2be9e3"},"cell_type":"code","source":"env.write_submission_file()\nsub  = pd.read_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a93ba4f0aa07092fe9d76d3a89aeeb51f45dbcda"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}