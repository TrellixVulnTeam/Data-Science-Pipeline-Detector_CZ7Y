{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\nimport xgboost\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\",category=UserWarning)\nwarnings.filterwarnings(\"ignore\",category=FutureWarning)\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0260539101eb52b8a364175423a409c2612337"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eccca89c8220ccc47f62cf6e89fe5da1c2705c27"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f95b346c8bbc58c22f0f7fdbdd26102ed3ded8ab"},"cell_type":"code","source":"market_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5aab8af8ffaa289d185f80d94b17d3ba1610ca95"},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"247029367187de43e7e2c7d614f0ae19b90d58fa"},"cell_type":"code","source":"data = []\nfor asset in np.random.choice(market_train_df[\"assetName\"].unique(), 10):\n    asset_df = market_train_df[(market_train_df[\"assetName\"]==asset)]\n    data.append(go.Scatter(\n        x = asset_df[\"time\"].dt.strftime(date_format=\"%Y-%m-%d\").values,\n        y = asset_df[\"close\"].values\n    ))\nlayout = go.Layout(dict(title = \"Random 10 companies close price\",\n                   xaxis = dict(title = \"Month\"),\n                   yaxis = dict(title = \"Price(USD)\"),\n                   ),legend = dict(\n                orientation = \"h\"))\n\npy.iplot(dict(data=data, layout=layout), filename=\"basic_file\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"421718d3754efe9d07e8e75b628c08fd95bdd6dc"},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['close'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['close'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of closing prices by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),\n    annotations=[\n        dict(\n            x='2008-09-01 22:00:00+0000',\n            y=82,\n            xref='x',\n            yref='y',\n            text='Collapse of Lehman Brothers',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        ),\n        dict(\n            x='2011-08-01 22:00:00+0000',\n            y=85,\n            xref='x',\n            yref='y',\n            text='Black Monday',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        ),\n        dict(\n            x='2014-10-01 22:00:00+0000',\n            y=120,\n            xref='x',\n            yref='y',\n            text='Another crisis',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=-20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        ),\n        dict(\n            x='2016-01-01 22:00:00+0000',\n            y=120,\n            xref='x',\n            yref='y',\n            text='Oil prices crash',\n            showarrow=True,\n            font=dict(\n                family='Courier New, monospace',\n                size=16,\n                color='#ffffff'\n            ),\n            align='center',\n            arrowhead=2,\n            arrowsize=1,\n            arrowwidth=2,\n            arrowcolor='#636363',\n            ax=20,\n            ay=-30,\n            bordercolor='#c7c7c7',\n            borderwidth=2,\n            borderpad=4,\n            bgcolor='#ff7f0e',\n            opacity=0.8\n        )\n    ])\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8b5c94a4c324a1e25f17c92b959b46bcdc36bf7"},"cell_type":"code","source":"data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby(\"time\")[\"returnsOpenNextMktres10\"].quantile(i).reset_index()\n    data.append(go.Scatter(\n       x = price_df[\"time\"].dt.strftime(date_format=\"%Y-%m-%d\").values,\n       y = price_df[\"returnsOpenNextMktres10\"].values,\n       name = f\"{i} quantile\" \n    ))\nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"759c81778d883b6e0bd748d9c795fe2c70431ddf"},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2ce68e756484d84660ebbdb602c819c08e8269f"},"cell_type":"code","source":"stop = set(stopwords.words(\"english\"))\ntext = \"\".join(news_train_df[\"headline\"].str.lower().values[-10000:])\nwordcloud = WordCloud(max_font_size=None, background_color=\"white\", stopwords=stop,\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(15,15))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title(\"Top words in headline\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69188bdf50e5aa13d9f30868d32aed6fd93a77e9"},"cell_type":"code","source":"(news_train_df['urgency'].value_counts() / 1000000).plot('bar');\nplt.xticks(rotation=30);\nplt.title(\"Urgency variable distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f32f490febbea431c9775a761a18657cf2f73fff"},"cell_type":"code","source":"news_train_df['sentence_word_count'] =  news_train_df['wordCount'] / news_train_df['sentenceCount']\nplt.boxplot(news_train_df['sentence_word_count'][news_train_df['sentence_word_count'] < 40]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a09b76d34afa317e6e726adbf574db683dc9c11"},"cell_type":"code","source":"news_train_df['provider'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17c3b86eb16f012b7f404ff4001024a52542e3f9"},"cell_type":"code","source":"(news_train_df['headlineTag'].value_counts() / 1000)[:10].plot('barh');\nplt.title('headlineTag counts (thousands)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91b47748641d4df0666a5287eb75ee23275b5ccf"},"cell_type":"code","source":"#%%time\n# code mostly takes from this kernel: https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-xgb\n\ndef data_prep(market_df,news_df):\n    market_df['time'] = market_df.time.dt.date\n    market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] / market_df['volume']\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df['volume_to_mean'] = market_df['volume'] / market_df['volume'].mean()\n    news_df['sentence_word_count'] =  news_df['wordCount'] / news_df['sentenceCount']\n    news_df['time'] = news_df.time.dt.hour\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['headlineLen'] = news_df['headline'].apply(lambda x: len(x))\n    news_df['assetCodesLen'] = news_df['assetCodes'].apply(lambda x: len(x))\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['asset_sentence_mean'] = news_df.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    lbl = {k: v for v, k in enumerate(news_df['headlineTag'].unique())}\n    news_df['headlineTagT'] = news_df['headlineTag'].map(lbl)\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n\n    lbl = {k: v for v, k in enumerate(market_df['assetCode'].unique())}\n    market_df['assetCodeT'] = market_df['assetCode'].map(lbl)\n    \n    market_df = market_df.dropna(axis=0)\n    \n    return market_df\n\n# market_train_df.drop(['price_diff', 'assetName_mean_open', 'assetName_mean_close'], axis=1, inplace=True)\nmarket_train = data_prep(market_train_df, news_train_df)\nprint(market_train.shape)\nup = market_train.returnsOpenNextMktres10 >= 0\n\nfcol = [c for c in market_train.columns if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'assetCodeT',\n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider',\n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81a51ae262c279e482612a567444c3dedb536647"},"cell_type":"code","source":"from sklearn import model_selection\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c71b7659f68172d097e22038ca2cfcdace3ddc9"},"cell_type":"code","source":"params = {'learning_rate': 0.013, 'max_depth': 10, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=up_train), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train, label=up_train), lgb.Dataset(X_test, label=up_test)],\n                  verbose_eval=100, early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5856427993c5e09c8ba0c0c375c20aac55d7207d"},"cell_type":"code","source":"days = env.get_prediction_days()\nimport time\n\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n    \n    t = time.time()\n    market_obs_df = data_prep(market_obs_df, news_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = model.predict(X_live)\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    confidence = 2 * lp -1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}