{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport multiprocessing\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\nprint('Done!')\n\ncpu_count = 2*multiprocessing.cpu_count()-1\nprint('Number of CPUs: {}'.format(cpu_count))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9e0c3eed0c341a91b8689beff0ca2e31f9f46dd"},"cell_type":"code","source":"print(\"Size of Stock Data: \",market_train_df.shape)\nprint(\"Size of News Data: \",news_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4248edee5b86ea175eea783b63bee6af804e58bd"},"cell_type":"code","source":"market_train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ced067e905e8499ff4ccc693cd6f2e3dd2ad5bf7"},"cell_type":"code","source":"news_train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6f979dbbbd15d1e3534fec4dbc3355b519add96"},"cell_type":"code","source":"print(news_train_df.groupby(['headlineTag']).assetName.value_counts().sort_values(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7279ca52b4d33fd5b3b221d6870c1c2cd2d2a3b"},"cell_type":"code","source":"# See the different news sources\nnews_train_df['provider'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5347989e95c10e86d54b8fab984efa427c97fd86"},"cell_type":"code","source":"# Get count headline tags ( type of news) in the news data set\n(news_train_df['headlineTag'].value_counts() / 1000)[:10].plot('barh');\nplt.title('headlineTag counts (thousands)');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f3534caab489fa4e885724ed68993b7914611c6"},"cell_type":"markdown","source":"## Plot News Sentiment"},{"metadata":{"trusted":true,"_uuid":"0f649a5c2715d53abb4eb7e8fecd61357fe27e7e"},"cell_type":"code","source":"dfsent = pd.DataFrame(news_train_df.groupby('assetName').sentimentClass.mean()).reset_index(level=['assetName'])\ndfsent['sentimentClass'] = dfsent['sentimentClass']*10\ndfsent[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4f153d7111daf51ad83cc42cc4f9aeb23dd3b6b"},"cell_type":"code","source":"from matplotlib import pyplot as plt\nax = plt.subplot(111)\nnews_train_df[news_train_df['assetName']=='Naugatuck Valley Financial Corp'][:10].sentimentClass.plot(ax = ax, kind='bar',title='Sentiment Score for Naugatuck Valley Financial Corp', edgecolor = \"black\", color=(0, 0.8, 0,1))\n#ax.get_xaxis().set_visible(False)\nax.set_xlabel('Time the news came out')\nax.set_xticklabels(news_train_df[news_train_df['assetName'] == 'Naugatuck Valley Financial Corp'][:10].sourceTimestamp, rotation=-30, ha = 'left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d55a38f263932e0a9b18546d3a0539761fc7148b"},"cell_type":"code","source":"dfsent1 = pd.concat([dfsent[dfsent['sentimentClass']>8].sample(4),dfsent[dfsent['sentimentClass']<-8].sample(5),dfsent[dfsent['sentimentClass']<2].sample(6)], axis = 0)\ndfsent1.sort_values(by = 'sentimentClass', ascending = False, inplace = True)\ndfsent1.reset_index(inplace = True)\ndfsent1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"380bcf51103126b23b92e8652df7a0a12632a57c"},"cell_type":"code","source":"for i, j in zip([-1, 0, 1], ['negative', 'neutral', 'positive']):\n    df_sentiment = news_train_df.loc[news_train_df['sentimentClass'] == i, 'assetName']\n    print(f'Top mentioned companies for {j} sentiment are:')\n    print(df_sentiment.value_counts().head(5))\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dbc90b935accef5dc7b0afdce62f2850d861ab9"},"cell_type":"code","source":"# plot histogram of sentiment by company\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\nax = plt.subplot(111)\nk = 15\ndfsent1.sentimentClass.plot(ax=ax, kind='barh',title='AVERAGE SENTIMENT SCORE', edgecolor = \"black\", color=(0, 0.8, 1,1))\nxmin, xmax = -11, 11\nymin, ymax = -1, 15\nX = [[.7, .5], [.7, .5]]\n\nax.imshow(X,interpolation='bicubic', cmap=plt.cm.Reds, extent=(xmin, xmax, ymin, ymax), alpha=1)\n#ax.set_xlim(-1, 1)\nax.get_yaxis().set_visible(False)\nfor i, x in enumerate(dfsent[:k].assetName):\n    ax.text(-12.2, i-0.3, x, ha='right', fontsize='large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fd2d7517a20ac3f161a9d86d0f5f6ed297928363"},"cell_type":"code","source":"print(\"Number of Unique Companies in the News Dataset: \",len(news_train_df['assetName'].unique()))\nprint(\"Number of Unique Companies in the Stock Prices Dataset: \",len(market_train_df['assetCode'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"677a9efb294babfc3d947202a6d9c6a8f455c0eb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e88432656b48b86bfe6949908ee9b1b7b14dcf8"},"cell_type":"code","source":"news_train_df['time'] = pd.to_datetime(news_train_df['time'])\nnews_train_df['time'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"add1c038452ed9c9d5b5a67fc52fb2f13d8e9dd6"},"cell_type":"markdown","source":"## Exploring Stock Data"},{"metadata":{"trusted":true,"_uuid":"4cd07e98d6bea7f167caecfe57f500332cdf4238"},"cell_type":"code","source":"# select some Pharma companies and plot their stock trends\npharmalist = ['ABT.N', 'PFE.N', 'MRK.N','MDT.N','NVO.N','TEVA.N','CELG.N']\ndfpharma = market_train_df[market_train_df['assetCode'].isin(pharmalist)]\ndfpharma = dfpharma[~(dfpharma['assetName'] == 'Unknown')]\ndfpharma.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02136cf946f227ade9eaf7d8d69f1c69088881f0"},"cell_type":"code","source":"dfpharma[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30e9d055fc3434c953770e902c499608e8a792d2"},"cell_type":"code","source":"market_train_df[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c94a3c80fec0a9e9623569529086b3ae032ca3e"},"cell_type":"code","source":"# See Stock price trends for selected Pharma Companies\nmarket_train_df['time'] = pd.to_datetime(market_train_df['time'], errors='coerce')\ndata = []\nfor asset in dfpharma.assetName.unique():\n    asset_df = market_train_df[(market_train_df['assetName'] == asset)]\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05568db74297da8f7e4315de7048f7049d715aa8"},"cell_type":"code","source":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] / market_train_df['open'])\nmarket_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n\n\nmarket_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby(['time']).agg({'price_diff': ['std', 'min']}).reset_index()\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * np.round(g['price_diff']['min'], 2)).astype(str)\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values * 5,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e72cd2abc3c3547a54c577d5e0f3ee115984fff"},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true,"_uuid":"1b734f2749b64049eb114e3d2dd739387616cfc7"},"cell_type":"code","source":"# code mostly takes from this kernel: https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-xgb\n# do a bit of feature engineering and merge market and news data\ndef data_prep(market_df,news_df):\n    market_df['time'] = market_df.time.dt.date\n    market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] / market_df['volume']\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df['volume_to_mean'] = market_df['volume'] / market_df['volume'].mean()\n    news_df['sentence_word_count'] =  news_df['wordCount'] / news_df['sentenceCount']\n    news_df['time'] = news_df.time.dt.hour\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['headlineLen'] = news_df['headline'].apply(lambda x: len(x))\n    news_df['assetCodesLen'] = news_df['assetCodes'].apply(lambda x: len(x))\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['asset_sentence_mean'] = news_df.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    lbl = {k: v for v, k in enumerate(news_df['headlineTag'].unique())}\n    news_df['headlineTagT'] = news_df['headlineTag'].map(lbl)\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n\n    lbl = {k: v for v, k in enumerate(market_df['assetCode'].unique())}\n    market_df['assetCodeT'] = market_df['assetCode'].map(lbl)\n    \n    market_df = market_df.dropna(axis=0)\n    \n    return market_df\n\n# market_train.drop(['price_diff', 'assetName_mean_open', 'assetName_mean_close'], axis=1, inplace=True)\nmarket_train = data_prep(market_train_df, news_train_df)\n\nprint(market_train.shape)\nup = market_train.returnsOpenNextMktres10 >= 0\n\nfcol = [c for c in market_train.columns if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'assetCodeT',\n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider',\n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_train[fcol].values\nup = up.values\nr = market_train.returnsOpenNextMktres10.values\n\n# Scaling of X values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"064010016a863a4d483bf1331eac0f1a76219e47"},"cell_type":"code","source":"np.bincount(up)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"ba9f5e476d47ce79fde9cd63ee1801c3b048d1e7"},"cell_type":"code","source":"from sklearn import model_selection\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=99)\n\nimport lightgbm as lgb\n# xgb_up = XGBClassifier(n_jobs=4,\n#                        n_estimators=300,\n#                        max_depth=3,\n#                        eta=0.15,\n#                        random_state=42)\nparams = {'learning_rate': 0.01, 'max_depth': 12, 'boosting': 'gbdt', 'objective': 'binary'\n          , 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=up_train), num_boost_round=20,\n                  valid_sets=[lgb.Dataset(X_train, label=up_train), lgb.Dataset(X_test, label=up_test)],\n                  early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c91075d3d7fbcf41ba31765dabc591c8dd45123d"},"cell_type":"markdown","source":"## Feature Importance"},{"metadata":{"trusted":true,"_uuid":"fbad0de91de21c1366d1b55531208652c013ff86"},"cell_type":"code","source":"df = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf.sort_values(by = ['imp'], ascending = False,inplace = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31b8d43023080c3ac7b509d61bad4efd57bea938"},"cell_type":"code","source":"def generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: np.random.randint(0, 255), range(3)))\n    return color\n\ndf = pd.DataFrame({'imp': model.feature_importance(), 'col':fcol})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndata = [df]\nfor dd in data:  \n    colors = []\n    for i in range(len(dd)):\n         colors.append(generate_color())\n\n    data = [\n        go.Bar(\n        orientation = 'h',\n        x=dd.imp,\n        y=dd.col,\n        name='Features',\n        textfont=dict(size=20),\n            marker=dict(\n            color= colors,\n            line=dict(\n                color='#000000',\n                width=0.5\n            ),\n            opacity = 0.87\n        )\n    )\n    ]\n    layout= go.Layout(\n        title= 'Feature Importance of LGB',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis=dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n\n    py.iplot(dict(data=data,layout=layout), filename='horizontal-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfa66d003a371f43b4c5e7c1caebd6e9f82c9908"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}