{"cells":[{"metadata":{"_uuid":"df0469ad5a80a03c4adfcbeae9a0d004c4d0d109"},"cell_type":"markdown","source":"## Some parts of code - and hyperparams -  copied from\n\n- https://www.kaggle.com/kazuokiriyama/tuning-hyper-params-in-lgbm-achieve-0-66-in-lb\n- https://www.kaggle.com/artgor/eda-feature-engineering-and-everything\n"},{"metadata":{"trusted":true,"_uuid":"9c400ff3548cff69a7c4b2815a06af0c9d5a51ea"},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport xgboost\nimport lightgbm as lgb\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import model_selection\nfrom datetime import datetime, date\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1ff91e59ddfa7a1cad64830b43c24de3bcf013d"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews;\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f36ba98d8b4e5ae43f2f2ede3552fb9e05d7dab8"},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca976379c5a2ffb93374e9749de4fc8ada13caca"},"cell_type":"code","source":"# market_train_df = market_train_df[:2000000]\n# news_train_df = news_train_df[:2000000]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bdeffb82892428e353a6fe302beb0bd3ec1b7ba"},"cell_type":"markdown","source":"## Utils"},{"metadata":{"trusted":true,"_uuid":"9e2e825ef151b2219813f09c3a43cb2f8664fbff"},"cell_type":"code","source":"maxs = None\nmins = None\nrng = None\nmean_volume = None\n\nmeans = None\nstds = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f26b34f1660e992a4554b766fdca6a486590959"},"cell_type":"code","source":"def drop_nans_and_infs(s:pd.Series):\n    return s[~(np.isinf(s)|np.isnan(s))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba47dd5b743554bb5f0f8bf953a165cf39ba56a8"},"cell_type":"code","source":"def nans_and_inf(X, val=None):\n    \"\"\"Replaces nans and infs with mean so that standart deviation normalization puts them to 0 \"\"\"\n    global means\n    X = np.transpose(X)\n    print(X.shape)\n    if means is None:\n        _means = np.mean(X, axis=0)\n    else:\n        _means = means\n    print(_means)\n    for i, m in zip(range(len(X)), _means):\n        X[i][np.isnan(X[i])] = m\n        X[i][np.abs(X[i]) > 1e7] = m\n    X = np.transpose(X)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b096f5e3cde6373fa212a08cee56e5084b7a391b"},"cell_type":"code","source":"def mis_impute(data):\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"other\")\n        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d830374d45c37b0ddc11f8e14ac6d2920997593c"},"cell_type":"code","source":"def _sd_norm(X):\n    global means, stds\n    if means is None or stds is None:\n        means = np.mean(X)\n        stds = np.std(X)\n    return (X-means)/stds\n\ndef sd_norm(X):\n    X = nans_and_inf(X)\n    return _sd_norm(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"855bf406088f977758864b82f7f63fa71eebb601"},"cell_type":"code","source":"def log_norm(X):\n    X = nans_and_inf(X)\n    X = np.log2(X)\n    X = _sd_norm(X)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c22392245ccbed70d51b37a6db80209bbca1015"},"cell_type":"code","source":"def min_max_norm(X):\n    global maxs, mins, rng\n    if maxs is None or mins is None or rng is None:\n        mins = np.min(X, axis=0)\n        maxs = np.max(X, axis=0)\n        rng = maxs - mins\n    X = 1 - ((maxs - X) / rng)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"841b47b531ad76d9d0e454ed44f385075abb1c12"},"cell_type":"code","source":"def no_norm(X):\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a098b208ae929145b1a5869067c7e7ca6891bb70"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33fcc391bfb6e5b2568afa5f715ff6fb59e868ea"},"cell_type":"markdown","source":"## Feature Extraction\n"},{"metadata":{"trusted":true,"_uuid":"160e613879c933a34ce315b2fb3d175adbeb5d97"},"cell_type":"code","source":"norm_method = min_max_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eb1d83dc31f6059ceccd78569c1e2afd71a307f"},"cell_type":"code","source":"def remove_economic_crises(market_train):\n    market_train = market_train.loc[market_train['time']>=date(2009, 1, 1)] # 2008 economic crises\n#     market_train = market_train.loc[~((market_train['time']>=date(2011, 5, 2)) & (market_train['time']<=date(2011, 10, 4)))] # 2011\n#     market_train = market_train.loc[~((market_train['time']>=date(2015, 6, 12)) & (market_train['time']<=date(2015, 8, 21)))] # 2015 Chinese and US market crashes\n    return market_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed76d5312c27aa3b59095983d99315bd971a6b22"},"cell_type":"code","source":"fcol = None\nasset_code_map = None\nheadline_tag_map = None\nprovider_map = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3dc90b1e9d414ead9d046b9e9f3bd97d4dd75c4"},"cell_type":"code","source":"def add_hand_crafted_features(market_df):\n    global mean_volume\n    \n    if mean_volume is None:\n        mean_volume = market_df['volume'].mean()\n    \n    market_df['volume_to_mean'] = market_df['volume'] / mean_volume\n    market_df['close_to_open_1'] = market_df['returnsClosePrevRaw1'] / market_df['returnsOpenPrevRaw1']\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df['returnsOpenPrevRaw1_to_volume'] = market_df['returnsOpenPrevRaw1'] / market_df['volume']\n    market_df['returnsOpenPrevRaw10_to_volume'] = market_df['returnsOpenPrevRaw10'] / market_df['volume']\n    return market_df\n\ndef data_prep(market_data):\n    market_data = add_hand_crafted_features(market_data)\n    market_data.time = market_data.time.dt.date\n    global asset_code_map\n    if asset_code_map is None:\n        asset_code_map = {k: v for v, k in enumerate(market_data['assetCode'].unique())}\n    market_data['assetCodeT'] = market_data['assetCode'].map(asset_code_map)\n    \n    market_data = market_data.dropna(axis=0)\n    \n    return market_data\n\ndef only_market(market_data):\n    market_data = mis_impute(market_data)\n    market_data = data_prep(market_data)\n    return market_data\n\n    \ndef market_and_news(market_data, news_data):\n    market_data = mis_impute(market_data)\n    news_data = mis_impute(news_data)\n    \n    market_data = add_hand_crafted_features(market_data)\n    market_data.time = market_data.time.dt.date\n    market_data = market_data.dropna(axis=0)\n    market_data = remove_economic_crises(market_data)\n    \n    news_data['time'] = news_data.time.dt.hour\n    news_data['sourceTimestamp']= news_data.sourceTimestamp.dt.hour\n    news_data['firstCreated'] = news_data.firstCreated.dt.date\n    news_data['assetCodesLen'] = news_data['assetCodes'].map(lambda x: len(eval(x)))\n    news_data['assetCodes'] = news_data['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_data['headlineLen'] = news_data['headline'].apply(lambda x: len(x))\n    news_data['assetCodesLen'] = news_data['assetCodes'].apply(lambda x: len(x))\n    news_data['asset_sentiment_mean'] = news_data.groupby(['assetName', 'sentimentClass'])['time'].transform('mean')\n    news_data['asset_sentiment_std'] = news_data.groupby(['assetName', 'sentimentClass'])['time'].transform('std')\n    \n    news_data['noveltyCount7D_mean'] = news_data.groupby(['assetName', 'noveltyCount7D'])['time'].transform('mean')\n    news_data['noveltyCount7D_max'] = news_data.groupby(['assetName', 'noveltyCount7D'])['time'].transform('max')\n    news_data['noveltyCount7D_min'] = news_data.groupby(['assetName', 'noveltyCount7D'])['time'].transform('min')\n    \n    news_data['asset_sentence_mean'] = news_data.groupby(['assetName', 'sentenceCount'])['time'].transform('mean')\n    news_data['asset_sentence_max'] = news_data.groupby(['assetName', 'sentenceCount'])['time'].transform('max')\n    news_data['asset_sentence_min'] = news_data.groupby(['assetName', 'sentenceCount'])['time'].transform('min')\n    \n    news_data['companyCount'] = news_data['companyCount'].astype(int)\n    \n    global headline_tag_map\n    if headline_tag_map is None:\n        headline_tag_map = {k: v for v, k in enumerate(news_data['headlineTag'].unique())}\n    news_data['headlineTagT'] = news_data['headlineTag'].map(headline_tag_map)\n    \n    \n    global provider_map\n    if provider_map is None:\n        provider_map = {k: v for v, k in enumerate(news_data['provider'].unique())}\n    news_data['provider'] = news_data['provider'].map(provider_map)\n    \n    kcol = ['firstCreated', 'assetCodes']\n    news_data = news_data.groupby(kcol, as_index=False).mean()\n    \n    market_data = pd.merge(market_data, news_data, how='left', left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n    \n    global asset_code_map\n    if asset_code_map is None:\n        asset_code_map = {k: v for v, k in enumerate(market_data['assetCode'].unique())}\n    market_data['assetCodeT'] = market_data['assetCode'].map(asset_code_map)\n    \n    market_data = mis_impute(market_data)\n    return market_data\n    \n\ndef train_processor(market_data, news_data=None):\n    if news_data is None:\n        market_data = only_market(market_data)\n        market_data = remove_economic_crises(market_data)\n    else:\n        market_data = market_and_news(market_data, news_data)\n    \n    global fcol\n    fcol = [c for c in market_data if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n    \n    X = market_data[fcol].values\n    up = market_data.returnsOpenNextMktres10 >= 0\n    up = up.values\n    r = market_data.returnsOpenNextMktres10.values\n\n    # Scaling of X values\n    # It is good to keep these scaling values for later\n    X = norm_method(X)\n\n    return X, up, r\n\ndef inferance_processor(market_data, predictions_template_df, news_data=None):\n    if news_data is None:\n        market_data = data_prep(market_data)\n        market_data = market_data[market_data.assetCode.isin(predictions_template_df.assetCode)]\n        X_live = market_data[fcol].values\n        X_live = norm_method(X_live)\n    else:\n        market_data = market_and_news(market_data, news_data)\n        market_data = market_data[market_data.assetCode.isin(predictions_template_df.assetCode)]\n        X_live = market_data[fcol].values\n        X_live = norm_method(X_live)\n    return X_live, market_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f2f82fcae6f53fb3d29f68a926f1c6dd9695879"},"cell_type":"markdown","source":"#### Workplace "},{"metadata":{"trusted":true,"_uuid":"526292bcb4c2e29a56b10fdab5e1201944b40836"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a57d55df3dc0692de894d5bbef454aa419222267"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cac0c78f2cbcf58cbeeda975ad12377c4ef0d30"},"cell_type":"markdown","source":"## Training "},{"metadata":{"trusted":true,"_uuid":"0b3c499542d3ae4b2579c432cbcf195305fef03d","scrolled":false},"cell_type":"code","source":"%%time\nX, up, r = train_processor(market_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b407d3d72d29492d3a090484af196a697cd370ff"},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de982cdad7e27ce74d5b5722af1b140a0bb9420b"},"cell_type":"code","source":"%%time\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.1, random_state=99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc34b5b4ab945933bc35aa734ba53d4a276f03f1"},"cell_type":"code","source":"xgb_train = xgboost.DMatrix(X_train, label=up_train, feature_names=fcol)\n\nxgb_evals = xgboost.DMatrix(X_test, label=up_test, feature_names=fcol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21bf36677038732343035317b41c54adb0b23a02"},"cell_type":"code","source":"eval_list = [(xgb_train,'train'), (xgb_evals,'eval')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c370c66a33d5fdab87542de623283bafde436d8","scrolled":true},"cell_type":"code","source":"params = {'eta': 0.15, 'max_depth': 6, 'max_bin': 300, 'booster': 'dart', 'objective': 'binary:logistic', 'eval_metric': ['auc', 'logloss'], \n          'is_training_metric': True, 'seed': 42, 'nthread': 4, 'gamma': 0.1, 'alpha': 0.1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27ebac97908ad3fb2ae318340f0856cea1a18ffa"},"cell_type":"code","source":"bst = xgboost.train(params, dtrain=xgb_train, num_boost_round= 500, evals=eval_list, early_stopping_rounds=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2425cd379178f6adb50fc3be7364e9c01921025f"},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=[15,20])\nxgboost.plot_importance(bst, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9b49291181706619fb07431d6530825ef06c120"},"cell_type":"markdown","source":"## Prediction "},{"metadata":{"trusted":true,"_uuid":"378f71fe584484c73995f6cc3d76087e785f990a"},"cell_type":"code","source":"days = env.get_prediction_days()\nimport time\n\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n    \n    X_live, market_obs_df = inferance_processor(market_obs_df, predictions_template_df)\n    d_live = xgboost.DMatrix(X_live, feature_names=fcol)\n    \n    t = time.time()\n    lp = bst.predict(d_live)\n    \n    t = time.time()\n    confidence = 2 * lp -1\n\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    \n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0963730b5189657720cd1fd10fe6a9ca5b8fb76f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d32ffda71f85f483236133e3b3f7f1d0880a81b5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b28f05c508fa43aff722d7a5da82ba0c133ee578"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"972eee79747e4c20662f5c1cc02a5825c2e6c9e7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}