{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# movie problem","metadata":{}},{"cell_type":"markdown","source":"# load data","metadata":{}},{"cell_type":"code","source":"# load data libraries\nimport numpy as np # linear algebra library\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile # to read zip files\nfrom sklearn.model_selection import train_test_split\n\n\n# data understanding libraries\nimport matplotlib.pyplot as plt # ploting library\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\n\n\n# data preparation\nimport re\nfrom nltk.stem import PorterStemmer\n\n\n# ADS Creation\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n# Modeling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Evaluation and Model Selection\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load data","metadata":{}},{"cell_type":"code","source":"#unzip the files\narchive_train = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\n\n#read training json file \ntrain = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip',sep='\\t')\n\n#output the frist 5 rows\ntrain.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# spliting data","metadata":{}},{"cell_type":"code","source":"train_data, test_data = train_test_split(train, test_size=0.4, random_state=1)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=1)\n\ntrain_data = train_data.reset_index(drop=True)\nval_data = val_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Length of each part","metadata":{}},{"cell_type":"code","source":"print(\"Train set size is \",len(train_data))\nprint(\"Val set size is \",len(val_data))\nprint(\"Test set size is \",len(test_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Data Understanding","metadata":{}},{"cell_type":"markdown","source":"### Data structure","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### there is no nulls \n#### there are 156060 entry","metadata":{}},{"cell_type":"markdown","source":"## 2.2 What is the frequency of each sentiment?","metadata":{}},{"cell_type":"code","source":"# words num\ncount = \" \".join([row[\"Phrase\"] for ind , row in train_data.iterrows()]).split()\nlen(set(count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's save list of sentiment we have\nlabels = train_data['Sentiment'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the graph\nfig, ax = plt.subplots(figsize=(15,10)) # create the plot and specify the figure size\nplt.xlabel('Sentiment') # specify the x labels\nplt.ylabel('Frequency') # specify the y labels\nplt.title('Frequency of Sentiment') # specify the plot title\nplt.bar(labels,train_data['Sentiment'].value_counts()) # create a bar plot\nplt.grid() # show the grid\nplt.show() # show the final plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* from the given graph it seem that about 48000 sentiment is 2","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Number of words per phrase","metadata":{}},{"cell_type":"code","source":"# add column with num of words per phrase\n\ntrain_data['Words_Num'] = train_data[\"Phrase\"].apply(len)\n\n# save list of the unique numbers we have\nnumbers = train_data[\"Phrase\"].apply(len).unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(30,10))\nplt.bar(numbers,train_data[\"Words_Num\"].value_counts().sort_index())\nplt.xlabel('Number of words')\nplt.ylabel('Phrase count')\nplt.title('Number of Words per Phrase Count')\nplt.xticks(np.arange(min(numbers), max(numbers)+1, 5.0)) # change x labels from the defult to the given range\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"bins = range(0,200,10)\n\nfig, ax = plt.subplots(figsize=(15,10))\nplt.hist(train_data['Words_Num'], bins=bins, edgecolor=\"k\") # output a histogram plot\nplt.xlabel('Number of Words')\nplt.ylabel('Phrase count')\nplt.title('Number of words per Phrase Count')\nplt.xticks(bins) # change x labels from the defult to the given range\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now its obvious that avarage number of words is from 10-60 for about 70000 to 80000 phrase**\n##### the outliers lies in more than 170 words and less than 2","metadata":{}},{"cell_type":"markdown","source":"#### Cheeck for outliers","metadata":{}},{"cell_type":"code","source":"print(\"There are \" ,len(train_data[train_data[\"Words_Num\"]<2]), \" Phrase with words less than 2.\")\nprint(\"There are \" ,len(train_data[train_data[\"Words_Num\"]>170]), \" Phrase with words more than 170.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[train_data[\"Words_Num\"]<2][['Phrase']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of phrase with Words >170 over with sentiment","metadata":{}},{"cell_type":"markdown","source":"## cloud to see words","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,8))\ntrain_data[train_data[\"Words_Num\"]>=170].groupby(['Sentiment']).size().sort_values().plot(kind='barh', ax=ax)\nplt.title('Distribution of phrase with Words >170 over with sentiment')\nplt.ylabel('Sentiment')\nplt.xlabel('Number of words')\nplt.grid()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Frequency of words","metadata":{}},{"cell_type":"code","source":"# spliting data\nfinal = \" \".join([row[\"Phrase\"] for ind , row in train.iterrows()]).split()\n\n\n\nfig, ax = plt.subplots(figsize=(10,8))\nlst = Counter(final).most_common(15)\ndf = pd.DataFrame(lst, columns = ['final', 'Count'])\ndf.plot.bar(x='final',y='Count', ax=ax)\nplt.title('15 Most Frequent word')\nplt.ylabel('Frequency')\nplt.xlabel('words')\nplt.xticks(rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(final))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Most Used words\")\nplt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['SplitPhrase'] =train_data['Phrase'].str.split()\ntrain_data['Phrase'] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncounters = {}\nfor Sentiment in train_data['Sentiment'].unique():\n    counters[Sentiment] = Counter()\n    indices = (train_data['Sentiment'] == Sentiment)\n    for SplitPhrase in train_data[indices]['SplitPhrase']:\n        counters[Sentiment].update(SplitPhrase)\n\n        \nfig, axes = plt.subplots(1, 5, figsize=(10,10),sharex='col', sharey='row')\nfor Sentiment, ax_index in zip(counters, range(1,21)): \n    wordcloud = WordCloud(background_color=\"white\")\n    wordcloud.generate_from_frequencies(frequencies=counters[Sentiment])\n    fig.add_subplot(3, 5, ax_index)    \n    plt.title(Sentiment)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data prepartion","metadata":{}},{"cell_type":"markdown","source":"#### another look on data","metadata":{}},{"cell_type":"code","source":"train_data['SplitPhrase'].sample(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Splited = pd.Series((' '.join([','.join(row[\"SplitPhrase\"]) for ind,row in train_data.iterrows()])).split(','))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in final if \"-\" in s]).unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([a for a in final if \"'\" in a]).unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### stop words\n","metadata":{}},{"cell_type":"code","source":"stopwords = set([\"'s\",\"-\",\"\",\"the\",\"that\",\"an\"])\nporter = PorterStemmer()\n# lancaster=LancasterStemmer()\n\ndef ret_words(final):\n    word_text = ' '.join(final)\n    word_text  = final.lower()\n    word_text  = final.replace('-', '')\n    word_text  = final.replace(',', ' ')\n    words = []\n    for word in word_text .split():\n        if len(word) <= 1: continue\n        if re.findall('[0-9]', word): continue\n        if '’' in word: continue\n        if '-' in word: continue\n        if word in stopwords: continue\n        if re.findall('[^a-zA-Z]',re.sub(r'[^\\w\\s]','',word)): continue\n        if len(word) > 0: words.append(porter.stem(re.sub(r'[^\\w\\s]','',word)))\n    return ' '.join(words)\n\ndef preprocess(df,flag):\n\n    \n    # Convert list of ingredients to string\n    df['final'] = df[\"Phrase\"].apply(ret_words)\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed = preprocess(train_data,0)\nval_preprocessed = preprocess(val_data,1)\ntest_preprocessed = preprocess(test_data,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## look on data after cleansing","metadata":{}},{"cell_type":"code","source":"train_preprocessed.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(pd.Series(' '.join([row[\"final\"] for ind,row in train_preprocessed.iterrows()]).split(' '))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train = train_preprocessed['PhraseId'], train_preprocessed['final'], train_preprocessed['Sentiment']\nid_test, X_test, y_test = test_preprocessed['PhraseId'], test_preprocessed['final'], test_preprocessed['Sentiment']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BoW\nBoW = CountVectorizer()\n\nBoW.fit(X_train)\nCount_data = BoW.transform(X_train)\n\nBoW_X_train = pd.DataFrame(Count_data.toarray(),columns=BoW.get_feature_names())\n\nBoW_X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BoW.fit(X_train.head())\nCount_data = BoW.transform(X_train.head())\nBoW_X_train = pd.DataFrame(Count_data.toarray(),columns=BoW.get_feature_names())\nBoW_X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TFIDF\nTFIDF = TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1',\\\n                ngram_range=(1, 2), stop_words='english')\n\nTFIDF.fit(X_train)\nCount_data = TFIDF.transform(X_train)\nTFIDF_X_train = pd.DataFrame(Count_data.toarray(),columns=TFIDF.get_feature_names())\n\n\nTFIDF_X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TFIDF = TfidfVectorizer()\nTFIDF.fit(X_train.head(5))\nCount_data = TFIDF.transform(X_train.head(5))\nTFIDF_X_train = pd.DataFrame(Count_data.toarray(),columns=TFIDF.get_feature_names())\n\n\nTFIDF_X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"id_train, X_train, y_train = train_preprocessed['PhraseId'], train_preprocessed['final'], train_preprocessed['Sentiment']\nid_val, X_val, y_val = val_preprocessed['PhraseId'], val_preprocessed['final'], val_preprocessed['Sentiment']\nid_test, X_test, y_test = test_preprocessed['PhraseId'], test_preprocessed['final'], test_preprocessed['Sentiment']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bow","metadata":{}},{"cell_type":"code","source":"LR_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', LogisticRegression(random_state=0, max_iter=2000))\n])\nLR_clf_counts.fit(X_train, y_train)\nLR_cnt_pred_tr = LR_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, LR_cnt_pred_tr))\nprint(precision_score(y_train, LR_cnt_pred_tr, average='weighted'))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM","metadata":{}},{"cell_type":"code","source":"SVM_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', LinearSVC(max_iter=3000))\n])\nSVM_clf_counts.fit(X_train, y_train)\nSVM_cnt_pred_tr = SVM_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, SVM_cnt_pred_tr))\nprint(precision_score(y_train, SVM_cnt_pred_tr, average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(SVM_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Naive base","metadata":{}},{"cell_type":"code","source":"NB_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', MultinomialNB())\n])\nNB_clf_counts.fit(X_train, y_train)\nNB_cnt_pred_tr = NB_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, NB_cnt_pred_tr))\nprint(precision_score(y_train, NB_cnt_pred_tr, average='weighted'))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(NB_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lR and tfidf","metadata":{}},{"cell_type":"code","source":"LR_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1',ngram_range=(1, 2), stop_words='english')),\n    ('clf', LogisticRegression(random_state=0, max_iter=2000))\n])\nLR_clf_tfidf.fit(X_train, y_train)\nLR_tfidf_pred_tr = LR_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, LR_tfidf_pred_tr))\nprint(precision_score(y_train, LR_tfidf_pred_tr, average='weighted'))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n    ('clf', LinearSVC( max_iter=2000))\n])\nSVM_clf_tfidf.fit(X_train, y_train)\nSVM_tfidf_pred_tr = SVM_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, SVM_tfidf_pred_tr))\nprint(precision_score(y_train, SVM_tfidf_pred_tr, average='weighted'))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(SVM_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n    ('clf', MultinomialNB())\n])\nNB_clf_tfidf.fit(X_train, y_train)\nNB_tfidf_pred_tr = NB_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, NB_tfidf_pred_tr))\nprint(precision_score(y_train, NB_tfidf_pred_tr, average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(NB_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### hyper tunning","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vect=  CountVectorizer()\nX_train_cnt = vect.fit_transform(X_train)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def svc_param_selection(X, y, nfolds, kernal):\n    Cs = [ 0.1, 1, 10]\n    gammas = [0.01, 0.1, 1]\n    degrees = [0, 1, 2, 3]\n    rbf_param_grid = {'C': Cs, 'gamma' : gammas}\n    linear_param_grid = {'C': Cs}\n    poly_param_grid = {'C': Cs, 'gamma' : gammas, 'degree':degrees}\n    if kernal == 'rbf':\n        grid_search = GridSearchCV(SVC(kernel=kernal), rbf_param_grid, cv=nfolds)\n    elif kernal == 'linear':\n        grid_search = GridSearchCV(SVC(kernel=kernal), linear_param_grid, cv=nfolds)\n    else:\n        grid_search = GridSearchCV(SVC(kernel=kernal), poly_param_grid, cv=nfolds)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## final model","metadata":{}},{"cell_type":"code","source":"vect=  CountVectorizer()\nX_train_cnt = vect.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def svc_param_selection(X, y, nfolds, kernal):\n    Cs = [ 0.1, 1, 10]\n    gammas = [0.01, 0.1, 1]\n    degrees = [0, 1, 2, 3]\n    rbf_param_grid = {'C': Cs, 'gamma' : gammas}\n    linear_param_grid = {'C': Cs}\n    poly_param_grid = {'C': Cs, 'gamma' : gammas, 'degree':degrees}\n    if kernal == 'rbf':\n        grid_search = GridSearchCV(SVC(kernel=kernal), rbf_param_grid, cv=nfolds)\n    elif kernal == 'linear':\n        grid_search = GridSearchCV(SVC(kernel=kernal), linear_param_grid, cv=nfolds)\n    else:\n        grid_search = GridSearchCV(SVC(kernel=kernal), poly_param_grid, cv=nfolds)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf_counts_lin = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', SVC(C=0.1, kernel='linear'))\n])\nSVM_clf_counts_lin.fit(X_train, y_train)\nSVM_cnt_pred_tr_lin = SVM_clf_counts_lin.predict(X_train)\nSVM_cnt_pred_val_lin = SVM_clf_counts_lin.predict(X_val)\nSVM_tst = SVM_clf_counts_lin.predict(X_test)\n\n\n\nprint(\"precision on training: \",precision_score(y_train, SVM_cnt_pred_tr_lin, average='micro'))\nprint(\"precision on validation: \",precision_score(y_val, SVM_cnt_pred_val_lin, average='micro'))\nprint(\"precision on testing: \",precision_score(y_test, SVM_tst, average='micro'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archive_train = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\narchive_test = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train = pd.read_csv(\"../input/sentiment-analysis-on-movie-reviews/train.tsv.zip\", sep='\\t')\nfinal_test = pd.read_csv(\"../input/sentiment-analysis-on-movie-reviews/test.tsv.zip\", sep='\\t')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ftrain_preprocessed = preprocess (final_train,0)\nftest_preprocessed = preprocess (final_test,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train = ftrain_preprocessed['PhraseId'], ftrain_preprocessed['final'], ftrain_preprocessed['Sentiment']\nid_test, X_test= ftest_preprocessed['PhraseId'], ftest_preprocessed['final']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf= Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', SVC(C=0.1, kernel='linear'))\n])\nSVM_clf.fit(X_train , y_train)\npred_tst = SVM_clf_counts_lin.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=pd.DataFrame({'PhraseId' : id_test , 'Sentiment' : pred_tst })\noutput.to_csv('Sentiment_preds_LR.csv' , index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}