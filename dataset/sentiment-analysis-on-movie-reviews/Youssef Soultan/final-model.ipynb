{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# load data libraries\nimport numpy as np # linear algebra library\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile # to read zip files\nfrom sklearn.model_selection import train_test_split\n\n\n# data understanding libraries\nimport matplotlib.pyplot as plt # ploting library\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\n\n\n# data preparation\nimport re\nfrom nltk.stem import PorterStemmer\n\n\n# ADS Creation\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n# Modeling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Evaluation and Model Selection\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T00:08:15.753767Z","iopub.execute_input":"2021-05-20T00:08:15.754108Z","iopub.status.idle":"2021-05-20T00:08:15.763752Z","shell.execute_reply.started":"2021-05-20T00:08:15.75408Z","shell.execute_reply":"2021-05-20T00:08:15.763058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Sentiment Analysis**\n#   Data Understanding\n* Business Question: What is the review of specific Phrases on a scale of five values?\n* Each row represent a phrase\n* What is the evaluation method: Submissions are evaluated on classification accuracy (the percent of labels that are predicted correctly)\n","metadata":{}},{"cell_type":"code","source":"#unzip the files\ntrain = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip',delimiter='\\t')\n\n#output the frist 5 rows\ntrain.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:15.772594Z","iopub.execute_input":"2021-05-20T00:08:15.772982Z","iopub.status.idle":"2021-05-20T00:08:15.974379Z","shell.execute_reply.started":"2021-05-20T00:08:15.772939Z","shell.execute_reply":"2021-05-20T00:08:15.97342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(train, test_size=0.4, random_state=1)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=1)\n\ntrain_data = train_data.reset_index(drop=True)\nval_data = val_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:15.976124Z","iopub.execute_input":"2021-05-20T00:08:15.976675Z","iopub.status.idle":"2021-05-20T00:08:16.022163Z","shell.execute_reply.started":"2021-05-20T00:08:15.976632Z","shell.execute_reply":"2021-05-20T00:08:16.021435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train set size is \",len(train_data))\nprint(\"Val set size is \",len(val_data))\nprint(\"Test set size is \",len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:16.023173Z","iopub.execute_input":"2021-05-20T00:08:16.023575Z","iopub.status.idle":"2021-05-20T00:08:16.02911Z","shell.execute_reply.started":"2021-05-20T00:08:16.023534Z","shell.execute_reply":"2021-05-20T00:08:16.028157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:16.030653Z","iopub.execute_input":"2021-05-20T00:08:16.031036Z","iopub.status.idle":"2021-05-20T00:08:16.065542Z","shell.execute_reply.started":"2021-05-20T00:08:16.031006Z","shell.execute_reply":"2021-05-20T00:08:16.06425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There is 93636 Record\n* There is no null data in all columns\n* We have 3 integers datatypes and 1 object","metadata":{}},{"cell_type":"code","source":"words = \" \".join([row[\"Phrase\"]for ind, row in train_data.iterrows()]).split()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:16.113507Z","iopub.execute_input":"2021-05-20T00:08:16.113866Z","iopub.status.idle":"2021-05-20T00:08:22.479211Z","shell.execute_reply.started":"2021-05-20T00:08:16.113836Z","shell.execute_reply":"2021-05-20T00:08:22.478255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['Phrase'].str.split()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:22.481046Z","iopub.execute_input":"2021-05-20T00:08:22.481309Z","iopub.status.idle":"2021-05-20T00:08:22.939822Z","shell.execute_reply.started":"2021-05-20T00:08:22.481284Z","shell.execute_reply":"2021-05-20T00:08:22.938689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(words))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:22.941068Z","iopub.execute_input":"2021-05-20T00:08:22.941623Z","iopub.status.idle":"2021-05-20T00:08:22.999548Z","shell.execute_reply.started":"2021-05-20T00:08:22.941579Z","shell.execute_reply":"2021-05-20T00:08:22.998369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation \n# Data Cleansing\n","metadata":{}},{"cell_type":"code","source":"stopwords = set([\"RRB\",\"LRB\",\"CGI\",\"zzzzzzzzz\",\"'s\"])\n\ndef ret_words(words):\n    words = words.replace('-', ' ')\n    words = words.replace(',', ' ')\n    words = words.replace('--', ' ')\n    words = words.replace('`', ' ')\n    words = words.replace('``', ' ')\n    words = words.replace('\\/', ' ')\n    words = words.replace(';', ' ')\n    words = words.replace(':', ' ')\n    words = words.replace('.', ' ')\n    words = words.replace('*', ' ')\n    words = words.replace(\"''\", ' ')\n    \n    text = []\n    for word in words.split():\n        if word in stopwords: continue\n        text.append(word)\n    return ' '.join(text)\n\ndef preprocess(df,flag):\n     # Convert list of ingredients to string\n    df['Phrase_txt'] = df[\"Phrase\"].apply(ret_words)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:23.0011Z","iopub.execute_input":"2021-05-20T00:08:23.00152Z","iopub.status.idle":"2021-05-20T00:08:23.012612Z","shell.execute_reply.started":"2021-05-20T00:08:23.001468Z","shell.execute_reply":"2021-05-20T00:08:23.011691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed = preprocess(train_data,0)\nval_preprocessed = preprocess(val_data,1)\ntest_preprocessed = preprocess(test_data,1)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:23.016307Z","iopub.execute_input":"2021-05-20T00:08:23.016784Z","iopub.status.idle":"2021-05-20T00:08:23.55568Z","shell.execute_reply.started":"2021-05-20T00:08:23.016738Z","shell.execute_reply":"2021-05-20T00:08:23.554723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:23.559471Z","iopub.execute_input":"2021-05-20T00:08:23.559752Z","iopub.status.idle":"2021-05-20T00:08:23.584662Z","shell.execute_reply.started":"2021-05-20T00:08:23.559726Z","shell.execute_reply":"2021-05-20T00:08:23.583602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(pd.Series(' '.join([row[\"Phrase_txt\"] for ind,row in train_preprocessed.iterrows()]).split(' '))))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:23.586046Z","iopub.execute_input":"2021-05-20T00:08:23.586417Z","iopub.status.idle":"2021-05-20T00:08:29.952013Z","shell.execute_reply.started":"2021-05-20T00:08:23.586376Z","shell.execute_reply":"2021-05-20T00:08:29.950985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train =  train_preprocessed['PhraseId'], train_preprocessed['Phrase_txt'], train_preprocessed['Sentiment']\nid_val, X_val, y_val = val_preprocessed['PhraseId'], val_preprocessed['Phrase_txt'], val_preprocessed['Sentiment']\nid_test, X_test, y_test =test_preprocessed['PhraseId'], test_preprocessed['Phrase_txt'], test_preprocessed['Sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:29.953164Z","iopub.execute_input":"2021-05-20T00:08:29.953428Z","iopub.status.idle":"2021-05-20T00:08:29.962408Z","shell.execute_reply.started":"2021-05-20T00:08:29.953403Z","shell.execute_reply":"2021-05-20T00:08:29.961396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', LogisticRegression(random_state=0, max_iter=2000))\n])\nLR_clf_counts.fit(X_train, y_train)\nLR_cnt_pred_tr = LR_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, LR_cnt_pred_tr))\nprint(precision_score(y_train, LR_cnt_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:08:29.963654Z","iopub.execute_input":"2021-05-20T00:08:29.963945Z","iopub.status.idle":"2021-05-20T00:09:29.9259Z","shell.execute_reply.started":"2021-05-20T00:08:29.963918Z","shell.execute_reply":"2021-05-20T00:09:29.924837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:09:29.927369Z","iopub.execute_input":"2021-05-20T00:09:29.927742Z","iopub.status.idle":"2021-05-20T00:11:24.258659Z","shell.execute_reply.started":"2021-05-20T00:09:29.927703Z","shell.execute_reply":"2021-05-20T00:11:24.257368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', LinearSVC(max_iter=3000))\n])\nSVM_clf_counts.fit(X_train, y_train)\nSVM_cnt_pred_tr = SVM_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, SVM_cnt_pred_tr))\nprint(precision_score(y_train, SVM_cnt_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:11:24.260496Z","iopub.execute_input":"2021-05-20T00:11:24.260953Z","iopub.status.idle":"2021-05-20T00:13:04.563596Z","shell.execute_reply.started":"2021-05-20T00:11:24.260899Z","shell.execute_reply":"2021-05-20T00:13:04.562592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(SVM_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:13:04.565948Z","iopub.execute_input":"2021-05-20T00:13:04.566488Z","iopub.status.idle":"2021-05-20T00:17:40.094895Z","shell.execute_reply.started":"2021-05-20T00:13:04.566446Z","shell.execute_reply":"2021-05-20T00:17:40.094059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', MultinomialNB())\n])\nNB_clf_counts.fit(X_train, y_train)\nNB_cnt_pred_tr = NB_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, NB_cnt_pred_tr))\nprint(precision_score(y_train, NB_cnt_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:17:40.096118Z","iopub.execute_input":"2021-05-20T00:17:40.096354Z","iopub.status.idle":"2021-05-20T00:17:41.544226Z","shell.execute_reply.started":"2021-05-20T00:17:40.09633Z","shell.execute_reply":"2021-05-20T00:17:41.543294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(NB_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:17:41.545547Z","iopub.execute_input":"2021-05-20T00:17:41.545814Z","iopub.status.idle":"2021-05-20T00:17:52.551429Z","shell.execute_reply.started":"2021-05-20T00:17:41.545787Z","shell.execute_reply":"2021-05-20T00:17:52.550759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1',ngram_range=(1, 2), stop_words='english')),\n    ('clf', LogisticRegression(random_state=0, max_iter=2000))\n])\nLR_clf_tfidf.fit(X_train, y_train)\nLR_tfidf_pred_tr = LR_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, LR_tfidf_pred_tr))\nprint(precision_score(y_train, LR_tfidf_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:17:52.552523Z","iopub.execute_input":"2021-05-20T00:17:52.552972Z","iopub.status.idle":"2021-05-20T00:18:45.892507Z","shell.execute_reply.started":"2021-05-20T00:17:52.552935Z","shell.execute_reply":"2021-05-20T00:18:45.891604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:18:45.893641Z","iopub.execute_input":"2021-05-20T00:18:45.893871Z","iopub.status.idle":"2021-05-20T00:20:04.719933Z","shell.execute_reply.started":"2021-05-20T00:18:45.893848Z","shell.execute_reply":"2021-05-20T00:20:04.718898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n    ('clf', LinearSVC( max_iter=2000))\n])\nSVM_clf_tfidf.fit(X_train, y_train)\nSVM_tfidf_pred_tr = SVM_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, SVM_tfidf_pred_tr))\nprint(precision_score(y_train, SVM_tfidf_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:04.721099Z","iopub.execute_input":"2021-05-20T00:20:04.721344Z","iopub.status.idle":"2021-05-20T00:20:09.607769Z","shell.execute_reply.started":"2021-05-20T00:20:04.721321Z","shell.execute_reply":"2021-05-20T00:20:09.606782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(SVM_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:09.609262Z","iopub.execute_input":"2021-05-20T00:20:09.609571Z","iopub.status.idle":"2021-05-20T00:20:32.76715Z","shell.execute_reply.started":"2021-05-20T00:20:09.609544Z","shell.execute_reply":"2021-05-20T00:20:32.76614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n    ('clf', MultinomialNB())\n])\nNB_clf_tfidf.fit(X_train, y_train)\nNB_tfidf_pred_tr = NB_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, NB_tfidf_pred_tr))\nprint(precision_score(y_train, NB_tfidf_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:32.768641Z","iopub.execute_input":"2021-05-20T00:20:32.769273Z","iopub.status.idle":"2021-05-20T00:20:35.065002Z","shell.execute_reply.started":"2021-05-20T00:20:32.769228Z","shell.execute_reply":"2021-05-20T00:20:35.063946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(NB_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:35.06649Z","iopub.execute_input":"2021-05-20T00:20:35.067159Z","iopub.status.idle":"2021-05-20T00:20:51.064665Z","shell.execute_reply.started":"2021-05-20T00:20:35.067114Z","shell.execute_reply":"2021-05-20T00:20:51.063627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vect=  CountVectorizer()\nX_train_cnt = vect.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:51.065922Z","iopub.execute_input":"2021-05-20T00:20:51.06619Z","iopub.status.idle":"2021-05-20T00:20:51.809192Z","shell.execute_reply.started":"2021-05-20T00:20:51.066165Z","shell.execute_reply":"2021-05-20T00:20:51.808172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LR_param_selection(X, y, nfolds):\n    Cs = [0.01, 0.1, 1, 10]\n    param_grid = {'C': Cs}\n    grid_search = GridSearchCV(LogisticRegression(random_state=0,max_iter=2000), param_grid, cv=nfolds)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:51.810708Z","iopub.execute_input":"2021-05-20T00:20:51.81105Z","iopub.status.idle":"2021-05-20T00:20:51.815996Z","shell.execute_reply.started":"2021-05-20T00:20:51.810979Z","shell.execute_reply":"2021-05-20T00:20:51.814941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_param_selection( X_train_cnt,y_train,2)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:20:51.817308Z","iopub.execute_input":"2021-05-20T00:20:51.817554Z","iopub.status.idle":"2021-05-20T00:25:53.154551Z","shell.execute_reply.started":"2021-05-20T00:20:51.817529Z","shell.execute_reply":"2021-05-20T00:25:53.153526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf_counts = Pipeline([('vect', CountVectorizer()),\n                   ('clf', LogisticRegression(C=1,random_state=0, max_iter=2000)),\n                  ])\nLR_clf_counts.fit(X_train, y_train)\nLR_cnt_pred_tr = LR_clf_counts.predict(X_train)\nLR_cnt_pred_val = LR_clf_counts.predict(X_val)\n\nprint(\"accuracy on training: \",accuracy_score(y_train, LR_cnt_pred_tr))\nprint(\"precision on training: \",precision_score(y_train, LR_cnt_pred_tr, average='micro'))\nprint(\"precision on validation: \",precision_score(y_val, LR_cnt_pred_val, average='micro'))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:25:53.159552Z","iopub.execute_input":"2021-05-20T00:25:53.16205Z","iopub.status.idle":"2021-05-20T00:26:53.314797Z","shell.execute_reply.started":"2021-05-20T00:25:53.161993Z","shell.execute_reply":"2021-05-20T00:26:53.313689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:26:53.316505Z","iopub.execute_input":"2021-05-20T00:26:53.316922Z","iopub.status.idle":"2021-05-20T00:28:50.790618Z","shell.execute_reply.started":"2021-05-20T00:26:53.316862Z","shell.execute_reply":"2021-05-20T00:28:50.789794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archive_train = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\narchive_test = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip')\nfinal_train = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip',delimiter='\\t')\nfinal_test = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip',delimiter='\\t')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:28:50.792033Z","iopub.execute_input":"2021-05-20T00:28:50.792651Z","iopub.status.idle":"2021-05-20T00:28:51.071503Z","shell.execute_reply.started":"2021-05-20T00:28:50.79261Z","shell.execute_reply":"2021-05-20T00:28:51.070645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ftrain_preprocessed = preprocess(final_train,0)\nftest_preprocessed = preprocess(final_test,1)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:28:51.072778Z","iopub.execute_input":"2021-05-20T00:28:51.073091Z","iopub.status.idle":"2021-05-20T00:28:51.761864Z","shell.execute_reply.started":"2021-05-20T00:28:51.073064Z","shell.execute_reply":"2021-05-20T00:28:51.760968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train =  ftrain_preprocessed['PhraseId'], ftrain_preprocessed['Phrase_txt'], ftrain_preprocessed['Sentiment']\nid_test, X_test = ftest_preprocessed['PhraseId'], ftest_preprocessed['Phrase_txt']","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:28:51.763169Z","iopub.execute_input":"2021-05-20T00:28:51.763426Z","iopub.status.idle":"2021-05-20T00:28:51.768778Z","shell.execute_reply.started":"2021-05-20T00:28:51.763402Z","shell.execute_reply":"2021-05-20T00:28:51.767541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf = Pipeline([('vect', CountVectorizer()),\n                   ('clf', LogisticRegression(C=1,random_state=0, max_iter=2000))\n])\nLR_clf.fit(X_train, y_train)\npred_tst = LR_clf_counts.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:28:51.770261Z","iopub.execute_input":"2021-05-20T00:28:51.770596Z","iopub.status.idle":"2021-05-20T00:30:34.849602Z","shell.execute_reply.started":"2021-05-20T00:28:51.770569Z","shell.execute_reply":"2021-05-20T00:30:34.848752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=pd.DataFrame({'PhraseId' : id_test , 'Sentiment' : pred_tst})\noutput.to_csv('Sentiment_preds_LR.csv' , index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:30:34.850631Z","iopub.execute_input":"2021-05-20T00:30:34.851024Z","iopub.status.idle":"2021-05-20T00:30:34.930188Z","shell.execute_reply.started":"2021-05-20T00:30:34.850994Z","shell.execute_reply":"2021-05-20T00:30:34.929427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', MultinomialNB())\n])\nNB_clf.fit(X_train, y_train)\npred_tst = NB_clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:32:56.08641Z","iopub.execute_input":"2021-05-20T00:32:56.086901Z","iopub.status.idle":"2021-05-20T00:32:57.608936Z","shell.execute_reply.started":"2021-05-20T00:32:56.086857Z","shell.execute_reply":"2021-05-20T00:32:57.607833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=pd.DataFrame({'PhraseId' : id_test , 'Sentiment' : pred_tst})\noutput.to_csv('Sentiment_preds_NB.csv' , index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T00:34:18.5986Z","iopub.execute_input":"2021-05-20T00:34:18.598949Z","iopub.status.idle":"2021-05-20T00:34:18.675949Z","shell.execute_reply.started":"2021-05-20T00:34:18.598919Z","shell.execute_reply":"2021-05-20T00:34:18.674979Z"},"trusted":true},"execution_count":null,"outputs":[]}]}