{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n   # for filename in filenames:\n      #  print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom nltk.corpus import stopwords\nimport sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\ntrainData = pd.read_table(\"train.tsv\")\n\n# trainData = trainData.head(50000)\nprint(trainData.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trainData['Sentiment'].value_counts())\ntrainData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nprint(stop_words)\nnon_stop_words = {\"not\",\"isn't\",\"don't\"}\n# # print(non_stop_words)\nstop_words = stop_words - non_stop_words\n# print(stop_words)\nprint(len(stop_words))\ntrainData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stopwords(text):\n    '''a function for removing the stopword'''\n    # removing the stop words and lowercasing the selected words\n    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n    # joining the list of words with space separator\n    return \" \".join(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData['Phrase'] = trainData['Phrase'].apply(stopwords)\ntrainData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef remove_punctuation(text):\n    '''a function for removing punctuation'''    \n    # replacing the punctuations with no space, \n    # which in effect deletes the punctuation marks \n    translator = str.maketrans('', '', string.punctuation)\n    # return the text stripped of punctuation marks\n    return text.translate(translator)\n\ntrainData['Phrase'] = trainData['Phrase'].apply(remove_punctuation)\ntrainData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData = trainData.drop_duplicates(subset = ['Phrase'])\nprint(trainData.shape)\ntrainData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trainData['Sentiment'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncountVectorizer = CountVectorizer()\ncountVectorizer.fit(trainData[\"Phrase\"])\n# collect the vocabulary items used in the vectorizer\ndictionary = countVectorizer.vocabulary_.items()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = []\nvocab = []\n# iterate through each vocab and count append the value to designated lists\nfor key, value in dictionary:\n    vocab.append(key)\n    count.append(value)\n# store the count in panadas dataframe with vocab as index\nvocab_bef_stem = pd.Series(count, index=vocab)\n# sort the dataframe\nvocab_bef_stem = vocab_bef_stem.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\n# create an object of stemming function\nstemmer = SnowballStemmer(\"english\")\n\ndef stemming(text):    \n    '''a function which stems each word in the given text'''\n    text = [stemmer.stem(word) for word in text.split()]\n    return \" \".join(text)\n\ntrainData[\"Phrase\"] = trainData[\"Phrase\"].apply(stemming)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def length(text):    \n    '''a function which returns the length of text'''\n    return len(text)\n\ntrainData['length'] = trainData['Phrase'].apply(length)\ntrainData.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = df.drop(df[df.score < 50].index)\ntrainData = trainData.drop(trainData[trainData.length == 0].index)\ntrainData.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\ndef applyKNN(new_trainData):\n    new_trainData = dropNaNSentiments(new_trainData)\n    Y = new_trainData['Y']\n    X = new_trainData.drop(['Y'], axis = 1)\n    print(Y.shape)\n    print(X.shape)\n    X[\"PhraseId\"].fillna( method ='ffill', inplace = True)\n    X[\"SeneteceId\"].fillna( method ='ffill', inplace = True)\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n    neighbor = KNeighborsClassifier(n_neighbors = 5,algorithm = 'ball_tree')\n    neighbor.fit(X_train,y_train)\n    print(neighbor.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def appendPharseIDY(phraseDataframe):\n    phraseDataframe['PhraseId'] = trainData['PhraseId']\n    phraseDataframe['SeneteceId'] = trainData['SentenceId']\n    phraseDataframe['Y'] = trainData['Sentiment']\n    return phraseDataframe\n# Drop rows with NaN entities in Sentiment.\ndef dropNaNSentiments(inputDataFrame):\n    return inputDataFrame.dropna(subset = ['Y'])\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(trainData['Phrase'])\nX_D = X.todense()\n\nnew_trainData = pd.DataFrame(X_D)\nnew_trainData = appendPharseIDY(new_trainData)\nprint(new_trainData.shape)\n\n\nprint(\"Apply K-NN On Bag of Words:\")\napplyKNN(new_trainData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(trainData['Phrase'])\nX_D = X.todense()\nnew_trainData = pd.DataFrame(X_D)\nnew_trainData = appendPharseIDY(new_trainData)\nprint(new_trainData.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Apply K-NN On TF-IDF:\")\napplyKNN(new_trainData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Word2Vec(trainData['Phrase'], min_count = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = model[model.wv.vocab]\nnew_trainData = pd.DataFrame(X_D)\nnew_trainData = appendPharseIDY(new_trainData)\nprint(new_trainData.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Apply K-NN On Word Embeddings:\")\napplyKNN(new_trainData)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}