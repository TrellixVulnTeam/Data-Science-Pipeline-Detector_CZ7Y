{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis with Keras Tokenization & Embeddings + Multilayer Bidirectional LSTM"},{"metadata":{},"cell_type":"markdown","source":"Import required libs"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport random\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensure TF using GPU, and enable eager execution."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"TF version: \", tf.__version__)\nif tf.__version__ < \"2.0.0\":\n    tf.enable_eager_execution()\n    print(\"Eager execution enabled.\")\nelse:\n    print(\"Eager execution enabled by default.\")\n\nif tf.test.gpu_device_name(): \n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n   print(\"Please install GPU version of TF\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set random seed so we get consistent result when improveing our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def setseed(seed = 0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    \nSEED = 0\nsetseed(SEED)\n\nsetseed()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep = '\\t')\ntest = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip', sep = '\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take a look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Text Preprocessing**\n\nNormalization:\n* converting numbers into words or removing numbers\n* expanding abbreviations\n* removing stop words\n* remove sparse terms and particular words (Stemming/Lemmatization)\n\nAvailable in the tokenizer:\n* converting all letters to lower case\n* removing punctuations, accent marks and other diacritics\n* removing white spaces"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_sentences(df):\n    reviews = []\n    \n    for sent in tqdm(df['Phrase']):       \n        #remove non-alphabetic characters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", sent)\n        \n        #tokenize the sentences\n        words = word_tokenize(review_text.lower())\n        \n        #lemmatize each word to its lemma\n        lemmatizer = WordNetLemmatizer()\n        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n        \n        reviews.append(lemma_words)\n    \n    return(reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_sentences = clean_sentences(train)\ntest_sentences = clean_sentences(test)\n\nprint(len(train_sentences))\nprint(len(test_sentences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Phrase'][0])\nprint(' '.join(train_sentences[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turn label into OHE format"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\ntarget = train.Sentiment.values\ny_target = to_categorical(target)\n\n# number of numerical values exist in y_target's column\nnum_classes = y_target.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sentiment labels are:\n\n* 0 - negative\n* 1 - somewhat negative\n* 2 - neutral\n* 3 - somewhat positive\n* 4 - positive"},{"metadata":{},"cell_type":"markdown","source":"Set Training & Validation set to 80/20"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_sentences,\n                                                  y_target,\n                                                  test_size = 0.2,\n                                                  stratify = y_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get vocab sizes and max length"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_words = set()\nlen_max = 0\n\nfor sent in tqdm(X_train):\n    unique_words.update(sent)\n    if(len_max < len(sent)):\n        len_max = len(sent)\n\n# length of the list of unique_words \nprint('Number of vocabs: ', len(list(unique_words)))\nprint('Max length of text is: ', len_max)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenize the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(list(unique_words))\nembedding_dim = 300\nmax_length = len_max\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntokenizer = Tokenizer(num_words = vocab_size,\n                      # filters = '#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                      oov_token = oov_tok,\n                      # lower = True,\n                      char_level = False)\n\ntokenizer.fit_on_texts(list(X_train))\n\n# Training\nX_train = tokenizer.texts_to_sequences(X_train)\nX_train = pad_sequences(X_train,\n                        maxlen = max_length,\n                        padding = padding_type,\n                        truncating = trunc_type)\n\n# Validation\nX_val = tokenizer.texts_to_sequences(X_val)\nX_val = pad_sequences(X_val,\n                      maxlen = max_length,\n                      padding = padding_type,\n                      truncating = trunc_type)\n\n# Testing\nX_test = tokenizer.texts_to_sequences(test_sentences)\nX_test = pad_sequences(X_test,\n                       maxlen = max_length,\n                       padding = padding_type,\n                       truncating = trunc_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_training shape   : \",X_train.shape)\nprint(\"X_validation shape : \",X_val.shape)\nprint(\"X_testing shape    : \",X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train a Sentiment Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout = 0.8, recurrent_dropout=0.8, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout = 0.5, recurrent_dropout=0.5, return_sequences=False)),\n    tf.keras.layers.Dense(128, activation = 'relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n])\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(min_delta = 0.001,\n                               mode = 'max',\n                               monitor = 'val_acc',\n                               patience = 2)\ncallback = [early_stopping]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nnum_epochs = 5\n\nhistory = model.fit(X_train,\n                    y_train,\n                    validation_data = (X_val, y_val),\n                    epochs = num_epochs,\n                    batch_size = 256,\n                    verbose = 1,\n                    callbacks = callback)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the training graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n  \nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test['PhraseId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# y_pred = model.predict_classes(X_test)\ny_pred = np.argmax(model.predict(X_test), axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'PhraseId': test_id, 'Sentiment': y_pred})\nsubmission.to_csv('movie_review_prediction_5EP_MLBDLSTM_submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}