{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Importing required packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Conv1D, MaxPool1D, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep = '\\t')\ntest = pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip', sep = '\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop unnecessary columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['PhraseId','SentenceId'], inplace = True, axis = 'columns')\n\nsubmission = pd.DataFrame()\nsubmission['PhraseId'] = test['PhraseId']\ntest.drop(['PhraseId','SentenceId'], inplace = True, axis = 'columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Total classes of sentiments"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(train['Sentiment'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(train['Phrase'])\ntrain['Phrase'] = tokenizer.texts_to_sequences(train['Phrase'])\n\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(test['Phrase'])\ntest['Phrase'] = tokenizer.texts_to_sequences(test['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dealing with the padding"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = 100\n\ntrain_copy = train['Phrase']\ntrain_copy = pad_sequences(train['Phrase'],maxlen = max_length)\n\ntest_copy = test['Phrase']\ntest_copy = pad_sequences(test['Phrase'],maxlen = max_length)\n\nvocab_size = len(tokenizer.word_index) + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_copy\ny = pd.get_dummies(train['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting data for training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model constants\nembedding_vector_length = 32\n\n# RNN Model\nmodel = Sequential()\n\n# Embedding layer\nmodel.add(Embedding(input_dim=vocab_size, \n                    output_dim=embedding_vector_length, \n                    input_length=max_length))\n\n# Convolutional layer(1D)\nmodel.add(Conv1D(filters = 16,\n                 kernel_size = 3,\n                 padding = 'same',\n                 activation = 'relu'))\n\n# MaxPool(1D) - Reduce to half\nmodel.add(MaxPool1D(pool_size = 2))\n\n# LSTM layers\nmodel.add(LSTM(32, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\nmodel.add(LSTM(16, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = False))\n\n# Dense layers\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation = 'softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(min_delta = 0.001,\n                               mode = 'max',\n                               monitor = 'val_acc',\n                               patience = 2)\ncallback = [early_stopping]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_history = model.fit(x = X_train,\n                          y = y_train,\n                          batch_size = 1024,\n                          epochs = 20,\n                          verbose = 1,\n                          validation_data = (X_val, y_val),\n                          callbacks = callback)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_history.history['accuracy'], label='Training accuracy')\nplt.plot(train_history.history['val_accuracy'], label='Validation accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting and submitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test_copy)\nfinal_prediction = [np.argmax(i) for i in prediction]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Sentiment'] = final_prediction\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('../working/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}