{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sentiment Analysis on Movie Reviews\n\n","metadata":{}},{"cell_type":"markdown","source":"## importants imports library","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra library\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile # to read zip files\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt # ploting library\nfrom collections import Counter\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## read data from zip file\n## print the information  about the data  non null in the data and one column is string ","metadata":{}},{"cell_type":"code","source":"#unzip the files\narchive_train = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\n\n#read training json file \ntrain = pd.read_csv(archive_train.open('train.tsv'),sep='\\t')\n\n#output the frist 5 rows\nprint(train.head(10))\nprint(\"the information about the data \")\ntrain.info()\nprint(train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## split the data to train valdiation test ","metadata":{}},{"cell_type":"code","source":"train_data, test_data = train_test_split(train, test_size=0.4, random_state=1)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train set size is \",len(train_data))\nprint(\"Val set size is \",len(val_data))\nprint(\"Test set size is \",len(test_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.Business and Data Understanding\n     1.1 Understand business question\n         the data to analysis review\n      1.2 Evaluation matrix.\n         the output of the analysis is \n               0 - negative\n               1 - somewhat negative\n               2 - neutral\n               3 - somewhat positive\n               4 - positive\n         depends on PhraseId,Sentiment\n    1.3  What each row represents\n         phrase id to represent the pharse \n         the phrase is the sentce of strings \n         the sentence id  is the sentene in the phrase \n         sentiment the output of the data \n    1.4 Features types (numerical/ categorical)\n         all is numerical but one column is string \n      ","metadata":{}},{"cell_type":"markdown","source":"##  see the uniqe values in the data","metadata":{}},{"cell_type":"code","source":"num_PhraseId = len(train['PhraseId'].unique())\nprint(\"there are \",num_PhraseId,\" unique PhraseId.\")\nnum_SentenceId = len(train_data['SentenceId'].unique())\nprint(\"there are \",num_SentenceId,\" unique SentenceId.\")\nnum_Phrase = len(train_data['Phrase'].unique())\nprint(\"there are \",num_Phrase,\" unique Phrase.\")\nnum_Sentiment = len(train_data['Sentiment'].unique())\nprint(\"there are \",num_Sentiment,\" unique Phrase.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## check distribution of each column","metadata":{}},{"cell_type":"markdown","source":"## in the sentiement distribution i know that the sentiment 2 is most of output","metadata":{}},{"cell_type":"code","source":"# let's save list of cuisine names we have\nlabels = train_data['Sentiment'].unique()\n# plot the graph\nfig, ax = plt.subplots(figsize=(15,10)) # create the plot and specify the figure size\nplt.xlabel('Sentiment') # specify the x labels\nplt.ylabel('Frequency') # specify the y labels\nplt.title('Frequency of Sentiment') # specify the plot title\nplt.bar(labels,train_data['Sentiment'].value_counts()) # create a bar plot\nplt.xticks(rotation=80) # rotate the x labels\nplt.grid() # show the grid\nplt.show() # show the final plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## from sentence id and phrase id   i know that isn't help me in the data analysis","metadata":{}},{"cell_type":"code","source":"# let's save list of cuisine names we have\nlabels = train_data['SentenceId'].unique()\n# plot the graph\nfig, ax = plt.subplots(figsize=(15,10)) # create the plot and specify the figure size\nplt.xlabel('SentenceId') # specify the x labels\nplt.ylabel('Frequency') # specify the y labels\nplt.title('Frequency of SentenceId') # specify the plot title\nplt.bar(labels,train_data['SentenceId'].value_counts()) # create a bar plot\nplt.xticks(rotation=80) # rotate the x labels\nplt.grid() # show the grid\nplt.show() # show the final plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## split to pharse column(string column)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['new_phrase_train']=train_data['Phrase'].str.split()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(train_data['Phrase'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_rows = 1000\npd.DataFrame(train_data['new_phrase_train'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy=[]\n# for i in range(len(train_data['Sentiment'])):\n#     if train_data['Sentiment'].iloc[i]==2:\n#        print(train_data['Phrase'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['new_phrase_train'].value_counts().sort_index().head(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['new_phrase_train'].sample(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['new_phrase_test']=test_data['Phrase'].str.split()\ntest_data['new_phrase_test'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}