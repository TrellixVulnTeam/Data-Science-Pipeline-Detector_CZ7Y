{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-11T17:42:23.050835Z","iopub.execute_input":"2022-06-11T17:42:23.051495Z","iopub.status.idle":"2022-06-11T17:42:23.065674Z","shell.execute_reply.started":"2022-06-11T17:42:23.051397Z","shell.execute_reply":"2022-06-11T17:42:23.0646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n\nfrom tqdm import tqdm\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nimport re\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Bidirectional,LSTM,Activation,Conv1D,MaxPool1D,Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, LSTM, Activation\nfrom keras.preprocessing import sequence\nfrom keras.initializers import glorot_uniform\nfrom keras.utils import np_utils\nnp.random.seed(1)\n\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:42:39.111218Z","iopub.execute_input":"2022-06-11T17:42:39.111931Z","iopub.status.idle":"2022-06-11T17:42:46.701055Z","shell.execute_reply.started":"2022-06-11T17:42:39.111875Z","shell.execute_reply":"2022-06-11T17:42:46.700167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep = '\\t')\nt.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:42:46.702401Z","iopub.execute_input":"2022-06-11T17:42:46.702653Z","iopub.status.idle":"2022-06-11T17:42:46.975279Z","shell.execute_reply.started":"2022-06-11T17:42:46.702629Z","shell.execute_reply":"2022-06-11T17:42:46.974401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"te = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip',sep = '\\t')\nte.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:42:46.976816Z","iopub.execute_input":"2022-06-11T17:42:46.977078Z","iopub.status.idle":"2022-06-11T17:42:47.077942Z","shell.execute_reply.started":"2022-06-11T17:42:46.977053Z","shell.execute_reply":"2022-06-11T17:42:47.077055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Data\\n\")\nprint(t.info())\nprint(\"***************************************\")\nprint(\"Test Data\\n\")\nte.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:42:47.07947Z","iopub.execute_input":"2022-06-11T17:42:47.07973Z","iopub.status.idle":"2022-06-11T17:42:47.117233Z","shell.execute_reply.started":"2022-06-11T17:42:47.079705Z","shell.execute_reply":"2022-06-11T17:42:47.116244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_sentences(df):\n    \n    reviews = []\n    for sent in tqdm(df['Phrase']):\n        # removing non-alphabetical characters \n        text = re.sub(\"[^a-zA-Z]\",\" \",sent)\n        \n        # Now tokenizing the sentence : \n        words = word_tokenize(text.lower())\n        \n        #removing stop words :\n        new_words = [ ele for ele in words if ele.lower() not in stopwords.words('english') ]\n        \n        # Lemmatizing each word to its lemma\n        lem = WordNetLemmatizer()\n        lem_words = [lem.lemmatize(i) for i in new_words]\n        \n        #finally\n        reviews.append(lem_words)\n        \n    return(reviews)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:42:47.118558Z","iopub.execute_input":"2022-06-11T17:42:47.119101Z","iopub.status.idle":"2022-06-11T17:42:47.126067Z","shell.execute_reply.started":"2022-06-11T17:42:47.119061Z","shell.execute_reply":"2022-06-11T17:42:47.125294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_sentences = clean_sentences(t)\ntest_sentences = clean_sentences(te)\n\nprint(len(train_sentences))\nprint(len(test_sentences))","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:42:47.127228Z","iopub.execute_input":"2022-06-11T17:42:47.127773Z","iopub.status.idle":"2022-06-11T17:46:27.440283Z","shell.execute_reply.started":"2022-06-11T17:42:47.127732Z","shell.execute_reply":"2022-06-11T17:46:27.439432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_target = to_categorical(t['Sentiment'].values)\ny_target.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:46:27.44158Z","iopub.execute_input":"2022-06-11T17:46:27.441857Z","iopub.status.idle":"2022-06-11T17:46:27.452457Z","shell.execute_reply.started":"2022-06-11T17:46:27.441828Z","shell.execute_reply":"2022-06-11T17:46:27.451629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train,X_val,y_train,y_val = train_test_split(train_sentences,y_target,test_size = 0.2,stratify = y_target)\n\nunique_words = set()\nlen_max = -1\n\nfor sent in tqdm(X_train):\n    unique_words.update(sent)\n    if(len_max < len(sent)):\n        len_max = len(sent)\n#Bag of words\nprint('Words in vocab : ' , len(list(unique_words)))\nprint('Max_length : ' , len_max)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:46:27.45492Z","iopub.execute_input":"2022-06-11T17:46:27.455306Z","iopub.status.idle":"2022-06-11T17:46:28.77907Z","shell.execute_reply.started":"2022-06-11T17:46:27.455266Z","shell.execute_reply":"2022-06-11T17:46:28.777967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v = len(list(unique_words))\nembedding_dim = 300\nmax_length = len_max\ntrunc_type = 'post'\npadding_type = 'post'\noov_tok = '<OOV>'\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:46:28.780831Z","iopub.execute_input":"2022-06-11T17:46:28.781203Z","iopub.status.idle":"2022-06-11T17:46:28.786762Z","shell.execute_reply.started":"2022-06-11T17:46:28.781162Z","shell.execute_reply":"2022-06-11T17:46:28.786037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntokenizer = Tokenizer(num_words = v,\n                      # filters = '#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                      oov_token = oov_tok,\n                      # lower = True,\n                      char_level = False)\n\ntokenizer.fit_on_texts(list(X_train))\n\n# Training\nX_train = tokenizer.texts_to_sequences(X_train)\nX_train = pad_sequences(X_train,\n                        maxlen = max_length,\n                        padding = padding_type,\n                        truncating = trunc_type)\n\n# Validation\nX_val = tokenizer.texts_to_sequences(X_val)\nX_val = pad_sequences(X_val,\n                      maxlen = max_length,\n                      padding = padding_type,\n                      truncating = trunc_type)\n\n# Testing\nX_test = tokenizer.texts_to_sequences(test_sentences)\nX_test = pad_sequences(X_test,\n                       maxlen = max_length,\n                       padding = padding_type,\n                       truncating = trunc_type)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:46:28.787858Z","iopub.execute_input":"2022-06-11T17:46:28.788095Z","iopub.status.idle":"2022-06-11T17:46:31.125052Z","shell.execute_reply.started":"2022-06-11T17:46:28.788073Z","shell.execute_reply":"2022-06-11T17:46:31.124044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_training shape   : \",X_train.shape)\nprint(\"X_validation shape : \",X_val.shape)\nprint(\"X_testing shape    : \",X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:46:31.126277Z","iopub.execute_input":"2022-06-11T17:46:31.126595Z","iopub.status.idle":"2022-06-11T17:46:31.132074Z","shell.execute_reply.started":"2022-06-11T17:46:31.126566Z","shell.execute_reply":"2022-06-11T17:46:31.131437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(v,embedding_dim,input_length = max_length))\nmodel.add(Bidirectional(LSTM(128,dropout = 0.2, recurrent_dropout = 0.2, return_sequences=True)))\nmodel.add(Bidirectional(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2, return_sequences=False)))\nmodel.add(Dense(128,activation = 'relu'))\nmodel.add(Dense(y_target.shape[1],activation = 'softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:46:31.132997Z","iopub.execute_input":"2022-06-11T17:46:31.133396Z","iopub.status.idle":"2022-06-11T17:46:31.814215Z","shell.execute_reply.started":"2022-06-11T17:46:31.133362Z","shell.execute_reply":"2022-06-11T17:46:31.813209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='./model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:48:01.22188Z","iopub.execute_input":"2022-06-11T17:48:01.22223Z","iopub.status.idle":"2022-06-11T17:48:01.789824Z","shell.execute_reply.started":"2022-06-11T17:48:01.222191Z","shell.execute_reply":"2022-06-11T17:48:01.788498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(min_delta = 0.001,\n                               mode = 'max',\n                               monitor = 'val_acc',\n                               patience = 2)\ncallback = [early_stopping]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:49:07.605474Z","iopub.execute_input":"2022-06-11T17:49:07.605911Z","iopub.status.idle":"2022-06-11T17:49:07.610755Z","shell.execute_reply.started":"2022-06-11T17:49:07.605871Z","shell.execute_reply":"2022-06-11T17:49:07.609822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nnum_epochs = 10\n\nhistory = model.fit(X_train,y_train,\n                    validation_data = (X_val, y_val),\n                    epochs = num_epochs,\n                    batch_size = 256,\n                    verbose = 1,\n                    callbacks = callback)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T17:49:14.180921Z","iopub.execute_input":"2022-06-11T17:49:14.181284Z","iopub.status.idle":"2022-06-11T18:44:06.584348Z","shell.execute_reply.started":"2022-06-11T17:49:14.181242Z","shell.execute_reply":"2022-06-11T18:44:06.583687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()\nplt.savefig('./accurac2y.png')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T18:52:05.321785Z","iopub.execute_input":"2022-06-11T18:52:05.322109Z","iopub.status.idle":"2022-06-11T18:52:05.462257Z","shell.execute_reply.started":"2022-06-11T18:52:05.322081Z","shell.execute_reply":"2022-06-11T18:52:05.4614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()\nplt.savefig('./loss.png')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T18:49:15.516567Z","iopub.execute_input":"2022-06-11T18:49:15.516909Z","iopub.status.idle":"2022-06-11T18:49:15.638555Z","shell.execute_reply.started":"2022-06-11T18:49:15.516881Z","shell.execute_reply":"2022-06-11T18:49:15.637767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.savefig('./books_read.png')\n# model.save('./new_model.h5')\nwith open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:35:27.407012Z","iopub.execute_input":"2021-12-30T07:35:27.407352Z","iopub.status.idle":"2021-12-30T07:35:27.435125Z","shell.execute_reply.started":"2021-12-30T07:35:27.407323Z","shell.execute_reply":"2021-12-30T07:35:27.433837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_id = te['PhraseId']\n\n# y_pred = np.argmax(model.predict(X_test), axis = -1)\n\n# submission_df = pd.DataFrame({'PhraseId': test_id, 'Sentiment': y_pred})\n# submission_df.to_csv('submission_.csv', index=False)\n# submission_df.head()\n\nimport pickle\nwith open('./tokenizer.pickle', 'rb') as handle:\n    tokenizer = pickle.load(handle)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:35:40.231293Z","iopub.execute_input":"2021-12-30T07:35:40.231694Z","iopub.status.idle":"2021-12-30T07:35:40.255871Z","shell.execute_reply.started":"2021-12-30T07:35:40.231663Z","shell.execute_reply":"2021-12-30T07:35:40.254735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 30\ntrunc_type = 'post'\npadding_type = 'post'\n\nimport pickle\nwith open('./tokenizer.pickle', 'rb') as handle:\n    tokenizer = pickle.load(handle)\nX_test = tokenizer.texts_to_sequences(['Very good movie'])\nfrom keras.preprocessing.sequence import pad_sequences\nX_test = pad_sequences(X_test,\n                       maxlen = max_length,\n                       padding = padding_type,\n                       truncating = trunc_type)\nnp.argmax(model.predict(X_test), axis = -1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:07:40.931081Z","iopub.execute_input":"2021-12-29T16:07:40.931428Z","iopub.status.idle":"2021-12-29T16:07:41.02699Z","shell.execute_reply.started":"2021-12-29T16:07:40.931398Z","shell.execute_reply":"2021-12-29T16:07:41.025856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(model.predict(X_test), axis = -1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:03:18.930109Z","iopub.execute_input":"2021-12-29T16:03:18.93067Z","iopub.status.idle":"2021-12-29T16:03:19.004255Z","shell.execute_reply.started":"2021-12-29T16:03:18.930605Z","shell.execute_reply":"2021-12-29T16:03:19.003269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = v,\n                      # filters = '#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                      oov_token = oov_tok,\n                      # lower = True,\n                      char_level = False)\n\ntokenizer.fit_on_texts(list(X_train))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:59:04.421273Z","iopub.execute_input":"2021-12-29T15:59:04.421645Z","iopub.status.idle":"2021-12-29T15:59:05.271321Z","shell.execute_reply.started":"2021-12-29T15:59:04.421613Z","shell.execute_reply":"2021-12-29T15:59:05.270196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 30\ntrunc_type = 'post'\npadding_type = 'post'","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:35:52.209542Z","iopub.execute_input":"2021-12-30T07:35:52.209935Z","iopub.status.idle":"2021-12-30T07:35:52.21715Z","shell.execute_reply.started":"2021-12-30T07:35:52.209902Z","shell.execute_reply":"2021-12-30T07:35:52.215726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nimport pickle\nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:35:53.826745Z","iopub.execute_input":"2021-12-30T07:35:53.827145Z","iopub.status.idle":"2021-12-30T07:35:53.832764Z","shell.execute_reply.started":"2021-12-30T07:35:53.827113Z","shell.execute_reply":"2021-12-30T07:35:53.831348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('./new_model.h5')\n# with open('../input/models/tokenizer.pickle', 'rb') as handle:\n#     tokenizer = pickle.load(handle)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:35:58.462708Z","iopub.execute_input":"2021-12-30T07:35:58.463348Z","iopub.status.idle":"2021-12-30T07:35:59.173755Z","shell.execute_reply.started":"2021-12-30T07:35:58.463292Z","shell.execute_reply":"2021-12-30T07:35:59.172603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Sentence = 'worst movie'","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:35:59.953992Z","iopub.execute_input":"2021-12-30T07:35:59.954333Z","iopub.status.idle":"2021-12-30T07:35:59.958865Z","shell.execute_reply.started":"2021-12-30T07:35:59.954304Z","shell.execute_reply":"2021-12-30T07:35:59.957649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentiment(Sentence, tokenizer = tokenizer, model = model):\n    Sentence = tokenizer.texts_to_sequences([Sentence])\n    Sentence = pad_sequences(Sentence,\n                           maxlen = max_length,\n                           padding = padding_type,\n                           truncating = trunc_type)\n    ans = np.argmax(model.predict(Sentence), axis = -1)\n    return ans[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:36:00.834917Z","iopub.execute_input":"2021-12-30T07:36:00.835315Z","iopub.status.idle":"2021-12-30T07:36:00.845799Z","shell.execute_reply.started":"2021-12-30T07:36:00.835283Z","shell.execute_reply":"2021-12-30T07:36:00.844721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment(Sentence)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:36:01.835021Z","iopub.execute_input":"2021-12-30T07:36:01.835801Z","iopub.status.idle":"2021-12-30T07:36:02.769017Z","shell.execute_reply.started":"2021-12-30T07:36:01.835751Z","shell.execute_reply":"2021-12-30T07:36:02.76374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('../input/models/model.h5')\n\nmax_length = 30\ntrunc_type = 'post'\npadding_type = 'post'\n\nimport pickle\nwith open('../input/models/tokenizer.pickle', 'rb') as handle:\n    tokenizer = pickle.load(handle)\nX_test = tokenizer.texts_to_sequences(['Very good movie'])\nfrom keras.preprocessing.sequence import pad_sequences\nX_test = pad_sequences(X_test,\n                       maxlen = max_length,\n                       padding = padding_type,\n                       truncating = trunc_type)\nnp.argmax(model.predict(X_test), axis = -1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:19:57.053331Z","iopub.execute_input":"2021-12-29T16:19:57.053743Z","iopub.status.idle":"2021-12-29T16:19:58.007882Z","shell.execute_reply.started":"2021-12-29T16:19:57.053709Z","shell.execute_reply":"2021-12-29T16:19:58.006916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T16:21:42.538402Z","iopub.execute_input":"2021-12-29T16:21:42.538814Z","iopub.status.idle":"2021-12-29T16:21:42.552338Z","shell.execute_reply.started":"2021-12-29T16:21:42.538726Z","shell.execute_reply":"2021-12-29T16:21:42.550534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}