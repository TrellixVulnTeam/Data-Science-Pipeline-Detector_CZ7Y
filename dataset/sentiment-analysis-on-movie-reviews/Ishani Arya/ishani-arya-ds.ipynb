{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"db9bdd5b-5db1-4e08-ba30-e8c07bf39fa4","_cell_guid":"f238d73b-0dd5-4a39-a558-943d77439893","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-16T15:37:55.745882Z","iopub.execute_input":"2022-03-16T15:37:55.746617Z","iopub.status.idle":"2022-03-16T15:37:55.756167Z","shell.execute_reply.started":"2022-03-16T15:37:55.746581Z","shell.execute_reply":"2022-03-16T15:37:55.755369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing rapids libraries\nimport cudf\nimport cupy\n\n#importing important libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nfrom bs4 import BeautifulSoup\nimport re\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import to_categorical\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Dense,Dropout,Embedding,LSTM\nfrom keras.callbacks import EarlyStopping\nfrom keras.losses import categorical_crossentropy\n\nfrom keras.models import Sequential\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:37:58.415961Z","iopub.execute_input":"2022-03-16T15:37:58.416684Z","iopub.status.idle":"2022-03-16T15:37:58.423271Z","shell.execute_reply.started":"2022-03-16T15:37:58.416649Z","shell.execute_reply":"2022-03-16T15:37:58.422226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing csv file of the given data \ntrain=pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip',sep='\\t')\ntest=pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip',sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:01.580727Z","iopub.execute_input":"2022-03-16T15:38:01.581406Z","iopub.status.idle":"2022-03-16T15:38:01.830768Z","shell.execute_reply.started":"2022-03-16T15:38:01.581371Z","shell.execute_reply":"2022-03-16T15:38:01.830036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Understanding the given dataset**\n\nThe next few steps will help us understand the data in terms of shape, description, etc such that it is easier to work on its preprocessing.","metadata":{}},{"cell_type":"code","source":"print(train.shape,test.shape)\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:03.794779Z","iopub.execute_input":"2022-03-16T15:38:03.795048Z","iopub.status.idle":"2022-03-16T15:38:03.805877Z","shell.execute_reply.started":"2022-03-16T15:38:03.79502Z","shell.execute_reply":"2022-03-16T15:38:03.805032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The sentiment labels are:\n\n0 - negative\n\n1 - somewhat negative\n\n2 - neutral\n\n3 - somewhat positive\n\n4 - positive","metadata":{}},{"cell_type":"code","source":"Sentiment_count=train.groupby('Sentiment').count()\nplt.bar(Sentiment_count.index.values, Sentiment_count['Phrase'])\nplt.xlabel('Review Sentiments')\nplt.ylabel('Number of Review')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:08.040545Z","iopub.execute_input":"2022-03-16T15:38:08.040801Z","iopub.status.idle":"2022-03-16T15:38:08.262796Z","shell.execute_reply.started":"2022-03-16T15:38:08.040774Z","shell.execute_reply":"2022-03-16T15:38:08.262105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:33:37.513023Z","iopub.execute_input":"2022-03-16T15:33:37.513299Z","iopub.status.idle":"2022-03-16T15:33:37.521107Z","shell.execute_reply.started":"2022-03-16T15:33:37.513272Z","shell.execute_reply":"2022-03-16T15:33:37.520164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().any().any()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:33:39.620448Z","iopub.execute_input":"2022-03-16T15:33:39.620707Z","iopub.status.idle":"2022-03-16T15:33:39.644787Z","shell.execute_reply.started":"2022-03-16T15:33:39.620677Z","shell.execute_reply":"2022-03-16T15:33:39.643896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().any().any()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:33:41.703301Z","iopub.execute_input":"2022-03-16T15:33:41.703555Z","iopub.status.idle":"2022-03-16T15:33:41.717893Z","shell.execute_reply.started":"2022-03-16T15:33:41.703527Z","shell.execute_reply":"2022-03-16T15:33:41.717155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing**\n\nThis stage will be used to clean the data by removing html tags, non-alphabetic characters, etc and make the data\n\na. consistent and efficient\n\nb. easier for the learning algorithm to parse","metadata":{}},{"cell_type":"code","source":"#Function for cleaning the reviews, tokenize and lemmatize them.\n\ndef clean_sentences(df):\n    reviews = []\n\n    for sent in tqdm(df['Phrase']):\n        \n        #remove html content\n        review_text = BeautifulSoup(sent).get_text()\n        \n        #remove non-alphabetic characters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n        \n    \n        #tokenize the sentences\n        words = word_tokenize(review_text.lower())\n    \n        #lemmatize each word to its lemma\n        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n    \n        reviews.append(lemma_words)\n\n    return(reviews)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:12.857678Z","iopub.execute_input":"2022-03-16T15:38:12.857961Z","iopub.status.idle":"2022-03-16T15:38:12.865002Z","shell.execute_reply.started":"2022-03-16T15:38:12.857931Z","shell.execute_reply":"2022-03-16T15:38:12.86397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#retrieving cleaned reviews for both train and test set \n\ntrain_sentences = clean_sentences(train)\ntest_sentences = clean_sentences(test)\n\nprint(len(train_sentences))\nprint(len(test_sentences))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:38:19.955279Z","iopub.execute_input":"2022-03-16T15:38:19.95553Z","iopub.status.idle":"2022-03-16T15:40:00.672425Z","shell.execute_reply.started":"2022-03-16T15:38:19.955502Z","shell.execute_reply":"2022-03-16T15:40:00.671668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Collect the dependent values and convert to one-hot encoded output using to_categorical\n\ntarget=train.Sentiment.values\ny_target=to_categorical(target)\nnum_classes=y_target.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:08.158286Z","iopub.execute_input":"2022-03-16T15:40:08.158542Z","iopub.status.idle":"2022-03-16T15:40:08.167298Z","shell.execute_reply.started":"2022-03-16T15:40:08.158515Z","shell.execute_reply":"2022-03-16T15:40:08.166427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(train_sentences,y_target,\n                                             test_size=0.2,stratify=y_target)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:12.535454Z","iopub.execute_input":"2022-03-16T15:40:12.535708Z","iopub.status.idle":"2022-03-16T15:40:13.800975Z","shell.execute_reply.started":"2022-03-16T15:40:12.535679Z","shell.execute_reply":"2022-03-16T15:40:13.800254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Geting the No. of unique words and max length of a review available in the list of cleaned reviews.\n\nunique_words = set()\nlen_max = 0\n\nfor sent in tqdm(X_train):\n    \n    unique_words.update(sent)\n    \n    if(len_max<len(sent)):\n        len_max = len(sent)\n        \nprint(len(list(unique_words)))\nprint(len_max)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:15.622209Z","iopub.execute_input":"2022-03-16T15:40:15.622482Z","iopub.status.idle":"2022-03-16T15:40:15.857316Z","shell.execute_reply.started":"2022-03-16T15:40:15.622455Z","shell.execute_reply":"2022-03-16T15:40:15.853379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=len(list(unique_words)))\ntokenizer.fit_on_texts(list(X_train))\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_val = tokenizer.texts_to_sequences(X_val)\nX_test = tokenizer.texts_to_sequences(test_sentences)\n\n\nX_train = sequence.pad_sequences(X_train, maxlen=len_max)\nX_val = sequence.pad_sequences(X_val, maxlen=len_max)\nX_test = sequence.pad_sequences(X_test, maxlen=len_max)\n\nprint(X_train.shape,X_val.shape,X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:22.825823Z","iopub.execute_input":"2022-03-16T15:40:22.826622Z","iopub.status.idle":"2022-03-16T15:40:26.295216Z","shell.execute_reply.started":"2022-03-16T15:40:22.826571Z","shell.execute_reply":"2022-03-16T15:40:26.294434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\ncallback = [early_stopping]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:30.556133Z","iopub.execute_input":"2022-03-16T15:40:30.556849Z","iopub.status.idle":"2022-03-16T15:40:30.560545Z","shell.execute_reply.started":"2022-03-16T15:40:30.556817Z","shell.execute_reply":"2022-03-16T15:40:30.559878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model using Keras LSTM\n\nmodel=Sequential()\n\nmodel.add(Embedding(len(list(unique_words)),300,input_length=len_max))\nmodel.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\nmodel.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes,activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy','mean_squared_error'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:33.577061Z","iopub.execute_input":"2022-03-16T15:40:33.577624Z","iopub.status.idle":"2022-03-16T15:40:33.806038Z","shell.execute_reply.started":"2022-03-16T15:40:33.577589Z","shell.execute_reply":"2022-03-16T15:40:33.805329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                  epochs=6, batch_size=256, verbose=1, callbacks=callback)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T15:40:38.147931Z","iopub.execute_input":"2022-03-16T15:40:38.148371Z","iopub.status.idle":"2022-03-16T16:03:04.333923Z","shell.execute_reply.started":"2022-03-16T15:40:38.148334Z","shell.execute_reply":"2022-03-16T16:03:04.333161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model using cnn\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\ntokenize = Tokenizer()\nembedding_dimension = 100\ninput_val = len(tokenize.word_index)+1\nmodel_CNN = tf.keras.Sequential([\n    tf.keras.layers.Embedding(len(list(unique_words)),300,input_length=len_max),\n    tf.keras.layers.Conv1D(128, 2, padding='same',activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv1D(64, 2, padding='same',activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:23:53.160706Z","iopub.execute_input":"2022-03-16T16:23:53.160959Z","iopub.status.idle":"2022-03-16T16:23:53.239513Z","shell.execute_reply.started":"2022-03-16T16:23:53.16093Z","shell.execute_reply":"2022-03-16T16:23:53.238675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_CNN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory=model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                  epochs=6, batch_size=256, verbose=1, callbacks=callback)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:26:52.325743Z","iopub.execute_input":"2022-03-16T16:26:52.32605Z","iopub.status.idle":"2022-03-16T16:49:27.239253Z","shell.execute_reply.started":"2022-03-16T16:26:52.326012Z","shell.execute_reply":"2022-03-16T16:49:27.238536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, we can clearly see that the accuracy in CNN model is more(76.15%) than in the lstm model(72.45%).","metadata":{}}]}