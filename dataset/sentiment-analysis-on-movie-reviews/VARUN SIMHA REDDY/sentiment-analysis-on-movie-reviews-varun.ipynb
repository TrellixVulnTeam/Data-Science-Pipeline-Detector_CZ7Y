{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-30T09:43:47.946472Z","iopub.execute_input":"2021-05-30T09:43:47.947176Z","iopub.status.idle":"2021-05-30T09:43:47.956343Z","shell.execute_reply.started":"2021-05-30T09:43:47.947056Z","shell.execute_reply":"2021-05-30T09:43:47.955543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport zipfile # to read zip files\nfrom sklearn.model_selection import train_test_split\n\n\n# data understanding libraries\nimport matplotlib.pyplot as plt # ploting library\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\n\n\n# data preparation\nimport re\nfrom nltk.stem import PorterStemmer\n\n\n# ADS Creation\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n# Modeling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Evaluation and Model Selection\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:43:54.834132Z","iopub.execute_input":"2021-05-30T09:43:54.834789Z","iopub.status.idle":"2021-05-30T09:43:56.703262Z","shell.execute_reply.started":"2021-05-30T09:43:54.834739Z","shell.execute_reply":"2021-05-30T09:43:56.702373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 10000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.precision',150)\npd.options.display.float_format = '{:,.3f}'.format","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:44:16.944972Z","iopub.execute_input":"2021-05-30T09:44:16.945369Z","iopub.status.idle":"2021-05-30T09:44:16.955688Z","shell.execute_reply.started":"2021-05-30T09:44:16.945336Z","shell.execute_reply":"2021-05-30T09:44:16.954347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archive_train = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\n\ntrain = pd.read_csv(\"../input/sentiment-analysis-on-movie-reviews/train.tsv.zip\", sep='\\t')\ntrain.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:44:32.59347Z","iopub.execute_input":"2021-05-30T09:44:32.594217Z","iopub.status.idle":"2021-05-30T09:44:32.872321Z","shell.execute_reply.started":"2021-05-30T09:44:32.594145Z","shell.execute_reply":"2021-05-30T09:44:32.871249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(train, test_size=0.2, random_state=1)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=1)\n\ntrain_data = train_data.reset_index(drop=True)\nval_data = val_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:44:51.242822Z","iopub.execute_input":"2021-05-30T09:44:51.24319Z","iopub.status.idle":"2021-05-30T09:44:51.289502Z","shell.execute_reply.started":"2021-05-30T09:44:51.24316Z","shell.execute_reply":"2021-05-30T09:44:51.288389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train set size is \",len(train_data))\nprint(\"Val set size is \",len(val_data))\nprint(\"Test set size is \",len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:45:01.984478Z","iopub.execute_input":"2021-05-30T09:45:01.98506Z","iopub.status.idle":"2021-05-30T09:45:01.992125Z","shell.execute_reply.started":"2021-05-30T09:45:01.984996Z","shell.execute_reply":"2021-05-30T09:45:01.990943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:45:15.624779Z","iopub.execute_input":"2021-05-30T09:45:15.625189Z","iopub.status.idle":"2021-05-30T09:45:15.664692Z","shell.execute_reply.started":"2021-05-30T09:45:15.625156Z","shell.execute_reply":"2021-05-30T09:45:15.663131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words=\" \".join([row[\"Phrase\"] for ind,row in train_data.iterrows() ]).split()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:45:42.394535Z","iopub.execute_input":"2021-05-30T09:45:42.394878Z","iopub.status.idle":"2021-05-30T09:45:52.567615Z","shell.execute_reply.started":"2021-05-30T09:45:42.394848Z","shell.execute_reply":"2021-05-30T09:45:52.566527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_set=set(words)\nlen(words_set)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:46:10.944621Z","iopub.execute_input":"2021-05-30T09:46:10.945011Z","iopub.status.idle":"2021-05-30T09:46:11.029575Z","shell.execute_reply.started":"2021-05-30T09:46:10.944972Z","shell.execute_reply":"2021-05-30T09:46:11.028317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = train_data['Sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:46:27.864509Z","iopub.execute_input":"2021-05-30T09:46:27.864905Z","iopub.status.idle":"2021-05-30T09:46:27.872374Z","shell.execute_reply.started":"2021-05-30T09:46:27.86487Z","shell.execute_reply":"2021-05-30T09:46:27.871335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,10)) # create the plot and specify the figure size\nplt.xlabel('Sentiment') # specify the x labels\nplt.ylabel('Frequency') # specify the y labels\nplt.title('Frequency of Sentiment') # specify the plot title\nplt.bar(labels,train_data['Sentiment'].value_counts()) # create a bar plot\nplt.xticks(rotation=0) # rotate the x labels\nplt.grid() # show the grid\nplt.show() # show the final plot","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:46:44.944585Z","iopub.execute_input":"2021-05-30T09:46:44.944927Z","iopub.status.idle":"2021-05-30T09:46:45.189855Z","shell.execute_reply.started":"2021-05-30T09:46:44.944898Z","shell.execute_reply":"2021-05-30T09:46:45.188818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add column with num of word per phrase\ntrain_data['Phrase_num'] = train_data[\"Phrase\"].apply(len)\n\n# save list of the unique numbers we have\nnumbers = train_data[\"Phrase\"].apply(len).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:47:03.183797Z","iopub.execute_input":"2021-05-30T09:47:03.184218Z","iopub.status.idle":"2021-05-30T09:47:03.328362Z","shell.execute_reply.started":"2021-05-30T09:47:03.184184Z","shell.execute_reply":"2021-05-30T09:47:03.327339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(30,10))\nplt.bar(numbers,train_data[\"Phrase_num\"].value_counts().sort_index())\nplt.xlabel('word Count')\nplt.ylabel('Number of phrase')\nplt.title('Number of word per phrase Count')\nplt.xticks(np.arange(min(numbers), max(numbers)+1, 4)) # change x labels from the defult to the given range\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:47:17.945112Z","iopub.execute_input":"2021-05-30T09:47:17.945696Z","iopub.status.idle":"2021-05-30T09:47:19.438443Z","shell.execute_reply.started":"2021-05-30T09:47:17.945663Z","shell.execute_reply":"2021-05-30T09:47:19.437261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins = range(0,180,5)\n\nfig, ax = plt.subplots(figsize=(20,10))\nplt.hist(train_data['Phrase_num'], bins=bins, edgecolor=\"k\") # output a histogram plot\nplt.xlabel('Word Count')\nplt.ylabel('Number of Phrases')\nplt.title('Number of word per phrase Count')\nplt.xticks(bins) # change x labels from the defult to the given range\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:47:33.52434Z","iopub.execute_input":"2021-05-30T09:47:33.524905Z","iopub.status.idle":"2021-05-30T09:47:33.964447Z","shell.execute_reply.started":"2021-05-30T09:47:33.524856Z","shell.execute_reply":"2021-05-30T09:47:33.963593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"There are \" ,len(train_data[train_data[\"Phrase_num\"]>130]), \" phrases with word more than 130.\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:47:48.334234Z","iopub.execute_input":"2021-05-30T09:47:48.334829Z","iopub.status.idle":"2021-05-30T09:47:48.366639Z","shell.execute_reply.started":"2021-05-30T09:47:48.334779Z","shell.execute_reply":"2021-05-30T09:47:48.365859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[train_data[\"Phrase_num\"]>130][['Phrase']]","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:48:03.37471Z","iopub.execute_input":"2021-05-30T09:48:03.375285Z","iopub.status.idle":"2021-05-30T09:48:03.815181Z","shell.execute_reply.started":"2021-05-30T09:48:03.375235Z","shell.execute_reply":"2021-05-30T09:48:03.813916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,8))\ntrain_data[train_data[\"Phrase_num\"]>=130].groupby(['Sentiment']).size().sort_values().plot(kind='barh', ax=ax)\nplt.title('Distribution of word with phrase >130 over sentiment')\nplt.ylabel('Sentiment')\nplt.xlabel('Number of word')\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:48:49.533923Z","iopub.execute_input":"2021-05-30T09:48:49.534293Z","iopub.status.idle":"2021-05-30T09:48:49.73313Z","shell.execute_reply.started":"2021-05-30T09:48:49.534263Z","shell.execute_reply":"2021-05-30T09:48:49.731943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,8))\nlst = Counter(words).most_common(15)\ndf = pd.DataFrame(lst, columns = ['words', 'Count'])\ndf.plot.bar(x='words',y='Count', ax=ax)\nplt.title('15 Most Frequent Ingredient')\nplt.ylabel('Frequency')\nplt.xlabel('word')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:49:09.034795Z","iopub.execute_input":"2021-05-30T09:49:09.035193Z","iopub.status.idle":"2021-05-30T09:49:09.410134Z","shell.execute_reply.started":"2021-05-30T09:49:09.035158Z","shell.execute_reply":"2021-05-30T09:49:09.409078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(words))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Most Used word\")\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:49:25.094696Z","iopub.execute_input":"2021-05-30T09:49:25.095105Z","iopub.status.idle":"2021-05-30T09:49:29.989176Z","shell.execute_reply.started":"2021-05-30T09:49:25.095056Z","shell.execute_reply":"2021-05-30T09:49:29.988376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['SplitPhrase']=train_data['Phrase'].str.split()\ntrain_data['SplitPhrase']","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:49:46.904477Z","iopub.execute_input":"2021-05-30T09:49:46.904817Z","iopub.status.idle":"2021-05-30T09:49:47.293534Z","shell.execute_reply.started":"2021-05-30T09:49:46.904789Z","shell.execute_reply":"2021-05-30T09:49:47.292538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counters = {}\nfor Sentiment in train_data['Sentiment'].unique():\n    counters[Sentiment] = Counter()\n    indices = (train_data['Sentiment'] == Sentiment)\n    for SplitPhrase in train_data[indices]['SplitPhrase']:\n        counters[Sentiment].update(SplitPhrase)\n\nfig, axes = plt.subplots(1, 5, figsize=(20, 8),sharex='col', sharey='row')\nfor Sentiment, ax_index in zip(counters, range(1,21)): \n    wordcloud = WordCloud(background_color=\"white\")\n    wordcloud.generate_from_frequencies(frequencies=counters[Sentiment])\n    fig.add_subplot(1, 5, ax_index)    \n    plt.title(Sentiment)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:50:04.040759Z","iopub.execute_input":"2021-05-30T09:50:04.041155Z","iopub.status.idle":"2021-05-30T09:50:07.222685Z","shell.execute_reply.started":"2021-05-30T09:50:04.04112Z","shell.execute_reply":"2021-05-30T09:50:07.221596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(30)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:50:21.156383Z","iopub.execute_input":"2021-05-30T09:50:21.156754Z","iopub.status.idle":"2021-05-30T09:50:21.190103Z","shell.execute_reply.started":"2021-05-30T09:50:21.156723Z","shell.execute_reply":"2021-05-30T09:50:21.188658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in words if \"-\" in s]).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:50:41.464524Z","iopub.execute_input":"2021-05-30T09:50:41.464884Z","iopub.status.idle":"2021-05-30T09:50:41.522279Z","shell.execute_reply.started":"2021-05-30T09:50:41.464847Z","shell.execute_reply":"2021-05-30T09:50:41.521164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in words if \"'\" in s]).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:51:03.184517Z","iopub.execute_input":"2021-05-30T09:51:03.184877Z","iopub.status.idle":"2021-05-30T09:51:03.237702Z","shell.execute_reply.started":"2021-05-30T09:51:03.184845Z","shell.execute_reply":"2021-05-30T09:51:03.236607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in words if any(char.isdigit() for char in s)]).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:51:29.96363Z","iopub.execute_input":"2021-05-30T09:51:29.964171Z","iopub.status.idle":"2021-05-30T09:51:30.767036Z","shell.execute_reply.started":"2021-05-30T09:51:29.964137Z","shell.execute_reply":"2021-05-30T09:51:30.766092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in words if \",\" in s]).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:52:00.314495Z","iopub.execute_input":"2021-05-30T09:52:00.31485Z","iopub.status.idle":"2021-05-30T09:52:00.371201Z","shell.execute_reply.started":"2021-05-30T09:52:00.31482Z","shell.execute_reply":"2021-05-30T09:52:00.369999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in words if \".\" in s]).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:52:40.294202Z","iopub.execute_input":"2021-05-30T09:52:40.294592Z","iopub.status.idle":"2021-05-30T09:52:40.343292Z","shell.execute_reply.started":"2021-05-30T09:52:40.294555Z","shell.execute_reply":"2021-05-30T09:52:40.342305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([s for s in words if re.findall('[^a-zA-Z]',re.sub(r'[^\\w\\s]','',s))]).unique()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:52:54.754544Z","iopub.execute_input":"2021-05-30T09:52:54.754914Z","iopub.status.idle":"2021-05-30T09:52:57.015882Z","shell.execute_reply.started":"2021-05-30T09:52:54.754884Z","shell.execute_reply":"2021-05-30T09:52:57.015146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:53:14.013798Z","iopub.execute_input":"2021-05-30T09:53:14.014202Z","iopub.status.idle":"2021-05-30T09:53:14.030609Z","shell.execute_reply.started":"2021-05-30T09:53:14.014168Z","shell.execute_reply":"2021-05-30T09:53:14.029505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"porter = PorterStemmer()\n# lancaster=LancasterStemmer()\n\ndef ret_words(SplitPhrase):\n    word_text=' '.join(SplitPhrase)\n    word_text = word_text.replace('-', ' ')\n    word_text = word_text.replace('.', '')\n    word_text = word_text.replace(',', '')\n    word_text= word_text.lower()\n\n    final=[]\n    for ana in word_text.split():\n        if re.findall('[0-9]', ana): continue\n        if re.findall('[^a-zA-Z]',re.sub(r'[^\\w\\s]','',ana)): continue\n        if len(ana) > 0: final.append(porter.stem(re.sub(r'[^\\w\\s]','',ana)))\n    return ' '.join(final)\n\ndef preprocess(df,flag):\n\n    # Convert list of ingredients to string\n    df['words'] = df['Phrase'].str.split().apply(ret_words)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:53:37.558529Z","iopub.execute_input":"2021-05-30T09:53:37.558889Z","iopub.status.idle":"2021-05-30T09:53:37.567244Z","shell.execute_reply.started":"2021-05-30T09:53:37.558858Z","shell.execute_reply":"2021-05-30T09:53:37.565858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed = preprocess(train_data,0)\nval_preprocessed = preprocess(val_data,1)\ntest_preprocessed = preprocess(test_data,1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:54:16.934961Z","iopub.execute_input":"2021-05-30T09:54:16.935351Z","iopub.status.idle":"2021-05-30T09:54:50.658059Z","shell.execute_reply.started":"2021-05-30T09:54:16.935318Z","shell.execute_reply":"2021-05-30T09:54:50.656998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed.head(100)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:54:56.784353Z","iopub.execute_input":"2021-05-30T09:54:56.784757Z","iopub.status.idle":"2021-05-30T09:54:56.862799Z","shell.execute_reply.started":"2021-05-30T09:54:56.784725Z","shell.execute_reply":"2021-05-30T09:54:56.861841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(pd.Series(' '.join([row[\"words\"] for ind,row in train_preprocessed.iterrows()]).split(' '))))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:55:04.474608Z","iopub.execute_input":"2021-05-30T09:55:04.474955Z","iopub.status.idle":"2021-05-30T09:55:15.003505Z","shell.execute_reply.started":"2021-05-30T09:55:04.474926Z","shell.execute_reply":"2021-05-30T09:55:15.002396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train = train_preprocessed['PhraseId'], train_preprocessed['words'], train_preprocessed['Sentiment']\nid_test, X_test, y_test = test_preprocessed['PhraseId'], test_preprocessed['words'], test_preprocessed['Sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:55:57.974616Z","iopub.execute_input":"2021-05-30T09:55:57.974979Z","iopub.status.idle":"2021-05-30T09:55:57.98009Z","shell.execute_reply.started":"2021-05-30T09:55:57.974941Z","shell.execute_reply":"2021-05-30T09:55:57.979121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BoW\nBoW = CountVectorizer()\n\nBoW.fit(X_train)\nCount_data = BoW.transform(X_train)\n\nBoW_X_train = pd.DataFrame(Count_data.toarray(),columns=BoW.get_feature_names())\n\nBoW_X_train","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:56:08.325214Z","iopub.execute_input":"2021-05-30T09:56:08.325579Z","iopub.status.idle":"2021-05-30T09:56:17.940729Z","shell.execute_reply.started":"2021-05-30T09:56:08.325544Z","shell.execute_reply":"2021-05-30T09:56:17.939522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:56:24.774631Z","iopub.execute_input":"2021-05-30T09:56:24.774989Z","iopub.status.idle":"2021-05-30T09:56:24.782367Z","shell.execute_reply.started":"2021-05-30T09:56:24.774958Z","shell.execute_reply":"2021-05-30T09:56:24.781329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BoW.fit(X_train.head())\nCount_data = BoW.transform(X_train.head())\nBoW_X_train = pd.DataFrame(Count_data.toarray(),columns=BoW.get_feature_names())\nBoW_X_train","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:56:42.112271Z","iopub.execute_input":"2021-05-30T09:56:42.112619Z","iopub.status.idle":"2021-05-30T09:56:42.131833Z","shell.execute_reply.started":"2021-05-30T09:56:42.112589Z","shell.execute_reply":"2021-05-30T09:56:42.130867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TFIDF\nTFIDF = TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1',\\\n                ngram_range=(1, 2), stop_words='english')\n\nTFIDF.fit(X_train)\nCount_data = TFIDF.transform(X_train)\nTFIDF_X_train = pd.DataFrame(Count_data.toarray(),columns=TFIDF.get_feature_names())\n\n\nTFIDF_X_train","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:56:55.099951Z","iopub.execute_input":"2021-05-30T09:56:55.100328Z","iopub.status.idle":"2021-05-30T09:57:07.759471Z","shell.execute_reply.started":"2021-05-30T09:56:55.100298Z","shell.execute_reply":"2021-05-30T09:57:07.758465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:57:25.800478Z","iopub.execute_input":"2021-05-30T09:57:25.800827Z","iopub.status.idle":"2021-05-30T09:57:25.808158Z","shell.execute_reply.started":"2021-05-30T09:57:25.800796Z","shell.execute_reply":"2021-05-30T09:57:25.807048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TFIDF = TfidfVectorizer()\nTFIDF.fit(X_train.head(5))\nCount_data = TFIDF.transform(X_train.head(5))\nTFIDF_X_train = pd.DataFrame(Count_data.toarray(),columns=TFIDF.get_feature_names())\n\n\nTFIDF_X_train","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:57:28.121776Z","iopub.execute_input":"2021-05-30T09:57:28.122181Z","iopub.status.idle":"2021-05-30T09:57:28.148913Z","shell.execute_reply.started":"2021-05-30T09:57:28.122145Z","shell.execute_reply":"2021-05-30T09:57:28.148111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train = train_preprocessed['PhraseId'], train_preprocessed['words'], train_preprocessed['Sentiment']\nid_val, X_val, y_val = val_preprocessed['PhraseId'], val_preprocessed['words'], val_preprocessed['Sentiment']\nid_test, X_test, y_test = test_preprocessed['PhraseId'], test_preprocessed['words'], test_preprocessed['Sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:57:43.319544Z","iopub.execute_input":"2021-05-30T09:57:43.320063Z","iopub.status.idle":"2021-05-30T09:57:43.325291Z","shell.execute_reply.started":"2021-05-30T09:57:43.320018Z","shell.execute_reply":"2021-05-30T09:57:43.324472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', LogisticRegression(random_state=0, max_iter=2000))\n])\nLR_clf_counts.fit(X_train, y_train)\nLR_cnt_pred_tr = LR_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, LR_cnt_pred_tr))\nprint(precision_score(y_train, LR_cnt_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:57:54.291412Z","iopub.execute_input":"2021-05-30T09:57:54.291902Z","iopub.status.idle":"2021-05-30T09:59:14.584196Z","shell.execute_reply.started":"2021-05-30T09:57:54.291864Z","shell.execute_reply":"2021-05-30T09:59:14.583342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T09:59:26.701828Z","iopub.execute_input":"2021-05-30T09:59:26.702216Z","iopub.status.idle":"2021-05-30T10:02:04.628824Z","shell.execute_reply.started":"2021-05-30T09:59:26.702185Z","shell.execute_reply":"2021-05-30T10:02:04.627944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', LinearSVC(max_iter=3000))\n])\nSVM_clf_counts.fit(X_train, y_train)\nSVM_cnt_pred_tr = SVM_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, SVM_cnt_pred_tr))\nprint(precision_score(y_train, SVM_cnt_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:02:15.02179Z","iopub.execute_input":"2021-05-30T10:02:15.022198Z","iopub.status.idle":"2021-05-30T10:05:29.877888Z","shell.execute_reply.started":"2021-05-30T10:02:15.02216Z","shell.execute_reply":"2021-05-30T10:05:29.876896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(SVM_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:05:38.932091Z","iopub.execute_input":"2021-05-30T10:05:38.932463Z","iopub.status.idle":"2021-05-30T10:14:00.875307Z","shell.execute_reply.started":"2021-05-30T10:05:38.932429Z","shell.execute_reply":"2021-05-30T10:14:00.874068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_clf_counts = Pipeline([\n    ('vect', CountVectorizer()),\n    ('clf', MultinomialNB())\n])\nNB_clf_counts.fit(X_train, y_train)\nNB_cnt_pred_tr = NB_clf_counts.predict(X_train)\n\nprint(accuracy_score(y_train, NB_cnt_pred_tr))\nprint(precision_score(y_train, NB_cnt_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:14:16.947893Z","iopub.execute_input":"2021-05-30T10:14:16.948289Z","iopub.status.idle":"2021-05-30T10:14:19.920763Z","shell.execute_reply.started":"2021-05-30T10:14:16.948257Z","shell.execute_reply":"2021-05-30T10:14:19.919539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(NB_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:14:27.890733Z","iopub.execute_input":"2021-05-30T10:14:27.891088Z","iopub.status.idle":"2021-05-30T10:14:47.617556Z","shell.execute_reply.started":"2021-05-30T10:14:27.891057Z","shell.execute_reply":"2021-05-30T10:14:47.6165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1',ngram_range=(1, 2), stop_words='english')),\n    ('clf', LogisticRegression(random_state=0, max_iter=2000))\n])\nLR_clf_tfidf.fit(X_train, y_train)\nLR_tfidf_pred_tr = LR_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, LR_tfidf_pred_tr))\nprint(precision_score(y_train, LR_tfidf_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:15:19.072194Z","iopub.execute_input":"2021-05-30T10:15:19.072544Z","iopub.status.idle":"2021-05-30T10:16:33.157822Z","shell.execute_reply.started":"2021-05-30T10:15:19.072514Z","shell.execute_reply":"2021-05-30T10:16:33.156903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:16:44.462632Z","iopub.execute_input":"2021-05-30T10:16:44.463212Z","iopub.status.idle":"2021-05-30T10:18:58.400503Z","shell.execute_reply.started":"2021-05-30T10:16:44.463158Z","shell.execute_reply":"2021-05-30T10:18:58.399555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n    ('clf', LinearSVC( max_iter=2000))\n])\nSVM_clf_tfidf.fit(X_train, y_train)\nSVM_tfidf_pred_tr = SVM_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, SVM_tfidf_pred_tr))\nprint(precision_score(y_train, SVM_tfidf_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:19:08.521561Z","iopub.execute_input":"2021-05-30T10:19:08.522111Z","iopub.status.idle":"2021-05-30T10:19:17.65089Z","shell.execute_reply.started":"2021-05-30T10:19:08.522078Z","shell.execute_reply":"2021-05-30T10:19:17.649806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(SVM_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:19:24.43405Z","iopub.execute_input":"2021-05-30T10:19:24.434466Z","iopub.status.idle":"2021-05-30T10:20:05.413943Z","shell.execute_reply.started":"2021-05-30T10:19:24.434435Z","shell.execute_reply":"2021-05-30T10:20:05.412908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_clf_tfidf = Pipeline([\n    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n    ('clf', MultinomialNB())\n])\nNB_clf_tfidf.fit(X_train, y_train)\nNB_tfidf_pred_tr = NB_clf_tfidf.predict(X_train)\n\nprint(accuracy_score(y_train, NB_tfidf_pred_tr))\nprint(precision_score(y_train, NB_tfidf_pred_tr, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:20:17.29175Z","iopub.execute_input":"2021-05-30T10:20:17.292141Z","iopub.status.idle":"2021-05-30T10:20:21.92035Z","shell.execute_reply.started":"2021-05-30T10:20:17.29211Z","shell.execute_reply":"2021-05-30T10:20:21.919117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(NB_clf_tfidf, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:20:27.754115Z","iopub.execute_input":"2021-05-30T10:20:27.754493Z","iopub.status.idle":"2021-05-30T10:20:55.866593Z","shell.execute_reply.started":"2021-05-30T10:20:27.754459Z","shell.execute_reply":"2021-05-30T10:20:55.86585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vect=  CountVectorizer()\nX_train_cnt = vect.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:21:12.931655Z","iopub.execute_input":"2021-05-30T10:21:12.932183Z","iopub.status.idle":"2021-05-30T10:21:14.382385Z","shell.execute_reply.started":"2021-05-30T10:21:12.932148Z","shell.execute_reply":"2021-05-30T10:21:14.381528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LR_param_selection(X, y, nfolds):\n    Cs = [0.01, 0.1, 1, 10]\n    param_grid = {'C': Cs}\n    grid_search = GridSearchCV(LogisticRegression(random_state=0,max_iter=2000), param_grid, cv=nfolds)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:21:16.930641Z","iopub.execute_input":"2021-05-30T10:21:16.930995Z","iopub.status.idle":"2021-05-30T10:21:16.936425Z","shell.execute_reply.started":"2021-05-30T10:21:16.930965Z","shell.execute_reply":"2021-05-30T10:21:16.935643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_param_selection( X_train_cnt,y_train,2)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:27:41.302067Z","iopub.execute_input":"2021-05-30T10:27:41.302737Z","iopub.status.idle":"2021-05-30T10:33:58.031234Z","shell.execute_reply.started":"2021-05-30T10:27:41.302693Z","shell.execute_reply":"2021-05-30T10:33:58.030124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf_counts = Pipeline([('vect', CountVectorizer()),\n                   ('clf', LogisticRegression(C=1,random_state=0, max_iter=2000)),\n                  ])\nLR_clf_counts.fit(X_train, y_train)\nLR_cnt_pred_tr = LR_clf_counts.predict(X_train)\nLR_cnt_pred_val = LR_clf_counts.predict(X_val)\nLR_cnt_pred_tst = LR_clf_counts.predict(X_test)\n\n\nprint(\"precision on training: \",precision_score(y_train, LR_cnt_pred_tr, average='micro'))\nprint(\"precision on validation: \",precision_score(y_val, LR_cnt_pred_val, average='micro'))\nprint(\"precision on testing: \",precision_score(y_test, LR_cnt_pred_tst, average='micro'))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:34:42.912564Z","iopub.execute_input":"2021-05-30T10:34:42.912926Z","iopub.status.idle":"2021-05-30T10:36:04.477249Z","shell.execute_reply.started":"2021-05-30T10:34:42.912894Z","shell.execute_reply":"2021-05-30T10:36:04.475857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create CV training and test scores for various training set sizes\ntrain_sizes, train_scores, test_scores = learning_curve(LR_clf_counts, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=3,\n                                                        # Evaluation metric\n                                                        scoring='precision_weighted',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 10))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nfig, ax = plt.subplots(figsize=(15,10))\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Weighted Precision Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:36:24.402923Z","iopub.execute_input":"2021-05-30T10:36:24.403339Z","iopub.status.idle":"2021-05-30T10:39:02.674376Z","shell.execute_reply.started":"2021-05-30T10:36:24.403305Z","shell.execute_reply":"2021-05-30T10:39:02.673017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archive_train = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\narchive_test = zipfile.ZipFile('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:39:16.282286Z","iopub.execute_input":"2021-05-30T10:39:16.282667Z","iopub.status.idle":"2021-05-30T10:39:16.298241Z","shell.execute_reply.started":"2021-05-30T10:39:16.282636Z","shell.execute_reply":"2021-05-30T10:39:16.297118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train = pd.read_csv(\"../input/sentiment-analysis-on-movie-reviews/train.tsv.zip\", sep='\\t')\nfinal_test = pd.read_csv(\"../input/sentiment-analysis-on-movie-reviews/test.tsv.zip\", sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:39:23.701697Z","iopub.execute_input":"2021-05-30T10:39:23.702085Z","iopub.status.idle":"2021-05-30T10:39:24.003368Z","shell.execute_reply.started":"2021-05-30T10:39:23.70202Z","shell.execute_reply":"2021-05-30T10:39:24.002338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ftrain_preprocessed = preprocess (final_train,0)\nftest_preprocessed = preprocess (final_test,1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:39:29.210819Z","iopub.execute_input":"2021-05-30T10:39:29.211218Z","iopub.status.idle":"2021-05-30T10:40:15.999066Z","shell.execute_reply.started":"2021-05-30T10:39:29.211185Z","shell.execute_reply":"2021-05-30T10:40:15.99804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_train, X_train, y_train = ftrain_preprocessed['PhraseId'], ftrain_preprocessed['words'], ftrain_preprocessed['Sentiment']\nid_test, X_test= ftest_preprocessed['PhraseId'], ftest_preprocessed['words']","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:40:25.910718Z","iopub.execute_input":"2021-05-30T10:40:25.911126Z","iopub.status.idle":"2021-05-30T10:40:25.916813Z","shell.execute_reply.started":"2021-05-30T10:40:25.911085Z","shell.execute_reply":"2021-05-30T10:40:25.915823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf = Pipeline([('vect', CountVectorizer()),\n                   ('clf', LogisticRegression(C=1,random_state=0, max_iter=2000)),\n                  ])\nLR_clf.fit(X_train , y_train)\npred_tst = LR_clf_counts.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:41:41.301153Z","iopub.execute_input":"2021-05-30T10:41:41.301716Z","iopub.status.idle":"2021-05-30T10:43:20.177192Z","shell.execute_reply.started":"2021-05-30T10:41:41.301684Z","shell.execute_reply":"2021-05-30T10:43:20.176062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output=pd.DataFrame({'PhraseId' : id_test , 'Sentiment' : pred_tst })\noutput.to_csv('Sentiment_preds_LR.csv' , index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:53:11.851337Z","iopub.execute_input":"2021-05-30T10:53:11.85179Z","iopub.status.idle":"2021-05-30T10:53:11.987533Z","shell.execute_reply.started":"2021-05-30T10:53:11.851757Z","shell.execute_reply":"2021-05-30T10:53:11.986557Z"},"trusted":true},"execution_count":null,"outputs":[]}]}