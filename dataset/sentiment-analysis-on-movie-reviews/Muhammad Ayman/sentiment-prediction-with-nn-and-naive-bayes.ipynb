{"cells":[{"metadata":{},"cell_type":"markdown","source":"Welcome to my kernel sentiment analysis on The Rotten Tomatoes movie review.\n\nAs this is my first time working on sentiment analysis problem, i will try to go through some basic process like tokenizing, stemming, lemmatizing, wordclouds, get rid of stop words and so on, also i will try to predict the sentiment in  test set, train set and the combination of the train and test set\n\nif you have any suggest,advice or correction please don't hesitate to write it, i think it will be very helpful for me.\n\nwe will go through these topics:\n        \n        1- Text Preprocessing\n        2- Word Clouds\n        3- Predicting sentiment for test data Using NN\n        4- Predicting sentiment for overall set with Naive bayes and NN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport string\nimport nltk\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n\nfrom nltk import PorterStemmer,WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep=\"\\t\")\ntest = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip', sep=\"\\t\")\nsampleSubmission = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\n\ntrain_original = train.copy()\ntest_original = test.copy()\n\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"SentenceId\"].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"Sentiment\"].unique())\n\nplt.rcParams['figure.figsize'] = (13, 7)\n\n#sns.set(style=\"white\")\n\nsns.countplot(train[\"Sentiment\"], palette='deep')\n\nplt.title('Sentiment count in train set', fontsize = 20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1- Text Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def Preprocess(df):\n\n\n    for i in df['Phrase']:\n        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n        i = tokenizer.tokenize(i)\n\n        \n#------------------------------------------------------------------------------------------------\n        \n    tokenized_review_1 = df['Phrase'].apply(lambda x: x.split())\n    \n\n\n#------------------------------------------------------------------------------------------------\n\n\n\n    ps = PorterStemmer()\n    WL = WordNetLemmatizer()\n\n    stemmed_review = tokenized_review_1.apply(lambda x: [ps.stem(i) for i in x])\n    lemmatized_review = tokenized_review_1.apply(lambda x: [WL.lemmatize(i) for i in x])\n\n\n#------------------------------------------------------------------------------------------------\n\n\n    stop = stopwords.words('english')\n    stemmed_review = stemmed_review.apply(lambda x: [item for item in x if item not in stop])\n    lemmatized_review = lemmatized_review.apply(lambda x: [item for item in x if item not in stop])\n\n    \n\n\n\n#------------------------------------------------------------------------------------------------\n\n    for i in range(len(stemmed_review)):\n        stemmed_review[i] = ' '.join(stemmed_review[i])\n\n    df['stemmed_review'] = stemmed_review\n\n    \n    for i in range(len(lemmatized_review)):\n        lemmatized_review[i] = ' '.join(lemmatized_review[i])\n\n    df['lemmatized_review'] = lemmatized_review\n\n\n\n    df = df[df[\"stemmed_review\"] != '']\n    df = df[df[\"lemmatized_review\"] != '']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Preprocess(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Preprocess(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"normal\")\nprint(\"-\"*100)\n\nprint(train['Phrase'][0])\nprint(\"\\nafter stemming\")\nprint(\"-\"*100)\n\nprint(train['stemmed_review'][0])\n\nprint(\"\\nafter lemmatizing\")\nprint(\"-\"*100)\nprint(train['lemmatized_review'][0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train = train.copy()\nplot_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train[\"Sentiment\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_words = plot_train[plot_train[\"Sentiment\"] !=  0 ]\npositive_words = positive_words[positive_words[\"Sentiment\"] !=  1 ]\npositive_words = positive_words[positive_words[\"Sentiment\"] !=  2 ]\n\n\n\nnegative_words = plot_train[plot_train[\"Sentiment\"] !=  3 ]\nnegative_words = negative_words[negative_words[\"Sentiment\"] !=  4 ]\nnegative_words = negative_words[negative_words[\"Sentiment\"] !=  2 ]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_words[\"Sentiment\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(negative_words.shape)\nprint(positive_words.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_all_words = ' '.join(text for text in train['lemmatized_review'])\n\nplot_positive_words = ' '.join(text for text in positive_words['lemmatized_review'])\n\nplot_negative_words = ' '.join(text for text in negative_words['lemmatized_review'])\n\nplot_positive_words[0:1000]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_negative_words[0:1000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2- Word Clouds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns\nfrom wordcloud import WordCloud,ImageColorGenerator\nfrom PIL import Image\nimport urllib\nimport requests\n\nMask = np.array(Image.open(r'../input/triangle/kisspng-black-triangle-computer-icons-symbol-arrow-5af0f4cd97c624.0510697015257407496217.jpg'))\n\nimage_colors = ImageColorGenerator(Mask)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color='white', height=1500, width=4000,mask=Mask).generate(plot_all_words)\n\nplt.figure(figsize=(10,20))\n\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(),interpolation=\"spline36\")\n\n#'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n#           'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n#           'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'\n        \nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Mask1 = np.array(Image.open(r'../input/likeee/lll.png'))\n\nimage_colors = ImageColorGenerator(Mask1)\n\n#def grey_color_func(word, font_size, position, orientation, random_state=None,\n #                   **kwargs):\n #   return \"hsl(0, 0%%, %d%%)\" % random.randint(60, 100)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask1).generate(plot_positive_words)\n\nplt.figure(figsize=(10,20))\n\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(color_func=image_colors),interpolation=\"spline36\")\n\n#'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n#           'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n#           'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'\n        \nplt.title(\"positive words\", fontsize=20)\n\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\n\nMask2 = np.array(Image.open(r'../input/dislikee/dislike.jpg'))\n\nimage_colors = ImageColorGenerator(Mask2)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask2).generate(plot_negative_words)\n\nplt.figure(figsize=(10,20))\n\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(color_func=image_colors),interpolation=\"hamming\")\n\n#interpolation : 'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n#                'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n#                'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'\n\nplt.title(\"negative words\", fontsize=20)\n        \nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3- Predicting sentiment for test data Using NN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_NN = train[\"Sentiment\"]\n\nx_Train_stemmed_NN = train[\"stemmed_review\"]\nx_test_stemmed_NN = test[\"stemmed_review\"]\n\nx_Train_lemmatized_NN = train[\"lemmatized_review\"]\nx_test_lemmatized_NN = test[\"lemmatized_review\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_Train_stemmed_NN.shape, y_train_NN.shape ,x_test_stemmed_NN.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenize = Tokenizer()\ntokenize.fit_on_texts(x_Train_stemmed_NN.values)\n\n#X_test = test.stemmed_review\nX_train_stemmed = tokenize.texts_to_sequences(x_Train_stemmed_NN)\nX_test_stemmed = tokenize.texts_to_sequences(x_test_stemmed_NN)\n\ntokenize.fit_on_texts(x_Train_lemmatized_NN.values)\n\nX_train_lemmatized = tokenize.texts_to_sequences(x_Train_lemmatized_NN)\nX_test_lemmatized = tokenize.texts_to_sequences(x_test_lemmatized_NN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_stemmed = pad_sequences(X_train_stemmed).astype(float)\nX_test_stemmed = pad_sequences(X_test_stemmed).astype(float)\n\nX_train_lemmatized = pad_sequences(X_train_lemmatized)\nX_test_lemmatized = pad_sequences(X_test_lemmatized)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_DIM = 100\nunknown = len(tokenize.word_index)+1\nmodel = Sequential()\nmodel.add(Embedding(unknown, EMBEDDING_DIM))\nmodel.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2 ))\nmodel.add(Dense(5, activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_stemmed, y_train_NN, batch_size=128, epochs=7, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = model.predict_classes(X_test_stemmed)\nfinal_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4- Predicting sentiment for overall set with Naive bayes and NN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Sentiment\"] = final_pred\ntest[\"Sentiment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Sentiment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB_data = pd.concat([train, test], ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n\npipeline = Pipeline([\n    ('bow',CountVectorizer(analyzer=\"word\")),  # strings to token integer counts\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**using stemmed data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n\nx_train,x_test,y_train,y_test = train_test_split(NB_data['stemmed_review'], NB_data['Sentiment'], test_size=0.2, random_state=42)\n\npipeline.fit(x_train,y_train)\nn_b_predictions = pipeline.predict(x_test)\nprint(classification_report(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(confusion_matrix(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(pipeline.score(x_train,y_train))\nprint(accuracy_score(n_b_predictions,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**using lemmatized data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n\nx_train,x_test,y_train,y_test = train_test_split(NB_data['lemmatized_review'], NB_data['Sentiment'], test_size=0.2, random_state=42)\n\npipeline.fit(x_train,y_train)\nn_b_predictions = pipeline.predict(x_test)\nprint(classification_report(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(confusion_matrix(n_b_predictions,y_test))\nprint(\"-\"*100)\nprint(pipeline.score(x_train,y_train))\nprint(accuracy_score(n_b_predictions,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NN with lemmatized data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenize = Tokenizer()\ntokenize.fit_on_texts(x_train.values)\nX_test = test.stemmed_review\nX_train = tokenize.texts_to_sequences(x_train)\nX_test = tokenize.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pad_sequences(X_train)\nX_test = pad_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=128, epochs=7, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred2 = model.predict_classes(X_test_stemmed)\nfinal_pred2","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}