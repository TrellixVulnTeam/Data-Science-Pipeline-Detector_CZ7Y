{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import and installation section","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\n\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-07T18:35:03.33326Z","iopub.execute_input":"2021-12-07T18:35:03.334022Z","iopub.status.idle":"2021-12-07T18:35:11.353343Z","shell.execute_reply.started":"2021-12-07T18:35:03.333877Z","shell.execute_reply":"2021-12-07T18:35:11.352241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install transformers\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:11.355112Z","iopub.execute_input":"2021-12-07T18:35:11.355379Z","iopub.status.idle":"2021-12-07T18:35:21.568266Z","shell.execute_reply.started":"2021-12-07T18:35:11.355349Z","shell.execute_reply":"2021-12-07T18:35:21.567251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the model and tokenizer\nfrom transformers import (DistilBertTokenizerFast, \n                         TFDistilBertForSequenceClassification)    ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:21.570011Z","iopub.execute_input":"2021-12-07T18:35:21.570401Z","iopub.status.idle":"2021-12-07T18:35:22.075985Z","shell.execute_reply.started":"2021-12-07T18:35:21.57035Z","shell.execute_reply":"2021-12-07T18:35:22.074913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Detect and initialze tpu","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    \nexcept:\n    strategy = tf.distribute.get_strategy()\n    \nprint('Number of replicas in sync: ', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:22.078082Z","iopub.execute_input":"2021-12-07T18:35:22.078393Z","iopub.status.idle":"2021-12-07T18:35:28.493348Z","shell.execute_reply.started":"2021-12-07T18:35:22.07836Z","shell.execute_reply":"2021-12-07T18:35:28.492298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataframe display settings\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:28.494842Z","iopub.execute_input":"2021-12-07T18:35:28.495194Z","iopub.status.idle":"2021-12-07T18:35:28.500214Z","shell.execute_reply.started":"2021-12-07T18:35:28.495158Z","shell.execute_reply":"2021-12-07T18:35:28.499068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read train and test data into pandas dataframe","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep = '\\t')\ntest_data = pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip', sep = '\\t')\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:28.502026Z","iopub.execute_input":"2021-12-07T18:35:28.502389Z","iopub.status.idle":"2021-12-07T18:35:28.988987Z","shell.execute_reply.started":"2021-12-07T18:35:28.502341Z","shell.execute_reply":"2021-12-07T18:35:28.988004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of the train data\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:28.990297Z","iopub.execute_input":"2021-12-07T18:35:28.990538Z","iopub.status.idle":"2021-12-07T18:35:28.99994Z","shell.execute_reply.started":"2021-12-07T18:35:28.990509Z","shell.execute_reply":"2021-12-07T18:35:28.999005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the head of test data\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:29.001054Z","iopub.execute_input":"2021-12-07T18:35:29.001308Z","iopub.status.idle":"2021-12-07T18:35:29.01593Z","shell.execute_reply.started":"2021-12-07T18:35:29.001272Z","shell.execute_reply":"2021-12-07T18:35:29.01503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of the test data\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:29.017759Z","iopub.execute_input":"2021-12-07T18:35:29.018088Z","iopub.status.idle":"2021-12-07T18:35:29.026168Z","shell.execute_reply.started":"2021-12-07T18:35:29.01804Z","shell.execute_reply":"2021-12-07T18:35:29.025504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the number of examples in each class\ntrain_data.Sentiment.value_counts(normalize = True).plot(kind = 'bar', figsize = (10, 6), xlabel = 'Sentiments');","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:29.02956Z","iopub.execute_input":"2021-12-07T18:35:29.029962Z","iopub.status.idle":"2021-12-07T18:35:29.329552Z","shell.execute_reply.started":"2021-12-07T18:35:29.029912Z","shell.execute_reply":"2021-12-07T18:35:29.328905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Dataset is highly imbalanced","metadata":{}},{"cell_type":"markdown","source":"## Cleaning of text","metadata":{}},{"cell_type":"code","source":"# set of stop words in english\nstop_words = set(stopwords.words('english'))\n\nneg = [\"aren't\", \"didn't\", \"doesn't\", \"hadn't\",  \"haven't\", \"isn't\", 'no', 'not', \"shouldn't\", \"wasn't\", \"weren't\", \"wouldn't\"]\nstop_words.difference_update(neg)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:29.330814Z","iopub.execute_input":"2021-12-07T18:35:29.331257Z","iopub.status.idle":"2021-12-07T18:35:29.343036Z","shell.execute_reply.started":"2021-12-07T18:35:29.331226Z","shell.execute_reply":"2021-12-07T18:35:29.342312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function will clean the text\ndef text_cleaning(text):\n    if text:\n        text = ' '.join(text.split('.'))\n        text = re.sub('\\/', ' ', text)\n        text = re.sub(r'\\\\', ' ', text)\n        text = re.sub(r'((http)\\S+)', '', text)\n        text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z]', ' ', text.strip().lower())).strip()\n        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n        text = [word for word in text.split() if word not in stop_words]\n        return text\n    return []","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:29.344338Z","iopub.execute_input":"2021-12-07T18:35:29.344745Z","iopub.status.idle":"2021-12-07T18:35:29.35242Z","shell.execute_reply.started":"2021-12-07T18:35:29.344686Z","shell.execute_reply":"2021-12-07T18:35:29.351719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean train and test dataframes\ntrain_data['Phrase'] = train_data['Phrase'].apply(lambda x: ' '.join(text_cleaning(x)))\ntest_data['Phrase'] = test_data['Phrase'].apply(lambda x: ' '.join(text_cleaning(x)))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:29.353867Z","iopub.execute_input":"2021-12-07T18:35:29.354176Z","iopub.status.idle":"2021-12-07T18:35:34.302697Z","shell.execute_reply.started":"2021-12-07T18:35:29.354133Z","shell.execute_reply":"2021-12-07T18:35:34.301673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop duplicates from train data\ntrain_data.drop_duplicates(subset = ['Phrase'], inplace = True)\ntrain_data.head(8)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:34.304143Z","iopub.execute_input":"2021-12-07T18:35:34.304805Z","iopub.status.idle":"2021-12-07T18:35:34.371893Z","shell.execute_reply.started":"2021-12-07T18:35:34.304768Z","shell.execute_reply":"2021-12-07T18:35:34.370986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculate length of the phrase","metadata":{}},{"cell_type":"code","source":"# add length column to train data\ntrain_data['length'] = train_data['Phrase'].apply(lambda x: len(x.split()))\n\n# add length column to test data\ntest_data['length'] = test_data['Phrase'].apply(lambda x: len(x.split()))\n\n# filter the phrases from the test data with zero length\nlen_zero_data = test_data[test_data['length'] == 0]\nlen_zero_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:34.373103Z","iopub.execute_input":"2021-12-07T18:35:34.373343Z","iopub.status.idle":"2021-12-07T18:35:34.530063Z","shell.execute_reply.started":"2021-12-07T18:35:34.373315Z","shell.execute_reply":"2021-12-07T18:35:34.529467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and validation split","metadata":{}},{"cell_type":"code","source":"# select phrases with length > 1 and split data into train and validation set\nx_train, x_val, y_train, y_val = train_test_split(train_data[train_data['length'] > 1]['Phrase'], \n                                                  train_data[train_data['length'] > 1]['Sentiment'], \n                                                  test_size = 0.2, \n                                                  stratify = train_data[train_data['length'] > 1]['Sentiment'],\n                                                  random_state = 42)\n\nprint(f'Shape of x_train: {x_train.shape}\\nShape of y_train: {y_train.shape}')\nprint(f'Shape of x_val: {x_val.shape}\\nShape of y_val: {y_val.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:34.531232Z","iopub.execute_input":"2021-12-07T18:35:34.531799Z","iopub.status.idle":"2021-12-07T18:35:34.627611Z","shell.execute_reply.started":"2021-12-07T18:35:34.531766Z","shell.execute_reply":"2021-12-07T18:35:34.626754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n\n# encode the training and validation data\ntrain_encodings = tokenizer(x_train.tolist(), truncation = True, padding = True)\nval_encodings = tokenizer(x_val.tolist(), truncation = True, padding = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:34.628998Z","iopub.execute_input":"2021-12-07T18:35:34.629643Z","iopub.status.idle":"2021-12-07T18:35:39.727421Z","shell.execute_reply.started":"2021-12-07T18:35:34.629602Z","shell.execute_reply":"2021-12-07T18:35:39.725991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create training and validation datasets for training","metadata":{}},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings), y_train.values)).shuffle(10000).batch(32).repeat()\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(val_encodings), y_val.values)).shuffle(10000).batch(32)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:35:39.728628Z","iopub.execute_input":"2021-12-07T18:35:39.728885Z","iopub.status.idle":"2021-12-07T18:36:01.421659Z","shell.execute_reply.started":"2021-12-07T18:35:39.728858Z","shell.execute_reply":"2021-12-07T18:36:01.420237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create model","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = TFDistilBertForSequenceClassification.from_pretrained(\n      'distilbert-base-uncased', num_labels = 5)\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5)\n    model.compile(optimizer = optimizer, loss = model.compute_loss, metrics = \n                ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:36:01.423111Z","iopub.execute_input":"2021-12-07T18:36:01.423956Z","iopub.status.idle":"2021-12-07T18:36:21.192313Z","shell.execute_reply.started":"2021-12-07T18:36:01.423904Z","shell.execute_reply":"2021-12-07T18:36:21.191092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel.fit(train_dataset, epochs = 3, batch_size = 32, steps_per_epoch = len(x_train) // 32,\n          validation_data = val_dataset, validation_steps = len(x_val) // 32)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T18:36:21.193889Z","iopub.execute_input":"2021-12-07T18:36:21.194207Z","iopub.status.idle":"2021-12-07T18:40:27.033988Z","shell.execute_reply.started":"2021-12-07T18:36:21.194178Z","shell.execute_reply":"2021-12-07T18:40:27.032637Z"},"trusted":true},"execution_count":null,"outputs":[]}]}