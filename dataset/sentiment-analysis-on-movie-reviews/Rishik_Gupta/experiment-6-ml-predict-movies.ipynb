{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-16T06:11:14.466363Z","iopub.execute_input":"2021-06-16T06:11:14.466793Z","iopub.status.idle":"2021-06-16T06:11:14.481269Z","shell.execute_reply.started":"2021-06-16T06:11:14.466703Z","shell.execute_reply":"2021-06-16T06:11:14.479547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:11:48.85679Z","iopub.execute_input":"2021-06-16T06:11:48.857127Z","iopub.status.idle":"2021-06-16T06:11:49.149572Z","shell.execute_reply.started":"2021-06-16T06:11:48.857097Z","shell.execute_reply":"2021-06-16T06:11:49.148463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:11:51.785279Z","iopub.execute_input":"2021-06-16T06:11:51.785667Z","iopub.status.idle":"2021-06-16T06:11:51.816072Z","shell.execute_reply.started":"2021-06-16T06:11:51.785629Z","shell.execute_reply":"2021-06-16T06:11:51.8153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:11:57.182896Z","iopub.execute_input":"2021-06-16T06:11:57.183268Z","iopub.status.idle":"2021-06-16T06:11:57.221619Z","shell.execute_reply.started":"2021-06-16T06:11:57.183237Z","shell.execute_reply":"2021-06-16T06:11:57.220501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def partition(x):\n    if x<2:\n        return 'negative'\n    return 'positive'\n\nrating = data['Sentiment']\npositiveNegative = rating.map(partition)\ndata['Score'] = positiveNegative\n","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:11:59.917203Z","iopub.execute_input":"2021-06-16T06:11:59.917578Z","iopub.status.idle":"2021-06-16T06:11:59.968446Z","shell.execute_reply.started":"2021-06-16T06:11:59.917544Z","shell.execute_reply":"2021-06-16T06:11:59.967356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nstop = set(stopwords.words('english')) #set of stopwords\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    return  cleaned\n\ni=0\nstr1=' '\nfinal_string=[]\nall_positive_words=[] # store words from +ve reviews here\nall_negative_words=[] # store words from -ve reviews here.\ns=''\n\nfinal_string=[]\nall_positive_words=[] # store words from +ve reviews here\nall_negative_words=[] # store words from -ve reviews here.\ns=''\nfor sent in data['Phrase'].values:\n    filtered_sentence=[]\n    #print(sent);\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n                    if (data['Score'].values)[i] == 'positive': \n                        all_positive_words.append(s) #list of all words used to describe positive reviews\n                    if(data['Score'].values)[i] == 'negative':\n                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n                else:\n                    continue\n            else:\n                continue \n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words    \n    final_string.append(str1)\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:12:16.57174Z","iopub.execute_input":"2021-06-16T06:12:16.572104Z","iopub.status.idle":"2021-06-16T06:12:39.838237Z","shell.execute_reply.started":"2021-06-16T06:12:16.572067Z","shell.execute_reply":"2021-06-16T06:12:39.837096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n#count_vect = CountVectorizer(ngram_range=(1,2) ) \ncount_vect = CountVectorizer() \nfinal_bow_count = count_vect.fit_transform(final_string)#final['Text'].values)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:05.647901Z","iopub.execute_input":"2021-06-16T06:13:05.648302Z","iopub.status.idle":"2021-06-16T06:13:07.131076Z","shell.execute_reply.started":"2021-06-16T06:13:05.648265Z","shell.execute_reply":"2021-06-16T06:13:07.129732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfinal_bow_np = StandardScaler(with_mean=False).fit_transform(final_bow_count )","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:11.174767Z","iopub.execute_input":"2021-06-16T06:13:11.175123Z","iopub.status.idle":"2021-06-16T06:13:11.217691Z","shell.execute_reply.started":"2021-06-16T06:13:11.175089Z","shell.execute_reply":"2021-06-16T06:13:11.216596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntf_idf_vec = TfidfVectorizer()#ngram_range=(2,2))\n\nfinal_tfidf_count = tf_idf_vec.fit_transform(final_string)#final['Text'].values)\n#print(final_string)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:15.586021Z","iopub.execute_input":"2021-06-16T06:13:15.586418Z","iopub.status.idle":"2021-06-16T06:13:16.930115Z","shell.execute_reply.started":"2021-06-16T06:13:15.586384Z","shell.execute_reply":"2021-06-16T06:13:16.929152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfinal_tfidf_np = StandardScaler(with_mean=False).fit_transform(final_tfidf_count )","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:26.634731Z","iopub.execute_input":"2021-06-16T06:13:26.635098Z","iopub.status.idle":"2021-06-16T06:13:26.659682Z","shell.execute_reply.started":"2021-06-16T06:13:26.635065Z","shell.execute_reply":"2021-06-16T06:13:26.658666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn.neighbors import KNeighborsClassifier\nimport math\n\nfrom sklearn.model_selection import train_test_split\n\nX = final_tfidf_np\ny = data['Sentiment']\n\nX_train =  final_tfidf_np[:math.ceil(len(data)*.7)] \nX_test = final_tfidf_np[math.ceil(len(data)*.7):]\ny_train = y[:math.ceil(len(data)*.7)]\ny_test =  y[math.ceil(len(data)*.7):]","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:29.103969Z","iopub.execute_input":"2021-06-16T06:13:29.104355Z","iopub.status.idle":"2021-06-16T06:13:29.198259Z","shell.execute_reply.started":"2021-06-16T06:13:29.104321Z","shell.execute_reply":"2021-06-16T06:13:29.196947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:37.743944Z","iopub.execute_input":"2021-06-16T06:13:37.744371Z","iopub.status.idle":"2021-06-16T06:13:37.768699Z","shell.execute_reply.started":"2021-06-16T06:13:37.744333Z","shell.execute_reply":"2021-06-16T06:13:37.767753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:13:40.700425Z","iopub.execute_input":"2021-06-16T06:13:40.70083Z","iopub.status.idle":"2021-06-16T06:15:52.342626Z","shell.execute_reply.started":"2021-06-16T06:13:40.700795Z","shell.execute_reply":"2021-06-16T06:15:52.341616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test ,pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-16T06:15:59.901292Z","iopub.execute_input":"2021-06-16T06:15:59.901644Z","iopub.status.idle":"2021-06-16T06:15:59.989382Z","shell.execute_reply.started":"2021-06-16T06:15:59.901614Z","shell.execute_reply":"2021-06-16T06:15:59.988002Z"},"trusted":true},"execution_count":null,"outputs":[]}]}