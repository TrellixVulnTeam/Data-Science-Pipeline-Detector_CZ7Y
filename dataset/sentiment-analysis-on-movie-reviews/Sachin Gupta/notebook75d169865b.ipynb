{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T14:49:06.831833Z","iopub.execute_input":"2021-05-25T14:49:06.832402Z","iopub.status.idle":"2021-05-25T14:49:06.846764Z","shell.execute_reply.started":"2021-05-25T14:49:06.832315Z","shell.execute_reply":"2021-05-25T14:49:06.845501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport random\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:06.848332Z","iopub.execute_input":"2021-05-25T14:49:06.848673Z","iopub.status.idle":"2021-05-25T14:49:14.068089Z","shell.execute_reply.started":"2021-05-25T14:49:06.84864Z","shell.execute_reply":"2021-05-25T14:49:14.06647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/train.tsv.zip', sep = '\\t')\ntest = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/test.tsv.zip', sep = '\\t')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:14.070496Z","iopub.execute_input":"2021-05-25T14:49:14.070942Z","iopub.status.idle":"2021-05-25T14:49:14.504508Z","shell.execute_reply.started":"2021-05-25T14:49:14.070899Z","shell.execute_reply":"2021-05-25T14:49:14.503224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape, test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:14.506635Z","iopub.execute_input":"2021-05-25T14:49:14.507061Z","iopub.status.idle":"2021-05-25T14:49:14.513658Z","shell.execute_reply.started":"2021-05-25T14:49:14.507019Z","shell.execute_reply":"2021-05-25T14:49:14.512536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:14.515404Z","iopub.execute_input":"2021-05-25T14:49:14.515786Z","iopub.status.idle":"2021-05-25T14:49:14.554665Z","shell.execute_reply.started":"2021-05-25T14:49:14.515755Z","shell.execute_reply":"2021-05-25T14:49:14.553603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:14.55622Z","iopub.execute_input":"2021-05-25T14:49:14.556566Z","iopub.status.idle":"2021-05-25T14:49:14.571472Z","shell.execute_reply.started":"2021-05-25T14:49:14.556529Z","shell.execute_reply":"2021-05-25T14:49:14.5704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:14.574625Z","iopub.execute_input":"2021-05-25T14:49:14.575Z","iopub.status.idle":"2021-05-25T14:49:14.618053Z","shell.execute_reply.started":"2021-05-25T14:49:14.574968Z","shell.execute_reply":"2021-05-25T14:49:14.61731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:14.619729Z","iopub.execute_input":"2021-05-25T14:49:14.6202Z","iopub.status.idle":"2021-05-25T14:49:16.177229Z","shell.execute_reply.started":"2021-05-25T14:49:14.620158Z","shell.execute_reply":"2021-05-25T14:49:16.17647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_sentences(df):\n    reviews = []\n    \n    for sent in tqdm(df['Phrase']):       \n        #remove non-alphabetic characters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", sent)\n        \n        #tokenize the sentences\n        words = word_tokenize(review_text.lower())\n        \n        #lemmatize each word to its lemma\n        lemmatizer = WordNetLemmatizer()\n        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n        \n        reviews.append(lemma_words)\n    \n    return(reviews)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:16.178455Z","iopub.execute_input":"2021-05-25T14:49:16.178888Z","iopub.status.idle":"2021-05-25T14:49:16.185008Z","shell.execute_reply.started":"2021-05-25T14:49:16.178846Z","shell.execute_reply":"2021-05-25T14:49:16.184014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_sentences = clean_sentences(train)\ntest_sentences = clean_sentences(test)\n\nprint(len(train_sentences))\nprint(len(test_sentences))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:49:16.18642Z","iopub.execute_input":"2021-05-25T14:49:16.186718Z","iopub.status.idle":"2021-05-25T14:50:00.372638Z","shell.execute_reply.started":"2021-05-25T14:49:16.18669Z","shell.execute_reply":"2021-05-25T14:50:00.371103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['Phrase'][0])\nprint(' '.join(train_sentences[0]))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:00.374134Z","iopub.execute_input":"2021-05-25T14:50:00.374578Z","iopub.status.idle":"2021-05-25T14:50:00.38226Z","shell.execute_reply.started":"2021-05-25T14:50:00.374523Z","shell.execute_reply":"2021-05-25T14:50:00.380499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\n\ntarget = train.Sentiment.values\ny_target = to_categorical(target)\n\n# number of numerical values exist in y_target's column\nnum_classes = y_target.shape[1]\nprint(num_classes)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:00.384348Z","iopub.execute_input":"2021-05-25T14:50:00.384777Z","iopub.status.idle":"2021-05-25T14:50:00.495173Z","shell.execute_reply.started":"2021-05-25T14:50:00.384735Z","shell.execute_reply":"2021-05-25T14:50:00.493917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(train_sentences,\n                                                  y_target,\n                                                  test_size = 0.2,\n                                                  stratify = y_target)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:00.49682Z","iopub.execute_input":"2021-05-25T14:50:00.497192Z","iopub.status.idle":"2021-05-25T14:50:02.254604Z","shell.execute_reply.started":"2021-05-25T14:50:00.497156Z","shell.execute_reply":"2021-05-25T14:50:02.253435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:02.256126Z","iopub.execute_input":"2021-05-25T14:50:02.25646Z","iopub.status.idle":"2021-05-25T14:50:02.263934Z","shell.execute_reply.started":"2021-05-25T14:50:02.256427Z","shell.execute_reply":"2021-05-25T14:50:02.26267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get vocab sizes and max length\n\nunique_words = set()\nlen_max = 0\n\nfor sent in tqdm(X_train):\n    unique_words.update(sent)\n    if(len_max < len(sent)):\n        len_max = len(sent)\n\n# length of the list of unique_words \nprint('Number of vocabs: ', len(list(unique_words)))\nprint('Max length of text is: ', len_max)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:02.26556Z","iopub.execute_input":"2021-05-25T14:50:02.266031Z","iopub.status.idle":"2021-05-25T14:50:02.532968Z","shell.execute_reply.started":"2021-05-25T14:50:02.266Z","shell.execute_reply":"2021-05-25T14:50:02.531124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tokenize the dataset\n\nvocab_size = len(list(unique_words))\nembedding_dim = 300\nmax_length = len_max\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:02.53476Z","iopub.execute_input":"2021-05-25T14:50:02.535071Z","iopub.status.idle":"2021-05-25T14:50:02.542239Z","shell.execute_reply.started":"2021-05-25T14:50:02.535041Z","shell.execute_reply":"2021-05-25T14:50:02.540924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntokenizer = Tokenizer(num_words = vocab_size,\n                      # filters = '#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                      oov_token = oov_tok,\n                      # lower = True,\n                      char_level = False)\n\ntokenizer.fit_on_texts(list(X_train))\n\n# Training\nX_train = tokenizer.texts_to_sequences(X_train)\nX_train = pad_sequences(X_train,\n                        maxlen = max_length,\n                        padding = padding_type,\n                        truncating = trunc_type)\n\n# Validation\nX_val = tokenizer.texts_to_sequences(X_val)\nX_val = pad_sequences(X_val,\n                      maxlen = max_length,\n                      padding = padding_type,\n                      truncating = trunc_type)\n\n# Testing\nX_test = tokenizer.texts_to_sequences(test_sentences)\nX_test = pad_sequences(X_test,\n                       maxlen = max_length,\n                       padding = padding_type,\n                       truncating = trunc_type)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:02.543679Z","iopub.execute_input":"2021-05-25T14:50:02.543972Z","iopub.status.idle":"2021-05-25T14:50:07.061207Z","shell.execute_reply.started":"2021-05-25T14:50:02.543944Z","shell.execute_reply":"2021-05-25T14:50:07.059681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_training shape   : \",X_train.shape)\nprint(\"X_validation shape : \",X_val.shape)\nprint(\"X_testing shape    : \",X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:07.062313Z","iopub.execute_input":"2021-05-25T14:50:07.062625Z","iopub.status.idle":"2021-05-25T14:50:07.069883Z","shell.execute_reply.started":"2021-05-25T14:50:07.062594Z","shell.execute_reply":"2021-05-25T14:50:07.068572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train a Sentiment Model\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout = 0.8, recurrent_dropout=0.8, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout = 0.5, recurrent_dropout=0.5, return_sequences=False)),\n    tf.keras.layers.Dense(128, activation = 'relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n])\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:07.074384Z","iopub.execute_input":"2021-05-25T14:50:07.074892Z","iopub.status.idle":"2021-05-25T14:50:07.854811Z","shell.execute_reply.started":"2021-05-25T14:50:07.074847Z","shell.execute_reply":"2021-05-25T14:50:07.85345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(min_delta = 0.001,\n                               mode = 'max',\n                               monitor = 'val_acc',\n                               patience = 2)\ncallback = [early_stopping]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:59:35.647259Z","iopub.execute_input":"2021-05-25T14:59:35.647864Z","iopub.status.idle":"2021-05-25T14:59:35.65528Z","shell.execute_reply.started":"2021-05-25T14:59:35.647819Z","shell.execute_reply":"2021-05-25T14:59:35.653474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.preprocessing.text import text_to_word_sequence\n# for i in range(len(train['Phrase'])):\n#     train['Phrase'][i] = text_to_word_sequence(train['Phrase'][i])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:07.856178Z","iopub.execute_input":"2021-05-25T14:50:07.856486Z","iopub.status.idle":"2021-05-25T14:54:55.90556Z","shell.execute_reply.started":"2021-05-25T14:50:07.856458Z","shell.execute_reply":"2021-05-25T14:54:55.904089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nnum_epochs = 5\n\nhistory = model.fit(X_train,\n                    y_train,\n                    validation_data = (X_val, y_val),\n                    epochs = num_epochs,\n                    batch_size = 256,\n                    verbose = 1,\n                    callbacks = callback)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:59:40.247423Z","iopub.execute_input":"2021-05-25T14:59:40.247932Z","iopub.status.idle":"2021-05-25T16:02:41.282847Z","shell.execute_reply.started":"2021-05-25T14:59:40.2479Z","shell.execute_reply":"2021-05-25T16:02:41.280878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the training graph\n\nimport matplotlib.pyplot as plt\n\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n  \nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:02:41.288324Z","iopub.execute_input":"2021-05-25T16:02:41.288804Z","iopub.status.idle":"2021-05-25T16:02:41.718565Z","shell.execute_reply.started":"2021-05-25T16:02:41.288748Z","shell.execute_reply":"2021-05-25T16:02:41.717281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_id = test['PhraseId']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:02:41.721209Z","iopub.execute_input":"2021-05-25T16:02:41.721672Z","iopub.status.idle":"2021-05-25T16:02:41.72783Z","shell.execute_reply.started":"2021-05-25T16:02:41.721618Z","shell.execute_reply":"2021-05-25T16:02:41.726429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# y_pred = model.predict_classes(X_test)\ny_pred = np.argmax(model.predict(X_test), axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:02:41.729698Z","iopub.execute_input":"2021-05-25T16:02:41.729995Z","iopub.status.idle":"2021-05-25T16:04:52.210486Z","shell.execute_reply.started":"2021-05-25T16:02:41.729969Z","shell.execute_reply":"2021-05-25T16:04:52.20882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'PhraseId': test_id, 'Sentiment': y_pred})\nsubmission.to_csv('movie_review_prediction_submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:04:52.212234Z","iopub.execute_input":"2021-05-25T16:04:52.212592Z","iopub.status.idle":"2021-05-25T16:04:52.350103Z","shell.execute_reply.started":"2021-05-25T16:04:52.212561Z","shell.execute_reply":"2021-05-25T16:04:52.349014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}