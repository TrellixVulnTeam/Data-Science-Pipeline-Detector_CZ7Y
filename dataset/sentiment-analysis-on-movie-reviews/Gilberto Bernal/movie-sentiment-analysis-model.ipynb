{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Note: Data taken from Kaggle dataset,  Ideas taken from kaggle-code, Youtube videos,and  from Neural Network and Deep Learning especialization. Course # 5 - Sequence Models - Transformers ....Dr  Andrew Ng. Table of Content.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-09-20T16:54:28.703534Z","iopub.status.busy":"2021-09-20T16:54:28.702829Z","iopub.status.idle":"2021-09-20T16:54:28.710041Z","shell.execute_reply":"2021-09-20T16:54:28.709046Z","shell.execute_reply.started":"2021-09-20T15:21:55.632981Z"},"papermill":{"duration":0.039867,"end_time":"2021-09-20T16:54:28.710306","exception":false,"start_time":"2021-09-20T16:54:28.670439","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:45:55.116985Z","iopub.execute_input":"2021-12-18T23:45:55.117243Z","iopub.status.idle":"2021-12-18T23:45:55.126798Z","shell.execute_reply.started":"2021-12-18T23:45:55.117215Z","shell.execute_reply":"2021-12-18T23:45:55.125951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Movie review sentiment Model.\n","metadata":{}},{"cell_type":"code","source":"import zipfile\nimport os\nwith zipfile.ZipFile('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip','r') as zip_ref:\n    zip_ref.extractall(\"./sentiment-analysis-on-movie-reviews/\")\nwith zipfile.ZipFile('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip','r') as zip_ref:\n    zip_ref.extractall(\"./sentiment-analysis-on-movie-reviews/\")","metadata":{"papermill":{"duration":0.19364,"end_time":"2021-09-20T16:54:28.924699","exception":false,"start_time":"2021-09-20T16:54:28.731059","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:45:55.128833Z","iopub.execute_input":"2021-12-18T23:45:55.129529Z","iopub.status.idle":"2021-12-18T23:45:55.291371Z","shell.execute_reply.started":"2021-12-18T23:45:55.129491Z","shell.execute_reply":"2021-12-18T23:45:55.290561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## Reading source data\n *  Data_source sotre all the data I am going to work with.\n *  Later on I am going to split the data_source between  train and validation data\n * The content includes index, Phtase and Sentiment ( 1 to 5 )\n * The shape of data_source is   ( 156060, 2 )","metadata":{}},{"cell_type":"code","source":"data_source=pd.read_table(\"/kaggle/working/sentiment-analysis-on-movie-reviews/train.tsv\",sep='\\t')\ndata_source=data_source[['Phrase','Sentiment']].copy()\ndata_source","metadata":{"papermill":{"duration":0.234836,"end_time":"2021-09-20T16:54:29.179536","exception":false,"start_time":"2021-09-20T16:54:28.9447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:45:55.292866Z","iopub.execute_input":"2021-12-18T23:45:55.293126Z","iopub.status.idle":"2021-12-18T23:45:55.473364Z","shell.execute_reply.started":"2021-12-18T23:45:55.293091Z","shell.execute_reply":"2021-12-18T23:45:55.472722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source.Sentiment.values","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:45:55.475531Z","iopub.execute_input":"2021-12-18T23:45:55.476018Z","iopub.status.idle":"2021-12-18T23:45:55.482068Z","shell.execute_reply.started":"2021-12-18T23:45:55.47598Z","shell.execute_reply":"2021-12-18T23:45:55.481231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source.index.values","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:45:55.484768Z","iopub.execute_input":"2021-12-18T23:45:55.485221Z","iopub.status.idle":"2021-12-18T23:45:55.491048Z","shell.execute_reply.started":"2021-12-18T23:45:55.485187Z","shell.execute_reply":"2021-12-18T23:45:55.490306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source.Phrase[:10]","metadata":{"papermill":{"duration":0.030671,"end_time":"2021-09-20T16:54:29.230714","exception":false,"start_time":"2021-09-20T16:54:29.200043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:45:55.492597Z","iopub.execute_input":"2021-12-18T23:45:55.492869Z","iopub.status.idle":"2021-12-18T23:45:55.500391Z","shell.execute_reply.started":"2021-12-18T23:45:55.492838Z","shell.execute_reply":"2021-12-18T23:45:55.499526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split each sentence in blocks of 10 words which is going to be the size of the tokens.\n\ndff=[len(i.split(\" \")) for i in data_source.Phrase[:10]]\nmax(dff)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:45:55.501849Z","iopub.execute_input":"2021-12-18T23:45:55.502498Z","iopub.status.idle":"2021-12-18T23:45:55.508928Z","shell.execute_reply.started":"2021-12-18T23:45:55.502434Z","shell.execute_reply":"2021-12-18T23:45:55.508095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dff","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:45:55.510468Z","iopub.execute_input":"2021-12-18T23:45:55.510971Z","iopub.status.idle":"2021-12-18T23:45:55.517575Z","shell.execute_reply.started":"2021-12-18T23:45:55.510939Z","shell.execute_reply":"2021-12-18T23:45:55.516729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing libraries and tools","metadata":{}},{"cell_type":"code","source":"from transformers import TFBertModel,  BertConfig, BertTokenizerFast, TFAutoModel\n\n# Then what you need from tensorflow.keras\nfrom tensorflow.keras.layers import Input, Dropout, Dense\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# And pandas for data import + sklearn because you allways need sklearn\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","metadata":{"papermill":{"duration":7.975528,"end_time":"2021-09-20T16:54:37.228272","exception":false,"start_time":"2021-09-20T16:54:29.252744","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:45:55.51894Z","iopub.execute_input":"2021-12-18T23:45:55.519394Z","iopub.status.idle":"2021-12-18T23:46:05.710582Z","shell.execute_reply.started":"2021-12-18T23:45:55.519359Z","shell.execute_reply":"2021-12-18T23:46:05.709849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the data for training and validation\n*  we are going to use 90% for training and 10% for validation\n*  Note that X_train_data, X_validation_fdata, y_train_data and y_validation_data store data's indices","metadata":{}},{"cell_type":"code","source":"# train_test_split : Split arrays or matrices into random train and test subsets\nX_train_data, X_validation_data, y_train_data, y_validation_data = train_test_split(data_source.index.values,  # sequence number from 1 to 156060\n                                                  data_source.Sentiment.values,   # values 1 to 5\n                                                  test_size=0.15,    # should be between 0.0 and 1.0  .10 = 10% for testing and 90% for training\n                                                  random_state=42,   # Controls the shuffling applied to the data before applying the split\n                                                  stratify=data_source.Sentiment) # data is split in a stratified fashion, using this as the class labels\n\n","metadata":{"papermill":{"duration":0.17398,"end_time":"2021-09-20T16:54:37.424326","exception":false,"start_time":"2021-09-20T16:54:37.250346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:05.711788Z","iopub.execute_input":"2021-12-18T23:46:05.712994Z","iopub.status.idle":"2021-12-18T23:46:05.847478Z","shell.execute_reply.started":"2021-12-18T23:46:05.712959Z","shell.execute_reply":"2021-12-18T23:46:05.846742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's take a look at X_train and X_validation data and shape","metadata":{}},{"cell_type":"code","source":"print(X_train_data)\nprint(X_validation_data)\nprint(y_train_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:05.849468Z","iopub.execute_input":"2021-12-18T23:46:05.84992Z","iopub.status.idle":"2021-12-18T23:46:05.857377Z","shell.execute_reply.started":"2021-12-18T23:46:05.849882Z","shell.execute_reply":"2021-12-18T23:46:05.856688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:05.860216Z","iopub.execute_input":"2021-12-18T23:46:05.860479Z","iopub.status.idle":"2021-12-18T23:46:05.865871Z","shell.execute_reply.started":"2021-12-18T23:46:05.860449Z","shell.execute_reply":"2021-12-18T23:46:05.865194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sns.countplot(data_source)\nplt.xlabel('Review Score')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:05.86715Z","iopub.execute_input":"2021-12-18T23:46:05.867758Z","iopub.status.idle":"2021-12-18T23:46:06.064458Z","shell.execute_reply.started":"2021-12-18T23:46:05.867723Z","shell.execute_reply":"2021-12-18T23:46:06.063783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### in Data_source file , assigning data-type 'training' to Training data and 'validation' to  validation data\n* I  use X_train_data  and X_validation_data to localise the corresponding records within the file  data_source","metadata":{}},{"cell_type":"code","source":"# in Data_source file , assigning data-type 'training' to Training data and 'validation' to  validation data\n\ndata_source['data_type'] = ['not_set']*data_source.shape[0]\ndata_source.loc[X_train_data, 'data_type'] = 'training'\ndata_source.loc[X_validation_data, 'data_type'] = 'validation'","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:06.068077Z","iopub.execute_input":"2021-12-18T23:46:06.068276Z","iopub.status.idle":"2021-12-18T23:46:06.100129Z","shell.execute_reply.started":"2021-12-18T23:46:06.068252Z","shell.execute_reply":"2021-12-18T23:46:06.099502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_data.shape)\nprint(X_validation_data)\nprint(y_train_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:06.101333Z","iopub.execute_input":"2021-12-18T23:46:06.101669Z","iopub.status.idle":"2021-12-18T23:46:06.107198Z","shell.execute_reply.started":"2021-12-18T23:46:06.101614Z","shell.execute_reply":"2021-12-18T23:46:06.106358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:06.108633Z","iopub.execute_input":"2021-12-18T23:46:06.108965Z","iopub.status.idle":"2021-12-18T23:46:06.152482Z","shell.execute_reply.started":"2021-12-18T23:46:06.108929Z","shell.execute_reply":"2021-12-18T23:46:06.151754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_data.shape, X_validation_data.shape\n","metadata":{"papermill":{"duration":0.03069,"end_time":"2021-09-20T16:54:37.475883","exception":false,"start_time":"2021-09-20T16:54:37.445193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:06.1539Z","iopub.execute_input":"2021-12-18T23:46:06.154203Z","iopub.status.idle":"2021-12-18T23:46:06.160192Z","shell.execute_reply.started":"2021-12-18T23:46:06.154164Z","shell.execute_reply":"2021-12-18T23:46:06.159368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source[data_source.data_type=='validation'].Phrase","metadata":{"execution":{"iopub.status.busy":"2021-12-19T02:12:49.203993Z","iopub.execute_input":"2021-12-19T02:12:49.204265Z","iopub.status.idle":"2021-12-19T02:12:49.240285Z","shell.execute_reply.started":"2021-12-19T02:12:49.204236Z","shell.execute_reply":"2021-12-19T02:12:49.239447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_source.Sentiment.values)\nprint(data_source.Phrase.values)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:06.201527Z","iopub.execute_input":"2021-12-18T23:46:06.201771Z","iopub.status.idle":"2021-12-18T23:46:06.209394Z","shell.execute_reply.started":"2021-12-18T23:46:06.20174Z","shell.execute_reply":"2021-12-18T23:46:06.208572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining parameters for the model\n*  Note that the bert model and tokenizer function is needed tp create the dataset","metadata":{}},{"cell_type":"code","source":"max_token_length = max(dff)+3   # Max length of tokens\nnumber_of_samples = len(data_source)\nbert = 'bert-base-cased'\nconfig = BertConfig.from_pretrained(bert)\nconfig.output_hidden_states = False\ntokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = bert, config = config)\n","metadata":{"papermill":{"duration":0.03171,"end_time":"2021-09-20T16:54:37.530381","exception":false,"start_time":"2021-09-20T16:54:37.498671","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:06.210955Z","iopub.execute_input":"2021-12-18T23:46:06.211216Z","iopub.status.idle":"2021-12-18T23:46:11.125798Z","shell.execute_reply.started":"2021-12-18T23:46:06.211183Z","shell.execute_reply":"2021-12-18T23:46:11.125061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining sentiment values or labels ( 1,2,3,4,5 )","metadata":{}},{"cell_type":"code","source":"data_source[\"Sentiment\"].values","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:11.127605Z","iopub.execute_input":"2021-12-18T23:46:11.12803Z","iopub.status.idle":"2021-12-18T23:46:11.133912Z","shell.execute_reply.started":"2021-12-18T23:46:11.127996Z","shell.execute_reply":"2021-12-18T23:46:11.133141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source['Phrase'].values","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:11.135031Z","iopub.execute_input":"2021-12-18T23:46:11.135856Z","iopub.status.idle":"2021-12-18T23:46:11.144343Z","shell.execute_reply.started":"2021-12-18T23:46:11.135812Z","shell.execute_reply":"2021-12-18T23:46:11.143592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent_values_array = data_source[\"Sentiment\"].values\nlen(sent_values_array)\n#sent_values_array.max()","metadata":{"papermill":{"duration":0.029488,"end_time":"2021-09-20T16:54:37.581246","exception":false,"start_time":"2021-09-20T16:54:37.551758","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-19T01:40:15.245037Z","iopub.execute_input":"2021-12-19T01:40:15.245406Z","iopub.status.idle":"2021-12-19T01:40:15.256347Z","shell.execute_reply.started":"2021-12-19T01:40:15.245363Z","shell.execute_reply":"2021-12-19T01:40:15.2554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This function receives 3 parameters and return two parameters:  One dictionary {'input_ids', 'attention_mask'},  labels\n* Note that 'input_ids and  'attention_mask' will be the model's input data","metadata":{}},{"cell_type":"code","source":"def map_function(input_ids, masks,labels):    # receives 3 tuples and returns 2 \n    return {'input_ids': input_ids, 'attention_mask': masks},labels","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:11.15437Z","iopub.execute_input":"2021-12-18T23:46:11.154846Z","iopub.status.idle":"2021-12-18T23:46:11.159791Z","shell.execute_reply.started":"2021-12-18T23:46:11.154814Z","shell.execute_reply":"2021-12-18T23:46:11.158838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining train_dataset\n*  Tokenization is the process of breaking up a string into tokens. Commonly, these tokens are words, numbers, and/or punctuation. The tensorflow_text package provides a number of tokenizers available for preprocessing text required by your text-based models. By performing the tokenization in the TensorFlow graph, you will not need to worry about differences between the training and inference workflows and managing preprocessing scripts.","metadata":{}},{"cell_type":"code","source":"# to_categorical : Converts a class vector (integers) to binary class matrix\n# converts training sentiment labels in to a binary  matrix  of shape  #items x # values    140454,  5 \nx_senti = to_categorical(data_source[data_source.data_type=='training'].Sentiment)  # x_senti.shape  140454,5\n\n# Tokenize the input \nx = tokenizer(\n    text=data_source[data_source.data_type=='training'].Phrase.to_list(), # list of all Phrases \n    add_special_tokens=True,\n    max_length=max_token_length,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    verbose = True)\n\ntrain_dataset=tf.data.Dataset.from_tensor_slices((x['input_ids'], x['attention_mask'], x_senti)) # creates tensor  of 512,84,5\n\n","metadata":{"papermill":{"duration":87.245384,"end_time":"2021-09-20T16:56:04.84797","exception":false,"start_time":"2021-09-20T16:54:37.602586","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:11.161575Z","iopub.execute_input":"2021-12-18T23:46:11.162118Z","iopub.status.idle":"2021-12-18T23:46:24.540064Z","shell.execute_reply.started":"2021-12-18T23:46:11.162085Z","shell.execute_reply":"2021-12-18T23:46:24.539266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.map(map_function)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.541397Z","iopub.execute_input":"2021-12-18T23:46:24.542172Z","iopub.status.idle":"2021-12-18T23:46:24.601108Z","shell.execute_reply.started":"2021-12-18T23:46:24.542132Z","shell.execute_reply":"2021-12-18T23:46:24.600403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n# shuffle and batch - dropping any remaining samples that don't cleanly\ntrain_dataset = train_dataset.shuffle(1000).batch(batch_size, drop_remainder=True) #  created object of shape 32x 84  32 is the batch size","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.603341Z","iopub.execute_input":"2021-12-18T23:46:24.603756Z","iopub.status.idle":"2021-12-18T23:46:24.612434Z","shell.execute_reply.started":"2021-12-18T23:46:24.603718Z","shell.execute_reply":"2021-12-18T23:46:24.611719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_senti.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.613744Z","iopub.execute_input":"2021-12-18T23:46:24.614064Z","iopub.status.idle":"2021-12-18T23:46:24.620461Z","shell.execute_reply.started":"2021-12-18T23:46:24.614029Z","shell.execute_reply":"2021-12-18T23:46:24.619746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.621697Z","iopub.execute_input":"2021-12-18T23:46:24.622425Z","iopub.status.idle":"2021-12-18T23:46:24.630946Z","shell.execute_reply.started":"2021-12-18T23:46:24.62239Z","shell.execute_reply":"2021-12-18T23:46:24.630184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's check the parameters of dataset:  x[input_ids], x[attention_mask],  x_senti","metadata":{}},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.632182Z","iopub.execute_input":"2021-12-18T23:46:24.6325Z","iopub.status.idle":"2021-12-18T23:46:24.638493Z","shell.execute_reply.started":"2021-12-18T23:46:24.632466Z","shell.execute_reply":"2021-12-18T23:46:24.637762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.639919Z","iopub.execute_input":"2021-12-18T23:46:24.640495Z","iopub.status.idle":"2021-12-18T23:46:24.648766Z","shell.execute_reply.started":"2021-12-18T23:46:24.640462Z","shell.execute_reply":"2021-12-18T23:46:24.64785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_senti.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.650156Z","iopub.execute_input":"2021-12-18T23:46:24.650541Z","iopub.status.idle":"2021-12-18T23:46:24.657995Z","shell.execute_reply.started":"2021-12-18T23:46:24.650507Z","shell.execute_reply":"2021-12-18T23:46:24.656944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x['input_ids']","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.65902Z","iopub.execute_input":"2021-12-18T23:46:24.660498Z","iopub.status.idle":"2021-12-18T23:46:24.668019Z","shell.execute_reply.started":"2021-12-18T23:46:24.660467Z","shell.execute_reply":"2021-12-18T23:46:24.667176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.669512Z","iopub.execute_input":"2021-12-18T23:46:24.669907Z","iopub.status.idle":"2021-12-18T23:46:24.677232Z","shell.execute_reply.started":"2021-12-18T23:46:24.669872Z","shell.execute_reply":"2021-12-18T23:46:24.676368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:24.678796Z","iopub.execute_input":"2021-12-18T23:46:24.679235Z","iopub.status.idle":"2021-12-18T23:46:24.684755Z","shell.execute_reply.started":"2021-12-18T23:46:24.679203Z","shell.execute_reply":"2021-12-18T23:46:24.684032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining validation_dataset","metadata":{}},{"cell_type":"code","source":"y_senti = to_categorical(data_source[data_source.data_type=='validation'].Sentiment)\n\n# Tokenize the input \nv= tokenizer(\n    text=data_source[data_source.data_type=='validation'].Phrase.to_list(),\n    add_special_tokens=True,\n    max_length=max_token_length,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    verbose = True)\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((v['input_ids'], v['attention_mask'], y_senti))\nvalidation_dataset = validation_dataset.map(map_function)\nvalidation_dataset = validation_dataset.shuffle(1000).batch(batch_size, drop_remainder=True)","metadata":{"papermill":{"duration":0.035522,"end_time":"2021-09-20T16:56:04.907952","exception":false,"start_time":"2021-09-20T16:56:04.87243","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:24.68616Z","iopub.execute_input":"2021-12-18T23:46:24.686861Z","iopub.status.idle":"2021-12-18T23:46:25.597946Z","shell.execute_reply.started":"2021-12-18T23:46:24.6868Z","shell.execute_reply":"2021-12-18T23:46:25.597218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_token_length","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:25.599058Z","iopub.execute_input":"2021-12-18T23:46:25.599299Z","iopub.status.idle":"2021-12-18T23:46:25.608233Z","shell.execute_reply.started":"2021-12-18T23:46:25.59927Z","shell.execute_reply":"2021-12-18T23:46:25.6075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's create a much nicer confusion matrix\ndef plot_confusion_matrix(y_test, y_pred, classes=None):\n  import itertools\n  figsize = (20, 20)\n  cm = confusion_matrix(y_test, tf.round(y_pred))\n\n  # let's normalize confusion matrix\n  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n  n_classes = cm.shape[0]\n\n  # Let's prettify it\n  fig , ax = plt.subplots(figsize=figsize)\n\n  # create matrix plot\n  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n  fig.colorbar(cax)\n\n  \n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n\n  # Label the axis\n  ax.set(title=\"Confusion Matrix\",\n          xlabel = \"Predicted Label\",\n          ylabel = \"True Label\",\n          xticks = np.arange(n_classes),\n          yticks = np.arange(n_classes),\n          xticklabels = labels,\n          yticklabels = labels)\n\n  # set X-axis labels to bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  # Adjust label size\n  ax.yaxis.label.set_size(20)\n  ax.xaxis.label.set_size(20)\n  ax.title.set_size(20)\n\n\n  # set threshold for different colors\n  threshold = ( cm.max() + cm.min()) /2. \n\n  # plot text in each cell\n\n  for i,j  in itertools.product(range(cm.shape[0]),  range(cm.shape[1])):\n    plt.text(j, i, f\"{cm[i,j]} ({cm_norm[i,j]*100:.1f}%)\",\n                               horizontalalignment = \"center\",\n                               color = \"white\" if cm[i,j] > threshold else \"black\",\n                               size = 15)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:25.609537Z","iopub.execute_input":"2021-12-18T23:46:25.60996Z","iopub.status.idle":"2021-12-18T23:46:25.62198Z","shell.execute_reply.started":"2021-12-18T23:46:25.609924Z","shell.execute_reply":"2021-12-18T23:46:25.621315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Plot the validation and training data separately\n\ndef plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:25.623068Z","iopub.execute_input":"2021-12-18T23:46:25.623379Z","iopub.status.idle":"2021-12-18T23:46:25.634645Z","shell.execute_reply.started":"2021-12-18T23:46:25.623346Z","shell.execute_reply":"2021-12-18T23:46:25.633897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining layers that will fit the model","metadata":{"papermill":{"duration":0.026066,"end_time":"2021-09-20T16:56:05.191145","exception":false,"start_time":"2021-09-20T16:56:05.165079","status":"completed"},"tags":[]}},{"cell_type":"code","source":"input_ids = tf.keras.Input(shape=(max_token_length,), name='input_ids', dtype='int32') # parameters of input layer\nattention_mask = tf.keras.Input(shape=(max_token_length,), name='attention_mask', dtype='int32')  # parameters of attention mask \ninputs = {'input_ids': input_ids, 'attention_mask': attention_mask}  # inputs will be the input of our model..  \nbert = TFAutoModel.from_pretrained('bert-base-cased')\nembeddings = bert.bert(inputs)[1]  #  access pooled activations with [1]  pool from 3 tensors to expecting  2 tensors\nxis = tf.keras.layers.Dense(1024,activation='relu')(embeddings)   # intermediate dense layer\nyhat = tf.keras.layers.Dense(sent_values_array.max()+1, activation='softmax', name='outputs')(xis)  # final output layer\n","metadata":{"papermill":{"duration":0.042339,"end_time":"2021-09-20T16:56:05.258787","exception":false,"start_time":"2021-09-20T16:56:05.216448","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:25.635545Z","iopub.execute_input":"2021-12-18T23:46:25.637739Z","iopub.status.idle":"2021-12-18T23:46:52.896038Z","shell.execute_reply.started":"2021-12-18T23:46:25.637708Z","shell.execute_reply":"2021-12-18T23:46:52.895256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:52.901179Z","iopub.execute_input":"2021-12-18T23:46:52.901395Z","iopub.status.idle":"2021-12-18T23:46:52.906582Z","shell.execute_reply.started":"2021-12-18T23:46:52.901369Z","shell.execute_reply":"2021-12-18T23:46:52.905886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the model","metadata":{}},{"cell_type":"code","source":"#model = tf.keras.Model(inputs=[train_dataset,mask], outputs=yhat)\nmodel = tf.keras.Model(inputs= inputs, outputs=yhat)   # inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\nmodel.summary()","metadata":{"papermill":{"duration":1.098693,"end_time":"2021-09-20T16:56:06.383988","exception":false,"start_time":"2021-09-20T16:56:05.285295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:52.908022Z","iopub.execute_input":"2021-12-18T23:46:52.908932Z","iopub.status.idle":"2021-12-18T23:46:52.954429Z","shell.execute_reply.started":"2021-12-18T23:46:52.908894Z","shell.execute_reply":"2021-12-18T23:46:52.953734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining Adam optimizer, loss and accuracy functions..","metadata":{"papermill":{"duration":0.026383,"end_time":"2021-09-20T16:56:06.436782","exception":false,"start_time":"2021-09-20T16:56:06.410399","status":"completed"},"tags":[]}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(lr=2e-5, decay=1e-6)    #  lr=1e-5\nloss = tf.keras.losses.CategoricalCrossentropy()\naccuracy = tf.keras.metrics.CategoricalAccuracy('accuracy')","metadata":{"papermill":{"duration":0.034537,"end_time":"2021-09-20T16:56:06.498094","exception":false,"start_time":"2021-09-20T16:56:06.463557","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:52.956403Z","iopub.execute_input":"2021-12-18T23:46:52.957204Z","iopub.status.idle":"2021-12-18T23:46:52.971014Z","shell.execute_reply.started":"2021-12-18T23:46:52.957168Z","shell.execute_reply":"2021-12-18T23:46:52.970311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compiling the model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])","metadata":{"papermill":{"duration":0.107886,"end_time":"2021-09-20T16:56:06.632067","exception":false,"start_time":"2021-09-20T16:56:06.524181","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:52.972326Z","iopub.execute_input":"2021-12-18T23:46:52.972907Z","iopub.status.idle":"2021-12-18T23:46:52.991475Z","shell.execute_reply.started":"2021-12-18T23:46:52.97287Z","shell.execute_reply":"2021-12-18T23:46:52.990686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset\n","metadata":{"execution":{"iopub.status.busy":"2021-12-18T23:46:52.994131Z","iopub.execute_input":"2021-12-18T23:46:52.994576Z","iopub.status.idle":"2021-12-18T23:46:53.002695Z","shell.execute_reply.started":"2021-12-18T23:46:52.994546Z","shell.execute_reply":"2021-12-18T23:46:53.00197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainig the model\n*  Using Training and validation data","metadata":{}},{"cell_type":"code","source":"history1 = model.fit(\n    train_dataset,  #train_dataset,\n    validation_data= validation_dataset,  #  validatio dataset\n    epochs=8)","metadata":{"papermill":{"duration":0.042858,"end_time":"2021-09-20T16:56:06.70174","exception":false,"start_time":"2021-09-20T16:56:06.658882","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-18T23:46:53.003903Z","iopub.execute_input":"2021-12-18T23:46:53.004221Z","iopub.status.idle":"2021-12-19T01:17:50.468305Z","shell.execute_reply.started":"2021-12-18T23:46:53.004141Z","shell.execute_reply":"2021-12-19T01:17:50.467593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:17:50.469496Z","iopub.execute_input":"2021-12-19T01:17:50.46977Z","iopub.status.idle":"2021-12-19T01:17:50.908558Z","shell.execute_reply.started":"2021-12-19T01:17:50.469734Z","shell.execute_reply":"2021-12-19T01:17:50.906971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"model.save('./sentiment-analysis-on-movie-reviews/Movie_sentiment_analysis_model')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:17:50.910073Z","iopub.execute_input":"2021-12-19T01:17:50.910371Z","iopub.status.idle":"2021-12-19T01:18:26.329351Z","shell.execute_reply.started":"2021-12-19T01:17:50.910333Z","shell.execute_reply":"2021-12-19T01:18:26.328604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('Movies_sentiment_analysis_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T02:26:28.25407Z","iopub.execute_input":"2021-12-19T02:26:28.254343Z","iopub.status.idle":"2021-12-19T02:26:31.387105Z","shell.execute_reply.started":"2021-12-19T02:26:28.254315Z","shell.execute_reply":"2021-12-19T02:26:31.386174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading test data","metadata":{}},{"cell_type":"code","source":"test=pd.read_table(\"/kaggle/working/sentiment-analysis-on-movie-reviews/test.tsv\",sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:26.339838Z","iopub.execute_input":"2021-12-19T01:18:26.341765Z","iopub.status.idle":"2021-12-19T01:18:26.412557Z","shell.execute_reply.started":"2021-12-19T01:18:26.341727Z","shell.execute_reply":"2021-12-19T01:18:26.41187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_source[data_source.data_type=='validation'].Phrase","metadata":{"execution":{"iopub.status.busy":"2021-12-19T02:14:32.729365Z","iopub.execute_input":"2021-12-19T02:14:32.729663Z","iopub.status.idle":"2021-12-19T02:14:32.763112Z","shell.execute_reply.started":"2021-12-19T02:14:32.729616Z","shell.execute_reply":"2021-12-19T02:14:32.762123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing test dataset","metadata":{}},{"cell_type":"code","source":"x_test = tokenizer(\n    text=test.Phrase.to_list(),\n    add_special_tokens=True,\n    max_length=max_token_length,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    verbose = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:26.413765Z","iopub.execute_input":"2021-12-19T01:18:26.41403Z","iopub.status.idle":"2021-12-19T01:18:31.032224Z","shell.execute_reply.started":"2021-12-19T01:18:26.413996Z","shell.execute_reply":"2021-12-19T01:18:31.031466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:31.033633Z","iopub.execute_input":"2021-12-19T01:18:31.034058Z","iopub.status.idle":"2021-12-19T01:18:31.041612Z","shell.execute_reply.started":"2021-12-19T01:18:31.034022Z","shell.execute_reply":"2021-12-19T01:18:31.040731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_items=tf.data.Dataset.from_tensor_slices((x_test['input_ids'],x_test['attention_mask']))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:31.042882Z","iopub.execute_input":"2021-12-19T01:18:31.043461Z","iopub.status.idle":"2021-12-19T01:18:31.050394Z","shell.execute_reply.started":"2021-12-19T01:18:31.043423Z","shell.execute_reply":"2021-12-19T01:18:31.04971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_func(input_ids, masks):\n    return {'input_ids': input_ids, 'attention_mask': masks}\n\ntest_items = test_items.map(map_func)\ntest_items = test_items.batch(32)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:31.051538Z","iopub.execute_input":"2021-12-19T01:18:31.051873Z","iopub.status.idle":"2021-12-19T01:18:31.090553Z","shell.execute_reply.started":"2021-12-19T01:18:31.051839Z","shell.execute_reply":"2021-12-19T01:18:31.089943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_items","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:31.091773Z","iopub.execute_input":"2021-12-19T01:18:31.092212Z","iopub.status.idle":"2021-12-19T01:18:31.099836Z","shell.execute_reply.started":"2021-12-19T01:18:31.09218Z","shell.execute_reply":"2021-12-19T01:18:31.0992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Making predictions","metadata":{}},{"cell_type":"code","source":"predictions=model.predict(test_items).argmax(axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:18:31.101252Z","iopub.execute_input":"2021-12-19T01:18:31.102062Z","iopub.status.idle":"2021-12-19T01:20:47.065791Z","shell.execute_reply.started":"2021-12-19T01:18:31.102028Z","shell.execute_reply":"2021-12-19T01:20:47.065022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprediction2=model.predict(validation_dataset).argmax(axis=-1)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T02:19:36.350987Z","iopub.execute_input":"2021-12-19T02:19:36.351552Z","iopub.status.idle":"2021-12-19T02:20:12.874031Z","shell.execute_reply.started":"2021-12-19T02:19:36.351515Z","shell.execute_reply":"2021-12-19T02:20:12.873085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction2.min()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T03:08:31.554251Z","iopub.execute_input":"2021-12-19T03:08:31.554519Z","iopub.status.idle":"2021-12-19T03:08:31.562875Z","shell.execute_reply.started":"2021-12-19T03:08:31.554492Z","shell.execute_reply":"2021-12-19T03:08:31.561981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=prediction2+1\npred.max()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T03:03:42.929314Z","iopub.execute_input":"2021-12-19T03:03:42.929595Z","iopub.status.idle":"2021-12-19T03:03:42.936454Z","shell.execute_reply.started":"2021-12-19T03:03:42.929566Z","shell.execute_reply":"2021-12-19T03:03:42.935582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_validation=y_validation_data[:23392]\ny_validation.min()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T03:07:35.293203Z","iopub.execute_input":"2021-12-19T03:07:35.293476Z","iopub.status.idle":"2021-12-19T03:07:35.300075Z","shell.execute_reply.started":"2021-12-19T03:07:35.293448Z","shell.execute_reply":"2021-12-19T03:07:35.299111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_validation.shape, pred.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-19T03:05:20.824086Z","iopub.execute_input":"2021-12-19T03:05:20.82436Z","iopub.status.idle":"2021-12-19T03:05:20.829899Z","shell.execute_reply.started":"2021-12-19T03:05:20.824331Z","shell.execute_reply":"2021-12-19T03:05:20.829032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiments = [0,1,2,3,4]\n#test_sent_array = test[\"Sentiment\"].values\nfrom sklearn.metrics import confusion_matrix\n\nplot_confusion_matrix(y_test=y_validation,\n                      y_pred=prediction2,\n                      classes=sentiments)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T03:09:33.004602Z","iopub.execute_input":"2021-12-19T03:09:33.004991Z","iopub.status.idle":"2021-12-19T03:09:33.463207Z","shell.execute_reply.started":"2021-12-19T03:09:33.004948Z","shell.execute_reply":"2021-12-19T03:09:33.462523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions and acknowledgements*","metadata":{}},{"cell_type":"markdown","source":"## Creating the submission file","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['PhraseId'] = test['PhraseId']\nsubmission['Sentiment'] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:20:47.085956Z","iopub.execute_input":"2021-12-19T01:20:47.086338Z","iopub.status.idle":"2021-12-19T01:20:47.291338Z","shell.execute_reply.started":"2021-12-19T01:20:47.086305Z","shell.execute_reply":"2021-12-19T01:20:47.290696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model =load_model('./sentiment-analysis-on-movie-reviews/Movie_sentiment_analysis_model')\nnew_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:20:47.292307Z","iopub.execute_input":"2021-12-19T01:20:47.296073Z","iopub.status.idle":"2021-12-19T01:20:59.510621Z","shell.execute_reply.started":"2021-12-19T01:20:47.296037Z","shell.execute_reply":"2021-12-19T01:20:59.50992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:20:59.512059Z","iopub.execute_input":"2021-12-19T01:20:59.512315Z","iopub.status.idle":"2021-12-19T01:20:59.520615Z","shell.execute_reply.started":"2021-12-19T01:20:59.512281Z","shell.execute_reply":"2021-12-19T01:20:59.519848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U tensorboard-plugin-profile\n","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:20:59.521666Z","iopub.execute_input":"2021-12-19T01:20:59.521919Z","iopub.status.idle":"2021-12-19T01:21:08.814634Z","shell.execute_reply.started":"2021-12-19T01:20:59.521886Z","shell.execute_reply":"2021-12-19T01:21:08.813748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --port=5036 --logdir tb_callback_dir","metadata":{"execution":{"iopub.status.busy":"2021-12-19T01:29:01.231158Z","iopub.execute_input":"2021-12-19T01:29:01.231476Z","iopub.status.idle":"2021-12-19T01:29:01.244935Z","shell.execute_reply.started":"2021-12-19T01:29:01.231441Z","shell.execute_reply":"2021-12-19T01:29:01.244071Z"},"trusted":true},"execution_count":null,"outputs":[]}]}