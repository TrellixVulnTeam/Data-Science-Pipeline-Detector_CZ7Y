{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import data from csv file"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/loan-default-prediction/train_v2.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the first 5 rows of training data\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shape of training data\ndata_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#information about data and it's types\ndata_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 653 of float type, 99 of integral type and 19 are categorical type"},{"metadata":{"trusted":true},"cell_type":"code","source":"#selecting categorical columns\ndata_cat = data_train.select_dtypes(include=['object']).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_cat.columns)\nprint(data_cat['f137'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"if we observe above columns, there are no f776 or f777 features but as per data, they are categorical too and the values of categorical columns above are way too high and encoding them will be difficult as they are in large counts while being unique for different consumers. Hence, we will deal only with numerical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting numerical columns from training data\ndata_num = data_train.select_dtypes(include=['float64', 'int64']).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for any missing values in each column\ndata_num.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputing missing values with mean of that column\ndata_num_imputed = data_num.fillna(data_num.mean(), inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for missing values\ndata_num_imputed.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that, all missing values have been imputed."},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing id column from imputed data\ndata_num_imputed.drop(columns='id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num_imputed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is arranged from old to new in time dimension. Hence, we will shuffle it to make a randomly sampled data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#shuffling dataframe in random order to remove any bias due to time sampling\ndata_num_shuffled = data_num_imputed.sample(frac=1, random_state=2)\ndata_num_shuffled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperating loss column and calculating correlation matrix for features\nloss = data_num_shuffled['loss'].copy()\ndata_num_shuffled.drop(columns='loss', inplace=True)\ncorr_matrix = data_num_shuffled.corr().abs()\ncorr_matrix.head()\ncorr_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking upper triangular part of correlation matrix \nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting highly correlated features with correlation coefficient of more than 0.8\nthreshold = 0.8\ncol_to_drop = [column for column in upper.columns if any(upper[column]>threshold)]\nlen(col_to_drop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are 541 highly correlated features to be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping highly correlated columns\ndata_num_shuffled.drop(columns=col_to_drop, inplace=True)\ndata_num_shuffled.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding correlation of features with target values of loss and convert into a dataframe\ncorr_tar = data_num_shuffled.corrwith(loss).sort_values()\nprint(corr_tar.head(30))\nprint(corr_tar.tail(30))\ncorr_tar_df = corr_tar.to_frame().transpose()\ncorr_tar_df.isna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting features having NaN value correlation with loss to remove them \ncol_to_drop_1 = corr_tar_df.columns[corr_tar_df.isna().any()].to_list()\nprint(len(col_to_drop_1))\nprint(col_to_drop_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num_shuffled.drop(columns=col_to_drop_1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num_shuffled.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a copy of final features dataframe \nX_feat = data_num_shuffled.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a copy of loss dataframe \nY_tar = loss.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making target or loss a binary valued variable for better classification and interpretation\nY_tar[Y_tar>0] = 1\nY_tar.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting data into train and test splits and normalizing data for better training\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X_feat, Y_tar, test_size=0.2, random_state=42)\nss = StandardScaler()\nX_train = ss.fit_transform(x_train)\nX_test = ss.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting y to one-dimensional array\ny_train = np.array(y_train).reshape((-1, ))\ny_test = np.array(y_test).reshape((-1, ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for calculating cross validation scores for evaluating model performance on train data and test data\ndef scores(X_train, y_train, X_test, y_test, model):\n    from sklearn.model_selection import cross_val_score, ShuffleSplit\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42) # shufflesplit is a cross validation strategy that is best used when n_features < n_samples\n    train_scores = cross_val_score(estimator = model, X = X_train, y = y_train, cv = cv)\n    test_scores = cross_val_score(estimator = model, X = X_test, y = y_test, cv = cv)\n    return [round(train_scores.mean(), 4), round(test_scores.mean(),4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to fit and evaluate model performance\ndef fit_and_evaluate(model):\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions and evalute\n    y_pred = model.predict(X_test)\n    cross_val_scores = scores(X_train, y_train, X_test, y_test, model)\n    \n    # calculate accuracy and f_score for model performance\n    from sklearn.metrics import accuracy_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred, normalize=True)\n    f_score = f1_score(y_test, y_pred, average='macro')\n    \n    # dictionary for storing all the above values\n    metric = dict()\n    metric['cv_scores'] = cross_val_scores\n    metric['accuracy'] = round(accuracy,4)\n    metric['f_score'] = round(f_score,4)\n    \n    # Return the performance metric \n    return metric","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we will compare three classification algorithms for their performance and choose the best one. We considered logistic regression, random forest and xgboost classifiers to compare T "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# logistic regression \nlogistic = LogisticRegression(max_iter = 50, random_state=42)\nlog_c = fit_and_evaluate(logistic)\nprint('performance of logistic regression on train and test data:', log_c['cv_scores'])\nlog_c.pop('cv_scores')\nprint(log_c)\ndf_log = pd.DataFrame(log_c, index=[0])\nprint(df_log)\n\n# Random forest classification\nRFC = RandomForestClassifier(n_estimators = 15, random_state=42)\nrandom = fit_and_evaluate(RFC)\nprint('performance of Random Forest Classifier on train and test data:', random['cv_scores'])\nrandom.pop('cv_scores')\nprint(random)\ndf_rand = pd.DataFrame(random, index=[1])\nprint(df_rand)\n\n# Xgboost classification\ngb = XGBClassifier()\ngb_c = fit_and_evaluate(gb)\nprint('performance of XGB Classifier on train and test data:', gb_c['cv_scores'])\ngb_c.pop('cv_scores')\nprint(gb_c)\ndf_gb = pd.DataFrame(gb_c, index=[2])\nprint(df_gb)\n\nframes = [df_log, df_rand, df_gb]\nmodel_compare_df = pd.concat(frames)\n\nprint(model_compare_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation scores for all three classifiers are almost same for both training data and test data which implies that our models are good and don't overfit. We will proceed with random forest classifier as it has best F score and also, it is better indicator than accuracy for model performance as we know it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding least important features from random forest classification so as to see if we can improve our model performance or we can get same performance with less features\nfeature_importances = RFC.feature_importances_\nfeature_importances = pd.DataFrame({'feature': list(X_feat.columns), 'importance': feature_importances}).sort_values('importance', ascending = True)\nprint(feature_importances['importance'].mean()/2) # threshold for filtering least important features\nleast_important_feat = list(feature_importances[feature_importances['importance'] < 0.0025]['feature'])\nlen(least_important_feat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are 12 features with least importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dataframe with important features\nX_feat_imp = X_feat.drop(columns=least_important_feat, inplace=False)\nlen(X_feat_imp.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting data into train and test\nx_train_imp, x_test_imp, y_train, y_test = train_test_split(X_feat_imp, Y_tar, test_size=0.2, random_state=42)\nss = StandardScaler()\nX_train_imp = ss.fit_transform(x_train_imp)\nX_test_imp = ss.transform(x_test_imp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting y to one-dimensional array\ny_train = np.array(y_train).reshape((-1, ))\ny_test = np.array(y_test).reshape((-1, ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to fit and evaluate model performance with important features\ndef fit_and_evaluate_imp(model):\n    \n    # Train the model\n    model.fit(X_train_imp, y_train)\n    \n    # Make predictions and evalute\n    y_pred = model.predict(X_test_imp)\n    cross_val_scores = scores(X_train_imp, y_train, X_test_imp, y_test, model)\n    \n    # calculate accuracy and f_score for model performance\n    from sklearn.metrics import accuracy_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred, normalize=True)\n    f_score = f1_score(y_test, y_pred, average='macro')\n    \n    # dictionary for storing all the above values\n    metric = dict()\n    metric['cv_scores'] = cross_val_scores\n    metric['accuracy'] = round(accuracy,4)\n    metric['f_score'] = round(f_score,4)\n    \n    # Return the performance metric \n    return metric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest classification with important features\nRFC_imp = RandomForestClassifier(n_estimators = 15, random_state=42)\nrandom_imp = fit_and_evaluate_imp(RFC_imp)\nprint('performance of Random Forest Classifier on train and test data:', random_imp['cv_scores'])\nrandom_imp.pop('cv_scores')\nprint(random_imp)\ndf_rand_imp = pd.DataFrame(random_imp, index=[0])\nprint(df_rand_imp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F score with most important features has improved. Now, we will preprocess test data for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.read_csv('/kaggle/input/loan-default-prediction/test_v2.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_feat.columns)\nprint(X_feat_imp.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting columns that are used for training\ntest_feat = data_test[X_feat.columns]\ntest_feat_imp = data_test[X_feat_imp.columns]\nprint(test_feat.columns)\nprint(test_feat_imp.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_feat.isnull().sum())\nprint(test_feat_imp.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_feat_imputed = test_feat.fillna(test_feat.mean(),inplace=False)\ntest_feat_imp_imputed = test_feat_imp.fillna(test_feat_imp.mean(),inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_feat_imputed.isnull().sum())\nprint(test_feat_imp_imputed.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = StandardScaler()\ntest_feat_scaled = ss.fit_transform(test_feat_imputed)\ntest_feat_imp_scaled = ss.fit_transform(test_feat_imp_imputed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_val = RFC.predict(test_feat_scaled)\npredicted_val_imp = RFC_imp.predict(test_feat_imp_scaled)\ndf_val = pd.DataFrame({'loss_as_binary':predicted_val})\ndf_val_imp = pd.DataFrame({'loss_as_binary':predicted_val_imp})\nprint(df_val)\nprint(df_val_imp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_prob = RFC.predict_proba(test_feat_scaled)\npredicted_prob_imp = RFC_imp.predict_proba(test_feat_imp_scaled)\ndf_prob = pd.DataFrame({'no_default': predicted_prob[:, 0], 'default': predicted_prob[:, 1]})\ndf_prob_imp = pd.DataFrame({'no_default': predicted_prob_imp[:, 0], 'default': predicted_prob_imp[:, 1]})\nprint(df_prob)\nprint(df_prob_imp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['id'] = data_test.id\nsubmission['loss_as_binary'] = df_val.loss_as_binary\nsubmission['default_prob'] = round(df_prob.default,2)\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission = submission.to_csv(index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_imp = pd.DataFrame()\nsubmission_imp['id'] = data_test.id\nsubmission_imp['loss_as_binary'] = df_val_imp.loss_as_binary\nsubmission_imp['default_prob'] = round(df_prob_imp.default,2)\nprint(submission_imp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_imp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission_imp = submission_imp.to_csv(index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nos.chdir(r'/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(r'SUBMISSION.csv',index=False)\nsubmission_imp.to_csv(r'SUBMISSION_imp.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'SUBMISSION.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(r'SUBMISSION_imp.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}