{"cells":[{"metadata":{"id":"3t9QJ8Sy1joO","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.linear_model import LogisticRegression\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"B_LLFXRqE6Nh","outputId":"5041005c-7b8d-4af9-9cdc-f13a1f0ad71e","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-default-prediction/train_v2.csv.zip')\ntest = pd.read_csv('../input/loan-default-prediction/test_v2.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"id":"G3vNhGxs2k3x","outputId":"b74749c6-8984-4418-90ea-48ecbf0c785a","scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing"},{"metadata":{"id":"5XCLNdFdKsqc","outputId":"249cd198-f189-4d1d-f128-ed90ad4c0d77","trusted":true},"cell_type":"code","source":"#checking the percentage of missing variables and printing out the names of the variables that are missing\nfor col in df.columns:\n    pct_missing = np.mean(df[col].isnull())\n    if (round(pct_missing*100)) != 0.0:\n        print('{} - {}%'.format(col, round(pct_missing*100)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##checking the percentage of missing variables and printing out the names of the variables that are missing in the test df\nfor col in test.columns:\n    pct_missing = np.mean(test[col].isnull())\n    if (round(pct_missing*100)) != 0.0:\n        print('{} - {}%'.format(col, round(pct_missing*100)))","execution_count":null,"outputs":[]},{"metadata":{"id":"f3Qd7KxxK7RF","outputId":"36dac2ba-2932-4f52-fc87-560e5488a0e9","trusted":true},"cell_type":"code","source":"#dealing with missing variables\ndf_numeric = df.select_dtypes(include=[np.number])\nnumeric_cols = df_numeric.columns.values\n\nfor col in numeric_cols:\n    missing = df[col].isnull()\n    num_missing = np.sum(missing)\n    \n    if num_missing > 0:\n        df['{}_ismissing'.format(col)] = missing\n        med = df[col].median()\n        df[col] = df[col].fillna(med)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dealing with missing variables in the test df\ntest_numeric = test.select_dtypes(include=[np.number])\ntest_numeric_cols = test_numeric.columns.values\n\nfor col in test_numeric_cols:\n    missing = test[col].isnull()\n    num_missing = np.sum(missing)\n    \n    if num_missing > 0:\n        test['{}_ismissing'.format(col)] = missing\n        med = test[col].median()\n        test[col] = test[col].fillna(med)","execution_count":null,"outputs":[]},{"metadata":{"id":"bRi2cfhpK-iG","outputId":"37fad973-2060-4437-e07e-0ecb4bb9d0d5","trusted":true},"cell_type":"code","source":"#checking the percentage of missing variables after dealing with numerical missing variables\nfor col in df.columns:\n    pct_missing = np.mean(df[col].isnull())\n    if (round(pct_missing*100)) != 0.0:\n        print('{} - {}%'.format(col, round(pct_missing*100)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the percentage of missing variables after dealing with numerical missing variables in the test df\nfor col in test.columns:\n    pct_missing = np.mean(test[col].isnull())\n    if (round(pct_missing*100)) != 0.0:\n        print('{} - {}%'.format(col, round(pct_missing*100)))","execution_count":null,"outputs":[]},{"metadata":{"id":"cWIN4m2LLBpM","trusted":true},"cell_type":"code","source":"#dropping irrelavant columns about the fact of missing\ndf.drop(df.iloc[:, 771:1284], inplace = True, axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping irrelavant columns about the fact of missing in the test df\ntest.drop(test.iloc[:, 770:1288], inplace = True, axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"id":"he9qCPJVLFGr","trusted":true},"cell_type":"code","source":"# Creating a correlation matrix and visualizing it\ncorr_matrix = df.corr().abs()\nsns.heatmap(df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping correlated columns in the df\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\ndf.drop(to_drop, axis=1, inplace=True)\n#also dropping these columns in the test df\ntest.drop(to_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Yq8VjZH_LVQG","trusted":true},"cell_type":"code","source":"#making a column stating whether a loss happened or not\ndf['loss_fact'] = df['loss']\n\nloss_fact = df['loss']\n\nfor i in loss_fact:\n    if i != 0:\n        loss_fact = loss_fact.replace(i, 1)\n        \ndf['loss_fact'] = loss_fact\n#train['loss_fact'] = train['loss'].apply(lambda x: 0 if x==0 else 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"yfsovQTeLi92","outputId":"60d6dad4-db9c-4862-dc7b-139191f8f4e0","trusted":true},"cell_type":"code","source":"df['loss'].describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"lhMjNeBELWtO","outputId":"72f719ba-76c4-4eb0-f956-b1a58e0dffaa","trusted":true},"cell_type":"code","source":"sns.distplot(df['loss'], hist=True, kde=False, \n             bins=int(180/5), color = 'blue',\n             hist_kws={'edgecolor':'black'})\n\nplt.title('Loss Distribution')\nplt.xlabel('Loss (in %)')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"id":"KQOEVJWWLeqp","outputId":"b1fedc99-0de3-4e77-aa73-158a0f4bb82d","trusted":true},"cell_type":"code","source":"df['loss_fact'].describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"RV7JpytALeQI","outputId":"718f6b5d-3c6b-475e-da82-feb576db830f","trusted":true},"cell_type":"code","source":"sns.distplot(df['loss_fact'], hist=True, kde=False, \n             bins=int(180/5), color = 'blue',\n             hist_kws={'edgecolor':'black'})\n\nplt.title('Loss Fact')\nplt.xlabel('Loss Happened or Not')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"id":"-5t1vhfx5H8E"},"cell_type":"markdown","source":"Building ML models"},{"metadata":{"id":"sbyH-ads8Tdn","trusted":true},"cell_type":"code","source":"#Training on float64","execution_count":null,"outputs":[]},{"metadata":{"id":"fEVTCmoA4ylb","trusted":true},"cell_type":"code","source":"trainfloatloss = pd.concat([df.select_dtypes(include=[np.float64]), df['loss_fact']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfloat = test.select_dtypes(include=[np.float64])","execution_count":null,"outputs":[]},{"metadata":{"id":"FPWC3tsK44st","trusted":true},"cell_type":"code","source":"#trainfloatlossdna = trainfloatloss.dropna(how='any')","execution_count":null,"outputs":[]},{"metadata":{"id":"jn7I5uI8pCGl","trusted":true},"cell_type":"code","source":"float_columns = [c for c in trainfloatloss.columns if trainfloatloss[c].dtype.name == 'float64']\n#print('float_columns:', float_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_float_train = testfloat\ntest_float_train = test_float_train.drop('f5', axis = 1)\ntest_float_train = test_float_train.drop('f531', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"float_columns_test = [c for c in testfloat.columns if testfloat[c].dtype.name == 'float64']\nfloat_columns_test.remove('f5')\nfloat_columns_test.remove('f531')\n#print('float_columns:', float_columns_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"7KceXuEXhhGw","trusted":true},"cell_type":"code","source":"for c in float_columns:\n    trainfloatloss[trainfloatloss[c].name + '_no_out'] = trainfloatloss[c]\n    loss_fact0_float = trainfloatloss[trainfloatloss['loss_fact'] == 0][c]\n    loss_fact1_float = trainfloatloss[trainfloatloss['loss_fact'] == 1][c]\n    loss_fact0_float_no_out = loss_fact0_float[~(loss_fact0_float > loss_fact0_float.mean() + 2*loss_fact0_float.std())]\n    loss_fact1_float_no_out = loss_fact1_float[~(loss_fact1_float > loss_fact1_float.mean() + 2*loss_fact1_float.std())]\n    trainfloatloss[trainfloatloss[c].name + '_no_out'] = loss_fact0_float_no_out.append(loss_fact1_float_no_out)","execution_count":null,"outputs":[]},{"metadata":{"id":"GpuGa3Dmhire","trusted":true},"cell_type":"code","source":"trainfloatloss[['f756_no_out']].isna().values.sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"dNxguXmChjDB","trusted":true},"cell_type":"code","source":"sns.violinplot(x='loss_fact', y='f756_no_out', data=trainfloatloss)","execution_count":null,"outputs":[]},{"metadata":{"id":"1dLwfCdV2Ne5","trusted":true},"cell_type":"code","source":"sns.violinplot(x='loss_fact', y='f756', data=trainfloatloss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainfloatlossdna = trainfloatloss.dropna(how='any')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainfloatlossdnanoout = pd.concat([trainfloatlossdna.filter(regex='no_out'), trainfloatlossdna['loss_fact']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"VGHDPInH2N70","trusted":true},"cell_type":"code","source":"X= trainfloatlossdnanoout.drop(['loss_fact'], axis=1)\ny= trainfloatlossdnanoout['loss_fact']","execution_count":null,"outputs":[]},{"metadata":{"id":"bRYpJ62EcznK","trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=17) ","execution_count":null,"outputs":[]},{"metadata":{"id":"IJADDKKw2ONK","trusted":true},"cell_type":"code","source":"X_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"bBTBoDPg2Obr","trusted":true},"cell_type":"code","source":"first_tree = DecisionTreeClassifier(random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"id":"WBeC6nrQ2Ood","trusted":true},"cell_type":"code","source":"np.mean(cross_val_score(first_tree, X_train, y_train, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"id":"X8S1RF_GhjQ2","trusted":true},"cell_type":"code","source":"first_knn = KNeighborsClassifier()","execution_count":null,"outputs":[]},{"metadata":{"id":"QGrPOZ_t5vif","trusted":true},"cell_type":"code","source":"np.mean(cross_val_score(first_knn, X_train, y_train, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bernoulli Naive Bayes Classifier\ndef bernoulli_naive_bayes(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    model = BernoulliNB(binarize = 0.01)\n    classifier = model.fit(X_train,y_train)\n    predict = classifier.predict(X_test)\n    cm = confusion_matrix(predict,y_test)\n    accuracy = cm.trace()/cm.sum()\n    acc.append(accuracy)\n    \n#     print('Accuracy:', format(accuracy, '.2f'))\n#     print('Confusion Matrix:', '\\n', confusion_matrix(predict,y_test))\n#     print('Classification Report:', '\\n', classification_report(predict,y_test))\n    \nprint('Bernoulli Naive Bayes Classifier')\nacc = []\nfor i in range(20):\n    bernoulli_naive_bayes(X, y)\n    \nacc_ = np.array(acc)\nprint('Average accuracy in 20 iterations is:', np.average(acc_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\ndef logistic_regression(X,y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n    classifier = model.fit(X_train,y_train)\n    predict = classifier.predict(X_test)\n    cm = confusion_matrix(predict,y_test)\n    accuracy = cm.trace()/cm.sum()\n    acc.append(accuracy)\n    \n#     print('Accuracy:', format(accuracy, '.2f'))\n#     print('Confusion Matrix:', '\\n', confusion_matrix(predict,y_test))\n#     print('Classification Report:', '\\n', classification_report(predict,y_test))\n    \nprint('Logistic Regression')\nacc = []\nfor i in range(20):\n    logistic_regression(X,y)\n    \nacc_ = np.array(acc)\nprint('Average accuracy in 20 iterations is:', np.average(acc_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nmodel = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\nclassifier = model.fit(X_train,y_train)\npredict = classifier.predict(X_test)\ncm = confusion_matrix(predict,y_test)\naccuracy = cm.trace()/cm.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_to_submission_file(predicted_labels, out_file, train_num=105471,\n                    target='loss', index_label=\"id\"):\n    #turning predictions into a data frame and saving them as a csv file\n    predicted_df = pd.DataFrame(predicted_labels,\n                                index = np.arange(train_num + 1,\n                                                  train_num + 1 +\n                                                  predicted_labels.shape[0]),\n                                columns=[target])\n    predicted_df.to_csv(out_file, index_label=index_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.predict(test_float_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_to_submission_file(classifier.predict(test_float_train), out_file=\"logistic_regression_loan_default_prediction.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"4WppEg2g54pJ","trusted":true},"cell_type":"code","source":"#Training on int64","execution_count":null,"outputs":[]},{"metadata":{"id":"0bBCNoLH5wRG","trusted":true},"cell_type":"code","source":"X= df.select_dtypes(include=[np.int64]).drop(['loss', 'loss_fact'], axis=1)\ny= df['loss_fact']","execution_count":null,"outputs":[]},{"metadata":{"id":"HprwPYtu6rNP","trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=17) ","execution_count":null,"outputs":[]},{"metadata":{"id":"YkgkHgZB6sOz","trusted":true},"cell_type":"code","source":"X_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bernoulli Naive Bayes Classifier\ndef bernoulli_naive_bayes(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    model = BernoulliNB(binarize = 0.01)\n    classifier = model.fit(X_train,y_train)\n    predict = classifier.predict(X_test)\n    cm = confusion_matrix(predict,y_test)\n    accuracy = cm.trace()/cm.sum()\n    acc.append(accuracy)\n    \n#     print('Accuracy:', format(accuracy, '.2f'))\n#     print('Confusion Matrix:', '\\n', confusion_matrix(predict,y_test))\n#     print('Classification Report:', '\\n', classification_report(predict,y_test))\n    \nprint('Bernoulli Naive Bayes Classifier')\nacc = []\nfor i in range(20):\n    bernoulli_naive_bayes(X, y)\n    \nacc_ = np.array(acc)\nprint('Average accuracy in 20 iterations is:', np.average(acc_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\ndef logistic_regression(X,y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    model = LogisticRegression(penalty='l2', solver='sag', max_iter=1000)\n    classifier = model.fit(X_train,y_train)\n    predict = classifier.predict(X_test)\n    cm = confusion_matrix(predict,y_test)\n    accuracy = cm.trace()/cm.sum()\n    acc.append(accuracy)\n    \n#     print('Accuracy:', format(accuracy, '.2f'))\n#     print('Confusion Matrix:', '\\n', confusion_matrix(predict,y_test))\n#     print('Classification Report:', '\\n', classification_report(predict,y_test))\n    \nprint('Logistic Regression')\nacc = []\nfor i in range(20):\n    logistic_regression(X,y)\n    \nacc_ = np.array(acc)\nprint('Average accuracy in 20 iterations is:', np.average(acc_))","execution_count":null,"outputs":[]},{"metadata":{"id":"kP-iqxV96sel","trusted":true},"cell_type":"code","source":"first_tree = DecisionTreeClassifier(random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"id":"y8mmeXTx6sqG","trusted":true},"cell_type":"code","source":"np.mean(cross_val_score(first_tree, X_train, y_train, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"id":"AtMlMS846s1e","trusted":true},"cell_type":"code","source":"first_knn = KNeighborsClassifier()","execution_count":null,"outputs":[]},{"metadata":{"id":"s8fLZimW6-Pr","trusted":true},"cell_type":"code","source":"np.mean(cross_val_score(first_knn, X_train, y_train, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"id":"8DtjQSSi6-f0","trusted":true},"cell_type":"code","source":"tree_params = {'max_depth': np.arange(1,11), 'max_features': [.5,.7,1]}","execution_count":null,"outputs":[]},{"metadata":{"id":"WNi8qFjJ6s_o","trusted":true},"cell_type":"code","source":"tree_grid = GridSearchCV(first_tree, tree_params, cv=5, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"id":"2mxS0bDW6tIc","trusted":true},"cell_type":"code","source":"%%time \ntree_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"4JojppdS6-xW","trusted":true},"cell_type":"code","source":"tree_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"id":"fY5Gl9_A7O_r","trusted":true},"cell_type":"code","source":"tree_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"id":"9OzM7BlJ6--z","trusted":true},"cell_type":"code","source":"#knn_params = {'n_neighbors':[1,2,3,4,]+ list(range(10,100,10))} ","execution_count":null,"outputs":[]},{"metadata":{"id":"9bRhv_fi6_K9","trusted":true},"cell_type":"code","source":"knn_params = {'n_neighbors':range(10,30,1)} ","execution_count":null,"outputs":[]},{"metadata":{"id":"XxzKNDGy7PU-","trusted":true},"cell_type":"code","source":"knn_grid = GridSearchCV(first_knn, knn_params, cv=5)","execution_count":null,"outputs":[]},{"metadata":{"id":"zgo8A2Rd7Pmc","trusted":true},"cell_type":"code","source":"%%time \nknn_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"_qBtPoVY7ePn","trusted":true},"cell_type":"code","source":"knn_grid.best_score_, knn_grid.best_params_ ","execution_count":null,"outputs":[]},{"metadata":{"id":"Sh3k7f037efX","trusted":true},"cell_type":"code","source":"tree_grid.best_estimator_ ","execution_count":null,"outputs":[]},{"metadata":{"id":"twyYD2xV7erN","trusted":true},"cell_type":"code","source":"tree_grid.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"id":"lUygOswH7e3J","trusted":true},"cell_type":"code","source":"tree_valid_pred = tree_grid.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"id":"GC6NfQ5C7fCi","trusted":true},"cell_type":"code","source":"tree_grid.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"id":"y8itw17E7fNi","trusted":true},"cell_type":"code","source":"1 - np.mean(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"WNJLnCOV7pdO","trusted":true},"cell_type":"code","source":"export_graphviz(tree_grid.best_estimator_, out_file='loan_tree.dot', feature_names=X.columns, filled=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"g5DYXrbD7pqt","trusted":true},"cell_type":"code","source":"#!ls *.dot\n!dot -Tpng loan_tree.dot -o loan_tree.png","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}