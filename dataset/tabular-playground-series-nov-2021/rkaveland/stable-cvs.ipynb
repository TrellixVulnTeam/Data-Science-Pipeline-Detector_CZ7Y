{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nfrom tqdm.notebook import trange\n\nrandom.seed(42)\nnp.random.seed(42)\ncv = StratifiedKFold(5, shuffle=True)\n\ndroot = os.environ.get('KAGGLE_DIR', '../input')\nold_y = pd.read_csv(\n    f'{droot}/november21/train.csv', usecols=['target']\n).target.astype(np.float32).to_numpy()\ntrain = pd.read_csv(\n    f'{droot}/tabular-playground-series-nov-2021/train.csv', dtype=np.float32\n).drop(columns=['id'])\nX, new_y = StandardScaler().fit_transform(train.drop(columns=['target'])), train.target","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-22T09:58:37.903477Z","iopub.execute_input":"2021-11-22T09:58:37.90534Z","iopub.status.idle":"2021-11-22T09:58:50.651787Z","shell.execute_reply.started":"2021-11-22T09:58:37.905282Z","shell.execute_reply":"2021-11-22T09:58:50.650782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Achieve stable CV scores\n==\n\nIn which we [use the old labels](https://www.kaggle.com/criskiev/november21) to get very stable CV scores. What I mean by stable CV score, is that all the splits achieve roughly the same score -- as opposed to having 1 out of 5 splits score, say, `.753`, but the rest score, say `.748`. \n\nWe'll do this experiment in a very simple way -- we'll just use the pre-flip labels as our predictions. We already know that this should score around `.7486`, so let's check what our CVs are for that:","metadata":{}},{"cell_type":"code","source":"clf = LogisticRegression()\n\ndef clf_pred(train_idx, val_idx):\n    clf.fit(X[train_idx], new_y[train_idx])\n    return clf.decision_function(X[val_idx])\n\ndef old_pred(train_idx, val_idx):\n    return old_y[val_idx]\n\ndef auc_cvs(stratify=new_y, predict=old_pred):\n    return np.array([\n        roc_auc_score(new_y[val_idx], predict(train_idx, val_idx)) \n        for train_idx, val_idx in cv.split(X, stratify)\n    ])\n\nscores = auc_cvs()\nscores","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:58:50.653323Z","iopub.execute_input":"2021-11-22T09:58:50.653592Z","iopub.status.idle":"2021-11-22T09:58:50.978499Z","shell.execute_reply.started":"2021-11-22T09:58:50.65356Z","shell.execute_reply":"2021-11-22T09:58:50.977567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The example here is typical for what we want to avoid, there's a huge difference between the best and worst split, and none of them are even very close to the real score of this prediction:","metadata":{}},{"cell_type":"code","source":"diff = scores.max() - scores.min()\nreal_score = roc_auc_score(new_y, old_y)\nprint(f'max() - min() = {diff:.4f}, std() = {scores.std():.4f}, real auc = {real_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:00:34.15094Z","iopub.execute_input":"2021-11-22T10:00:34.151219Z","iopub.status.idle":"2021-11-22T10:00:34.322862Z","shell.execute_reply.started":"2021-11-22T10:00:34.151188Z","shell.execute_reply":"2021-11-22T10:00:34.32198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's repeat this, but stratify by whether the label was flipped or not (`old != new`):","metadata":{}},{"cell_type":"code","source":"scores = auc_cvs(new_y != old_y)\nscores","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:01:28.018574Z","iopub.execute_input":"2021-11-22T10:01:28.019295Z","iopub.status.idle":"2021-11-22T10:01:28.307576Z","shell.execute_reply.started":"2021-11-22T10:01:28.019254Z","shell.execute_reply":"2021-11-22T10:01:28.306701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diff = scores.max() - scores.min()\nreal_score = roc_auc_score(new_y, old_y)\nprint(f'max() - min() = {diff:.4f}, std() = {scores.std():.4f}, real auc = {real_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:01:28.726773Z","iopub.execute_input":"2021-11-22T10:01:28.727094Z","iopub.status.idle":"2021-11-22T10:01:28.895003Z","shell.execute_reply.started":"2021-11-22T10:01:28.72706Z","shell.execute_reply":"2021-11-22T10:01:28.894031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's a fairly big change. But does this also affect real models? We've not been doing any training. Well, I think this should also affect real models, so let's try running a few tests:","metadata":{}},{"cell_type":"code","source":"spread_stratify_label = np.concatenate([auc_cvs(predict=clf_pred) for _ in trange(10)])\nspread_stratify_flipped = np.concatenate([auc_cvs(new_y != old_y, predict=clf_pred) for _ in trange(10)])\n\nff.create_distplot(\n    [spread_stratify_label, spread_stratify_flipped],\n    ['stratify=target', 'stratify=target != old_target'],\n    bin_size=.00025, show_curve=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:03:48.417255Z","iopub.execute_input":"2021-11-22T10:03:48.417545Z","iopub.status.idle":"2021-11-22T10:06:21.225029Z","shell.execute_reply.started":"2021-11-22T10:03:48.417504Z","shell.execute_reply":"2021-11-22T10:06:21.22408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of these cases is clearly less spread out, as we could also see by comparing std:","metadata":{}},{"cell_type":"code","source":"spread_stratify_flipped.std(), spread_stratify_label.std()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:06:50.642589Z","iopub.execute_input":"2021-11-22T10:06:50.642854Z","iopub.status.idle":"2021-11-22T10:06:50.649432Z","shell.execute_reply.started":"2021-11-22T10:06:50.642825Z","shell.execute_reply":"2021-11-22T10:06:50.648464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It might look like stratifying by `target` creates a better-performing classifier. Is that the case, though? Let's plot the spread of the mean CV scores:","metadata":{}},{"cell_type":"code","source":"ff.create_distplot(\n    [spread_stratify_label.reshape(-1, 5).mean(axis=1), spread_stratify_flipped.reshape(-1, 5).mean(axis=1)],\n    ['stratify=target', 'stratify=target != old_target'],\n    bin_size=.00025, show_curve=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:12:00.194131Z","iopub.execute_input":"2021-11-22T10:12:00.194756Z","iopub.status.idle":"2021-11-22T10:12:00.215226Z","shell.execute_reply.started":"2021-11-22T10:12:00.19471Z","shell.execute_reply":"2021-11-22T10:12:00.214338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, no. It looks like we receive the same OOF predictions from these, the differences are so small that it could easily just be some kind of accumulated rounding error.","metadata":{}}]}