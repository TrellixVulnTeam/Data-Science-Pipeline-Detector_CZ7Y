{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" # November TPS - Building an Ensemble","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelBinarizer, MinMaxScaler\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-11-09T22:12:56.232763Z","iopub.execute_input":"2021-11-09T22:12:56.233241Z","iopub.status.idle":"2021-11-09T22:12:56.239719Z","shell.execute_reply.started":"2021-11-09T22:12:56.233203Z","shell.execute_reply":"2021-11-09T22:12:56.238852Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Intel Scikit-learn Patch\nSource: https://intel.github.io/scikit-learn-intelex/","metadata":{}},{"cell_type":"code","source":"# Use this line to install Intel's update to library if needed\n!pip install scikit-learn-intelex --progress-bar off >> /tmp/pip_sklearnex.log\n\n# Can give a small (or large) boost to speed depending on the available processor\nfrom sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T20:46:38.044336Z","iopub.execute_input":"2021-11-09T20:46:38.044599Z","iopub.status.idle":"2021-11-09T20:47:07.641193Z","shell.execute_reply.started":"2021-11-09T20:46:38.044566Z","shell.execute_reply":"2021-11-09T20:47:07.639486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting Competition Data\n\nThe target column contains 'True' and 'False' values instead of 1 and 0, so LabelBinarizer is used to process it. Also the features and target columns are separated into the variables X and y.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv', index_col=False).drop(columns=['id'])\n\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv')\ntest_ids = test_df.id\ntest_df.drop(columns=['id'], inplace=True)\n\nlb = LabelBinarizer() # Need to map target values (true and false) into 1's and 0's\ndf['target'] = np.ravel(lb.fit_transform(df['target'])) # ravel makes y a 1d vector instead of a column vector\n\ncontinuous_cols = list(df.columns[:-1]) # All columns are continuous besides 'target', which is a binary label\n\ny = df.target\nX = df.drop(columns=['target']).to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T21:14:56.550255Z","iopub.execute_input":"2021-11-09T21:14:56.55055Z","iopub.status.idle":"2021-11-09T21:15:14.338533Z","shell.execute_reply.started":"2021-11-09T21:14:56.550507Z","shell.execute_reply":"2021-11-09T21:15:14.337721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using Cross Validation will give us a better idea of whether a parameter change or preprocessing step has improved the model. The evaluate_model function performs multiple cross validations, which gives us more consistent scores to compare models and sets of parameters.","metadata":{}},{"cell_type":"code","source":"def evaluate_model(X, y, model):\n    cv_method = RepeatedStratifiedKFold(n_splits=5, n_repeats=2)\n    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv_method, error_score='raise')\n    return scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Baseline XGBoost","metadata":{}},{"cell_type":"code","source":"xgb = XGBClassifier(n_estimators=100, tree_method='gpu_hist', gpu_id=0, eval_metric='auc', use_label_encoder=False, verbosity=0)\nprint(\"Cross Validation Score: \", np.mean(evaluate_model(X, y, xgb)))","metadata":{"execution":{"iopub.status.busy":"2021-11-09T20:53:13.929455Z","iopub.execute_input":"2021-11-09T20:53:13.930321Z","iopub.status.idle":"2021-11-09T20:53:45.893852Z","shell.execute_reply.started":"2021-11-09T20:53:13.93028Z","shell.execute_reply":"2021-11-09T20:53:45.89306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding scaling and tuning parameters\n\nThe XGB model for the ensemble has the same parameters as the one defined in this next code cell.","metadata":{}},{"cell_type":"code","source":"p = Pipeline([\n    ('scale', MinMaxScaler()),\n    ('model', XGBClassifier(n_estimators=200, max_depth=4, reg_lambda=60, reg_alpha=60,\n                            tree_method='gpu_hist', gpu_id=0, eval_metric='auc', use_label_encoder=False))\n])\n\nprint(\"Score: \", np.mean(evaluate_model(X, y, p)))","metadata":{"execution":{"iopub.status.busy":"2021-11-09T22:55:51.225581Z","iopub.execute_input":"2021-11-09T22:55:51.225991Z","iopub.status.idle":"2021-11-09T22:56:26.499878Z","shell.execute_reply.started":"2021-11-09T22:55:51.22595Z","shell.execute_reply":"2021-11-09T22:56:26.499198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best params so far:\n\nXGBClassifier(n_estimators=200, max_depth=4, reg_lambda=60, reg_alpha=60,\n                            tree_method='gpu_hist', gpu_id=0, eval_metric='auc', use_label_encoder=False)","metadata":{}},{"cell_type":"markdown","source":"## Building the Ensemble","metadata":{}},{"cell_type":"markdown","source":"#### Logistic Regression","metadata":{}},{"cell_type":"code","source":"p_2 = Pipeline([\n    ('scale', MinMaxScaler()),\n    ('logr', LogisticRegression(solver='sag', n_jobs=-1))\n])\n\nprint(\"Score: \", np.mean(evaluate_model(X, y, p_2)))","metadata":{"execution":{"iopub.status.busy":"2021-11-09T20:58:22.825812Z","iopub.execute_input":"2021-11-09T20:58:22.826528Z","iopub.status.idle":"2021-11-09T21:01:26.942545Z","shell.execute_reply.started":"2021-11-09T20:58:22.826486Z","shell.execute_reply":"2021-11-09T21:01:26.941542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the 'sag' solver because the scikit-learn documentation it is recommended with medium to large size datasets. The default solver is much slower to train. With default parameters otherwise, this model performs the best.","metadata":{}},{"cell_type":"code","source":"p_2.fit(X, y)\npd.DataFrame({'id': test_ids, 'target': p_2.predict_proba(test_df)[:,1]}).to_csv('logregr_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T21:34:15.23646Z","iopub.execute_input":"2021-11-09T21:34:15.237011Z","iopub.status.idle":"2021-11-09T21:34:17.326408Z","shell.execute_reply.started":"2021-11-09T21:34:15.236973Z","shell.execute_reply":"2021-11-09T21:34:17.325662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Naive Bayes\n\nI experimented with adding naive bayes but it did not improve the ensemble's score. I may try to experiment with the parameters, but it may be more worthwile finding other models that can score above 0.73 without tuning.","metadata":{}},{"cell_type":"code","source":"p_3 = Pipeline([\n    ('scale', MinMaxScaler([0,1])), # Naive Bayes' input can't contain negative values, so scale to positive range\n    ('nb', MultinomialNB())\n])\n\nprint(\"Score: \", np.mean(evaluate_model(X, y, p_3)))","metadata":{"execution":{"iopub.status.busy":"2021-11-09T22:28:33.403596Z","iopub.execute_input":"2021-11-09T22:28:33.40466Z","iopub.status.idle":"2021-11-09T22:28:45.125389Z","shell.execute_reply.started":"2021-11-09T22:28:33.40461Z","shell.execute_reply":"2021-11-09T22:28:45.122491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Voting Ensemble\n\nFirst the list of estimators needs to be created. Add more models to this list to try different ensembles.","metadata":{}},{"cell_type":"code","source":"to_ens = [('xgb', XGBClassifier(n_estimators=200, max_depth=4, reg_lambda=60, reg_alpha=60, tree_method='gpu_hist', gpu_id=0, \n                        eval_metric='auc', use_label_encoder=False)),\n          ('logr', LogisticRegression(solver='sag', n_jobs=-1))]","metadata":{"execution":{"iopub.status.busy":"2021-11-09T22:48:11.503079Z","iopub.execute_input":"2021-11-09T22:48:11.503367Z","iopub.status.idle":"2021-11-09T22:48:11.508056Z","shell.execute_reply.started":"2021-11-09T22:48:11.503334Z","shell.execute_reply":"2021-11-09T22:48:11.50739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pipe = Pipeline([\n    ('scale', MinMaxScaler()),\n    ('ensemble', VotingClassifier(to_ens, voting='soft'))\n])\n\nprint(\"Score: \", np.mean(evaluate_model(X, y, final_pipe)))","metadata":{"execution":{"iopub.status.busy":"2021-11-09T22:52:51.338776Z","iopub.execute_input":"2021-11-09T22:52:51.339051Z","iopub.status.idle":"2021-11-09T22:55:51.224098Z","shell.execute_reply.started":"2021-11-09T22:52:51.339013Z","shell.execute_reply":"2021-11-09T22:55:51.223333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ensemble of estimators is not an improvement over all individual estimators. Next step: tuning XGBoost and adding more models to the ensemble. \n\n#### The predictions for LogisticRegression are the current submission for this version of this notebook. \n\n### Thanks for reading!","metadata":{}},{"cell_type":"code","source":"final_pipe.fit(X, y)\npd.DataFrame({'id': test_ids, 'target': final_pipe.predict_proba(test_df)[:,1]}).to_csv('ensemble_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T20:16:02.592818Z","iopub.execute_input":"2021-11-09T20:16:02.593073Z","iopub.status.idle":"2021-11-09T20:16:04.241085Z","shell.execute_reply.started":"2021-11-09T20:16:02.593044Z","shell.execute_reply":"2021-11-09T20:16:04.240221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}