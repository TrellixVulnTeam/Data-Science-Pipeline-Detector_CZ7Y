{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-07T12:20:28.226187Z","iopub.execute_input":"2021-11-07T12:20:28.226628Z","iopub.status.idle":"2021-11-07T12:20:28.233826Z","shell.execute_reply.started":"2021-11-07T12:20:28.226589Z","shell.execute_reply":"2021-11-07T12:20:28.233174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport shap\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom warnings import filterwarnings\n\nfilterwarnings(\"ignore\", category=DeprecationWarning) \nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:22:13.471448Z","iopub.execute_input":"2021-11-07T12:22:13.472256Z","iopub.status.idle":"2021-11-07T12:22:13.483408Z","shell.execute_reply.started":"2021-11-07T12:22:13.472209Z","shell.execute_reply":"2021-11-07T12:22:13.482574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:20:32.237262Z","iopub.execute_input":"2021-11-07T12:20:32.237491Z","iopub.status.idle":"2021-11-07T12:21:02.455425Z","shell.execute_reply.started":"2021-11-07T12:20:32.237464Z","shell.execute_reply":"2021-11-07T12:21:02.454303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:21:02.45682Z","iopub.execute_input":"2021-11-07T12:21:02.457072Z","iopub.status.idle":"2021-11-07T12:21:02.593691Z","shell.execute_reply.started":"2021-11-07T12:21:02.457043Z","shell.execute_reply":"2021-11-07T12:21:02.592734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:21:02.595603Z","iopub.execute_input":"2021-11-07T12:21:02.595828Z","iopub.status.idle":"2021-11-07T12:21:02.75013Z","shell.execute_reply.started":"2021-11-07T12:21:02.595801Z","shell.execute_reply":"2021-11-07T12:21:02.749291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()\n# all float columns except id and target means no categorical columns","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:21:02.751459Z","iopub.execute_input":"2021-11-07T12:21:02.751744Z","iopub.status.idle":"2021-11-07T12:21:02.776829Z","shell.execute_reply.started":"2021-11-07T12:21:02.751713Z","shell.execute_reply":"2021-11-07T12:21:02.775956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = train.drop(['id','target'],axis=1)\ny_train = train['target']","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:21:02.778538Z","iopub.execute_input":"2021-11-07T12:21:02.779064Z","iopub.status.idle":"2021-11-07T12:21:02.952556Z","shell.execute_reply.started":"2021-11-07T12:21:02.779018Z","shell.execute_reply":"2021-11-07T12:21:02.951607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_noisy_samples(X,y,thres=.5): #Returns noisy indexes\n    rf = RandomForestClassifier(oob_score=True,n_jobs=-1).fit(X,y)\n    noise_prob = 1 - rf.oob_decision_function_[range(len(y)),y]\n    return noise_prob>thres","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:39:32.783764Z","iopub.execute_input":"2021-11-07T12:39:32.784098Z","iopub.status.idle":"2021-11-07T12:39:32.790788Z","shell.execute_reply.started":"2021-11-07T12:39:32.784061Z","shell.execute_reply":"2021-11-07T12:39:32.789512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nnoise = detect_noisy_samples(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:39:34.293691Z","iopub.execute_input":"2021-11-07T12:39:34.294572Z","iopub.status.idle":"2021-11-07T12:47:20.035299Z","shell.execute_reply.started":"2021-11-07T12:39:34.294525Z","shell.execute_reply":"2021-11-07T12:47:20.034349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_idx =[]\nfor idx,boo in enumerate(noise):\n    if boo:\n        noise_idx.append(idx)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:47:20.037549Z","iopub.execute_input":"2021-11-07T12:47:20.037914Z","iopub.status.idle":"2021-11-07T12:47:20.176513Z","shell.execute_reply.started":"2021-11-07T12:47:20.037853Z","shell.execute_reply":"2021-11-07T12:47:20.175625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %percentage of noise in our dataset(It will have also added some clean data in it too)\nprint(f\"noise = {len(noise_idx)/len(noise) *100}%\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:47:20.177705Z","iopub.execute_input":"2021-11-07T12:47:20.177968Z","iopub.status.idle":"2021-11-07T12:47:20.183172Z","shell.execute_reply.started":"2021-11-07T12:47:20.177935Z","shell.execute_reply":"2021-11-07T12:47:20.182233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing noise rows\ntrain.drop(noise_idx,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:51:03.934875Z","iopub.execute_input":"2021-11-07T12:51:03.935857Z","iopub.status.idle":"2021-11-07T12:51:04.208483Z","shell.execute_reply.started":"2021-11-07T12:51:03.935811Z","shell.execute_reply":"2021-11-07T12:51:04.207773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:51:04.986383Z","iopub.execute_input":"2021-11-07T12:51:04.987035Z","iopub.status.idle":"2021-11-07T12:51:05.091997Z","shell.execute_reply.started":"2021-11-07T12:51:04.987002Z","shell.execute_reply":"2021-11-07T12:51:05.091191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = train.drop(['id','target'],axis=1)\ny_train = train['target']\n\nx_cols = x_train.columns\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_train = pd.DataFrame(data = x_train, columns=x_cols)\nx_train","metadata":{"execution":{"iopub.status.busy":"2021-11-07T12:51:09.068204Z","iopub.execute_input":"2021-11-07T12:51:09.068513Z","iopub.status.idle":"2021-11-07T12:51:10.085449Z","shell.execute_reply.started":"2021-11-07T12:51:09.068479Z","shell.execute_reply":"2021-11-07T12:51:10.084385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6,n_estimators=10000, output_process=False):\n    # prepare data\n    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n    # parameters\n    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n        params = {'application':'binary', 'metric':'auc'}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['max_bin'] = int(round(max_depth))\n        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n        params['subsample'] = max(min(subsample, 1), 0)\n                \n        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n        return max(cv_result['auc-mean'])\n     \n    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.001, 0.2),\n                                            'num_leaves': (25, 60),\n                                            'feature_fraction': (0.1, 1),\n                                            'bagging_fraction': (0.5, 1),\n                                           'max_depth': (2, 20),\n                                            'max_bin':(20,90),\n                                            'min_data_in_leaf': (20, 80),\n                                            'min_sum_hessian_in_leaf':(0,100),\n                                           'subsample': (0.01, 1.0)}, random_state=200)\n\n\n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    model_auc=[]\n    for model in range(len( lgbBO.res)):\n        model_auc.append(lgbBO.res[model]['target'])\n    \n    # return best parameters\n    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n\nopt_params = bayes_parameter_opt_lgb(x_train, y_train, init_round=5, opt_round=10, n_folds=5, random_seed=6,n_estimators=10000)","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-11-07T12:51:13.536137Z","iopub.execute_input":"2021-11-07T12:51:13.536833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\nopt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\nopt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\nopt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\nopt_params[1]['objective']='binary'\nopt_params[1]['metric']='auc'\nopt_params[1]['is_unbalance']=True\nopt_params[1]['boost_from_average']=False\nopt_params=opt_params[1]\nopt_params","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:15:01.785878Z","iopub.execute_input":"2021-11-07T07:15:01.786283Z","iopub.status.idle":"2021-11-07T07:15:01.891125Z","shell.execute_reply.started":"2021-11-07T07:15:01.786242Z","shell.execute_reply":"2021-11-07T07:15:01.890149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_train = train.target\nfeatures= [c for c in x_train.columns ]\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=31416)\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=y_train.iloc[trn_idx])\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=y_train.iloc[val_idx])\n\n    num_round = 10000\n    clf = lgb.train(opt_params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 250,)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(y_train, oof)))","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:15:06.34977Z","iopub.execute_input":"2021-11-07T07:15:06.350143Z","iopub.status.idle":"2021-11-07T07:15:06.361974Z","shell.execute_reply.started":"2021-11-07T07:15:06.3501Z","shell.execute_reply":"2021-11-07T07:15:06.360912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_id = test.id\nx_test = test.drop(['id'],axis=1)\n# filling the NaN with mean\nx_test = scaler.transform(x_test)\nx_test = pd.DataFrame(data = x_test, columns=x_cols)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:15:08.669574Z","iopub.execute_input":"2021-11-07T07:15:08.670298Z","iopub.status.idle":"2021-11-07T07:20:23.363945Z","shell.execute_reply.started":"2021-11-07T07:15:08.670252Z","shell.execute_reply":"2021-11-07T07:20:23.363285Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission(model,filename):\n    pred = model.predict(x_test, num_iteration=model.best_iteration)\n    pred = pd.DataFrame(pred,columns=['target'])\n    sub = pd.concat([test_id,pred],axis=1)\n    sub.set_index('id',inplace=True)\n    sub.to_csv(f\"Submission_file_{filename}.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating submission file\nsubmission(clf,\"Tuned_lgbm\")\npred = pd.DataFrame(predictions,columns=['target'])\nsub = pd.concat([test_id,pred],axis=1)\nsub.set_index('id',inplace=True)\nsub.to_csv(\"Submission_file_Model_raw.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}