{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-07T05:10:59.639613Z","iopub.execute_input":"2021-11-07T05:10:59.640463Z","iopub.status.idle":"2021-11-07T05:10:59.646206Z","shell.execute_reply.started":"2021-11-07T05:10:59.640394Z","shell.execute_reply":"2021-11-07T05:10:59.645379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. quick check on the dataset","metadata":{}},{"cell_type":"code","source":"path = \"../input/tabular-playground-series-nov-2021\"\nsample_submission_df = pd.read_csv(\"{}//sample_submission.csv\".format(path))\ntest_df = pd.read_csv(\"{}//test.csv\".format(path))\ntrain_df = pd.read_csv(\"{}//train.csv\".format(path))","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:10:59.655572Z","iopub.execute_input":"2021-11-07T05:10:59.655867Z","iopub.status.idle":"2021-11-07T05:11:16.748194Z","shell.execute_reply.started":"2021-11-07T05:10:59.655834Z","shell.execute_reply":"2021-11-07T05:11:16.747177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Check the shape of submission data sheet\nsample_submission_df\n\n## -> note: need to remove index column for upload","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:16.74975Z","iopub.execute_input":"2021-11-07T05:11:16.750016Z","iopub.status.idle":"2021-11-07T05:11:16.76601Z","shell.execute_reply.started":"2021-11-07T05:11:16.749986Z","shell.execute_reply":"2021-11-07T05:11:16.764856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop \"id\" columns\ntry:\n    train_X = train_df.drop(\"id\", axis=1)\n    test_X = test_df.drop(\"id\", axis=1)\nexcept KeyError as e:\n    print(e)\n\ntrain_X_wid = train_df\ntest_X_wid = test_df","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:16.767392Z","iopub.execute_input":"2021-11-07T05:11:16.768083Z","iopub.status.idle":"2021-11-07T05:11:17.061017Z","shell.execute_reply.started":"2021-11-07T05:11:16.768036Z","shell.execute_reply":"2021-11-07T05:11:17.060278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_X\ntrain_X","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:17.062611Z","iopub.execute_input":"2021-11-07T05:11:17.063244Z","iopub.status.idle":"2021-11-07T05:11:17.231914Z","shell.execute_reply.started":"2021-11-07T05:11:17.063207Z","shell.execute_reply":"2021-11-07T05:11:17.230981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## check target population\nratio_label = round(float(train_X[\"target\"].value_counts()[0]/train_X[\"target\"].value_counts()[1]),3)\nprint(f\"ratio:{ratio_label}\")\ntrain_df[\"target\"].hist()\n\n##-> almost 50/50 on train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:17.232988Z","iopub.execute_input":"2021-11-07T05:11:17.233225Z","iopub.status.idle":"2021-11-07T05:11:17.494777Z","shell.execute_reply.started":"2021-11-07T05:11:17.233194Z","shell.execute_reply":"2021-11-07T05:11:17.493805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop \"target\" columns for building models\ntry :\n    train_X = train_X.drop(\"target\", axis=1)\nexcept KeyError as e:\n    print(e)\n\ntrain_y = train_df[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:17.496102Z","iopub.execute_input":"2021-11-07T05:11:17.496341Z","iopub.status.idle":"2021-11-07T05:11:17.646726Z","shell.execute_reply.started":"2021-11-07T05:11:17.496312Z","shell.execute_reply":"2021-11-07T05:11:17.645848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds=3\nkf = KFold(n_splits=folds)\nlgb_params = {\"objective\":\"binary\",\n              \"metrics\":\"auc\",\n              \"random_seed\":1234}","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:17.648175Z","iopub.execute_input":"2021-11-07T05:11:17.648397Z","iopub.status.idle":"2021-11-07T05:11:17.665702Z","shell.execute_reply.started":"2021-11-07T05:11:17.648371Z","shell.execute_reply":"2021-11-07T05:11:17.664868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Building a LightGBM Model for base line\nOf cousese I belive I can create better model with dataset which doesn't have \"id\" columns\nsince \"id\" have nothing to do with target lavel. \nBut I want to make sure how much \"id\" affects to the score.\nFist of all, I will create a model with dataset which doesn't have \"id\" columns","metadata":{}},{"cell_type":"markdown","source":"### 2-1. using dataset without \"id\" column \n","metadata":{"execution":{"iopub.status.busy":"2021-11-07T00:23:25.832938Z","iopub.execute_input":"2021-11-07T00:23:25.83328Z","iopub.status.idle":"2021-11-07T00:23:25.838138Z","shell.execute_reply.started":"2021-11-07T00:23:25.833235Z","shell.execute_reply":"2021-11-07T00:23:25.837168Z"}}},{"cell_type":"code","source":"##\nmodels=[]\nfor train_index, valid_index in kf.split(train_X):\n    X_train = train_X.iloc[train_index]\n    y_train = train_y.iloc[train_index]\n    X_valid = train_X.iloc[valid_index]\n    y_valid = train_y.iloc[valid_index]\n    \n    lgb_train= lgb.Dataset(X_train, y_train)\n    lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n    \n    model_lgb = lgb.train(lgb_params, \n                          lgb_train, \n                          valid_sets=lgb_valid, \n                          num_boost_round=100,\n                          early_stopping_rounds=20,\n                          verbose_eval=10\n                         )\n                          \n    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n#     print(accuracy_score(np.round(y_pred), y_valid))\n    \n    models.append(model_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:11:17.667185Z","iopub.execute_input":"2021-11-07T05:11:17.66745Z","iopub.status.idle":"2021-11-07T05:12:19.711364Z","shell.execute_reply.started":"2021-11-07T05:11:17.667391Z","shell.execute_reply":"2021-11-07T05:12:19.710609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=[]\nfor model in models:\n    lgb.plot_importance(model, importance_type=\"gain\", max_num_features=15)\n    pred = model_lgb.predict(test_X)\n    preds.append(pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:12:19.712492Z","iopub.execute_input":"2021-11-07T05:12:19.713339Z","iopub.status.idle":"2021-11-07T05:12:27.062048Z","shell.execute_reply.started":"2021-11-07T05:12:19.713297Z","shell.execute_reply":"2021-11-07T05:12:27.06117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_array = np.array(preds)\npreds_mean = np.mean(preds_array, axis=0)\n# preds_mean\npreds_int = (preds_mean > 0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T05:14:02.894096Z","iopub.execute_input":"2021-11-07T05:14:02.89436Z","iopub.status.idle":"2021-11-07T05:14:02.90704Z","shell.execute_reply.started":"2021-11-07T05:14:02.894331Z","shell.execute_reply":"2021-11-07T05:14:02.906041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}