{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://lightgbm.readthedocs.io/en/latest/_images/LightGBM_logo_black_text.svg)","metadata":{}},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import roc_auc_score\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\nfrom lightgbm import LGBMClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"features = [c for c in df_test.columns if 'f' in c]\n\ndf_train['sum'] = df_train[features].sum(axis=1)\ndf_test['sum'] = df_test[features].sum(axis=1)\nfeatures.append('sum')\n\ndf_train['std'] = df_train[features].std(axis=1)\ndf_test['std'] = df_test[features].std(axis=1)\nfeatures.append('std')\n\nscaler = preprocessing.RobustScaler()\ndf_train[features] = scaler.fit_transform(df_train[features])\ndf_test[features] = scaler.transform(df_test[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating folds","metadata":{}},{"cell_type":"code","source":"df_train['kfold'] = -1\n\ny_train = df_train.target\nX_train = df_train.drop('target', axis=1)\n\nskf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (i_train, i_valid) in enumerate (skf.split(X_train, y_train)):\n    df_train.loc[i_valid, 'kfold'] = fold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter optimization with Optuna","metadata":{}},{"cell_type":"code","source":"# s = 0\n\n# def objective(trial):\n#     fold = 0\n#     params = {\n#         'num_leaves': trial.suggest_int('num_leaves', 30, 70),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 2000, 4000),\n#         'max_depth': trial.suggest_int('max_depth', 4, 10),\n#         'max_bin': trial.suggest_int('max_bin', 200, 400),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.00001, 50),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.00001, 50),\n#         'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 10),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.9),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.2, 0.9),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 1)        \n#     }\n\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        \n#     y_train = X_train.target\n#     y_valid = X_valid.target\n    \n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n    \n#     model = LGBMClassifier(\n#             objective='binary',\n#             tree_learner='serial',\n#             random_state=s,\n#             n_estimators=30000,\n#             **params)\n    \n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=200,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               callbacks=[LightGBMPruningCallback(trial, 'auc')],\n#               verbose=1000)\n    \n#     valid_pred = model.predict_proba(X_valid)[:,1]\n#     auc = roc_auc_score(y_valid, valid_pred)\n#     return auc\n\n# study = optuna.create_study(direction=\"maximize\")\n# study.optimize(objective, n_trials=5000)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"%%time\n\nm = 1\ns = 0\n\nvalid_preds = {}\ntest_preds = []\nscores = []\n\nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.target\n    y_valid = X_valid.target\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n                                                \n    params = {'num_leaves': 68,\n              'min_data_in_leaf': 2213,\n              'max_depth': 0,\n              'max_bin': 352,\n              'learning_rate': 0.01475315458728817,\n              'lambda_l1': 0.18507317882864482,\n              'lambda_l2': 4.884457066789047,\n              'min_gain_to_split': 1.1320575715988301,\n              'feature_fraction': 0.49146056893550066,\n              'bagging_fraction': 0.5615998320661925,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split',\n        boosting_type='gbdt',\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=s,\n        n_estimators=30000,\n        **params)\n\n    model.fit(X_train,\n              y_train,\n              early_stopping_rounds=200,\n              eval_set=[(X_valid, y_valid)],\n              eval_metric='auc',\n              verbose=1000)\n\n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n\n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n\nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\n# Out-of-fold predictions for later use\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'm{m}s{s}_pred']\nvalid_preds.to_csv(f'm{m}s{s}_valid_pred.csv', index=False)\n\n# Test predictions for later use\nsample_submission.target = np.mean(np.column_stack(test_preds), axis=1)\nsample_submission.columns = ['id', f'm{m}s{s}_pred']\nsample_submission.to_csv(f'm{m}s{s}_test_pred.csv', index=False)\n\n# Submission\nsample_submission.target = np.mean(np.column_stack(test_preds), axis=1)\nsample_submission.columns = ['id', 'target']\nsample_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}