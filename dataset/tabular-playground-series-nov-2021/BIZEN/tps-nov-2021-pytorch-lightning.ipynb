{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport gc\nimport glob\nimport random\nimport shutil\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom torch.optim.lr_scheduler import ExponentialLR\n\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"execution":{"iopub.status.busy":"2021-11-25T00:04:18.627648Z","iopub.execute_input":"2021-11-25T00:04:18.628035Z","iopub.status.idle":"2021-11-25T00:04:21.954145Z","shell.execute_reply.started":"2021-11-25T00:04:18.627947Z","shell.execute_reply":"2021-11-25T00:04:21.953167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SPLITS = 10\nSEED = 42\n\nBATCH_SIZE = 1024\nWORKERS = 4\nEPOCHS = 100\n\nLEARNING_RATE = 2e-3\n\nMODEL_PATH = \"models\"\nTB_LOG_NAME = \"lightning_logs\"","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:21.95633Z","iopub.execute_input":"2021-11-25T00:04:21.956608Z","iopub.status.idle":"2021-11-25T00:04:21.961839Z","shell.execute_reply.started":"2021-11-25T00:04:21.956565Z","shell.execute_reply":"2021-11-25T00:04:21.961118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    pl.utilities.seed.seed_everything(seed, workers=True)\n    \nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:21.962962Z","iopub.execute_input":"2021-11-25T00:04:21.963466Z","iopub.status.idle":"2021-11-25T00:04:21.976112Z","shell.execute_reply.started":"2021-11-25T00:04:21.963427Z","shell.execute_reply":"2021-11-25T00:04:21.975321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-11-25T00:04:21.977796Z","iopub.execute_input":"2021-11-25T00:04:21.978134Z","iopub.status.idle":"2021-11-25T00:04:36.101116Z","shell.execute_reply.started":"2021-11-25T00:04:21.97809Z","shell.execute_reply":"2021-11-25T00:04:36.100398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.target.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:36.105105Z","iopub.execute_input":"2021-11-25T00:04:36.105321Z","iopub.status.idle":"2021-11-25T00:04:36.122803Z","shell.execute_reply.started":"2021-11-25T00:04:36.105294Z","shell.execute_reply":"2021-11-25T00:04:36.122103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[train_df.columns[1:]]\n\ntrain_df['fold'] = -1\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n    train_df.loc[val_idx, 'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:36.124256Z","iopub.execute_input":"2021-11-25T00:04:36.124587Z","iopub.status.idle":"2021-11-25T00:04:36.427629Z","shell.execute_reply.started":"2021-11-25T00:04:36.124549Z","shell.execute_reply":"2021-11-25T00:04:36.426874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:36.429007Z","iopub.execute_input":"2021-11-25T00:04:36.42928Z","iopub.status.idle":"2021-11-25T00:04:36.534184Z","shell.execute_reply.started":"2021-11-25T00:04:36.429245Z","shell.execute_reply":"2021-11-25T00:04:36.53341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Network implementation </h1>","metadata":{"execution":{"iopub.execute_input":"2021-09-02T09:17:24.053872Z","iopub.status.busy":"2021-09-02T09:17:24.053526Z","iopub.status.idle":"2021-09-02T09:17:24.060523Z","shell.execute_reply":"2021-09-02T09:17:24.059215Z","shell.execute_reply.started":"2021-09-02T09:17:24.053837Z"}}},{"cell_type":"code","source":"!pip install -q monai-weekly","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:36.535682Z","iopub.execute_input":"2021-11-25T00:04:36.535936Z","iopub.status.idle":"2021-11-25T00:04:46.601677Z","shell.execute_reply.started":"2021-11-25T00:04:36.535902Z","shell.execute_reply":"2021-11-25T00:04:46.600802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom monai.metrics import ROCAUCMetric\nfrom pytorch_lightning.core.memory import ModelSummary\n\n\nclass Model(pl.LightningModule):\n    def __init__(self, in_size, learning_rate, num_targets=1, hidden_size=384):\n        super().__init__()\n        self.in_size = in_size\n        self.lr = learning_rate\n        self.num_targets = num_targets\n        self.hidden_size = hidden_size\n        \n        self.fc1 = nn.Linear(self.in_size, self.hidden_size)\n        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size//2)\n        self.fc3 = nn.Linear(self.hidden_size//2, self.hidden_size//4)\n        self.fc4 = nn.Linear(self.hidden_size//4, self.hidden_size//2)\n        self.fc5 = nn.Linear(self.hidden_size//2, self.hidden_size)\n        self.fc6 = nn.Linear(self.hidden_size+self.hidden_size//4, 128)\n        self.fc7 = nn.Linear(128, self.num_targets)\n        self.relu = F.relu\n        self.swish = F.hardswish\n        self.flatten = nn.Flatten()\n        self.dropout1 = nn.Dropout(0.45)\n        self.dropout2 = nn.Dropout(0.35)\n        self.dropout3 = nn.Dropout(0.25)\n        self.batchnorm1 = nn.BatchNorm1d(self.hidden_size)\n        self.batchnorm2 = nn.BatchNorm1d(self.hidden_size//2)\n        self.batchnorm3 = nn.BatchNorm1d(self.hidden_size//4)\n        self.batchnorm4 = nn.BatchNorm1d(128)\n        self.concat = torch.cat\n        self.multiply = torch.mul\n        self.roc_auc_metric = ROCAUCMetric()\n    \n    def forward(self, x):\n        x1 = self.flatten(x)\n        x1 = self.swish(self.fc1(x1))\n        x1 = self.batchnorm1(x1)\n        x2 = self.dropout1(x1)\n        \n        x2 = self.swish(self.fc2(x2))\n        x2 = self.batchnorm2(x2)\n        x3 = self.dropout2(x2)\n\n        x3 = self.swish(self.fc3(x3))\n        x3 = self.batchnorm3(x3)\n        x3 = self.dropout3(x3)\n        \n        x4 = self.swish(self.fc4(x3))\n        x4 = self.batchnorm2(x4)\n        x4 = self.multiply(x2, x4)\n        x4 = self.dropout2(x4)\n        \n        x5 = self.swish(self.fc5(x4))\n        x5 = self.batchnorm1(x5)\n        x5 = self.multiply(x1, x5)\n        x5 = self.dropout1(x5)\n\n        x = self.concat((x3, x5), dim=1)\n        x = self.swish(self.fc6(x))\n        x = self.batchnorm4(x)\n        x = self.dropout3(x)\n        \n        x = self.fc7(x)\n        \n        return x\n    \n    def training_step(self, batch, batch_idx):\n        X, y = batch\n        y_hat = self(X).squeeze(1)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y)  \n        self.log('loss', loss)\n        return {'loss': loss}\n        \n    def validation_step(self, batch, batch_idx):\n        X, y = batch\n        y_hat = self(X).squeeze(1)\n        self.roc_auc_metric(y_hat, y)      \n    \n    def validation_epoch_end(self, training_step_outputs):\n        roc_auc = self.roc_auc_metric.aggregate()\n        self.roc_auc_metric.reset()\n        self.log('roc_auc', roc_auc)\n        \n    def predict_step(self, X, batch_idx: int, dataloader_idx: int = None):\n        return self(X[0])    \n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, eps=1e-8, weight_decay=1e-2, amsgrad=False)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:46.603657Z","iopub.execute_input":"2021-11-25T00:04:46.603939Z","iopub.status.idle":"2021-11-25T00:04:48.977133Z","shell.execute_reply.started":"2021-11-25T00:04:46.603899Z","shell.execute_reply":"2021-11-25T00:04:48.976421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipes = []\n\nfor fold in range(N_SPLITS):\n    print('Fold:', fold)\n    train_data = train_df[train_df['fold']!=fold]\n    val_data = train_df[train_df['fold']==fold]\n    \n    X_train = train_data.drop(['target', 'fold'], axis=1)\n    y_train = train_data['target']\n    \n    X_val = val_data.drop(['target', 'fold'], axis=1)\n    y_val = val_data['target']\n\n    pipe = Pipeline([\n            (\"scaler\", MinMaxScaler()),\n    ])\n\n    pipe.fit(X_train)\n    pipes.append(pipe)\n    \n    X_train = pd.DataFrame(pipe.transform(X_train), columns=X_train.columns, index=X_train.index)\n    X_val = pd.DataFrame(pipe.transform(X_val), columns=X_val.columns, index=X_val.index)\n    \n    train_ds = TensorDataset(torch.FloatTensor(X_train.values), torch.FloatTensor(y_train.values))\n    val_ds = TensorDataset(torch.FloatTensor(X_val.values), torch.FloatTensor(y_val.values))\n\n    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS)\n\n    model = Model(X_train.shape[1],\n                  LEARNING_RATE,\n                  1,\n                  384,\n                 )\n\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n        dirpath=MODEL_PATH,\n        filename=f'model_{fold}_' + '{roc_auc:.3}',\n        monitor='roc_auc',\n        mode='max',\n        save_weights_only=True)\n\n    logger = TensorBoardLogger(\n        save_dir=os.getcwd(),\n        version=fold,\n        name=TB_LOG_NAME\n    )\n \n    early_stop_callback = EarlyStopping(\n        monitor='loss',\n        min_delta=0.00,\n        patience=3,\n        verbose=False,\n        mode='min'\n    )\n    \n    # print(ModelSummary(model))\n    trainer = pl.Trainer(\n        fast_dev_run=False,\n        max_epochs=EPOCHS,\n        gpus=1,\n        precision=32,\n        limit_train_batches=1.0,\n        limit_val_batches=1.0, \n        num_sanity_val_steps=0,\n        val_check_interval=1.0, \n        callbacks=[checkpoint_callback],\n        logger=logger\n     )\n\n    trainer.fit(model, train_dl, val_dl)\n    \n    del model, trainer, val_data, train_data, X_train, X_val, y_train, y_val, train_ds, val_ds, train_dl, val_dl\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-11-25T00:04:48.978682Z","iopub.execute_input":"2021-11-25T00:04:48.978921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Inference </h1>","metadata":{}},{"cell_type":"code","source":"trained_models = []\nfor i in range(N_SPLITS):\n    list = glob.glob(f\"./models/model_{i}_*.ckpt\")\n    list.sort()\n    trained_models.append(list[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = []\ntest_df = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')\ntest_df = test_df[test_df.columns[1:]]\n\nsample_df = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv')\ntrainer = pl.Trainer(gpus=1)\n\nmodel = Model(test_df.shape[1], LEARNING_RATE)\nfor model_name in trained_models:\n    fold = int(model_name.split('_')[1])\n    pipe = pipes[fold]\n    test_data = pipe.transform(test_df)\n    \n    model.load_state_dict(torch.load(model_name)['state_dict'])\n    test_ds = TensorDataset(torch.FloatTensor(test_data))\n    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS)\n    \n    preds = trainer.predict(model, test_dl)\n    preds = torch.cat(preds).cpu().numpy().flatten()\n    \n    all_preds.append(preds)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np_all_preds = np.array(all_preds)\n\nnp_all_preds[:, :4], np_all_preds[:, -4:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_preds = np.mean(np_all_preds, axis=0)\n\navg_preds[:4], avg_preds[-4:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df['target'] = avg_preds\nsample_df.to_csv('submission.csv', index=False)\nsample_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}