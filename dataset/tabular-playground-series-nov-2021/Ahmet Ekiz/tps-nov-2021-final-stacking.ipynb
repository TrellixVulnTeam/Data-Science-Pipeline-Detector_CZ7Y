{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"0\"></a> <br>\n# Table of Contents\n\n1. [Introduction to Tabular Playground Series - Nov 2021](#1)\n    1. [Variable Describtions](#2)\n1. [Load and Glance at the Data](#3)   \n1. [Merge the Data](#4)\n1. [Helper Functions](#5) \n1. [XGBoost](#6) ","metadata":{"execution":{"iopub.status.busy":"2021-11-04T17:34:40.692397Z","iopub.execute_input":"2021-11-04T17:34:40.692771Z","iopub.status.idle":"2021-11-04T17:34:40.711343Z","shell.execute_reply.started":"2021-11-04T17:34:40.692679Z","shell.execute_reply":"2021-11-04T17:34:40.710674Z"}}},{"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# 1. Introduction to Tabular Playground Series - Nov 2021 \n\nTPS is a monthly competition prepared by Kaggle. The data is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. More information can be found on the [Competition Overview Page](https://www.kaggle.com/c/tabular-playground-series-nov-2021/overview).\n\n**The goal** is **predicting probability** of the observed target 0 or 1. So it is **supervised learning** and **classification task**. Also **evaluation metric** is selected **area under the ROC curve**.\n\n1. [My first Notebook on this competition: TPS Nov 2021 Starter with XGBoost](https://www.kaggle.com/ahmetekiz/tps-nov-2021-starter-with-xgboost#7.-Selecting-Models)\n1. [My second Notebook on this competition: TPS Nov 2021 Stacking](https://www.kaggle.com/ahmetekiz/tps-nov-2021-stacking)\n\n[back to the top](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n## A. Variable Describtions:\n- **df_train** : Pandas data frame for training data set\n- **df_test** : Pandas data frame for test data set\n- **x_train** : Pandas data frame removed target columns from df_train\n- **y_train** : Pandas data frame from df_train","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n# 2. Load the Data\n\n[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:38.266736Z","iopub.execute_input":"2021-12-01T13:00:38.267286Z","iopub.status.idle":"2021-12-01T13:00:38.276818Z","shell.execute_reply.started":"2021-12-01T13:00:38.267251Z","shell.execute_reply":"2021-12-01T13:00:38.275957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/tabular-playground-series-nov-2021/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/tabular-playground-series-nov-2021/test.csv\")\n\ndf_valid_preds_0 = pd.read_csv(\"/kaggle/input/tps-nov-2021-logistic-reg-xgboost-stacking1/valid_preds_LogisticRegression.csv\")\ndf_valid_preds_1 = pd.read_csv(\"/kaggle/input/tps-nov-2021-logistic-reg-xgboost-stacking1/valid_preds_XGB.csv\")\n\ndf_test_preds_0 = pd.read_csv(\"/kaggle/input/tps-nov-2021-logistic-reg-xgboost-stacking1/test_preds_LogisticRegression.csv\")\ndf_test_preds_1 = pd.read_csv(\"/kaggle/input/tps-nov-2021-logistic-reg-xgboost-stacking1/test_preds_XGB.csv\")\n\nrandom_state = 42","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:38.285886Z","iopub.execute_input":"2021-12-01T13:00:38.286184Z","iopub.status.idle":"2021-12-01T13:00:57.17489Z","shell.execute_reply.started":"2021-12-01T13:00:38.286155Z","shell.execute_reply":"2021-12-01T13:00:57.174128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:57.176848Z","iopub.execute_input":"2021-12-01T13:00:57.177344Z","iopub.status.idle":"2021-12-01T13:00:57.202733Z","shell.execute_reply.started":"2021-12-01T13:00:57.177304Z","shell.execute_reply":"2021-12-01T13:00:57.201933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"df_valid_preds_0.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:57.204203Z","iopub.execute_input":"2021-12-01T13:00:57.20447Z","iopub.status.idle":"2021-12-01T13:00:57.212744Z","shell.execute_reply.started":"2021-12-01T13:00:57.204423Z","shell.execute_reply":"2021-12-01T13:00:57.211991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_preds_0.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:57.215046Z","iopub.execute_input":"2021-12-01T13:00:57.215567Z","iopub.status.idle":"2021-12-01T13:00:57.227932Z","shell.execute_reply.started":"2021-12-01T13:00:57.215529Z","shell.execute_reply":"2021-12-01T13:00:57.227159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to the top](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n# 3. Merge the Data","metadata":{}},{"cell_type":"code","source":"df_train = df_train.merge(df_valid_preds_0, on=\"id\", how=\"left\")\ndf_train = df_train.merge(df_valid_preds_1, on=\"id\", how=\"left\")\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:57.22961Z","iopub.execute_input":"2021-12-01T13:00:57.230701Z","iopub.status.idle":"2021-12-01T13:00:58.224016Z","shell.execute_reply.started":"2021-12-01T13:00:57.230655Z","shell.execute_reply":"2021-12-01T13:00:58.223351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test.merge(df_test_preds_0, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test_preds_1, on=\"id\", how=\"left\")\n\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:58.225162Z","iopub.execute_input":"2021-12-01T13:00:58.225654Z","iopub.status.idle":"2021-12-01T13:00:58.749543Z","shell.execute_reply.started":"2021-12-01T13:00:58.225615Z","shell.execute_reply":"2021-12-01T13:00:58.748665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features_train = [\"pred_0\", \"pred_1\", \"target\"]\n\ndf_train[useful_features_train].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:58.750877Z","iopub.execute_input":"2021-12-01T13:00:58.751195Z","iopub.status.idle":"2021-12-01T13:00:59.082788Z","shell.execute_reply.started":"2021-12-01T13:00:58.751158Z","shell.execute_reply":"2021-12-01T13:00:59.081948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = df_test.columns[1:]\n\n# columns = [\"pred_0\", \"pred_1\"]\nprint(columns)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:59.08424Z","iopub.execute_input":"2021-12-01T13:00:59.084595Z","iopub.status.idle":"2021-12-01T13:00:59.089813Z","shell.execute_reply.started":"2021-12-01T13:00:59.084554Z","shell.execute_reply":"2021-12-01T13:00:59.088874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# assert False","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:59.091148Z","iopub.execute_input":"2021-12-01T13:00:59.09183Z","iopub.status.idle":"2021-12-01T13:00:59.099437Z","shell.execute_reply.started":"2021-12-01T13:00:59.091788Z","shell.execute_reply":"2021-12-01T13:00:59.098279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = df_train[\"target\"]\ndf_train = df_train.drop(labels = \"target\", axis=1)\n\ndf_train.head()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:59.104049Z","iopub.execute_input":"2021-12-01T13:00:59.10453Z","iopub.status.idle":"2021-12-01T13:00:59.272847Z","shell.execute_reply.started":"2021-12-01T13:00:59.104497Z","shell.execute_reply":"2021-12-01T13:00:59.272053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:59.274011Z","iopub.execute_input":"2021-12-01T13:00:59.275598Z","iopub.status.idle":"2021-12-01T13:00:59.298668Z","shell.execute_reply.started":"2021-12-01T13:00:59.275558Z","shell.execute_reply":"2021-12-01T13:00:59.297926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n# 3. Feature Scaling\nIn order to, ML algorithms perform well, I will scale data with Standardization method.\n\n[Variable Describtions](#7)\n\n[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:59.299785Z","iopub.execute_input":"2021-12-01T13:00:59.300196Z","iopub.status.idle":"2021-12-01T13:00:59.307391Z","shell.execute_reply.started":"2021-12-01T13:00:59.300157Z","shell.execute_reply":"2021-12-01T13:00:59.306485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a Pipeline for Preparing Data to Training","metadata":{}},{"cell_type":"code","source":"std_scaler = StandardScaler()\n\nnum_pipeline = Pipeline([(('std_scaler'), StandardScaler()),])\nfull_pipeline = ColumnTransformer([('num', num_pipeline, columns),])\n\ndf_train[columns] = full_pipeline.fit_transform(df_train)\ndf_test[columns] = full_pipeline.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:59.30916Z","iopub.execute_input":"2021-12-01T13:00:59.309424Z","iopub.status.idle":"2021-12-01T13:00:59.632115Z","shell.execute_reply.started":"2021-12-01T13:00:59.309381Z","shell.execute_reply":"2021-12-01T13:00:59.631363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Variable Describtions](#7)\n\n[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:59.633547Z","iopub.execute_input":"2021-12-01T13:00:59.633798Z","iopub.status.idle":"2021-12-01T13:00:59.660787Z","shell.execute_reply.started":"2021-12-01T13:00:59.633764Z","shell.execute_reply":"2021-12-01T13:00:59.660061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:59.662217Z","iopub.execute_input":"2021-12-01T13:00:59.662508Z","iopub.status.idle":"2021-12-01T13:00:59.686212Z","shell.execute_reply.started":"2021-12-01T13:00:59.662471Z","shell.execute_reply":"2021-12-01T13:00:59.685317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Variable Describtions](#7)\n[back to the top](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n# 4. Helper Functions\n[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:59.687888Z","iopub.execute_input":"2021-12-01T13:00:59.688194Z","iopub.status.idle":"2021-12-01T13:00:59.694425Z","shell.execute_reply.started":"2021-12-01T13:00:59.688147Z","shell.execute_reply":"2021-12-01T13:00:59.693566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, label=None, title=None):\n    \"\"\"\n    \"\"\"\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') \n    plt.legend(loc = 'lower right')\n    plt.title(title)\n    plt.show()\n\n    \ndef roc_auc_score_func(y_true, y_head, plot_roc=False):\n    \"\"\" evaluate roc auc score\n    Args:\n        y_true : a numpy array. True labels.\n        y_head : a numpy array. Predicted labels.\n        plot_roc : if you want to plot roc curve. (Default is False)\n        \n    \"\"\"\n    \n    if plot_roc:\n        fpr, tpr, thresholds = roc_curve(y_true, y_head)\n        plot_roc_curve(fpr, tpr, label=None, title=None)\n        \n        \n    # evaluate roc auc score\n    model_roc_auc_score = roc_auc_score(y_true, y_true)\n    \n    return model_roc_auc_score\n\n\ndef train_and_predict(clf, clf_name, X, Y, x_test, n_splits=5):\n    \"\"\"train ml models with Stratified Kfol return auc score for probability of test data with ml model name\n    \n    Args:\n        clf : model classifier\n        clf_name : classifier name\n        x_train : a numpy.darray training data \n        y_train : a numpy.darray training labels\n        x_test: test data\n        n_splits : StratifiedKFold splits number\n        \n    Returns:\n        roc_auc_score_mean\n        accuracy_mean\n        valid_preds_dict : a dict that stores validation set ids and predictions probabilities from StratifiedKFold\n        test_preds: predictions probabilities of test set\n    \"\"\"\n    \n    valid_preds = []\n    valid_ids = []\n    valid_preds_dict = {}\n    \n    test_preds = []\n    \n    roc_auc_score_list = []  # roc auc score list\n    acc_score_list = [] # auc score list\n    \n\n\n    skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n    \n    for i, (train_index, val_index) in enumerate(skf.split(X, Y)):\n        print(\"Fitting fold\", i+1)\n        X_train, X_val = X[train_index], X[val_index]\n        Y_train, Y_val = Y[train_index], Y[val_index]\n        \n        print(\"Model:\", clf_name)\n\n        # TRAINING\n        training_start_time = time.time()\n        local_time = time.ctime(training_start_time)\n        print(\"Local time:\", local_time)\n        \n        model = clf\n        model.fit(X_train, Y_train)  # except id column\n\n        training_end_time = time.time()\n        training_time = training_end_time - training_start_time\n        print(f\"Training elapsed seconds: {round(training_time,3)}\")\n\n\n        # EVALUATING\n        evaluating_start_time = time.time()\n        local_time = time.ctime(evaluating_start_time)\n        print(\"Local time:\", local_time)\n        \n        valid_preds = model.predict_proba(X_val)[:, 1]  # predict probabilty of validation set\n        valid_ids = X[val_index,0].tolist()\n        valid_preds_dict.update(dict(zip(valid_ids, valid_preds)))  \n    \n        \n        roc_auc_score_list.append(roc_auc_score(Y_val, valid_preds))\n        acc_score_list.append(accuracy_score(Y_val, model.predict(X_val)))\n\n        evaluating_end_time = time.time()\n        evaluating_time = evaluating_end_time - evaluating_start_time\n        print(f\"evaluating scores elapsed seconds: {round(evaluating_time,3)}\")\n    \n    \n        # PREDICTION\n        prediction_start_time = time.time()\n        local_time = time.ctime(prediction_start_time)\n        print(\"Local time:\", local_time)\n        \n        test_pred = clf.predict_proba(x_test)[:, 1]\n        test_preds.append(test_pred)\n\n        prediction_end_time = time.time()\n        prediction_time = prediction_end_time - prediction_start_time\n        print(f\"predicting test probability scores elapsed seconds: {round(prediction_time,3)}\")\n    \n    roc_auc_score_mean = np.mean(roc_auc_score_list)\n    accuracy_mean = np.mean(acc_score_list) \n    \n    \n    print(f\"Mean accuracy: {round(accuracy_mean*100,3)}, Mean AUC Score: {round(roc_auc_score_mean*100,3)}\")\n    \n    return roc_auc_score_mean, accuracy_mean, valid_preds_dict, test_preds","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:00:59.695951Z","iopub.execute_input":"2021-12-01T13:00:59.696539Z","iopub.status.idle":"2021-12-01T13:00:59.717046Z","shell.execute_reply.started":"2021-12-01T13:00:59.696495Z","shell.execute_reply":"2021-12-01T13:00:59.716247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of my references here [abhishek's notebook](https://www.kaggle.com/abhishek/competition-part-6-stacking/notebookhttps://www.kaggle.com/abhishek/competition-part-6-stacking/notebook), especially mean of several kfold test predictions. \n\n[back to the top](#0)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n## A. Split Train and Validation Data\n[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"# IT CONTROLS THE CODE WORKS BEFORE SUBMIT\n# from sklearn.model_selection import StratifiedShuffleSplit\n\n# split = StratifiedShuffleSplit(n_splits=1, test_size=0.001, random_state=42)\n\n# for train_index, val_index in split.split(df_train, y_train):\n#     df_train, y_train = df_train.loc[val_index], y_train.loc[val_index] \n#     x_val, y_val = df_train.loc[val_index], y_train.loc[val_index]\n\n# # x_train_2 = x_train_2.values\n# # y_train_2 = y_train_2.values\n\n# # # x_train_2[:,0] # id","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T13:00:59.720496Z","iopub.execute_input":"2021-12-01T13:00:59.720704Z","iopub.status.idle":"2021-12-01T13:01:00.098337Z","shell.execute_reply.started":"2021-12-01T13:00:59.720682Z","shell.execute_reply":"2021-12-01T13:01:00.097507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n# 5. XGBoost\n[back to the top](#0)","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade xgboost\n\n# # xgb.__version__","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:00.101806Z","iopub.execute_input":"2021-12-01T13:01:00.102019Z","iopub.status.idle":"2021-12-01T13:01:20.840616Z","shell.execute_reply.started":"2021-12-01T13:01:00.101994Z","shell.execute_reply":"2021-12-01T13:01:20.839756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.842688Z","iopub.execute_input":"2021-12-01T13:01:20.843031Z","iopub.status.idle":"2021-12-01T13:01:20.872009Z","shell.execute_reply.started":"2021-12-01T13:01:20.842994Z","shell.execute_reply":"2021-12-01T13:01:20.871377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# assert False","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.873484Z","iopub.execute_input":"2021-12-01T13:01:20.873968Z","iopub.status.idle":"2021-12-01T13:01:20.87713Z","shell.execute_reply.started":"2021-12-01T13:01:20.873931Z","shell.execute_reply":"2021-12-01T13:01:20.876406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to the top](#0)","metadata":{}},{"cell_type":"markdown","source":"I've chosen three classifiers according to my previous notebook's evaluation results.","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.878749Z","iopub.execute_input":"2021-12-01T13:01:20.879333Z","iopub.status.idle":"2021-12-01T13:01:20.909806Z","shell.execute_reply.started":"2021-12-01T13:01:20.879292Z","shell.execute_reply":"2021-12-01T13:01:20.908846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.values\ny_train = y_train.values","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.91125Z","iopub.execute_input":"2021-12-01T13:01:20.91172Z","iopub.status.idle":"2021-12-01T13:01:20.916133Z","shell.execute_reply.started":"2021-12-01T13:01:20.911686Z","shell.execute_reply":"2021-12-01T13:01:20.91527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.917373Z","iopub.execute_input":"2021-12-01T13:01:20.917866Z","iopub.status.idle":"2021-12-01T13:01:20.927768Z","shell.execute_reply.started":"2021-12-01T13:01:20.91783Z","shell.execute_reply":"2021-12-01T13:01:20.927086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clf = XGBClassifier(max_depth=8,\n#                     learning_rate=0.01,\n#                     n_estimators=10000,\n#                     verbosity=1,\n#                     silent=None,\n#                     objective='binary:logistic',  \n#                     tree_method = 'gpu_hist',\n#                     booster='gbtree',\n#                     n_jobs=-1,\n#                     nthread=None,\n#                     eval_metric='auc',\n#                     gamma=0,\n#                     min_child_weight=1,\n#                     max_delta_step=0,\n#                     subsample=0.7,\n#                     colsample_bytree=1,\n#                     colsample_bylevel=1,\n#                     colsample_bynode=1,\n#                     reg_alpha=0,\n#                     reg_lambda=1,\n#                     scale_pos_weight=1,\n#                     base_score=0.5,\n#                     random_state=random_state,\n#                     seed=None)\n\n# clf_name = \"XGB\"","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.929446Z","iopub.execute_input":"2021-12-01T13:01:20.92976Z","iopub.status.idle":"2021-12-01T13:01:20.9379Z","shell.execute_reply.started":"2021-12-01T13:01:20.929725Z","shell.execute_reply":"2021-12-01T13:01:20.937122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LogisticRegression(solver='liblinear', random_state = random_state)\nclf_name = \"LogisticRegression\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[:,1:].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:01:20.939424Z","iopub.execute_input":"2021-12-01T13:01:20.940082Z","iopub.status.idle":"2021-12-01T13:01:20.948123Z","shell.execute_reply.started":"2021-12-01T13:01:20.940029Z","shell.execute_reply":"2021-12-01T13:01:20.947027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport time\n\n\nroc_auc_score_mean, accuracy_mean, valid_preds_dict, test_preds = train_and_predict(clf, \n                                                                                    clf_name, \n                                                                                    df_train[:,1:], \n                                                                                    y_train,  \n                                                                                    df_test[columns],\n                                                                                    n_splits=2)\n    \n    \n    \n\n\n#save predictions of test data to csv\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv')\nprint(sub)\ntest_preds = np.mean(np.column_stack(test_preds), axis=1)  # mean of every kfold predictions. Before that it gives a list has two columns\n\nsub['target'] = test_preds\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-12-01T13:01:50.651402Z","iopub.execute_input":"2021-12-01T13:01:50.651703Z","iopub.status.idle":"2021-12-01T13:03:32.947923Z","shell.execute_reply.started":"2021-12-01T13:01:50.651672Z","shell.execute_reply":"2021-12-01T13:03:32.947176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to the top](#0)","metadata":{}}]}