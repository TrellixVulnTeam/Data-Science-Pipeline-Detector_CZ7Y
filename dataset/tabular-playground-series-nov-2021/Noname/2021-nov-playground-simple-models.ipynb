{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries, basic functions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:17:46.114671Z","iopub.execute_input":"2021-11-15T07:17:46.115288Z","iopub.status.idle":"2021-11-15T07:17:46.136241Z","shell.execute_reply.started":"2021-11-15T07:17:46.115195Z","shell.execute_reply":"2021-11-15T07:17:46.13545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_me_the_clock():\n    return (datetime.utcnow() + timedelta(hours=+9)).strftime('%Y-%m-%d %H:%M:%S')\n\ndef load_dataset(train_or_test='train'):\n    file_path = f'../input/tabular-playground-series-nov-2021/{train_or_test}.csv'\n    df = pd.read_csv(file_path)\n    print(show_me_the_clock(), f'Dataset loaded, shape={df.shape}')\n    df = tame_data(df)\n    print(show_me_the_clock(), f'Dataset tamed, shape={df.shape}')\n    if train_or_test == 'train':\n        y = df['target'].to_numpy()\n        del df['target']\n        X = df.to_numpy()\n        print(show_me_the_clock(), f'Dataset prepared, X.shape={X.shape}, y.shape={y.shape}')\n        return X, y\n    else:\n        X = df.to_numpy()\n        return X\n    return df\n\ndef tame_data(df):\n    df = df.copy()\n    for i in range(100):\n        q1, q2, q3 = df['f%d' % i].quantile([0.25, 0.5, 0.75]).iloc\n        \n        # normalization by median and IQR\n        df['f%d' % i] = (df['f%d' % i] - q2) / (q3 - q1) \n        \n        # concentrating data toward median\n        df['f%d' % i] = df['f%d' % i].apply(lambda x: np.sign(x)*np.log1p(np.log1p(np.abs(x))))\n    del df['id']\n    df = df.rename(columns=lambda name: name + '_tamed' if name != 'target' else name)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:17:46.137631Z","iopub.execute_input":"2021-11-15T07:17:46.13819Z","iopub.status.idle":"2021-11-15T07:17:46.148265Z","shell.execute_reply.started":"2021-11-15T07:17:46.138153Z","shell.execute_reply":"2021-11-15T07:17:46.147036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(*load_dataset('train'), test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:17:46.149875Z","iopub.execute_input":"2021-11-15T07:17:46.150541Z","iopub.status.idle":"2021-11-15T07:23:25.013042Z","shell.execute_reply.started":"2021-11-15T07:17:46.150504Z","shell.execute_reply":"2021-11-15T07:23:25.01169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and testing simple models\n**(1) Logistic Regression - L1 regularized**\n\nAll of these exhibit low performances, and their metrics are similar.\n\nSome features (e.g. f34, f27, f43, etc.) are found influential in each of those models.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.linear_model import LogisticRegression\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor C, ax_coef, ax_roc, ax_pr in zip([0.0001, 0.0003, 0.001, 0.003, 0.01], *axs):\n    model = LogisticRegression(penalty='l1', C=C, solver='saga')\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc = roc_auc_score(y_test, y_proba)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    height = model.coef_.ravel()\n    ax_coef.bar(x=list(range(100)), height=height, label='Coefficients')\n    for h_ind in np.argsort(-np.abs(height)):\n        ax_coef.text(h_ind, height[h_ind], f'{h_ind}')\n    ax_coef.set_title(f'Linear model(L1 reg, C={C})', fontsize=16)\n    ax_coef.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n    \n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label='PR curve', color='green')\n    ax_pr.text(0.2, 0.2, f'precision={prec:.3f}\\nrecall={rec:.3f}', fontsize=12)\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:23:25.01969Z","iopub.execute_input":"2021-11-15T07:23:25.020323Z","iopub.status.idle":"2021-11-15T07:25:05.35117Z","shell.execute_reply.started":"2021-11-15T07:23:25.020282Z","shell.execute_reply":"2021-11-15T07:25:05.347783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(2) Logistic Regression - L2 regularized**","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor C, ax_coef, ax_roc, ax_pr in zip([1e-7, 1e-6, 1e-5, 1e-4, 1e-3], *axs):\n    model = LogisticRegression(penalty='l2', C=C)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc = roc_auc_score(y_test, y_proba)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    height = model.coef_.ravel()\n    ax_coef.bar(x=list(range(100)), height=height, label='Coefficients')\n    for h_ind in np.argsort(-np.abs(height)):\n        ax_coef.text(h_ind, height[h_ind], f'{h_ind}')\n    ax_coef.set_title(f'Linear model(L2 reg, C={C})', fontsize=16)\n    ax_coef.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n    \n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label='PR curve', color='green')\n    ax_pr.text(0.2, 0.2, f'precision={prec:.3f}\\nrecall={rec:.3f}', fontsize=12)\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:25:05.355921Z","iopub.execute_input":"2021-11-15T07:25:05.357388Z","iopub.status.idle":"2021-11-15T07:25:25.426139Z","shell.execute_reply.started":"2021-11-15T07:25:05.356646Z","shell.execute_reply":"2021-11-15T07:25:25.425153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(3) Decision tree**","metadata":{}},{"cell_type":"markdown","source":"a. varying \"max_depth\"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor max_depth, ax_fi, ax_roc, ax_pr in zip([5, 10, 15, 20, 25], *axs):\n    model = DecisionTreeClassifier(max_depth=max_depth, \n                                   min_samples_split=2, \n                                   min_samples_leaf=1,\n                                   max_features=None)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, max_depth={max_depth}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:25:25.427388Z","iopub.execute_input":"2021-11-15T07:25:25.428225Z","iopub.status.idle":"2021-11-15T07:34:34.703984Z","shell.execute_reply.started":"2021-11-15T07:25:25.428188Z","shell.execute_reply":"2021-11-15T07:34:34.702828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"b. varying \"min_samples_split\"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor min_samples_split, ax_fi, ax_roc, ax_pr in zip([1e-3, 1e-2, 1e-1, 2e-1, 3e-1], *axs):\n    model = DecisionTreeClassifier(max_depth=10, \n                                   min_samples_split=min_samples_split, \n                                   min_samples_leaf=1,\n                                   max_features=None)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, min_samples_split={min_samples_split}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:34:34.706673Z","iopub.execute_input":"2021-11-15T07:34:34.706942Z","iopub.status.idle":"2021-11-15T07:39:20.299912Z","shell.execute_reply.started":"2021-11-15T07:34:34.706914Z","shell.execute_reply":"2021-11-15T07:39:20.298847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"c. varying \"min_samples_leaf\"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor min_samples_leaf, ax_fi, ax_roc, ax_pr in zip([1e-5, 1e-4, 1e-3, 1e-2, 1e-1], *axs):\n    model = DecisionTreeClassifier(max_depth=10, \n                                   min_samples_split=1e-3, \n                                   min_samples_leaf=min_samples_leaf,\n                                   max_features=None)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, min_samples_leaf={min_samples_leaf}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:39:20.302271Z","iopub.execute_input":"2021-11-15T07:39:20.302712Z","iopub.status.idle":"2021-11-15T07:45:29.275922Z","shell.execute_reply.started":"2021-11-15T07:39:20.302666Z","shell.execute_reply":"2021-11-15T07:45:29.273816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"d. varying \"max_features\"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor max_features, ax_fi, ax_roc, ax_pr in zip([8, 16, 32, 64, 82], *axs):\n    model = DecisionTreeClassifier(max_depth=10, \n                                   min_samples_split=1e-3, \n                                   min_samples_leaf=1e-3,\n                                   max_features=max_features)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, max_features={max_features}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:45:29.277578Z","iopub.execute_input":"2021-11-15T07:45:29.277873Z","iopub.status.idle":"2021-11-15T07:48:35.983035Z","shell.execute_reply.started":"2021-11-15T07:45:29.277837Z","shell.execute_reply":"2021-11-15T07:48:35.981874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"e. What if criterion is replaced by \"entropy\"?","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor max_features, ax_fi, ax_roc, ax_pr in zip([8, 16, 32, 64, 82], *axs):\n    model = DecisionTreeClassifier(criterion='entropy', \n                                   max_depth=10, \n                                   min_samples_split=1e-3, \n                                   min_samples_leaf=1e-3,\n                                   max_features=max_features)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n    fi = model.feature_importances_\n    ax_fi.bar(list(range(100)), fi, label='feature importances')\n    for f_num in np.argsort(-fi):\n        ax_fi.text(f_num, fi[f_num], f'{f_num}')\n    ax_fi.set_title(f'Decision tree, max_features={max_features}', fontsize=16)\n    ax_fi.set_xlabel('features')\n    ax_fi.set_ylabel('importance')\n    ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:48:35.987692Z","iopub.execute_input":"2021-11-15T07:48:35.987962Z","iopub.status.idle":"2021-11-15T07:53:11.834715Z","shell.execute_reply.started":"2021-11-15T07:48:35.98793Z","shell.execute_reply":"2021-11-15T07:53:11.83388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(4) kernel SVM**\n\nThis takes too long, even with much smaller training set .","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\nfrom sklearn.svm import SVC\n\nfig, axs = plt.subplots(nrows=3, ncols=5, figsize=(24, 12))\nfor C, ax_fi, ax_roc, ax_pr in zip([1e-4, 1e-2, 1e0, 1e2, 1e4], *axs):\n    model = SVC(C=C, kernel='rbf', probability=True)\n    model.fit(X_train[::100], y_train[::100])\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    \n    y_pred_train = model.predict(X_train)\n    y_proba_train = model.predict_proba(X_train)[:, 1]\n    acc_train = accuracy_score(y_train, y_pred_train)\n    auc_train = roc_auc_score(y_train, y_proba_train)\n    prec_train = precision_score(y_train, y_pred_train)\n    rec_train = recall_score(y_train, y_pred_train)\n\n#     fi = model.coef_[1]\n#     ax_fi.bar(list(range(100)), fi, label='feature importances')\n#     for f_num in np.argsort(-fi):\n#         ax_fi.text(f_num, fi[f_num], f'{f_num}')\n#     ax_fi.set_title(f'SVC with rbf, C={C}', fontsize=16)\n#     ax_fi.set_xlabel('features')\n#     ax_fi.set_ylabel('importance')\n#     ax_fi.legend()\n    \n    ax_roc.plot(*roc_curve(y_train, y_proba_train)[:2], label=f'ROC curve(train)\\naccuracy={acc_train:.3f}\\nauc={auc_train:.3f}', color='green')\n    ax_roc.plot(*roc_curve(y_test, y_proba)[:2], label=f'ROC curve(test)\\naccuracy={acc:.3f}\\nauc={auc:.3f}', color='red')\n    ax_roc.set_xlim([0, 1])\n    ax_roc.set_ylim([0, 1])\n    ax_roc.set_xlabel('FPR')\n    ax_roc.set_ylabel('TPR')\n    ax_roc.legend()\n\n    ax_pr.plot(*precision_recall_curve(y_train, y_proba_train)[:2], label=f'PR curve(train)\\nprecision={prec_train:.3f}\\nrecall={rec_train:.3f}', color='green')\n    ax_pr.plot(*precision_recall_curve(y_test, y_proba)[:2], label=f'PR curve(test)\\nprecision={prec:.3f}\\nrecall={rec:.3f}', color='red')\n    ax_pr.set_xlim([0, 1])\n    ax_pr.set_ylim([0, 1])\n    ax_pr.set_xlabel('precision')\n    ax_pr.set_ylabel('recall')\n    ax_pr.legend()\n\nplt.tight_layout()\nplt.show()\nplt.close('all')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:53:11.904498Z","iopub.execute_input":"2021-11-15T07:53:11.904728Z","iopub.status.idle":"2021-11-15T09:13:26.913172Z"},"trusted":true},"execution_count":null,"outputs":[]}]}