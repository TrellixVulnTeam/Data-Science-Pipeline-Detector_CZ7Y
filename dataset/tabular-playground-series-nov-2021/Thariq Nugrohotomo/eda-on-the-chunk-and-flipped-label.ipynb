{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.rcParams['axes.grid'] = True\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-21T00:21:16.079297Z","iopub.execute_input":"2021-11-21T00:21:16.079623Z","iopub.status.idle":"2021-11-21T00:21:16.091882Z","shell.execute_reply.started":"2021-11-21T00:21:16.079587Z","shell.execute_reply":"2021-11-21T00:21:16.09103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_before = pd.read_csv('/kaggle/input/november21/train.csv', index_col=0)\ntrain_after = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv', index_col=0)\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv', index_col=0)\nybefore = train_before.target\nyafter = train_after.target","metadata":{"execution":{"iopub.status.busy":"2021-11-21T00:26:10.808166Z","iopub.execute_input":"2021-11-21T00:26:10.808487Z","iopub.status.idle":"2021-11-21T00:26:47.199869Z","shell.execute_reply.started":"2021-11-21T00:26:10.808454Z","shell.execute_reply":"2021-11-21T00:26:47.198931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As already discussed in https://www.kaggle.com/c/tabular-playground-series-nov-2021/discussion/286731 that the label seems chunked for every 60000 rows.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(11,5))\nplt.xticks(np.arange(0,600000,60000))\n(ybefore-.5).cumsum().plot(label='before flip')\n(yafter-.5).cumsum().plot(label='after flip')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-11-21T00:22:07.767878Z","iopub.execute_input":"2021-11-21T00:22:07.768219Z","iopub.status.idle":"2021-11-21T00:22:09.460811Z","shell.execute_reply.started":"2021-11-21T00:22:07.768185Z","shell.execute_reply":"2021-11-21T00:22:09.460002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The predicted label of the **test** set seems chunked too for every 60000 rows, this can be observed using almost any available model (the chunk is always visible).","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.svm import LinearSVC\ndef fit_predict(train,test):\n    est = make_pipeline(StandardScaler(), LinearSVC(dual=False))\n    est.fit(train.drop(columns='target'), train.target)\n    return pd.Series(est.predict(test))\nplt.figure(figsize=(11,5))\nplt.xticks(np.arange(0,600000,60000))\n(fit_predict(train_before, test)-.5).cumsum().plot(label='before flip')\n(fit_predict(train_after, test)-.5).cumsum().plot(label='after flip')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-11-21T00:31:50.76924Z","iopub.execute_input":"2021-11-21T00:31:50.770566Z","iopub.status.idle":"2021-11-21T00:32:12.02139Z","shell.execute_reply.started":"2021-11-21T00:31:50.770491Z","shell.execute_reply":"2021-11-21T00:32:12.020704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Average/mean on each chunk","metadata":{}},{"cell_type":"code","source":"mean_before = []\nmean_after = []\nfor start in range(0,600000,60000):\n    endx = start+60000\n    mean_before.append(ybefore[start:endx].mean())\n    mean_after.append(yafter[start:endx].mean())\nplt.xticks(np.arange(10))\nplt.scatter(np.arange(len(mean_before)), mean_before, label='before flip')\nplt.scatter(np.arange(len(mean_after)), mean_after, label='after flip')\nplt.plot(np.arange(10), [0.5]*10, linestyle='--')\nplt.xlabel('chunk')\nplt.ylabel('mean')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-11-21T00:41:12.419511Z","iopub.execute_input":"2021-11-21T00:41:12.419816Z","iopub.status.idle":"2021-11-21T00:41:12.728826Z","shell.execute_reply.started":"2021-11-21T00:41:12.41978Z","shell.execute_reply":"2021-11-21T00:41:12.728073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown above, the flipping seems pushing the label average closer to **0.5**.\n\nThe further away the initial average from 0.5, it will get pushed at greater length, closer to 0.5.","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:06:12.092017Z","iopub.execute_input":"2021-11-21T01:06:12.092407Z","iopub.status.idle":"2021-11-21T01:06:12.099776Z","shell.execute_reply.started":"2021-11-21T01:06:12.092345Z","shell.execute_reply":"2021-11-21T01:06:12.098571Z"}}},{"cell_type":"markdown","source":"Let's take a look at the correlation between the average before flipping versus after flipping.","metadata":{}},{"cell_type":"code","source":"plt.scatter(mean_before, mean_after)\nplt.xlabel('mean before')\nplt.ylabel('mean after');","metadata":{"execution":{"iopub.status.busy":"2021-11-21T00:47:11.679765Z","iopub.execute_input":"2021-11-21T00:47:11.680064Z","iopub.status.idle":"2021-11-21T00:47:11.908993Z","shell.execute_reply.started":"2021-11-21T00:47:11.68003Z","shell.execute_reply":"2021-11-21T00:47:11.908161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's almost linearly correlated.\n\nHence probably we can predict the label average on the test set after the flipping too, but it's difficult to prove this.","metadata":{}},{"cell_type":"markdown","source":"Let's have a closer look at the statistics of the flipping on each chunk = how many 0 flipped to 1, and vice versa","metadata":{}},{"cell_type":"code","source":"flip01 = []\nflip10 = []\nfor start in range(0,600000,60000):\n    endx = start+60000\n    before = ybefore[start:endx]\n    after = yafter[start:endx]\n    flip01.append(((~before) & after).sum())\n    flip10.append((before & (~after)).sum())\ndf = pd.DataFrame(dict(\n    mean_before=mean_before, \n    mean_after=mean_after, \n    flip_0_1=flip01, \n    flip_1_0=flip10\n))\ndf.index.name = 'chunk'\ndf","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:09:30.737697Z","iopub.execute_input":"2021-11-21T01:09:30.738015Z","iopub.status.idle":"2021-11-21T01:09:30.770615Z","shell.execute_reply.started":"2021-11-21T01:09:30.737981Z","shell.execute_reply":"2021-11-21T01:09:30.769739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The table above shows that for the flipping to be able to push the average closer to 0.5 =\n* If the average < 0.5 (label 0 is majority), then need to perform a lot of flipping of 0 into 1 (`flip_0_1`)\n* If the average > 0.5 (label 1 is majority), then need to perform a lot of flipping of 1 into 0 (`flip_1_0`)","metadata":{}},{"cell_type":"markdown","source":"Let's try to correlate the initial average into `flip_0_1` and `flip_1_0`.","metadata":{}},{"cell_type":"code","source":"df.plot.scatter('flip_0_1', 'mean_before');\ndf.plot.scatter('flip_1_0', 'mean_before');","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:03:22.930591Z","iopub.execute_input":"2021-11-21T01:03:22.9309Z","iopub.status.idle":"2021-11-21T01:03:23.391984Z","shell.execute_reply.started":"2021-11-21T01:03:22.930867Z","shell.execute_reply":"2021-11-21T01:03:23.39107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both of them are almost linearly correlated with the initial average.","metadata":{}}]}