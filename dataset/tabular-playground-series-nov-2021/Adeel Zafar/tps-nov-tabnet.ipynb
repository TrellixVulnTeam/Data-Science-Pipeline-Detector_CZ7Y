{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reference\nThis Notebook uses the code provided by firefliesqn,Link Below\nhttps://www.kaggle.com/firefliesqn/tabnet-cv-0-81\nThanks for providing the code firefliesqn","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-05T09:13:02.097768Z","iopub.execute_input":"2021-11-05T09:13:02.098279Z","iopub.status.idle":"2021-11-05T09:13:02.119282Z","shell.execute_reply.started":"2021-11-05T09:13:02.098195Z","shell.execute_reply":"2021-11-05T09:13:02.118511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installing TabNet","metadata":{}},{"cell_type":"code","source":"!pip install pytorch_tabnet ","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:13:18.777638Z","iopub.execute_input":"2021-11-05T09:13:18.778393Z","iopub.status.idle":"2021-11-05T09:13:27.911593Z","shell.execute_reply.started":"2021-11-05T09:13:18.778355Z","shell.execute_reply":"2021-11-05T09:13:27.910584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import roc_auc_score\nnp.random.seed(0)\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import QuantileTransformer,  KBinsDiscretizer\nfrom sklearn.impute import SimpleImputer\n\nimport torch\n\nfrom sklearn.decomposition import PCA\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:13:51.118559Z","iopub.execute_input":"2021-11-05T09:13:51.119241Z","iopub.status.idle":"2021-11-05T09:13:53.316156Z","shell.execute_reply.started":"2021-11-05T09:13:51.119198Z","shell.execute_reply":"2021-11-05T09:13:53.315404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')\n\ntrain['n_missing'] = train.isna().sum(axis=1)\ntest['n_missing'] = test.isna().sum(axis=1)\ntrain['target'] = train['target'].astype(str)\n\nfeatures = [col for col in train.columns if col not in ['target', 'id']]\n\npipe = Pipeline([\n        ('imputer', SimpleImputer(strategy='median',missing_values=np.nan)),\n        (\"scaler\", QuantileTransformer(n_quantiles=200, output_distribution='normal'))\n        ])\nX = pipe.fit_transform(train[features])\nX_test=pipe.transform(test[features])","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:15:24.227648Z","iopub.execute_input":"2021-11-05T09:15:24.228242Z","iopub.status.idle":"2021-11-05T09:16:28.99048Z","shell.execute_reply.started":"2021-11-05T09:15:24.228201Z","shell.execute_reply":"2021-11-05T09:16:28.989699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:16:54.172117Z","iopub.execute_input":"2021-11-05T09:16:54.172592Z","iopub.status.idle":"2021-11-05T09:16:54.205332Z","shell.execute_reply.started":"2021-11-05T09:16:54.172554Z","shell.execute_reply":"2021-11-05T09:16:54.204629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"tabnet_params = dict(n_steps = 1,\n                   optimizer_fn=torch.optim.Adam,\n                   optimizer_params=dict(lr=1e-2, weight_decay = 5e-4),\n                   scheduler_params={\"step_size\":1, # how to use learning rate scheduler\n                                     \"gamma\":0.9},\n                   scheduler_fn=torch.optim.lr_scheduler.StepLR,\n                   mask_type='entmax',\n                   verbose = 5)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:17:20.665411Z","iopub.execute_input":"2021-11-05T09:17:20.666003Z","iopub.status.idle":"2021-11-05T09:17:20.671329Z","shell.execute_reply.started":"2021-11-05T09:17:20.665963Z","shell.execute_reply":"2021-11-05T09:17:20.670541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport torch\n\nkf = KFold(n_splits=5, random_state = 42, shuffle = True)\npreds = np.zeros((540000,))\nfor  fold , (train_index, test_index) in enumerate(kf.split(X)):\n    print(20*\"*\")\n    print(\"Fold {}:\".format(fold))\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = train.target[train_index].values, train.target[test_index].values\n\n    clf = TabNetClassifier(**tabnet_params)\n    clf.fit(\n        X_train=X_train, y_train=y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        eval_name=['train', 'valid'],\n        eval_metric=['auc'],\n        max_epochs= 10, patience=5,\n        batch_size=1024*10, virtual_batch_size=128*10,\n        num_workers=0,\n        weights=1,\n        drop_last=False\n    ) \n    preds += clf.predict_proba(X_test)[:,1]/5\n    print(preds.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:24:24.946461Z","iopub.execute_input":"2021-11-05T09:24:24.946728Z","iopub.status.idle":"2021-11-05T09:33:24.431738Z","shell.execute_reply.started":"2021-11-05T09:24:24.946683Z","shell.execute_reply":"2021-11-05T09:33:24.430855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv')\nsub.iloc[:,1]= preds\nsub=sub.set_index('id')\nsub.to_csv('submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-05T09:34:38.329935Z","iopub.execute_input":"2021-11-05T09:34:38.330398Z","iopub.status.idle":"2021-11-05T09:34:40.264825Z","shell.execute_reply.started":"2021-11-05T09:34:38.330353Z","shell.execute_reply":"2021-11-05T09:34:40.264117Z"},"trusted":true},"execution_count":null,"outputs":[]}]}