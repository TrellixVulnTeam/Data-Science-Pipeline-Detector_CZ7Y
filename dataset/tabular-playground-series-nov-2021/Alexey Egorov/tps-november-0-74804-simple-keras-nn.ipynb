{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS November: simple Keras NN + GPU\n\nThis notebook work with simple Keras NN with GPU.\n\nNotebook plan:\n\n1. Modules import.\n2. Utils.\n3. Data load and prepare\n4. NN creation and training.\n5. Results.","metadata":{}},{"cell_type":"markdown","source":"## Modules","metadata":{}},{"cell_type":"code","source":"import os # operation system variables\nimport gc \n\nimport numpy as np\nimport pandas as pd\nimport feather\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler # data preprocessing\nfrom sklearn.pipeline import make_pipeline # additionals modules\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras # nn modeling\nfrom tensorflow.keras import layers\nimport tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:51:24.96653Z","iopub.execute_input":"2021-11-02T10:51:24.967259Z","iopub.status.idle":"2021-11-02T10:51:32.011506Z","shell.execute_reply.started":"2021-11-02T10:51:24.967204Z","shell.execute_reply":"2021-11-02T10:51:32.010528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we activate GPU and swithc off warnings.","metadata":{}},{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #suppressing GPU warnings\nos.environ[\"CUDA_VISIBLE_DEVICES\"]='1'# GPU using on","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:51:32.013051Z","iopub.execute_input":"2021-11-02T10:51:32.01328Z","iopub.status.idle":"2021-11-02T10:51:32.019007Z","shell.execute_reply.started":"2021-11-02T10:51:32.013252Z","shell.execute_reply":"2021-11-02T10:51:32.017776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check GPU status.","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:51:32.020575Z","iopub.execute_input":"2021-11-02T10:51:32.021273Z","iopub.status.idle":"2021-11-02T10:51:32.075466Z","shell.execute_reply.started":"2021-11-02T10:51:32.021233Z","shell.execute_reply":"2021-11-02T10:51:32.074431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.debugging.set_log_device_placement(True)\n\n# Create some tensors\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\n\nprint(c)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T07:57:54.357828Z","iopub.execute_input":"2021-11-02T07:57:54.358326Z","iopub.status.idle":"2021-11-02T07:57:54.369523Z","shell.execute_reply.started":"2021-11-02T07:57:54.358289Z","shell.execute_reply":"2021-11-02T07:57:54.368716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Utils\n\nWe use only one util to reduce memory usage.","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n#                 elif\n\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:51:32.078515Z","iopub.execute_input":"2021-11-02T10:51:32.07955Z","iopub.status.idle":"2021-11-02T10:51:32.097154Z","shell.execute_reply.started":"2021-11-02T10:51:32.079493Z","shell.execute_reply":"2021-11-02T10:51:32.096298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data load and prepare\n\nAt first we load data to our memory, then reduce memory usage.","metadata":{}},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv', index_col='id')\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:17:10.812032Z","iopub.execute_input":"2021-11-02T11:17:10.812372Z","iopub.status.idle":"2021-11-02T11:17:36.643978Z","shell.execute_reply.started":"2021-11-02T11:17:10.812335Z","shell.execute_reply":"2021-11-02T11:17:36.642795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:17:36.646082Z","iopub.execute_input":"2021-11-02T11:17:36.646693Z","iopub.status.idle":"2021-11-02T11:17:51.035894Z","shell.execute_reply.started":"2021-11-02T11:17:36.64664Z","shell.execute_reply":"2021-11-02T11:17:51.034539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:52:20.394832Z","iopub.execute_input":"2021-11-02T10:52:20.395075Z","iopub.status.idle":"2021-11-02T10:52:20.414038Z","shell.execute_reply.started":"2021-11-02T10:52:20.395046Z","shell.execute_reply":"2021-11-02T10:52:20.412696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train.pop('target')\nsubmission_index = test.index\nfeatures = list(train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:17:51.037378Z","iopub.execute_input":"2021-11-02T11:17:51.037611Z","iopub.status.idle":"2021-11-02T11:17:51.047804Z","shell.execute_reply.started":"2021-11-02T11:17:51.037582Z","shell.execute_reply":"2021-11-02T11:17:51.046222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we do preprocessing: standartization and normalization. \nWe have to do same operation with test data as train data.","metadata":{}},{"cell_type":"code","source":"numerical_transformer = make_pipeline(\n    StandardScaler(), #Standardization\n    MinMaxScaler(),    #Normalization\n)\n\npreprocessor = make_column_transformer(\n    (numerical_transformer, features), #since all features are numerical/continous\n)\n\ntrain = preprocessor.fit_transform(train)\ntest = preprocessor.transform(test)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:17:51.050061Z","iopub.execute_input":"2021-11-02T11:17:51.050304Z","iopub.status.idle":"2021-11-02T11:17:53.549488Z","shell.execute_reply.started":"2021-11-02T11:17:51.050276Z","shell.execute_reply":"2021-11-02T11:17:53.54834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train, y, test_size=0.33)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:17:53.550832Z","iopub.execute_input":"2021-11-02T11:17:53.551059Z","iopub.status.idle":"2021-11-02T11:17:54.248817Z","shell.execute_reply.started":"2021-11-02T11:17:53.551032Z","shell.execute_reply":"2021-11-02T11:17:54.247904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. NN creation and training\n\nWe use simple NN model with 3 hidden layers (128, 64, 32 neurons).","metadata":{}},{"cell_type":"code","source":"input_shape = [x_train.shape[1]]\nPATIENCE = 10\nMIN_DELTA = 0.0005\n\nmodel = keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(units=166, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(units=100, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(units=50, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    layers.Dense(units=1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n\n#early_stopping = keras.callbacks.EarlyStopping( # it's important feature to stop our training procedure early\n#    patience=PATIENCE,\n#    min_delta=MIN_DELTA,\n#    restore_best_weights=True,\n#)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:06.842821Z","iopub.execute_input":"2021-11-02T11:32:06.843142Z","iopub.status.idle":"2021-11-02T11:32:06.957306Z","shell.execute_reply.started":"2021-11-02T11:32:06.843097Z","shell.execute_reply":"2021-11-02T11:32:06.95632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:20:36.259897Z","iopub.execute_input":"2021-11-02T11:20:36.260202Z","iopub.status.idle":"2021-11-02T11:20:36.270654Z","shell.execute_reply.started":"2021-11-02T11:20:36.260169Z","shell.execute_reply":"2021-11-02T11:20:36.269941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nBATCH_SIZE = 128\nEPOCHS = 40\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_data=(x_val, y_val),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    #callbacks=[early_stopping], \n    verbose=1 # we need it to control ou NN training\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:09.334743Z","iopub.execute_input":"2021-11-02T11:32:09.335168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Results\n\nPredict our results and save them to `submission.csv`","metadata":{}},{"cell_type":"code","source":"%%time\ny_pred_f = model.predict(test).ravel()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:15:16.635186Z","iopub.execute_input":"2021-11-02T09:15:16.635673Z","iopub.status.idle":"2021-11-02T09:16:05.794074Z","shell.execute_reply.started":"2021-11-02T09:15:16.635616Z","shell.execute_reply":"2021-11-02T09:16:05.792663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_f ","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:16:05.796275Z","iopub.execute_input":"2021-11-02T09:16:05.796811Z","iopub.status.idle":"2021-11-02T09:16:05.810312Z","shell.execute_reply.started":"2021-11-02T09:16:05.796765Z","shell.execute_reply":"2021-11-02T09:16:05.809055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_f = np.array([1 if x>=0.5 else 0 for x in y_pred_f])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T08:35:00.792669Z","iopub.execute_input":"2021-11-02T08:35:00.793464Z","iopub.status.idle":"2021-11-02T08:35:02.467263Z","shell.execute_reply.started":"2021-11-02T08:35:00.793412Z","shell.execute_reply":"2021-11-02T08:35:02.466397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_f ","metadata":{"execution":{"iopub.status.busy":"2021-11-02T08:35:02.548203Z","iopub.execute_input":"2021-11-02T08:35:02.548669Z","iopub.status.idle":"2021-11-02T08:35:02.555079Z","shell.execute_reply.started":"2021-11-02T08:35:02.548618Z","shell.execute_reply":"2021-11-02T08:35:02.554229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = y_pred_f\nsub.to_csv('submission.csv', index = 0)\nsub","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:16:05.813786Z","iopub.execute_input":"2021-11-02T09:16:05.815288Z","iopub.status.idle":"2021-11-02T09:16:07.796173Z","shell.execute_reply.started":"2021-11-02T09:16:05.815227Z","shell.execute_reply":"2021-11-02T09:16:07.795117Z"},"trusted":true},"execution_count":null,"outputs":[]}]}