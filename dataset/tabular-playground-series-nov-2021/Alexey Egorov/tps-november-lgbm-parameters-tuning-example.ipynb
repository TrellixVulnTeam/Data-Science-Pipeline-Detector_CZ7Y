{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Discription\nThis notebook work with two simple ML model: KNN and LogisticRegression.\n\nNotebook plan:\n\n1. Modules import.\n2. Utils.\n3. LGBM parameters tuning and modeling.\n3. Full model training.","metadata":{}},{"cell_type":"markdown","source":"## Modules","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nfrom sklearn.model_selection import train_test_split, cross_validate # creat train and test datasets to modeling\nfrom sklearn.metrics import classification_report, f1_score, precision_score, recall_score # report and metrics modules \n\n\n# ML models upload\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Additional models\nimport xgboost as xgb, lightgbm as lgbm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T12:37:07.349589Z","iopub.execute_input":"2021-11-01T12:37:07.35055Z","iopub.status.idle":"2021-11-01T12:37:07.357656Z","shell.execute_reply.started":"2021-11-01T12:37:07.350491Z","shell.execute_reply":"2021-11-01T12:37:07.356843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:39:24.839168Z","iopub.execute_input":"2021-11-01T12:39:24.839832Z","iopub.status.idle":"2021-11-01T12:39:24.843816Z","shell.execute_reply.started":"2021-11-01T12:39:24.839793Z","shell.execute_reply":"2021-11-01T12:39:24.842904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do not forget to update sklearn vesrsion.","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn  -U","metadata":{"execution":{"iopub.status.busy":"2021-11-01T11:46:07.309423Z","iopub.execute_input":"2021-11-01T11:46:07.309977Z","iopub.status.idle":"2021-11-01T11:46:23.272483Z","shell.execute_reply.started":"2021-11-01T11:46:07.309923Z","shell.execute_reply":"2021-11-01T11:46:23.271634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Utils\n\nWe use three difeerent functions:\n\n1. reduce_mem_usage - to deduce dataset memory size \n2. show_proba_calibration_plots - to visualize the key characteristics of learning outcomes\n3. get_classification_report - to see simple classification report","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n#                 elif\n\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-01T11:46:23.291614Z","iopub.execute_input":"2021-11-01T11:46:23.291869Z","iopub.status.idle":"2021-11-01T11:46:23.308214Z","shell.execute_reply.started":"2021-11-01T11:46:23.291839Z","shell.execute_reply":"2021-11-01T11:46:23.307357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_proba_calibration_plots(y_predicted_probs, y_true_labels):\n    preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n\n    thresholds = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n\n    for threshold in np.linspace(0.1, 0.9, 50):\n        thresholds.append(threshold)\n        precisions.append(precision_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n        recalls.append(recall_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n        f1_scores.append(f1_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n\n    scores_table = pd.DataFrame({'f1':f1_scores,\n                                 'precision':precisions,\n                                 'recall':recalls,\n                                 'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n  \n    figure = plt.figure(figsize = (25, 12))\n\n    plt1 = figure.add_subplot(121)\n    plt1.plot(thresholds, precisions, label='Precision', linewidth=4)\n    plt1.plot(thresholds, recalls, label='Recall', linewidth=4)\n    plt1.plot(thresholds, f1_scores, label='F1', linewidth=4)\n    plt1.set_ylabel('Scores')\n    plt1.set_xlabel('Probability threshold')\n    plt1.set_title('Probabilities threshold calibration')\n    plt1.legend(bbox_to_anchor=(0.25, 0.25))   \n    plt1.table(cellText = scores_table.values,\n               colLabels = scores_table.columns, \n               colLoc = 'center', cellLoc = 'center', loc = 'bottom', bbox = [0, -1.1, 1, 1])\n\n    plt2 = figure.add_subplot(122)\n    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 0][:, 0], \n              label='Another class', color='royalblue', alpha=1)\n    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 1][:, 0], \n              label='Main class', color='darkcyan', alpha=0.8)\n    plt2.set_ylabel('Number of examples')\n    plt2.set_xlabel('Probabilities')\n    plt2.set_title('Probability histogram')\n    plt2.legend(bbox_to_anchor=(1, 1))\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:24:51.664878Z","iopub.execute_input":"2021-11-01T12:24:51.665814Z","iopub.status.idle":"2021-11-01T12:24:51.679715Z","shell.execute_reply.started":"2021-11-01T12:24:51.665776Z","shell.execute_reply":"2021-11-01T12:24:51.679056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n    print('CONFUSION MATRIX\\n')\n    print(pd.crosstab(y_test_true, y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T11:46:23.330428Z","iopub.execute_input":"2021-11-01T11:46:23.330723Z","iopub.status.idle":"2021-11-01T11:46:23.344762Z","shell.execute_reply.started":"2021-11-01T11:46:23.330642Z","shell.execute_reply":"2021-11-01T11:46:23.343727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data load and work preparation\n\nDownload data and prepare it to modeling. ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv')\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:08.15481Z","iopub.execute_input":"2021-11-01T13:01:08.155111Z","iopub.status.idle":"2021-11-01T13:01:27.630475Z","shell.execute_reply.started":"2021-11-01T13:01:08.155076Z","shell.execute_reply":"2021-11-01T13:01:27.629829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\nsub = reduce_mem_usage(sub)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:27.631894Z","iopub.execute_input":"2021-11-01T13:01:27.632134Z","iopub.status.idle":"2021-11-01T13:01:42.191092Z","shell.execute_reply.started":"2021-11-01T13:01:27.632105Z","shell.execute_reply":"2021-11-01T13:01:42.190204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T11:47:08.597063Z","iopub.execute_input":"2021-11-01T11:47:08.597303Z","iopub.status.idle":"2021-11-01T11:47:08.617409Z","shell.execute_reply.started":"2021-11-01T11:47:08.597273Z","shell.execute_reply":"2021-11-01T11:47:08.616437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_features = list(train.columns) [1:-1]","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:42.192313Z","iopub.execute_input":"2021-11-01T13:01:42.192526Z","iopub.status.idle":"2021-11-01T13:01:42.197379Z","shell.execute_reply.started":"2021-11-01T13:01:42.1925Z","shell.execute_reply":"2021-11-01T13:01:42.196737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[base_features]\ny = train['target']\nX_test_fin = test[base_features]","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:42.198999Z","iopub.execute_input":"2021-11-01T13:01:42.199331Z","iopub.status.idle":"2021-11-01T13:01:42.636994Z","shell.execute_reply.started":"2021-11-01T13:01:42.199301Z","shell.execute_reply":"2021-11-01T13:01:42.636116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.30)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:42.638245Z","iopub.execute_input":"2021-11-01T13:01:42.63848Z","iopub.status.idle":"2021-11-01T13:01:43.001606Z","shell.execute_reply.started":"2021-11-01T13:01:42.638451Z","shell.execute_reply":"2021-11-01T13:01:43.000849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 0\nfold = 2","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:43.002749Z","iopub.execute_input":"2021-11-01T13:01:43.003149Z","iopub.status.idle":"2021-11-01T13:01:43.00631Z","shell.execute_reply.started":"2021-11-01T13:01:43.003099Z","shell.execute_reply":"2021-11-01T13:01:43.005707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling\n","metadata":{}},{"cell_type":"code","source":"'''\nmodel_lgbm = lgbm.LGBMClassifier(\n    num_iterations=100,\n    objective = \"binary\",\n    num_leaves= 31,\n    feature_pre_filter = False\n    )\ndef score(X, y, model_lgbm, cv):\n    scoring = [\"roc_auc\"]\n    scores = cross_validate(\n        model_lgbm, X, y, scoring=scoring, cv=cv, return_train_score=True\n    )\n    scores = pd.DataFrame(scores).T\n    return scores.assign(\n        mean = lambda x: x.mean(axis=1),\n        std = lambda x: x.std(axis=1),\n    )\n\nscores = score(X, y, model_lgbm, cv=fold)\ndisplay(scores)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:37:11.212498Z","iopub.execute_input":"2021-11-01T12:37:11.21324Z","iopub.status.idle":"2021-11-01T12:39:01.421717Z","shell.execute_reply.started":"2021-11-01T12:37:11.213182Z","shell.execute_reply":"2021-11-01T12:39:01.420853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef score(X, y, model_lgbm, cv):\n    scoring = [\"roc_auc\"]\n    scores = cross_validate(\n        model_lgbm, X, y, scoring=scoring, cv=cv, return_train_score=True\n    )\n    scores = pd.DataFrame(scores).T\n    return scores.assign(\n        mean = lambda x: x.mean(axis=1),\n        std = lambda x: x.std(axis=1),\n    )\n\ntest_roc_auc_row = []\n\nfor num_iter in range(200, 700, 40):\n    for max_d in range (8, 15, 1):\n        model_lgbm = lgbm.LGBMClassifier(\n        num_iterations=num_iter,\n        objective = \"binary\",\n        feature_pre_filter = False,\n        max_depth = max_d\n        )\n\n        res = {}\n        res['num_iter'] = num_iter\n        res['max_depth'] = max_d\n        scores = score(X, y, model_lgbm, cv=fold)\n        res['test_roc_auc'] = scores.loc['test_roc_auc','mean']\n        print(num_iter, max_d, res['test_roc_auc'])\n\n        test_roc_auc_row.append(res)'''","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:01:44.986435Z","iopub.execute_input":"2021-11-01T13:01:44.986757Z","iopub.status.idle":"2021-11-01T15:06:43.610002Z","shell.execute_reply.started":"2021-11-01T13:01:44.986719Z","shell.execute_reply":"2021-11-01T15:06:43.609143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''df = pd.DataFrame(test_roc_auc_row)\ndf.sort_values(by='test_roc_auc', ascending=False).head(10)'''","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:06:43.611776Z","iopub.execute_input":"2021-11-01T15:06:43.612076Z","iopub.status.idle":"2021-11-01T15:06:43.62609Z","shell.execute_reply.started":"2021-11-01T15:06:43.612034Z","shell.execute_reply":"2021-11-01T15:06:43.625115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Final mode train","metadata":{}},{"cell_type":"code","source":"model_fin = lgbm.LGBMClassifier(num_iterations = 240,max_depth = 13, eval_metric='auc')\nmodel_fin.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:07:55.262183Z","iopub.execute_input":"2021-11-01T15:07:55.262477Z","iopub.status.idle":"2021-11-01T15:08:43.684039Z","shell.execute_reply.started":"2021-11-01T15:07:55.262444Z","shell.execute_reply":"2021-11-01T15:08:43.683342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_fin.predict_proba(X_test_fin)\ny_pred_f = np.array([1 if x>=0.5 else 0 for x in predictions[:,1]])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:08:43.687696Z","iopub.execute_input":"2021-11-01T15:08:43.688254Z","iopub.status.idle":"2021-11-01T15:08:48.479213Z","shell.execute_reply.started":"2021-11-01T15:08:43.688218Z","shell.execute_reply":"2021-11-01T15:08:48.478487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = y_pred_f\nsub.to_csv('submission.csv', index = 0)\nsub","metadata":{"execution":{"iopub.status.busy":"2021-11-01T15:08:49.492942Z","iopub.execute_input":"2021-11-01T15:08:49.493146Z","iopub.status.idle":"2021-11-01T15:08:50.507295Z","shell.execute_reply.started":"2021-11-01T15:08:49.49312Z","shell.execute_reply":"2021-11-01T15:08:50.506386Z"},"trusted":true},"execution_count":null,"outputs":[]}]}