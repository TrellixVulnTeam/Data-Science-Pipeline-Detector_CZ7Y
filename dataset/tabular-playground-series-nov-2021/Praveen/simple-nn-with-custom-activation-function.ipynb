{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Learning with Feature Engineering \n\nThis is a simple model with neural networks, I hope that you like it. It will be a pleasure hear any comment or feedback.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# Reading the dataset\nraw_train = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\nraw_test = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")\n\ntrain = raw_train.drop(['id','target'], axis = 1)\ntest = raw_test.drop('id', axis = 1)\n\ntarget = raw_train.target\nid_train = raw_train.id\nid_test = raw_test.id\n\n\n# -----------------------------------------------------------------\n# Some parameters to config \n\nEPOCHS = 700\nBATCH_SIZE = 2048 \nACTIVATION = 'swish'\nLEARNING_RATE = 0.0007\nFOLDS = 5","metadata":{"papermill":{"duration":28.22398,"end_time":"2021-11-10T03:26:44.193802","exception":false,"start_time":"2021-11-10T03:26:15.969822","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T14:02:44.642693Z","iopub.execute_input":"2021-11-11T14:02:44.643058Z","iopub.status.idle":"2021-11-11T14:03:13.81022Z","shell.execute_reply.started":"2021-11-11T14:02:44.642966Z","shell.execute_reply":"2021-11-11T14:03:13.809223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering\n\nTo begin I split the dataset by distribution of each column and added some basic columns (mea, std, var, mean, etc).","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\n# the number 2 is just a threshold to split \nh_skew = train.loc[:,train.skew() >= 2].columns  # with Skewed \nl_skew = train.loc[:,train.skew() < 2].columns   # Bimodal\n\n# -----------------------------------------------------------------\n# Skewed distrubutions\n\n# train['mean_h'] = train[h_skew].mean(axis=1)\n# test['mean_h'] = test[h_skew].mean(axis=1)\n\n# train['std_h'] = np.log1p(train[h_skew].std(axis=1))\n# test['std_h'] = np.log1p(test[h_skew].std(axis=1))\n\ntrain['median_h'] = train[h_skew].median(axis=1)\ntest['median_h'] = test[h_skew].median(axis=1)\n\n# train['min_h'] = train[h_skew].min(axis=1)\n# test['min_h'] = test[h_skew].min(axis=1)\n\n# train['skew_h'] = train[h_skew].skew(axis=1)\n# test['skew_h'] = test[h_skew].skew(axis=1)\n\n# train['max_h'] = train[h_skew].max(axis=1)\n# test['max_h'] = test[h_skew].max(axis=1)\n\ntrain['var_h'] = train[h_skew].var(axis=1)\ntest['var_h'] = test[h_skew].var(axis=1)\n\n# -----------------------------------------------------------------\n# Bimodal distributions\n\ntrain['mean_l'] = train[l_skew].mean(axis=1)\ntest['mean_l'] = test[l_skew].mean(axis=1)\n\ntrain['std_l'] = train[l_skew].std(axis=1)\ntest['std_l'] = test[l_skew].std(axis=1)\n\ntrain['median_l'] = train[l_skew].median(axis=1)\ntest['median_l'] = test[l_skew].median(axis=1)\n\n# train['min_l'] = train[l_skew].min(axis=1)\n# test['min_l'] = test[l_skew].min(axis=1)\n\ntrain['skew_l'] = train[l_skew].skew(axis=1)\ntest['skew_l'] = test[l_skew].skew(axis=1)\n\ntrain['max_l'] = train[l_skew].max(axis=1)\ntest['max_l'] = test[l_skew].max(axis=1)\n\ntrain['var_l'] = train[l_skew].var(axis=1)\ntest['var_l'] = test[l_skew].var(axis=1)\n\n\nraw_train = train.copy()\nraw_test = test.copy()\n\n# -----------------------------------------------------------------\n# Scaling and Nomalization\n\ntransformer_high_skew = make_pipeline(\n    StandardScaler(), \n    MinMaxScaler(feature_range=(0, 1))\n)\n\ntransformer_low_skew = make_pipeline(\n    StandardScaler(),\n    MinMaxScaler(feature_range=(0, 1))\n)\n\nnew_cols = train.columns[-8:]\n\ntransformer_new_cols = make_pipeline(\n    StandardScaler(),\n    MinMaxScaler(feature_range=(0, 1))\n)\n\npreprocessor = make_column_transformer(\n    (transformer_high_skew, l_skew),\n    (transformer_low_skew, h_skew),\n    (transformer_new_cols, new_cols),\n)","metadata":{"papermill":{"duration":13.455351,"end_time":"2021-11-10T03:26:57.659068","exception":false,"start_time":"2021-11-10T03:26:44.203717","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T14:03:13.812413Z","iopub.execute_input":"2021-11-11T14:03:13.812784Z","iopub.status.idle":"2021-11-11T14:03:29.090836Z","shell.execute_reply.started":"2021-11-11T14:03:13.812736Z","shell.execute_reply":"2021-11-11T14:03:29.089868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network","metadata":{}},{"cell_type":"markdown","source":"### Custom Activation Function","metadata":{}},{"cell_type":"markdown","source":"#### model.add(Conv2D(64, (3, 3)))\n\n#### model.add(Swish(beta=1.0, trainable=True))","metadata":{}},{"cell_type":"code","source":"from keras.layers import Layer\n\nclass Swish(Layer):\n\n    def __init__(self, beta=1.0, trainable=False, **kwargs):\n        super(Swish, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.beta = beta\n        self.trainable = trainable\n\n    def build(self, input_shape):\n        self.beta_factor = K.variable(self.beta,\n                                      dtype=K.floatx(),\n                                      name='beta_factor')\n        if self.trainable:\n            self._trainable_weights.append(self.beta_factor)\n\n        super(Swish, self).build(input_shape)\n\n    def call(self, inputs, mask=None):\n        return swish(inputs, self.beta_factor)\n\n    def get_config(self):\n        config = {'beta': self.get_weights()[0] if self.trainable else self.beta,\n                  'trainable': self.trainable}\n        base_config = super(Swish, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:24:32.984461Z","iopub.execute_input":"2021-11-11T14:24:32.984925Z","iopub.status.idle":"2021-11-11T14:24:32.996546Z","shell.execute_reply.started":"2021-11-11T14:24:32.984873Z","shell.execute_reply":"2021-11-11T14:24:32.995296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.layers.core import Activation\nfrom keras.utils.generic_utils import get_custom_objects\n\n### Note! You cannot use random python functions, activation function gets as an input tensorflow tensors and should return tensors. There are a lot of helper functions in keras backend.\ndef custom_activation(x):\n  \n    return (1/(1 + K.exp(-x)))\n     \nget_custom_objects().update({'custom_activation': Activation(custom_activation)})","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:31:48.581084Z","iopub.execute_input":"2021-11-11T14:31:48.581387Z","iopub.status.idle":"2021-11-11T14:31:48.589611Z","shell.execute_reply.started":"2021-11-11T14:31:48.581354Z","shell.execute_reply":"2021-11-11T14:31:48.588524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\n\nimport tensorflow as tf\nimport random\nimport os\n\n# -----------------------------------------------------------------\n# Seed \n\nmy_seed = 42\ndef seedAll(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \nseedAll(my_seed)\n\n# -----------------------------------------------------------------\n\ndef load_model(name:str):\n    \n    early_stopping = callbacks.EarlyStopping(\n        patience=20,\n        min_delta=0,\n        monitor='val_loss',\n        restore_best_weights=True,\n        verbose=0,\n        mode='min', \n        baseline=None,\n    )\n\n    plateau = callbacks.ReduceLROnPlateau(\n            monitor='val_loss', \n            factor=0.2, \n            patience=7, \n            verbose=0,\n            mode='min')\n\n# -----------------------------------------------------------------\n# Model \n\n    model = keras.Sequential([\n        layers.Dense(108, activation = ACTIVATION, input_shape = [train.shape[1]]),      \n        layers.Dense(64, activation =ACTIVATION), \n        layers.Dense(32, activation =ACTIVATION),\n        layers.Dense(1, activation='sigmoid'),\n    ])\n\n# -----------------------------------------------------------------\n\n    model.compile(\n        optimizer= keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n        loss='binary_crossentropy',\n        metrics=['AUC'],\n    )\n    \n    return model, early_stopping, plateau","metadata":{"papermill":{"duration":4.804345,"end_time":"2021-11-10T03:27:02.470705","exception":false,"start_time":"2021-11-10T03:26:57.66636","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T14:03:29.092378Z","iopub.execute_input":"2021-11-11T14:03:29.092741Z","iopub.status.idle":"2021-11-11T14:03:35.289794Z","shell.execute_reply.started":"2021-11-11T14:03:29.092695Z","shell.execute_reply":"2021-11-11T14:03:35.288801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n\npreds_valid_f = {}\npreds_test = []\ntotal_auc = []\nf_scores = []\n\nkf = StratifiedKFold(n_splits=FOLDS,random_state=0,shuffle=True)\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(train,target)):\n\n    X_train,X_valid = train.loc[train_index], train.loc[valid_index]\n    y_train,y_valid = target.loc[train_index], target.loc[valid_index]\n\n    #   --------------------------------------------------------  \n    # Preprocessing\n    index_valid  = X_valid.index.tolist()\n    test  = raw_test.copy()\n    \n    X_train = preprocessor.fit_transform(X_train)\n    X_valid = preprocessor.transform(X_valid)\n    test = preprocessor.transform(test)\n    \n    #  ----------------------------------------------------------    \n    # Model\n    \n    model, early_stopping, plateau  = load_model('version1')\n\n    history = model.fit(  X_train, y_train,\n                validation_data = (X_valid, y_valid),\n                batch_size = BATCH_SIZE, \n                epochs = EPOCHS,\n                callbacks = [early_stopping, plateau],\n                shuffle = True,\n                verbose = 0\n              )\n\n    #  ----------------------------------------------------------\n    #  oof\n    preds_valid = model.predict(X_valid).reshape(1,-1)[0] \n    \n    #  ----------------------------------------------------------\n    #  test  predictions\n    preds_test.append(model.predict(test).reshape(1,-1)[0])\n    \n    #  ----------------------------------------------------------\n    #  Saving  scores to plot the end  \n    scores = pd.DataFrame(history.history)\n    scores['folds'] = fold\n    \n    if fold == 0:\n        f_scores = scores \n    else: \n        f_scores = pd.concat([f_scores, scores], axis  = 0)\n        \n    #  ----------------------------------------------------------\n    #  concatenating valid preds\n    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n\n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, preds_valid)\n    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n\n    # Total auc\n    total_auc.append(fold_auc)\n\nprint(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")","metadata":{"papermill":{"duration":904.734462,"end_time":"2021-11-10T03:42:07.212492","exception":false,"start_time":"2021-11-10T03:27:02.47803","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T14:03:35.292576Z","iopub.execute_input":"2021-11-11T14:03:35.292946Z","iopub.status.idle":"2021-11-11T14:24:27.332566Z","shell.execute_reply.started":"2021-11-11T14:03:35.292899Z","shell.execute_reply":"2021-11-11T14:24:27.33145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outcomes","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor fold in range(f_scores['folds'].nunique()):\n    history_f = f_scores[f_scores['folds'] == fold]\n\n    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n    fig.suptitle('Fold : '+str(fold), fontsize=14)\n        \n    plt.subplot(1,2,1)\n    plt.plot(history_f.loc[:, ['loss', 'val_loss']], label= ['loss', 'val_loss'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    plt.subplot(1,2,2)\n    plt.plot(history_f.loc[:, ['auc', 'val_auc']],label= ['auc', 'val_auc'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    print(\"Validation Loss: {:0.4f}\".format(history_f['val_loss'].min()));","metadata":{"papermill":{"duration":2.963485,"end_time":"2021-11-10T03:42:10.185167","exception":false,"start_time":"2021-11-10T03:42:07.221682","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T14:24:27.334569Z","iopub.execute_input":"2021-11-11T14:24:27.334948Z","iopub.status.idle":"2021-11-11T14:24:31.197956Z","shell.execute_reply.started":"2021-11-11T14:24:27.3349Z","shell.execute_reply":"2021-11-11T14:24:31.196732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\nsub['target'] = np.mean(preds_test, axis = 0)\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"papermill":{"duration":1.933432,"end_time":"2021-11-10T03:42:12.172879","exception":false,"start_time":"2021-11-10T03:42:10.239447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T14:24:31.199764Z","iopub.execute_input":"2021-11-11T14:24:31.200207Z","iopub.status.idle":"2021-11-11T14:24:32.982032Z","shell.execute_reply.started":"2021-11-11T14:24:31.200159Z","shell.execute_reply":"2021-11-11T14:24:32.980967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"from keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:30:32.217802Z","iopub.execute_input":"2021-11-11T14:30:32.21811Z","iopub.status.idle":"2021-11-11T14:30:32.223579Z","shell.execute_reply.started":"2021-11-11T14:30:32.218077Z","shell.execute_reply":"2021-11-11T14:30:32.221789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\n\nimport tensorflow as tf\nimport random\nimport os\n\n# -----------------------------------------------------------------\n# Seed \n\nmy_seed = 42\ndef seedAll(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \nseedAll(my_seed)\n\n# -----------------------------------------------------------------\n\ndef load_model(name:str):\n    \n    early_stopping = callbacks.EarlyStopping(\n        patience=20,\n        min_delta=0,\n        monitor='val_loss',\n        restore_best_weights=True,\n        verbose=0,\n        mode='min', \n        baseline=None,\n    )\n\n    plateau = callbacks.ReduceLROnPlateau(\n            monitor='val_loss', \n            factor=0.2, \n            patience=7, \n            verbose=0,\n            mode='min')\n\n# -----------------------------------------------------------------\n# Model \n\n    model = keras.Sequential([\n        layers.Dense(108, activation = ACTIVATION, input_shape = [train.shape[1]]),      \n        layers.Dense(64, activation =ACTIVATION), \n        layers.Dense(32, activation =ACTIVATION),\n        layers.Dense(1, activation='custom_activation'),\n    ])\n\n# -----------------------------------------------------------------\n\n    model.compile(\n        optimizer= keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n        loss='binary_crossentropy',\n        metrics=['AUC'],\n    )\n    \n    return model, early_stopping, plateau","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:32:18.860248Z","iopub.execute_input":"2021-11-11T14:32:18.860561Z","iopub.status.idle":"2021-11-11T14:32:18.8755Z","shell.execute_reply.started":"2021-11-11T14:32:18.860527Z","shell.execute_reply":"2021-11-11T14:32:18.874345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n\npreds_valid_f = {}\npreds_test = []\ntotal_auc = []\nf_scores = []\n\nkf = StratifiedKFold(n_splits=FOLDS,random_state=0,shuffle=True)\n\nfor fold,(train_index, valid_index) in enumerate(kf.split(train,target)):\n\n    X_train,X_valid = train.loc[train_index], train.loc[valid_index]\n    y_train,y_valid = target.loc[train_index], target.loc[valid_index]\n\n    #   --------------------------------------------------------  \n    # Preprocessing\n    index_valid  = X_valid.index.tolist()\n    test  = raw_test.copy()\n    \n    X_train = preprocessor.fit_transform(X_train)\n    X_valid = preprocessor.transform(X_valid)\n    test = preprocessor.transform(test)\n    \n    #  ----------------------------------------------------------    \n    # Model\n    \n    model, early_stopping, plateau  = load_model('version1')\n\n    history = model.fit(  X_train, y_train,\n                validation_data = (X_valid, y_valid),\n                batch_size = BATCH_SIZE, \n                epochs = EPOCHS,\n                callbacks = [early_stopping, plateau],\n                shuffle = True,\n                verbose = 0\n              )\n\n    #  ----------------------------------------------------------\n    #  oof\n    preds_valid = model.predict(X_valid).reshape(1,-1)[0] \n    \n    #  ----------------------------------------------------------\n    #  test  predictions\n    preds_test.append(model.predict(test).reshape(1,-1)[0])\n    \n    #  ----------------------------------------------------------\n    #  Saving  scores to plot the end  \n    scores = pd.DataFrame(history.history)\n    scores['folds'] = fold\n    \n    if fold == 0:\n        f_scores = scores \n    else: \n        f_scores = pd.concat([f_scores, scores], axis  = 0)\n        \n    #  ----------------------------------------------------------\n    #  concatenating valid preds\n    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n\n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, preds_valid)\n    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n\n    # Total auc\n    total_auc.append(fold_auc)\n\nprint(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:32:19.384131Z","iopub.execute_input":"2021-11-11T14:32:19.384515Z","iopub.status.idle":"2021-11-11T14:54:09.431356Z","shell.execute_reply.started":"2021-11-11T14:32:19.384469Z","shell.execute_reply":"2021-11-11T14:54:09.429099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor fold in range(f_scores['folds'].nunique()):\n    history_f = f_scores[f_scores['folds'] == fold]\n\n    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n    fig.suptitle('Fold : '+str(fold), fontsize=14)\n        \n    plt.subplot(1,2,1)\n    plt.plot(history_f.loc[:, ['loss', 'val_loss']], label= ['loss', 'val_loss'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    plt.subplot(1,2,2)\n    plt.plot(history_f.loc[:, ['auc', 'val_auc']],label= ['auc', 'val_auc'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    print(\"Validation Loss: {:0.4f}\".format(history_f['val_loss'].min()));","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:54:09.433867Z","iopub.execute_input":"2021-11-11T14:54:09.434236Z","iopub.status.idle":"2021-11-11T14:54:12.838141Z","shell.execute_reply.started":"2021-11-11T14:54:09.434188Z","shell.execute_reply":"2021-11-11T14:54:12.836962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}