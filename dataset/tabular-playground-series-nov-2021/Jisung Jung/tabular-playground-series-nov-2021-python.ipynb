{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport statsmodels.formula.api as smf                # logistic regression\nfrom sklearn.model_selection import train_test_split # train/test split\nfrom sklearn.linear_model import LogisticRegression  # logistic regression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import confusion_matrix         # confusion matrix\nfrom sklearn.metrics import roc_auc_score            # auc score\nfrom sklearn.neighbors import KNeighborsClassifier   # KNN for classification\nfrom sklearn.preprocessing import StandardScaler     # standard scaler\n\n# CART model packages\nfrom sklearn.tree import DecisionTreeClassifier      # classification trees\nfrom sklearn.tree import export_graphviz             # exports graphics\nfrom six import StringIO                             # saves objects in memory\nfrom IPython.display import Image                    # displays on frontend\n\n# Hyperparameter Tuning\nfrom sklearn.model_selection import RandomizedSearchCV  # hyperparameter tuning\nfrom sklearn.metrics import make_scorer                 # customizable scorer\n\n# Ensemble Modeling\nfrom sklearn.ensemble import RandomForestClassifier     # random forest\nfrom sklearn.ensemble import GradientBoostingClassifier # gbm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T23:11:11.204131Z","iopub.execute_input":"2021-11-15T23:11:11.204416Z","iopub.status.idle":"2021-11-15T23:11:17.625635Z","shell.execute_reply.started":"2021-11-15T23:11:11.204382Z","shell.execute_reply":"2021-11-15T23:11:17.624639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import data as dataframe","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv', index_col='id')\ntest_df = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:17.627187Z","iopub.execute_input":"2021-11-15T23:11:17.627425Z","iopub.status.idle":"2021-11-15T23:11:42.778316Z","shell.execute_reply.started":"2021-11-15T23:11:17.627389Z","shell.execute_reply":"2021-11-15T23:11:42.777322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:42.779769Z","iopub.execute_input":"2021-11-15T23:11:42.780099Z","iopub.status.idle":"2021-11-15T23:11:42.816435Z","shell.execute_reply.started":"2021-11-15T23:11:42.780069Z","shell.execute_reply":"2021-11-15T23:11:42.815566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:42.819412Z","iopub.execute_input":"2021-11-15T23:11:42.819771Z","iopub.status.idle":"2021-11-15T23:11:42.845595Z","shell.execute_reply.started":"2021-11-15T23:11:42.819728Z","shell.execute_reply":"2021-11-15T23:11:42.844656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore the dataset - row and column\nprint(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:42.846786Z","iopub.execute_input":"2021-11-15T23:11:42.847009Z","iopub.status.idle":"2021-11-15T23:11:42.852814Z","shell.execute_reply.started":"2021-11-15T23:11:42.846982Z","shell.execute_reply":"2021-11-15T23:11:42.851892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train data count: 600,000 / Test data count : 540,000","metadata":{}},{"cell_type":"code","source":"# Explore the datatype per each column\nprint(train_df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:42.85438Z","iopub.execute_input":"2021-11-15T23:11:42.854729Z","iopub.status.idle":"2021-11-15T23:11:42.872011Z","shell.execute_reply.started":"2021-11-15T23:11:42.854686Z","shell.execute_reply":"2021-11-15T23:11:42.871168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:42.872957Z","iopub.execute_input":"2021-11-15T23:11:42.873177Z","iopub.status.idle":"2021-11-15T23:11:42.885308Z","shell.execute_reply.started":"2021-11-15T23:11:42.873152Z","shell.execute_reply":"2021-11-15T23:11:42.884605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature columns : float64 / Target column : int","metadata":{}},{"cell_type":"code","source":"# Show the number of missing values in the dataset.\ntrain_df.isnull().sum(axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:42.886282Z","iopub.execute_input":"2021-11-15T23:11:42.886537Z","iopub.status.idle":"2021-11-15T23:11:43.020285Z","shell.execute_reply.started":"2021-11-15T23:11:42.886508Z","shell.execute_reply":"2021-11-15T23:11:43.019419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.isnull().sum(axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:43.021656Z","iopub.execute_input":"2021-11-15T23:11:43.021964Z","iopub.status.idle":"2021-11-15T23:11:43.135553Z","shell.execute_reply.started":"2021-11-15T23:11:43.021933Z","shell.execute_reply":"2021-11-15T23:11:43.134644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's no missing value on the dataframe","metadata":{}},{"cell_type":"code","source":"# Show the number of target values in the dataset.\n\ny = train_df[\"target\"]\n\nsns.countplot(y)\n\n\ntarget_temp = train_df.target.value_counts()\n\nprint(target_temp)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:43.139291Z","iopub.execute_input":"2021-11-15T23:11:43.139603Z","iopub.status.idle":"2021-11-15T23:11:43.413566Z","shell.execute_reply.started":"2021-11-15T23:11:43.139554Z","shell.execute_reply":"2021-11-15T23:11:43.412454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot data distributions for every variables\nfig, ax = plt.subplots(figsize = (15, 70))\ni = 0\nFEATS = list(train_df.columns)\n\nfor val in FEATS:\n    plt.subplot(21, 5, i + 1)\n    sns.kdeplot(data = train_df, x = val)\n    i = i + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:33:54.567964Z","iopub.execute_input":"2021-11-15T11:33:54.568841Z","iopub.status.idle":"2021-11-15T11:38:43.813219Z","shell.execute_reply.started":"2021-11-15T11:33:54.568783Z","shell.execute_reply":"2021-11-15T11:38:43.812344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a correlation matrix.\nprint(train_df.corr())","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:39:34.44458Z","iopub.execute_input":"2021-11-15T11:39:34.444813Z","iopub.status.idle":"2021-11-15T11:39:51.204728Z","shell.execute_reply.started":"2021-11-15T11:39:34.444784Z","shell.execute_reply":"2021-11-15T11:39:51.203733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling feature values\n\n### MinMaxScaler Transform\n\n<ul>\n<li> Normalization is a rescaling of the data from the original range so that all values are within the new range of 0 and 1. </li> \n<li> Data scaling is a recommended pre-processing step when working with many machine learning algorithms. (<a href=\"https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/\">Jason Brownlee</a>, 2020) </li> \n</ul>","metadata":{}},{"cell_type":"code","source":"# perform a robust scaler transform of the dataset\nfrom sklearn.preprocessing import MinMaxScaler\ntrans = MinMaxScaler()\ntrain_df = trans.fit_transform(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:11:45.459115Z","iopub.execute_input":"2021-11-15T23:11:45.460001Z","iopub.status.idle":"2021-11-15T23:11:45.993465Z","shell.execute_reply.started":"2021-11-15T23:11:45.459953Z","shell.execute_reply":"2021-11-15T23:11:45.99253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas import DataFrame\n# convert the array back to a dataframe\ntrain_df = DataFrame(train_df)\n# summarize\nprint(train_df.describe())","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:06.162364Z","iopub.execute_input":"2021-11-15T23:12:06.162597Z","iopub.status.idle":"2021-11-15T23:12:08.652893Z","shell.execute_reply.started":"2021-11-15T23:12:06.162552Z","shell.execute_reply":"2021-11-15T23:12:08.652255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n                    'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n                    'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n                    'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40',\n                    'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50',\n                    'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60',\n                    'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70',\n                    'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80',\n                    'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90',\n                    'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'target']","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:08.653996Z","iopub.execute_input":"2021-11-15T23:12:08.654494Z","iopub.status.idle":"2021-11-15T23:12:08.661776Z","shell.execute_reply.started":"2021-11-15T23:12:08.65446Z","shell.execute_reply":"2021-11-15T23:12:08.660899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiating a logistic model object\nlogistic_full = smf.logit(formula = \"\"\"  target ~ \n                                         f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10 +\n                                         f11 + f12 + f13 + f14 + f15 + f16 + f17 + f18 + f19 + f20 + \n                                         f21 + f22 + f23 + f24 + f25 + f26 + f27 + f28 + f29 + f30 +\n                                         f31 + f32 + f33 + f34 + f35 + f36 + f37 + f39 + f40 +\n                                         f41 + f42 + f43 + f44 + f45 + f46 + f47 + f48 + f49 + f50 +\n                                         f51 + f53 + f54 + f55 + f56 + f57 + f58 + f59 + f60 + \n                                         f61 + f62 + f63 + f64 + f65 + f66 + f67 + f68 + f69 + f70 +\n                                         f71 + f73 + f74 + f75 + f76 + f77 + f78 + f79 + f80 +\n                                         f81 + f82 + f83 + f84 + f85 + f86 + f87 + f88 + f89 + f90 +\n                                         f91 + f93 + f94 + f95 + f96 + f97 + f98 + f99 \"\"\",\n                                         data = train_df)\n\n# fitting the model object\nresults_full = logistic_full.fit()\n\n\n# checking the results SUMMARY\nresults_full.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:46:05.187966Z","iopub.execute_input":"2021-11-15T11:46:05.18921Z","iopub.status.idle":"2021-11-15T11:46:18.104612Z","shell.execute_reply.started":"2021-11-15T11:46:05.189129Z","shell.execute_reply":"2021-11-15T11:46:18.103956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiment with the validation split\n\nIn the following code cell, you'll see a variable named validation_split, which we've initialized at 0.2. The validation_split variable specifies the proportion of the original training set that will serve as the validation set. \n\nThe following code builds a model, trains it on the training set, and evaluates the built model on both:\n\n- The training set.\n- And the validation set.","metadata":{}},{"cell_type":"code","source":"candidate_dict = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n                  'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n                  'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n                  'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f39', 'f40',\n                  'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50',\n                  'f51', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60',\n                  'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70',\n                  'f71', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80',\n                  'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90',\n                  'f91', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99']\n\ny_train = train_df.iloc[:,-1]\nX_train = train_df.loc[:, candidate_dict]\nX_train = train_df.drop('target', axis=1)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=1) ","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:08.66408Z","iopub.execute_input":"2021-11-15T23:12:08.664287Z","iopub.status.idle":"2021-11-15T23:12:09.6442Z","shell.execute_reply.started":"2021-11-15T23:12:08.664262Z","shell.execute_reply":"2021-11-15T23:12:09.643092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression with Default Hyperparameters in scikit-learn","metadata":{}},{"cell_type":"code","source":"# INSTANTIATING a logistic regression model\nlogreg = LogisticRegression(solver ='liblinear',\n                            C = 1.0,\n                            warm_start = True,\n                            random_state = 1)\n\n# FITTING the training data\nlogreg_fit = logreg.fit(X_train, y_train)\n\n\n# PREDICTING based on the testing set\nlogreg_pred = logreg_fit.predict(X_val)\n\n\n# SCORING the results\nprint('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\nprint('Testing  ACCURACY:', logreg_fit.score(X_val, y_val).round(4))\n\n\n# SCORING with AUC\nprint('AUC Score        :', roc_auc_score(y_true  = y_val,\n                                          y_score = logreg_pred).round(decimals = 4))\n\n# unpacking the confusion matrix\nlogreg_tn, \\\nlogreg_fp, \\\nlogreg_fn, \\\nlogreg_tp = confusion_matrix(y_true = y_val, y_pred = logreg_pred).ravel()\n\n\n# printing each result one-by-one\nprint(f\"\"\"\nTrue Negatives : {logreg_tn}\nFalse Positives: {logreg_fp}\nFalse Negatives: {logreg_fn}\nTrue Positives : {logreg_tp}\n\"\"\")\n\n# creating a confusion matrix\nprint(confusion_matrix(y_true = y_val,\n                       y_pred = logreg_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:47:23.352613Z","iopub.execute_input":"2021-11-15T11:47:23.353113Z","iopub.status.idle":"2021-11-15T11:48:05.069335Z","shell.execute_reply.started":"2021-11-15T11:47:23.35308Z","shell.execute_reply":"2021-11-15T11:48:05.06848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Trees (CART Models)","metadata":{}},{"cell_type":"code","source":"# INSTANTIATING a classification tree object\npruned_tree = DecisionTreeClassifier(max_depth = 5,\n                                     min_samples_leaf = 17,\n                                     criterion = 'entropy',\n                                     random_state = 1)\n\n# FITTING the training data\npruned_tree_fit  = pruned_tree.fit(X_train, y_train)\n\n\n# PREDICTING on new data\npruned_tree_pred = pruned_tree_fit.predict(X_val)\n\n\n# SCORING the model\nprint('Training ACCURACY:', pruned_tree_fit.score(X_train, y_train).round(4))\nprint('Testing  ACCURACY:', pruned_tree_fit.score(X_val, y_val).round(4))\nprint('AUC Score        :', roc_auc_score(y_true  = y_val,\n                                          y_score = pruned_tree_pred).round(4))\n\n# unpacking the confusion matrix\npruned_tree_tn, \\\npruned_tree_fp, \\\npruned_tree_fn, \\\npruned_tree_tp = confusion_matrix(y_true = y_val, y_pred = pruned_tree_pred).ravel()\n\n\n# printing each result one-by-one\nprint(f\"\"\"\nTrue Negatives : {pruned_tree_tn}\nFalse Positives: {pruned_tree_fp}\nFalse Negatives: {pruned_tree_fn}\nTrue Positives : {pruned_tree_tp}\n\"\"\")\n\n# creating a confusion matrix\nprint(confusion_matrix(y_true = y_val,\n                       y_pred = pruned_tree_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:49:13.16147Z","iopub.execute_input":"2021-11-15T11:49:13.162528Z","iopub.status.idle":"2021-11-15T11:50:29.96803Z","shell.execute_reply.started":"2021-11-15T11:49:13.162483Z","shell.execute_reply":"2021-11-15T11:50:29.967003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"# INSTANTIATING a random forest model with hyperparameters tuned values\nrandom_forest = RandomForestClassifier(n_estimators     = 350,\n                                       criterion        = 'gini',\n                                       max_depth        = 7,\n                                       max_features     = 'auto',\n                                       min_samples_leaf = 1,\n                                       bootstrap        = True,\n                                       warm_start       = True,\n                                       random_state     = 1)\n\n# FITTING the training data\nrandom_forest_fit = random_forest.fit(X_train, y_train)\n\n\n# PREDICTING based on the testing set\nrandom_forest_fit_pred = random_forest_fit.predict(X_val)\n\n\n# SCORING the results\nprint('Training ACCURACY:', random_forest_fit.score(X_train, y_train).round(4))\nprint('Testing  ACCURACY:', random_forest_fit.score(X_val, y_val).round(4))\n\n\n# saving AUC score\nprint('AUC Score        :', roc_auc_score(y_true  = y_val,\n                                          y_score = random_forest_fit_pred).round(4))\n\n# unpacking the confusion matrix\nrf_tn, \\\nrf_fp, \\\nrf_fn, \\\nrf_tp = confusion_matrix(y_true = y_val, y_pred = random_forest_fit_pred).ravel()\n\n\n# printing each result one-by-one\nprint(f\"\"\"\nTrue Negatives : {rf_tn}\nFalse Positives: {rf_fp}\nFalse Negatives: {rf_fn}\nTrue Positives : {rf_tp}\n\"\"\")\n\n# creating a confusion matrix\nprint(confusion_matrix(y_true = y_val,\n                       y_pred = random_forest_fit_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T11:53:05.746155Z","iopub.execute_input":"2021-11-15T11:53:05.746502Z","iopub.status.idle":"2021-11-15T12:22:13.482336Z","shell.execute_reply.started":"2021-11-15T11:53:05.746464Z","shell.execute_reply":"2021-11-15T12:22:13.481439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosted Machines","metadata":{}},{"cell_type":"code","source":"# INSTANTIATING a Gradient Boosted Machines\ngbm = GradientBoostingClassifier(loss          = 'deviance',\n                                 learning_rate = 0.1,\n                                 n_estimators  = 100,\n                                 criterion     = 'friedman_mse',\n                                 max_depth     = 2,\n                                 warm_start    = False,\n                                 random_state  = 1)\n\n# FITTING the training data\ngbm_fit = gbm.fit(X_train, y_train)\n\n\n# PREDICTING based on the testing set\ngbm_pred = gbm_fit.predict(X_val)\n\n\n# SCORING the results\nprint('Training ACCURACY:', gbm_fit.score(X_train, y_train).round(4))\nprint('Testing ACCURACY :', gbm_fit.score(X_val, y_val).round(4))\nprint('AUC Score        :', roc_auc_score(y_true  = y_val,\n                                          y_score = gbm_pred).round(4))\n\n# unpacking the confusion matrix\ngbm_tn, \\\ngbm_fp, \\\ngbm_fn, \\\ngbm_tp = confusion_matrix(y_true = y_val, y_pred = gbm_pred).ravel()\n\n\n# printing each result one-by-one\nprint(f\"\"\"\nTrue Negatives : {gbm_tn}\nFalse Positives: {gbm_fp}\nFalse Negatives: {gbm_fn}\nTrue Positives : {gbm_tp}\n\"\"\")\n\n# creating a confusion matrix\nprint(confusion_matrix(y_true = y_val,\n                       y_pred = gbm_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:22:32.38934Z","iopub.execute_input":"2021-11-15T12:22:32.389649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Binary Classification with Keras NN","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:19.106311Z","iopub.execute_input":"2021-11-15T23:12:19.10664Z","iopub.status.idle":"2021-11-15T23:12:19.770684Z","shell.execute_reply.started":"2021-11-15T23:12:19.106605Z","shell.execute_reply":"2021-11-15T23:12:19.769651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct the Sequential model\n\nmodel = Sequential()\nmodel.add(Dense(128, activation=\"relu\", input_shape = (X_train.shape[1],))) # Hidden Layer 1 that receives the Input from the Input Layer\n\nmodel.add(Dense(64, activation=\"relu\")) # Hidden Layer 2\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(32, activation=\"relu\")) # Hidden Layer 3\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(16, activation=\"relu\")) # Hidden Layer 4\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Dense(1, activation=\"sigmoid\")) # Outout Layer\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:21.885108Z","iopub.execute_input":"2021-11-15T23:12:21.885427Z","iopub.status.idle":"2021-11-15T23:12:22.045345Z","shell.execute_reply.started":"2021-11-15T23:12:21.885394Z","shell.execute_reply":"2021-11-15T23:12:22.044622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss = \"binary_crossentropy\", metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:27.25846Z","iopub.execute_input":"2021-11-15T23:12:27.258775Z","iopub.status.idle":"2021-11-15T23:12:27.272923Z","shell.execute_reply.started":"2021-11-15T23:12:27.258742Z","shell.execute_reply":"2021-11-15T23:12:27.27187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nmodel.fit(X_train, y_train, batch_size = 64, epochs = 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:12:30.434349Z","iopub.execute_input":"2021-11-15T23:12:30.435211Z","iopub.status.idle":"2021-11-15T23:53:07.28221Z","shell.execute_reply.started":"2021-11-15T23:12:30.435155Z","shell.execute_reply":"2021-11-15T23:53:07.281466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validate the model\nvalidation_loss, validation_accuracy = model.evaluate(X_val, y_val, batch_size=32)\nprint(\"Loss: \"+ str(np.round(validation_loss, 3)))\nprint(\"Accuracy: \"+ str(np.round(validation_accuracy, 3)))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:53:27.444798Z","iopub.execute_input":"2021-11-15T23:53:27.445184Z","iopub.status.idle":"2021-11-15T23:53:30.32206Z","shell.execute_reply.started":"2021-11-15T23:53:27.44514Z","shell.execute_reply":"2021-11-15T23:53:30.321268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the Keras NN model with the test set\ntest_df = trans.fit_transform(test_df)\ntest_df = DataFrame(test_df)\ntest_df.columns = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n                   'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n                   'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n                   'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40',\n                   'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50',\n                   'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60',\n                   'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70',\n                   'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80',\n                   'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90',\n                   'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99']\n\nX_test = test_df\n\n# test_df[\"test_pred\"] = np.nan\n# y_test = test_df.drop(\"test_pred\", axis=1)\n\ny_predict = model.predict(X_test)\ny_predict = np.ravel(y_predict)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:54:08.626569Z","iopub.execute_input":"2021-11-15T23:54:08.626889Z","iopub.status.idle":"2021-11-15T23:54:28.618611Z","shell.execute_reply.started":"2021-11-15T23:54:08.62685Z","shell.execute_reply":"2021-11-15T23:54:28.617734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save predition to the submission.csv\ntest_df_temp = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')\noutput = pd.DataFrame({'id': test_df_temp.id, 'target': y_predict})\noutput = output.loc[:, ['id', 'target']]\n\noutput.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T23:58:38.775865Z","iopub.execute_input":"2021-11-15T23:58:38.776171Z","iopub.status.idle":"2021-11-15T23:58:46.743422Z","shell.execute_reply.started":"2021-11-15T23:58:38.776141Z","shell.execute_reply":"2021-11-15T23:58:46.742438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}