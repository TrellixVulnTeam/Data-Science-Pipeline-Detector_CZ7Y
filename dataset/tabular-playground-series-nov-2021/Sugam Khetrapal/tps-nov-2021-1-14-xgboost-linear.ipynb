{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement\n\nIn this competition, we predict whether or not an email is spam.\n\nWe are going to cover the following steps:\n1. Import Libraries\n2. Model: XGBoost Linear using gblinear\n3. Evaluation\n4. Submission\n5. References\n6. Notes\n\nLet's get started.\n\n# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\ndata_dir = Path('../input/tabular-playground-series-nov-2021/')\n\ndf_train = pd.read_csv(\n    data_dir / \"train.csv\",\n    index_col='id'\n)\n\nFEATURES = df_train.columns[:-1]\nTARGET = df_train.columns[-1]\n\ndf_train.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T07:30:07.960742Z","iopub.execute_input":"2021-11-15T07:30:07.961523Z","iopub.status.idle":"2021-11-15T07:30:19.910187Z","shell.execute_reply.started":"2021-11-15T07:30:07.961474Z","shell.execute_reply":"2021-11-15T07:30:19.909617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'target' has binary outcomes: 0 for not spam and 1 for spam.\n\n# Model: XGBoost Linear using gblinear","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nX = df_train.loc[:, FEATURES]\ny = df_train.loc[:, TARGET]\n\nmodel = XGBClassifier(\n#     max_depth=3,\n#     subsample=0.5,\n#     colsample_bytree=0.5,\n    n_jobs=-1,\n    # Uncomment if you want to use GPU. Recommended for whole training set.\n    #tree_method='gpu_hist',\n    random_state=0,\n    objective ='reg:squarederror', # WARNING -> reg:linear is now deprecated in favor of reg:squarederror\n    booster='gblinear'\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:30:19.911748Z","iopub.execute_input":"2021-11-15T07:30:19.911993Z","iopub.status.idle":"2021-11-15T07:30:20.11171Z","shell.execute_reply.started":"2021-11-15T07:30:19.91195Z","shell.execute_reply":"2021-11-15T07:30:20.110847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n\nThe evaluation metric is AUC, which stands for \"area under curve\".","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndef score(X, y, model, cv):\n    scoring = [\"roc_auc\"]\n    scores = cross_validate(\n        model, X, y, scoring=scoring, cv=cv, return_train_score=True\n    )\n    scores = pd.DataFrame(scores).T\n    return scores.assign(\n        mean = lambda x: x.mean(axis=1),\n        std = lambda x: x.std(axis=1),\n    )\n\nscores = score(X, y, model, cv=2)\n\ndisplay(scores)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:30:20.112834Z","iopub.execute_input":"2021-11-15T07:30:20.113254Z","iopub.status.idle":"2021-11-15T07:30:43.02058Z","shell.execute_reply.started":"2021-11-15T07:30:20.113221Z","shell.execute_reply":"2021-11-15T07:30:43.019757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A \"neutral\" AUC is 0.5, so anything better than that means our model learned something useful.\n\n# Submission\n\nOur predictions are binary 0 and 1, but we're allowed to submit probabilities instead. In scikit-learn, we would use the predict_proba method instead of predict.","metadata":{}},{"cell_type":"code","source":"# Fit on full training set\nmodel.fit(X, y)\n\nX_test = pd.read_csv(data_dir / \"test.csv\", index_col='id')\n\n# Make predictions\ny_pred = pd.Series(\n    model.predict(X_test),\n    index=X_test.index,\n    name=TARGET,\n)\n\n# Create submission file\ny_pred.to_csv(\"submission_xgb_linear.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:30:43.021831Z","iopub.execute_input":"2021-11-15T07:30:43.022132Z","iopub.status.idle":"2021-11-15T07:31:11.654569Z","shell.execute_reply.started":"2021-11-15T07:30:43.02209Z","shell.execute_reply":"2021-11-15T07:31:11.653789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\n\n1. Thank you to [link](https://stackoverflow.com/questions/55493454/xgboost-linear-regression-gblinear-wrong-predictions) for demonstrating how to use XGBoost Linear.\n2. Thank you to Ryan Holbrook, Alexis Cook and inversion for demonstrating how to use XGBoost in their [notebook](https://www.kaggle.com/ryanholbrook/getting-started-september-2021-tabular-playground/notebook).\n3. Thank you to @pinstripezebra (Lucas See) for suggesting that I try XGBoost Linear Model instead of a tree based one.\n\n# Notes\n\n1. What is the difference between XGBRegressor, XGBClassifier, booster='gblinear', booster='tree'?\n2. Compare outputs of [XGBClassifier (tree)](https://www.kaggle.com/sugamkhetrapal/tps-nov-2021-1-06-xgboost/notebook) and [XGBClassifier (linear)](https://www.kaggle.com/sugamkhetrapal/tps-nov-2021-1-14-xgboost-linear/).","metadata":{}}]}