{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T22:30:59.423462Z","iopub.execute_input":"2021-11-01T22:30:59.424389Z","iopub.status.idle":"2021-11-01T22:30:59.457831Z","shell.execute_reply.started":"2021-11-01T22:30:59.424287Z","shell.execute_reply":"2021-11-01T22:30:59.456813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv', index_col='id')\nX_test_full = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv', index_col='id')\n# Remove rows with missing target, separate target from predictors\ny = X.target              \nX.drop(['target'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T01:28:28.157976Z","iopub.execute_input":"2021-11-02T01:28:28.158246Z","iopub.status.idle":"2021-11-02T01:28:35.215413Z","shell.execute_reply.started":"2021-11-02T01:28:28.158164Z","shell.execute_reply":"2021-11-02T01:28:35.214738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = \\\n    train_test_split(X, y, stratify=y, train_size=0.99)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T22:31:31.136109Z","iopub.execute_input":"2021-11-01T22:31:31.136459Z","iopub.status.idle":"2021-11-01T22:31:32.138087Z","shell.execute_reply.started":"2021-11-01T22:31:31.13643Z","shell.execute_reply":"2021-11-01T22:31:32.137406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Define the model\n\nmy_model_1 = XGBClassifier(n_estimators=1000, learning_rate=0.0001, n_jobs=4, max_depth = 12)\n\n# Fit the model\nmy_model_1.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T22:31:32.13946Z","iopub.execute_input":"2021-11-01T22:31:32.140459Z","iopub.status.idle":"2021-11-01T23:41:50.192888Z","shell.execute_reply.started":"2021-11-01T22:31:32.14041Z","shell.execute_reply":"2021-11-01T23:41:50.191741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_1 = my_model_1.predict(X_valid)\n\nf = []\nfor i in range(len(list(predictions_1))):\n    if predictions_1[i] <.50001:\n        f.append(0)\n    else:\n        f.append(1)\nc = 0\nfor i in range(len(y_valid)):\n    if f[i] == list(y_valid)[i]:\n        c +=1\nprint(c/len(y_valid))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-01T23:41:50.195381Z","iopub.execute_input":"2021-11-01T23:41:50.195612Z","iopub.status.idle":"2021-11-02T00:11:49.514252Z","shell.execute_reply.started":"2021-11-01T23:41:50.195583Z","shell.execute_reply":"2021-11-02T00:11:49.513195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Yhat = my_model_1.predict(X_test_full)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T20:58:23.245655Z","iopub.execute_input":"2021-11-01T20:58:23.245984Z","iopub.status.idle":"2021-11-01T21:08:37.212776Z","shell.execute_reply.started":"2021-11-01T20:58:23.245945Z","shell.execute_reply":"2021-11-01T21:08:37.211676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': X_test_full.index,\n                       'target': Yhat})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T21:08:37.214759Z","iopub.execute_input":"2021-11-01T21:08:37.215275Z","iopub.status.idle":"2021-11-01T21:08:38.508922Z","shell.execute_reply.started":"2021-11-01T21:08:37.215237Z","shell.execute_reply":"2021-11-01T21:08:38.507908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}