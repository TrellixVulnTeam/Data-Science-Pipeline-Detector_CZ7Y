{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"t0.\"></a>\n## Intoduction\n* Starter notebook to help Kagglers to get going\n* This was generated using Databricks AutoML \n* Using a simple Logistic Regression model. Logistic Regression is a supervised machine learning classification algorithm that is used to predict the probability of a categorical dependent variable.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"t1.\"></a>\n## 1. Import libraries","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nimport sklearn\nfrom sklearn import set_config\nfrom sklearn.pipeline import Pipeline\n\nimport warnings\nwarnings.simplefilter(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:38:02.667929Z","iopub.execute_input":"2021-11-06T23:38:02.668384Z","iopub.status.idle":"2021-11-06T23:38:03.904377Z","shell.execute_reply.started":"2021-11-06T23:38:02.668258Z","shell.execute_reply":"2021-11-06T23:38:03.903376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t2.\"></a>\n## 2. Load datasets","metadata":{}},{"cell_type":"code","source":"# df_loaded\ndf_loaded = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\n\n# test_df\ntest_df = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")\n\n# sample_submission\nsample_submission = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:38:03.906249Z","iopub.execute_input":"2021-11-06T23:38:03.906497Z","iopub.status.idle":"2021-11-06T23:38:34.522346Z","shell.execute_reply.started":"2021-11-06T23:38:03.906461Z","shell.execute_reply":"2021-11-06T23:38:34.52168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t3.\"></a>\n## 3. Preview data","metadata":{}},{"cell_type":"code","source":"df_loaded.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:52:30.900505Z","iopub.execute_input":"2021-11-06T23:52:30.90168Z","iopub.status.idle":"2021-11-06T23:52:30.935724Z","shell.execute_reply.started":"2021-11-06T23:52:30.901607Z","shell.execute_reply":"2021-11-06T23:52:30.934862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t4.\"></a>\n## 4. Pipeline\n### Below is a pipeline that imputes the missing values in numeric data, scales them, and fits an Logistic Regression model. \n* Numerical columns\n\n* Missing values for numerical columns are imputed with mean.","metadata":{}},{"cell_type":"code","source":"transformers = []\n\nnumerical_pipeline = Pipeline(steps=[\n    (\"converter\", FunctionTransformer(lambda df: df.apply(pd.to_numeric, errors=\"coerce\"))),\n    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n])\n\ntransformers.append((\"numerical\", numerical_pipeline, [\"f0\", \"f1\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\", \"f2\", \"f20\", \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f3\", \"f30\", \"f31\", \"f32\", \"f33\", \"f34\", \"f35\", \"f36\", \"f37\", \"f38\", \"f39\", \"f4\", \"f40\", \"f41\", \"f42\", \"f43\", \"f44\", \"f45\", \"f46\", \"f47\", \"f48\", \"f49\", \"f5\", \"f50\", \"f51\", \"f52\", \"f53\", \"f54\", \"f55\", \"f56\", \"f57\", \"f58\", \"f59\", \"f6\", \"f60\", \"f61\", \"f62\", \"f63\", \"f64\", \"f65\", \"f66\", \"f67\", \"f68\", \"f69\", \"f7\", \"f70\", \"f71\", \"f72\", \"f73\", \"f74\", \"f75\", \"f76\", \"f77\", \"f78\", \"f79\", \"f8\", \"f80\", \"f81\", \"f82\", \"f83\", \"f84\", \"f85\", \"f86\", \"f87\", \"f88\", \"f89\", \"f9\", \"f90\", \"f91\", \"f92\", \"f93\", \"f94\", \"f95\", \"f96\", \"f97\", \"f98\", \"f99\", \"id\"]))","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:38:34.545522Z","iopub.execute_input":"2021-11-06T23:38:34.545839Z","iopub.status.idle":"2021-11-06T23:38:34.557007Z","shell.execute_reply.started":"2021-11-06T23:38:34.545797Z","shell.execute_reply":"2021-11-06T23:38:34.555832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(transformers, remainder=\"passthrough\", sparse_threshold=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:38:34.559274Z","iopub.execute_input":"2021-11-06T23:38:34.55961Z","iopub.status.idle":"2021-11-06T23:38:34.56891Z","shell.execute_reply.started":"2021-11-06T23:38:34.559566Z","shell.execute_reply":"2021-11-06T23:38:34.567908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t5.\"></a>\n## 5. Feature standardization\n### Scale all feature columns to be centered around zero with unit variance.","metadata":{}},{"cell_type":"code","source":"standardizer = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:38:34.570198Z","iopub.execute_input":"2021-11-06T23:38:34.570513Z","iopub.status.idle":"2021-11-06T23:38:34.580854Z","shell.execute_reply.started":"2021-11-06T23:38:34.570477Z","shell.execute_reply":"2021-11-06T23:38:34.580082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t6.\"></a>\n## 6. Training - Validation Split\n### Split the input data into training and validation data","metadata":{}},{"cell_type":"code","source":"target_col = \"target\"\nsplit_X = df_loaded.drop([target_col], axis=1)\nsplit_y = df_loaded[target_col]\n\nX_train, X_val, y_train, y_val = train_test_split(split_X, split_y, random_state=43, stratify=split_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t7.\"></a>\n## 7. Train classification model","metadata":{}},{"cell_type":"code","source":"set_config(display=\"diagram\")\n\nsklr_classifier = LogisticRegression(\n  C=0.00030024581542297343,\n  penalty=\"l2\",\n  random_state=102376075,\n)\n\nmodel = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"standardizer\", standardizer),\n    (\"classifier\", sklr_classifier),\n])\n\nmodel\n\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T23:38:35.896179Z","iopub.execute_input":"2021-11-06T23:38:35.896445Z","iopub.status.idle":"2021-11-06T23:38:39.900704Z","shell.execute_reply.started":"2021-11-06T23:38:35.896413Z","shell.execute_reply":"2021-11-06T23:38:39.899706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"t8.\"></a>\n## 8. Prediction","metadata":{}},{"cell_type":"code","source":"model_pred = model.predict(test_df)\nsample_submission['target'] = model_pred\nsample_submission.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T19:50:15.119806Z","iopub.execute_input":"2021-11-04T19:50:15.120106Z","iopub.status.idle":"2021-11-04T19:50:17.528795Z","shell.execute_reply.started":"2021-11-04T19:50:15.120071Z","shell.execute_reply":"2021-11-04T19:50:17.527883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Notes \n\n#### Thank you for reading my notebook. Please upvote if this was helpful in any way. If you have any comments/feedback/suggestions, please feel free to comment.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}