{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries and Loading datasets","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Feature Engineering\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.feature_selection import mutual_info_classif\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\n# Neural Network\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\n\n# Cross-Validation\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-21T01:04:12.41832Z","iopub.execute_input":"2021-11-21T01:04:12.418601Z","iopub.status.idle":"2021-11-21T01:04:12.427594Z","shell.execute_reply.started":"2021-11-21T01:04:12.418571Z","shell.execute_reply":"2021-11-21T01:04:12.426792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:12.429614Z","iopub.execute_input":"2021-11-21T01:04:12.429967Z","iopub.status.idle":"2021-11-21T01:04:30.544599Z","shell.execute_reply.started":"2021-11-21T01:04:12.429925Z","shell.execute_reply":"2021-11-21T01:04:30.543882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore Data","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:30.545811Z","iopub.execute_input":"2021-11-21T01:04:30.547822Z","iopub.status.idle":"2021-11-21T01:04:30.574698Z","shell.execute_reply.started":"2021-11-21T01:04:30.547792Z","shell.execute_reply":"2021-11-21T01:04:30.573655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:30.577073Z","iopub.execute_input":"2021-11-21T01:04:30.577801Z","iopub.status.idle":"2021-11-21T01:04:32.638254Z","shell.execute_reply.started":"2021-11-21T01:04:30.577763Z","shell.execute_reply":"2021-11-21T01:04:32.637557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n","metadata":{}},{"cell_type":"code","source":"# Get train data without the target and ids\nX = train_data.iloc[:, 1:-1].copy()\n# Get the target\ny = train_data.target.copy()\n# Create test X, drop ids.\ntest_X = test_data.iloc[:, 1:].copy()\n\n# It takes time to handle all of the data.\n# So, I am using a smaller portion of the data\n# while debugging/testing.\n#X = train_data.iloc[0:10000, 1:-1].copy()\n#y = train_data.target[0:10000].copy()\n#test_X = test_data.iloc[0:10000, 1:].copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:32.639665Z","iopub.execute_input":"2021-11-21T01:04:32.639935Z","iopub.status.idle":"2021-11-21T01:04:33.25119Z","shell.execute_reply.started":"2021-11-21T01:04:32.639902Z","shell.execute_reply":"2021-11-21T01:04:33.250391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mutual Information\n\nFor now, I am using mutual information so select some features.  \nThe reason is simple, I am reading some tutorials https://www.kaggle.com/ryanholbrook/mutual-information :) and I am trying to find a way that I can implement what I have learned.","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(mi_scores, X, y):\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\")\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:33.252571Z","iopub.execute_input":"2021-11-21T01:04:33.252857Z","iopub.status.idle":"2021-11-21T01:04:33.260478Z","shell.execute_reply.started":"2021-11-21T01:04:33.252822Z","shell.execute_reply":"2021-11-21T01:04:33.259744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = mutual_info_classif(X, y)\nmi_scores_classif = make_mi_scores(mi_scores, X, y)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:33.262087Z","iopub.execute_input":"2021-11-21T01:04:33.262723Z","iopub.status.idle":"2021-11-21T01:04:41.543581Z","shell.execute_reply.started":"2021-11-21T01:04:33.262687Z","shell.execute_reply":"2021-11-21T01:04:41.54286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=100, figsize=(20, 16))\nplot_mi_scores(mi_scores_classif[mi_scores_classif > 1e-4])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:41.544754Z","iopub.execute_input":"2021-11-21T01:04:41.546722Z","iopub.status.idle":"2021-11-21T01:04:42.467237Z","shell.execute_reply.started":"2021-11-21T01:04:41.546689Z","shell.execute_reply":"2021-11-21T01:04:42.46656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selected Features","metadata":{}},{"cell_type":"code","source":"selected_features = mi_scores_classif[mi_scores_classif > 1e-4].index.tolist()\nselected_features = [f'f{feature}' for feature in selected_features]\nprint(f\"Selected Features: {selected_features}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.47018Z","iopub.execute_input":"2021-11-21T01:04:42.470659Z","iopub.status.idle":"2021-11-21T01:04:42.47767Z","shell.execute_reply.started":"2021-11-21T01:04:42.470622Z","shell.execute_reply":"2021-11-21T01:04:42.476967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is splitted according to the distributions of each column.  \nThis idea is taken from, https://www.kaggle.com/javiervallejos/simple-nn-with-good-results-tps-nov-21, https://www.kaggle.com/adityasharma01/simple-nn-tps-nov-21  \nThe difference is, that notebook is using all columns to create new basic columns while this notebook is creating those columns from selected features.","metadata":{}},{"cell_type":"code","source":"# The number 2 is just a threshold to split\ndata = X[selected_features].copy()\nh_skew = data.loc[:,data.skew() >= 2].columns  # with Skewed\nl_skew = data.loc[:,data.skew() < 2].columns   # Bimodal","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.47904Z","iopub.execute_input":"2021-11-21T01:04:42.479306Z","iopub.status.idle":"2021-11-21T01:04:42.506146Z","shell.execute_reply.started":"2021-11-21T01:04:42.47927Z","shell.execute_reply":"2021-11-21T01:04:42.505398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Skewed distrubutions\nX['median_h'] = X[h_skew].median(axis=1)\ntest_X['median_h'] = test_X[h_skew].median(axis=1)\n\nX['var_h'] = X[h_skew].var(axis=1)\ntest_X['var_h'] = test_X[h_skew].var(axis=1)\n\n# Bimodal distributions\nX['mean_l'] = X[l_skew].mean(axis=1)\ntest_X['mean_l'] = test_X[l_skew].mean(axis=1)\n\nX['std_l'] = X[l_skew].std(axis=1)\ntest_X['std_l'] = test_X[l_skew].std(axis=1)\n\nX['median_l'] = X[l_skew].median(axis=1)\ntest_X['median_l'] = test_X[l_skew].median(axis=1)\n\nX['skew_l'] = X[l_skew].skew(axis=1)\ntest_X['skew_l'] = test_X[l_skew].skew(axis=1)\n\nX['max_l'] = X[l_skew].max(axis=1)\ntest_X['max_l'] = test_X[l_skew].max(axis=1)\n\nX['var_l'] = X[l_skew].var(axis=1)\ntest_X['var_l'] = test_X[l_skew].var(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.507304Z","iopub.execute_input":"2021-11-21T01:04:42.507664Z","iopub.status.idle":"2021-11-21T01:04:42.609271Z","shell.execute_reply.started":"2021-11-21T01:04:42.507623Z","shell.execute_reply":"2021-11-21T01:04:42.608538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"# Scaling and Nomalization\ntransformer_high_skew = make_pipeline(\n    StandardScaler(), \n    MinMaxScaler(feature_range=(0, 1))\n)\n\ntransformer_low_skew = make_pipeline(\n    StandardScaler(),\n    MinMaxScaler(feature_range=(0, 1))\n)\n\nh_skew = X.loc[:, X.skew() >= 2].columns\nl_skew = X.loc[:, X.skew() < 2].columns\n\npreprocessor = make_column_transformer(\n    (transformer_high_skew, l_skew),\n    (transformer_low_skew, h_skew)\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.610531Z","iopub.execute_input":"2021-11-21T01:04:42.611895Z","iopub.status.idle":"2021-11-21T01:04:42.646526Z","shell.execute_reply.started":"2021-11-21T01:04:42.611853Z","shell.execute_reply":"2021-11-21T01:04:42.645769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling\n\n\nI will use my setup from https://www.kaggle.com/sfktrkl/tps-nov-2021-nn?scriptVersionId=80095054","metadata":{}},{"cell_type":"code","source":"# Set seeds\nmy_seed = 1\nnp.random.seed(my_seed)\ntf.random.set_seed(my_seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.657438Z","iopub.execute_input":"2021-11-21T01:04:42.657922Z","iopub.status.idle":"2021-11-21T01:04:42.669913Z","shell.execute_reply.started":"2021-11-21T01:04:42.657886Z","shell.execute_reply":"2021-11-21T01:04:42.669133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001,           # Minimium amount of change to count as an improvement\n    patience=5,               # How many epochs to wait before stopping\n    restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.671478Z","iopub.execute_input":"2021-11-21T01:04:42.671791Z","iopub.status.idle":"2021-11-21T01:04:42.679456Z","shell.execute_reply.started":"2021-11-21T01:04:42.671698Z","shell.execute_reply":"2021-11-21T01:04:42.678754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.2,                # Factor by which the learning rate will be reduced\n    patience=5,                # Number of epochs with no improvement\n    min_lr=0.001)              # Lower bound on the learning rate","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.680473Z","iopub.execute_input":"2021-11-21T01:04:42.680786Z","iopub.status.idle":"2021-11-21T01:04:42.688169Z","shell.execute_reply.started":"2021-11-21T01:04:42.68075Z","shell.execute_reply":"2021-11-21T01:04:42.687394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"EPOCHS = 100\nBATCH_SIZE = 512\nN_SPLITS = 15\nCALLBACKS = [early_stopping]","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.689429Z","iopub.execute_input":"2021-11-21T01:04:42.689779Z","iopub.status.idle":"2021-11-21T01:04:42.699335Z","shell.execute_reply.started":"2021-11-21T01:04:42.689744Z","shell.execute_reply":"2021-11-21T01:04:42.698677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(100, activation='swish', input_shape=[X.shape[1]]),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='swish'),\n    layers.Dropout(0.3),\n    layers.Dense(32, activation='swish'),\n    layers.Dropout(0.3),\n    # For a binary classification function use sigmoid\n    layers.Dense(1, activation='sigmoid')])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.701981Z","iopub.execute_input":"2021-11-21T01:04:42.702164Z","iopub.status.idle":"2021-11-21T01:04:42.75155Z","shell.execute_reply.started":"2021-11-21T01:04:42.702143Z","shell.execute_reply":"2021-11-21T01:04:42.75094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['AUC'])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.753397Z","iopub.execute_input":"2021-11-21T01:04:42.753768Z","iopub.status.idle":"2021-11-21T01:04:42.761893Z","shell.execute_reply.started":"2021-11-21T01:04:42.75372Z","shell.execute_reply":"2021-11-21T01:04:42.761205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.763479Z","iopub.execute_input":"2021-11-21T01:04:42.764305Z","iopub.status.idle":"2021-11-21T01:04:42.77008Z","shell.execute_reply.started":"2021-11-21T01:04:42.76427Z","shell.execute_reply":"2021-11-21T01:04:42.769274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 0\ntest_predictions = np.zeros(test_X.shape[0])\nskf = StratifiedKFold(n_splits=N_SPLITS, random_state=48, shuffle=True)\nscores = {fold:None for fold in range(skf.n_splits)}\nfor train_idx, test_idx in skf.split(X, y):\n    train_X, val_X = X.loc[train_idx], X.loc[test_idx]\n    train_y, val_y = y.loc[train_idx], y.loc[test_idx]\n\n    # Preprocessing\n    test  = test_X.copy()\n    \n    train_X = preprocessor.fit_transform(train_X)\n    val_X = preprocessor.transform(val_X)\n    test = preprocessor.transform(test)\n\n    # Model\n    history = model.fit(\n        train_X, train_y,\n        validation_data=(val_X, val_y),\n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        callbacks=CALLBACKS,        # Put your callbacks in a list\n        verbose=0)                  # Turn off training log\n\n    scores[fold] = (history.history)\n    print(f\"Fold {fold + 1} \\t\\t AUC: {np.max(scores[fold]['val_auc'])}\")\n\n    # Get the average values from each fold to the prediction\n    test_predictions += model.predict(test, batch_size=BATCH_SIZE).reshape(1,-1)[0] / skf.n_splits\n    fold += 1\n\noverall_auc = [np.max(scores[fold]['val_auc']) for fold in range(skf.n_splits)]\nprint('Overall Mean AUC: ', np.mean(overall_auc))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:42.77128Z","iopub.execute_input":"2021-11-21T01:04:42.771545Z","iopub.status.idle":"2021-11-21T01:04:59.070256Z","shell.execute_reply.started":"2021-11-21T01:04:42.771511Z","shell.execute_reply":"2021-11-21T01:04:59.068617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# Credits to https://www.kaggle.com/mlanhenke/tps-11-nn-baseline-keras?scriptVersionId=79830528\nfig, ax = plt.subplots(3, 5, figsize=(20, 15))\nax = ax.flatten()\n\nfor fold in range(skf.n_splits):\n    df_eval = pd.DataFrame({'train_loss': scores[fold]['loss'], 'valid_loss': scores[fold]['val_loss']})\n\n    min_train = np.round(np.min(df_eval['train_loss']),5)\n    min_valid = np.round(np.min(df_eval['valid_loss']),5)\n    delta = np.round(min_valid - min_train,5)\n    \n    sns.lineplot(\n        x=df_eval.index,\n        y=df_eval['train_loss'],\n        label='train_loss',\n        ax = ax[fold]\n    )\n\n    sns.lineplot(\n        x=df_eval.index,\n        y=df_eval['valid_loss'],\n        label='valid_loss',\n        ax = ax[fold]\n    )\n    \n    ax[fold].set_ylabel('')\n    ax[fold].set_xlabel(f\"Fold {fold+1}\\nmin_train: {min_train}\\nmin_valid: {min_valid}\\ndelta: {delta}\", fontstyle='italic')\n\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:04:59.07176Z","iopub.execute_input":"2021-11-21T01:04:59.072189Z","iopub.status.idle":"2021-11-21T01:05:02.538832Z","shell.execute_reply.started":"2021-11-21T01:04:59.072151Z","shell.execute_reply":"2021-11-21T01:05:02.538133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Run the code to save predictions in the format used for competition scoring\noutput = pd.DataFrame({'id': test_data.id, 'target': test_predictions})\noutput.to_csv('submission.csv', index=False)\noutput","metadata":{"execution":{"iopub.status.busy":"2021-11-21T01:05:02.540141Z","iopub.execute_input":"2021-11-21T01:05:02.540528Z","iopub.status.idle":"2021-11-21T01:05:02.573968Z","shell.execute_reply.started":"2021-11-21T01:05:02.54049Z","shell.execute_reply":"2021-11-21T01:05:02.572333Z"},"trusted":true},"execution_count":null,"outputs":[]}]}