{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Full Pipeline for classic & modern ML (sklearn API), SHAP-based variables interaction with GPU acceleration.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Sources:\n\nhttps://www.kaggle.com/rumasinha/featureselectionanddiffmodelexperiments\nhttps://www.kaggle.com/tunguz/tps-02-21-feature-importance-with-xgboost-and-shap\nhttps://www.kaggle.com/hamzaghanmi/make-it-simple","metadata":{}},{"cell_type":"markdown","source":"Contents:\n\n    - Simple basic EDA\n    \n    - Feature preprocessing\n    \n    - Classic ML baselines\n    \n    - Modern ML baselines\n    \n    - Best Baseline model\n    \n    - Add new features using XGBoost and SHAP\n    \n    - Baseline model with added features\n    \n    - Hyperparameters tuning (Optuna)\n    \n    - Cross-validation with optimized params\n    \n    - Submission prepare","metadata":{"execution":{"iopub.status.busy":"2021-11-24T13:12:58.51714Z","iopub.execute_input":"2021-11-24T13:12:58.517402Z","iopub.status.idle":"2021-11-24T13:12:58.52335Z","shell.execute_reply.started":"2021-11-24T13:12:58.517373Z","shell.execute_reply":"2021-11-24T13:12:58.521944Z"}}},{"cell_type":"code","source":"!pip install xgboost==1.5.0\n!pip install shap\n!pip install optuna\n!pip install seaborn\n!pip install pandas_profiling==3.1.0","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:59:56.378275Z","iopub.execute_input":"2021-11-24T14:59:56.379035Z","iopub.status.idle":"2021-11-24T15:00:36.468654Z","shell.execute_reply.started":"2021-11-24T14:59:56.378898Z","shell.execute_reply":"2021-11-24T15:00:36.467753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:00:36.472573Z","iopub.execute_input":"2021-11-24T15:00:36.472802Z","iopub.status.idle":"2021-11-24T15:00:36.481591Z","shell.execute_reply.started":"2021-11-24T15:00:36.472774Z","shell.execute_reply":"2021-11-24T15:00:36.480695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nfrom pandas_profiling import ProfileReport\n\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom xgboost import XGBClassifier, XGBRegressor\nimport xgboost as xgb\n\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, \\\n                                SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, classification_report, f1_score, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler, PowerTransformer\nfrom sklearn.utils import shuffle\nfrom sklearn import metrics\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nfrom tqdm.notebook import tqdm\nimport gc\nimport shap\nimport pickle\n\n%matplotlib inline\n\n#plt.rcParams['figure.dpi'] = 100\n#plt.rcParams.update({'font.size': 16})\n\n# load JS visualization code to notebook\nshap.initjs()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:00:36.483032Z","iopub.execute_input":"2021-11-24T15:00:36.483451Z","iopub.status.idle":"2021-11-24T15:00:40.931524Z","shell.execute_reply.started":"2021-11-24T15:00:36.483414Z","shell.execute_reply":"2021-11-24T15:00:40.930854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_with_data = '/kaggle/input/tabular-playground-series-nov-2021/'\npath_to_data = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:00:40.933107Z","iopub.execute_input":"2021-11-24T15:00:40.933348Z","iopub.status.idle":"2021-11-24T15:00:40.938274Z","shell.execute_reply.started":"2021-11-24T15:00:40.93331Z","shell.execute_reply":"2021-11-24T15:00:40.937391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\nTRAIN_MODEL = True\nINFER_TEST = True\nONE_FOLD_ONLY = False\nCOMPUTE_IMPORTANCE = True\nOOF = True","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:00:40.940153Z","iopub.execute_input":"2021-11-24T15:00:40.940653Z","iopub.status.idle":"2021-11-24T15:00:40.951024Z","shell.execute_reply.started":"2021-11-24T15:00:40.940615Z","shell.execute_reply":"2021-11-24T15:00:40.950144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test, sub = pd.read_csv(path_with_data + \"train.csv\", index_col=\"id\"), \\\n    pd.read_csv(path_with_data + \"test.csv\", index_col=\"id\"), \\\n    pd.read_csv(path_with_data + \"sample_submission.csv\")\n\nif DEBUG:\n    train = train[:50000]\n    test = test[:50000]\n\nprint(f'Train shape: {train.shape}')\nprint(f'Test shape: {test.shape}')\n\ntarget = 'target'","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:00:40.952512Z","iopub.execute_input":"2021-11-24T15:00:40.953074Z","iopub.status.idle":"2021-11-24T15:01:09.025438Z","shell.execute_reply.started":"2021-11-24T15:00:40.953037Z","shell.execute_reply":"2021-11-24T15:01:09.024646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:01:09.026665Z","iopub.execute_input":"2021-11-24T15:01:09.026925Z","iopub.status.idle":"2021-11-24T15:01:09.063028Z","shell.execute_reply.started":"2021-11-24T15:01:09.026889Z","shell.execute_reply":"2021-11-24T15:01:09.06228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Memory reducing","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:01:09.064426Z","iopub.execute_input":"2021-11-24T15:01:09.064689Z","iopub.status.idle":"2021-11-24T15:01:09.078734Z","shell.execute_reply.started":"2021-11-24T15:01:09.064656Z","shell.execute_reply":"2021-11-24T15:01:09.077601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:01:09.080708Z","iopub.execute_input":"2021-11-24T15:01:09.081038Z","iopub.status.idle":"2021-11-24T15:01:23.029702Z","shell.execute_reply.started":"2021-11-24T15:01:09.080988Z","shell.execute_reply":"2021-11-24T15:01:23.028899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple EDA","metadata":{}},{"cell_type":"markdown","source":"#### Pandas profiler","metadata":{}},{"cell_type":"code","source":"profile = ProfileReport(train, title=\"Pandas Profiling Report\", explorative=False, minimal=True, dark_mode=True)\nprofile","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:01:23.032989Z","iopub.execute_input":"2021-11-24T15:01:23.033189Z","iopub.status.idle":"2021-11-24T15:03:11.907225Z","shell.execute_reply.started":"2021-11-24T15:01:23.033164Z","shell.execute_reply":"2021-11-24T15:03:11.906469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Seaborn plots","metadata":{}},{"cell_type":"code","source":"#sns.relplot(data=train, x=train['f0'], y=train['f1'], kind='scatter', hue='target')\n#sns.displot(data=train, x='f1', kind='hist', hue='target')\n#sns.displot(data=train, x='f1', kind='kde', hue='target', fill=True)\n#sns.jointplot(data=train, x=train['f0'], y=train['f1'], kind='scatter', hue='target')\n#sns.pairplot(data=train[['f0', 'f1', 'f2', 'f3']], hue='target')  # very slow","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:03:11.909031Z","iopub.execute_input":"2021-11-24T15:03:11.909501Z","iopub.status.idle":"2021-11-24T15:03:11.913671Z","shell.execute_reply.started":"2021-11-24T15:03:11.909456Z","shell.execute_reply":"2021-11-24T15:03:11.912995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Correlation heatmap","metadata":{}},{"cell_type":"code","source":"predictors_amount = 20 + 1  # should div by 4  + 1\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Spearman Correlation of Features', y=1.05, size=15)\ncorrmat = train.corr(method='spearman').abs()\ncols = corrmat.nlargest(predictors_amount, target)[target].index\ncm = abs(np.corrcoef(train[cols].values.T))\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nmost_correlated = list(set(cols) - set([target]))","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:03:11.914708Z","iopub.execute_input":"2021-11-24T15:03:11.916022Z","iopub.status.idle":"2021-11-24T15:04:13.113949Z","shell.execute_reply.started":"2021-11-24T15:03:11.915985Z","shell.execute_reply":"2021-11-24T15:04:13.113227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the first most correlated features \n\ni = 1\ncols_amount = 4\nrows_amount = int(len(most_correlated) / cols_amount) \nplt.figure()\nfig, ax = plt.subplots(rows_amount, cols_amount, figsize=(20, 22))\nfor feature in most_correlated:\n    plt.subplot(rows_amount, cols_amount, i)\n    sns.histplot(train[feature],color=\"blue\", kde=True, bins=100, label='train_'+feature)\n    sns.histplot(test[feature],color=\"olive\", kde=True, bins=100, label='test_'+feature)\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:04:13.115432Z","iopub.execute_input":"2021-11-24T15:04:13.115879Z","iopub.status.idle":"2021-11-24T15:06:24.131565Z","shell.execute_reply.started":"2021-11-24T15:04:13.115843Z","shell.execute_reply":"2021-11-24T15:06:24.130917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data=train[most_correlated])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:06:24.132741Z","iopub.execute_input":"2021-11-24T15:06:24.13309Z","iopub.status.idle":"2021-11-24T15:06:25.241093Z","shell.execute_reply.started":"2021-11-24T15:06:24.133055Z","shell.execute_reply":"2021-11-24T15:06:25.240415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature preprocessing","metadata":{}},{"cell_type":"code","source":"columns = train.columns\npreproc = dict()\npreproc['target'] = target","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:06:25.242452Z","iopub.execute_input":"2021-11-24T15:06:25.242865Z","iopub.status.idle":"2021-11-24T15:06:25.247236Z","shell.execute_reply.started":"2021-11-24T15:06:25.242826Z","shell.execute_reply":"2021-11-24T15:06:25.246388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_drop = [target]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:06:25.248453Z","iopub.execute_input":"2021-11-24T15:06:25.248769Z","iopub.status.idle":"2021-11-24T15:06:25.257265Z","shell.execute_reply.started":"2021-11-24T15:06:25.248732Z","shell.execute_reply":"2021-11-24T15:06:25.256552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Select features","metadata":{}},{"cell_type":"code","source":"features = [col for col in train.columns if col not in to_drop ]\npreproc['features'] = features","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:06:25.260313Z","iopub.execute_input":"2021-11-24T15:06:25.2606Z","iopub.status.idle":"2021-11-24T15:06:25.266875Z","shell.execute_reply.started":"2021-11-24T15:06:25.260573Z","shell.execute_reply":"2021-11-24T15:06:25.266169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Collinear (highly correlated) features","metadata":{}},{"cell_type":"code","source":"# Threshold for removing correlated variables\nthreshold = 0.90\n# Absolute value correlation matrix\ncorr_matrix = train[features].corr(method='spearman').abs()\n# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n# Select columns with correlations above threshold\nhighly_correlated = [column for column in upper.columns if any(upper[column] > threshold)]\nfeatures = [col for col in features if col not in highly_correlated]\npreproc['features'] = features","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:06:25.268333Z","iopub.execute_input":"2021-11-24T15:06:25.268621Z","iopub.status.idle":"2021-11-24T15:07:23.556845Z","shell.execute_reply.started":"2021-11-24T15:06:25.268585Z","shell.execute_reply":"2021-11-24T15:07:23.556054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Zero standard deviation","metadata":{}},{"cell_type":"code","source":"threshold = 0\nzero_std = train[features].std().index[train[features].std() <= threshold]\nfeatures = [col for col in features if col not in zero_std]    \npreproc['features'] = features","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:07:23.558201Z","iopub.execute_input":"2021-11-24T15:07:23.558484Z","iopub.status.idle":"2021-11-24T15:07:24.025199Z","shell.execute_reply.started":"2021-11-24T15:07:23.558448Z","shell.execute_reply":"2021-11-24T15:07:24.024306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Zero coefficient of variantion","metadata":{}},{"cell_type":"code","source":"threshold = 1  # in %\nzero_cv = (100 * train[features].std() / train[features].mean()).index[(100 * train[features].std() / train[features].mean()) <= threshold]\nfeatures = [col for col in features if col not in zero_cv]\npreproc['features'] = features","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:07:24.026711Z","iopub.execute_input":"2021-11-24T15:07:24.026979Z","iopub.status.idle":"2021-11-24T15:07:24.789084Z","shell.execute_reply.started":"2021-11-24T15:07:24.02694Z","shell.execute_reply":"2021-11-24T15:07:24.788325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaler transform","metadata":{}},{"cell_type":"code","source":"scaler = RobustScaler()\nscaler.fit(train[features])\ntrain[features] = scaler.transform(train[features])\ntest[features] = scaler.transform(test[features])\npreproc['scaler'] = scaler","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:07:24.790451Z","iopub.execute_input":"2021-11-24T15:07:24.790706Z","iopub.status.idle":"2021-11-24T15:07:27.828788Z","shell.execute_reply.started":"2021-11-24T15:07:24.790673Z","shell.execute_reply":"2021-11-24T15:07:27.828032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Power transform","metadata":{}},{"cell_type":"code","source":"if 0:\n  pt = PowerTransformer()\n  pt.fit(train[features])\n  train[features] = pt.transform(train[features])\n  test[features] = pt.transform(test[features])\n  preproc['power_transformer'] = pt","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:07:27.829948Z","iopub.execute_input":"2021-11-24T15:07:27.831857Z","iopub.status.idle":"2021-11-24T15:07:27.837239Z","shell.execute_reply.started":"2021-11-24T15:07:27.831816Z","shell.execute_reply":"2021-11-24T15:07:27.836537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Distribution Plots with changes","metadata":{}},{"cell_type":"code","source":"# plot the first most correlated features \n\ni = 1\ncols_amount = 4\nrows_amount = int(len(most_correlated) / cols_amount) \nplt.figure()\nfig, ax = plt.subplots(rows_amount, cols_amount, figsize=(20, 22))\nfor feature in most_correlated:\n    plt.subplot(rows_amount, cols_amount, i)\n    sns.histplot(train[feature],color=\"blue\", kde=True, bins=100, label='train_'+feature)\n    sns.histplot(test[feature],color=\"olive\", kde=True, bins=100, label='test_'+feature)\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:07:27.838342Z","iopub.execute_input":"2021-11-24T15:07:27.838768Z","iopub.status.idle":"2021-11-24T15:09:36.358688Z","shell.execute_reply.started":"2021-11-24T15:07:27.838732Z","shell.execute_reply":"2021-11-24T15:09:36.358024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classic ML baselines","metadata":{}},{"cell_type":"markdown","source":"#### Data split","metadata":{}},{"cell_type":"code","source":"features = preproc['features']\nX_train, X_test, y_train, y_test = train_test_split(train[features], \n                                                    train[target],\n                                                    stratify=train[target], \n                                                    test_size=0.25, \n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:09:36.35993Z","iopub.execute_input":"2021-11-24T15:09:36.360311Z","iopub.status.idle":"2021-11-24T15:09:37.097332Z","shell.execute_reply.started":"2021-11-24T15:09:36.360275Z","shell.execute_reply":"2021-11-24T15:09:37.096616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clfs = {\n        'Logistic Regression': LogisticRegression(random_state=0), \n        'Naive Bayes': GaussianNB(),\n        #'SVM': SVC(gamma='auto'),\n        #'Random Forest': RandomForestClassifier(random_state=0),\n        'SGD Classifier': SGDClassifier(random_state=0),\n        'Ridge': RidgeClassifier(random_state=0),\n        'Passive Aggressive Classifier': PassiveAggressiveClassifier(random_state=0),\n        #'KNN': KNeighborsClassifier(),\n        #'MLP': MLPClassifier(),\n        'Decision Tree': DecisionTreeClassifier()\n       }","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:09:37.09858Z","iopub.execute_input":"2021-11-24T15:09:37.098844Z","iopub.status.idle":"2021-11-24T15:09:37.104247Z","shell.execute_reply.started":"2021-11-24T15:09:37.098811Z","shell.execute_reply":"2021-11-24T15:09:37.103583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for clf_name in clfs:   \n    clf = clfs[clf_name].fit(X_train, y_train)\n    y_pred = clf.predict(X_test)   \n    print(f'{clf_name}: F1 = {f1_score(y_test, y_pred)}, AUC = {roc_auc_score(y_test, y_pred)}, Accuracy = {accuracy_score(y_test, y_pred)}')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:09:37.105595Z","iopub.execute_input":"2021-11-24T15:09:37.106064Z","iopub.status.idle":"2021-11-24T15:11:53.829461Z","shell.execute_reply.started":"2021-11-24T15:09:37.106027Z","shell.execute_reply":"2021-11-24T15:11:53.828678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modern ML baselines","metadata":{}},{"cell_type":"code","source":"clfs = {\n        'XGBoost': XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor'),\n        'LGB': LGBMClassifier()\n       }","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:11:53.830891Z","iopub.execute_input":"2021-11-24T15:11:53.831308Z","iopub.status.idle":"2021-11-24T15:11:53.83554Z","shell.execute_reply.started":"2021-11-24T15:11:53.831271Z","shell.execute_reply":"2021-11-24T15:11:53.834826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for clf_name in clfs:   \n    clf = clfs[clf_name].fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(f'{clf_name}: F1 = {f1_score(y_test, y_pred)}, AUC = {roc_auc_score(y_test, y_pred)}, Accuracy = {accuracy_score(y_test, y_pred)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:11:53.840807Z","iopub.execute_input":"2021-11-24T15:11:53.841014Z","iopub.status.idle":"2021-11-24T15:12:28.072901Z","shell.execute_reply.started":"2021-11-24T15:11:53.84099Z","shell.execute_reply":"2021-11-24T15:12:28.072103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Best Baseline model","metadata":{}},{"cell_type":"code","source":"baseline_model = LogisticRegression(random_state=0)\nbaseline_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:28.074068Z","iopub.execute_input":"2021-11-24T15:12:28.074311Z","iopub.status.idle":"2021-11-24T15:12:35.909764Z","shell.execute_reply.started":"2021-11-24T15:12:28.074274Z","shell.execute_reply":"2021-11-24T15:12:35.908853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = baseline_model.predict(test[features])\ny_pred = baseline_model.predict(X_test) \nprint(f'LR: F1 = {f1_score(y_test, y_pred)}, AUC = {roc_auc_score(y_test, y_pred)}, Accuracy = {accuracy_score(y_test, y_pred)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:35.91105Z","iopub.execute_input":"2021-11-24T15:12:35.911307Z","iopub.status.idle":"2021-11-24T15:12:36.674628Z","shell.execute_reply.started":"2021-11-24T15:12:35.91127Z","shell.execute_reply":"2021-11-24T15:12:36.673927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = preds\nsub.to_csv(path_to_data + 'submission_bl.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:36.678634Z","iopub.execute_input":"2021-11-24T15:12:36.680553Z","iopub.status.idle":"2021-11-24T15:12:37.55288Z","shell.execute_reply.started":"2021-11-24T15:12:36.680512Z","shell.execute_reply":"2021-11-24T15:12:37.552127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### intermediate conclusion\nBaseline Logistic regression model gives us 0.734 on LB, which is within 95% of max LB result (0.75091)","metadata":{}},{"cell_type":"markdown","source":"## Add new features using XGBoost and SHAP","metadata":{}},{"cell_type":"code","source":"train_oof = np.zeros((train.shape[0],))\ntest_preds = 0\ntrain_oof.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:37.554316Z","iopub.execute_input":"2021-11-24T15:12:37.554586Z","iopub.status.idle":"2021-11-24T15:12:37.562005Z","shell.execute_reply.started":"2021-11-24T15:12:37.554552Z","shell.execute_reply":"2021-11-24T15:12:37.561183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params= {\n        \"objective\": \"binary:logistic\",\n        \"eval_metric\": \"error\",  \n        \"seed\": 2001,\n        'tree_method': \"gpu_hist\",\n        'predictor': 'gpu_predictor'\n    }","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:37.563605Z","iopub.execute_input":"2021-11-24T15:12:37.564104Z","iopub.status.idle":"2021-11-24T15:12:37.571916Z","shell.execute_reply.started":"2021-11-24T15:12:37.564066Z","shell.execute_reply":"2021-11-24T15:12:37.57121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_xgb = xgb.DMatrix(test[features])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:37.573439Z","iopub.execute_input":"2021-11-24T15:12:37.574164Z","iopub.status.idle":"2021-11-24T15:12:38.571813Z","shell.execute_reply.started":"2021-11-24T15:12:37.574121Z","shell.execute_reply":"2021-11-24T15:12:38.571224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_FOLDS = 5\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train[features], train[target]))):\n        #print(f'Fold {f}')\n        train_df, val_df = train[features].iloc[train_ind], train[features].iloc[val_ind]\n        train_target, val_target = train[target].iloc[train_ind], train[target].iloc[val_ind]\n                      \n        train_df = xgb.DMatrix(train_df, label=train_target)\n        val_df = xgb.DMatrix(val_df, label=val_target)\n        \n        model =  xgb.train(xgb_params, train_df, 100)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(test_xgb)\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test/NUM_FOLDS\n        \n        print(accuracy_score(np.round(temp_oof), val_target))","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:38.574596Z","iopub.execute_input":"2021-11-24T15:12:38.575165Z","iopub.status.idle":"2021-11-24T15:12:53.544881Z","shell.execute_reply.started":"2021-11-24T15:12:38.575128Z","shell.execute_reply":"2021-11-24T15:12:53.544158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nshap_preds = model.predict(test_xgb, pred_contribs=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:53.546202Z","iopub.execute_input":"2021-11-24T15:12:53.546949Z","iopub.status.idle":"2021-11-24T15:12:58.801863Z","shell.execute_reply.started":"2021-11-24T15:12:53.546908Z","shell.execute_reply":"2021-11-24T15:12:58.801151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize the effects of all the features\nshap.summary_plot(shap_preds[:,:-1], test[features])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:12:58.805693Z","iopub.execute_input":"2021-11-24T15:12:58.807814Z","iopub.status.idle":"2021-11-24T15:14:23.435994Z","shell.execute_reply.started":"2021-11-24T15:12:58.807774Z","shell.execute_reply":"2021-11-24T15:14:23.435241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_preds[:,:-1], test[features], plot_type=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:23.437213Z","iopub.execute_input":"2021-11-24T15:14:23.437558Z","iopub.status.idle":"2021-11-24T15:14:24.0124Z","shell.execute_reply.started":"2021-11-24T15:14:23.437518Z","shell.execute_reply":"2021-11-24T15:14:24.011678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nshap_interactions = model.predict(xgb.DMatrix(test[features][:50000]), pred_interactions=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:24.013952Z","iopub.execute_input":"2021-11-24T15:14:24.014241Z","iopub.status.idle":"2021-11-24T15:14:32.481438Z","shell.execute_reply.started":"2021-11-24T15:14:24.014204Z","shell.execute_reply":"2021-11-24T15:14:32.480579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_top_k_interactions(feature_names, shap_interactions, k):\n    # Get the mean absolute contribution for each feature interaction\n    aggregate_interactions = np.mean(np.abs(shap_interactions[:, :-1, :-1]), axis=0)\n    interactions = []\n    for i in range(aggregate_interactions.shape[0]):\n        for j in range(aggregate_interactions.shape[1]):\n            if j < i:\n                interactions.append(\n                    (feature_names[i] + \"*\" + feature_names[j], aggregate_interactions[i][j] * 2))\n    # sort by magnitude\n    interactions.sort(key=lambda x: x[1], reverse=True)\n    interaction_features, interaction_values = map(tuple, zip(*interactions))\n    plt.bar(interaction_features[:k], interaction_values[:k])\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    plt.show()\n    return interaction_features\n\ninteractions_to_add = 10    \ninteraction_features = plot_top_k_interactions(features, shap_interactions, interactions_to_add)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:32.482748Z","iopub.execute_input":"2021-11-24T15:14:32.483003Z","iopub.status.idle":"2021-11-24T15:14:35.338833Z","shell.execute_reply.started":"2021-11-24T15:14:32.482967Z","shell.execute_reply":"2021-11-24T15:14:35.337692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_new_features(df, interaction_features, amount_of_features):\n    features_list = interaction_features[:amount_of_features]\n    for feat in features_list: \n      first_name, second_name = feat.split('*')\n      df[feat] = df[first_name]*df[second_name]\n    return df, features_list","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:35.340479Z","iopub.execute_input":"2021-11-24T15:14:35.340971Z","iopub.status.idle":"2021-11-24T15:14:35.346594Z","shell.execute_reply.started":"2021-11-24T15:14:35.340931Z","shell.execute_reply":"2021-11-24T15:14:35.34576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, features_added = add_new_features(train, interaction_features, interactions_to_add)\ntest, _ = add_new_features(test, interaction_features, interactions_to_add)\nfeatures += list(features_added)\n\ndel test_xgb\ndel shap_interactions\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:35.347964Z","iopub.execute_input":"2021-11-24T15:14:35.348299Z","iopub.status.idle":"2021-11-24T15:14:35.765233Z","shell.execute_reply.started":"2021-11-24T15:14:35.348265Z","shell.execute_reply":"2021-11-24T15:14:35.764593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_added","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:35.767096Z","iopub.execute_input":"2021-11-24T15:14:35.767589Z","iopub.status.idle":"2021-11-24T15:14:35.774161Z","shell.execute_reply.started":"2021-11-24T15:14:35.767549Z","shell.execute_reply":"2021-11-24T15:14:35.773278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaler transform","metadata":{}},{"cell_type":"code","source":"scaler = RobustScaler()\nscaler.fit(train[features])\ntrain[features] = scaler.transform(train[features])\ntest[features] = scaler.transform(test[features])\npreproc['scaler'] = scaler","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:35.775312Z","iopub.execute_input":"2021-11-24T15:14:35.775645Z","iopub.status.idle":"2021-11-24T15:14:39.64677Z","shell.execute_reply.started":"2021-11-24T15:14:35.775609Z","shell.execute_reply":"2021-11-24T15:14:39.645998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline model with added features","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train[features], \n                                                    train[target],\n                                                    stratify=train[target], \n                                                    test_size=0.25, \n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:39.648184Z","iopub.execute_input":"2021-11-24T15:14:39.648455Z","iopub.status.idle":"2021-11-24T15:14:40.423335Z","shell.execute_reply.started":"2021-11-24T15:14:39.64842Z","shell.execute_reply":"2021-11-24T15:14:40.422585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_model_af = LogisticRegression(random_state=0)\nbaseline_model_af.fit(X_train, y_train)\npreds = baseline_model_af.predict(test[features])\ny_pred = baseline_model_af.predict(X_test) \nprint(f'LR: F1 = {f1_score(y_test, y_pred)}, AUC = {roc_auc_score(y_test, y_pred)}, Accuracy = {accuracy_score(y_test, y_pred)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:40.424737Z","iopub.execute_input":"2021-11-24T15:14:40.424988Z","iopub.status.idle":"2021-11-24T15:14:50.120508Z","shell.execute_reply.started":"2021-11-24T15:14:40.424954Z","shell.execute_reply":"2021-11-24T15:14:50.119755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = preds\nsub.to_csv(path_to_data + 'submission_blaf.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:50.121735Z","iopub.execute_input":"2021-11-24T15:14:50.121987Z","iopub.status.idle":"2021-11-24T15:14:50.961231Z","shell.execute_reply.started":"2021-11-24T15:14:50.121952Z","shell.execute_reply":"2021-11-24T15:14:50.960487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters tuning (Optuna)","metadata":{}},{"cell_type":"code","source":"# HPO using opuna\n\ndef lr_objective(trial):\n    params = {\n        'C': trial.suggest_loguniform('C', 1e-8, 1000.0),        \n        'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear']), \n        'random_state': 42,\n        'penalty' : 'l2',         \n    }\n    \n    X_train, X_val, y_train, y_val = train_test_split(train[features], train[target], test_size = 0.25, random_state = 42)\n    \n    model = LogisticRegression(**params)    \n    model.fit(X_train, y_train)\n    pred_val = model.predict(X_val)\n    \n    return roc_auc_score(y_val, pred_val)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:50.962453Z","iopub.execute_input":"2021-11-24T15:14:50.96277Z","iopub.status.idle":"2021-11-24T15:14:50.96998Z","shell.execute_reply.started":"2021-11-24T15:14:50.962727Z","shell.execute_reply":"2021-11-24T15:14:50.969294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampler = TPESampler(seed = 42)\nstudy = optuna.create_study(study_name = 'LR optimization',\n                            direction = 'maximize',\n                            sampler = sampler)\nstudy.optimize(lr_objective, n_trials = 10)\n\nprint(\"Best AUC:\", study.best_value)\nprint(\"Best params:\", study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:14:50.971417Z","iopub.execute_input":"2021-11-24T15:14:50.971847Z","iopub.status.idle":"2021-11-24T15:16:41.332487Z","shell.execute_reply.started":"2021-11-24T15:14:50.971808Z","shell.execute_reply":"2021-11-24T15:16:41.331696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 1:\n    params = study.best_params\nelse:\n    params = {'C': 0.00045858194103088424, 'solver': 'liblinear'}","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:16:41.336822Z","iopub.execute_input":"2021-11-24T15:16:41.337427Z","iopub.status.idle":"2021-11-24T15:16:41.345252Z","shell.execute_reply.started":"2021-11-24T15:16:41.337369Z","shell.execute_reply":"2021-11-24T15:16:41.343246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross-validation with optimized params","metadata":{}},{"cell_type":"code","source":"#EPOCH = 250\n#BATCH_SIZE = 512\nNUM_FOLDS = 5\nCOLS = features.copy()\n\nkf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\ntest_preds = []\noof_preds = []\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train[features], train[target])):\n        \n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[features].iloc[train_idx], train[features].iloc[test_idx]\n        y_train, y_valid = train[target].iloc[train_idx], train[target].iloc[test_idx]\n        \n        filename = f\"folds{fold}.pkl\"\n        \n        if TRAIN_MODEL:\n            #model = LogisticRegression(C = params['C'], solver = params['solver'])\n            model = LogisticRegression(**params)\n            model.fit(X_train, y_train)\n            pickle.dump(model, open(path_to_data + filename, 'wb'))                                    \n            \n        else:                  \n            model = pickle.load(open(path_to_data + filename, 'rb'))                  \n    \n        if OOF:\n            print(' Predicting OOF data...')                \n            oof = model.predict(X_valid)\n            baseline_accuracy = accuracy_score(y_valid, oof)            \n            oof_preds.append(baseline_accuracy)\n            print('OOF Accuracy = {0}'.format(baseline_accuracy))\n            print(' Done!')\n                       \n        if INFER_TEST:\n            print(' Predicting test data...')\n            preds = model.predict(test[features])\n            test_preds.append(np.array(preds))\n            print(' Done!')\n                    \n        if COMPUTE_IMPORTANCE:\n            # from  https://www.kaggle.com/cdeotte/lstm-feature-importance\n            results = []\n            print(' Computing feature importance...')\n            \n            # COMPUTE BASELINE (NO SHUFFLE)\n            oof = model.predict(X_valid)\n            baseline_accuracy = accuracy_score(y_valid, oof)\n            results.append({'feature':'BASELINE','accuracy':baseline_accuracy})\n                                    \n            for k in tqdm(range(len(COLS))):\n                \n                # SHUFFLE FEATURE K\n                save_col = X_valid.copy()\n                np.random.shuffle(X_valid[COLS[k]].values)\n                                \n                # COMPUTE OOF Accuracy WITH FEATURE K SHUFFLED\n                oof = model.predict(X_valid)\n                acc = accuracy_score(y_valid, oof)\n                results.append({'feature':COLS[k],'accuracy':acc})                               \n                \n                X_valid = save_col.copy()\n         \n            # DISPLAY FEATURE IMPORTANCE\n            print()\n            df = pd.DataFrame(results)\n            df = df.sort_values('accuracy')\n            plt.figure(figsize=(10,20))\n            plt.barh(np.arange(len(COLS)+1),df.accuracy)\n            plt.yticks(np.arange(len(COLS)+1),df.feature.values)\n            plt.title('Feature Importance',size=16)\n            plt.ylim((-1,len(COLS)+1))\n            plt.plot([baseline_accuracy,baseline_accuracy],[-1,len(COLS)+1], '--', color='orange',\n                     label=f'Baseline OOF\\naccuracy={baseline_accuracy:.3f}')\n            plt.xlabel(f'Fold {fold+1} OOF accuracy with feature permuted',size=14)\n            plt.ylabel('Feature',size=14)\n            plt.legend()\n            plt.show()\n                               \n            # SAVE LSTM FEATURE IMPORTANCE\n            df = df.sort_values('accuracy',ascending=False)\n            df.to_csv(f'feature_importance_fold_{fold+1}.csv',index=False)\n                               \n        # ONLY DO ONE FOLD\n        if ONE_FOLD_ONLY: break","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:16:41.346585Z","iopub.execute_input":"2021-11-24T15:16:41.346831Z","iopub.status.idle":"2021-11-24T15:20:21.56711Z","shell.execute_reply.started":"2021-11-24T15:16:41.346796Z","shell.execute_reply":"2021-11-24T15:20:21.566398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot of roc curve for the last fold","metadata":{}},{"cell_type":"code","source":"y_pred_proba = model.predict_proba(X_valid)[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_valid,  y_pred_proba)\nauc = metrics.roc_auc_score(y_valid, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data, auc for last fold = \" + str(round(auc*100,2)))\nplt.legend(loc=4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:20:21.568336Z","iopub.execute_input":"2021-11-24T15:20:21.568782Z","iopub.status.idle":"2021-11-24T15:20:21.970901Z","shell.execute_reply.started":"2021-11-24T15:20:21.568741Z","shell.execute_reply":"2021-11-24T15:20:21.970205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission prepare","metadata":{}},{"cell_type":"code","source":"sub['target'] = sum(test_preds) / NUM_FOLDS\nsub.to_csv(path_to_data + 'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:20:21.972129Z","iopub.execute_input":"2021-11-24T15:20:21.972589Z","iopub.status.idle":"2021-11-24T15:20:23.049363Z","shell.execute_reply.started":"2021-11-24T15:20:21.972549Z","shell.execute_reply":"2021-11-24T15:20:23.048629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Final conclusion: the best baseline mode is the best without feature engineering :)","metadata":{}}]}