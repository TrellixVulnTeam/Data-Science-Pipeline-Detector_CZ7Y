{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datatable as dt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:35:01.139131Z","iopub.execute_input":"2021-11-03T11:35:01.139638Z","iopub.status.idle":"2021-11-03T11:35:02.019868Z","shell.execute_reply.started":"2021-11-03T11:35:01.139555Z","shell.execute_reply":"2021-11-03T11:35:02.019008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Xgboost attempt in this TPS**\nSince i found everyone doing NN. So I thought of doing something different. I had done this xgboost by my past experiences from the competitions. So there can be some techniques which some think might be used by them. ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\ntest = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')\nss = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv')\ntrain = train.drop('id',axis=1)\ntest = test.drop('id',axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:35:02.021191Z","iopub.execute_input":"2021-11-03T11:35:02.02145Z","iopub.status.idle":"2021-11-03T11:35:24.449285Z","shell.execute_reply.started":"2021-11-03T11:35:02.021415Z","shell.execute_reply":"2021-11-03T11:35:24.448406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop('target', axis=1).copy()\ny = train['target'].copy()\nX_test = test.copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:35:24.450776Z","iopub.execute_input":"2021-11-03T11:35:24.451052Z","iopub.status.idle":"2021-11-03T11:35:24.917841Z","shell.execute_reply.started":"2021-11-03T11:35:24.451016Z","shell.execute_reply":"2021-11-03T11:35:24.917068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'max_depth': 6,\n    'n_estimators': 9500,\n    'subsample': 0.7,\n    'colsample_bytree': 0.2,\n    'colsample_bylevel': 0.6000000000000001,\n    'min_child_weight': 56.41980735551558,\n    'reg_lambda': 75.56651890088857,\n    'reg_alpha': 0.11766857055687065,\n    'gamma': 0.6407823221122686,\n    'booster': 'gbtree',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'use_label_encoder': False\n    }","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:35:24.92003Z","iopub.execute_input":"2021-11-03T11:35:24.920299Z","iopub.status.idle":"2021-11-03T11:35:24.926065Z","shell.execute_reply.started":"2021-11-03T11:35:24.920264Z","shell.execute_reply":"2021-11-03T11:35:24.925079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['std'] = X.std(axis=1)\nX['min'] = X.min(axis=1)\nX['max'] = X.max(axis=1)\n\nX_test['std'] = X_test.std(axis=1)\nX_test['min'] = X_test.min(axis=1)\nX_test['max'] = X_test.max(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:35:24.92768Z","iopub.execute_input":"2021-11-03T11:35:24.928215Z","iopub.status.idle":"2021-11-03T11:35:27.238871Z","shell.execute_reply.started":"2021-11-03T11:35:24.928162Z","shell.execute_reply":"2021-11-03T11:35:27.238149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nimport optuna\nkf = StratifiedKFold(n_splits=9, shuffle=True, random_state=12)\n\npreds = []\nscores = []\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    params['learning_rate']=0.0001\n    model1 = XGBClassifier(**params)\n    \n    model1.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_valid,y_valid)],\n              early_stopping_rounds=200,\n              verbose=False)\n    \n    params['learning_rate']=0.001\n    model2 = XGBClassifier(**params)\n    model2.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_valid,y_valid)],\n              early_stopping_rounds=200,\n              verbose=False,\n              xgb_model=model1)\n    \n    params['learning_rate']=0.001\n    model3 = XGBClassifier(**params)\n    \n    model3.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_valid,y_valid)],\n              early_stopping_rounds=200,\n              verbose=False,\n              xgb_model=model2)\n    \n    pred_valid = model3.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('||'*30)\n    \n    test_preds = model3.predict_proba(X_test)[:,1]\n    preds.append(test_preds)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-03T11:35:27.240312Z","iopub.execute_input":"2021-11-03T11:35:27.240586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.mean(np.column_stack(preds),axis=1)\n\nss['target'] = predictions\nss.to_csv('./submission.csv', index=False)\nss.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}