{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:rgba(0, 167, 255, 0.6);border-radius:5px;display:fill\">\n    <h1><center>Tabular Playground Series - Nov 2021</center></h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<center><a><img src=\"https://i.ibb.co/PWvpT9F/header.png\" alt=\"header\" border=\"0\" width=800 height=400></a></center>","metadata":{}},{"cell_type":"markdown","source":"<div align='center'>\n    <h1>PyTorch Tutorial</h1>\n    <img src='https://pytorch.org/assets/images/pytorch-logo.png' style=\"width:200px;height:200px;\">\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 69, 0, 0.5);border-radius:5px;display:fill\">\n    <h1><center>Importing Libraries and Data</center></h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.utils import shuffle\nfrom torch.autograd import Variable\n\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:17:43.974407Z","iopub.execute_input":"2021-11-06T10:17:43.975214Z","iopub.status.idle":"2021-11-06T10:17:43.980444Z","shell.execute_reply.started":"2021-11-06T10:17:43.975165Z","shell.execute_reply":"2021-11-06T10:17:43.979637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"id_column = 'id'\ntrain_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-nov-2021/train.csv\", index_col=id_column)\ntest_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-nov-2021/test.csv\", index_col=id_column)\nsubmission = pd.read_csv(\"/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv\", index_col=id_column)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:17:43.982509Z","iopub.execute_input":"2021-11-06T10:17:43.982963Z","iopub.status.idle":"2021-11-06T10:18:05.655508Z","shell.execute_reply.started":"2021-11-06T10:17:43.982916Z","shell.execute_reply":"2021-11-06T10:18:05.654607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 69, 0, 0.5);border-radius:5px;display:fill\">\n    <h1><center>Basic Data Check</center></h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Reduce memory","metadata":{}},{"cell_type":"code","source":"label = 'target'\nfeatures = [col for col in train_data.columns if 'f' in col]\n\ncont_features = []\ndisc_features = []\n\nfor col in features:\n    if train_data[col].dtype=='float64':\n        cont_features.append(col)\n    else:\n        disc_features.append(col)\n\ntrain_data[cont_features] = train_data[cont_features].astype('float32')\ntrain_data[disc_features] = train_data[disc_features].astype('uint8')\ntrain_data[cont_features] = train_data[cont_features].astype('float32')\ntrain_data[disc_features] = train_data[disc_features].astype('uint8')","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:05.657021Z","iopub.execute_input":"2021-11-06T10:18:05.657316Z","iopub.status.idle":"2021-11-06T10:18:18.602656Z","shell.execute_reply.started":"2021-11-06T10:18:05.657278Z","shell.execute_reply":"2021-11-06T10:18:18.601853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Collect garbage to reduce memory usage","metadata":{}},{"cell_type":"code","source":"import gc\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.604945Z","iopub.execute_input":"2021-11-06T10:18:18.605265Z","iopub.status.idle":"2021-11-06T10:18:18.732869Z","shell.execute_reply.started":"2021-11-06T10:18:18.605223Z","shell.execute_reply":"2021-11-06T10:18:18.730707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[:5]","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.734685Z","iopub.execute_input":"2021-11-06T10:18:18.735093Z","iopub.status.idle":"2021-11-06T10:18:18.764893Z","shell.execute_reply.started":"2021-11-06T10:18:18.735048Z","shell.execute_reply":"2021-11-06T10:18:18.763978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.766175Z","iopub.execute_input":"2021-11-06T10:18:18.766395Z","iopub.status.idle":"2021-11-06T10:18:18.781153Z","shell.execute_reply.started":"2021-11-06T10:18:18.766369Z","shell.execute_reply":"2021-11-06T10:18:18.780249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.782942Z","iopub.execute_input":"2021-11-06T10:18:18.783277Z","iopub.status.idle":"2021-11-06T10:18:18.793177Z","shell.execute_reply.started":"2021-11-06T10:18:18.783234Z","shell.execute_reply":"2021-11-06T10:18:18.792608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = train_data.drop(['target'], axis = 1), train_data['target']","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.794423Z","iopub.execute_input":"2021-11-06T10:18:18.794671Z","iopub.status.idle":"2021-11-06T10:18:18.921012Z","shell.execute_reply.started":"2021-11-06T10:18:18.794637Z","shell.execute_reply":"2021-11-06T10:18:18.919929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 69, 0, 0.5);border-radius:5px;display:fill\">\n    <h1><center>Logistic Regression with PyTorch</center></h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"In Logistic Regression we use:\n* One hidden layer with 1500 neurons\n* Activation function - leaky Relu\n* Dropout with p = 0.3\n* Sigmoid","metadata":{}},{"cell_type":"code","source":"class LogisticRegression(nn.Module):\n    def __init__(self,input_size,output_size):\n        super(LogisticRegression,self).__init__()\n        self.f1 = nn.Linear(input_dim, 1500)\n        self.f2 = nn.Linear(1500, output_dim)\n\n    def forward(self,x):\n        x = self.f1(x)\n        x = F.leaky_relu(x)\n        x = F.dropout(x, p = 0.3)\n        x = self.f2(x)\n        return  F.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.925072Z","iopub.execute_input":"2021-11-06T10:18:18.925486Z","iopub.status.idle":"2021-11-06T10:18:18.932857Z","shell.execute_reply.started":"2021-11-06T10:18:18.925429Z","shell.execute_reply":"2021-11-06T10:18:18.932213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 500\nbatch_no = len(X_train) // batch_size","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.933756Z","iopub.execute_input":"2021-11-06T10:18:18.934348Z","iopub.status.idle":"2021-11-06T10:18:18.944304Z","shell.execute_reply.started":"2021-11-06T10:18:18.934314Z","shell.execute_reply":"2021-11-06T10:18:18.943438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.945377Z","iopub.execute_input":"2021-11-06T10:18:18.94561Z","iopub.status.idle":"2021-11-06T10:18:18.956492Z","shell.execute_reply.started":"2021-11-06T10:18:18.945563Z","shell.execute_reply":"2021-11-06T10:18:18.955938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_batches(X, y, batch_size):\n    assert len(X) == len(y)\n    np.random.seed(42)\n    X = np.array(X)\n    y = np.array(y)\n    perm = np.random.permutation(len(X))\n\n    for i in range(len(X)//batch_size):\n        if i + batch_size >= len(X):\n            continue\n        ind = perm[i*batch_size : (i+1)*batch_size]\n        yield (X[ind], y[ind])","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.957549Z","iopub.execute_input":"2021-11-06T10:18:18.958206Z","iopub.status.idle":"2021-11-06T10:18:18.966684Z","shell.execute_reply.started":"2021-11-06T10:18:18.958169Z","shell.execute_reply":"2021-11-06T10:18:18.966102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In training stage we use:\n* Learning rate = 0.0001\n* Optimizer - Adam\n* Loss - CrossEntropyLoss\n* Epochs = 200","metadata":{}},{"cell_type":"code","source":"input_dim = 100\noutput_dim = 2\nlearning_rate = 0.0001\nmodel = LogisticRegression(input_dim,output_dim)\nerror = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nloss_list = []\nroc_list = []\niteration_number = 200\n\nfor iteration in range(iteration_number):\n    batch_loss = 0\n    batch_roc = 0\n    size = 0\n\n    for (x, y) in generate_batches(X_train, y_train, batch_size):\n        inputs = Variable(torch.from_numpy(x)).float()\n        labels = Variable(torch.from_numpy(y))\n            \n        optimizer.zero_grad() \n        results = model(inputs)\n        loss = error(results, labels)\n\n        batch_loss += loss.data\n        \n        loss.backward()\n        optimizer.step()\n        \n        batch_roc += roc_auc_score(labels.detach().numpy(), results[:, 1].detach().numpy())\n        size += 1\n    \n    loss_list.append(batch_loss/batch_no)\n    roc_list.append(batch_roc/size)\n    \n    if (iteration % 20 == 0):\n        print('Epoch {}: loss {}, ROC {}'.format(iteration, batch_loss / batch_no, batch_roc / size))\n\nplt.plot(range(iteration_number), loss_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"Loss\")\nplt.show()\nplt.plot(range(iteration_number), roc_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"ROC\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:18:18.967792Z","iopub.execute_input":"2021-11-06T10:18:18.968181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 69, 0, 0.5);border-radius:5px;display:fill\">\n    <h1><center>Predictions</center></h1>\n</div>","metadata":{}},{"cell_type":"code","source":"test_data =  np.array(test_data)\ntest_data = Variable(torch.FloatTensor(test_data), requires_grad=True) \npredictions = model(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = predictions[:, 1].detach().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submit.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 69, 0, 0.5);border-radius:5px;display:fill\">\n    <h1><center>Conclusion</center></h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div>\n    <p>\nFor best results you can change number of hidden layers in Logistic Regression and increase the number of epochs. </p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"*Please upvote if you liked it.*","metadata":{}}]}