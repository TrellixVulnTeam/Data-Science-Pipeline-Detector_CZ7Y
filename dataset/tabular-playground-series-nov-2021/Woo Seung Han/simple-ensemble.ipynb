{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"머신러닝을 몰라도 \"Config\"에 5가지만 넣으면, 실행할 수 있게 만들었습니다. \nEven if you don't know machine learning, you can submit only 5 things in \"config\"\n\n회사에서 많이 사용하게 만들었었고, 도움이 많이 될 겁니다. \nI made a lot of use of it in my company, and it will help a lot.","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"import os\n\n# 기본폴더(base folder)\ndir_ad = '/kaggle/input/tabular-playground-series-nov-2021'\n# dir_ad = os.getcwd()\n\n# 학습데이터, predict data 파일명(train, test file name)\ntrain = 'train.csv'\ntest = 'test.csv'\n\n# 어떤것을 분석 및 데이터 추출할지 구분할 수 있는 파일명 선택 \n# tag = 'train_MAU_3M_pred_MAUX_4M'← 이런 방식으로 나올 것으로 예상\ntag = 'house_result'\n\n# 모델 및 각종 산출물이 저장될 폴더\nmodel_dir = os.path.join(dir_ad, tag + '_v')\n\n# 레이블에 해당하는 컬럼(column corresponding to label: Y value)\ntarget = 'target'\n\n# 타겟팅 대상을 식별하기 위한 컬럼(Column to identify the target)\nindex_col = 'id'\n\n# 평가방법 \"accuracy\", \"roc_auc\",\"f1\" 등 선택\nchoice = \"roc_auc\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import SVC\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(os.path.join(dir_ad, train))\ndf_test = pd.read_csv(os.path.join(dir_ad, test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = [col for col in df_test.columns if df_test[col].dtype in [\"float16\",\"float32\",\"float64\", \"int64\", \"int32\"]]\ncat_cols = [col for col in df_test.columns if df_test[col].dtype not in [\"float16\",\"float32\",\"float64\", \"int64\", \"int32\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_outliers(data, col_name):\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in col_name:\n        Q1 = np.percentile(data[col], 25)\n        Q3 = np.percentile(data[col],75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outlier_list_col = data[(data[col] < Q1 - outlier_step) | (data[col] > Q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop outliers\ndf_train = df_train.drop(detect_outliers(df_train, num_cols), axis = 0).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_replace(data, col_name, q1=0.25, q3=0.75):\n    quartile1 = data[col_name].quantile(q1)\n    quartile3 = data[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    data.loc[(data[col_name] < low_limit), col_name] = low_limit\n    data.loc[(data[col_name] > up_limit), col_name] = up_limit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_cols:\n    outlier_replace(df_train,i)\n    outlier_replace(df_test, i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\ndf_test = df_test.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"over_column_name = list()\n\nfor i in num_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, target, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train)\ndf_test = pd.get_dummies(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_col = []\ndelete_train = []\n\nfor i in df_test.columns:\n    test_col.append(i)\nfor j in df_train.columns:\n    if j not in test_col:\n        delete_train.append(j)\ndelete_train.remove(target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_col = []\ndelete_test = []\n\nfor i in df_train.columns:\n    train_col.append(i)\nfor j in df_test.columns:\n    if j not in train_col:\n        delete_test.append(j)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for delete in delete_train:\n    df_train = df_train.drop([delete],axis=1)\n    \nfor delete in delete_test:\n    df_test = df_test.drop([delete],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[target] = df_train[target].astype(int)\ntrain_y = df_train[target]\ntrain_x = df_train.drop(labels = [target],axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kfold로 Cross validate\n# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RFC Parameters tunning \nRFC = RandomForestClassifier()\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [10],\n              \"max_features\": [3,20],\n              \"min_samples_split\": [3, 10],\n              \"min_samples_leaf\": [3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[4000],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring = choice, verbose = 1)\ngsRFC.fit(train_x, train_y)\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGB Parameters tunning \nXGB = xgb.XGBClassifier()\n\n## Search grid for optimal parameters\nxg_param_grid = {\"max_depth\": [5],\n              \"learning_rate\": [0.007],\n              \"eval_metric\": ['auc'],\n#               \"n_estimators\": [6000],\n              \"tree_method\": ['gpu_hist'], \n              \"gamma\": [1.5],\n              \"subsample\": [0.6],\n              \"max_delta_step\": [3],\n              \"min_child_weight\": [5]}\n\ngsXGB = GridSearchCV(XGB,param_grid = xg_param_grid, cv=kfold, scoring = choice, verbose = 1)\ngsXGB.fit(train_x, train_y)\nXGB_best = gsXGB.best_estimator_\n\n# Best score\ngsXGB.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LR Parameters tunning \nLR = LogisticRegression()\n\n## Search grid for optimal parameters\nlr_param_grid = {\"max_iter\": [20000],\n                 \"penalty\": ['l2']}\n\n\ngsLR = GridSearchCV(LR,param_grid = lr_param_grid, cv=kfold, scoring = choice, verbose = 1)\ngsLR.fit(train_x, train_y)\nLR_best = gsLR.best_estimator_\n\n# Best score\ngsLR.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\ng = plot_learning_curve(gsRFC.best_estimator_,\"RF learning curves\",train_x,train_y,cv=kfold)\n# g = plot_learning_curve(gsXGB.best_estimator_,\"XGB learning curves\",train_x,train_y,cv=kfold)\ng = plot_learning_curve(gsLR.best_estimator_,\"LR learning curves\",train_x,train_y,cv=kfold)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3개 모델 heat map으로 상관관계 비교\n# Correlation comparison with three model heat maps\n\ntest_RFC = pd.Series(RFC_best.predict(df_test), name=\"RFC\")\ntest_XGB = pd.Series(XGB_best.predict(df_test), name=\"XGB\")\ntest_LR = pd.Series(LR_best.predict(df_test), name=\"LR\")\n\nensemble_results = pd.concat([test_RFC,test_XGB,test_LR],axis=1)\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('xgb', XGB_best),('lr', LR_best)], voting='soft', n_jobs=4)\nvotingC = votingC.fit(train_x, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_Result = pd.Series(votingC.predict(df_test), name=target)\ndf_test = pd.read_csv(os.path.join(dir_ad, test))\nsubmission = pd.DataFrame({index_col: df_test[index_col], target: test_Result})\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}