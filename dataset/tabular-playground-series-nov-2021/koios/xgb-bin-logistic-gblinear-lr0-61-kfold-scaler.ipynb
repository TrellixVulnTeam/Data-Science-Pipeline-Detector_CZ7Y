{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-06T14:57:37.568728Z","iopub.execute_input":"2021-11-06T14:57:37.569043Z","iopub.status.idle":"2021-11-06T14:57:37.604844Z","shell.execute_reply.started":"2021-11-06T14:57:37.568963Z","shell.execute_reply":"2021-11-06T14:57:37.604166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/tabular-playground-series-nov-2021/train.csv'\ntest = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv', index_col = 'id')\ndf = pd.read_csv(train_dir)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:57:39.217333Z","iopub.execute_input":"2021-11-06T14:57:39.217923Z","iopub.status.idle":"2021-11-06T14:58:08.729002Z","shell.execute_reply.started":"2021-11-06T14:57:39.21787Z","shell.execute_reply":"2021-11-06T14:58:08.727891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:56:56.198481Z","iopub.status.idle":"2021-11-06T14:56:56.199067Z","shell.execute_reply.started":"2021-11-06T14:56:56.198809Z","shell.execute_reply":"2021-11-06T14:56:56.198837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum().sort_values # all not null","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:56:56.200199Z","iopub.status.idle":"2021-11-06T14:56:56.200765Z","shell.execute_reply.started":"2021-11-06T14:56:56.200518Z","shell.execute_reply":"2021-11-06T14:56:56.200545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target'].value_counts() # that's why I use binary classification","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:56:56.201864Z","iopub.status.idle":"2021-11-06T14:56:56.202485Z","shell.execute_reply.started":"2021-11-06T14:56:56.202232Z","shell.execute_reply":"2021-11-06T14:56:56.202273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = df.columns[1:-1]\ncol","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:58:08.730688Z","iopub.execute_input":"2021-11-06T14:58:08.730935Z","iopub.status.idle":"2021-11-06T14:58:08.738215Z","shell.execute_reply.started":"2021-11-06T14:58:08.730907Z","shell.execute_reply":"2021-11-06T14:58:08.737387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_curve,RocCurveDisplay,ConfusionMatrixDisplay,confusion_matrix,roc_auc_score,accuracy_score\nfrom sklearn import metrics\n\n # 정규분포로 표준화\nscaler = StandardScaler()\ndf[col] = scaler.fit_transform(df[col])\ntest[col] = scaler.transform(test[col])\n\n# cross validation - StratifiedKFold\n#Takes group information into account to avoid building folds with imbalanced class distributions\n#(for binary or multiclass classification tasks).\nskf = StratifiedKFold(n_splits=8, random_state=48, shuffle=True)\nauc, acc = [], []\npreds = np.zeros(test.shape[0])\nn = 0\n\nfor trn_idx, val_idx in skf.split(df[col], df['target']):\n    X_train, X_val = df[col].iloc[trn_idx], df[col].iloc[val_idx]\n    y_train, y_val =  df['target'].iloc[trn_idx], df['target'].iloc[val_idx]\n    \n    model = XGBClassifier(objective='binary:logistic', # 0 or 1\n                               learning_rate=0.75,\n                               n_jobs=2, \n                               booster='gblinear',\n                               updater='coord_descent') \n    model.fit(X_train, y_train ,\n              early_stopping_rounds=5,\n              eval_set=[(X_val, y_val)]\n            ) \n\n    preds += model.predict_proba(test[col])[:,1] / skf.n_splits\n    \n    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))\n    acc.append(accuracy_score(y_val, model.predict(X_val)))\n    \n    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n    n+=1\nprint(f\"the mean AUC is : {round(np.mean(auc)*100,2)} while the mean Accuracy is : {round(np.mean(acc)*100,2)} \")\n","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:58:08.739644Z","iopub.execute_input":"2021-11-06T14:58:08.740139Z","iopub.status.idle":"2021-11-06T14:59:03.120871Z","shell.execute_reply.started":"2021-11-06T14:58:08.740094Z","shell.execute_reply":"2021-11-06T14:59:03.11964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv')\nsub['target']=preds\nsub.to_csv('submission.csv', index=False)\n\nsub","metadata":{"execution":{"iopub.status.busy":"2021-11-06T14:59:27.216091Z","iopub.execute_input":"2021-11-06T14:59:27.216415Z","iopub.status.idle":"2021-11-06T14:59:29.389411Z","shell.execute_reply.started":"2021-11-06T14:59:27.216371Z","shell.execute_reply":"2021-11-06T14:59:29.388562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}