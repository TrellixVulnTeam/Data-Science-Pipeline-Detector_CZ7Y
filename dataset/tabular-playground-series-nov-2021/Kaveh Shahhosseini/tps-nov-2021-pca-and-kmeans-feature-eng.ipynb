{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport numpy as np\nimport pandas as pd\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.linear_model import LogisticRegression\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport shap","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-13T19:18:04.118101Z","iopub.execute_input":"2021-11-13T19:18:04.118513Z","iopub.status.idle":"2021-11-13T19:18:04.130581Z","shell.execute_reply.started":"2021-11-13T19:18:04.118417Z","shell.execute_reply":"2021-11-13T19:18:04.12929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv', index_col=0)\ntest = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv', index_col=0)\nsample_submission = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\nfeature_cols = test.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-11-13T19:18:04.137769Z","iopub.execute_input":"2021-11-13T19:18:04.138503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Data","metadata":{}},{"cell_type":"code","source":"train.hist(figsize=(20,15), grid=False, ylabelsize=5, xlabelsize=5, bins=30)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scale Data","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler()\ntrain[feature_cols] = sc.fit_transform(train[feature_cols])\ntest[feature_cols] = sc.transform(test[feature_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KMeans","metadata":{}},{"cell_type":"code","source":"useful_features = [\"f34\", \"f55\", \"f43\", \"f8\", \"f91\", \"f80\", \"f71\", \"f27\", \"f50\", \"f97\", \"f41\", \"f25\", \"f57\", \"f66\", \"f22\", \"f96\", \"f82\", \"f26\", \"f81\", \"f40\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n\n## You can uncomment and run the following lines to find the elbow point\n# inertia = {}\n# for i in range(2,18):\n#     kmeans = KMeans(n_clusters=i, random_state=42)\n#     kmeans.fit_predict(train[useful_features])\n#     inertia.update({i:kmeans.inertia_})\n\n# inertia_df = pd.Series(inertia)\n# plt.plot(inertia_df,marker=\"o\")\n# plt.xticks(inertia_df.index)\n# plt.xlabel(\"Number of clusters\")\n# plt.ylabel(\"Inertia\")\n# plt.show()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nn_clusters = 5\ncd_feature = True # cluster distance instead of cluster number  \n\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\n\nif cd_feature:\n    cluster_cols = [f\"cluster{i+1}\" for i in range(n_clusters)]\n    \n    X_cd = kmeans.fit_transform(train[useful_features])\n    X_cd = pd.DataFrame(X_cd, columns=cluster_cols, index=train.index)\n    train = train.join(X_cd)\n    \n    X_cd = kmeans.transform(test[useful_features])\n    X_cd = pd.DataFrame(X_cd, columns=cluster_cols, index=test.index)\n    test = test.join(X_cd)\n\nelse:\n    cluster_cols = [\"cluster\"]  \n    train[\"cluster\"] = kmeans.fit_predict(train[useful_features])\n    test[\"cluster\"] = kmeans.predict(test[useful_features])\n    \n\nfeature_cols += cluster_cols\n\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding New Features?","metadata":{}},{"cell_type":"code","source":"%%time\nsns.pairplot(train[cluster_cols+[\"target\"]].sample(1000, random_state=0), hue=\"target\", diag_kind='kde')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"new_f1\"] = train[\"cluster1\"]-train[\"cluster4\"]\ntrain[\"new_f2\"] = train[\"cluster3\"]-train[\"cluster4\"]\ntest[\"new_f1\"]  = test[\"cluster1\"]-test[\"cluster4\"]\ntest[\"new_f2\"]  = test[\"cluster3\"]-test[\"cluster4\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.scatterplot(data=train, x=\"new_f1\", y=\"new_f2\", hue=\"target\", alpha=0.8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"new_f3\"] = train[\"new_f1\"]-train[\"new_f2\"]\ntrain[\"new_f4\"] = train[\"new_f1\"]+train[\"new_f2\"]\ntest[\"new_f3\"]  = test[\"new_f1\"]-test[\"new_f2\"]\ntest[\"new_f4\"]  = test[\"new_f1\"]+test[\"new_f2\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.scatterplot(data=train, x=\"new_f3\", y=\"new_f4\", hue=\"target\", alpha=0.8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(\"new_f3\", axis=1, inplace=True) # since it doesn't look promising based on above plots\ntest.drop(\"new_f3\", axis=1, inplace=True)\n\nfeature_cols += [\"new_f1\", \"new_f2\", \"new_f4\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"folds = 5\ntrain[\"kfold\"] = -1\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(train,train[\"target\"])):\n    train.loc[valid_indicies, \"kfold\"] = fold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nscores = []\n\ntrain[\"lr\"] = 0\ntest[\"lr\"] = 0\nfor fold in range(folds):\n    x_train = train[train.kfold != fold].copy()\n    x_valid = train[train.kfold == fold].copy()\n    x_test  = test[feature_cols].copy()\n    \n    y_train = x_train['target']\n    y_valid = x_valid['target']\n    \n    x_train = x_train[feature_cols]\n    x_valid = x_valid[feature_cols]\n\n    \n    lr_model = LogisticRegression()\n    lr_model.fit(x_train, y_train)\n    \n    preds_train = lr_model.predict_proba(x_train)[:,1]\n    preds_valid = lr_model.predict_proba(x_valid)[:,1]\n    auc_train = roc_auc_score(y_train, preds_train)\n    auc = roc_auc_score(y_valid, preds_valid)\n    print(\"Fold\",fold,\", train:\", f\"{auc_train:.6f}\", \", valid:\", f\"{auc:.6f}\")\n    scores.append(auc)\n    \n    preds_test = lr_model.predict_proba(x_test)[:,1]\n    train[\"lr\"].loc[x_valid.index] = preds_valid\n    test[\"lr\"] += preds_test\n    \ntest[\"lr\"] /= folds\nprint(\"AVG AUC:\",np.mean(scores))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.scatterplot(data=train, x=\"lr\", y=\"new_f4\", hue=\"target\", alpha=0.8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols.append(\"lr\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=2, random_state=42)\nX_pca = pca.fit_transform(train[feature_cols])\nT_pca = pca.transform(test[feature_cols])\n\npca_cols = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n\nX_pca = pd.DataFrame(X_pca, columns=pca_cols, index=train.index)\nT_pca = pd.DataFrame(T_pca, columns=pca_cols, index=test.index)\n\ntrain = pd.concat([train, X_pca], axis=1)\ntest = pd.concat([test, T_pca], axis=1)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loadings = pd.DataFrame(pca.components_, index=pca_cols, columns=train[feature_cols].columns)\nloadings.style.bar(align='mid', color=['#d65f5f', '#5fba7d'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.scatterplot(data=train, x=\"PC1\", y=\"PC2\", hue=\"target\", alpha=0.8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols += [\"PC1\", \"PC2\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mutual Information","metadata":{}},{"cell_type":"code","source":"%%time\nx = train.iloc[:5000,:][feature_cols].copy()\ny = train.iloc[:5000,:]['target'].copy()\nmi_scores = mutual_info_regression(x, y)\nmi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=x.columns)\nmi_scores = mi_scores.sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = 20\nplt.figure(figsize=(20,10))\nsns.barplot(x=mi_scores.values[:top], y=mi_scores.index[:top], palette=\"summer\")\nplt.title(f\"Top {top} Strong Relationships Between Feature Columns and Target Column\")\nplt.xlabel(\"Relationship with Target\")\nplt.ylabel(\"Feature Columns\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"%%time\nfinal_test_predictions = []\nscores = []\n\nfor fold in range(folds):\n    x_train = train[train.kfold != fold].copy()\n    x_valid = train[train.kfold == fold].copy()\n    x_test  = test[feature_cols].copy()\n    \n    y_train = x_train['target']\n    y_valid = x_valid['target']\n    \n    x_train = x_train[feature_cols]\n    x_valid = x_valid[feature_cols]\n\n    xgb_params = {\n        'eval_metric': 'auc', \n        'objective': 'binary:logistic', \n        'tree_method': 'gpu_hist', \n        'gpu_id': 0, \n        'predictor': 'gpu_predictor', \n        'n_estimators': 10000, \n        'learning_rate': 0.01063045229441343, \n        'gamma': 0.24652519525750877, \n        'max_depth': 4, \n        'seed': 42,       \n        'min_child_weight': 366, \n        'subsample': 0.6423040816299684, \n        'colsample_bytree': 0.7751264493218339, \n        'colsample_bylevel': 0.8675692743597421, \n        'use_label_encoder': False,\n        'lambda': 0, \n        'alpha': 10\n    }\n    \n    xgb_model = XGBClassifier(**xgb_params)\n    xgb_model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n    \n    preds_train = xgb_model.predict_proba(x_train)[:,1]\n    preds_valid = xgb_model.predict_proba(x_valid)[:,1]\n    auc_train = roc_auc_score(y_train, preds_train)\n    auc = roc_auc_score(y_valid, preds_valid)\n    print(\"Fold\",fold,\", train:\", f\"{auc_train:.6f}\", \", valid:\", f\"{auc:.6f}\")\n    scores.append(auc)\n    \n    preds_test = xgb_model.predict_proba(x_test)[:,1]\n    final_test_predictions.append(preds_test)\n    \n    \nprint(\"AVG AUC:\",np.mean(scores))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP Values","metadata":{}},{"cell_type":"code","source":"shap_values = shap.TreeExplainer(xgb_model).shap_values(x_valid)\nshap.summary_plot(shap_values, x_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"lr\", shap_values, x_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 5\ndata_for_prediction = x_valid.iloc[idx]\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nprint(xgb_model.predict_proba(data_for_prediction_array))\n\nshap.initjs()\nexplainer = shap.TreeExplainer(xgb_model)\nshap_values = explainer.shap_values(data_for_prediction_array)\nshap.force_plot(explainer.expected_value, shap_values, data_for_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.decision_plot(explainer.expected_value, shap_values, data_for_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Prediction","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.histplot(x=np.mean(np.column_stack(final_test_predictions), axis=1), kde=True, color=\"blue\")\nplt.title(\"Predictions Distribution\")\nplt.xlabel(\"Prediction\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sample_submission['target'] = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}