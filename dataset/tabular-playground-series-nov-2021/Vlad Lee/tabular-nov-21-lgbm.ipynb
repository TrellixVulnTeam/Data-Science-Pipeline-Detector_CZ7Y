{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport gc\nimport random\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom IPython import display as ipd\n\nfrom pandas_profiling import ProfileReport as profile\n\nimport pkg_resources as pkg\nprint( f\"pandas_profiling version: {pkg.get_distribution('pandas_profiling').version}\")\n\nfrom tqdm import tqdm\nimport lightgbm as lgb\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.metrics import roc_curve, auc, cohen_kappa_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-10T04:10:24.826348Z","iopub.execute_input":"2021-11-10T04:10:24.827192Z","iopub.status.idle":"2021-11-10T04:10:24.843057Z","shell.execute_reply.started":"2021-11-10T04:10:24.82713Z","shell.execute_reply":"2021-11-10T04:10:24.842141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 42\nDEBUG = False\nPROFILE = False\n\ndef seeding(SEED, use_tf=False):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    if use_tf:\n        tf.random.set_seed(SEED)\n    print('seeding done!!!')\n\nseeding(RANDOM_SEED)\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv')\n\nif DEBUG:\n    train = train[:50000]\n    \ntarget = train.target\ntrain.drop(['id','target'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:10:25.495785Z","iopub.execute_input":"2021-11-10T04:10:25.4967Z","iopub.status.idle":"2021-11-10T04:10:52.029261Z","shell.execute_reply.started":"2021-11-10T04:10:25.496645Z","shell.execute_reply":"2021-11-10T04:10:52.028447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train:',train.shape)\nprint('test:',test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:10:52.031482Z","iopub.execute_input":"2021-11-10T04:10:52.031794Z","iopub.status.idle":"2021-11-10T04:10:52.037618Z","shell.execute_reply.started":"2021-11-10T04:10:52.031752Z","shell.execute_reply":"2021-11-10T04:10:52.036436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"%%time\n\nif PROFILE:\n    train_profile = profile(train, title=\"Train Data\", minimal=True)\n    display(train_profile)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:10:52.039269Z","iopub.execute_input":"2021-11-10T04:10:52.03963Z","iopub.status.idle":"2021-11-10T04:10:52.051266Z","shell.execute_reply.started":"2021-11-10T04:10:52.039562Z","shell.execute_reply":"2021-11-10T04:10:52.050386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with skew data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndef minmax_scale(df, cols):\n    scaler = MinMaxScaler()\n    for col in cols:\n        df[col] = scaler.fit_transform(df[col].values.reshape(-1,1))\n\nskewed_cols = ['f46', 'f59', 'f89']\nminmax_scale( train, skewed_cols)\nminmax_scale( test, skewed_cols)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:10:52.053874Z","iopub.execute_input":"2021-11-10T04:10:52.054135Z","iopub.status.idle":"2021-11-10T04:10:52.095994Z","shell.execute_reply.started":"2021-11-10T04:10:52.054104Z","shell.execute_reply":"2021-11-10T04:10:52.095149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ntrain_scaled = scaler.fit_transform(train)\ntest_scaled = scaler.transform(test)\n\npca = PCA(n_components=2)\nX_pca_train = pca.fit_transform(train_scaled)\nX_pca_test = pca.transform(test_scaled)\n\nf, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize=(15, 6))\nax1.scatter(X_pca_train[:,0],X_pca_train[:,1],c=target,cmap='rainbow')\nax2.scatter(X_pca_test[:,0],X_pca_test[:,1],cmap='rainbow')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:10:52.09721Z","iopub.execute_input":"2021-11-10T04:10:52.097475Z","iopub.status.idle":"2021-11-10T04:11:14.442053Z","shell.execute_reply.started":"2021-11-10T04:10:52.097446Z","shell.execute_reply":"2021-11-10T04:11:14.441182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:11:14.443814Z","iopub.execute_input":"2021-11-10T04:11:14.444101Z","iopub.status.idle":"2021-11-10T04:11:14.653179Z","shell.execute_reply.started":"2021-11-10T04:11:14.444062Z","shell.execute_reply":"2021-11-10T04:11:14.652566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_classes = pd.value_counts(target, sort = True).sort_index()\ncount_classes.plot(kind = 'bar')\nplt.title(\"histogram\")\nplt.xlabel(\"traget\")\nplt.ylabel(\"Frequency\")","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:11:14.654138Z","iopub.execute_input":"2021-11-10T04:11:14.654504Z","iopub.status.idle":"2021-11-10T04:11:14.827089Z","shell.execute_reply.started":"2021-11-10T04:11:14.65447Z","shell.execute_reply":"2021-11-10T04:11:14.826265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef run_train(X, y, run_params, splits, num_boost_round, verbose_eval, early_stopping_rounds ):\n    scores = []\n    models = []\n    evals_results = {}  # to record eval results for plotting\n    folds = KFold(n_splits=splits)\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print(f'Fold {fold_n+1} started')\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        model = lgb.train(\n            run_params, valid_names=[\"train\", \"valid\"], \n            train_set=lgb.Dataset(X_train, y_train ), \n            num_boost_round = num_boost_round,\n            valid_sets = [lgb.Dataset(X_valid, y_valid)],\n            verbose_eval = verbose_eval,\n            evals_result=evals_results,\n            early_stopping_rounds = early_stopping_rounds,\n        )\n\n        y_predicted = model.predict(X_valid)\n        score = roc_auc_score(y_valid, y_predicted)   \n        print(f'roc_auc_score: {score}')\n\n        models.append(model)\n        scores.append(score)\n    return scores, models, evals_results\n\n\nLEARNING_RATE = 0.00497\nMAX_DEPTH = -1\nNUM_LEAVES = 250    \nTOTAL_SPLITS = 6\nNUM_BOOST_ROUND = 4000\nEARLY_STOPPING_ROUNDS = 100\nVERBOSE_EVAL = 250    \n    \nnegative = target.value_counts()[0]\npositive = target.value_counts()[1]\nscale_pos_weight = negative / positive    \n    \nrun_params = {\n    'verbose': -1, \n    'boosting_type': 'gbdt', \n    'objective': 'binary', \n    'metric': ['auc', 'binary_logloss'],\n    'learning_rate': LEARNING_RATE, \n    'num_leaves': NUM_LEAVES, \n    'scale_pos_weight':scale_pos_weight,\n    'feature_fraction': 0.5, \n    'bagging_fraction': 0.5, \n    #'bagging_freq': 4, \n    'max_depth': MAX_DEPTH, \n}\n\nFEATURES = [col for col in train.columns if col.startswith('f')]\nscores, models, evals_results = run_train(train, target, run_params, TOTAL_SPLITS, NUM_BOOST_ROUND, \n                                          VERBOSE_EVAL, EARLY_STOPPING_ROUNDS)\nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T04:16:06.312084Z","iopub.execute_input":"2021-11-10T04:16:06.313031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting metrics recorded during training","metadata":{}},{"cell_type":"code","source":"ax = lgb.plot_metric(evals_results, metric='auc')\nplt.show()\n\nax = lgb.plot_metric(evals_results, metric='binary_logloss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T01:44:33.677091Z","iopub.execute_input":"2021-11-10T01:44:33.677455Z","iopub.status.idle":"2021-11-10T01:44:33.723725Z","shell.execute_reply.started":"2021-11-10T01:44:33.677416Z","shell.execute_reply":"2021-11-10T01:44:33.722542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = []\nfor model in models:\n    predicted.append(model.predict(test))\n\navg_preds = np.zeros(len(predicted[0]))\nfor pred in predicted:\n    avg_preds += pred\navg_pred = avg_preds / len(models)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T01:44:38.687648Z","iopub.execute_input":"2021-11-10T01:44:38.687969Z","iopub.status.idle":"2021-11-10T01:44:38.712366Z","shell.execute_reply.started":"2021-11-10T01:44:38.687934Z","shell.execute_reply":"2021-11-10T01:44:38.711101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = avg_pred\nsubmission.to_csv('submission.csv', index=False, float_format='%.6f')\nsubmission.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:13:40.736975Z","iopub.execute_input":"2021-11-04T03:13:40.737236Z","iopub.status.idle":"2021-11-04T03:13:43.141747Z","shell.execute_reply.started":"2021-11-04T03:13:40.737206Z","shell.execute_reply":"2021-11-04T03:13:43.140999Z"},"trusted":true},"execution_count":null,"outputs":[]}]}