{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lab 9\n# Data Science 311\n# Phelix Tang\n    In this lab we'll be entering a machine learning competition, we're given a data set and were supposed to predict the target column, this lab is very similar to the last one we did, example we'll use a couple different functions here. Since we have binary classifications, we're not going to use a regression to predict like the in the previous labs, we're going to use ROC predict. We'll still be using a scaler to train our train and validation sets. From there we'll use the standard scaler and CLF regression that we trained on those two sets to fit our test set.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# I had to do this in the kaggle ide since my laptop was broken, and it's too old to work with python3, thie following line of code just makes it so\n# the browser can see the dataframes I downloaded.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T02:25:46.091502Z","iopub.execute_input":"2021-11-30T02:25:46.091763Z","iopub.status.idle":"2021-11-30T02:25:46.102734Z","shell.execute_reply.started":"2021-11-30T02:25:46.091736Z","shell.execute_reply":"2021-11-30T02:25:46.102087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Splitting the data\n    In this lab i'm using kaggles online ide, we simply import the data set in here, then split them up into our x df's and our y dfs. we also drop id and target from train_x, since train_x is what we're going to be working with, id is the index, and target is what we're looking for","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")\n\ntrain_x = train.drop(columns=['target','id'])\ntrain_y = train[\"target\"]\ntest","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:25:46.104321Z","iopub.execute_input":"2021-11-30T02:25:46.104561Z","iopub.status.idle":"2021-11-30T02:26:05.866731Z","shell.execute_reply.started":"2021-11-30T02:25:46.104533Z","shell.execute_reply":"2021-11-30T02:26:05.865738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Standard Scaler and preprocessing\nHere we split up our data set into two, the reason we don't use 3 is because our test set is on the kaggle website, and it's unavailble to us. We then use the preprocessing standard scaler to better fit our data. I tried a couple other encodings, like ordinal and the oneencoder, but i decided to go with the one you refered to in the lab manual","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split( train_x, train_y, test_size=0.10, random_state=42)\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_scaled = scaler.transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:26:05.867974Z","iopub.execute_input":"2021-11-30T02:26:05.868212Z","iopub.status.idle":"2021-11-30T02:26:07.624067Z","shell.execute_reply.started":"2021-11-30T02:26:05.868183Z","shell.execute_reply":"2021-11-30T02:26:07.623351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Training model accuracy\nHere we use the logisticregression, to fit our X_Scaled above, and our y train, then we check our area roc accuracy score. X_scaled is our x vectors that we convered into z scores and y train is our ground truths from the split training model. We use an ROC curve, because we have binary classifications.","metadata":{}},{"cell_type":"code","source":"clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X_scaled, y_train)\n#reg = LinearRegression().fit(X_scaled,y_train)\nroc_auc_score(y_train, clf.predict_proba(X_scaled)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:26:07.62522Z","iopub.execute_input":"2021-11-30T02:26:07.625465Z","iopub.status.idle":"2021-11-30T02:26:12.627242Z","shell.execute_reply.started":"2021-11-30T02:26:07.62543Z","shell.execute_reply":"2021-11-30T02:26:12.626378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4 Validation model accuracy\nHere we check our use our standard scaler we used for the training model onto our validation set, and we check the score for that. we don't change our scaler and use the original one from our training set. This is pretty much a repeat of what we did above but with our validation set.","metadata":{}},{"cell_type":"code","source":"\nvalid_scaled = scaler.transform(X_valid)\nroc_auc_score(y_valid, clf.predict_proba(valid_scaled)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:26:12.62919Z","iopub.execute_input":"2021-11-30T02:26:12.629432Z","iopub.status.idle":"2021-11-30T02:26:12.714892Z","shell.execute_reply.started":"2021-11-30T02:26:12.629397Z","shell.execute_reply":"2021-11-30T02:26:12.71378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Complete model\nNow that our score is decently high, we'll rescale the entire dataset on a new standardscaler, using all of our data, from there we'll do the same thing, and use our logisticalregression to make a prediction. We will then use these two to fit our test model and make predictions off that.","metadata":{}},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler().fit(train_x)\nX_scaled = scaler.transform(train_x)\nclf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X_scaled, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:26:12.716479Z","iopub.execute_input":"2021-11-30T02:26:12.717139Z","iopub.status.idle":"2021-11-30T02:26:19.801488Z","shell.execute_reply.started":"2021-11-30T02:26:12.71709Z","shell.execute_reply":"2021-11-30T02:26:19.800386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final\nNow that we have our model fully trained, we'll just fit our test_x onto our scaler and logisticregression, that we used for our training model. From there we'll make a CSV from our test_predict, and grab the y column('id) from our test and submit it.","metadata":{}},{"cell_type":"code","source":"test_x = test.drop(columns=['id'])\ntest_y = test['id']\n#scaler = preprocessing.StandardScaler().fit(test_x)\nX_scaled = scaler.transform(test_x)\n#clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X_scaled, test_y)\ntest_predict = clf.predict_proba(X_scaled)[:, 1]\n#roc_auc_score(test_y, clf.predict_proba(X_scaled)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:26:19.802733Z","iopub.execute_input":"2021-11-30T02:26:19.802984Z","iopub.status.idle":"2021-11-30T02:26:20.318403Z","shell.execute_reply.started":"2021-11-30T02:26:19.802938Z","shell.execute_reply":"2021-11-30T02:26:20.317438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.DataFrame()\nsubmit['id'] = test['id']\nsubmit['target'] = test_predict\nsubmit.to_csv(\"Submit.csv\", header=submit.columns, index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:26:20.331442Z","iopub.execute_input":"2021-11-30T02:26:20.332141Z","iopub.status.idle":"2021-11-30T02:26:22.411994Z","shell.execute_reply.started":"2021-11-30T02:26:20.332089Z","shell.execute_reply":"2021-11-30T02:26:22.411082Z"},"trusted":true},"execution_count":null,"outputs":[]}]}