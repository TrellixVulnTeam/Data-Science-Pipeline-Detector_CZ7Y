{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime, timedelta\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import StratifiedKFold, TimeSeriesSplit,cross_val_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\nfrom tensorflow.keras import Model, Input\nfrom tensorflow.keras.layers import Dense, Dropout,LSTM,Bidirectional\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-21T07:43:31.168721Z","iopub.execute_input":"2021-07-21T07:43:31.169161Z","iopub.status.idle":"2021-07-21T07:43:37.820149Z","shell.execute_reply.started":"2021-07-21T07:43:31.169052Z","shell.execute_reply":"2021-07-21T07:43:37.819013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def json_to_df(df, column):\n    num_rows = len(df)\n    \n    data_list = []\n    for row in tqdm(range(num_rows)):\n        \n        json_data = df.iloc[row][column]\n        if str(json_data) != \"nan\":\n            data = pd.read_json(json_data)\n            data_list.append(data)\n        \n    all_data = pd.concat(data_list, axis = 0)\n    \n    return all_data\n\ndef create_model(input_shape):\n    inputs = Input(shape=input_shape)\n    \n   # x = Dense(320, activation='relu')(inputs)\n   # x = Dropout(0.5)(x)\n    x = Dense(120, activation='relu')(inputs)#(x)\n    x = Dropout(0.4)(x)\n    x = Dense(40, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(20, activation='relu')(x)\n    outputs = Dense(4, activation='relu')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    \n#     model.summary()\n    \n    return model\n\ndef prediction(df):\n    df = df.reset_index()\n    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n    df['playerId'] = df['date_playerId'].apply(lambda x: x.split('_')[1]).astype(int)\n    \n    for x in range(lag):\n        df['date'] = df['date'] - timedelta(days=1)\n        df = df.merge(player_engagement, how='left', on=['date', 'playerId'], suffixes=['',f'_{x+1}'])\n        df = df.fillna(0.)\n    \n    for x in range(4):\n        columns = [f'target{x+1}_{i+1}' for i in range(lag)]\n        df[f'target{x+1}_mean'] = df[columns].mean(axis=1)\n        df[f'target{x+1}_median'] = df[columns].median(axis=1)\n        df[f'target{x+1}_std'] = df[columns].std(axis=1)\n        df[f'target{x+1}_lower_quartile'] = df[columns].quantile(0.25, axis=1)\n        df[f'target{x+1}_upper_quartile'] = df[columns].quantile(0.75, axis=1)\n        df[f'target{x+1}_IQR'] = df[f'target{x+1}_upper_quartile'] - df[f'target{x+1}_lower_quartile']\n        df = df.drop(columns=columns)\n        \n    pred = np.zeros(df[target_columns].shape)\n    \n    for x in range(splits):\n        best_model = load_model(f'./best_model_split{x+1}.h5')\n        pred += best_model.predict(df[feature_columns].to_numpy()) / splits\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2021-07-21T07:43:37.821654Z","iopub.execute_input":"2021-07-21T07:43:37.821943Z","iopub.status.idle":"2021-07-21T07:43:37.83501Z","shell.execute_reply.started":"2021-07-21T07:43:37.821915Z","shell.execute_reply":"2021-07-21T07:43:37.833912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players = pd.read_csv(\"/kaggle/input/mlb-player-digital-engagement-forecasting/players.csv\",\n                      parse_dates = [\"DOB\",\"mlbDebutDate\"],infer_datetime_format = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:34:12.30464Z","iopub.execute_input":"2021-07-20T13:34:12.305048Z","iopub.status.idle":"2021-07-20T13:34:12.337412Z","shell.execute_reply.started":"2021-07-20T13:34:12.305014Z","shell.execute_reply":"2021-07-20T13:34:12.336469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/mlb-player-digital-engagement-forecasting/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T07:43:37.83817Z","iopub.execute_input":"2021-07-21T07:43:37.83864Z","iopub.status.idle":"2021-07-21T07:44:48.622847Z","shell.execute_reply.started":"2021-07-21T07:43:37.838594Z","shell.execute_reply":"2021-07-21T07:44:48.6219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_engagement = json_to_df(train, 'nextDayPlayerEngagement')\nplayer_engagement.insert(0, 'date', pd.to_datetime(player_engagement['engagementMetricsDate'])-\\\n                                                   timedelta(days=1))\nplayer_engagement['engagementMetricsDate'] = pd.to_datetime(player_engagement['engagementMetricsDate'])\nplayer_engagement.reset_index(drop=True, inplace=True)\nprint(player_engagement.shape)\nplayer_engagement.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T07:44:48.624413Z","iopub.execute_input":"2021-07-21T07:44:48.624961Z","iopub.status.idle":"2021-07-21T07:45:10.519526Z","shell.execute_reply.started":"2021-07-21T07:44:48.624924Z","shell.execute_reply":"2021-07-21T07:45:10.518419Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_engagement[['target1','target2','target3','target4']] = player_engagement[['target1','target2',\n                                                                                  'target3','target4']].astype(np.float16)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-21T07:45:10.521265Z","iopub.execute_input":"2021-07-21T07:45:10.521557Z","iopub.status.idle":"2021-07-21T07:45:10.709256Z","shell.execute_reply.started":"2021-07-21T07:45:10.521528Z","shell.execute_reply":"2021-07-21T07:45:10.70721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lag = 100\n\nlag_df = player_engagement.loc[player_engagement['date'] >= player_engagement.loc[0, 'date'] +\\\n                               timedelta(lag)]\n\nfor x in tqdm(range(1, (lag+1))):\n    drop_columns = [f'date_{x}', f'engagementMetricsDate_{x}']\n    lag_df = lag_df.merge(player_engagement, how='left', \n                          left_on=['date', 'playerId'],\n                          right_on=['engagementMetricsDate', 'playerId'],\n                          suffixes=['',f'_{x}'])\n    lag_df.drop(columns=drop_columns, inplace=True)\n    lag_df['date'] = lag_df['date'] - timedelta(days=1)\n    \nlag_df['date'] = lag_df['date'] + timedelta(days=lag)\nlag_df = lag_df.drop(columns=['engagementMetricsDate'])\nlag_df = lag_df.dropna()\nlag_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T07:57:51.008334Z","iopub.execute_input":"2021-07-21T07:57:51.008707Z","iopub.status.idle":"2021-07-21T08:08:02.260848Z","shell.execute_reply.started":"2021-07-21T07:57:51.008672Z","shell.execute_reply":"2021-07-21T08:08:02.259758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_columns = [x for x in lag_df.columns[6:]]","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:09:10.575016Z","iopub.execute_input":"2021-07-21T08:09:10.575467Z","iopub.status.idle":"2021-07-21T08:09:10.581766Z","shell.execute_reply.started":"2021-07-21T08:09:10.575426Z","shell.execute_reply":"2021-07-21T08:09:10.580922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lag_df = lag_df.sort_values(by=['date','playerId']).reset_index(drop=True)\nlag_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:09:10.758465Z","iopub.execute_input":"2021-07-21T08:09:10.758836Z","iopub.status.idle":"2021-07-21T08:09:21.507351Z","shell.execute_reply.started":"2021-07-21T08:09:10.758804Z","shell.execute_reply":"2021-07-21T08:09:21.506274Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,9))\nfor i in tqdm(lag_df.index[0:20]):\n    print(lag_df.loc[i][\"playerId\"])\n    plt.plot(lag_df.loc[i][feature_columns].tolist())","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:08:10.700606Z","iopub.execute_input":"2021-07-21T08:08:10.700895Z","iopub.status.idle":"2021-07-21T08:08:11.409564Z","shell.execute_reply.started":"2021-07-21T08:08:10.700865Z","shell.execute_reply":"2021-07-21T08:08:11.408483Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in tqdm(range(4)):\n    columns = [f'target{x+1}_{i+1}' for i in range(lag)]\n    lag_df[f'target{x+1}_mean'] = lag_df[columns].mean(axis=1).astype(np.float32)\n    lag_df[f'target{x+1}_median'] = lag_df[columns].median(axis=1).astype(np.float32)\n    lag_df[f'target{x+1}_std'] = lag_df[columns].std(axis=1).astype(np.float32)\n    lag_df[f'target{x+1}_lower_quartile'] = lag_df[columns].quantile(0.25, axis=1).astype(np.float32)\n    lag_df[f'target{x+1}_upper_quartile'] = lag_df[columns].quantile(0.75, axis=1).astype(np.float32)\n    lag_df[f'target{x+1}_IQR'] = lag_df[f'target{x+1}_upper_quartile'] - lag_df[f'target{x+1}_lower_quartile']\n    lag_df = lag_df.drop(columns=columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:09:53.444616Z","iopub.execute_input":"2021-07-21T08:09:53.444997Z","iopub.status.idle":"2021-07-21T08:15:32.844837Z","shell.execute_reply.started":"2021-07-21T08:09:53.444962Z","shell.execute_reply":"2021-07-21T08:15:32.843537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor,StackingRegressor","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:18:42.497656Z","iopub.execute_input":"2021-07-19T16:18:42.497921Z","iopub.status.idle":"2021-07-19T16:18:43.872062Z","shell.execute_reply.started":"2021-07-19T16:18:42.497894Z","shell.execute_reply":"2021-07-19T16:18:43.871179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimators = [\n     ('rf', RandomForestRegressor(n_estimators=10,criterion = \"mae\")),\n     #('xgb',XGBRegressor(n_estimators = 100)),\n    ('lgb',LGBMRegressor(n_estimators = 10,max_depth = 10)),\n    (\"lr\", LinearRegression())\n ]\nreg = MultiOutputRegressor(StackingRegressor(\n     estimators=estimators,\n     final_estimator=XGBRegressor(n_estimators = 100)))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:18:43.873242Z","iopub.execute_input":"2021-07-19T16:18:43.873497Z","iopub.status.idle":"2021-07-19T16:18:43.878818Z","shell.execute_reply.started":"2021-07-19T16:18:43.873472Z","shell.execute_reply":"2021-07-19T16:18:43.877858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_columns = [x for x in lag_df.columns[2:6]]\nfeature_columns = [x for x in lag_df.columns[6:]]","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:16:06.12428Z","iopub.execute_input":"2021-07-21T08:16:06.124667Z","iopub.status.idle":"2021-07-21T08:16:06.130389Z","shell.execute_reply.started":"2021-07-21T08:16:06.124632Z","shell.execute_reply":"2021-07-21T08:16:06.129232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nsplits = 5\n\ntss = TimeSeriesSplit(n_splits=splits)\n\nsplit = 1\n\nfor train_index, val_index in tqdm(tss.split(lag_df)):\n    plt.figure(figsize = (16,9))\n    X_train = lag_df.loc[train_index, feature_columns].to_numpy()\n    y_train = lag_df.loc[train_index, target_columns].to_numpy()\n    print(X_train.shape,y_train.shape)\n    \n    X_val =  lag_df.loc[val_index, feature_columns]\n    y_val = lag_df.loc[val_index, target_columns].to_numpy()\n\n    input_shape = (X_train.shape[1],)\n    \n    model = create_model(input_shape)\n    model.compile(\n        optimizer='adam',\n        loss='mean_absolute_error'\n    )\n    #     es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n    mc = ModelCheckpoint(f'best_model_split{split}.h5', monitor='val_loss', mode='min',\n                         save_best_only=True,verbose=1)\n\n    history = model.fit(X_train,\n                        y_train,\n                        validation_data=(X_val, y_val),\n                        epochs=10,\n                        batch_size=30000,\n                        callbacks=[mc])\n\n    plt.figure()\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.title(f'Training-Validation Loss Split-{split}')\n    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n    plt.show()\n    \n    split += 1\n","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:27:58.329435Z","iopub.execute_input":"2021-07-21T08:27:58.32978Z","iopub.status.idle":"2021-07-21T08:28:14.545871Z","shell.execute_reply.started":"2021-07-21T08:27:58.32975Z","shell.execute_reply":"2021-07-21T08:28:14.543532Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_engagement = player_engagement.drop(columns=['engagementMetricsDate'])","metadata":{"execution":{"iopub.status.busy":"2021-07-21T08:28:41.391713Z","iopub.execute_input":"2021-07-21T08:28:41.392066Z","iopub.status.idle":"2021-07-21T08:28:41.455104Z","shell.execute_reply.started":"2021-07-21T08:28:41.392034Z","shell.execute_reply":"2021-07-21T08:28:41.453877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mlb\nlag = 100\nsplits = 10\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in iter_test:\n    targets = prediction(sample_prediction_df)\n    sample_prediction_df[target_columns] = np.clip(targets, 0, 100)\n    env.predict(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:22:21.443285Z","iopub.execute_input":"2021-07-19T16:22:21.44369Z","iopub.status.idle":"2021-07-19T16:24:57.763747Z","shell.execute_reply.started":"2021-07-19T16:22:21.443646Z","shell.execute_reply":"2021-07-19T16:24:57.762765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}