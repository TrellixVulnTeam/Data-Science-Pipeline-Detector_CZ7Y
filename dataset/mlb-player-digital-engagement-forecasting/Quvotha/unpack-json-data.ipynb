{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T14:27:17.306763Z","iopub.execute_input":"2021-07-26T14:27:17.307272Z","iopub.status.idle":"2021-07-26T14:27:17.319193Z","shell.execute_reply.started":"2021-07-26T14:27:17.307221Z","shell.execute_reply":"2021-07-26T14:27:17.318101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nimport gc\nimport json\nimport os.path\nimport time\n\nimport datatable as dt\nfrom joblib import delayed, parallel","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:27:17.320639Z","iopub.execute_input":"2021-07-26T14:27:17.321088Z","iopub.status.idle":"2021-07-26T14:27:17.473735Z","shell.execute_reply.started":"2021-07-26T14:27:17.321057Z","shell.execute_reply":"2021-07-26T14:27:17.47257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/mlb-player-digital-engagement-forecasting/'","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:27:17.475935Z","iopub.execute_input":"2021-07-26T14:27:17.476235Z","iopub.status.idle":"2021-07-26T14:27:17.481054Z","shell.execute_reply.started":"2021-07-26T14:27:17.476207Z","shell.execute_reply":"2021-07-26T14:27:17.479902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train.csv","metadata":{}},{"cell_type":"code","source":"%%time\ntrain = dt.fread(os.path.join(INPUT_DIR, 'train_updated.csv')).to_pandas()\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:27:17.482847Z","iopub.execute_input":"2021-07-26T14:27:17.483216Z","iopub.status.idle":"2021-07-26T14:28:12.734272Z","shell.execute_reply.started":"2021-07-26T14:27:17.483177Z","shell.execute_reply":"2021-07-26T14:28:12.732901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unpack_json(row: pd.Series, json_col: str) -> pd.DataFrame:\n    try:\n        json_dict = json.loads(row[json_col])\n    except json.JSONDecodeError:\n        return pd.DataFrame()\n    json_df = pd.DataFrame(json_dict)\n    json_df['date__'] = row.date\n    return json_df","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:28:12.73613Z","iopub.execute_input":"2021-07-26T14:28:12.736599Z","iopub.status.idle":"2021-07-26T14:28:12.744038Z","shell.execute_reply.started":"2021-07-26T14:28:12.736553Z","shell.execute_reply":"2021-07-26T14:28:12.74261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsince = time.time()\njson_columns = train.drop(columns='date').columns.tolist()\nfor c in json_columns:\n    unpack_func = partial(unpack_json, json_col=c)\n    json_df = pd.concat((train[['date', c]].dropna().apply(unpack_func, axis=1)).tolist())\n    print(f'Extract {json_df.shape[0]} rows from {c} ({time.time() - since:.5f} seconds passed)')\n    json_df.to_csv(f'{c}.csv', index=False)\n    print(f'Write \"{c}.csv\" ({time.time() - since:.5f} seconds passed)')\n    del json_df\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:28:12.745595Z","iopub.execute_input":"2021-07-26T14:28:12.745927Z","iopub.status.idle":"2021-07-26T14:29:57.533187Z","shell.execute_reply.started":"2021-07-26T14:28:12.74589Z","shell.execute_reply":"2021-07-26T14:29:57.531844Z"},"trusted":true},"execution_count":null,"outputs":[]}]}