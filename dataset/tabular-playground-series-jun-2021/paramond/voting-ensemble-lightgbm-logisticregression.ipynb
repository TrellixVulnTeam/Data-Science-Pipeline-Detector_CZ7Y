{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VotingClassifier ensemble (lightgbm, catboost, LogisticRegression)","metadata":{"papermill":{"duration":0.011523,"end_time":"2021-06-19T01:51:10.003038","exception":false,"start_time":"2021-06-19T01:51:09.991515","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1. read datasets and initialize random seed.","metadata":{"papermill":{"duration":0.010215,"end_time":"2021-06-19T01:51:10.024044","exception":false,"start_time":"2021-06-19T01:51:10.013829","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv')\n\nSEED=2147483647\nrandom.seed(SEED)\nnp.random.seed(SEED)","metadata":{"papermill":{"duration":2.275248,"end_time":"2021-06-19T01:51:12.309685","exception":false,"start_time":"2021-06-19T01:51:10.034437","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. preprocessing datasets.","metadata":{"papermill":{"duration":0.010327,"end_time":"2021-06-19T01:51:12.330496","exception":false,"start_time":"2021-06-19T01:51:12.320169","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 2.1. convert 'target' value to 0,1,2,3,...,9. ","metadata":{"papermill":{"duration":0.010032,"end_time":"2021-06-19T01:51:12.35096","exception":false,"start_time":"2021-06-19T01:51:12.340928","status":"completed"},"tags":[]}},{"cell_type":"code","source":"target_dict = {\n    'Class_1' : 0,\n    'Class_2' : 1,\n    'Class_3' : 2,\n    'Class_4' : 3,\n    'Class_5' : 4,\n    'Class_6' : 5,\n    'Class_7' : 6,\n    'Class_8' : 7,\n    'Class_9' : 8,\n}\ntrain['target'] = train['target'].map(target_dict)","metadata":{"papermill":{"duration":0.061963,"end_time":"2021-06-19T01:51:12.423303","exception":false,"start_time":"2021-06-19T01:51:12.36134","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. define my transformer.","metadata":{"papermill":{"duration":0.010637,"end_time":"2021-06-19T01:51:12.444539","exception":false,"start_time":"2021-06-19T01:51:12.433902","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.base import TransformerMixin\n\nfeatures=['feature_{}'.format(x) for x in range(75)]\n\nclass MyTransformer1(TransformerMixin):\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n\n    def transform(self, X):\n        X = X.copy()\n        X = X[features]\n        return X\n\nclass MyTransformer2(TransformerMixin):\n    def clip(self,X):\n        for feature in features:\n            X[feature] = X[feature].clip(upper=4)\n        return X\n\n    def setup_new_feature(self,X):\n        for feature_value in [0,1,2,3]:\n            new_feature = 'count_{}'.format(feature_value)\n            X[new_feature] = X[features].apply(lambda x:(x.values==feature_value).sum(),axis=1)\n        return X\n\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n\n    def transform(self, X):\n        X = X.copy()\n        X = X[features]\n        X = self.setup_new_feature(self.clip(X))\n        return X\n\nclass MyTransformer3(TransformerMixin):\n    def clip(self,X):\n        for feature in features:\n            X[feature] = X[feature].clip(upper=4)\n        return X\n\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n\n    def transform(self, X):\n        X = X.copy()\n        X = X[features]\n        X = pd.get_dummies(self.clip(X),columns=features)\n        return X\n\nclass MyTransformer4(TransformerMixin):\n    def clip(self,X):\n        for feature in features:\n            X[feature] = X[feature].clip(upper=4)\n        return X\n\n    def setup_new_feature(self,X):\n        for feature_value in [0,1,2,3]:\n            new_feature = 'count_{}'.format(feature_value)\n            X[new_feature] = X[features].apply(lambda x:(x.values==feature_value).sum(),axis=1)\n        return X\n\n    def fit_transform(self, X, y=None,**fit_params):\n        return self.transform(X)\n\n    def transform(self, X):\n        X = X.copy()\n        X = X[features]\n        X = self.setup_new_feature(self.clip(X))\n        return pd.get_dummies(X, columns=features)\n\n    ","metadata":{"papermill":{"duration":0.863064,"end_time":"2021-06-19T01:51:13.318399","exception":false,"start_time":"2021-06-19T01:51:12.455335","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. define my classifier.","metadata":{"papermill":{"duration":0.010109,"end_time":"2021-06-19T01:51:13.339189","exception":false,"start_time":"2021-06-19T01:51:13.32908","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.base import ClassifierMixin\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\noptuna_recommended_params1 = {\n    'objective': 'multiclass',\n    'num_classes': 9,\n    'metric': 'multi_logloss',\n    'verbosity': 0,\n    'boosting_type': 'gbdt',\n    'feature_pre_filter': False,\n    'lambda_l1': 8.934626150848016,\n    'lambda_l2': 1.3751929899381281e-08,\n    'num_leaves': 8,\n    'feature_fraction': 0.4,\n    'bagging_fraction': 0.8781081160423493,\n    'bagging_freq': 4,\n    'min_child_samples': 50,\n}\n\noptuna_recommended_best_iteration1=123\n\noptuna_recommended_params2 = {\n    'objective': 'multiclass',\n    'num_classes': 9,\n    'metric': 'multi_logloss',\n    'verbosity': 0,\n    'boosting_type': 'gbdt',\n    'feature_pre_filter': False,\n    'lambda_l1': 8.934626150848016,\n    'lambda_l2': 6.580392901707003e-06,\n    'num_leaves': 4,\n    'feature_fraction': 0.4,\n    'bagging_fraction': 1.0,\n    'bagging_freq': 0,\n    'min_child_samples': 20,\n}\n\noptuna_recommended_best_iteration2=276\n\nmy_model1 = LGBMClassifier(\n    n_estimators=optuna_recommended_best_iteration1,\n    random_state=SEED,\n    **optuna_recommended_params1\n)\n\nmy_model2 = LGBMClassifier(\n    n_estimators=optuna_recommended_best_iteration2,\n    random_state=SEED,\n    **optuna_recommended_params2\n)\n\nmy_model3 = LogisticRegression(random_state=SEED,max_iter=2000)\n\ngrid_search_recommended_params4 = {\n    'min_data_in_leaf': 50,\n    'depth': 4,\n    'iterations': 300,\n    'learning_rate': 0.1\n}\n\nmy_model4 = CatBoostClassifier(loss_function='MultiClass', random_state=SEED,**grid_search_recommended_params4,verbose=0)\n\npipeline1 = make_pipeline(MyTransformer1(),my_model1)\npipeline2 = make_pipeline(MyTransformer2(),my_model2)\npipeline3 = make_pipeline(MyTransformer3(),my_model3)\npipeline4 = make_pipeline(MyTransformer4(),my_model4)\n","metadata":{"papermill":{"duration":1.196927,"end_time":"2021-06-19T01:51:14.546548","exception":false,"start_time":"2021-06-19T01:51:13.349621","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. train the VotingClassifier.","metadata":{"papermill":{"duration":0.010865,"end_time":"2021-06-19T01:51:14.569706","exception":false,"start_time":"2021-06-19T01:51:14.558841","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier,StackingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss,accuracy_score\n\nvoting_estimators = [\n    ('mod1', pipeline1),\n    ('mod2', pipeline2),\n    ('mod3', pipeline3),\n    ('mod4', pipeline4),\n]\n\nX = train[features]\ny = train['target']\n\nmod_vot = VotingClassifier(\n    estimators=voting_estimators,\n    voting = 'soft',\n).fit(X, y)\n\n","metadata":{"papermill":{"duration":135.187828,"end_time":"2021-06-19T01:53:29.768481","exception":false,"start_time":"2021-06-19T01:51:14.580653","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. create my submission file.","metadata":{"papermill":{"duration":0.013026,"end_time":"2021-06-19T01:53:29.795117","exception":false,"start_time":"2021-06-19T01:53:29.782091","status":"completed"},"tags":[]}},{"cell_type":"code","source":"y_pred_test  = mod_vot.predict_proba(test[features]) \n\nsubmission = test[['id']].copy()\nsubmission['Class_1'] = y_pred_test[:,0]\nsubmission['Class_2'] = y_pred_test[:,1]\nsubmission['Class_3'] = y_pred_test[:,2]\nsubmission['Class_4'] = y_pred_test[:,3]\nsubmission['Class_5'] = y_pred_test[:,4]\nsubmission['Class_6'] = y_pred_test[:,5]\nsubmission['Class_7'] = y_pred_test[:,6]\nsubmission['Class_8'] = y_pred_test[:,7]\nsubmission['Class_9'] = y_pred_test[:,8]\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":13.176188,"end_time":"2021-06-19T01:53:42.984394","exception":false,"start_time":"2021-06-19T01:53:29.808206","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.013191,"end_time":"2021-06-19T01:53:43.010883","exception":false,"start_time":"2021-06-19T01:53:42.997692","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}