{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS 6 - Supervised DAE + AutoLGB\n\nThe contents of the notebooks are organized as follows:\n\n1. Installing and loading libraries: installs `Kaggler` and load data and libraries\n3. Model definition and training: shows how to train LightGBM with `Kaggler`'s `AutoLGB`\n4. Submission\n\nEnjoy~!","metadata":{}},{"cell_type":"markdown","source":"# Part 1. Loading Libraries and Data","metadata":{}},{"cell_type":"code","source":"import gc\nimport joblib\nimport lightgbm as lgb\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom warnings import simplefilter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T16:11:56.744707Z","iopub.execute_input":"2021-06-02T16:11:56.745146Z","iopub.status.idle":"2021-06-02T16:11:56.751806Z","shell.execute_reply.started":"2021-06-02T16:11:56.745112Z","shell.execute_reply":"2021-06-02T16:11:56.750617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install kaggler","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-02T16:11:56.753623Z","iopub.execute_input":"2021-06-02T16:11:56.754042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import kaggler\nfrom kaggler.model import AutoLGB\nprint(kaggler.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\npd.set_option('max_columns', 100)\nsimplefilter('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_name = 'le_te_sdae'\nalgo_name = 'lgb'\nversion = 2\nmodel_name = f'{algo_name}_{feature_name}_v{version}'\n\ndata_dir = Path('../input/tabular-playground-series-jun-2021')\ntrain_file = data_dir / 'train.csv'\ntest_file = data_dir / 'test.csv'\nsample_file = data_dir / 'sample_submission.csv'\n\nfeature_dir = Path('../input/tps-6-dae-features')\n\nbuild_dir = Path('.')\npredict_val_file = build_dir / f'{model_name}.val.txt'\npredict_tst_file = build_dir / f'{model_name}.tst.txt'\nsubmission_file = build_dir / f'{model_name}.sub.csv'\n\nid_col = 'id'\ntarget_col = 'target'\n\nn_fold = 5\nseed = 42\nn_class = 9\nencoding_dim = 128\nratio = 4\nbatch_size = 64 * ratio\nlr = 0.0001 * ratio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn = pd.read_csv(train_file, index_col=id_col)\ntst = pd.read_csv(test_file, index_col=id_col)\nsub = pd.read_csv(sample_file, index_col=id_col)\nprint(trn.shape, tst.shape, sub.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = trn[target_col].str.split('_').str[1].astype(int) - 1\nn_trn = trn.shape[0]\ndf = pd.concat([trn.drop(target_col, axis=1), tst], axis=0)\nprint(df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 2. Model Training with AutoLGB","metadata":{}},{"cell_type":"code","source":"feature_cols = [f'le_{x}' for x in df.columns] + [f'te_{x}' for x in df.columns] + [f'sdae_{i}' for i in range(encoding_dim)]\nprint(len(feature_cols))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parameters and best epochs from AutoLGB\nis_tuned = True\nn_best = 376\nparams = {'bagging_freq': 1, \n          'verbosity': -1, \n          'seed': seed, \n          'num_threads': -1, \n          'feature_pre_filter': False, \n          'num_class': n_class, \n          'objective': 'multiclass', \n          'metric': 'multi_logloss', \n          'boosting': 'gbdt', \n          'bagging_fraction': 0.5, \n          'feature_fraction': 0.8, \n          'lambda_l1': 10, \n          'lambda_l2': 10, \n          'learning_rate': 0.013959172480364537, \n          'max_depth': 6, \n          'min_child_samples': 25, \n          'num_leaves': 31}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n\nP = np.zeros((n_trn, n_class), dtype=float)\nP_tst = np.zeros((tst.shape[0], n_class), dtype=float)\nfor i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n    y_trn, y_val = y[i_trn], y[i_val]\n    \n    X_trn_i = joblib.load(str(feature_dir / f'{feature_name}.trn{i}.joblib'))\n    X_val_i = joblib.load(str(feature_dir / f'{feature_name}.val{i}.joblib'))\n    X_tst_i = joblib.load(str(feature_dir / f'{feature_name}.tst{i}.joblib'))\n    \n    if not is_tuned:\n        clf = AutoLGB(objective='multiclass', metric='multi_logloss', params={'num_class': n_class}, \n                      sample_size=X_trn_i.shape[0], feature_selection=False, random_state=seed)\n        clf.tune(pd.DataFrame(X_trn_i, columns=feature_cols), y_trn)\n        features = clf.features\n        params = clf.params\n        n_best = clf.n_best\n        print(f'{n_best}')\n        print(f'{params}')\n        print(f'{features}')\n        is_tuned = True\n    \n    trn_data = lgb.Dataset(X_trn_i, y_trn)\n    val_data = lgb.Dataset(X_val_i, y_val)\n    clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100)\n    \n    P[i_val] = clf.predict(X_val_i)\n    P_tst += clf.predict(X_tst_i) / n_fold\n    print(f'CV #{i} Loss: {log_loss(y_val, P[i_val]):.6f}')","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'CV Loss: {log_loss(y, P):.6f}')\nnp.savetxt(predict_val_file, P, fmt='%.6f')\nnp.savetxt(predict_tst_file, P_tst, fmt='%.6f')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3. Submission","metadata":{}},{"cell_type":"code","source":"sub[sub.columns] = P_tst\nsub.to_csv(submission_file)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hope this helps.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}