{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id='tab'></a>\n## Table of Contents ‚è©\n* [Dataset üìã](#dat)\n* [Basic Overview üì∫](#1)\n  * [Train Dataset](#1.1)\n  * [Test Dataset](#1.2)\n\n* [Exploratory Data Analysis üìä](#2)\n  * [Target Distribution](#2.1)\n  * [Unique value of each feature in datasets](#2.2)\n  * [Percentage of zeroes in each feature of datasets](#2.3)\n  * [Distribution of each feature in training data](#2.4)\n  * [Feature Correlation of training dataset](#2.5)\n  * [Distribution of each feature in test dataset](#2.7)\n  * [Distribution of features according to targets](#2.8)\n  \n* [Conclusions ü§û](#3)\n* [References üí´](#4)\n  \n   ","metadata":{}},{"cell_type":"markdown","source":"<a id='dat'></a>\n# **Dataset üìã**","metadata":{}},{"cell_type":"markdown","source":"* The dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.","metadata":{}},{"cell_type":"markdown","source":"#### If you like this notebook do provide your feedback and upvote if you really my work .\n#### This notebook contains only EDA of dataset , will publish my nextbook regarding predictions and different methods of dealing with this problem (Hoping for getting good resultsüò∂üòè)\n#### But for now do enjoy this notebook and will come back soon üîúüòÉ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:03:25.17148Z","iopub.execute_input":"2021-06-11T17:03:25.172645Z","iopub.status.idle":"2021-06-11T17:03:25.184778Z","shell.execute_reply.started":"2021-06-11T17:03:25.172561Z","shell.execute_reply":"2021-06-11T17:03:25.182727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv(\"../input/tabular-playground-series-jun-2021/train.csv\")\ndf_test=pd.read_csv(\"../input/tabular-playground-series-jun-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:03:28.213018Z","iopub.execute_input":"2021-06-11T17:03:28.213391Z","iopub.status.idle":"2021-06-11T17:03:30.233484Z","shell.execute_reply.started":"2021-06-11T17:03:28.213359Z","shell.execute_reply":"2021-06-11T17:03:30.232486Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n<a id=\"1\"></a>\n</html>\n\n# 1. **Basic Overview üì∫**","metadata":{}},{"cell_type":"markdown","source":"<a id='1.1'></a>\n### 1.1 Train Dataset","metadata":{}},{"cell_type":"markdown","source":"*  There are 77 columns in training dataset , in which two are \"id\" and \"target\" columns , other remaining 75 columns are our independent features\n\n* There is no null values in the dataset , but there are lot of 0 values in each feature , is there any chance it can effect our predictions will talk about this later\n\n* \"feature_19\" has the highest mean and standard deviation\n\n* We have overall 9 classes to predict\n\n*  Data is imbalanced, class_6 (51811) and class_8 (51763) both combined covers more than 50% of data\n\n* All the features are in \"int64\" type except the \"target\" column which is in \"string\" type\n","metadata":{}},{"cell_type":"code","source":"print(\"***** Shape of training dataset *****\")\nprint()\nprint(df_train.shape)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:03:34.238378Z","iopub.execute_input":"2021-06-11T17:03:34.238764Z","iopub.status.idle":"2021-06-11T17:03:34.249293Z","shell.execute_reply.started":"2021-06-11T17:03:34.238727Z","shell.execute_reply":"2021-06-11T17:03:34.248056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** First five rows of training dataset *****\")\nprint()\ndf_train.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:03:37.792063Z","iopub.execute_input":"2021-06-11T17:03:37.792415Z","iopub.status.idle":"2021-06-11T17:03:37.858099Z","shell.execute_reply.started":"2021-06-11T17:03:37.792386Z","shell.execute_reply":"2021-06-11T17:03:37.857104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** dtypes of our training dataset *****\")\nprint()\nprint(df_train.dtypes)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:03:41.209404Z","iopub.execute_input":"2021-06-11T17:03:41.210102Z","iopub.status.idle":"2021-06-11T17:03:41.220941Z","shell.execute_reply.started":"2021-06-11T17:03:41.209994Z","shell.execute_reply":"2021-06-11T17:03:41.219054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** Basic stats about our training dataset *****\")\nprint()\ndf_train.drop(['id'],axis=1).describe().T.style.bar(subset=['mean'],color='#205ff2').background_gradient(subset=['std'],cmap='coolwarm').background_gradient(subset=['50%'],cmap='coolwarm').background_gradient(subset=['75%'],cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:03:45.021248Z","iopub.execute_input":"2021-06-11T17:03:45.021624Z","iopub.status.idle":"2021-06-11T17:03:46.213979Z","shell.execute_reply.started":"2021-06-11T17:03:45.021573Z","shell.execute_reply":"2021-06-11T17:03:46.213132Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** Value counts of target columns *****\")\nprint()\ndf_train['target'].value_counts()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:03:54.144756Z","iopub.execute_input":"2021-06-11T17:03:54.1452Z","iopub.status.idle":"2021-06-11T17:03:54.205403Z","shell.execute_reply.started":"2021-06-11T17:03:54.145156Z","shell.execute_reply":"2021-06-11T17:03:54.203999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Test Dataset","metadata":{}},{"cell_type":"markdown","source":"*  There are 76 columns in training dataset , in which one is \"id\" column , other remaining 75 columns are our independent features\n\n*  There is no null values in the dataset , but there are lot of 0 values in each feature , is there any chance it can effect our predictions will talk about this later\n\n*  \"feature_19\" has the highest mean and standard deviation\n\n*  All the features are of \"int64\" type\n","metadata":{}},{"cell_type":"code","source":"print(\"***** Shape of test dataset *****\")\nprint()\nprint(df_test.shape)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:03:58.555651Z","iopub.execute_input":"2021-06-11T17:03:58.556023Z","iopub.status.idle":"2021-06-11T17:03:58.562542Z","shell.execute_reply.started":"2021-06-11T17:03:58.555991Z","shell.execute_reply":"2021-06-11T17:03:58.560838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** First five rows of test dataset *****\")\nprint()\ndf_test.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:04:01.574531Z","iopub.execute_input":"2021-06-11T17:04:01.574955Z","iopub.status.idle":"2021-06-11T17:04:01.598544Z","shell.execute_reply.started":"2021-06-11T17:04:01.574918Z","shell.execute_reply":"2021-06-11T17:04:01.596918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** dtypes of our test dataset *****\")\nprint()\nprint(df_test.dtypes)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:04:04.784802Z","iopub.execute_input":"2021-06-11T17:04:04.785217Z","iopub.status.idle":"2021-06-11T17:04:04.795394Z","shell.execute_reply.started":"2021-06-11T17:04:04.785182Z","shell.execute_reply":"2021-06-11T17:04:04.794143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"***** Basic stats about our test dataset *****\")\nprint()\ndf_test.drop(['id'],axis=1).describe().T.style.bar(subset=['mean'],color='#205ff2').background_gradient(subset=['std'],cmap='coolwarm').background_gradient(subset=['50%'],cmap='coolwarm').background_gradient(subset=['75%'],cmap='coolwarm')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:04:07.950747Z","iopub.execute_input":"2021-06-11T17:04:07.951153Z","iopub.status.idle":"2021-06-11T17:04:08.468813Z","shell.execute_reply.started":"2021-06-11T17:04:07.951118Z","shell.execute_reply":"2021-06-11T17:04:08.467625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2'> </a>\n# 2. **Exploratory Data Analysis üìä**","metadata":{}},{"cell_type":"code","source":"def with_hue(data,feature,ax):\n    \n    #Numnber of categories\n    num_of_cat=len([x for x in data[feature].unique() if x==x])\n    \n    bars=ax.patches\n    \n    for ind in range(num_of_cat):\n        ##     Get every hue bar\n        ##     ex. 8 X categories, 4 hues =>\n        ##    [0, 8, 16, 24] are hue bars for 1st X category\n        hueBars=bars[ind:][::num_of_cat] \n        # Get the total height (for percentages)\n        total=sum([x.get_height() for x in hueBars])\n        #Printing percentages on bar\n        for bar in hueBars:\n            percentage='{:.1f}%'.format(100 * bar.get_height()/total)\n            ax.text(bar.get_x()+bar.get_width()/2.0,\n                   bar.get_height(),\n                   percentage,\n                    ha=\"center\",va=\"bottom\",fontweight='bold',fontsize=14)\n    \n\n    \ndef without_hue(data,feature,ax):\n    \n    total=float(len(data))\n    bars_plot=ax.patches\n    \n    for bars in bars_plot:\n        percentage = '{:.1f}%'.format(100 * bars.get_height()/total)\n        x = bars.get_x() + bars.get_width()/2.0\n        y = bars.get_height()\n        ax.text(x, y,(percentage,bars.get_height()),ha='center',fontweight='bold',fontsize=14)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:04:14.163548Z","iopub.execute_input":"2021-06-11T17:04:14.164138Z","iopub.status.idle":"2021-06-11T17:04:14.17611Z","shell.execute_reply.started":"2021-06-11T17:04:14.164089Z","shell.execute_reply":"2021-06-11T17:04:14.174663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.1'> </a>\n \n###  2.1 Target Distribution","metadata":{}},{"cell_type":"code","source":"#setting theme\nsns.set_theme(context='notebook',style='white',font_scale=3)\n\n#setting the background and foreground color\nfig=plt.figure(figsize=(24,12))\nax=plt.axes()\nax.set_facecolor(\"#F2EDD7FF\")\nfig.patch.set_color(\"#F2EDD7FF\")\n\n#Dealing with spines\nfor i in ['left','top','right']:\n    ax.spines[i].set_visible(False)\n    \nax.grid(linestyle=\"--\",axis='y',color='gray')\n\n#countplot\na=sns.countplot(data=df_train,x='target',saturation=3,palette='cool')\n\nwithout_hue(df_train,'target',a)\n\nplt.title(\"Target Distribution\",weight='bold')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T17:04:18.817268Z","iopub.execute_input":"2021-06-11T17:04:18.817924Z","iopub.status.idle":"2021-06-11T17:04:19.423621Z","shell.execute_reply.started":"2021-06-11T17:04:18.817863Z","shell.execute_reply":"2021-06-11T17:04:19.422773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.2'> </a>\n\n### 2.2 Unique value of each feature in datasets","metadata":{}},{"cell_type":"markdown","source":"* Unique values of most of the features in both 'train' and 'test' dataset are equal\n* feature_15 , feature_28 , feature_46 , feature_59 , feature_60 , feature_73  , these are the features which have difference in number of unique values\n* feature_60 have most difference in number of unique values","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(nrows=1,ncols=3,figsize=(18,12))\n\n#Train Dataset\n#ax=plt.axes()\nfor i in range(0,2):\n    ax[0].set_facecolor(\"#F2EDD7FF\")\n    \n#ax.set_facecolor(\"#F2EDD7FF\")\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nsns.set_palette(['#ff355d']*75)\n\nfor i in ['top','right']:\n    ax[0].spines[i].set_visible(False)\n    \nax[0].grid(linestyle=\"--\",axis='x',color='gray')\n\ny_col=df_train.columns[1:76]\ny_col=list(y_col)\nunique=[]\nfor i in y_col:\n    unique.append(df_train[i].nunique())\n\na=sns.barplot(x=unique,y=y_col,orient='h',zorder=2,alpha=1,saturation=1,linewidth=0,ax=ax[0])\na.set_xlabel(\"Unique Values\",fontsize=6, weight='bold')\na.set_ylabel(\"Features\",fontsize=6, weight='bold')\na.tick_params(labelsize=6, width=1, length=1.5)\na.text(2,-1.9,\"Unique values of each feature in training dataset\",fontsize=10,fontweight='bold')\nbars=a.patches\nfor bar in bars:\n    x = bar.get_x() + bar.get_width()+2\n    y = bar.get_y() + bar.get_height() / 2 \n    a.text(x, y,bar.get_width(),ha='center',va='center',fontweight='bold',fontsize=6)\n    \n\n\n#Test Dataset\n#ax=plt.axes()\nfor i in range(0,2):\n    ax[1].set_facecolor(\"#F2EDD7FF\")\n    \n#ax.set_facecolor(\"#F2EDD7FF\")\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nsns.set_palette(['#84DE02']*75)\n\nfor i in ['top','right']:\n    ax[1].spines[i].set_visible(False)\n    \nax[1].grid(linestyle=\"--\",axis='x',color='gray')\n\ny_col=df_test.columns[1:76]\ny_col=list(y_col)\nunique_test=[]\nfor i in y_col:\n    unique_test.append(df_test[i].nunique())\n\nb=sns.barplot(x=unique_test,y=y_col,orient='h',zorder=2,alpha=1,saturation=1,linewidth=0,ax=ax[1])\nb.set_xlabel(\"Unique Values\",fontsize=6, weight='bold')\nb.set_ylabel(\"Features\",fontsize=6, weight='bold')\nb.tick_params(labelsize=6, width=1, length=1.5)\nb.text(2,-1.9,\"Unique values of each feature in test dataset\",fontsize=10,fontweight='bold')\nbars=b.patches\nfor bar in bars:\n    x = bar.get_x() + bar.get_width()+2\n    y = bar.get_y() + bar.get_height() / 2 \n    b.text(x, y,bar.get_width(),ha='center',va='center',fontweight='bold',fontsize=6)\n    \n\n    \n#Difference in unique values between features\nfor i in range(0,2):\n    ax[2].set_facecolor(\"#F2EDD7FF\")\n    \n#ax.set_facecolor(\"#F2EDD7FF\")\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nsns.set_palette(['#fefe22']*75)\n\nfor i in ['top','right']:\n    ax[2].spines[i].set_visible(False)\n    \nax[2].grid(linestyle=\"--\",axis='x',color='gray')\n\ny_col=df_test.columns[1:76]\ny_col=list(y_col)\nunique_diff=[]\nfor i in y_col:\n    unique_diff.append(df_train[i].nunique()-df_test[i].nunique())\n\nb=sns.barplot(x=unique_diff,y=y_col,orient='h',zorder=2,alpha=1,saturation=1,linewidth=0,ax=ax[2])\nb.set_xlabel(\"Unique Values\",fontsize=6, weight='bold')\nb.set_ylabel(\"Features\",fontsize=6, weight='bold')\nb.tick_params(labelsize=6, width=1, length=1.5)\nb.text(2,-1.9,\"Difference of unique values in each features\",fontsize=10,fontweight='bold')\nbars=b.patches\nfor bar in bars:\n    x = bar.get_x() + bar.get_width()+2\n    y = bar.get_y() + bar.get_height() / 2 \n    b.text(x, y,bar.get_width(),ha='center',va='center',fontweight='bold',fontsize=6)\n    \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T18:17:34.833141Z","iopub.execute_input":"2021-06-11T18:17:34.833504Z","iopub.status.idle":"2021-06-11T18:17:40.326526Z","shell.execute_reply.started":"2021-06-11T18:17:34.833474Z","shell.execute_reply":"2021-06-11T18:17:40.325452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.3'> </a>\n\n### 2.3 Percentage of zeroes in each feature of datasets","metadata":{}},{"cell_type":"markdown","source":"* Majority of features in both dataset have more than 50% of zero values\n* Percentages of zeroes in each feature of train and test dataset is almost same ","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(nrows=1,ncols=3,figsize=(15,12))\n\n#Training dataset\nzeroes=(((df_train.iloc[:,1:76]==0).sum())/len(df_train))*100\n\nzero=np.array(zeroes)\nhundred=[100]*75\nfig=plt.figure(figsize=(12,12))\n\n#ax=plt.axes()\nfor i in range(0,2):\n    ax[0].set_facecolor(\"#F2EDD7FF\")\n\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nsns.set_palette(['#ff355d']*75)\n\nfor i in ['top','right']:\n    ax[0].spines[i].set_visible(False)\n    \nax[0].grid(linestyle=\"--\",axis='x',color='gray')\n\nsns.barplot(y=zeroes.index,x=hundred, color='#dadada',ax=ax[0])\nbarh = sns.barplot(y=zeroes.index, x=zero,zorder=2,alpha=1,saturation=1,linewidth=0,ax=ax[0])\nbarh.tick_params(labelsize=6, width=1, length=1.5)\nbarh.set_xlabel(\"% of zeroes\",fontsize=4, weight='bold')\nbarh.set_ylabel(\"Features\",fontsize=4, weight='bold')\n\nbarh.text(2,-1.9,\"% of zeroes in training data of  each feature\",fontsize=10,fontweight='bold')\n\nbars=barh.patches\nfor bar in bars:\n    x = bar.get_x() + bar.get_width()+2\n    y = bar.get_y() + bar.get_height() / 2 \n    percentage=str(bar.get_width())[:5]+\"%\"\n    barh.text(x, y,percentage,ha='center',va='center',fontweight='bold',fontsize=6)\n\n    \n    \n#Test dataset\nzeroes_test=(((df_test.iloc[:,1:76]==0).sum())/len(df_test))*100\n\nzero_test=np.array(zeroes_test)\nhundred_test=[100]*75\nfig=plt.figure(figsize=(12,12))\n\n#ax=plt.axes()\nfor i in range(0,2):\n    ax[1].set_facecolor(\"#F2EDD7FF\")\n\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nsns.set_palette(['#84DE02']*75)\n\nfor i in ['top','right']:\n    ax[1].spines[i].set_visible(False)\n    \nax[1].grid(linestyle=\"--\",axis='x',color='gray')\n\nsns.barplot(y=zeroes_test.index,x=hundred_test, color='#dadada',ax=ax[1])\nbarh = sns.barplot(y=zeroes_test.index, x=zero_test,zorder=2,alpha=1,saturation=1,linewidth=0,ax=ax[1])\nbarh.tick_params(labelsize=6, width=1, length=1.5)\nbarh.set_xlabel(\"% of zeroes\",fontsize=4, weight='bold')\nbarh.set_ylabel(\"Features\",fontsize=4, weight='bold')\n\nbarh.text(2,-1.9,\"% of zeroes in test data of each feature\",fontsize=10,fontweight='bold')\n\nbars=barh.patches\nfor bar in bars:\n    x = bar.get_x() + bar.get_width()+2\n    y = bar.get_y() + bar.get_height() / 2 \n    percentage=str(bar.get_width())[:5]+\"%\"\n    barh.text(x, y,percentage,ha='center',va='center',fontweight='bold',fontsize=6)\n    \n    \n    \n#difference in % of zeroes\nzeroes_test=(((df_train.iloc[:,1:76]==0).sum())/len(df_train))*100-(((df_test.iloc[:,1:76]==0).sum())/len(df_test))*100\n\nzero_test=np.array(zeroes_test)\nhundred_test=[100]*75\nfig=plt.figure(figsize=(12,12))\n\n#ax=plt.axes()\nfor i in range(0,2):\n    ax[2].set_facecolor(\"#F2EDD7FF\")\n\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nsns.set_palette(['#84DE02']*75)\n\nfor i in ['top','right']:\n    ax[2].spines[i].set_visible(False)\n    \nax[2].grid(linestyle=\"--\",axis='x',color='gray')\n\nsns.barplot(y=zeroes_test.index,x=hundred_test, color='#dadada',ax=ax[2])\nbarh = sns.barplot(y=zeroes_test.index, x=zero_test,zorder=2,alpha=1,saturation=1,linewidth=0,ax=ax[2])\nbarh.tick_params(labelsize=6, width=1, length=1.5)\nbarh.set_xlabel(\"% of zeroes\",fontsize=4, weight='bold')\nbarh.set_ylabel(\"Features\",fontsize=4, weight='bold')\n\nbarh.text(2,-1.9,\"Difference in % of zeroes in each feature\",fontsize=10,fontweight='bold')\n\nbars=barh.patches\nfor bar in bars:\n    x = bar.get_x() + bar.get_width()+2\n    y = bar.get_y() + bar.get_height() / 2 \n    percentage=str(bar.get_width())[:5]+\"%\"\n    barh.text(x, y,percentage,ha='center',va='center',fontweight='bold',fontsize=6)\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-11T18:22:33.397711Z","iopub.execute_input":"2021-06-11T18:22:33.398126Z","iopub.status.idle":"2021-06-11T18:22:41.234549Z","shell.execute_reply.started":"2021-06-11T18:22:33.398091Z","shell.execute_reply":"2021-06-11T18:22:41.233313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.4'> </a>\n\n### 2.4 Distribution of each feature in training data","metadata":{}},{"cell_type":"markdown","source":"* Most of the values in each feature is zero\n* Mostly all the features are right skewed\n* Some features have disturbances in their kdeplot distribution such as feature_16 , feature_18 , feature_22","metadata":{}},{"cell_type":"code","source":"print(\"***** Distribution of each feature in training dataset *****\")\nfig,ax=plt.subplots(nrows=19,ncols=4,figsize=(20,40))\nfig.patch.set_facecolor(\"#F2EDD7FF\")\ncols=list(df_train.columns)[1:76]\nfor i in range(0,19):\n    for j in range(0,4):\n        try:\n            ax[i][j].set_facecolor(\"#F2EDD7FF\")\n            a=sns.kdeplot(data=df_train,x=df_train[cols[i*4+j]],ax=ax[i][j],hue=df_train['target'],legend=False,palette=\"cool\",fill=True)\n        \n            ax[i][j].spines['top'].set_visible(False)\n            ax[i][j].spines['left'].set_visible(False)\n            ax[i][j].spines['right'].set_visible(False)\n            a.set(xticklabels=[])  \n            a.set(xlabel=None)\n            a.set(yticklabels=[])  \n            a.set(ylabel=None)\n            #a.set(title=cols[i*4+j])\n            a.set_title(cols[i*4+j],size=8,fontweight='bold')\n        except:\n            pass\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:19:01.933158Z","iopub.execute_input":"2021-06-11T17:19:01.933527Z","iopub.status.idle":"2021-06-11T17:21:11.331826Z","shell.execute_reply.started":"2021-06-11T17:19:01.933497Z","shell.execute_reply":"2021-06-11T17:21:11.330494Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.5'> </a>\n\n### 2.5 Feature Correlation of training dataset","metadata":{}},{"cell_type":"markdown","source":"* As we can see the highest correlation between any two features is 0.14 , so that means we don't have any significant correlation between all the available features","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(40,40))\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nax=plt.axes()\nax.set_facecolor(\"#F2EDD7FF\")\n\ncorr = df_train.drop('id',axis=1).corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\n\na=sns.heatmap(corr,\n        square=True, center=0, linewidth=0.2,\n        mask=mask) \n\na.set_title('Feature Correlation of training dataset', loc='left', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:54:29.26517Z","iopub.execute_input":"2021-06-11T17:54:29.265581Z","iopub.status.idle":"2021-06-11T17:54:34.294582Z","shell.execute_reply.started":"2021-06-11T17:54:29.265546Z","shell.execute_reply":"2021-06-11T17:54:34.293261Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.6'> </a>\n\n### 2.6 Distribution of each feature in test dataset","metadata":{}},{"cell_type":"markdown","source":"* Most of the values in each feature is zero\n* Mostly all the features are right skewed\n* Some features have disturbances in their kdeplot distribution such as feature_16 , feature_18 , feature_22","metadata":{}},{"cell_type":"code","source":"print(\"***** Distribution of each feature in test dataset *****\")\nprint()\nfig,ax=plt.subplots(nrows=19,ncols=4,figsize=(20,40))\nfig.patch.set_facecolor(\"#F2EDD7FF\")\ncols=list(df_test.columns)[1:76]\nfor i in range(0,19):\n    for j in range(0,4):\n        try:\n            ax[i][j].set_facecolor(\"#F2EDD7FF\")\n            a=sns.kdeplot(data=df_test,x=df_test[cols[i*4+j]],ax=ax[i][j],legend=False,palette=\"cool\",fill=True)\n        \n            ax[i][j].spines['top'].set_visible(False)\n            ax[i][j].spines['left'].set_visible(False)\n            ax[i][j].spines['right'].set_visible(False)\n            a.set(xticklabels=[])  \n            a.set(xlabel=None)\n            a.set(yticklabels=[])  \n            a.set(ylabel=None)\n            #a.set(title=cols[i*4+j])\n            a.set_title(cols[i*4+j],size=8,fontweight='bold')\n        except:\n            pass\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:42:37.662286Z","iopub.execute_input":"2021-06-11T17:42:37.662676Z","iopub.status.idle":"2021-06-11T17:43:19.638514Z","shell.execute_reply.started":"2021-06-11T17:42:37.662643Z","shell.execute_reply":"2021-06-11T17:43:19.63747Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.7'> </a>\n\n### 2.7 Feature Correlation of test dataset","metadata":{}},{"cell_type":"markdown","source":"* As we can see the highest correlation between any two features is 0.12 , so that means we don't have any significant correlation between all the available features","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(40,40))\nfig.patch.set_facecolor(\"#F2EDD7FF\")\nax=plt.axes()\nax.set_facecolor(\"#F2EDD7FF\")\n\ncorr = df_test.drop('id',axis=1).corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\n\na=sns.heatmap(corr,\n        square=True, center=0, linewidth=0.2,\n        mask=mask) \n\na.set_title('Feature Correlation of test dataset', loc='left', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:54:40.250882Z","iopub.execute_input":"2021-06-11T17:54:40.251324Z","iopub.status.idle":"2021-06-11T17:54:43.50042Z","shell.execute_reply.started":"2021-06-11T17:54:40.251285Z","shell.execute_reply":"2021-06-11T17:54:43.496254Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='2.8'> </a>\n\n### 2.8 Distribution of features according to targets","metadata":{}},{"cell_type":"markdown","source":"* From the below stripplot , we can observe that none of features in our train dataset have some patterns or any type of correlation with any of classes available","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(nrows=19,ncols=4,figsize=(20,40))\nfig.patch.set_facecolor(\"#F2EDD7FF\")\ncols=list(df_test.columns)[1:76]\nfor i in range(0,19):\n    for j in range(0,4):\n        try:\n            ax[i][j].set_facecolor(\"#F2EDD7FF\")\n            a=sns.stripplot(data=df_train,x=df_train['target'],y=df_test[cols[i*4+j]],ax=ax[i][j],palette=\"cool\")\n        \n            ax[i][j].spines['top'].set_visible(False)\n            ax[i][j].spines['left'].set_visible(False)\n            ax[i][j].spines['right'].set_visible(False)\n            a.set(xticklabels=[])  \n            a.set(xlabel=None)\n            a.set(yticklabels=[])  \n            a.set(ylabel=None)\n            #a.set(title=cols[i*4+j])\n            a.set_title(cols[i*4+j],size=8,fontweight='bold')\n        except:\n            pass\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T17:51:34.976165Z","iopub.execute_input":"2021-06-11T17:51:34.976573Z","iopub.status.idle":"2021-06-11T17:52:40.566327Z","shell.execute_reply.started":"2021-06-11T17:51:34.976536Z","shell.execute_reply":"2021-06-11T17:52:40.56542Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='3'> </a>\n\n# 3. **Conclusions ü§û**","metadata":{}},{"cell_type":"markdown","source":"* In my opinion , nature of train and test dataset is almost same . That means we can apply same preprocessing on both train and test dataset\n\n* All features have lot of zeroes , as we don't have any description about any dataset so we can't say anything about the features available . May be we can say that not all features from 0 t0 74 is contributing towards any class , that's why dataset creater put zeroes instead of null values\n\n* As there are a lot of features , but none of them is correlated to each other means all of them are independent of each other . \n\n","metadata":{}},{"cell_type":"markdown","source":"[slide to top](#tab)\n<a id='4'> </a>\n\n# 4. **References üí´**\n\n* https://www.kaggle.com/subinium/tps-may-categorical-eda\n\n* https://www.kaggle.com/dwin183287/tps-june-2021-eda","metadata":{}},{"cell_type":"markdown","source":"## Please provide your feedback in comment section , Do give an upvote if you like my work üòÄüëç","metadata":{}}]}