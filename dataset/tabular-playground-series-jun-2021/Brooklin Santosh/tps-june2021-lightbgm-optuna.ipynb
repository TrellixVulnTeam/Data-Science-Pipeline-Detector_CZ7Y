{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Hi everyone, in this notebook we will start with basic LGBMClassifier and then we will see how to optimize hyper paramters of LGBMClassifier with Optuna.","metadata":{}},{"cell_type":"markdown","source":"## Approach","metadata":{}},{"cell_type":"markdown","source":"1. Import libraries\n2. Read the data\n3. Check for missing values and target distribution\n4. Create folds for Cross Validation\n5. Fit with base LGBMClassifier\n6. Tune hyperparamters with Optuna\n7. Retrain the model with tuned hyperparameters.\n8. Create submission files","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T02:27:49.753051Z","iopub.execute_input":"2021-06-11T02:27:49.753501Z","iopub.status.idle":"2021-06-11T02:27:49.769564Z","shell.execute_reply.started":"2021-06-11T02:27:49.753404Z","shell.execute_reply":"2021-06-11T02:27:49.768541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold # For creating folds\nfrom sklearn.metrics import log_loss # Evaluation metrics\n\nimport optuna\n#from optuna.integration.lightgbm import LGBMClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:27:52.155707Z","iopub.execute_input":"2021-06-11T02:27:52.156071Z","iopub.status.idle":"2021-06-11T02:27:55.428147Z","shell.execute_reply.started":"2021-06-11T02:27:52.156039Z","shell.execute_reply":"2021-06-11T02:27:55.426925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Reading the train, test and sample submission file","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/test.csv\")\nss = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:28:49.128387Z","iopub.execute_input":"2021-06-11T02:28:49.128746Z","iopub.status.idle":"2021-06-11T02:28:51.30182Z","shell.execute_reply.started":"2021-06-11T02:28:49.128717Z","shell.execute_reply":"2021-06-11T02:28:51.300773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Basic data check","metadata":{}},{"cell_type":"code","source":"print(f\"Shape of train : {df.shape}\")\nprint(f\"Shape of test : {test.shape}\")\nprint(f\"Shape of sample submission : {ss.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:29:11.309388Z","iopub.execute_input":"2021-06-11T02:29:11.309794Z","iopub.status.idle":"2021-06-11T02:29:11.316211Z","shell.execute_reply.started":"2021-06-11T02:29:11.309751Z","shell.execute_reply":"2021-06-11T02:29:11.31485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:29:12.602937Z","iopub.execute_input":"2021-06-11T02:29:12.603352Z","iopub.status.idle":"2021-06-11T02:29:12.63934Z","shell.execute_reply.started":"2021-06-11T02:29:12.603315Z","shell.execute_reply":"2021-06-11T02:29:12.638302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:29:13.691844Z","iopub.execute_input":"2021-06-11T02:29:13.692367Z","iopub.status.idle":"2021-06-11T02:29:13.768792Z","shell.execute_reply.started":"2021-06-11T02:29:13.692333Z","shell.execute_reply":"2021-06-11T02:29:13.767928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:29:14.840423Z","iopub.execute_input":"2021-06-11T02:29:14.840895Z","iopub.status.idle":"2021-06-11T02:29:14.880519Z","shell.execute_reply.started":"2021-06-11T02:29:14.840865Z","shell.execute_reply":"2021-06-11T02:29:14.879191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing values in the both train and test datasets and all are integers, so the categories might be encoded already.","metadata":{}},{"cell_type":"code","source":"sns.countplot(x= df.target)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:29:20.10925Z","iopub.execute_input":"2021-06-11T02:29:20.10961Z","iopub.status.idle":"2021-06-11T02:29:20.518901Z","shell.execute_reply.started":"2021-06-11T02:29:20.109581Z","shell.execute_reply":"2021-06-11T02:29:20.517917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target column is imbalanced, so I will use StratifiedKFold for cross validation.","metadata":{}},{"cell_type":"markdown","source":"Since it is a baseline/starter model, I am not doing EDA and directly moving onto model building part.","metadata":{}},{"cell_type":"markdown","source":"## 4. Create folds for Cross Validation","metadata":{}},{"cell_type":"markdown","source":"Creating folds for the train dataset, so that we can train the model for the n folds, to avoid overfitting.","metadata":{}},{"cell_type":"code","source":"df[\"kfold\"] = -1\ndf = df.sample(frac=1,random_state=42).reset_index(drop=True)\ny = df.target\nkf = StratifiedKFold(n_splits=5)\nfor f, (t_,v_) in enumerate(kf.split(X=df,y=y)):\n  df.loc[v_,\"kfold\"] = f","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:30:57.58191Z","iopub.execute_input":"2021-06-11T02:30:57.582288Z","iopub.status.idle":"2021-06-11T02:30:58.455084Z","shell.execute_reply.started":"2021-06-11T02:30:57.582259Z","shell.execute_reply":"2021-06-11T02:30:58.454136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Basline model","metadata":{}},{"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=42)\nlogloss = []\nlgbm_pred = 0\nfor f in range(5): # Looping around 5 folds\n    \n    #Splitting the data into train and validation set\n    train = df[df.kfold!= f].reset_index(drop=True) \n    valid = df[df.kfold== f].reset_index(drop=True)\n    \n    #Creating X_train and y_train\n    X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_train = train.target\n    X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_valid = valid.target\n    X_test = test.drop([\"id\"], axis=1)\n    \n    \n    #Fitting the model\n    lgbm.fit(X_train,y_train)\n    \n    #Predicting for valid and test datasets\n    valid_preds = lgbm.predict_proba(X_valid)\n    lgbm_pred += lgbm.predict_proba(X_test)/5\n    \n    #Calculating log loss\n    logloss.append(log_loss(y_valid,valid_preds))\n    \nprint(logloss)\nprint(sum(logloss)/len(logloss))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:31:10.756733Z","iopub.execute_input":"2021-06-11T02:31:10.757147Z","iopub.status.idle":"2021-06-11T02:32:37.60184Z","shell.execute_reply.started":"2021-06-11T02:31:10.757106Z","shell.execute_reply":"2021-06-11T02:32:37.600523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Optuna - Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"def optimize(trial):\n    param = {\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'objective': 'multiclass',\n        #'metric' : ''\n        \"random_state\" : 42}\n\n\n\n    model = LGBMClassifier(**param)\n    logloss = []\n    for f in range(5):\n        train = df[df.kfold!= f].reset_index(drop=True)\n        valid = df[df.kfold== f].reset_index(drop=True)\n\n        X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n        y_train = train[\"target\"]\n        X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n        y_valid = valid[\"target\"]\n\n        model.fit(X_train,y_train)\n        pred = model.predict_proba(X_valid)\n        fold_logloss = log_loss(y_valid, pred)\n        logloss.append(fold_logloss)\n    \n    return np.mean(logloss)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:33:12.408399Z","iopub.execute_input":"2021-06-11T02:33:12.408803Z","iopub.status.idle":"2021-06-11T02:33:12.420059Z","shell.execute_reply.started":"2021-06-11T02:33:12.408769Z","shell.execute_reply":"2021-06-11T02:33:12.41884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(optimize, n_trials=15)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-11T02:33:23.653215Z","iopub.execute_input":"2021-06-11T02:33:23.653578Z","iopub.status.idle":"2021-06-11T03:19:24.095666Z","shell.execute_reply.started":"2021-06-11T02:33:23.653546Z","shell.execute_reply":"2021-06-11T03:19:24.094564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best parameters are below.","metadata":{}},{"cell_type":"code","source":"print(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T03:19:24.097454Z","iopub.execute_input":"2021-06-11T03:19:24.097756Z","iopub.status.idle":"2021-06-11T03:19:24.103916Z","shell.execute_reply.started":"2021-06-11T03:19:24.097725Z","shell.execute_reply":"2021-06-11T03:19:24.102563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Tuned model","metadata":{}},{"cell_type":"markdown","source":"Retraining with the tuned parameters","metadata":{}},{"cell_type":"code","source":"param = {\n    'lambda_l1': 7.288238692320857, \n    'lambda_l2': 0.0011320378225972616, \n    'num_leaves': 23, \n    'feature_fraction': 0.8423047951534829, \n    'bagging_fraction': 0.8752188255110098, \n    'bagging_freq': 1, \n    'min_child_samples': 93,\n    'objective': 'multiclass',\n    'random_state' : 42\n}\nlgbm = LGBMClassifier(**param)\nlogloss = []\nlgbm_pred = 0\nfor f in range(5): # Looping around 5 folds\n    \n    #Splitting the data into train and validation set\n    train = df[df.kfold!= f].reset_index(drop=True) \n    valid = df[df.kfold== f].reset_index(drop=True)\n    \n    #Creating X_train and y_train\n    X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_train = train.target\n    X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_valid = valid.target\n    X_test = test.drop([\"id\"], axis=1)\n    \n    \n    #Fitting the model\n    lgbm.fit(X_train,y_train)\n    \n    #Predicting for valid and test datasets\n    valid_preds = lgbm.predict_proba(X_valid)\n    lgbm_pred += lgbm.predict_proba(X_test)/5\n    \n    #Calculating log loss\n    logloss.append(log_loss(y_valid,valid_preds))\n    \nprint(logloss)\nprint(sum(logloss)/len(logloss))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-11T03:22:31.993497Z","iopub.execute_input":"2021-06-11T03:22:31.993874Z","iopub.status.idle":"2021-06-11T03:24:05.683155Z","shell.execute_reply.started":"2021-06-11T03:22:31.993844Z","shell.execute_reply":"2021-06-11T03:24:05.682116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sum(logloss)/len(logloss))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T03:24:05.684856Z","iopub.execute_input":"2021-06-11T03:24:05.685313Z","iopub.status.idle":"2021-06-11T03:24:05.691784Z","shell.execute_reply.started":"2021-06-11T03:24:05.685269Z","shell.execute_reply":"2021-06-11T03:24:05.69066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Submission file","metadata":{}},{"cell_type":"code","source":"ss[\"Class_1\"] = lgbm_pred[:,0]\nss[\"Class_2\"] = lgbm_pred[:,1]\nss[\"Class_3\"] = lgbm_pred[:,2]\nss[\"Class_4\"] = lgbm_pred[:,3]\nss[\"Class_5\"] = lgbm_pred[:,4]\nss[\"Class_6\"] = lgbm_pred[:,5]\nss[\"Class_7\"] = lgbm_pred[:,6]\nss[\"Class_8\"] = lgbm_pred[:,7]\nss[\"Class_9\"] = lgbm_pred[:,8]\nss.to_csv(\"/kaggle/working/tuned_lgbm_sub.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T18:36:52.453986Z","iopub.execute_input":"2021-06-03T18:36:52.454315Z","iopub.status.idle":"2021-06-03T18:36:54.427493Z","shell.execute_reply.started":"2021-06-03T18:36:52.454287Z","shell.execute_reply":"2021-06-03T18:36:54.42654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you like the notebook kindly upvote it. It will motivate me to write more notebooks. :)","metadata":{}},{"cell_type":"markdown","source":"### Thank you!","metadata":{}}]}