{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Hi everyone, this is a very basic starter notebook for this competition with LightGBM.","metadata":{}},{"cell_type":"markdown","source":"## Approach","metadata":{}},{"cell_type":"markdown","source":"1. Import libraries\n2. Read the data\n3. Check for missing values and target distribution\n4. Create folds for Cross Validation\n5. Fit with base LGBMClassifier\n6. Create submission files","metadata":{}},{"cell_type":"markdown","source":"## 1. Import libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T03:27:51.424472Z","iopub.execute_input":"2021-06-01T03:27:51.424794Z","iopub.status.idle":"2021-06-01T03:27:51.432444Z","shell.execute_reply.started":"2021-06-01T03:27:51.424761Z","shell.execute_reply":"2021-06-01T03:27:51.43143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold # For creating folds\nfrom sklearn.metrics import log_loss # Evaluation metrics","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:31:25.111224Z","iopub.execute_input":"2021-06-01T03:31:25.111546Z","iopub.status.idle":"2021-06-01T03:31:25.117746Z","shell.execute_reply.started":"2021-06-01T03:31:25.111516Z","shell.execute_reply":"2021-06-01T03:31:25.116893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Reading the train, test and sample submission file","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/test.csv\")\nss = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:28:09.081429Z","iopub.execute_input":"2021-06-01T03:28:09.081746Z","iopub.status.idle":"2021-06-01T03:28:10.741861Z","shell.execute_reply.started":"2021-06-01T03:28:09.081713Z","shell.execute_reply":"2021-06-01T03:28:10.741089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Shape of train : {df.shape}\")\nprint(f\"Shape of test : {test.shape}\")\nprint(f\"Shape of sample submission : {ss.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:28:15.547108Z","iopub.execute_input":"2021-06-01T03:28:15.547424Z","iopub.status.idle":"2021-06-01T03:28:15.552475Z","shell.execute_reply.started":"2021-06-01T03:28:15.547396Z","shell.execute_reply":"2021-06-01T03:28:15.551601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Basic data check","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:28:22.006747Z","iopub.execute_input":"2021-06-01T03:28:22.007089Z","iopub.status.idle":"2021-06-01T03:28:22.03631Z","shell.execute_reply.started":"2021-06-01T03:28:22.00706Z","shell.execute_reply":"2021-06-01T03:28:22.035336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:28:28.605143Z","iopub.execute_input":"2021-06-01T03:28:28.60547Z","iopub.status.idle":"2021-06-01T03:28:28.674812Z","shell.execute_reply.started":"2021-06-01T03:28:28.605438Z","shell.execute_reply":"2021-06-01T03:28:28.67393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:28:54.635014Z","iopub.execute_input":"2021-06-01T03:28:54.635323Z","iopub.status.idle":"2021-06-01T03:28:54.66326Z","shell.execute_reply.started":"2021-06-01T03:28:54.635294Z","shell.execute_reply":"2021-06-01T03:28:54.662356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing values in the both train and test datasets and all are integers, so the categories might be encoded already.","metadata":{}},{"cell_type":"markdown","source":"## 4. Checking target distribution","metadata":{}},{"cell_type":"code","source":"sns.countplot(x= df.target)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:29:20.439582Z","iopub.execute_input":"2021-06-01T03:29:20.439898Z","iopub.status.idle":"2021-06-01T03:29:20.759947Z","shell.execute_reply.started":"2021-06-01T03:29:20.439855Z","shell.execute_reply":"2021-06-01T03:29:20.759238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target column is imbalanced, so I will use StratifiedKFold for cross validation.","metadata":{}},{"cell_type":"markdown","source":"Since it is a baseline/starter model, I am not doing EDA and directly moving onto model building part.","metadata":{}},{"cell_type":"markdown","source":"## 5. Basline model","metadata":{}},{"cell_type":"markdown","source":"Creating folds for the train dataset, so that we can train the model for the n folds, to avoid overfitting.","metadata":{}},{"cell_type":"code","source":"df[\"kfold\"] = -1\ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target\nkf = StratifiedKFold(n_splits=5)\nfor f, (t_,v_) in enumerate(kf.split(X=df,y=y)):\n  df.loc[v_,\"kfold\"] = f","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:30:12.019224Z","iopub.execute_input":"2021-06-01T03:30:12.01954Z","iopub.status.idle":"2021-06-01T03:30:12.722001Z","shell.execute_reply.started":"2021-06-01T03:30:12.01951Z","shell.execute_reply":"2021-06-01T03:30:12.721236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=42)\nlogloss = []\nlgbm_pred = 0\nfor f in range(5): # Looping around 5 folds\n    \n    #Splitting the data into train and validation set\n    train = df[df.kfold!= f].reset_index(drop=True) \n    valid = df[df.kfold== f].reset_index(drop=True)\n    \n    #Creating X_train and y_train\n    X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_train = train.target\n    X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_valid = valid.target\n    X_test = test.drop([\"id\"], axis=1)\n    \n    \n    #Fitting the model\n    lgbm.fit(X_train,y_train)\n    \n    #Predicting for valid and test datasets\n    valid_preds = lgbm.predict_proba(X_valid)\n    lgbm_pred += lgbm.predict_proba(X_test)/5\n    \n    #Calculating log loss\n    logloss.append(log_loss(y_valid,valid_preds))\n    \nprint(logloss)\nprint(sum(logloss)/len(logloss))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:31:31.194994Z","iopub.execute_input":"2021-06-01T03:31:31.195308Z","iopub.status.idle":"2021-06-01T03:33:37.06146Z","shell.execute_reply.started":"2021-06-01T03:31:31.195278Z","shell.execute_reply":"2021-06-01T03:33:37.059671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The average log loss is 1.7560632816516921**","metadata":{}},{"cell_type":"markdown","source":"## 6. Creating submission file","metadata":{}},{"cell_type":"code","source":"ss[\"Class_1\"] = lgbm_pred[:,0]\nss[\"Class_2\"] = lgbm_pred[:,1]\nss[\"Class_3\"] = lgbm_pred[:,2]\nss[\"Class_4\"] = lgbm_pred[:,3]\nss[\"Class_5\"] = lgbm_pred[:,4]\nss[\"Class_6\"] = lgbm_pred[:,5]\nss[\"Class_7\"] = lgbm_pred[:,6]\nss[\"Class_8\"] = lgbm_pred[:,7]\nss[\"Class_9\"] = lgbm_pred[:,8]\nss.to_csv(\"/kaggle/working/sub.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T03:36:20.913316Z","iopub.execute_input":"2021-06-01T03:36:20.913628Z","iopub.status.idle":"2021-06-01T03:36:23.369049Z","shell.execute_reply.started":"2021-06-01T03:36:20.913598Z","shell.execute_reply":"2021-06-01T03:36:23.368237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you like the notebook kindly upvote it. It will motivate me to write more notebooks. :)","metadata":{}},{"cell_type":"markdown","source":"### Thank you! ","metadata":{}}]}