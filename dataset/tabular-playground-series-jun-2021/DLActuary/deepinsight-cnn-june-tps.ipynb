{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook was inspired by [this](https://towardsdatascience.com/turning-non-image-data-into-images-for-classification-is-surprisingly-effective-70ce82cfee27) article by [Andre Ye](https://www.linkedin.com/in/andre-ye).\n\n\nModel training/code comes from [here](https://github.com/alok-ai-lab/DeepInsight/blob/master/examples/pytorch_squeezenet.ipynb). Thanks to [Keith A. Boroevich](https://github.com/kaboroevich)/kaboroevich for the starter code.\n\n\nThis is my first dive into CNNs, so this model is pretty sketchy and it model seems to be very poor. In fact, if I pick even samples of each class all probabilities are equal to 1/number of classes. I think I've done something wrong here, or this is just a inappropriate use of this approach.","metadata":{}},{"cell_type":"code","source":"#pytorch utils\nimport torch\nimport torchvision.transforms as transforms\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\n\n#check gpu\nprint(torch.cuda.is_available())\ndevice = torch.device(device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n\n#deep insight utils\n!pip install git+git://github.com/alok-ai-lab/DeepInsight.git#egg=DeepInsight\nfrom pyDeepInsight import ImageTransformer, LogScaler\n\n#sklearn utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import log_loss\n\n#essential utils\nimport pandas as pd\nimport numpy as np\n\n#read in data and get sample since it is too big to handle otherwise\ntraining = pd.read_csv(\"../input/tabular-playground-series-jun-2021/train.csv\")\ntraining = training.sample(frac = .25)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T02:11:54.217285Z","iopub.execute_input":"2021-06-24T02:11:54.217713Z","iopub.status.idle":"2021-06-24T02:12:02.757278Z","shell.execute_reply.started":"2021-06-24T02:11:54.217674Z","shell.execute_reply":"2021-06-24T02:12:02.75637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load untrained model\nfrom torchvision.models import squeezenet1_1\nnet = squeezenet1_1(pretrained=False).float()\nnet.classifier[1] = nn.Conv2d(512, 9, kernel_size=(1,1), stride=(1,1)).to(device)\n\n#create tnse\ntsne = TSNE(\n    n_components = 2,\n    random_state = 1,\n    n_jobs=-1)\n\n#create transformer\nit = ImageTransformer(\n    feature_extractor=tsne, \n    pixels = 18)\n\n#create scaler\nls = LogScaler()\nls.fit(np.ascontiguousarray(training.iloc[:,1:76]))\n\n#create tensor transformer\npreprocess = transforms.Compose([transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T02:54:30.190345Z","iopub.execute_input":"2021-06-24T02:54:30.190706Z","iopub.status.idle":"2021-06-24T02:54:30.314543Z","shell.execute_reply.started":"2021-06-24T02:54:30.190675Z","shell.execute_reply":"2021-06-24T02:54:30.313572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CNNPIPE(model, data, batch = 32, epochs = 20, learning = .01, momentum = 0.9, reg = 0):    \n    \n    #make sure model is on device\n    net = model.to(device)\n    \n    results = {}\n    \n    #pull out features\n    X = data.iloc[:, 1:76]\n    X = np.ascontiguousarray(X)\n\n    #create label encoder\n    le = LabelEncoder()\n\n    #pull out responses\n    y = data.iloc[:, 76]\n    y = le.fit_transform(y)\n\n    #split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1, stratify = y)\n    \n    #transform\n    ls = LogScaler()\n    X_train = ls.fit_transform(X_train)\n    X_test = ls.transform(X_test)\n\n    #create matricies\n    X_train = it.fit_transform(X_train)\n    X_test = it.transform(X_test)\n    \n    #create tensors\n    X_train = torch.stack([preprocess(img) for img in X_train]).to(device)\n    y_train = torch.from_numpy(le.fit_transform(y_train)).to(device)\n    X_test = torch.stack([preprocess(np.float32(img)) for img in X_test]).to(device, dtype = torch.float)\n    \n    #load data\n    trainset = TensorDataset(X_train, y_train)\n    trainloader = DataLoader(trainset, batch_size = batch, shuffle = True)\n    \n    #set loss function and add to device\n    criterion = nn.CrossEntropyLoss()\n    criterion.to(device)\n    optimizer = optim.SGD(net.parameters(), lr = learning, momentum = momentum, weight_decay = reg)\n\n    #run epochs\n    for epoch in range(epochs):\n\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n       \n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device)\n        \n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            #update loss\n            running_loss += loss.item()\n        \n        #average loss\n        train_score = round(running_loss / len(X_train) * batch, 4)\n        \n        #get test predictions\n        test_outputs = net(X_test)\n        preds = torch.nn.functional.softmax(test_outputs, 1)\n        preds = preds.to('cpu')\n        preds = pd.DataFrame(preds.detach().numpy())\n        \n        #score predictions\n        test_score = round(log_loss(y_test, preds), 4)\n        \n        #results to dict\n        results[epoch] = {'train_score' : train_score, 'test_score': test_score}\n        print(\"Epoch: \", epoch, \" Train score: \", train_score, \" Test score: \", test_score)\n    \n    return results","metadata":{"execution":{"iopub.status.busy":"2021-06-24T02:12:02.795598Z","iopub.execute_input":"2021-06-24T02:12:02.795935Z","iopub.status.idle":"2021-06-24T02:12:02.810513Z","shell.execute_reply.started":"2021-06-24T02:12:02.795899Z","shell.execute_reply":"2021-06-24T02:12:02.809782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run\nresults = CNNPIPE(net, training, batch = 32, epochs = 15, learning = .1, reg = .01)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T02:12:02.811985Z","iopub.execute_input":"2021-06-24T02:12:02.812524Z","iopub.status.idle":"2021-06-24T02:20:08.873015Z","shell.execute_reply.started":"2021-06-24T02:12:02.812485Z","shell.execute_reply":"2021-06-24T02:20:08.871528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The part below makes the test predictions.","metadata":{}},{"cell_type":"code","source":"#load data\nraw_test = pd.read_csv(\"../input/tabular-playground-series-jun-2021/test.csv\")\nraw_train = pd.read_csv(\"../input/tabular-playground-series-jun-2021/train.csv\")\n\n#grab ids\nids = raw_test.iloc[:,0]\n\n#grab features\ntraining = raw_train.iloc[:,1:76]\ntraining = np.ascontiguousarray(training)\ntest = raw_test.iloc[:,1:76]\ntest = np.ascontiguousarray(test)\n\n#scale\nls = LogScaler()\nls.fit(training)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:10:40.653062Z","iopub.execute_input":"2021-06-24T03:10:40.653381Z","iopub.status.idle":"2021-06-24T03:10:41.969619Z","shell.execute_reply.started":"2021-06-24T03:10:40.653353Z","shell.execute_reply":"2021-06-24T03:10:41.968763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create tnse\ntsne = TSNE(n_components = 2, random_state = 1, n_jobs=-1)\n\n#create transformer\nit = ImageTransformer(feature_extractor = tsne, pixels = 75)\n\n#fit transformer images\ntrain = it.fit(training)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:10:44.163423Z","iopub.execute_input":"2021-06-24T03:10:44.16374Z","iopub.status.idle":"2021-06-24T03:10:48.273096Z","shell.execute_reply.started":"2021-06-24T03:10:44.16371Z","shell.execute_reply":"2021-06-24T03:10:48.27223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create prep\npreprocess = transforms.Compose([transforms.ToTensor()])\n\ndef predict(obs):\n    \n    #preprocess\n    obs = obs.reshape(1, -1)\n    obs = ls.transform(obs)\n    obs = it.transform(obs)\n    obs = torch.stack([preprocess(np.float32(img)) for img in obs]).to(device, dtype = torch.float)\n    \n    #infer\n    outs = net(obs)\n    outs = torch.nn.functional.softmax(outs, 1)\n    outs = outs.cpu()\n    outs = outs.detach().numpy()\n    outs = outs.tolist()\n    outs = [item for sublist in outs for item in sublist]\n    return outs\n\n#save inference\nrep = []\nfor row in test:\n    rep.append(predict(row))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:10:51.873462Z","iopub.execute_input":"2021-06-24T03:10:51.873778Z","iopub.status.idle":"2021-06-24T03:10:51.90985Z","shell.execute_reply.started":"2021-06-24T03:10:51.873748Z","shell.execute_reply":"2021-06-24T03:10:51.909059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make submission\nids = pd.DataFrame(ids, columns = ['id'])\n\nrep = pd.DataFrame(rep)\n\nsubmission = ids.merge(rep, left_index = True, right_index = True)\n\nsubmission.columns = [\"id\", \"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\",\n                  \"Class_5\", \"Class_6\", \"Class_7\", \"Class_8\", \"Class_9\"]\n\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:11:03.16948Z","iopub.execute_input":"2021-06-24T03:11:03.169798Z","iopub.status.idle":"2021-06-24T03:11:03.315969Z","shell.execute_reply.started":"2021-06-24T03:11:03.169768Z","shell.execute_reply":"2021-06-24T03:11:03.315177Z"},"trusted":true},"execution_count":null,"outputs":[]}]}