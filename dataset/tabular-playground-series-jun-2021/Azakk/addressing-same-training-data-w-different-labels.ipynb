{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import the Pandas library\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-04T21:55:33.742196Z","iopub.execute_input":"2021-06-04T21:55:33.742678Z","iopub.status.idle":"2021-06-04T21:55:33.75023Z","shell.execute_reply.started":"2021-06-04T21:55:33.742598Z","shell.execute_reply":"2021-06-04T21:55:33.749624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the train data\ntrain_df = pd.read_csv(\"../input/tabular-playground-series-jun-2021/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T21:59:43.276092Z","iopub.execute_input":"2021-06-04T21:59:43.27669Z","iopub.status.idle":"2021-06-04T21:59:44.661091Z","shell.execute_reply.started":"2021-06-04T21:59:43.276654Z","shell.execute_reply":"2021-06-04T21:59:44.6603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check size of original dataset\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-04T22:00:15.411234Z","iopub.execute_input":"2021-06-04T22:00:15.411549Z","iopub.status.idle":"2021-06-04T22:00:15.418661Z","shell.execute_reply.started":"2021-06-04T22:00:15.411522Z","shell.execute_reply":"2021-06-04T22:00:15.41778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are a lot of data rows with exactly the data in the features, but are provided with different target labels.\n# A good example are lines with id = 64196, 78662, 87596, 104839, 111418, 118758, 134796\n# Observe how all feature columns are zero with exception of feature_69 = 1, but target varies from Class_2, Class_3 and Class_6\ntrain_df[train_df['id'].isin([64196, 78662, 87596, 104839, 111418, 118758, 134796])]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T22:04:36.890204Z","iopub.execute_input":"2021-06-04T22:04:36.890706Z","iopub.status.idle":"2021-06-04T22:04:36.911341Z","shell.execute_reply.started":"2021-06-04T22:04:36.890673Z","shell.execute_reply":"2021-06-04T22:04:36.91047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, we will remove duplicate rows when all features are the same and the target is the same.\n# We will keep only 1 row of such records.\nignore_columns = train_df.columns.drop('id')\ntrain_df = train_df.drop_duplicates(subset=ignore_columns,keep='first')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T22:06:07.073615Z","iopub.execute_input":"2021-06-04T22:06:07.07396Z","iopub.status.idle":"2021-06-04T22:06:07.467209Z","shell.execute_reply.started":"2021-06-04T22:06:07.073924Z","shell.execute_reply":"2021-06-04T22:06:07.46655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now check the size of our train dataframe.\n# We can find the number of rows reduced from 200000 to 199894 count\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-04T22:06:33.275073Z","iopub.execute_input":"2021-06-04T22:06:33.275588Z","iopub.status.idle":"2021-06-04T22:06:33.280401Z","shell.execute_reply.started":"2021-06-04T22:06:33.275555Z","shell.execute_reply":"2021-06-04T22:06:33.279567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Next, we will remove duplicate rows when all features are the same but the target varies.\n# We will not keep any of such records.\nignore_columns = train_df.columns.drop(['id', 'target'])\ntrain_df = train_df.drop_duplicates(subset=ignore_columns,keep=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T22:08:37.711448Z","iopub.execute_input":"2021-06-04T22:08:37.711977Z","iopub.status.idle":"2021-06-04T22:08:38.080246Z","shell.execute_reply.started":"2021-06-04T22:08:37.711942Z","shell.execute_reply":"2021-06-04T22:08:38.079578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now check the size of our train dataframe again\n# We can find the number of rows reduced from 199894 to 199698 count\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-04T22:08:50.786233Z","iopub.execute_input":"2021-06-04T22:08:50.786756Z","iopub.status.idle":"2021-06-04T22:08:50.790587Z","shell.execute_reply.started":"2021-06-04T22:08:50.786722Z","shell.execute_reply":"2021-06-04T22:08:50.790012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Congrats.  We now have a dataset with rows of unique feature data all mapping to 1 target label for better learning experience by any machine learning techniques. ","metadata":{},"execution_count":null,"outputs":[]}]}