{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport datetime\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nimport optuna\nfrom optuna.trial import TrialState","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-06-02T17:46:49.879107Z","iopub.execute_input":"2021-06-02T17:46:49.879673Z","iopub.status.idle":"2021-06-02T17:46:52.43338Z","shell.execute_reply.started":"2021-06-02T17:46:49.879534Z","shell.execute_reply":"2021-06-02T17:46:52.432515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/test.csv\")\npd.set_option(\"display.max_columns\", 77)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:46:52.434691Z","iopub.execute_input":"2021-06-02T17:46:52.43502Z","iopub.status.idle":"2021-06-02T17:46:53.994516Z","shell.execute_reply.started":"2021-06-02T17:46:52.434986Z","shell.execute_reply":"2021-06-02T17:46:53.993702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-02T17:46:53.997172Z","iopub.execute_input":"2021-06-02T17:46:53.997739Z","iopub.status.idle":"2021-06-02T17:46:54.042386Z","shell.execute_reply.started":"2021-06-02T17:46:53.9977Z","shell.execute_reply":"2021-06-02T17:46:54.041497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:46:54.044023Z","iopub.execute_input":"2021-06-02T17:46:54.044373Z","iopub.status.idle":"2021-06-02T17:46:54.090714Z","shell.execute_reply.started":"2021-06-02T17:46:54.044329Z","shell.execute_reply":"2021-06-02T17:46:54.089808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_df['target'] = encoder.fit_transform(train_df['target'])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:46:54.092189Z","iopub.execute_input":"2021-06-02T17:46:54.092748Z","iopub.status.idle":"2021-06-02T17:46:54.160698Z","shell.execute_reply.started":"2021-06-02T17:46:54.09271Z","shell.execute_reply":"2021-06-02T17:46:54.159865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = list(train_df.columns)[1:-1]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:46:54.16212Z","iopub.execute_input":"2021-06-02T17:46:54.162476Z","iopub.status.idle":"2021-06-02T17:46:54.170567Z","shell.execute_reply.started":"2021-06-02T17:46:54.16244Z","shell.execute_reply":"2021-06-02T17:46:54.169764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\ntrain_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\ntest_df[feature_cols] = scaler.transform(test_df[feature_cols])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:46:54.173453Z","iopub.execute_input":"2021-06-02T17:46:54.1737Z","iopub.status.idle":"2021-06-02T17:47:01.425312Z","shell.execute_reply.started":"2021-06-02T17:46:54.173677Z","shell.execute_reply":"2021-06-02T17:47:01.424446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:01.427956Z","iopub.execute_input":"2021-06-02T17:47:01.428303Z","iopub.status.idle":"2021-06-02T17:47:01.48447Z","shell.execute_reply.started":"2021-06-02T17:47:01.428268Z","shell.execute_reply":"2021-06-02T17:47:01.48358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.drop(['target','id'],axis=1)\ny = train_df['target']","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:01.486383Z","iopub.execute_input":"2021-06-02T17:47:01.486718Z","iopub.status.idle":"2021-06-02T17:47:01.598528Z","shell.execute_reply.started":"2021-06-02T17:47:01.486684Z","shell.execute_reply":"2021-06-02T17:47:01.597705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:01.599787Z","iopub.execute_input":"2021-06-02T17:47:01.600268Z","iopub.status.idle":"2021-06-02T17:47:01.655645Z","shell.execute_reply.started":"2021-06-02T17:47:01.600229Z","shell.execute_reply":"2021-06-02T17:47:01.654757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:01.656888Z","iopub.execute_input":"2021-06-02T17:47:01.657223Z","iopub.status.idle":"2021-06-02T17:47:01.662864Z","shell.execute_reply.started":"2021-06-02T17:47:01.65719Z","shell.execute_reply":"2021-06-02T17:47:01.661923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n\nfor train_index, val_index in sss.split(X, y):    \n    print(\"TRAIN:\\t\", train_index, \"Size:\\t\", len(train_index))\n    print(\"VAL:\\t\", val_index, \"Size:\\t\", len(val_index))\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:01.664159Z","iopub.execute_input":"2021-06-02T17:47:01.664822Z","iopub.status.idle":"2021-06-02T17:47:01.910413Z","shell.execute_reply.started":"2021-06-02T17:47:01.664782Z","shell.execute_reply":"2021-06-02T17:47:01.909518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()/y.value_counts()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-02T17:47:01.91172Z","iopub.execute_input":"2021-06-02T17:47:01.91209Z","iopub.status.idle":"2021-06-02T17:47:01.937352Z","shell.execute_reply.started":"2021-06-02T17:47:01.912052Z","shell.execute_reply":"2021-06-02T17:47:01.936526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val.value_counts()/y.value_counts()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-02T17:47:01.938612Z","iopub.execute_input":"2021-06-02T17:47:01.939229Z","iopub.status.idle":"2021-06-02T17:47:01.95134Z","shell.execute_reply.started":"2021-06-02T17:47:01.939191Z","shell.execute_reply":"2021-06-02T17:47:01.950369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optuna","metadata":{}},{"cell_type":"code","source":"CLASSES = 9\nNUM_FEATURES = 75\nDEVICE = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n\nBATCHSIZE = 1000\nEPOCHS = 10\nN_TRAIN_EXAMPLES = BATCHSIZE * 14\nN_VALID_EXAMPLES = BATCHSIZE * 6\n\ncriterion = nn.CrossEntropyLoss()\n\ndef define_model(trial):\n    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n    layers = []\n\n    in_features = NUM_FEATURES\n    for i in range(n_layers):\n        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 32, 1024)\n        layers.append(nn.Linear(in_features, out_features))\n        layers.append(nn.ReLU(inplace=True))\n        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.1, 0.5)\n        layers.append(nn.Dropout(p))\n        layers.append(nn.BatchNorm1d(out_features))\n\n        in_features = out_features\n        \n    layers.append(nn.Linear(in_features, CLASSES))\n\n    return nn.Sequential(*layers)\n\ndef get_data(X_train, y_train, X_val, y_val):\n    train = TensorDataset(torch.Tensor(np.array(X_train)), torch.Tensor(np.array(y_train)))\n    train_loader = DataLoader(train, batch_size = 10000, shuffle = True)\n\n    val = TensorDataset(torch.Tensor(np.array(X_val)), torch.Tensor(np.array(y_val)))\n    val_loader = DataLoader(val, batch_size = 10000, shuffle = True)\n\n    return train_loader, val_loader\n\ndef objective(trial):\n    model = define_model(trial).to(DEVICE)\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n    \n    train_loader, valid_loader = get_data(X_train, y_train, X_val, y_val)\n    \n    for epoch in range(EPOCHS):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n\n            optimizer.zero_grad()\n            output = model(data)\n            \n            loss = criterion(output, target.long())\n            loss.backward()\n            optimizer.step()\n\n        # Validation of the model.\n        model.eval()\n        val_loss = []\n        with torch.no_grad():\n            for batch_idx, (data, target) in enumerate(valid_loader):\n                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n                output = model(data)\n                \n                loss = criterion(output, target.long())\n                val_loss.append(loss.item())\n        \n        avg_val_loss = np.mean(val_loss)\n\n        trial.report(avg_val_loss, epoch)\n\n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n    \n    return avg_val_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:01.95261Z","iopub.execute_input":"2021-06-02T17:47:01.953128Z","iopub.status.idle":"2021-06-02T17:47:02.02765Z","shell.execute_reply.started":"2021-06-02T17:47:01.953089Z","shell.execute_reply":"2021-06-02T17:47:02.026845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:02.028961Z","iopub.execute_input":"2021-06-02T17:47:02.029304Z","iopub.status.idle":"2021-06-02T17:47:02.044123Z","shell.execute_reply.started":"2021-06-02T17:47:02.02926Z","shell.execute_reply":"2021-06-02T17:47:02.043355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50, timeout=600)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:47:02.047143Z","iopub.execute_input":"2021-06-02T17:47:02.047457Z","iopub.status.idle":"2021-06-02T17:57:29.075072Z","shell.execute_reply.started":"2021-06-02T17:47:02.047432Z","shell.execute_reply":"2021-06-02T17:57:29.074263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\ncomplete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n\nprint(\"Study statistics: \")\nprint(\"  Number of finished trials: \", len(study.trials))\nprint(\"  Number of pruned trials: \", len(pruned_trials))\nprint(\"  Number of complete trials: \", len(complete_trials))\n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Value: \", trial.value)\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:57:29.07634Z","iopub.execute_input":"2021-06-02T17:57:29.076666Z","iopub.status.idle":"2021-06-02T17:57:29.093236Z","shell.execute_reply.started":"2021-06-02T17:57:29.076631Z","shell.execute_reply":"2021-06-02T17:57:29.092443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_intermediate_values(study).show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:57:29.095823Z","iopub.execute_input":"2021-06-02T17:57:29.096186Z","iopub.status.idle":"2021-06-02T17:57:29.244752Z","shell.execute_reply.started":"2021-06-02T17:57:29.096145Z","shell.execute_reply":"2021-06-02T17:57:29.24395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training with the best parameters","metadata":{}},{"cell_type":"markdown","source":"### Stratified Split","metadata":{}},{"cell_type":"code","source":"batch_size = 1000\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n\nfor train_index, val_index in sss.split(X, y):    \n    print(\"TRAIN:\\t\", train_index, \"Size:\\t\", len(train_index))\n    print(\"VAL:\\t\", val_index, \"Size:\\t\", len(val_index))\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n\ntrain = TensorDataset(torch.Tensor(np.array(X_train)), torch.Tensor(np.array(y_train)))\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = True)\n\nval = TensorDataset(torch.Tensor(np.array(X_val)), torch.Tensor(np.array(y_val)))\nval_loader = DataLoader(val, batch_size = batch_size, shuffle = True)\n\nphases = [\"train\", \"val\"]\nloaders = {\"train\": train_loader, \"val\": val_loader}","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:57:29.246048Z","iopub.execute_input":"2021-06-02T17:57:29.246387Z","iopub.status.idle":"2021-06-02T17:57:29.563395Z","shell.execute_reply.started":"2021-06-02T17:57:29.246339Z","shell.execute_reply":"2021-06-02T17:57:29.562405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()/y.value_counts()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-02T17:57:29.564724Z","iopub.execute_input":"2021-06-02T17:57:29.565084Z","iopub.status.idle":"2021-06-02T17:57:29.576747Z","shell.execute_reply.started":"2021-06-02T17:57:29.565048Z","shell.execute_reply":"2021-06-02T17:57:29.575676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val.value_counts()/y.value_counts()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-02T17:57:29.578086Z","iopub.execute_input":"2021-06-02T17:57:29.578465Z","iopub.status.idle":"2021-06-02T17:57:29.590862Z","shell.execute_reply.started":"2021-06-02T17:57:29.578427Z","shell.execute_reply":"2021-06-02T17:57:29.590059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class classification_model(nn.Module):\n    def __init__(self, n_in, n_out, layers, p=None):\n        super(classification_model, self).__init__()\n\n        all_layers = []\n        self.n_in = n_in\n        self.n_out = n_out\n\n        for i in range(len(layers)):\n            all_layers.append(nn.Linear(self.n_in, layers[i]))\n            all_layers.append(nn.ReLU(inplace=True))\n            if p:\n                all_layers.append(nn.Dropout(p[i]))\n            all_layers.append(nn.BatchNorm1d(layers[i]))\n            self.n_in = layers[i]\n\n        all_layers.append(nn.Linear(layers[-1], self.n_out))\n\n        self.layers = nn.Sequential(*all_layers)\n\n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\n    net_name = \"classification_model\"","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:57:29.594316Z","iopub.execute_input":"2021-06-02T17:57:29.594558Z","iopub.status.idle":"2021-06-02T17:57:29.60214Z","shell.execute_reply.started":"2021-06-02T17:57:29.594534Z","shell.execute_reply":"2021-06-02T17:57:29.601206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nBest trial:\n  Value:  1.7740078568458557\n  Params: \n    n_layers: 2\n    n_units_l0: 582\n    dropout_l0: 0.32774551169492927\n    n_units_l1: 73\n    dropout_l1: 0.20755288576753822\n    optimizer: RMSprop\n    lr: 0.0009641167645278553\n\"\"\"\n\nlayers_ = []\ndropout_ = []\nl_rate = trial.params[\"lr\"]\n\nfor i in range(trial.params[\"n_layers\"]):\n    layers_.append(trial.params[f\"n_units_l{i}\"])\n    dropout_.append(trial.params[f\"dropout_l{i}\"])\n\ndevice = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n#model = classification_model(75, 9, [1007, 552, 607, 564, 595], p=[0.4458008129590088, 0.41239986533350254, 0.4446225146055265, 0.42198656364503173, 0.10940623981859748])\nmodel = classification_model(75, 9, layers_, p=dropout_)\nmodel.to(device)\n\n#l_rate = 0.0009624002880303564\n\ncriterion = nn.CrossEntropyLoss()\nif trial.params[\"optimizer\"] == \"RMSprop\":\n    optimizer = optim.RMSprop(model.parameters(), lr=l_rate)\nelif trial.params[\"optimizer\"] == \"Adam\":\n    optimizer = optim.Adam(model.parameters(), lr=l_rate)\nelif trial.params[\"optimizer\"] == \"SGD\":\n    optimizer = optim.SGD(model.parameters(), lr=l_rate)\n\nprint(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:57:29.604249Z","iopub.execute_input":"2021-06-02T17:57:29.604817Z","iopub.status.idle":"2021-06-02T17:57:29.620507Z","shell.execute_reply.started":"2021-06-02T17:57:29.604749Z","shell.execute_reply":"2021-06-02T17:57:29.619159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_train = []\nloss_valid = []\nbest_validation_loss = 1000\nbest_epoch = 1\ncorrect = 0\ntotal = 0\n\nn_epochs = 50\n\nnow = datetime.datetime.now()\nweights_path = \"./output/{:%Y%m%dT%H%M}\".format(now)\nos.makedirs(weights_path, exist_ok=True)\n\nbreak_st = False\n\nfor epoch in range(1, n_epochs + 1):\n    for phase in phases:\n        if phase == \"train\":\n            model.train()\n        elif phase == \"val\":\n            model.eval()\n            \n        for _, data in enumerate(loaders[phase], 0):\n            features, y_true = data[0], data[1]\n            features = features.to(device, dtype=torch.float)\n            y_true = y_true.to(device, dtype=torch.float)\n\n            optimizer.zero_grad()\n            \n            with torch.set_grad_enabled(phase == \"train\"):\n                y_pred = model(features)\n                \n                sm = nn.Softmax(dim=1)\n                pred_percentage = sm(y_pred)\n                \n                if break_st:\n                    break\n                    \n                y_true = y_true.long()\n                \n                _, preds = torch.max(pred_percentage, 1)\n                total += y_true.size(0)\n                correct += (preds == y_true).sum().item()\n                    \n                loss = criterion(y_pred, y_true)\n                \n                if phase == \"val\":\n                    loss_valid.append(loss.item())\n\n                if phase == \"train\":\n                    loss_train.append(loss.item())\n                    loss.backward()\n                        \n                    optimizer.step()\n        \n        if break_st:\n            break\n        \n        if phase == \"train\":\n            mean_train_loss = np.mean(loss_train)\n            acc_train = 100 * correct / total\n            loss_train = []\n            correct = 0\n            total = 0\n            \n        if phase == \"val\":\n            validation_loss = np.mean(loss_valid)\n            acc_valid = 100 * correct / total\n            loss_valid = []\n            correct = 0\n            total = 0\n    \n    if break_st:\n        break\n        \n    if validation_loss < best_validation_loss:\n        print(\"saving weights...\")\n        best_epoch = epoch\n        best_validation_loss = validation_loss\n        torch.save(model.state_dict(),\n            os.path.join(weights_path, \"model.pt\"),\n            )\n        \n    print(f\"Epoch={epoch}/{n_epochs}\\tloss={mean_train_loss:.4f}\\tval_loss={validation_loss:.4f}\\tacc={acc_train:.4f}\\tval_acc={acc_valid:.4f}\")\n    ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-02T18:02:36.109911Z","iopub.execute_input":"2021-06-02T18:02:36.110219Z","iopub.status.idle":"2021-06-02T18:04:34.817424Z","shell.execute_reply.started":"2021-06-02T18:02:36.110191Z","shell.execute_reply":"2021-06-02T18:04:34.816499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing","metadata":{}},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T18:05:36.438689Z","iopub.execute_input":"2021-06-02T18:05:36.439043Z","iopub.status.idle":"2021-06-02T18:05:36.494661Z","shell.execute_reply.started":"2021-06-02T18:05:36.439013Z","shell.execute_reply":"2021-06-02T18:05:36.493635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_df.drop(['id'],axis=1)\n\ntest = TensorDataset(torch.Tensor(np.array(X_test)))\ntest_loader = DataLoader(test, batch_size = 100000, shuffle = False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-02T18:05:36.859469Z","iopub.execute_input":"2021-06-02T18:05:36.859809Z","iopub.status.idle":"2021-06-02T18:05:36.92545Z","shell.execute_reply.started":"2021-06-02T18:05:36.859757Z","shell.execute_reply":"2021-06-02T18:05:36.924627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not weights_path:\n    print(\"Choose weights path\")\n    sys.exit()\n\ndevice = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n\nmodel_name = weights_path + \"/model.pt\"\nprint(model_name)\nstate_dict = torch.load(model_name, map_location=device)\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\nfor _, data in enumerate(test_loader, 0):\n    features = data[0]\n    print(features.size())\n    features = features.to(device, dtype=torch.float)\n    \n    with torch.set_grad_enabled(False):\n        y_pred = model(features)\n        \n        sm = nn.Softmax(dim=1)\n        pred_percentage = sm(y_pred)\n        \n        print(pred_percentage.size())\n\nprint(pred_percentage.detach().cpu().numpy())\nprint(\"DONE!\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T18:06:38.081787Z","iopub.execute_input":"2021-06-02T18:06:38.082101Z","iopub.status.idle":"2021-06-02T18:06:38.997175Z","shell.execute_reply.started":"2021-06-02T18:06:38.082072Z","shell.execute_reply":"2021-06-02T18:06:38.996163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\npred_array = pred_percentage.detach().cpu().numpy()\nsub.loc[:,\"Class_1\":\"Class_9\"] = pred_array\nsub = sub.set_index(\"id\")\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T18:07:03.572248Z","iopub.execute_input":"2021-06-02T18:07:03.572579Z","iopub.status.idle":"2021-06-02T18:07:03.956489Z","shell.execute_reply.started":"2021-06-02T18:07:03.572549Z","shell.execute_reply":"2021-06-02T18:07:03.9557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"./output/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T18:07:04.02952Z","iopub.execute_input":"2021-06-02T18:07:04.029814Z","iopub.status.idle":"2021-06-02T18:07:06.157604Z","shell.execute_reply.started":"2021-06-02T18:07:04.029786Z","shell.execute_reply":"2021-06-02T18:07:06.156785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}