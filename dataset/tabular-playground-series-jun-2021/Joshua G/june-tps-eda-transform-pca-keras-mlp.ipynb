{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''General Header for Python Operations'''\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\nimport warnings\nimport os\n\n# set graphics and print options\n%matplotlib inline\nplt.style.use('ggplot')\nplt.rcParams[\"figure.figsize\"] = (15,20)\npd.set_option('precision', 3)\nnp.set_printoptions(precision=3)\n\n# hide warnings\nwarnings.filterwarnings('ignore')\n\n# print input files for dataset\nfiles_dict = {}\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        files_dict[filename.split('.')[0]] = os.path.join(dirname, filename)\n        print(files_dict[filename.split('.')[0]])\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-15T13:38:26.757882Z","iopub.execute_input":"2021-06-15T13:38:26.758271Z","iopub.status.idle":"2021-06-15T13:38:26.775965Z","shell.execute_reply.started":"2021-06-15T13:38:26.758237Z","shell.execute_reply":"2021-06-15T13:38:26.774738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- train.csv - the training data, one product (id) per row, with the associated features (feature_*) and class label (target)\n\n- test.csv - the test data; you must predict the probability the id belongs to each class\n\n- sample_submission.csv - a sample submission file in the correct format","metadata":{}},{"cell_type":"code","source":"# Import Datasets\ndata_dict = {}\nfor file in files_dict.keys():\n    data_dict[file] = pd.read_csv(files_dict[file])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:52:12.14223Z","iopub.execute_input":"2021-06-15T13:52:12.142855Z","iopub.status.idle":"2021-06-15T13:52:13.667698Z","shell.execute_reply.started":"2021-06-15T13:52:12.142806Z","shell.execute_reply":"2021-06-15T13:52:13.66664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Examine Data\nfor df in data_dict.keys():\n    print(f'\\n {df}')\n    display(data_dict[df].head())\n    display(data_dict[df].info())","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:52:16.684128Z","iopub.execute_input":"2021-06-15T13:52:16.684566Z","iopub.status.idle":"2021-06-15T13:52:16.83381Z","shell.execute_reply.started":"2021-06-15T13:52:16.68453Z","shell.execute_reply":"2021-06-15T13:52:16.832581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check For NaN's\ntrain_df = data_dict['train']\nprint('Any Features with NaN?')\nany(train_df.isna().sum() > 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:28.489871Z","iopub.execute_input":"2021-06-15T13:38:28.490148Z","iopub.status.idle":"2021-06-15T13:38:28.536958Z","shell.execute_reply.started":"2021-06-15T13:38:28.490108Z","shell.execute_reply":"2021-06-15T13:38:28.535985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Check Balance of training set classes\ntrain_df.groupby('target').describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:28.538081Z","iopub.execute_input":"2021-06-15T13:38:28.538365Z","iopub.status.idle":"2021-06-15T13:38:30.478159Z","shell.execute_reply.started":"2021-06-15T13:38:28.538339Z","shell.execute_reply":"2021-06-15T13:38:30.477118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The classes are highly imbalanced. Classes 3 and 4 are extremely under represented. Models where initially built having undersampled the majorities to even out the data set but resulted in a data set that was too small. So, training should be done on the data as is.","metadata":{}},{"cell_type":"code","source":"# check feature cadinality\nfor col in train_df.columns:\n    print(f'{col}: {train_df[col].nunique()} unique values.')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:30.479731Z","iopub.execute_input":"2021-06-15T13:38:30.480128Z","iopub.status.idle":"2021-06-15T13:38:30.705355Z","shell.execute_reply.started":"2021-06-15T13:38:30.480085Z","shell.execute_reply":"2021-06-15T13:38:30.704294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at descriptive stats for each column\nfor col in train_df.columns[:-1]:\n    tmp = train_df[col].describe()\n    tmp = [tmp['mean'],tmp['50%'],tmp['std'],tmp['min'],tmp['max']]\n    print(f'{col}: Mean {tmp[0]:0.4f}, Med: {tmp[1]:0.4f}, Std: {tmp[2]:0.4f}, Range: ({tmp[3]}, {tmp[4]})')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:30.708195Z","iopub.execute_input":"2021-06-15T13:38:30.708629Z","iopub.status.idle":"2021-06-15T13:38:31.238895Z","shell.execute_reply.started":"2021-06-15T13:38:30.708584Z","shell.execute_reply":"2021-06-15T13:38:31.237769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All values are non-negative and appear to be badly skewed right","metadata":{}},{"cell_type":"code","source":"# check normality of features\nfor col in train_df.columns[:-1]:\n    print(f'{col}: SW test p-value = {stats.shapiro(train_df[col]).pvalue}')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:31.240678Z","iopub.execute_input":"2021-06-15T13:38:31.240961Z","iopub.status.idle":"2021-06-15T13:38:31.779402Z","shell.execute_reply.started":"2021-06-15T13:38:31.240933Z","shell.execute_reply":"2021-06-15T13:38:31.778334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"None of the features are normally distributed","metadata":{}},{"cell_type":"code","source":"# Examine Hist of all features\n_= train_df[train_df.columns[1:-1]].hist(figsize=(15,40), layout=(15,5), bins=40)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:31.78099Z","iopub.execute_input":"2021-06-15T13:38:31.781419Z","iopub.status.idle":"2021-06-15T13:38:45.511155Z","shell.execute_reply.started":"2021-06-15T13:38:31.781375Z","shell.execute_reply":"2021-06-15T13:38:45.510159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, the data is all skewed right, so we'll transform it via Box-Cox method.","metadata":{}},{"cell_type":"code","source":"# Examine Hist of all features with power transforms and iterate to find best by hand\n_= train_df[train_df.columns[1:-1]].pow(1/2.).hist(figsize=(15,40), layout=(15,5), bins=40)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:45.512233Z","iopub.execute_input":"2021-06-15T13:38:45.512498Z","iopub.status.idle":"2021-06-15T13:38:59.613004Z","shell.execute_reply.started":"2021-06-15T13:38:45.512472Z","shell.execute_reply":"2021-06-15T13:38:59.61201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"None of them look great, but the square root is as good as any other transform.\n\nLooking at correlation between features...","metadata":{}},{"cell_type":"code","source":"# Examine intra-feature correlations\nm = train_df[train_df.columns[1:-1]].corr()\nmsk = np.triu(np.ones_like(m, dtype=bool))\nplt.figure(figsize=(20,20))\n_=sns.heatmap(m, mask = msk, cmap = 'coolwarm', annot=False, cbar=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:38:59.614267Z","iopub.execute_input":"2021-06-15T13:38:59.614543Z","iopub.status.idle":"2021-06-15T13:39:05.496692Z","shell.execute_reply.started":"2021-06-15T13:38:59.614516Z","shell.execute_reply":"2021-06-15T13:39:05.49586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like there are some highly correlated features, so we'll look at performing pca.","metadata":{}},{"cell_type":"code","source":"# Examine singular values\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PowerTransformer\n\nsclr = PowerTransformer(method='yeo-johnson', standardize=True)\n\npca = PCA().fit(sclr.fit_transform(train_df[train_df.columns[1:-1]]))\nplt.figure(figsize=(10,7))\nplt.plot(np.arange(1,len(train_df.columns[1:-1])+1),np.cumsum(pca.explained_variance_ratio_))\nplt.hlines(0.95, *plt.xlim(), colors='k', linestyles='dotted', alpha = 0.5)\nplt.ylabel('Cumulative Explained Var Ratio')\nplt.xlabel('Number of Components')\n_= plt.title('PCA of Raw Features', fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:39:05.497955Z","iopub.execute_input":"2021-06-15T13:39:05.498446Z","iopub.status.idle":"2021-06-15T13:39:25.983657Z","shell.execute_reply.started":"2021-06-15T13:39:05.498414Z","shell.execute_reply":"2021-06-15T13:39:25.982915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are roughly 68 components required to explain 95% of the variance in the data, so we'll use PCA to eliminate the extra feature count.","metadata":{}},{"cell_type":"code","source":"# Find number of components to explain 95% of var\npca = PCA(n_components=0.95).fit(sclr.fit_transform(train_df[train_df.columns[1:-1]]))\nprint(f'95% Var Number of Components: {pca.n_components_}, Explained Variance: {np.sum(pca.explained_variance_ratio_)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:39:25.984828Z","iopub.execute_input":"2021-06-15T13:39:25.985092Z","iopub.status.idle":"2021-06-15T13:39:46.155548Z","shell.execute_reply.started":"2021-06-15T13:39:25.985066Z","shell.execute_reply":"2021-06-15T13:39:46.154487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data for ML\n\n### Cap data since it's all non-negative and skrewed right","metadata":{}},{"cell_type":"code","source":"# Cap data at 99th percentile\ntrain_df[train_df.columns[1:-1]].clip(upper = train_df[train_df.columns[1:-1]].quantile(0.99), axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:39:46.157275Z","iopub.execute_input":"2021-06-15T13:39:46.157995Z","iopub.status.idle":"2021-06-15T13:39:46.761347Z","shell.execute_reply.started":"2021-06-15T13:39:46.157935Z","shell.execute_reply":"2021-06-15T13:39:46.760448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode the Target","metadata":{}},{"cell_type":"code","source":"# Encode Target variable\nfrom sklearn.preprocessing import LabelEncoder\ntarget_le = LabelEncoder()\ntrain_df['target_enc'] = target_le.fit_transform(train_df['target'])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:39:46.762524Z","iopub.execute_input":"2021-06-15T13:39:46.762776Z","iopub.status.idle":"2021-06-15T13:39:46.837042Z","shell.execute_reply.started":"2021-06-15T13:39:46.762751Z","shell.execute_reply":"2021-06-15T13:39:46.835946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save raw feature column names\nraw_cols = list(train_df.columns[1:-2])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:39:46.838567Z","iopub.execute_input":"2021-06-15T13:39:46.838973Z","iopub.status.idle":"2021-06-15T13:39:46.843778Z","shell.execute_reply.started":"2021-06-15T13:39:46.838932Z","shell.execute_reply":"2021-06-15T13:39:46.842781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform Yeo-Johnson Transform, Standardization, PCA on transformed data, separate out features and target, split in to train and validation sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\npca_tr = PCA(n_components=70)\n\n# Separate Targets and Features\nX = pd.DataFrame(pca_tr.fit_transform(sclr.fit_transform(train_df[raw_cols])))\nX_test = pd.DataFrame(pca_tr.fit_transform(sclr.fit_transform(data_dict['test'][raw_cols])))\ny = train_df['target_enc']\n\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\nprint()\n\n# Stratified train validation split\nX_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state= 42, test_size=0.20)\nprint(f'X Train {X_train.shape}')\nprint(f'X Val {X_val.shape}')\nprint(f'X Test {X_test.shape}')\nprint(f'y Train {y_train.shape}')\nprint(f'y Val {y_val.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:39:46.845076Z","iopub.execute_input":"2021-06-15T13:39:46.845496Z","iopub.status.idle":"2021-06-15T13:40:17.477553Z","shell.execute_reply.started":"2021-06-15T13:39:46.845453Z","shell.execute_reply":"2021-06-15T13:40:17.476797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Category Percentages from stratification\nprint('Original Splits:')\nprint(y.value_counts() / len(y), '\\n')\nprint('Training Splits:')\nprint(y_train.value_counts() / len(y_train), '\\n')\nprint('Validation Splits:')\nprint(y_val.value_counts() / len(y_val), '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.478753Z","iopub.execute_input":"2021-06-15T13:40:17.479237Z","iopub.status.idle":"2021-06-15T13:40:17.495405Z","shell.execute_reply.started":"2021-06-15T13:40:17.479205Z","shell.execute_reply":"2021-06-15T13:40:17.494191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection\nThe competition metric is log loss.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import log_loss, accuracy_score\nimport joblib\n\ndef clfr_perfomance(y_true,X_, model):\n    print(f'Accuracy: {accuracy_score(y_true,model.predict(X_)):0.4f}')\n    print(f'Log Loss Function: {log_loss(y_true,model.predict_proba(X_)):0.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.498354Z","iopub.execute_input":"2021-06-15T13:40:17.498664Z","iopub.status.idle":"2021-06-15T13:40:17.504071Z","shell.execute_reply.started":"2021-06-15T13:40:17.498616Z","shell.execute_reply":"2021-06-15T13:40:17.502939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we need to predict class probablies, find all the classifiers with predict_proba function in sklearn","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import all_estimators\n\nestimators = all_estimators()\n\nfor name, class_ in estimators:\n    if hasattr(class_, 'predict_proba'):\n        print(name)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.505901Z","iopub.execute_input":"2021-06-15T13:40:17.506267Z","iopub.status.idle":"2021-06-15T13:40:17.550807Z","shell.execute_reply.started":"2021-06-15T13:40:17.506238Z","shell.execute_reply":"2021-06-15T13:40:17.549722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup Gridsearch with crossvalidation to opt hyperparams","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\n\nmdls = {'rf': RandomForestClassifier(n_jobs=-1),\n       'gbc': GradientBoostingClassifier(),\n       'mlp': MLPClassifier()}\n\nprms = {'rf': {'n_estimators': [2**i for i in range(3,8)],\n               'max_depth':  [8,16,32,64,None]},\n        'gbc': {'n_estimators': [250,500],\n               'max_depth':  [1,5,9],\n               'learning_rate': [0.001,0.01,0.1]},\n        'mlp': {'hidden_layer_sizes': [(10,),(50,),(100,),(200,)],\n               'activation': ['logistic','tanh','relu'],\n               'learning_rate': ['constant','invscaling','adaptive']}\n        \n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.552992Z","iopub.execute_input":"2021-06-15T13:40:17.553312Z","iopub.status.idle":"2021-06-15T13:40:17.56089Z","shell.execute_reply.started":"2021-06-15T13:40:17.55328Z","shell.execute_reply":"2021-06-15T13:40:17.560184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Models for Evaluation","metadata":{}},{"cell_type":"code","source":"def train_model(key,models,params):\n    print('Training model: {}'.format(key))\n    gs_cv = GridSearchCV(models[key],params[key], cv = 5,\n                         scoring='neg_log_loss', n_jobs = -1, verbose=1)\n    best_est = gs_cv.fit(X_train, y_train)\n    print('Best Estimator: {}'.format(best_est.best_params_))\n    print('Best Estimator Score: {}'.format(best_est.best_score_))\n    joblib.dump(best_est.best_estimator_,'{}_tr.pkl'.format(key))","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.561851Z","iopub.execute_input":"2021-06-15T13:40:17.562111Z","iopub.status.idle":"2021-06-15T13:40:17.577578Z","shell.execute_reply.started":"2021-06-15T13:40:17.562085Z","shell.execute_reply":"2021-06-15T13:40:17.576661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# Train random forest\ntrain_model('rf',mdls,prms)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T11:55:30.527388Z","iopub.execute_input":"2021-06-06T11:55:30.527794Z","iopub.status.idle":"2021-06-06T13:00:00.810652Z","shell.execute_reply.started":"2021-06-06T11:55:30.527758Z","shell.execute_reply":"2021-06-06T13:00:00.809469Z"}}},{"cell_type":"markdown","source":"Training model: rf <br>\nFitting 5 folds for each of 25 candidates, totalling 125 fits<br>\nBest Estimator: {'max_depth': 16, 'n_estimators': 128}<br>\nBest Estimator Score: -1.7731683449052305<br>\n","metadata":{}},{"cell_type":"raw","source":"# Train multilayer perceptron classifier\ntrain_model('mlp',mdls,prms)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T13:04:38.149636Z","iopub.execute_input":"2021-06-06T13:04:38.150009Z","iopub.status.idle":"2021-06-06T16:49:34.65546Z","shell.execute_reply.started":"2021-06-06T13:04:38.14998Z","shell.execute_reply":"2021-06-06T16:49:34.653846Z"}}},{"cell_type":"markdown","source":"Training model: mlp <br>\nFitting 5 folds for each of 36 candidates, totalling 180 fits<br>\nBest Estimator: {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}<br>\nBest Estimator Score: -1.7609277700753556<br>","metadata":{}},{"cell_type":"raw","source":"from sklearn.model_selection import cross_val_score\nmlp = MLPClassifier(activation='tanh',hidden_layer_sizes = (10,),\n                    learning_rate='invscaling')\ncv_mlp = cross_val_score(mlp, X_train,y_train, scoring='neg_log_loss', cv = 10)\nprint(f'CV Score for MLP min: {np.min(-cv_mlp)}, max: {np.max(-cv_mlp)}, mean: {np.mean(-cv_mlp)}, median: {np.median(-cv_mlp)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T11:28:07.670611Z","iopub.execute_input":"2021-06-15T11:28:07.670962Z","iopub.status.idle":"2021-06-15T11:37:01.302693Z","shell.execute_reply.started":"2021-06-15T11:28:07.670922Z","shell.execute_reply":"2021-06-15T11:37:01.301672Z"}}},{"cell_type":"markdown","source":"\nCV Score for MLP min: 1.7457966814685377, max: 1.756144311735689, mean: 1.7520049992817097, median: 1.7515735323667034","metadata":{}},{"cell_type":"raw","source":"# Train gradient boosted tree classifier\ntrain_model('gbc',mdls,prms)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T20:33:35.061677Z","iopub.execute_input":"2021-06-14T20:33:35.06196Z"}}},{"cell_type":"markdown","source":"Training model: gbc <br>\nFitting 5 folds for each of 18 candidates, totalling 90 fits <br>\n*Did not converge in a reasonable amount of time*","metadata":{}},{"cell_type":"markdown","source":"# Final Model Training and Optimization\nThe multilayer perceptron performed the best, so we will use a Keras MLP as the final model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import *\nfrom keras.losses import SparseCategoricalCrossentropy\n\n# Define the model\nmodel = Sequential()\nmodel.add(Dense(70, input_dim = 70, activation='tanh', name='input'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='relu', name = 'hidden'))\nmodel.add(Dense(9, activation='sigmoid', name = 'output')) \nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.578771Z","iopub.execute_input":"2021-06-15T13:40:17.579204Z","iopub.status.idle":"2021-06-15T13:40:17.632111Z","shell.execute_reply.started":"2021-06-15T13:40:17.579162Z","shell.execute_reply":"2021-06-15T13:40:17.631114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callbacks","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping,ReduceLROnPlateau\nlr_dec = ReduceLROnPlateau(monitor='loss')\nes_callback = EarlyStopping(monitor='loss', restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.633401Z","iopub.execute_input":"2021-06-15T13:40:17.633716Z","iopub.status.idle":"2021-06-15T13:40:17.638797Z","shell.execute_reply.started":"2021-06-15T13:40:17.633685Z","shell.execute_reply":"2021-06-15T13:40:17.638022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Model","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:03:07.721017Z","iopub.execute_input":"2021-06-15T12:03:07.721413Z","iopub.status.idle":"2021-06-15T12:03:07.725613Z","shell.execute_reply.started":"2021-06-15T12:03:07.721381Z","shell.execute_reply":"2021-06-15T12:03:07.724455Z"}}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohc = OneHotEncoder(sparse=False)\n\n# fit model\nnp.random.seed(42)\nhist = model.fit(X_train.values,ohc.fit_transform(y_train.values.reshape(-1,1)),verbose = 1,\n                 epochs=200,callbacks=[lr_dec, es_callback])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:40:17.639719Z","iopub.execute_input":"2021-06-15T13:40:17.639986Z","iopub.status.idle":"2021-06-15T13:42:42.922602Z","shell.execute_reply.started":"2021-06-15T13:40:17.639959Z","shell.execute_reply":"2021-06-15T13:42:42.921832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check Validation Score\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:56:53.449854Z","iopub.execute_input":"2021-06-15T12:56:53.450253Z","iopub.status.idle":"2021-06-15T12:56:53.454454Z","shell.execute_reply.started":"2021-06-15T12:56:53.450217Z","shell.execute_reply":"2021-06-15T12:56:53.453375Z"}}},{"cell_type":"code","source":"model.evaluate(x=X_val.values,y=ohc.fit_transform(y_val.values.reshape(-1,1)))","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:42:42.9237Z","iopub.execute_input":"2021-06-15T13:42:42.924153Z","iopub.status.idle":"2021-06-15T13:42:44.104258Z","shell.execute_reply.started":"2021-06-15T13:42:42.924106Z","shell.execute_reply":"2021-06-15T13:42:44.10326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission","metadata":{}},{"cell_type":"code","source":"X_test['id'] = data_dict['test']['id']\nsub_df = data_dict['sample_submission']\nsub_df['id'] = X_test['id']\npred = model.predict(X_test.drop(columns=['id']))\nsub_df[[x for x in sub_df.columns if x != 'id']] = pred \n#sub_df.set_index(columns = 'id', inplace=True)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:52:43.020641Z","iopub.execute_input":"2021-06-15T13:52:43.021032Z","iopub.status.idle":"2021-06-15T13:52:45.072129Z","shell.execute_reply.started":"2021-06-15T13:52:43.020981Z","shell.execute_reply":"2021-06-15T13:52:45.071172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.set_index('id', drop=True).head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:53:42.931029Z","iopub.execute_input":"2021-06-15T13:53:42.931575Z","iopub.status.idle":"2021-06-15T13:53:42.951205Z","shell.execute_reply.started":"2021-06-15T13:53:42.931533Z","shell.execute_reply":"2021-06-15T13:53:42.95016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# write submission to file\nsub_df.set_index('id', drop=True).to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T13:53:49.436724Z","iopub.execute_input":"2021-06-15T13:53:49.437076Z","iopub.status.idle":"2021-06-15T13:53:51.364949Z","shell.execute_reply.started":"2021-06-15T13:53:49.437047Z","shell.execute_reply":"2021-06-15T13:53:51.364234Z"},"trusted":true},"execution_count":null,"outputs":[]}]}