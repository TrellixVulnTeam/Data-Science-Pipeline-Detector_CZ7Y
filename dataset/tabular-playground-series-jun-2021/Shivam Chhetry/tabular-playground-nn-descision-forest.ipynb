{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import initializers\nimport tqdm as tqdm\nfrom keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-13T04:57:55.368034Z","iopub.execute_input":"2021-08-13T04:57:55.368404Z","iopub.status.idle":"2021-08-13T04:58:00.465456Z","shell.execute_reply.started":"2021-08-13T04:57:55.368326Z","shell.execute_reply":"2021-08-13T04:58:00.464654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jun-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T04:58:04.655359Z","iopub.execute_input":"2021-08-13T04:58:04.655725Z","iopub.status.idle":"2021-08-13T04:58:06.769908Z","shell.execute_reply.started":"2021-08-13T04:58:04.655693Z","shell.execute_reply":"2021-08-13T04:58:06.769061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = pd.get_dummies(train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T04:58:09.549317Z","iopub.execute_input":"2021-08-13T04:58:09.549678Z","iopub.status.idle":"2021-08-13T04:58:09.580328Z","shell.execute_reply.started":"2021-08-13T04:58:09.549645Z","shell.execute_reply":"2021-08-13T04:58:09.579456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> Decision Forest building (\"concatenation\" of decision trees)\n\n> Indented block","metadata":{}},{"cell_type":"code","source":"class Decision_Tree(keras.Model):\n    def __init__(self, depth, num_features, used_features_rate, num_classes):\n        super(Decision_Tree, self).__init__()\n        self.depth = depth\n        self.num_leaves = 2 ** depth\n        self.num_classes = num_classes\n        num_used_features = int(num_features * used_features_rate)    \n        one_hot = np.eye(num_features)                                \n        sampled_feature_indicies = np.random.choice(\n            np.arange(num_features), num_used_features, replace=False\n        )                                                            \n        self.used_features_mask = one_hot[sampled_feature_indicies]   \n        self.pi = tf.Variable(\n            initial_value = tf.random_normal_initializer()(\n            shape = [self.num_leaves, self.num_classes]\n            ),\n            dtype=\"float32\",\n            trainable=True,\n        )\n        \n        self.decision_fn = layers.Dense(\n            units=self.num_leaves, \n            activation=\"sigmoid\", \n            name=\"decision\"\n            )\n\n    def call(self, features):\n        batch_size = tf.shape(features)[0]\n        features = tf.matmul(\n            features, \n            self.used_features_mask, \n            transpose_b=True\n            )  \n        decisions = tf.expand_dims(\n            self.decision_fn(features),\n            axis=2\n            )  \n        decisions = layers.concatenate(\n            [decisions, 1 - decisions],\n            axis=2\n            ) \n\n        mu = tf.ones([batch_size, 1, 1]) \n        begin_idx = 1\n        end_idx = 2\n\n        for level in range(self.depth):\n            mu = tf.reshape(mu, [batch_size, -1, 1])  \n            mu = tf.tile(mu, (1, 1, 2))  \n            level_decisions = decisions[:, begin_idx:end_idx, :]  \n            mu = mu * level_decisions  \n            begin_idx = end_idx\n            end_idx = begin_idx + 2 ** (level + 1)\n\n        mu = tf.reshape(mu, [batch_size, self.num_leaves])  \n        probabilities = keras.activations.softmax(self.pi)  \n        outputs = tf.matmul(mu, probabilities) \n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2021-08-13T04:58:12.990091Z","iopub.execute_input":"2021-08-13T04:58:12.990405Z","iopub.status.idle":"2021-08-13T04:58:13.00214Z","shell.execute_reply.started":"2021-08-13T04:58:12.990379Z","shell.execute_reply":"2021-08-13T04:58:13.001015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decision_Forest(keras.Model):\n    def __init__(self, num_trees, depth, num_features, used_features_rate, num_classes):\n        super(Decision_Forest, self).__init__()\n        self.ensemble = []\n        self.num_classes = num_classes\n        \n        for _ in range(num_trees):\n            self.ensemble.append(\n                Decision_Tree(depth, \n                              num_features,\n                              used_features_rate,\n                              self.num_classes)\n                                )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        outputs = tf.zeros([batch_size, \n                            num_classes])\n        \n        for tree in self.ensemble:\n            outputs += tree(inputs)\n            \n        outputs /= len(self.ensemble)\n        \n        return outputs\n\nnum_trees = 30\n#depth = 5\ndepth = 6\n\nused_features_rate = 0.5\nnum_classes = 9\nnum_features = 30\nforest_model = Decision_Forest(\n                        num_trees,\n                        depth, \n                        num_features,\n                        used_features_rate,\n                        num_classes\n                        )","metadata":{"execution":{"iopub.status.busy":"2021-08-13T04:58:14.459576Z","iopub.execute_input":"2021-08-13T04:58:14.459905Z","iopub.status.idle":"2021-08-13T04:58:16.616678Z","shell.execute_reply.started":"2021-08-13T04:58:14.459879Z","shell.execute_reply":"2021-08-13T04:58:16.615708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = [tf.keras.metrics.CategoricalCrossentropy()]\nloss = tf.keras.losses.CategoricalCrossentropy()\n\nes = tf.keras.callbacks.EarlyStopping(\n    #monitor='val_loss', min_delta=0.0000001, patience=2, verbose=0,\n    monitor='val_loss', min_delta=0.0000001, patience=10, verbose=0,\n\n    mode='min', baseline=None, restore_best_weights=True)\n\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n   # monitor='val_loss', factor=0.5, patience=2, verbose=0,\n    monitor='val_loss', factor=0.5, patience=10, verbose=0,\n\n    #mode='min', min_delta=0.0000001, cooldown=0, min_lr=10e-7)\n    mode='min', min_delta=0.0000001, cooldown=0, min_lr=10e-7)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T04:58:19.956937Z","iopub.execute_input":"2021-08-13T04:58:19.957266Z","iopub.status.idle":"2021-08-13T04:58:19.97529Z","shell.execute_reply.started":"2021-08-13T04:58:19.957236Z","shell.execute_reply":"2021-08-13T04:58:19.974379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<h3> Definition model and training + prediction**","metadata":{}},{"cell_type":"code","source":"N_FOLDS = 10\nSEED = 2021\noof_embedding = np.zeros((train.shape[0],9))\npred_embedding = np.zeros((test.shape[0],9))\noof_forest = np.zeros((train.shape[0],9))\npred_forest = np.zeros((test.shape[0],9))\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train,train.iloc[:,-1])):\n    print(f\"\\n===== TRAINING FOLD {fold} =====\\n\")\n       \n    X_train = train.iloc[:,1:-1].iloc[tr_idx]\n    y_train = target.iloc[tr_idx]\n    X_test = train.iloc[:,1:-1].iloc[ts_idx]\n    y_test = target.iloc[ts_idx]\n    \n\n    #----------NN Model definition ----------\n    \n    inp = layers.Input(shape = (75,))\n    x = layers.Embedding(400, 8, input_length = 256)(inp)\n    x = layers.Flatten()(x)\n    # API is the future imput layer for decision forest :\n    API = layers.Dense(30, \n                       activation='relu',\n                       kernel_initializer='random_uniform',\n                       bias_initializer=initializers.Constant(0.1))(x)\n    x = layers.Dropout(0.3)(API)\n    x = layers.Dense(50, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(30, activation = 'relu')(x)\n    output = layers.Dense(9, activation = 'softmax')(x)\n\n    #----------Models instantiation ---------\n\n    model_embedding = Model(inp,output)\n    model_embedding_without_head = tf.keras.models.Model(inputs=model_embedding.inputs,outputs=API)\n    model_forest = Model(inp,forest_model(API))\n\n    #----------NN Model training ------------\n\n    model_embedding.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n            loss = loss ,\n            metrics = metrics)\n\n    model_embedding.fit(X_train,y_train,\n            validation_data=(X_test,y_test),\n            epochs=150,\n            verbose=0,\n            batch_size = 256,\n            callbacks=[es,plateau])\n     \n    #----------NN Model prediction------------\n    \n    oof_embedding[ts_idx] = model_embedding.predict(X_test)\n    score_embedding = log_loss(y_test, oof_embedding[ts_idx])\n    print(f\"\\nFOLD {fold} Score for NN model {score_embedding}\\n\")\n    pred_embedding += model_embedding.predict(test.iloc[:,1:]) / N_FOLDS\n    \n    \n    #----------Model forest training -----------\n    \n    model_forest.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n            loss = loss,\n            metrics = metrics)\n    \n    model_forest.fit(X_train,y_train,\n                    validation_data = (X_test,y_test),\n                    batch_size = 256,\n                    epochs = 50,\n                    verbose = 0,\n                    callbacks = [es,plateau])\n    \n    #----------Model forest prediction------------ \n        \n    oof_forest[ts_idx] = model_forest.predict(X_test)\n    score_forest = log_loss(y_test, oof_forest[ts_idx])\n    print(f\"\\nFOLD {fold} Score for decision forest : {score_forest}\\n\")\n    \n    pred_forest += model_forest.predict(test.iloc[:,1:]) / N_FOLDS\n    \nscore_embedding = log_loss(target, oof_embedding)\nprint(f\"\\n=== FINAL SCORE FOR NN MODEL : {score_embedding}===\\n\")   \n\nscore_forest = log_loss(target, oof_forest)\nprint(f\"\\n=== FINAL SCORE FOR DECISION FOREST : {score_forest}===\\n\")  ","metadata":{"execution":{"iopub.status.busy":"2021-08-13T04:58:23.456307Z","iopub.execute_input":"2021-08-13T04:58:23.456634Z","iopub.status.idle":"2021-08-13T06:28:43.307036Z","shell.execute_reply.started":"2021-08-13T04:58:23.456603Z","shell.execute_reply":"2021-08-13T06:28:43.306104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1 = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\nsubmission1['Class_1']=pred_forest[:,0]\nsubmission1['Class_2']=pred_forest[:,1]\nsubmission1['Class_3']=pred_forest[:,2]\nsubmission1['Class_4']=pred_forest[:,3]\nsubmission1['Class_5']=pred_forest[:,4]\nsubmission1['Class_6']=pred_forest[:,5]\nsubmission1['Class_7']=pred_forest[:,6]\nsubmission1['Class_8']=pred_forest[:,7]\nsubmission1['Class_9']=pred_forest[:,8]","metadata":{"execution":{"iopub.status.busy":"2021-08-13T06:29:48.783142Z","iopub.execute_input":"2021-08-13T06:29:48.783472Z","iopub.status.idle":"2021-08-13T06:29:49.024254Z","shell.execute_reply.started":"2021-08-13T06:29:48.783443Z","shell.execute_reply":"2021-08-13T06:29:49.023409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission1.to_csv(\"Keras_forest.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T06:29:52.089357Z","iopub.execute_input":"2021-08-13T06:29:52.089711Z","iopub.status.idle":"2021-08-13T06:29:53.889069Z","shell.execute_reply.started":"2021-08-13T06:29:52.089678Z","shell.execute_reply":"2021-08-13T06:29:53.887911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2 = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\nsubmission2['Class_1']=pred_embedding[:,0]\nsubmission2['Class_2']=pred_embedding[:,1]\nsubmission2['Class_3']=pred_embedding[:,2]\nsubmission2['Class_4']=pred_embedding[:,3]\nsubmission2['Class_5']=pred_embedding[:,4]\nsubmission2['Class_6']=pred_embedding[:,5]\nsubmission2['Class_7']=pred_embedding[:,6]\nsubmission2['Class_8']=pred_embedding[:,7]\nsubmission2['Class_9']=pred_embedding[:,8]","metadata":{"execution":{"iopub.status.busy":"2021-08-13T06:30:01.246235Z","iopub.execute_input":"2021-08-13T06:30:01.246628Z","iopub.status.idle":"2021-08-13T06:30:01.36109Z","shell.execute_reply.started":"2021-08-13T06:30:01.246591Z","shell.execute_reply":"2021-08-13T06:30:01.360134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission2.to_csv(\"Keras_embedding.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T06:30:03.164526Z","iopub.execute_input":"2021-08-13T06:30:03.164905Z","iopub.status.idle":"2021-08-13T06:30:04.990291Z","shell.execute_reply.started":"2021-08-13T06:30:03.164875Z","shell.execute_reply":"2021-08-13T06:30:04.989458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}