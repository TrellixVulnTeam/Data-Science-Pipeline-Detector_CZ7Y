{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T13:40:08.024755Z","iopub.execute_input":"2021-06-13T13:40:08.025123Z","iopub.status.idle":"2021-06-13T13:40:08.041549Z","shell.execute_reply.started":"2021-06-13T13:40:08.025092Z","shell.execute_reply":"2021-06-13T13:40:08.040103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets import the dataset into variables :-\n* train for training data\n* test for test data\n* ss for sample submission","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/test.csv\")\nSS = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:15.421884Z","iopub.execute_input":"2021-06-13T13:02:15.42228Z","iopub.status.idle":"2021-06-13T13:02:17.130271Z","shell.execute_reply.started":"2021-06-13T13:02:15.422238Z","shell.execute_reply":"2021-06-13T13:02:17.12929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Part one :- Exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"> ***Clearly this is a multi-class classification problem***","metadata":{}},{"cell_type":"code","source":"train[\"target\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:17.131708Z","iopub.execute_input":"2021-06-13T13:02:17.13202Z","iopub.status.idle":"2021-06-13T13:02:17.186252Z","shell.execute_reply.started":"2021-06-13T13:02:17.13199Z","shell.execute_reply":"2021-06-13T13:02:17.185304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **So, we have the following classes in the dataset :- Class_1 through 9 i.e 9 classes** ","metadata":{}},{"cell_type":"code","source":"train.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:18.086498Z","iopub.execute_input":"2021-06-13T13:02:18.086886Z","iopub.status.idle":"2021-06-13T13:02:18.136695Z","shell.execute_reply.started":"2021-06-13T13:02:18.086853Z","shell.execute_reply":"2021-06-13T13:02:18.135668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Hence, there is no null value in the data, so we dont require any imputation**","metadata":{}},{"cell_type":"markdown","source":"# Part two :- Getting dataset ready","metadata":{}},{"cell_type":"code","source":"X = train[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n       'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n       'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n       'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49',\n       'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54',\n       'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59',\n       'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64',\n       'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69',\n       'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74',]]\ntest1 = test[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n       'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24',\n       'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29',\n       'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34',\n       'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39',\n       'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44',\n       'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49',\n       'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54',\n       'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59',\n       'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64',\n       'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69',\n       'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74',]]\nY = train[[\"target\"]]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:19.503042Z","iopub.execute_input":"2021-06-13T13:02:19.503494Z","iopub.status.idle":"2021-06-13T13:02:19.790272Z","shell.execute_reply.started":"2021-06-13T13:02:19.503453Z","shell.execute_reply":"2021-06-13T13:02:19.789399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,30))\nfor i in range(0,75):\n    plt.subplot(25,3,i+1)\n    plt.hist(X.iloc[:,i])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:20.171099Z","iopub.execute_input":"2021-06-13T13:02:20.171469Z","iopub.status.idle":"2021-06-13T13:02:28.404753Z","shell.execute_reply.started":"2021-06-13T13:02:20.171438Z","shell.execute_reply":"2021-06-13T13:02:28.403543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj_standatd_scalar = StandardScaler()\nX_normalized = obj_standatd_scalar.fit_transform(X)\nX_normalized_df = pd.DataFrame(X_normalized)\nX= X_normalized_df","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:28.406422Z","iopub.execute_input":"2021-06-13T13:02:28.406706Z","iopub.status.idle":"2021-06-13T13:02:28.929443Z","shell.execute_reply.started":"2021-06-13T13:02:28.406679Z","shell.execute_reply":"2021-06-13T13:02:28.92838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,30))\nfor i in range(0,75):\n    plt.subplot(25,3,i+1)\n    plt.hist(X_normalized_df.iloc[:,i])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:28.9312Z","iopub.execute_input":"2021-06-13T13:02:28.931492Z","iopub.status.idle":"2021-06-13T13:02:37.645978Z","shell.execute_reply.started":"2021-06-13T13:02:28.931465Z","shell.execute_reply":"2021-06-13T13:02:37.644947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:02:37.647501Z","iopub.execute_input":"2021-06-13T13:02:37.647801Z","iopub.status.idle":"2021-06-13T13:02:37.836374Z","shell.execute_reply.started":"2021-06-13T13:02:37.647771Z","shell.execute_reply":"2021-06-13T13:02:37.835668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">  We will be applying different classification model and check for the one which gives the most accurate result :-\n\n> 1. Decision Tree classifier\n> 2. K-nearest neighbours\n> 3. Random forest regressor  \n\n\n> SVM cant be used here because the dataset is huge\n","metadata":{}},{"cell_type":"code","source":"#DTC = DecisionTreeClassifier(random_state=1,max_depth=10).fit(x_train,y_train)\n#KNN = KNeighborsClassifier(n_neighbors=20).fit(x_train,y_train)\n#RFC = RandomForestClassifier(random_state=1).fit(x_train,y_train.values.ravel())\nDTC = GaussianNB().fit(x_train, y_train.values.ravel())\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:41:30.270195Z","iopub.execute_input":"2021-06-13T13:41:30.27055Z","iopub.status.idle":"2021-06-13T13:41:30.909365Z","shell.execute_reply.started":"2021-06-13T13:41:30.270518Z","shell.execute_reply":"2021-06-13T13:41:30.908116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DTC_predict = DTC.predict(x_test)\n#DTC_predict = KNN.predict(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:41:33.842323Z","iopub.execute_input":"2021-06-13T13:41:33.842728Z","iopub.status.idle":"2021-06-13T13:41:34.135856Z","shell.execute_reply.started":"2021-06-13T13:41:33.842694Z","shell.execute_reply":"2021-06-13T13:41:34.134727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the accuracy of the model\ny_pred_list = list(DTC_predict)\ny_test_list = list(y_test[\"target\"])\ncount = 0\nfor i in range (0,len(y_pred_list)):\n    if(y_pred_list[i]==y_test_list[i]):\n        count =count+1\naccuracy = count/len(y_test)\naccuracy  \n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:41:37.688511Z","iopub.execute_input":"2021-06-13T13:41:37.688888Z","iopub.status.idle":"2021-06-13T13:41:37.748182Z","shell.execute_reply.started":"2021-06-13T13:41:37.688857Z","shell.execute_reply":"2021-06-13T13:41:37.747077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_mat = confusion_matrix(y_test,RFC_predict)\nplt.matshow(conf_mat, cmap = plt.cm.gray)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:04:51.994119Z","iopub.execute_input":"2021-06-13T13:04:51.994684Z","iopub.status.idle":"2021-06-13T13:04:52.693381Z","shell.execute_reply.started":"2021-06-13T13:04:51.994648Z","shell.execute_reply":"2021-06-13T13:04:52.692239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This shows that the model performs really bad.","metadata":{}},{"cell_type":"code","source":"preds = RFC.predict_proba(test1)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:05:23.444354Z","iopub.execute_input":"2021-06-13T13:05:23.444691Z","iopub.status.idle":"2021-06-13T13:05:25.806884Z","shell.execute_reply.started":"2021-06-13T13:05:23.444661Z","shell.execute_reply":"2021-06-13T13:05:25.805849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm1 = pd.DataFrame(preds, columns=['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'])\nsubm = pd.DataFrame({'id':SS['id']}) \ns = pd.concat([subm,subm1],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:05:29.168436Z","iopub.execute_input":"2021-06-13T13:05:29.168791Z","iopub.status.idle":"2021-06-13T13:05:29.179679Z","shell.execute_reply.started":"2021-06-13T13:05:29.168751Z","shell.execute_reply":"2021-06-13T13:05:29.178851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" s.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T13:05:33.431215Z","iopub.execute_input":"2021-06-13T13:05:33.431701Z","iopub.status.idle":"2021-06-13T13:05:34.350319Z","shell.execute_reply.started":"2021-06-13T13:05:33.431669Z","shell.execute_reply":"2021-06-13T13:05:34.349362Z"},"trusted":true},"execution_count":null,"outputs":[]}]}