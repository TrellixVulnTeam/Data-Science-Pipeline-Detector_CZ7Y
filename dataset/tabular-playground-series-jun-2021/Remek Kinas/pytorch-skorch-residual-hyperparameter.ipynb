{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch (+skorch) RESIDUAL (skipped connection) with CROSS VALIDATION and HYPERPARAMETER SEARCH (GridSearchCV)\n\n\n<div class=\"alert alert-success\">\n  <strong>Content of this notebook</strong>\n    <ul>\n        <li>Notebook contribution</li>\n        <li>Model definition</li>\n        <li>Callback definition</li>\n        <li>Pilepine for data preprocessing and model run</li>\n        <li>Hyperparameter search</li>\n        <ul>\n            <li>number of residual modules in NN</li>\n            <li>number of embedding dimention</li>\n<li>best network optimizer</li>\n            <li>optimal linear nodes number</li>\n<li>dropout </li>\n<li>and many more (I just provided framework for searching the best params for NN)</li></ul>\n        <li>Model ranking + optimal parameters</li>\n        <li>Prediction smoothing - using many models</li>\n        <li>Submission</li>\n    </ul>\n</div>\n</br>\n<hr class=\"background-color: #fff; border-top: 2px dotted #8c8b8b;\">\n</br>\nScope of seach defined as a standard GridSearchCV\n<code>\n    grid_params = {\n    'net__module__dropout': [0.2, 0.3], \n    'net__optimizer': [optim.Adam], \n    'net__module__linear_nodes' : [64, 32, 16],\n    'net__module__emb_output' : [2, 4, 6],\n    'net__module__linear_out' : [16],\n    'net__module__num_block' : [2, 3, 4]\n} \n </code>\n\n\n<div>\n   <strong>Contributions</strong>\n    <ul>\n        <li><a href = \"https://www.kaggle.com/oxzplvifi/tabular-residual-network\">Tabular Residual Network by @oxzplvifi</a></li>\n        <li><a href = \"https://www.kaggle.com/oxzplvifi/tabular-residual-network\">Python keras NN (residual) by @alexryzhkov</a></li>\n    </ul>\n</div>\n\n<div>\n<strong>List of experiments which have not provide better result</strong>\n<ul>\n    <li>I have used different ways to normalize weight - batch norm, weight norm and layer norm - the best so far is weight norm</li>\n    <li> Mixing many activation function (ReLU, ELU, SELU) works fine. If using only ReLU score has not improved.</li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install -U skorch -q","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-08T20:26:41.55072Z","iopub.execute_input":"2021-06-08T20:26:41.55102Z","iopub.status.idle":"2021-06-08T20:26:49.259906Z","shell.execute_reply.started":"2021-06-08T20:26:41.550953Z","shell.execute_reply":"2021-06-08T20:26:49.258972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nimport seaborn as sns\nsns.set(font_scale= 1.0)\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\n\n\nimport torch\nfrom torch import nn\nfrom torch.nn.utils import weight_norm\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom skorch import NeuralNetClassifier, NeuralNet\nfrom skorch.callbacks import EpochScoring\nfrom skorch.callbacks import LRScheduler, EarlyStopping\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:49.263269Z","iopub.execute_input":"2021-06-08T20:26:49.263531Z","iopub.status.idle":"2021-06-08T20:26:51.906976Z","shell.execute_reply.started":"2021-06-08T20:26:49.263501Z","shell.execute_reply":"2021-06-08T20:26:51.906079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jun-2021/train.csv', index_col = 'id')\ntest = pd.read_csv('../input/tabular-playground-series-jun-2021/test.csv', index_col = 'id')\ntest_pred = test.values.astype('float32')\n\n\nX = train.drop('target', axis = 1).values.astype('float32')\n\nlencoder = LabelEncoder()\ny = lencoder.fit_transform(train['target']).astype('int64')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:51.910143Z","iopub.execute_input":"2021-06-08T20:26:51.910409Z","iopub.status.idle":"2021-06-08T20:26:53.759322Z","shell.execute_reply.started":"2021-06-08T20:26:51.910381Z","shell.execute_reply":"2021-06-08T20:26:53.758413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MODEL DEFINITION \n\nThis model is prepared for maximum tuning by scikit GridSearchCV. Certainly you can add more feature to optimize. ","metadata":{}},{"cell_type":"code","source":"feature_dictionary_size = 360\nnum_features = 75\n\ndef residual_block(in_features, out_features, p_drop, non_linear = nn.ReLU(), *args, **kwargs):  \n        return nn.Sequential(\n            nn.Dropout(p = p_drop),\n            weight_norm(nn.Linear(in_features, out_features)),\n            non_linear)\n\n\nclass TPSResidual(nn.Module):\n    def __init__(self, num_class = 9, dropout = 0.3, linear_nodes = 32, linear_out = 16, emb_output = 4, num_block = 3):\n        super(TPSResidual, self).__init__()\n        \n        self.num_block = num_block\n        self.final_module_list = nn.ModuleList()\n    \n        \n        self.embedding = nn.Embedding(feature_dictionary_size, emb_output)\n        self.flatten = nn.Flatten()\n\n        self.linear = weight_norm(nn.Linear(emb_output * num_features, linear_nodes))\n        \n        for res_num in range(self.num_block):\n            self.non_linear = nn.ELU() if res_num % 2 else nn.ReLU()\n            self.lin_out = linear_out if res_num == (self.num_block - 1) else linear_nodes\n            self.final_module_list.append(residual_block(emb_output * num_features + (res_num + 1) * linear_nodes, self.lin_out, dropout, self.non_linear))\n            \n        self.out = nn.Linear(linear_out, num_class)\n        \n        # nonlinearity - activation function\n        self.selu = nn.SELU()\n        \n        self.dropout = nn.Dropout(p = dropout)\n    \n   \n    def forward(self, x):\n        x = torch.tensor(x).to(torch.int64)\n        \n        # Embedding \n        e = self.embedding(x)\n        e = self.flatten(e)\n        \n        h1 = self.dropout(e)\n        h1 = self.linear(h1)\n        h1 = self.selu(h1)\n        \n        ri = torch.cat((e, h1), 1)\n        \n        for res_num in range(self.num_block):          \n            rx = self.final_module_list[res_num](ri)\n            ri = torch.cat((ri, rx), 1)\n        \n        return  F.softmax(self.out(rx), dim = -1)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.760982Z","iopub.execute_input":"2021-06-08T20:26:53.761326Z","iopub.status.idle":"2021-06-08T20:26:53.774656Z","shell.execute_reply.started":"2021-06-08T20:26:53.76128Z","shell.execute_reply":"2021-06-08T20:26:53.773822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CALLBACKS \nI decided to define to callback (1) Learning Rate Scheduler and (2) Early Stopping. You can look for it using GridSearch as well but I think that this is a way better approach (dynamic search).","metadata":{}},{"cell_type":"code","source":"lr_scheduler = LRScheduler(policy = ReduceLROnPlateau, monitor = 'valid_loss', mode = 'min', patience = 3, factor = 0.1, verbose = True)\nearly_stopping = EarlyStopping(monitor='valid_loss', patience = 10, threshold = 0.0001, threshold_mode='rel', lower_is_better=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.776002Z","iopub.execute_input":"2021-06-08T20:26:53.776344Z","iopub.status.idle":"2021-06-08T20:26:53.79007Z","shell.execute_reply.started":"2021-06-08T20:26:53.776308Z","shell.execute_reply":"2021-06-08T20:26:53.78918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = NeuralNetClassifier(TPSResidual, device = device, lr = 0.001, max_epochs = 50, callbacks = [lr_scheduler, early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.790948Z","iopub.execute_input":"2021-06-08T20:26:53.791962Z","iopub.status.idle":"2021-06-08T20:26:53.804174Z","shell.execute_reply.started":"2021-06-08T20:26:53.791921Z","shell.execute_reply":"2021-06-08T20:26:53.803369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HYPERPARAMETER SEARCH PARAMETERS ","metadata":{}},{"cell_type":"code","source":"# if you can search for hyperparamteters set OPTIM = True\n# I ran many experiments (270 runs) o local machine. Results provided below.\n\nOPTIM = False","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.807118Z","iopub.execute_input":"2021-06-08T20:26:53.80744Z","iopub.status.idle":"2021-06-08T20:26:53.813046Z","shell.execute_reply.started":"2021-06-08T20:26:53.807415Z","shell.execute_reply":"2021-06-08T20:26:53.812312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Each parameter you can define as you want. For testing purposes and limited Kaggle notebook uptime I decided to compute them on my local machine and use it here.  \n\n# This is demo only so I dropped some of parameters (it is only subset, full list of params (about 270 runs) will be trained locally and then I will provide here)\ngrid_params = {\n    'net__module__dropout': [0.2, 0.3], \n    'net__optimizer': [optim.AdamW, optim.Adam, optim.RMSprop],\n    'net__module__linear_nodes' : [64, 32, 16],\n    'net__module__emb_output' : [2, 4, 6],\n    'net__module__linear_out' : [16],\n    'net__module__num_block' : [2, 3, 4]\n} \n\n\n\n# Here you can define steps in Pipeline (eg. data preprocessing). In this example there is no such needs.\nsteps = [('net', net)]\npipeline = Pipeline(steps)\n\n\ngrid_net = GridSearchCV(pipeline, grid_params, cv = 5, refit = True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.815833Z","iopub.execute_input":"2021-06-08T20:26:53.816217Z","iopub.status.idle":"2021-06-08T20:26:53.823556Z","shell.execute_reply.started":"2021-06-08T20:26:53.81618Z","shell.execute_reply":"2021-06-08T20:26:53.822756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TOP3 - AFTER 270 RUNS THE BEST PARAMETERS SO FAR:\n**Model with rank: 1**\nMean validation score: -1.744 (std: 0.004)\nParameters: {'net__module__dropout': 0.3, 'net__module__emb_output': 2, 'net__module__linear_nodes': 16, 'net__module__linear_out': 16, 'net__module__num_block': 2, 'net__optimizer': <class 'torch.optim.adam.Adam'>}\n\n**Model with rank: 2**\nMean validation score: -1.745 (std: 0.003)\nParameters: {'net__module__dropout': 0.3, 'net__module__emb_output': 2, 'net__module__linear_nodes': 32, 'net__module__linear_out': 16, 'net__module__num_block': 2, 'net__optimizer': <class 'torch.optim.adam.Adam'>}\n\n**Model with rank: 3**\nMean validation score: -1.745 (std: 0.004)\nParameters: {'net__module__dropout': 0.2, 'net__module__emb_output': 2, 'net__module__linear_nodes': 16, 'net__module__linear_out': 16, 'net__module__num_block': 3, 'net__optimizer': <class 'torch.optim.adam.Adam'>}","metadata":{}},{"cell_type":"code","source":"if OPTIM:\n    result = grid_net.fit(X,y)\n\n# You can look into training history below","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-08T20:26:53.825245Z","iopub.execute_input":"2021-06-08T20:26:53.825596Z","iopub.status.idle":"2021-06-08T20:26:53.832617Z","shell.execute_reply.started":"2021-06-08T20:26:53.82556Z","shell.execute_reply":"2021-06-08T20:26:53.83182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TOP5 MODELS RANKING ","metadata":{}},{"cell_type":"code","source":"def report(results, n_top=5):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\nif OPTIM:\n    report(grid_net.cv_results_,5)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.835475Z","iopub.execute_input":"2021-06-08T20:26:53.83571Z","iopub.status.idle":"2021-06-08T20:26:53.843009Z","shell.execute_reply.started":"2021-06-08T20:26:53.835687Z","shell.execute_reply":"2021-06-08T20:26:53.842217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BEST ESTIMATOR ","metadata":{}},{"cell_type":"code","source":"if OPTIM:\n    grid_net.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.844288Z","iopub.execute_input":"2021-06-08T20:26:53.844625Z","iopub.status.idle":"2021-06-08T20:26:53.856268Z","shell.execute_reply.started":"2021-06-08T20:26:53.844591Z","shell.execute_reply":"2021-06-08T20:26:53.855416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LEARNING HISTORY ","metadata":{}},{"cell_type":"code","source":"if OPTIM:\n    epochs = [i for i in range(len(grid_net.best_estimator_[0].history))]\n    train_loss = grid_net.best_estimator_[0].history[:,'train_loss']\n    valid_loss = grid_net.best_estimator_[0].history[:,'valid_loss']\n\n    plt.plot(epochs,train_loss,'g-');\n    plt.plot(epochs,valid_loss,'r-');\n    plt.title('Training Loss Curves');\n    plt.xlabel('Epochs');\n    plt.ylabel('Mean Squared Error');\n    plt.legend(['Train','Validation']);","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.857237Z","iopub.execute_input":"2021-06-08T20:26:53.859404Z","iopub.status.idle":"2021-06-08T20:26:53.866603Z","shell.execute_reply.started":"2021-06-08T20:26:53.859378Z","shell.execute_reply":"2021-06-08T20:26:53.865835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ESTIMATOR LEARNING AND BLENDING","metadata":{}},{"cell_type":"code","source":"# This parameters were taken from TOP3 searchgridcv estimators (computed on local machine) \n\nnet_params = [{'net__module__dropout': 0.3, 'net__module__emb_output': 2, \n               'net__module__linear_nodes': 16, 'net__module__linear_out': 16, \n               'net__module__num_block': 2, 'net__optimizer': optim.Adam},\n             \n              {'net__module__dropout': 0.3, 'net__module__emb_output': 2, \n              'net__module__linear_nodes': 32, 'net__module__linear_out': 16, \n              'net__module__num_block': 2, 'net__optimizer': optim.Adam},\n              \n              {'net__module__dropout': 0.2, 'net__module__emb_output': 2, \n              'net__module__linear_nodes': 16, 'net__module__linear_out': 16, \n              'net__module__num_block': 3, 'net__optimizer': optim.Adam},\n             \n              {'net__module__dropout': 0.3, 'net__module__emb_output': 2, \n               'net__module__linear_nodes': 16, 'net__module__linear_out': 16, \n               'net__module__num_block': 3, 'net__optimizer': optim.Adam},\n              \n              {'net__module__dropout': 0.3, 'net__module__emb_output': 2, \n               'net__module__linear_nodes': 16, 'net__module__linear_out': 16, \n               'net__module__num_block': 4, 'net__optimizer': optim.Adam}]\n\ndef get_estimator(net_params):\n    return NeuralNetClassifier(TPSResidual, \n                               device = device, \n                               lr = 3e-2, \n                               max_epochs = 50, \n                               optimizer = optim.AdamW,\n                               callbacks = [lr_scheduler, early_stopping],\n                               module__dropout = net_params['net__module__dropout'],\n                               module__emb_output = net_params['net__module__emb_output'],\n                               module__linear_nodes = net_params['net__module__linear_nodes'],\n                               module__linear_out = net_params['net__module__linear_out'],\n                               module__num_block = net_params['net__module__num_block'],\n                               iterator_train__shuffle = True\n                             )","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.867942Z","iopub.execute_input":"2021-06-08T20:26:53.868327Z","iopub.status.idle":"2021-06-08T20:26:53.878598Z","shell.execute_reply.started":"2021-06-08T20:26:53.868293Z","shell.execute_reply":"2021-06-08T20:26:53.877896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not OPTIM:\n    NUM_MODELS = len(net_params)\n    y_pred = np.zeros((100000,9))\n\n    for net_config in net_params:\n        print(f'MODEL PARMAETERS {net_config}\\n')\n        net = get_estimator(net_config)\n        net.fit(X,y)\n        y_pred += net.predict_proba(test_pred) / NUM_MODELS\n        print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:26:53.880001Z","iopub.execute_input":"2021-06-08T20:26:53.880351Z","iopub.status.idle":"2021-06-08T20:27:05.924862Z","shell.execute_reply.started":"2021-06-08T20:26:53.880316Z","shell.execute_reply":"2021-06-08T20:27:05.922234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SUBMISSION","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\npredictions_df = pd.DataFrame(y_pred, columns = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\", \"Class_5\", \"Class_6\", \"Class_7\", \"Class_8\", \"Class_9\" ])\npredictions_df['id'] = sub['id']","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:27:05.925599Z","iopub.status.idle":"2021-06-08T20:27:05.925984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:27:05.926991Z","iopub.status.idle":"2021-06-08T20:27:05.927432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palette = itertools.cycle(sns.color_palette())\n\nplt.figure(figsize=(16, 8))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    c = next(palette)\n    sns.histplot(predictions_df, x = f'Class_{i+1}', color=c)\nplt.suptitle(\"CLASS PREDICTION - DISTRIBUTION\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:27:05.928289Z","iopub.status.idle":"2021-06-08T20:27:05.928738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.drop(\"id\", axis=1).describe().T.style.bar(subset=['mean'], color='#205ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:27:05.929667Z","iopub.status.idle":"2021-06-08T20:27:05.930282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df.to_csv(\"TPS06-pytorch_residual_submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T20:27:05.931437Z","iopub.status.idle":"2021-06-08T20:27:05.932057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I really appreciate any feedback and support. Thank you very much!","metadata":{}}]}