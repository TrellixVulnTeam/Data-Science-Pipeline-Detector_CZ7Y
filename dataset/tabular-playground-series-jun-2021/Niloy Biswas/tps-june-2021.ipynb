{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ground up solution","metadata":{"id":"endless-divorce"}},{"cell_type":"markdown","source":"First of all, this solution is built on the idea to practise the complete workflow of machine learning prediction. Even though auto ML and blending other people's results are frequently used and legit in Kaggle, I think building a ground up solution is beneficial for gaining really solid understanding of the ML techniques.\n\nSince my computer is not powerful enough to handle the size of data here (100K times 50) with ease, I will strive for simple and efficient way to build the classification model on Kaggle hosting server. Again, the modelling process here is for learning the ML process rather than doing the fancy stuff or building specific solutions that are not ready for generalisation to other problems.\n\nBased on the background above, you will see a solution in favour of simple ML workflow and low computation cost, ready to be deployed for different problems. The presentation may be raw, but I will keep it to show how the result is improved gradually.\n\nWorkflow:\n1. Data Exploration\n2. Data Preprocessing\n3. Feature Engineering\n4. Feature Selection\n5. Model Validation And Selection\n6. Hyperparameter Tuning\n","metadata":{"id":"representative-parent"}},{"cell_type":"markdown","source":"# Preparation","metadata":{"id":"thorough-vertex"}},{"cell_type":"markdown","source":"## **Code Imported from** [https://www.kaggle.com/lilkaskitc/tps-may-2021](http://)","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"powered-clerk"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-06-07T07:55:28.565455Z","iopub.execute_input":"2021-06-07T07:55:28.56613Z","iopub.status.idle":"2021-06-07T07:55:28.574854Z","shell.execute_reply.started":"2021-06-07T07:55:28.566007Z","shell.execute_reply":"2021-06-07T07:55:28.573915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install catboost","metadata":{"id":"x7O_oOxQsemw","executionInfo":{"status":"ok","timestamp":1623048347049,"user_tz":-360,"elapsed":2574,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"50cbe57d-fbdf-4b0c-d3ce-4dcc63166f37","execution":{"iopub.status.busy":"2021-06-07T08:00:55.153466Z","iopub.execute_input":"2021-06-07T08:00:55.153944Z","iopub.status.idle":"2021-06-07T08:01:03.022393Z","shell.execute_reply.started":"2021-06-07T08:00:55.153908Z","shell.execute_reply":"2021-06-07T08:01:03.021214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install xgboost==0.71\n!pip install mlxtend==0.18.0","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:01:03.024714Z","iopub.execute_input":"2021-06-07T08:01:03.025148Z","iopub.status.idle":"2021-06-07T08:03:16.880888Z","shell.execute_reply.started":"2021-06-07T08:01:03.025102Z","shell.execute_reply":"2021-06-07T08:03:16.879691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Essentials\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport random\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Models\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesClassifier, StackingClassifier\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import RidgeClassifier, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV, LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n#from mlxtend.classifier import StackingCVClassifier\nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\nfrom mlxtend.classifier import StackingCVClassifier\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import Pool, CatBoostClassifier\n\n# Stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Misc\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, validation_curve\nfrom sklearn.metrics import log_loss, confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_classif\n\npd.set_option('display.max_columns', None)\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\n\nimport os\nos.listdir(\"../input/\")","metadata":{"id":"naval-singapore","executionInfo":{"status":"ok","timestamp":1623048349270,"user_tz":-360,"elapsed":559,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"4d5b5d67-37ed-4078-9b8a-b076cc7eb2d9","execution":{"iopub.status.busy":"2021-06-07T08:04:29.788383Z","iopub.execute_input":"2021-06-07T08:04:29.788775Z","iopub.status.idle":"2021-06-07T08:04:29.806146Z","shell.execute_reply.started":"2021-06-07T08:04:29.788739Z","shell.execute_reply":"2021-06-07T08:04:29.805087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read data","metadata":{"id":"understanding-cherry"}},{"cell_type":"code","source":"# Read in the dataset as a dataframe\ntrain = pd.read_csv(\"../input/tabular-playground-series-jun-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-jun-2021/test.csv\")\nsubmission = pd.read_csv(\"../input/tabular-playground-series-jun-2021/sample_submission.csv\")\n\ntrain.info()\n#test.info()\n#submission.info()","metadata":{"id":"purple-holmes","executionInfo":{"status":"ok","timestamp":1623048354618,"user_tz":-360,"elapsed":1575,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"execution":{"iopub.status.busy":"2021-06-07T08:04:49.580595Z","iopub.execute_input":"2021-06-07T08:04:49.58098Z","iopub.status.idle":"2021-06-07T08:04:51.278747Z","shell.execute_reply.started":"2021-06-07T08:04:49.580951Z","shell.execute_reply":"2021-06-07T08:04:51.277535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split datasets","metadata":{"id":"harmful-shooting"}},{"cell_type":"code","source":"# Split features and labels\ntrain_labels = train['target'].reset_index(drop=True)\ntrain_features = train.drop(['id','target'], axis=1)\ntest_features = test.drop(['id'], axis=1)\ntrain_labels.head()","metadata":{"id":"defined-geometry","executionInfo":{"status":"ok","timestamp":1623048357437,"user_tz":-360,"elapsed":360,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"d011f273-7b49-44fc-8004-6c9e85ed8571"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{"id":"elegant-vehicle"}},{"cell_type":"markdown","source":"## Target distribution\n\nAs observed, 57% of the target in the training set is of \"Class 2\", which is moderately imbalanced.","metadata":{"id":"dated-fiction"}},{"cell_type":"code","source":"\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.histplot(train['target'].sort_values(), color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n","metadata":{"id":"opening-scanning","executionInfo":{"elapsed":1073,"status":"ok","timestamp":1622717627225,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"},"user_tz":-360},"outputId":"88f81c5a-d1f0-447f-e8c6-64538a90961d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts().sort_values(ascending=False)/sum(train['target'].value_counts())","metadata":{"id":"developmental-machine","executionInfo":{"elapsed":331,"status":"ok","timestamp":1622717631721,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"},"user_tz":-360},"outputId":"15871ec4-545b-4913-dc16-645a4e76afed"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features EDA\n\nNo specific pattern is observed in this case.","metadata":{"id":"consistent-uganda"}},{"cell_type":"code","source":"\n# visualising some more outliers in the data values\nfig, axs = plt.subplots(ncols=2, nrows=1, figsize=(12, 120))\nplt.subplots_adjust(right=2)\nplt.subplots_adjust(top=2)\nsns.color_palette(\"husl\", 8)\nfor i, feature in enumerate(list(train_features), 1):\n    plt.subplot(len(list(train_features)), 3, i)\n    sns.boxplot(x=feature, y=train_labels, hue=train_labels, palette='Blues', data=train_features)\n        \n    plt.xlabel('{}'.format(feature), size=15,labelpad=12.5)\n    plt.ylabel('Target', size=15, labelpad=12.5)\n    \n    for j in range(2):\n        plt.tick_params(axis='x', labelsize=12)\n        plt.tick_params(axis='y', labelsize=12)\n    \n    plt.legend(loc='best', prop={'size': 10})\n        \nplt.show()\n","metadata":{"id":"global-royalty","executionInfo":{"elapsed":62259,"status":"ok","timestamp":1622717700059,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"},"user_tz":-360},"outputId":"3c591d35-4562-4b4b-9271-48b4b679d20f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation\n\nFilter by RF feature importance first when the number of features is too large.\n\nThe 50 features show no significant correlation with each other.","metadata":{"id":"approximate-geneva"}},{"cell_type":"code","source":"\n# Random Forest Classifier\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\n\nrf_model = rf.fit(train_features, train_labels)\n#rf_pred = rf_model.predict_proba(test_features)\n\nforest_importances = pd.Series(rf.feature_importances_, index=train_features.columns)\ntop_feat = forest_importances.sort_values(ascending = False).head(20)\ntop_feat\n\ntrain_features[top_feat.index]\n","metadata":{"id":"partial-politics","outputId":"aaa710c8-607c-48f2-9913-8b0470b441b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#corr = train_features[top_feat.index].corr()\n#corr\ncorr = train.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"Blues\", square=True)\n","metadata":{"id":"focused-archives","outputId":"bde0f964-a785-42cf-b8fc-57c18b32a92c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Further exploration for high correlation to target\n\nThe most important features by RF is feature_38, but visually its standalone correlation with the target is insignificant.","metadata":{"id":"comfortable-motel"}},{"cell_type":"code","source":"\ndata = pd.concat([train['feature_38'], train['target']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=train['feature_38'], y=\"target\", data=data)\n#fig.axis(ymin=0, ymax=800000);\n","metadata":{"id":"valid-market","outputId":"c31092ef-25ee-40c9-df12-3a5c7f5d878a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"functioning-bangladesh"}},{"cell_type":"markdown","source":"No outliers or missing values observed from EDA.","metadata":{"id":"cordless-pilot"}},{"cell_type":"markdown","source":"## Recombine datasets\n\nNo treatment is needed in this case.","metadata":{"id":"sublime-utility"}},{"cell_type":"markdown","source":"# Feature Engineering\n\nObserved that the training set has large amount of zero values in the original 50 features, I have tried to add 50 binary features depending on whether each of the original 50 features is zero or not. The trial does not provide significant improvement in preliminary RF model, so this idea is not adopted. There maybe information loss in grouping all nonzero values together, which leads to worse performance.","metadata":{"id":"auburn-equality"}},{"cell_type":"code","source":"'''\n# feature of zero or nonzero values\n\ndef zeroornot(res, ls):\n    m = res.shape[1]\n    for l in ls:\n        res = res.assign(newcol=pd.Series(res[l] == 0).astype(int)) \n        res.columns.values[m] = l + '_zero'\n        m += 1\n    return res\n\ntrain_features_zero = zeroornot(train_features, train_features.columns.tolist())\ntest_features_zero = zeroornot(test_features, test_features.columns.tolist())\n'''","metadata":{"id":"welsh-sympathy","outputId":"c3a93d17-0b79-4824-ecff-5d37b1d534ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_features_zero = train_features_zero.drop(train_features_zero.iloc[:,0:50], axis=1)\n#test_features_zero = test_features_zero.drop(test_features_zero.iloc[:,0:50], axis=1)","metadata":{"id":"flexible-disorder"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PCA\n\nSince there are 50 features, the dimension reduction technique may help. I have tried PCA, but the result is not satisfactory. This is intuitive given the low features correlation shown in EDA, and the almost identical contributions from all the principal components.","metadata":{"id":"patient-celebrity"}},{"cell_type":"code","source":"'''\nX=train_features\n# Standardize\nX_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n\n# Create principal components\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Convert to dataframe\ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_pca.head()\n'''","metadata":{"id":"relative-dublin","outputId":"e4197df7-9c0f-4557-e0c2-b7f1447df63a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nloadings = pd.DataFrame(\n    pca.components_.T,  # transpose the matrix of loadings\n    columns=component_names,  # so the columns are the principal components\n    index=X.columns,  # and the rows are the original features\n)\nloadings\n'''","metadata":{"id":"affecting-russian","outputId":"413fd454-a392-43e3-87fa-5a6a768ac812"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 0.05)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs\n\n# Look at explained variance\nplot_variance(pca);\n'''","metadata":{"id":"czech-grave","outputId":"338298c5-4823-4d2c-e7a6-7ed4a9369b7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X_pca, train_labels, discrete_features=False)\nmi_scores\n'''","metadata":{"id":"partial-logic","outputId":"e1b6528b-97d3-40a9-b8a4-1dbc486496b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nmiindex = mi_scores.index[mi_scores.values>0]\nmiload = loadings[miindex]\n'''","metadata":{"id":"protective-appeal","outputId":"baa85fce-705f-46a0-ec91-39ce8afdea8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrain_features_pca = pd.DataFrame(data = np.matmul(train_features,miload))\ntrain_features_pca.columns=miindex\n'''","metadata":{"id":"pressing-myrtle","outputId":"14619d51-d308-4303-c569-dee633c9e6cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntest_features_pca = pd.DataFrame(data = np.matmul(test_features,miload))\ntest_features_pca.columns=miindex\n'''","metadata":{"id":"handmade-identification","outputId":"cb8f5f25-803b-40ea-f014-58975216b21d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recreate training and test sets\n\nNo treatment is needed in this case.","metadata":{"id":"important-scheme"}},{"cell_type":"markdown","source":"# Feature Selection","metadata":{"id":"refined-rocket"}},{"cell_type":"markdown","source":"# Model Validation and Selection","metadata":{"id":"thorough-nitrogen"}},{"cell_type":"markdown","source":"## Set up CV","metadata":{"id":"gentle-nursery"}},{"cell_type":"code","source":"# Set up cross validation folds\nkf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Define error metrics\ndef loss(y, y_pred):\n    return np.sqrt(log_loss(y, y_pred))\n\ndef cv_loss(model, X = train_features):\n    loss = np.sqrt(-cross_val_score(model, X, train_labels, scoring=\"neg_log_loss\", cv=kf, n_jobs=-1))\n    return (loss)","metadata":{"id":"several-breathing","executionInfo":{"status":"ok","timestamp":1623048365823,"user_tz":-360,"elapsed":1489,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Base Models","metadata":{"id":"processed-people"}},{"cell_type":"markdown","source":"### XGBoost","metadata":{"id":"charged-symbol"}},{"cell_type":"code","source":"\n# XGBoost Classifier\nxgb =  XGBClassifier(learning_rate = 0.1,\n                        colsample_bytree = 0.5,\n                        max_depth = 10,\n                        min_child_weight=5,\n                       gamma=0.001,\n                       subsample=0.9,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\n#xgb_model = xgb.fit(train_features, train_labels)\n#xgb_pred = xgb_model.predict_proba(test_features)\n","metadata":{"id":"macro-frequency","executionInfo":{"status":"ok","timestamp":1623048369621,"user_tz":-360,"elapsed":6,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# XGBoost Classifier2\nxgb2 = XGBClassifier(n_estimators=110,\n                        learning_rate = 0.5,\n                        colsample_bytree = 0.13,\n                       max_depth = 2,\n                        min_child_weight=5,\n                       gamma=0.001,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\n#xgb2_model = xgb2.fit(train_features, train_labels)\n#xgb2_pred = xgb2_model.predict_proba(test_features)","metadata":{"id":"temporal-threat","executionInfo":{"status":"ok","timestamp":1623048370876,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# XGBoost Classifier3\nxgb3 =XGBClassifier(n_estimators=250,\n                        learning_rate = 0.06,\n                        colsample_bytree = 0.4,\n                       max_depth = 6,\n                        min_child_weight=5,\n                       subsample=0.75,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       random_state=42)\n                       \n\n#xgb3_model = xgb3.fit(train_features, train_labels)\n#xgb3_pred = xgb3_model.predict_proba(test_features)","metadata":{"id":"dimensional-operation","executionInfo":{"status":"ok","timestamp":1623048371326,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier4\nxgb4 = XGBClassifier(n_estimators=130, \n                        learning_rate = 0.5,\n                        colsample_bytree = 0.13,\n                        max_depth = 2,\n                        min_child_weight=7, \n                       gamma=0.001,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n                       \n\n#xgb4_model = xgb4.fit(train_features, train_labels)\n#xgb4_pred = xgb4_model.predict_proba(test_features)","metadata":{"id":"bottom-vehicle","executionInfo":{"status":"ok","timestamp":1623048372411,"user_tz":-360,"elapsed":4,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier5\nxgb5 = XGBClassifier( n_estimators=200,\n                        learning_rate = 0.5,\n                       colsample_bytree = 0.1,\n                       max_depth = 2,\n                        min_child_weight=5,\n                      gamma=0.005,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=5,\n                         reg_lambda = 0.3,\n                         eval_metric = 'mlogloss',\n                       random_state=42)\n                       \n\n#xgb5_model = xgb5.fit(train_features, train_labels)\n#xgb5_pred = xgb5_model.predict_proba(test_features)","metadata":{"id":"constitutional-third","executionInfo":{"status":"ok","timestamp":1623048372975,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{"id":"southwest-disorder"}},{"cell_type":"code","source":"\n# Random Forest Classifier\nrf = RandomForestClassifier(min_samples_split = 5,\n                            min_samples_leaf = 5,\n                            max_depth = None,\n                            bootstrap = True,\n                            n_jobs=-1,\n                            criterion = \"entropy\",\n                            n_estimators=500,\n                            max_features = 12,\n                            random_state = 42)\n'''\nrf_model = rf.fit(train_features, train_labels)\nrf_pred = rf_model.predict_proba(test_features)\n'''","metadata":{"id":"tracked-movement","executionInfo":{"status":"ok","timestamp":1623048374958,"user_tz":-360,"elapsed":369,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"a7980e64-5b58-4569-8e02-d6015af61c95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Light GBM","metadata":{"id":"sorted-progressive"}},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb =  LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    max_depth=6,\n                       learning_rate=0.1, \n                       n_estimators=220,\n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.7,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\nlgb_model = lgb.fit(train_features, train_labels)\nlgb_pred = lgb_model.predict_proba(test_features)\n","metadata":{"id":"living-chambers","executionInfo":{"status":"ok","timestamp":1623048440396,"user_tz":-360,"elapsed":63923,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb2 =  LGBMClassifier(objective='multiclass', \n                       num_leaves=2,\n                    max_depth=1,\n                       learning_rate=0.5, \n                       n_estimators=550,\n                      max_bin=25, \n                       bagging_fraction=0.6,\n                       bagging_freq=8, \n                       bagging_seed=8,\n                      feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgb2_model = lgb2.fit(train_features, train_labels)\n#lgb2_pred = lgb2_model.predict_proba(test_features)","metadata":{"id":"mounted-seeker","executionInfo":{"status":"ok","timestamp":1623048447091,"user_tz":-360,"elapsed":384,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb3 = LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=7, \n                    max_depth=4,\n                       learning_rate=0.066, \n                       n_estimators=200,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgb3_model = lgb3.fit(train_features, train_labels)\n#lgb3_pred = lgb3_model.predict_proba(test_features)","metadata":{"id":"quick-canyon","executionInfo":{"status":"ok","timestamp":1623048456013,"user_tz":-360,"elapsed":347,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb4 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    max_depth=6,\n                       learning_rate=0.1, \n                       n_estimators=250, \n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.5,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgb4_model = lgb4.fit(train_features, train_labels)\n#lgb4_pred = lgb4_model.predict_proba(test_features)","metadata":{"id":"ignored-billy","executionInfo":{"status":"ok","timestamp":1623048457359,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb5 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    min_data_in_leaf=19, \n                    max_depth=6,\n                       learning_rate=0.1, \n                      n_estimators=310, \n                       max_bin=80, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgb5_model = lgb5.fit(train_features, train_labels)\n#lgb5_pred = lgb5_model.predict_proba(test_features)","metadata":{"id":"steady-guess","executionInfo":{"status":"ok","timestamp":1623048458721,"user_tz":-360,"elapsed":12,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb6 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    min_data_in_leaf=19, \n                    max_depth=5,\n                      learning_rate=0.1, \n                      n_estimators=310, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                           lambda_l2 = 0.003,\n                           min_gain_to_split = 0.0001,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgb6_model = lgb6.fit(train_features, train_labels)\n#lgb6_pred = lgb6_model.predict_proba(test_features)","metadata":{"id":"ready-aging","executionInfo":{"status":"ok","timestamp":1623048459161,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Light Gradient Boosting Regressor\nlgb7 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    min_data_in_leaf=19, \n                    max_depth=5,\n                      learning_rate=0.1, \n                     n_estimators=500, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                          lambda_l1 = 9,\n                           lambda_l2 = 0.003,\n                           min_gain_to_split = 0.0001,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgb7_model = lgb7.fit(train_features, train_labels)\n#lgb7_pred = lgb7_model.predict_proba(test_features)","metadata":{"id":"separate-thanks","executionInfo":{"status":"ok","timestamp":1623048459691,"user_tz":-360,"elapsed":2,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extra Trees","metadata":{"id":"homeless-paint"}},{"cell_type":"code","source":"\n# Extra Trees Classifier\next =ExtraTreesClassifier(  min_samples_split = 5,\n                            min_samples_leaf = 5,\n                            max_depth = 15,\n                            bootstrap = True,\n                            n_jobs=-1,\n                            n_estimators=10,\n                            max_features = 20,\n                            random_state = 42,\n                            criterion = 'entropy')\n'''\next_model = ext.fit(train_features, train_labels)\next_pred = ext_model.predict_proba(test_features)\n'''","metadata":{"id":"difficult-edinburgh","executionInfo":{"status":"ok","timestamp":1623048461213,"user_tz":-360,"elapsed":6,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"8ec0e525-7803-4b38-f5b8-8c7e6a9985b5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CatBoost","metadata":{"id":"sized-wallpaper"}},{"cell_type":"code","source":"\n#CatBoost\ncat_features = train_features.columns.values.tolist()\n\ntrain_dataset = Pool(data=train_features,\n                     label=train_labels,\n                     cat_features=cat_features)\n\neval_dataset = Pool(data=test_features,\n                    cat_features=cat_features)\n\n# Initialize CatBoostClassifier\ncat =  CatBoostClassifier(n_estimators=500,\n                           learning_rate=0.3,\n                           max_depth=2,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.5,\n                            min_data_in_leaf=5,\n                            verbose=0)\n# Fit model\n#cat.fit(train_dataset)\n# Get predicted probabilities for each class\n#cat_pred = cat.predict_proba(eval_dataset)\n","metadata":{"id":"veterinary-football","executionInfo":{"status":"ok","timestamp":1623048468094,"user_tz":-360,"elapsed":5539,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#CatBoost2\n\n\n# Initialize CatBoostClassifier\ncat2 = CatBoostClassifier(n_estimators=550,\n                           learning_rate=0.5,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                            verbose=0)\n# Fit model\n#cat2.fit(train_dataset)\n# Get predicted probabilities for each class\n#cat2_pred = cat2.predict_proba(eval_dataset)","metadata":{"id":"southeast-catalyst","executionInfo":{"status":"ok","timestamp":1623048468096,"user_tz":-360,"elapsed":12,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#CatBoost3\n\n\n# Initialize CatBoostClassifier\ncat3 = CatBoostClassifier(n_estimators=250,\n                           learning_rate=0.1,\n                           max_depth=6,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=3,\n                            verbose=0)\n\n# Fit model\n#cat3.fit(train_dataset)\n# Get predicted probabilities for each class\n#cat3_pred = cat3.predict_proba(eval_dataset)","metadata":{"id":"skilled-mauritius","executionInfo":{"status":"ok","timestamp":1623048471338,"user_tz":-360,"elapsed":2,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CatBoost4\n\n# Initialize CatBoostClassifier\n\ncat4 = CatBoostClassifier(n_estimators=600,\n                           learning_rate=0.6,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                            verbose=0)\n\n\n# Fit model\n#cat4.fit(train_dataset)\n# Get predicted probabilities for each class\n#cat4_pred = cat4.predict_proba(eval_dataset)","metadata":{"id":"dietary-south","executionInfo":{"status":"ok","timestamp":1623048472642,"user_tz":-360,"elapsed":6,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CatBoost5\n\n# Initialize CatBoostClassifier\n\ncat5 = CatBoostClassifier(n_estimators=600,\n                           learning_rate=0.6,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                               bagging_temperature = 0.2,\n                             sampling_frequency = 'PerTreeLevel',\n                               reg_lambda = 3,\n                            verbose=0)\n\n# Fit model\n#cat5.fit(train_dataset)\n# Get predicted probabilities for each class\n#cat5_pred = cat5.predict_proba(eval_dataset)","metadata":{"id":"former-courtesy","executionInfo":{"status":"ok","timestamp":1623048472644,"user_tz":-360,"elapsed":6,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking\n\nOnly one level of meta model is trained on the base model predictions and the original features. The type of meta models would still be chosen from the available types in the base models. ","metadata":{"id":"existing-folks"}},{"cell_type":"code","source":"# %%time\n# Stack up all the models above, optimized using lgb\nstack_gen = StackingCVClassifier(classifiers = (rf, lgb, xgb, ext),\n                                meta_classifier = lgb,\n                                use_probas= True,\n                                use_features_in_secondary=True, \n                                verbose=2,\n                                n_jobs=-1,\n                                random_state=17\n                                )\n\n#stack_gen_model = stack_gen.fit(np.array(train_features), np.array(train_labels))\n#stack_pred = stack_gen_model.predict_proba(np.array(test_features))\n","metadata":{"id":"mobile-hundred","executionInfo":{"status":"ok","timestamp":1623048489253,"user_tz":-360,"elapsed":369,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%%time\n# Stack2\n# Stack up all the models above, optimized using cat\nstack_gen2 = StackingCVClassifier(classifiers = (xgb2, lgb, cat),\n                                meta_classifier = cat,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                verbose=2,\n                                n_jobs=-1,\n                                random_state=17)\n\n#stack_gen2_model = stack_gen2.fit(np.array(train_features), np.array(train_labels))\n#stack2_pred = stack_gen2_model.predict_proba(np.array(test_features))\n","metadata":{"id":"loving-worse","executionInfo":{"status":"ok","timestamp":1623048494520,"user_tz":-360,"elapsed":395,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"0ac7dfa8-149a-44ef-d8e5-2d2ff307ba26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack4\n# Stack up all the models above, optimized using cat2\nstack_gen4 = StackingCVClassifier(classifiers = (xgb2,lgb, cat2),\n                                meta_classifier = cat,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                verbose=2,\n                                n_jobs=-1,\n                                random_state=17\n                                )\n\n#stack_gen4_model = stack_gen4.fit(np.array(train_features), np.array(train_labels))\n#stack4_pred = stack_gen4_model.predict_proba(np.array(test_features))","metadata":{"id":"addressed-wagon","executionInfo":{"status":"ok","timestamp":1623048496088,"user_tz":-360,"elapsed":10,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"603f74f0-2738-41fa-cfa0-b353d5ae1a91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack5\n# Stack up all the models above, optimized using cats5\n\ncats5 = CatBoostClassifier(n_estimators=450, \n                           learning_rate=0.1, \n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.5,\n                            min_data_in_leaf=5,\n                            verbose=0)\n                            \n\nstack_gen5 = StackingCVClassifier(classifiers = (xgb2,lgb, cat2),\n                                meta_classifier = cats5,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n\n#stack_gen5_model = stack_gen5.fit(np.array(train_features), np.array(train_labels))\n#stack5_pred = stack_gen5_model.predict_proba(np.array(test_features))","metadata":{"id":"unusual-proportion","executionInfo":{"status":"ok","timestamp":1623048496602,"user_tz":-360,"elapsed":5,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"ddb82c8c-2a33-4ecc-c497-6626b5fc9c72"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack6\n# Stack up all the models above, optimized using lgbs6\n\nlgbs6 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    max_depth=6,\n                       learning_rate=0.03, \n                       n_estimators=160, \n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.7,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                            \n\nstack_gen6 = StackingCVClassifier(classifiers = (lgb, xgb, cat),\n                                meta_classifier = lgbs6,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n\n#stack_gen6_model = stack_gen6.fit(np.array(train_features), np.array(train_labels))\n#stack6_pred = stack_gen6_model.predict_proba(np.array(test_features))","metadata":{"id":"surgical-appraisal","executionInfo":{"status":"ok","timestamp":1623048498306,"user_tz":-360,"elapsed":564,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"34541c08-4a68-4bf0-c96e-c01af37fed30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack7\n# Stack up all the models above, optimized using lgbs7\n\n\nlgbs7 = LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=7, \n                    max_depth=4,\n                       learning_rate=0.05, \n                       n_estimators=100,\n                       bagging_fraction=1,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1\n                   )\n\nstack_gen7 =  StackingCVClassifier(classifiers = (lgb3, xgb3, cat),\n                                meta_classifier = lgbs7,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n\n#stack_gen7_model = stack_gen7.fit(np.array(train_features), np.array(train_labels))\n#stack7_pred = stack_gen7_model.predict_proba(np.array(test_features))","metadata":{"id":"relative-tradition","executionInfo":{"status":"ok","timestamp":1623048498308,"user_tz":-360,"elapsed":9,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"657dda7a-2c50-45dd-900a-d2ed65151fc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack8\n# Stack up all the models above, optimized using lgbs8\n\n\nlgbs8 = LGBMClassifier(objective='multiclass', \n                     min_data_in_leaf=3, \n                    max_depth=4,\n                       learning_rate=0.05, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1\n                   )\n\nstack_gen8 = StackingCVClassifier(classifiers = (xgb2, lgb, cat2),\n                                meta_classifier = lgbs8,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n#stack_gen8_model = stack_gen8.fit(np.array(train_features), np.array(train_labels))\n#stack8_pred = stack_gen8_model.predict_proba(np.array(test_features))","metadata":{"id":"fifteen-aruba","executionInfo":{"status":"ok","timestamp":1623048498743,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"009f4bae-4a9b-40e6-9cfa-d92641e10c1e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack9\n# Stack up all the models above, optimized using lgbs9\n\n\nlgbs9 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                   min_data_in_leaf=23, \n                    max_depth=3,\n                       learning_rate=0.05, \n                    n_estimators=270, \n                      max_bin=60, \n                    bagging_fraction=0.7, \n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1\n                   )\n\nstack_gen9 = StackingCVClassifier(classifiers = (xgb4, lgb5, cat4),\n                                meta_classifier = lgbs9,\n                                 use_probas= True,\n                                use_features_in_secondary=True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n#stack_gen9_model = stack_gen9.fit(np.array(train_features), np.array(train_labels))\n#stack9_pred = stack_gen9_model.predict_proba(np.array(test_features))","metadata":{"id":"impressed-representative","executionInfo":{"status":"ok","timestamp":1623048504843,"user_tz":-360,"elapsed":15,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"427755ad-0547-427b-8cbd-dc8c5cdd2b81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack10\n# Stack up all the models above, optimized using lgbs10\n\n\nlgbs10 = LGBMClassifier(objective='multiclass', \n                       num_leaves=4,\n                  min_data_in_leaf=400, \n                    max_depth=1, \n                     learning_rate=0.05, \n                   n_estimators=270, \n                      max_bin=60, \n                    bagging_fraction=0.5, \n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.15, \n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1\n                   )\n\n                            \n\nstack_gen10 = StackingCVClassifier(classifiers = (xgb4, lgb5, cat4),\n                                meta_classifier = lgbs10,\n                                 use_probas= True,\n                                use_features_in_secondary= False, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n\n#stack_gen10_model = stack_gen10.fit(np.array(train_features), np.array(train_labels))\n#stack10_pred = stack_gen10_model.predict_proba(np.array(test_features))","metadata":{"id":"civil-still","executionInfo":{"status":"ok","timestamp":1623048504846,"user_tz":-360,"elapsed":15,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"bfea4de6-498e-48ae-a930-82b1df567e33"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Stack11\n# Stack up all the models above, optimized using lgbs11\n\n\nlgbs11 = LGBMClassifier(objective='multiclass', \n                       num_leaves=5,\n                    min_data_in_leaf=19, \n                    max_depth=4,\n                      learning_rate=0.1, \n                     n_estimators=180, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                          lambda_l1 = 7,\n                           lambda_l2 = 0.1,\n                           min_gain_to_split = 0.01,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                       \nstack_gen11 = StackingCVClassifier(classifiers = (xgb5, lgb7, cat5),\n                                meta_classifier = lgbs11,\n                                 use_probas= True,\n                                use_features_in_secondary= True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n\nstack_gen11_model = stack_gen11.fit(np.array(train_features), np.array(train_labels))\nstack11_pred = stack_gen11_model.predict_proba(np.array(test_features))","metadata":{"id":"specific-prevention","executionInfo":{"status":"ok","timestamp":1623049129825,"user_tz":-360,"elapsed":624990,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"9185440b-ffc3-4e21-934e-19446bf54d1e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV result","metadata":{"id":"occupational-sense"}},{"cell_type":"code","source":"scores = {}\n\nscore = cv_loss(stack_gen11)\nprint(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['rf'] = (score.mean(), score.std())\n","metadata":{"id":"automotive-anime","executionInfo":{"status":"ok","timestamp":1623051479758,"user_tz":-360,"elapsed":2233046,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"c0fc0ced-1162-48c2-b5ef-4b3030fae1c8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Redefine CV function for PCA","metadata":{"id":"southern-webmaster"}},{"cell_type":"code","source":"'''\ndef cvpca_loss(model, X = train_features_pca):\n    loss = np.sqrt(-cross_val_score(model, X, train_labels, scoring=\"neg_log_loss\", cv=kf, n_jobs=-1))\n    return (loss)\n\nscores = {}\n\nscore = cvpca_loss(cat2)\nprint(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['rf'] = (score.mean(), score.std())\n'''","metadata":{"id":"sitting-carol","outputId":"84cc5d3e-ec91-4f68-8929-1b33c75467ff"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix\n\nThe result shows that the imbalanced target data has led to prediction highly in favour of \"Class 2\", which is worth noting for insights.","metadata":{"id":"overall-julian"}},{"cell_type":"code","source":"lgb_pred = lgb_model.predict(np.array(train_features))","metadata":{"id":"sudden-renaissance","executionInfo":{"status":"ok","timestamp":1623051506928,"user_tz":-360,"elapsed":11936,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique, counts = np.unique(lgb_pred, return_counts=True)\nnp.asarray((unique, counts)).T","metadata":{"id":"vietnamese-cuisine","executionInfo":{"status":"ok","timestamp":1623051510195,"user_tz":-360,"elapsed":357,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"b59717a3-987d-416b-b965-d53a1bc8c10f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.around(confusion_matrix(train_labels,lgb_pred, normalize = 'true'),3)","metadata":{"id":"sorted-climate","executionInfo":{"status":"ok","timestamp":1623051516803,"user_tz":-360,"elapsed":923,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"aa1118e0-ed76-4698-a0d8-0bf0ccb495f0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{"id":"ranking-cleveland"}},{"cell_type":"markdown","source":"## Validation Curves\n\nValidation curve is most frequently used in hyperparameters tuning for its lower computation cost. Past studies have also shown that its performance is not far from the grid search if used properly.","metadata":{"id":"scenic-click"}},{"cell_type":"code","source":"'''\n%%time\nnum_est = [100,200,300]\n\nvc_model = CatBoostClassifier(n_estimators=600,\n                           learning_rate=0.6,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                           # min_data_in_leaf=5,\n                               bagging_temperature = 0.2,\n                             sampling_frequency = 'PerTreeLevel',\n                               reg_lambda = 3,\n                            verbose=0)\n\n\n\n# Calculate accuracy on training and test set using the\n# parameter with 5-fold cross validation\ntrain_score, test_score = validation_curve( vc_model,\n                                X = train_features, y = train_labels, \n                                param_name = 'min_data_in_leaf', \n                                param_range = num_est, cv = kf, scoring=\"neg_log_loss\", n_jobs=-1\n                            )\n \n# Calculating mean and standard deviation of training score\nmean_train_score = -np.mean(train_score, axis = 1)\nstd_train_score = np.std(train_score, axis = 1)\n \n# Calculating mean and standard deviation of testing score\nmean_test_score = -np.mean(test_score, axis = 1)\nstd_test_score = np.std(test_score, axis = 1)\n \n# Plot mean accuracy scores for training and testing scores\nplt.plot(num_est, mean_train_score,\n     label = \"Training Score\", color = 'b')\nplt.plot(num_est, mean_test_score,\n   label = \"Cross Validation Score\", color = 'g')\n \n# Creating the plot\nplt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"LogLoss\")\nplt.tight_layout()\nplt.legend(loc = 'best')\nplt.show()\n'''","metadata":{"id":"fatal-nirvana","outputId":"4e9da767-ec17-46c9-91af-3e549be641d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mean_test_score","metadata":{"id":"derived-european"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Hyperparameter Grid\n\nThe random grid is mostly used as a preliminary to narrow down the range of hyperparameters for the finer grid search.","metadata":{"id":"statistical-times"}},{"cell_type":"code","source":"'''\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n# Number of features to consider at every split\nmax_features = [int(x) for x in np.linspace(5, 15, num = 10)]\nmax_features.append(\"auto\")\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(2, 10, num = 5)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = 5\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = 5\n# Method of selecting samples for training each tree\nbootstrap = True\n\n#XGB\nlearning_rate = [0.01,0.1,0.3,0.5, 0.7,1]\ncolsample_bytree = [0.05,0.1, 0.3, 0.5,0.7,1]\n\n#LGB\nfeature_fraction = [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n\n#CAT\ncolsample_bylevel =[0.1, 0.3, 0.5, 0.7, 0.9, 1]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               #'max_features': max_features,\n               'max_depth': max_depth,\n               #'min_samples_split': min_samples_split,\n               #'min_samples_leaf': min_samples_leaf,\n               #'bootstrap': bootstrap,\n               'learning_rate': learning_rate,\n               #'colsample_bytree': colsample_bytree\n               #'feature_fraction':feature_fraction,\n               'colsample_bylevel':colsample_bylevel\n              }\n'''","metadata":{"id":"paperback-saturday","outputId":"73f24488-0ed4-46d3-a0b1-8c04d496eb35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = CatBoostClassifier(#n_estimators=550,\n                           #learning_rate=0.5,\n                           #max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            #colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                            reg_lambda = 3,\n                            subsample = 0.8,\n                            bootstrap_type = 'Bernoulli'\n\n                            )\n# Random search of parameters, using 2 fold cross validation, \n# search across 30 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 33, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(train_features, train_labels)\n'''","metadata":{"id":"soviet-jimmy","outputId":"9c4d811d-b9c3-446d-feda-d0ebc82dbfca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rf_random.best_params_","metadata":{"id":"allied-tokyo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Grid Search","metadata":{"id":"strong-taxation"}},{"cell_type":"code","source":"'''\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    #'max_depth': [5,7],\n    'n_estimators': [220,240,260],\n    #'learning_rate':[0.1,0.3,0.5],\n    #'feature_fraction':[0.1,0.3],\n    #'num_leaves':[2,6,10],\n    #'bagging_fraction':[0.4,0.6,0.8],\n    #'bagging_freq':[6,8,10],\n    #'max_bin':[10,15,25],\n    #'colsample_bylevel':[0.05,0.1,0.3],\n    'min_data_in_leaf':[3,5,7],\n    'reg_lambda':[1,3,5],\n    'subsample':[0.6,0.8,1]\n    \n}\n# Create a based model\nrf = XGBClassifier(n_estimators=100,\n                        learning_rate = 0.5,\n                        colsample_bytree = 0.4,\n                       max_depth = 6,\n                        min_child_weight=5,\n                       gamma=0.001,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n)\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\n'''","metadata":{"id":"knowing-division","outputId":"b76806c5-8357-4247-bd04-aa026b6bb5b1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Fit the grid search to the data\ngrid_search.fit(train_features, train_labels)\n#best_grid = \ngrid_search.best_estimator_\n'''","metadata":{"id":"indian-calculator","outputId":"b01ff0b1-ebec-49e6-9474-c0624593fd39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grid_search.best_params_","metadata":{"id":"prime-insider"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tuning for meta-model","metadata":{"id":"suited-liquid"}},{"cell_type":"code","source":"#stack_gen.get_params().keys()","metadata":{"id":"roman-suspension"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\nnum_est = [0.08,0.1,0.12]\n\nvc_model = LGBMClassifier(objective='multiclass', \n                       num_leaves=5,\n                    min_data_in_leaf=19, \n                    max_depth=4,\n                      learning_rate=0.1, \n                     n_estimators=180, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                          lambda_l1 = 7,\n                           lambda_l2 = 0.1,\n                           min_gain_to_split = 0.01,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                       \nstack_gen_vc = StackingCVClassifier(classifiers = (xgb5, lgb7, cat5),\n                                meta_classifier = vc_model,\n                                 use_probas= True,\n                                use_features_in_secondary= True, \n                                 verbose=2,\n                                 n_jobs=-1,\n                                random_state=17,\n                                   stratify = True)\n\n\n# Calculate accuracy on training and test set using the\n# parameter with 3-fold cross validation\ntrain_score, test_score = validation_curve( stack_gen_vc,\n                                X = train_features, y = train_labels, \n                                param_name = 'meta_classifier__learning_rate', \n                                param_range = num_est, cv = kf, scoring=\"neg_log_loss\", n_jobs=-1\n                            )\n \n# Calculating mean and standard deviation of training score\nmean_train_score = -np.mean(train_score, axis = 1)\nstd_train_score = np.std(train_score, axis = 1)\n \n# Calculating mean and standard deviation of testing score\nmean_test_score = -np.mean(test_score, axis = 1)\nstd_test_score = np.std(test_score, axis = 1)\n \n# Plot mean accuracy scores for training and testing scores\nplt.plot(num_est, mean_train_score,\n     label = \"Training Score\", color = 'b')\nplt.plot(num_est, mean_test_score,\n   label = \"Cross Validation Score\", color = 'g')\n \n# Creating the plot\nplt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"LogLoss\")\nplt.tight_layout()\nplt.legend(loc = 'best')\nplt.show()\n'''","metadata":{"id":"functional-ribbon","outputId":"eda76d01-e8ee-48fb-bc8b-38a5667f0086"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mean_test_score","metadata":{"id":"unauthorized-tattoo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"id":"racial-database"}},{"cell_type":"code","source":"\n# Read in sample_submission dataframe\nsubmission[['Class_1', 'Class_2', 'Class_3', 'Class_4','Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']] = stack11_pred\nsubmission.head()\n","metadata":{"id":"medium-porter","executionInfo":{"status":"ok","timestamp":1623051528224,"user_tz":-360,"elapsed":1980,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"541a1ad9-cef4-43e8-e4a8-96cb6387a845"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission_stack11.csv\", index=False)","metadata":{"id":"angry-serial","executionInfo":{"status":"ok","timestamp":1623051537688,"user_tz":-360,"elapsed":1756,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission_stack11.csv')","metadata":{"id":"dgs3kilLabNv","executionInfo":{"status":"ok","timestamp":1623051589306,"user_tz":-360,"elapsed":355,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"d3797fae-17e6-468c-b74c-4af3c3779da7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import files\nfiles.download('submission_stack11.csv') ","metadata":{"id":"grQ9oweGaqqq","executionInfo":{"status":"ok","timestamp":1623051655196,"user_tz":-360,"elapsed":1110,"user":{"displayName":"Niloy Biswas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTqYULMF9CI_J6hEwQJIyElOXF8SbwBn5T0PyxrRY=s64","userId":"00033384564844961881"}},"outputId":"cfbe0190-f8f1-4c43-a489-042e02545050"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance Log","metadata":{"id":"sharing-electric"}},{"cell_type":"code","source":"'''\nPerformance\n# CV scores have taken square root by careless setting, but would not affect the comparison of results.\n\nBasic rf (n=100)\nCV 1.0633 (0.0022)\npublic 1.12521\n\nFeatured rf (n=100)\nCV 1.0643 (0.0024)\npublic 1.12140\n\nTuned rf\nCV 1.0506 (0.0005)\npublic 1.09957\n\nTuned rf with criterion = \"entropy\"\nCV 1.0501 (0.0007)\npublic 1.09912\n\nBasic xgb\npublic 1.09495\n\nTuned xgb\nCV 1.0473 (0.0007)\npublic 1.08944\n\nTuned2 xgb\nCV 1.0453 (0.0006)\npublic 1.08896\n\nTuned3 xgb\nCV 1.0455 (0.0005)\npublic 1.08767\n\nTuned4 xgb\nCV 1.0453 (0.0007)\npublic 1.08834\n\nTuned5 xgb\nCV 1.0445 (0.0007)\npublic 1.08785\n\nBasic lgb\nCV 1.0470 (0.0006)\npublic 1.09036\n\nTuned lgb\nCV 1.0454 (0.0007)\npublic 1.08871\n\nTuned2 lgb\nCV 1.0459 (0.0007)\npublic 1.08916\n\nTuned3 lgb\nCV 1.0455 (0.0007)\npublic 1.08872\n\nTuned4 lgb\nCV 1.0452 (0.0007)\npublic 1.08789\n\nTuned5 lgb\nCV 1.0447 (0.0006)\npublic 1.08785\n\nTuned6 lgb\nCV 1.0447 (0.0006)\npublic 1.08790\n\nTuned7 lgb\nCV 1.0441 (0.0008)\npublic 1.08723\n\nBasic ext\nCV 1.0643 (0.0011)\npublic 1.12962\n\nTuned ext\nCV 1.0550 (0.0004)\npublic 1.10729\n\nTuned2 ext\nCV 1.0536 (0.0005)\npublic 1.10495\n\nBasic cat\nCV 1.0516 (0.0009)\npublic 1.10367\n\nTuned cat\nCV 1.0450 (0.0008)\npublic 1.09039\n\nTuned2 cat\nCV 1.0449 (0.0007)\npublic 1.09092\n\nTuned3 cat\nCV 1.0456 (0.0006)\npublic 1.09146\n\nTuned4 cat\nCV 1.0448 (0.0009)\npublic 1.09089\n\nTuned5 cat\nCV 1.0446 (0.0007)\npublic 1.09073\n\nStacking (rf, xgb, lgb, ext)>lgb\nCV 1.0455 (0.0007)\npublic 1.08811\n\nStacking1 (xgb, lgb, cat)>lgb\nCV 1.0450 (0.0008)\npublic 1.08605\n\nStacking2 (xgb2, lgb, cat)>cat\nCV 1.0448 (0.0008)\npublic 1.08766\n\nStacking3 (xgb2, lgb, cat)>xgb2\nCV 1.0458 (0.0008)\npublic 1.08729\n\nStacking4 (xgb2, lgb, cat2)>cat\nCV 1.0447 (0.0007)\npublic 1.08679\n\nStacking5 (xgb2, lgb, cat2)>cats5\nCV 1.0443 (0.0008)\npublic 1.08685\n\nStacking6 (xgb, lgb, cat)>lgbs6\nCV 1.0443 (0.0007)\npublic 1.08604\n\nStacking7 (xgb3, lgb3, cat)>lgbs7\nCV 1.0443 (0.0008)\npublic 1.08641\n\nStacking8 (xgb2, lgb, cat2)>lgbs8\nCV 1.0444 (0.0007)\npublic 1.08592\n\nStacking9 (xgb4, lgb5, cat4)>lgbs9\nCV 1.0439 (0.0008)\npublic 1.08613\n\nStacking10 (Stacking9 with no features input to meta model)\nCV 1.0440 (0.0007)\npublic 1.08674\n\nStacking11 (xgb5, lgb7, cat5)>lgbs11\nCV 1.0436 (0.0008)\npublic 1.08627\n\n\nrf = RandomForestClassifier(min_samples_split = 5,\n                            min_samples_leaf = 5,\n                            max_depth = None,\n                            bootstrap = True,\n                            n_jobs=-1,\n                            criterion = \"entropy\",\n                            n_estimators=500,\n                            max_features = 12,\n                            random_state = 42)\n\nxgb1 = XGBClassifier(learning_rate = 0.1,\n                        colsample_bytree = 0.5,\n                        max_depth = 10,\n                        min_child_weight=5,\n                       gamma=0.001,\n                       subsample=0.9,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n                       \nxgb2 = XGBClassifier(n_estimators=110,\n                        learning_rate = 0.5,\n                        colsample_bytree = 0.13,\n                       max_depth = 2,\n                        min_child_weight=5,\n                       gamma=0.001,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n                       \n                       \nxgb3 = XGBClassifier(n_estimators=250,\n                        learning_rate = 0.06,\n                        colsample_bytree = 0.4,\n                       max_depth = 6,\n                        min_child_weight=5,\n                       subsample=0.75,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       random_state=42)\n\nxgb4 = XGBClassifier(n_estimators=130, \n                        learning_rate = 0.5,\n                        colsample_bytree = 0.13,\n                        max_depth = 2,\n                        min_child_weight=7, \n                       gamma=0.001,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\nxgb5 = XGBClassifier( n_estimators=200,\n                        learning_rate = 0.5,\n                       colsample_bytree = 0.1,\n                       max_depth = 2,\n                        min_child_weight=5,\n                      gamma=0.005,\n                       subsample=0.7,\n                       objective='multi:softprob',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       reg_alpha=5,\n                         reg_lambda = 0.3,\n                         eval_metric = 'mlogloss',\n                       random_state=42)\n                       \nlgb = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    max_depth=6,\n                       learning_rate=0.1, \n                       n_estimators=220,\n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.7,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \nlgb2 = LGBMClassifier(objective='multiclass', \n                       num_leaves=2,\n                    max_depth=1,\n                       learning_rate=0.5, \n                       n_estimators=550,\n                      max_bin=25, \n                       bagging_fraction=0.6,\n                       bagging_freq=8, \n                       bagging_seed=8,\n                      feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \nlgb3 =  LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=7, \n                    max_depth=4,\n                       learning_rate=0.066, \n                       n_estimators=200,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\nlgb4 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    max_depth=6,\n                       learning_rate=0.1, \n                       n_estimators=250, \n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.5,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\nlgb5 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    min_data_in_leaf=19, \n                    max_depth=6,\n                       learning_rate=0.1, \n                      n_estimators=310, \n                       max_bin=80, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\nlgb6 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    min_data_in_leaf=19, \n                    max_depth=5,\n                      learning_rate=0.1, \n                      n_estimators=310, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                           lambda_l2 = 0.003,\n                           min_gain_to_split = 0.0001,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\nlgb7 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    min_data_in_leaf=19, \n                    max_depth=5,\n                      learning_rate=0.1, \n                     n_estimators=500, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                          lambda_l1 = 9,\n                           lambda_l2 = 0.003,\n                           min_gain_to_split = 0.0001,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n                   \next = ExtraTreesClassifier(  min_samples_split = 5,\n                            min_samples_leaf = 5,\n                            max_depth = 15,\n                            bootstrap = True,\n                            n_jobs=-1,\n                            n_estimators=10,\n                            max_features = 20,\n                            random_state = 42,\n                            criterion = 'entropy')\n                            \n\ncat = CatBoostClassifier(n_estimators=500,\n                           learning_rate=0.3,\n                           max_depth=2,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.5,\n                            min_data_in_leaf=5,\n                            verbose=0)\n                            \n                            \ncat2 = CatBoostClassifier(n_estimators=550,\n                           learning_rate=0.5,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                            verbose=0)\n                            \n                            \ncat3 =   CatBoostClassifier(n_estimators=250,\n                           learning_rate=0.1,\n                           max_depth=6,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=3,\n                            verbose=0)\n\ncat4 = CatBoostClassifier(n_estimators=600,\n                           learning_rate=0.6,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                            verbose=0)\n\ncat5 = CatBoostClassifier(n_estimators=600,\n                           learning_rate=0.6,\n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.4,\n                            min_data_in_leaf=5,\n                               bagging_temperature = 0.2,\n                             sampling_frequency = 'PerTreeLevel',\n                               reg_lambda = 3,\n                            verbose=0)\n\n\ncats5 = CatBoostClassifier(n_estimators=450, \n                           learning_rate=0.1, \n                           max_depth=1,\n                           loss_function='MultiClass',\n                          random_state=17,\n                          thread_count=-1,\n                            colsample_bylevel=0.5,\n                            min_data_in_leaf=5,\n                            verbose=0)\n                            \n                            \nlgbs6 = LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                    max_depth=6,\n                       learning_rate=0.03, \n                       n_estimators=160, \n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.7,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \n                   \nlgbs7 = LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=7, \n                    max_depth=4,\n                       learning_rate=0.05, \n                       n_estimators=100,\n                       bagging_fraction=1,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \nlgbs8 = LGBMClassifier(objective='multiclass', \n                     min_data_in_leaf=3, \n                    max_depth=4,\n                       learning_rate=0.05, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \nlgbs9 =  LGBMClassifier(objective='multiclass', \n                       num_leaves=6,\n                   min_data_in_leaf=23, \n                    max_depth=3,\n                       learning_rate=0.05, \n                    n_estimators=270, \n                      max_bin=60, \n                    bagging_fraction=0.7, \n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \nlgbs10 = LGBMClassifier(objective='multiclass', \n                       num_leaves=4,\n                  min_data_in_leaf=400, \n                    max_depth=1, \n                     learning_rate=0.05, \n                   n_estimators=270, \n                      max_bin=60, \n                    bagging_fraction=0.5, \n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.15, \n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \nlgbs11 = LGBMClassifier(objective='multiclass', \n                       num_leaves=5,\n                    min_data_in_leaf=19, \n                    max_depth=4,\n                      learning_rate=0.1, \n                     n_estimators=180, \n                       max_bin=20, \n                      bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.1, \n                       feature_fraction_seed=8,\n                          lambda_l1 = 7,\n                           lambda_l2 = 0.1,\n                           min_gain_to_split = 0.01,\n                           metric = 'multi_logloss',\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n'''","metadata":{"id":"elegant-municipality","outputId":"2ae408e9-d5e5-426c-fcbb-8df6bdc7e3f5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional: Class 2 pre-modelling","metadata":{"id":"accessible-monster"}},{"cell_type":"markdown","source":"Try to do modelling in sequence that first trained on separating \"Class 2\" from others, and then classify Class 1, 3, 4 in the remaining block. Result not satisfactory.","metadata":{"id":"anticipated-silicon"}},{"cell_type":"code","source":"'''\n# Split features and labels\ntrain2_labels = train_labels.apply(lambda x: 'Class_2'  if x == 'Class_2' else 'Others')\ntrain2_features = train_features\ntrain2_labels.unique()\n'''","metadata":{"id":"senior-building","outputId":"5226ab70-1b65-4b76-b80c-c21c0692c6fc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrain134_labels = train.loc[train['target']!='Class_2']['target'].reset_index(drop=True)\ntrain134_features = train.loc[train['target']!='Class_2'].drop(['id','target'], axis=1).reset_index(drop=True)\ntrain134_labels.unique()\n'''","metadata":{"id":"addressed-modification","outputId":"025cda85-7280-4809-a959-dad0763e685f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Light Gradient Boosting Regressor\nlgbp2 =  LGBMClassifier(objective='binary', \n                      min_data_in_leaf=3, \n                    max_depth=4,\n                      learning_rate=0.066, \n                       n_estimators=250,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n#lgbp2_model = lgbp2.fit(train2_features, train2_labels)\n#lgbp2_pred = lgbp2_model.predict_proba(test_features)\n\n'''","metadata":{"id":"driven-danger","outputId":"2456eb3b-b830-4497-861a-4a07cfc78158"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Light Gradient Boosting Regressor\nlgbp134 =  LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=3, \n                    max_depth=4,\n                      learning_rate=0.1, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.4,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n\n#lgbp134_model = lgbp134.fit(train134_features, train134_labels)\n#lgbp134_pred = lgbp134_model.predict_proba(test_features)\n'''","metadata":{"id":"crucial-multimedia","outputId":"015d06c5-9dad-4212-bc0c-5058d9997f84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\nnum_est = [0.3,0.4,0.5]\n\nvc_model = LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=3, \n                    max_depth=4,\n                      learning_rate=0.1, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.4,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n\n# Calculate accuracy on training and test set using the\n# parameter with 3-fold cross validation\ntrain_score, test_score = validation_curve( vc_model,\n                                X = train134_features, y = train134_labels, \n                                param_name = 'feature_fraction', \n                                param_range = num_est, cv = 2, scoring=\"neg_log_loss\", n_jobs=-1\n                            )\n \n# Calculating mean and standard deviation of training score\nmean_train_score = -np.mean(train_score, axis = 1)\nstd_train_score = np.std(train_score, axis = 1)\n \n# Calculating mean and standard deviation of testing score\nmean_test_score = -np.mean(test_score, axis = 1)\nstd_test_score = np.std(test_score, axis = 1)\n \n# Plot mean accuracy scores for training and testing scores\nplt.plot(num_est, mean_train_score,\n     label = \"Training Score\", color = 'b')\nplt.plot(num_est, mean_test_score,\n   label = \"Cross Validation Score\", color = 'g')\n \n# Creating the plot\nplt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"LogLoss\")\nplt.tight_layout()\nplt.legend(loc = 'best')\nplt.show()\n'''","metadata":{"id":"junior-waterproof","outputId":"a746eb10-0ee2-4456-b2ba-82b4569278dc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mean_test_score","metadata":{"id":"potential-illness"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Read in sample_submission dataframe\nsubmission[['Class_1']] = lgbp2_pred[:,1]*lgbp134_pred[:,0]\nsubmission[['Class_2']] =lgbp2_pred[:,0]\nsubmission[['Class_3']] = lgbp2_pred[:,1]*lgbp134_pred[:,1]\nsubmission[['Class_4']] = lgbp2_pred[:,1]*lgbp134_pred[:,2]\n\nsubmission.head()\n'''","metadata":{"id":"editorial-receptor","outputId":"034a9959-5bfa-4dc3-8d9b-e1fe5e2dee24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission[['Class_1','Class_2','Class_3','Class_4']].sum(axis=1).unique()","metadata":{"id":"solid-hawaiian"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission.to_csv(\"submission_p2model.csv\", index=False)","metadata":{"id":"handmade-activity"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nBasic lgb\npublic 1.09213\n\nTuned lgbp2>lgbp134\npublic 1.08981\n\nlgbp2 = LGBMClassifier(objective='binary', \n                      min_data_in_leaf=3, \n                    max_depth=4,\n                      learning_rate=0.066, \n                       n_estimators=250,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n                   \n                   \n lgbp134 =   LGBMClassifier(objective='multiclass', \n                      min_data_in_leaf=3, \n                    max_depth=4,\n                      learning_rate=0.1, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                      feature_fraction=0.4,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)                \n\n'''","metadata":{"id":"upper-dancing","outputId":"5adf801b-f92d-4e0f-802e-1fd8e467a2ca"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional2: Summation of features","metadata":{"id":"operating-muscle"}},{"cell_type":"markdown","source":"Combinatorial summation of the 50 features as new features. The features dimension is exploding with high computation cost. Result is not satisfactory, and not good enough to justify the higher complexity.","metadata":{"id":"vocational-baptist"}},{"cell_type":"code","source":"'''\ntrainsum_features = train_features\ntestsum_features = test_features\n'''","metadata":{"id":"revised-impact","outputId":"bca9e213-1db9-490c-dbea-6c58d1c984fd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\nfor i in range(0,49):\n    a='feature_'+str(i)\n    \n    for j in range(i+1,50): \n        b='feature_'+str(j)\n        trainsum_features[str(i)+\"_\"+str(j)+\"_sum\"] = train_features[[a,b]].sum(axis=1)\n        '''","metadata":{"id":"joined-affect","outputId":"928c1730-be08-40c9-8dd8-c9c62dc055b1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\nfor i in range(0,49):\n    a='feature_'+str(i)\n    \n    for j in range(i+1,50): \n        b='feature_'+str(j)\n        testsum_features[str(i)+\"_\"+str(j)+\"_sum\"] = test_features[[a,b]].sum(axis=1)\n        '''","metadata":{"id":"nuclear-standing","outputId":"82aa644d-97d1-4ae8-815d-524f086c4e2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\n# Light Gradient Boosting Regressor\nlgb =  LGBMClassifier(objective='multiclass',                     \n                            verbose=-1,\n                       random_state=17,\n                      importance_type='gain',\n                   n_jobs=-1)\n\nlgb_model = lgb.fit(trainsum_features, train_labels)\nlgb_pred = lgb_model.predict_proba(testsum_features)\n'''","metadata":{"id":"legislative-surgery","outputId":"1c451c4f-24d9-41c0-9d85-18ecbe3d44e3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\narr = np.stack((lgb.feature_name_, lgb.feature_importances_) ,axis=1)\nm = [row[0] for row in arr if row[1] != \"0.0\"]\n'''","metadata":{"id":"apparent-price","outputId":"6b6b075f-7c69-43b1-d3aa-dc733b3381f9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrainsum_features = trainsum_features[m]\ntestsum_features = testsum_features[m]\n'''","metadata":{"id":"harmful-weight","outputId":"fc97c66f-1a5b-4eba-c7c4-2ab63fc67ac7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Read in the dataset as a dataframe\ntrainsum_features = pd.read_csv(\"../input/tps-may-2021/trainsum_features.csv\")\ntestsum_features = pd.read_csv(\"../input/tps-may-2021/testsum_features.csv\")\n'''","metadata":{"id":"aging-unemployment","outputId":"53d2f9be-e897-4aa6-e6ad-6dbc83102f24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrainsum_features.to_csv(\"trainsum_features.csv\", index=False)\ntestsum_features.to_csv(\"testsum_features.csv\", index=False)\n'''","metadata":{"id":"contemporary-liver","outputId":"8855867c-212f-4a67-a40e-3fc387f9844b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Light Gradient Boosting Regressor\nlgbsum =  LGBMClassifier(objective='multiclass', \n                     min_data_in_leaf=1, \n                    max_depth=4,\n                      learning_rate=0.07, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                     feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\nlgbsum_model = lgbsum.fit(trainsum_features, train_labels)\nlgbsum_pred = lgbsum_model.predict_proba(testsum_features)\n'''","metadata":{"id":"affected-lesbian","outputId":"bef75c00-1f78-4a00-d58d-8603f41ae1e1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Setup cross validation folds\nkf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Define error metrics\ndef loss(y, y_pred):\n    return np.sqrt(log_loss(y, y_pred))\n\ndef cvsum_loss(model, X = trainsum_features):\n    loss = np.sqrt(-cross_val_score(model, X, train_labels, scoring=\"neg_log_loss\", cv=kf, n_jobs=-1))\n    return (loss)\n    '''","metadata":{"id":"toxic-client","outputId":"3b52dc90-2bc8-4105-ca71-d307f300248a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nscores = {}\n\nscore = cvsum_loss(lgbsum)\nprint(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['rf'] = (score.mean(), score.std())\n'''","metadata":{"id":"interim-grain","outputId":"7d310546-0651-4d9e-c92e-e30adbfda677"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n%%time\nnum_est = [0.05,0.07,0.1]\n\nvc_model = LGBMClassifier(objective='multiclass', \n                     min_data_in_leaf=1, \n                    max_depth=4,\n                      learning_rate=0.07, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                     feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n\n\n# Calculate accuracy on training and test set using the\n# parameter with 3-fold cross validation\ntrain_score, test_score = validation_curve( vc_model,\n                                X = trainsum_features, y = train_labels, \n                                param_name = 'learning_rate', \n                                param_range = num_est, cv = 2, scoring=\"neg_log_loss\", n_jobs=-1\n                            )\n \n# Calculating mean and standard deviation of training score\nmean_train_score = -np.mean(train_score, axis = 1)\nstd_train_score = np.std(train_score, axis = 1)\n \n# Calculating mean and standard deviation of testing score\nmean_test_score = -np.mean(test_score, axis = 1)\nstd_test_score = np.std(test_score, axis = 1)\n \n# Plot mean accuracy scores for training and testing scores\nplt.plot(num_est, mean_train_score,\n     label = \"Training Score\", color = 'b')\nplt.plot(num_est, mean_test_score,\n   label = \"Cross Validation Score\", color = 'g')\n \n# Creating the plot\nplt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"LogLoss\")\nplt.tight_layout()\nplt.legend(loc = 'best')\nplt.show()\n'''","metadata":{"id":"colored-threshold","outputId":"d391ee2f-8242-408f-be6c-676fe7205cf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mean_test_score","metadata":{"id":"willing-documentation"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Read in sample_submission dataframe\nsubmission[['Class_1', 'Class_2', 'Class_3', 'Class_4']] = lgbsum_pred\nsubmission.head()\n'''","metadata":{"id":"tough-darkness","outputId":"b386a91d-2130-44af-e683-330fb88b93f8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission.to_csv(\"submission_sumlgb.csv\", index=False)","metadata":{"id":"intense-toolbox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nBasic lgb\nCV 1.0478 (0.0006)\npublic 1.09072\n\nTuned lgbsum\nCV 1.0462 (0.0007)\npublic 1.09009\n\nlgbsum = LGBMClassifier(objective='multiclass', \n                     min_data_in_leaf=1, \n                    max_depth=4,\n                      learning_rate=0.07, \n                       n_estimators=100,\n                       bagging_fraction=0.75,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                     feature_fraction=0.3,\n                       feature_fraction_seed=8,\n                            verbose=-1,\n                       random_state=17,\n                   n_jobs=-1)\n'''","metadata":{"id":"guilty-jungle","outputId":"2088e23f-2527-4e8b-b62a-96e9e35c4ccd"},"execution_count":null,"outputs":[]}]}