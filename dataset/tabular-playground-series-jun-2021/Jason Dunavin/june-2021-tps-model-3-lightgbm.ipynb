{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T19:23:03.601102Z","iopub.execute_input":"2021-06-11T19:23:03.601475Z","iopub.status.idle":"2021-06-11T19:23:03.611351Z","shell.execute_reply.started":"2021-06-11T19:23:03.601442Z","shell.execute_reply":"2021-06-11T19:23:03.609987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# June 2021 TPS - Model 3: LightGBM with tuning\nI previously tried XGBoost with tuning, with poor results. You'll see this in older versions of this notebook. I didn't want to spam notebooks out here so I just relegated my previous attempts to prior versions.\n\nSee my [previous notebook](https://www.kaggle.com/jdunavin/june-2021-tps-eda-and-modeling) for EDA and a basic model.","metadata":{}},{"cell_type":"markdown","source":"## Load and clean the data","metadata":{}},{"cell_type":"code","source":"train_X = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/train.csv\")\ntest_X = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:23:11.196912Z","iopub.execute_input":"2021-06-11T19:23:11.197295Z","iopub.status.idle":"2021-06-11T19:23:13.055549Z","shell.execute_reply.started":"2021-06-11T19:23:11.19726Z","shell.execute_reply":"2021-06-11T19:23:13.054794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Any duplicates? - Yes, drop them all - we won't make any assumption which one is right\ndupes = train_X.drop(['id','target'], axis=1).duplicated(keep=False)\nprint(dupes.value_counts())\ndropthese = list(dupes[dupes == True].index)\ntrain_X = train_X.drop(dropthese)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:23:14.016158Z","iopub.execute_input":"2021-06-11T19:23:14.016674Z","iopub.status.idle":"2021-06-11T19:23:14.469382Z","shell.execute_reply.started":"2021-06-11T19:23:14.016627Z","shell.execute_reply":"2021-06-11T19:23:14.468412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load some libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold # For creating folds\nfrom sklearn.metrics import log_loss # Evaluation metrics\n\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:23:16.761961Z","iopub.execute_input":"2021-06-11T19:23:16.762335Z","iopub.status.idle":"2021-06-11T19:23:16.768981Z","shell.execute_reply.started":"2021-06-11T19:23:16.762304Z","shell.execute_reply":"2021-06-11T19:23:16.767646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not a lot of commentary there because it turned out much worse. Not sure what, if anything, I might have done to make that turn out better. Let's try the non-random-forest version.","metadata":{}},{"cell_type":"markdown","source":"## LightGBM\nStill have quite a bit of learning to do on this one.","metadata":{}},{"cell_type":"code","source":"train_X[\"kfold\"] = -1\ndf = train_X.sample(frac=1,random_state=14000605).reset_index(drop=True)\ny = df.target\nkf = StratifiedKFold(n_splits=5)\nfor f, (t_,v_) in enumerate(kf.split(X=df,y=y)):\n  df.loc[v_,\"kfold\"] = f","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:23:21.175886Z","iopub.execute_input":"2021-06-11T19:23:21.176283Z","iopub.status.idle":"2021-06-11T19:23:21.979099Z","shell.execute_reply.started":"2021-06-11T19:23:21.176241Z","shell.execute_reply":"2021-06-11T19:23:21.978156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# My previous best guess - redone with stratified k-fold.\nmodel_lgb = LGBMClassifier(\n    objective = 'multiclass',\n    reg_lambda = 10,\n    learning_rate = 0.1,\n    max_depth = 4,\n    seed = 14000605,\n    colsample_bytree = 0.5,\n    subsample = 0.9,\n    is_unbalance = True\n    )\nlogloss = []\nlgbm_pred = 0\nfor f in range(5): # Looping around 5 folds\n    \n    #Splitting the data into train and validation set\n    train = df[df.kfold!= f].reset_index(drop=True) \n    valid = df[df.kfold== f].reset_index(drop=True)\n    \n    #Creating X_train and y_train\n    X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_train = train.target\n    X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_valid = valid.target\n    X_test = test_X.drop([\"id\"], axis=1)\n    \n    \n    #Fitting the model\n    model_lgb.fit(X_train,y_train)\n    \n    #Predicting for valid and test datasets\n    valid_preds = model_lgb.predict_proba(X_valid)\n    lgbm_pred += model_lgb.predict_proba(X_test)/5\n    \n    #Calculating log loss\n    logloss.append(log_loss(y_valid,valid_preds))\n    \nprint(logloss)\nprint(sum(logloss)/len(logloss))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:23:22.960583Z","iopub.execute_input":"2021-06-11T19:23:22.961408Z","iopub.status.idle":"2021-06-11T19:25:48.565428Z","shell.execute_reply.started":"2021-06-11T19:23:22.961361Z","shell.execute_reply":"2021-06-11T19:25:48.564308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = sorted(train_X.target.value_counts().index)\nlgbpreds = model_lgb.predict(test_X.drop('id',axis=1), num_iteration=model_lgb.best_iteration_)\nlgbprods = model_lgb.predict_proba(test_X.drop('id',axis=1)) # used for submission\nsubmission = pd.DataFrame(lgbprods, columns=class_labels, index=test_X.index + 200000)\nsubmission.index.name = 'id'\nsubmission.head()\nsubmission.to_csv('submission_lgbtune.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:25:48.567054Z","iopub.execute_input":"2021-06-11T19:25:48.567495Z","iopub.status.idle":"2021-06-11T19:25:53.728408Z","shell.execute_reply.started":"2021-06-11T19:25:48.567453Z","shell.execute_reply":"2021-06-11T19:25:53.727346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def optimize(trial):\n    param = {\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'objective': 'multiclass',\n        #'metric' : ''\n        \"random_state\" : 42}\n\n\n\n    model = LGBMClassifier(**param)\n    logloss = []\n    for f in range(5):\n        train = df[df.kfold!= f].reset_index(drop=True)\n        valid = df[df.kfold== f].reset_index(drop=True)\n\n        X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n        y_train = train[\"target\"]\n        X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n        y_valid = valid[\"target\"]\n\n        model.fit(X_train,y_train)\n        pred = model.predict_proba(X_valid)\n        fold_logloss = log_loss(y_valid, pred)\n        logloss.append(fold_logloss)\n    \n    return np.mean(logloss)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:25:57.872272Z","iopub.execute_input":"2021-06-11T19:25:57.872654Z","iopub.status.idle":"2021-06-11T19:25:57.882425Z","shell.execute_reply.started":"2021-06-11T19:25:57.872625Z","shell.execute_reply":"2021-06-11T19:25:57.881353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(optimize, n_trials=15)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T19:26:02.378894Z","iopub.execute_input":"2021-06-11T19:26:02.379242Z","iopub.status.idle":"2021-06-11T20:04:53.61128Z","shell.execute_reply.started":"2021-06-11T19:26:02.379199Z","shell.execute_reply":"2021-06-11T20:04:53.610251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T20:09:45.189622Z","iopub.execute_input":"2021-06-11T20:09:45.189983Z","iopub.status.idle":"2021-06-11T20:09:45.195117Z","shell.execute_reply.started":"2021-06-11T20:09:45.189951Z","shell.execute_reply":"2021-06-11T20:09:45.194363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best guess after learning new tricks\nmodel_lgb2 = LGBMClassifier(\n    lambda_l1= 4.2986828029788605e-08, \n    lambda_l2= 2.290124579576187, \n    num_leaves= 6, \n    feature_fraction= 0.9832712273137326, \n    bagging_fraction= 0.41331491154011984, \n    bagging_freq= 1, \n    min_child_samples= 73,\n    seed = 14000605\n    )\nlogloss = []\nlgbm_pred = 0\nfor f in range(5): # Looping around 5 folds\n    \n    #Splitting the data into train and validation set\n    train = df[df.kfold!= f].reset_index(drop=True) \n    valid = df[df.kfold== f].reset_index(drop=True)\n    \n    #Creating X_train and y_train\n    X_train = train.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_train = train.target\n    X_valid = valid.drop([\"id\",\"target\", \"kfold\"], axis=1)\n    y_valid = valid.target\n    X_test = test_X.drop([\"id\"], axis=1)\n    \n    \n    #Fitting the model\n    model_lgb2.fit(X_train,y_train)\n    \n    #Predicting for valid and test datasets\n    valid_preds = model_lgb2.predict_proba(X_valid)\n    lgbm_pred += model_lgb2.predict_proba(X_test)/5\n    \n    #Calculating log loss\n    logloss.append(log_loss(y_valid,valid_preds))\n    \nprint(logloss)\nprint(sum(logloss)/len(logloss))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T20:13:32.882397Z","iopub.execute_input":"2021-06-11T20:13:32.882966Z","iopub.status.idle":"2021-06-11T20:14:30.86108Z","shell.execute_reply.started":"2021-06-11T20:13:32.882932Z","shell.execute_reply":"2021-06-11T20:14:30.860132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = sorted(train_X.target.value_counts().index)\nlgbpreds = model_lgb2.predict(test_X.drop('id',axis=1), num_iteration=model_lgb.best_iteration_)\nlgbprods = model_lgb2.predict_proba(test_X.drop('id',axis=1)) # used for submission\nsubmission = pd.DataFrame(lgbprods, columns=class_labels, index=test_X.index + 200000)\nsubmission.index.name = 'id'\nsubmission.head()\nsubmission.to_csv('submission_lgboptuna.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T20:17:10.641568Z","iopub.execute_input":"2021-06-11T20:17:10.641957Z","iopub.status.idle":"2021-06-11T20:17:15.202688Z","shell.execute_reply.started":"2021-06-11T20:17:10.641923Z","shell.execute_reply":"2021-06-11T20:17:15.201716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}