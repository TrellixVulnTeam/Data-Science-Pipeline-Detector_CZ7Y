{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-24T07:06:58.617593Z","iopub.execute_input":"2021-06-24T07:06:58.618029Z","iopub.status.idle":"2021-06-24T07:06:58.631846Z","shell.execute_reply.started":"2021-06-24T07:06:58.617938Z","shell.execute_reply":"2021-06-24T07:06:58.630832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')\n\nX_train = train.iloc[:,1:-1]\ny_train = train.iloc[:,-1]\nX_test = test.iloc[:,1:]\nX_train.shape, y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:06:58.633507Z","iopub.execute_input":"2021-06-24T07:06:58.633864Z","iopub.status.idle":"2021-06-24T07:07:00.66651Z","shell.execute_reply.started":"2021-06-24T07:06:58.633831Z","shell.execute_reply":"2021-06-24T07:07:00.665228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\ndef loss(y_true,y_pred):\n    # gt is short for ground -truth\n    # it is a matrix in which each line has only one 1 and others are 0\n    # you can get it from get_dummies(df.target)\n    # \n    # pred is from clf.pred_proba()\n    \n    assert y_pred.shape == y_true.shape\n    \n    sum = 0\n    for i in y_pred * y_true:\n        sum += np.log(\n            min( max(10e-15, np.sum(i)), 1 - 10e-15)\n        )\n    return sum * (-1) * (1/y_pred.shape[0])\n\ndef my_scorer(y_true, y_pred_proba):\n    y_true_mat = pd.get_dummies(y_true).values\n    error = loss(y_true_mat, y_pred_proba)\n    return error\n\nthe_scorer = make_scorer(my_scorer, needs_proba=True, greater_is_better=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:07:00.668219Z","iopub.execute_input":"2021-06-24T07:07:00.668526Z","iopub.status.idle":"2021-06-24T07:07:01.697798Z","shell.execute_reply.started":"2021-06-24T07:07:00.668497Z","shell.execute_reply":"2021-06-24T07:07:01.696863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"clf.get_params()\n```\n{'boosting_type': 'gbdt',\n 'class_weight': None,\n 'colsample_bytree': 1.0,\n 'importance_type': 'split',\n 'learning_rate': 0.1,\n 'max_depth': -1,\n 'min_child_samples': 20,\n 'min_child_weight': 0.001,\n 'min_split_gain': 0.0,\n 'n_estimators': 100,\n 'n_jobs': -1,\n 'num_leaves': 31,\n 'objective': None,\n 'random_state': None,\n 'reg_alpha': 0.0,\n 'reg_lambda': 0.0,\n 'silent': True,\n 'subsample': 1.0,\n 'subsample_for_bin': 200000,\n 'subsample_freq': 0}\n ```","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:15:15.47772Z","iopub.execute_input":"2021-06-24T03:15:15.478083Z","iopub.status.idle":"2021-06-24T03:15:15.485108Z","shell.execute_reply.started":"2021-06-24T03:15:15.478051Z","shell.execute_reply":"2021-06-24T03:15:15.484126Z"}}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\n\n# grid = GridSearchCV(\n#     estimator=lgb.LGBMClassifier(),\n#     param_grid={\n#         'n_estimators':[800],\n#         'learning_rate':[0.01]\n#     },\n#     scoring=the_scorer,\n#     verbose=3\n# )\n# grid.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:07:01.699099Z","iopub.execute_input":"2021-06-24T07:07:01.699374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for result in grid.cv_results_:\n#     print(result, grid.cv_results_[result])\n# grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = lgb.LGBMClassifier(n_estimators=800, learning_rate=0.01)\nclf.fit(X_train, y_train)\ny_pred = clf.predict_proba(X_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clf = lgb.LGBMClassifier()\n# clf.fit(X_train, y_train)\n\n# y_pred = clf.predict_proba(X_test)\n# y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv')\nsubmit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submit = pd.DataFrame()\n# my_submit = pd.DataFrame(y_pred,columns=submit.columns[1:])\nmy_submit['id'] = submit.id\nmy_submit[submit.columns[1:]] = y_pred\nmy_submit\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submit.to_csv('my_submit_lgbm-02.csv',index=False)\nreload = pd.read_csv('my_submit_lgbm-02.csv')\nreload\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}