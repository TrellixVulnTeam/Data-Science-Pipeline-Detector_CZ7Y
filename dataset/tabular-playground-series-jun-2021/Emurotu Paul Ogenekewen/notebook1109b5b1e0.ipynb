{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T16:36:56.253985Z","iopub.execute_input":"2022-02-16T16:36:56.254509Z","iopub.status.idle":"2022-02-16T16:36:56.267264Z","shell.execute_reply.started":"2022-02-16T16:36:56.254458Z","shell.execute_reply":"2022-02-16T16:36:56.266398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wine_quality_df = pd.read_csv(\"/kaggle/input/wine-quality-dataset/WineQT.csv\", index_col = \"Id\")\nwine_quality_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:56.269681Z","iopub.execute_input":"2022-02-16T16:36:56.269913Z","iopub.status.idle":"2022-02-16T16:36:56.300845Z","shell.execute_reply.started":"2022-02-16T16:36:56.269885Z","shell.execute_reply":"2022-02-16T16:36:56.299851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wine_quality_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:56.302055Z","iopub.execute_input":"2022-02-16T16:36:56.302265Z","iopub.status.idle":"2022-02-16T16:36:56.315123Z","shell.execute_reply.started":"2022-02-16T16:36:56.302238Z","shell.execute_reply":"2022-02-16T16:36:56.314278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check distribution of quality\n\nwine_quality_df[\"quality\"].hist()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:56.31659Z","iopub.execute_input":"2022-02-16T16:36:56.317482Z","iopub.status.idle":"2022-02-16T16:36:56.538978Z","shell.execute_reply.started":"2022-02-16T16:36:56.317437Z","shell.execute_reply":"2022-02-16T16:36:56.538105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(wine_quality_df.drop(\"quality\", axis = 1), \n                                                    wine_quality_df[\"quality\"],\n                                                    test_size = 0.2, stratify = wine_quality_df[\"quality\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:56.541027Z","iopub.execute_input":"2022-02-16T16:36:56.541264Z","iopub.status.idle":"2022-02-16T16:36:56.55025Z","shell.execute_reply.started":"2022-02-16T16:36:56.541235Z","shell.execute_reply":"2022-02-16T16:36:56.549405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's plot relationship between wine quality and each input feature\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (20, 20))\n\nfor n, column in enumerate(X_train.columns):\n    plt.subplot(4, 3, n + 1)\n    sns.stripplot(x = y_train, y = X_train[column], size = 1.5)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:56.551516Z","iopub.execute_input":"2022-02-16T16:36:56.55216Z","iopub.status.idle":"2022-02-16T16:36:58.54Z","shell.execute_reply.started":"2022-02-16T16:36:56.552114Z","shell.execute_reply":"2022-02-16T16:36:58.539119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#polynomial regression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n\npolynomial_regressor = Pipeline([\n    (\"poly_features\", PolynomialFeatures(2)),\n    (\"lin_reg\", LinearRegression())\n])\n\npolynomial_regressor.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:58.541227Z","iopub.execute_input":"2022-02-16T16:36:58.541461Z","iopub.status.idle":"2022-02-16T16:36:58.571935Z","shell.execute_reply.started":"2022-02-16T16:36:58.541432Z","shell.execute_reply":"2022-02-16T16:36:58.570738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_predictions = polynomial_regressor.predict(X_test)\nsimple_predictions[:5], y_test[:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:58.577933Z","iopub.execute_input":"2022-02-16T16:36:58.578436Z","iopub.status.idle":"2022-02-16T16:36:58.603156Z","shell.execute_reply.started":"2022-02-16T16:36:58.578383Z","shell.execute_reply":"2022-02-16T16:36:58.601359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ridge regression model uses l2 regularization to reduce overfitting.\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\n\nridge_regressor = Pipeline([\n    (\"poly_features\", PolynomialFeatures(2)),\n    (\"scaler\", StandardScaler()),\n    (\"ridge_reg\", Ridge(alpha = 1))\n])\n\nridge_regressor.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:36:58.606507Z","iopub.execute_input":"2022-02-16T16:36:58.609664Z","iopub.status.idle":"2022-02-16T16:36:58.664227Z","shell.execute_reply.started":"2022-02-16T16:36:58.60961Z","shell.execute_reply":"2022-02-16T16:36:58.663271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.model_selection import GridSearchCV\n\nridge_regressor = Pipeline([\n    (\"poly_features\", PolynomialFeatures()),\n    (\"scaler\", StandardScaler()),\n    (\"ridge_reg\", Ridge())\n])\n\nparam_grid = {'poly_features__degree' : [1, 2, 3, 4],\n              'ridge_reg__alpha' : [1.0, 10.0, 100.0, 1000.0]}\n\nsearch = GridSearchCV(estimator = ridge_regressor,\n                     param_grid = param_grid, \n                     verbose = 1, cv = 5,\n                     scoring = \"neg_mean_absolute_error\")\n\nsearch.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:37:17.690757Z","iopub.execute_input":"2022-02-16T16:37:17.691037Z","iopub.status.idle":"2022-02-16T16:37:22.587458Z","shell.execute_reply.started":"2022-02-16T16:37:17.691008Z","shell.execute_reply":"2022-02-16T16:37:22.586579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search.best_params_, search.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:37:40.161213Z","iopub.execute_input":"2022-02-16T16:37:40.161492Z","iopub.status.idle":"2022-02-16T16:37:40.167823Z","shell.execute_reply.started":"2022-02-16T16:37:40.161463Z","shell.execute_reply":"2022-02-16T16:37:40.166817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}