{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# XGBoost Implementation: 1.75670","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport xgboost as xgb\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-10T01:31:50.755398Z","iopub.execute_input":"2021-06-10T01:31:50.755786Z","iopub.status.idle":"2021-06-10T01:31:50.83259Z","shell.execute_reply.started":"2021-06-10T01:31:50.755758Z","shell.execute_reply":"2021-06-10T01:31:50.831509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import all the requisite sklearn packages\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"execution":{"iopub.status.busy":"2021-06-10T01:31:51.410398Z","iopub.execute_input":"2021-06-10T01:31:51.410755Z","iopub.status.idle":"2021-06-10T01:31:51.537824Z","shell.execute_reply.started":"2021-06-10T01:31:51.410726Z","shell.execute_reply":"2021-06-10T01:31:51.536858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Loading and Formatting\ntrain = pd.read_csv('../input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jun-2021/test.csv')\nfeatures = ['feature_'+str(i) for i in range(71)]\n\n# Label Encoder to transform the targets to numerical values for use in XGB\nle = LabelEncoder()\n\n# Standard Scaler for use with PCA\nss = StandardScaler()\ntrain['target'] = le.fit_transform(train['target'])\ntrain_pca = pd.DataFrame(columns=features,index=range(200000))\ntrain_pca.loc[:,features] = ss.fit_transform(train[features])\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T01:31:52.752963Z","iopub.execute_input":"2021-06-10T01:31:52.753319Z","iopub.status.idle":"2021-06-10T01:31:57.857754Z","shell.execute_reply.started":"2021-06-10T01:31:52.753292Z","shell.execute_reply":"2021-06-10T01:31:57.856639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PCA - Shows little covariance between the different features\npca = PCA()\ndata = pca.fit_transform(train_pca[features])\ntrain_pca[features]=data\npca.explained_variance_ratio_","metadata":{"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2021-06-09T22:38:34.074987Z","iopub.execute_input":"2021-06-09T22:38:34.075303Z","iopub.status.idle":"2021-06-09T22:38:35.377294Z","shell.execute_reply.started":"2021-06-09T22:38:34.075269Z","shell.execute_reply":"2021-06-09T22:38:35.376174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating data sets for all possible uses\n# Train test splits for impromptu testing\nX_train,X_test,y_train,y_test = train_test_split(train[features],train['target'])\n\n# DataMatrices for using XGB without the SKLearn wrapper\ndtrain = xgb.DMatrix(data=train[features],label=train['target'])\ndtest = xgb.DMatrix(data=X_test)\n\n# Sanity Check\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T01:32:05.684009Z","iopub.execute_input":"2021-06-10T01:32:05.684352Z","iopub.status.idle":"2021-06-10T01:32:06.142746Z","shell.execute_reply.started":"2021-06-10T01:32:05.684324Z","shell.execute_reply":"2021-06-10T01:32:06.141805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross Validation - Implemented in Colab using GPU\n\n# estimator = xgb.XGBClassifier(num_class=9,objective='multi:softmax',use_label_encoder=False,verbosity=1)\n# grid = {'max_depth': [1, 5, 10, 15, 20],\n#        'learning_rate': np.logspace(-3,1,5),\n#        'n_estimators': [100, 200, 300, 500, 700],\n#        'reg_lambda': np.append(np.logspace(-4,0,5),[0]),\n#        'reg_alpha': np.append(np.logspace(-4,0,5),[0])}\n# clf = RandomizedSearchCV(estimator,grid,verbose=4,cv=3)\n# clf.fit(train[features],train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T22:38:35.857146Z","iopub.execute_input":"2021-06-09T22:38:35.85918Z","iopub.status.idle":"2021-06-09T22:38:35.864114Z","shell.execute_reply.started":"2021-06-09T22:38:35.859133Z","shell.execute_reply":"2021-06-09T22:38:35.863354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting a model using the best parameters found in the random grid search\n# This may take a while without a GPU :(\n\"\"\"\nBest Parameters:\n{'learning_rate': 0.01,\n 'max_depth': 5,\n 'n_estimators': 300,\n 'reg_alpha': 0.01,\n 'reg_lambda': 1.0}\n {reg_lambda=0.0001,\n reg_alpha=0.0001,\n n_estimators=300,\n max_depth=2,\n learning_rate=0.1}\n learning_rate=0.1,max_depth=5,n_estimators=100,reg_alpha=0.01,reg_lambda=0.1\n\"\"\"\nmodel = xgb.XGBClassifier(num_class=9,\n                          objective='multi:softmax',\n                          use_label_encoder=False,\n                          learning_rate=0.1,\n                          max_depth=5,\n                          n_estimators=100,\n                          reg_alpha=0.01,\n                          reg_lambda=0.1,\n                          verbosity=0)\n\n# Fit the model, you can change the \nmodel.fit(train[features],train['target'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T22:38:39.035728Z","iopub.execute_input":"2021-06-09T22:38:39.036086Z","iopub.status.idle":"2021-06-09T22:41:52.627268Z","shell.execute_reply.started":"2021-06-09T22:38:39.036058Z","shell.execute_reply":"2021-06-09T22:41:52.626372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting a confusion matrix to visualize the training results\n\ny_pred = model.predict(train[features])\n\ncm = confusion_matrix(train['target'], y_pred, labels=[i for i in range(9)])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                               display_labels=[i for i in range(9)])\n\ndisp.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the training label distribution\nplt.hist(train['target'],bins=9);","metadata":{"execution":{"iopub.status.busy":"2021-06-08T07:09:10.3746Z","iopub.status.idle":"2021-06-08T07:09:10.375058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Submission Predictions and save them\ntest_pred = model.predict_proba(test[features])\nsubmission = pd.DataFrame()\nsubmission['id'] = test['id']\nsubmission[['Class_'+str(i) for i in range(1,10)]] = test_pred\nsubmission.to_csv('submission.csv',index=False)\n\n# Display Submitted Label distributions\npred_vals = model.predict(test[features])\nplt.hist(pred_vals,bins=9);","metadata":{"execution":{"iopub.status.busy":"2021-06-09T22:41:52.628889Z","iopub.execute_input":"2021-06-09T22:41:52.629299Z","iopub.status.idle":"2021-06-09T22:41:56.825428Z","shell.execute_reply.started":"2021-06-09T22:41:52.629266Z","shell.execute_reply":"2021-06-09T22:41:56.824178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare to a ~very~ simple NN\n\n\"\"\"\nThe MLP classifier should perform a little worse\nthan the tuned XGB Classifier\nbased on the constriants of the presented parameter grid.\n\"\"\"\n\nfrom sklearn.neural_network import MLPClassifier\nmodel = MLPClassifier(hidden_layer_sizes=(9,9,9))\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T01:35:51.830993Z","iopub.execute_input":"2021-06-10T01:35:51.831707Z","iopub.status.idle":"2021-06-10T01:38:22.429301Z","shell.execute_reply.started":"2021-06-10T01:35:51.831645Z","shell.execute_reply":"2021-06-10T01:38:22.428281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}