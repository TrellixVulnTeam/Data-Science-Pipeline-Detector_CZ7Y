{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n<h1 style = \"font-size:25px; font-family:cursive ; font-weight : bold; color : #020296; text-align: center; border-radius: 10px 15px;\"> üöÄ Fast Logistic Regression with Intel(R) Extension for Scikit-learn  </h1>\n<br>\n\nFor classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. We use it to fit models and search for optimal parameters, but‚ÄØscikit-learn‚ÄØsometimes works for hours, if not days. Speeding up this process is something anyone who uses Scikit-learn would be interested in.\n\nI want to show you how to get results faster without changing the code. To do this, we will use another Python library,‚ÄØ**[Intel(R) Extension for Scikit-learn](https://github.com/intel/scikit-learn-intelex)**. It accelerates Scikit-learn and does not require you changing the code written for scikit-learn.\n\nI will show you how to speed up your kernel from **14 minutes to 2 minutes** without changes of code!","metadata":{"execution":{"iopub.status.busy":"2021-06-20T18:03:07.679988Z","iopub.execute_input":"2021-06-20T18:03:07.680341Z","iopub.status.idle":"2021-06-20T18:03:07.687254Z","shell.execute_reply.started":"2021-06-20T18:03:07.680306Z","shell.execute_reply":"2021-06-20T18:03:07.685841Z"}}},{"cell_type":"markdown","source":"# üî® Installing Intel(R) Extension for Scikit-learn\n\nLet's try to use Intel(R) Extension for Scikit-learn. First, download it. Package also avaialble in conda - please refer to details https://github.com/intel/scikit-learn-intelex","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex -q --progress-bar off","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport time\nimport pandas as pd\nimport optuna\nfrom sklearn.pipeline import Pipeline\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-20T20:08:21.442919Z","iopub.execute_input":"2021-06-20T20:08:21.44342Z","iopub.status.idle":"2021-06-20T20:08:22.505827Z","shell.execute_reply.started":"2021-06-20T20:08:21.443338Z","shell.execute_reply":"2021-06-20T20:08:22.504853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìã Reading data and splitting on training and validation datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jun-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-jun-2021/sample_submission.csv')\n\ny_train = train['target']\nx_train = train.drop(['id','target'], axis=1)\nx_test = test.drop(['id'], axis=1)\n\nfrom sklearn.model_selection import train_test_split\nx_train_sub, x_val, y_train_sub, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\nprint(x_train_sub.shape, x_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:08:22.509443Z","iopub.execute_input":"2021-06-20T20:08:22.50972Z","iopub.status.idle":"2021-06-20T20:08:24.879962Z","shell.execute_reply.started":"2021-06-20T20:08:22.509694Z","shell.execute_reply":"2021-06-20T20:08:24.878893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üîç Defining model and parameters for search optimal model\n\nAs Intel(R) Extension for Scikit-learn have pretty fast Logistic Regression now - I can try running optune for with a sufficiently large search to find the optimal model. For prepocessing I use Quantile transformer and for it I will also select the most optimal number of quantiles.","metadata":{}},{"cell_type":"code","source":"def logreg_model(params, x_train, y_train, x_test):\n    from sklearn.preprocessing import QuantileTransformer\n    from sklearn.linear_model import LogisticRegression\n\n    params_quantile = {\n        'n_quantiles': params['n_quantiles'],\n        'random_state': 46,\n    }\n    params_logreg = {\n        'C': params['C'],\n    }\n    \n    pipe = Pipeline([\n        ('quantile', QuantileTransformer(**params_quantile)),\n        ('logreg',   LogisticRegression(**params_logreg))\n    ])\n    pipe.fit(x_train, y_train)\n    y_pred = pipe.predict_proba(x_test)\n    return y_pred\n\ndef objective(trial):\n    from sklearn.metrics import log_loss\n    \n    params = {\n        'n_quantiles': trial.suggest_int('n_quantiles', 3, 10),\n        'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n    }\n    \n    y_pred = logreg_model(params, x_train_sub, y_train_sub, x_val)\n    return log_loss(y_val, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:08:24.881541Z","iopub.execute_input":"2021-06-20T20:08:24.881925Z","iopub.status.idle":"2021-06-20T20:08:24.889706Z","shell.execute_reply.started":"2021-06-20T20:08:24.881883Z","shell.execute_reply":"2021-06-20T20:08:24.888459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚ö° Logistic Regression Optuna Optimization with Intel(R) Extension for Scikit-learn","metadata":{}},{"cell_type":"markdown","source":"We can take advantage of the performance optimizations of Intel Extension for Scikit-learn by adding just two lines of code before the usual scikit-learn imports:","metadata":{}},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:08:24.89159Z","iopub.execute_input":"2021-06-20T20:08:24.892032Z","iopub.status.idle":"2021-06-20T20:08:25.096315Z","shell.execute_reply.started":"2021-06-20T20:08:24.891991Z","shell.execute_reply":"2021-06-20T20:08:25.095377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Intel(R) Extension for Scikit-learn patching affects performance of specific Scikit-learn functionality. Refer to the [list of supported algorithms and parameters](https://intel.github.io/scikit-learn-intelex/algorithms.html) for details. In cases when unsupported parameters are used, the package fallbacks into original Scikit-learn.","metadata":{}},{"cell_type":"code","source":"%%time\nt0 = time.time()\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())\nstudy.optimize(objective, n_trials=40, show_progress_bar=True)\nt1 = time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-20T20:08:25.097889Z","iopub.execute_input":"2021-06-20T20:08:25.098301Z","iopub.status.idle":"2021-06-20T20:11:00.93217Z","shell.execute_reply.started":"2021-06-20T20:08:25.098254Z","shell.execute_reply":"2021-06-20T20:11:00.93116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Time for search optimal params: {t1 - t0} sec\")\nprint(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:11:00.936332Z","iopub.execute_input":"2021-06-20T20:11:00.936628Z","iopub.status.idle":"2021-06-20T20:11:00.943444Z","shell.execute_reply.started":"2021-06-20T20:11:00.9366Z","shell.execute_reply":"2021-06-20T20:11:00.942229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚è≥ Logistic Regression Optuna Optimization with original Scikit-learn\n\nIn order to cancel Intel(R) Extension for Scikit-learn optimizations to run the original Scikit-learn, need to use *unpatch_sklearn*:","metadata":{}},{"cell_type":"code","source":"from sklearnex import unpatch_sklearn\nunpatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:11:00.945397Z","iopub.execute_input":"2021-06-20T20:11:00.945755Z","iopub.status.idle":"2021-06-20T20:11:00.954649Z","shell.execute_reply.started":"2021-06-20T20:11:00.94571Z","shell.execute_reply":"2021-06-20T20:11:00.953756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nt0 = time.time()\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"minimize\",\n                            pruner=optuna.pruners.HyperbandPruner())\nstudy.optimize(objective, n_trials=40, show_progress_bar=True)\nt1 = time.time()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-20T20:11:00.95805Z","iopub.execute_input":"2021-06-20T20:11:00.95836Z","iopub.status.idle":"2021-06-20T20:25:33.695658Z","shell.execute_reply.started":"2021-06-20T20:11:00.958331Z","shell.execute_reply":"2021-06-20T20:25:33.694639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Time for search optimal params: {t1 - t0} sec\")\nprint(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:25:33.696933Z","iopub.execute_input":"2021-06-20T20:25:33.697198Z","iopub.status.idle":"2021-06-20T20:25:33.704313Z","shell.execute_reply.started":"2021-06-20T20:25:33.697171Z","shell.execute_reply":"2021-06-20T20:25:33.703062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The search optimal parameters for Logistic Regression model for original Logistic Regression took **almost 14 minutes**. However, the same search using Intel(R) Extension for Scikit-learn took **a little over two minutes**. And most importantly, **the optimal model and quality on the validation dataset are equal**.","metadata":{}},{"cell_type":"markdown","source":"# üéØ Fit final model and submit result","metadata":{}},{"cell_type":"code","source":"patch_sklearn()\ny_pred = logreg_model(study.best_params, x_train, y_train, x_test)\nsample_submission[['Class_1','Class_2', 'Class_3', 'Class_4','Class_5','Class_6', 'Class_7', 'Class_8', 'Class_9']] = y_pred\nsample_submission.to_csv(f'logreg.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T20:25:33.70565Z","iopub.execute_input":"2021-06-20T20:25:33.70624Z","iopub.status.idle":"2021-06-20T20:25:40.415596Z","shell.execute_reply.started":"2021-06-20T20:25:33.706193Z","shell.execute_reply":"2021-06-20T20:25:40.41448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìú Conclusions\n\nWith Intel(R) Extension for Scikit-learn patching you can:\n\n- Use your scikit-learn code for training and inference without modification;\n- Train and predict scikit-learn models and get more time for experiments;\n- Get the same quality of predictions.\n\n*Please, upvote if you like.*","metadata":{"execution":{"iopub.status.busy":"2021-06-20T19:00:52.053656Z","iopub.execute_input":"2021-06-20T19:00:52.054022Z","iopub.status.idle":"2021-06-20T19:00:53.639534Z","shell.execute_reply.started":"2021-06-20T19:00:52.053985Z","shell.execute_reply":"2021-06-20T19:00:53.63856Z"}}}]}