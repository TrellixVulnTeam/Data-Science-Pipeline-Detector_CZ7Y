{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download Data And Basic Setting ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nprint(os.getcwd())\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-09T18:11:32.264363Z","iopub.execute_input":"2021-06-09T18:11:32.264747Z","iopub.status.idle":"2021-06-09T18:11:32.273125Z","shell.execute_reply.started":"2021-06-09T18:11:32.264714Z","shell.execute_reply":"2021-06-09T18:11:32.272361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle competitions download -c tabular-playground-series-jun-2021\n# !unzip ./tabular-playground-series-jun-2021.zip -d /kaggle/working/input/tabular_202106data","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:33.368741Z","iopub.execute_input":"2021-06-09T18:11:33.369414Z","iopub.status.idle":"2021-06-09T18:11:33.373604Z","shell.execute_reply.started":"2021-06-09T18:11:33.369374Z","shell.execute_reply":"2021-06-09T18:11:33.372559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '/kaggle/input/tabular-playground-series-jun-2021'\nos.listdir(file_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:34.332573Z","iopub.execute_input":"2021-06-09T18:11:34.332974Z","iopub.status.idle":"2021-06-09T18:11:34.3404Z","shell.execute_reply.started":"2021-06-09T18:11:34.332941Z","shell.execute_reply":"2021-06-09T18:11:34.339175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import missingno as missno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom  contextlib import contextmanager\nimport time\nfrom datetime import datetime\nfrom functools import wraps\npd.set_option('display.max_rows', 200)\n\n@contextmanager\ndef timer(msg):\n    st = datetime.now()\n    yield\n    cost = datetime.now() - st\n    print(f'{msg} Done. It cost {cost}')\n\n    \ndef clock(func):\n    @wraps(func)\n    def clocked(*args, **kwargs):\n        st = datetime.now()\n        res = func(*args, **kwargs)\n        cost_ = datetime.now() - st\n        print(f'{func.__name__} cost {cost_}')\n        return res\n    return clocked","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:53.857023Z","iopub.execute_input":"2021-06-09T18:11:53.857556Z","iopub.status.idle":"2021-06-09T18:11:53.866319Z","shell.execute_reply.started":"2021-06-09T18:11:53.857515Z","shell.execute_reply":"2021-06-09T18:11:53.865374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(file_path, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(file_path, 'test.csv'))\nsub_df = pd.read_csv(os.path.join(file_path, 'sample_submission.csv'))\n\nneed_columns = [col for col in train_df.columns if 'feature' in col] + ['target']","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:54.311008Z","iopub.execute_input":"2021-06-09T18:11:54.311375Z","iopub.status.idle":"2021-06-09T18:11:55.774827Z","shell.execute_reply.started":"2021-06-09T18:11:54.311344Z","shell.execute_reply":"2021-06-09T18:11:55.773733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Explore (simple) ","metadata":{}},{"cell_type":"code","source":"## missing\nmissno.matrix(train_df[need_columns], figsize=(12, 6))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:55.776852Z","iopub.execute_input":"2021-06-09T18:11:55.777429Z","iopub.status.idle":"2021-06-09T18:11:59.261Z","shell.execute_reply.started":"2021-06-09T18:11:55.777383Z","shell.execute_reply":"2021-06-09T18:11:59.259897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## target \nplt.figure(figsize=(16,8))\ntrain_df['target'].value_counts().plot.pie(autopct='%3.1f%%', pctdistance=0.7, wedgeprops=dict(linewidth=2,width=0.5,edgecolor='w'))\n# help(train_df[need_columns].describe().T.style)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:59.263302Z","iopub.execute_input":"2021-06-09T18:11:59.263759Z","iopub.status.idle":"2021-06-09T18:11:59.519624Z","shell.execute_reply.started":"2021-06-09T18:11:59.263709Z","shell.execute_reply":"2021-06-09T18:11:59.518488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## data overview\ndef zero_rate(series_):\n    return np.mean(series_ == 0)\n\nwith timer('data_over_view'):\n    overview_columns = [i for i in need_columns if 'feat' in i]\n    desc_df = train_df[overview_columns].describe().T\n    nunique_df = pd.DataFrame(train_df[overview_columns].nunique()).rename(columns = {0: 'nunique'})\n    \n    train_df['gp_fake'] = '1'\n    zero_df = train_df[overview_columns+['gp_fake']].groupby('gp_fake').agg(zero_rate).T.rename(columns = {'1': 'zero_rate'})\n    range_df = train_df[overview_columns+['gp_fake']].groupby('gp_fake').agg(np.ptp).T.rename(columns = {'1': 'max_min_range'})\n    train_df.drop(columns='gp_fake', inplace=True)\n    exp_df = desc_df.merge(nunique_df, left_index=True, right_index=True)\\\n                    .merge(range_df, left_index=True, right_index=True)\\\n                    .merge(zero_df, left_index=True, right_index=True)\n    \n    del nunique_df, desc_df, range_df, zero_df\n    display(exp_df.style.format('{:.2f}',subset=['mean', 'std', 'zero_rate']).bar('std',vmin=0)\\\n                    .highlight_max('nunique').highlight_min('nunique')\\\n                    .background_gradient('Greens',subset='max_min_range')\\\n                    .bar('zero_rate', vmin=0, vmax=1).highlight_max('zero_rate')\n           )","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:11:59.521237Z","iopub.execute_input":"2021-06-09T18:11:59.521541Z","iopub.status.idle":"2021-06-09T18:12:01.788265Z","shell.execute_reply.started":"2021-06-09T18:11:59.521512Z","shell.execute_reply":"2021-06-09T18:12:01.787272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corr\nfrom sklearn.preprocessing import LabelEncoder\nlb = LabelEncoder()\ntrain_df['target_encode'] = lb.fit_transform(train_df['target'])\n\nneed_columns = overview_columns + ['target_encode']\n\nwith timer('Get corr df'):\n    corr_df = train_df[need_columns+['target']].corr(method='spearman')\n\nwith timer('Get mask matrix'):\n    mask = np.triu(np.ones_like(corr_df))\n    mask_small = (mask + (np.abs(corr_df.values) > 0.01)).astype(bool)\n    mask_big = (mask + (np.abs(corr_df.values) < 0.2)).astype(bool)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:01.789517Z","iopub.execute_input":"2021-06-09T18:12:01.789876Z","iopub.status.idle":"2021-06-09T18:12:19.629991Z","shell.execute_reply.started":"2021-06-09T18:12:01.789844Z","shell.execute_reply":"2021-06-09T18:12:19.628276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 12))\nsns.heatmap(corr_df, mask=mask_small) #, annot=True, fmt='.3f')\nplt.show()\n\n\nplt.figure(figsize=(16, 12))\nsns.heatmap(corr_df, mask=mask_big) #, annot=True, fmt='.2f')\nplt.show()\n\n\nplt.figure(figsize=(16, 8))\ncorr_df.iloc[:-1, -1].sort_values().plot.bar()\nplt.title('target & featues')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:19.63143Z","iopub.execute_input":"2021-06-09T18:12:19.631728Z","iopub.status.idle":"2021-06-09T18:12:22.872735Z","shell.execute_reply.started":"2021-06-09T18:12:19.631699Z","shell.execute_reply":"2021-06-09T18:12:22.871717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"feature 17 low corr & min nunique & max zero rate\n\nwe may drop the features","metadata":{}},{"cell_type":"markdown","source":"## test vs train","metadata":{}},{"cell_type":"code","source":"def class_unique_plot(df, columns, traget, axe):\n    if len(traget) == 0:\n        df[columns].nunique().plot(ax=axe)\n        plt.show()\n        return None\n\n    gp = df[[traget]+columns].groupby(traget)\n    for name, tmp_df in gp:\n        tmp_df.nunique().plot(ax=axe, label=name)\n    \n    plt.legend()\n    plt.show()\n    \n    \nfig, axes = plt.subplots(figsize=(18, 4))\nclass_unique_plot(train_df, overview_columns, 'target', axe=axes)\n\nfig, axes = plt.subplots(figsize=(18, 4))\nclass_unique_plot(train_df, overview_columns, '', axe=axes)\n\nfig, axes = plt.subplots(figsize=(18, 4))\nclass_unique_plot(test_df, overview_columns, '', axe=axes)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:22.875266Z","iopub.execute_input":"2021-06-09T18:12:22.875572Z","iopub.status.idle":"2021-06-09T18:12:24.305635Z","shell.execute_reply.started":"2021-06-09T18:12:22.875541Z","shell.execute_reply":"2021-06-09T18:12:24.304641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(figsize=(18, 4))\nclass_unique_plot(train_df.loc[train_df.target_encode.isin([5, 7]), :], overview_columns, 'target', axe=axes)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:24.308151Z","iopub.execute_input":"2021-06-09T18:12:24.308618Z","iopub.status.idle":"2021-06-09T18:12:24.732451Z","shell.execute_reply.started":"2021-06-09T18:12:24.308552Z","shell.execute_reply":"2021-06-09T18:12:24.731206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = pd.DataFrame(train_df.loc[train_df.target_encode.isin([5]), :].nunique())\\\n.merge(pd.DataFrame(train_df.loc[train_df.target_encode.isin([7]), :].nunique()), left_index=True, right_index=True)\na['diff'] =  a['0_y'] - a['0_x']\ndisplay(a.style.bar('diff',vmin=0))\n\nfrequnce_add_col = ['feature_60', 'feature_15', 'feature_28', 'feature_61', 'feature_62']","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:24.734181Z","iopub.execute_input":"2021-06-09T18:12:24.734611Z","iopub.status.idle":"2021-06-09T18:12:24.94826Z","shell.execute_reply.started":"2021-06-09T18:12:24.734545Z","shell.execute_reply":"2021-06-09T18:12:24.94752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generator Features","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n@clock\ndef low_freqence_detector(df, vars_to_agg, agg_threshold=0.999):\n    \"\"\"\n    将低频值归为一类\n    \"\"\"\n    replace_dict = {}\n    for col in tqdm(vars_to_agg):\n        a_cumsum = df[col].value_counts(normalize=True).cumsum()\n        value_count_series = df[col].value_counts()\n        will_be_replaced_values = value_count_series[a_cumsum >= agg_threshold].index.tolist()\n        n = len(will_be_replaced_values)\n        replace_value = min(will_be_replaced_values)\n        tmp_dict = (will_be_replaced_values, replace_value)\n        replace_dict[col] = tmp_dict\n    return replace_dict\n\ndef aggregate_low_freq_values(df, replace_dict):\n    df_out = df.copy(deep=True)\n    for replace_feat in tqdm(replace_dict):\n        need_replaced_values = replace_dict[replace_feat][0]\n        replace_value = replace_dict[replace_feat][1]\n        df_out.loc[df[replace_feat].isin(need_replaced_values), replace_feat] = replace_value\n    return df_out\n\ndef quick_agg_low_freq_values(tr_df, te_df, vars_to_agg, agg_threshold=0.999):\n    c = pd.concat([tr_df[vars_to_agg], te_df[vars_to_agg]], ignore_index=True)\n    replace_dict = low_freqence_detector(c, vars_to_agg, agg_threshold)\n    return aggregate_low_freq_values(tr_df, replace_dict), aggregate_low_freq_values(te_df, replace_dict)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:24.949197Z","iopub.execute_input":"2021-06-09T18:12:24.949479Z","iopub.status.idle":"2021-06-09T18:12:24.959912Z","shell.execute_reply.started":"2021-06-09T18:12:24.949452Z","shell.execute_reply":"2021-06-09T18:12:24.958798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overview_columns = [i for i in train_df.columns if 'feat' in i]\ntrain_df, test_df = quick_agg_low_freq_values(\n    train_df, test_df,\n    overview_columns\n)\n\n# for col_ in tqdm(frequnce_add_col):\n#     dict_ = train_df[col_].value_counts(normalize=True).to_dict()\n#     train_df[f'{col_}_freq'] = train_df[col_].map(dict_)\n#     test_df[f'{col_}_freq'] = test_df[col_].map(dict_)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:24.961702Z","iopub.execute_input":"2021-06-09T18:12:24.96213Z","iopub.status.idle":"2021-06-09T18:12:26.055864Z","shell.execute_reply.started":"2021-06-09T18:12:24.962082Z","shell.execute_reply":"2021-06-09T18:12:26.054573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5fold - LGB","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import log_loss, confusion_matrix\nfrom lightgbm import LGBMClassifier\n\n\ndef plot_heatmap(y_true, y_pred_prob):\n    y_pred = np.argmax(y_pred_prob, axis=1)\n    conf = confusion_matrix(y_true, y_pred)\n    conf = conf/ conf.sum(axis=1)\n    sns.heatmap(conf, annot=True, fmt='.2f')\n    plt.show()\n\n@clock\ndef cross_val(X, y, model, params, folds=5):\n    models = []\n    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n        print(f\"Fold: {fold}\")\n        x_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        x_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n\n        alg = model(**params)\n        alg.fit(x_train, y_train,\n                eval_set=[(x_test, y_test)],\n                early_stopping_rounds=100,\n                verbose=50)\n\n        pred = alg.predict_proba(x_test)\n        loss = log_loss(y_test, pred)\n        models.append((alg, loss))\n        plot_heatmap(y_test, pred)\n        print(f\"Log loss: {loss}\")\n        print(\"-\"*50)\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:26.057097Z","iopub.execute_input":"2021-06-09T18:12:26.057363Z","iopub.status.idle":"2021-06-09T18:12:26.068461Z","shell.execute_reply.started":"2021-06-09T18:12:26.057337Z","shell.execute_reply":"2021-06-09T18:12:26.067106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb_params = {\n#     'n_estimators': 1500, \n#      'max_depth': 8, \n#      'num_leaves': 25, \n#      'learning_rate': 0.05, \n#      'reg_lambda': 28,\n#      'subsample': 0.85, \n#      'colsample_bytree': 0.75, \n#       'n_jobs':-1\n# }\n# def f1_metric(preds, train_data):\n#     labels = train_data.get_label()\n#     return 'f1', f1_score(labels, preds, average='marco'), True\n\n# lgb_params = { # 1.75060\n#         'num_leaves': 14,\n#         'min_data_in_leaf': 52,\n#         'learning_rate': 0.04,\n#         'min_sum_hessian_in_leaf': 10.090025079493055,\n#         'bagging_fraction': 1.0,\n#         'bagging_freq': 5,\n#         'boost_from_average':'false',\n# #         'subsample': 0.6798695128633439,\n#         'colsample_bytree': 0.7727780074568463,\n#         'reg_alpha': 0.45606998421703593,\n#         'reg_lambda': 78.51759613930136,\n#         'min_gain_to_split': 0.13949386065204183,\n#         'max_depth': 6, \n#         'n_jobs': -1,\n#         'boosting_type': 'gbdt',\n#         'metric':'multi_logloss',\n#         'early_stopping_round' : 100,\n#         'n_estimators': 500,\n#         'tree_learner': 'serial',\n#     }\n\nlgb_params = {\n        'num_leaves': 10,\n        'min_data_in_leaf': 63,\n        'learning_rate': 0.05,\n        'min_sum_hessian_in_leaf': 8.140308692805194,\n        'bagging_fraction': 1.0,\n        'bagging_freq': 5,\n        'boost_from_average':'false',\n        'subsample': 0.749948437333368,\n        'colsample_bytree': 0.6168504947710284,\n         'reg_alpha': 0.227796749807186,\n         'reg_lambda': 70.2792417704872,\n        'min_gain_to_split': 0.4758826409257615,\n        'max_depth': 14, \n        'n_jobs': -1,\n        'boosting_type': 'gbdt',\n        'metric':'multi_logloss',\n        'early_stopping_round' : 100,\n        'n_estimators': 500,\n        'tree_learner': 'serial',\n    }\n\n\nX = train_df[overview_columns]\ny = train_df['target_encode']\n\nlgb_models = cross_val(X, y, LGBMClassifier, lgb_params)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:12:26.069729Z","iopub.execute_input":"2021-06-09T18:12:26.070011Z","iopub.status.idle":"2021-06-09T18:17:25.646818Z","shell.execute_reply.started":"2021-06-09T18:12:26.069983Z","shell.execute_reply":"2021-06-09T18:17:25.645032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# os.makedirs('./submit_data')\nos.listdir(); os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:17:25.648857Z","iopub.execute_input":"2021-06-09T18:17:25.649215Z","iopub.status.idle":"2021-06-09T18:17:25.655038Z","shell.execute_reply.started":"2021-06-09T18:17:25.649178Z","shell.execute_reply":"2021-06-09T18:17:25.654056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def models_merge(models_loss, pred_df):\n    n = 0\n    loss_d_sum = 0\n    for m, l in tqdm(models_loss, desc='MODEL PREDICT：'):\n        loss_d_sum += 1 / l\n        if n == 0:\n            pred_res = m.predict_proba(pred_df) * 1/l\n            n += 1\n            continue\n        n += 1\n        pred_res += m.predict_proba(pred_df) * 1/l\n    return pred_res / loss_d_sum","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:17:25.656433Z","iopub.execute_input":"2021-06-09T18:17:25.656807Z","iopub.status.idle":"2021-06-09T18:17:25.671586Z","shell.execute_reply.started":"2021-06-09T18:17:25.656738Z","shell.execute_reply":"2021-06-09T18:17:25.670476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with timer('submit data'):\n    pred = models_merge(lgb_models[1:], test_df[overview_columns])\n    now_ = datetime.now().strftime('%Y%m%d_%H_%M')\n    sub_df.loc[:, ['Class_1','Class_2', 'Class_3', 'Class_4','Class_5','Class_6', 'Class_7', 'Class_8', 'Class_9']] = np.clip(pred, 10**-15, 1-10**-15)\n    display(sub_df.head())\n    sub_df.to_csv(f'lgb_model_{now_}.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:18:18.591732Z","iopub.execute_input":"2021-06-09T18:18:18.592299Z","iopub.status.idle":"2021-06-09T18:18:38.945833Z","shell.execute_reply.started":"2021-06-09T18:18:18.592264Z","shell.execute_reply":"2021-06-09T18:18:38.944757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(), os.getcwd(), now_","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:18:38.947303Z","iopub.execute_input":"2021-06-09T18:18:38.947645Z","iopub.status.idle":"2021-06-09T18:18:38.954231Z","shell.execute_reply.started":"2021-06-09T18:18:38.947579Z","shell.execute_reply":"2021-06-09T18:18:38.953143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm ./submit_data/lgb_model_20210607_20_03.csv","metadata":{"execution":{"iopub.status.busy":"2021-06-07T20:52:17.267432Z","iopub.status.idle":"2021-06-07T20:52:17.271416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.environ['KAGGLE_USERNAME'] = \"scchuy\" # username from the json file \n# os.environ['KAGGLE_KEY'] = \"..\" #\n# !kaggle competitions submit -c tabular-playground-series-jun-2021 -f ./lgb_model_20210609_18_18.csv -m \"Message\"","metadata":{"execution":{"iopub.status.busy":"2021-06-09T18:18:50.319738Z","iopub.execute_input":"2021-06-09T18:18:50.320257Z","iopub.status.idle":"2021-06-09T18:18:55.532054Z","shell.execute_reply.started":"2021-06-09T18:18:50.320208Z","shell.execute_reply":"2021-06-09T18:18:55.531027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}