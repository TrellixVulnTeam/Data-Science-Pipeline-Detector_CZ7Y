{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-03T12:17:39.577387Z","iopub.execute_input":"2021-06-03T12:17:39.578103Z","iopub.status.idle":"2021-06-03T12:17:39.595385Z","shell.execute_reply.started":"2021-06-03T12:17:39.577958Z","shell.execute_reply":"2021-06-03T12:17:39.593733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly_express as px","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:39.901693Z","iopub.execute_input":"2021-06-03T12:17:39.902083Z","iopub.status.idle":"2021-06-03T12:17:42.141821Z","shell.execute_reply.started":"2021-06-03T12:17:39.902046Z","shell.execute_reply":"2021-06-03T12:17:42.14087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jun-2021/test.csv')\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:42.143266Z","iopub.execute_input":"2021-06-03T12:17:42.143547Z","iopub.status.idle":"2021-06-03T12:17:44.318902Z","shell.execute_reply.started":"2021-06-03T12:17:42.14352Z","shell.execute_reply":"2021-06-03T12:17:44.317912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.target.unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:44.321156Z","iopub.execute_input":"2021-06-03T12:17:44.321576Z","iopub.status.idle":"2021-06-03T12:17:44.345678Z","shell.execute_reply.started":"2021-06-03T12:17:44.321531Z","shell.execute_reply":"2021-06-03T12:17:44.344754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:44.347256Z","iopub.execute_input":"2021-06-03T12:17:44.347606Z","iopub.status.idle":"2021-06-03T12:17:44.401477Z","shell.execute_reply.started":"2021-06-03T12:17:44.347554Z","shell.execute_reply":"2021-06-03T12:17:44.400253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(train,'target', histnorm='percent')\nfig.show()\n#histnorm gives the format of y. By default it gives the count of value occurences of x variable","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:44.402674Z","iopub.execute_input":"2021-06-03T12:17:44.403117Z","iopub.status.idle":"2021-06-03T12:17:47.29994Z","shell.execute_reply.started":"2021-06-03T12:17:44.403087Z","shell.execute_reply":"2021-06-03T12:17:47.298824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(train,values='feature_48',names='target',title='Class Distribution')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\n#In px.pie, data visualized by the sectors of the pie is set in values. The sector labels are set in names.","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:47.301324Z","iopub.execute_input":"2021-06-03T12:17:47.301706Z","iopub.status.idle":"2021-06-03T12:17:48.529114Z","shell.execute_reply.started":"2021-06-03T12:17:47.301669Z","shell.execute_reply":"2021-06-03T12:17:48.528046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Class_6 and Class 8 alone rakes up >50% of the samples. While Class_5 and Class_4 have very less representation","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(train, x = 'feature_0', y= 'feature_7', \n                 hover_name='target', color='target')\nfig.show()\n#hovername gives the value of the point as we move our cursor over the plot","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:48.530489Z","iopub.execute_input":"2021-06-03T12:17:48.530819Z","iopub.status.idle":"2021-06-03T12:17:50.765717Z","shell.execute_reply.started":"2021-06-03T12:17:48.530788Z","shell.execute_reply":"2021-06-03T12:17:50.764698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation Plot","metadata":{}},{"cell_type":"code","source":"corr_mat = train.corr()\nmask = np.zeros_like(corr_mat)\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize=(20,20))\nsns.heatmap(corr_mat, annot=False, mask=mask,\n           linewidths=.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:50.767823Z","iopub.execute_input":"2021-06-03T12:17:50.768308Z","iopub.status.idle":"2021-06-03T12:17:56.84403Z","shell.execute_reply.started":"2021-06-03T12:17:50.768269Z","shell.execute_reply":"2021-06-03T12:17:56.842898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"some_columns = train.columns[:8]\nsns.pairplot(data=train[some_columns], kind='scatter')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:17:56.845754Z","iopub.execute_input":"2021-06-03T12:17:56.84619Z","iopub.status.idle":"2021-06-03T12:18:50.019109Z","shell.execute_reply.started":"2021-06-03T12:17:56.846156Z","shell.execute_reply":"2021-06-03T12:18:50.01806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns='id',inplace=True)  #not required","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:18:50.020427Z","iopub.execute_input":"2021-06-03T12:18:50.020721Z","iopub.status.idle":"2021-06-03T12:18:50.076327Z","shell.execute_reply.started":"2021-06-03T12:18:50.020691Z","shell.execute_reply":"2021-06-03T12:18:50.075306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:18:50.077533Z","iopub.execute_input":"2021-06-03T12:18:50.07782Z","iopub.status.idle":"2021-06-03T12:18:50.644962Z","shell.execute_reply.started":"2021-06-03T12:18:50.07779Z","shell.execute_reply":"2021-06-03T12:18:50.644014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(train.describe().T, x='mean', y= 'max', size='std',\n          hover_name='std', title='Describe Plot')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:18:50.646141Z","iopub.execute_input":"2021-06-03T12:18:50.646413Z","iopub.status.idle":"2021-06-03T12:18:51.265942Z","shell.execute_reply.started":"2021-06-03T12:18:50.646386Z","shell.execute_reply":"2021-06-03T12:18:51.264645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that mean and max are mostly positively correlated, except for a few features. Also, in general std dev is high for higher mean and max values.","metadata":{}},{"cell_type":"markdown","source":"# Unique Counts of each Feature","metadata":{}},{"cell_type":"code","source":"feat_unique_counts= np.zeros(len(train.columns[:-1]))\nc=0\nfor i in train.columns[:-1]:\n    feat_unique_counts[c]= train[i].nunique()\n    c+=1\n\nplt.figure(figsize=(20,8))\nplt.grid()\nplt.xticks(rotation=90)\nplt.stem(train.columns[:-1],feat_unique_counts)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:18:51.268157Z","iopub.execute_input":"2021-06-03T12:18:51.268657Z","iopub.status.idle":"2021-06-03T12:18:52.563294Z","shell.execute_reply.started":"2021-06-03T12:18:51.26861Z","shell.execute_reply":"2021-06-03T12:18:52.562162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's hard to distinguish numerical and categorical values as there are no binary/trinary features","metadata":{}},{"cell_type":"markdown","source":"# Visualising Zero & Non-Zero proportion in Features","metadata":{}},{"cell_type":"code","source":"features = train.columns[:-1]\nzero_counts, nonzero_counts= np.zeros(len(features)),np.zeros(len(features))\nc=0\n\nfor i in features:\n    zero_counts[c] = train[i].value_counts()[0]/len(train)\n    nonzero_counts[c] = 1-zero_counts[c]\n    c+=1\n    \nvaluecounts_df = pd.DataFrame(data=zero_counts,\n                             columns=['zeros'],\n                             index=features)\n\nvaluecounts_df['non-zeros'] = nonzero_counts\nvaluecounts_df","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:30:26.21781Z","iopub.execute_input":"2021-06-03T12:30:26.218227Z","iopub.status.idle":"2021-06-03T12:30:26.396777Z","shell.execute_reply.started":"2021-06-03T12:30:26.218192Z","shell.execute_reply":"2021-06-03T12:30:26.395565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['0','!0']\nexplode = [0.1,0]\n\nfig, ax = plt.subplots(15,5, figsize=(20,20))\nfor  i ,feature  in enumerate(features , 1):\n    plt.subplot(15, 5, i)\n    plt.pie(valuecounts_df.T[feature], labels=labels,explode=explode)\n    plt.xlabel(feature, fontsize=9)\n    \nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:30:35.892823Z","iopub.execute_input":"2021-06-03T12:30:35.893237Z","iopub.status.idle":"2021-06-03T12:30:42.48928Z","shell.execute_reply.started":"2021-06-03T12:30:35.893201Z","shell.execute_reply":"2021-06-03T12:30:42.48827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_diff = np.zeros(len(features))\nc=0\nfor i in features:\n    mean_diff[c] = train[i].mean()-test[i].mean()\n    c+=1\n    \npx.bar(mean_diff, hover_name=mean_diff,\n      title='Mean difference between train & test sets')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:32:25.340197Z","iopub.execute_input":"2021-06-03T12:32:25.340567Z","iopub.status.idle":"2021-06-03T12:32:25.467392Z","shell.execute_reply.started":"2021-06-03T12:32:25.340535Z","shell.execute_reply":"2021-06-03T12:32:25.466322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Difference in mean is quite small (<0.06 in almost all features). However train means > test means in almost all the features.","metadata":{}},{"cell_type":"code","source":"px.histogram(train, y='feature_12', x='target')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:43:10.422025Z","iopub.execute_input":"2021-06-03T12:43:10.422428Z","iopub.status.idle":"2021-06-03T12:43:12.48841Z","shell.execute_reply.started":"2021-06-03T12:43:10.422379Z","shell.execute_reply":"2021-06-03T12:43:12.48745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding the Classes","metadata":{}},{"cell_type":"code","source":"enc = {\n    'Class_1':0.0,\n    'Class_2':1.0,\n    'Class_3':2.0,\n    'Class_4':3.0,\n    'Class_5':4.0,\n    'Class_6':5.0,\n    'Class_7':6.0,\n    'Class_8':7.0,\n    'Class_9':8.0    \n}\n\ntrain.target.replace(to_replace=enc,inplace=True)\ntrain.target","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:18:52.91869Z","iopub.status.idle":"2021-06-03T12:18:52.919613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns='target').to_numpy()\ny = train.target.to_numpy()\ntest = test.drop(columns='id').to_numpy()\n\nX.shape,test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:18:52.921057Z","iopub.status.idle":"2021-06-03T12:18:52.921968Z"},"trusted":true},"execution_count":null,"outputs":[]}]}