{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'\npd.set_option('display.max_columns', 500)\nfrom zipfile import ZipFile ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/sberbank-russian-housing-market')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(ZipFile(\"../input/sberbank-russian-housing-market/train.csv.zip\").open('train.csv'), parse_dates=['timestamp'])\ntest_df = pd.read_csv(ZipFile(\"../input/sberbank-russian-housing-market/test.csv.zip\").open('test.csv'), parse_dates=['timestamp'])\nmacro_df = pd.read_csv(ZipFile(\"../input/sberbank-russian-housing-market/macro.csv.zip\").open('macro.csv'), parse_dates=['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"macro_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(train_df, macro_df, how=\"left\", on=\"timestamp\")\ntest_df = pd.merge(test_df, macro_df, how=\"left\", on=\"timestamp\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['price_doc'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.price_doc.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(train_df.price_doc.values, bins=50, kde=True)\nplt.xlabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A very long right tail. Since our metric is Root Mean Square Logarithmic error, let us plot the log of price_doc variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(np.log(train_df.price_doc.values), bins=50, kde=True)\nplt.xlabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_limit = np.percentile(train_df['price_doc'], 99)\nlower_limit = np.percentile(train_df['price_doc'], 1)\n\ntrain_df.loc[(train_df['price_doc'] > upper_limit), 'price_doc'] = upper_limit\ntrain_df.loc[(train_df['price_doc'] < lower_limit), 'price_doc'] = lower_limit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[(missing_df['missing_count'] > 0), :]\nmissing_df = missing_df.sort_values(by='missing_count')\nind = range(missing_df.shape[0])\n\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, missing_df['missing_count'], color=\"purple\")\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coverting the categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [col for col in train_df.columns if train_df[col].dtype == 'object']\n\nle = preprocessing.LabelEncoder()\n\nfor col in cat_cols:\n    train_df[col] = le.fit_transform(train_df[col].astype('str'))\n    test_df[col] = le.fit_transform(test_df[col].astype('str'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Floor:\n\nWe will see the count plot of floor variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x='floor', data=train_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('floor number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution is right skewed. There are some good drops in between (5 to 6, 9 to 10, 12 to 13, 17 to 18). Now let us see how the price changes with respect to floors.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = train_df.groupby(['floor'])['price_doc'].aggregate(np.median).reset_index()\nplt.figure(figsize=(12,8))\nsns.pointplot(x='floor', y='price_doc', data=temp_df)\nplt.ylabel('Median Price', fontsize=12)\nplt.xlabel('Floor number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows an overall increasing trend (individual houses seems to be costlier as well - check price of 0 floor houses). A sudden increase in the house price is also observed at floor 18.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Max floor:\n\nTotal number of floors in the building is one another important variable. So let us plot that one and see.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"max_floor\", data=train_df)\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Max floor number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how the median prices vary with the max floors.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.boxplot(x=\"max_floor\", y=\"price_doc\", data=train_df)\nplt.ylabel('Median Price', fontsize=12)\nplt.xlabel('Max Floor number', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also have some null values in the dataset. So one feature idea could be to use the count of nulls in the row.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# count null values of each row\ntrain_df['null_count'] = train_df.isnull().sum(axis=1)\ntest_df['null_count'] = test_df.isnull().sum(axis=1)\n\n# plot to check affect of null values on the pric_doc col, point plot shows only the mean (or other estimator) value,\nplt.figure(figsize=(20, 8))\nsns.pointplot(x='null_count', y='price_doc', data=train_df)\nplt.ylabel('price_doc', fontsize=12)\nplt.xlabel('null_count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let us impute the missing values with some value which is outside the range of values of the column, say -99.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.fillna(-99, inplace=True)\ntest_df.fillna(-99, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# year and month\ntrain_df['yearmonth'] = train_df['timestamp'].dt.year*100 + train_df['timestamp'].dt.month\ntest_df['yearmonth'] = test_df['timestamp'].dt.year*100 + test_df['timestamp'].dt.month\n\n# year and week\ntrain_df['yearweek'] = train_df['timestamp'].dt.year*100 + train_df['timestamp'].dt.weekofyear\ntest_df['yearweek'] = test_df['timestamp'].dt.year*100 + test_df['timestamp'].dt.weekofyear\n\n# year\ntrain_df['year'] = train_df['timestamp'].dt.year\ntest_df['year'] = test_df['timestamp'].dt.year\n\n# month of year\ntrain_df['month_of_year'] = train_df['timestamp'].dt.month\ntest_df['month_of_year'] = test_df['timestamp'].dt.month\n\n# week of year \ntrain_df[\"week_of_year\"] = train_df[\"timestamp\"].dt.weekofyear\ntest_df[\"week_of_year\"] = test_df[\"timestamp\"].dt.weekofyear\n\n# day of week \ntrain_df[\"day_of_week\"] = train_df[\"timestamp\"].dt.weekday\ntest_df[\"day_of_week\"] = test_df[\"timestamp\"].dt.weekday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.pointplot(x='yearweek', y='price_doc', data=train_df)\nplt.ylabel('price_doc', fontsize=12)\nplt.xlabel('yearweek', fontsize=12)\nplt.title('Median Price distribution by year and week_num')\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.pointplot(x='week_of_year', y='price_doc', data=train_df)\nplt.ylabel('price_doc', fontsize=12)\nplt.xlabel('week_of_year', fontsize=12)\nplt.title('Median Price distribution by week of year')\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.boxplot(x='month_of_year', y='price_doc', data=train_df)\nplt.ylabel('price_doc', fontsize=12)\nplt.xlabel('month_of_year', fontsize=12)\nplt.title('Median Price distribution by month_of_year')\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.boxplot(x='day_of_week', y='price_doc', data=train_df)\nplt.ylabel('price_doc', fontsize=12)\nplt.xlabel('day_of_week', fontsize=12)\nplt.title('Median Price distribution by day of week')\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ratio of living area to full area\ntrain_df[\"ratio_life_sq_full_sq\"] = train_df[\"life_sq\"] / np.maximum(train_df[\"full_sq\"].astype(\"float\"), 1)\ntest_df[\"ratio_life_sq_full_sq\"] = test_df[\"life_sq\"] / np.maximum(test_df[\"full_sq\"].astype(\"float\"),1)\n\ntrain_df.loc[(train_df[\"ratio_life_sq_full_sq\"] < 0), \"ratio_life_sq_full_sq\"] = 0\ntrain_df.loc[(train_df[\"ratio_life_sq_full_sq\"] > 1), \"ratio_life_sq_full_sq\"] = 1\n\ntest_df.loc[(test_df[\"ratio_life_sq_full_sq\"] < 0), \"ratio_life_sq_full_sq\"] = 0\ntest_df.loc[(test_df[\"ratio_life_sq_full_sq\"] > 1), \"ratio_life_sq_full_sq\"] = 1\n\n# ratio of kitchen area to living area \ntrain_df[\"ratio_kitch_sq_life_sq\"] = train_df[\"kitch_sq\"] / np.maximum(train_df[\"life_sq\"].astype(\"float\"),1)\ntest_df[\"ratio_kitch_sq_life_sq\"] = test_df[\"kitch_sq\"] / np.maximum(test_df[\"life_sq\"].astype(\"float\"),1)\n\ntrain_df.loc[(train_df[\"ratio_kitch_sq_life_sq\"] < 0), \"ratio_kitch_sq_life_sq\"] = 0\ntrain_df.loc[(train_df[\"ratio_kitch_sq_life_sq\"] > 1), \"ratio_kitch_sq_life_sq\"] = 1\n\ntest_df.loc[(test_df[\"ratio_kitch_sq_life_sq\"] < 0), \"ratio_kitch_sq_life_sq\"] = 0\ntest_df.loc[(test_df[\"ratio_kitch_sq_life_sq\"] > 1), \"ratio_kitch_sq_life_sq\"] = 1\n\n# ratio of kitchen area to full area #\ntrain_df[\"ratio_kitch_sq_full_sq\"] = train_df[\"kitch_sq\"] / np.maximum(train_df[\"full_sq\"].astype(\"float\"),1)\ntest_df[\"ratio_kitch_sq_full_sq\"] = test_df[\"kitch_sq\"] / np.maximum(test_df[\"full_sq\"].astype(\"float\"),1)\n\ntrain_df.loc[(train_df[\"ratio_kitch_sq_full_sq\"] < 0), \"ratio_kitch_sq_full_sq\"] = 0\ntrain_df.loc[(train_df[\"ratio_kitch_sq_full_sq\"] > 1), \"ratio_kitch_sq_full_sq\"] = 1\n\ntest_df.loc[(test_df[\"ratio_kitch_sq_full_sq\"] < 0), \"ratio_kitch_sq_full_sq\"] = 0\ntest_df.loc[(test_df[\"ratio_kitch_sq_full_sq\"] > 1), \"ratio_kitch_sq_full_sq\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.jointplot(x=train_df[\"ratio_life_sq_full_sq\"], y=np.log1p(train_df[\"price_doc\"]), size=10)\nplt.ylabel('Log of Price', fontsize=12)\nplt.xlabel('Ratio of living area to full area', fontsize=12)\nplt.title(\"Joint plot on log of living price to ratio_life_sq_full_sq\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.jointplot(x=train_df[\"ratio_life_sq_full_sq\"], y=np.log1p(train_df[\"price_doc\"]), kind='kde',size=10)\nplt.ylabel('Log of Price', fontsize=12)\nplt.xlabel('Ratio of kitchen area to living area', fontsize=12)\nplt.title(\"Joint plot on log of living price to ratio_kitch_sq_life_sq\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# floor of the house to the total number of floors in the house \ntrain_df[\"ratio_floor_max_floor\"] = train_df[\"floor\"] / train_df[\"max_floor\"].astype(\"float\")\ntest_df[\"ratio_floor_max_floor\"] = test_df[\"floor\"] / test_df[\"max_floor\"].astype(\"float\")\n\n# num of floor from top\ntrain_df[\"floor_from_top\"] = train_df[\"max_floor\"] - train_df[\"floor\"]\ntest_df[\"floor_from_top\"] = test_df[\"max_floor\"] - test_df[\"floor\"]\n\n# difference between full area and living area\ntrain_df[\"extra_sq\"] = train_df[\"full_sq\"] - train_df[\"life_sq\"]\ntest_df[\"extra_sq\"] = test_df[\"full_sq\"] - test_df[\"life_sq\"]\n\n# age of the building\ntrain_df[\"age_of_building\"] = train_df[\"build_year\"] - train_df[\"year\"]\ntest_df[\"age_of_building\"] = test_df[\"build_year\"] - test_df[\"year\"]\n\n# effect of school\ntrain_df[\"ratio_preschool\"] = train_df[\"children_preschool\"] / train_df[\"preschool_quota\"].astype(\"float\")\ntest_df[\"ratio_preschool\"] = test_df[\"children_preschool\"] / test_df[\"preschool_quota\"].astype(\"float\")\n\ntrain_df[\"ratio_school\"] = train_df[\"children_school\"] / train_df[\"school_quota\"].astype(\"float\")\ntest_df[\"ratio_school\"] = test_df[\"children_school\"] / test_df[\"school_quota\"].astype(\"float\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Price of the house could also be affected by the availability of other houses at the same time period. So creating a count variable on the number of houses at the given time period might help.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_by_dates(df, col):\n    temp_df = df.groupby(col)[\"id\"].aggregate(\"count\").reset_index()\n    temp_df.columns = [col, \"count_\" + col]\n    df = pd.merge(df, temp_df, on=col, how=\"left\")\n    return df\n\ntrain_df = count_by_dates(train_df, \"yearmonth\")\ntest_df = count_by_dates(test_df, \"yearmonth\")\n\ntrain_df = count_by_dates(train_df, \"yearweek\")\ntest_df = count_by_dates(test_df, \"yearweek\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\ntrain_y = np.log1p(train_df[\"price_doc\"])\n\ntest_X = test_df.drop([\"id\", \"timestamp\"] , axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this competition, the train and test set are from different time periods and so let us use the last 1 year as validation set for building our models and rest as model development set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_time = 201407\n\ndev_X = train_X[(train_X[\"yearmonth\"] < val_time)]\ndev_y = train_y[(train_X[\"yearmonth\"] < val_time)]\n\nval_X = train_X[(train_X[\"yearmonth\"] >= val_time)]\nval_y = train_y[(train_X[\"yearmonth\"] >= val_time)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dev_X.shape, dev_y.shape)\nprint(val_X.shape, val_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 4,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'min_child_weight':1,\n    'silent': 1,\n    'seed':0\n}\nnum_rounds = 100\n\nxgtrain = xgb.DMatrix(dev_X, dev_y, feature_names = dev_X.columns)\nxgtest = xgb.DMatrix(val_X, val_y, feature_names = val_X.columns)\nwatchlist = [(xgtrain, 'train'), (xgtest, 'test')]\nmodel = xgb.train(xgb_params, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}