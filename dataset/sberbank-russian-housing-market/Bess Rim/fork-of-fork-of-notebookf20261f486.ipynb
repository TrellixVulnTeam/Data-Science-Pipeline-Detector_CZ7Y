{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c01175f4-5ab4-1071-c9f1-419bbd4887f9"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3765b8ce-b464-5194-4a66-9a529597fa6f"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6221de4-ca3d-1973-b682-286a0abfdd1a"},"outputs":[],"source":"import numpy as np\nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.base import TransformerMixin\nfrom sklearn import metrics\n\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"train:\", train_df.shape)\nprint(\"test:\" ,test_df.shape)\n\n                                    #correlation matrix#\ndef corr_plot2(dataframe2, top_n2, target2, fig_x2, fig_y2):\n    corrmat2 = dataframe2.corr()\n    top_n2 = top_n2 + 1 \n    cols2 = corrmat2.nlargest(top_n2, target2)[target2].index\n    cm2 = np.corrcoef(train_df[cols2].values.T)\n    f2, ax2 = plt.subplots(figsize=(fig_x2,fig_y2))\n    sns.set(font_scale=1.25)\n    cmap2 = plt.cm.viridis\n    hm2 = sns.heatmap(cm2, cbar=False, annot=True, square=True,cmap = cmap2, fmt='.2f', annot_kws={'size': 10},\t yticklabels=cols2.values, xticklabels=cols2.values)\n    plt.show()\n    return cols2,cm2\ndef corr_plot(dataframe, top_n, target, fig_x, fig_y):\n    corrmat = dataframe.corr()\n    top_n = top_n + 1 \n    cols = corrmat.nlargest(top_n, target)[target].index\n    cm = np.corrcoef(train_df[cols].values.T)\n    return cols,cm\ncorr_20,cm = corr_plot(train_df, 30, 'price_doc', 10,10) \ncorr_22 = corr_plot2(train_df, 30, 'price_doc', 10,10)  \n\n\n\n                           #Determine numerical columns and strings colums#\ndtypes = train_df.iloc[:,2:-1].dtypes\nstring_cols = dtypes[dtypes == object].index\nnum_cols = dtypes[dtypes != object].index\n\n\n                              #description of non_mumerical colones  #\ndef categorical_summary(data, col):\n    filled_values = sum(data[col].notnull())\n    missing = sum(data[col].isnull())\n    cardinality = len(data[col].unique())\n    print(col.upper())\n    print('-------------------------------')\n    print('filled count: %s' %filled_values)\n    print('missing count: %s' %missing)\n    print('cardinality: %s' %cardinality)\n    print(data[col].value_counts())\nfor col in string_cols:\n    categorical_summary(train_df, col)\n    \n    \n                                  #\"yes\" and \"no\" transformation #\nyes_no_list = ['culture_objects_top_25', 'thermal_power_plant_raion', 'incineration_raion', 'oil_chemistry_raion',\n          'radiation_raion', 'railroad_terminal_raion', 'big_market_raion', 'nuclear_reactor_raion',\n          'detention_facility_raion', 'water_1line', 'big_road1_1line', 'railroad_1line']\nfor col in yes_no_list:\n    train_df.ix[train_df[col]=='yes', col]=1\n    train_df.ix[train_df[col]=='no', col]=0\n    test_df.ix[test_df[col]=='yes', col]=1\n    test_df.ix[test_df[col]=='no', col]=0\n    \n\n                                   #ecology column transformation#\ntrain_df.ix[train_df[\"ecology\"]=='poor', \"ecology\"]=0\ntrain_df.ix[train_df[\"ecology\"]=='good', \"ecology\"]=2\ntrain_df.ix[train_df[\"ecology\"]=='excellent', \"ecology\"]=3\ntrain_df.ix[train_df[\"ecology\"]=='satisfactory', \"ecology\"]=1\ntest_df.ix[test_df[\"ecology\"]=='poor', \"ecology\"]=0\ntest_df.ix[test_df[\"ecology\"]=='good', \"ecology\"]=2\ntest_df.ix[test_df[\"ecology\"]=='excellent', \"ecology\"]=3\ntest_df.ix[test_df[\"ecology\"]=='satisfactory', \"ecology\"]=1\n\n\n                     #determine the ecology's mean without missing data#\ni = 0;\ns = 0;\nfor lig in train_df[\"ecology\"]:\n    if lig != \"no data\" :\n        i=i+1\n        s=s+lig\nmean = s/i   \nprint (mean)\ni = 0;\ns = 0;\nfor lig in test_df[\"ecology\"]:\n    if lig != \"no data\" :\n        i=i+1\n        s=s+lig\nmean = s/i   \nprint (mean)\n\n\n                  #replace the missing data with the mean of ecology#\ntrain_df.ix[train_df[\"ecology\"]=='no data', \"ecology\"]=1\ntest_df.ix[test_df[\"ecology\"]=='no data', \"ecology\"]=1\n\n\n                        #transformation of product_type#\ntrain_df.ix[train_df[\"product_type\"]=='Investment', \"product_type\"]=1\ntrain_df.ix[train_df[\"product_type\"]=='OwnerOccupier', \"product_type\"]=0\ntest_df.ix[test_df[\"product_type\"]=='Investment', \"product_type\"]=1\ntest_df.ix[test_df[\"product_type\"]=='OwnerOccupier', \"product_type\"]=0\nprint (test_df.head)\n\n\n                          #test , train  's transformation# \nclass DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n        if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n        index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\ntrain_df = DataFrameImputer().fit_transform(train_df)\ntest_df = DataFrameImputer().fit_transform(test_df)\n\n\n\n                                  #linear regression#\ny = train_df.price_doc\ntrain_X = train_df.drop([\"price_doc\",\"id\",\"timestamp\",\"sub_area\"],axis=1)\nlinreg = LinearRegression()\nlinreg.fit(train_X, y)\nprint(linreg.intercept_)\nprint(linreg.coef_)\ntest_X = test_df.drop([\"id\",\"timestamp\",\"sub_area\"],axis=1)\ny_pred = linreg.predict(test_X)\nprint (y_pred)\nprint (y_pred.shape)\n\n\n                                       #submission#\nsubmission_df = pd.DataFrame({'id':test_df.id, 'price_doc':y_pred}).set_index('id').to_csv('submission.csv')\ncwd = os.getcwd()\n#print (cwd)\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}