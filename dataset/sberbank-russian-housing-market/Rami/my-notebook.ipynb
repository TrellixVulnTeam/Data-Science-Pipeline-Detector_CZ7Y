{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce57aff9-df2e-8bf8-372a-fe987df02f04"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n\ndef corr_plot(dataframe, top_n, target, fig_x, fig_y):\n    corrmat = dataframe.corr()\n    #top_n - top n correlations +1 since price is included\n    top_n = top_n + 1 \n    cols = corrmat.nlargest(top_n, target)[target].index\n    cm = np.corrcoef(train[cols].values.T)\n    return cols,cm\n# matrice correlation \n\ntrain = pd.read_csv(\"./input/train.csv\")\n\n\ntrain2 = pd.read_csv(\"./input/macro.csv\")\n\ntrain = pd.merge(train, train2, on='timestamp')\n\n\ndel train[\"timestamp\"]\n# fusion du train et du macro \n\ntrain3 = train\n\n\ntotal = train.isnull().sum().sort_values(ascending=False)\n #calculer le total des valeurs manquantes\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n #le pourcentage de valeur manquantes pour chaque variable \nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nprint(missing_data)\n\ntrain = train.drop((missing_data[missing_data['Total'] > 10000]).index,1)\n# supprimer les variables avec des valeurs manquantes sup a 10000\n\ntrain = train.dropna(thresh=train.shape[1])\n# supprimer l'observation si une observation est manquante \nprint train.shape\n\ndtype_df = train.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()\n\n# identifier le type des variables\n\ntab = []\n\nfor x in range(0,dtype_df.shape[0]):\n\tif(dtype_df[\"Column Type\"][x] == \"object\"):\n\t\ttab.append(dtype_df[\"Count\"][x])\n# nombre de variable de chaque type\nfor x in range(0,15):\n\ttrain[tab[x]] = pd.factorize(train[tab[x]])[0]\n\n# transforme des variables object en variables de type entier , quali en quanti \n\n\n\ncorr_20,cm = corr_plot(train, 150, 'price_doc', 10,10)\n\nfor y in range(1,25):\n\tfor x in range(y+1,cm.shape[0]):\n\t\tif(cm[y][x] > 0.75):\n\t\t\tdel train[corr_20[x]]\n\tcorr_20,cm = corr_plot(train, 150, 'price_doc', 10,10)\n\tprint train.shape\n\ncorr_20 = corr_20[0:25]\n\nprint corr_20\n\n# si deux variable sont corrÃ©lÃ© on elimine un des deux \n\n\n\ntrain3 = train3[corr_20].copy()\n\n# on retient 25 variables\n\n#meme algo sur le test \n\ntest = pd.read_csv(\"./input/test.csv\")\n\ntrain2 = pd.read_csv(\"./input/macro.csv\")\n\ntest = pd.merge(test, train2, on='timestamp')\n\ndel test[\"timestamp\"]\nprint test.shape\ntest = test[corr_20[1:corr_20.shape[0]]].copy()\n\n\n\ntotal = train3.isnull().sum().sort_values(ascending=False) #calculer le total des valeurs manquantes\npercent = (train3.isnull().sum()/train3.isnull().count()).sort_values(ascending=False) #le pourcentage de valeur manquantes pour chaque variable \nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\n\n\ntrain3 = train3.drop((missing_data[missing_data['Total'] > 10000]).index,1)\n\n\ntrain3 = train3.dropna(thresh=train3.shape[1])\ndtype_df = train3.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()\n\ntab = []\n\nfor x in range(0,dtype_df.shape[0]):\n    if(dtype_df[\"Column Type\"][x] == \"object\"):\n        tab.append(dtype_df[\"Count\"][x])\n        #print dtype_df[\"Count\"][x]\n\nfor x in range(0,len(tab)):\n    train3[tab[x]] = pd.factorize(train3[tab[x]])[0]\n    test[tab[x]] = pd.factorize(test[tab[x]])[0]\n\n\ntest  = test.fillna(test.mean())\n\n# test ready \n\n# traitement des outlyers \ntrain3 = train3[train3.price_doc > 100]\ntrain3 = train3[train3.price_doc < 0.2e8]\ntrain3 = train3[train3.full_sq < 130]\ntrain3 = train3[train3.full_sq > 4]\ntrain3 = train3[train3.max_floor < 80]\n\n\n\n\nprice = train3.price_doc\ndel train3[\"price_doc\"]\ntrain3 = train3[corr_20[1:corr_20.shape[0]]].copy()\n\n\n\nmodeleReg=LinearRegression()\n\n\n\nmodeleReg.fit(train3,price) #effectuer la regression lineaire\ny_predicted = modeleReg.predict(test)\n\nid_test = range(30474,38136)\noutput = pd.DataFrame({'id': id_test, 'price_doc': y_predicted})\noutput.head()\noutput.to_csv('submission.csv', index=False)\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}