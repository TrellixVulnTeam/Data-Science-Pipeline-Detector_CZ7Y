{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"070bdeca-9fbc-eddd-a8e1-5dc0ae26012c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff740c1f-6e73-f762-dcaa-afe17ec3a01b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aba850b1-cc0a-2295-a170-7394b730ced2"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5094b6ec-006d-4cf5-498d-63456fe8e0e6"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ndf_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\ndf_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n\ndf_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89088e47-1e5d-ce56-74fe-5a7ed3117b65"},"outputs":[],"source":"df_train['price_doc'].hist(bins=50)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c490c536-d925-e717-736e-c621533bf456"},"outputs":[],"source":"y_train = df_train['price_doc'].values\nid_test = df_test['id']\n\ndf_train.drop(['id', 'price_doc'], axis=1, inplace=True)\ndf_test.drop(['id'], axis=1, inplace=True)\n\n# Build df_all = (df_train+df_test).join(df_macro)\nnum_train = len(df_train)\ndf_all = pd.concat([df_train, df_test])\ndf_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')\nprint(df_all.shape)\n\n# Add month-year\nmonth_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\nmonth_year_cnt_map = month_year.value_counts().to_dict()\ndf_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n\n# Add week-year count\nweek_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\nweek_year_cnt_map = week_year.value_counts().to_dict()\ndf_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n\n# Add month and day-of-week\ndf_all['month'] = df_all.timestamp.dt.month\ndf_all['dow'] = df_all.timestamp.dt.dayofweek\n\n# Other feature engineering\ndf_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\ndf_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n\n# Remove timestamp column (may overfit the model in train)\ndf_all.drop(['timestamp'], axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce614e14-892b-b9a5-d84d-de759c4d570b"},"outputs":[],"source":"# Deal with categorical values\ndf_numeric = df_all.select_dtypes(exclude=['object'])\ndf_obj = df_all.select_dtypes(include=['object']).copy()\n\nfor c in df_obj:\n    df_obj[c] = pd.factorize(df_obj[c])[0]\n\ndf_values = pd.concat([df_numeric, df_obj], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb5e8c45-2579-d11e-c617-a93b88002969"},"outputs":[],"source":"# Convert to numpy values\nX_all = df_values.values\nprint(X_all.shape)\n\nX_train = X_all[:num_train]\nX_test = X_all[num_train:]\n\ndf_columns = df_values.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c587df64-61be-f0e4-cb81-54f1d7ffc377"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\ndtest = xgb.DMatrix(X_test, feature_names=df_columns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe60cdc1-c557-31bf-2946-ba9bc62ad29c"},"outputs":[],"source":"# Uncomment to tune XGB `num_boost_rounds`\n\n#cv_result = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n#    verbose_eval=True, show_stdv=False)\n#cv_result[['train-rmse-mean', 'test-rmse-mean']].plot()\n#num_boost_rounds = len(cv_result)\n\nnum_boost_round = 383"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b8fa400-38ea-5da4-126f-8dd81db5b06e"},"outputs":[],"source":"model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_round)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"180652fe-a571-e317-5dd8-d6f7a47f5abd"},"outputs":[],"source":"fig, ax = plt.subplots(1, 1, figsize=(8, 16))\nxgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"384abd38-b7f9-61dc-ff76-ca5eae267b6b"},"outputs":[],"source":"y_pred = model.predict(dtest)\n\ndf_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n\ndf_sub.to_csv('sub.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4f3b562-9c21-d1cc-d212-ef22c7f566ab"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}