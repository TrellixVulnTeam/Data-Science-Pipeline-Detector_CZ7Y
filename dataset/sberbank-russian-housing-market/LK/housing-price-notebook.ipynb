{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"bbce192b-0b32-a193-d26b-39b505026dbf"},"source":"This my first notebook on Kaggle.  I will be working on Russian Housing price prediction problem. There are many independent variables in the data. I will use ML algorithms to find the best features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e91b4bdf-a245-0c79-b6b9-e6423f778543"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'\npd.set_option('display.max_columns', 600)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ea4910c3-6981-bc5a-a549-ba24550f7635"},"source":"Reading the datasets"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c4dcea2-0af1-6c39-15fb-cca05f031790"},"outputs":[],"source":"train_df = pd.read_csv(\"../input/train.csv\")\ntrain_df.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"e44e6266-413e-1970-8223-91a0381bcf6b"},"source":"Observing the variables by seeing header"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a34edef-e373-2ae0-7871-80ca8ca3a916"},"outputs":[],"source":"train_df.head()\ntrain_df.tail() "},{"cell_type":"markdown","metadata":{"_cell_guid":"26718276-127a-37bb-207b-8cd1b7eacbcc"},"source":"to get a list of the column headers from a pandas DataFrame"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"611d553c-eeba-1ddb-62ad-4cf3ded6ce3e"},"outputs":[],"source":"plt.figure(figsize=(10,8))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.price_doc.values))\nplt.xlabel('obs', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e83bf6b2-63ae-c5d5-8df5-203eb738eeb1"},"source":"Checking the data types of the variables in train_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"089ef73a-e55f-d4f1-81f1-1a2773710485"},"outputs":[],"source":"train_df.dtypes\ntrain_df.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"165b680d-5f64-3a51-ca12-22aad050317b"},"outputs":[],"source":"for f in train_df.columns:\n    if train_df[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_df[f].values)) \n      \n        train_df[f] = lbl.transform(list(train_df[f].values))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e340c66-5fbb-b278-6339-03974dfd554f"},"outputs":[],"source":"train_df.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c2294ea-3e9c-ed3b-8a2f-42306682336a"},"outputs":[],"source":"for f in train_df.columns:\n    if train_df[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_df[f].values)) \n        train_df[f] = lbl.transform(list(train_df[f].values))\n        \ntrain_y = train_df.price_doc.values\ntrain_X = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\ndtrain = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns.values)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100)\n\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0942b020-a1b8-6cb5-3502-c0d4e536fb5d"},"source":"Label encoding of categories "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70425f4e-1518-832b-3b9c-054f6231e80f"},"outputs":[],"source":"train_y = train_df.price_doc.values\ntrain_y\ntrain_X = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\ntrain_X.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"432d0fb1-b16a-de17-b7e8-bcfaab4d76c4"},"outputs":[],"source":"for f in train_df.columns:\n    if train_df[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_df[f].values)) \n        train_df[f] = lbl.transform(list(train_df[f].values))\nimport math\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nn_features=40\ntrain_df=train_df.fillna(train_df.median())  \ntarget=train_df['price_doc']\nrf = RandomForestRegressor(n_estimators=20,max_features=int(math.sqrt(n_features)),random_state=0)\nrf.fit(train_df, target)\nrow=list(train_df.columns.values)\nfeature_names = np.array(row)\nimportances1 = rf.feature_importances_\nimportant_names1 = feature_names[importances1 > np.mean(importances1)]\nimportant_names1"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}