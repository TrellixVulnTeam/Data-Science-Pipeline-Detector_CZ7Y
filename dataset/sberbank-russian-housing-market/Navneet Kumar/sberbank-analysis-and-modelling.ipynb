{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Description\n\nHousing costs demand a significant investment from both consumers and developers. And when it comes to planning a budget—whether personal or corporate—the last thing anyone needs is uncertainty about one of their biggets expenses. Sberbank, Russia’s oldest and largest bank, helps their customers by making predictions about realty prices so renters, developers, and lenders are more confident when they sign a lease or purchase a building.\n\nAlthough the housing market is relatively stable in Russia, the country’s volatile economy makes forecasting prices as a function of apartment characteristics a unique challenge. Complex interactions between housing features such as number of bedrooms and location are enough to make pricing predictions complicated. Adding an unstable economy to the mix means Sberbank and their customers need more than simple regression models in their arsenal.\n\nIn this competition, Sberbank is challenging Kagglers to develop algorithms which use a broad spectrum of features to predict realty prices. Competitors will rely on a rich dataset that includes housing data and macroeconomic patterns. An accurate forecasting model will allow Sberbank to provide more certainty to their customers in an uncertain economy.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:29.904687Z","iopub.execute_input":"2021-09-14T16:59:29.905341Z","iopub.status.idle":"2021-09-14T16:59:30.861004Z","shell.execute_reply.started":"2021-09-14T16:59:29.905253Z","shell.execute_reply":"2021-09-14T16:59:30.860309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check all the columns present\npd.set_option('display.max_columns', 500)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:30.862507Z","iopub.execute_input":"2021-09-14T16:59:30.863021Z","iopub.status.idle":"2021-09-14T16:59:30.866911Z","shell.execute_reply.started":"2021-09-14T16:59:30.862984Z","shell.execute_reply":"2021-09-14T16:59:30.866232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unzip Files","metadata":{}},{"cell_type":"code","source":"! unzip /kaggle/input/sberbank-russian-housing-market/train.csv.zip","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:30.868416Z","iopub.execute_input":"2021-09-14T16:59:30.869001Z","iopub.status.idle":"2021-09-14T16:59:32.064666Z","shell.execute_reply.started":"2021-09-14T16:59:30.868962Z","shell.execute_reply":"2021-09-14T16:59:32.063855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! unzip /kaggle/input/sberbank-russian-housing-market/test.csv.zip","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:32.067099Z","iopub.execute_input":"2021-09-14T16:59:32.067495Z","iopub.status.idle":"2021-09-14T16:59:32.83933Z","shell.execute_reply.started":"2021-09-14T16:59:32.067452Z","shell.execute_reply":"2021-09-14T16:59:32.838566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:32.840575Z","iopub.execute_input":"2021-09-14T16:59:32.840816Z","iopub.status.idle":"2021-09-14T16:59:33.547294Z","shell.execute_reply.started":"2021-09-14T16:59:32.840788Z","shell.execute_reply":"2021-09-14T16:59:33.546361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading train and test data**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(f\"/kaggle/working/train.csv\")\ntest_df = pd.read_csv(f\"/kaggle/working/test.csv\")\nprint(f\"train data shape:- {train_df.shape}\")\nprint(f\"test data shape:- {test_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:33.549075Z","iopub.execute_input":"2021-09-14T16:59:33.549581Z","iopub.status.idle":"2021-09-14T16:59:34.822365Z","shell.execute_reply.started":"2021-09-14T16:59:33.549535Z","shell.execute_reply":"2021-09-14T16:59:34.82091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*datetime column into timestamp*","metadata":{}},{"cell_type":"code","source":"train_df['timestamp'] =pd.to_datetime(train_df.timestamp)\ntest_df['timestamp'] =pd.to_datetime(test_df.timestamp)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:34.823631Z","iopub.execute_input":"2021-09-14T16:59:34.824226Z","iopub.status.idle":"2021-09-14T16:59:35.03903Z","shell.execute_reply.started":"2021-09-14T16:59:34.824189Z","shell.execute_reply":"2021-09-14T16:59:35.038264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sorting the training data based on time stamp because house prices does increases over time**","metadata":{}},{"cell_type":"code","source":"train_df = train_df.sort_values(by=['timestamp'])\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:35.039932Z","iopub.execute_input":"2021-09-14T16:59:35.040169Z","iopub.status.idle":"2021-09-14T16:59:35.337448Z","shell.execute_reply.started":"2021-09-14T16:59:35.040139Z","shell.execute_reply":"2021-09-14T16:59:35.3365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:35.339145Z","iopub.execute_input":"2021-09-14T16:59:35.34096Z","iopub.status.idle":"2021-09-14T16:59:35.634289Z","shell.execute_reply.started":"2021-09-14T16:59:35.340914Z","shell.execute_reply":"2021-09-14T16:59:35.633445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets dig deep into o/p variable price_doc**","metadata":{}},{"cell_type":"code","source":"train_df['year'] = pd.DatetimeIndex(train_df['timestamp']).year\ntrain_df['month'] = pd.DatetimeIndex(train_df['timestamp']).month\ntest_df['year'] = pd.DatetimeIndex(test_df['timestamp']).year\ntest_df['month'] = pd.DatetimeIndex(test_df['timestamp']).month\ntrain_df['day'] = pd.DatetimeIndex(train_df['timestamp']).day\ntrain_df['week'] = pd.DatetimeIndex(train_df['timestamp']).week\ntest_df['day'] = pd.DatetimeIndex(test_df['timestamp']).day\ntest_df['week'] = pd.DatetimeIndex(test_df['timestamp']).week","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:35.637431Z","iopub.execute_input":"2021-09-14T16:59:35.637752Z","iopub.status.idle":"2021-09-14T16:59:35.681973Z","shell.execute_reply.started":"2021-09-14T16:59:35.637712Z","shell.execute_reply":"2021-09-14T16:59:35.681243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Groupby year in price mean\nmean_year_df = train_df.groupby(\"year\")[\"price_doc\"].agg(\"mean\").reset_index()\nplt.figure(figsize=(8,6))\nplt.scatter(range(mean_year_df.shape[0]), mean_year_df.price_doc.values)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:35.683286Z","iopub.execute_input":"2021-09-14T16:59:35.683772Z","iopub.status.idle":"2021-09-14T16:59:35.940889Z","shell.execute_reply.started":"2021-09-14T16:59:35.683736Z","shell.execute_reply":"2021-09-14T16:59:35.940222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above price plot we can see that mean price has increased every year\n\n> We also check median price and how much there is a difference in price every year","metadata":{}},{"cell_type":"code","source":"# Groupby month on price\nmean_month_df = train_df.groupby(\"month\")[\"price_doc\"].agg(\"mean\").reset_index()\nplt.figure(figsize=(8,6))\nplt.scatter(range(mean_month_df.shape[0]), mean_month_df.price_doc.values)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:35.942274Z","iopub.execute_input":"2021-09-14T16:59:35.942541Z","iopub.status.idle":"2021-09-14T16:59:36.14285Z","shell.execute_reply.started":"2021-09-14T16:59:35.942492Z","shell.execute_reply":"2021-09-14T16:59:36.142079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above we can see that price is maximum b/w 2nd to 4th month","metadata":{}},{"cell_type":"code","source":"# groupby year and month on price mean\nmean_year_month_df = train_df.groupby([\"year\", \"month\"])[\"price_doc\"].agg(\"mean\").reset_index()\nplt.figure(figsize=(8,6))\nplt.scatter(range(mean_year_month_df.shape[0]), mean_year_month_df.price_doc.values)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:36.144881Z","iopub.execute_input":"2021-09-14T16:59:36.145109Z","iopub.status.idle":"2021-09-14T16:59:36.352485Z","shell.execute_reply.started":"2021-09-14T16:59:36.14508Z","shell.execute_reply":"2021-09-14T16:59:36.351822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Above graph represents how the price has increased over the year and month","metadata":{}},{"cell_type":"code","source":"mean_month_year_df = train_df.groupby([\"month\", \"year\"])[\"price_doc\"].agg(\"mean\").reset_index()\nplt.figure(figsize=(8,6))\nplt.scatter(range(mean_month_year_df.shape[0]), mean_month_year_df.price_doc.values)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:36.353815Z","iopub.execute_input":"2021-09-14T16:59:36.354351Z","iopub.status.idle":"2021-09-14T16:59:36.54886Z","shell.execute_reply.started":"2021-09-14T16:59:36.354309Z","shell.execute_reply":"2021-09-14T16:59:36.548207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_df.plot.scatter(x='product_type', y='price_doc')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:36.550228Z","iopub.execute_input":"2021-09-14T16:59:36.550506Z","iopub.status.idle":"2021-09-14T16:59:37.000237Z","shell.execute_reply.started":"2021-09-14T16:59:36.55047Z","shell.execute_reply":"2021-09-14T16:59:36.999311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Seems like people tend to pay more when they are buying for investment purpose","metadata":{}},{"cell_type":"code","source":"\ntrain_df.plot.scatter(x='num_room', y='price_doc')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.001713Z","iopub.execute_input":"2021-09-14T16:59:37.001972Z","iopub.status.idle":"2021-09-14T16:59:37.441152Z","shell.execute_reply.started":"2021-09-14T16:59:37.001938Z","shell.execute_reply":"2021-09-14T16:59:37.440424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> With increse in num rooms price increases\n\n> Here are some num rooms greater than 10 but prices are very less, these seems like an outlier we can define remove them","metadata":{}},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.442508Z","iopub.execute_input":"2021-09-14T16:59:37.442768Z","iopub.status.idle":"2021-09-14T16:59:37.449749Z","shell.execute_reply.started":"2021-09-14T16:59:37.442736Z","shell.execute_reply":"2021-09-14T16:59:37.448756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[(train_df[\"num_room\"]<10) | (train_df[\"num_room\"].isnull())]\ntrain_df.plot.scatter(x='num_room', y='price_doc')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.45127Z","iopub.execute_input":"2021-09-14T16:59:37.451842Z","iopub.status.idle":"2021-09-14T16:59:37.895139Z","shell.execute_reply.started":"2021-09-14T16:59:37.451806Z","shell.execute_reply":"2021-09-14T16:59:37.894408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.89658Z","iopub.execute_input":"2021-09-14T16:59:37.896848Z","iopub.status.idle":"2021-09-14T16:59:37.903463Z","shell.execute_reply.started":"2021-09-14T16:59:37.896814Z","shell.execute_reply":"2021-09-14T16:59:37.902596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note: Same way we can do multivariate analysis for other categorial variable also**","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop([\"id\", \"timestamp\"], 1)\ntest_df = test_df.drop([\"id\", \"timestamp\"], 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.905306Z","iopub.execute_input":"2021-09-14T16:59:37.905934Z","iopub.status.idle":"2021-09-14T16:59:37.947085Z","shell.execute_reply.started":"2021-09-14T16:59:37.905894Z","shell.execute_reply":"2021-09-14T16:59:37.94632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separating the target price as series\ntarget = train_df[\"price_doc\"]\n#train_df = train_df.drop([\"price_doc\"], 1)\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.948487Z","iopub.execute_input":"2021-09-14T16:59:37.948778Z","iopub.status.idle":"2021-09-14T16:59:37.955374Z","shell.execute_reply.started":"2021-09-14T16:59:37.948743Z","shell.execute_reply":"2021-09-14T16:59:37.954475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.957038Z","iopub.execute_input":"2021-09-14T16:59:37.957339Z","iopub.status.idle":"2021-09-14T16:59:37.967748Z","shell.execute_reply.started":"2021-09-14T16:59:37.957305Z","shell.execute_reply":"2021-09-14T16:59:37.9667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.scatter(range(target.shape[0]), np.sort(target.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:37.969376Z","iopub.execute_input":"2021-09-14T16:59:37.969695Z","iopub.status.idle":"2021-09-14T16:59:38.318534Z","shell.execute_reply.started":"2021-09-14T16:59:37.969662Z","shell.execute_reply":"2021-09-14T16:59:38.317822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> This is how price has increased over the years, not filtering any of the price for now after sorting","metadata":{}},{"cell_type":"markdown","source":"**without sorting**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(8,6))\nplt.scatter(range(target.shape[0]), target.values)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.31988Z","iopub.execute_input":"2021-09-14T16:59:38.320142Z","iopub.status.idle":"2021-09-14T16:59:38.571241Z","shell.execute_reply.started":"2021-09-14T16:59:38.320109Z","shell.execute_reply":"2021-09-14T16:59:38.570566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Semms like there are some outliers in price as well. But let's model it without filtering it first","metadata":{}},{"cell_type":"markdown","source":"# Merging both train and test for preprocessing","metadata":{}},{"cell_type":"code","source":"#merged_df = pd.concat([train_df,test_df])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.572411Z","iopub.execute_input":"2021-09-14T16:59:38.572902Z","iopub.status.idle":"2021-09-14T16:59:38.57679Z","shell.execute_reply.started":"2021-09-14T16:59:38.572863Z","shell.execute_reply":"2021-09-14T16:59:38.575991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.578188Z","iopub.execute_input":"2021-09-14T16:59:38.578938Z","iopub.status.idle":"2021-09-14T16:59:38.607027Z","shell.execute_reply.started":"2021-09-14T16:59:38.578901Z","shell.execute_reply":"2021-09-14T16:59:38.606287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All cols present\nall_cols = train_df.columns\n# numerical columns\nnum_and_float_cols = train_df._get_numeric_data().columns\n# categories columns\nobject_cols = list(set(all_cols) - set(num_and_float_cols))\nprint(f\"total numeric cols :- {len(num_and_float_cols)}, categorical cols:- {len(object_cols)}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.608059Z","iopub.execute_input":"2021-09-14T16:59:38.608893Z","iopub.status.idle":"2021-09-14T16:59:38.615073Z","shell.execute_reply.started":"2021-09-14T16:59:38.608854Z","shell.execute_reply":"2021-09-14T16:59:38.614327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtering out all the columns which contains some nan values\nnull_cols_val = {all_cols[col_idx]:val for col_idx, val in enumerate(train_df.isnull().sum()) if val>0}\nnull_cols = [i[0] for i in null_cols_val.items() ]\n# List of all columns having null value\nnull_cols","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.622106Z","iopub.execute_input":"2021-09-14T16:59:38.622564Z","iopub.status.idle":"2021-09-14T16:59:38.684314Z","shell.execute_reply.started":"2021-09-14T16:59:38.622533Z","shell.execute_reply":"2021-09-14T16:59:38.683422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.685791Z","iopub.execute_input":"2021-09-14T16:59:38.686046Z","iopub.status.idle":"2021-09-14T16:59:38.877205Z","shell.execute_reply.started":"2021-09-14T16:59:38.686013Z","shell.execute_reply":"2021-09-14T16:59:38.876435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multicolinear check starts here","metadata":{}},{"cell_type":"code","source":"corelated_df = train_df[num_and_float_cols].corr()#.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:38.878595Z","iopub.execute_input":"2021-09-14T16:59:38.879053Z","iopub.status.idle":"2021-09-14T16:59:44.43601Z","shell.execute_reply.started":"2021-09-14T16:59:38.879014Z","shell.execute_reply":"2021-09-14T16:59:44.435284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corelated_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:44.437244Z","iopub.execute_input":"2021-09-14T16:59:44.43748Z","iopub.status.idle":"2021-09-14T16:59:44.687994Z","shell.execute_reply.started":"2021-09-14T16:59:44.437449Z","shell.execute_reply":"2021-09-14T16:59:44.687238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_important_feat = corelated_df.loc[\"price_doc\"].to_dict()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:44.689121Z","iopub.execute_input":"2021-09-14T16:59:44.689649Z","iopub.status.idle":"2021-09-14T16:59:44.69399Z","shell.execute_reply.started":"2021-09-14T16:59:44.689594Z","shell.execute_reply":"2021-09-14T16:59:44.693184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot of all corelated variables\nplt.figure(figsize=(50,50))\nplt.bar(range(len(price_important_feat)), list(price_important_feat.values()), align='center')\nplt.xticks(range(len(price_important_feat)), list(price_important_feat.keys()))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:44.695103Z","iopub.execute_input":"2021-09-14T16:59:44.695678Z","iopub.status.idle":"2021-09-14T16:59:49.570242Z","shell.execute_reply.started":"2021-09-14T16:59:44.69564Z","shell.execute_reply":"2021-09-14T16:59:49.569582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlated_features = set()\n# Corelated sets\ncorrelated_features = {}\n # Featues that is related to price\nfeatures_related_to_price = []\ncorr_cols = corelated_df.columns\nalready_done = []\nfor i in range(len(corr_cols)):\n    correlated_features[corr_cols[i]] = []\n    for j in range(len(corr_cols)):\n        if  i!=j and ([i,j] not in already_done or [j,i] not in already_done)  and abs(corelated_df.iloc[i, j]) > 0.8:\n            already_done.append([i,j])\n            if corr_cols[i]==\"price_doc\":\n                features_related_to_price.append([corr_cols[j],corelated_df.iloc[i, j]])\n            elif corr_cols[j]==\"price_doc\":\n                features_related_to_price.append([corr_cols[i],corelated_df.iloc[i, j]])    \n            else:    \n                #correlated_features.add(corr_cols[i])\n                correlated_features[corr_cols[i]].append(corr_cols[j])\n    if not correlated_features[corr_cols[i]]:\n        del correlated_features[corr_cols[i]]\n           ","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:49.571612Z","iopub.execute_input":"2021-09-14T16:59:49.571877Z","iopub.status.idle":"2021-09-14T16:59:55.441014Z","shell.execute_reply.started":"2021-09-14T16:59:49.571842Z","shell.execute_reply":"2021-09-14T16:59:55.440273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"value_correlated_features = []\nfor kv in correlated_features.items():\n    value_correlated_features.extend(kv[1])\nfinal_corelated_sets = []    \nrestricted_sets = set(value_correlated_features)\nfor kv in correlated_features.items():\n    if kv[0] not in restricted_sets:\n\n        restricted_sets.add(kv[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:55.442391Z","iopub.execute_input":"2021-09-14T16:59:55.442682Z","iopub.status.idle":"2021-09-14T16:59:55.448774Z","shell.execute_reply.started":"2021-09-14T16:59:55.442647Z","shell.execute_reply":"2021-09-14T16:59:55.447858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment to check features\n#corelated_sets_to_remove","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:55.450315Z","iopub.execute_input":"2021-09-14T16:59:55.450642Z","iopub.status.idle":"2021-09-14T16:59:55.457616Z","shell.execute_reply.started":"2021-09-14T16:59:55.450588Z","shell.execute_reply":"2021-09-14T16:59:55.456775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> corelated_sets_to_remove these are the inter corelated sets which is intercorelated and more than 80%","metadata":{}},{"cell_type":"code","source":"len(restricted_sets)\ncorelated_sets_to_remove = list(restricted_sets)\ntrain_df = train_df.drop(corelated_sets_to_remove,axis=1)\ntest_df = test_df.drop(corelated_sets_to_remove,axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:55.458841Z","iopub.execute_input":"2021-09-14T16:59:55.459117Z","iopub.status.idle":"2021-09-14T16:59:55.476826Z","shell.execute_reply.started":"2021-09-14T16:59:55.459083Z","shell.execute_reply":"2021-09-14T16:59:55.476021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_cols_list = train_df.columns\nprint(train_df.shape)\nnum_and_float_cols = [col for col in num_and_float_cols if col in new_cols_list]\nobject_cols = [col for col in object_cols if col in new_cols_list]","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:55.478183Z","iopub.execute_input":"2021-09-14T16:59:55.478447Z","iopub.status.idle":"2021-09-14T16:59:55.484626Z","shell.execute_reply.started":"2021-09-14T16:59:55.478415Z","shell.execute_reply":"2021-09-14T16:59:55.483455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**corelation free depandend variable and plots**","metadata":{}},{"cell_type":"code","source":"limited_price_important_feat = {i[0]:i[1] for i in price_important_feat.items() if i[0] not in corelated_sets_to_remove+[\"price_doc\"]}\nplt.figure(figsize=(20,20))\nplt.barh(*zip(*limited_price_important_feat.items()))\n# plt.bar(range(len(limited_price_important_feat)), list(limited_price_important_feat.values()), align='center')\n# plt.xticks(range(len(limited_price_important_feat)), list(limited_price_important_feat.keys()))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:55.486257Z","iopub.execute_input":"2021-09-14T16:59:55.486583Z","iopub.status.idle":"2021-09-14T16:59:56.737016Z","shell.execute_reply.started":"2021-09-14T16:59:55.486548Z","shell.execute_reply":"2021-09-14T16:59:56.736343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Seems like num_rooms is contributing more than full_sq followed by others","metadata":{}},{"cell_type":"code","source":"train_df[object_cols[-5]]","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:56.73838Z","iopub.execute_input":"2021-09-14T16:59:56.738659Z","iopub.status.idle":"2021-09-14T16:59:56.746066Z","shell.execute_reply.started":"2021-09-14T16:59:56.738623Z","shell.execute_reply":"2021-09-14T16:59:56.745211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(object_cols), len(num_and_float_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:56.747604Z","iopub.execute_input":"2021-09-14T16:59:56.747926Z","iopub.status.idle":"2021-09-14T16:59:56.755953Z","shell.execute_reply.started":"2021-09-14T16:59:56.74788Z","shell.execute_reply":"2021-09-14T16:59:56.755006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Numeric univariate plote and its distribution in space**","metadata":{}},{"cell_type":"code","source":"for col in num_and_float_cols:\n    if col in null_cols:\n        print(col)\n        plt.figure(figsize=(10,6))\n        sns.distplot(train_df[col].values, bins=50, kde=True)\n        plt.xlabel(col, fontsize=12)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T16:59:56.757782Z","iopub.execute_input":"2021-09-14T16:59:56.758081Z","iopub.status.idle":"2021-09-14T17:00:04.72525Z","shell.execute_reply.started":"2021-09-14T16:59:56.758046Z","shell.execute_reply":"2021-09-14T17:00:04.724495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:04.72682Z","iopub.execute_input":"2021-09-14T17:00:04.727117Z","iopub.status.idle":"2021-09-14T17:00:04.796795Z","shell.execute_reply.started":"2021-09-14T17:00:04.727079Z","shell.execute_reply":"2021-09-14T17:00:04.795825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bin some of the features","metadata":{}},{"cell_type":"code","source":"# Converting continuous variables into limited bins bases on quantiles\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nfeatures_to_bin = [\"industrial_km\", \"big_market_km\", \"market_shop_km\", \"church_synagogue_km\", \"incineration_km\", \"big_road1_km\", \"bus_terminal_avto_km\", \"mosque_km\"]\nbinned_features = []\ndef binning():\n    global binned_features\n    for feature in features_to_bin:\n        binf = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n        binf = binf.fit(train_df[feature].values.reshape(-1,1))#.astype(int)\n        train_df[f\"{feature}_bin\"] = binf.transform(train_df[feature].values.reshape(-1,1)).astype(int)\n        test_df[f\"{feature}_bin\"] = binf.transform(test_df[feature].values.reshape(-1,1)).astype(int)\n        binned_features.append(f\"{feature}_bin\")\n\n         \nbinning()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:04.798136Z","iopub.execute_input":"2021-09-14T17:00:04.798439Z","iopub.status.idle":"2021-09-14T17:00:04.929941Z","shell.execute_reply.started":"2021-09-14T17:00:04.798398Z","shell.execute_reply":"2021-09-14T17:00:04.929123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:04.931228Z","iopub.execute_input":"2021-09-14T17:00:04.931532Z","iopub.status.idle":"2021-09-14T17:00:05.001713Z","shell.execute_reply.started":"2021-09-14T17:00:04.931498Z","shell.execute_reply":"2021-09-14T17:00:05.000941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engneering(data):\n    numeric_data_added = []\n    categoric_data_added = []\n    \n    \n    # When someone buys a home for living he makes sure, school is nearby, hospital is nearby\n    # metro is nearbuy, market is nearby, water is nearby\n    data[\"sub_area_hospital_centres\"] = data[\"sub_area\"] + data[\"healthcare_centers_raion\"].astype(\"str\")\n    categoric_data_added.append(\"sub_area_hospital_centres\")\n    data[\"sub_area_school\"] = data[\"sub_area\"] + data[\"school_education_centers_top_20_raion\"].astype(\"str\")\n    categoric_data_added.append(\"sub_area_school\")\n    data[\"sub_area_market\"] = data[\"sub_area\"] + data[\"big_market_raion\"].astype(\"str\")\n    categoric_data_added.append(\"sub_area_market\")\n    data[\"sub_area_metro\"] = data[\"sub_area\"] + data[\"ID_metro\"].astype(\"str\")\n    categoric_data_added.append(\"sub_area_metro\")\n    for feature in binned_features:\n        data[f\"sub_area_{feature}\"] = data[\"sub_area\"] + data[feature].astype(\"str\")\n        categoric_data_added.append(f\"sub_area_{feature}\")\n        \n    return data, categoric_data_added, numeric_data_added\n    \n    \ntrain_df, categoric_data_added, numeric_data_added = feature_engneering(train_df) \ntest_df, categoric_data_added, numeric_data_added = feature_engneering(test_df) \n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:05.002953Z","iopub.execute_input":"2021-09-14T17:00:05.003358Z","iopub.status.idle":"2021-09-14T17:00:05.517831Z","shell.execute_reply.started":"2021-09-14T17:00:05.003323Z","shell.execute_reply":"2021-09-14T17:00:05.517096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Note: Have done some basic Feature Engineering. Could have been extended to few more featues but I am stopping with these features only","metadata":{}},{"cell_type":"code","source":"#err","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:05.519173Z","iopub.execute_input":"2021-09-14T17:00:05.519415Z","iopub.status.idle":"2021-09-14T17:00:05.524668Z","shell.execute_reply.started":"2021-09-14T17:00:05.519382Z","shell.execute_reply":"2021-09-14T17:00:05.523678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**filling null values with -1, for continus we can also try, mean, median values. I used -1 just to separate this feature and it will also contribute less while training**","metadata":{}},{"cell_type":"code","source":"for col in num_and_float_cols:\n    if col in null_cols:\n        #print(null_cols_val[col])\n        #print(abs(price_important_feat[col]))\n        train_df[col].fillna(-1, inplace=True)\n        test_df[col].fillna(-1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:05.52606Z","iopub.execute_input":"2021-09-14T17:00:05.526372Z","iopub.status.idle":"2021-09-14T17:00:05.542723Z","shell.execute_reply.started":"2021-09-14T17:00:05.526334Z","shell.execute_reply":"2021-09-14T17:00:05.542005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Based on experience onehot encoding should have worked better but that will increase the number of features as well. So I decided to target encoding(Just for testing)**","metadata":{}},{"cell_type":"code","source":"# Import label encoder\n#from sklearn import preprocessing\n#label_encoder = preprocessing.LabelEncoder()\nfrom category_encoders import TargetEncoder\n \nfor col in object_cols+categoric_data_added:\n    if col in null_cols:\n        train_df[col].fillna(f\"{col}nan\", inplace=True)\n        test_df[col].fillna(f\"{col}nan\", inplace=True)\n    encoder = TargetEncoder()\n    encoder = encoder.fit(train_df[col], train_df['price_doc'])\n    train_df[col] = encoder.transform(train_df[col])\n    test_df[col] = encoder.transform(test_df[col])\n#     label_encoder= label_encoder.fit(train_df[col])\n#     train_df[col] = label_encoder.transform(train_df[col])\n#     test_df[col] = label_encoder.transform(test_df[col])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:05.543941Z","iopub.execute_input":"2021-09-14T17:00:05.544217Z","iopub.status.idle":"2021-09-14T17:00:06.767566Z","shell.execute_reply.started":"2021-09-14T17:00:05.54418Z","shell.execute_reply":"2021-09-14T17:00:06.766864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:06.770316Z","iopub.execute_input":"2021-09-14T17:00:06.770527Z","iopub.status.idle":"2021-09-14T17:00:06.859131Z","shell.execute_reply.started":"2021-09-14T17:00:06.770493Z","shell.execute_reply":"2021-09-14T17:00:06.858452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Uncomment below codes to get univariate box plot to remove outliers if any. Sicnce Currenty I am going with outliers also. So commented it**","metadata":{}},{"cell_type":"code","source":"# for cols in num_and_float_cols:\n#     fig = plt.figure(figsize =(5, 3))\n\n#     # Creating plot\n#     plt.boxplot(train_df[cols].values)\n\n#     # show plot\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:06.860371Z","iopub.execute_input":"2021-09-14T17:00:06.860618Z","iopub.status.idle":"2021-09-14T17:00:06.864828Z","shell.execute_reply.started":"2021-09-14T17:00:06.860585Z","shell.execute_reply":"2021-09-14T17:00:06.863923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all the X variables\nX = train_df.drop([\"price_doc\"], 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:06.86612Z","iopub.execute_input":"2021-09-14T17:00:06.86704Z","iopub.status.idle":"2021-09-14T17:00:06.891566Z","shell.execute_reply.started":"2021-09-14T17:00:06.866847Z","shell.execute_reply":"2021-09-14T17:00:06.890881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = target#.iloc[:10000]","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:06.892839Z","iopub.execute_input":"2021-09-14T17:00:06.893116Z","iopub.status.idle":"2021-09-14T17:00:06.896747Z","shell.execute_reply.started":"2021-09-14T17:00:06.893083Z","shell.execute_reply":"2021-09-14T17:00:06.895974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:06.898022Z","iopub.execute_input":"2021-09-14T17:00:06.898439Z","iopub.status.idle":"2021-09-14T17:00:06.905494Z","shell.execute_reply.started":"2021-09-14T17:00:06.898403Z","shell.execute_reply":"2021-09-14T17:00:06.904615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train test split data into train 80% and cv*(X_test) 20%**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:00:06.906453Z","iopub.execute_input":"2021-09-14T17:00:06.907124Z","iopub.status.idle":"2021-09-14T17:00:07.027385Z","shell.execute_reply.started":"2021-09-14T17:00:06.907081Z","shell.execute_reply":"2021-09-14T17:00:07.026637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:06.444805Z","iopub.execute_input":"2021-09-14T17:15:06.44508Z","iopub.status.idle":"2021-09-14T17:15:06.474729Z","shell.execute_reply.started":"2021-09-14T17:15:06.445052Z","shell.execute_reply":"2021-09-14T17:15:06.473977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"logreg = LinearRegression(n_jobs=-1)\nlogreg.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:07.771859Z","iopub.execute_input":"2021-09-14T17:15:07.77261Z","iopub.status.idle":"2021-09-14T17:15:07.929169Z","shell.execute_reply.started":"2021-09-14T17:15:07.772578Z","shell.execute_reply":"2021-09-14T17:15:07.928399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_log = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:08.072334Z","iopub.execute_input":"2021-09-14T17:15:08.072935Z","iopub.status.idle":"2021-09-14T17:15:08.086355Z","shell.execute_reply.started":"2021-09-14T17:15:08.072904Z","shell.execute_reply":"2021-09-14T17:15:08.085549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = logreg.predict(test_df)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:09.197367Z","iopub.execute_input":"2021-09-14T17:15:09.197991Z","iopub.status.idle":"2021-09-14T17:15:09.214658Z","shell.execute_reply.started":"2021-09-14T17:15:09.19795Z","shell.execute_reply":"2021-09-14T17:15:09.213797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:09.760333Z","iopub.execute_input":"2021-09-14T17:15:09.760869Z","iopub.status.idle":"2021-09-14T17:15:09.764327Z","shell.execute_reply.started":"2021-09-14T17:15:09.760832Z","shell.execute_reply":"2021-09-14T17:15:09.763669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(y_pred_log, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:10.515954Z","iopub.execute_input":"2021-09-14T17:15:10.51624Z","iopub.status.idle":"2021-09-14T17:15:10.527555Z","shell.execute_reply.started":"2021-09-14T17:15:10.516212Z","shell.execute_reply":"2021-09-14T17:15:10.526452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_absolute_error(y_pred_log, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:11.847172Z","iopub.execute_input":"2021-09-14T17:15:11.847852Z","iopub.status.idle":"2021-09-14T17:15:11.857422Z","shell.execute_reply.started":"2021-09-14T17:15:11.847816Z","shell.execute_reply":"2021-09-14T17:15:11.85644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xgboost","metadata":{}},{"cell_type":"code","source":"# Train XGBoost model and validate results\n\nimport xgboost as xgb\nfrom sklearn import metrics\nclf = xgb.XGBRegressor(n_estimators=150, max_depth=7, learning_rate=0.01, min_child_weight=20)\nclf.fit(X_train, y_train)\n\nprint(metrics.mean_squared_error(y_test, clf.predict(X_test))**0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:14.505315Z","iopub.execute_input":"2021-09-14T17:15:14.505608Z","iopub.status.idle":"2021-09-14T17:15:34.693767Z","shell.execute_reply.started":"2021-09-14T17:15:14.505575Z","shell.execute_reply":"2021-09-14T17:15:34.692949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot importances of XGBoost model\n# Some of created features can be noticed in top 50 important features!\nfig, ax = plt.subplots(1, 1, figsize=(8, 16))\nxgb.plot_importance(clf, max_num_features=50, height=0.5, ax=ax);","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:34.697028Z","iopub.execute_input":"2021-09-14T17:15:34.697313Z","iopub.status.idle":"2021-09-14T17:15:35.633835Z","shell.execute_reply.started":"2021-09-14T17:15:34.697281Z","shell.execute_reply":"2021-09-14T17:15:35.633143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot true values vs preicted ones\n\nplt.scatter(y_train, clf.predict(X_train), alpha=0.3, c='red')\nplt.scatter(y_test, clf.predict(X_test), alpha=0.3, c='blue');\nplt.xlabel('true values')\nplt.ylabel('predicted values')\nplt.axis([13,19,13,19])\nplt.plot([13,19],[13,19]);\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:35.635202Z","iopub.execute_input":"2021-09-14T17:15:35.635452Z","iopub.status.idle":"2021-09-14T17:15:35.99667Z","shell.execute_reply.started":"2021-09-14T17:15:35.635418Z","shell.execute_reply":"2021-09-14T17:15:35.99588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:35.998792Z","iopub.execute_input":"2021-09-14T17:15:35.999226Z","iopub.status.idle":"2021-09-14T17:15:36.045616Z","shell.execute_reply.started":"2021-09-14T17:15:35.999185Z","shell.execute_reply":"2021-09-14T17:15:36.044978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:36.04682Z","iopub.execute_input":"2021-09-14T17:15:36.047209Z","iopub.status.idle":"2021-09-14T17:15:36.053979Z","shell.execute_reply.started":"2021-09-14T17:15:36.047175Z","shell.execute_reply":"2021-09-14T17:15:36.053424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n# \"Learn\" the mean from the training data\nmean_train = np.mean(y_train)\n# Get predictions on the test set\nbaseline_predictions = np.ones(y_test.shape) * mean_train\n# Compute MAE\nmae_baseline = mean_squared_error(y_test, baseline_predictions)\nprint(\"Baseline MAE is {:.2f}\".format(mae_baseline))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:36.057361Z","iopub.execute_input":"2021-09-14T17:15:36.059096Z","iopub.status.idle":"2021-09-14T17:15:36.06625Z","shell.execute_reply.started":"2021-09-14T17:15:36.059065Z","shell.execute_reply":"2021-09-14T17:15:36.065108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I chose this parameters for initial testing.\n# We can also use gridsearchcv or randomsearch to select different best features \nparams = {'eta': 0.05, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'silent':1,\n          'min_child_weight': 1, 'gamma': 0, 'objective': 'reg:linear', 'eval_metric': 'rmse'} # default params","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:36.067832Z","iopub.execute_input":"2021-09-14T17:15:36.068294Z","iopub.status.idle":"2021-09-14T17:15:36.074172Z","shell.execute_reply.started":"2021-09-14T17:15:36.068255Z","shell.execute_reply":"2021-09-14T17:15:36.073191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#params['eval_metric'] = \"rmse\"\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:36.07588Z","iopub.execute_input":"2021-09-14T17:15:36.076477Z","iopub.status.idle":"2021-09-14T17:15:36.080735Z","shell.execute_reply.started":"2021-09-14T17:15:36.076443Z","shell.execute_reply":"2021-09-14T17:15:36.079973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_boost_round = 999\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:36.081669Z","iopub.execute_input":"2021-09-14T17:15:36.08211Z","iopub.status.idle":"2021-09-14T17:15:36.087629Z","shell.execute_reply.started":"2021-09-14T17:15:36.082076Z","shell.execute_reply":"2021-09-14T17:15:36.086877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, \"Test\")],\n    early_stopping_rounds=20\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:15:36.0905Z","iopub.execute_input":"2021-09-14T17:15:36.091616Z","iopub.status.idle":"2021-09-14T17:16:30.436262Z","shell.execute_reply.started":"2021-09-14T17:15:36.091577Z","shell.execute_reply":"2021-09-14T17:16:30.435528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\nxgb_cv = model.predict(dtest)\nmean_absolute_error(xgb_cv, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:30.437583Z","iopub.execute_input":"2021-09-14T17:16:30.437826Z","iopub.status.idle":"2021-09-14T17:16:30.504782Z","shell.execute_reply.started":"2021-09-14T17:16:30.437793Z","shell.execute_reply":"2021-09-14T17:16:30.504186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_score(xgb_cv, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:30.506114Z","iopub.execute_input":"2021-09-14T17:16:30.506558Z","iopub.status.idle":"2021-09-14T17:16:30.514259Z","shell.execute_reply.started":"2021-09-14T17:16:30.506508Z","shell.execute_reply":"2021-09-14T17:16:30.513363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(model.predict(dtest), y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:16:30.515585Z","iopub.execute_input":"2021-09-14T17:16:30.516368Z","iopub.status.idle":"2021-09-14T17:16:30.524019Z","shell.execute_reply.started":"2021-09-14T17:16:30.516331Z","shell.execute_reply":"2021-09-14T17:16:30.523257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple LSTM time series(Browser started to get freezed at this point)","metadata":{}},{"cell_type":"markdown","source":"# Things left in time series.\n\n> Prepare the data accordingly considering all previous results and predicting future values Like below link\n\n> https://towardsdatascience.com/simple-multivariate-time-series-forecasting-7fa0e05579b2","metadata":{}},{"cell_type":"code","source":"# !pip install --upgrade tensorflow\n# !pip install --upgrade tensorflow-gpu","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:09:24.442637Z","iopub.execute_input":"2021-09-14T17:09:24.443104Z","iopub.status.idle":"2021-09-14T17:09:24.447855Z","shell.execute_reply.started":"2021-09-14T17:09:24.443075Z","shell.execute_reply":"2021-09-14T17:09:24.447319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! pip install keras","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:09:24.448664Z","iopub.execute_input":"2021-09-14T17:09:24.449221Z","iopub.status.idle":"2021-09-14T17:09:24.45554Z","shell.execute_reply.started":"2021-09-14T17:09:24.449193Z","shell.execute_reply":"2021-09-14T17:09:24.454627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\nimport matplotlib.pyplot as plt\nimport pandas\nimport math\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:09:24.456891Z","iopub.execute_input":"2021-09-14T17:09:24.457288Z","iopub.status.idle":"2021-09-14T17:09:28.470256Z","shell.execute_reply.started":"2021-09-14T17:09:24.457253Z","shell.execute_reply":"2021-09-14T17:09:28.469539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize the dataset\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# normalize the dataset\n#scaler = MinMaxScaler(feature_range=(0, 1))\n#dataset = scaler.fit_transform(dataset)\nX_train_new = np.reshape(X_train, X_train.shape + (1,))\nX_test_new = np.reshape(X_test, X_test.shape + (1,))","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:09:28.471359Z","iopub.execute_input":"2021-09-14T17:09:28.471666Z","iopub.status.idle":"2021-09-14T17:09:28.518237Z","shell.execute_reply.started":"2021-09-14T17:09:28.471633Z","shell.execute_reply":"2021-09-14T17:09:28.517521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training with few epochs and layers because of hanging issue**","metadata":{}},{"cell_type":"code","source":"# Reason I used Dense + LSTM because it's capturing better result.\n# Optimiser is adam\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(X_train.shape[1], 1)))\nmodel.add(Dense(50))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train_new, y_train, epochs=1000, batch_size=64, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:05.716201Z","iopub.execute_input":"2021-09-14T17:13:05.716465Z","iopub.status.idle":"2021-09-14T17:13:16.621443Z","shell.execute_reply.started":"2021-09-14T17:13:05.716434Z","shell.execute_reply":"2021-09-14T17:13:16.620713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_predict = model.predict(X_test_new)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:16.623238Z","iopub.execute_input":"2021-09-14T17:13:16.623609Z","iopub.status.idle":"2021-09-14T17:13:17.339245Z","shell.execute_reply.started":"2021-09-14T17:13:16.623573Z","shell.execute_reply":"2021-09-14T17:13:17.338519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,20), sharey=True)\nplt.title('output plot')\naxs.scatter(list(range(len(y_test))),cv_predict, color=\"red\")\naxs.scatter(list(range(len(y_test))), y_test, color=\"blue\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:17.340709Z","iopub.execute_input":"2021-09-14T17:13:17.340973Z","iopub.status.idle":"2021-09-14T17:13:17.744205Z","shell.execute_reply.started":"2021-09-14T17:13:17.340939Z","shell.execute_reply":"2021-09-14T17:13:17.743536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_absolute_error(cv_predict, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:17.745978Z","iopub.execute_input":"2021-09-14T17:13:17.74631Z","iopub.status.idle":"2021-09-14T17:13:17.754819Z","shell.execute_reply.started":"2021-09-14T17:13:17.746272Z","shell.execute_reply":"2021-09-14T17:13:17.753745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(cv_predict, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:17.756546Z","iopub.execute_input":"2021-09-14T17:13:17.757017Z","iopub.status.idle":"2021-09-14T17:13:17.763808Z","shell.execute_reply.started":"2021-09-14T17:13:17.7568Z","shell.execute_reply":"2021-09-14T17:13:17.762982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n\n> I chose mean_squared_error as metric because it is generally used when large errors are particularly undesirable. Like in this case we are tend to get large errors.\n\n> 2nd metric i tried on in mean absolute error.\n\n> Lstm + dense model tend to have worked better","metadata":{}},{"cell_type":"markdown","source":"# Comparision","metadata":{}},{"cell_type":"code","source":"! pip install prettytable","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:17.764936Z","iopub.execute_input":"2021-09-14T17:13:17.765708Z","iopub.status.idle":"2021-09-14T17:13:25.589109Z","shell.execute_reply.started":"2021-09-14T17:13:17.76567Z","shell.execute_reply":"2021-09-14T17:13:25.58826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from prettytable import PrettyTable\nx=PrettyTable()\nx.field_names = [\"Model\", \"mean_squared_error\", \"mean_absolute_error\"]\n\nx.add_row([\"Lstm\", f\"{mean_squared_error(cv_predict, y_test)}\", f\"{mean_absolute_error(cv_predict, y_test)}\"])\nx.add_row([\"Xgboost\", f\"{mean_squared_error(xgb_cv, y_test)}\", f\"{mean_absolute_error(xgb_cv, y_test)}\"])\nx.add_row([\"linear regression\", f\"{mean_squared_error(y_pred_log, y_test)}\", f\"{mean_absolute_error(y_pred_log, y_test)}\"])\n\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T17:13:25.591004Z","iopub.execute_input":"2021-09-14T17:13:25.591285Z","iopub.status.idle":"2021-09-14T17:13:25.607611Z","shell.execute_reply.started":"2021-09-14T17:13:25.591248Z","shell.execute_reply":"2021-09-14T17:13:25.606684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}