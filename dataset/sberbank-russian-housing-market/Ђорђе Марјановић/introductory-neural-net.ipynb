{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e832c671-0681-870b-81df-833282070a91"},"source":"Neural Net Sample.  I have not yet tuned this succesfully (I've tried!), and can only approach 0.32 error on the leaderboard( which is not the same as the error listed below--there is not a strong relation between training/cv error ans submission error).  I chose 5 epochs for demonstration--I have a GPU so can (and have done) do 100 epoch 5 split CVs w/o issue."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2894ff91-ea43-5d35-1ba7-f81eb39b311c"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\ntrain=pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\nn=train.shape[0]\ntrain['data_set']=1\ntest['data_set']=0\ntest.price_doc=np.nan\nids=test['id']\ntrain.price_doc=np.log(train.price_doc)\ntarget=train.price_doc\ntrain=train.append(test)\ntrain.drop(['id'],axis=1,inplace=True)\nbinary=[]\nfor i in train:\n    if train[i].dtypes=='object':\n        #print(train[i].value_counts())\n        if train[i].value_counts().shape[0]==2:\n            binary.append(i)\nfor i in binary:\n    train[i]=pd.factorize(train[i])[0]\ntrain.loc[train['ecology']=='no data','ecology_dat']=0\ntrain.loc[train['ecology']!='no data','ecology_dat']=1\ntrain.loc[train['ecology']=='no data','ecology']=np.nan\ntrain.loc[train['ecology']=='poor','ecology']=1\ntrain.loc[train['ecology']=='satisfactory','ecology']=2\ntrain.loc[train['ecology']=='good','ecology']=3\ntrain.loc[train['ecology']=='excellent','ecology']=4\ntrain.ecology=pd.to_numeric(train.ecology)\ntrain=pd.concat([train,pd.get_dummies(train.sub_area)],axis=1)\n\na=train.describe()\nfor i in a:\n    train[i]=train[i].fillna((a.loc['min',i]-a.loc['max',i]*2))\n    \ntrain.drop(['timestamp','sub_area'],inplace=True,axis=1)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ncols=train.columns.tolist()\n\ntrain = pd.DataFrame(scaler.fit_transform(train), columns=cols)\n\"\"\"\nfor i in train:    \n    train[i]=train[i]/(train[i].max()-train[i].min())\n\"\"\"\ntest=train[train['data_set']==0]\ntrain=train[train['data_set']==1]\nprint(test.shape,train.shape,n)\ntest.drop(['data_set','price_doc',],inplace=True,axis=1)\ntrain.drop(['data_set','price_doc'],inplace=True,axis=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ed286c35-b0a7-9633-001c-a7173ac81964"},"source":"Lets get our Neural Net setup.  I used a refernce to pick my hidden layers\nhttps://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n\nNh=Ns/(α∗(Ni+No))\n\nNi = number of input neurons.\n\nNo = number of output neurons.\n\nNs = number of samples in training data set.\n\nα = an arbitrary scaling factor usually 2-10."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea413fd7-a22b-c35f-a4c8-2b8c81e9e43b"},"outputs":[],"source":"from sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.optimizers import SGD\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"dcbaeac2-4c4b-7077-8be5-b04a79b08623"},"source":"You can see if you turn on validation (and on the CV) that the validation loss tends to be less than training loss--this is quite a worry.  I have tuned training rates and dropouts to improve this without much success.  Notice here I am only training on half the data, you may remove the validation split, I wanted to split the data to show the difference in training and validation loss--how the validation loss is typically below training loss (not good!)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bbf0355d-d61e-c337-8d68-0f3bae82a0c4"},"outputs":[],"source":"    model = Sequential()\n    \n    model.add(Dense(40, input_dim = train.shape[1], init = 'he_normal'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(40, init = 'he_normal'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())    \n    model.add(Dense(20, init = 'he_normal'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())    \n    model.add(Dense(1, init = 'he_normal'))\n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    outputs=model.fit(train.as_matrix(),target.as_matrix() , batch_size=32, nb_epoch=5, verbose=1,validation_split=0.5)\n    preds=model.predict( test.as_matrix(), batch_size=32, verbose=0)\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83531e70-4474-f8e7-a8f6-5c59e6459059"},"outputs":[],"source":"y=np.reshape(preds,preds.shape[0])\ny=np.exp(y)\nsubs=pd.DataFrame({'id':ids.as_matrix(),'price_doc':y})\nsubs.to_csv(\"test_smallnn.csv\",index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6671a3ee-cd81-010c-096d-9027253186b9"},"source":"For CV testing, I have used below.  Includes Early Stopping.  I had dropout when using larger nets, and feel free to tune as needed.  While it is not quite 'Black Box' I have not found a consistent manner to estimate my submission error for this challenge."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4827087c-df71-4471-67cd-ee621d004048"},"outputs":[],"source":"\"\"\"\nfrom sklearn.cross_validation import KFold\npredict_x=np.zeros(train.shape[0])\nkf=KFold(train.shape[0],n_folds=5)\noutputs_all=[]\n\nfor train_index, target_index in kf:\n    model = Sequential()\n    \n    model.add(Dense(40, input_dim = train.loc[train_index,].shape[1], init = 'he_normal'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.4))\n\n    model.add(Dense(40, init = 'he_normal'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())    \n    #model.add(Dropout(0.2))\n    model.add(Dense(20, init = 'he_normal'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())    \n    #model.add(Dropout(0.2))\n\n    model.add(Dense(1, init = 'he_normal'))\n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    callbacks = [\n    EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n    \n    ]\n    outputs=model.fit(train.loc[train_index,].as_matrix(),target[train_index].as_matrix() , batch_size=32, \n                      nb_epoch=100, verbose=1,\n                      validation_data=[train.loc[target_index,].as_matrix(),target[target_index].as_matrix()],\n                      callbacks=callbacks\n                     )\n    outputs_all.append(outputs)\n    preds=model.predict( train.loc[target_index,].as_matrix(), batch_size=32, verbose=0)\n    predict_x[target_index]=preds\n    \"\"\""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}