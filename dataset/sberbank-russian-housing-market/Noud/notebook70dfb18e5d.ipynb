{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7e760510-e332-c461-5551-37aa91bf21ae"},"source":"Quick data exploration of Sberbank Rusian Housing"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f520c3c-755a-ae31-588f-2ae191352b61"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nimport matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\n\nimport xgboost as xgb\n\nfrom time import mktime\nfrom datetime import datetime\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3b61b4c-fd86-65d1-8d88-6b1fe5283bab"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv')\nprint(train_df.shape)\ntrain_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"495a062d-afe6-2a19-f4fc-36c4c5f19319"},"outputs":[],"source":"train_df.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2900ec3-e36b-51d0-957e-05f8f010a461"},"outputs":[],"source":"# Plot histogram of house price values\nplt.figure(figsize = (10, 8))\ndp = sns.distplot(train_df.price_doc.values, bins = 100)\ndp.set_xscale('log')\nplt.xlabel('House price')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24316c4c-1bf6-b8e1-f399-7f12816533ff"},"outputs":[],"source":"# Prepare dataset\n\ntrain_df = train_df.drop(['id'], axis = 1)\n\n# Convert timestamp to Gregorian timestamp\ntoordinal = lambda x : datetime.strptime(x, '%Y-%m-%d').toordinal()\ntrain_df['gregorian'] = train_df['timestamp'].apply(toordinal) # Converts to proleptic Gregorian ordinal.\n\n# Convert catogorical values\nnum_df = train_df.select_dtypes(exclude = ['object'])\nobj_df = train_df.select_dtypes(include = ['object']).copy()\n\nfor c in obj_df:\n    obj_df[c] = pd.factorize(obj_df[c])[0]\n\ntrain_df = pd.concat([num_df, obj_df], axis=1)\ntrain_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"996f7a2c-0f3b-9063-14a1-4b821f83eef7"},"outputs":[],"source":"# Train a simple linear regression classifier with xgboost\nX_train = train_df.drop(['price_doc'], axis = 1)\ny_train = train_df['price_doc']\n\nxgb_params = {\n    'eta': 0.1,\n    'max_depth': 7,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse'\n}\n\ndtrain = xgb.DMatrix(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22d40a52-18e6-076b-95c8-bb5d0ef147ef"},"outputs":[],"source":"cv_result = xgb.cv(xgb_params, dtrain, num_boost_round = 1000, early_stopping_rounds = 50, verbose_eval = True, show_stdv = False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f259668-3092-7b5e-082a-c2f2d42ab927"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}