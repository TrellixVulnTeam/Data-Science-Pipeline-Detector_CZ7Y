{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom scipy.spatial import distance\nfrom keras.models import load_model\nimport pandas as pd\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/train_relationships.csv\")\ntest_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodel_path = '../input/facenet-keras51/facenet_keras.h5'\nmodel = load_model(model_path)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prewhiten(x):\n    if x.ndim == 4:\n        axis = (1, 2, 3)\n        size = x[0].size\n    elif x.ndim == 3:\n        axis = (0, 1, 2)\n        size = x.size\n    else:\n        raise ValueError('Dimension should be 3 or 4')\n\n    mean = np.mean(x, axis=axis, keepdims=True)\n    std = np.std(x, axis=axis, keepdims=True)\n    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n    y = (x - mean) / std_adj\n    return y\n\ndef l2_normalize(x, axis=-1, epsilon=1e-10):\n    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n    return output\n\ndef load_and_align_images(filepaths, margin,image_size = 160):\n    \n    aligned_images = []\n    for filepath in filepaths:\n        img = imread(filepath)\n        aligned = resize(img, (image_size, image_size), mode='reflect')\n        aligned_images.append(aligned)\n            \n    return np.array(aligned_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef calc_embs(filepaths, margin=10, batch_size=512):\n    pd = []\n    for start in tqdm(range(0, len(filepaths), batch_size)):\n        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n        pd.append(model.predict_on_batch(aligned_images))\n    embs = l2_normalize(np.concatenate(pd))\n\n    return embs\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntest_images = os.listdir(\"../input/recognizing-faces-in-the-wild/test/\")\ntest_embs = calc_embs([os.path.join(\"../input/recognizing-faces-in-the-wild/test/\", f) for f in test_images])\nnp.save(\"test_embs.npy\", test_embs)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"distance\"] = 0\nimg2idx = dict()\nfor idx, img in enumerate(test_images):\n    img2idx[img] = idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    imgs = [test_embs[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    test_df.loc[idx, \"distance\"] = distance.euclidean(*imgs)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nall_distances = test_df.distance.values\nsum_dist = np.sum(all_distances)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = []\nfor dist in tqdm(all_distances):\n    prob = np.sum(all_distances[np.where(all_distances <= dist)[0]])/sum_dist\n    probs.append(1 - prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")\nsub_df.is_related = probs\nsub_df.to_csv(\"TeguhSubmission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}