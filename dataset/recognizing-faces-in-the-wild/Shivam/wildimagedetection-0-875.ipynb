{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/rcmalli/keras-vggface.git","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting git+https://github.com/rcmalli/keras-vggface.git\n  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-e1xbclqa\n  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-e1xbclqa\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (1.16.4)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (1.3.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (2.9.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (5.4.1)\nRequirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (2.2.4)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (1.12.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (5.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-vggface==0.5) (1.1.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-vggface==0.5) (1.0.8)\nBuilding wheels for collected packages: keras-vggface\n  Building wheel for keras-vggface (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-kfzzvqej/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\nSuccessfully built keras-vggface\nInstalling collected packages: keras-vggface\nSuccessfully installed keras-vggface-0.5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom glob import glob\nfrom random import choice, sample\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.optimizers import Adam\nfrom keras_vggface.utils import preprocess_input\nfrom keras_vggface.vggface import VGGFace\nimport h5py","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file_path = \"../input/train_relationships.csv\"\ntrain_folders_path = \"../input/train/\"\nval_famillies = \"F09\"","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_images = glob(train_folders_path + \"*/*/*.jpg\")\ntrain_images = [x for x in all_images if val_famillies not in x]\nval_images = [x for x in all_images if val_famillies in x]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_person_to_images_map = defaultdict(list)\nppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n\nfor x in train_images:\n    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n\nval_person_to_images_map = defaultdict(list)\n\nfor x in val_images:\n    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relationships = pd.read_csv(train_file_path)\nrelationships = list(zip(relationships.p1.values, relationships.p2.values))\nrelationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = [x for x in relationships if val_famillies not in x[0]]\nval = [x for x in relationships if val_famillies in x[0]]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_img(path):\n    img = image.load_img(path, target_size=(197, 197))\n    img = np.array(img).astype(np.float)\n    return preprocess_input(img, version=2)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen(list_tuples, person_to_images_map, batch_size=16):\n    ppl = list(person_to_images_map.keys())\n    while True:\n        batch_tuples = sample(list_tuples, batch_size // 2)\n        labels = [1] * len(batch_tuples)\n        while len(batch_tuples) < batch_size:\n            p1 = choice(ppl)\n            p2 = choice(ppl)\n\n            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n                batch_tuples.append((p1, p2))\n                labels.append(0)\n\n        for x in batch_tuples:\n            if not len(person_to_images_map[x[0]]):\n                print(x[0])\n\n        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n        X1 = np.array([read_img(x) for x in X1])\n\n        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n        X2 = np.array([read_img(x) for x in X2])\n\n        yield [X1, X2], labels\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline_model():\n    input_1 = Input(shape=(197, 197, 3))\n    input_2 = Input(shape=(197, 197, 3))\n\n    base_model = VGGFace(model='resnet50', include_top=False)\n\n    for x in base_model.layers[:-3]:\n        x.trainable = True\n\n    x1 = base_model(input_1)\n    x2 = base_model(input_2)\n\n    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n\n    x3 = Subtract()([x1, x2])\n    x3 = Multiply()([x3, x3])\n\n    x1_ = Multiply()([x1, x1])\n    x2_ = Multiply()([x2, x2])\n    x4 = Subtract()([x1_, x2_])\n    x = Concatenate(axis=-1)([x4, x3])\n\n    x = Dense(100, activation=\"relu\")(x)\n    x = Dropout(0.01)(x)\n    out = Dense(1, activation=\"sigmoid\")(x)\n\n    model = Model([input_1, input_2], out)\n\n    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n\n    model.summary()\n\n    return model","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = \"vgg_face.h5\"\n\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nreduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n\ncallbacks_list = [checkpoint, reduce_on_plateau]\n\nmodel = baseline_model()\nmodel.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)\n\ntest_path = \"../input/test/\"","execution_count":null,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_10 (InputLayer)           (None, 197, 197, 3)  0                                            \n__________________________________________________________________________________________________\ninput_11 (InputLayer)           (None, 197, 197, 3)  0                                            \n__________________________________________________________________________________________________\nvggface_resnet50 (Model)        multiple             23561152    input_10[0][0]                   \n                                                                 input_11[0][0]                   \n__________________________________________________________________________________________________\nglobal_max_pooling2d_5 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n__________________________________________________________________________________________________\nglobal_average_pooling2d_5 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n__________________________________________________________________________________________________\nglobal_max_pooling2d_6 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n__________________________________________________________________________________________________\nglobal_average_pooling2d_6 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 4096)         0           global_max_pooling2d_5[0][0]     \n                                                                 global_average_pooling2d_5[0][0] \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 4096)         0           global_max_pooling2d_6[0][0]     \n                                                                 global_average_pooling2d_6[0][0] \n__________________________________________________________________________________________________\nmultiply_8 (Multiply)           (None, 4096)         0           concatenate_8[0][0]              \n                                                                 concatenate_8[0][0]              \n__________________________________________________________________________________________________\nmultiply_9 (Multiply)           (None, 4096)         0           concatenate_9[0][0]              \n                                                                 concatenate_9[0][0]              \n__________________________________________________________________________________________________\nsubtract_6 (Subtract)           (None, 4096)         0           concatenate_8[0][0]              \n                                                                 concatenate_9[0][0]              \n__________________________________________________________________________________________________\nsubtract_7 (Subtract)           (None, 4096)         0           multiply_8[0][0]                 \n                                                                 multiply_9[0][0]                 \n__________________________________________________________________________________________________\nmultiply_7 (Multiply)           (None, 4096)         0           subtract_6[0][0]                 \n                                                                 subtract_6[0][0]                 \n__________________________________________________________________________________________________\nconcatenate_10 (Concatenate)    (None, 8192)         0           subtract_7[0][0]                 \n                                                                 multiply_7[0][0]                 \n__________________________________________________________________________________________________\ndense_10 (Dense)                (None, 100)          819300      concatenate_10[0][0]             \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 100)          0           dense_10[0][0]                   \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 1)            101         dropout_7[0][0]                  \n==================================================================================================\nTotal params: 24,380,553\nTrainable params: 24,327,433\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\nEpoch 1/110\n200/200 [==============================] - 115s 577ms/step - loss: 3.6487 - acc: 0.5909 - val_loss: 3.9630 - val_acc: 0.5863\n\nEpoch 00001: val_acc improved from -inf to 0.58625, saving model to vgg_face.h5\nEpoch 2/110\n200/200 [==============================] - 66s 328ms/step - loss: 2.0958 - acc: 0.6103 - val_loss: 2.3433 - val_acc: 0.6044\n\nEpoch 00002: val_acc improved from 0.58625 to 0.60437, saving model to vgg_face.h5\nEpoch 3/110\n200/200 [==============================] - 66s 328ms/step - loss: 1.1525 - acc: 0.6319 - val_loss: 1.4406 - val_acc: 0.6106\n\nEpoch 00003: val_acc improved from 0.60437 to 0.61062, saving model to vgg_face.h5\nEpoch 4/110\n191/200 [===========================>..] - ETA: 2s - loss: 0.7919 - acc: 0.6463","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def chunker(seq, size=32):\n    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n\n\nfrom tqdm import tqdm\n\nsubmission = pd.read_csv('../input/sample_submission.csv')\n\npredictions = []\n\nfor batch in tqdm(chunker(submission.img_pair.values)):\n    X1 = [x.split(\"-\")[0] for x in batch]\n    X1 = np.array([read_img(test_path + x) for x in X1])\n\n    X2 = [x.split(\"-\")[1] for x in batch]\n    X2 = np.array([read_img(test_path + x) for x in X2])\n\n    pred = model.predict([X1, X2]).ravel().tolist()\n    predictions += pred\n\nsubmission['is_related'] = predictions\n\nsubmission.to_csv(\"vgg_face.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}