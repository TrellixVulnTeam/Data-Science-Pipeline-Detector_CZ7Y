{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,Activation, Dropout, BatchNormalization,  GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Subtract,Multiply\nfrom keras.models import Model, Sequential\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom skimage.io import imshow\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport random\nimport cv2\nimport os\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras_vggface\nfrom keras.engine import  Model\nfrom keras.layers import Input\nfrom keras_vggface.vggface import VGGFace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_train_dir = \"../input/train/\"\n\ndef train_image():\n    train_image = map(lambda f : os.path.join(input_train_dir, f) , os.listdir(\"%s\" % input_train_dir))\n    train_images = []\n    for f in train_image:\n        for d in os.listdir(f):\n            p = os.path.join(f,d)\n            train_images.extend([os.path.join(p,l) for l in os.listdir(p) ] )\n    \n    return train_images\n\ntrain_images = train_image()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def f_path(x):\n    r = []\n    for i in train_images:\n        if x in i:\n            r.append(i)\n    if r != []:\n        return random.choice(r)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train_relationships.csv\")\ntrain_df['p1_path'] = train_df['p1'].apply(lambda x : f_path(x) )\ntrain_df['p2_path'] = train_df['p2'].apply(lambda x : f_path(x) )\ntrain_df['add'] = train_df['p1'] + train_df['p2']\ntrain_df = train_df[train_df['p1']!=train_df['p1_path']]\ntrain_df = train_df[train_df['p2']!=train_df['p2_path']]\ntrain_df[\"target\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_shuffle = 1\ntrain_target_0 = pd.concat([ train_df.copy() for i in range(n_shuffle)],ignore_index=True)\ntrain_target_0['target'] = 0\np1_shuffle = train_target_0[['p1','p1_path']].values\nnp.random.shuffle(p1_shuffle)\ntrain_target_0[['p1','p1_path']] = p1_shuffle\np2_shuffle = train_target_0[['p2','p2_path']].values\nnp.random.shuffle(p2_shuffle)\ntrain_target_0[['p2','p2_path']] = p2_shuffle\ntrain_target_0['add'] = train_target_0['p1'] + train_target_0['p2']\ndata_1 = list(train_df['add'].values)\ndata_0 = list(train_target_0['add'].values)\ndata = []\nfor d in data_0:\n    if d in data_1:\n        data.append(d)\ntrain_target_0 = train_target_0[~train_target_0['add'].isin(data)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_concate = pd.concat([train_df, train_target_0], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_concate['family1'] = train_concate['p1'].apply(lambda x : x.split('/')[0])\ntrain_concate['family2'] = train_concate['p2'].apply(lambda x : x.split('/')[0])\n# Family approach\ntrain_concate['target'] = train_concate[['family1', 'family2']].apply(lambda x : 1 if x['family1'] == x['family2'] else 0, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of data %d' % len(train_concate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shape = (224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_concate = train_concate.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Siamese NN \n(credits : https://www.kaggle.com/arpandhatt/siamese-neural-networks)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# We have 2 inputs, 1 for each picture\nleft_input = Input(shape)\nright_input = Input(shape)\n\n# We will use 2 instances of 1 network for this task\nconvnet = Sequential([\n    Conv2D(32,3, input_shape=shape),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(16,3),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(8,2),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(4,2),\n    BatchNormalization(),\n    Activation('relu'),\n    Flatten(),\n    Dense(2),\n    Activation('sigmoid')\n])\n# Connect each 'leg' of the network to each input\n# Remember, they have the same weights\nencoded_l = convnet(left_input)\nencoded_r = convnet(right_input)\n\n# Getting the L1 Distance between the 2 encodings\nL1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n\n# Add the distance function to the network\nL1_distance = L1_layer([encoded_l, encoded_r])\n\nprediction = Dense(1,activation='sigmoid')(L1_distance)\nsiamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n\noptimizer = Adam(0.001, decay=2.5e-4)\n#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\nsiamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Siamese With VGG_FACE\nhttps://github.com/rcmalli/keras-vggface"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef baseline_model():\n    vgg_features = VGGFace(include_top=False, input_shape=shape, pooling='avg') # pooling: None, avg or max\n    input_1 = Input(shape=shape)\n    input_2 = Input(shape=shape)\n\n    base_model = VGGFace(include_top=False, input_shape=shape, pooling='avg')\n\n    for x in base_model.layers[:-3]:\n        x.trainable = True\n\n    x1 = base_model(input_1)\n    x2 = base_model(input_2)\n\n    \n    \n    \n    L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n\n    # Add the distance function to the network\n    x = L1_layer([x1, x2])\n    out = Dense(1, activation=\"sigmoid\")(x)\n\n    model = Model([input_1, input_2], out)\n\n    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n\n    model.summary()\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histories = {\"loss\":[], 'acc' : []}\nhistories_vgg = {\"loss\":[], 'acc' : []}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\nfor _ in tqdm_notebook(range(50), desc=\"Epochs ...\"):\n    left_data = []\n    right_data = []\n    targets = []\n    for i in tqdm_notebook(range(len(train_concate)), desc=\"Files process ...\", leave=False):\n        dt = train_concate.iloc[i].to_dict()\n        left_img = cv2.imread(dt['p1_path'])\n        left_img = cv2.resize(left_img, (shape[0], shape[1]))\n        left_data.append(left_img)\n\n        right_img = cv2.imread(dt['p2_path'])\n        right_img = cv2.resize(right_img, (shape[0], shape[1]))\n        right_data.append(right_img)\n        targets.append(dt['target'])\n\n        if  len(left_data) % batch_size ==0:\n            left_data = np.squeeze(np.array(left_data))\n            right_data = np.squeeze(np.array(right_data))\n            targets = np.squeeze(np.array(targets))\n            history = siamese_net.train_on_batch([left_data,right_data], targets)\n            #history_vgg = siamese_net_vgg.train_on_batch([left_data,right_data], targets)\n            left_data = []\n            right_data = []\n            targets = []\n\n    left_data = np.squeeze(np.array(left_data))\n    right_data = np.squeeze(np.array(right_data))\n    targets = np.squeeze(np.array(targets))\n    history = siamese_net.train_on_batch([left_data,right_data], targets)\n    left_data = []\n    right_data = []\n    targets = []\n    histories['loss'].append(history[0])\n    histories['acc'].append(history[1])\n    #histories_vgg['loss'].append(history_vgg[0])\n    #histories_vgg['acc'].append(history_vgg[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# summarize history for accuracy\nplt.plot(histories['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overfitting ... "},{"metadata":{"trusted":true},"cell_type":"code","source":"# # summarize history for accuracy\n# plt.plot(histories_vgg['acc'])\n# plt.title('model accuracy')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['train'], loc='upper left')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"../input/test/\"\ntest_df = pd.read_csv(\"../input/sample_submission.csv\")\ntest_df['p1_path'] = test_df['img_pair'].apply(lambda x : os.path.join(test_path, x.split('-')[0] ))\ntest_df['p2_path'] = test_df['img_pair'].apply(lambda x : os.path.join(test_path, x.split('-')[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_left = []\ntest_img_right = []\n\nfor i in range(len(test_df)):\n    \n    dt = test_df.iloc[i].to_dict()\n    left_img = cv2.imread(dt['p1_path'])\n    left_img = cv2.resize(left_img, (shape[0], shape[1]))\n    test_img_left.append(left_img)\n    \n    right_img = cv2.imread(dt['p2_path'])\n    right_img = cv2.resize(right_img, (shape[0], shape[1]))\n    test_img_right.append(right_img)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_data = np.squeeze(np.array(test_img_left))\nright_data = np.squeeze(np.array(test_img_right))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = test_df[['img_pair']]\nsub['is_related'] = siamese_net.predict([left_data,right_data])\nsub.to_csv('sub.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub = test_df[['img_pair']]\n# sub['is_related'] = siamese_net_vgg.predict([left_data,right_data])\n# sub.to_csv('sub_vgg.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}