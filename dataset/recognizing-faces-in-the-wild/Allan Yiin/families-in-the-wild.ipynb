{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#這是jupyter notebook的magic word˙\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom IPython import display","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-10T09:23:52.151327Z","iopub.execute_input":"2021-10-10T09:23:52.152194Z","iopub.status.idle":"2021-10-10T09:23:52.248688Z","shell.execute_reply.started":"2021-10-10T09:23:52.152089Z","shell.execute_reply":"2021-10-10T09:23:52.247697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 視覺親緣鑑定","metadata":{}},{"cell_type":"code","source":"import os\n#判斷是否在jupyter notebook上\ndef is_in_ipython():\n    \"Is the code running in the ipython environment (jupyter including)\"\n    program_name = os.path.basename(os.getenv('_', ''))\n\n    if ('jupyter-notebook' in program_name or # jupyter-notebook\n        'ipython'          in program_name or # ipython\n        'jupyter' in program_name or  # jupyter\n        'JPY_PARENT_PID'   in os.environ):    # ipython-notebook\n        return True\n    else:\n        return False\n\n\n#判斷是否在colab上\ndef is_in_colab():\n    if not is_in_ipython(): return False\n    try:\n        from google import colab\n        return True\n    except: return False\n\n#判斷是否在kaggke_kernal上\ndef is_in_kaggle_kernal():\n    if 'kaggle' in os.environ['PYTHONPATH']:\n        return True\n    else:\n        return False\n\nif is_in_colab():\n    from google.colab import drive\n    drive.mount('/content/gdrive')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:23:52.251519Z","iopub.execute_input":"2021-10-10T09:23:52.251916Z","iopub.status.idle":"2021-10-10T09:23:52.262557Z","shell.execute_reply.started":"2021-10-10T09:23:52.251858Z","shell.execute_reply":"2021-10-10T09:23:52.261173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ['TRIDENT_BACKEND'] = 'pytorch'\n\nif is_in_kaggle_kernal():\n    os.environ['TRIDENT_HOME'] = './trident'\n    \nelif is_in_colab():\n    os.environ['TRIDENT_HOME'] = '/content/gdrive/My Drive/trident'\n\n#為確保安裝最新版 \n\n!pip uninstall tridentx -y\n!pip install ../input/trident/tridentx-0.7.3.20-py3-none-any.whl --upgrade\n#!pip install cupy\n\nimport json\nimport copy\nimport numpy as np\n#調用trident api\nimport trident as T\nfrom trident import *\n\nfrom trident.layers.pytorch_initializers import orthogonal\nimport random\nfrom tqdm import tqdm\nimport glob\nimport scipy\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:23:52.264885Z","iopub.execute_input":"2021-10-10T09:23:52.265634Z","iopub.status.idle":"2021-10-10T09:24:19.741002Z","shell.execute_reply.started":"2021-10-10T09:23:52.265589Z","shell.execute_reply":"2021-10-10T09:24:19.739812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_dir_if_need('./train-faces')\n!unzip ../input/recognizing-faces-in-the-wild/train-faces.zip -d ./train-faces","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-10-10T09:24:19.742853Z","iopub.execute_input":"2021-10-10T09:24:19.743201Z","iopub.status.idle":"2021-10-10T09:24:25.553413Z","shell.execute_reply.started":"2021-10-10T09:24:19.743143Z","shell.execute_reply":"2021-10-10T09:24:25.552176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"family_labels=glob.glob('./train-faces/F*')\nfamily_labels=list(sorted(set([f.replace('./train-faces/','') for f in family_labels])))\nprint(len(family_labels))\nprint(family_labels[:10])\n\nperson_labels=glob.glob('./train-faces/F*/MID*')\nperson_labels=list(sorted(set([f.replace('./train-faces/','') for f in person_labels])))\nprint(len(person_labels))\nprint(person_labels[:10])","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:25.557773Z","iopub.execute_input":"2021-10-10T09:24:25.558073Z","iopub.status.idle":"2021-10-10T09:24:25.617015Z","shell.execute_reply.started":"2021-10-10T09:24:25.558027Z","shell.execute_reply":"2021-10-10T09:24:25.615802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=[]\nfamilies=[]\npersons=[]\ntrain_faces=glob.glob('./train-faces/F*/MID*/*.jpg')\nprint(len(train_faces))\nfor i in tqdm(range(len(train_faces))):\n    im_path=train_faces[i]\n    cols=im_path.split('/')\n    images.append(im_path)\n    families.append(family_labels.index(cols[-3]))\n    persons.append(person_labels.index(cols[-3]+'/'+cols[-2]))\n\nprint(images[:10])\nprint(families[:10])\nprint(persons[:10])\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:25.61874Z","iopub.execute_input":"2021-10-10T09:24:25.619109Z","iopub.status.idle":"2021-10-10T09:24:27.160933Z","shell.execute_reply.started":"2021-10-10T09:24:25.619069Z","shell.execute_reply":"2021-10-10T09:24:27.159672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds1=ImageDataset(images,object_type=ObjectType.rgb, symbol='images')\nds2=LabelDataset(families,object_type=ObjectType.classification_label, symbol='families_label')\nds3=LabelDataset(persons, object_type=ObjectType.classification_label,symbol='persons_label')\n\n\nzipdata=ZipDataset(ds2,ds3)\ndata_provider=DataProvider(traindata=Iterator(data=ds1,label=zipdata))\ndata_provider.image_transform_funcs=[\n    Resize(output_size=(112,112)),\n    RandomTransform(rotation_range= 15, zoom_range= 0.02, shift_range= 0.00,shear_range = 0.02,random_flip= 0.15),\n    RandomAdjustGamma(gamma_range=(0.6,1.4)),\n    RandomAdjustContrast(value_range=(0.6,1.4)),\n    RandomAdjustHue(scale=(-0.3,0.3)),#調整色相\n    RandomAdjustSaturation(scale=(0.6,1.4)),#調整飽和度\n    RandomBlur(scale=(3,7)),#隨機模糊\n    SaltPepperNoise(prob=0.001),#椒鹽噪音\n    RandomErasing(size_range=(0.08,0.2),transparency_range=(0.4,0.6),transparancy_ratio=0.8),\n    Normalize(127.5,127.5)]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:27.16304Z","iopub.execute_input":"2021-10-10T09:24:27.163419Z","iopub.status.idle":"2021-10-10T09:24:27.214775Z","shell.execute_reply.started":"2021-10-10T09:24:27.163363Z","shell.execute_reply":"2021-10-10T09:24:27.213759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_data,label1,label2=data_provider.next()\nprint(img_data.shape)\nprint(label1.shape)\nprint(label2.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:27.216235Z","iopub.execute_input":"2021-10-10T09:24:27.216955Z","iopub.status.idle":"2021-10-10T09:24:27.31254Z","shell.execute_reply.started":"2021-10-10T09:24:27.216909Z","shell.execute_reply":"2021-10-10T09:24:27.311507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_provider.preview_images()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:27.313822Z","iopub.execute_input":"2021-10-10T09:24:27.314471Z","iopub.status.idle":"2021-10-10T09:24:27.454Z","shell.execute_reply.started":"2021-10-10T09:24:27.314414Z","shell.execute_reply":"2021-10-10T09:24:27.453077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trident.models import arcfacenet\nnum_faces=10575\n#標準生成結構\n#不包含原有分類器\nse_resnet50 =arcfacenet.SEResNet_IR_50_512(include_top=False,\n             pretrained=True,\n             freeze_features=True,\n             input_shape=(3,112,112))\n\n#加入output_layer\nse_resnet50.model.add_module('output_layer', \n    Sequential(\n        Dropout(dropout_rate=0.4),\n        Flatten(),\n        Dense((512),use_bias=False,keep_output=True),\n    ))\n\n#se_resnet50.model.output_layer[0].inplace = False\n#從之前預訓練的人臉識別arcFace還原權重\nse_resnet50.model.add_module('l2norm',L2Norm())\nse_resnet50.model.add_module('fc',Dense((num_faces),use_bias=False,weights_norm='l2'))\nif os.path.exists('../input/face-recognition/Models/arcface.pth.tar'):\n    se_resnet50.load_model('../input/face-recognition/Models/arcface.pth.tar')\n\nse_resnet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:27.455235Z","iopub.execute_input":"2021-10-10T09:24:27.456348Z","iopub.status.idle":"2021-10-10T09:24:40.283054Z","shell.execute_reply.started":"2021-10-10T09:24:27.456306Z","shell.execute_reply":"2021-10-10T09:24:40.282078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"所以接下來我們要稍微改裝一下我們預訓練好的arcface，首先我們的輸出必須改成兩組，一個是親屬關係，另一個是個人，等於是我們的人臉識別模型同時要識別這兩者差異。","metadata":{}},{"cell_type":"code","source":"se_resnet50.model.trainable=False\nse_resnet50.model.body[23].trainable=True\nse_resnet50.model.remove_at(-1)\nresults=ModuleDict({'family':Dense(786),'person':Dense(3965),'features':Identity()},is_multicasting=True)\nse_resnet50.model.add_module('results',results)\n\n\nse_resnet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:40.284619Z","iopub.execute_input":"2021-10-10T09:24:40.284965Z","iopub.status.idle":"2021-10-10T09:24:40.552482Z","shell.execute_reply.started":"2021-10-10T09:24:40.284923Z","shell.execute_reply":"2021-10-10T09:24:40.551325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在損失函數上仍然是使用arcFace，只不過這邊的分類要變成兩個階層，一個是判斷是哪一個家族，再來才是判斷是哪一個個人。由於兩者層級不同，根據組內差距小、組間差距大的原則，可以得知家族間的差異應該要大於個人間的差異。因此我們把同樣的arcFace的損失函數複製兩份，修改兩者的Forward部分，同時我們把家族的損失函數的Margin以及Scale都放大一倍。  \n同時也在此定義了家族與個人分類的準確率函數。","metadata":{}},{"cell_type":"code","source":"\nclass Family_ArcMarginProductLoss(Layer):\n    def __init__(self, scale=64.0, margin=1, easy_margin=False, name='ArcMarginProductLoss'):\n        super(Family_ArcMarginProductLoss, self).__init__()\n        self._name=name\n        self.scale = scale\n        self.m = margin\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(margin)\n        self.sin_m = math.sin(margin)\n\n        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n        self.th = math.cos(math.pi - margin)\n        self.mm = math.sin(math.pi - margin) * margin\n    \n        self.base_loss=CrossEntropyLoss(reduction='mean')\n\n\n    def forward(self, family, families_label,**kwargs):\n        # cos(theta)\n        try:\n            cosine=family\n            target=families_label\n            # cos(theta + m)\n            sine = sqrt(1.0 - pow(cosine, 2))\n            phi = cosine * self.cos_m - sine * self.sin_m\n\n            if self.easy_margin:\n                phi = where(cosine > 0, phi, cosine)\n            else:\n                phi = where((cosine - self.th) > 0, phi, cosine - self.mm)\n\n            one_hot = zeros_like(cosine,requires_grad=True)\n            one_hot.scatter(1, target.view(-1, 1), 1)\n\n            output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n            output = output * self.scale\n        except Exception as e:\n            print(e)\n            PrintException()\n\n        loss = self.base_loss(output, target)\n        return loss\n    \n    \nclass Person_ArcMarginProductLoss(Layer):\n    def __init__(self, scale=32.0, margin=0.50, easy_margin=False, name='ArcMarginProductLoss'):\n        super(Person_ArcMarginProductLoss, self).__init__()\n        self._name=name\n        self.scale = scale\n        self.m = margin\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(margin)\n        self.sin_m = math.sin(margin)\n\n        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n        self.th = math.cos(math.pi - margin)\n        self.mm = math.sin(math.pi - margin) * margin\n    \n        self.base_loss=CrossEntropyLoss(reduction='mean')\n\n\n    def forward(self, person, persons_label,**kwargs):\n        # cos(theta)\n        try:\n            cosine=person\n            target=persons_label\n            # cos(theta + m)\n            sine = sqrt(1.0 - pow(cosine, 2))\n            phi = cosine * self.cos_m - sine * self.sin_m\n\n            if self.easy_margin:\n                phi = where(cosine > 0, phi, cosine)\n            else:\n                phi = where((cosine - self.th) > 0, phi, cosine - self.mm)\n\n            one_hot = zeros_like(cosine,requires_grad=True)\n            one_hot.scatter(1, target.view(-1, 1), 1)\n\n            output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n            output = output * self.scale\n        except Exception as e:\n            print(e)\n            PrintException()\n\n        loss = self.base_loss(output, target)\n        return loss\n    \ndef center_loss(features,families_label):\n    return CenterLoss(num_classes=786, feat_dim=512)(features,families_label)\n    \ndef family_accuracy(family, families_label):\n    return accuracy(family, families_label)\n\n    \ndef person_accuracy(person, persons_label):\n    return accuracy(person, persons_label)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:40.554706Z","iopub.execute_input":"2021-10-10T09:24:40.555058Z","iopub.status.idle":"2021-10-10T09:24:40.577154Z","shell.execute_reply.started":"2021-10-10T09:24:40.555016Z","shell.execute_reply":"2021-10-10T09:24:40.576056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在這邊我們仍然使用AdaBelief優化器，學習速率在1e-3，定且加入剛才定義好的損失函數與評估函數。","metadata":{}},{"cell_type":"code","source":"se_resnet50.with_optimizer(optimizer=AdaBelief, lr=1e-3, betas=(0.9, 0.999)) \\\n    .with_loss(Family_ArcMarginProductLoss(scale=64.0, margin=1.00, easy_margin=False)) \\\n    .with_loss(Person_ArcMarginProductLoss(scale=32.0, margin=0.50, easy_margin=False)) \\\n    .with_loss(center_loss) \\\n    .with_metric(family_accuracy, name='family_accuracy') \\\n    .with_metric(person_accuracy, name='person_accuracy') \\\n    .with_regularizer('l2',reg_weight=1e-5) \\\n    .with_accumulate_grads(10)\\\n    .with_model_save_path('./Models/arcface_family.pth')\\\n    .with_automatic_mixed_precision_training()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:40.579011Z","iopub.execute_input":"2021-10-10T09:24:40.57941Z","iopub.status.idle":"2021-10-10T09:24:40.606992Z","shell.execute_reply.started":"2021-10-10T09:24:40.579368Z","shell.execute_reply":"2021-10-10T09:24:40.605395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plan=TrainingPlan()\\\n    .add_training_item(se_resnet50, name='arcface')\\\n    .with_data_loader(data_provider)\\\n    .repeat_epochs(20)\\\n    .with_batch_size(64)\\\n    .print_progress_scheduling(10,unit='batch')\\\n    .out_sample_evaluation_scheduling(100,unit='batch')\\\n    .display_loss_metric_curve_scheduling(200,unit='batch',imshow=True)\\\n    .save_model_scheduling(50,unit='batch')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:40.610971Z","iopub.execute_input":"2021-10-10T09:24:40.611463Z","iopub.status.idle":"2021-10-10T09:24:40.618435Z","shell.execute_reply.started":"2021-10-10T09:24:40.61142Z","shell.execute_reply":"2021-10-10T09:24:40.616999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plan.start_now()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:24:40.620389Z","iopub.execute_input":"2021-10-10T09:24:40.620984Z","iopub.status.idle":"2021-10-10T09:26:09.250946Z","shell.execute_reply.started":"2021-10-10T09:24:40.620878Z","shell.execute_reply":"2021-10-10T09:26:09.249843Z"},"trusted":true},"execution_count":null,"outputs":[]}]}