{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is clone of this nice kernel: https://www.kaggle.com/suicaokhoailang/facenet-baseline-in-keras-0-749-lb Just add pretrained vggface model and take the average of the predictions of the two models."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom scipy.spatial import distance\nfrom keras.models import load_model\nimport pandas as pd\nfrom tqdm import tqdm","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/train_relationships.csv\")\ntest_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load our pretrained model."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install git+https://github.com/rcmalli/keras-vggface.git","execution_count":20,"outputs":[{"output_type":"stream","text":"Collecting git+https://github.com/rcmalli/keras-vggface.git\n  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-llk1o2si\nRequirement already satisfied (use --upgrade to upgrade): keras-vggface==0.5 from git+https://github.com/rcmalli/keras-vggface.git in /opt/conda/lib/python3.6/site-packages\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (1.16.3)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (1.1.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (2.9.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (5.1.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (2.2.4)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (1.12.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras-vggface==0.5) (3.12)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-vggface==0.5) (1.0.9)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-vggface==0.5) (1.0.7)\nBuilding wheels for collected packages: keras-vggface\n  Building wheel for keras-vggface (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-fe2cf9ln/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\nSuccessfully built keras-vggface\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras_vggface.vggface import VGGFace\n\n# Convolution Features\nvgg_features = VGGFace(include_top=False, input_shape=(160, 160, 3), pooling='avg')\nmodel = vgg_features","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here's preprocessing stuff. The images from the test set seem to already be aligned, so I'll omit that part here for clarity."},{"metadata":{"trusted":true,"_uuid":"b8da009689331982f628256abc151cbbd7e288a1"},"cell_type":"code","source":"def prewhiten(x):\n    if x.ndim == 4:\n        axis = (1, 2, 3)\n        size = x[0].size\n    elif x.ndim == 3:\n        axis = (0, 1, 2)\n        size = x.size\n    else:\n        raise ValueError('Dimension should be 3 or 4')\n\n    mean = np.mean(x, axis=axis, keepdims=True)\n    std = np.std(x, axis=axis, keepdims=True)\n    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n    y = (x - mean) / std_adj\n    return y\n\ndef l2_normalize(x, axis=-1, epsilon=1e-10):\n    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n    return output\n\ndef load_and_align_images(filepaths, margin,image_size = 160):\n    \n    aligned_images = []\n    for filepath in filepaths:\n        img = imread(filepath)\n        aligned = resize(img, (image_size, image_size), mode='reflect')\n        aligned_images.append(aligned)\n            \n    return np.array(aligned_images)\n\n","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we'll compute all the embeddings for the test images using the pretrained model"},{"metadata":{"trusted":true,"_uuid":"4d81f154869853bcc2fb8b1899094d97ba237c72"},"cell_type":"code","source":"def calc_embs(filepaths, margin=10, batch_size=512):\n    pd = []\n    for start in tqdm(range(0, len(filepaths), batch_size)):\n        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n        pd.append(model.predict_on_batch(aligned_images))\n    embs = l2_normalize(np.concatenate(pd))\n\n    return embs","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = os.listdir(\"../input/recognizing-faces-in-the-wild/test/\")\ntest_embs = calc_embs([os.path.join(\"../input/recognizing-faces-in-the-wild/test/\", f) for f in test_images])\nnp.save(\"test_embs_vgg.npy\", test_embs)","execution_count":24,"outputs":[{"output_type":"stream","text":"100%|██████████| 13/13 [01:09<00:00,  4.39s/it]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_embs.shape","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(6282, 512)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"FaceNet model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '../input/facenet-keras/facenet_keras.h5'\nmodel = load_model(model_path)","execution_count":27,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n  warnings.warn('No training configuration found in save file: '\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_embs_vgg = calc_embs([os.path.join(\"../input/recognizing-faces-in-the-wild/test/\", f) for f in test_images])\nnp.save(\"test_embs_fnet.npy\", test_embs_vgg)","execution_count":28,"outputs":[{"output_type":"stream","text":"100%|██████████| 13/13 [01:10<00:00,  4.43s/it]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_embs_vgg.shape","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"(6282, 128)"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"c65eb6eeef58b3e1c59a2a35890971245bbb4529"},"cell_type":"code","source":"test_df[\"distance\"] = 0\nimg2idx = dict()\nfor idx, img in enumerate(test_images):\n    img2idx[img] = idx","execution_count":31,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we compute the actual distance between provided image pairs"},{"metadata":{"trusted":true,"_uuid":"1e2db3e5261a20466cb11b4bfc1273627abcfeb9"},"cell_type":"code","source":"for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    imgs = [test_embs[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    test_df.loc[idx, \"distance1\"] = distance.euclidean(*imgs)\n    \n    # For vggface\n    imgs_2 = [test_embs_vgg[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    test_df.loc[idx, \"distance2\"] = distance.euclidean(*imgs_2)","execution_count":38,"outputs":[{"output_type":"stream","text":"100%|██████████| 5310/5310 [00:05<00:00, 906.96it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['distance'] = test_df[['distance1','distance2']].mean(axis=1)\ntest_df.head()","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"                      img_pair  is_related    ...      distance2  distance1\n0  face05508.jpg-face01210.jpg           0    ...       1.466604   1.102604\n1  face05750.jpg-face00898.jpg           0    ...       1.390086   1.092807\n2  face05820.jpg-face03938.jpg           0    ...       1.460218   1.050548\n3  face02104.jpg-face01172.jpg           0    ...       1.278298   0.920364\n4  face02428.jpg-face05611.jpg           0    ...       1.225088   0.976633\n\n[5 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_pair</th>\n      <th>is_related</th>\n      <th>distance</th>\n      <th>distance2</th>\n      <th>distance1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>face05508.jpg-face01210.jpg</td>\n      <td>0</td>\n      <td>1.284604</td>\n      <td>1.466604</td>\n      <td>1.102604</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>face05750.jpg-face00898.jpg</td>\n      <td>0</td>\n      <td>1.241447</td>\n      <td>1.390086</td>\n      <td>1.092807</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>face05820.jpg-face03938.jpg</td>\n      <td>0</td>\n      <td>1.255383</td>\n      <td>1.460218</td>\n      <td>1.050548</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>face02104.jpg-face01172.jpg</td>\n      <td>0</td>\n      <td>1.099331</td>\n      <td>1.278298</td>\n      <td>0.920364</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>face02428.jpg-face05611.jpg</td>\n      <td>0</td>\n      <td>1.100860</td>\n      <td>1.225088</td>\n      <td>0.976633</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we convert the distances to probabiliy values and submit the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_distances = test_df.distance.values\nsum_dist = np.sum(all_distances)","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = []\nfor dist in tqdm(all_distances):\n    prob = np.sum(all_distances[np.where(all_distances <= dist)[0]])/sum_dist\n    probs.append(1 - prob)","execution_count":44,"outputs":[{"output_type":"stream","text":"100%|██████████| 5310/5310 [00:00<00:00, 30981.31it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")\nsub_df.is_related = probs\nsub_df.to_csv(\"submission.csv\", index=False)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"                      img_pair  is_related\n0  face05508.jpg-face01210.jpg    0.124012\n1  face05750.jpg-face00898.jpg    0.281501\n2  face05820.jpg-face03938.jpg    0.221899\n3  face02104.jpg-face01172.jpg    0.753986\n4  face02428.jpg-face05611.jpg    0.749834","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_pair</th>\n      <th>is_related</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>face05508.jpg-face01210.jpg</td>\n      <td>0.124012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>face05750.jpg-face00898.jpg</td>\n      <td>0.281501</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>face05820.jpg-face03938.jpg</td>\n      <td>0.221899</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>face02104.jpg-face01172.jpg</td>\n      <td>0.753986</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>face02428.jpg-face05611.jpg</td>\n      <td>0.749834</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}