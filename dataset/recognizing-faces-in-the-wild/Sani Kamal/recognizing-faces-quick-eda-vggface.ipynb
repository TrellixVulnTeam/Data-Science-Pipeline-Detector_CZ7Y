{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Northeastern SMILE Lab - Recognizing Faces in the Wild"},{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport networkx as nx \nfrom PIL import Image\nfrom pathlib import Path\nimport cv2\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom scipy.spatial import distance\nfrom keras.models import load_model\nfrom tqdm import tqdm\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/recognizing-faces-in-the-wild/train_relationships.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_image_path(x):\n    image_path = '../input/recognizing-faces-in-the-wild/train/' + x\n    if os.path.exists(image_path):\n        path = os.path.join(image_path, os.listdir(image_path)[0])\n        return path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['p1_path'] = train_df.p1.apply(lambda x: add_image_path(x))\ntrain_df['p2_path'] = train_df.p2.apply(lambda x: add_image_path(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's explore the train folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"fam = os.listdir(\"../input/recognizing-faces-in-the-wild/train\")\nprint('We have',len(fam),'families')\nind = []\nnum = []\npic = []\ntot = 0\ntotpic = 0\nfor i in fam:\n    path = \"../input/recognizing-faces-in-the-wild/train/\"+str(i)\n    temp = os.listdir(path)\n    ind.append(temp)\n    num.append(len(temp))\n    tot+=len(temp)\n    for j in temp:\n        newpath = path+\"/\"+str(j)\n        temp = os.listdir(newpath)\n        pic.append(temp)\n        totpic+=len(temp)\nprint('And',tot,'individuals with',totpic,'pictures.')\nprint('On average, we see',tot/len(fam),'members per family.')\nprint('With an average of',totpic/tot,'per individual.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets Visualize Some Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_path = Path('../input/recognizing-faces-in-the-wild/train/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_list = os.listdir(img_path / train_df.p1[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(2,5, figsize=(50,20))\n\nfor i in range(len(img_list)):\n    with open(img_path / train_df.p1[0] / img_list[i] ,'rb') as f:\n        img = Image.open(f)\n        ax[i%2][i//2].imshow(img)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_list = os.listdir(img_path / train_df.p2[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(2,5, figsize=(50,20))\n\nfor i in range(len(img_list)):\n    with open(img_path / train_df.p2[0] / img_list[i] ,'rb') as f:\n        img = Image.open(f)\n        ax[i%2][i//2].imshow(img)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's put train relations in a graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create graph from data \ng = nx.Graph()\ncolor_map = []\nitt = 0\nfor i in range(0,len(fam)): #len(names)\n    g.add_node(fam[i], type = 'fam')\n    for j in ind[i]:\n        temp = fam[i]+j\n        g.add_node(temp, type = 'ind')\n        g.add_edge(fam[i], temp, color='green', weight=1)\n        for k in pic[itt]:\n            g.add_node(k, type = 'pic')\n            g.add_edge(temp, k, color='blue', weight=1)\n        itt+=1\nfor n1, attr in g.nodes(data=True):\n    if attr['type'] == 'fam':\n        color_map.append('lime')\n    else: \n        if attr['type'] == 'ind':\n            color_map.append('cyan')\n        else:\n            color_map.append('red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the graph\nplt.figure(3,figsize=(90,90))  \nedges = g.edges()\ncolors = [g[u][v]['color'] for u,v in edges]\nnx.draw(g,node_color = color_map, edge_color = colors, with_labels = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What can we learn from our graph?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract reference graph facts & metrics \nprint('Reference Graph')\nprint('Do we have a fully connected graph? ',nx.is_connected(g))\nd = list(nx.connected_component_subgraphs(g))\nprint('The graph contains',len(d), 'sub-graph')\nnx.isolates(g)\nh = g.to_directed()\nN, K = h.order(), h.size()\navg_deg= float(K) / N\nprint (\"# Nodes: \", N)\nprint (\"# Edges: \", K)\nprint (\"Average Degree: \", avg_deg)\n# Extract reference graph facts & metrics \nin_degrees= h.in_degree() # dictionary node:degree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's load our pretrained model."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/rcmalli/keras-vggface.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras_vggface.vggface import VGGFace\n\n# Convolution Features\nvgg_features = VGGFace(include_top=False, input_shape=(160, 160, 3), pooling='avg')\nmodel = vgg_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing stuff"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prewhiten(x):\n    if x.ndim == 4:\n        axis = (1, 2, 3)\n        size = x[0].size\n    elif x.ndim == 3:\n        axis = (0, 1, 2)\n        size = x.size\n    else:\n        raise ValueError('Dimension should be 3 or 4')\n\n    mean = np.mean(x, axis=axis, keepdims=True)\n    std = np.std(x, axis=axis, keepdims=True)\n    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n    y = (x - mean) / std_adj\n    return y\n\ndef l2_normalize(x, axis=-1, epsilon=1e-10):\n    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n    return output\n\ndef load_and_align_images(filepaths, margin,image_size = 160):\n    \n    aligned_images = []\n    for filepath in filepaths:\n        img = imread(filepath)\n        aligned = resize(img, (image_size, image_size), mode='reflect')\n        aligned_images.append(aligned)\n            \n    return np.array(aligned_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compute all the embeddings for the test images using the pretrained model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_embs(filepaths, margin=10, batch_size=512):\n    pd = []\n    for start in tqdm(range(0, len(filepaths), batch_size)):\n        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n        pd.append(model.predict_on_batch(aligned_images))\n    embs = l2_normalize(np.concatenate(pd))\n\n    return embs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = os.listdir(\"../input/recognizing-faces-in-the-wild/test/\")\ntest_embs = calc_embs([os.path.join(\"../input/recognizing-faces-in-the-wild/test/\", f) for f in test_images])\nnp.save(\"test_embs_vgg.npy\", test_embs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_embs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FaceNet model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '../input/facenet-keras/facenet_keras.h5'\nmodel = load_model(model_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_embs_vgg = calc_embs([os.path.join(\"../input/recognizing-faces-in-the-wild/test/\", f) for f in test_images])\nnp.save(\"test_embs_fnet.npy\", test_embs_vgg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_embs_vgg.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit = pd.read_csv('../input/recognizing-faces-in-the-wild/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit[\"distance\"] = 0\nimg2idx = dict()\nfor idx, img in enumerate(test_images):\n    img2idx[img] = idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compute the actual distance between provided image pairs**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, row in tqdm(df_submit.iterrows(), total=len(df_submit)):\n    imgs = [test_embs[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    df_submit.loc[idx, \"distance1\"] = distance.euclidean(*imgs)\n    \n    # For vggface\n    imgs_2 = [test_embs_vgg[img2idx[img]] for img in row.img_pair.split(\"-\")]\n    df_submit.loc[idx, \"distance2\"] = distance.euclidean(*imgs_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submit['distance'] = df_submit[['distance1','distance2']].mean(axis=1)\ndf_submit.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert the distances to probabiliy values and submit the result**"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_distances = df_submit.distance.values\nsum_dist = np.sum(all_distances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = []\nfor dist in tqdm(all_distances):\n    prob = np.sum(all_distances[np.where(all_distances <= dist)[0]])/sum_dist\n    probs.append(1 - prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")\nsub_df.is_related = probs\nsub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reference:\n1. [iFace (Basic) EDA](https://www.kaggle.com/a45632/iface-basic-eda)\n2. [VGGFace baseline in Keras](https://www.kaggle.com/ateplyuk/vggface-baseline-in-keras)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}