{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\nfrom pathlib import Path\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataFrame = pd.read_csv(\"../input/train_relationships.csv\")\ntrainset = Path('../input/train/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_dataFrame.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"by running the train_dataFrame.head() we can know about the kin relationship of parents(father/mother) considered as p1 and the respective child is directed towards p2 ( p1(father & mother) is mapped to child \n\nFor Example compare the viewColumnFrames ( i.e P1 and P2 ) with train.csv files to get insights\n\nNote F000X is a family and in which MID1 , MID2 corrosponds to the same family member\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_dataFrame.p1[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataFrame.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: My DataFrame has 3598 rows and 2 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"find = list(train_dataFrame.p1)\n#print(len(find))\n\nfind_child = list(train_dataFrame.p2)\n#print(len(find_child))\n\ntemp = find + find_child\n\n#print(temp)\n\n#using set to remove redundancies (duplicates) in a list\n\nstore_list = list(set(temp)) # we wanna sort the list so wrapping up with list(set())\n\nstore_list.sort() \n\nprint(store_list[:5])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#our mission is to find the missing directory \n#print(trainset)\ncount = 0 \nmodify_dir = []\n\nfor a in store_list:\n    #print(a)\n    if(os.path.exists(trainset/a)==False):\n        #print(a)\n        modify_dir.append(a)\n        count = count+1\n\nprint(\"blacksheeps :\",count)\nprint(\"missing directories\" , len(modify_dir))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I ve counted the number of files which are acting as dummies , ( it can be verifiable with train_dataset.csv and images we are provided with)\n\nYes I understood train.csv is pretty much loaded with dummies ( 96 directories ) but no source files while comparable with train.zip ( bunch of MID files)\n"},{"metadata":{},"cell_type":"markdown","source":"**Remove the useless directories in train.zip by comparing with the train.csv**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataFrame = train_dataFrame[~train_dataFrame[\"p1\"].isin(modify_dir)]\ntrain_dataFrame = train_dataFrame[~train_dataFrame[\"p2\"].isin(modify_dir)]\nprint(train_dataFrame.shape)\n#len(train_dataFrame)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find = list(train_dataFrame.p1)\n\nfind_child = list(train_dataFrame.p2)\n\n\ntemp = find + find_child\n\n#print(temp)\n\n#using set to remove redundancies (duplicates) in a list\n\nfinal_folder = list(set(temp)) # we wanna sort the list so wrapping up with list(set())\n\nfinal_folder.sort() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_folder[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import * ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef imshow(label):\n    #print(int(store_list[label]))\n    fetch_img = os.listdir(trainset/final_folder[label])\n    #print(len(fetch_img))\n    total_img = len(fetch_img)\n    \n    fig,ax = plt.subplots(2,5,figsize=(20,10))\n    print(ax.shape)\n    \n    for iterator in range(total_img):\n        # specifying the exact location and displaying all the pictures in the present directory \n        with open (trainset/final_folder[label]/fetch_img[iterator] , 'rb') as f :\n            get_img = Image.open(f)\n            ax[iterator%2][iterator//2].imshow(get_img)\n        fig.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time to visualize lets see the image of family \n\n* p1[0] seems to be 0 th directory MID2 ( same family folder)\n* p1[1] seems to be 1 st directory of MID2\n* p2[0] seems to be 0 th directory ( child mapped to p1[0] and p1[1]"},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(0)   # imshow indicates train_dataFrame.p1[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = \"../input/train/\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_directory = \"F07\"\nall_images = glob(trainset + \"/*/*/*.jpg\")\n\ntrain_images = [x for x in all_images if sample_directory not in x]\nval_images = [x for x in all_images if sample_directory in x]\n\n\n#print(len(train_images))\n#print(len(val_images))\n#print(train_images)\nfrom collections import defaultdict\ntrain_map = defaultdict(list)\n\nfor x in train_images:\n    train_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n \nval_map = defaultdict(list)\n\nfor x in val_images:\n    val_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n\n    \n    \ncheck = [x.split(\"/\")[-3] +\"/\"+ x.split(\"/\")[-2] for x in all_images]\n#print(check)\nphase = pd.read_csv(\"../input/train_relationships.csv\")\nphase = list(zip(phase.p1.values,phase.p2.values))\nphase = [x for x in phase if x[0] in check and x[1] in check ]\n#print(phase)\n\ntrain_pair = [x for x in phase if sample_directory not in x[0]]\nval_pair = [x for x in phase if sample_directory in x[0]]\nprint(\"train pair\",len(train_pair))\nprint(\"valid_pair\",len(val_pair))\n#print(len(train_pair))\n#al_pair = \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(val_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    \n#print(train_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = [x for x in all_images if sample_directory not in x]\n#print(train_images)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_map.items()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###for key,value in train_map.items():\n    #print(\"key\",key,end=\"\") #key represents the directory\n    #print(\"value\",value) #value unpacks the number of files resided\n   ## print(train_map[key]) ### similar to the values obtained ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    \n#print(val_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_dict = {}\n\nprint(len(final_folder))\n#for x in final_folder:\n#    print(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom pathlib import Path\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader,Dataset\nfrom torchvision.models import *\nimport torchvision.transforms as transforms\nimport torchvision.utils\nimport torchvision.datasets as datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### TESTING THE LOADING IMAGE LABELS FOR PHASE( TRAIN_IMAGES / TEST IMAGES ) AND THE IMGDATA\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show = load_image_labels(imgdata = data_folder,phase = train_images,transforms = data_transforms['train_transf'])\n\n#print(len(show))\n#print(show.phase[2])\n#print(show.imgdata[2])\n\n#print(show.transforms)\n\n#print(load_image_labels(data_folder,train_images))\n#print(show.find_relations)\n\n\n\n#print(show_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load_train = load_image_labels(imgdata = data_folder,phase = train_images,transforms = data_transforms['train_transf'])\n\n#train_data = datasets.ImageFolder(data_folder,train_images,data_transforms['train_transf'])\n\n#valid_data = datasets.ImageFolder(val_images,transform = data_transforms['valid_transf'])\n\n#trainloader = torch.utils.data.DataLoader(load_train,shuffle = True , num_workers = 8 ,batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/train'\n\nprint(data_dir)\n\ndata_folder = datasets.ImageFolder(root = \"../input/train/\")\nprint(data_folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nnum_workers = 8\n\n\ndata_transforms = {\n    \n    'train_transf' : transforms.Compose([transforms.Resize((64,64)),\n                                         transforms.RandomResizedCrop(64),\n                                         transforms.RandomHorizontalFlip(),\n                                         transforms.ToTensor(),\n                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225]),\n                                         \n                                        ]),\n    'valid_transf':transforms.Compose([transforms.Resize((64,64)),\n                                       transforms.RandomSizedCrop(64),\n                                       transforms.RandomHorizontalFlip(),\n                                        transforms.ToTensor(),\n                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225]),\n                                        ])\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #val_pair","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class load_image_labels(Dataset):\n        def __init__(self,imgdata,phase,transforms):\n            self.imgdata = imgdata\n            self.phase = phase\n            self.transforms = transforms \n            \n        def __getitem__(self,index):\n            \n            load_img1 = self.phase[index][0]\n            #print(load_img1)\n            \n            loadimg1_path = glob(\"../input/train/\"+load_img1+\"/*.jpg\") \n            loadimg1_path = random.choice(loadimg1_path)\n            #print(loadimg1_path)\n            # it is used to trace the relations whether the image files under the directory is related to specified person\n            find_relations = [go for go in self.phase if go[0] == load_img1 or go[1] == load_img1]\n            \n            #print(find_relations)\n            \n            same_class = 1\n            #print(get_img1)    \n            if find_relations == []:\n                same_class = 0\n            else:\n                same_class = random.randint(0,1)\n            \n            if same_class == 1 : \n                load_img2 = random.choice(find_relations)\n                \n                if load_img2[0] != load_img1 :\n                    load_img2 = load_img2[0]\n                \n                else:\n                    load_img2 = load_img2[1]\n                \n                loadimg2_path = glob(\"../input/train/\"+load_img2+\"/*.jpg\")\n                loadimg2_path = random.choice(loadimg2_path)\n                \n            else:\n                randy = True\n                \n                while randy:\n                    loadimg2_path = random.choice(self.imgdata.imgs)[0]\n                    load_img2_info = loadimg2_path.split(\"/\")[-3]+\"/\"+loadimg2_path.split(\"/\")[-2]\n                    randy = False\n                    \n                    for check in find_relations:\n                        if check[0] == load_img2_info or check[1] ==load_img2_info:\n                            randy = True\n                            break\n            #print(loadimg2_path)\n            #print(get_img1)\n            #get_img1 = Image.open(\"../input/train/F0733/MID2/P07682_face1.jpg\")\n            get_img1 = Image.open(loadimg1_path) \n            get_img2 = Image.open(loadimg2_path)\n            #get_img2 = Image.open(\"../input/train/F0733/MID5/P07690_face2.jpg\")\n            \n            if self.transforms is not None:\n                get_img1 = self.transforms(get_img1)\n                get_img2 = self.transforms(get_img2)\n                \n            return get_img1,get_img2,same_class\n        \n        def __len__(self):\n            return len(self.phase)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_train = load_image_labels(imgdata = data_folder,phase = train_pair,transforms = data_transforms['train_transf'])\n\n#train_data = datasets.ImageFolder(data_folder,train_images,data_transforms['train_transf'])\n\n#valid_data = datasets.ImageFolder(val_images,transform = data_transforms['valid_transf'])\n\ntrainloader = torch.utils.data.DataLoader(load_train,shuffle = True , num_workers = num_workers ,batch_size = batch_size)\n\n\n#valid_data = datasets.ImageFolder(val_images,transform = data_transforms['valid_transf'])\n#validloader = DataLoader(valid_data , shuffle = True , num_workers = 8 , batch_size = batch_size)\n\nload_valid = load_image_labels(data_folder,val_pair,data_transforms['valid_transf'])\nvalloader = DataLoader(load_valid,shuffle = True , num_workers = num_workers ,batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class architecture(nn.Module):\n    def __init__(self):\n        super(architecture, self).__init__()\n        self.features = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(3, 64, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            nn.Dropout2d(p=.25), \n            \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(64,16, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(p=.25),\n            \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(16,8, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(8),\n            nn.Dropout2d(p=.25),\n            )\n        \n        self.fc1 = nn.Linear(2*8*64*64,300)\n        self.fc2 = nn.Linear(300,100)\n        self.fc3 = nn.Linear(100,2)\n\n    def forward(self,x1,x2):\n        outp1 = self.features(x1)\n        outp1 = outp1.view(outp1.size()[0],-1)\n        outp2 = self.features(x2)\n        outp2 = outp2.view(outp2.size()[0],-1)\n        \n        outp = torch.cat((outp1, outp2),1)\n        outp = F.relu(self.fc1(outp))\n        #print(\"final outp 1 shape\",outp.shape)\n        outp = F.relu(self.fc2(outp))\n        #print(\"final outp 1 shape\",outp.shape)\n        outp = self.fc3(outp)\n        #print(\"final outp 1 shape\",outp.shape)\n        return outp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = architecture()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = models.resnet50(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model.parameters(),lr=0.008,momentum=0.8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_min_loss = np.Inf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import cuda","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gpu_on = torch.cuda.is_available()\nprint(gpu_on)\nif gpu_on:\n    model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"for i,data in enumerate(trainloader,0):\n    img1 ,img2,target = data\n    print(img1)\n    print(img2)\n    print(data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(img1.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(img2.size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(target.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(1,epoch+1):\n    \n    train_loss_calc = 0.0\n    valid_loss_calc = 0.0\n    \n    model.train()\n    \n    for i,data in enumerate(trainloader,0):\n        img1 ,img2 ,target = data\n        #print(img1.size())\n        #print(img2.size())\n        #print(target.size())\n        if gpu_on:\n            img1,img2,target = img1.cuda(),img2.cuda(),target.cuda()\n        else:\n            img1,img2,target = img1.cpu(),img2.cpu(),target.cpu()\n            \n        optimizer.zero_grad()\n        \n        outp = model.forward(img1,img2)\n        \n        loss = criterion(outp,target)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_loss_calc += loss.item()\n        \n        ########### Validation Part #################\n        \n        model.eval()\n        total_val = 0\n        correct_val = 0\n    with torch.no_grad():\n        for iterator,data in enumerate(valloader,0):\n            if gpu_on:\n                img1,img2,target = data \n                img1,img2,target = img1.cuda(),img2.cuda(),target.cuda()\n                optimizer.zero_grad()\n                outp = model.forward(img1,img2)\n                loss = criterion(outp,target)\n\n                valid_loss_calc += loss.item()\n                _,predicted = torch.max(outp,1)\n\n                total_val += target.size(0)\n                correct_val += (predicted == target).sum().item()\n    print(\"epoch: \",epoch,end=\" \")\n    print('accuracy: %d %%' % (100 * correct_val / total_val))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collect_td = pd.read_csv(\"../input/sample_submission.csv\")\nprint(collect_td.head())\n#Before sample subm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class generalizeTest(Dataset):\n    \n    def __init__(self,transform):\n        self.collect_td = pd.read_csv(\"../input/sample_submission.csv\")\n        self.transform = transform\n        \n    def __getitem__(self,key):\n        #note that img_pair is dataFrame Column name\n        img1relate = self.collect_td.iloc[key].img_pair.split(\"-\")[0] ### person1 \n        \n        img2relate = self.collect_td.iloc[key].img_pair.split(\"-\")[1] ### person 2 \n        \n        img1 = Image.open(\"../input/test/\"+img1relate) \n        img2 = Image.open(\"../input/test/\"+img2relate)\n        \n        if self.transform is not None:\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n            \n        return img1,img2\n    \n    def __len__(self):\n        return len(self.collect_td) \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data = generalizeTest(transform=data_transforms['valid_transf'])\ntest_set = DataLoader(testing_data,shuffle=False,batch_size = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample submissision\ncollect_td = pd.read_csv(\"../input/sample_submission.csv\")\nbloody = []\nwith torch.no_grad():\n    for data in test_set:\n        img1,img2 = data \n        img1,img2 = img1.cuda(),img2.cuda()\n        #optimizer.zero_grad()\n        outp = model(img1,img2)\n        _,predicted = torch.max(outp,1)\n        #print(predicted)\n        bloody = np.concatenate((bloody,predicted.cpu().numpy()),0)\ncollect_td['is_related'] = bloody ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(collect_td.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collect_td.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collect_td.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collect_td.to_json()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}