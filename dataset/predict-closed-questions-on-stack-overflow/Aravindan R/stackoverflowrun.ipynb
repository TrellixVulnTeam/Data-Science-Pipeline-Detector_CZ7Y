{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic imports\n \nimport torch \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-05T05:25:42.556547Z","iopub.execute_input":"2022-07-05T05:25:42.55708Z","iopub.status.idle":"2022-07-05T05:25:44.185095Z","shell.execute_reply.started":"2022-07-05T05:25:42.557039Z","shell.execute_reply":"2022-07-05T05:25:44.18402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the data \ndata = pd.read_csv(\"../input/predict-closed-questions-on-stack-overflow/train-sample.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:25:51.241179Z","iopub.execute_input":"2022-07-05T05:25:51.241836Z","iopub.status.idle":"2022-07-05T05:25:54.795873Z","shell.execute_reply.started":"2022-07-05T05:25:51.241795Z","shell.execute_reply":"2022-07-05T05:25:54.794648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.OpenStatus.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:25:54.798247Z","iopub.execute_input":"2022-07-05T05:25:54.798988Z","iopub.status.idle":"2022-07-05T05:25:54.833918Z","shell.execute_reply.started":"2022-07-05T05:25:54.79894Z","shell.execute_reply":"2022-07-05T05:25:54.832631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's take 'TITLE' & 'BODYMARKDOWN' & OpenStatus Columns \ndata_train = data[['Title', 'BodyMarkdown', 'OpenStatus']]\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:25:59.12126Z","iopub.execute_input":"2022-07-05T05:25:59.121797Z","iopub.status.idle":"2022-07-05T05:25:59.150383Z","shell.execute_reply.started":"2022-07-05T05:25:59.121755Z","shell.execute_reply":"2022-07-05T05:25:59.14899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.shape  # it's tooo big, let's take just 20 k rows. ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:22:59.266599Z","iopub.execute_input":"2022-07-05T05:22:59.267496Z","iopub.status.idle":"2022-07-05T05:22:59.275624Z","shell.execute_reply.started":"2022-07-05T05:22:59.267456Z","shell.execute_reply":"2022-07-05T05:22:59.274618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample 80k randomly! \ndata_train = data_train.sample(80000, random_state = 234)\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:26:02.569322Z","iopub.execute_input":"2022-07-05T05:26:02.569954Z","iopub.status.idle":"2022-07-05T05:26:02.608102Z","shell.execute_reply.started":"2022-07-05T05:26:02.569909Z","shell.execute_reply":"2022-07-05T05:26:02.607287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install texthero  # For text pre processing ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:26:06.670672Z","iopub.execute_input":"2022-07-05T05:26:06.671928Z","iopub.status.idle":"2022-07-05T05:26:19.028821Z","shell.execute_reply.started":"2022-07-05T05:26:06.67185Z","shell.execute_reply":"2022-07-05T05:26:19.027363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's pre process the data using library called \"Text_hero\"\nimport texthero as hero \n\ndata_train['Title'] = hero.clean(data_train['Title'])\ndata_train['BodyMarkdown'] = hero.clean(data_train['BodyMarkdown'])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:26:23.580434Z","iopub.execute_input":"2022-07-05T05:26:23.581Z","iopub.status.idle":"2022-07-05T05:26:59.655726Z","shell.execute_reply.started":"2022-07-05T05:26:23.580943Z","shell.execute_reply":"2022-07-05T05:26:59.654438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```Python \nhero.clear(df['something'])  \n\n# It does many things, They are: \nfillna()\nlowercase()\nremove_digits()\nremove_punctuation()\nremove_diacritics()\nremove_stopwords()\nremove_whitespace()\n```","metadata":{}},{"cell_type":"code","source":"# Let's see the data now! \ndata_train.head()  # look how clean our text is:) ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:24:09.48448Z","iopub.execute_input":"2022-07-05T05:24:09.484864Z","iopub.status.idle":"2022-07-05T05:24:09.496208Z","shell.execute_reply.started":"2022-07-05T05:24:09.484834Z","shell.execute_reply":"2022-07-05T05:24:09.494945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's change the target to numbers: \ndata_train.OpenStatus.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:27:28.933885Z","iopub.execute_input":"2022-07-05T05:27:28.935055Z","iopub.status.idle":"2022-07-05T05:27:28.955349Z","shell.execute_reply.started":"2022-07-05T05:27:28.935009Z","shell.execute_reply":"2022-07-05T05:27:28.954238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['OpenStatus']= data_train['OpenStatus'].map({'open': 0, 'not a real question': 1, 'off topic': 2, 'not constructive': 3, 'too localized': 4}) \ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:27:30.860117Z","iopub.execute_input":"2022-07-05T05:27:30.860531Z","iopub.status.idle":"2022-07-05T05:27:30.891445Z","shell.execute_reply.started":"2022-07-05T05:27:30.860497Z","shell.execute_reply":"2022-07-05T05:27:30.890458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's seperate x and y: \nx = data_train['Title'] + ' '+ data_train['BodyMarkdown']\ny = data_train['OpenStatus']\n\n# xtrain, ytrian \nfrom sklearn.model_selection import train_test_split \nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.3, random_state = 203)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:27:34.695328Z","iopub.execute_input":"2022-07-05T05:27:34.695719Z","iopub.status.idle":"2022-07-05T05:27:34.761596Z","shell.execute_reply.started":"2022-07-05T05:27:34.695687Z","shell.execute_reply":"2022-07-05T05:27:34.760526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```Python \nLet us go from basic to Advance modeling :) \n```","metadata":{"execution":{"iopub.status.busy":"2022-07-05T04:18:42.995019Z","iopub.execute_input":"2022-07-05T04:18:42.995416Z","iopub.status.idle":"2022-07-05T04:18:43.004567Z","shell.execute_reply.started":"2022-07-05T04:18:42.995386Z","shell.execute_reply":"2022-07-05T04:18:43.003419Z"}}},{"cell_type":"code","source":"# Let's covvert words to numbers using TF-IDF \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(max_features = 10000)  # it contains only 10k features (fixed!)\n\nxtrain_tfidf = vectorizer.fit_transform(xtrain).toarray()  # converting words to numbers for train data \nxtest_tfidf = vectorizer.transform(xtest).toarray()        # converting words to numbers for test data ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:27:37.411381Z","iopub.execute_input":"2022-07-05T05:27:37.411782Z","iopub.status.idle":"2022-07-05T05:27:51.511343Z","shell.execute_reply.started":"2022-07-05T05:27:37.41175Z","shell.execute_reply":"2022-07-05T05:27:51.510138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes \nfrom sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\n\nclf.fit(xtrain_tfidf, ytrain)\n\npredicted_naive = clf.predict(xtest_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:28:12.963069Z","iopub.execute_input":"2022-07-05T05:28:12.964369Z","iopub.status.idle":"2022-07-05T05:28:28.326455Z","shell.execute_reply.started":"2022-07-05T05:28:12.964326Z","shell.execute_reply":"2022-07-05T05:28:28.325209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics :) \nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n\nprint('Accuracy Score \\n',accuracy_score(predicted_naive, ytest))\nprint('Confusion Matrix \\n', confusion_matrix(predicted_naive, ytest))\nprint('Classification Report \\n', classification_report(predicted_naive, ytest))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:29:24.111456Z","iopub.execute_input":"2022-07-05T05:29:24.11214Z","iopub.status.idle":"2022-07-05T05:29:24.189263Z","shell.execute_reply.started":"2022-07-05T05:29:24.112077Z","shell.execute_reply":"2022-07-05T05:29:24.187901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MLP classifier \nfrom sklearn.neural_network import MLPClassifier\n\nmlp_cv=MLPClassifier(early_stopping=True, verbose=2)\nmlp_cv.fit(xtrain_tfidf, ytrain)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:30:48.030098Z","iopub.execute_input":"2022-07-05T05:30:48.031318Z","iopub.status.idle":"2022-07-05T05:33:48.485854Z","shell.execute_reply.started":"2022-07-05T05:30:48.031268Z","shell.execute_reply":"2022-07-05T05:33:48.484512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict :) \npredicted_mlp = mlp_cv.predict(xtest_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:35:48.202223Z","iopub.execute_input":"2022-07-05T05:35:48.202638Z","iopub.status.idle":"2022-07-05T05:35:49.895838Z","shell.execute_reply.started":"2022-07-05T05:35:48.202604Z","shell.execute_reply":"2022-07-05T05:35:49.893234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics :) \nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n\ndef metrics(predicted): \n    predicted_naive = predicted \n    print('Accuracy Score \\n',accuracy_score(predicted_naive, ytest))\n    print('Confusion Matrix \\n', confusion_matrix(predicted_naive, ytest))\n    print('Classification Report \\n', classification_report(predicted_naive, ytest))","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:36:28.927956Z","iopub.execute_input":"2022-07-05T05:36:28.928374Z","iopub.status.idle":"2022-07-05T05:36:28.936061Z","shell.execute_reply.started":"2022-07-05T05:36:28.92834Z","shell.execute_reply":"2022-07-05T05:36:28.934705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics(predicted_mlp)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T05:36:41.280445Z","iopub.execute_input":"2022-07-05T05:36:41.280874Z","iopub.status.idle":"2022-07-05T05:36:41.34209Z","shell.execute_reply.started":"2022-07-05T05:36:41.280838Z","shell.execute_reply":"2022-07-05T05:36:41.341046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}