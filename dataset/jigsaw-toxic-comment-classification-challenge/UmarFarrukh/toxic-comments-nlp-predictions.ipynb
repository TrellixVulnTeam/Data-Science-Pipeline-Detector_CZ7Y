{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import coo_matrix, hstack\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport textblob\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n    \nimport os\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nfrom sklearn.metrics import precision_recall_fscore_support\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils.vis_utils import plot_model\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[42]['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ndata.iloc[42][labels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for null values in the data\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data distribution for each of the target label\nfor col in labels:\n    print(data[col].value_counts())\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_word_cloud(col):\n    text = \" \".join(review for review in data['comment_text'][data[col]==1])\n    stopwords = set(STOPWORDS)\n    # lower max_font_size, change the maximum number of word and lighten the background:\n    wordcloud = WordCloud(max_font_size=50, max_words=100, stopwords=stopwords, background_color=\"white\").generate(text)\n    plt.figure()\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the legth of sentences \nstop_words = set(stopwords.words('english'))\ndata['words_length'] = data['comment_text'].apply(lambda x: len(x)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#descriptive stats of the number of words in the sentence\ndata['words_length'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#words length distribution\nfor col in labels:\n    print(data.groupby([col])['words_length'].mean())\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_word_cloud('toxic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_word_cloud('severe_toxic')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_word_cloud('obscene')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_word_cloud('threat')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_word_cloud('insult')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_word_cloud('identity_hate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Trasformations**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions = {\n\"ain't\": \"am not \",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he shall have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"i'd\": \"I would\",\n\"i'd've\": \"I would have\",\n\"i'll\": \"I will\",\n\"i'll've\": \"I shall have\",\n\"i'm\": \"I am\",\n\"i've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what'll've\": \"what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"when's\": \"when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who will\",\n\"who'll've\": \"who will have\",\n\"who's\": \"who is\",\n\"who've\": \"who have\",\n\"why's\": \"why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you will\",\n\"you'll've\": \"you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_text_for_word_embeddings(text):    \n    for word in text.split():\n        if word.lower() in contractions:\n            text = text.replace(word, contractions[word.lower()])    \n    text = re.sub(r'\\d+', '', text)\n    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n    text = text.strip()\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_text = [i for i in data['comment_text']]\nfull_text = [(lambda x: preprocess_text_for_word_embeddings(x))(x) for x in full_text]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['clean_text'] = full_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data['id']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['clean_text'].fillna(\"##\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the data for training and testing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(data, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_case_text = [i.lower() for i in data['clean_text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tfidf_transform(clean_text):\n    vectorizer = TfidfVectorizer(stop_words = set(stopwords.words('english')))\n    vectorizer.fit(clean_text)\n    x_train_tfidf_vec = vectorizer.transform(train['clean_text'])\n    x_test_tfidf_vec = vectorizer.transform(test['clean_text'])\n    print(x_train_tfidf_vec.shape, x_test_tfidf_vec.shape)\n    return x_train_tfidf_vec, x_test_tfidf_vec  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_tfidf_vec, x_test_tfidf_vec =  tfidf_transform(lower_case_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression()\ngrid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01]}\ngrid_clf = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\ngrid_clf.fit(x_train_tfidf_vec, train['toxic'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_acc = grid_clf.predict_proba(x_test_tfidf_vec)[:,1]\nroc_auc_score(test['toxic'], y_pred_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = pd.DataFrame(columns=labels)\nfor col in labels:\n    model = LogisticRegression()\n    model.fit(x_train_tfidf_vec, train[col])\n    y_prediction[col] = model.predict_proba(x_test_tfidf_vec)[:,1]\n    print(col, \" ROC AUC Score = \",roc_auc_score(test[col], y_prediction[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_roc_plot(y_true, y_pred):\n    [fpr, tpr, thr] = roc_curve(y_true, y_pred)\n\n    idx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\n    plt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n    plt.ylabel('True Positive Rate (recall)', fontsize=14)\n    plt.title('Receiver operating characteristic (ROC) curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    print(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +  \n      \"and a specificity of %.3f\" % (1-fpr[idx]) + \n      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_roc_plot(test['toxic'], y_prediction['toxic'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_roc_plot(test['obscene'], y_prediction['obscene'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision tree Classifier**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = pd.DataFrame(columns=labels)\nfor col in labels:\n    model = DecisionTreeClassifier()\n    model.fit(x_train_tfidf_vec[:10000], train[col][:10000])\n    y_prediction[col] = model.predict_proba(x_test_tfidf_vec)[:,1]\n    print(col, \" metrics = \",precision_recall_fscore_support(test[col], y_prediction[col], average='binary'))\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"y_prediction = pd.DataFrame(columns=labels)\nfor col in labels:\n    model = RandomForestClassifier()\n    model.fit(x_train_tfidf_vec[:10000], train[col][:10000])\n    y_prediction[col] = model.predict_proba(x_test_tfidf_vec)[:,1]\n    print(col, \" metrics = \",precision_recall_fscore_support(test[col], y_prediction[col], average='binary'))\n    print(\"\\n\")","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Support vector machine**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = pd.DataFrame(columns=labels)\nfor col in labels:\n    model = SVG(gamma='auto')\n    model.fit(x_train_tfidf_vec[:10000], train[col][:10000])\n    y_prediction[col] = model.predict_proba(x_test_tfidf_vec)[:,1]\n    print(col, \" metrics = \",precision_recall_fscore_support(test[col], y_prediction[col], average='binary'))\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word Embedding and Recurrent Neural Networks Approach","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_text, x_val_text, y_train, y_val = train_test_split(train['clean_text'], train[labels],\n                                                    test_size=0.2,\n                                                    random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv1 = CountVectorizer()\ncv1.fit(x_train_text)\n\ncv2 = CountVectorizer()\ncv2.fit(x_val_text)\n\ncv3 = CountVectorizer()\ncv3.fit(test['clean_text'])\n\nprint(\"Train Set Vocabulary Size:\", len(cv1.vocabulary_))\nprint(\"Val Set Vocabulary Size:\", len(cv2.vocabulary_))\nprint(\"Test Set Vocabulary Size:\", len(cv3.vocabulary_))\n\nprint(\"Number of Words that occur in both:\", \n      len(set(cv1.vocabulary_.keys()).intersection(set(cv3.vocabulary_.keys()))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\nEMBEDDING_DIM = 300\nall_words = set(cv1.vocabulary_.keys()).union(set(cv2.vocabulary_.keys())).union(set(cv3.vocabulary_.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_embedding():\n    embeddings_index = {}\n    f = open(EMBEDDING_FILE)\n    for line in f:\n        values = line.split()\n        word = values[0]\n        if len(values) == EMBEDDING_DIM + 1 and word in all_words:\n            coefs = np.asarray(values[1:], dtype=\"float32\")\n            embeddings_index[word] = coefs\n    f.close()\n    return embeddings_index\n\nembeddings_index = get_embedding()\nprint(\"Number of words that don't exist in GLOVE:\", len(all_words - set(embeddings_index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()\n\nnp_text =  np.append(x_train_text.values,x_val_text.values)\n\ntokenizer.fit_on_texts(np.append(np_text, test['clean_text'].values))\n\nword_index = tokenizer.word_index\n\nnb_words = len(word_index) + 1\nembedding_matrix = np.random.rand(nb_words, EMBEDDING_DIM + 2)\n\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    sent = textblob.TextBlob(word).sentiment\n    if embedding_vector is not None:\n        embedding_matrix[i] = np.append(embedding_vector, [sent.polarity, sent.subjectivity])\n    else:\n        embedding_matrix[i, -2:] = [sent.polarity, sent.subjectivity]\n        \ntrain_seq = pad_sequences(tokenizer.texts_to_sequences(x_train_text), maxlen=MAX_SEQUENCE_LENGTH)\nval_seq = pad_sequences(tokenizer.texts_to_sequences(x_val_text), maxlen=MAX_SEQUENCE_LENGTH)\ntest_seq = pad_sequences(tokenizer.texts_to_sequences(test['clean_text']), maxlen=MAX_SEQUENCE_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_seq.shape)\nprint(val_seq.shape)\nprint(test_seq.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\ninp = Input(shape=(MAX_SEQUENCE_LENGTH,))\n\nx = Embedding(nb_words, EMBEDDING_DIM+2, weights=[embedding_matrix], trainable=True)(inp)\nx = SpatialDropout1D(0.35)(x)\n\nx = Bidirectional(LSTM(128, return_sequences=True, dropout=0.15, recurrent_dropout=0.15))(x)\nx = Conv1D(64, kernel_size=3, padding='valid', kernel_initializer='glorot_uniform')(x)\n\navg_pool = GlobalAveragePooling1D()(x)\nmax_pool = GlobalMaxPooling1D()(x)\nx = concatenate([avg_pool, max_pool])\n\nout = Dense(6, activation='sigmoid')(x)\n\nmodel = Model(inp, out)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_seq.shape)\nprint(val_seq.shape)\nprint(test_seq.shape)\n\nprint(y_train.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = build_model()\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nearly_stopping = EarlyStopping(monitor=\"val_acc\", patience=2, verbose=1)\n\nprint(\"Training the model\")\nmodel.fit(train_seq, y_train.values, validation_data=(val_seq, y_val.values),epochs=1,\n          batch_size=32, shuffle=True, callbacks=[early_stopping], verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = model.predict(test_seq, batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_df = np.where(test_preds > 0.5, 1, 0)\n\ny_df = pd.DataFrame(y_df, columns=['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\ny_df = y_df.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_metri_scores(y_test, y_test_pred):\n    vals = precision_recall_fscore_support(y_test, y_test_pred, average='macro')\n    precision = vals[0]\n    recall = vals[1]\n    f1 = vals[2]\n    acc = accuracy_score(y_test, y_test_pred)\n    return precision, recall, f1, acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_cv = pd.DataFrame({'labels': labels})\nresults_cv['acc'] = 0\nresults_cv['f1'] = 0\nresults_cv['precision'] = 0\nresults_cv['recall']  = 0\nfor col in labels:\n    print(col)\n    precision, recall, f1, acc = get_metri_scores(test[col], y_df[col])\n    results_cv['acc'][results_cv['labels']==col] = acc\n    results_cv['f1'][results_cv['labels']==col] = f1\n    results_cv['precision'][results_cv['labels']==col] = precision\n    results_cv['recall'][results_cv['labels']==col] = recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}