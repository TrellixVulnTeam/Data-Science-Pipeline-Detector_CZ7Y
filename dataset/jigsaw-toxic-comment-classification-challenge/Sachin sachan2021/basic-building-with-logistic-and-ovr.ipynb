{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport zipfile\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T07:32:19.508697Z","iopub.execute_input":"2022-01-09T07:32:19.50906Z","iopub.status.idle":"2022-01-09T07:32:25.878732Z","shell.execute_reply.started":"2022-01-09T07:32:19.508944Z","shell.execute_reply":"2022-01-09T07:32:25.877638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Files Unzipping","metadata":{}},{"cell_type":"code","source":"train_path = '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\nwith zipfile.ZipFile(train_path,\"r\") as z:\n    z.extractall()\ndf = pd.read_csv('./train.csv')\n\ntest_path = '../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip'\nwith zipfile.ZipFile(test_path,\"r\") as z:\n    z.extractall()\nreal_test_df = pd.read_csv('./test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:32:25.880496Z","iopub.execute_input":"2022-01-09T07:32:25.880755Z","iopub.status.idle":"2022-01-09T07:32:31.038579Z","shell.execute_reply.started":"2022-01-09T07:32:25.880724Z","shell.execute_reply":"2022-01-09T07:32:31.036545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.Minor Analysis","metadata":{}},{"cell_type":"code","source":"##Splitting dataset\nsplit_test_df = df.iloc[-1000:,:]\ndf = df.iloc[:-1000,:]\n\nprint('Percentage of comments that are not labelled:')\nprint(len(df[(df['toxic']==0) &\n             (df['severe_toxic']==0) & \n             (df['obscene']==0) &\n             (df['threat']== 0) & \n             (df['insult']==0) & \n             (df['identity_hate']==0)])/len(df))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:32:31.040206Z","iopub.execute_input":"2022-01-09T07:32:31.041157Z","iopub.status.idle":"2022-01-09T07:32:31.080657Z","shell.execute_reply.started":"2022-01-09T07:32:31.041115Z","shell.execute_reply":"2022-01-09T07:32:31.079545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## min max and average length of texts\n\nlens = df.comment_text.str.len()\nlens.mean(), lens.std(), lens.max()\n\n## found no empty text\ndf['is_empty'] = np.where(len(df['comment_text'])<1, 1,0)\ndf[df['is_empty']==1]","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:32:31.082753Z","iopub.execute_input":"2022-01-09T07:32:31.083319Z","iopub.status.idle":"2022-01-09T07:32:31.509414Z","shell.execute_reply.started":"2022-01-09T07:32:31.083263Z","shell.execute_reply":"2022-01-09T07:32:31.508427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install contractions","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:32:31.51048Z","iopub.execute_input":"2022-01-09T07:32:31.510707Z","iopub.status.idle":"2022-01-09T07:32:47.014159Z","shell.execute_reply.started":"2022-01-09T07:32:31.510678Z","shell.execute_reply":"2022-01-09T07:32:47.013017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Text Refinement","metadata":{}},{"cell_type":"code","source":"## removing those two turkish words\ndef text_refining(text):\n    new_text = []\n    for word in text.split():\n        try:\n            new_word = contractions.fix(word)  \n        except:\n            new_word = word\n            \n        finally:\n            new_text.append(new_word)\n    \n    return \" \".join(new_text)\n\ndf['comment_text'] = df.comment_text.apply(lambda text: text_refining(text))\nsplit_test_df['comment_text'] = split_test_df.comment_text.apply(lambda text: text_refining(text))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:32:47.015951Z","iopub.execute_input":"2022-01-09T07:32:47.016585Z","iopub.status.idle":"2022-01-09T07:32:54.924328Z","shell.execute_reply.started":"2022-01-09T07:32:47.016551Z","shell.execute_reply":"2022-01-09T07:32:54.923407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Tfidf Vectorizer 1-gram","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\ntfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=10000)\n\nX = tfidf_vectorizer.fit_transform(df.comment_text.values)\nX_test = tfidf_vectorizer.transform(split_test_df.comment_text.values)\n\nreal_test_df['comment_text'] = real_test_df.comment_text.apply(lambda text: text_refining(text))\nreal_X_test = tfidf_vectorizer.transform(real_test_df.comment_text.values)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:32:54.925557Z","iopub.execute_input":"2022-01-09T07:32:54.925816Z","iopub.status.idle":"2022-01-09T07:33:29.106379Z","shell.execute_reply.started":"2022-01-09T07:32:54.925775Z","shell.execute_reply":"2022-01-09T07:33:29.105319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Wordcloud","metadata":{}},{"cell_type":"code","source":"import math\nfrom wordcloud import WordCloud\nlabel_columns = ['toxic', 'severe_toxic', 'obscene', 'threat',\n       'insult', 'identity_hate']\ncount_label = {}\n\nfig, axes = plt.subplots(math.ceil(len(label_columns)/3),3,figsize = (25,15))\nfor n,col in enumerate(label_columns):\n    check_df = df[df[col]>0]\n    words = ' '.join(check_df.comment_text.values)\n    count_label[col] = len(check_df)\n    wordcloud = WordCloud(\n                      background_color='white',\n                      width=2500,\n                      height=2000\n                     ).generate(words)\n    \n    axes[n//3,n%3].imshow(wordcloud)\n    axes[n//3,n%3].axis('off')\n    axes[n//3,n%3].set_title(col)\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:48:56.804466Z","iopub.execute_input":"2022-01-09T07:48:56.805232Z","iopub.status.idle":"2022-01-09T07:50:10.148166Z","shell.execute_reply.started":"2022-01-09T07:48:56.805195Z","shell.execute_reply":"2022-01-09T07:50:10.14382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imbalance Data labels\npd.DataFrame.from_dict(count_label, orient = 'index',columns = ['count'] ).count","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:50:10.151165Z","iopub.execute_input":"2022-01-09T07:50:10.151597Z","iopub.status.idle":"2022-01-09T07:50:10.1614Z","shell.execute_reply.started":"2022-01-09T07:50:10.15155Z","shell.execute_reply":"2022-01-09T07:50:10.160645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. logistic model per label","metadata":{}},{"cell_type":"code","source":"import numpy as np\nresult = real_test_df.id.values.reshape(-1,1)\nclf = Pipeline([('ovr',LogisticRegression(solver='sag', n_jobs=-1))])\nfor label in label_columns:\n    print(\"-----------------{0}---------------\".format(label))\n    clf.fit(X,df[label].values)\n    pred = clf.predict(real_X_test).reshape(-1,1)\n    result = np.concatenate((result,pred), axis = 1)\n    print(pred.shape,type(pred))\n    #print(\"accuracy : \", accuracy_score(split_test_df[label].values,pred))\n    \npd.DataFrame(result,columns = ['id','toxic', 'severe_toxic', 'obscene', 'threat',\n       'insult', 'identity_hate']).to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:50:10.162841Z","iopub.execute_input":"2022-01-09T07:50:10.163274Z","iopub.status.idle":"2022-01-09T07:50:27.808961Z","shell.execute_reply.started":"2022-01-09T07:50:10.163231Z","shell.execute_reply":"2022-01-09T07:50:27.808093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One Vs Rest","metadata":{}},{"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nclf = Pipeline([('ovr',OneVsRestClassifier(LogisticRegression(solver='sag', n_jobs=-1)))])\nclf.fit(X,df[label_columns].values)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:54:12.942711Z","iopub.execute_input":"2022-01-09T07:54:12.943625Z","iopub.status.idle":"2022-01-09T07:54:38.986645Z","shell.execute_reply.started":"2022-01-09T07:54:12.94357Z","shell.execute_reply":"2022-01-09T07:54:38.985602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_pred = clf.predict(real_X_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:13:11.481514Z","iopub.execute_input":"2022-01-09T08:13:11.481987Z","iopub.status.idle":"2022-01-09T08:13:11.594294Z","shell.execute_reply.started":"2022-01-09T08:13:11.481947Z","shell.execute_reply":"2022-01-09T08:13:11.593143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(np.concatenate((real_test_df.id.values.reshape(-1,1),clf_pred), axis = 1),columns = ['id','toxic', 'severe_toxic', 'obscene', 'threat',\n       'insult', 'identity_hate']).to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:15:02.539839Z","iopub.execute_input":"2022-01-09T08:15:02.540165Z","iopub.status.idle":"2022-01-09T08:15:03.212538Z","shell.execute_reply.started":"2022-01-09T08:15:02.540132Z","shell.execute_reply":"2022-01-09T08:15:03.21151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}