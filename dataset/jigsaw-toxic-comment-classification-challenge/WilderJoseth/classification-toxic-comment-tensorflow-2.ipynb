{"cells":[{"metadata":{"id":"H365O9poccAp"},"cell_type":"markdown","source":"# Introduction\nThis is a work where I have to classify toxic comment using different levels (multiclassification). This is an opportunity to use tensorflow skills."},{"metadata":{"id":"qJ0v_AQpdO5Z"},"cell_type":"markdown","source":"# Data understanding"},{"metadata":{"id":"udvnaWnHdNEz","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport tensorflow as tf\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"id":"QlVBDlZxdTWU","trusted":true},"cell_type":"code","source":"seed = 1\npathData = '../input/jigsaw-toxic-comment-classification-challenge'\nbatchSize = 128","execution_count":null,"outputs":[]},{"metadata":{"id":"9qGUo8F5dU4q","trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 200)","execution_count":null,"outputs":[]},{"metadata":{"id":"j7HF5DavdY7c"},"cell_type":"markdown","source":"## Training data"},{"metadata":{"id":"ryTQ1ktJdWzK","outputId":"d15f2169-ebfe-455e-8399-ae9753056729","trusted":true},"cell_type":"code","source":"dsTrain = pd.read_csv(os.path.join(pathData, 'train.csv.zip'))\nprint('Shape:', dsTrain.shape)\ndsTrain.head(20)","execution_count":null,"outputs":[]},{"metadata":{"id":"DDWtXzWkdaly","outputId":"f2c5d64f-bd1b-4886-a834-8c50bf43a965","trusted":true},"cell_type":"code","source":"dsTrain.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"vzVYGNEi5gpr"},"cell_type":"markdown","source":"Identifying empty comments"},{"metadata":{"id":"GAoo6mradcrw","outputId":"5bf32b11-9600-4e96-b273-82e0cf2df45a","trusted":true},"cell_type":"code","source":"blanks = []\nfor index, id, text in dsTrain[['id', 'comment_text']].itertuples():\n  newText = str(text)\n  if newText.isspace():\n    blanks.append(index)\nprint(f'Number of observations without text: {len(blanks)}')","execution_count":null,"outputs":[]},{"metadata":{"id":"-u6Gv-zP5VJx"},"cell_type":"markdown","source":"Identifying comments with more than one classification"},{"metadata":{"id":"LjbffWOFdd8b","outputId":"b49a106c-25da-4a8f-ff2c-f09efda568b3","trusted":true},"cell_type":"code","source":"dsTrain['countToxic'] = dsTrain['toxic'] + dsTrain['severe_toxic'] + dsTrain['obscene'] + dsTrain['threat'] + dsTrain['insult'] + dsTrain['identity_hate']\ndsTrainCount = dsTrain[['id', 'countToxic']].groupby('id').count().reset_index()\ndsTrainCount[dsTrainCount['countToxic'] > 1]","execution_count":null,"outputs":[]},{"metadata":{"id":"jWl-xEbb4zl7"},"cell_type":"markdown","source":"Observations:\n* There are no null values.\n* There are no empty values.\n* There are no observatio with more than one classification."},{"metadata":{"id":"WkyAoPtRdsSr"},"cell_type":"markdown","source":"### Cleaning\nIn this step I will remove numbers and special characters, because these words do not help to understand toxic comments."},{"metadata":{"id":"jKGcrDQ8eWNz","trusted":true},"cell_type":"code","source":"import re\nimport spacy","execution_count":null,"outputs":[]},{"metadata":{"id":"LRUlNZAeUC0r","trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')","execution_count":null,"outputs":[]},{"metadata":{"id":"W48mtnGudf0Z","trusted":true},"cell_type":"code","source":"def customCleaning(text):\n  '''Function to get only valid words'''\n\n  # Remove http texts\n  text = re.sub(r'http\\S+', ' ', text)\n\n  # Remove numbers and special characters\n  text = re.sub(r'[^A-Za-z\\']+', ' ', text)\n  \n  text = text.lower()\n\n  return text","execution_count":null,"outputs":[]},{"metadata":{"id":"1rxtc07id3rx","trusted":true},"cell_type":"code","source":"dsTrain['comment_text'] = dsTrain['comment_text'].map(customCleaning)","execution_count":null,"outputs":[]},{"metadata":{"id":"pIC87plve759","outputId":"6e7cb94c-4e51-44dc-f0c7-ed84c0e7febd","trusted":true},"cell_type":"code","source":"dsTrain.head(20)","execution_count":null,"outputs":[]},{"metadata":{"id":"wpGNnQMWfpBL"},"cell_type":"markdown","source":"### Spliting data"},{"metadata":{"id":"cU983_Fje-7D","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"id":"O4eKMK5jfw0P","trusted":true},"cell_type":"code","source":"X = dsTrain['comment_text'].values\ny = dsTrain[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values","execution_count":null,"outputs":[]},{"metadata":{"id":"YZZfrju5fy8M","outputId":"bd32fba9-1542-404f-c9bf-a100fd7600df","trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = seed)\n\nprint('X_train:', X_train.shape)\nprint('X_val:', X_val.shape)\nprint('y_train:', y_train.shape)\nprint('y_val:', y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"tYjBeA9Df51R"},"cell_type":"markdown","source":"### Tokenizer\nIn this step, I will turn words into numbers, where each word will has its id."},{"metadata":{"id":"vakufeb5f1Ac","trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"id":"15gUEVhmgTlg","trusted":true},"cell_type":"code","source":"vocabSize = 10000\nembeddingDim = 128\nmaxLength = 120\ntruncType='post'\noovTok = \"<OOV>\"","execution_count":null,"outputs":[]},{"metadata":{"id":"FFQ5lXdtgZ9H","trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocabSize, oov_token=oovTok)\ntokenizer.fit_on_texts(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"Aj-q6Eufh6Gc"},"cell_type":"markdown","source":"#### Training"},{"metadata":{"id":"RwPBkssmhCEC","trusted":true},"cell_type":"code","source":"trainSequences = tokenizer.texts_to_sequences(X_train)\ntrainPadded = pad_sequences(trainSequences, maxlen=maxLength, truncating=truncType)","execution_count":null,"outputs":[]},{"metadata":{"id":"4sSeepkMoLsg","outputId":"ec50f766-58bd-472b-ad15-d3a8a44bb340","trusted":true},"cell_type":"code","source":"trainPadded.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"-KxZrHiyh22E"},"cell_type":"markdown","source":"#### Validation"},{"metadata":{"id":"EiDqWAn7hl-P","trusted":true},"cell_type":"code","source":"valSequences = tokenizer.texts_to_sequences(X_val)\nvalPadded = pad_sequences(valSequences, maxlen=maxLength, truncating=truncType)","execution_count":null,"outputs":[]},{"metadata":{"id":"RtUJWPuDoNhI","outputId":"7fd40b3f-6fb4-4528-955f-db93b4fa1bb7","trusted":true},"cell_type":"code","source":"valPadded.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"VG0DAF1ViI7B"},"cell_type":"markdown","source":"## Testing data"},{"metadata":{"id":"o0MPM97jh100","outputId":"fd4fa8e8-933c-484a-e9a6-57fac0a0d2d7","trusted":true},"cell_type":"code","source":"dsTest = pd.read_csv(os.path.join(pathData, 'test.csv.zip'))\nprint('Shape:', dsTest.shape)\ndsTest.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"udj4p_AfiQ-v","outputId":"bbb803cd-372c-4ff5-ed08-d5d3dca42ce7","trusted":true},"cell_type":"code","source":"dsTest.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"lc3vZ1pLiVpk","outputId":"46d06134-4826-42c5-dad1-45b979df8356","trusted":true},"cell_type":"code","source":"blanks = []\nfor index, id, text in dsTest[['id', 'comment_text']].itertuples():\n  newText = str(text)\n  if newText.isspace():\n    blanks.append(index)\nprint(f'Number of observations without text: {len(blanks)}')","execution_count":null,"outputs":[]},{"metadata":{"id":"tKlWPZUFCBeO"},"cell_type":"markdown","source":"### Cleaning"},{"metadata":{"id":"0uWL07AwCCRd","trusted":true},"cell_type":"code","source":"dsTest['comment_text'] = dsTest['comment_text'].map(customCleaning)","execution_count":null,"outputs":[]},{"metadata":{"id":"m-ISqelJCEpb","outputId":"48adf174-d4b7-40b3-b739-0da41afde6b6","trusted":true},"cell_type":"code","source":"dsTest.head(20)","execution_count":null,"outputs":[]},{"metadata":{"id":"JhzSPj5aCT8v"},"cell_type":"markdown","source":"### Transforming"},{"metadata":{"id":"T_D9KGKhCOvU","trusted":true},"cell_type":"code","source":"testSequences = tokenizer.texts_to_sequences(dsTest['comment_text'].values)\ntestPadded = pad_sequences(testSequences, maxlen=maxLength, truncating=truncType)","execution_count":null,"outputs":[]},{"metadata":{"id":"B_FNtHcbCcoD","outputId":"c604aa11-75f0-49ee-d908-2a801f5e0905","trusted":true},"cell_type":"code","source":"testPadded.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"iRRSbMUkitQP"},"cell_type":"markdown","source":"# Modeling\nIn this case, I will use a basic model based on tensorflow tutorial."},{"metadata":{"id":"K-tvXlIoia2w","trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  tf.keras.layers.Embedding(vocabSize, embeddingDim),\n  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(6, activation='sigmoid')\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"gF4nVgTjjJRk","trusted":true},"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"_Z8_UyS_jJus","outputId":"c28e5b83-32a4-47ce-852a-e41f9da29c9e","trusted":true},"cell_type":"code","source":"history = model.fit(trainPadded, y_train, epochs=10, batch_size=32, validation_data=(valPadded, y_val), callbacks=[tf.keras.callbacks.EarlyStopping(monitor = 'val_loss')])","execution_count":null,"outputs":[]},{"metadata":{"id":"U6ht9A2BpXLm"},"cell_type":"markdown","source":"## Predict"},{"metadata":{"id":"MWVt5Lzo9MMH"},"cell_type":"markdown","source":"Showing submission file example."},{"metadata":{"id":"mcOtTHoXrLfX","outputId":"2d83d04d-86d0-4d5c-83c4-e10b5cee162e","trusted":true},"cell_type":"code","source":"dsSampleSubmission = pd.read_csv(os.path.join(pathData, 'sample_submission.csv.zip'))\ndsSampleSubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"dzkDwurn9Src"},"cell_type":"markdown","source":"Predicting"},{"metadata":{"id":"D2sQV8owpYp3","outputId":"a4be615f-8165-43b5-ef3a-ea7e7e54a9e5","trusted":true},"cell_type":"code","source":"predicted = model.predict(testPadded)\nprint('Shape:', predicted.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"JiW69mAludei","trusted":true},"cell_type":"code","source":"predicted = np.round(predicted, 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"GsaPY0rTviTo","outputId":"dd065a6b-ddd1-4ae9-fe96-f5d8e4c1b16f","trusted":true},"cell_type":"code","source":"dsPredicted = pd.DataFrame(predicted, columns=['toxic', 'severe_toxic',\t'obscene', 'threat', 'insult', 'identity_hate'])\ndsSubmission = pd.concat([dsTest['id'], dsPredicted], axis=1)\ndsSubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"BdlGR6-BuiaU","trusted":true},"cell_type":"code","source":"dsSubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"gDGpfO3KxJzV"},"cell_type":"markdown","source":"# References\nhttps://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview\n\nhttps://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35\n\nhttps://www.jeansnyman.com/posts/multi-class-text-classification-with-tensorflow/"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}