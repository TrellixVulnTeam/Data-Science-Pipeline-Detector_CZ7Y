{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T20:21:24.703588Z","iopub.execute_input":"2021-05-20T20:21:24.704083Z","iopub.status.idle":"2021-05-20T20:21:24.719957Z","shell.execute_reply.started":"2021-05-20T20:21:24.70405Z","shell.execute_reply":"2021-05-20T20:21:24.718622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow-text\n!pip install bert-tensorflow==1.0.1\n!pip install -q tf-models-official==2.4.0\n!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:24.721783Z","iopub.execute_input":"2021-05-20T20:21:24.722449Z","iopub.status.idle":"2021-05-20T20:21:46.47329Z","shell.execute_reply.started":"2021-05-20T20:21:24.722387Z","shell.execute_reply":"2021-05-20T20:21:46.471919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\nimport tensorflow_text\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english')) \nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.stem import PorterStemmer\nimport tensorflow as tf\nlem = WordNetLemmatizer()\nps = PorterStemmer()\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:46.47603Z","iopub.execute_input":"2021-05-20T20:21:46.47655Z","iopub.status.idle":"2021-05-20T20:21:46.485394Z","shell.execute_reply.started":"2021-05-20T20:21:46.476502Z","shell.execute_reply":"2021-05-20T20:21:46.484167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense,Input,GlobalMaxPooling1D\nfrom keras.layers import Conv1D,MaxPooling1D,Embedding,Bidirectional\nfrom keras.layers import LSTM,Dropout\nfrom keras import regularizers\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.callbacks import ReduceLROnPlateau, TensorBoard\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:46.487496Z","iopub.execute_input":"2021-05-20T20:21:46.487799Z","iopub.status.idle":"2021-05-20T20:21:46.498946Z","shell.execute_reply.started":"2021-05-20T20:21:46.48777Z","shell.execute_reply":"2021-05-20T20:21:46.497981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"# some configuration\nmax_sequence_length = 100\nmax_vocab_size = 20000\nembedding_dim = 300\nvalidation_split = 0.2\nbatch_size = 128\nepoch = 5\n\nsizes ={\"tiny\":16,\"mini\":32,\"small\":64,\"medium\":128,\"large\":256,\"grand\":512}\nsize = \"tiny\"","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:46.500137Z","iopub.execute_input":"2021-05-20T20:21:46.500473Z","iopub.status.idle":"2021-05-20T20:21:46.516517Z","shell.execute_reply.started":"2021-05-20T20:21:46.50042Z","shell.execute_reply":"2021-05-20T20:21:46.515331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ndf2 = df.copy()\ndf_test = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:46.517936Z","iopub.execute_input":"2021-05-20T20:21:46.518242Z","iopub.status.idle":"2021-05-20T20:21:49.433748Z","shell.execute_reply.started":"2021-05-20T20:21:46.518214Z","shell.execute_reply":"2021-05-20T20:21:49.433027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.435024Z","iopub.execute_input":"2021-05-20T20:21:49.435606Z","iopub.status.idle":"2021-05-20T20:21:49.448219Z","shell.execute_reply.started":"2021-05-20T20:21:49.435562Z","shell.execute_reply":"2021-05-20T20:21:49.447204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.450691Z","iopub.execute_input":"2021-05-20T20:21:49.451171Z","iopub.status.idle":"2021-05-20T20:21:49.50915Z","shell.execute_reply.started":"2021-05-20T20:21:49.451121Z","shell.execute_reply":"2021-05-20T20:21:49.508069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df.comment_text.max())","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.510848Z","iopub.execute_input":"2021-05-20T20:21:49.51131Z","iopub.status.idle":"2021-05-20T20:21:49.553213Z","shell.execute_reply.started":"2021-05-20T20:21:49.511268Z","shell.execute_reply":"2021-05-20T20:21:49.55225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.554486Z","iopub.execute_input":"2021-05-20T20:21:49.554769Z","iopub.status.idle":"2021-05-20T20:21:49.604063Z","shell.execute_reply.started":"2021-05-20T20:21:49.554743Z","shell.execute_reply":"2021-05-20T20:21:49.602975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_list = [f for f in df.columns if df.dtypes[f] != 'object']\ndfP = pd.DataFrame(columns=column_list)\nfor col in column_list:\n    dfP.loc[0,col] = df[df[col] == 1][col].sum()\ndfP['non_hate'] = df.shape[0] - dfP.sum(axis=1)    ","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.605346Z","iopub.execute_input":"2021-05-20T20:21:49.605642Z","iopub.status.idle":"2021-05-20T20:21:49.637283Z","shell.execute_reply.started":"2021-05-20T20:21:49.605615Z","shell.execute_reply":"2021-05-20T20:21:49.636177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pie, ax = plt.subplots(figsize=[13,10])\nlabels = dfP.keys()\nplt.pie(x=dfP.values[0], autopct=\"%.12f\", explode=[0.05]*len(dfP.values[0]), labels=labels, pctdistance=0.55)\nplt.title(\"Types of Toxic Comments\", fontsize=14);\ndel dfP\ndel column_list","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.638597Z","iopub.execute_input":"2021-05-20T20:21:49.638904Z","iopub.status.idle":"2021-05-20T20:21:49.819185Z","shell.execute_reply.started":"2021-05-20T20:21:49.638873Z","shell.execute_reply":"2021-05-20T20:21:49.818128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    \n    text = text.lower()\n    text = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '', text) # clean url\n    text = re.sub(r'#(\\w+)', '', text)   # clean hashes\n    text = re.sub(r'@(\\w+)', '', text)   # clean @\n    text = re.sub(r'<[^>]+>', '', text)  # clean tags\n    text = re.sub(r'\\d+', '', text)      # clean digits\n    text = re.sub(r'[,!@\\'\\\"?\\.$%_&#*+-:;]', '', text)   # clean punctuation\n    #word_tokens = nltk.word_tokenize(text)\n    #filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    #text = \"\".join(filtered_sentence)\n    text = lem.lemmatize(text)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.820753Z","iopub.execute_input":"2021-05-20T20:21:49.821054Z","iopub.status.idle":"2021-05-20T20:21:49.827834Z","shell.execute_reply.started":"2021-05-20T20:21:49.821025Z","shell.execute_reply":"2021-05-20T20:21:49.826707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating embedding layer","metadata":{}},{"cell_type":"code","source":"# load in pre-trained vectors\n# loading word vectors by using pre trained glove.6B.txt file\nprint('Loading word vectors...')\nword2vec = {}\nwith open(os.path.join('../input/glove6b/glove.6B.%sd.txt' % embedding_dim)) as f:\n    # word vec[0] vec[1] vec[2] ...\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vec = np.asarray(values[1:], dtype='float128')\n        word2vec[word] = vec","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:21:49.829201Z","iopub.execute_input":"2021-05-20T20:21:49.829541Z","iopub.status.idle":"2021-05-20T20:23:04.209158Z","shell.execute_reply.started":"2021-05-20T20:21:49.829509Z","shell.execute_reply":"2021-05-20T20:23:04.208261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:04.210687Z","iopub.execute_input":"2021-05-20T20:23:04.211109Z","iopub.status.idle":"2021-05-20T20:23:04.259675Z","shell.execute_reply.started":"2021-05-20T20:23:04.211068Z","shell.execute_reply":"2021-05-20T20:23:04.258471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare text samples and their labels\nprint('loading in comments...')\nclean_sentences = df2['comment_text'].apply(clean_text)\nsentences = clean_sentences\nsentences[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:04.260997Z","iopub.execute_input":"2021-05-20T20:23:04.261411Z","iopub.status.idle":"2021-05-20T20:23:12.992214Z","shell.execute_reply.started":"2021-05-20T20:23:04.261366Z","shell.execute_reply":"2021-05-20T20:23:12.991209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('loading in test comments...')\ntest_sentences = df_test['comment_text'].values","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:12.993448Z","iopub.execute_input":"2021-05-20T20:23:12.993755Z","iopub.status.idle":"2021-05-20T20:23:12.99872Z","shell.execute_reply.started":"2021-05-20T20:23:12.993728Z","shell.execute_reply":"2021-05-20T20:23:12.997778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"possible_labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\ntrain_labels = df[possible_labels].values","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:13.000048Z","iopub.execute_input":"2021-05-20T20:23:13.00036Z","iopub.status.idle":"2021-05-20T20:23:13.018457Z","shell.execute_reply.started":"2021-05-20T20:23:13.000332Z","shell.execute_reply":"2021-05-20T20:23:13.017143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the sentences into tokens/integers\ntokenizer = Tokenizer(num_words=max_vocab_size)\ntokenizer.fit_on_texts(sentences)\nsequences = tokenizer.texts_to_sequences(sentences)\ntest_sequences = tokenizer.texts_to_sequences(test_sentences)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:13.019639Z","iopub.execute_input":"2021-05-20T20:23:13.019941Z","iopub.status.idle":"2021-05-20T20:23:43.628057Z","shell.execute_reply.started":"2021-05-20T20:23:13.019913Z","shell.execute_reply":"2021-05-20T20:23:43.627047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get word -> integer mapping\nword2idx = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word2idx))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:43.629197Z","iopub.execute_input":"2021-05-20T20:23:43.629513Z","iopub.status.idle":"2021-05-20T20:23:43.634449Z","shell.execute_reply.started":"2021-05-20T20:23:43.629473Z","shell.execute_reply":"2021-05-20T20:23:43.633466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pad sequences so that we get a NxT matrix\ntrain_data = pad_sequences(sequences,maxlen=max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:43.635801Z","iopub.execute_input":"2021-05-20T20:23:43.636115Z","iopub.status.idle":"2021-05-20T20:23:45.932337Z","shell.execute_reply.started":"2021-05-20T20:23:43.636078Z","shell.execute_reply":"2021-05-20T20:23:45.931288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pad_sequences(test_sequences,maxlen=max_sequence_length)\ntest_data","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:45.933779Z","iopub.execute_input":"2021-05-20T20:23:45.934103Z","iopub.status.idle":"2021-05-20T20:23:47.965493Z","shell.execute_reply.started":"2021-05-20T20:23:45.934071Z","shell.execute_reply":"2021-05-20T20:23:47.964752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare embedding matrix\nprint('Filling pre-trained embeddings...')\nnum_words = min(max_vocab_size, len(word2idx) + 1)\nembedding_matrix = np.zeros((num_words, embedding_dim))\nfor word, i in word2idx.items():\n      if i < max_vocab_size:\n        embedding_vector = word2vec.get(word)\n        if embedding_vector is not None:\n          # words not found in embedding index will be all zeros.\n          embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:47.969259Z","iopub.execute_input":"2021-05-20T20:23:47.969743Z","iopub.status.idle":"2021-05-20T20:23:48.125177Z","shell.execute_reply.started":"2021-05-20T20:23:47.969711Z","shell.execute_reply":"2021-05-20T20:23:48.124017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.127321Z","iopub.execute_input":"2021-05-20T20:23:48.127648Z","iopub.status.idle":"2021-05-20T20:23:48.131649Z","shell.execute_reply.started":"2021-05-20T20:23:48.127617Z","shell.execute_reply":"2021-05-20T20:23:48.130627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cyclic_lr import CyclicLR\n\nclr_cnn = CyclicLR(base_lr=8e-5,max_lr=4e-4,step_size=4000,mode='triangular2')\n\nclr_lstm = CyclicLR(base_lr=1e-6,max_lr=1e-4,step_size=4000,mode='triangular2')\n\nclr_hybrid = CyclicLR(base_lr=1e-6,max_lr=1e-4,step_size=2000,mode='triangular2')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.133031Z","iopub.execute_input":"2021-05-20T20:23:48.133618Z","iopub.status.idle":"2021-05-20T20:23:48.169824Z","shell.execute_reply.started":"2021-05-20T20:23:48.133574Z","shell.execute_reply":"2021-05-20T20:23:48.168753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_layer = Embedding(num_words,\n                           embedding_dim,\n                           weights=[embedding_matrix],\n                           input_length= max_sequence_length,\n                           trainable = False,name='Embedding')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.171399Z","iopub.execute_input":"2021-05-20T20:23:48.171846Z","iopub.status.idle":"2021-05-20T20:23:48.189049Z","shell.execute_reply.started":"2021-05-20T20:23:48.1718Z","shell.execute_reply":"2021-05-20T20:23:48.188124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create train,validation set, with split of 0.2\nX_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.190272Z","iopub.execute_input":"2021-05-20T20:23:48.190605Z","iopub.status.idle":"2021-05-20T20:23:48.254382Z","shell.execute_reply.started":"2021-05-20T20:23:48.190574Z","shell.execute_reply":"2021-05-20T20:23:48.253661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=2,mode='min',min_delta=0.005)\n \n    \n    \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n                                                     patience=2, min_lr=0.000001)\nfrom lrfinder import LRFinder\nlr_finder = LRFinder(min_lr=1e-7, \n                                 max_lr=1e-2, \n                                 steps_per_epoch=998, \n                                 epochs=5)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.255643Z","iopub.execute_input":"2021-05-20T20:23:48.256151Z","iopub.status.idle":"2021-05-20T20:23:48.274584Z","shell.execute_reply.started":"2021-05-20T20:23:48.256118Z","shell.execute_reply":"2021-05-20T20:23:48.273629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_auc_loss(history):\n    history_dict = history.history\n    print(history_dict.keys())\n\n    acc = history_dict['auc']\n    val_acc = history_dict['val_auc']\n    loss = history_dict['loss']\n    val_loss = history_dict['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n    fig = plt.figure(figsize=(10, 6))\n    plt.subplot(2, 1, 1)\n    # \"bo\" is for \"blue dot\"\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    # b is for \"solid blue line\"\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \n    \n    plt.plot(epochs, acc, 'r', label='Training AUC')\n    plt.plot(epochs, val_acc, 'b', label='Validation AUC')\n    plt.title('Training and validation AUC')\n    plt.xlabel('Epochs')\n    plt.ylabel('AUC')\n    plt.legend(loc='lower right')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.276004Z","iopub.execute_input":"2021-05-20T20:23:48.276461Z","iopub.status.idle":"2021-05-20T20:23:48.28594Z","shell.execute_reply.started":"2021-05-20T20:23:48.27639Z","shell.execute_reply":"2021-05-20T20:23:48.284849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hybrid Model","metadata":{}},{"cell_type":"code","source":"model_hybrid = Sequential(name='Hybrid')\nmodel_hybrid.add(embedding_layer)\nmodel_hybrid.add(Bidirectional(LSTM(sizes[size],return_sequences=True),name='Bidirectional'))\nmodel_hybrid.add(Dense(sizes[size],name='Dense1'))\nmodel_hybrid.add(Dropout(0.2,name='Dropout1'))\nmodel_hybrid.add(Conv1D(sizes[size],3))\nmodel_hybrid.add(GlobalMaxPooling1D(name='Pooling'))\nmodel_hybrid.add(Dense(sizes[size],name='Dense2'))\nmodel_hybrid.add(Dropout(0.2,name='Dropout2'))\nmodel_hybrid.add(Dense(6,activation='sigmoid',name='Classifier'))\nmodel_hybrid.summary()\nmodel_hybrid.compile(loss = 'binary_crossentropy', optimizer = Adam(), metrics = ['AUC'])\nhistory_hybrid = model_hybrid.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = epoch, batch_size = batch_size ,callbacks=[clr_hybrid,early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:23:48.287755Z","iopub.execute_input":"2021-05-20T20:23:48.28821Z","iopub.status.idle":"2021-05-20T20:33:02.799227Z","shell.execute_reply.started":"2021-05-20T20:23:48.288152Z","shell.execute_reply":"2021-05-20T20:33:02.798192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_auc_loss(history_hybrid)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:33:02.801234Z","iopub.execute_input":"2021-05-20T20:33:02.801557Z","iopub.status.idle":"2021-05-20T20:33:03.15178Z","shell.execute_reply.started":"2021-05-20T20:33:02.801527Z","shell.execute_reply":"2021-05-20T20:33:03.150732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prints the learning rate finder loss vs lr\n#lr_finder.plot_loss()\n#lr_finder.plot_lr()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:33:03.153461Z","iopub.execute_input":"2021-05-20T20:33:03.153868Z","iopub.status.idle":"2021-05-20T20:33:03.158161Z","shell.execute_reply.started":"2021-05-20T20:33:03.153826Z","shell.execute_reply":"2021-05-20T20:33:03.157185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model","metadata":{}},{"cell_type":"code","source":"print('Training model')\n\nmodel_cnn = Sequential(name='CNN')\ninput_ = Input(shape=(max_sequence_length,))\nmodel_cnn.add(embedding_layer)\nmodel_cnn.add(Conv1D(sizes[size],3,activation='relu',name='Convolutional1'))\nmodel_cnn.add(MaxPooling1D(3))\nmodel_cnn.add(Conv1D(sizes[size],3,activation='relu',name='Convolutional2'))\nmodel_cnn.add(GlobalMaxPooling1D(name='Pooling'))\nmodel_cnn.add(Dense(sizes[size],name='Dense'))\nmodel_cnn.add(Dropout(0.2))\nmodel_cnn.add(Dense(len(possible_labels),activation='sigmoid',name='Classifier'))\n\nmodel_cnn.compile(loss='binary_crossentropy',\n             optimizer=Adam(),\n             metrics=['AUC'])\n\n\nhistory_cnn = model_cnn.fit(X_train,y_train,batch_size=batch_size, epochs=epoch,validation_data=(X_test,y_test),callbacks=[clr_cnn,early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:33:03.159712Z","iopub.execute_input":"2021-05-20T20:33:03.160108Z","iopub.status.idle":"2021-05-20T20:36:29.652328Z","shell.execute_reply.started":"2021-05-20T20:33:03.16007Z","shell.execute_reply":"2021-05-20T20:36:29.651352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_losses = pd.DataFrame(history_cnn.history)\nprint_auc_loss(history_cnn)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:36:29.653893Z","iopub.execute_input":"2021-05-20T20:36:29.654207Z","iopub.status.idle":"2021-05-20T20:36:30.015044Z","shell.execute_reply.started":"2021-05-20T20:36:29.654177Z","shell.execute_reply":"2021-05-20T20:36:30.013938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plots the learning rate when using lr_finder\n#lr_finder.plot_loss()\n#lr_finder.plot_lr()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:36:30.016363Z","iopub.execute_input":"2021-05-20T20:36:30.016731Z","iopub.status.idle":"2021-05-20T20:36:30.020764Z","shell.execute_reply.started":"2021-05-20T20:36:30.016699Z","shell.execute_reply":"2021-05-20T20:36:30.019748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM Model","metadata":{}},{"cell_type":"code","source":"print('Training model')\n\nmodel_lstm = Sequential(name='LSTM')\nmodel_lstm.add(embedding_layer)\nmodel_lstm.add(Bidirectional(LSTM(sizes[size]),name='BidirectionalLSTM'))\nmodel_lstm.add(Dense(sizes[size],name='Dense'))\n#odel_lstm.add(Dropout(0.2))\nmodel_lstm.add(Dense(sizes[size]))\n#odel_lstm.add(Dropout(0.2))\nmodel_lstm.add(Dense(len(possible_labels),activation='sigmoid',name='Classifier'))\n    \nmodel_lstm.compile(loss='binary_crossentropy',\n             optimizer=Adam(),\n             metrics=['AUC','accuracy'])\n\n\nhistory_lstm = model_lstm.fit(X_train,y_train,batch_size=batch_size, epochs=epoch,validation_data=(X_test,y_test),callbacks=[clr_lstm,early_stop])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:36:30.021958Z","iopub.execute_input":"2021-05-20T20:36:30.022235Z","iopub.status.idle":"2021-05-20T20:45:09.876996Z","shell.execute_reply.started":"2021-05-20T20:36:30.022209Z","shell.execute_reply":"2021-05-20T20:45:09.876027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_auc_loss(history_lstm)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:09.87853Z","iopub.execute_input":"2021-05-20T20:45:09.878816Z","iopub.status.idle":"2021-05-20T20:45:10.238557Z","shell.execute_reply.started":"2021-05-20T20:45:09.87879Z","shell.execute_reply":"2021-05-20T20:45:10.237504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding the mean AUC score of the models trained.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:10.239873Z","iopub.execute_input":"2021-05-20T20:45:10.240173Z","iopub.status.idle":"2021-05-20T20:45:10.244711Z","shell.execute_reply.started":"2021-05-20T20:45:10.240144Z","shell.execute_reply":"2021-05-20T20:45:10.243498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_string = \"\"","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:10.246177Z","iopub.execute_input":"2021-05-20T20:45:10.246602Z","iopub.status.idle":"2021-05-20T20:45:10.25933Z","shell.execute_reply.started":"2021-05-20T20:45:10.24656Z","shell.execute_reply":"2021-05-20T20:45:10.258145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LSTM\npL = model_lstm.predict(X_test)\naucsL = []\nfor j in range(6):\n    auc = roc_auc_score(y_test[:,j],pL[:,j])\n    aucsL.append(auc)\nprint(\"auc lstm:\" +str(np.mean(aucsL)))\ntotal_string+=\"auc lstm:\" +str(np.mean(aucsL))+\"\\n\"","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:10.261157Z","iopub.execute_input":"2021-05-20T20:45:10.261587Z","iopub.status.idle":"2021-05-20T20:45:28.397618Z","shell.execute_reply.started":"2021-05-20T20:45:10.261542Z","shell.execute_reply":"2021-05-20T20:45:28.396826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CNN\npC = model_cnn.predict(X_test)\naucsC = []\nfor j in range(6):\n    auc = roc_auc_score(y_test[:,j],pC[:,j])\n    aucsC.append(auc)\nprint(\"auc cnn:\" +str(np.mean(aucsC)))\ntotal_string+=\"auc cnn:\" +str(np.mean(aucsC))+\"\\n\"","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:28.398798Z","iopub.execute_input":"2021-05-20T20:45:28.399081Z","iopub.status.idle":"2021-05-20T20:45:31.431455Z","shell.execute_reply.started":"2021-05-20T20:45:28.399051Z","shell.execute_reply":"2021-05-20T20:45:31.43042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hybrid\npH = model_hybrid.predict(X_test)\naucsH = []\n##precs = []\n#recalls = []\n#f1_scores = []\nfor j in range(6):\n    auc = roc_auc_score(y_test[:,j],pH[:,j])\n    aucsH.append(auc)\n    \nprint(\"auc hybrid:\" +str(np.mean(aucsH)))\ntotal_string+=\"auc hybrid:\" +str(np.mean(aucsH))+\"\\n\"\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:31.432744Z","iopub.execute_input":"2021-05-20T20:45:31.433036Z","iopub.status.idle":"2021-05-20T20:45:50.777695Z","shell.execute_reply.started":"2021-05-20T20:45:31.433008Z","shell.execute_reply":"2021-05-20T20:45:50.776723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"size is: \"+size+\"\\n\"+\"embedding dimensions: \"+str(embedding_dim)+\"\\n\"+total_string)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:29.284417Z","iopub.execute_input":"2021-05-20T20:56:29.284828Z","iopub.status.idle":"2021-05-20T20:56:29.290977Z","shell.execute_reply.started":"2021-05-20T20:56:29.284794Z","shell.execute_reply":"2021-05-20T20:56:29.289603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make CSV out of predictions to be submission ready.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#p = model_cnn.predict(test_data)\n#predict = np.hstack((df_test.id[:, np.newaxis], p))\n#subm = pd.DataFrame(predict, columns = ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n#subm.to_csv('subm_CNN.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.812794Z","iopub.status.idle":"2021-05-20T20:45:50.813287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#p = model_lstm.predict(test_data)\n#predict = np.hstack((df_test.id[:, np.newaxis], p))\n#subm = pd.DataFrame(predict, columns = ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n#subm.to_csv('subm_LSTM2.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.814149Z","iopub.status.idle":"2021-05-20T20:45:50.814605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#p = model_hybrid.predict(test_data)\n#predict = np.hstack((df_test.id[:, np.newaxis], p))\n#subm = pd.DataFrame(predict, columns = ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n#subm.to_csv('subm_HYBRID2.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.81564Z","iopub.status.idle":"2021-05-20T20:45:50.816109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prints the model overview to file.","metadata":{}},{"cell_type":"code","source":"\"\"\"\"tf.keras.utils.plot_model( model_hybrid, to_file='model_hybrid.png', show_shapes=False, show_dtype=False,\n    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=48)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.817016Z","iopub.status.idle":"2021-05-20T20:45:50.817413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first exp\nx = [16,32,64,128,256]\nc = [0.924,0.934,0.942,0.952,0.957]\nl =[0.948,0.952,0.959,0.964,0.971]\nh =[0.953,0.951,0.959,0.966,0.974]\nplt.plot(x, c, \"-o\")\nplt.plot(x,l, \"-o\")\nplt.plot(x,h,\"-o\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:38.210773Z","iopub.execute_input":"2021-05-20T20:56:38.211122Z","iopub.status.idle":"2021-05-20T20:56:38.345318Z","shell.execute_reply.started":"2021-05-20T20:56:38.211093Z","shell.execute_reply":"2021-05-20T20:56:38.344342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#second exp\nx = [16,32,64,128,256]\nc = [0.928,0.933,0.944,0.951,0.962]\nl =[0.950,0.954,0.955,0.971,0.975]\nh =[0.945,0.951,0.958,0.963,0.973]\nplt.plot(x, c, \"-o\")\nplt.plot(x,l, \"-o\")\nplt.plot(x,h,\"-o\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:40.429794Z","iopub.execute_input":"2021-05-20T20:56:40.430151Z","iopub.status.idle":"2021-05-20T20:56:40.56462Z","shell.execute_reply.started":"2021-05-20T20:56:40.430123Z","shell.execute_reply":"2021-05-20T20:56:40.563647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BERT MODEL IMPLEMENTATION\nFollowing this tutorial\n[Bert google colab](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=US_EAnICvP7f)\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from official import nlp\nfrom transformers import AutoTokenizer,TFAutoModel\nfrom bert_tokenizer_v2 import FullTokenizer\n\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:43.671122Z","iopub.execute_input":"2021-05-20T20:56:43.67152Z","iopub.status.idle":"2021-05-20T20:56:45.513279Z","shell.execute_reply.started":"2021-05-20T20:56:43.671486Z","shell.execute_reply":"2021-05-20T20:56:45.511978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from official.nlp import bert\n# Load the required submodules\nimport official.nlp.bert.bert_models\nimport official.nlp.bert.configs\nimport official.nlp.bert.run_classifier\nimport official.nlp.bert.tokenization\nimport official.nlp.data.classifier_data_lib\nimport official.nlp.modeling.losses\nimport official.nlp.modeling.models\nimport official.nlp.modeling.networks\nfrom official.nlp import optimization","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:45.514942Z","iopub.execute_input":"2021-05-20T20:56:45.515243Z","iopub.status.idle":"2021-05-20T20:56:46.230798Z","shell.execute_reply.started":"2021-05-20T20:56:45.515212Z","shell.execute_reply":"2021-05-20T20:56:46.229756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 4\nsteps_per_epoch = np.ceil(len(X_train)/batch_size)\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizerr = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:46.232617Z","iopub.execute_input":"2021-05-20T20:56:46.232922Z","iopub.status.idle":"2021-05-20T20:56:46.239591Z","shell.execute_reply.started":"2021-05-20T20:56:46.232892Z","shell.execute_reply":"2021-05-20T20:56:46.238516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"bert_model_name = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1'\n#bert_model_name = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1'\nbert_preprocess_name = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n\ntfhub_handle_encoder = bert_model_name\ntfhub_handle_preprocess = bert_preprocess_name\n\nprint(f'BERT model selected           : {tfhub_handle_encoder}') \nprint(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:47.141222Z","iopub.execute_input":"2021-05-20T20:56:47.141622Z","iopub.status.idle":"2021-05-20T20:56:47.147754Z","shell.execute_reply.started":"2021-05-20T20:56:47.141588Z","shell.execute_reply":"2021-05-20T20:56:47.146641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:49.313526Z","iopub.execute_input":"2021-05-20T20:56:49.313888Z","iopub.status.idle":"2021-05-20T20:56:52.085102Z","shell.execute_reply.started":"2021-05-20T20:56:49.313859Z","shell.execute_reply":"2021-05-20T20:56:52.083956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def build_classifier_model():\n  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n  encoder_inputs = preprocessing_layer(text_input)\n  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n  outputs = encoder(encoder_inputs)\n  net = outputs['pooled_output']\n  net = tf.keras.layers.Dropout(0.25,name='Dropout')(net)\n  net = tf.keras.layers.Dense(6, activation='sigmoid', name='classifier')(net)\n  return tf.keras.Model(text_input, net)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:52.086426Z","iopub.execute_input":"2021-05-20T20:56:52.086726Z","iopub.status.idle":"2021-05-20T20:56:52.095563Z","shell.execute_reply.started":"2021-05-20T20:56:52.086698Z","shell.execute_reply":"2021-05-20T20:56:52.094525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = build_classifier_model()\nbert_model.compile(loss='binary_crossentropy',\n             optimizer=optimizerr,\n             metrics=['AUC'])\n\nbert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:52.097024Z","iopub.execute_input":"2021-05-20T20:56:52.097303Z","iopub.status.idle":"2021-05-20T20:56:59.691224Z","shell.execute_reply.started":"2021-05-20T20:56:52.097275Z","shell.execute_reply":"2021-05-20T20:56:59.690278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The bert training is commented out, because it takes a lot of time. \n\nprint(f'Training model with {tfhub_handle_encoder}')\n\nX_train, X_test, y_train, y_test = train_test_split(sentences, train_labels, test_size=0.2, random_state=42)\n\n#history_bert = bert_model.fit(X_train,y_train,batch_size=batch_size,\n        #                 epochs=epochs,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:56:59.692859Z","iopub.execute_input":"2021-05-20T20:56:59.693271Z","iopub.status.idle":"2021-05-20T20:56:59.747464Z","shell.execute_reply.started":"2021-05-20T20:56:59.69323Z","shell.execute_reply":"2021-05-20T20:56:59.746366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print_acc_loss(history_bert)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.83152Z","iopub.status.idle":"2021-05-20T20:45:50.831931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_s = df_test['comment_text']\n#test_s.apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.833208Z","iopub.status.idle":"2021-05-20T20:45:50.833637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\"\"\"p = bert_model.predict(test_s)\naucs = []\nfor j in range(6):\n    auc = roc_auc_score(y_test[:,j],p[:,j])\n    aucs.append(auc)\nprint(\"auc bert:\" +str(np.mean(aucs)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-05-20T20:45:50.83484Z","iopub.status.idle":"2021-05-20T20:45:50.835345Z"},"trusted":true},"execution_count":null,"outputs":[]}]}