{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NLP Practical 3\n> 19BCE245 - Aayush Shah","metadata":{"id":"4mOYQQikJfTt"}},{"cell_type":"markdown","source":"## 1. Explore `CountVectorizer` and `TfidfVectorizer`","metadata":{"id":"kWK4ctDkJg98"}},{"cell_type":"markdown","source":"  - ### with `CountVectorizer` : ","metadata":{"id":"bVPQUI07WHTN"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer","metadata":{"id":"bx86JA5cJRRK","execution":{"iopub.status.busy":"2022-03-11T17:48:04.916783Z","iopub.execute_input":"2022-03-11T17:48:04.917082Z","iopub.status.idle":"2022-03-11T17:48:04.921849Z","shell.execute_reply.started":"2022-03-11T17:48:04.917048Z","shell.execute_reply":"2022-03-11T17:48:04.921228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = [\n  'This is the first document.',\n  'This document is the second document.',\n  'And this is the third one.',\n  'Is this the first document?',\n]","metadata":{"id":"_WpoN3i8JVwP","execution":{"iopub.status.busy":"2022-03-11T17:48:04.923419Z","iopub.execute_input":"2022-03-11T17:48:04.923723Z","iopub.status.idle":"2022-03-11T17:48:04.934932Z","shell.execute_reply.started":"2022-03-11T17:48:04.923693Z","shell.execute_reply":"2022-03-11T17:48:04.934077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX = vectorizer.fit_transform(corpus)\nvectorizer.get_feature_names_out()","metadata":{"id":"QXX04vHZK5WX","outputId":"c33722c5-f284-4981-8150-704aa27fc527","execution":{"iopub.status.busy":"2022-03-11T17:48:04.936179Z","iopub.execute_input":"2022-03-11T17:48:04.936644Z","iopub.status.idle":"2022-03-11T17:48:04.951946Z","shell.execute_reply.started":"2022-03-11T17:48:04.936601Z","shell.execute_reply":"2022-03-11T17:48:04.951024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.toarray())","metadata":{"id":"adOKx2FMLHGj","outputId":"789d81e0-0634-461d-8e36-65c3e4d70ec3","execution":{"iopub.status.busy":"2022-03-11T17:48:04.954116Z","iopub.execute_input":"2022-03-11T17:48:04.954818Z","iopub.status.idle":"2022-03-11T17:48:04.96134Z","shell.execute_reply.started":"2022-03-11T17:48:04.95477Z","shell.execute_reply":"2022-03-11T17:48:04.960466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2,2))\nX2 = vectorizer2.fit_transform(corpus)\nvectorizer2.get_feature_names_out()","metadata":{"id":"cK7c3nGWLJm4","outputId":"0d919c83-478a-4eb1-816f-350b171b824d","execution":{"iopub.status.busy":"2022-03-11T17:48:04.962818Z","iopub.execute_input":"2022-03-11T17:48:04.963275Z","iopub.status.idle":"2022-03-11T17:48:04.97438Z","shell.execute_reply.started":"2022-03-11T17:48:04.963236Z","shell.execute_reply":"2022-03-11T17:48:04.973829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X2.toarray())","metadata":{"id":"yO2GO1DlLeJz","outputId":"837ef216-8460-40bb-f276-4234233694d6","execution":{"iopub.status.busy":"2022-03-11T17:48:04.976005Z","iopub.execute_input":"2022-03-11T17:48:04.976312Z","iopub.status.idle":"2022-03-11T17:48:04.983198Z","shell.execute_reply.started":"2022-03-11T17:48:04.976274Z","shell.execute_reply":"2022-03-11T17:48:04.982381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer3 = CountVectorizer(decode_error='ignore', stop_words='english', ngram_range=(1,3))\nX3 = vectorizer3.fit_transform(corpus)\nvectorizer3.get_feature_names_out()","metadata":{"id":"WcPOL8V9LqcP","outputId":"b786e1a0-61b3-4dd6-ea2b-35ae19562cb6","execution":{"iopub.status.busy":"2022-03-11T17:48:04.984442Z","iopub.execute_input":"2022-03-11T17:48:04.984781Z","iopub.status.idle":"2022-03-11T17:48:04.998402Z","shell.execute_reply.started":"2022-03-11T17:48:04.984744Z","shell.execute_reply":"2022-03-11T17:48:04.997388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X3.toarray())","metadata":{"id":"nuQGooaTMMij","outputId":"40678f2a-4fe1-43d0-c268-c25de232a9cf","execution":{"iopub.status.busy":"2022-03-11T17:48:04.999568Z","iopub.execute_input":"2022-03-11T17:48:04.999885Z","iopub.status.idle":"2022-03-11T17:48:05.014213Z","shell.execute_reply.started":"2022-03-11T17:48:04.999859Z","shell.execute_reply":"2022-03-11T17:48:05.013581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"  - ### with `TfidfVectorizer` : ","metadata":{"id":"5EddNOZtWPLz"}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(corpus)\nvectorizer.get_feature_names_out()","metadata":{"id":"xZRJuM2VWOwt","outputId":"abb92df5-2478-4d58-8ce3-4df4d648b9e0","execution":{"iopub.status.busy":"2022-03-11T17:48:05.01637Z","iopub.execute_input":"2022-03-11T17:48:05.017092Z","iopub.status.idle":"2022-03-11T17:48:05.028987Z","shell.execute_reply.started":"2022-03-11T17:48:05.017055Z","shell.execute_reply":"2022-03-11T17:48:05.027833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(vectorizer.get_feature_names_out())\nprint(X.toarray())","metadata":{"id":"nG8pTByXWuGf","outputId":"39ec04c1-9733-4eca-e110-fa0d4eed0109","execution":{"iopub.status.busy":"2022-03-11T17:48:05.031385Z","iopub.execute_input":"2022-03-11T17:48:05.031862Z","iopub.status.idle":"2022-03-11T17:48:05.038231Z","shell.execute_reply.started":"2022-03-11T17:48:05.031818Z","shell.execute_reply":"2022-03-11T17:48:05.037483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Do 1st part with file handling.","metadata":{"id":"0BTcdr2pMrw9"}},{"cell_type":"code","source":"# Making files\nfor i in range(len(corpus)):\n  f = open(\"data\"+str(i+1)+\".txt\", \"w\")\n  f.write(corpus[i])\n  f.close()","metadata":{"id":"Hi1nndOvMwFw","execution":{"iopub.status.busy":"2022-03-11T17:48:05.039604Z","iopub.execute_input":"2022-03-11T17:48:05.040051Z","iopub.status.idle":"2022-03-11T17:48:05.052182Z","shell.execute_reply.started":"2022-03-11T17:48:05.040016Z","shell.execute_reply":"2022-03-11T17:48:05.051219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading files\nextracted_corpus = []\nfor i in range(len(corpus)):\n  f = open(\"data\"+str(i+1)+\".txt\",'r')\n  extracted_corpus.append(f.read())\n\nprint(extracted_corpus)","metadata":{"id":"PjwIF_43NHrC","outputId":"a5d12cf4-f239-4257-c455-fa56c1104eba","execution":{"iopub.status.busy":"2022-03-11T17:48:05.053418Z","iopub.execute_input":"2022-03-11T17:48:05.05371Z","iopub.status.idle":"2022-03-11T17:48:05.066987Z","shell.execute_reply.started":"2022-03-11T17:48:05.05368Z","shell.execute_reply":"2022-03-11T17:48:05.065875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting document names from current directory\ndoc_names = os.listdir('.')\nprint(doc_names)\ndoc_names = [i for i in doc_names if ('.txt' in i)]\nprint(doc_names)","metadata":{"id":"Kx1F8fNbTNee","outputId":"f104a5b2-95d9-4272-9661-e90d661fa923","execution":{"iopub.status.busy":"2022-03-11T17:48:05.068397Z","iopub.execute_input":"2022-03-11T17:48:05.068813Z","iopub.status.idle":"2022-03-11T17:48:05.078537Z","shell.execute_reply.started":"2022-03-11T17:48:05.06878Z","shell.execute_reply":"2022-03-11T17:48:05.077668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- ### with `CountVectorizer` : ","metadata":{"id":"A-pDhVz7Xh14"}},{"cell_type":"code","source":"vectorizer4 = CountVectorizer(input=doc_names)\nX4 = vectorizer4.fit_transform(corpus)\nvectorizer4.get_feature_names_out()","metadata":{"id":"FF_RqiYPS27Z","outputId":"c82bbd9b-fba0-4666-d68c-7dddcc44b973","execution":{"iopub.status.busy":"2022-03-11T17:48:05.079781Z","iopub.execute_input":"2022-03-11T17:48:05.080369Z","iopub.status.idle":"2022-03-11T17:48:05.091087Z","shell.execute_reply.started":"2022-03-11T17:48:05.080318Z","shell.execute_reply":"2022-03-11T17:48:05.09009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# files = ['data1.txt','data2.txt','data3.txt','data4.txt']","metadata":{"id":"m_KHDAoxSLLl","execution":{"iopub.status.busy":"2022-03-11T17:48:05.092283Z","iopub.execute_input":"2022-03-11T17:48:05.093076Z","iopub.status.idle":"2022-03-11T17:48:05.099056Z","shell.execute_reply.started":"2022-03-11T17:48:05.093043Z","shell.execute_reply":"2022-03-11T17:48:05.098451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer4 = CountVectorizer(input=doc_names)\nX4 = vectorizer4.fit_transform(extracted_corpus)\nvectorizer4.get_feature_names_out()","metadata":{"id":"e3a_Pb2GNy7l","outputId":"182c3bc4-5451-4f18-f3e8-ca5728e18f53","execution":{"iopub.status.busy":"2022-03-11T17:48:05.10003Z","iopub.execute_input":"2022-03-11T17:48:05.100592Z","iopub.status.idle":"2022-03-11T17:48:05.115719Z","shell.execute_reply.started":"2022-03-11T17:48:05.100557Z","shell.execute_reply":"2022-03-11T17:48:05.114535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X4.toarray())","metadata":{"id":"PVWN_-PMSWFC","outputId":"687992a3-fffa-405e-ce3e-4e83e261efb8","execution":{"iopub.status.busy":"2022-03-11T17:48:05.117181Z","iopub.execute_input":"2022-03-11T17:48:05.118006Z","iopub.status.idle":"2022-03-11T17:48:05.124839Z","shell.execute_reply.started":"2022-03-11T17:48:05.117961Z","shell.execute_reply":"2022-03-11T17:48:05.123929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X4.toarray())","metadata":{"id":"L_TW4t30N54K","outputId":"e47f5002-b691-4729-ebe9-284e6dc657cc","execution":{"iopub.status.busy":"2022-03-11T17:48:05.126262Z","iopub.execute_input":"2022-03-11T17:48:05.126761Z","iopub.status.idle":"2022-03-11T17:48:05.139244Z","shell.execute_reply.started":"2022-03-11T17:48:05.126714Z","shell.execute_reply":"2022-03-11T17:48:05.138169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- ### with `TfidfVectorizer` : ","metadata":{"id":"pc2iqJVuXjJO"}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(input=doc_names)\nX5 = vectorizer.fit_transform(extracted_corpus)\nvectorizer.get_feature_names_out()","metadata":{"id":"Md4C26LPXkqX","outputId":"a3319905-991b-4425-b0f2-bee23c0dd4ed","execution":{"iopub.status.busy":"2022-03-11T17:48:05.141184Z","iopub.execute_input":"2022-03-11T17:48:05.14183Z","iopub.status.idle":"2022-03-11T17:48:05.153902Z","shell.execute_reply.started":"2022-03-11T17:48:05.141786Z","shell.execute_reply":"2022-03-11T17:48:05.153176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X5.shape)\nprint(vectorizer.get_feature_names_out())\nprint(X5.toarray())","metadata":{"id":"0dDwU6lnX9Qr","outputId":"1dafd45c-6ce7-40ed-cad3-cc2eadb82929","execution":{"iopub.status.busy":"2022-03-11T17:48:05.155137Z","iopub.execute_input":"2022-03-11T17:48:05.155361Z","iopub.status.idle":"2022-03-11T17:48:05.164224Z","shell.execute_reply.started":"2022-03-11T17:48:05.155335Z","shell.execute_reply":"2022-03-11T17:48:05.163518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Take part in competition \n> [Refer this notebook](https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments/notebook)","metadata":{"id":"GhJxxlYNOOso"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import  matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nimport pickle\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df  =  pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntrain_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\ntest_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_review_text(text):\n    text = text.lower()  # covert the text to lowercase\n    text = re.sub('<.*?>','',text).strip() # remove html chars\n    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n    return text.strip()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.comment_text = train_df.comment_text.astype(str)\ntrain_df.comment_text = train_df.comment_text.apply(clean_review_text)\ntrain_df.comment_text.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem.snowball import SnowballStemmer\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\n\nsnow_stemmer = SnowballStemmer(language='english')\n\nstopwords = nlp.Defaults.stop_words\ndef apply_stemmer(text):\n    words = text.split()\n    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n    return ' '.join(sent)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.comment_text = train_df.comment_text.apply(apply_stemmer)\ntrain_df.comment_text.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.comment_text\ny = train_df.drop(['id','comment_text'],axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test =  train_test_split(X,y,test_size = 0.2,random_state = 45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    strip_accents='unicode',     \n    analyzer='word',            \n    token_pattern=r'\\w{1,}',    \n    ngram_range=(1, 3),         \n    stop_words='english',\n    sublinear_tf=True)\n\nword_vectorizer.fit(x_train)    \ntrain_word_features = word_vectorizer.transform(x_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_transformed = word_vectorizer.transform(x_train)\nX_test_transformed = word_vectorizer.transform(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.linear_model import LogisticRegression\nseed=100\n\nlog_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=seed)\n\n# fit model\nclassifier_ovr_log = OneVsRestClassifier(log_reg)\nclassifier_ovr_log.fit(X_train_transformed, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\ny_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_predictions(df,classifier):\n    df.comment_text = df.comment_text.apply(clean_review_text)\n    df.comment_text = df.comment_text.apply(apply_stemmer)\n    X_test = df.comment_text\n    X_test_transformed = word_vectorizer.transform(X_test)\n    y_test_pred = classifier.predict_proba(X_test_transformed)\n    return y_test_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=make_test_predictions(test_df,classifier_ovr_log)\ny_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_df = pd.DataFrame(y_pred,columns=y.columns)\ny_pred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.concat([test_df.id, y_pred_df], axis=1)\nsubmission_df.to_csv('submission.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]}]}