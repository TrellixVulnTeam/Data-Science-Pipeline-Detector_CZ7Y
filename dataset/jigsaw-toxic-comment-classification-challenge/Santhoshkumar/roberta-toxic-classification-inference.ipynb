{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom torch.nn.modules.loss import _WeightedLoss\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nimport gc\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport random\nimport warnings \nwarnings.filterwarnings('ignore')\nfrom transformers import RobertaModel, RobertaTokenizer\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-22T01:17:44.416891Z","iopub.execute_input":"2022-03-22T01:17:44.417596Z","iopub.status.idle":"2022-03-22T01:17:51.968931Z","shell.execute_reply.started":"2022-03-22T01:17:44.417483Z","shell.execute_reply":"2022-03-22T01:17:51.968202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(seed=2019)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:17:53.615345Z","iopub.execute_input":"2022-03-22T01:17:53.616121Z","iopub.status.idle":"2022-03-22T01:17:53.624782Z","shell.execute_reply.started":"2022-03-22T01:17:53.616072Z","shell.execute_reply":"2022-03-22T01:17:53.623918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/jigsaw-toxic-comment-classification-challenge'\ntest = pd.read_csv(os.path.join(PATH, 'test.csv.zip'))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:17:56.803448Z","iopub.execute_input":"2022-03-22T01:17:56.803996Z","iopub.status.idle":"2022-03-22T01:17:58.084481Z","shell.execute_reply.started":"2022-03-22T01:17:56.803943Z","shell.execute_reply":"2022-03-22T01:17:58.083787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv.zip'))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:00.123346Z","iopub.execute_input":"2022-03-22T01:18:00.123879Z","iopub.status.idle":"2022-03-22T01:18:00.335572Z","shell.execute_reply.started":"2022-03-22T01:18:00.123839Z","shell.execute_reply":"2022-03-22T01:18:00.334792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:03.443198Z","iopub.execute_input":"2022-03-22T01:18:03.443673Z","iopub.status.idle":"2022-03-22T01:18:03.450414Z","shell.execute_reply.started":"2022-03-22T01:18:03.443637Z","shell.execute_reply":"2022-03-22T01:18:03.449726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    debug=False\n    apex=False\n    print_freq=100\n    num_workers=4\n    model_name='roberta-base' #'swin_large_patch4_window7_224'\n    size=224\n    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    epochs=5\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    T_max=10 # CosineAnnealingLR\n    opt_wd_non_norm_bias = 0.01\n    opt_wd_norm_bias = 0 # same as Adam in Fastai\n    opt_beta1 = 0.9\n    opt_beta2 = 0.99 # same as Adam in Fastai\n    opt_eps = 1e-5 # same as Adam in Fastai\n    T_0=10 # CosineAnnealingWarmRestarts\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=32\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=2019\n    target_size=1\n    n_fold=5","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:15.255352Z","iopub.execute_input":"2022-03-22T01:18:15.255607Z","iopub.status.idle":"2022-03-22T01:18:15.262442Z","shell.execute_reply.started":"2022-03-22T01:18:15.255579Z","shell.execute_reply":"2022-03-22T01:18:15.261662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\ntokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:20.2235Z","iopub.execute_input":"2022-03-22T01:18:20.223815Z","iopub.status.idle":"2022-03-22T01:18:20.422751Z","shell.execute_reply.started":"2022-03-22T01:18:20.223781Z","shell.execute_reply":"2022-03-22T01:18:20.422047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_fn(model, dataloader):\n    model.eval()\n    predictions = [] \n    with torch.no_grad():\n        for data in dataloader:\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            \n            output = model(ids, mask, token_type_ids)\n            predictions.append(output.cpu().detach().numpy())\n            \n    return np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:22.824333Z","iopub.execute_input":"2022-03-22T01:18:22.824591Z","iopub.status.idle":"2022-03-22T01:18:22.831404Z","shell.execute_reply.started":"2022-03-22T01:18:22.824563Z","shell.execute_reply":"2022-03-22T01:18:22.830288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentimentData(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe.comment_text.values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:25.336431Z","iopub.execute_input":"2022-03-22T01:18:25.336684Z","iopub.status.idle":"2022-03-22T01:18:25.347654Z","shell.execute_reply.started":"2022-03-22T01:18:25.336656Z","shell.execute_reply":"2022-03-22T01:18:25.34675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaClass(torch.nn.Module):\n    def __init__(self):\n        super(RobertaClass, self).__init__()\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained('../input/roberta-base')\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n                \"num_labels\": 6,\n            }\n        )\n        self.transformer = AutoModel.from_pretrained('../input/roberta-base', config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, 6)\n        \n    def forward(self, input_ids, attention_mask, token_type_ids):\n        transformer_out = self.transformer(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        sequence_output = transformer_out[0]\n        sequence_output = self.dropout(torch.mean(sequence_output, 1))\n        logits1 = self.output(self.dropout1(sequence_output))\n        logits2 = self.output(self.dropout2(sequence_output))\n        logits3 = self.output(self.dropout3(sequence_output))\n        logits4 = self.output(self.dropout4(sequence_output))\n        logits5 = self.output(self.dropout5(sequence_output))\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:40.537475Z","iopub.execute_input":"2022-03-22T01:18:40.538132Z","iopub.status.idle":"2022-03-22T01:18:40.550276Z","shell.execute_reply.started":"2022-03-22T01:18:40.538091Z","shell.execute_reply":"2022-03-22T01:18:40.549497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_fold(df, model, fold, MODEL_PATH):    \n    \n    test_dataset = SentimentData(df, tokenizer, MAX_LEN) \n\n    test_loader = DataLoader(test_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    model.load_state_dict(torch.load(f\"{MODEL_PATH}/toxicx_model_{fold}.pth\", map_location=device), strict=False)\n    model.to(device)\n    \n    predictions = np.zeros((df.shape[0], 6))\n    predictions = inference_fn(model, test_loader)\n    \n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:43.216402Z","iopub.execute_input":"2022-03-22T01:18:43.216869Z","iopub.status.idle":"2022-03-22T01:18:43.222911Z","shell.execute_reply.started":"2022-03-22T01:18:43.216832Z","shell.execute_reply":"2022-03-22T01:18:43.222046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_k_fold(NFOLDS, df, model, MODEL_PATH):\n    predictions = np.zeros((df.shape[0], 6))\n    \n    for fold in range(NFOLDS):\n        pred_ = run_fold(df, model, fold, MODEL_PATH)\n        \n        predictions += pred_/ NFOLDS\n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:51.204584Z","iopub.execute_input":"2022-03-22T01:18:51.2049Z","iopub.status.idle":"2022-03-22T01:18:51.211168Z","shell.execute_reply.started":"2022-03-22T01:18:51.204865Z","shell.execute_reply":"2022-03-22T01:18:51.21043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def TTA_Wrapper(df, tta, model, NFOLDS, MODEL_PATH):\n    predictions = np.zeros((df.shape[0], 6))\n    for tta_id in range(tta):\n        predictions_ = run_k_fold(NFOLDS, df,  model, MODEL_PATH)\n        predictions += predictions_/ tta\n        print(f'TTA {tta_id}')\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:55.896006Z","iopub.execute_input":"2022-03-22T01:18:55.896568Z","iopub.status.idle":"2022-03-22T01:18:55.904679Z","shell.execute_reply.started":"2022-03-22T01:18:55.89653Z","shell.execute_reply":"2022-03-22T01:18:55.903902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ENSEMBLE = ['../input/roberta-toxic-classification/', ]","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:57.675253Z","iopub.execute_input":"2022-03-22T01:18:57.675756Z","iopub.status.idle":"2022-03-22T01:18:57.679069Z","shell.execute_reply.started":"2022-03-22T01:18:57.675716Z","shell.execute_reply":"2022-03-22T01:18:57.678389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    model = RobertaClass()\n    predicted = TTA_Wrapper(test, 1 , model, 5, ENSEMBLE[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-22T01:18:59.811174Z","iopub.execute_input":"2022-03-22T01:18:59.811943Z","iopub.status.idle":"2022-03-22T01:19:48.045167Z","shell.execute_reply.started":"2022-03-22T01:18:59.811897Z","shell.execute_reply":"2022-03-22T01:19:48.044034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']] = predicted","metadata":{"execution":{"iopub.status.busy":"2022-02-14T14:35:49.113661Z","iopub.execute_input":"2022-02-14T14:35:49.114196Z","iopub.status.idle":"2022-02-14T14:35:49.123671Z","shell.execute_reply.started":"2022-02-14T14:35:49.114157Z","shell.execute_reply":"2022-02-14T14:35:49.122868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}