{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip3 install -q -U keras-tuner","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import kerastuner as kt\n\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nstop_words = set(stopwords.words('english')) \n  \nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 2_000\nembedding_dim = 100\nmax_length = 1403","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\nprint(train_df.shape)\ntrain_df[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\")\nprint(test_df.shape)\ntest_df[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = np.array(['toxic','severe_toxic',\n                        'obscene', 'threat',\n                        'insult', 'identity_hate'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove stop words\ndef remove_stopwords(sent):\n    word_tokens = word_tokenize(sent) \n    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n    return \" \".join(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.comment_text=train_df.comment_text.apply(remove_stopwords)\n# test_df.comment_text=test_df.comment_text.apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_labels(row):\n    label_idx = np.where(row)[0]\n    # print(label_idx, len(label_idx), row.index)\n    \n    if len(label_idx)>0:\n        return \" \".join(row.index[label_idx].tolist())\n    else:\n        return \"none\"\n\ndef onehot_labels(row):\n        return row.astype(\"int\").values.reshape(1, -1)\n    \n# (train_df[target_cols]>0)[:12].apply(concat_labels,1)\n(train_df[target_cols]>0)[:12].apply(onehot_labels,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_x, idx_y = np.where(train_df[target_cols]>0)\nlen(idx_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = train_df[\"comment_text\"].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentences = test_df[\"comment_text\"].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels = (train_df[target_cols]>0).apply(concat_labels,1)\nlabels = (train_df[target_cols]>0).apply(onehot_labels,1)\nlabels_npy = np.concatenate(labels.values, axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenize","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Sentence","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(oov_token = \"<OOV>\", num_words=vocab_size)\ntokenizer.fit_on_texts(sentences)\nword_index = tokenizer.word_index\nprint(len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(sentences) # Your Code Here\npadded = pad_sequences(sequences, padding = 'post')  # Your Code here\nprint(padded[0])\nprint(padded.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(test_sentences) # Your Code Here\ntest_padded = pad_sequences(test_sequences, padding = 'post', maxlen=max_length)  # Your Code here\nprint(test_padded[0])\nprint(test_padded.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(padded[0]))\nprint(len(test_padded[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# v1 labels\n# label_tokenizer = Tokenizer()\n# label_tokenizer.fit_on_texts(labels)\n# label_word_index = label_tokenizer.word_index\n# label_seq = label_tokenizer.texts_to_sequences(labels)\n# print(label_seq[:5])\n# print(label_word_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel = tf.keras.Sequential([\n# YOUR CODE HERE\n    tf.keras.layers.Input(max_length),\n    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),    \n    tf.keras.layers.Conv1D(64, 3, padding='valid', strides=1, activation='relu'),\n    tf.keras.layers.Conv1D(64, 3, padding='same', strides=1, activation='relu'),\n    tf.keras.layers.MaxPooling1D(2),\n    \n    tf.keras.layers.Conv1D(64, 3, padding='valid', strides=1, activation='relu'),\n    tf.keras.layers.Conv1D(64, 3, padding='same', strides=1, activation='relu'),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    \n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Flatten(), \n    tf.keras.layers.Dense(32, activation = 'relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation = 'sigmoid')\n    \n])\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['mae', tf.keras.metrics.AUC()])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1291)\nX_train, X_test, y_train, y_test = train_test_split(padded, labels_npy, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=5, mode=\"min\", restore_best_weights=True, verbose=1),\n    tf.keras.callbacks.ModelCheckpoint(filepath=\"best_model-{epoch:02d}-{val_auc:.4f}.hdf5\", save_best_only=True, verbose=1, monitor=\"val_auc\")\n] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=15, batch_size=120, validation_split=0.2, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evel_loss, evel_mae, evel_auc = model.evaluate(x=X_test, y=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(history):\n        # plt.plot(history.epoch, history.history[\"auc\"], \".:\")\n        # plt.plot(history.epoch, history.history[\"val_auc\"], \".:\")\n\n        plt.plot(history.epoch, history.history[\"loss\"], \".:\", label=\"loss\")\n        plt.plot(history.epoch, history.history[\"val_loss\"], \".:\", label=\"val_loss\")\n        plt.legend()\n\nplot_learning_curve(history)\nval_auc = history.history[\"val_auc\"][-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_auc, evel_auc, min(val_auc,evel_auc)-abs(val_auc - evel_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# prediction for submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict(test_padded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# (test_pred>0.5).astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.concat([test_df[\"id\"], pd.DataFrame(test_pred, columns=target_cols)], 1).to_csv(\"sub.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# !kaggle competitions submit -f sub.csv -m \"\" jigsaw-toxic-comment-classification-challenge","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# !kaggle competitions submissions jigsaw-toxic-comment-classification-challenge","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"```\npublicScore  privateScore\n0.93708      0.93811\n```","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}