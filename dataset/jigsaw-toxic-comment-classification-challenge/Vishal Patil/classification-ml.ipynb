{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip '/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\n!unzip '/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip'\n!unzip '/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip'\n!unzip '/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip'","execution_count":null,"outputs":[]},{"metadata":{"id":"csAQgv3nuHh_","outputId":"df643df4-c377-414d-ddc5-b9266a9f6634","trusted":false},"cell_type":"code","source":"### Import Libraries \nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nimport seaborn as sns\nimport pandas as pd\nfrom scipy.sparse import hstack\nfrom nltk.stem import PorterStemmer\nimport string\n!pip install scikit-multilearn             ### For installing scikit-multilearn\n#import skmultilearn\nfrom skmultilearn.problem_transform import LabelPowerset        # if error in this line this use import skmultilearn first\n","execution_count":null,"outputs":[]},{"metadata":{"id":"EuLgSFPuuHiC","trusted":false},"cell_type":"code","source":"### Reading csv data files using pandas dataframe \n\ntrain = pd.read_csv(\"./train.csv\", encoding = \"ISO-8859-1\")\ntest = pd.read_csv(\"./test.csv\", encoding = \"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{"id":"mMdmNDP9uHiD","outputId":"ea14723b-ddda-494e-e582-d424fbb9f856","trusted":false},"cell_type":"code","source":"### Checking nulls in both the datasets\n\nprint(\"Nulls in training dataset\",train.isnull().sum())\nprint(\"\\nNulls in test dataset\",test.isnull().sum())\n\n### There are no missing values in both the datasets","execution_count":null,"outputs":[]},{"metadata":{"id":"v9nwXJWauHiE","trusted":false},"cell_type":"code","source":"### Before cleaning the dataset I would like to perform EDA(Exploratory data analysis) by performing data visualization to understand\n### the distribution of different classes. I will be performing EDA on training dataset\n\ncategorywise_data = train.drop(['id', 'comment_text'], axis=1)     ### Removed unnecessary columns - id and comment_text\ncounts_category = []                                               ### A list that contains tuple which consists of class label and number of comments for that particular class \ncategories = list(categorywise_data.columns.values)\nfor i in categories:\n    counts_category.append((i, categorywise_data[i].sum()))\n    \ndataframe = pd.DataFrame(counts_category, columns=['Labels', 'number_of_comments'])   ### Dataframe made up of category and total number of comments","execution_count":null,"outputs":[]},{"metadata":{"id":"FGkoBzbpuHiF","outputId":"2931cc53-d55f-4f14-ab5b-0aca515ecd86","trusted":false},"cell_type":"code","source":"### Visualization 1\n\n### Bar graph of total number of comments per label \n### This visualization is helpful in identifying the total number of comments per label\ndataframe.plot(x='Labels', y='number_of_comments', kind='bar',figsize=(8,8))\nplt.title(\"Number of comments per category\")\nplt.ylabel('No. of Occurrences', fontsize=12)\nplt.xlabel('Labels', fontsize=12)\n\n### From the below graph we can observe that most of the comments having toxic label. \n### Threat label is having lowest no. of comments","execution_count":null,"outputs":[]},{"metadata":{"id":"ar5XKZy9uHiG","outputId":"582fb722-7420-4ba3-d7cb-08dcd2e21db5","trusted":false},"cell_type":"code","source":"### Visualization 2\n\n### Bar graph of Total No. of labels in a sentence against Total no. of sentences\n### This visualization is helpful in identifying whether a sentence belongs to only one category or many categories\n\ndataframe = pd.DataFrame(pd.DataFrame(train[train.columns[2:]].sum(axis=1)).reset_index()[0].value_counts())\ndataframe[\"Total no. of sentences\"]=dataframe[0]\ndataframe[\"Total No. of labels in a sentence\"]=dataframe.index\ndataframe.plot(x=\"Total No. of labels in a sentence\", y=\"Total no. of sentences\", kind='bar',figsize=(8,8))\nplt.title(\"No of comments based on the count of labels\")\nplt.ylabel('Total no. of sentences', fontsize=12)\nplt.xlabel('Total No. of labels in a sentence', fontsize=12)\ndataframe\n\n### From the below graph we can see that 1,43,346 out of 1,59,571 sentences does not have any labels(class 0).\n### we can observe that a single sentence can have multiple labels. It can be a toxic sentence or it can be a toxic as well as obscene senetence.","execution_count":null,"outputs":[]},{"metadata":{"id":"XNxo89FOuHiG","outputId":"bbd6e15c-b68d-432c-f7ce-205ecf42820d","trusted":false},"cell_type":"code","source":"### Visualization 3\n\n### Graph of individual class against the total no. of labelled and unlabelled sentences for the same class\n\nfig, plots = plt.subplots(2,3,figsize=(15,12))\nplot1, plot2, plot3, plot4, plot5, plot6 = plots.flatten()\nsns.countplot(train['obscene'], ax = plot1)\nsns.countplot(train['threat'], ax = plot2)\nsns.countplot(train['insult'], ax = plot3)\nsns.countplot(train['identity_hate'], ax = plot4)\nsns.countplot(train['toxic'], ax = plot5)\nsns.countplot(train['severe_toxic'], ax = plot6)\n\n### From this graph it can be concluded that every class(category) is having higher no. of unlabelled sentences(0) as compared\n### to labelled sentences(1)","execution_count":null,"outputs":[]},{"metadata":{"id":"ywP-k9QTuHiH","outputId":"231d6e95-5ca4-4896-f001-5da28794ec50","trusted":false},"cell_type":"code","source":"### Visualization 4\n\n### Correlation between different variables\n### Correlation helps us finding relationship/dependency between different variables. \n\ntarget_data = train.drop(['id', 'comment_text'], axis=1)\ncorrMatrix = target_data.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"B7aYlGl8yo6T","trusted":false},"cell_type":"code","source":"## I have used stemming NLP operation below. It is taking time. Hence you need to increase the system recursionlimit. Otherwise it will give you an error.\nimport sys\nsys.setrecursionlimit(10**6) ","execution_count":null,"outputs":[]},{"metadata":{"id":"6hy5Yht1uHiI","trusted":false},"cell_type":"code","source":"### Data cleaning/Preparation \n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub('\\@\\w+|\\#', ' ', text)                                                 ### removing non-word characters\n    text = re.sub('[^A-Za-z\\' ]+', '',text)                                              ### removing all non-alphanumeric values(Except single quotes)\n    text = re.sub('\\s+', ' ', text)\n    text = text.strip(' ')\n    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)                                  ### Remove urls\n    text = text.translate(str.maketrans('', '', string.punctuation))                     ### remove punctuations\n    tokenized_words = [word for word in text.split() if word not in (stop_words)]         ### Stopwords removal\n    ps = PorterStemmer()\n    stemmed_words = [ps.stem(w) for w in tokenized_words]                                ### Stemming the words\n    \n    return \" \".join(stemmed_words)\n\n\ntrain[\"comment_text\"] = train[\"comment_text\"].apply(clean_text)\ntest[\"comment_text\"] = test[\"comment_text\"].apply(clean_text)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"H7raEsFquHiJ","trusted":false},"cell_type":"code","source":"### Splitting up the labels and data\n### Training dataset is splitted into 2 parts. 1st part includes the training data(train_data) and 2nd part includes labels(train_label) \n### associated with the training data\n### Test dataset is having only 1 part i.e. test data which is used to predict the labels. \n\ntrain_data = train[\"comment_text\"]\ntest_data = test[\"comment_text\"]\ntrain_label=train[['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"fU9-lfeE1qL0","trusted":false},"cell_type":"code","source":"\nword_vec = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    ngram_range=(1, 2),\n    max_features=20000)\ntrain_word_features = word_vec.fit_transform(train_data)\ntest_word_features =  word_vec.fit_transform(test_data)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"SRt7AxX33Rjb","trusted":false},"cell_type":"code","source":"\nchar_vec = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(2, 6),\n    max_features=50000)\ntrain_char_features = char_vec.fit_transform(train_data)\ntest_char_features = char_vec.fit_transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{"id":"Nrbz-QuC5RIp","trusted":false},"cell_type":"code","source":"### Stacking the word and character embeddings together\n\ntrain_final_features = hstack([train_char_features, train_word_features])\ntest_final_features = hstack([test_char_features, test_word_features])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"VQf2iZhpqXnS","outputId":"8916eedb-ff86-4b97-b066-862f7fb777bc","trusted":false},"cell_type":"code","source":"### OneVsRest method using logistic regression - This is the 1st method I tried. \n\nLogReg_pipeline = Pipeline([('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])\ncategories = list(train_label.columns.values)\nx_train, x_test, y_train, y_test = train_test_split(train_final_features, train_label, shuffle = True, random_state = 123)\n\nfor category in categories:\n    print('**Processing {} comments...**'.format(category))\n    \n    # Training logistic regression model on train data\n    LogReg_pipeline.fit(x_train, y_train[category])\n    \n    # calculating test accuracy\n    prediction = LogReg_pipeline.predict(x_test)\n    print('Test accuracy is {}'.format(accuracy_score(y_test[category], prediction)))\n    print(\"\\n\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}