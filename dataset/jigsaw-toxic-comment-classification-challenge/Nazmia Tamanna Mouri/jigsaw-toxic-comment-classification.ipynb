{"cells":[{"metadata":{"id":"ICquijPRmdkw"},"cell_type":"markdown","source":"# **Importing libraries**","execution_count":null},{"metadata":{"id":"oWiUpqlaDX3i","outputId":"b2104b7e-c635-480d-ba19-0c9981f9c2f1","trusted":true},"cell_type":"code","source":"\n#!pip install textblob\nfrom textblob import TextBlob\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport nltk\n\n#nltk.download('wordnet')\n\n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords \nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet as wn\nfrom nltk import word_tokenize, pos_tag\nfrom collections import defaultdict\n\n#!pip install langdetect\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt \nimport pickle\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"iRMhiG0rmrNl"},"cell_type":"markdown","source":"# **Loading csv**","execution_count":null},{"metadata":{"id":"l6Bh7rMfDYIG","trusted":true},"cell_type":"code","source":"train_data_path='/kaggle/input/jigsaw-toxic-comment/train.csv'\n\n\ntrain = pd.read_csv(train_data_path,encoding='utf-8')\ntest = pd.read_csv('/kaggle/input/jigsaw-toxic-comment/test.csv',encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Histograms for each numerical columns","execution_count":null},{"metadata":{"id":"DtpNhWjTFozV","outputId":"8b3c758c-3a91-41e9-f258-84fa1bf25d3e","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain.hist(bins=50,figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"L5C3sBarEK8h","outputId":"dfc992f1-7aee-4f4f-a70c-64fc04b7a14f","trusted":true},"cell_type":"code","source":"train_data=train\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dropping Id Column","execution_count":null},{"metadata":{"id":"eH-Ojv1rENUR","outputId":"d5222b8e-6745-436e-e05d-d1107e230231","trusted":true},"cell_type":"code","source":"train_data.drop(['id'],axis=1,inplace=True)\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"id":"bsXNLB6irHCK","trusted":true},"cell_type":"code","source":"\ntest_data=test\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-iYvSYpbu1LU","outputId":"9c99376f-2244-4307-9a82-5fe5ad03e55e","trusted":true},"cell_type":"code","source":"print(test_data)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"AZD3brrzmwuU"},"cell_type":"markdown","source":"# **Cleaning data(removing punctuation, url**","execution_count":null},{"metadata":{"id":"_Z_JsN8eoVQ4","trusted":true},"cell_type":"code","source":"def clean_data(all_comment):\n  clean_comment=[]\n  for input_text in all_comment:\n    #removing URL\n    input_text=re.sub(r'http\\S+','',input_text)\n    #removing digits\n    input_text=re.sub(r'\\d*','',input_text)\n    #removing punctuation\n    punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~\\,.'\n    input_text=''.join(ch for ch in input_text if ch not in set(punctuation))\n    #converting in lower case\n    input_text=input_text.lower()\n    # removing whitespace, newline'''\n    input_text=re.sub(r'\\n',' ',input_text)\n    input_text=re.sub(r'\\t',' ',input_text)\n    input_text=' '.join(input_text.split())\n    clean_comment.append(input_text)\n  return clean_comment","execution_count":null,"outputs":[]},{"metadata":{"id":"_kOwFLezqD-i"},"cell_type":"markdown","source":"# **spell checkr**","execution_count":null},{"metadata":{"id":"NI7XnrArbSwH","trusted":true},"cell_type":"code","source":"\ndef spell_checker(input_text):\n    for x in input_text:\n        text=TextBlob(x)\n        txt=pd.Series(text.correct())\n        input_text.append(txt)\n    return input_text","execution_count":null,"outputs":[]},{"metadata":{"id":"PXoSrkEWagWN","trusted":true},"cell_type":"code","source":"def contradiction(all_comment):\n  comment=[]\n  for all_str in all_comment:\n        all_str = re.sub(r\"\\*'r\", ' are ', all_str)\n        all_str = re.sub(r\"\\*'m \", ' am ', all_str)\n        all_str = re.sub(r' u ', ' you ', all_str)\n        all_str = re.sub(r\" *'s \", ' is ', all_str)\n        all_str = re.sub(r' b ', ' be ', all_str)\n        all_str = re.sub(r' hv ', ' have ', all_str)\n        all_str = re.sub(r' bt ', ' but ', all_str)\n        all_str = re.sub(r' ur ', ' your ', all_str)\n        all_str = re.sub(r' n ', ' and ', all_str)\n        all_str = re.sub(r\" *n't \" , ' not ', all_str)\n        all_str = re.sub(r' bro ', ' brother ', all_str)\n        all_str = re.sub(r' it(z)+ ', ' it\\'s ', all_str)\n        all_str = re.sub(r' btw ', ' by the way ', all_str)\n        comment.append(all_str)\n  return comment\n","execution_count":null,"outputs":[]},{"metadata":{"id":"PcFQ6bEdnpAr"},"cell_type":"markdown","source":"# **removing stop words and lemmetizing**","execution_count":null},{"metadata":{"id":"-CpezgFZEgIN","trusted":true},"cell_type":"code","source":"\n\nstop_words = set(stopwords.words('english'))\nlem = WordNetLemmatizer() \n\n\ndef _remove_noise(input_text):\n    print(input_text)\n    comment=[]\n    word=[]\n    stop_free_text=[]\n    \n    for i in range(len(input_text)):\n            word_tokens = word_tokenize(input_text[i])\n            #print('list and tokens\\n',input_text[i],'\\n',word_tokens)\n            for w in word_tokens: \n              if w not in stop_words:\n                    #print('not stop word\\n',w)\n                    lemma=lem.lemmatize(w, pos=\"v\")\n                    word.append(lemma)\n                    #print('lemmitized word:\\n',word)\n                    sentence=' '.join(word)\n                    #print('sentence\\n',sentence)\n            comment.append(sentence)\n            word.clear()\n           \n    \n    return comment \n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"B4WnAwB6loXe","trusted":true},"cell_type":"code","source":"def detect_language(all_comment):\n    \n    eng_comm=[]\n    from langdetect import detect\n    for x in all_comment:\n      try:\n       check=detect(x)\n       if check=='en':\n         eng_comm.append(x)\n       else:\n         eng_comm.append('')\n      except:\n        eng_comm.append('')\n         \n    return eng_comm\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Train data","execution_count":null},{"metadata":{"id":"XTnxXHIiilG1","outputId":"44135925-e9d8-4ded-f90e-006208e3b809","trusted":true},"cell_type":"code","source":"\ntrain_data['comment_text']=detect_language(train_data['comment_text'])\nprint(train_data['comment_text'])\ntrain_data['comment_text'].replace('', np.nan, inplace=True)\ntrain_data.dropna(subset=['comment_text'], inplace=True)\ntrain_data.reset_index(inplace=True)\nprint('remove all other language\\ns',train_data)\ntrain_data['comment_text']=contradiction(train_data['comment_text'])\nprint('Contradiction\\n',train_data['comment_text'])\ntrain_data['comment_text']=clean_data(train_data['comment_text'])\nprint('removed punctuation\\n',train_data['comment_text'])\ntrain_data['comment_text']=spell_checker(train_data['comment_text'])\nprint('Corrected spelling\\n',train_data['comment_text'])\ntrain_data['comment_text']=_remove_noise(train_data['comment_text'])\nprint('removed stop words\\n',train_data['comment_text'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Test data","execution_count":null},{"metadata":{"id":"Tkbg01iKjN_d","outputId":"d897703e-6afd-4e0b-f660-f69b5dce6520","trusted":true},"cell_type":"code","source":"\ntest_data['comment_text']=detect_language(test_data['comment_text'])\nprint(test_data['comment_text'])\ntest_data['comment_text'].replace('', np.nan, inplace=True)\ntest_data.dropna(subset=['comment_text'], inplace=True)\ntest_data.reset_index(inplace=True)\nprint('remove all other language\\ns',test_data)\ntest_data['comment_text']=contradiction(test_data['comment_text'])\nprint('Contradiction\\n',test_data['comment_text'])\ntest_data['comment_text']=clean_data(test_data['comment_text'])\nprint('removed punctuation\\n',test_data['comment_text'])\ntest_data['comment_text']=spell_checker(test_data['comment_text'])\nprint('Corrected spelling\\n',test_data['comment_text'])\ntest_data['comment_text']=_remove_noise(test_data['comment_text'])\nprint('removed stop words\\n',test_data['comment_text'])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Separating the train labels","execution_count":null},{"metadata":{"id":"oEdftoGg5F0T","trusted":true},"cell_type":"code","source":"train_label=train_data.drop(['comment_text','index',],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Counting values of each class","execution_count":null},{"metadata":{"id":"vCjdf_nMkT1S","outputId":"a31ad4c9-abad-464b-ab75-e3cb8b444e1f","trusted":true},"cell_type":"code","source":"print(train_data['toxic'].value_counts())\nprint(train_data['severe_toxic'].value_counts())\nprint(train_data['obscene'].value_counts())\nprint(train_data['threat'].value_counts())\nprint(train_data['insult'].value_counts())\nprint(train_data['identity_hate'].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ZGB_9QTBCM5C"},"cell_type":"markdown","source":"# **Resampling**\n\nAs from the above it can be seen that the dataset is so much imbalanced to make the balance I did oversampling here (increasing the minority class by creating duplicates).\nI did sampling according to severe_toxic label.","execution_count":null},{"metadata":{"id":"LMQgVAbiONcS","outputId":"11008524-c280-4bf4-fdf3-eebd607d15ae","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\n#split data into test and training sets\nX_train, X_test, y_train, y_test = train_test_split( train_data['comment_text'], train_label, test_size=0.20, random_state=42)\n#combine them back for resampling\ntrain_info = pd.concat([X_train, y_train], axis=1)\n# separate minority and majority classes\nnegative = train_info[train_info.threat==0]\npositive = train_info[train_info.threat==1]\n# upsample minority\npos_upsampled = resample(positive,replace=True, # sample with replacement\n                         n_samples=len(negative), # match number in majority class\n                         random_state=27) # reproducible results\n# combine majority and upsampled minority\nupsampled = pd.concat([negative, pos_upsampled])\n\nnegative = upsampled[upsampled.severe_toxic==0]\npositive = upsampled[upsampled.severe_toxic==1]\n\npos_upsampled = resample(positive,replace=True, # sample with replacement\n                         n_samples=len(negative), # match number in majority class\n                         random_state=27) # reproducible results\nupsampled = pd.concat([negative, pos_upsampled])\n# check new class counts\nupsampled.threat.value_counts()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Counting the freaquancy of each class after resampling","execution_count":null},{"metadata":{"id":"wvVl_T3HIYeM","outputId":"af54cb83-68b4-43fb-9e0d-797952478733","trusted":true},"cell_type":"code","source":"print(upsampled['toxic'].value_counts())\nprint(upsampled['severe_toxic'].value_counts())\nprint(upsampled['obscene'].value_counts())\nprint(upsampled['threat'].value_counts())\nprint(upsampled['insult'].value_counts())\nprint(upsampled['identity_hate'].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ccY1FVM1iq_P","outputId":"626389e2-591d-4e5f-9b40-0a0764aff0e3","trusted":true},"cell_type":"code","source":"upsampled","execution_count":null,"outputs":[]},{"metadata":{"id":"sNUjrsVE73C6","outputId":"c48d9308-0ac5-4a7a-8c07-5e0616f89485","trusted":true},"cell_type":"code","source":"unsampled['identity_hate'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"f_hxh4ddh7Gv","outputId":"4d3d12b0-e7f4-463a-f3cc-bab64ce56304","trusted":true},"cell_type":"code","source":"upsampled['identity_hate'].value_counts()\ntest_comm","execution_count":null,"outputs":[]},{"metadata":{"id":"YhTGlrcn9NDM","outputId":"bd14864f-e17d-413c-8c07-30f237b8c711","trusted":true},"cell_type":"code","source":"\n#upsampled.reset_index(inplace=True)\ntrain_label=unsampled.drop(['comment_text'],axis=1)\ntrain_label\n","execution_count":null,"outputs":[]},{"metadata":{"id":"uexDq4gCCTCI"},"cell_type":"markdown","source":"# **Vectorizing using TfidfVectorizer**","execution_count":null},{"metadata":{"id":"bgUUGEQ87DAm","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer()\n\ntrain_comment=vectorizer.fit_transform(unsampled['comment_text'])\n\nvalid_comment=vectorizer.transform(X_test)\n\n#\n","execution_count":null,"outputs":[]},{"metadata":{"id":"z9Zd2lXdDKKk","trusted":true},"cell_type":"code","source":"test_comment=vectorizer.transform(test_data['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"id":"Slkc2DewED6z","outputId":"a7e47ba1-0047-4902-8c87-d5022b0acba3","trusted":true},"cell_type":"code","source":"test_comment.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_comment.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"EDmpKhwAmFgr"},"cell_type":"markdown","source":"# **Model**","execution_count":null},{"metadata":{"id":"Q7t4yupsUDti","trusted":true},"cell_type":"code","source":"def model(X_train,y_train,valid_comment,y_test,test_comment):\n    from sklearn.naive_bayes import MultinomialNB\n    clf = MultinomialNB()\n    clf.fit(X_train,y_train)\n    prediction1=clf.predict(valid_comment)\n    prediction2=clf.predict(test_comment)\n    accuracy=clf.score(valid_comment,y_test)\n    print('accuracy',accuracy)\n    \n    return prediction1,prediction2","execution_count":null,"outputs":[]},{"metadata":{"id":"eQvUNgtNrVv6"},"cell_type":"markdown","source":"# **Toxic model**","execution_count":null},{"metadata":{"id":"HE21kdTTpN8t","outputId":"07fa8841-4cc4-408b-c3bd-d9f37a8909e9","trusted":true},"cell_type":"code","source":"\ntoxic_prediction,toxic_test_pred=model(train_comment,train_label['toxic'],valid_comment,y_test['toxic'],test_comment)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"D4cqvsR-rYJh"},"cell_type":"markdown","source":"# **Severe toxic**","execution_count":null},{"metadata":{"id":"tpuEH6BpDsAv","outputId":"dc3aaaa8-e695-4f86-9e0d-c9928dc4ffd6","trusted":true},"cell_type":"code","source":"\nsevere_toxic_prediction,severe_toxic_test_pred=model(train_comment,train_label['severe_toxic'],valid_comment,y_test['severe_toxic'],test_comment)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"4LkjKnRGrbyK"},"cell_type":"markdown","source":"# **Obsence model**","execution_count":null},{"metadata":{"id":"8gfbYr_LDv5m","outputId":"e02f040a-47f2-4a3c-8556-99ecf851af78","trusted":true},"cell_type":"code","source":"\n\nobscene_prediction,obsence_test_pred=model(train_comment,train_label['obscene'],valid_comment,y_test['obscene'],test_comment)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"IxPkif_usdVx"},"cell_type":"markdown","source":"# **Threat**","execution_count":null},{"metadata":{"id":"kZxfdT--Dwni","outputId":"8f200345-6fb9-4431-ae4f-9f0ccb424aa8","trusted":true},"cell_type":"code","source":"\nthreat_prediction,threat_test_pred=model(train_comment,train_label['threat'],valid_comment,y_test['threat'],test_comment)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"N3HCI8THshIq"},"cell_type":"markdown","source":"# **Insult**","execution_count":null},{"metadata":{"id":"b7qrw043DxW_","outputId":"4d218bc3-1899-4765-ef2e-43c53e26bf13","trusted":true},"cell_type":"code","source":"\ninsult_prediction,insult_test_pred=model(train_comment,train_label['insult'],valid_comment,y_test['insult'],test_comment)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"WZHNBHlKsldT"},"cell_type":"markdown","source":"# **Identity hate**","execution_count":null},{"metadata":{"id":"WWfsorEmDx_-","outputId":"aaa293ef-173d-4071-bcc4-57082a52e2be","trusted":true},"cell_type":"code","source":"\nidentity_hate_prediction,identity_hate_test_pred=model(train_comment,train_label['identity_hate'],valid_comment,y_test['identity_hate'],test_comment)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test['severe_toxic'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"oT_79RQIv7Ey"},"cell_type":"markdown","source":"# **average auc roc score**","execution_count":null},{"metadata":{"id":"mnZw_JFIqfu0","outputId":"0ac7a20c-c98b-414c-881e-469152a3a501","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nauc=[]\nauc.append(roc_auc_score(y_test['toxic'], toxic_prediction))\nauc.append(roc_auc_score(y_test['severe_toxic'], severe_toxic_prediction))\nauc.append(roc_auc_score(y_test['obscene'], obscene_prediction))\nauc.append(roc_auc_score(y_test['threat'], threat_prediction))\nauc.append(roc_auc_score(y_test['insult'], insult_prediction))\nauc.append(roc_auc_score(y_test['identity_hate'], identity_hate_prediction))\n \nprint('average AUC', sum(auc)/len(auc))","execution_count":null,"outputs":[]},{"metadata":{"id":"4DP8zJrXmQ-I","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"64Hsaf-jwFgJ"},"cell_type":"markdown","source":"# **Final prediction**","execution_count":null},{"metadata":{"id":"7eLaWy384Viy","trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_data.id, 'toxic':toxic_test_pred,\t\n                      'severe_toxic':severe_toxic_test_pred,'obscene':obsence_test_pred,\n                       'threat':threat_test_pred,\t'insult':insult_test_pred,'identity_hate':identity_hate_test_pred})\noutput.to_csv('my_submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6m2lss0BnNcz","outputId":"1f269f48-752c-481e-f6aa-1fa253115378","trusted":true},"cell_type":"code","source":"final=pd.read_csv('my_submission.csv')\nfinal","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}