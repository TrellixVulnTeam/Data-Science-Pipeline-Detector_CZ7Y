{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Toxic Comments Classification\n\nThis notebook is a way for me to get into Sentiment Analysis and Naïve Bayes algorithm. \nFor this project  I used TF-IDF word embeddings and Naïve Bayes + Logistic Regression to create a model. \n\nMy work comes from the superbe notebook of Jeremy Howard (https://www.kaggle.com/code/jhoward/nb-svm-strong-linear-baseline/data).  \nHonours are for him only. \n\nHowever, if we consider the training dataset, it appears there are only few toxic comments compare to the size of the dataset (<10% for toxic, <1% for some). Therefore, training a model on this dataset can't be accurate.  \n\nFor this reason, if I look at the overall accuracy (one error in any classification makes the analyss wrong), I got a little bit more than 11% accuracy, which is very low. So I post this project on Kaggle to submit it and check how accuracy is calculated.\n\nFeel free to comment and give advices. I am here to learn. \n\nThe complete Notebook is on my Github, where I used the labeled data set to test my models, and calculate accuracy.\n\nhttps://github.com/JeremyArancio/Toxic_Comments_Classification\n\nHave a good reading !\n\nJérémy\n","metadata":{}},{"cell_type":"markdown","source":"# Updates","metadata":{}},{"cell_type":"markdown","source":"**V6**  \nTFIDF + Logistic Regression  \nPunct & Stopwords removed\n\n**V7**  \nInverse of regularization strength C=4 in Logistic regression  \nPunct & Stopwords accepted\n\n**V8**  \nUnigrams & Bigrams","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:02.537244Z","iopub.execute_input":"2022-04-12T14:03:02.537666Z","iopub.status.idle":"2022-04-12T14:03:02.544655Z","shell.execute_reply.started":"2022-04-12T14:03:02.53763Z","shell.execute_reply":"2022-04-12T14:03:02.543417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"markdown","source":"## File descriptions\n* train.csv - the training set, contains comments with their binary labels\n* test.csv - the test set, you must predict the toxicity probabilities for these comments. To deter hand \nlabeling, the test set contains some comments which are not included in scoring.\n* sample_submission.csv - a sample submission file in the correct format\n* test_labels.csv - labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:02.546999Z","iopub.execute_input":"2022-04-12T14:03:02.547389Z","iopub.status.idle":"2022-04-12T14:03:02.577602Z","shell.execute_reply.started":"2022-04-12T14:03:02.547327Z","shell.execute_reply":"2022-04-12T14:03:02.576485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\ntest_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\ntest_label_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip')\nsamp_subm = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:02.579249Z","iopub.execute_input":"2022-04-12T14:03:02.57995Z","iopub.status.idle":"2022-04-12T14:03:06.183465Z","shell.execute_reply.started":"2022-04-12T14:03:02.579915Z","shell.execute_reply":"2022-04-12T14:03:06.182178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.184645Z","iopub.execute_input":"2022-04-12T14:03:06.184865Z","iopub.status.idle":"2022-04-12T14:03:06.246478Z","shell.execute_reply.started":"2022-04-12T14:03:06.184839Z","shell.execute_reply":"2022-04-12T14:03:06.245262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.248802Z","iopub.execute_input":"2022-04-12T14:03:06.249114Z","iopub.status.idle":"2022-04-12T14:03:06.305073Z","shell.execute_reply.started":"2022-04-12T14:03:06.249036Z","shell.execute_reply":"2022-04-12T14:03:06.303647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.306589Z","iopub.execute_input":"2022-04-12T14:03:06.306935Z","iopub.status.idle":"2022-04-12T14:03:06.322318Z","shell.execute_reply.started":"2022-04-12T14:03:06.306889Z","shell.execute_reply":"2022-04-12T14:03:06.320924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see the training dataset contains :\n* the comment ID\n* the raw text\n* the different categories of toxicity","metadata":{}},{"cell_type":"code","source":"# Let's check some comments\nfor i in range(10):\n    print(train_data['comment_text'][i])\n    print('---------------')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.323894Z","iopub.execute_input":"2022-04-12T14:03:06.324765Z","iopub.status.idle":"2022-04-12T14:03:06.340318Z","shell.execute_reply.started":"2022-04-12T14:03:06.324719Z","shell.execute_reply":"2022-04-12T14:03:06.339507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check in the test.csv\ntest_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.341651Z","iopub.execute_input":"2022-04-12T14:03:06.341919Z","iopub.status.idle":"2022-04-12T14:03:06.354796Z","shell.execute_reply.started":"2022-04-12T14:03:06.341855Z","shell.execute_reply":"2022-04-12T14:03:06.35392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we just have the ID's and comments with no classification","metadata":{}},{"cell_type":"code","source":"# Submission data set\nsamp_subm","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.356028Z","iopub.execute_input":"2022-04-12T14:03:06.356607Z","iopub.status.idle":"2022-04-12T14:03:06.383286Z","shell.execute_reply.started":"2022-04-12T14:03:06.356571Z","shell.execute_reply":"2022-04-12T14:03:06.382689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clean the corpus","metadata":{}},{"cell_type":"code","source":"#Let''s define a function that preprocesses a text\n\ndef preprocess(corpus):\n    \n    '''\n    From a string, make text lowercase, remove hyperlinks, word containing numbers.\n    Input : a list of strings\n    Output : a list of tokens stored in a generator (yield)\n    '''\n\n    for text in corpus:\n\n        text = text.lower()                                               # Lowercase\n        text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)                   # Remove links\n        #text = re.sub('[%s]' % re.escape(string.punctuation), '', text)   # Remove punctuation\n        text = re.sub('\\w*\\d\\w*', '', text)                               # Remove words containing numbers\n    \n        yield ' '.join([word for word in text.split(' ')]) # Return a generator ","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.384335Z","iopub.execute_input":"2022-04-12T14:03:06.385099Z","iopub.status.idle":"2022-04-12T14:03:06.391986Z","shell.execute_reply.started":"2022-04-12T14:03:06.385057Z","shell.execute_reply":"2022-04-12T14:03:06.390845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# We save the cleaned comments in a list to be easily manipulated\nclean_comments = list(preprocess(train_data['comment_text']))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:06.393552Z","iopub.execute_input":"2022-04-12T14:03:06.393982Z","iopub.status.idle":"2022-04-12T14:03:25.688096Z","shell.execute_reply.started":"2022-04-12T14:03:06.393947Z","shell.execute_reply":"2022-04-12T14:03:25.687442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    print(clean_comments[i])\n    print('------------')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:25.689272Z","iopub.execute_input":"2022-04-12T14:03:25.689678Z","iopub.status.idle":"2022-04-12T14:03:25.696952Z","shell.execute_reply.started":"2022-04-12T14:03:25.689636Z","shell.execute_reply":"2022-04-12T14:03:25.696013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We note some words with no meaning, or typos. It can be better but we are going to work with that at first.\n\n","metadata":{}},{"cell_type":"code","source":"%%time\n# We do the same for the test set\ntest_clean_comments = list(preprocess(test_data[\"comment_text\"]))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:25.6982Z","iopub.execute_input":"2022-04-12T14:03:25.698731Z","iopub.status.idle":"2022-04-12T14:03:42.052998Z","shell.execute_reply.started":"2022-04-12T14:03:25.698694Z","shell.execute_reply":"2022-04-12T14:03:42.052047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"# Let's define target, which is the classification made by human\ntarget = train_data[['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']]\n# target = np.array(target) #transform dataframe into array\ntarget.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:42.055863Z","iopub.execute_input":"2022-04-12T14:03:42.056172Z","iopub.status.idle":"2022-04-12T14:03:42.072972Z","shell.execute_reply.started":"2022-04-12T14:03:42.05614Z","shell.execute_reply":"2022-04-12T14:03:42.071898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check if target values are balanced.   \nIn other words, is the target made of as much toxic as non-toxic comments","metadata":{}},{"cell_type":"code","source":"target.sum(axis=0) / target.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:42.074395Z","iopub.execute_input":"2022-04-12T14:03:42.074743Z","iopub.status.idle":"2022-04-12T14:03:42.088414Z","shell.execute_reply.started":"2022-04-12T14:03:42.074702Z","shell.execute_reply":"2022-04-12T14:03:42.087755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the target set  is not balanced.","metadata":{}},{"cell_type":"markdown","source":"We define NaÏve Bayes relation","metadata":{}},{"cell_type":"code","source":"def probNB(bow,target,cat):\n\n    '''\n    Naive Bayes probability for each word\n    Inputs :\n    bow : bag of words (with doc in rows and words in columns)\n    target : classification vector (filled with 1 and 0)\n    cat : 1 or 0, in target\n    Output : \n    Vector of Naive Bayes probabilities with smoothing (n_words,1)\n    '''\n\n    p = np.array(bow[target==cat].sum(axis=0))\n\n    return np.transpose((p+1) / (p.sum() + bow.shape[1]))\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:42.089768Z","iopub.execute_input":"2022-04-12T14:03:42.090129Z","iopub.status.idle":"2022-04-12T14:03:42.09826Z","shell.execute_reply.started":"2022-04-12T14:03:42.090101Z","shell.execute_reply":"2022-04-12T14:03:42.097406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(bow,target):\n\n    '''\n    Function that return the log likelihood of a document\n    Inputs :\n    bow : bag of words (n_doc,n_words)\n    target : classification of comments (n_doc,1)\n    Output : \n    Return a vector of Log Likelihood for each comment (Naïve Bayes) (n_doc,1)\n    '''\n\n    log = np.log(probNB(bow,target,1)/probNB(bow,target,0))\n    m = bow.dot(log)\n    model = LogisticRegression(C=4).fit(m,target)\n    return model , log","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:42.100099Z","iopub.execute_input":"2022-04-12T14:03:42.100472Z","iopub.status.idle":"2022-04-12T14:03:42.123166Z","shell.execute_reply.started":"2022-04-12T14:03:42.100427Z","shell.execute_reply":"2022-04-12T14:03:42.121817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF NB-Logistic regression","metadata":{}},{"cell_type":"code","source":"# Word embeddings\ntfidf_vec = TfidfVectorizer(ngram_range=(1,2),min_df=3,max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntfidf = tfidf_vec.fit_transform(clean_comments)\ntfidf_test = tfidf_vec.transform(test_clean_comments)\n\n# Let's create our model\ndf_classification = pd.DataFrame() #We store probabilities into a Dataframe\ndf_classification['Comments'] = test_data['comment_text']\n\nfor i,j in enumerate(target.columns):\n    print('fit', j)\n    model,log = get_model(tfidf,target[j])\n    df_classification[j] = model.predict_proba(tfidf_test.dot(log))[:,1]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:03:42.125153Z","iopub.execute_input":"2022-04-12T14:03:42.125729Z","iopub.status.idle":"2022-04-12T14:04:52.245208Z","shell.execute_reply.started":"2022-04-12T14:03:42.125682Z","shell.execute_reply":"2022-04-12T14:04:52.244014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\n","metadata":{}},{"cell_type":"code","source":"keys = target.columns\nsubmid = pd.DataFrame({\"id\" : samp_subm[\"id\"]})\nsubmission = pd.concat([submid,df_classification[keys]],axis=1)\nsubmission.to_csv('submission.csv', index=False)\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T14:04:52.24662Z","iopub.execute_input":"2022-04-12T14:04:52.247011Z","iopub.status.idle":"2022-04-12T14:04:54.573706Z","shell.execute_reply.started":"2022-04-12T14:04:52.246979Z","shell.execute_reply":"2022-04-12T14:04:54.572783Z"},"trusted":true},"execution_count":null,"outputs":[]}]}