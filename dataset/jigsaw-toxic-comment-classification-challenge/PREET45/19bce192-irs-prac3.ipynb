{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-11T19:50:34.152113Z","iopub.execute_input":"2022-03-11T19:50:34.152717Z","iopub.status.idle":"2022-03-11T19:50:34.185356Z","shell.execute_reply.started":"2022-03-11T19:50:34.152622Z","shell.execute_reply":"2022-03-11T19:50:34.184489Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import  matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nimport pickle\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:50:34.187479Z","iopub.execute_input":"2022-03-11T19:50:34.187878Z","iopub.status.idle":"2022-03-11T19:50:41.439949Z","shell.execute_reply.started":"2022-03-11T19:50:34.187836Z","shell.execute_reply":"2022-03-11T19:50:41.438716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df  =  pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:50:41.441704Z","iopub.execute_input":"2022-03-11T19:50:41.442036Z","iopub.status.idle":"2022-03-11T19:50:43.701974Z","shell.execute_reply.started":"2022-03-11T19:50:41.441993Z","shell.execute_reply":"2022-03-11T19:50:43.700933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:50:43.704829Z","iopub.execute_input":"2022-03-11T19:50:43.705152Z","iopub.status.idle":"2022-03-11T19:50:45.509116Z","shell.execute_reply.started":"2022-03-11T19:50:43.705109Z","shell.execute_reply":"2022-03-11T19:50:45.507978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:50:45.511467Z","iopub.execute_input":"2022-03-11T19:50:45.512114Z","iopub.status.idle":"2022-03-11T19:50:45.573876Z","shell.execute_reply.started":"2022-03-11T19:50:45.512051Z","shell.execute_reply":"2022-03-11T19:50:45.572963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_review_text(text):\n    text = text.lower()  # covert the text to lowercase\n    text = re.sub('<.*?>','',text).strip() # remove html chars\n    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n    return text.strip()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:50:45.60152Z","iopub.execute_input":"2022-03-11T19:50:45.602265Z","iopub.status.idle":"2022-03-11T19:50:45.614367Z","shell.execute_reply.started":"2022-03-11T19:50:45.602218Z","shell.execute_reply":"2022-03-11T19:50:45.612872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.comment_text = train_df.comment_text.astype(str)\ntrain_df.comment_text = train_df.comment_text.apply(clean_review_text)\ntrain_df.comment_text.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:50:45.625968Z","iopub.execute_input":"2022-03-11T19:50:45.626344Z","iopub.status.idle":"2022-03-11T19:51:13.075479Z","shell.execute_reply.started":"2022-03-11T19:50:45.626298Z","shell.execute_reply":"2022-03-11T19:51:13.074547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem.snowball import SnowballStemmer\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\n\nsnow_stemmer = SnowballStemmer(language='english')\n\nstopwords = nlp.Defaults.stop_words\ndef apply_stemmer(text):\n    words = text.split()\n    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n    return ' '.join(sent)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:51:13.077187Z","iopub.execute_input":"2022-03-11T19:51:13.077473Z","iopub.status.idle":"2022-03-11T19:51:21.416017Z","shell.execute_reply.started":"2022-03-11T19:51:13.077432Z","shell.execute_reply":"2022-03-11T19:51:21.415026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.comment_text = train_df.comment_text.apply(apply_stemmer)\ntrain_df.comment_text.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:51:21.417397Z","iopub.execute_input":"2022-03-11T19:51:21.417811Z","iopub.status.idle":"2022-03-11T19:54:03.664833Z","shell.execute_reply.started":"2022-03-11T19:51:21.41777Z","shell.execute_reply":"2022-03-11T19:54:03.663759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.comment_text\ny = train_df.drop(['id','comment_text'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:03.668827Z","iopub.execute_input":"2022-03-11T19:54:03.672379Z","iopub.status.idle":"2022-03-11T19:54:03.692286Z","shell.execute_reply.started":"2022-03-11T19:54:03.672334Z","shell.execute_reply":"2022-03-11T19:54:03.690825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test =  train_test_split(X,y,test_size = 0.2,random_state = 45)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:55:10.60006Z","iopub.execute_input":"2022-03-11T19:55:10.600579Z","iopub.status.idle":"2022-03-11T19:55:10.652167Z","shell.execute_reply.started":"2022-03-11T19:55:10.600541Z","shell.execute_reply":"2022-03-11T19:55:10.651113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    strip_accents='unicode',     \n    analyzer='word',            \n    token_pattern=r'\\w{1,}',    \n    ngram_range=(1, 3),         \n    stop_words='english',\n    sublinear_tf=True)\n\nword_vectorizer.fit(x_train)    \ntrain_word_features = word_vectorizer.transform(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.444039Z","iopub.status.idle":"2022-03-11T19:54:04.445085Z","shell.execute_reply.started":"2022-03-11T19:54:04.444751Z","shell.execute_reply":"2022-03-11T19:54:04.444783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_transformed = word_vectorizer.transform(x_train)\nX_test_transformed = word_vectorizer.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.446842Z","iopub.status.idle":"2022-03-11T19:54:04.447409Z","shell.execute_reply.started":"2022-03-11T19:54:04.447078Z","shell.execute_reply":"2022-03-11T19:54:04.447107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.linear_model import LogisticRegression\nseed=100\n\nlog_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=seed)\n\n# fit model\nclassifier_ovr_log = OneVsRestClassifier(log_reg)\nclassifier_ovr_log.fit(X_train_transformed, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.449329Z","iopub.status.idle":"2022-03-11T19:54:04.450173Z","shell.execute_reply.started":"2022-03-11T19:54:04.449856Z","shell.execute_reply":"2022-03-11T19:54:04.449901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\ny_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.452542Z","iopub.status.idle":"2022-03-11T19:54:04.45317Z","shell.execute_reply.started":"2022-03-11T19:54:04.452848Z","shell.execute_reply":"2022-03-11T19:54:04.452877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_predictions(df,classifier):\n    df.comment_text = df.comment_text.apply(clean_review_text)\n    df.comment_text = df.comment_text.apply(apply_stemmer)\n    X_test = df.comment_text\n    X_test_transformed = word_vectorizer.transform(X_test)\n    y_test_pred = classifier.predict_proba(X_test_transformed)\n    return y_test_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.45516Z","iopub.status.idle":"2022-03-11T19:54:04.455876Z","shell.execute_reply.started":"2022-03-11T19:54:04.455571Z","shell.execute_reply":"2022-03-11T19:54:04.455602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=make_test_predictions(test_df,classifier_ovr_log)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.45782Z","iopub.status.idle":"2022-03-11T19:54:04.458734Z","shell.execute_reply.started":"2022-03-11T19:54:04.458396Z","shell.execute_reply":"2022-03-11T19:54:04.458429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_df = pd.DataFrame(y_pred,columns=y.columns)\ny_pred_df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.46297Z","iopub.status.idle":"2022-03-11T19:54:04.463548Z","shell.execute_reply.started":"2022-03-11T19:54:04.463241Z","shell.execute_reply":"2022-03-11T19:54:04.46327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.concat([test_df.id, y_pred_df], axis=1)\nsubmission_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T19:54:04.46507Z","iopub.status.idle":"2022-03-11T19:54:04.46621Z","shell.execute_reply.started":"2022-03-11T19:54:04.465885Z","shell.execute_reply":"2022-03-11T19:54:04.465916Z"},"trusted":true},"execution_count":null,"outputs":[]}]}