{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install transformers clean-text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\n\ndata = pd.read_csv(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Records: {}, Number of features/columns: {}'.format(data.shape[0], data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Null values: {}'.format(data.isnull().values.sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = list(data.columns)[2:]\ny_labels = data[target_columns].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertConfig, TFDistilBertModel\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom cleantext import clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distil_bert = 'distilbert-base-uncased'\n\ntokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n                                                max_length=128, pad_to_max_length=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleaning(text):\n    return clean(text, no_line_breaks=True, no_urls=True, no_punct=True)\n\ndef tokenize(sentences, tokenizer):\n    \n    input_ids = []\n    input_masks = []\n    #input_segments = []\n    \n    for sentence in tqdm(sentences):\n        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, \n                                       max_length=128, pad_to_max_length=True, \n                                       return_attention_mask=True, return_token_type_ids=True)\n        \n        input_ids.append(inputs['input_ids'])\n        input_masks.append(inputs['attention_mask'])\n        #input_segments.append(inputs['token_type_ids'])        \n        \n    return np.asarray(input_ids, dtype='int32'),np.asarray(input_masks, dtype='int32')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"data['comment_text'] = data['comment_text'].apply(cleaning)\ninput_ids, input_masks = tokenize(data['comment_text'], tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n\nconfig.output_hidden_states = False\n\ntransformer_model = TFDistilBertModel.from_pretrained(distil_bert, config=config)\n\ninput_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\ninput_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n\nembedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\nX = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, \n                                                       return_sequences=True, \n                                                       dropout=0.1, \n                                                       recurrent_dropout=0.1))(embedding_layer)\nX = tf.keras.layers.GlobalMaxPool1D()(X)\nX = tf.keras.layers.Dense(50, activation='relu')(X)\nX = tf.keras.layers.Dropout(0.2)(X)\nX = tf.keras.layers.Dense(6, activation='sigmoid')(X)\n\nmodel = tf.keras.models.Model(inputs=[input_ids_in, input_masks_in], outputs=X)\n\nfor layer in model.layers[:3]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_id, X_test_id, X_train_mask, X_test_mask, y_train, y_test = train_test_split(input_ids, \n                                                                                     input_masks, \n                                                                                     y_labels,\n                                                                                     test_size=0.2, \n                                                                                     random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit([X_train_id, X_train_mask], \n                 y_train, \n                 validation_data=([X_test_id, X_test_mask], y_test),\n                 epochs=1,\n                 batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save_weights('toxix.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_text = 'I hate you, you idiot!'\nclean_txt = cleaning(sample_text)\ninput_ids_test, input_masks_test = tokenize(clean_txt, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict([input_ids_test, input_masks_test])[0]\nprediction = target_columns[np.argmax(preds, axis=0)]\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SUBMISSION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_path = '../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip'\nsample_submission = pd.read_csv(sample_submission_path)\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = '../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip'\ndf_test = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = df_test['id']\nX_t = df_test['comment_text'].apply(cleaning)\nsub_input_ids, sub_input_masks = tokenize(X_t, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict([sub_input_ids, sub_input_masks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = pd.Series(ids)\ny_preds = pd.DataFrame(predictions, columns=target_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission = pd.concat([ids, y_preds], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}