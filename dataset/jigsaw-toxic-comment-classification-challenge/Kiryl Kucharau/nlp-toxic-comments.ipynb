{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nunzip = zipfile.ZipFile('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\nunzip.extractall()\nunzip = zipfile.ZipFile('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\nunzip.extractall()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/working/test.csv')\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/working/train.csv')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[3,'comment_text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[:,'toxic':].mean(axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[(train_df['toxic']==0) & (train_df['severe_toxic']==0) & (train_df['obscene']==0) & (train_df['threat']==0) & \n          (train_df['insult']==0) & (train_df['identity_hate']==0)].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"APPO = {\n\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"that's\" : \"that is\",\n\"there's\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    \n    text = text.lower()\n    text = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '', text) # clean url\n    text = re.sub(r'#(\\w+)', '', text)   # clean hashes\n    text = re.sub(r'@(\\w+)', '', text)   # clean @\n    text = re.sub(r'<[^>]+>', '', text)  # clean tags\n    text = re.sub(r'\\d+', '', text)      # clean digits\n    text = re.sub(r'[,!@\\'\\\"?\\.$%_&#*+-:;]', '', text)   # clean punctuation\n    text = [APPO[word] if word in APPO else word for word in text.split()]  #\n    \n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['comment_text'] = train_df['comment_text'].apply(clean_text)\ntest_df['comment_text'] = test_df['comment_text'].apply(clean_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set, val_set = train_test_split(train_df, test_size = 0.2, random_state=11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = 100000, oov_token='<oov>')\ntokenizer.fit_on_texts(train_df.comment_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traning_sequences = tokenizer.texts_to_sequences(train_set.comment_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlen = max([len(x) for x in np.array(traning_sequences)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_padded = pad_sequences(traning_sequences, maxlen = maxlen,\n                                padding = 'pre',\n                                truncating='pre')\ntrain_y = np.array(train_set.loc[:,'toxic':])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traning_sequences = tokenizer.texts_to_sequences(val_set.comment_text)\nval_padded = pad_sequences(traning_sequences,maxlen = 1403,\n                                padding = 'pre',\n                                truncating='pre')\nval_y = np.array(val_set.loc[:,'toxic':])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.Sequential([tf.keras.layers.Embedding(150000, 128),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(32, activation=\"relu\"),\n    tf.keras.layers.Dense(6, activation=\"sigmoid\")])\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, validation_data = (val_padded, val_y), epochs = 2, batch_size = 100)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.Sequential([tf.keras.layers.Embedding(150000, 128),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),    \n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(6, activation='sigmoid')])\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, validation_data = (val_padded, val_y), epochs = 5, batch_size = 200)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.Sequential([tf.keras.layers.Embedding(100000, 128),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),    \n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation='sigmoid')])\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, validation_data = (val_padded, val_y), epochs = 5, batch_size = 200)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.Sequential([tf.keras.layers.Embedding(10000, 128),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True, dropout=0.15, recurrent_dropout=0.15)),    \n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation='sigmoid')])\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, validation_data = (val_padded, val_y), epochs = 5, batch_size = 200)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.Sequential([tf.keras.layers.Embedding(150000, 128),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True)),\n    tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='valid', kernel_initializer='glorot_uniform'),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation='sigmoid')])\n                             \nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, validation_data = (val_padded, val_y), epochs = 5, batch_size = 200)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.Sequential([tf.keras.layers.Embedding(150000, 300),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences = True)),\n    tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='valid', kernel_initializer='glorot_uniform'),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation='sigmoid')])\n                             \nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, validation_data = (val_padded, val_y), epochs = 5, batch_size = 50)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traning_sequences = tokenizer.texts_to_sequences(train_df.comment_text)\ntraining_padded = pad_sequences(traning_sequences, maxlen = maxlen,\n                                padding = 'pre',\n                                truncating='pre')\ntrain_y = np.array(train_df.loc[:,'toxic':])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([tf.keras.layers.Embedding(150000, 300),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences = True)),\n    tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='valid', kernel_initializer='glorot_uniform'),\n    tf.keras.layers.GlobalMaxPooling1D(),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation='sigmoid')])\n                             \nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['AUC'])\nmodel.fit(x = training_padded, y = train_y, epochs = 2, batch_size = 200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_sequences = tokenizer.texts_to_sequences(test_df.comment_text)\ntest_padded = pad_sequences(testing_sequences, maxlen = maxlen,\n                                padding = 'pre',\n                                truncating='pre')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = model.predict(test_padded, batch_size = 200)\npredict = np.hstack((test_df.id[:, np.newaxis], predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm = pd.DataFrame(predict, columns = ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\nsubm.to_csv('subm.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}