{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-12T04:48:06.178367Z","iopub.execute_input":"2022-03-12T04:48:06.178667Z","iopub.status.idle":"2022-03-12T04:48:06.206327Z","shell.execute_reply.started":"2022-03-12T04:48:06.178589Z","shell.execute_reply":"2022-03-12T04:48:06.205499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd ","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:48:06.20803Z","iopub.execute_input":"2022-03-12T04:48:06.208353Z","iopub.status.idle":"2022-03-12T04:48:06.212866Z","shell.execute_reply.started":"2022-03-12T04:48:06.208319Z","shell.execute_reply":"2022-03-12T04:48:06.211961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df  =  pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:48:06.214373Z","iopub.execute_input":"2022-03-12T04:48:06.215042Z","iopub.status.idle":"2022-03-12T04:48:10.188819Z","shell.execute_reply.started":"2022-03-12T04:48:06.215006Z","shell.execute_reply":"2022-03-12T04:48:10.188053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:48:10.190308Z","iopub.execute_input":"2022-03-12T04:48:10.190713Z","iopub.status.idle":"2022-03-12T04:48:10.226068Z","shell.execute_reply.started":"2022-03-12T04:48:10.190672Z","shell.execute_reply":"2022-03-12T04:48:10.222339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:48:10.227982Z","iopub.execute_input":"2022-03-12T04:48:10.228312Z","iopub.status.idle":"2022-03-12T04:48:10.248355Z","shell.execute_reply.started":"2022-03-12T04:48:10.228274Z","shell.execute_reply":"2022-03-12T04:48:10.247649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:48:10.25031Z","iopub.execute_input":"2022-03-12T04:48:10.251018Z","iopub.status.idle":"2022-03-12T04:48:10.342897Z","shell.execute_reply.started":"2022-03-12T04:48:10.25098Z","shell.execute_reply":"2022-03-12T04:48:10.341886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\n\ndef clean_review_text(text):\n    text = text.lower()  # covert the text to lowercase\n    text = re.sub('<.*?>','',text).strip() # remove html chars\n    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n    return text.strip()\n\ntrain_df.comment_text = train_df.comment_text.astype(str)\ntrain_df.comment_text = train_df.comment_text.apply(clean_review_text)\ntrain_df.comment_text.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:48:10.345805Z","iopub.execute_input":"2022-03-12T04:48:10.346172Z","iopub.status.idle":"2022-03-12T04:48:34.281855Z","shell.execute_reply.started":"2022-03-12T04:48:10.346132Z","shell.execute_reply":"2022-03-12T04:48:34.281156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import  matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nimport pickle\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport en_core_web_sm\n\n\nnlp = en_core_web_sm.load()\nsnow_stemmer = SnowballStemmer(language='english')\nstopwords = nlp.Defaults.stop_words","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:50:19.704591Z","iopub.execute_input":"2022-03-12T04:50:19.705343Z","iopub.status.idle":"2022-03-12T04:50:31.912235Z","shell.execute_reply.started":"2022-03-12T04:50:19.705302Z","shell.execute_reply":"2022-03-12T04:50:31.91148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_stemmer(text):\n    words = text.split()\n    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n    return ' '.join(sent)\n\ntrain_df.comment_text = train_df.comment_text.apply(apply_stemmer)\ntrain_df.comment_text.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:50:56.995503Z","iopub.execute_input":"2022-03-12T04:50:56.995755Z","iopub.status.idle":"2022-03-12T04:53:04.639289Z","shell.execute_reply.started":"2022-03-12T04:50:56.995727Z","shell.execute_reply":"2022-03-12T04:53:04.638613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.comment_text\ny = train_df.drop(['id','comment_text'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:54:05.154349Z","iopub.execute_input":"2022-03-12T04:54:05.15461Z","iopub.status.idle":"2022-03-12T04:54:05.165216Z","shell.execute_reply.started":"2022-03-12T04:54:05.154581Z","shell.execute_reply":"2022-03-12T04:54:05.164498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test =  train_test_split(X,y,test_size = 0.2,random_state = 45)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:54:18.079424Z","iopub.execute_input":"2022-03-12T04:54:18.079674Z","iopub.status.idle":"2022-03-12T04:54:18.120855Z","shell.execute_reply.started":"2022-03-12T04:54:18.079646Z","shell.execute_reply":"2022-03-12T04:54:18.120143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    strip_accents='unicode',     \n    analyzer='word',            \n    token_pattern=r'\\w{1,}',    \n    ngram_range=(1, 3),         \n    stop_words='english',\n    sublinear_tf=True)\n\nword_vectorizer.fit(x_train)    \ntrain_word_features = word_vectorizer.transform(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:54:37.693375Z","iopub.execute_input":"2022-03-12T04:54:37.693628Z","iopub.status.idle":"2022-03-12T04:55:29.027021Z","shell.execute_reply.started":"2022-03-12T04:54:37.6936Z","shell.execute_reply":"2022-03-12T04:55:29.02627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_transformed = word_vectorizer.transform(x_train)\nX_test_transformed = word_vectorizer.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:55:33.912896Z","iopub.execute_input":"2022-03-12T04:55:33.91359Z","iopub.status.idle":"2022-03-12T04:55:51.832043Z","shell.execute_reply.started":"2022-03-12T04:55:33.913554Z","shell.execute_reply":"2022-03-12T04:55:51.831293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_regression = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=100)\nclassifier_ovr_log = OneVsRestClassifier(logistic_regression)\nclassifier_ovr_log.fit(X_train_transformed, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:56:33.428684Z","iopub.execute_input":"2022-03-12T04:56:33.42936Z","iopub.status.idle":"2022-03-12T04:58:27.748167Z","shell.execute_reply.started":"2022-03-12T04:56:33.429317Z","shell.execute_reply":"2022-03-12T04:58:27.747218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\ny_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T04:58:49.316932Z","iopub.execute_input":"2022-03-12T04:58:49.317514Z","iopub.status.idle":"2022-03-12T04:58:49.78108Z","shell.execute_reply.started":"2022-03-12T04:58:49.317478Z","shell.execute_reply":"2022-03-12T04:58:49.780293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_predictions(df,classifier):\n    df.comment_text = df.comment_text.apply(clean_review_text)\n    df.comment_text = df.comment_text.apply(apply_stemmer)\n    X_test = df.comment_text\n    X_test_transformed = word_vectorizer.transform(X_test)\n    y_test_pred = classifier.predict_proba(X_test_transformed)\n    return y_test_pred\n\ny_pred=make_test_predictions(test_df,classifier_ovr_log)\ny_pred_df = pd.DataFrame(y_pred,columns=y.columns)\ny_pred_df","metadata":{"execution":{"iopub.status.busy":"2022-03-12T05:01:21.405016Z","iopub.execute_input":"2022-03-12T05:01:21.405419Z","iopub.status.idle":"2022-03-12T05:03:14.25331Z","shell.execute_reply.started":"2022-03-12T05:01:21.405382Z","shell.execute_reply":"2022-03-12T05:03:14.250975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.concat([test_df.id, y_pred_df], axis=1)\nsubmission_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T05:04:39.714582Z","iopub.execute_input":"2022-03-12T05:04:39.714835Z","iopub.status.idle":"2022-03-12T05:04:41.819024Z","shell.execute_reply.started":"2022-03-12T05:04:39.714805Z","shell.execute_reply":"2022-03-12T05:04:41.818293Z"},"trusted":true},"execution_count":null,"outputs":[]}]}