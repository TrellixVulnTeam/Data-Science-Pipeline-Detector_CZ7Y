{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **A NLP model using CNN to classify the toxic words from the comments.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"MemFGW7ksHC4"},"cell_type":"markdown","source":"<h2 align=center> Toxic Comments Classification using 1D CNN with Keras</h2>","execution_count":null},{"metadata":{"id":"x_XiyvkqfYS0"},"cell_type":"markdown","source":"### Task 1: Import Packages and Functions","execution_count":null},{"metadata":{"id":"PvVbtuzBsHDO","outputId":"e8d81969-344e-4681-e6ea-c160f21e3b4c","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"_yPEK8PqgKQt"},"cell_type":"markdown","source":"### Task 2: Load and Explore Data","execution_count":null},{"metadata":{"id":"UkOBp_TDsHDj","outputId":"75040da1-3b8d-41c3-970b-3e4026fae17a","trusted":true},"cell_type":"code","source":"# Load data\ntrain_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip').fillna(' ')\ntrain_df.sample(10, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"KLqhFuE2sHDp","outputId":"f49d8331-6d4d-4012-d3c9-3c8d74def399","trusted":true},"cell_type":"code","source":" x = train_df['comment_text'].values\n print(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"dLEAz9Mx7apX","outputId":"15d81c26-0856-4a37-c1d6-f2ef9294be70","trusted":true},"cell_type":"code","source":"# View few toxic comments\ntrain_df.loc[train_df['toxic'] == 1].sample(10 , random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{"id":"0hGVtLwo2VlV","outputId":"c4b5a36d-76b7-418c-bc69-2e2487102cb5","trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\ncomments = train_df['comment_text'].loc[train_df['toxic']==1].values\nwordcloud = WordCloud(\n    width = 640,\n    height = 640,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(comments))\nfig = plt.figure(\n    figsize = (12, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"qmfnwRYksHDu","outputId":"6b765736-eb62-4262-b7b4-e7bb1fc9fac6","trusted":true},"cell_type":"code","source":"y = train_df['toxic'].values\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"3-pxZLFQw3VR","outputId":"55550efc-46d7-4c5c-d0c1-67fd24bba93a","trusted":true},"cell_type":"code","source":"# Plot frequency of toxic comments\ntrain_df['toxic'].plot(kind = 'hist' , title = 'Distribution Of Toxic Comments')","execution_count":null,"outputs":[]},{"metadata":{"id":"8v5D7BG5w_nV","outputId":"77d73905-e5b2-4f21-b75f-0650d7229a03","trusted":true},"cell_type":"code","source":"train_df['toxic'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"IZs1wuFjhxss"},"cell_type":"markdown","source":"### Task 3: Data Prep â€” Tokenize and Pad Text Data","execution_count":null},{"metadata":{"id":"51i_F9iRsHDV","trusted":true},"cell_type":"code","source":"# Most frequent 20000 words will be embedded and rest will be ignored\nmax_features = 20000\n\n# The max lenth of the comments will be set as 400 and all those comments where lenght will not be 40\n# They'll be padded to 400 length\nmax_text_length = 400","execution_count":null,"outputs":[]},{"metadata":{"id":"wRuNEC_DsHDy","trusted":true},"cell_type":"code","source":"# text.Tokenizer - It vectorises the values of each text into integers where each integer is index of a token in a dictionary.\nx_tokenizer = text.Tokenizer(max_features)\n\n# We'll fit the tokenizer onto the list of x\nx_tokenizer.fit_on_texts(list(x))\n\n#After that we'll convert the tokenized text into list of list of sequences of numbers\nx_tokenized = x_tokenizer.texts_to_sequences(x)\n\n#We'll pad each of these sequences to the max_length of 400\nx_train_val = sequence.pad_sequences(x_tokenized , maxlen = max_text_length)","execution_count":null,"outputs":[]},{"metadata":{"id":"Wki7nrWgiRTp"},"cell_type":"markdown","source":"### Task 4: Prepare Embedding Matrix with Pre-trained GloVe Embeddings","execution_count":null},{"metadata":{"id":"YTSlrTEOqcW8","outputId":"f09522ed-0723-474f-e344-ceb68d771022","trusted":true},"cell_type":"code","source":"# # !wget http://nlp.stanford.edu/data/glove.6B.zip\n# !unzip glove.6B.zip.1","execution_count":null,"outputs":[]},{"metadata":{"id":"08VYEZ8DqwRH","outputId":"5ce223d8-5211-47c6-ae14-38875b5193e4","trusted":true},"cell_type":"code","source":"embedding_dim = 100\nembeddings_index = dict()\nf = open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt')\nfor line in f:\n  values = line.split()\n  word = values[0]\n  coefs = np.asarray(values[1:] , dtype = 'float32')\n  embeddings_index[word] = coefs\n\nf.close()\nprint(f'Found {len(embeddings_index)} word vectors. ')","execution_count":null,"outputs":[]},{"metadata":{"id":"csgEyJ88ij9x","trusted":true},"cell_type":"code","source":"embedding_matrix = np.zeros((max_features , embedding_dim))\nfor word , index in x_tokenizer.word_index.items():\n  if index > max_features -1:\n    break\n  else:\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n      embedding_matrix[index] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"id":"9ikSokUmeptj"},"cell_type":"markdown","source":"### Task 5: Create the Embedding Layer","execution_count":null},{"metadata":{"id":"mHxD6duxf5r5","trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_features,\n                    embedding_dim,\n                    embeddings_initializer = tf.keras.initializers.Constant(\n                        embedding_matrix),\n                    trainable = False\n                    ))\n\nmodel.add(Dropout(0.2))","execution_count":null,"outputs":[]},{"metadata":{"id":"EMLOgUx2UT2d"},"cell_type":"markdown","source":"### Task 6: Build the Model","execution_count":null},{"metadata":{"id":"bH2cnwbrUT2d","trusted":true},"cell_type":"code","source":"filters = 250\nkernel_size = 3 \nhidden_dims = 250","execution_count":null,"outputs":[]},{"metadata":{"id":"XpTcFfxhUT2i","outputId":"388d14d7-524b-4784-dc0e-2ba0499d4d55","trusted":true},"cell_type":"code","source":"model.add(Conv1D(filters,\n                 kernel_size,\n                 padding = 'valid'))\nmodel.add(MaxPooling1D())\nmodel.add(Conv1D(filters,\n                 5,\n                 padding = 'valid',\n                 activation = 'relu'))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(hidden_dims , activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1 , activation= 'sigmoid'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"6M2eT9JnUT2l","trusted":true},"cell_type":"code","source":"model.compile(loss = 'binary_crossentropy' , optimizer= 'adam' , metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"yds9-uJbeygs"},"cell_type":"markdown","source":"### Task 7: Train Model","execution_count":null},{"metadata":{"id":"jBAmWQbLsHD4","trusted":true},"cell_type":"code","source":"x_train , x_val , y_train , y_val = train_test_split(x_train_val , y , test_size = 0.15 ,random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZDQkgmhOsHED","outputId":"3ddda709-ed81-477f-8945-cca970507106","trusted":true},"cell_type":"code","source":"batch_size = 32\nmodel.fit(x_train , y_train ,\n          batch_size = 32,\n          epochs =3,\n          validation_data = (x_val ,y_val))","execution_count":null,"outputs":[]},{"metadata":{"id":"NFFWvo5nfGAP"},"cell_type":"markdown","source":"### Task 8: Evaluate Model","execution_count":null},{"metadata":{"id":"9J54v6q0UEVM","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"id":"iNisHnvRsHEK","trusted":true},"cell_type":"code","source":"x_test = test_df['comment_text'].values","execution_count":null,"outputs":[]},{"metadata":{"id":"Su5kx6yjsHEQ","trusted":true},"cell_type":"code","source":"x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\nx_testing = sequence.pad_sequences(x_test_tokenized ,maxlen =max_text_length)","execution_count":null,"outputs":[]},{"metadata":{"id":"4u5at1KRsHEU","outputId":"4427f543-62e4-46d0-b345-daedcfadfb69","trusted":true},"cell_type":"code","source":"y_testing =model.predict(x_testing , verbose = 1 , batch_size= 32)","execution_count":null,"outputs":[]},{"metadata":{"id":"kvgZCuCZsHEZ","outputId":"50475bfe-3cd4-4eae-eb8b-b0242456c839","trusted":true},"cell_type":"code","source":"y_testing.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"N1dgQKexOyHF","outputId":"51cb5874-31f9-4c4f-e0d8-5ce550c29fa7","trusted":true},"cell_type":"code","source":"y_testing[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"rYejiiqUG64C","outputId":"b1203e0c-ddc0-4978-856c-b4b8b0589b6d","trusted":true},"cell_type":"code","source":"test_df['Toxic'] = ['not toxic' if x < .5 else 'toxic' for x in y_testing]\ntest_df[[ 'comment_text' , 'Toxic']].head(20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}