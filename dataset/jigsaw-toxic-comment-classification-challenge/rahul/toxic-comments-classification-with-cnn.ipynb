{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU,Conv1D,MaxPooling1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\nsubmit = pd.read_csv('../input/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]], test_size = 0.10, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_sentences_train = X_train[\"comment_text\"]\nlist_sentences_test = X_test[\"comment_text\"]\nlist_sentences_submit = submit[\"comment_text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features,char_level=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(list(list_sentences_train))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_sentences_test = tokenizer.texts_to_sequences(list_sentences_test)\nlist_tokenized_submit = tokenizer.texts_to_sequences(list_sentences_submit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 500\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_sentences_test, maxlen=maxlen)\nX_sub = pad_sequences(list_tokenized_submit, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]\nplt.hist(totalNumWords)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = Input(shape=(maxlen, ))\n\nembed_size = 240\nx = Embedding(len(tokenizer.word_index)+1, embed_size)(inp)\n\nx = Conv1D(filters=100,kernel_size=4,padding='same', activation='relu')(x)\n\nx=MaxPooling1D(pool_size=4)(x)\n\nx = Bidirectional(GRU(60, return_sequences=True,name='lstm_layer',dropout=0.2,recurrent_dropout=0.2))(x)\n\nx = GlobalMaxPool1D()(x)\n\nx = Dense(50, activation=\"relu\")(x)\n\nx = Dropout(0.2)(x)\nx = Dense(6, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                 metrics=['accuracy'])\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 1\nhist = model.fit(X_t,y_train, batch_size=batch_size, epochs=epochs,validation_data=(X_te,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def toxicity_level(string):\n    \"\"\"\n    Return toxicity probability based on inputed string.\n    \"\"\"\n    # Process string\n    new_string = [string]\n    new_string = tokenizer.texts_to_sequences(new_string)\n    new_string = pad_sequences(new_string, maxlen=500, padding='post', truncating='post')\n    \n    # Predict\n    prediction = model.predict(new_string)\n    \n    # Print output\n    print(\"Toxicity levels for '{}':\".format(string))\n    print('Toxic:         {:.0%}'.format(prediction[0][0]))\n    print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))\n    print('Obscene:       {:.0%}'.format(prediction[0][2]))\n    print('Threat:        {:.0%}'.format(prediction[0][3]))\n    print('Insult:        {:.0%}'.format(prediction[0][4]))\n    print('Identity Hate: {:.0%}'.format(prediction[0][5]))\n    print()\n    \n    return\n\ntoxicity_level('go jump off a bridge jerk')\ntoxicity_level('i will kill you')\ntoxicity_level('have a nice day')\ntoxicity_level('hola, como estas')\ntoxicity_level('hola mierda joder')\ntoxicity_level('fuck off!!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_metrics(accuracy):\n    print(\"Simple cnn model performance\")\n    print('Accuracy: ', np.round(accuracy, 4))\n    print('\\n')\n    \nloss, accuracy = model.evaluate(X_t, y_train)\nprint_metrics(accuracy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}