{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNGRU, Conv1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import LearningRateScheduler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nprint(tf.__version__)\ntf.test.is_gpu_available(\n    cuda_only=False,\n    min_cuda_compute_capability=None\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"EMBEDDING_FILES = [\n        '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec',\n    '../input/glove840b300dtxt/glove.840B.300d.txt'\n]\n\nBATCH_SIZE = 512\nLSTM_UNITS = 128\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nEPOCHS = 4\nMAX_LEN = 220\n\n\nTEXT_COLUMN = 'comment_text'\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\nCHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\nsubmission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n\ny = train_df[list_classes].values\nx_train = train_df[TEXT_COLUMN].astype(str)\ny_train = y\nx_test = test_df[TEXT_COLUMN].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in f)\n\n\ndef build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in word_index.items():\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            pass\n    return embedding_matrix\n\ndef build_model(embedding_matrix):\n    words = Input(shape=(None,))\n    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n    x = SpatialDropout1D(0.2)(x)\n    x = Bidirectional(CuDNNGRU(LSTM_UNITS, return_sequences=True))(x)\n    x = Bidirectional(CuDNNGRU(LSTM_UNITS, return_sequences=True))(x)\n\n    hidden = concatenate([\n        GlobalMaxPooling1D()(x),\n        GlobalAveragePooling1D()(x),\n    ])\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    result = Dense(6, activation='sigmoid')(hidden)\n    \n    \n    model = Model(inputs=words, outputs=result)\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE)\ntokenizer.fit_on_texts(list(x_train) + list(x_test))\n\nx_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\nx_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\nx_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nembedding_matrix = np.concatenate(\n    [build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 5\nSEEDS = 10\n\npred = 0\n\nfor ii in range(SEEDS):\n    model = build_model(embedding_matrix)\n    for global_epoch in range(EPOCHS):\n        print(global_epoch)\n        model.fit(\n                    X_train,\n                    Y_train,\n                    validation_data = (X_valid, Y_valid),\n                    batch_size=128,\n                    epochs=1,\n                    verbose=2,\n                    callbacks=[\n                        LearningRateScheduler(lambda _: 1e-3 * (0.55 ** global_epoch))\n                    ]\n                )\n        val_preds_3 = model.predict(X_valid)\n        AUC = 0\n        for i in range(6):\n             AUC += roc_auc_score(Y_valid[:,i], val_preds_3[:,i])/6.\n        print(AUC)\n\n    pred += model.predict(x_test, batch_size = 1024, verbose = 1)/SEEDS\n    model.save_weights('model_weights_'+str(ii)+'.h5')\n    os.system('gzip '+'model_weights_'+str(ii)+'.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission[list_classes] = (pred)\nsubmission.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}