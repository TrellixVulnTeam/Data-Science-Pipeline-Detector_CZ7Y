{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> DistilBERT for multilabel classification with Catalyst and HuggingFace\n##  <center>  Toxic comments classification","metadata":{"papermill":{"duration":0.012527,"end_time":"2020-08-25T11:30:15.448725","exception":false,"start_time":"2020-08-25T11:30:15.436198","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pip install catalyst=='20.07'","metadata":{"execution":{"iopub.status.busy":"2021-08-07T20:40:33.707151Z","iopub.execute_input":"2021-08-07T20:40:33.707447Z","iopub.status.idle":"2021-08-07T20:40:43.880894Z","shell.execute_reply.started":"2021-08-07T20:40:33.707375Z","shell.execute_reply":"2021-08-07T20:40:43.879997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Python \nimport os\nimport warnings\nimport logging\nfrom typing import Mapping, List, Union, Optional, Tuple\nfrom pprint import pprint\n\n# Numpy, Pandas, Sklearn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# PyTorch \nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# Transformers \nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\n# Catalyst\nimport catalyst\nfrom catalyst.dl import SupervisedRunner\n# this will appear in Catalyst 20.08\n# from catalyst.dl.callbacks.metrics.accuracy import MultiLabelAccuracyCallback\nfrom catalyst.dl.callbacks import OptimizerCallback, CheckpointCallback, InferCallback\nfrom catalyst.dl.utils import plot_metrics\nfrom catalyst.utils import set_global_seed, prepare_cudnn","metadata":{"papermill":{"duration":10.915556,"end_time":"2020-08-25T11:30:26.375522","exception":false,"start_time":"2020-08-25T11:30:15.459966","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:40:47.789097Z","iopub.execute_input":"2021-08-07T20:40:47.789523Z","iopub.status.idle":"2021-08-07T20:40:56.506008Z","shell.execute_reply.started":"2021-08-07T20:40:47.789481Z","shell.execute_reply":"2021-08-07T20:40:56.504984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catalyst.__version__","metadata":{"papermill":{"duration":0.023095,"end_time":"2020-08-25T11:30:26.412749","exception":false,"start_time":"2020-08-25T11:30:26.389654","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:41:09.64082Z","iopub.execute_input":"2021-08-07T20:41:09.641196Z","iopub.status.idle":"2021-08-07T20:41:09.665768Z","shell.execute_reply.started":"2021-08-07T20:41:09.641156Z","shell.execute_reply":"2021-08-07T20:41:09.664574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Setup**","metadata":{"papermill":{"duration":0.011011,"end_time":"2020-08-25T11:30:26.43529","exception":false,"start_time":"2020-08-25T11:30:26.424279","status":"completed"},"tags":[]}},{"cell_type":"code","source":"MODEL_NAME = 'distilbert-base-uncased' # pretrained model from Transformers\nLOG_DIR = \"./logdir\"                   # for training logs and tensorboard visualizations\nNUM_EPOCHS = 3                         # smth around 2-6 epochs is typically fine when finetuning transformers\nBATCH_SIZE = 96                        # depends on your available GPU memory (in combination with max seq length)\nMAX_SEQ_LENGTH = 256                   # depends on your available GPU memory (in combination with batch size)\nLEARN_RATE = 3e-5                      # learning rate is typically ~1e-5 for transformers\nACCUM_STEPS = 4                        # one optimization step for that many backward passes\nSEED = 17                              # random seed for reproducibility","metadata":{"papermill":{"duration":0.020004,"end_time":"2020-08-25T11:30:26.466809","exception":false,"start_time":"2020-08-25T11:30:26.446805","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:41:16.488423Z","iopub.execute_input":"2021-08-07T20:41:16.48876Z","iopub.status.idle":"2021-08-07T20:41:16.49318Z","shell.execute_reply.started":"2021-08-07T20:41:16.488727Z","shell.execute_reply":"2021-08-07T20:41:16.492366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dataset**\n\nToxic comments - [competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\nGiven text of a comment, we need to classify it into several toxicity categories: 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', or 'identity_hate'.","metadata":{"papermill":{"duration":0.011117,"end_time":"2020-08-25T11:30:26.489273","exception":false,"start_time":"2020-08-25T11:30:26.478156","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# to reproduce, download the data and customize this path\nPATH_TO_DATA = '../input/jigsaw-toxic-comment-classification-challenge/'\nTEXT_FIELD = 'comment_text'\nTARGET_FIELDS = ['toxic','severe_toxic','obscene','threat','insult', 'identity_hate']\nNUM_CLASSES = len(TARGET_FIELDS)\nPRED_THRES = 0.4   ","metadata":{"papermill":{"duration":0.020142,"end_time":"2020-08-25T11:30:26.520669","exception":false,"start_time":"2020-08-25T11:30:26.500527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:41:25.428272Z","iopub.execute_input":"2021-08-07T20:41:25.428634Z","iopub.status.idle":"2021-08-07T20:41:25.433942Z","shell.execute_reply.started":"2021-08-07T20:41:25.4286Z","shell.execute_reply":"2021-08-07T20:41:25.43273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_DATA + 'train.csv.zip', index_col='id')\ntest_df = pd.read_csv(PATH_TO_DATA + 'test.csv.zip', index_col='id')","metadata":{"papermill":{"duration":2.413835,"end_time":"2020-08-25T11:30:28.945251","exception":false,"start_time":"2020-08-25T11:30:26.531416","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:41:44.168641Z","iopub.execute_input":"2021-08-07T20:41:44.169002Z","iopub.status.idle":"2021-08-07T20:41:48.366058Z","shell.execute_reply.started":"2021-08-07T20:41:44.168971Z","shell.execute_reply":"2021-08-07T20:41:48.365197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"papermill":{"duration":0.057753,"end_time":"2020-08-25T11:30:29.014788","exception":false,"start_time":"2020-08-25T11:30:28.957035","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:41:51.797556Z","iopub.execute_input":"2021-08-07T20:41:51.797894Z","iopub.status.idle":"2021-08-07T20:41:51.838932Z","shell.execute_reply.started":"2021-08-07T20:41:51.797862Z","shell.execute_reply":"2021-08-07T20:41:51.838038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"papermill":{"duration":0.04651,"end_time":"2020-08-25T11:30:29.074788","exception":false,"start_time":"2020-08-25T11:30:29.028278","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:41:58.57868Z","iopub.execute_input":"2021-08-07T20:41:58.579042Z","iopub.status.idle":"2021-08-07T20:41:58.608798Z","shell.execute_reply.started":"2021-08-07T20:41:58.579012Z","shell.execute_reply":"2021-08-07T20:41:58.60776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"papermill":{"duration":0.031202,"end_time":"2020-08-25T11:30:29.117598","exception":false,"start_time":"2020-08-25T11:30:29.086396","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:42:01.377394Z","iopub.execute_input":"2021-08-07T20:42:01.377715Z","iopub.status.idle":"2021-08-07T20:42:01.392954Z","shell.execute_reply.started":"2021-08-07T20:42:01.377684Z","shell.execute_reply":"2021-08-07T20:42:01.391994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_df[TEXT_FIELD],\n                                                      train_df[TARGET_FIELDS], \n                                                      test_size=0.1, \n                                                      random_state=17)\nX_test = test_df[TEXT_FIELD]","metadata":{"papermill":{"duration":0.102631,"end_time":"2020-08-25T11:30:29.231771","exception":false,"start_time":"2020-08-25T11:30:29.12914","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:42:05.727261Z","iopub.execute_input":"2021-08-07T20:42:05.727586Z","iopub.status.idle":"2021-08-07T20:42:05.792549Z","shell.execute_reply.started":"2021-08-07T20:42:05.727554Z","shell.execute_reply":"2021-08-07T20:42:05.791689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train), len(X_valid), len(X_test)","metadata":{"papermill":{"duration":0.024087,"end_time":"2020-08-25T11:30:29.269624","exception":false,"start_time":"2020-08-25T11:30:29.245537","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:42:12.677877Z","iopub.execute_input":"2021-08-07T20:42:12.678239Z","iopub.status.idle":"2021-08-07T20:42:12.684756Z","shell.execute_reply.started":"2021-08-07T20:42:12.678208Z","shell.execute_reply":"2021-08-07T20:42:12.683877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Torch Dataset\n\nThis is left for user to be defined. Catalyst will take care of the rest. ","metadata":{"papermill":{"duration":0.012302,"end_time":"2020-08-25T11:30:29.294752","exception":false,"start_time":"2020-08-25T11:30:29.28245","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class TextClassificationDataset(Dataset):\n    \"\"\"\n    Wrapper around Torch Dataset to perform text classification\n    \"\"\"\n    def __init__(self,\n                 texts: List[str],\n                 labels: np.ndarray = None,\n                 max_seq_length: int = 512,\n                 model_name: str = 'distilbert-base-uncased'):\n        \"\"\"\n        Args:\n            texts (List[str]): a list with texts to classify or to train the\n                classifier on\n            labels List[str]: \n            max_seq_length (int): maximal sequence length in tokens,\n                texts will be stripped to this length\n            model_name (str): transformer model name, needed to perform\n                appropriate tokenization\n\n        \"\"\"\n\n        self.texts = texts\n        self.labels = labels\n        self.max_seq_length = max_seq_length\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        # suppresses tokenizer warnings\n        logging.getLogger(\n            \"transformers.tokenization_utils\").setLevel(logging.FATAL)\n\n    def __len__(self):\n        \"\"\"\n        Returns:\n            int: length of the dataset\n        \"\"\"\n        return len(self.texts)\n\n    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n        \"\"\"Gets element of the dataset\n\n        Args:\n            index (int): index of the element in the dataset\n        Returns:\n            Single element by index\n        \"\"\"\n\n        # encoding the text\n        x = self.texts[index]\n        \n        # a dictionary with `input_ids` and `attention_mask` as keys\n        output_dict = self.tokenizer.encode_plus(\n            x,\n            add_special_tokens=True,\n            pad_to_max_length=True,\n            max_length=self.max_seq_length,\n            return_tensors=\"pt\",\n            return_attention_mask=True\n        )\n        \n        # for Catalyst, there needs to be a key called features\n        output_dict['features'] = output_dict['input_ids'].squeeze(0)\n        del output_dict['input_ids']\n        \n        # encoding target\n        if self.labels is not None:\n            output_dict[\"targets\"] = torch.from_numpy(self.labels[index]).float()\n\n        return output_dict","metadata":{"papermill":{"duration":0.0294,"end_time":"2020-08-25T11:30:29.336698","exception":false,"start_time":"2020-08-25T11:30:29.307298","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:43:03.862277Z","iopub.execute_input":"2021-08-07T20:43:03.862631Z","iopub.status.idle":"2021-08-07T20:43:03.872048Z","shell.execute_reply.started":"2021-08-07T20:43:03.862602Z","shell.execute_reply":"2021-08-07T20:43:03.871105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Torch Datasets with train, validation, and test data.**","metadata":{"papermill":{"duration":0.011467,"end_time":"2020-08-25T11:30:29.360286","exception":false,"start_time":"2020-08-25T11:30:29.348819","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_dataset = TextClassificationDataset(\n    texts=X_train.values.tolist(),\n    labels=y_train.values,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\nvalid_dataset = TextClassificationDataset(\n    texts=X_valid.values.tolist(),\n    labels=y_valid.values,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\ntest_dataset = TextClassificationDataset(\n    texts=X_test.values.tolist(),\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)","metadata":{"papermill":{"duration":8.832516,"end_time":"2020-08-25T11:30:38.204721","exception":false,"start_time":"2020-08-25T11:30:29.372205","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:43:37.703914Z","iopub.execute_input":"2021-08-07T20:43:37.704269Z","iopub.status.idle":"2021-08-07T20:43:46.065883Z","shell.execute_reply.started":"2021-08-07T20:43:37.704237Z","shell.execute_reply":"2021-08-07T20:43:46.064963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the training dataset instances:","metadata":{"papermill":{"duration":0.013074,"end_time":"2020-08-25T11:30:38.231445","exception":false,"start_time":"2020-08-25T11:30:38.218371","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df.iloc[0]","metadata":{"papermill":{"duration":0.024233,"end_time":"2020-08-25T11:30:38.268579","exception":false,"start_time":"2020-08-25T11:30:38.244346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:43:46.067486Z","iopub.execute_input":"2021-08-07T20:43:46.067824Z","iopub.status.idle":"2021-08-07T20:43:46.077595Z","shell.execute_reply.started":"2021-08-07T20:43:46.067774Z","shell.execute_reply":"2021-08-07T20:43:46.076651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint(train_dataset[0])","metadata":{"papermill":{"duration":0.086227,"end_time":"2020-08-25T11:30:38.367763","exception":false,"start_time":"2020-08-25T11:30:38.281536","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:44:05.949215Z","iopub.execute_input":"2021-08-07T20:44:05.949657Z","iopub.status.idle":"2021-08-07T20:44:06.048938Z","shell.execute_reply.started":"2021-08-07T20:44:05.94962Z","shell.execute_reply":"2021-08-07T20:44:06.046048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Finally, we define standard PyTorch loaders. This dictionary will be fed to Catalyst.**","metadata":{"papermill":{"duration":0.012335,"end_time":"2020-08-25T11:30:38.393458","exception":false,"start_time":"2020-08-25T11:30:38.381123","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_val_loaders = {\n    \"train\": DataLoader(dataset=train_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=True),\n    \"valid\": DataLoader(dataset=valid_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False)    \n}","metadata":{"papermill":{"duration":0.022125,"end_time":"2020-08-25T11:30:38.428818","exception":false,"start_time":"2020-08-25T11:30:38.406693","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:44:13.299155Z","iopub.execute_input":"2021-08-07T20:44:13.299524Z","iopub.status.idle":"2021-08-07T20:44:13.304232Z","shell.execute_reply.started":"2021-08-07T20:44:13.299491Z","shell.execute_reply":"2021-08-07T20:44:13.303255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The model","metadata":{"papermill":{"duration":0.01316,"end_time":"2020-08-25T11:30:38.454935","exception":false,"start_time":"2020-08-25T11:30:38.441775","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class BertForSequenceClassification(nn.Module):\n    \"\"\"\n    Simplified version of the same class by HuggingFace.\n    See transformers/modeling_distilbert.py in the transformers repository.\n    \"\"\"\n\n    def __init__(self, pretrained_model_name: str, num_classes: int = None, dropout: float = 0.3):\n        \"\"\"\n        Args:\n            pretrained_model_name (str): HuggingFace model name.\n                See transformers/modeling_auto.py\n            num_classes (int): the number of class labels\n                in the classification task\n        \"\"\"\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(\n            pretrained_model_name, num_labels=num_classes)\n\n        self.model = AutoModel.from_pretrained(pretrained_model_name,\n                                                    config=config)\n#         self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n        self.classifier = nn.Linear(config.hidden_size, num_classes)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, features, attention_mask=None, head_mask=None):\n        \"\"\"Compute class probabilities for the input sequence.\n\n        Args:\n            features (torch.Tensor): ids of each token,\n                size ([bs, seq_length]\n            attention_mask (torch.Tensor): binary tensor, used to select\n                tokens which are used to compute attention scores\n                in the self-attention heads, size [bs, seq_length]\n            head_mask (torch.Tensor): 1.0 in head_mask indicates that\n                we keep the head, size: [num_heads]\n                or [num_hidden_layers x num_heads]\n        Returns:\n            PyTorch Tensor with predicted class probabilities\n        \"\"\"\n        assert attention_mask is not None, \"attention mask is none\"\n        \n        bert_output = self.model(input_ids=features,\n                                            attention_mask=attention_mask,\n                                            head_mask=head_mask)\n        # we only need the hidden state here and don't need\n        # transformer output, so index 0\n        seq_output = bert_output[0]  # (bs, seq_len, dim)\n        # mean pooling, i.e. getting average representation for all tokens\n        pooled_output = seq_output.mean(axis=1)  # (bs, dim)\n        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n        logits = self.classifier(pooled_output)  # (bs, dim)\n\n        return logits","metadata":{"papermill":{"duration":0.027685,"end_time":"2020-08-25T11:30:38.496244","exception":false,"start_time":"2020-08-25T11:30:38.468559","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:44:38.68217Z","iopub.execute_input":"2021-08-07T20:44:38.682517Z","iopub.status.idle":"2021-08-07T20:44:38.691743Z","shell.execute_reply.started":"2021-08-07T20:44:38.682483Z","shell.execute_reply":"2021-08-07T20:44:38.690826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification(pretrained_model_name=MODEL_NAME,\n                                      num_classes=NUM_CLASSES)","metadata":{"papermill":{"duration":137.750141,"end_time":"2020-08-25T11:32:56.259335","exception":false,"start_time":"2020-08-25T11:30:38.509194","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:44:48.763368Z","iopub.execute_input":"2021-08-07T20:44:48.763693Z","iopub.status.idle":"2021-08-07T20:45:03.192336Z","shell.execute_reply.started":"2021-08-07T20:44:48.763662Z","shell.execute_reply":"2021-08-07T20:45:03.19155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d = next(iter(train_val_loaders['train']))\n# p = model(d['features'], d['attention_mask'])\n# criterion(p, d['targets'])","metadata":{"execution":{"iopub.execute_input":"2020-08-25T11:32:56.290304Z","iopub.status.busy":"2020-08-25T11:32:56.289634Z","iopub.status.idle":"2020-08-25T11:32:56.294135Z","shell.execute_reply":"2020-08-25T11:32:56.293606Z"},"papermill":{"duration":0.020937,"end_time":"2020-08-25T11:32:56.29424","exception":false,"start_time":"2020-08-25T11:32:56.273303","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training\n\nFirst we specify optimizer and scheduler (pure PyTorch). Then Catalyst stuff.","metadata":{"papermill":{"duration":0.013304,"end_time":"2020-08-25T11:32:56.32084","exception":false,"start_time":"2020-08-25T11:32:56.307536","status":"completed"},"tags":[]}},{"cell_type":"code","source":"criterion = torch.nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)","metadata":{"papermill":{"duration":0.02284,"end_time":"2020-08-25T11:32:56.35719","exception":false,"start_time":"2020-08-25T11:32:56.33435","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:45:03.193758Z","iopub.execute_input":"2021-08-07T20:45:03.194271Z","iopub.status.idle":"2021-08-07T20:45:03.201089Z","shell.execute_reply.started":"2021-08-07T20:45:03.19423Z","shell.execute_reply":"2021-08-07T20:45:03.200275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Implementation of multilabel accuracy is under development in Catalyst, so we've copied the code for `MultiLabelAccuracyCallback` and dependencies here (branch [metrics-update-2](https://github.com/catalyst-team/catalyst/blob/feature/metrics-update-2/catalyst/dl/callbacks/metrics/accuracy.py)).","metadata":{"papermill":{"duration":0.013184,"end_time":"2020-08-25T11:32:56.383628","exception":false,"start_time":"2020-08-25T11:32:56.370444","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from catalyst.core import MetricCallback\nfrom catalyst.utils.torch import get_activation_fn\n\ndef preprocess_multi_label_metrics(\n    outputs: torch.Tensor,\n    targets: torch.Tensor,\n    weights: Optional[torch.Tensor] = None,\n) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    General preprocessing and check for multi-label-based metrics.\n    Args:\n        outputs (torch.Tensor): NxK tensor that for each of the N examples\n            indicates the probability of the example belonging to each of\n            the K classes, according to the model.\n        targets (torch.Tensor): binary NxK tensor that encodes which of the K\n            classes are associated with the N-th input\n            (eg: a row [0, 1, 0, 1] indicates that the example is\n            associated with classes 2 and 4)\n        weights (torch.Tensor): importance for each sample\n    Returns:\n        processed ``outputs`` and ``targets``\n        with [batch_size; num_classes] shape\n    \"\"\"\n    if not torch.is_tensor(outputs):\n        outputs = torch.from_numpy(outputs)\n    if not torch.is_tensor(targets):\n        targets = torch.from_numpy(targets)\n    if weights is not None:\n        if not torch.is_tensor(weights):\n            weights = torch.from_numpy(weights)\n        weights = weights.squeeze()\n\n    if outputs.dim() == 1:\n        outputs = outputs.view(-1, 1)\n    else:\n        assert outputs.dim() == 2, (\n            \"wrong `outputs` size \"\n            \"(should be 1D or 2D with one column per class)\"\n        )\n\n    if targets.dim() == 1:\n        targets = targets.view(-1, 1)\n    else:\n        assert targets.dim() == 2, (\n            \"wrong `targets` size \"\n            \"(should be 1D or 2D with one column per class)\"\n        )\n\n    if weights is not None:\n        assert weights.dim() == 1, \"Weights dimension should be 1\"\n        assert weights.numel() == targets.size(\n            0\n        ), \"Weights dimension 1 should be the same as that of target\"\n        assert torch.min(weights) >= 0, \"Weight should be non-negative only\"\n\n    assert torch.equal(\n        targets ** 2, targets\n    ), \"targets should be binary (0 or 1)\"\n\n    return outputs, targets, weights\n\ndef multi_label_accuracy(\n    outputs: torch.Tensor,\n    targets: torch.Tensor,\n    threshold: Union[float, torch.Tensor],\n    activation: Optional[str] = None,\n) -> torch.Tensor:\n    \"\"\"\n    Computes multi-label accuracy for the specified activation and threshold.\n    Args:\n        outputs (torch.Tensor): NxK tensor that for each of the N examples\n            indicates the probability of the example belonging to each of\n            the K classes, according to the model.\n        targets (torch.Tensor): binary NxK tensort that encodes which of the K\n            classes are associated with the N-th input\n            (eg: a row [0, 1, 0, 1] indicates that the example is\n            associated with classes 2 and 4)\n        threshold (float): threshold for for model output\n        activation (str): activation to use for model output\n    Returns:\n        computed multi-label accuracy\n    \"\"\"\n    outputs, targets, _ = preprocess_multi_label_metrics(\n        outputs=outputs, targets=targets\n    )\n    activation_fn = get_activation_fn(activation)\n    outputs = activation_fn(outputs)\n\n    outputs = (outputs > threshold).long()\n    output = (targets.long() == outputs.long()).sum().float() / np.prod(\n        targets.shape\n    )\n    return output\n\n\nclass MultiLabelAccuracyCallback(MetricCallback):\n    \"\"\"Accuracy metric callback.\n    Computes multi-class accuracy@topk for the specified values of `topk`.\n    .. note::\n        For multi-label accuracy please use\n        `catalyst.dl.callbacks.metrics.MultiLabelAccuracyCallback`\n    \"\"\"\n\n    def __init__(\n        self,\n        input_key: str = \"targets\",\n        output_key: str = \"logits\",\n        prefix: str = \"multi_label_accuracy\",\n        threshold: float = None,\n        activation: str = \"Sigmoid\",\n    ):\n        \"\"\"\n        Args:\n            input_key (str): input key to use for accuracy calculation;\n                specifies our `y_true`\n            output_key (str): output key to use for accuracy calculation;\n                specifies our `y_pred`\n            prefix (str): key for the metric's name\n            threshold (float): threshold for for model output\n            activation (str): An torch.nn activation applied to the outputs.\n                Must be one of ``\"none\"``, ``\"Sigmoid\"``, or ``\"Softmax\"``\n        \"\"\"\n        super().__init__(\n            prefix=prefix,\n            metric_fn=multi_label_accuracy,\n            input_key=input_key,\n            output_key=output_key,\n            threshold=threshold,\n            activation=activation,\n        )","metadata":{"papermill":{"duration":0.04087,"end_time":"2020-08-25T11:32:56.437232","exception":false,"start_time":"2020-08-25T11:32:56.396362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:45:06.24949Z","iopub.execute_input":"2021-08-07T20:45:06.249839Z","iopub.status.idle":"2021-08-07T20:45:06.265275Z","shell.execute_reply.started":"2021-08-07T20:45:06.249801Z","shell.execute_reply":"2021-08-07T20:45:06.264156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To run Deep Learning experiments, Catalyst resorts to the [`Runner`](https://catalyst-team.github.io/catalyst/api/dl.html#catalyst.dl.core.runner.Runner) abstraction, in particular, to [`SupervisedRunner`](https://catalyst-team.github.io/catalyst/api/dl.html#module-catalyst.dl.runner.supervised).\n\n`SupervisedRunner` implements the following methods:\n - `train` - starts the training process of the model\n - `predict_loader` - makes a prediction on the whole loader with the specified model\n - `infer` - makes the inference on the model\n \nTo train the model within this interface you pass the following to the `train` method:\n - model (`torch.nn.Module`) – PyTorch model to train\n - criterion (`nn.Module`) – PyTorch criterion function for training\n - optimizer (`optim.Optimizer`) – PyTorch optimizer for training\n - loaders (dict) – dictionary containing one or several `torch.utils.data.DataLoader` for training and validation\n - logdir (str) – path to output directory. There Catalyst will write logs, will dump the best model and the actual code to train the model\n - callbacks – list of Catalyst callbacks\n - scheduler (`optim.lr_scheduler._LRScheduler`) – PyTorch scheduler for training\n - ...\n \nIn our case we'll pass the created `DistilBertForSequenceClassification` model, cross-entropy criterion, Adam optimizer, scheduler and data loaders that we created earlier. Also, we'll be tracking accuracy and thus will need `AccuracyCallback`. To perform batch accumulation, we'll be using `OptimizationCallback`.\n\nThere are many more useful [callbacks](https://catalyst-team.github.io/catalyst/api/dl.html#module-catalyst.dl.callbacks.checkpoint) implemented, also check out [Catalyst examples](https://github.com/catalyst-team/catalyst/tree/master/examples/notebooks).","metadata":{"papermill":{"duration":0.012905,"end_time":"2020-08-25T11:32:56.463615","exception":false,"start_time":"2020-08-25T11:32:56.45071","status":"completed"},"tags":[]}},{"cell_type":"code","source":"os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"    # can be changed in case of multiple GPUs onboard\nset_global_seed(SEED)                       # reproducibility\nprepare_cudnn(deterministic=True)           # reproducibility","metadata":{"papermill":{"duration":0.380064,"end_time":"2020-08-25T11:32:56.856711","exception":false,"start_time":"2020-08-25T11:32:56.476647","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:45:17.498968Z","iopub.execute_input":"2021-08-07T20:45:17.499366Z","iopub.status.idle":"2021-08-07T20:45:17.553018Z","shell.execute_reply.started":"2021-08-07T20:45:17.499334Z","shell.execute_reply":"2021-08-07T20:45:17.552024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# here we specify that we pass masks to the runner. So model's forward method will be called with\n# these arguments passed to it. \nrunner = SupervisedRunner(\n    input_key=(\n        \"features\",\n        \"attention_mask\"\n    )\n)\n\n\n# model training\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=train_val_loaders,\n    callbacks=[\n        MultiLabelAccuracyCallback(threshold=PRED_THRES),\n        OptimizerCallback(accumulation_steps=ACCUM_STEPS)\n    ],\n    logdir=LOG_DIR,\n    num_epochs=NUM_EPOCHS,\n    verbose=True\n)","metadata":{"papermill":{"duration":6546.546907,"end_time":"2020-08-25T13:22:03.418114","exception":false,"start_time":"2020-08-25T11:32:56.871207","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-08-07T20:45:19.612674Z","iopub.execute_input":"2021-08-07T20:45:19.613047Z","iopub.status.idle":"2021-08-07T22:15:58.358263Z","shell.execute_reply.started":"2021-08-07T20:45:19.613015Z","shell.execute_reply":"2021-08-07T22:15:58.356509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!du -hc $LOG_DIR","metadata":{"papermill":{"duration":1.567201,"end_time":"2020-08-25T13:22:05.649633","exception":false,"start_time":"2020-08-25T13:22:04.082432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:15:58.360171Z","iopub.execute_input":"2021-08-07T22:15:58.360528Z","iopub.status.idle":"2021-08-07T22:15:59.132211Z","shell.execute_reply.started":"2021-08-07T22:15:58.360485Z","shell.execute_reply":"2021-08-07T22:15:59.131105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls $LOG_DIR/checkpoints","metadata":{"papermill":{"duration":1.285834,"end_time":"2020-08-25T13:22:07.497808","exception":false,"start_time":"2020-08-25T13:22:06.211974","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:15:59.134774Z","iopub.execute_input":"2021-08-07T22:15:59.135253Z","iopub.status.idle":"2021-08-07T22:16:03.592866Z","shell.execute_reply.started":"2021-08-07T22:15:59.135209Z","shell.execute_reply":"2021-08-07T22:16:03.591749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"papermill":{"duration":1.308851,"end_time":"2020-08-25T13:22:09.402851","exception":false,"start_time":"2020-08-25T13:22:08.094","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:16:03.597183Z","iopub.execute_input":"2021-08-07T22:16:03.597484Z","iopub.status.idle":"2021-08-07T22:16:04.380284Z","shell.execute_reply.started":"2021-08-07T22:16:03.597452Z","shell.execute_reply":"2021-08-07T22:16:04.379155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"papermill":{"duration":1.054064,"end_time":"2020-08-25T13:22:11.054191","exception":false,"start_time":"2020-08-25T13:22:10.000127","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:16:04.383958Z","iopub.execute_input":"2021-08-07T22:16:04.38429Z","iopub.status.idle":"2021-08-07T22:16:06.235851Z","shell.execute_reply.started":"2021-08-07T22:16:04.384256Z","shell.execute_reply":"2021-08-07T22:16:06.234814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"papermill":{"duration":1.315963,"end_time":"2020-08-25T13:22:12.93052","exception":false,"start_time":"2020-08-25T13:22:11.614557","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:16:06.237596Z","iopub.execute_input":"2021-08-07T22:16:06.237997Z","iopub.status.idle":"2021-08-07T22:16:07.006241Z","shell.execute_reply.started":"2021-08-07T22:16:06.237964Z","shell.execute_reply":"2021-08-07T22:16:07.005142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metrics(\n    logdir=LOG_DIR,\n    step='epoch',\n    metrics=['accuracy']\n)","metadata":{"papermill":{"duration":2.267205,"end_time":"2020-08-25T13:22:16.904773","exception":false,"start_time":"2020-08-25T13:22:14.637568","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:16:07.008196Z","iopub.execute_input":"2021-08-07T22:16:07.0086Z","iopub.status.idle":"2021-08-07T22:16:08.597536Z","shell.execute_reply.started":"2021-08-07T22:16:07.008554Z","shell.execute_reply":"2021-08-07T22:16:08.596688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference for the test set","metadata":{"papermill":{"duration":0.607076,"end_time":"2020-08-25T13:22:18.10429","exception":false,"start_time":"2020-08-25T13:22:17.497214","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Let's create a Torch loader for the test set and launch `infer` to actually make predictions fot the test set. First, we load the best model checkpoint, then make inference with this model.","metadata":{"papermill":{"duration":0.60429,"end_time":"2020-08-25T13:22:19.349742","exception":false,"start_time":"2020-08-25T13:22:18.745452","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_loaders = {\n    \"test\": DataLoader(dataset=test_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False) \n}","metadata":{"papermill":{"duration":0.663695,"end_time":"2020-08-25T13:22:20.606774","exception":false,"start_time":"2020-08-25T13:22:19.943079","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:16:08.600499Z","iopub.execute_input":"2021-08-07T22:16:08.600889Z","iopub.status.idle":"2021-08-07T22:16:08.605661Z","shell.execute_reply.started":"2021-08-07T22:16:08.600812Z","shell.execute_reply":"2021-08-07T22:16:08.604491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrunner.infer(\n    model=model,\n    loaders=test_loaders,\n    callbacks=[\n        CheckpointCallback(\n            resume=f\"{LOG_DIR}/checkpoints/best.pth\"\n        ),\n        InferCallback(),\n    ],   \n    verbose=True\n)","metadata":{"papermill":{"duration":1000.005689,"end_time":"2020-08-25T13:39:01.203657","exception":false,"start_time":"2020-08-25T13:22:21.197968","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:16:08.607494Z","iopub.execute_input":"2021-08-07T22:16:08.607879Z","iopub.status.idle":"2021-08-07T22:27:10.919949Z","shell.execute_reply.started":"2021-08-07T22:16:08.607841Z","shell.execute_reply":"2021-08-07T22:27:10.918887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probs = runner.callbacks[0].predictions['logits']","metadata":{"papermill":{"duration":0.891843,"end_time":"2020-08-25T13:39:02.882583","exception":false,"start_time":"2020-08-25T13:39:01.99074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:10.921679Z","iopub.execute_input":"2021-08-07T22:27:10.922091Z","iopub.status.idle":"2021-08-07T22:27:10.927211Z","shell.execute_reply.started":"2021-08-07T22:27:10.922049Z","shell.execute_reply":"2021-08-07T22:27:10.926185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probs.shape","metadata":{"papermill":{"duration":0.841877,"end_time":"2020-08-25T13:39:04.651996","exception":false,"start_time":"2020-08-25T13:39:03.810119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:10.928911Z","iopub.execute_input":"2021-08-07T22:27:10.929297Z","iopub.status.idle":"2021-08-07T22:27:10.950159Z","shell.execute_reply.started":"2021-08-07T22:27:10.929258Z","shell.execute_reply":"2021-08-07T22:27:10.94902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have predicted probabilities, let's finally create a submission file.","metadata":{"papermill":{"duration":0.854562,"end_time":"2020-08-25T13:39:06.283841","exception":false,"start_time":"2020-08-25T13:39:05.429279","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sample_sub_df = pd.read_csv(PATH_TO_DATA + 'sample_submission.csv.zip',\n                           index_col='id')","metadata":{"papermill":{"duration":1.099808,"end_time":"2020-08-25T13:39:08.16488","exception":false,"start_time":"2020-08-25T13:39:07.065072","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:10.95186Z","iopub.execute_input":"2021-08-07T22:27:10.95221Z","iopub.status.idle":"2021-08-07T22:27:11.213342Z","shell.execute_reply.started":"2021-08-07T22:27:10.952158Z","shell.execute_reply":"2021-08-07T22:27:11.212317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub_df.head(2)","metadata":{"papermill":{"duration":0.83673,"end_time":"2020-08-25T13:39:09.776206","exception":false,"start_time":"2020-08-25T13:39:08.939476","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:11.21472Z","iopub.execute_input":"2021-08-07T22:27:11.2151Z","iopub.status.idle":"2021-08-07T22:27:11.23628Z","shell.execute_reply.started":"2021-08-07T22:27:11.215061Z","shell.execute_reply":"2021-08-07T22:27:11.234872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub_df[TARGET_FIELDS] = predicted_probs","metadata":{"papermill":{"duration":0.816823,"end_time":"2020-08-25T13:39:11.378056","exception":false,"start_time":"2020-08-25T13:39:10.561233","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:11.237807Z","iopub.execute_input":"2021-08-07T22:27:11.238395Z","iopub.status.idle":"2021-08-07T22:27:11.248305Z","shell.execute_reply.started":"2021-08-07T22:27:11.238361Z","shell.execute_reply":"2021-08-07T22:27:11.247372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub_df.to_csv('submissions.csv')","metadata":{"papermill":{"duration":2.699674,"end_time":"2020-08-25T13:39:14.845391","exception":false,"start_time":"2020-08-25T13:39:12.145717","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:11.249763Z","iopub.execute_input":"2021-08-07T22:27:11.250117Z","iopub.status.idle":"2021-08-07T22:27:12.50297Z","shell.execute_reply.started":"2021-08-07T22:27:11.250081Z","shell.execute_reply":"2021-08-07T22:27:12.501976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head -3 submissions.csv","metadata":{"papermill":{"duration":1.511595,"end_time":"2020-08-25T13:39:17.115033","exception":false,"start_time":"2020-08-25T13:39:15.603438","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-07T22:27:12.504479Z","iopub.execute_input":"2021-08-07T22:27:12.504957Z","iopub.status.idle":"2021-08-07T22:27:13.239508Z","shell.execute_reply.started":"2021-08-07T22:27:12.504897Z","shell.execute_reply":"2021-08-07T22:27:13.238376Z"},"trusted":true},"execution_count":null,"outputs":[]}]}