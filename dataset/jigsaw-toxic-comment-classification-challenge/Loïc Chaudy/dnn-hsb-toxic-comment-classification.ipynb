{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# ***Toxic Comment Classification :***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\nfrom statistics import mean\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, SimpleRNN, TimeDistributed, ConvLSTM2D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.utils import plot_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Team Members :***\n* Dusan MAKSIMOVIC\n* Dejan LUTOVAC\n* Loïc CHAUDY","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *Introduction :*\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Why is this project usefull for the society ?\n>  There are some concrete application of this project in our society:\n\n> This could initially limit cases of cyber harassment. Indeed, we are in a world that is more and more virtualized. The virtual world plays an important role in our lives. \n> For example, access to social networks is easier, so many young people have the opportunity to create an account. Some children are victims of cyber harassment. In France, 22% of teenagers admit to having been a victim of cyber harassment on social networks in 2019.\n\n> An application of this project could make a selection of the messages a person can send. And thus limit any form of harm such as insults, for example.\n\n\nWhy is team members interested in this project ?\n> Loïc : I did tutoring at a high school a few years ago. I realized that a lot of people feel bad about cyber stalking, and they don't talk about it. This project can provide a solution so that there are less cases by being able to detect and delete messages of this type \n\n> Dusan : I chose this project because I think that a lot of racism begins at the Internet and there are a lot of toxic and racist comments.\n\n> Dejan : I‘m interested in this project becaus I hate the toxic comments like for example the racist comments and there are also a lot of fatal cases that I heard about.\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *Dataset Information :*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Loading the data*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**dataset explanation :**\n\n\n> We retrieved some comments from the internet. We are going to use these comments in order to know their nature.\n> For this we will classify them in different categories: toxic, severe toxic, obscene, threat, insult, indentity hate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here are some examples of comments :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['comment_text'][1689]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Let's have a look on some examples**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Some of them are very short, you can't misinterpret them, there's nothing toxic. *","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['comment_text'][4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*But some of them are also not so easy. *\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*At first, we can think that this comment is easy to classify. Indeed, we find insults, which puts it in the class toxic or even insult. But one wonders if he can't get into identity_hate because of the last sentence. This comment is not easy to classify.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# *Preprocessing Tasks:*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The first preprocessing step is to check if there are any NULL value. If there are, we need to fill this value with something.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are lucky to work with a 'clean' database. We don't find null values. We won't check all the cases by hand, it would take too much time. So we prefer to use already available functions. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Then, we separate our training list, on one side we have the comments(list_sentences_train) and on the other side we have the categories (y). We also retrieve the comments from the test list (list_sentences_test). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_train = train[\"comment_text\"]\nlist_sentences_test = test[\"comment_text\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to convert our text into number. A way to do this is to use the Tokenizer function in keras.\nThe *fit_on_texts* method will update the internal vocabulary based on the sentences, it will also create the index based on the frequency.\nThen, the *texts_to_sequences* method will transform each text into the corresponding numbers in the dictionary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see here wich number is linked with which text :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"index = tokenizer.word_index\nprint(index['the'])\nprint(index['cat'])\nprint(index['cars'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But it's not finised, we still got one problem. Neural Network need to have the same type of input to work but the comments may not have the same amount of word. \nThis two comments didn't have the same length","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list_tokenized_train[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list_tokenized_train[250])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Therefore, we need to add padding. We decided to have a maximum length of 200. So we can see from the graph that we won't lose a lot of data. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]\nplt.hist(totalNumWords,bins = np.arange(0,410,10))\nplt.axvline(x=200, color='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 200\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_t[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_t[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now have our two list ready for the model : **X_t = train** & **X_te = test**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *Deep Learning Models :*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*** Baseline model performance (simple model) 0.91761 **","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For our first model, we decided to put 2 layers : \nThe first with 20 neurons and the second with 6. \nOur last layer need to have 6 neurons because we've got 6 class to predict.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For the Input \ninp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\nembed_size = 128\nx = Embedding(max_features, embed_size)(inp)\n\n# != layers \n\nx = Dense(6, activation=\"tanh\")(x)\nx = Dense(6, activation=\"tanh\")(x)\n\n\n# For the Output\nx = GlobalMaxPool1D()(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use an embedding layer. Indeed, it allows to transform a word into a vector, which makes it more easily processed by the network. It also allows azussi to reduce the representation of words (compared to a vector model for example). \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here is a way to illustrate it (only the Enbedding part, the rest does not concern us) ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://www.researchgate.net/profile/Xingsheng_Yuan/publication/332810604/figure/fig2/AS:754128875683841@1556809743129/Simple-word-embedding-based-model-with-modified-hierarchical-pooling-strategy.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It allows to facilitate the learning by the network. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs=inp, outputs=x)\nmodel.compile(loss='mean_squared_error',\n                  optimizer='adam',\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True, dpi=96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 5\nhistory = model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()\n\nacc_basic = history.history['accuracy']\nval_loss_basic = history.history['val_loss']\nloss_basic = history.history['loss']\nval_acc_basic = history.history['val_accuracy']\n\nepochs = range(1, len(acc_basic) + 1)\n\nplt.subplot(221)\nplt.plot(epochs, loss_basic, 'b', label='Training loss')\nplt.plot(epochs, val_loss_basic, 'g', label='Validation loss')\n\nplt.title('Training vs validation (loss)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n\nplt.subplot(224)\n\nplt.plot(epochs, acc_basic, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc_basic, 'red', label='Validation accuracy')\n\nplt.title('Training vs Validation (accuracy)')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score, test_acc_basic = model.evaluate(X_t,y,verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_acc_basic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To create Kaggle submission :","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We need to use the predic function proposed by keras. We make the prediction with the test value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_te, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When we've got the prediction, we need to put this value into a csv file for the submission in Kaggle. We use Pandas to creathe such a file \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['id'] + list_classes)\nsubmission['id'] = test['id'].values \nsubmission[list_classes] = y_pred\nsubmission.to_csv(\"./submission_basicmodel.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** Complex Models**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, we made a model with base layers. We will now use a more powerful type of neuron to deal with languages: Recurent Neural Networks ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Thanks to the keras API, there are already layers that are implemented in it. So we are going to use the 3 following layers: LSTM, GRU and SimpleRNN*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*xTKE0g6XNMLM8IQ4aFdP0w.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"X(t) is input, h(t) is output and A is the neural network which gains information from the previous step in a loop. The output of one neurons goes into the next one and forward the information.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First we will use the simplest RNN of the Keras API: The simple RNN.\nThis is a fully connected RNN where the output of the previous time step must be sent to the next time step.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One simpleRNN cell : ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/415/1*28XR1ajfW1WuTOkjpOc9xA.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It's a multiplication of the current input (Xt) and the previous output (Ht-1). The get the current output, the activation function is applied to the result of the multiplication of the other two values. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"You can find more information on how to use this network layer at the following link: [SimpleRNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For the Input \ninp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\nembed_size = 128\nx = Embedding(max_features, embed_size)(inp)\n\n# != layers \n\n\nx = SimpleRNN(6,return_sequences=True)(x)\nx = Dense(6, activation=\"sigmoid\")(x)\n\n\n# For the Output\nx = GlobalMaxPool1D()(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnn = Model(inputs=inp, outputs=x)\nmodel_rnn.compile(loss='mean_squared_error',\n                  optimizer='adam',\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model_rnn, to_file='model_gru.png', show_shapes=True, show_layer_names=True, dpi=96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 5\nhistory = model_rnn.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()\n\nacc_rnn = history.history['accuracy']\nloss_rnn = history.history['loss']\nval_acc_rnn = history.history['val_accuracy']\nval_loss_rnn = history.history['val_loss']\n\nepochs = range(1, len(acc_rnn) + 1)\n\nplt.subplot(221)\nplt.plot(epochs, loss_rnn, 'b', label='Training loss')\nplt.plot(epochs, val_loss_rnn, 'g', label='Validation loss')\n\nplt.title('Training vs validation (loss)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n\nplt.subplot(224)\n\nplt.plot(epochs, acc_rnn, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc_rnn, 'red', label='Validation accuracy')\n\nplt.title('Training vs Validation (accuracy)')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the prediction :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score, test_acc_rnn = model_rnn.evaluate(X_t,y,verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_rnn.predict(X_te, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['id'] + list_classes)\nsubmission['id'] = test['id'].values \nsubmission[list_classes] = y_pred\nsubmission.to_csv(\"/kaggle/working/submission_model_RNN.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second layer that we will use is the Long Short Time Memory (LSTM).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One LSTM cell :","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here we use 3 states for each cell: The memory of the previous LSTM layer (on the top line), the result of the previous block (Ht-1) and finally the input layer (Xt). To have the result of all the states, mathematical calculations are made according to the diagram below.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"You can find more information on how to use this network layer at the following link: [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Here](https://en.wikipedia.org/wiki/Recurrent_neural_network#Long_short-term_memory) to have more explaination about the LSTM cell","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For the Input \ninp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\nembed_size = 128\nx = Embedding(max_features, embed_size)(inp)\n\n# != layers \n\nx = LSTM(6, return_sequences=True)(x)\nx = Dense(6, activation=\"sigmoid\")(x)\n\n\n# For the Output\nx = GlobalMaxPool1D()(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm = Model(inputs=inp, outputs=x)\nmodel_lstm.compile(loss='mean_squared_error',\n                  optimizer='adam',\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model_lstm, to_file='model_lstm.png', show_shapes=True, show_layer_names=True, dpi=96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 5\nhistory = model_lstm.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()\n\nacc_lstm = history.history['accuracy']\nval_acc_lstm = history.history['val_accuracy']\nval_loss_lstm = history.history['val_loss']\nloss_lstm = history.history['loss']\n\nepochs = range(1, len(acc_lstm) + 1)\n\nplt.subplot(221)\nplt.plot(epochs, loss_lstm, 'b', label='Training loss')\nplt.plot(epochs, val_loss_lstm, 'g', label='Validation loss')\n\nplt.title('Training vs validation (loss)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n\nplt.subplot(224)\n\nplt.plot(epochs, acc_lstm, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc_lstm, 'red', label='Validation accuracy')\n\nplt.title('Training vs Validation (accuracy)')\nplt.xlabel('Accuracy')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score, test_acc_lstm = model_lstm.evaluate(X_t,y,verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_acc_lstm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_lstm.predict(X_te, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['id'] + list_classes)\nsubmission['id'] = test['id'].values \nsubmission[list_classes] = y_pred\nsubmission.to_csv(\"./submission_model_LSTM.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The last is called the Gated Recurrent Unit (GRU).This is a variant of the LSTM.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One GRU cell : ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/552/1*GSZ0ZQZPvcWmTVatAeOiIw.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A GRU cell depends on only two parameters: the input value and the value of previous output blocks. \nThe interest of GRU compared to LSTM is the execution time which is faster since fewer parameters have to be calculated.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"You can find more information on how to use this network layer at the following link: [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Here](https://en.wikipedia.org/wiki/Recurrent_neural_network#Gated_recurrent_unit) to have more explaination about the GRU cell\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For the Input \ninp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\nembed_size = 128\nx = Embedding(max_features, embed_size)(inp)\n\n# != layers \n\nx = GRU(10,return_sequences=True, activation=\"sigmoid\")(x)\nx = Dense(6, activation=\"sigmoid\")(x)\n\n\n# For the Output\nx = GlobalMaxPool1D()(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gru = Model(inputs=inp, outputs=x)\nmodel_gru.compile(loss='mean_squared_error',\n                  optimizer='adam',\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model_gru, to_file='model_gru.png', show_shapes=True, show_layer_names=True, dpi=96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 5\nhistory = model_gru.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()\n\nacc_gru = history.history['accuracy']\nloss_gru = history.history['loss']\nval_acc_gru = history.history['val_accuracy']\nval_loss_gru = history.history['val_loss']\n\nepochs = range(1, len(acc_gru) + 1)\n\nplt.subplot(221)\nplt.plot(epochs, loss_gru, 'b', label='Training loss')\nplt.plot(epochs, val_loss_gru, 'g', label='Validation loss')\n\nplt.title('Training vs validation (loss)')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n\nplt.subplot(224)\n\nplt.plot(epochs, acc_gru, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc_gru, 'red', label='Validation accuracy')\n\nplt.title('Training vs Validation (accuracy)')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score, test_acc_gru = model_gru.evaluate(X_t,y,verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_acc_gru","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_gru.predict(X_te, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['id'] + list_classes)\nsubmission['id'] = test['id'].values \nsubmission[list_classes] = y_pred\nsubmission.to_csv(\"./submission_model_GRU.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Table Comparison of Models:*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"comp = pd.DataFrame(columns = ['Models'] + ['Training Accuracy (avg)'] + ['Validation Accuracy (avg)'] + ['Test Accuracy'] + ['Time /epochs (avg)']+ ['Kaggle Score'])\ncomp['Models'] = ['Baseline',\"LSTM\",'GRU','SimpleRNN']\ncomp['Training Accuracy (avg)'] = [mean(acc_basic),mean(acc_lstm),mean(acc_gru),mean(acc_rnn)]\ncomp['Validation Accuracy (avg)'] = [mean(val_acc_basic), mean(val_acc_lstm), mean(val_acc_gru), mean(val_acc_rnn)]\ncomp['Test Accuracy'] = [test_acc_basic, test_acc_lstm, test_acc_gru, test_acc_rnn]\ncomp['Time /epochs (avg)'] = [\"54s\", \"208s\", \"246.2s\", \"151.4s\"]\ncomp['Kaggle Score'] = [\"0.89238\",\"0.92040\",\"0.95050\",\"0.91707\"]\ncomp.to_csv(\"./Models_comp.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displaycomp = pd.read_csv('/kaggle/working/Models_comp.csv')\nprint(displaycomp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*we check what we said about the difficulties to predict some comments:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.read_csv('/kaggle/working/submission_model_GRU.csv')\npredict_val = predict[list_classes].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['comment_text'][4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_val[4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_val[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Difficulties encountered:*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As on all projects, we had to face several problems to complete this one :","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The first problem is the coronavirus. Indeed, the arrival of this virus has already changed the way the project has been carried out because of the introduction of online courses. As we are all erasmus students (two from Luxembourg and one from France), we all went home. So setting up slots to work on this project was a bit more difficult than it would have been without this situation with COVID.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Two people hadn't really practiced before the Python. So it was difficult to start working directly on the project. Luckily, attending Python classes in parallel to this course allowed a better understanding of this scripting language.   ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It also took a long time to understand the existing notebook before starting to work on this project. Indeed, we did not start this project from scratch, we started from an existing notebook. All the members of the group had never done neural networks before, so it would have been complicated to start from scratch without any basis. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *Conclusion:*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We decided to do the test on 5 epochs. Doing it on more might be more interesting in terms of values. But it would take too much time. Indeed, for the longest model (GRU) which has an average of 246s / epochs. This would make on 50 epochs or 205 min total and for 100 epochs 410 min which is too much waiting time.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We had already noticed that the average time by epochs and logic. Indeed, the time for the simplest model (baseline) and the one that takes the shortest time, on average 54s.The more complex the model, the longer the time increases: simpleRNN got an average time of 154.4s per epochs, 208s for the LSTM and finally 246.2s for the GRU.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to get a better idea of the performance of each model, we mainly look at the test accuracy, but also to the other metrics (Training accuracy, validation accuracy). We notice that the LSTM and the GRU have the two best results for all categories. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To choose between the two, we look at the Kaggle score. We notice that this one is 0.95050 for the GRU against 0.92040 for the LSTM.The GRU also got better performance to all the metrics, comparing to the LSTM. It tends to converge to the optimal solution.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We would say that, to answer the problem, we prefer to use our GRU model, in this case. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}