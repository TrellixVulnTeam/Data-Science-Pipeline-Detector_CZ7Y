{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, sys, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#keras\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Seperation\ntrain_comments = train[\"comment_text\"]\ntest_comments = test[\"comment_text\"]\nclasses = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[classes].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tokenization\nfrom keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words = 20000)\ntokenizer.fit_on_texts(list(train_comments))\ntokenized_train_comments = tokenizer.texts_to_sequences(train_comments)\ntokenized_test_comments = tokenizer.texts_to_sequences(test_comments)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments_len = [len(comment) for comment in tokenized_train_comments]\nplt.hist(comments_len, bins=np.arange(0,400,10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Seqeunce Padding\nfrom keras.preprocessing.sequence import pad_sequences\nX_train = pad_sequences(tokenized_train_comments, maxlen=200)\nX_test = pad_sequences(tokenized_test_comments, maxlen=200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create model\nfrom keras.layers import Input, Dense, LSTM, Embedding, Dropout,GlobalMaxPooling1D\nfrom keras.models import Model\n\ninputLayer = Input(shape=200)\nembedLayer = Embedding(input_dim=20000, output_dim=128)(inputLayer)\nlstmLayer = LSTM(units=60, return_sequences=True)(embedLayer)\nmaxPool = GlobalMaxPooling1D()(lstmLayer)\ndropOut1 = Dropout(0.1)(maxPool)\nfcLayer1 = Dense(units=50, activation='relu')(dropOut1)\ndropOut2 = Dropout(0.1)(fcLayer1)\nfcLayer2 = Dense(units=6, activation='sigmoid')(dropOut2)\n\nmodel = Model(inputs=inputLayer, outputs=fcLayer2)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y, batch_size=32, epochs=2, validation_split=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}