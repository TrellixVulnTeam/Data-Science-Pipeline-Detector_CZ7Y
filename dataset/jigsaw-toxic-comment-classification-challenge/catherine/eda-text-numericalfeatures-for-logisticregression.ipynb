{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.preprocessing import StandardScaler\nimport scipy.sparse as sparse\nfrom scipy.sparse import hstack, csr_matrix\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read the data:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we have six types of labels: toxic, severe_toxic, obscene, threat, insult, identity_hate\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape, test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# take only comments from test and train sets\n\ntrain_text = train_data['comment_text']\ntest_text = test_data['comment_text']\n\ntexts_data = pd.concat([train_text, test_text]).to_frame()\ntexts_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### plans to carry out text processing and build word clouds for each text in train and test data."},{"metadata":{},"cell_type":"markdown","source":"# EDA and Feature engineering:\n"},{"metadata":{},"cell_type":"markdown","source":"Let`s try to create some features and explore how they useful are:\n\n* comment length - angry comments may be short, I mean, that the more aggressive the comment, the shorter it is;\n* uppercase - angry comments usually have a lot of uppercase letters;\n* emoji - angry users maybe not use a happy emoji (and emoji in general), also we could have a situation, in which emoji means sarcasm;\n* punctuation - angry persons usually do not use , . : ? and etc, they maybe use a lot of \"!\" ;\n* number of symbols - people usually encoded bad words with special symbols '@', '$' and etc;\n* specific words for each category - with term frequency we can find the most common words in the category."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['total_length'] = train_data['comment_text'].apply(len)\ntrain_data['uppercase'] = train_data['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntrain_data['exclamation_punctuation'] = train_data['comment_text'].apply(lambda comment: comment.count('!'))\ntrain_data['num_punctuation'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:?'))\ntrain_data['num_symbols'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\ntrain_data['num_words'] = train_data['comment_text'].apply(lambda comment: len(comment.split()))\ntrain_data['num_happy_smilies'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\ntrain_data['num_sad_smilies'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-(', ':(', ';-(', ';(')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['total_length'] = test_data['comment_text'].apply(len)\ntest_data['uppercase'] = test_data['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntest_data['exclamation_punctuation'] = test_data['comment_text'].apply(lambda comment: comment.count('!'))\ntest_data['num_punctuation'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:?'))\ntest_data['num_symbols'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\ntest_data['num_words'] = test_data['comment_text'].apply(lambda comment: len(comment.split()))\ntest_data['num_happy_smilies'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\ntest_data['num_sad_smilies'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-(', ':(', ';-(', ';(')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spearman correlation. \n\ncorr = train_data.corr(method='spearman')\nf, ax = plt.subplots(figsize=(20, 10))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's drop one of the features which have a high correlation with another feature\n# in our case, num_words have a very high correlation with the total length\n\ntrain_data = train_data.drop(['num_words'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spearman correlation. \n\ncorr = train_data.corr(method='spearman')\nf, ax = plt.subplots(figsize=(20, 10))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data = train_data\ntrain_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Explore each type of toxic comments:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data['toxic_type'] = ''\ntrain_features_data['toxic_type'].loc[train_features_data['toxic'] == 1] += 'toxic '\ntrain_features_data['toxic_type'].loc[train_features_data['severe_toxic'] == 1] += 'severe_toxic '\ntrain_features_data['toxic_type'].loc[train_features_data['obscene'] == 1] += 'obscene '\ntrain_features_data['toxic_type'].loc[train_features_data['threat'] == 1] += 'threat '\ntrain_features_data['toxic_type'].loc[train_features_data['insult'] == 1] += 'insult '\ntrain_features_data['toxic_type'].loc[train_features_data['identity_hate'] == 1] += 'identity_hate '","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table_top = train_features_data['toxic_type'].value_counts().to_frame()[:10].style.background_gradient(cmap=cmap)\ntable_top","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fisrt value is ''. It means, we have a lot of comment without any toxic."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Explore length of comments:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_toxic = train_features_data.loc[train_features_data['toxic'] == 1]\ndf_severe_toxic = train_features_data.loc[train_features_data['severe_toxic'] == 1]\ndf_obscene = train_features_data.loc[train_features_data['obscene'] == 1]\ndf_threat = train_features_data.loc[train_features_data['threat'] == 1]\ndf_insult = train_features_data.loc[train_features_data['insult'] == 1]\ndf_identity_hate = train_features_data.loc[train_features_data['identity_hate'] == 1]\ndf_normal = train_features_data.loc[train_features_data['toxic_type'] == '']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Histogram(x=df_toxic.total_length, name='toxic'))\nfig.add_trace(go.Histogram(x=df_severe_toxic.total_length, name='severe_toxic'))\nfig.add_trace(go.Histogram(x=df_obscene.total_length, name='obscene'))\nfig.add_trace(go.Histogram(x=df_threat.total_length, name='threat'))\nfig.add_trace(go.Histogram(x=df_insult.total_length, name='insult'))\nfig.add_trace(go.Histogram(x=df_identity_hate.total_length, name='identity hate'))\nfig.add_trace(go.Histogram(x=df_normal.total_length, name='normal'))\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, assumption about length is true. Non-toxic comments have a higher length."},{"metadata":{},"cell_type":"markdown","source":"### Explore how much types has each comment:\n\n- how much types has each comments;\n- visualization means for that;\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data['list_toxic_type'] = train_features_data['toxic_type'].apply(lambda row: row.split(' '))\ntrain_features_data['list_toxic_type'] =train_features_data['list_toxic_type'].apply(lambda row: len(row)-1)\ntable_types = train_features_data['list_toxic_type'].value_counts().to_frame().style.background_gradient(cmap=cmap)\ntable_types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==0] = 'normal comment'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==1] = 'has one type of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==2] = 'has two types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==3] = 'has three types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==4] = 'has four types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==5] = 'has five types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==6] = 'has six types of toxic'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types = ['normal comment', 'has one type of toxic', 'has two types of toxic', 'has three types of toxic',\n         'has four types of toxic', 'has five types of toxic', 'has six types of toxic']\n\ncolumns = ['total_length', 'uppercase', 'exclamation_punctuation',\n                                'num_punctuation', 'num_symbols', 'num_happy_smilies', 'num_sad_smilies']\n\ndf_mean = pd.DataFrame(columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, toxic_type in enumerate(types):\n    for col in columns:    \n        df_mean.at[i, col] = train_features_data[col].loc[train_features_data['list_toxic_type'] == toxic_type].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean['toxic_types'] = types ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean['total_length'] = pd.to_numeric(df_mean['total_length'])\ndf_mean['uppercase'] = pd.to_numeric(df_mean['uppercase'])\ndf_mean['exclamation_punctuation'] = pd.to_numeric(df_mean['exclamation_punctuation'])\ndf_mean['num_punctuation'] = pd.to_numeric(df_mean['num_punctuation'])\ndf_mean['num_symbols'] = pd.to_numeric(df_mean['num_symbols'])\ndf_mean['num_happy_smilies'] = pd.to_numeric(df_mean['num_happy_smilies'])\ndf_mean['num_sad_smilies'] = pd.to_numeric(df_mean['num_sad_smilies'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\n\npx.scatter(df_mean, x=\"exclamation_punctuation\", y=\"num_punctuation\",\n           size=\"total_length\", color=\"toxic_types\", hover_name=\"toxic_types\",\n           size_max=55)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- the comments with four toxic types are far from others;\n- the comments with six toxic types have a lot of punctuation and an average number of exclamation punctuation;\n- the normal types of comments have an average number of  punctuation and a low number of exclamation punctuation."},{"metadata":{},"cell_type":"markdown","source":"### Explore each toxic type:"},{"metadata":{"trusted":true},"cell_type":"code","source":"types = ['toxic', 'severe_toxic', 'obscene', 'threat',\n         'insult', 'identity_hate']\n\ndf_types_mean = pd.DataFrame(columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, toxic_type in enumerate(types):\n    for col in columns:    \n        df_types_mean.at[i, col] = train_features_data[col].loc[train_features_data[toxic_type] == 1].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in columns:    \n        df_types_mean.at[6, col] = train_features_data[col].loc[train_features_data['toxic'] == 0] \\\n                                                        .loc[train_features_data['severe_toxic'] == 0] \\\n                                                        .loc[train_features_data['obscene'] == 0] \\\n                                                        .loc[train_features_data['threat'] == 0] \\\n                                                        .loc[train_features_data['insult'] == 0] \\\n                                                        .loc[train_features_data['identity_hate'] == 0] \\\n                                                        .mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_types_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types.append('normal comment')\n\ndf_types_mean['type'] = types\ndf_types_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_types_mean['total_length'] = pd.to_numeric(df_types_mean['total_length'])\ndf_types_mean['uppercase'] = pd.to_numeric(df_types_mean['uppercase'])\ndf_types_mean['exclamation_punctuation'] = pd.to_numeric(df_types_mean['exclamation_punctuation'])\ndf_types_mean['num_punctuation'] = pd.to_numeric(df_types_mean['num_punctuation'])\ndf_types_mean['num_symbols'] = pd.to_numeric(df_types_mean['num_symbols'])\ndf_types_mean['num_happy_smilies'] = pd.to_numeric(df_types_mean['num_happy_smilies'])\ndf_types_mean['num_sad_smilies'] = pd.to_numeric(df_types_mean['num_sad_smilies'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(df_types_mean, x=\"exclamation_punctuation\", y=\"num_punctuation\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(df_types_mean, x='exclamation_punctuation', y='num_punctuation', z='uppercase', size='total_length', color='type',\n                    hover_data=['type'])\nfig.update_layout(scene_zaxis_type=\"log\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- we can see four \"clusters\": 1 - threat, severe toxic, 2 -  normal comments, 3 - toxic, obscene, insult, identity hate."},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(df_types_mean, x=\"uppercase\", y=\"num_punctuation\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(df_types_mean, x=\"uppercase\", y=\"num_symbols\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(df_types_mean, x=\"uppercase\", y=\"exclamation_punctuation\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- in each case we can see that severe toxic is far from other types;\n- toxic, insult, obscene always are very close;\n- normal comments always at the origin of coordinates;"},{"metadata":{},"cell_type":"markdown","source":"**It`s not final version.**\n"},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression with TF-IDF and numeric features:"},{"metadata":{},"cell_type":"markdown","source":"## TF-IDF for comments (text data):"},{"metadata":{"trusted":true},"cell_type":"code","source":"tvec = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    max_features=10000\n)\n\ntvec.fit(train_data['comment_text'])\n\ntrain_texts = tvec.transform(train_data['comment_text'])\ntest_texts = tvec.transform(test_data['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataFrameMapper for joining numerical and text features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# If we want to work with frames from pandas for algorithms in Scikit-Learn, we could use a special module for that - Sklearn-pandas\n# This module provides a bridge between Scikit-Learn's machine learning methods and pandas-style Data Frames.\n\nmapper = DataFrameMapper([\n      (['uppercase'], StandardScaler()),\n      (['exclamation_punctuation'], StandardScaler()),\n      (['num_punctuation'], StandardScaler()),\n      (['num_symbols'], StandardScaler()),\n      (['num_happy_smilies'],StandardScaler()),\n      (['num_sad_smilies'],StandardScaler()),\n      (['total_length'],StandardScaler())\n], df_out=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate numeric and text training features"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features_train = train_data.iloc[:, 8:15]\nnumeric_features_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.round(mapper.fit_transform(numeric_features_train.copy()), 2).values\nx_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_features = sparse.hstack((csr_matrix(x_train), train_texts))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate numeric and text testing features"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features_test = test_data.iloc[:, 1:]\nnumeric_features_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.round(mapper.fit_transform(numeric_features_test.copy()), 2).values\nx_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_features = sparse.hstack((csr_matrix(x_test), test_texts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = x_train_features\ntest_features  = x_test_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic regression, cross_val_score:"},{"metadata":{},"cell_type":"markdown","source":"Scikit-Learn's cross_val_score now could work with DataFrameMapper.\n\nAnd  we can estimate with cross_val_score our solution quality:"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\nfor class_name in class_names:\n  train_target = train_data[class_name]\n  classifier = LogisticRegression(C=0.1, solver='sag')\n  cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n  scores.append(cv_score)\n  print('CV score for class {} is {}'.format(class_name, cv_score))\n\n  classifier.fit(train_features, train_target)\n\nprint('Total CV score is {}'.format(np.mean(scores)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}