{"cells":[{"metadata":{"_cell_guid":"91bc9f4c-9535-42bb-969d-80340840ef5f","_uuid":"1d9358b4afbf4c53c8d90b83198c00628e979020"},"cell_type":"markdown","source":"# Feature engineering\n\nIn this notebook I'd like to expand [@eikedehling search for features](https://www.kaggle.com/eikedehling/feature-engineering) and in part revise his findings. ","outputs":[],"execution_count":null},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aacef7d0425304f542c746a9a8dd9763528e1bea"},"cell_type":"code","source":"import pandas as pd\nimport collections\nimport string\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b46975da2c4510bef61d01cb104dc171af8f318"},"cell_type":"markdown","source":"Let's add a few constants:","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5e92aba5c2fb6b16e95f1f6aadf1f24c8e0344e0"},"cell_type":"code","source":"COMMENT = 'comment_text'\nLABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f961a24-8ce0-4671-bd14-84077a802a53","_uuid":"b11eb49ad9b57030d1bbf8729f72ce45ac600c26","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\", encoding=\"utf-8\")\nprint(train.head())\nprint(\"Train: %s samples\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa509eed-dfdb-41a7-b41c-b5c08ca328d4","_uuid":"03003e1fb8a8ff49f0076dd78f1717c7d4f689eb"},"cell_type":"markdown","source":"In the following I'll add two sets of manually engineered features. The first set takes into account the structure of the comment (lengths, punctuation, capitals, etc...). The second set will investigate lexical categories.\n\nThe main assumption is that an angry/disgruntled/mad user will follow a particular pattern while writing a toxic comment. Let's see if we found any.\n\nIn my experience bare counts of occurrences will not help you much to visualize patterns. Normalization is key here. I will add two: vs length and vs words count.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"34610778-9d43-4369-a39a-98b0315af51e","_uuid":"71bafb31ff381838ebee97d4c43dc7a9b30abd2f","trusted":true,"collapsed":true},"cell_type":"code","source":"train['total_length'] = train[COMMENT].apply(len)\n\ntrain['words'] = train[COMMENT].apply(lambda comment: len(comment.split()))\ntrain['words_vs_length'] = train['words'] / train['total_length']\n\ntrain['capitals'] = train[COMMENT].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntrain['capitals_vs_length'] = train['capitals'] / train['total_length']\ntrain['capitals_vs_words'] = train['capitals'] / train['words']\n\ntrain['paragraphs'] = train[COMMENT].apply(lambda comment: comment.count('\\n'))\ntrain['paragraphs_vs_length'] = train['paragraphs'] / train['total_length']\ntrain['paragraphs_vs_words'] = train['paragraphs'] / train['words']\n\neng_stopwords = set(stopwords.words(\"english\"))\ntrain['stopwords'] = train[COMMENT].apply(lambda comment: sum(comment.count(w) for w in eng_stopwords))\ntrain['stopwords_vs_length'] = train['stopwords'] / train['total_length']\ntrain['stopwords_vs_words'] = train['stopwords'] / train['words']\n\ntrain['exclamation_marks'] = train[COMMENT].apply(lambda comment: comment.count('!'))\ntrain['exclamation_marks_vs_length'] = train['exclamation_marks'] / train['total_length']\ntrain['exclamation_marks_vs_words'] = train['exclamation_marks'] / train['words']\n\ntrain['question_marks'] = train[COMMENT].apply(lambda comment: comment.count('?'))\ntrain['question_marks_vs_length'] = train['question_marks'] / train['total_length']\ntrain['question_marks_vs_words'] = train['question_marks'] / train['words']\n\ntrain['punctuation'] = train[COMMENT].apply(\n    lambda comment: sum(comment.count(w) for w in string.punctuation))\ntrain['punctuation_vs_length'] = train['punctuation'] / train['total_length']\ntrain['punctuation_vs_words'] = train['punctuation'] / train['words']\n\ntrain['unique_words'] = train[COMMENT].apply(\n    lambda comment: len(set(w for w in comment.split())))\ntrain['unique_words_vs_length'] = train['unique_words'] / train['total_length']\ntrain['unique_words_vs_words'] = train['unique_words'] / train['words']\n\nrepeated_threshold = 15\ndef count_repeated(text):\n    text_splitted = text.split()\n    word_counts = collections.Counter(text_splitted)\n    return sum(count for word, count in sorted(word_counts.items()) if count > repeated_threshold)\n\ntrain['repeated_words'] = train[COMMENT].apply(lambda comment: count_repeated(comment))\ntrain['repeated_words_vs_length'] = train['repeated_words'] / train['total_length']\ntrain['repeated_words_vs_words'] = train['repeated_words'] / train['words']\n\ntrain['mentions'] = train[COMMENT].apply(\n    lambda comment: comment.count(\"User:\"))\ntrain['mentions_vs_length'] = train['mentions'] / train['total_length']\ntrain['mentions_vs_words'] = train['mentions'] / train['words']\n\n\ntrain['smilies'] = train[COMMENT].apply(\n    lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\ntrain['smilies_vs_length'] = train['smilies'] / train['total_length']\ntrain['smilies_vs_words'] = train['smilies'] / train['words']\n\ntrain['symbols'] = train[COMMENT].apply(\n    lambda comment: sum(comment.count(w) for w in '*&#$%“”¨«»®´·º½¾¿¡§£₤‘’'))\ntrain['symbols_vs_length'] = train['symbols'] / train['total_length']\ntrain['symbols_vs_words'] = train['symbols'] / train['words']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf42fea4ce6633ad180d2b131e3188ea59204ab6"},"cell_type":"markdown","source":"Ok, now let's see if nouns/verbs/adjectives distributions tell us anything worth the effort of tagging the comment corpus. For this I will use the excellent nltk support for category/tagging part of speech. This part, at least, in this form, only applies to english.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e66ea469-91d7-4c9c-ae5d-dc17faca1c8f","_uuid":"3a7bbd42c35f0a6e2572927f472d34de08b4f93b","trusted":true,"collapsed":true},"cell_type":"code","source":"def tag_part_of_speech(text):\n    text_splited = text.split(' ')\n    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n    text_splited = [s for s in text_splited if s]\n    pos_list = pos_tag(text_splited)\n    noun_count = len([w for w in pos_list if w[1] in ('NN','NNP','NNPS','NNS')])\n    adjective_count = len([w for w in pos_list if w[1] in ('JJ','JJR','JJS')])\n    verb_count = len([w for w in pos_list if w[1] in ('VB','VBD','VBG','VBN','VBP','VBZ')])\n    return[noun_count, adjective_count, verb_count]\n\n\ntrain['nouns'], train['adjectives'], train['verbs'] = zip(*train[COMMENT].apply(\n    lambda comment: tag_part_of_speech(comment)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da9480f90cec0abaaa4d43ee534e647102ba73ab"},"cell_type":"markdown","source":"Ok, even here, let's apply normalization..","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"62f2e88affc7b1fbf92804a7e17245f5c3adcc74"},"cell_type":"code","source":"train['nouns_vs_length'] = train['nouns'] / train['total_length']\ntrain['adjectives_vs_length'] = train['adjectives'] / train['total_length']\ntrain['verbs_vs_length'] = train['verbs'] / train['total_length']\ntrain['nouns_vs_words'] = train['nouns'] / train['words']\ntrain['adjectives_vs_words'] = train['adjectives'] / train['words']\ntrain['verbs_vs_words'] = train['verbs'] / train['words']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99fad39a6594de397d4dea8411409461f209a74f"},"cell_type":"markdown","source":"Let's see if everthing is ok...","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"5fa2b473-f6b9-4564-9889-78d14ba88d23","_uuid":"09d66504f7abeb475a833d58421e39008c486832","scrolled":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e3f10ae2-718c-4e78-a23f-6f092cb6d72b","_uuid":"74f817ad4c774172e44deae5212529b90f49cb94"},"cell_type":"markdown","source":"Now let's explore the correlation between the added features and the to-be-predicted columns, this should be an indication of whether a model could use these features:","outputs":[],"execution_count":null},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1f40afa3f90dbbc30148a2d62155b02ccaa7597"},"cell_type":"code","source":"features = ('total_length', \n            'words', 'words_vs_length',\n            'capitals', 'capitals_vs_length', 'capitals_vs_words',\n            'paragraphs', 'paragraphs_vs_length', 'paragraphs_vs_words',\n            'stopwords', 'stopwords_vs_length', 'stopwords_vs_words',\n            'exclamation_marks', 'exclamation_marks_vs_length', 'exclamation_marks_vs_words',\n            'question_marks', 'question_marks_vs_length', 'question_marks_vs_words',\n            'punctuation', 'punctuation_vs_length', 'punctuation_vs_words',\n            'unique_words', 'unique_words_vs_length', 'unique_words_vs_words',\n            'repeated_words', 'repeated_words_vs_length', 'repeated_words_vs_words',\n            'mentions', 'mentions_vs_words', 'mentions_vs_length',\n            'smilies', 'smilies_vs_length', 'smilies_vs_words',\n            'symbols', 'symbols_vs_length', 'symbols_vs_words',\n            'nouns', 'nouns_vs_words', 'nouns_vs_length', \n            'adjectives', 'adjectives_vs_words', 'adjectives_vs_length',\n            'verbs', 'verbs_vs_words', 'verbs_vs_length',\n           )\ntrain['none'] = 1 - train[LABELS].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6a576a79-62e7-430a-9d18-3b5ae53e3648","_uuid":"a1234d2a68c42835b390d767e6a590a9422371f5","trusted":true},"cell_type":"code","source":"columns = LABELS + ['none']\n\nrows = [{c:train[f].corr(train[c]) for c in columns} for f in features]\ntrain_correlations = pd.DataFrame(rows, index=features)\ntrain_correlations","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b84c0f9-9edd-49bf-92f1-76f2d6af23a6","_uuid":"2dd30cb117effd9fdd1bb8aa16d1a0f6e252e2bf"},"cell_type":"markdown","source":"Pretty impressive, but still not useful without a proper visualization. Let's see in heatmap form","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"fcddde11-e833-4292-9874-eb0c675e9966","_uuid":"613ef976113f51c3e690431b54c6c508bc54961c","trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(train_correlations, annot=True, vmin=-0.23, vmax=0.23, center=0.0, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"57a7e0a2-8865-4950-bd8c-12ccea7f2de8","_uuid":"e93dc934e0a4b247bc72471c8617dad17ff97136"},"cell_type":"markdown","source":"I may be biased... but wow! :)\n\nWrapping up...\n\nWe can see lots of cells lighting up. In particular:\n- number of words: severe toxic comments tend to have a high count of words, toxic a somewhat higher count than normal\n- capitals: toxic loves capitals. It is probably the most significant indicator we've got.\n- paragraphs: probably not so useful, the correlations are quite low. Still...\n- stopwords: clean comments tend to have more of them than toxic ones. It may worth not to filter them out.\n- exclamation marks: toxic are quite full of them.\n- repeated words: toxic (especially severe toxic) tend to have the same words repeated over and over (we had a 15 threshold count, but we could probably lower it and still get something useful)\n- nouns: adjectives and verbs mean little, but nouns are used all over in toxic comments. Nice to know.\n\nIn addition:\n- length vs words: normalizing vs length seems to return more meaningful correlation than vs words. That seems counterintuitive to me, so it's a good finding in my opinion.\n- threat is an outsider: it's really difficult to find correlation with any indicator I throw at it. It probably demands more attention.\n- identity_hate: again difficult. A little help comes from capitals, but not so much.\n- clean comments are quite uncorrelated to all the high correlations that we found. That is nice.\n\nOk, all these may be useful hints for cleaning your corpus during data preparation. But the main point here is that counting occurrences in the comments is nice and fine, but the missing part is that some kind of normalization is needed to get meaningful results. Just look, for example, at the nouns or paragraph rows: pretty insignificant until you reduce them to fractions. \n\nFeedback or ideas are welcome. \n\nThanks for you time!","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4b24f890-7c66-469b-9542-9f1261997b6d","_uuid":"138db0cdfc6185f3a5b538dc05ff33deae57aa5b"},"cell_type":"markdown","source":"","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}