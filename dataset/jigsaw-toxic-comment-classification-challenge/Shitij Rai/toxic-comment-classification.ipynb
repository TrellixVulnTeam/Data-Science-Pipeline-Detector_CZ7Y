{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nimport re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import data\ntrain_data = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest_data = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taining data\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for any null comments\nnull_comments = train_data[train_data['comment_text'].isnull()]\nprint(\"Number of null comments: \" + str(len(null_comments)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counting total comments with above labels\nprint(train_data[target_labels].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot for text length in each comments\ntrain_data['char_length'] = train_data['comment_text'].apply(lambda x:len(str(x)))\nsns.set()\ntrain_data['char_length'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning up comment text for every comment in train and test data\n#function for cleaning up comments\ndef clean_comment(text):\n    text = text.lower()\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    text = re.sub('\\W', ' ', text)\n    text = re.sub('\\s+', ' ', text)\n    text = text.strip(' ')\n    return text\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['comment_text'] = train_data['comment_text'].apply(lambda x:clean_comment(x))\ntest_data['comment_text'] = test_data['comment_text'].apply(lambda x:clean_comment(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizing the text data\nvec = TfidfVectorizer(max_features = 5000,stop_words = 'english')\nx_train = vec.fit_transform(train_data['comment_text'])\nx_test = vec.transform(test_data['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using logistic regression to create as many number of binary classifiers as number of labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\nclassifier = LogisticRegression(C=12.0)\nfor label in target_labels:\n    print('Fitting the model for label: ' + label)\n    y_labels = train_data[label]\n    classifier.fit(x_train,y_labels.values)\n    y_pred = classifier.predict(x_train)\n    print('Training accuracy: ' + str(accuracy_score(y_labels,y_pred)))\n    y_test_prob = classifier.predict(x_test)\n    submission[label] = y_test_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create submission file\nsubmission.to_csv('test_submissions.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}