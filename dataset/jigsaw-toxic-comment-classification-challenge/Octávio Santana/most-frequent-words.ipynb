{"metadata":{"language_info":{"file_extension":".py","name":"python","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1,"cells":[{"metadata":{"_uuid":"fe55bbea968ce4337ea7bbdfbdccacc64348d2f2","_cell_guid":"2b08b3aa-f798-4e70-8eb9-b0ee2ada4fd0"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom collections import Counter\nimport string\nimport nltk\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\nprint('DataFrame Train:')\nprint(df_train.isnull().any())"},{"metadata":{},"source":"***Turning all strings into lowercase ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment = df_train[df_train['toxic'] == 1]['comment_text'].str.lower()\nsevere_toxic_comment = df_train[df_train['severe_toxic'] == 1]['comment_text'].str.lower()\nobscene_comment = df_train[df_train['obscene'] == 1]['comment_text'].str.lower()\nthreat_comment = df_train[df_train['threat'] == 1]['comment_text'].str.lower()\ninsult_comment = df_train[df_train['insult'] == 1]['comment_text'].str.lower()\nidentity_hate_comment = df_train[df_train['identity_hate'] == 1]['comment_text'].str.lower()"},{"metadata":{},"source":"*** Converting into a arrays ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment = toxic_comment.values.tolist()\nsevere_toxic_comment = severe_toxic_comment.values.tolist()\nobscene_comment = obscene_comment.values.tolist()\nthreat_comment = threat_comment.values.tolist()\ninsult_comment = insult_comment.values.tolist()\nidentity_hate_comment = identity_hate_comment.values.tolist()"},{"metadata":{},"source":"*** Breaking all comments by words ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment_break = [nltk.tokenize.wordpunct_tokenize(text) for text in toxic_comment]\nsevere_toxic_comment_break = [nltk.tokenize.wordpunct_tokenize(text) for text in severe_toxic_comment]\nobscene_comment_break = [nltk.tokenize.wordpunct_tokenize(text) for text in obscene_comment]\nthreat_comment_break = [nltk.tokenize.wordpunct_tokenize(text) for text in threat_comment]\ninsult_comment_break = [nltk.tokenize.wordpunct_tokenize(text) for text in insult_comment]\nidentity_hate_comment_break = [nltk.tokenize.wordpunct_tokenize(text) for text in identity_hate_comment]"},{"metadata":{},"source":"*** Delete all common English words ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"stopwords = nltk.corpus.stopwords.words('english')"},{"metadata":{},"source":"*** Delete repeated characters in words, for example looooooong -> long ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"from itertools import groupby\n\ndef clear_multiple_char(comment):        \n    ti = []\n    for words in comment:\n        t = [''.join([\"\".join(i) for i, _ in groupby(word)]) if len(word)>10 else word for word in words]\n        ti.append(t)\n    return ti"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment_break = clear_multiple_char(toxic_comment_break)\nsevere_toxic_comment_break = clear_multiple_char(severe_toxic_comment_break)\nobscene_comment_break = clear_multiple_char(obscene_comment_break)\nthreat_comment_break = clear_multiple_char(threat_comment_break)\ninsult_comment_break = clear_multiple_char(insult_comment_break)\nidentity_hate_comment_break = clear_multiple_char(identity_hate_comment_break)"},{"metadata":{},"source":"*** Eliminate punctuations, numbers and reduce words by their root ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"from nltk.stem.lancaster import LancasterStemmer\nstemmer = LancasterStemmer()\npunctuation = string.punctuation # '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n# Add numbers\npunctuation += '0123456789'\n\ndef comment_raiz(comment):\n    text = []\n    for lista in comment:\n        valids = [stemmer.stem(word) for word in lista if word not in stopwords and word not in punctuation \n                  and len(word)>2]\n        valids_true = [''.join([char for char in word if char not in punctuation]) for word in valids if \n                       len(''.join([char for char in word if char not in punctuation]))>0]\n        text.append(valids_true)\n    return text"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment_clear = comment_raiz(toxic_comment_break)\nsevere_toxic_comment_clear = comment_raiz(severe_toxic_comment_break)\nobscene_comment_clear = comment_raiz(obscene_comment_break)\nthreat_comment_clear = comment_raiz(threat_comment_break)\ninsult_comment_clear = comment_raiz(insult_comment_break)\nidentity_hate_comment_clear = comment_raiz(identity_hate_comment_break)"},{"metadata":{},"source":"*** Function that counts the number of times each word was used in the comments ***","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"def counter(comment_clear):\n    cnt = Counter()\n    for words in comment_clear:\n        for word in words:\n            cnt[word] += 1\n    return cnt"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment_cnt = counter(toxic_comment_clear)\nsevere_toxic_comment_cnt = counter(severe_toxic_comment_clear)\nobscene_comment_cnt = counter(obscene_comment_clear)\nthreat_comment_cnt = counter(threat_comment_clear)\ninsult_comment_cnt = counter(insult_comment_clear)\nidentity_hate_comment_cnt = counter(identity_hate_comment_clear)"},{"metadata":{},"source":"*** The ten most frequent words of toxic ***","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"toxic_comment_cnt.most_common(10)"},{"metadata":{},"source":"*** The ten most frequent words of severe toxic ***","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"severe_toxic_comment_cnt.most_common(10)"},{"metadata":{},"source":"*** The ten most frequent words of obscene ***","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"obscene_comment_cnt.most_common(10)"},{"metadata":{},"source":"*** The ten most frequent words of threat ***","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"threat_comment_cnt.most_common(10)"},{"metadata":{},"source":"*** The ten most frequent words of insult ***","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"insult_comment_cnt.most_common(10)"},{"metadata":{},"source":"*** The ten most frequent words of identify hate ***","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"identity_hate_comment_cnt.most_common(10)"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":""}]}