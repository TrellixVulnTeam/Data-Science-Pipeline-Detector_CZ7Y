{"cells":[{"cell_type":"markdown","metadata":{},"source":"**Data Description**\n\nYou are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n\n    toxic\n    severe_toxic\n    obscene\n    threat\n    insult\n    identity_hate\n\nYou must create a model which predicts a probability of each type of toxicity for each comment.\n\n**File descriptions**\n\n    train.csv - the training set, contains comments with their binary labels\n    test.csv - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.\n    sample_submission.csv - a sample submission file in the correct format\n    "},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_uuid":"918b78bf67a06cea1727671184be3a401a67a08f","_cell_guid":"d7b8c968-336f-48c0-abbd-678e987e52e4"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"print('DataFrame Train:')\nprint(df_train.isnull().any())\nprint('\\n')\nprint('DataFrame Test:')\nprint(df_test.isnull().any())"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"df_test = df_test.fillna('unknown')"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"col = np.array(df_train.columns)\ncol = col[2:]\nprint(col)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"print('Dataframe Train:')\nfor c in col:\n    print(\"The dataframe has '{1}' of comments '{0}' of the total '{2}'.\".format(c, \n                                                                                 df_train[c].sum(), \n                                                                                 len(df_train)))"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"comment_text_all = pd.concat([df_train['comment_text'], df_test['comment_text']],axis=0)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"nrow_train = df_train.shape[0]\nprint(nrow_train)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode')"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"train_test_comment_text = vectorizer.fit_transform(comment_text_all)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"y = df_train[col]\ny.head(5)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"predict = np.zeros((df_test.shape[0], len(col)))\npredict.shape"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"loss = []\naccuracy = []\nfor num, index in enumerate(col):\n    x_train, x_test, y_train, y_test = train_test_split(train_test_comment_text[:nrow_train], y[index])\n    print(\"Fit: {}\".format(index))\n    model = LogisticRegression(C=5)\n    model.fit(x_train, y_train)\n    predict[:,num] = model.predict_proba(train_test_comment_text[nrow_train:])[:,1]    \n    predict_01 = model.predict_proba(x_test)[:,1]    \n    logloss = log_loss(y_test, predict_01)\n    print('log loss:', logloss)\n    predict_02 = model.predict(x_test)\n    acc = np.mean(predict_02 == y_test)\n    print('accuracy:', acc)\n    loss.append(logloss)\n    accuracy.append(acc)\n    print('\\n')\nprint('mean column-wise log loss:', np.mean(loss))\nprint('mean column-wise accuracy:', np.mean(accuracy))"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"submid = pd.DataFrame({'id': submission[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(predict, columns = col)], axis=1)\nsubmission.to_csv('submission.csv', index=False)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":""}],"metadata":{"language_info":{"nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","version":"3.6.3"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat_minor":1,"nbformat":4}