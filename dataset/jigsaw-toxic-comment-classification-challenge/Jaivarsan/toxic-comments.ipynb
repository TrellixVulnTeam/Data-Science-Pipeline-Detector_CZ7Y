{"cells":[{"cell_type":"markdown","source":"# Kaggle Toxic Comments Challenge","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gensim\nimport keras","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/train.csv',index_col='id')\ndf_test = pd.read_csv('../input/test.csv', index_col = 'id')","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"df_test.isnull().sum()","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"df_test.fillna('', inplace = True)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"df.head()","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"df.shape","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"df.info()","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"simple_tokens = df.comment_text.apply(gensim.utils.simple_preprocess)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"simple_tokens","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"df[df.index==999898414104]['comment_text'] # this is the actual conversion : [it, staying, let, move, on, corbett]","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"phrases = gensim.models.phrases.Phrases(simple_tokens)\ntokenizer = gensim.models.phrases.Phraser(phrases)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"tokenized_text = list(tokenizer[simple_tokens]) # a 2D list of all the keywords from comment_text","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"tokenized_text[0]","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"corpus_dict = gensim.corpora.dictionary.Dictionary(tokenized_text)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"TARGET_CLASSES = df.columns[1:]","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"TARGET_CLASSES","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"targets = df[TARGET_CLASSES].values","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Analysis using seaborn","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"sns.distplot([len(doc) for doc in tokenized_text], bins=100, kde=False, label='Number of tokens per comment.')\nplt.xlabel(\"Tokens in a comment\")\nplt.ylabel(\"Frequency\")\nplt.xlim((0, 400))","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Training word2vec on comment data","metadata":{}},{"cell_type":"code","source":"word2vec = gensim.models.word2vec.Word2Vec(tokenized_text, window=5, size=100, min_count=2, workers=6)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"word2vec.wv.most_similar('popularity')","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"word2vec.wv.most_similar('idiot')","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## word2vec-based based model.","metadata":{}},{"cell_type":"code","source":"features = np.zeros((len(tokenized_text), word2vec.vector_size))\nfor i, tokens in enumerate(tokenized_text):\n    tokens = [t for t in tokens if t in word2vec.wv.vocab]\n    if tokens:\n        features[i, :] = np.mean([word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens], axis=0)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\nmodel.add(Dense(256, activation='relu', input_shape=(word2vec.vector_size,)))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(len(TARGET_CLASSES), activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"model.fit(features, targets, epochs=10, validation_split=0.1)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"# serialize model to YAML\nmodel_yaml = model.to_yaml()\nwith open(\"model-baseline.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n    \n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model-baseline.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# serialize weights to HDF5\nmodel.save_weights(\"model-baseline.h5\")\nprint(\"Saved model to disk\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Sequential models","metadata":{}},{"cell_type":"code","source":"# Note: shifting indices by 1 as index 0 will be used for padding.\ndocs = [[idx + 1 for idx in corpus_dict.doc2idx(doc)]  for doc in tokenized_text]","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"MAX_SEQ_LEN = 50\npadded_docs = keras.preprocessing.sequence.pad_sequences(docs, maxlen=MAX_SEQ_LEN, truncating='post', value=0)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"max_idx = max(c for d in docs for c in d)\nmax_idx","outputs":[],"execution_count":null,"metadata":{"scrolled":true}},{"cell_type":"code","source":"embeddings = np.array([np.random.normal(size=word2vec.vector_size)]+ # for the '0' padding word\n                      [word2vec.wv[corpus_dict[idx]]\n                      if corpus_dict[idx] in word2vec.wv.vocab\n                      else np.random.normal(size=word2vec.vector_size)\n                      for idx in range(max_idx)])","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import SimpleRNN\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.wrappers import TimeDistributed\nfrom keras.layers import Convolution1D, MaxPool1D, Flatten, BatchNormalization\n\nmodel = Sequential()\nmodel.add(Embedding(max_idx + 1, word2vec.vector_size, input_length=MAX_SEQ_LEN))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Convolution1D(52, 5, padding='same',\n                        kernel_regularizer=keras.regularizers.l2(0.01)))\nmodel.add(MaxPool1D())\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Convolution1D(128, 3, padding='same',\n                        kernel_regularizer=keras.regularizers.l2(0.01)))\nmodel.add(MaxPool1D())\nmodel.add(Flatten())\nmodel.add(Dense(len(TARGET_CLASSES), activation='sigmoid',\n                kernel_regularizer=keras.regularizers.l2(0.02)))\nmodel.compile(Adam(0.001), 'binary_crossentropy')","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"model.fit(padded_docs, targets, batch_size=512, epochs=20, validation_split=0.1)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"# serialize model to YAML\nmodel_yaml = model.to_yaml()\nwith open(\"model-cnn.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n    \n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model-cnn.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# serialize weights to HDF5\nmodel.save_weights(\"model-cnn.h5\")\nprint(\"Saved model to disk\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def comment_to_sequential_input(comment):\n    tokens = tokenizer[gensim.utils.simple_preprocess(comment)]\n    t_ids = [corpus_dict.token2id[t] + 1 for t in tokens if t in word2vec.wv.vocab and t in corpus_dict.token2id]\n    return keras.preprocessing.sequence.pad_sequences([t_ids], maxlen=MAX_SEQ_LEN)[0]","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"test_input = [comment_to_sequential_input(\"You are a jerk you freakin indian.\").reshape(1, -1)]\nfor target_class, score in zip(TARGET_CLASSES, model.predict(test_input)[0]):\n    print(\"{}: {:.2f}%\".format(target_class, score * 100))","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"test_inputs = np.array([comment_to_sequential_input(doc) for doc in df_test.comment_text])","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"test_outputs = model.predict(test_inputs)","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"test_outputs[0]","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"output_df = df_test.reset_index()[['id']].copy()","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"for i, target_class in enumerate(TARGET_CLASSES):\n    output_df[target_class] = test_outputs[:, i]","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"code","source":"output_df[output_df.toxic > 0.5].sample(10, random_state=0).merge(df_test.reset_index(), on='id')","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"output_df.to_csv('cnn-pred.csv', index=False)","outputs":[],"execution_count":null,"metadata":{}}],"nbformat":4,"nbformat_minor":1,"metadata":{"language_info":{"file_extension":".py","version":"3.6.0","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}