{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-19T07:59:08.131586Z","iopub.execute_input":"2022-01-19T07:59:08.131907Z","iopub.status.idle":"2022-01-19T07:59:08.143448Z","shell.execute_reply.started":"2022-01-19T07:59:08.131872Z","shell.execute_reply":"2022-01-19T07:59:08.142448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom datetime import datetime\nfrom collections import Counter\nimport re, spacy, string\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom pprint import pprint\nimport time\n\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n# set options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:08.145171Z","iopub.execute_input":"2022-01-19T07:59:08.145915Z","iopub.status.idle":"2022-01-19T07:59:08.712295Z","shell.execute_reply.started":"2022-01-19T07:59:08.145868Z","shell.execute_reply":"2022-01-19T07:59:08.711284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"path = '../input/jigsaw-toxic-comment-classification-challenge/'\ndf = pd.read_csv(path+'train.csv.zip')\ndf_test = pd.read_csv(path+'test.csv.zip')\ndf_submission = pd.read_csv(path+'sample_submission.csv.zip')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:08.714194Z","iopub.execute_input":"2022-01-19T07:59:08.71452Z","iopub.status.idle":"2022-01-19T07:59:11.856579Z","shell.execute_reply.started":"2022-01-19T07:59:08.714477Z","shell.execute_reply":"2022-01-19T07:59:11.855652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking shape of the data","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:11.858652Z","iopub.execute_input":"2022-01-19T07:59:11.859208Z","iopub.status.idle":"2022-01-19T07:59:11.86513Z","shell.execute_reply.started":"2022-01-19T07:59:11.859158Z","shell.execute_reply":"2022-01-19T07:59:11.864218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking missing values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:11.867631Z","iopub.execute_input":"2022-01-19T07:59:11.867963Z","iopub.status.idle":"2022-01-19T07:59:11.91288Z","shell.execute_reply.started":"2022-01-19T07:59:11.867919Z","shell.execute_reply":"2022-01-19T07:59:11.911913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments = df.drop(['id','comment_text'],axis = 1)\ncomments.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:11.914753Z","iopub.execute_input":"2022-01-19T07:59:11.915064Z","iopub.status.idle":"2022-01-19T07:59:11.925483Z","shell.execute_reply.started":"2022-01-19T07:59:11.915019Z","shell.execute_reply":"2022-01-19T07:59:11.924658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of the target variable data in terms of proportions.\n\nfor i in list(comments.columns):\n    print(\"Percent of {0}s: \".format(i), round(100*comments[i].mean(),2), \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:11.926856Z","iopub.execute_input":"2022-01-19T07:59:11.927648Z","iopub.status.idle":"2022-01-19T07:59:11.947652Z","shell.execute_reply.started":"2022-01-19T07:59:11.9276Z","shell.execute_reply":"2022-01-19T07:59:11.946701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"com_dict = {}\nfor i in list(comments.columns):\n    com_dict[i]=comments[i].sum()\n\ncom_list = sorted(com_dict,key=com_dict.get,reverse=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:11.951224Z","iopub.execute_input":"2022-01-19T07:59:11.951896Z","iopub.status.idle":"2022-01-19T07:59:11.959596Z","shell.execute_reply.started":"2022-01-19T07:59:11.951844Z","shell.execute_reply":"2022-01-19T07:59:11.959026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### visualization of the distribution of types of toxic comments","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(com_list,comments.sum().sort_values(ascending=False))\nplt.xticks(rotation=80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:11.960595Z","iopub.execute_input":"2022-01-19T07:59:11.961032Z","iopub.status.idle":"2022-01-19T07:59:12.179134Z","shell.execute_reply.started":"2022-01-19T07:59:11.960991Z","shell.execute_reply":"2022-01-19T07:59:12.178121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"# Function to clean the review text and remove all the unnecessary elements.\n\ndef clean_review_text(text):\n    text = text.lower()  # covert the text to lowercase\n    text = re.sub('<.*?>','',text).strip() # remove html chars\n    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n    return text.strip()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:12.182271Z","iopub.execute_input":"2022-01-19T07:59:12.182601Z","iopub.status.idle":"2022-01-19T07:59:12.18795Z","shell.execute_reply.started":"2022-01-19T07:59:12.182564Z","shell.execute_reply":"2022-01-19T07:59:12.187369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.comment_text = df.comment_text.astype(str)\ndf.comment_text = df.comment_text.apply(clean_review_text)\ndf.comment_text.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:59:12.190234Z","iopub.execute_input":"2022-01-19T07:59:12.190558Z","iopub.status.idle":"2022-01-19T07:59:27.423638Z","shell.execute_reply.started":"2022-01-19T07:59:12.19053Z","shell.execute_reply":"2022-01-19T07:59:27.422724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lemmatization","metadata":{}},{"cell_type":"code","source":"# Snowball stemmer\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\n\nsnow_stemmer = SnowballStemmer(language='english')\n\nstopwords = nlp.Defaults.stop_words\ndef apply_stemmer(text):\n    words = text.split()\n    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n    return ' '.join(sent)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:34:11.021571Z","iopub.execute_input":"2022-01-19T08:34:11.021907Z","iopub.status.idle":"2022-01-19T08:34:11.02875Z","shell.execute_reply.started":"2022-01-19T08:34:11.021872Z","shell.execute_reply":"2022-01-19T08:34:11.028062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.comment_text = df.comment_text.apply(apply_stemmer)\ndf.comment_text.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:34:11.03036Z","iopub.execute_input":"2022-01-19T08:34:11.031253Z","iopub.status.idle":"2022-01-19T08:36:12.144019Z","shell.execute_reply.started":"2022-01-19T08:34:11.031204Z","shell.execute_reply":"2022-01-19T08:36:12.143118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using a word cloud find the top 50 words by frequency among all the review texts\n!pip install wordcloud\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(stopwords=stopwords,max_words=50).generate(str(df.comment_text))\n\nprint(wordcloud)\nplt.figure(figsize=(10,6))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:36:12.145414Z","iopub.execute_input":"2022-01-19T08:36:12.145824Z","iopub.status.idle":"2022-01-19T08:36:30.974823Z","shell.execute_reply.started":"2022-01-19T08:36:12.145786Z","shell.execute_reply":"2022-01-19T08:36:30.971188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.comment_text\ny = df.drop(['id','comment_text'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:36:30.976706Z","iopub.execute_input":"2022-01-19T08:36:30.977757Z","iopub.status.idle":"2022-01-19T08:36:30.985831Z","shell.execute_reply.started":"2022-01-19T08:36:30.977695Z","shell.execute_reply":"2022-01-19T08:36:30.984889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into test and train\nfrom sklearn.model_selection import train_test_split\nseed = 100 \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:36:30.9883Z","iopub.execute_input":"2022-01-19T08:36:30.988542Z","iopub.status.idle":"2022-01-19T08:36:31.077963Z","shell.execute_reply.started":"2022-01-19T08:36:30.988512Z","shell.execute_reply":"2022-01-19T08:36:31.077297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n\nword_vectorizer = TfidfVectorizer(\n    strip_accents='unicode',     \n    analyzer='word',            \n    token_pattern=r'\\w{1,}',    \n    ngram_range=(1, 3),         \n    stop_words='english',\n    sublinear_tf=True)\n\nword_vectorizer.fit(X_train)    # Fiting it on Train\ntrain_word_features = word_vectorizer.transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:36:31.079634Z","iopub.execute_input":"2022-01-19T08:36:31.080163Z","iopub.status.idle":"2022-01-19T08:37:33.926415Z","shell.execute_reply.started":"2022-01-19T08:36:31.080115Z","shell.execute_reply":"2022-01-19T08:37:33.925741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## transforming the train and test datasets\nX_train_transformed = word_vectorizer.transform(X_train)\nX_test_transformed = word_vectorizer.transform(X_test)\n\n\n# # Print the shape of each dataset.\nprint('X_train_transformed', X_train_transformed.shape)\nprint('y_train', y_train.shape)\nprint('X_test_transformed', X_test_transformed.shape)\nprint('y_test', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:37:33.928002Z","iopub.execute_input":"2022-01-19T08:37:33.928295Z","iopub.status.idle":"2022-01-19T08:37:57.153506Z","shell.execute_reply.started":"2022-01-19T08:37:33.928259Z","shell.execute_reply":"2022-01-19T08:37:57.152412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\n\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:37:57.154824Z","iopub.execute_input":"2022-01-19T08:37:57.155088Z","iopub.status.idle":"2022-01-19T08:37:57.161021Z","shell.execute_reply.started":"2022-01-19T08:37:57.155054Z","shell.execute_reply":"2022-01-19T08:37:57.160132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom skmultilearn.problem_transform import BinaryRelevance","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:37:57.162339Z","iopub.execute_input":"2022-01-19T08:37:57.162579Z","iopub.status.idle":"2022-01-19T08:37:57.175595Z","shell.execute_reply.started":"2022-01-19T08:37:57.162549Z","shell.execute_reply":"2022-01-19T08:37:57.174872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression \ntime1 = time.time()\n# logistic regression\nlog_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=seed)\n\n# fit model\nclassifier_ovr_log = OneVsRestClassifier(log_reg)\nclassifier_ovr_log.fit(X_train_transformed, y_train)\n\ntime_taken = time.time() - time1\nprint('Time Taken: {:.2f} seconds'.format(time_taken))\n\ny_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\ny_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)\n\n\nroc_auc_score_train = roc_auc_score(y_train, y_train_pred_proba,average='weighted')\nroc_auc_score_test = roc_auc_score(y_test, y_test_pred_proba,average='weighted')\n\nprint(\"ROC AUC Score Train:\", roc_auc_score_train)\nprint(\"ROC AUC Score Test:\", roc_auc_score_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:14:02.027318Z","iopub.execute_input":"2022-01-19T12:14:02.028099Z","iopub.status.idle":"2022-01-19T12:15:58.878704Z","shell.execute_reply.started":"2022-01-19T12:14:02.028033Z","shell.execute_reply":"2022-01-19T12:15:58.877631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred_proba","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:23:46.975962Z","iopub.execute_input":"2022-01-19T12:23:46.97638Z","iopub.status.idle":"2022-01-19T12:23:46.990547Z","shell.execute_reply.started":"2022-01-19T12:23:46.976337Z","shell.execute_reply":"2022-01-19T12:23:46.989167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = classifier_ovr_log","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:23:46.992487Z","iopub.execute_input":"2022-01-19T12:23:46.99274Z","iopub.status.idle":"2022-01-19T12:23:47.023381Z","shell.execute_reply.started":"2022-01-19T12:23:46.992712Z","shell.execute_reply":"2022-01-19T12:23:47.022392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:23:47.024922Z","iopub.execute_input":"2022-01-19T12:23:47.025205Z","iopub.status.idle":"2022-01-19T12:23:47.053252Z","shell.execute_reply.started":"2022-01-19T12:23:47.025173Z","shell.execute_reply":"2022-01-19T12:23:47.052072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_predictions(df,classifier):\n    df.comment_text = df.comment_text.astype(str)\n    df.comment_text = df.comment_text.apply(clean_review_text)\n    df.comment_text = df.comment_text.apply(apply_stemmer)\n    X_test = df.comment_text\n    X_test_transformed = word_vectorizer.transform(X_test)\n    y_test_pred = classifier.predict_proba(X_test_transformed)\n    y_test_pred_df = pd.DataFrame(y_test_pred,columns=comments.columns)\n    submission_df = pd.concat([df.id, y_test_pred_df], axis=1)\n    submission_df.to_csv('submission.csv', index = False)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:23:47.055198Z","iopub.execute_input":"2022-01-19T12:23:47.055445Z","iopub.status.idle":"2022-01-19T12:23:47.072276Z","shell.execute_reply.started":"2022-01-19T12:23:47.055415Z","shell.execute_reply":"2022-01-19T12:23:47.071092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_test_predictions(df_test,classifier)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T12:23:47.07387Z","iopub.execute_input":"2022-01-19T12:23:47.074651Z","iopub.status.idle":"2022-01-19T12:26:08.118533Z","shell.execute_reply.started":"2022-01-19T12:23:47.07459Z","shell.execute_reply":"2022-01-19T12:26:08.117221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}