{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re                                  \nimport string  \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nimport torch\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import EarlyStoppingCallback\nfrom transformers import BertModel, BertConfig","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:11.098346Z","iopub.execute_input":"2021-06-24T11:47:11.098673Z","iopub.status.idle":"2021-06-24T11:47:18.068682Z","shell.execute_reply.started":"2021-06-24T11:47:11.098587Z","shell.execute_reply":"2021-06-24T11:47:18.067875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\ntorch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:22.628569Z","iopub.execute_input":"2021-06-24T11:47:22.628913Z","iopub.status.idle":"2021-06-24T11:47:22.683224Z","shell.execute_reply.started":"2021-06-24T11:47:22.62888Z","shell.execute_reply":"2021-06-24T11:47:22.682446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\n\n\n# Will unzip the files so that you can see them..\nwith zipfile.ZipFile(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\",\"r\") as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:25.080516Z","iopub.execute_input":"2021-06-24T11:47:25.080849Z","iopub.status.idle":"2021-06-24T11:47:27.477697Z","shell.execute_reply.started":"2021-06-24T11:47:25.080818Z","shell.execute_reply":"2021-06-24T11:47:27.476862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df=pd.read_csv('./sample_submission.csv')\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2021-06-24T15:13:25.984483Z","iopub.execute_input":"2021-06-24T15:13:25.984813Z","iopub.status.idle":"2021-06-24T15:13:26.133893Z","shell.execute_reply.started":"2021-06-24T15:13:25.984764Z","shell.execute_reply":"2021-06-24T15:13:26.133068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv(\"./train.csv\")\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:31.219112Z","iopub.execute_input":"2021-06-24T11:47:31.21944Z","iopub.status.idle":"2021-06-24T11:47:31.871439Z","shell.execute_reply.started":"2021-06-24T11:47:31.21941Z","shell.execute_reply":"2021-06-24T11:47:31.870467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('./test.csv')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:34.931214Z","iopub.execute_input":"2021-06-24T11:47:34.931546Z","iopub.status.idle":"2021-06-24T11:47:35.489595Z","shell.execute_reply.started":"2021-06-24T11:47:34.931514Z","shell.execute_reply":"2021-06-24T11:47:35.488635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:38.309403Z","iopub.execute_input":"2021-06-24T11:47:38.309854Z","iopub.status.idle":"2021-06-24T11:47:38.317753Z","shell.execute_reply.started":"2021-06-24T11:47:38.309814Z","shell.execute_reply":"2021-06-24T11:47:38.316865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['comment_text'] = train_df['comment_text'].apply(lambda x: clean_text(x))\nX = list(train_df['comment_text'])\ny = np.array(train_df.loc[:,'toxic':])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:47:41.497453Z","iopub.execute_input":"2021-06-24T11:47:41.497779Z","iopub.status.idle":"2021-06-24T11:48:00.225203Z","shell.execute_reply.started":"2021-06-24T11:47:41.497748Z","shell.execute_reply":"2021-06-24T11:48:00.22433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['comment_text'] = test_df['comment_text'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:49:12.238653Z","iopub.execute_input":"2021-06-24T11:49:12.239021Z","iopub.status.idle":"2021-06-24T11:49:28.142677Z","shell.execute_reply.started":"2021-06-24T11:49:12.23899Z","shell.execute_reply":"2021-06-24T11:49:28.141851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:49:55.95737Z","iopub.execute_input":"2021-06-24T11:49:55.957685Z","iopub.status.idle":"2021-06-24T11:49:56.033367Z","shell.execute_reply.started":"2021-06-24T11:49:55.957655Z","shell.execute_reply":"2021-06-24T11:49:56.032549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\ndef preprocessing_for_bert(data):\n    input_ids = []\n    attention_masks = []\n    for sent in data:\n        encoded_sent = tokenizer.encode_plus(\n            text = sent,\n            add_special_tokens = True,\n            max_length = MAX_LEN,\n            pad_to_max_length = True,\n            return_attention_mask = True\n        )\n        input_ids.append(encoded_sent.get('input_ids'))\n        attention_masks.append(encoded_sent.get('attention_mask'))\n    input_ids = torch.tensor(input_ids)\n    attention_masks = torch.tensor(attention_masks)\n    \n    return input_ids, attention_masks","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:49:59.798913Z","iopub.execute_input":"2021-06-24T11:49:59.799231Z","iopub.status.idle":"2021-06-24T11:50:03.845002Z","shell.execute_reply.started":"2021-06-24T11:49:59.799203Z","shell.execute_reply":"2021-06-24T11:50:03.8442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_text = np.concatenate([train_df.comment_text.values, test_df.comment_text.values])\nlen_sent = [len(sent) for sent in all_text]\navg_len = np.mean(len_sent)\navg_len","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:50:07.823325Z","iopub.execute_input":"2021-06-24T11:50:07.823636Z","iopub.status.idle":"2021-06-24T11:50:07.955766Z","shell.execute_reply.started":"2021-06-24T11:50:07.823606Z","shell.execute_reply":"2021-06-24T11:50:07.9548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 150\ntoken_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\nprint(X[0])\nprint(token_ids)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:50:10.339017Z","iopub.execute_input":"2021-06-24T11:50:10.339348Z","iopub.status.idle":"2021-06-24T11:50:10.36316Z","shell.execute_reply.started":"2021-06-24T11:50:10.339318Z","shell.execute_reply":"2021-06-24T11:50:10.362317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs, train_masks = preprocessing_for_bert(X_train)\nval_inputs, val_masks = preprocessing_for_bert(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:50:13.095944Z","iopub.execute_input":"2021-06-24T11:50:13.096291Z","iopub.status.idle":"2021-06-24T11:55:43.778939Z","shell.execute_reply.started":"2021-06-24T11:50:13.09626Z","shell.execute_reply":"2021-06-24T11:55:43.778061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\ntrain_labels = torch.tensor(y_train)\nval_labels = torch.tensor(y_val)\nbatch_size = 32\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:02:41.792078Z","iopub.execute_input":"2021-06-24T12:02:41.792448Z","iopub.status.idle":"2021-06-24T12:02:41.811158Z","shell.execute_reply.started":"2021-06-24T12:02:41.792417Z","shell.execute_reply":"2021-06-24T12:02:41.810357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport torch\nimport torch.nn as nn\nfrom transformers import BertModel\n\nclass BertClassifier(nn.Module):\n    def __init__(self, freeze_bert=False):\n        super(BertClassifier, self).__init__()\n        D_in, H, D_out = 768, 50, 6\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.classifier = nn.Sequential(\n                        nn.Linear(D_in, H),\n                        nn.ReLU(),\n                        nn.Linear(H, D_out))\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n    \n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state_cls = outputs[0][:,0,:]\n        logits = self.classifier(last_hidden_state_cls)\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:02:45.151264Z","iopub.execute_input":"2021-06-24T12:02:45.151593Z","iopub.status.idle":"2021-06-24T12:02:45.159318Z","shell.execute_reply.started":"2021-06-24T12:02:45.151562Z","shell.execute_reply":"2021-06-24T12:02:45.158398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\ndef initialize_model(epochs=4):\n    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n    \"\"\"\n    \n    # Instantiate Bert Classifier\n    bert_classifier = BertClassifier(freeze_bert=False)\n    \n    bert_classifier.to(device)\n    \n    # Create the optimizer\n    optimizer = AdamW(bert_classifier.parameters(),\n                     lr=5e-5, #Default learning rate\n                     eps=1e-8 #Default epsilon value\n                     )\n    \n    # Total number of training steps\n    total_steps = len(train_dataloader) * epochs\n    \n    # Set up the learning rate scheduler\n    scheduler = get_linear_schedule_with_warmup(optimizer, \n                                              num_warmup_steps=0, # Default value\n                                              num_training_steps=total_steps)\n    return bert_classifier, optimizer, scheduler","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:02:49.095266Z","iopub.execute_input":"2021-06-24T12:02:49.095591Z","iopub.status.idle":"2021-06-24T12:02:49.101923Z","shell.execute_reply.started":"2021-06-24T12:02:49.09556Z","shell.execute_reply":"2021-06-24T12:02:49.100708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport time\n\nloss_fn = nn.BCEWithLogitsLoss()\n\ndef set_seed(seed_value=42):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n\ndef train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n    print(\"Start training...\\n\")\n    for epoch_i in range(epochs):\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*70)\n        t0_epoch, t0_batch = time.time(), time.time()\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n        model.train()\n        \n        for step, batch in enumerate(train_dataloader):\n            batch_counts += 1\n            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n            model.zero_grad()\n            logits = model(b_input_ids, b_attn_mask)\n            loss = loss_fn(logits, b_labels.float())\n            batch_loss += loss.item()\n            total_loss += loss.item()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n        \n            if (step % 10 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                time_elapsed = time.time() - t0_batch\n                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n    avg_train_loss = total_loss / len(train_dataloader)\n    \n    print(\"-\"*70)\n    \n    if evaluation == True:\n        val_loss, val_accuracy = evaluate(model, val_dataloader)\n        time_elapsed = time.time() - t0_epoch\n        print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n        print(\"-\"*70)\n    print(\"\\n\")\n    \nprint(\"Training complete!\")","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:43:26.094216Z","iopub.execute_input":"2021-06-24T12:43:26.094537Z","iopub.status.idle":"2021-06-24T12:43:26.109314Z","shell.execute_reply.started":"2021-06-24T12:43:26.094507Z","shell.execute_reply":"2021-06-24T12:43:26.106042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_dataloader):\n    model.eval()\n    val_accuracy = []\n    val_loss = []\n    for batch in val_dataloader:\n        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n        loss = loss_fn(logits, b_labels.float())\n        val_loss.append(loss.item())\n        accuracy = accuracy_thresh(logits.view(-1,6), b_labels.view(-1,6))\n        val_accuracy.append(accuracy)\n    val_loss = np.mean(val_loss)\n    val_accuracy = np.mean(val_accuracy)\n    \n    return val_loss, val_accuracy\n\ndef accuracy_thresh(y_pred, y_true, thresh:float=0.5, sigmoid:bool=True):\n    if sigmoid:\n        y_pred = y_pred.sigmoid()\n    return ((y_pred>thresh)==y_true.byte()).float().mean().item()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T13:20:07.486597Z","iopub.execute_input":"2021-06-24T13:20:07.486956Z","iopub.status.idle":"2021-06-24T13:20:07.495157Z","shell.execute_reply.started":"2021-06-24T13:20:07.48692Z","shell.execute_reply":"2021-06-24T13:20:07.493833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(42)\nbert_classifier, optimizer, scheduler = initialize_model(epochs=1)\ntrain(bert_classifier, train_dataloader, val_dataloader, epochs=1, evaluation=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T13:20:10.977343Z","iopub.execute_input":"2021-06-24T13:20:10.977678Z","iopub.status.idle":"2021-06-24T13:51:51.585919Z","shell.execute_reply.started":"2021-06-24T13:20:10.977647Z","shell.execute_reply":"2021-06-24T13:51:51.583922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef bert_predict(model, test_dataloader):\n    model.eval()\n    all_logits = []\n    for batch in test_dataloader:\n        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n        all_logits.append(logits)\n    all_logits = torch.cat(all_logits, dim=0)\n    probs = all_logits.sigmoid().cpu().numpy()\n    \n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:22:12.6141Z","iopub.execute_input":"2021-06-24T14:22:12.61445Z","iopub.status.idle":"2021-06-24T14:22:12.620091Z","shell.execute_reply.started":"2021-06-24T14:22:12.61442Z","shell.execute_reply":"2021-06-24T14:22:12.619269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = bert_predict(bert_classifier, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:22:15.924121Z","iopub.execute_input":"2021-06-24T14:22:15.924433Z","iopub.status.idle":"2021-06-24T14:26:34.667628Z","shell.execute_reply.started":"2021-06-24T14:22:15.924404Z","shell.execute_reply":"2021-06-24T14:26:34.666796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inputs, test_masks = preprocessing_for_bert(test_df.comment_text)\ntest_dataset = TensorDataset(test_inputs, test_masks)\ntest_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:11.799338Z","iopub.execute_input":"2021-06-24T14:43:11.799648Z","iopub.status.idle":"2021-06-24T14:48:07.160045Z","shell.execute_reply.started":"2021-06-24T14:43:11.79962Z","shell.execute_reply":"2021-06-24T14:48:07.15903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = bert_predict(bert_classifier, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:49:18.945219Z","iopub.execute_input":"2021-06-24T14:49:18.945541Z","iopub.status.idle":"2021-06-24T15:01:51.414977Z","shell.execute_reply.started":"2021-06-24T14:49:18.945508Z","shell.execute_reply":"2021-06-24T15:01:51.414131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(probs,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'])\ntest_df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]=submission\nfinal_sub = test_df[['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T15:14:29.498702Z","iopub.execute_input":"2021-06-24T15:14:29.499033Z","iopub.status.idle":"2021-06-24T15:14:29.514233Z","shell.execute_reply.started":"2021-06-24T15:14:29.499Z","shell.execute_reply":"2021-06-24T15:14:29.513299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T15:14:34.828127Z","iopub.execute_input":"2021-06-24T15:14:34.828465Z","iopub.status.idle":"2021-06-24T15:14:36.473761Z","shell.execute_reply.started":"2021-06-24T15:14:34.828433Z","shell.execute_reply":"2021-06-24T15:14:36.472747Z"},"trusted":true},"execution_count":null,"outputs":[]}]}