{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Magic Of Tensorflow \n### Tensorflow can create magic with simplest implementaion .This Kernel is proof of that \n### If you are Beginner in NLP and Tensorflow then this for You \n### Achieved 99% Accuracy with this implementation.Upvotes are really appreciable !!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load All important packages "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\npd.set_option('display.max_colwidth', -1)\nimport warnings; warnings.simplefilter('ignore')\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read train and Test CSV File"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check some values of toxic comments "},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['toxic']== -1].head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### this is multi class classification problem , for simplicity we will consider only one column at a time i.e 'toxic' as label"},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking comment_text as input feature and toxic as output feature \n\n#list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n#train_labels = train[list_classes].values\ntrain_data = train[['comment_text']]\ntrain_labels = train['toxic']\ntest_data = test[['comment_text']]\n#test_labels = test[['toxic']]\n#pd.DataFrame(train_data)\nprint('training data shape',train_data.shape)\nprint('training label shape',train_labels.shape)\nprint('testing data shape',test_data.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning is require as there are so many junk values , chracters and symbol\n### first we will convert all char to lower case and will perform operations "},{"metadata":{"trusted":true},"cell_type":"code","source":"#data pre-processing packages \nfrom nltk.corpus import stopwords\nfrom nltk import WordNetLemmatizer\nfrom nltk import pos_tag, word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert to lower case \n\ntrain_data['comment_text'] = train_data['comment_text'].str.lower()\ntest_data['comment_text'] = test_data['comment_text'].str.lower()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove \\n \n#print(train_data['comment_text'].head(2))\ntrain_data['comment_text'] = train_data['comment_text'].str.replace('\\n',' ')\ntest_data['comment_text'] = test_data['comment_text'].str.replace('\\n',' ')\n#print(train_data['comment_text'].head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#similarly replace all possible phrases \ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"i'm\",'i am')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"he's\",'he is')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"weren't\",'were not')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"she's\",'she is')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"that's\",'that is')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"you'r\",'you are')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"what's\",'what is')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"how's\",'how is')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"where's\",'where is')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"\\'ll\",'will')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"\\'ve\", \"have\")\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"won't\",'will not')\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"can't\",'can not')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#similarly replace all possible phrases in test\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"i'm\",'i am')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"he's\",'he is')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"weren't\",'were not')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"she's\",'she is')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"that's\",'that is')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"you'r\",'you are')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"what's\",'what is')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"how's\",'how is')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"where's\",'where is')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"\\'ll\",'will')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"\\'ve\", \"have\")\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"won't\",'will not')\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"can't\",'can not')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove ip address \ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\")\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\")\n\n#train_data['comment_text'] = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\",train_data['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove username \ntrain_data['comment_text'] = train_data['comment_text'].str.replace(\"\\[\\[.*\\]\",\"\")\ntest_data['comment_text'] = test_data['comment_text'].str.replace(\"\\[\\[.*\\]\",\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove symbols , special char\ntrain_data['comment_text'] = train_data['comment_text'].str.replace(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\")\ntest_data['comment_text'] = test_data['comment_text'].str.replace(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenizing and Padding Words \n### In Tensorflow we cant process stream of characters as it as , so convert them into integer format .Now Each statement is of differrent length so need to convert it into same length hence extra padding of 0 is required\n### It is good practice to define all imp parameter before code as shown below , here i am taking vocab_size = 20k , max_lenght = 200 and embedding size = 16"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 20000\nembedding_dim = 16\nmax_length = 200\ntrunc_type = 'post'\noov_tok =\"<OOV>\"\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nlist_train_sentences = train_data['comment_text']\nlist_test_sentences = test_data['comment_text']\ntokenizer = Tokenizer(num_words = vocab_size,oov_token=oov_tok)\ntokenizer.fit_on_texts(list(list_train_sentences))\ntokenizer.fit_on_texts(list(list_test_sentences))\nword_index = tokenizer.word_index\ntrain_sequences = tokenizer.texts_to_sequences(list_train_sentences)\ntrain_padded = pad_sequences(train_sequences,maxlen=max_length,truncating=trunc_type)\n\ntest_sequences = tokenizer.texts_to_sequences(list_test_sentences)\ntest_padded = pad_sequences(test_sequences,maxlen=max_length,truncating=trunc_type)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build model \nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(6,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 99% accuracy is achieved with Basic Tensorflow Implementation !!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\nnum_epochs = 10\nmodel.fit(train_padded,train_labels,epochs=num_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict toxicity on Test Data \nnum_epochs = 10\ntest_res = model.predict(test_padded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create New data Frame For Predicted Toxic Values for 'toxic' column\ntest_result = pd.DataFrame(test_res,columns=['Predicted'])\ntest_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read Actual Toxic Value for comarision \n#test_l = pd.read_csv(r'../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n#test_l = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n# for some reason kaggel was not reading test_labels file so i uploaded externally and reading as follows \n# otherwise you can uncomment above \ntest_l = pd.read_csv('../input/test-lab/test_labels.csv')\n#../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv\ntest_result['Actual'] = test_l['toxic']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check Comparision \ntest_result.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### you can check from above predicted and actual values most of the values are correctly predicted specially value 0 , there is no explanation of value -1 in problem statement, infact there are no -1 values in train set.So need Feature Engineering there !\n\n### We have calculated it for only column 'toxic' , similarly you can try for other column and can submit by uncommenting below cell \n\n### If you really like this kernel , please upvote it and give feedback in comment section below , Thanks !\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_submission = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n# sample_submission['toxic'] = test_res\n# sample_submission.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}