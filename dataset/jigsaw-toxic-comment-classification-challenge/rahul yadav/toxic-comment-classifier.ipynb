{"cells":[{"metadata":{"_uuid":"49daba6e4a24b0494d2fe64f65548cab72fefa7c","scrolled":true,"_cell_guid":"36ebea9c-5130-41be-8907-8f41b29944b4","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import RidgeClassifier\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.linear_model.logistic import LogisticRegression\n#from xgboost import XGBClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom lightgbm.sklearn import LGBMClassifier \n\n\n\nprint('Reading data...')\ntrain=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\n\ndf_train=train.copy()\nfor col in df_train.columns.values:\n  df_train[col]=df_train[col].astype('str')\n\nprint('Transforming target field...')\ndf_train['target']=df_train.apply(lambda x: x.toxic+x.severe_toxic+x.obscene+x.threat+x.insult+x.identity_hate,axis=1)\ndf_train['target']=df_train.target.apply(lambda x: int(x,2))\n\ndf_train=df_train.drop(['toxic','severe_toxic','obscene','threat','insult','identity_hate'],axis=1)\n\nprint('Execution finished....')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da18f2de3bf087ce40a8915761e4c99ca9a0edb5","scrolled":true,"_cell_guid":"747e35a3-b91d-4913-9539-2e53ae3aba50","trusted":true},"cell_type":"code","source":"df_target=pd.DataFrame(df_train.target.unique(),columns=['target'])\ndf_target['num']=df_target.target.apply(lambda x: len(df_train[df_train.target==x]))\ndf_target['percentage']=df_target.num.apply(lambda x: (x/len(df_train))*100)\ndf_target","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2457206ee4071f52e0eb8fb21b6a550115ec26c8","_cell_guid":"ebc78bee-0a7e-4066-b0d5-5fe5b6081f61"},"cell_type":"markdown","source":"**OBSERVATIONS**\n* This is an example of Imbalanced classed. Need to do some data preparation activities to balance the classes.\n* Selecting correct algorithum for this task"},{"metadata":{"_uuid":"53442beb15695181d121ecab5aa6cfc431037772","_cell_guid":"445f9c6f-798a-4e2c-a98e-68ff9f8d538c","collapsed":true,"trusted":true},"cell_type":"code","source":"def get_sparse(df,df1,df2):\n  \n  Tvect=TfidfVectorizer(ngram_range=(1,4))  \n\n  vect=Tvect.fit(df)\n  vect1=vect.transform(df)\n  vect2=vect.transform(df1)\n  vect3=vect.transform(df2)\n  \n  return(vect1,vect2,vect3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2966a33d0c239846881088f335e4f9c0632345c6","_cell_guid":"670e030c-00c7-49d3-945f-ba9cdf93003f","collapsed":true,"trusted":true},"cell_type":"code","source":"def get_sparseH(df,df1,df2):\n  \n  Hvect=HashingVectorizer(ngram_range=(1,4))  \n\n  vect=Hvect.fit(df)\n  vect1=vect.transform(df)\n  vect2=vect.transform(df1)\n  vect3=vect.transform(df2)\n  \n  return(vect1,vect2,vect3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43a4188597920fbb08fbc0513ae2f6a4cd8911c1","scrolled":false,"_cell_guid":"e1286d89-fd08-4218-aa0f-caa06e3ded24","trusted":true},"cell_type":"code","source":"df_y=df_train.target\ndf_X=df_train.comment_text\ntrain_X,test_X,train_y,test_y=train_test_split(df_X,df_y)\nprint('train shape:',train_X.shape,train_y.shape)\nprint('test shape:',test_X.shape,test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21e8bfcc06b08a5c130cfba08e76a8d8200da8d4","_cell_guid":"631df568-3e9c-44f4-9cf3-cace24a107a4","collapsed":true,"trusted":true},"cell_type":"code","source":"df_pred_X=test.comment_text","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dd9b6fc33283844565e24da4b9aca8b055fadab","scrolled":false,"_cell_guid":"8211217a-95cb-4436-b0ce-91a7165c7466","trusted":true},"cell_type":"code","source":"%%time\nsp_train,sp_test,sp_pred=get_sparseH(train_X,test_X,df_pred_X)\nprint(sp_train.shape,sp_test.shape,sp_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e05d85e349af24f243185d6177eabe399eb5e87c","scrolled":true,"_cell_guid":"144bb1a8-7ff1-42d2-aa45-7d09636a6602","trusted":true},"cell_type":"code","source":"clf=LGBMClassifier(n_jobs=-1,objective='multi:softmax')\nclf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e4f7edfc49c930b9f02392091eba420a31aa5c1","scrolled":true,"_cell_guid":"cefcbe08-9232-4c39-93ed-db793f603eb4","collapsed":true,"trusted":true},"cell_type":"code","source":"%%time\n\n\nclf.fit(sp_train,train_y)\npred_y=clf.predict(sp_test)\nprint('accuracy for classifier is:',accuracy_score(test_y,pred_y))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6740524deee654742fab9f49776f66be762cfe4","_cell_guid":"0140925d-c9e8-4e8d-9522-556a01bc9b0a","collapsed":true,"trusted":false},"cell_type":"code","source":"print(metrics.classification_report(test_y,pred_y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"926f7b818aea36cda19d2cd3691b10fd218b9ae8","_cell_guid":"62126233-04f4-4ff5-b0c0-cc193a1b221a","collapsed":true,"trusted":false},"cell_type":"code","source":"%%time\ndf_final_sub=pd.DataFrame(test.id,columns=['id','target'])\ndf_final_sub['target']=clf.predict(sp_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e87042a61000fab9a5b7f16ca80ad0d21dd5e194","scrolled":true,"_cell_guid":"9460c917-4004-4e69-b83b-64c379bf98a8","collapsed":true,"trusted":false},"cell_type":"code","source":"df_final=pd.DataFrame(df_final_sub.target.unique(),columns=['target'])\ndf_final['count']=df_final.target.apply(lambda x: len(df_final_sub[df_final_sub.target==x]))\ndf_final","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc0a88626ff681a50ed0cb1916da9660af004142","scrolled":true,"_cell_guid":"58bc0de6-39b9-4549-8c7a-2a6b78d2062d","collapsed":true,"trusted":false},"cell_type":"code","source":"df_target","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9675301df3299b43baa1f4868ca12559162626c5","_cell_guid":"d8506db2-f484-4dc6-9f29-8155165adcae","collapsed":true,"trusted":false},"cell_type":"code","source":"df_final_sub1=df_final_sub.copy()\ndf_final_sub1['toxic']=df_final_sub1.target.apply(lambda x: '{:0>6}'.format(str(bin(x)).split('b')[1])[0])\ndf_final_sub1['severe_toxic']=df_final_sub1.target.apply(lambda x: '{:0>6}'.format(str(bin(x)).split('b')[1])[1])\ndf_final_sub1['obscene']=df_final_sub1.target.apply(lambda x: '{:0>6}'.format(str(bin(x)).split('b')[1])[2])\ndf_final_sub1['threat']=df_final_sub1.target.apply(lambda x: '{:0>6}'.format(str(bin(x)).split('b')[1])[3])\ndf_final_sub1['insult']=df_final_sub1.target.apply(lambda x: '{:0>6}'.format(str(bin(x)).split('b')[1])[4])\ndf_final_sub1['identity_hate']=df_final_sub1.target.apply(lambda x: '{:0>6}'.format(str(bin(x)).split('b')[1])[5])\ndf_final_sub1=df_final_sub1.drop(['target'],axis=1)\ndf_final_sub1.to_csv('final_sub.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"mimetype":"text/x-python","version":"3.6.5","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":1}