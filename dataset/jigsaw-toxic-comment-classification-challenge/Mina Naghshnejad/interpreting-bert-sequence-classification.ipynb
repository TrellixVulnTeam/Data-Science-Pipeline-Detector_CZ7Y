{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!wget https://github.com/t-davidson/hate-speech-and-offensive-language/raw/master/data/labeled_data.p\n\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n\n!pip install pandarallel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nfrom pandarallel import pandarallel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pandarallel.initialize(progress_bar=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\ntrain_df = pd.read_csv(os.path.join('./', 'train.csv'))\ntest_df = pd.read_csv(os.path.join('./', 'test.csv')).merge(pd.read_csv(os.path.join('./', 'test_labels.csv')), on='id')\ntest_df.drop(test_df[test_df[label_cols].min(axis=1) == -1].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train_df, test_df], ignore_index=True)\ndf['toxic?'] = df.parallel_apply(lambda row: row[label_cols].any(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(label_cols, inplace=True, axis=1)\ndf.drop('id', inplace=True, axis=1)\ndf.rename(columns={'comment_text': 'text'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_pickle('labeled_data.p')\ndf2.rename(columns={'tweet': 'text'}, inplace=True)\ndf2['toxic?'] = df2.parallel_apply(lambda row: int(row['class'] != 2), axis=1)\ndf2 = df2[['text', 'toxic?']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, df2], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_pickle('df.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['toxic?'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['toxic?'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install interpret-text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"QUICK_RUN = True\nTRAIN_DATA_FRACTION = 1\nTEST_DATA_FRACTION = 1\nNUM_EPOCHS = 1\nif QUICK_RUN:\n    TRAIN_DATA_FRACTION = 0.1\n    TEST_DATA_FRACTION = 0.1\n    NUM_EPOCHS = 1\nimport torch\nimport torch.nn as nn\n    \nif torch.cuda.is_available():\n    BATCH_SIZE = 1\nelse:\n    BATCH_SIZE = 9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n#split data\ndf_train, df_test = train_test_split(df, train_size = 0.6, random_state=0)\ndf_train = df_train.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\n\ndf_train = df_train.sample(frac=TRAIN_DATA_FRACTION).reset_index(drop=True)\ndf_test = df_test.sample(frac=TEST_DATA_FRACTION).reset_index(drop=True)\n# encode labels\nlabel_encoder = LabelEncoder()\nlabels_train = label_encoder.fit_transform(df_train[\"toxic?\"])\nlabels_test = label_encoder.transform(df_test[\"toxic?\"])\nnum_labels = len(np.unique(labels_train))\nprint(\"Number of unique labels: {}\".format(num_labels))\nprint(\"Number of training examples: {}\".format(df_train.shape[0]))\nprint(\"Number of testing examples: {}\".format(df_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from interpret_text.experimental.common.utils_bert import Language, Tokenizer\nBERT_CACHE_DIR = \"./temp\"\nLANGUAGE = Language.ENGLISH\ntokenizer = Tokenizer(LANGUAGE, to_lower=True, cache_dir=BERT_CACHE_DIR)\ntokens_train = tokenizer.tokenize(list(df_train[\"text\"]))\ntokens_test = tokenizer.tokenize(list(df_test[\"text\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 150\ntokens_train, mask_train, _ = tokenizer.preprocess_classification_tokens(tokens_train, MAX_LEN)\ntokens_test, mask_test, _ = tokenizer.preprocess_classification_tokens(tokens_test, MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_labels=2\nfrom interpret_text.experimental.common.utils_bert import BERTSequenceClassifier\nclassifier = BERTSequenceClassifier(language=LANGUAGE, num_labels=num_labels, cache_dir=BERT_CACHE_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from interpret_text.experimental.common.timer import Timer\nwith Timer() as t:\n    classifier.fit(token_ids=tokens_train,\n                    input_mask=mask_train,\n                    labels=labels_train,    \n                    num_epochs=NUM_EPOCHS,\n                    batch_size=BATCH_SIZE,    \n                    verbose=True)\nprint(\"[Training time: {:.3f} hrs]\".format(t.interval / 3600))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = classifier.predict(token_ids=tokens_test, \n                           input_mask=mask_test, \n                           batch_size=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\nimport json\nreport = classification_report(labels_test, preds, target_names=label_encoder.classes_, output_dict=True) \naccuracy = accuracy_score(labels_test, preds)\nprint(\"accuracy: {}\".format(accuracy))\n#print(json.dumps(report, indent=4, sort_keys=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\nclassifier.model.to(device)\nfor param in classifier.model.parameters():\n    param.requires_grad = False\nclassifier.model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from interpret_text.experimental.unified_information import UnifiedInformationExplainer\ninterpreter_unified = UnifiedInformationExplainer(model=classifier.model, \n                                 train_dataset=list(df_train[\"text\"]), \n                                 device=device, \n                                 target_layer=14, \n                                 classes=label_encoder.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 10\ntext = df_test[\"text\"][idx]\ntrue_label = df_test[\"toxic?\"][idx]\npredicted_label = label_encoder.inverse_transform([preds[idx]])\nprint(text, true_label, predicted_label)\nexplanation_unified = interpreter_unified.explain_local(text, true_label, predicted_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 9\ntext = df_test[\"text\"][idx]\ntrue_label = df_test[\"toxic?\"][idx]\npredicted_label = label_encoder.inverse_transform([preds[idx]])\nprint(text, true_label, predicted_label)\nexplanation_unified = interpreter_unified.explain_local(text, true_label, predicted_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explanation_unified","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom interpret_text.experimental.widget import ExplanationDashboard\nExplanationDashboard(explanation_unified)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sorted feature importance values and feature names\nsorted_local_importance_names = explanation_unified.get_ranked_local_names()\nsorted_local_importance_values = explanation_unified.get_ranked_local_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_local_importance_names ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_local_importance_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(99):\n    if df_test[\"toxic?\"][i]:\n        print(df_test[\"text\"][i])\n        explanation_unified = interpreter_unified.explain_local(df_test[\"text\"][i], df_test[\"toxic?\"][i], label_encoder.inverse_transform([preds[i]]))\n        sorted_local_importance_names = explanation_unified.get_ranked_local_names()\n        sorted_local_importance_values = explanation_unified.get_ranked_local_values()\n        print(sorted_local_importance_names[:4],sorted_local_importance_values[:4])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}