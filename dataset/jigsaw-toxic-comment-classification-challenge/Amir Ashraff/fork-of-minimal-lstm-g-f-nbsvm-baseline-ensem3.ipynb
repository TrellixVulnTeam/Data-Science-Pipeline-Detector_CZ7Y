{"cells":[{"metadata":{"_uuid":"6c82c5ade1ea2ebe3115b7acdbcb5eb01b8dc604","_cell_guid":"d1aed5c1-2284-4aa0-9bdd-8b3a87f10455"},"cell_type":"markdown","source":"## Introduction"},{"metadata":{"_uuid":"c8b9bb50ea3e069843370be618e835cd53a2dc5e","_cell_guid":"5a738023-69cc-4acc-a92b-53c338dd1ab3"},"cell_type":"markdown","source":"There are two very different strong baselines currently in the kernels for this competition:\n    \n- An *LSTM* model, which uses a recurrent neural network to model state across each text, with no feature engineering\n- An *NB-SVM* inspired model, which uses a simple linear approach on top of naive bayes features\n\nIn theory, an ensemble works best when the individual models are as different as possible. Therefore, we should see that even a simple average of these two models gets a good result. Let's try it! First, we'll load the outputs of the models (in the Kaggle Kernels environment you can add these as input files directly from the UI; otherwise you'll need to download them first)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3acc5945691f3ac94b41a99efd00d2f794b28d9","_cell_guid":"4f49e4ea-a226-4d61-921b-db33c41453a8","trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd\n\n#f_lstm_glove_pl = '../input/improved-lstm-baseline-glove-dropout-pl/submission.csv'\nf_nbsvm = '../input/nb-svm-strong-linear-baseline/submission.csv'\n#f_lstm_fast_pl = '../input/improved-lstm-baseline-fasttext-dropout-pl/submission.csv'\nf_bi_lstm_dual = '../input/bi-gru-lstm-dual-embedding-with-mish/submission.csv'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12511977319d644ed8a07af913b0f8e00b14f22f","_cell_guid":"55a8085b-7a52-4c20-975d-4f6fe0dc7202","trusted":true},"cell_type":"code","source":"#p_lstm_glove_pl = pd.read_csv(f_lstm_glove_pl)\np_nbsvm = pd.read_csv(f_nbsvm)\n#p_lstm_fast_pl = pd.read_csv(f_lstm_fast_pl)\np_bi_lstm_dual = pd.read_csv(f_bi_lstm_dual)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"756837877eacd2ab5312623640c66e156a75c1fe","_cell_guid":"74113048-4055-4ead-98b8-a003b6b075bd"},"cell_type":"markdown","source":"Now we can take the average of the label columns."},{"metadata":{"_uuid":"d3a16c6bb660eb600e68c11c03bd2d841b7515f4","_cell_guid":"c736d49f-de3b-46f5-b4c3-04a26ac98d31","trusted":true},"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\np_res = p_nbsvm.copy()\n#p_res[label_cols] = (p_nbsvm[label_cols] + p_lstm_glove_pl[label_cols] + p_lstm_fast_pl[label_cols] + p_bi_lstm_dual[label_cols]) / 4\np_res[label_cols] = (p_nbsvm[label_cols] + p_bi_lstm_dual[label_cols]) / 2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"807d5f936cc49ccff2e4edc28287be06b008beb1","_cell_guid":"d4359384-5657-4660-8fd9-6b395bb7c2a6"},"cell_type":"markdown","source":"And finally, create our CSV."},{"metadata":{"_uuid":"30905be21b812c74c8bb1e3469134b226cbcfc78","_cell_guid":"5f73aafe-81a9-4149-b879-717fee5f1814","trusted":true},"cell_type":"code","source":"p_res.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"648c18c7829885667bbb79a4ed95b82cb5cc620d","_cell_guid":"d66ecdcc-6339-48d5-94ad-519187078972"},"cell_type":"markdown","source":"As we hoped, when we submit this to Kaggle, we get a great result - much better than the individual scores of the kernels we based off. This is currently the best Kaggle kernel submission that runs within the kernels sandbox!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}