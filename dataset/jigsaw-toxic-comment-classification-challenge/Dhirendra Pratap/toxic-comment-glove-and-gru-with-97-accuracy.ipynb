{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-04T03:31:40.694048Z","iopub.execute_input":"2022-07-04T03:31:40.69461Z","iopub.status.idle":"2022-07-04T03:31:40.725884Z","shell.execute_reply.started":"2022-07-04T03:31:40.694519Z","shell.execute_reply":"2022-07-04T03:31:40.724757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport random\nfrom sklearn.model_selection import train_test_split\n\nSEED = 0\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:36:25.967081Z","iopub.execute_input":"2022-07-04T03:36:25.967525Z","iopub.status.idle":"2022-07-04T03:36:25.989353Z","shell.execute_reply.started":"2022-07-04T03:36:25.967495Z","shell.execute_reply":"2022-07-04T03:36:25.988154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:40.768444Z","iopub.execute_input":"2022-07-04T03:31:40.768732Z","iopub.status.idle":"2022-07-04T03:31:46.006718Z","shell.execute_reply.started":"2022-07-04T03:31:40.768704Z","shell.execute_reply":"2022-07-04T03:31:46.004918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:46.009857Z","iopub.execute_input":"2022-07-04T03:31:46.010816Z","iopub.status.idle":"2022-07-04T03:31:47.163075Z","shell.execute_reply.started":"2022-07-04T03:31:46.010762Z","shell.execute_reply":"2022-07-04T03:31:47.161664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tst_label = pd.read_csv(\"test_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:47.526542Z","iopub.execute_input":"2022-07-04T03:31:47.527256Z","iopub.status.idle":"2022-07-04T03:31:47.755206Z","shell.execute_reply.started":"2022-07-04T03:31:47.527214Z","shell.execute_reply":"2022-07-04T03:31:47.753588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tst_label.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:47.75738Z","iopub.execute_input":"2022-07-04T03:31:47.757806Z","iopub.status.idle":"2022-07-04T03:31:47.776829Z","shell.execute_reply.started":"2022-07-04T03:31:47.757762Z","shell.execute_reply":"2022-07-04T03:31:47.773671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:47.779892Z","iopub.execute_input":"2022-07-04T03:31:47.780958Z","iopub.status.idle":"2022-07-04T03:31:48.809878Z","shell.execute_reply.started":"2022-07-04T03:31:47.780913Z","shell.execute_reply":"2022-07-04T03:31:48.808557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:48.811869Z","iopub.execute_input":"2022-07-04T03:31:48.812558Z","iopub.status.idle":"2022-07-04T03:31:48.827752Z","shell.execute_reply.started":"2022-07-04T03:31:48.812514Z","shell.execute_reply":"2022-07-04T03:31:48.825428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = df[\"comment_text\"].values\ntest_X = df_test[\"comment_text\"].values\ntrain_y = df.iloc[:, 2:].values","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:48.832644Z","iopub.execute_input":"2022-07-04T03:31:48.833411Z","iopub.status.idle":"2022-07-04T03:31:48.85213Z","shell.execute_reply.started":"2022-07-04T03:31:48.833353Z","shell.execute_reply":"2022-07-04T03:31:48.850813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import text, sequence\nmax_num_words = 30000\ntokenizer = text.Tokenizer(num_words=max_num_words)\ntokenizer.fit_on_texts(list(train_X) + list(test_X) )\n\ntrain_X = tokenizer.texts_to_sequences(train_X)\ntest_X = tokenizer.texts_to_sequences(test_X)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:31:48.853986Z","iopub.execute_input":"2022-07-04T03:31:48.859829Z","iopub.status.idle":"2022-07-04T03:32:38.467902Z","shell.execute_reply.started":"2022-07-04T03:31:48.859789Z","shell.execute_reply":"2022-07-04T03:32:38.466505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsentence_lengths = [len(sentence) for sentence in train_X]\nsns.distplot(sentence_lengths);\n\nmax_length = 400\ntrain_X = sequence.pad_sequences(train_X, maxlen=max_length)\ntest_X = sequence.pad_sequences(test_X, maxlen=max_length)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:33:05.865726Z","iopub.execute_input":"2022-07-04T03:33:05.866696Z","iopub.status.idle":"2022-07-04T03:33:12.689493Z","shell.execute_reply.started":"2022-07-04T03:33:05.866646Z","shell.execute_reply":"2022-07-04T03:33:12.687965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replace this line with a path to the glove embeddings file which you can download here: https://www.kaggle.com/watts2/glove6b50dtxt\nEMBEDDING_FILE =  '../input/glove6b50dtxt/glove.6B.50d.txt'   \n\ndef get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n\nword_index = tokenizer.word_index\nmax_number_words = 30000\nembedding_dimension = 50\nnumber_words = min(max_number_words, len(word_index))\nembedding_matrix = np.zeros((number_words, embedding_dimension))\nfor word, i in word_index.items():\n    if i >= max_number_words: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:34:20.570045Z","iopub.execute_input":"2022-07-04T03:34:20.570461Z","iopub.status.idle":"2022-07-04T03:34:28.568181Z","shell.execute_reply.started":"2022-07-04T03:34:20.570432Z","shell.execute_reply":"2022-07-04T03:34:28.566948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import Model, activations\nfrom tensorflow.keras.layers import Dense, Concatenate, GRU, LSTM, SpatialDropout1D, \\\nBidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Embedding\n\ngru_hidden_size = 40\ndropout_rate = 0.1\n\nclass gru_model(Model):\n\n  def __init__(self):\n    Model.__init__(self)\n    self.gru = Bidirectional(GRU(units=gru_hidden_size, return_sequences=True))\n    #We use spatial dropout instead of dropout because the different dimensions of an embedding are likely to be highly correlated and so it is a more effective method of regularisation to drop whole embedding\n    #vectors at a time rather than only dropping parts of embedding vectors\n    self.spatial_dropout = SpatialDropout1D(dropout_rate) \n    self.global_avg_pooling = GlobalAveragePooling1D()\n    self.global_max_pooling = GlobalMaxPooling1D()\n    self.embedding = Embedding(max_number_words, embedding_dimension, input_length=max_length, weights=[embedding_matrix])\n    self.fc_layer = Dense(6, activation=\"sigmoid\")\n  \n  def call(self, x, training=True):\n    \"\"\"Forward pass for the network. Note that it expects input data in the form (batch, seq length, features)\"\"\"\n    x = self.embedding(x)\n    if training:\n      x = self.spatial_dropout(x)\n    x = self.gru(x)\n    avg_pool = self.global_avg_pooling(x)\n    max_pool = self.global_max_pooling(x)\n    x = Concatenate(axis=1)([avg_pool, max_pool])\n    x = self.fc_layer(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:35:01.19592Z","iopub.execute_input":"2022-07-04T03:35:01.196483Z","iopub.status.idle":"2022-07-04T03:35:01.623927Z","shell.execute_reply.started":"2022-07-04T03:35:01.196439Z","shell.execute_reply":"2022-07-04T03:35:01.622733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import Callback\nfrom sklearn.metrics import roc_auc_score\n                                          \nclass ROCAUCEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:35:17.035396Z","iopub.execute_input":"2022-07-04T03:35:17.035778Z","iopub.status.idle":"2022-07-04T03:35:17.152347Z","shell.execute_reply.started":"2022-07-04T03:35:17.03575Z","shell.execute_reply":"2022-07-04T03:35:17.150881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 1\nmodel = gru_model()\noptimizer = tf.keras.optimizers.Adam()\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])                            \ntr_X, val_X, tr_y, val_y = train_test_split(train_X, train_y, train_size=0.95, random_state=SEED)\nrocauc = ROCAUCEvaluation(validation_data=(val_X, val_y), interval=1)\nhist = model.fit(tr_X, tr_y, batch_size=batch_size, epochs=epochs, validation_data=(val_X, val_y), callbacks=[rocauc]) ","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:36:34.144888Z","iopub.execute_input":"2022-07-04T03:36:34.145683Z","iopub.status.idle":"2022-07-04T03:40:01.481502Z","shell.execute_reply.started":"2022-07-04T03:36:34.14565Z","shell.execute_reply":"2022-07-04T03:40:01.480173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How to create a submission csv file for Kaggle\ndf_sample = pd.read_csv(\"sample_submission.csv\")\ny_pred = model.predict(test_X, batch_size=1024)\ndf_sample[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\ndf_sample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T03:40:37.975691Z","iopub.execute_input":"2022-07-04T03:40:37.976393Z","iopub.status.idle":"2022-07-04T03:40:45.106144Z","shell.execute_reply.started":"2022-07-04T03:40:37.97629Z","shell.execute_reply":"2022-07-04T03:40:45.104754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}