{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-30T12:24:53.573872Z","iopub.execute_input":"2021-05-30T12:24:53.57421Z","iopub.status.idle":"2021-05-30T12:24:53.580134Z","shell.execute_reply.started":"2021-05-30T12:24:53.574177Z","shell.execute_reply":"2021-05-30T12:24:53.578707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install BeautifulSoup4","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:05:31.873549Z","iopub.execute_input":"2021-05-30T07:05:31.873872Z","iopub.status.idle":"2021-05-30T07:05:39.437215Z","shell.execute_reply.started":"2021-05-30T07:05:31.873843Z","shell.execute_reply":"2021-05-30T07:05:39.436306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import text_hammer as th\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom tensorflow.keras import layers, Input\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.losses import BinaryCrossentropy\nfrom keras.layers import Dense, LSTM, Dropout, Flatten, GRU, Bidirectional\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.metrics import AUC\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n\nfrom sklearn.model_selection import train_test_split\n\nfrom  matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nimport collections\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\n# from bs4 import BeautifulSoup\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:24:56.085738Z","iopub.execute_input":"2021-05-30T12:24:56.086073Z","iopub.status.idle":"2021-05-30T12:24:58.149358Z","shell.execute_reply.started":"2021-05-30T12:24:56.086038Z","shell.execute_reply":"2021-05-30T12:24:58.148436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading pretrained glove word embeddings\n# !wget http://nlp.stanford.edu/data/glove.6B.zip\n# !unzip -q glove.6B.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nltk.download()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the word embeddings\ndef read_glove_vecs():\n    path_to_glove_file = os.path.join(\"../input/glove50/glove.6B.50d.txt\")\n\n    embeddings_index = {}\n    word_to_index = {}\n    index_to_word = {}\n    with open(path_to_glove_file) as f:\n        for line in f:\n            word, coefs = line.split(maxsplit=1)\n            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n            embeddings_index[word] = coefs\n    \n    words_list = list(embeddings_index.keys())\n    \n    for i in range(len(words_list)):\n        word_to_index[words_list[i]] = i\n        index_to_word[i] = words_list[i]            \n    \n    print(\"Found %s word vectors.\" % len(embeddings_index))\n    return word_to_index, index_to_word, embeddings_index","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:04.646568Z","iopub.execute_input":"2021-05-30T12:25:04.646899Z","iopub.status.idle":"2021-05-30T12:25:04.65363Z","shell.execute_reply.started":"2021-05-30T12:25:04.646868Z","shell.execute_reply":"2021-05-30T12:25:04.65259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_to_index, index_to_word, embeddings_matrix = read_glove_vecs()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:05.281877Z","iopub.execute_input":"2021-05-30T12:25:05.282183Z","iopub.status.idle":"2021-05-30T12:25:11.653967Z","shell.execute_reply.started":"2021-05-30T12:25:05.282152Z","shell.execute_reply":"2021-05-30T12:25:11.653035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\"\nTEST_PATH = \"../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\"\nSAMPLE_PATH = \"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\"\nMAX_LENGTH = 1000","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:11.655395Z","iopub.execute_input":"2021-05-30T12:25:11.655733Z","iopub.status.idle":"2021-05-30T12:25:11.660074Z","shell.execute_reply.started":"2021-05-30T12:25:11.655695Z","shell.execute_reply":"2021-05-30T12:25:11.659139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\nsample_df = pd.read_csv(SAMPLE_PATH)\nprint(train_df.head())\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:06:33.683231Z","iopub.execute_input":"2021-05-30T07:06:33.683578Z","iopub.status.idle":"2021-05-30T07:06:37.446074Z","shell.execute_reply.started":"2021-05-30T07:06:33.683545Z","shell.execute_reply":"2021-05-30T07:06:37.444343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"comment_text\"] == float(\"NaN\")]","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:07:33.770801Z","iopub.execute_input":"2021-05-30T07:07:33.771175Z","iopub.status.idle":"2021-05-30T07:07:33.779635Z","shell.execute_reply.started":"2021-05-30T07:07:33.771141Z","shell.execute_reply":"2021-05-30T07:07:33.778829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def review_to_words(raw_review_df, colname):\n    # Function to convert a raw review to a string of words\n    # The input is an array of strings (a raw movie review), and \n    # the output is an array of strings (a preprocessed movie review)\n    #\n    for i in range(len(raw_review_df[colname])):\n        if i % 1000 == 0:\n            print(\"Training {} / {}\".format(i, len(raw_review_df[colname])))\n        # 1. Remove HTML\n        raw_review_df[colname][i] = BeautifulSoup(raw_review_df[colname][i]).get_text() \n        #\n        # 2. Remove non-letters        \n        raw_review_df[colname][i] = re.sub(\"[^a-zA-Z]\", \" \", raw_review_df[colname][i]) \n        #\n        # 3. Convert to lower case, split into individual words\n        raw_review_df[colname][i] = raw_review_df[colname][i].lower().split()   \n        #\n        # 4. Remove stop words\n        stops = set(stopwords.words(\"english\"))\n        raw_review_df[colname][i] = [w for w in raw_review_df[colname][i] if not w in stops] \n        # 4. Join the words back into one string separated by space, \n        # and return the result.\n        raw_review_df[colname][i] = \" \".join(raw_review_df[colname][i])\n    return raw_review_df  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_clean_df = review_to_words(train_df.iloc[:3], \"comment_text\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_clean_df[\"comment_text\"][0])\nlen(train_clean_df[\"comment_text\"][0].split(\" \"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max len of train comments\",max([len(x.split()) for x in train_df.comment_text]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lengths and their count to set upper limit of the length of comment\ndef plot_length_dict(df):\n    lengths = {}\n    for i in range(len(df)):\n        comment = df[\"comment_text\"][i].split(\" \")\n        if len(comment) in lengths:\n            lengths[len(comment)] += 1\n        else:\n            lengths[len(comment)] = 0\n    ordered_lengths = collections.OrderedDict(sorted(lengths.items()))\n    plt.hist(ordered_lengths.keys())\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:19:05.588836Z","iopub.execute_input":"2021-05-30T07:19:05.589149Z","iopub.status.idle":"2021-05-30T07:19:05.594604Z","shell.execute_reply.started":"2021-05-30T07:19:05.589119Z","shell.execute_reply":"2021-05-30T07:19:05.593758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_length_dict(train_clean_df)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:19:06.426417Z","iopub.execute_input":"2021-05-30T07:19:06.426987Z","iopub.status.idle":"2021-05-30T07:19:08.423433Z","shell.execute_reply.started":"2021-05-30T07:19:06.426947Z","shell.execute_reply":"2021-05-30T07:19:08.422647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_length_dict(test_clean_df)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:19:08.424812Z","iopub.execute_input":"2021-05-30T07:19:08.425161Z","iopub.status.idle":"2021-05-30T07:19:09.942042Z","shell.execute_reply.started":"2021-05-30T07:19:08.425116Z","shell.execute_reply":"2021-05-30T07:19:09.941059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_df = review_to_words(train_df, \"comment_text\")\ntrain_clean_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_clean_df = review_to_words(test_df, \"comment_text\")\ntest_clean_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_df.to_csv(\"train_clean_2.csv\", index=False)\ntest_clean_df.to_csv(\"test_clean_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:14:09.781287Z","iopub.execute_input":"2021-05-30T07:14:09.781654Z","iopub.status.idle":"2021-05-30T07:14:12.919014Z","shell.execute_reply.started":"2021-05-30T07:14:09.781622Z","shell.execute_reply":"2021-05-30T07:14:12.918183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_df = pd.read_csv(\"../input/toxiccleanset/train_clean_2.csv\")\ntest_clean_df = pd.read_csv(\"../input/toxiccleanset/test_clean_2.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:11.698957Z","iopub.execute_input":"2021-05-30T12:25:11.699223Z","iopub.status.idle":"2021-05-30T12:25:12.551817Z","shell.execute_reply.started":"2021-05-30T12:25:11.699197Z","shell.execute_reply":"2021-05-30T12:25:12.550885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max len of train comments\",max([len(x.split()) for x in train_clean_df.comment_text]))\nprint(\"max len of test comment\",max([len(x.split()) for x in test_clean_df.comment_text]))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:13.940772Z","iopub.execute_input":"2021-05-30T12:25:13.941105Z","iopub.status.idle":"2021-05-30T12:25:14.528781Z","shell.execute_reply.started":"2021-05-30T12:25:13.941074Z","shell.execute_reply":"2021-05-30T12:25:14.528006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set, eval_set = train_test_split(train_clean_df, test_size=0.3, shuffle=True)\nprint(\"X_train shape: \" + str(train_set.shape))\nprint(\"X_test shape: \" + str(eval_set.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:15.971061Z","iopub.execute_input":"2021-05-30T12:25:15.971409Z","iopub.status.idle":"2021-05-30T12:25:16.006417Z","shell.execute_reply.started":"2021-05-30T12:25:15.971374Z","shell.execute_reply":"2021-05-30T12:25:16.005381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentences_to_indices(X, word_to_index, max_len):\n    m = X.shape[0]\n    X_indices = np.zeros((m, max_len))\n    for i in range(m):\n        sentence_words = X[i].lower().split()\n        j = 0\n        for  w in sentence_words:\n            if j < 1000:\n                try:\n                    X_indices[i, j] = word_to_index[w]\n                except:\n                    X_indices[i, j] = 0\n            j += 1\n    X_indices = np.array(X_indices).astype(np.int64)\n    return X_indices","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:16.413601Z","iopub.execute_input":"2021-05-30T12:25:16.413914Z","iopub.status.idle":"2021-05-30T12:25:16.419393Z","shell.execute_reply.started":"2021-05-30T12:25:16.413884Z","shell.execute_reply":"2021-05-30T12:25:16.418592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_ind = sentences_to_indices(np.array(train_set.comment_text), word_to_index, max_len = MAX_LENGTH)\nX_eval_ind = sentences_to_indices(np.array(eval_set.comment_text), word_to_index, max_len = MAX_LENGTH)\nprint(X_train_ind[:5, : ])\nprint(X_eval_ind[:5, : ])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:16.860877Z","iopub.execute_input":"2021-05-30T12:25:16.861186Z","iopub.status.idle":"2021-05-30T12:25:21.401442Z","shell.execute_reply.started":"2021-05-30T12:25:16.861156Z","shell.execute_reply":"2021-05-30T12:25:21.400581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.count_nonzero(X_train_ind[0][120] == 0)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:21.402981Z","iopub.execute_input":"2021-05-30T12:25:21.403347Z","iopub.status.idle":"2021-05-30T12:25:21.407524Z","shell.execute_reply.started":"2021-05-30T12:25:21.403307Z","shell.execute_reply":"2021-05-30T12:25:21.406403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since the length of each comment is very large and will require significant resources to train the model, \n# we will compress the input and remove the zeros in between.\n# But before that we will attempt to train the large model with a gpu and see the difference in accuracies.","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:21.409376Z","iopub.execute_input":"2021-05-30T12:25:21.409808Z","iopub.status.idle":"2021-05-30T12:25:21.418014Z","shell.execute_reply.started":"2021-05-30T12:25:21.409767Z","shell.execute_reply":"2021-05-30T12:25:21.417274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_eval_ind.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:21.421177Z","iopub.execute_input":"2021-05-30T12:25:21.421533Z","iopub.status.idle":"2021-05-30T12:25:21.430939Z","shell.execute_reply.started":"2021-05-30T12:25:21.421506Z","shell.execute_reply":"2021-05-30T12:25:21.429898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.array(train_set.drop([\"id\", \"comment_text\"], axis=1))\ny_eval = np.array(eval_set.drop([\"id\", \"comment_text\"], axis=1))\nprint(\"y_train: \" + str(y_train.shape))\nprint(\"y_test: \" + str(y_eval.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:21.43246Z","iopub.execute_input":"2021-05-30T12:25:21.433101Z","iopub.status.idle":"2021-05-30T12:25:21.446515Z","shell.execute_reply.started":"2021-05-30T12:25:21.43306Z","shell.execute_reply":"2021-05-30T12:25:21.445515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:31.217266Z","iopub.execute_input":"2021-05-30T12:25:31.217941Z","iopub.status.idle":"2021-05-30T12:25:31.22737Z","shell.execute_reply.started":"2021-05-30T12:25:31.217893Z","shell.execute_reply":"2021-05-30T12:25:31.226407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_tensor = tf.convert_to_tensor(X_train_ind, np.int64)\nX_eval_tensor = tf.convert_to_tensor(X_eval_ind, np.int64)\nprint(X_train_tensor.shape)\nprint(X_eval_tensor.shape) ","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:32.217898Z","iopub.execute_input":"2021-05-30T12:25:32.218222Z","iopub.status.idle":"2021-05-30T12:25:33.710246Z","shell.execute_reply.started":"2021-05-30T12:25:32.218188Z","shell.execute_reply":"2021-05-30T12:25:33.709167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n    vocab_len = len(word_to_index) + 1\n    emb_dim = word_to_vec_map[\"the\"].shape[0]\n    emb_matrix = np.zeros((vocab_len, emb_dim))\n    \n    for word, index in word_to_index.items():\n        emb_matrix[index, :] = word_to_vec_map[word]\n    \n    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n    embedding_layer.build((None,))\n    embedding_layer.set_weights([emb_matrix])\n    \n    return embedding_layer","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:33.711897Z","iopub.execute_input":"2021-05-30T12:25:33.712357Z","iopub.status.idle":"2021-05-30T12:25:33.719635Z","shell.execute_reply.started":"2021-05-30T12:25:33.712314Z","shell.execute_reply":"2021-05-30T12:25:33.718661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(input_shape, word_to_vec_map, word_to_index):\n    model = Sequential()\n    \n    model.add(Input(shape=input_shape))\n    \n    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n    model.add(embedding_layer)\n    \n    model.add(LSTM(750, return_sequences=False))    # try 700 hidden units\n    model.add(Dropout(0.4))\n    model.add(Dense(6, \"softmax\"))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:33.721757Z","iopub.execute_input":"2021-05-30T12:25:33.722341Z","iopub.status.idle":"2021-05-30T12:25:33.728866Z","shell.execute_reply.started":"2021-05-30T12:25:33.722276Z","shell.execute_reply":"2021-05-30T12:25:33.727872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(MAX_LENGTH, embeddings_matrix, word_to_index)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:33.730351Z","iopub.execute_input":"2021-05-30T12:25:33.730732Z","iopub.status.idle":"2021-05-30T12:25:35.561749Z","shell.execute_reply.started":"2021-05-30T12:25:33.730696Z","shell.execute_reply":"2021-05-30T12:25:35.560843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:35.563172Z","iopub.execute_input":"2021-05-30T12:25:35.563521Z","iopub.status.idle":"2021-05-30T12:25:35.572237Z","shell.execute_reply.started":"2021-05-30T12:25:35.563485Z","shell.execute_reply":"2021-05-30T12:25:35.571328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\nloss_fn = BinaryCrossentropy(from_logits=True)\nmetrics = AUC(multi_label=True)\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=[metrics, \"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:35.8072Z","iopub.execute_input":"2021-05-30T12:25:35.807528Z","iopub.status.idle":"2021-05-30T12:25:35.827213Z","shell.execute_reply.started":"2021-05-30T12:25:35.807498Z","shell.execute_reply":"2021-05-30T12:25:35.826373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:38.474459Z","iopub.execute_input":"2021-05-30T12:25:38.474793Z","iopub.status.idle":"2021-05-30T12:25:38.47851Z","shell.execute_reply.started":"2021-05-30T12:25:38.474764Z","shell.execute_reply":"2021-05-30T12:25:38.477371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# # instantiating the model in the strategy scope creates the model on the TPU\n# with tpu_strategy.scope():\n#     model = create_model(MAX_LENGTH, embeddings_matrix, word_to_index)\n#     optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n#     loss_fn = BinaryCrossentropy(from_logits=True)\n#     model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n\n# # train model normally\n# history = model.fit(X_train_tensor, y_train, epochs=EPOCHS, batch_size=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train_tensor, y_train, epochs=EPOCHS, batch_size=250)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:25:48.539946Z","iopub.execute_input":"2021-05-30T12:25:48.540299Z","iopub.status.idle":"2021-05-30T12:58:46.028854Z","shell.execute_reply.started":"2021-05-30T12:25:48.540249Z","shell.execute_reply":"2021-05-30T12:58:46.027993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"execution":{"iopub.status.busy":"2021-05-30T13:01:48.082395Z","iopub.execute_input":"2021-05-30T13:01:48.082753Z","iopub.status.idle":"2021-05-30T13:01:48.091074Z","shell.execute_reply.started":"2021-05-30T13:01:48.082718Z","shell.execute_reply":"2021-05-30T13:01:48.090256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history[\"loss\"]\nacc = history.history[\"accuracy\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = np.arange(EPOCHS)\nplt.plot(epoch, loss)\n# plt.plot(epoch, val_loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend(['train', 'val'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch = np.arange(EPOCHS)\nplt.plot(epoch, acc)\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"ToxicCommentsv2-BS4-re-nltk\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T13:01:59.460208Z","iopub.execute_input":"2021-05-30T13:01:59.460557Z","iopub.status.idle":"2021-05-30T13:02:03.695122Z","shell.execute_reply.started":"2021-05-30T13:01:59.460524Z","shell.execute_reply":"2021-05-30T13:02:03.694262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a zip of the model folder \n!tar -zcvf ToxicCommentsv2-BS4-re-nltk.tar.gz /kaggle/working/ToxicCommentsv2-BS4-re-nltk","metadata":{"execution":{"iopub.status.busy":"2021-05-30T13:02:03.698126Z","iopub.execute_input":"2021-05-30T13:02:03.698487Z","iopub.status.idle":"2021-05-30T13:02:09.43436Z","shell.execute_reply.started":"2021-05-30T13:02:03.698451Z","shell.execute_reply":"2021-05-30T13:02:09.433409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_score = model.evaluate(X_eval_tensor, y_eval)\nprint(eval_score)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T13:02:10.940162Z","iopub.execute_input":"2021-05-30T13:02:10.940532Z","iopub.status.idle":"2021-05-30T13:03:55.086187Z","shell.execute_reply.started":"2021-05-30T13:02:10.940487Z","shell.execute_reply":"2021-05-30T13:03:55.085229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_pred = sentences_to_indices(X_eval_tensor, word_to_index, max_len = MAX_LENGTH)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = model.predict(x_pred)\npredicted","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted = np.where(predicted>0.5, 1, 0)\ny_predicted","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted = y_predicted.reshape((1, len(y_predicted)))[0]\ny_predicted","metadata":{},"execution_count":null,"outputs":[]}]}