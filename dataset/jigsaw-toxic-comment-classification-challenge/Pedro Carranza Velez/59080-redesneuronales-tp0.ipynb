{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:12.947633Z","iopub.execute_input":"2022-04-30T23:35:12.947908Z","iopub.status.idle":"2022-04-30T23:35:12.953384Z","shell.execute_reply.started":"2022-04-30T23:35:12.947886Z","shell.execute_reply":"2022-04-30T23:35:12.952248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatizer","metadata":{}},{"cell_type":"code","source":"from nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer \nclass LemmaTokenizer(object):\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:13.087178Z","iopub.execute_input":"2022-04-30T23:35:13.087494Z","iopub.status.idle":"2022-04-30T23:35:13.094425Z","shell.execute_reply.started":"2022-04-30T23:35:13.087465Z","shell.execute_reply":"2022-04-30T23:35:13.093573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming\n","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nimport re\ntoken_pattern=r\"(?u)\\b\\w\\w+\\b\"\ncompiled_reg_exp = re.compile(token_pattern)\ndef StemTokenizer(text):\n    tokens = compiled_reg_exp.findall(text)\n    stems = []\n    for item in tokens:\n        if len(item)>100:\n            item = 'tooLongWord'\n        stems.append(PorterStemmer().stem(item))\n    return stems","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:13.230232Z","iopub.execute_input":"2022-04-30T23:35:13.230613Z","iopub.status.idle":"2022-04-30T23:35:13.237548Z","shell.execute_reply.started":"2022-04-30T23:35:13.230577Z","shell.execute_reply":"2022-04-30T23:35:13.236758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Open dataset and split into Train set and Validate set\nHold-Out vs K-folding","metadata":{}},{"cell_type":"code","source":"# Dataset\nfolder = '/kaggle/input/jigsaw-toxic-comment-classification-challenge/'\ntrain = pd.read_csv(folder+\"train.csv.zip\")\ntest = pd.read_csv(folder+\"test.csv.zip\")\nsubmission = pd.read_csv(folder+\"sample_submission.csv.zip\")\n\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\n\n# Split\nX_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = 0.1)\nprint(len(Y_train[0]))\n# Raw datasets\nraw_text_train = X_train[\"comment_text\"].str.lower()\nraw_text_valid = X_valid[\"comment_text\"].str.lower()\nraw_text_test = test[\"comment_text\"].str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:13.370674Z","iopub.execute_input":"2022-04-30T23:35:13.370907Z","iopub.status.idle":"2022-04-30T23:35:16.131511Z","shell.execute_reply.started":"2022-04-30T23:35:13.370884Z","shell.execute_reply":"2022-04-30T23:35:16.130624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vectorize\n\nPara realizar la vectorización, se podría hacer a través de count vectorizer o tf-idf vectorizer. Por un lado, count vectorizer separa las palabras por la frecuencia de ocurrencia. Es una manera simple de ordenar las palabras para entender el contenido de un dataset con base en cuáles son las palabras comunes. Igualmente, count vectorizer tiene ciertas limitaciones. Por ejemplo, asume que las palabras más frecuentes son las más importantes, cuando necesariamente no es ese el caso. También, es incapaz de determinar la importancia de las palabras en sí, ya que se basa solo en la frecuencia de ocurrencia. Y finalmente, no reconoce las similitudes y relaciones que pueden tener las palabras.\nEs por eso que se tiene el term frequency–inverse document frequency, o tf-idf, vectorizer. El objetivo de tfidf es no solamente ordenar las palabras por frecuencia de ocurrencia, sino también por su importancia. El proceso se puede dividir en dos partes, la parte tf, y la parte idf. La parte tf, o 'term frequency' funciona similar al count vectorizer, ya que ordena las palabras por su frecuencia de ocurrencia relatva, es decir, dentro de cada documento particular. Mientras tanto, el idf, o 'inverse document frecuency', nos determina la importancia de cada palabra basándose en que tanta información nos provee. En particular, se estima la cantidad de información de cada palabra en relación con la inversa de su frecuencia de ocurrencia, es decir, cuanto menos veces ocurra la palabra, se obtiene más información.\nEs decir, la importancia se define como un balance entre que tantas veces ocurre una palabra con poca ocurrencia. Se puede decir entonces que tf-idf determina que una palabra dentro de un documento es importante si se utiliza muchas veces en un documento, pero pocas veces en todos los documentos. De esta manera, puede corregir las limitaciones del count vectorizer, ya que se puede estimar la importancia de cada palabra más allá de su frecuencia de ocurrencia.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nmax_features = 200000\n\ntokenizer = LemmaTokenizer()\n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.11, min_df=10,\n                                   max_features=max_features,\n                                   #tokenizer=StemTokenizer,\n                                   #tokenizer=tokenizer,\n                                   stop_words='english')\n\n%time tfidf_matrix_train = tfidf_vectorizer.fit_transform(raw_text_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:16.132875Z","iopub.execute_input":"2022-04-30T23:35:16.133042Z","iopub.status.idle":"2022-04-30T23:35:23.177205Z","shell.execute_reply.started":"2022-04-30T23:35:16.133019Z","shell.execute_reply":"2022-04-30T23:35:23.176381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time tfidf_matrix_valid = tfidf_vectorizer.transform(raw_text_valid)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:23.17803Z","iopub.execute_input":"2022-04-30T23:35:23.178196Z","iopub.status.idle":"2022-04-30T23:35:24.543317Z","shell.execute_reply.started":"2022-04-30T23:35:23.178175Z","shell.execute_reply":"2022-04-30T23:35:24.542438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time tfidf_matrix_test = tfidf_vectorizer.transform(raw_text_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:24.545794Z","iopub.execute_input":"2022-04-30T23:35:24.546488Z","iopub.status.idle":"2022-04-30T23:35:36.824036Z","shell.execute_reply.started":"2022-04-30T23:35:24.54645Z","shell.execute_reply":"2022-04-30T23:35:36.822936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bag of Words\nwtf is BoW","metadata":{}},{"cell_type":"markdown","source":"# Reducción de Dimensionalidad","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\ntrunSVD = TruncatedSVD(n_components=300)\n%time dense_matrix_train = trunSVD.fit_transform(tfidf_matrix_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:35:36.825324Z","iopub.execute_input":"2022-04-30T23:35:36.825774Z","iopub.status.idle":"2022-04-30T23:36:00.048578Z","shell.execute_reply.started":"2022-04-30T23:35:36.825741Z","shell.execute_reply":"2022-04-30T23:36:00.04803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time dense_matrix_valid = trunSVD.transform(tfidf_matrix_valid)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:00.050527Z","iopub.execute_input":"2022-04-30T23:36:00.050812Z","iopub.status.idle":"2022-04-30T23:36:00.15895Z","shell.execute_reply.started":"2022-04-30T23:36:00.050783Z","shell.execute_reply":"2022-04-30T23:36:00.158116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_matrix_train.shape, dense_matrix_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:00.160048Z","iopub.execute_input":"2022-04-30T23:36:00.160248Z","iopub.status.idle":"2022-04-30T23:36:00.168736Z","shell.execute_reply.started":"2022-04-30T23:36:00.160221Z","shell.execute_reply":"2022-04-30T23:36:00.168269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dense_matrix_train[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:00.169923Z","iopub.execute_input":"2022-04-30T23:36:00.170274Z","iopub.status.idle":"2022-04-30T23:36:00.181972Z","shell.execute_reply.started":"2022-04-30T23:36:00.170249Z","shell.execute_reply":"2022-04-30T23:36:00.181226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time dense_matrix_test = trunSVD.transform(tfidf_matrix_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:00.183347Z","iopub.execute_input":"2022-04-30T23:36:00.183605Z","iopub.status.idle":"2022-04-30T23:36:01.017985Z","shell.execute_reply.started":"2022-04-30T23:36:00.183569Z","shell.execute_reply":"2022-04-30T23:36:01.016779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Activation","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:01.021164Z","iopub.execute_input":"2022-04-30T23:36:01.021688Z","iopub.status.idle":"2022-04-30T23:36:06.511075Z","shell.execute_reply.started":"2022-04-30T23:36:01.021655Z","shell.execute_reply":"2022-04-30T23:36:06.510563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_features = dense_matrix_train.shape[1]\noutput_size = Y_train.shape[1]\n\nmodel = Sequential()\nmodel.add(Dense(20, activation = 'sigmoid', input_dim=input_features, name='Capa_Oculta_1'))\nmodel.add(Dense(output_size, activation = 'sigmoid',name='Capa_Final'))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:06.512093Z","iopub.execute_input":"2022-04-30T23:36:06.51307Z","iopub.status.idle":"2022-04-30T23:36:06.627579Z","shell.execute_reply.started":"2022-04-30T23:36:06.513035Z","shell.execute_reply":"2022-04-30T23:36:06.626955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:06.629035Z","iopub.execute_input":"2022-04-30T23:36:06.629492Z","iopub.status.idle":"2022-04-30T23:36:06.637526Z","shell.execute_reply.started":"2022-04-30T23:36:06.629459Z","shell.execute_reply":"2022-04-30T23:36:06.637013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer = 'adam')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:06.638483Z","iopub.execute_input":"2022-04-30T23:36:06.638888Z","iopub.status.idle":"2022-04-30T23:36:06.656152Z","shell.execute_reply.started":"2022-04-30T23:36:06.638861Z","shell.execute_reply":"2022-04-30T23:36:06.65491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nepochs = 10\n\nmodel.fit(dense_matrix_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(dense_matrix_valid, Y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:06.658831Z","iopub.execute_input":"2022-04-30T23:36:06.659043Z","iopub.status.idle":"2022-04-30T23:36:34.261348Z","shell.execute_reply.started":"2022-04-30T23:36:06.659019Z","shell.execute_reply":"2022-04-30T23:36:34.260651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"pred_test = model.predict(dense_matrix_test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:34.263028Z","iopub.execute_input":"2022-04-30T23:36:34.263347Z","iopub.status.idle":"2022-04-30T23:36:40.21266Z","shell.execute_reply.started":"2022-04-30T23:36:34.263318Z","shell.execute_reply":"2022-04-30T23:36:40.211686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[list_classes] = pred_test\nsubmission.to_csv(\"submission_model.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:40.214112Z","iopub.execute_input":"2022-04-30T23:36:40.214274Z","iopub.status.idle":"2022-04-30T23:36:41.183807Z","shell.execute_reply.started":"2022-04-30T23:36:40.214252Z","shell.execute_reply":"2022-04-30T23:36:41.182751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"pred_valid = model.predict(dense_matrix_valid, verbose = 1)\npred_train = model.predict(dense_matrix_train, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:41.185293Z","iopub.execute_input":"2022-04-30T23:36:41.185509Z","iopub.status.idle":"2022-04-30T23:36:47.084999Z","shell.execute_reply.started":"2022-04-30T23:36:41.185478Z","shell.execute_reply":"2022-04-30T23:36:47.08399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(dense_matrix_valid, Y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:47.086821Z","iopub.execute_input":"2022-04-30T23:36:47.087525Z","iopub.status.idle":"2022-04-30T23:36:47.789514Z","shell.execute_reply.started":"2022-04-30T23:36:47.087476Z","shell.execute_reply":"2022-04-30T23:36:47.788414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict for Test","metadata":{}},{"cell_type":"code","source":"%time dense_matrix_train = trunSVD.fit_transform(tfidf_matrix_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:36:47.790637Z","iopub.execute_input":"2022-04-30T23:36:47.790821Z","iopub.status.idle":"2022-04-30T23:37:15.7123Z","shell.execute_reply.started":"2022-04-30T23:36:47.790797Z","shell.execute_reply":"2022-04-30T23:37:15.711751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(dense_matrix_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:37:15.713331Z","iopub.execute_input":"2022-04-30T23:37:15.713754Z","iopub.status.idle":"2022-04-30T23:37:21.408268Z","shell.execute_reply.started":"2022-04-30T23:37:15.713717Z","shell.execute_reply":"2022-04-30T23:37:21.407444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[list_classes] = pred\nsubmission.to_csv(\"submission_test.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:37:21.409725Z","iopub.execute_input":"2022-04-30T23:37:21.409955Z","iopub.status.idle":"2022-04-30T23:37:22.301473Z","shell.execute_reply.started":"2022-04-30T23:37:21.409923Z","shell.execute_reply":"2022-04-30T23:37:22.30099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC Curve\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nfrom itertools import cycle\n\nprint(roc_auc_score(Y_train, pred_train, average='macro'))\nprint(roc_auc_score(Y_valid, pred_valid, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:37:22.302352Z","iopub.execute_input":"2022-04-30T23:37:22.302971Z","iopub.status.idle":"2022-04-30T23:37:22.529829Z","shell.execute_reply.started":"2022-04-30T23:37:22.302944Z","shell.execute_reply":"2022-04-30T23:37:22.529145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nn_classes = Y_valid.shape[1]\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_valid[:, i], pred_valid[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_valid.ravel(), pred_valid.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:37:22.530773Z","iopub.execute_input":"2022-04-30T23:37:22.530946Z","iopub.status.idle":"2022-04-30T23:37:22.572393Z","shell.execute_reply.started":"2022-04-30T23:37:22.530922Z","shell.execute_reply":"2022-04-30T23:37:22.571445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n# Compute macro-average ROC curve and ROC area\nlw = 2\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T23:37:22.573951Z","iopub.execute_input":"2022-04-30T23:37:22.574224Z","iopub.status.idle":"2022-04-30T23:37:22.818928Z","shell.execute_reply.started":"2022-04-30T23:37:22.57415Z","shell.execute_reply":"2022-04-30T23:37:22.81829Z"},"trusted":true},"execution_count":null,"outputs":[]}]}