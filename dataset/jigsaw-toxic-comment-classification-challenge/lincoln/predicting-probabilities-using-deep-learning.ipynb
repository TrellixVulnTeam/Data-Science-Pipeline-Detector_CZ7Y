{"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ndef read_data(train):\n    data_comments=[]\n    data_y = []\n    for index,row in train.iterrows():\n        comment = row.comment_text\n        data_comments.append(comment)\n        y_values = np.array([row.toxic,row.severe_toxic,row.obscene,row.threat,row.insult,row.identity_hate])\n        data_y.append(y_values)\n    return data_comments,data_y\n\ntrain = pd.read_csv('../input/train.csv',encoding='utf-8',error_bad_lines=False)\ntrain_comments,train_y = read_data(train)\n\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(train_comments)\n# one_hot_encoding_results = tokenizer.texts_to_matrix(train_comments,mode='binary')\n# print(one_hot_encoding_results.shape = [95851,10000])\n\nx_train = tokenizer.texts_to_matrix(train_comments,mode='binary')\n\n#vectorize the labels as well\ny_train = np.asarray(train_y).astype('float32')\n\n\nfrom keras import models\nfrom keras import layers\nnum_classes =6\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(32,activation='relu',input_shape=(10000,)))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dense(num_classes,activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n\n\nhistory = model.fit(x_train,y_train,epochs=8,batch_size=512,\n                   validation_split=0.2)\n\n\n\nhistory_dict = history.history\n\nprint(history_dict.keys())\n\nacc =history_dict['acc']\nval_acc =history_dict['val_acc']\n\n#Plot the training and val loss and accuracy\nimport matplotlib.pyplot as plt\n\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n\nplt.clf()\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n\n\ndef read_data_test(test_data):\n    data_comments = []\n    for index, row in test_data.iterrows():\n        comment = row.comment_text\n        if comment is not np.nan:\n            data_comments.append(comment)\n    return data_comments\n\ntest = pd.read_csv('../input/test.csv',encoding='utf-8',error_bad_lines=False)\n\ntest_comments = read_data_test(test)\n\ntokenizer.fit_on_texts(test_comments)\nx_test = tokenizer.texts_to_matrix(test_comments,mode='binary')\n\n# values of probabilities for each id\nprobabilities =model.predict(x_test)\n\n#creating dataframe\nprob_df= pd.DataFrame(probabilities)\n\n\n#creating dataframe of id's\nid_df = test['id']\n\n\n#final results will be\nresults = pd.concat([id_df,prob_df],axis=1)\n\nprint(results)\n\n# results.to_csv('final_results.csv',index=False)\n\n\n\n","metadata":{"_uuid":"09bd1c190482f814e81f77ae18cc25de1e275510","_cell_guid":"e6d9f56a-b356-40fd-9ae4-1ffd7e1eec85","collapsed":true}}],"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python"}}}