{"cells":[{"metadata":{"_cell_guid":"d3b04218-0413-4e6c-8751-5d8a404d73a9","_uuid":"0bca9739b82d5d51e1229243e03ea1b6db35c17e"},"cell_type":"markdown","source":"## Introduction\n\n<!--\nThis kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a strong baseline for the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) competition. NBSVM was introduced by Sida Wang and Chris Manning in the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf). In this kernel, we use sklearn's logistic regression, rather than SVM, although in practice the two are nearly identical (sklearn uses the liblinear library behind the scenes).\n\nIf you're not familiar with naive bayes and bag of words matrices, I've made a preview available of one of fast.ai's upcoming *Practical Machine Learning* course videos, which introduces this topic. Here is a link to the section of the video which discusses this: [Naive Bayes video](https://youtu.be/37sFIak42Sc?t=3745).\n-->\n\n이 노트북은 [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) 대회에서 좋은 베이스 라인을 만들기 위해 NBSVM(Naive Bayes - Support Vecotor Machine)를 사용하는 법을 보여준다. NBSVM은 Sida Wang과 Chris Manning이 [Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) 논문에서 도입했다. 이 노트북에서, sklearn의 SVM 대신에 logistic regression 사용한다. 실제로, 이 둘은 거의 동일하지만 (sklearn은 liblinear 라이브러리를 사용한다.)\n\n만약 여러분이 naive bayes와 bag of words matrices에 익숙하지 않는다면, fast.ai의 곧 올려질 *Practical Machine Learning* 코스 비디오에 중 하나를 미리보기로 만들었다. 거기서 이 주제에 대한 설명한다. 이것은 비디오에서 얘기할 섹션의 링크이다. [Naive Bayes video](https://youtu.be/37sFIak42Sc?t=3745)."},{"metadata":{"_cell_guid":"ef06cd19-66b6-46bc-bf45-184e12d3f7d4","_uuid":"cca038ca9424a3f66e10262fc9129de807b5f855","trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a494f561-0c2f-4a38-8973-6b60c22da357","_uuid":"f70ebe669fcf6b434c595cf6fb7a76120bf7809c","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv.zip')\ntest = pd.read_csv('../input/test.csv.zip')\nsubm = pd.read_csv('../input/sample_submission.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3996a226-e1ca-4aa8-b39f-6524d4dadb07","_uuid":"2c18461316f17d1d323b1959c8eb4e5448e8a44e"},"cell_type":"markdown","source":"## Looking at the data\n\n<!--\nThe training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict.\n-->\n\n훈련 데이터는 댓글 당 id와 댓글의 텍스트로 이루어진 하나의 행으로 되어있다. 그리고 우리가 예측해야할 6개의 다른 label이 있다."},{"metadata":{"_cell_guid":"5ddb337b-c9b2-4fec-9652-cb26769dc3c6","_uuid":"5f5269c56ea6ded273881b0d4dcdb6af83a3e089","scrolled":true,"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b3b071fb-7a2c-4195-9817-b01983d11c0e","_uuid":"004d2e823056e98afc5adaac433b7afbfe93b82d"},"cell_type":"markdown","source":"<!--\nHere's a couple of examples of comments, one toxic, and one with no labels.\n-->\n\ntoxic인 것들과 아닌 것들의 몇 가지의 댓글 예시가 있다."},{"metadata":{"_cell_guid":"d57f0b31-c09b-4305-a0b0-0b864e944fd1","_uuid":"1ba9522a65227881a3a55aefaee9de93c4cfd792","trusted":true},"cell_type":"code","source":"train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9caf5da3-33bb-422d-81c4-fef20fbda1a8","_uuid":"b0d70e9d745411ea6228c95c5f19bd3a2ca6dd55","scrolled":true,"trusted":true},"cell_type":"code","source":"train['comment_text'][6]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ea37597-02f7-43cf-ad16-a3d50aac1aba","_uuid":"5c4c716de98a4b1c2ecc0e516e67813b4fc1473e"},"cell_type":"markdown","source":"<!--\nThe length of the comments varies a lot.\n-->\n\n댓글의 길이는 많이 다르다."},{"metadata":{"_cell_guid":"fd3fe158-4d7f-4b30-ac15-42605240ea4f","_uuid":"9c1a3f81397199fa250a2b642edc7fbc5f9f504e","trusted":true},"cell_type":"code","source":"lens = train.comment_text.str.len()\nlens.mean(), lens.std(), lens.max()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d2e55012-4736-425f-84f3-c148ac1f4852","_uuid":"eb68f1c83a5ad11e652ca5f2150993a06d43edb4","trusted":true},"cell_type":"code","source":"lens.hist();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b8515824-b2dd-4c95-bbf9-dc74c80355db","_uuid":"0151ab55887071aed82d297acb2c6545ed964c2b"},"cell_type":"markdown","source":"<!--\nWe'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset.\n-->\n\n예측을 위한 모든 label 목록을 만들 것이다. 그리고 'none' 라벨도 만들 것이다. 그래서 얼마나 많은 댓글들에 label이 없는 지 확인할 수 있다. 그러면 데이터셋을 요약할 수도 있다."},{"metadata":{"_cell_guid":"c66f79d1-1d9f-4d94-82c1-8026af198f2a","_uuid":"4ba6ef86c82f073bf411785d971a694348c3efa9","trusted":true},"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain['none'] = 1-train[label_cols].max(axis=1)\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f6316e3-7e29-431b-abef-73acf4a08637","_uuid":"b7b0d391248f929a026b16fc38936b7fc0176351","trusted":true},"cell_type":"code","source":"len(train),len(test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1b221e62-e23f-422a-939d-6747edf2d613","_uuid":"bfdcf59624717b37ca4ffc0c99d2c28a2d419b06"},"cell_type":"markdown","source":"<!--\nThere are a few empty comments that we need to get rid of, otherwise sklearn will complain.\n-->\n\n제거해야할 몇 개의 비어있는 댓글이 있다. 제거를 안 한다면 sklearn이 작동하지 않을 것이다."},{"metadata":{"_cell_guid":"fdba531c-7ef2-4967-88e2-fc2b04f6f2ef","_uuid":"1e1229f403225f1889c7a7b4fc9be90fda818af5","trusted":true},"cell_type":"code","source":"COMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"480780f1-00c0-4f9a-81e5-fc1932516a80","_uuid":"f2e77e8e6df5e29b620c7a2a0add1438c35af932"},"cell_type":"markdown","source":"## Building the model\n\n<!--\nWe'll start by creating a *bag of words* representation, as a *term document matrix*. We'll use ngrams, as suggested in the NBSVM paper.\n-->\n\n*bag of words* 표현을 *term document matrix*로 만들면서 시작할 것이다. NBSVR 논문에서 제안한 ngram을 사용할 것이다."},{"metadata":{"_cell_guid":"b7f11db7-5c12-4eb8-9f2d-0323d629fed9","_uuid":"b043a3fb66c443fab0129e863c134ec813dadb87","trusted":true},"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bfdebf11-133c-4b12-8664-8bf64757d6cc","_uuid":"941759df15c71d42853515e4d1006f4ab000ce75"},"cell_type":"markdown","source":"<!--\nIt turns out that using TF-IDF gives even better priors than the binarized features used in the paper. I don't think this has been mentioned in any paper before, but it improves leaderboard score from 0.59 to 0.55.\n-->\n\nTF-IDF를 사용하는 것이 논문에서 사용된 binarized features 보다 훨씬 더 좋다고 알려졌다. 이전에는 어떤 논문에서도 이것이 언급되었다고 생각하지 않는다. 그러나 이것이 leaderboard 점수를 0.59에서 0.55로 상승시켰다."},{"metadata":{"_cell_guid":"31ad6c98-d054-426c-b3bd-b3b18f52eb6f","_uuid":"75f3f27d56fb2d7d539e65c292d9e77c92ceead3","trusted":true},"cell_type":"code","source":"n = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train[COMMENT])\ntest_term_doc = vec.transform(test[COMMENT])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4cf3ec26-8237-452b-90c9-831cb0297955","_uuid":"6d215bc460e64d88b08f501d5c5a67c290e40635"},"cell_type":"markdown","source":"<!--\nThis creates a *sparse matrix* with only a small number of non-zero elements (*stored elements* in the representation  below).\n-->\n\n이것은 0이 아닌 원소가 매우 적은 *sparse matrix* 를 만들어낸다. (아래 표현에서 *stored elements*)"},{"metadata":{"_cell_guid":"4c7bdbcc-4451-4477-944c-772e99bac777","_uuid":"8816cc35f66b9fed9c12978fbdef5bb68fae10f4","trusted":true},"cell_type":"code","source":"trn_term_doc, test_term_doc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"59131479-a861-4f46-add9-b2af09a51976","_uuid":"5fc487461f4c6fdaea25f2cd471fc801856c6689"},"cell_type":"markdown","source":"<!--\nHere's the basic naive bayes feature equation:\n-->\n\n기본적인 naive bayes feature 식:"},{"metadata":{"_cell_guid":"45fc6070-ba13-455b-9274-5c2611e2809c","_uuid":"8b277f01cecd575ed4fcae2e630c0dd8ce979793","trusted":true},"cell_type":"code","source":"def pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2299d24b-5515-4d37-92d9-e7f6b16a290a","_uuid":"926eaa2e40e588f4ef2b86e0a28f8e575c9ed5f4","trusted":true},"cell_type":"code","source":"x = trn_term_doc\ntest_x = test_term_doc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0b494ac-0dfc-4faa-a909-0a6d7696d1fc","_uuid":"dc5cafeab86d17ac4f036d58658437636a885a87"},"cell_type":"markdown","source":"<!--\nFit a model for one dependent at a time:\n-->\n\n한 번에 하나의 의존 모델을 적용한다."},{"metadata":{"_cell_guid":"b756c889-a383-4952-9ee9-eca79fd3454f","_uuid":"8652ab2f5f84e77fa395252be9b60be1e44fd583","trusted":true},"cell_type":"code","source":"def get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4, dual=True)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33fd5f8c-adfc-45a1-9fde-1769a0993e76","_uuid":"0fa103b5406aabdc36ea9ef21612d343e4982fc4","trusted":true},"cell_type":"code","source":"preds = np.zeros((len(test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1a99c4d9-916f-4189-9a25-fedcb7700336","_uuid":"5525045116474e6d12b6edc890250d30c0790f06"},"cell_type":"markdown","source":"<!--\nAnd finally, create the submission file.\n-->\n\n그리고 마지막으로, submission file을 만든다."},{"metadata":{"_cell_guid":"bc6a4575-fbbb-47ea-81ac-91fa702dc194","_uuid":"5dd033a93e6cf32cdbdaa0a8b05cd8d27de2b21d","trusted":true},"cell_type":"code","source":"submid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1c345d02-b768-491c-8c03-8c3459a552a8","_uuid":"adbbfb0156952a6a43833e337b8a418ccac257aa","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}