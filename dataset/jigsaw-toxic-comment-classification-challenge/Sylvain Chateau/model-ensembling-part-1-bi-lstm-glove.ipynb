{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this competition, we have a multi-label scenario, because a sample can have any number of labels (or none at all). To solve it, we'll use an ensemble of models that includes:\n- Bi-directionnal LSTM + visu (present notebook)\n- ConvLSTM ?\n- Random Forest (works well with imbalanced datasets)\n- XGBoost"},{"metadata":{},"cell_type":"markdown","source":"## Loading libraries"},{"metadata":{"_cell_guid":"2f9b7a76-8625-443d-811f-8f49781aef81","_uuid":"598f965bc881cfe6605d92903b758778d400fa8b","trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define paths"},{"metadata":{"_cell_guid":"66a6b5fd-93f0-4f95-ad62-3253815059ba","_uuid":"729b0f0c2a02c678631b8c072d62ff46146a82ef","trusted":true},"cell_type":"code","source":"path = '../input/'\ncomp = 'jigsaw-toxic-comment-classification-challenge/'\n\nEMBEDDING_FILE = f'{path}glove6b50d/glove.6B.50d.txt'\n#EMBEDDING_FILE = f'{path}glove6b100dtxt/glove.6B.100d.txt'\n\nTRAIN_DATA_FILE = f'{path}{comp}train.csv'\nTEST_DATA_FILE = f'{path}{comp}test.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(TRAIN_DATA_FILE)\ntest = pd.read_csv(TEST_DATA_FILE)\n\nprint('train shape:', train.shape,\n      '\\ntest shape:', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the data\ntrain.isnull().any(), test.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing values, we're good to go."},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize word distribution:\n#first, we add a new column where we put the number of words of the corresponding comment_text\ntrain[\"document_length\"] = train[\"comment_text\"].apply(lambda words: len(words.split(\" \")))\nmax_seq_len = np.round(train[\"document_length\"].mean() + train[\"document_length\"].std()).astype(int)\n\nplt.figure(figsize=(15,8))\nsns.set(font_scale = 1.5)\nsns.distplot(train[\"document_length\"], hist=True, kde=True, color='b', label='Document length')\nlabel = 'Max length = {}'.format(max_seq_len)\nplt.axvline(x=max_seq_len, color='k', linestyle='--', label=label)\nplt.legend()\nplt.show()\n\n#free space\ndel train[\"document_length\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll also look at how are distributed the different classes:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_classes = list(train.columns[2:].values)\nnum_classes = len(list_classes)\ny_train = train[list_classes].to_numpy()\ndistrib_classes = train[list_classes].sum(axis=0)\n\n#visualize classes distribution\nplt.figure(figsize=(15,8))\nsns.set(font_scale = 1.5)\nax= sns.barplot(list_classes, distrib_classes)\n\nplt.title(\"Comments in each category\", fontsize=24)\nplt.ylabel('Number of comments', fontsize=18)\nplt.xlabel('Comment Type ', fontsize=18)\n\n#add the count above:\nrects = ax.patches\nfor rect, distrib_classe in zip(rects, distrib_classes):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, distrib_classe, ha='center', va='bottom', fontsize=18)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have an unbalanced dataset: a lot of \"good\" comments compared to \"bad\" ones. In particular, we have very few \"threat\" comments (only 0.3%)... This might pose a problem if we want to split the training set to create an evaluation set, as the \"stratify\" argument in train_test_split might fail."},{"metadata":{},"cell_type":"markdown","source":"Let's see how many comments have multiple labels:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sum on each row: results go from 0 (good comment) to 6 (the \"winners\" that have all tags)\nrowSums = train[list_classes].sum(axis=1)\nmultiLabel_counts = rowSums.value_counts()\nmultiLabel_counts = multiLabel_counts.iloc[1:]\n\nsns.set(font_scale = 1.5)\nplt.figure(figsize=(15,8))\nax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n\nplt.title(\"Comments having multiple labels \")\nplt.ylabel('Number of comments', fontsize=18)\nplt.xlabel('Number of labels', fontsize=18)\n\n#adding the text labels\nrects = ax.patches\nlabels = multiLabel_counts.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wordcloud representations"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\nplt.figure(figsize=(18,7))\n\nfor i in range (1,7):\n    plt.subplot(2, 3, i)\n    subset = train[train[train.keys()[i+1]] == 1]\n    text = subset.comment_text.values\n    cloud_i = WordCloud(background_color='black',\n                        collocations=False,\n                        max_words = 100\n                       ).generate(\" \".join(text))\n    \n    plt.axis('off')\n    title = list_classes[i-1]\n    plt.title(title,fontsize=15)\n    plt.imshow(cloud_i)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and parse the GloVe word-embeddings file"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load embeddings\nprint('loading word embeddings...')\nembeddings_index = {}\nf = open(EMBEDDING_FILE)\n\n#more readable:\nfor line in f:\n    values = line.strip().split(' ')\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('found %s word vectors.' % len(embeddings_index))\n\n#alternative, shorter but less readable:\n#def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n#embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing the text"},{"metadata":{},"cell_type":"markdown","source":"First, we'll define stopwords for future removing because we don't want these words taking up space in our database, or taking up processing time.\n\n(Note to self: not sure if it's a good idea, we might loose information by removing them... Have to check it)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the librairies\nimport re   # module re for regular expression\nimport nltk #Natural Language Toolkit\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer #Tokenizer for preprocessing\n\npreprop_tokenizer = RegexpTokenizer(r'\\w+')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's set the list of stopwords:"},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n#stop_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll add some punctuation marks to the list. We will keep '?' and '!' as they may help classify violent comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}', '_'])\nstop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are ready to pre-process our data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_comments_train = train['comment_text'].tolist()\nraw_comments_test = test['comment_text'].tolist() \n\nprint(\"pre-processing training data...\")\nprocessed_comments_train = []\nfor comment in raw_comments_train:\n    tokens = preprop_tokenizer.tokenize(comment)\n    filtered = [word for word in tokens if word not in stop_words]\n    processed_comments_train.append(\" \".join(filtered))\n\nprint(\"pre-processing test data...\")\nprocessed_comments_test = []\nfor comment in raw_comments_test:\n    tokens = preprop_tokenizer.tokenize(comment)\n    filtered = [word for word in tokens if word not in stop_words]\n    processed_comments_test.append(\" \".join(filtered))\n    \nprint(\"Done.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenizing the text"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Config parameters:\nembed_size = 50 # how big is each word vector\nmax_features = 20000#20000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = max_seq_len # max number of words in a comment to use. Here, mean+std as defined earlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nprint(\"tokenizing input data...\")\ntokenizer = Tokenizer(num_words=max_features)\n\n####creates the vocabulary index (i.e. word -> index dictionary) based on word frequency. (0 is reserved for padding, and lower integer means more frequent word.)\ntokenizer.fit_on_texts(processed_comments_train)\n\n#Transforms each text in texts to a sequence of integers taken from the word_index dictionary:\nlist_tokenized_train = tokenizer.texts_to_sequences(processed_comments_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(processed_comments_test)\n\n#pad or trunc the sequences\nX_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' %len(word_index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the GloVe word-embeddings matrix"},{"metadata":{"_cell_guid":"7370416a-094a-4dc7-84fa-bdbf469f6579","_uuid":"20cea54904ac1eece20874e9346905a59a604985"},"cell_type":"markdown","source":"We will now create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and standard deviation of embeddings the GloVe has when generating the random init."},{"metadata":{"_cell_guid":"4d29d827-377d-4d2f-8582-4a92f9569719","_uuid":"96fc33012e7f07a2169a150c61574858d49a561b","trusted":true},"cell_type":"code","source":"all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nemb_mean,emb_std","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"62acac54-0495-4a26-ab63-2520d05b3e19","_uuid":"574c91e270add444a7bc8175440274bdd83b7173","trusted":true},"cell_type":"code","source":"#embedding matrix\nprint('preparing embedding matrix...')\nwords_not_found = []\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: \n        embedding_matrix[i] = embedding_vector\n    else:\n        words_not_found.append(word)\nprint('Done.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at some words not found in the embeddings:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"sample words not found: \", np.random.choice(words_not_found, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Callbacks"},{"metadata":{},"cell_type":"markdown","source":"Accuracy is not helpful with imbalanced dataset. Thus, we'll use Area under ROC (ROC-AUC) as our performance metric. We'll also look at the precision and recall"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\nfrom sklearn.metrics import roc_auc_score\n\nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split into a train, val, and eval sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Create validation split\nX_train_splitted_tmp, X_val, y_train_splitted_tmp, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=True)\n#Create training and evaluation split\nX_train_splitted, X_eval, y_train_splitted, y_eval = train_test_split(X_train_splitted_tmp, y_train_splitted_tmp, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(X_train_splitted), np.shape(y_train_splitted))\nprint(np.shape(X_val) , np.shape(y_val))\nprint(np.shape(X_eval) , np.shape(y_eval))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the distibutions in the new sets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#New train set:\ndistrib_classes_y_train_splitted = y_train_splitted.sum(axis=0)\ndistrib_classes_y_train_splitted/len(y_train_splitted)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation set:\ndistrib_classes_y_val = y_val.sum(axis=0)\ndistrib_classes_y_val/len(y_val)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation set:\ndistrib_classes_y_eval = y_eval.sum(axis=0)\ndistrib_classes_y_eval/len(y_eval)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using train_test_split without the stratifying option still gives us distributions that are somehow similar. That will be good enough for a first try with a first model."},{"metadata":{},"cell_type":"markdown","source":"## Tackle imbalance with class_weight"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n\ndef calculating_class_weights(y_true):\n    from sklearn.utils.class_weight import compute_class_weight\n    number_dim = np.shape(y_true)[1]\n    weights = np.empty([number_dim, 2])\n    for i in range(number_dim):\n        weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n    return weights\nclass_weights = calculating_class_weights(y_train_splitted)\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weighted_loss(weights):\n    def weighted_loss(y_true, y_pred):\n        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n    return weighted_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How to load this model and the custom weighted loss (for model ensembling)\n#model = load_model(\"path/to/model.hd5f\", custom_objects={\"weighted_loss\": get_weighted_loss(weights)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model : GloVe-Pretrained Bidirectional LSTM + dropout"},{"metadata":{},"cell_type":"markdown","source":"Simple bidirectional LSTM with two fully connected layers and dropout."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Conv1D, BatchNormalization\nfrom keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model\nfrom keras.optimizers import adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(maxlen,))\n#x = BatchNormalization()(inputs)\nx = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable = False)(inputs)\n#x = SpatialDropout1D(0.2)(x)\nx = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1, kernel_initializer='he_normal'))(x)\n#x = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"he_normal\")(x)\nx = GlobalMaxPooling1D()(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\noutputs = Dense(6, activation=\"sigmoid\")(x) #Sigmoid gives independent probabilities for each class.\n\nmodel_LSTM = Model(inputs=inputs, outputs=outputs)\nmodel_LSTM.name = 'model_LSTM'\n\nmodel_LSTM.compile(loss=get_weighted_loss(class_weights), optimizer=adam(lr=1e-3), metrics=['acc']) #binary_crossentropy independently optimises each class.\n\nmodel_LSTM.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping,ModelCheckpoint\n\nfilepath=\"best_weights.hdf5\"\nmcp = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,  save_weights_only=True, mode='min')\nearlystop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=4)\nRocAuc_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)\n\ncallbacks_list = [RocAuc_val, mcp, earlystop]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"333626f1-a838-4fea-af99-0c78f1ef5f5c","scrolled":false,"_uuid":"c1558c6b2802fc632edc4510c074555a590efbd8","trusted":true},"cell_type":"code","source":"history_model_LSTM = model_LSTM.fit(X_train_splitted, \n                                    y_train_splitted, \n                                    batch_size=batch_size, \n                                    epochs=epochs, \n                                    validation_data=(X_val, y_val),\n                                    callbacks = callbacks_list, \n                                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define a smooth function to display the training and validation curves\ndef plot_learning_curves(history):\n    val_loss = history.history['val_loss']\n    loss = history.history['loss']\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    \n    epochs = range(1, len(loss)+1 )\n    \n    # Plot the loss and accuracy curves for training and validation \n    fig, ax = plt.subplots(2,1, figsize=(12, 12))\n    ax[0].plot(epochs, loss, 'bo', label=\"Training loss\")\n    ax[0].plot(epochs, val_loss, 'b', label=\"Validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')#\n\n    ax[1].plot(epochs, acc, 'bo', label=\"Training accuracy\")\n    ax[1].plot(epochs, val_acc, 'b',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualisation:\nplot_learning_curves(history_model_LSTM)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading model weights\nmodel_LSTM.load_weights(filepath)\n#Get the prediction:\nprint('Predicting....')\ny_pred = model_LSTM.predict(X_eval,batch_size=1024,verbose=1)\nprint('Done.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy classification score"},{"metadata":{},"cell_type":"markdown","source":"In multilabel classification, the [accuracy classification score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_eval."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_eval, np.where(y_pred > 0.9, 1, 0)) #np.where(a > 0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrices"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\n\n#you can fine tune the threshold for increasing recall or precision\ny_pred_col0 = np.where(y_pred[:,0] > 0.4, 1, 0)\ny_pred_col1 = np.where(y_pred[:,1] > 0.5, 1, 0)\ny_pred_col2 = np.where(y_pred[:,3] > 0.3, 1, 0)\ny_pred_col3 = np.where(y_pred[:,3] > 0.6, 1, 0)\ny_pred_col4 = np.where(y_pred[:,4] > 0.5, 1, 0)\ny_pred_col5 = np.where(y_pred[:,5] > 0.5, 1, 0)\n\ny_pred_col0 = np.expand_dims(y_pred_col0, axis=1)\ny_pred_col1 = np.expand_dims(y_pred_col1, axis=1)\ny_pred_col2 = np.expand_dims(y_pred_col2, axis=1)\ny_pred_col3 = np.expand_dims(y_pred_col3, axis=1)\ny_pred_col4 = np.expand_dims(y_pred_col4, axis=1)\ny_pred_col5 = np.expand_dims(y_pred_col5, axis=1)\n\ny_pred_colTot = np.concatenate((y_pred_col0, y_pred_col1, y_pred_col2, y_pred_col3, y_pred_col4, y_pred_col5), axis=1)\n\nmcm = multilabel_confusion_matrix(y_eval, y_pred_colTot, sample_weight=None, samplewise=False)\n\nfig = plt.figure(figsize = (12,10))\nfor i in range(1,7):\n    plt.subplot(2,3,i)\n    if i%2==0:\n        cmap = \"Reds\"\n    else:\n        cmap = \"Blues\"\n    sns.set(font_scale=0.8)\n    title = '{}'.format(list_classes[i-1])\n    plt.title(title, fontsize = 15)\n    sns.heatmap(mcm[i-1], cmap=cmap, square=True, fmt='.0f', cbar=False, annot=True)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ncr = classification_report(y_eval, np.round(y_pred), target_names = list_classes)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Production: \nhistory_model_LSTM = model_LSTM.fit(X_train, \n                                    y_train, \n                                    batch_size=batch_size, \n                                    epochs=epochs,\n                                    callbacks = callbacks_list, \n                                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28ce30e3-0f21-48e5-af3c-7e5512c9fbdc","_uuid":"e59ad8a98ac5bb25a6bddd72718f3ed8a7fb52e0","trusted":true},"cell_type":"code","source":"print('Predicting....')\ny_test = model_LSTM.predict(X_test,batch_size=1024,verbose=1)\nsample_submission = pd.read_csv(f'{path}{comp}sample_submission.csv')\nsample_submission[list_classes] = y_test\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## To do list:\n- Test labelPowerset"},{"metadata":{"trusted":true},"cell_type":"code","source":"###---  Test with the LabelPowerset + RandomOverSampler   ---####\n###-------------------Not used-------------------------------####\n\n#from skmultilearn.problem_transform import LabelPowerset\n#from imblearn.over_sampling import RandomOverSampler\n#\n#lp = LabelPowerset()\n#ros = RandomOverSampler(random_state=42)\n## Applies the above stated multi-label (ML) to multi-class (MC) transformation.\n#yt = lp.transform(y_train_splitted)\n#X_resampled, y_resampled = ros.fit_sample(X_train_splitted, yt)\n## Inverts the ML-MC transformation to recreate the ML set\n#y_train_splitted = lp.inverse_transform(y_resampled)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"version":"3.6.4","name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":1}