{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"# https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport re, string\nimport time\nfrom scipy.sparse import hstack, vstack\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Functions\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aa2cb9fcc682e468d312ae591479d2ec2647df3b"},"cell_type":"code","source":"# read data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubm = pd.read_csv('../input/sample_submission.csv')\n\nid_train = train['id'].copy()\nid_test = test['id'].copy()\n\n# add empty label for None\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain['none'] = 1-train[label_cols].max(axis=1)\n# fill missing values\nCOMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ce02d0adc4d6071a7ead88c2d3835712f8403469"},"cell_type":"code","source":"# Tf-idf\n\n# prepare tokenizer\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n\n# create sparse matrices\nn = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n\n                      smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train[COMMENT])\ntest_term_doc = vec.transform(test[COMMENT])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"374ce096ac6647c16ce23a2f0db583a7f1364afc"},"cell_type":"code","source":"# combine\nytrain = np.zeros((trn_term_doc.shape[0],1)) + 1\nytest = np.zeros((test_term_doc.shape[0],1))\nydat = np.vstack((ytrain, ytest))\n\nxdat = vstack([trn_term_doc, test_term_doc], format='csr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"39d59a57ac6e04813490e9f98ceb6712b082a2ed"},"cell_type":"code","source":"nfolds = 5\nxseed = 29\ncval = 4\n\n# stratified split\nskf = StratifiedKFold(n_splits= nfolds, random_state= xseed)\n\nscore_vec = np.zeros((nfolds,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"876127dbbf84f93929c7399cf6de9a0e7176014c"},"cell_type":"code","source":"for (f, (train_index, test_index)) in enumerate(skf.split(xdat, ydat[:,0])):\n    # split \n    x0, x1 = xdat[train_index], xdat[test_index]\n    y0, y1 = ydat[train_index,0], ydat[test_index,0]    \n\n    clf = LogisticRegression()\n    clf.fit(x0,y0)\n    prv = clf.predict_proba(x1)[:,1]\n    score_vec[f,:] = roc_auc_score(y1,prv)\n    print(score_vec[f,:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3631e6dd5529cc8450063e4f6cdb08c2b79699ef"},"cell_type":"markdown","source":"","outputs":[],"execution_count":null},{"metadata":{"_uuid":"c83b5fe9cd0dfd58823c924c344d778f16ade90d"},"cell_type":"markdown","source":"","outputs":[],"execution_count":null}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}