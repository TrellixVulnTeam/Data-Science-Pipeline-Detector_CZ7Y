{"cells":[{"metadata":{"_uuid":"72376fd8-819d-486d-a2b5-df1b8e7f7678","_cell_guid":"5e2b6939-2efc-439c-919b-204565cb3078","trusted":true},"cell_type":"markdown","source":"## Introduction\n\nThis kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine)"},{"metadata":{"_uuid":"b3f03ad7-1d4c-427f-8710-fadaa9beecdf","_cell_guid":"aeee4340-4c03-4dfe-955a-eda2bb387ede","trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1637266-38cc-4907-aa62-4b98af1cc16d","_cell_guid":"8fbe9f53-16de-408c-bad3-caf4a4730a8f","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv.zip')\ntest = pd.read_csv('../input/test.csv.zip')\nsubm = pd.read_csv('../input/sample_submission.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12604412-0c2f-4ee0-8722-93a5897e086e","_cell_guid":"10ea2bd5-73a6-4da4-8557-2fec24d59023","trusted":true},"cell_type":"markdown","source":"## Looking at the data\n\nThe training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict."},{"metadata":{"_uuid":"9e6b5d63-6393-40ab-9dc9-8a289415efa3","_cell_guid":"8055ee79-968d-49d4-b28f-a120d948742a","trusted":true,"scrolled":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6ad08e6-6aa2-4610-9c87-c4b65a5406de","_cell_guid":"cb8e602a-23e0-441e-9d16-1361823adf6a","trusted":true},"cell_type":"markdown","source":"Example"},{"metadata":{"_uuid":"3ecf0128-c236-4ed0-833b-ce99ef6a3c18","_cell_guid":"3c7e4bcb-111f-491b-a2e8-98832c43e5cd","trusted":true},"cell_type":"code","source":"train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aeb39944-f91d-414d-a91e-0c8c76b61fb3","_cell_guid":"221de073-f15c-44ea-9229-35bfe02bbfdd","trusted":true,"scrolled":true},"cell_type":"code","source":"train['comment_text'][2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25c2f4b9-f0f9-4595-8b25-3febc0ea7a90","_cell_guid":"d41934d1-036e-4a1e-8d30-c2926c036fd5","trusted":true},"cell_type":"markdown","source":"The length of the comments varies a lot."},{"metadata":{"_uuid":"95484b84-f791-4e49-a04e-803ac6aab9b3","_cell_guid":"2fe2d47e-285a-493d-a4d3-0bdaec8cb8a9","trusted":true},"cell_type":"code","source":"lens = train.comment_text.str.len()\nlens.mean(), lens.std(), lens.max()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64cc2596-48f7-4a7b-bb26-e2e5b211a284","_cell_guid":"60e4a8f0-543b-429c-8e35-c00814ede631","trusted":true},"cell_type":"code","source":"lens.hist();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b928f29c-0e33-4e73-9a88-daae78d32ccf","_cell_guid":"4603fb61-635e-46c2-9e41-7c066303eef9","trusted":true},"cell_type":"markdown","source":"We'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset."},{"metadata":{"_uuid":"c58e99fa-819d-4142-9b7b-9de3ddde87e8","_cell_guid":"bef6c5b1-2a72-4d87-aaf4-e552b25ad959","trusted":true},"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain['none'] = 1-train[label_cols].max(axis=1)\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89940984-356e-485d-8095-26fc510c6ed4","_cell_guid":"b6ccbea7-c026-492c-a1c2-89b40f533761","trusted":true},"cell_type":"code","source":"len(train),len(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a7dcec7-22f6-486e-a4a1-c31faf47fdd9","_cell_guid":"64edbcf2-7a83-4eda-ae6f-d4402c94b78f","trusted":true},"cell_type":"markdown","source":"There are a few empty comments that we need to get rid of, otherwise sklearn will complain."},{"metadata":{"_uuid":"e66914ad-9202-401d-a057-3db7e1ec415c","_cell_guid":"5174df84-455c-47ef-949a-6cd3b91594fd","trusted":true},"cell_type":"code","source":"COMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a28c4ee4-b05d-4f7d-b591-082761275da4","_cell_guid":"0cbf8c8c-7d0a-44d4-9705-840f8d3167f4","trusted":true},"cell_type":"markdown","source":"## Building the model\n\nWe'll start by creating a *bag of words* representation, as a *term document matrix*. We'll use ngrams, as suggested in the NBSVM paper."},{"metadata":{"_uuid":"1adddf38-57c5-4ce4-86df-1ca13cee2570","_cell_guid":"cd505ddf-284f-4aa5-9d1c-4392c2e8c012","trusted":true},"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a9914d1-47f8-48e6-8aa0-bd49cb0f2ef3","_cell_guid":"7689c32d-6dfe-402c-ad7c-a4034f49a61a","trusted":true},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"9661950b-e71b-4b3c-8c4e-d69b19c6deef","_cell_guid":"2aa373e9-a119-4609-a7e7-12efaf32d450","trusted":true},"cell_type":"code","source":"n = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train[COMMENT])\ntest_term_doc = vec.transform(test[COMMENT])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04a013ea-15bb-4406-b36e-bda34ded6d6b","_cell_guid":"949a31b8-588a-4998-9a4b-09d2ee525903","trusted":true},"cell_type":"markdown","source":"This creates a *sparse matrix* with only a small number of non-zero elements."},{"metadata":{"_uuid":"e4fd1309-5841-4ef8-984c-381bef1d9475","_cell_guid":"8b4b7ddf-4ef8-4fa1-b1df-afc67d5caae5","trusted":true},"cell_type":"code","source":"trn_term_doc, test_term_doc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"170e4a9c-245c-442f-a80b-4aeedd45082a","_cell_guid":"e2dbb50b-2441-40f6-aaa4-32bc3d8c19f3","trusted":true},"cell_type":"markdown","source":"Here's the basic naive bayes feature equation:"},{"metadata":{"_uuid":"60878a38-c090-494b-acb8-4622b7b8543b","_cell_guid":"e6069d97-7b5c-4356-b28b-f248eed9dd31","trusted":true},"cell_type":"code","source":"def pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e3e3f5d-0c9c-4345-829e-6f2415fecd28","_cell_guid":"061abed2-2cf4-4c40-b3e9-a11de1b31aa1","trusted":true},"cell_type":"code","source":"x = trn_term_doc\ntest_x = test_term_doc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"635e1534-97fc-49cd-979f-fb600df0fffc","_cell_guid":"88c52212-e11c-4161-a15d-3316086d7fda","trusted":true},"cell_type":"markdown","source":"Fit a model for one dependent at a time:"},{"metadata":{"_uuid":"323f17a7-019f-4a1c-a81c-f3612bd16e62","_cell_guid":"0db00447-11fe-4fc2-95cd-9b635888a6ec","trusted":true},"cell_type":"code","source":"def get_mdl(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4, dual=True)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98209bdc-705a-487b-942c-8260ae62f9ba","_cell_guid":"0f61669e-9756-4c0a-92d1-3eee11e8018c","trusted":true},"cell_type":"code","source":"preds = np.zeros((len(test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_mdl(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb82b7af-212f-436a-8ae6-42149e35ca42","_cell_guid":"bcf99768-44c6-40e7-a667-355c6fbf8231","trusted":true},"cell_type":"markdown","source":"1. And finally, creating a submission file"},{"metadata":{"_uuid":"cab8fb93-f32e-40f8-84bc-c93d415e2dcb","_cell_guid":"7e33de3d-04a2-4314-8b9e-f0c7ce5a31a7","trusted":true},"cell_type":"code","source":"submid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24d05474-e86c-4b54-9346-fdab4498c84e","_cell_guid":"3226cee0-46df-4eb9-a985-b87d3399557e","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}