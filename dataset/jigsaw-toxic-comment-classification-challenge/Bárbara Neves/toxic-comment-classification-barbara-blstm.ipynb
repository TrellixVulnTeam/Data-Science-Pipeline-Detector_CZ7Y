{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mineração de Dados - Trabalho Prático\n\n- **Aluna:** Bárbara Neves\n- **Matrícula:** 388713"},{"metadata":{},"cell_type":"markdown","source":"## Descrição do Trabalho\n\n***Toxic Comment Classification*: Identifique e classifique comentários \"tóxicos\"**, foi retirado das competições da Plataforma *Kaggle* e se trata de um problema de Regressão e Processamento de Linguagem Natural (LPN).\n\nO objetivo é criar um *multi-headed model* capaz de detectar diferentes tipos de comentários tóxicos, como os que possuem ameaças, obscenidade, insultos e ódio baseado em identidade. \n\nEste modelo deve prever a **probabilidade** de comportamento tóxico para cada comentário."},{"metadata":{},"cell_type":"markdown","source":"## Imports Iniciais"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Leitura e Exploração dos Dados "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ndf_test = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\nsubmission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"labels = ['obscene', 'insult', 'toxic', 'severe_toxic', 'identity_hate', 'threat']\n\nfor label in labels :\n    print(\"Entidade: \", label)\n    print(df_train[label].value_counts(), '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para os **dados de treino**, o número **0** indica que o comentário não foi classificado para uma determinada entidade, e o número **1** indica que ele foi classificado."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Valores Faltantes"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Quantidade de valores faltantes nos dados de treino:\")\ndf_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Quantidade de valores faltantes nos dados de teste:\")\ndf_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como verificado anteriormente, não existem valores faltantes. Entretanto, podem existir comentários com campos \"nulos\". "},{"metadata":{},"cell_type":"markdown","source":"### Comentários Nulos"},{"metadata":{"trusted":true},"cell_type":"code","source":"coment_nulo = {}\ncoment_nulo['Treino'] = {'Quantidade' : len(df_train[df_train['comment_text'].isnull()])}\ncoment_nulo['Teste'] = {'Quantidade' : len(df_test[df_test['comment_text'].isnull()])}\n\nprint(\"Comentários nulos nos dados de:\")\nfor key in coment_nulo :\n    print(str(key) + ' = ' + str(coment_nulo[key]['Quantidade']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os conjuntos de treino e teste não possuem comentários nulos. "},{"metadata":{},"cell_type":"markdown","source":"### Comentários Sem Classificação"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percebe-se que os valores médios (*mean*) são muito pequenos (um pouco abaixo de 0.05). Aparentemente, muitos comentários não estão rotulados em nenhuma das seis categorias."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"comments_unlabelled_train = df_train[(df_train['toxic'] != 1) & (df_train['severe_toxic'] != 1) & \n                                     (df_train['obscene'] != 1) & (df_train['threat'] != 1) & \n                                     (df_train['insult'] != 1) & (df_train['identity_hate'] != 1)]\n\nprint('Percentual de comentários sem classificação: ', str(len(comments_unlabelled_train) / len(df_train)*100) + \n      '%\\nQuantidade de comentários de cada categoria:')\nprint(df_train[labels].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlação"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_train[labels]\n\ncolormap = plt.cm.coolwarm\nplt.figure(figsize = (8,8))\n\nsns.heatmap(data.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', \n            annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O quadro acima mostra que muitas das labels possuem correlação forte. Por exemplo, **insult - obscene** tem o valor mais alto em 0.74, seguido de **toxic - obscene** e **toxic - insult**.\n\nPortanto, este problema não trata cada rótulo como um único problema de classificação separado, já que há correlação entre os vários rótulos."},{"metadata":{},"cell_type":"markdown","source":"## Pré-Processamento dos Dados"},{"metadata":{},"cell_type":"markdown","source":"### Padronizando os Comentários"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_test['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def padroniza_df(df, func) :\n    \n    df = df.map(lambda coment : func(coment))\n                \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Função de padronização"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef padroniza_texto(texto):\n    \n    texto = texto.encode('ascii', errors = 'ignore').decode() #Decodificando caracteres em ASCII\n    texto = texto.lower() #Apenas caracteres minúsculos\n    texto = re.sub(r'http\\S+', ' ', texto) #Evitando links\n    texto = re.sub(r'#+', ' ', texto)\n    texto = re.sub(r'@[A-Za-z0-9]+', ' ', texto)\n    texto = re.sub(r\"([A-Za-z]+)'s\", r\"\\1 is\", texto)\n    texto = re.sub(r\"what's\", \"what is \", texto) #Evitando contrações\n    texto = re.sub(r\"\\'s\", \" \", texto) #Evitando contrações\n    texto = re.sub(r\"won't\", \"will not \", texto) #Evitando contrações\n    texto = re.sub(r\"\\'ve\", \" have \", texto) #Evitando contrações\n    texto = re.sub(r\"can't\", \"can not \", texto) #Evitando contrações\n    texto = re.sub(r\"n't\", \" not \", texto) #Evitando contrações\n    texto = re.sub(r\"isn't\", \"is not \", texto) #Evitando contrações\n    texto = re.sub(r\"i'm\", \"i am \", texto) #Evitando contrações\n    texto = re.sub(r\"\\'re\", \" are \", texto) #Evitando contrações\n    texto = re.sub(r\"\\'d\", \" would \", texto) #Evitando contrações\n    texto = re.sub(r\"\\'ll\", \" will \", texto) #Evitando contrações\n    texto = re.sub(r\"\\'scuse\", \" excuse \", texto) #Evitando contrações\n    texto = re.sub('\\W', ' ', texto)\n    texto = re.sub('\\s+', ' ', texto)\n    texto = re.sub(r'\\d+', ' ', texto)\n    texto = texto.strip(' ') #Removendo espaços do começo e fim \n    \n    return texto","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['comment_text'] = padroniza_df(df_train['comment_text'], padroniza_texto)\ndf_test['comment_text'] = padroniza_df(df_test['comment_text'], padroniza_texto)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Função que remove as stopwords"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \n\ndef remove_stopwords(texto):\n    \n    stop_words = set(stopwords.words('english')) \n  \n    word_tokens = word_tokenize(texto) \n  \n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n  \n    filtered_sentence = [] \n  \n    for w in word_tokens: \n        if w not in stop_words: \n            filtered_sentence.append(w) \n        \n    return filtered_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['comment_text'] = padroniza_df(df_train['comment_text'], remove_stopwords)\ndf_test['comment_text'] = padroniza_df(df_test['comment_text'], remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['comment_text'].head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_test['comment_text'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resolvendo o Problema de *Multi-label Classification*"},{"metadata":{},"cell_type":"markdown","source":"### Separando os dados de treino e teste"},{"metadata":{},"cell_type":"markdown","source":"#### X"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train['comment_text']\nX_test = df_test['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### y"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.asarray(df_train[labels].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Processo de Tokenização"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Imports necessários\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Função que conta a quantidade de palavras\ndef word_count(vector):\n    \n    count = 0\n    \n    for word in vector :\n        count += 1\n\n    return count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5 maiores números de palavras presentes no dados de treino"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"new_df_train = df_train\nnew_df_train['number_of_words'] = df_train['comment_text'].apply(lambda x: word_count(x))\n\nnew_df_train.nlargest(5, 'number_of_words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5 maiores números de palavras presente nos dados de teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df_test = df_test\nnew_df_test['number_of_words'] = df_test['comment_text'].apply(lambda x: word_count(x))\n\nnew_df_test.nlargest(5, 'number_of_words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Treino"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_tokenizer = Tokenizer(num_words=1500)\nX_train_tokenizer.fit_on_texts(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_tokens = X_train_tokenizer.texts_to_sequences(X_train)\nX_train_tokens = pad_sequences(X_train_tokens, maxlen=100)\n                               \nX_train_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_train_tokens.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_tokenizer = Tokenizer(num_words=1500)\nX_test_tokenizer.fit_on_texts(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_tokens = X_test_tokenizer.texts_to_sequences(X_test)\nX_test_tokens = pad_sequences(X_test_tokens, maxlen=100)\n\nX_test_tokens","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_test.shape, X_test_tokens.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Criação do Modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports necessários\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Embedding, Dense\nfrom tensorflow.keras import Sequential","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Montando a arquitetura de uma rede neural BLSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim=1500, output_dim=64))\nmodel.add(Bidirectional(LSTM(64)))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(6, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(1e-4),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train_tokens, y_train, batch_size=32, verbose=1, epochs=10, validation_split=0.02, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test_pred = model.predict_proba(X_test_tokens, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparando o Arquivo de Submissão"},{"metadata":{"trusted":false},"cell_type":"code","source":"submission[labels] = y_test_pred\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}