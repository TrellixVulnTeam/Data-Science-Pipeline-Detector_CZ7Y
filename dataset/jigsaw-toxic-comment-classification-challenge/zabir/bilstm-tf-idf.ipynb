{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubm = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"COMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nnum_classes = len(label_cols) \ny_train = train[label_cols].values\nprint(num_classes)\n#train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(max_features=200,tokenizer=tokenize,sublinear_tf=True, min_df=1, norm='l2', encoding='utf-8', lowercase=False , ngram_range=(1, 2), stop_words='english')\n\nX_train = tfidf.fit_transform(train[COMMENT]).toarray()\nX_test = tfidf.transform(test[COMMENT])\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deep learning implementation\n\nfrom keras import utils\nfrom keras.layers import Dense, LSTM, Embedding, Flatten, Dropout, ActivityRegularization,Activation, Lambda\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import optimizers\nfrom collections import defaultdict\nimport gzip\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom keras.layers import Input,Bidirectional,Activation,Conv1D,GRU\nfrom keras.callbacks import Callback\nfrom keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\nfrom keras.preprocessing import text, sequence\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the keras model\n\ndef build_model(X_train,num_classes):\n    model = Sequential()\n    model.add(Dense(64,input_shape=(X_train.shape[1],)))   \n    model.add(Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n#    model.add(SpatialDropout1D(0.3))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n#    model.add(Flatten())\n#    model.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(num_classes, 1)))\n#    model.add(Activation('relu'))\n#    model.add(BatchNormalization())\n    model.add(Dense(128))\n    model.add(Dropout(0.3))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n#    model.add(GlobalMaxPooling1D())\n#    model.add(Lambda(lambda x: tf.expand_dims(model.output, axis=2)))\n   \n    model.add(Dense(64))\n    model.add(Dropout(0.3))\n    model.add(Activation('relu'))\n    model.add(Flatten())\n#    model.add(LSTM(64,return_sequences=True, dropout=0.2))\n    model.add(Dense(num_classes, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelDL = build_model(X_train,num_classes)\nmodelDL.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From Deep Learning with Python book\ndef make_history_plot(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b-', color='green',label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b-', color='green',label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model, record history\n#print(y_train)\nbatch_size=32\nhistoryDL = modelDL.fit(X_train, y_train,\n                    epochs=100,\n                    batch_size=batch_size,\n                    verbose=1,\n                    validation_split=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nmake_history_plot(historyDL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = modelDL.predict([X_test], batch_size=1024, verbose=1)\nsample_submission = pd.read_csv('../input/sample_submission.csv')\nsample_submission[label_cols] = y_test\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}