{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Toxic Comments Classification"},{"metadata":{},"cell_type":"markdown","source":"In this program, we are going to classify a comment in 6 different labels such as *toxic, severe_toxic, obsene*, etc."},{"metadata":{},"cell_type":"markdown","source":"## Importing libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, GlobalAvgPool1D, Dropout, Embedding,Bidirectional, Flatten, CuDNNLSTM, Conv1D, MaxPooling1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nimport random\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Getting the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"training_set = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set = training_set.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of training records :\",len(training_set))\nprint(\"Columns :\")\nfor i in training_set:\n    print(\"\\t\"+i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training set consists of 159571 records and 8 columns. The columns are very much self explanatory.<br>\n<br>\n>The **id** contains the id of our training records and is quite irrelevant for the training purpose, so we will eventually end up dropping this column.<br>\n>Then we have **comment_text**, which consists of the text of comment text.<br>\n>Rest other columns have values 0/1 based on whether the comment text qualifies for that label.\n<br>\n"},{"metadata":{},"cell_type":"markdown","source":"**Now, let's take a look at how many examples of training data do we have satifying our labels.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot 2\ncolumns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']  \ncount_ones = []\nfor i in columns:\n    count_ones.append(training_set[training_set[i]==1][i].count())\ny_pos = np.arange(len(columns))\nplt.bar(y_pos, count_ones, align=\"center\", alpha=0.5)\nplt.xticks(y_pos, columns)\nplt.ylabel(\"Number of Ones\")\nplt.title(\"Number of Ones\")\nplt.show()\n\n#plot 1\ncount_zeros = []\nfor i in columns:\n    count_zeros.append(training_set[training_set[i]==0][i].count())\ny_pos = np.arange(len(columns))\nplt.bar(y_pos, count_zeros, align=\"center\", alpha=0.5)\nplt.xticks(y_pos, columns)\nplt.ylabel(\"Number of Zeros\")\nplt.title(\"Number of Zeros\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plots, we can see that our training set has more records which are negative(or have '0' value). We have around 15000 records which have are positively classified as toxic and around 140000 which are classified as negative. The worst case is with the threat class, here we have aroung 500-700 positive records only, while having 160000 negative records. So, our data is could be highly biased towards predicting a comment as negative toxicity for most of the classes."},{"metadata":{},"cell_type":"markdown","source":"**Let's have a look at some of the data examples.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1):\n    j = random.randint(0, 10000)\n    print(training_set.values[j])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Okay, so enough of analyzing the data. Now, let's preprocess our data for training.**"},{"metadata":{},"cell_type":"markdown","source":"Since, we have text data and the semantics of text are very important to correctly classify them as being toxic, severe_toxic, and so on, we will be using pre-trained word embeddings as inputs."},{"metadata":{},"cell_type":"markdown","source":"## Getting Word Embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open(\"../input/glove-embeddings/glove.6B.300d.txt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = {}\nfor line in tqdm(f):\n    temp = line.split(\" \")\n    word = temp[0]\n    embeds = np.array(temp[1:], dtype='float32')\n    embedding_matrix[word] = embeds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the words which may not be present in glove word embeddings, we will be using zero vectos."},{"metadata":{},"cell_type":"markdown","source":"**Let's now create x and y datasets where 'x' will be the values we will use for making predictions and 'y', the values to predict.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = training_set['comment_text']\ny = training_set[columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will tokenize our texts and convert them to sequences."},{"metadata":{"trusted":true},"cell_type":"code","source":"token = Tokenizer(num_words=20000)\ntoken.fit_on_texts(x)\nseq = token.texts_to_sequences(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will need to pad our sequences. This is useful for making all the sentences of the same size."},{"metadata":{"trusted":true},"cell_type":"code","source":"padded_seq = pad_sequences(seq, maxlen=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(token.word_index)+1\nprint(vocab_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create word embeddings for words in our dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = np.zeros((vocab_size, 300))\nfor word, i in tqdm(token.word_index.items(), position=0):\n    embeds = embedding_matrix.get(word)\n    if embeds is not None:\n        embeddings[i] = embeds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining our models"},{"metadata":{},"cell_type":"markdown","source":"Since we have to make predictions for six classes, let's have a separate classifier for each of them."},{"metadata":{},"cell_type":"markdown","source":"**Model for TOXIC **"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = Sequential()\nmodel1.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel1.add(Conv1D(128, 5, activation='relu'))\nmodel1.add(MaxPooling1D(5))\nmodel1.add(Conv1D(128, 5, activation='relu'))\nmodel1.add(MaxPooling1D(3))\nmodel1.add(Flatten())\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(Dense(1, activation='sigmoid'))\n\nmodel1.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(padded_seq, training_set['toxic'], epochs=3, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model for SEVERE_TOXIC**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel2.add(Conv1D(128, 5, activation='relu'))\nmodel2.add(MaxPooling1D(5))\nmodel2.add(Conv1D(128, 5, activation='relu'))\nmodel2.add(MaxPooling1D(3))\nmodel2.add(Flatten())\nmodel2.add(Dense(128, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))\n\nmodel2.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(padded_seq, training_set['severe_toxic'], epochs=2, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model for OBSCENE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = Sequential()\nmodel3.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel3.add(Conv1D(128, 5, activation='relu'))\nmodel3.add(MaxPooling1D(5))\nmodel3.add(Conv1D(128, 5, activation='relu'))\nmodel3.add(MaxPooling1D(3))\nmodel3.add(Flatten())\nmodel3.add(Dense(128, activation='relu'))\nmodel3.add(Dense(1, activation='sigmoid'))\n\nmodel3.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.fit(padded_seq, training_set['obscene'], epochs=2, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model for THREAT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = Sequential()\nmodel4.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel4.add(Conv1D(128, 5, activation='relu'))\nmodel4.add(MaxPooling1D(5))\nmodel4.add(Conv1D(128, 5, activation='relu'))\nmodel4.add(MaxPooling1D(3))\nmodel4.add(Flatten())\nmodel4.add(Dense(128, activation='relu'))\nmodel4.add(Dense(1, activation='sigmoid'))\n\nmodel4.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4.fit(padded_seq, training_set['threat'], epochs=1, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model for INSULT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model5 = Sequential()\nmodel5.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel5.add(Conv1D(128, 5, activation='relu'))\nmodel5.add(MaxPooling1D(5))\nmodel5.add(Conv1D(128, 5, activation='relu'))\nmodel5.add(MaxPooling1D(3))\nmodel5.add(Flatten())\nmodel5.add(Dense(128, activation='relu'))\nmodel5.add(Dense(1, activation='sigmoid'))\n\nmodel5.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel5.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model5.fit(padded_seq, training_set['insult'], epochs=2, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model fot IDENTITY_HATE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model6 = Sequential()\nmodel6.add(Embedding(vocab_size, 300, weights = [embeddings],\n                     input_length=40, trainable=False))\nmodel6.add(Conv1D(128, 5, activation='relu'))\nmodel6.add(MaxPooling1D(5))\nmodel6.add(Conv1D(128, 5, activation='relu'))\nmodel6.add(MaxPooling1D(3))\nmodel6.add(Flatten())\nmodel6.add(Dense(128, activation='relu'))\nmodel6.add(Dense(1, activation='sigmoid'))\n\nmodel6.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model6.fit(padded_seq, training_set['identity_hate'], epochs=1, batch_size=32, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's make some predictions now"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = test_set['comment_text']\ntoken = Tokenizer(num_words=20000)\ntoken.fit_on_texts(x_test)\nseq = token.texts_to_sequences(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_padded_seq = pad_sequences(seq, maxlen=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxic = model1.predict(test_padded_seq)\nsevere_toxic = model2.predict(test_padded_seq)\nobscene = model3.predict(test_padded_seq)\nthreat = model4.predict(test_padded_seq)\ninsult = model5.predict(test_padded_seq)\nidentity_hate = model6.predict(test_padded_seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"toxic = [1 if i>=0.5 else 0 for i in toxic]\nsevere_toxic = [1 if i>=0.5 else 0 for i in severe_toxic]\nobscene = [1 if i>=0.5 else 0 for i in obscene]\nthreat = [1 if i>=0.5 else 0 for i in threat]\ninsult = [1 if i>=0.5 else 0 for i in insult]\nidentity_hate = [1 if i>=0.5 else 0 for i in identity_hate]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id = test_set['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'id':id,\n                   'toxic':toxic,\n                   'severe_toxic':severe_toxic,\n                   'obscene':obscene,\n                   'threat':threat,\n                   'insult':insult,\n                   'identity_hate':identity_hate})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}