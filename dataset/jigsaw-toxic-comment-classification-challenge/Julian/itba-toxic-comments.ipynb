{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test_labels.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Análisis de un problema multilabel\n\nCompetencia original:\n\nhttps://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"},{"metadata":{},"cell_type":"markdown","source":"# EDA (Exploratory Data Analysis)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"folder = '../input/'","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(folder+\"train.csv\")\ntest = pd.read_csv(folder+\"test.csv\")\ntest_labels = pd.read_csv(folder+\"test_labels.csv\")\nsubmission = pd.read_csv(folder+\"sample_submission.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                 id      ...      identity_hate\n0  0000997932d777bf      ...                  0\n1  000103f0d9cfb60f      ...                  0\n2  000113f07ec002fd      ...                  0\n3  0001b41b1c6bb37e      ...                  0\n4  0001d958c54c6e35      ...                  0\n5  00025465d4725e87      ...                  0\n6  0002bcb3da6cb337      ...                  0\n7  00031b1e95af7921      ...                  0\n8  00037261f536c51d      ...                  0\n9  00040093b2687caa      ...                  0\n\n[10 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00025465d4725e87</td>\n      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0002bcb3da6cb337</td>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>00031b1e95af7921</td>\n      <td>Your vandalism to the Matt Shirvington article...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00037261f536c51d</td>\n      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>00040093b2687caa</td>\n      <td>alignment on this subject and which are contra...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cantidad de observaciones\ntrain.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(159571, 8)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Defino salida del modelo $y$"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defino y (Salida del modelo)\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nprint(y.shape)\nprint(y[:10])","execution_count":6,"outputs":[{"output_type":"stream","text":"(159571, 6)\n[[0 0 0 0 0 0]\n [0 0 0 0 0 0]\n [0 0 0 0 0 0]\n [0 0 0 0 0 0]\n [0 0 0 0 0 0]\n [0 0 0 0 0 0]\n [1 1 1 0 1 0]\n [0 0 0 0 0 0]\n [0 0 0 0 0 0]\n [0 0 0 0 0 0]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset muy desbalanceado\ntoxic_ratio = (y.sum(axis = 1) > 0).sum()/y.shape[0]\nprint('Porcentaje de comentarios toxicos:', toxic_ratio)","execution_count":14,"outputs":[{"output_type":"stream","text":"Porcentaje de comentarios toxicos: 0.10167887648758234\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# La mayoría son toxic\nprint(train[list_classes].sum())\nprint()\nprint(train[list_classes].sum()/y.shape[0])","execution_count":18,"outputs":[{"output_type":"stream","text":"toxic            15294\nsevere_toxic      1595\nobscene           8449\nthreat             478\ninsult            7877\nidentity_hate     1405\ndtype: int64\n\ntoxic            0.095844\nsevere_toxic     0.009996\nobscene          0.052948\nthreat           0.002996\ninsult           0.049364\nidentity_hate    0.008805\ndtype: float64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Superposición entre las clases (Multilabel)\nfor cl in list_classes[1:]:\n    N = ((train['toxic'] == 0) & (train[cl] == 1)).sum()\n    print(f'Es {cl} pero no es toxic:', N)","execution_count":19,"outputs":[{"output_type":"stream","text":"Es severe_toxic pero no es toxic: 0\nEs obscene pero no es toxic: 523\nEs threat pero no es toxic: 29\nEs insult pero no es toxic: 533\nEs identity_hate pero no es toxic: 103\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Se puede ver aca por ejemplo que si es severe_toxic es si o si toxic, pero que insulto puede no ser tóxico por ejemplo"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Baseline (Suponer que siempre elijo zeros (No toxico))\n1-(train[list_classes].sum().values/len(train)).mean()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"0.9633412921729722"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"((y == np.zeros_like(y)).sum(axis=0)/len(y)).mean()","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"0.9633412921729722"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[list_classes].sum().values/len(train)","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"array([0.09584448, 0.00999555, 0.05294822, 0.00299553, 0.04936361,\n       0.00880486])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Divido entre train y valid"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(train['comment_text'], y, test_size = 0.1)\n\nprint(X_train.shape, X_valid.shape)\nprint(Y_train.shape, Y_valid.shape)","execution_count":23,"outputs":[{"output_type":"stream","text":"(143613,) (15958,)\n(143613, 6) (15958, 6)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Armo TFIDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[:10]","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"98458     \"RfC: controversial multi-page move ==\\n\\n Sum...\n39047     Wikify\\nI have begun wikifying this article in...\n7825      \"\\n Well, have a look at this photo, especiall...\n9962      \"\\n\\nThe message I left on your talk page begi...\n131435    \"\\nAhh didn't notice that it was after the nex...\n55735     Re \\n\\nAre you stalking me now? Don't you have...\n126330    \"\\n\\nHere's why there was no consensus looking...\n15620            matt J! \\n\\nmatty j is a right winged nut!\n56449     \"\\n\\Go to my userpage! Just click on \"\"codelyo...\n117705    Kangaroo, wallaroo and wallaby have the same p...\nName: comment_text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_text_train = X_train.apply(str.lower)\nraw_text_valid = X_valid.apply(str.lower)\nraw_text_test = test[\"comment_text\"].apply(str.lower)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(raw_text_train[:10]) # Recordar que train_test_split hace shuffle ","execution_count":26,"outputs":[{"output_type":"stream","text":"98458     \"rfc: controversial multi-page move ==\\n\\n sum...\n39047     wikify\\ni have begun wikifying this article in...\n7825      \"\\n well, have a look at this photo, especiall...\n9962      \"\\n\\nthe message i left on your talk page begi...\n131435    \"\\nahh didn't notice that it was after the nex...\n55735     re \\n\\nare you stalking me now? don't you have...\n126330    \"\\n\\nhere's why there was no consensus looking...\n15620            matt j! \\n\\nmatty j is a right winged nut!\n56449     \"\\n\\go to my userpage! just click on \"\"codelyo...\n117705    kangaroo, wallaroo and wallaby have the same p...\nName: comment_text, dtype: object\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nmax_features = 10000\n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.11, min_df=1,\n                                   max_features=max_features,\n                                   stop_words='english')\n\n%time tfidf_matrix_train = tfidf_vectorizer.fit_transform(raw_text_train)","execution_count":27,"outputs":[{"output_type":"stream","text":"CPU times: user 8.87 s, sys: 88 ms, total: 8.96 s\nWall time: 8.98 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time tfidf_matrix_valid = tfidf_vectorizer.transform(raw_text_valid)","execution_count":28,"outputs":[{"output_type":"stream","text":"CPU times: user 956 ms, sys: 0 ns, total: 956 ms\nWall time: 955 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(max_df=0.11, min_df=1,\n                                   max_features=max_features,\n                                   stop_words='english')\n\n%time count_matrix_train = count_vectorizer.fit_transform(raw_text_train)","execution_count":29,"outputs":[{"output_type":"stream","text":"CPU times: user 8.83 s, sys: 60 ms, total: 8.89 s\nWall time: 8.9 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_matrix_train.shape, count_matrix_train.shape","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"((143613, 10000), (143613, 10000))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Sparsity"},{"metadata":{"trusted":true},"cell_type":"code","source":"sparsity = 1 - (tfidf_matrix_train>0).sum()/(tfidf_matrix_train.shape[0]*tfidf_matrix_train.shape[1])\nprint(sparsity)","execution_count":31,"outputs":[{"output_type":"stream","text":"0.9979016850842194\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Resultados TFIDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_10 = np.argsort(tfidf_matrix_train.sum(axis=0))[0,::-1][0,:10].tolist()[0]\nfeature_names = np.array(tfidf_vectorizer.get_feature_names())\nprint(feature_names[np.array(top_10)])","execution_count":32,"outputs":[{"output_type":"stream","text":"['thanks' 'edit' 'know' 'think' 'did' 'user' 'people' 'articles' 'time'\n 'good']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_10_count = np.argsort(count_matrix_train.sum(axis=0))[0,::-1][0,:10].tolist()[0]\nfeature_names_count = np.array(count_vectorizer.get_feature_names())\nprint(feature_names_count[np.array(top_10_count)])","execution_count":33,"outputs":[{"output_type":"stream","text":"['think' 'know' 'edit' 'people' 'articles' 'use' 'time' 'did' 'user'\n 'thanks']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dense_matrix_train = tfidf_matrix_train.todense()\ndense_matrix_valid = tfidf_matrix_valid.todense()","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creación del modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import initializers","execution_count":35,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_features = dense_matrix_train.shape[1]\noutput_size = Y_train.shape[1]\n\nmodel_rl = Sequential()\nmodel_rl.add(Dense(output_size, input_dim=input_features, activation='sigmoid', \n                   kernel_initializer=initializers.normal(mean=0, stddev=0.001)))\nmodel_rl.summary()\nmodel_rl.compile('Adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":36,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 6)                 60006     \n=================================================================\nTotal params: 60,006\nTrainable params: 60,006\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rl.evaluate(dense_matrix_valid, Y_valid)","execution_count":37,"outputs":[{"output_type":"stream","text":"15958/15958 [==============================] - 4s 278us/step\n","name":"stdout"},{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"[0.6931596473204878, 0.48956637050307983]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 20\nmodel_rl.fit(dense_matrix_train, \n          Y_train, \n          batch_size = batch_size,\n          epochs=epochs, \n          verbose=1, \n          validation_data=(dense_matrix_valid, Y_valid))","execution_count":38,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 143613 samples, validate on 15958 samples\nEpoch 1/20\n143613/143613 [==============================] - 10s 68us/step - loss: 0.3332 - acc: 0.9633 - val_loss: 0.1830 - val_acc: 0.9651\nEpoch 2/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.1466 - acc: 0.9655 - val_loss: 0.1221 - val_acc: 0.9671\nEpoch 3/20\n143613/143613 [==============================] - 8s 56us/step - loss: 0.1103 - acc: 0.9679 - val_loss: 0.1009 - val_acc: 0.9692\nEpoch 4/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0944 - acc: 0.9703 - val_loss: 0.0896 - val_acc: 0.9714\nEpoch 5/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0847 - acc: 0.9725 - val_loss: 0.0824 - val_acc: 0.9733\nEpoch 6/20\n143613/143613 [==============================] - 8s 56us/step - loss: 0.0780 - acc: 0.9742 - val_loss: 0.0774 - val_acc: 0.9745\nEpoch 7/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0730 - acc: 0.9757 - val_loss: 0.0737 - val_acc: 0.9757\nEpoch 8/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0691 - acc: 0.9767 - val_loss: 0.0709 - val_acc: 0.9766\nEpoch 9/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0659 - acc: 0.9777 - val_loss: 0.0686 - val_acc: 0.9772\nEpoch 10/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0632 - acc: 0.9785 - val_loss: 0.0668 - val_acc: 0.9777\nEpoch 11/20\n143613/143613 [==============================] - 8s 56us/step - loss: 0.0610 - acc: 0.9791 - val_loss: 0.0653 - val_acc: 0.9780\nEpoch 12/20\n143613/143613 [==============================] - 8s 56us/step - loss: 0.0590 - acc: 0.9796 - val_loss: 0.0640 - val_acc: 0.9784\nEpoch 13/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0573 - acc: 0.9801 - val_loss: 0.0629 - val_acc: 0.9787\nEpoch 14/20\n143613/143613 [==============================] - 8s 56us/step - loss: 0.0558 - acc: 0.9805 - val_loss: 0.0620 - val_acc: 0.9790\nEpoch 15/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0544 - acc: 0.9809 - val_loss: 0.0613 - val_acc: 0.9793\nEpoch 16/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0532 - acc: 0.9812 - val_loss: 0.0606 - val_acc: 0.9796\nEpoch 17/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0521 - acc: 0.9815 - val_loss: 0.0601 - val_acc: 0.9797\nEpoch 18/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0512 - acc: 0.9818 - val_loss: 0.0596 - val_acc: 0.9799\nEpoch 19/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0503 - acc: 0.9820 - val_loss: 0.0592 - val_acc: 0.9801\nEpoch 20/20\n143613/143613 [==============================] - 8s 55us/step - loss: 0.0495 - acc: 0.9823 - val_loss: 0.0589 - val_acc: 0.9802\n","name":"stdout"},{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"<keras.callbacks.History at 0x7fe4be31d860>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Interpretación"},{"metadata":{"trusted":true},"cell_type":"code","source":"(model_rl.get_weights()[0]).shape","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"(10000, 6)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- toxic\n- severe_toxic\n- obscene\n- threat\n- insult\n- identity_hate"},{"metadata":{"trusted":true},"cell_type":"code","source":"salida = 3\nsorted_indexes = np.argsort(model_rl.get_weights()[0][:,salida])[::-1]\nnp.array(tfidf_vectorizer.get_feature_names())[sorted_indexes][:20]","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"array(['kill', 'die', 'rape', 'burn', 'shoot', 'death', 'hope', 'fucking',\n       'going', 'ass', 'punch', 'kick', 'destroy', 'house', 'deserve',\n       'hunt', 'raped', 'blood', 'beat', 'live'], dtype='<U39')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# MLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nfrom keras import initializers\nfrom keras.layers import Activation\nfrom keras import optimizers","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"default_initializer = initializers.normal(mean=0, stddev=0.01)\n","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_features = dense_matrix_train.shape[1]\noutput_size = Y_train.shape[1]\nhidden_units = 100\nlambd = 0 #0.001\nmodel_sig_nn = Sequential()\nmodel_sig_nn.add(Dense(200,\n                       input_dim=input_features, \n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Oculta_1\"))\nmodel_sig_nn.add(Activation('sigmoid'))\nmodel_sig_nn.add(Dense(200,\n                       input_dim=input_features, \n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Oculta_2\"))\nmodel_sig_nn.add(Activation('sigmoid'))\nmodel_sig_nn.add(Dense(output_size,\n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Salida\"))\nmodel_sig_nn.add(Activation('sigmoid', name=\"output\")) \nmodel_sig_nn.summary()\n\n\nlr = 0.001 \nbatch_size = 256\nepochs = 10\n\n#selectedOptimizer = optimizers.SGD(lr=lr)\nselectedOptimizer = optimizers.adam(lr=lr, decay=0.001)\n\nmodel_sig_nn.compile(loss = 'binary_crossentropy', optimizer=selectedOptimizer, \n                     metrics=['accuracy']) #auc","execution_count":43,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nCapa_Oculta_1 (Dense)        (None, 200)               2000200   \n_________________________________________________________________\nactivation_1 (Activation)    (None, 200)               0         \n_________________________________________________________________\nCapa_Oculta_2 (Dense)        (None, 200)               40200     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 200)               0         \n_________________________________________________________________\nCapa_Salida (Dense)          (None, 6)                 1206      \n_________________________________________________________________\noutput (Activation)          (None, 6)                 0         \n=================================================================\nTotal params: 2,041,606\nTrainable params: 2,041,606\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sig_nn.evaluate(dense_matrix_valid, Y_valid)","execution_count":44,"outputs":[{"output_type":"stream","text":"15958/15958 [==============================] - 1s 83us/step\n","name":"stdout"},{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"[0.6936332652825493, 0.49924803879763313]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_sig_nn.fit(dense_matrix_train, \n          Y_train, \n          batch_size = batch_size,\n          epochs=epochs, \n          verbose=1, \n          validation_data=(dense_matrix_valid, Y_valid), \n         )","execution_count":45,"outputs":[{"output_type":"stream","text":"Train on 143613 samples, validate on 15958 samples\nEpoch 1/10\n143613/143613 [==============================] - 9s 66us/step - loss: 0.1480 - acc: 0.9621 - val_loss: 0.1351 - val_acc: 0.9639\nEpoch 2/10\n 83968/143613 [================>.............] - ETA: 3s - loss: 0.1352 - acc: 0.9634","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-7f2571518d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_matrix_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m          )\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_valid = model_sig_nn.predict(dense_matrix_valid, verbose = 1)\npred_train = model_sig_nn.predict(dense_matrix_train, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Curva ROC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nfrom itertools import cycle\n\nprint(roc_auc_score(Y_train, pred_train, average='macro'))\nprint(roc_auc_score(Y_valid, pred_valid, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nn_classes = Y_valid.shape[1]\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_valid[:, i], pred_valid[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_valid.ravel(), pred_valid.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n# Compute macro-average ROC curve and ROC area\nlw = 2\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}