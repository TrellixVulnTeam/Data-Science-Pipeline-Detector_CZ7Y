{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T15:51:45.359333Z","iopub.execute_input":"2021-12-22T15:51:45.359672Z","iopub.status.idle":"2021-12-22T15:51:45.372863Z","shell.execute_reply.started":"2021-12-22T15:51:45.35964Z","shell.execute_reply":"2021-12-22T15:51:45.371655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n!unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:51:45.375825Z","iopub.execute_input":"2021-12-22T15:51:45.376361Z","iopub.status.idle":"2021-12-22T15:51:50.04188Z","shell.execute_reply.started":"2021-12-22T15:51:45.376312Z","shell.execute_reply":"2021-12-22T15:51:50.04079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Config File\nTRAIN = './train.csv'\nTEST = './test.csv'\nTEST_LABEL = './test_labels.csv'\nSAMPLE = './sample_submission.csv'\nEPOCHS = 2\nMAX_TOKEN_COUNT = 128\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:51:50.043714Z","iopub.execute_input":"2021-12-22T15:51:50.044112Z","iopub.status.idle":"2021-12-22T15:51:50.050947Z","shell.execute_reply.started":"2021-12-22T15:51:50.044065Z","shell.execute_reply":"2021-12-22T15:51:50.049838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy, f1, auroc\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, multilabel_confusion_matrix\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nRANDOM_SEED = 42\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\n\npl.seed_everything(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:51:50.053837Z","iopub.execute_input":"2021-12-22T15:51:50.05439Z","iopub.status.idle":"2021-12-22T15:52:00.472225Z","shell.execute_reply.started":"2021-12-22T15:51:50.054327Z","shell.execute_reply":"2021-12-22T15:52:00.471142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(TRAIN)\ntest_df = pd.read_csv(TEST)\ntest_label = pd.read_csv(TEST_LABEL)\nsample_sub = pd.read_csv(SAMPLE)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:00.474115Z","iopub.execute_input":"2021-12-22T15:52:00.474702Z","iopub.status.idle":"2021-12-22T15:52:02.558325Z","shell.execute_reply.started":"2021-12-22T15:52:00.474649Z","shell.execute_reply":"2021-12-22T15:52:02.557166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:02.559999Z","iopub.execute_input":"2021-12-22T15:52:02.560456Z","iopub.status.idle":"2021-12-22T15:52:02.575672Z","shell.execute_reply.started":"2021-12-22T15:52:02.560388Z","shell.execute_reply":"2021-12-22T15:52:02.574494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:02.577732Z","iopub.execute_input":"2021-12-22T15:52:02.578612Z","iopub.status.idle":"2021-12-22T15:52:02.592462Z","shell.execute_reply.started":"2021-12-22T15:52:02.578567Z","shell.execute_reply":"2021-12-22T15:52:02.591322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:02.594271Z","iopub.execute_input":"2021-12-22T15:52:02.594535Z","iopub.status.idle":"2021-12-22T15:52:02.612475Z","shell.execute_reply.started":"2021-12-22T15:52:02.594506Z","shell.execute_reply":"2021-12-22T15:52:02.611517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.05)\ntrain_df.shape, val_df.shape, test_df.shape #test hs only ids and comment_text\n\nLABEL_COLUMNS = df.columns.tolist()[2:]\ndf[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:02.614064Z","iopub.execute_input":"2021-12-22T15:52:02.61443Z","iopub.status.idle":"2021-12-22T15:52:03.168915Z","shell.execute_reply.started":"2021-12-22T15:52:02.614387Z","shell.execute_reply":"2021-12-22T15:52:03.167924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\ntrain_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n\npd.DataFrame(dict(\n  toxic=[len(train_toxic)], \n  clean=[len(train_clean.sample(15_000))]\n)).plot(kind='barh');\n\n#Balanced dataset of toxic and non_toxic comments\ntrain_df = pd.concat([\n  train_toxic,\n  train_clean.sample(15_000)\n])\n\ntrain_df.shape, val_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:03.173692Z","iopub.execute_input":"2021-12-22T15:52:03.173944Z","iopub.status.idle":"2021-12-22T15:52:03.673592Z","shell.execute_reply.started":"2021-12-22T15:52:03.173915Z","shell.execute_reply":"2021-12-22T15:52:03.672641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToxicCommentsDataset(Dataset):\n    \"\"\"\n    Pass pandas dataframe, and tokeizer along with the max token length[128 default]\n    \n    Example: \n    -------\n    train_dataset = ToxicCommentsDataset(\n      train_df,\n      tokenizer,\n      max_token_len=MAX_TOKEN_COUNT\n    )\n\n    sample_item = train_dataset[0]\n    \n    \"\"\"\n    \n    \n    def __init__(\n        self,\n        data: pd.DataFrame,\n        tokenizer: BertTokenizer,\n        max_token_len: int = 128,\n        test= False\n    ):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_token_len = max_token_len\n        self.test = test\n        \n    \n    def __len__(self):\n        return len(self.data)\n    \n    \n    def __getitem__(self, index: int):\n        data_row = self.data.iloc[index]\n        _id = data_row['id']\n        comment_text = data_row.comment_text\n        \n        if not self.test:\n            labels = data_row[LABEL_COLUMNS]\n        \n        encoding = self.tokenizer.encode_plus(\n            comment_text,\n            max_length=self.max_token_len,\n            padding=\"max_length\",\n            truncation=True,\n            add_special_tokens=True, # [CLS] & [SEP]\n            return_token_type_ids=False,\n            return_attention_mask=True, #attention_mask\n            return_tensors='pt',\n        )\n        \n        if not self.test:\n            return dict(\n            _id = _id,\n            comment_text=comment_text,\n            input_ids = encoding[\"input_ids\"].flatten(),\n            attention_mask=encoding[\"attention_mask\"].flatten(),\n            labels=torch.FloatTensor(labels)\n        )\n        else:\n            return dict(\n                _id = _id,\n                comment_text=comment_text,\n                input_ids = encoding[\"input_ids\"].flatten(),\n                attention_mask=encoding[\"attention_mask\"].flatten()\n            )\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:03.676028Z","iopub.execute_input":"2021-12-22T15:52:03.676378Z","iopub.status.idle":"2021-12-22T15:52:03.688915Z","shell.execute_reply.started":"2021-12-22T15:52:03.676322Z","shell.execute_reply":"2021-12-22T15:52:03.687431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nBERT_MODEL_NAME = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:03.690988Z","iopub.execute_input":"2021-12-22T15:52:03.691319Z","iopub.status.idle":"2021-12-22T15:52:10.239521Z","shell.execute_reply.started":"2021-12-22T15:52:03.691274Z","shell.execute_reply":"2021-12-22T15:52:10.238458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test=False\ntrain_dataset = ToxicCommentsDataset(\n  train_df,\n  tokenizer,\n  max_token_len=MAX_TOKEN_COUNT\n)\n\nval_dataset = ToxicCommentsDataset(\n  val_df,\n  tokenizer,\n  max_token_len=MAX_TOKEN_COUNT\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.241168Z","iopub.execute_input":"2021-12-22T15:52:10.241619Z","iopub.status.idle":"2021-12-22T15:52:10.247987Z","shell.execute_reply.started":"2021-12-22T15:52:10.241573Z","shell.execute_reply":"2021-12-22T15:52:10.246745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = ToxicCommentsDataset(\n  test_df,\n  tokenizer,\n  max_token_len=MAX_TOKEN_COUNT,\n  test=True\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.24997Z","iopub.execute_input":"2021-12-22T15:52:10.25037Z","iopub.status.idle":"2021-12-22T15:52:10.262685Z","shell.execute_reply.started":"2021-12-22T15:52:10.250325Z","shell.execute_reply":"2021-12-22T15:52:10.261491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_item = train_dataset[0]\nprint(sample_item.keys())\nprint(sample_item[\"_id\"])\nprint(sample_item[\"comment_text\"])\nprint(sample_item[\"input_ids\"])\nprint(sample_item[\"attention_mask\"])\nprint(sample_item[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.264429Z","iopub.execute_input":"2021-12-22T15:52:10.264979Z","iopub.status.idle":"2021-12-22T15:52:10.345953Z","shell.execute_reply.started":"2021-12-22T15:52:10.26492Z","shell.execute_reply":"2021-12-22T15:52:10.344972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_item = val_dataset[0]\nprint(sample_item.keys())\nprint(sample_item[\"_id\"])\nprint(sample_item[\"comment_text\"])\nprint(sample_item[\"input_ids\"])\nprint(sample_item[\"attention_mask\"])\nprint(sample_item[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.34759Z","iopub.execute_input":"2021-12-22T15:52:10.3479Z","iopub.status.idle":"2021-12-22T15:52:10.3628Z","shell.execute_reply.started":"2021-12-22T15:52:10.347845Z","shell.execute_reply":"2021-12-22T15:52:10.361938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_item = test_dataset[0]\nprint(sample_item.keys())\nprint(sample_item[\"_id\"])\nprint(sample_item[\"comment_text\"])\nprint(sample_item[\"input_ids\"])\nprint(sample_item[\"attention_mask\"])\n# print(sample_item[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.364667Z","iopub.execute_input":"2021-12-22T15:52:10.365077Z","iopub.status.idle":"2021-12-22T15:52:10.378065Z","shell.execute_reply.started":"2021-12-22T15:52:10.36503Z","shell.execute_reply":"2021-12-22T15:52:10.376896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from torch.utils.data import Subset\n\n# num_train_examples = 100\n# sample_train_ds = Subset(train_dataset, np.arange(num_train_examples))\n# assert len(sample_train_ds) == num_train_examples\n\n# num_val_examples = 100\n# sample_val_ds = Subset(val_dataset, np.arange(num_val_examples))\n# assert len(sample_val_ds) == num_val_examples\n\n# num_test_examples = 100\n# sample_test_ds = Subset(test_dataset, np.arange(num_test_examples))\n# assert len(sample_test_ds) == num_test_examples\n\n# train_dataloader = DataLoader(sample_train_ds, batch_size=8, shuffle=True)\n# val_dataloader = DataLoader(sample_val_ds, batch_size=8, shuffle=False)\n# test_dataloader = DataLoader(sample_test_ds, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.38104Z","iopub.execute_input":"2021-12-22T15:52:10.381671Z","iopub.status.idle":"2021-12-22T15:52:10.388524Z","shell.execute_reply.started":"2021-12-22T15:52:10.381622Z","shell.execute_reply":"2021-12-22T15:52:10.387034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.389925Z","iopub.execute_input":"2021-12-22T15:52:10.391154Z","iopub.status.idle":"2021-12-22T15:52:10.398199Z","shell.execute_reply.started":"2021-12-22T15:52:10.391098Z","shell.execute_reply":"2021-12-22T15:52:10.397175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.400917Z","iopub.execute_input":"2021-12-22T15:52:10.403437Z","iopub.status.idle":"2021-12-22T15:52:10.412203Z","shell.execute_reply.started":"2021-12-22T15:52:10.403355Z","shell.execute_reply":"2021-12-22T15:52:10.411038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.413711Z","iopub.execute_input":"2021-12-22T15:52:10.41471Z","iopub.status.idle":"2021-12-22T15:52:10.668857Z","shell.execute_reply.started":"2021-12-22T15:52:10.414664Z","shell.execute_reply":"2021-12-22T15:52:10.667797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(iter(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.670524Z","iopub.execute_input":"2021-12-22T15:52:10.672421Z","iopub.status.idle":"2021-12-22T15:52:10.678925Z","shell.execute_reply.started":"2021-12-22T15:52:10.672359Z","shell.execute_reply":"2021-12-22T15:52:10.677967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToxicCommentTagger(nn.Module):\n    \n    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True) #load the pretrained bert model\n        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes) # add a linear layer to the bert\n        self.n_training_steps = n_training_steps\n        self.n_warmup_steps = n_warmup_steps\n        self.criterion = nn.BCELoss()\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        output = self.bert(input_ids, attention_mask=attention_mask)\n        output = self.classifier(output.pooler_output)\n        output = torch.sigmoid(output) \n        loss = 0\n        if labels is not None:\n            loss = self.criterion(output, labels)\n        return loss, output","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.68187Z","iopub.execute_input":"2021-12-22T15:52:10.683017Z","iopub.status.idle":"2021-12-22T15:52:10.694156Z","shell.execute_reply.started":"2021-12-22T15:52:10.68297Z","shell.execute_reply":"2021-12-22T15:52:10.693114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbert_model = ToxicCommentTagger(len(LABEL_COLUMNS)).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:10.696132Z","iopub.execute_input":"2021-12-22T15:52:10.696541Z","iopub.status.idle":"2021-12-22T15:52:34.318068Z","shell.execute_reply.started":"2021-12-22T15:52:10.696497Z","shell.execute_reply":"2021-12-22T15:52:34.317095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(bert_model)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-22T15:52:34.319876Z","iopub.execute_input":"2021-12-22T15:52:34.320184Z","iopub.status.idle":"2021-12-22T15:52:34.328608Z","shell.execute_reply.started":"2021-12-22T15:52:34.320142Z","shell.execute_reply":"2021-12-22T15:52:34.327511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = bert_model","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.3305Z","iopub.execute_input":"2021-12-22T15:52:34.331056Z","iopub.status.idle":"2021-12-22T15:52:34.340051Z","shell.execute_reply.started":"2021-12-22T15:52:34.331009Z","shell.execute_reply":"2021-12-22T15:52:34.338495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def training_step():\n#     model.train()\n#     input_ids = batch[\"input_ids\"]\n#     attention_mask = batch[\"attention_mask\"]\n#     labels = batch[\"labels\"]\n#     loss, outputs = model(input_ids, attention_mask, labels)\n#     return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n\n# def validation_step():\n#     model.eval()\n#     input_ids = batch[\"input_ids\"]\n#     attention_mask = batch[\"attention_mask\"]\n#     labels = batch[\"labels\"]\n#     with torch.no_grad():\n#         loss, outputs = model(input_ids, attention_mask, labels)\n#     return loss\n\n# def test_step():\n#     model.eval()\n#     input_ids = batch[\"input_ids\"]\n#     attention_mask = batch[\"attention_mask\"]\n#     labels = batch[\"labels\"]\n#     with torch.no_grad():\n#         loss, outputs = model(input_ids, attention_mask, labels)\n#     return loss","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.342474Z","iopub.execute_input":"2021-12-22T15:52:34.343813Z","iopub.status.idle":"2021-12-22T15:52:34.352073Z","shell.execute_reply.started":"2021-12-22T15:52:34.343765Z","shell.execute_reply":"2021-12-22T15:52:34.351023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = EPOCHS\n\n\nsteps_per_epoch=len(train_df) // BATCH_SIZE\ntotal_training_steps = steps_per_epoch * N_EPOCHS\nwarmup_steps = total_training_steps // 5\nwarmup_steps, total_training_steps","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.358655Z","iopub.execute_input":"2021-12-22T15:52:34.35914Z","iopub.status.idle":"2021-12-22T15:52:34.370771Z","shell.execute_reply.started":"2021-12-22T15:52:34.359107Z","shell.execute_reply":"2021-12-22T15:52:34.369593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_training_steps\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.371891Z","iopub.execute_input":"2021-12-22T15:52:34.372157Z","iopub.status.idle":"2021-12-22T15:52:34.38529Z","shell.execute_reply.started":"2021-12-22T15:52:34.372127Z","shell.execute_reply":"2021-12-22T15:52:34.384196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to train the model\ndef train():\n  \n  model.train()\n\n  total_loss, total_accuracy = 0, 0\n  avg_loss = 0\n  \n  # empty list to save model predictions\n  total_preds=[]\n  # iterate over batches\n  for step,batch in enumerate(train_dataloader):\n    \n    # progress update after every 50 batches.\n    if step % 50 == 0 and not step == 0:\n      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n\n    # push the batch to gpu\n#     batch = [r.to(device) for r in batch]\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    labels = batch[\"labels\"].to(device)     \n\n    # clear previously calculated gradients \n    model.zero_grad()        \n    loss, outputs = model(input_ids, attention_mask, labels)\n\n    # add on to the total loss\n    total_loss = total_loss + loss.item()\n\n    # backward pass to calculate the gradients\n    loss.backward()\n\n    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n    # update parameters\n    optimizer.step()\n    scheduler.step()\n\n    # model predictions are stored on GPU. So, push it to CPU\n    outputs=outputs.detach().cpu().numpy()\n\n    # append the model predictions\n    total_preds.append(outputs)\n\n  # compute the training loss of the epoch\n  avg_loss = total_loss / len(train_dataloader)\n  print(f\"{step}: {avg_loss}\")\n  \n\n    \n  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n  # reshape the predictions in form of (number of samples, no. of classes)\n  total_preds  = np.concatenate(total_preds, axis=0)\n\n  #returns the loss and predictions\n  return avg_loss, total_preds","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.386911Z","iopub.execute_input":"2021-12-22T15:52:34.388002Z","iopub.status.idle":"2021-12-22T15:52:34.401003Z","shell.execute_reply.started":"2021-12-22T15:52:34.38796Z","shell.execute_reply":"2021-12-22T15:52:34.39978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import time\n# from datetime import date, datetime\n# from babel.dates import format_date, format_datetime, format_time","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.404731Z","iopub.execute_input":"2021-12-22T15:52:34.405462Z","iopub.status.idle":"2021-12-22T15:52:34.416053Z","shell.execute_reply.started":"2021-12-22T15:52:34.40543Z","shell.execute_reply":"2021-12-22T15:52:34.414869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n# function for evaluating the model\ndef evaluate():\n  \n  print(\"\\nEvaluating...\")\n  #t0 = time.time()\n  # deactivate dropout layers\n  model.eval()\n\n  total_loss, total_accuracy = 0, 0\n  \n  # empty list to save the model predictions\n  total_preds = []\n  total_labels = []\n\n  # iterate over batches\n  for step,batch in enumerate(val_dataloader):\n    \n    # Progress update every 50 batches.\n    if step % 50 == 0 and not step == 0:\n      \n      # Calculate elapsed time in minutes.\n      #elapsed = format_time(time.time() - t0)\n            \n      # Report progress.\n      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n    # push the batch to gpu\n\n#     batch = [r.to(device) for r in batch]\n    \n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    labels = batch[\"labels\"].to(device)   \n    # deactivate autograd\n    with torch.no_grad():\n      \n      loss, outputs = model(input_ids, attention_mask, labels)\n\n      total_loss = total_loss + loss.item()\n\n      outputs = outputs.detach().cpu().numpy()\n      labels = labels.detach().cpu().numpy()\n      total_preds.append(outputs)\n      total_labels.append(labels)\n\n\n  # compute the validation loss of the epoch\n  avg_loss = total_loss / len(val_dataloader)\n  print(f\"{step}: {avg_loss}\")\n\n\n\n  # reshape the predictions in form of (number of samples, no. of classes)\n  total_preds  = np.concatenate(total_preds, axis=0)\n  total_labels = np.concatenate(total_labels, axis=0)\n  true = np.array(total_labels)\n  pred = np.array(total_preds>0.5)\n  #print(true)\n  #print(pred)\n  for i, name in enumerate(LABEL_COLUMNS):\n      try:\n          print(f\"{name} roc_auc {roc_auc_score(true[:, i], pred[:, i])}\")\n      except Exception as e:\n        print(e)\n        pass\n  print(f\"Evaluate loss {total_loss / len(val_dataloader)}\")\n  return avg_loss, total_preds, total_labels","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.419034Z","iopub.execute_input":"2021-12-22T15:52:34.419631Z","iopub.status.idle":"2021-12-22T15:52:34.434665Z","shell.execute_reply.started":"2021-12-22T15:52:34.419572Z","shell.execute_reply":"2021-12-22T15:52:34.433179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# set initial loss to infinite\nbest_valid_loss = float('inf')\n\n# empty lists to store training and validation loss of each epoch\ntrain_losses=[]\nvalid_losses=[]\nEPOCHS = 2\n#for each epoch\nfor epoch in range(EPOCHS):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, EPOCHS))\n    \n    #train model\n    train_loss, _ = train()\n    \n    #evaluate model\n    valid_loss, _, _ = evaluate()\n    \n    #save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    # append training and validation loss\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:52:34.43675Z","iopub.execute_input":"2021-12-22T15:52:34.437576Z","iopub.status.idle":"2021-12-22T16:08:19.094445Z","shell.execute_reply.started":"2021-12-22T15:52:34.437521Z","shell.execute_reply":"2021-12-22T16:08:19.093309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for evaluating the model\ndef test():\n  \n  print(\"\\nTesting...\")\n  #t0 = time.time()\n  # deactivate dropout layers\n  model.eval()\n\n  total_loss, total_accuracy = 0, 0\n  \n  # empty list to save the model predictions\n  total_preds = []\n  _ids = []\n\n  # iterate over batches\n  for step,batch in enumerate(test_dataloader):\n    \n    # Progress update every 50 batches.\n    if step % 50 == 0 and not step == 0:\n      \n      # Calculate elapsed time in minutes.\n      #elapsed = format_time(time.time() - t0)\n            \n      # Report progress.\n      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\n\n    # push the batch to gpu\n\n#     batch = [r.to(device) for r in batch]\n    _id = batch[\"_id\"]\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    #labels = batch[\"labels\"].to(device)   \n    # deactivate autograd\n    with torch.no_grad():\n      \n      loss, outputs = model(input_ids, attention_mask)\n\n      total_loss = total_loss + loss\n\n      outputs = outputs#.detach().cpu().numpy()\n      _ids.append(_id)\n      total_preds.append(outputs)\n    \n  # compute the validation loss of the epoch\n  avg_loss = total_loss / len(test_dataloader) \n\n  # reshape the predictions in form of (number of samples, no. of classes)\n#   _ids  = torch.cat(_ids, axis=0)\n  _ids = np.concatenate(_ids, axis=0)\n  total_preds  = torch.cat(total_preds, axis=0)\n  results = dict(id=_ids,\n      predictions = total_preds\n      )\n    \n\n  return avg_loss, total_preds, results","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:10:23.978594Z","iopub.execute_input":"2021-12-22T16:10:23.978875Z","iopub.status.idle":"2021-12-22T16:10:23.990318Z","shell.execute_reply.started":"2021-12-22T16:10:23.978844Z","shell.execute_reply":"2021-12-22T16:10:23.989214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_curve, auc\n\ndef evaluate_roc(probs, y_true):\n    \"\"\"\n    - Print AUC and accuracy on the test set\n    - Plot ROC\n    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n    \"\"\"\n    preds = probs#[:, 1]\n    fpr, tpr, threshold = roc_curve(y_true, preds)\n    roc_auc = auc(fpr, tpr)\n    print(f'AUC: {roc_auc:.4f}')\n       \n    # Get accuracy over the test set\n    y_pred = np.where(preds >= 0.5, 1, 0)\n    accuracy = accuracy_score(y_true, y_pred)\n    print(f'Accuracy: {accuracy*100:.2f}%')\n    \n    # Plot ROC AUC\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:10:25.667342Z","iopub.execute_input":"2021-12-22T16:10:25.668044Z","iopub.status.idle":"2021-12-22T16:10:25.676967Z","shell.execute_reply.started":"2021-12-22T16:10:25.668003Z","shell.execute_reply":"2021-12-22T16:10:25.67592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_loss, total_preds, total_labels = evaluate()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:10:28.10055Z","iopub.execute_input":"2021-12-22T16:10:28.100848Z","iopub.status.idle":"2021-12-22T16:11:10.420274Z","shell.execute_reply.started":"2021-12-22T16:10:28.100818Z","shell.execute_reply":"2021-12-22T16:11:10.419112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, name in enumerate(LABEL_COLUMNS):\n    print(f\"label: {name}\")\n    evaluate_roc(total_preds[:,i]>0.5, total_labels[:,i])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:11:10.422347Z","iopub.execute_input":"2021-12-22T16:11:10.422845Z","iopub.status.idle":"2021-12-22T16:11:13.000056Z","shell.execute_reply.started":"2021-12-22T16:11:10.4228Z","shell.execute_reply":"2021-12-22T16:11:12.999104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_test_loss, total_test_preds, sub = test()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:11:13.001663Z","iopub.execute_input":"2021-12-22T16:11:13.002326Z","iopub.status.idle":"2021-12-22T16:20:56.647746Z","shell.execute_reply.started":"2021-12-22T16:11:13.002269Z","shell.execute_reply":"2021-12-22T16:20:56.64671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D = pd.DataFrame()\nD['id'] = sub['id']\nD","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:20:56.650461Z","iopub.execute_input":"2021-12-22T16:20:56.650871Z","iopub.status.idle":"2021-12-22T16:20:56.721306Z","shell.execute_reply.started":"2021-12-22T16:20:56.650824Z","shell.execute_reply":"2021-12-22T16:20:56.720268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D[LABEL_COLUMNS] = (sub['predictions'].cpu().numpy())\nD","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:20:56.722782Z","iopub.execute_input":"2021-12-22T16:20:56.723215Z","iopub.status.idle":"2021-12-22T16:20:56.753133Z","shell.execute_reply.started":"2021-12-22T16:20:56.723166Z","shell.execute_reply":"2021-12-22T16:20:56.751971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:23:15.173006Z","iopub.execute_input":"2021-12-22T16:23:15.17338Z","iopub.status.idle":"2021-12-22T16:23:16.963419Z","shell.execute_reply.started":"2021-12-22T16:23:15.173336Z","shell.execute_reply":"2021-12-22T16:23:16.96232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}