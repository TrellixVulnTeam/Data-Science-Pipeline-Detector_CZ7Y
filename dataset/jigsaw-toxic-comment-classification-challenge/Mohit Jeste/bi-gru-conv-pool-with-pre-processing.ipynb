{"cells":[{"metadata":{},"cell_type":"markdown","source":"Read in the necessary libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport re\nimport sys\nimport warnings\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom tensorflow.keras.layers import Bidirectional, GRU, Conv1D, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read in the training and testing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for any null values in the training or test set and fill them up","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Check for missing values in Train dataset\")\nnull_check=train.isnull().sum()\nprint(null_check)\nprint(\"Check for missing values in Test dataset\")\nnull_check=test.isnull().sum()\nprint(null_check)\nprint(\"filling NA with \\\"unknown\\\"\")\ntrain[\"comment_text\"].fillna(\"unknown\", inplace=True)\ntest[\"comment_text\"].fillna(\"unknown\", inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean the data by removing any html tags, cleaning any punctuations, special characters, IP addresses.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\ndef cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', str(sentence))\n    return cleantext\ndef cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    cleaned = cleaned.strip()\n    cleaned = cleaned.replace(\"\\n\",\" \")\n    return cleaned\ndef keepAlpha(sentence):\n    alpha_sent = \"\"\n    for word in sentence.split():\n        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n        alpha_sent += alpha_word\n        alpha_sent += \" \"\n    alpha_sent = alpha_sent.strip()\n    return alpha_sent\ndata['comment_text'] = data['comment_text'].str.lower()\ndata['comment_text'] = data['comment_text'].apply(cleanHtml)\ndata['comment_text'] = data['comment_text'].apply(cleanPunc)\ndata['comment_text'] = data['comment_text'].apply(keepAlpha)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"remove any stopwords from the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nstop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\nre_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\ndef removeStopWords(sentence):\n    global re_stop_words\n    return re_stop_words.sub(\" \", sentence)\ndata['comment_text'] = data['comment_text'].apply(removeStopWords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data\nprint(train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply the same preprocessing functions to test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = test\n\ndata['comment_text'] = data['comment_text'].str.lower()\ndata['comment_text'] = data['comment_text'].apply(cleanHtml)\ndata['comment_text'] = data['comment_text'].apply(cleanPunc)\ndata['comment_text'] = data['comment_text'].apply(keepAlpha)\ndata['comment_text'] = data['comment_text'].apply(removeStopWords)\n\ntest = data\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load in the training labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_train = train[\"comment_text\"]\nlist_sentences_test = test[\"comment_text\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenize the training and test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make the length of input sequences to be 200 words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 200\nX_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\nprint(X_train.shape)\nprint(y.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split into training and validation sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y, train_size=0.8, random_state=233)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Code for implementing AUC-ROC evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define the model. We will be training our embeddings. It is followed by a bidirectional GRU layer. Then a Conv1D layer and then a Global avg pooling layer. A dense layer of 32 neurons is connected to it which has a relu activation and the final layer has 6 neurons and sigmoid activation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def model():\n    inputs = Input(shape=(maxlen,), name=\"input\")\n    layer = Embedding(max_features, 128, name=\"embedding\")(inputs)\n    layer = Bidirectional(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, name=\"bi_gru_0\"))(layer)\n    layer = Conv1D(64, kernel_size = 3, padding = \"valid\", activation='relu', name=\"conv1d_0\")(layer)\n    layer = GlobalAveragePooling1D(name=\"avg_pool_0\")(layer)\n    layer = Dense(32,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5,name=\"fc1_dropout\")(layer)\n    layer = Dense(6,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                  optimizer='adam',\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check pointing the model based on validation accuracy and creating a callback for AUC-ROC evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_path = os.path.join(\"../input/output/\",\"lstm-custom-embeddings-v4.hdf5\")\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 verbose=1, monitor='val_accuracy',save_best_only=True, mode='max')\n\n\nra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 3\nhistory = model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),shuffle=True, callbacks=[cp_callback,ra_val])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test,batch_size=1024,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nsubmission = pd.read_csv(os.path.join(\"../input/jigsaw-toxic-comment-classification-challenge/\",\"sample_submission.csv.zip\"))\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\nsubmission.to_csv(os.path.join(\"../input/toxic-comment-challenge-submission/\",'submission.csv'), index=False)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since I am posting this notebook after the competition is over I had access to the test labels and I evaluated my model on them","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For the testing kaggle had marked the labels of certain samples in the test labels to be -1 since they were not used for testing. So it is necessary to eliminate those rows from the test set and test labels. To do that I join the test sentences and the test labels based on the id column and then eliminate the test labels that are labelled -1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = pd.read_csv(os.path.join(\"../input/jigsaw-toxic-comment-classification-challenge\",\"test_labels.csv.zip\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = test.join(test_labels.set_index(\"id\"),on=\"id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = test_set[test_set.obscene!=-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny_test = test_set[list_classes].values\nlist_sentences_test = test_set[\"comment_text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 20000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_test))\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 200\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\nprint(y_test.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see I got an accuracy of 99.76%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}