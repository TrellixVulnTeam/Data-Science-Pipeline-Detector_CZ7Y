{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest_data=pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_data.info())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys,os,re,csv,codecs\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense,Conv1D,LSTM,Embedding,Dropout,Bidirectional,MaxPooling1D,GlobalMaxPooling1D\nfrom keras.models import Sequential\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r=train_data.copy()\nr.drop(columns=['id','comment_text'],inplace=True)\nclass_names=list(r.columns)\nprint(class_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train=train_data[class_names].values\nfeatures_train=train_data['comment_text']\nfeatures_test=test_data['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_limit_of_words=30000\ntokenizer=Tokenizer(num_words=max_limit_of_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)\ntokenizer.fit_on_texts(list(features_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_train=tokenizer.texts_to_sequences(features_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_test = tokenizer.texts_to_sequences(features_test)\nword_index = tokenizer.word_index\nvocab_size = len(word_index)\nmean = np.mean([len(i) for i in token_train])\nstd = np.std([len(i) for i in token_train])\nmaximum=int(mean+std*3)\n\naX_train = pad_sequences(token_train,maxlen=maximum,padding='post',truncating='post')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aX_test=pad_sequences(token_test,maxlen=maximum,padding='post',truncating='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dim=100\nei={}\nfile=open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt',encoding='utf-8')\nfor line in file:\n    vals=line.rstrip().rsplit(' ',dim)\n    word = vals[0]\n    coefs = np.asarray(vals[1:], dtype='float32')\n    ei[word] = coefs\nfile.close()\nprint('Found {} word vectors.'.format(len(ei)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"em = np.zeros((vocab_size +1,dim))\ntokens = []\nlabels = []\n\nfor word,i in word_index.items():\n    temp = ei.get(word)\n    if temp is not None:\n        em[i] = temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_layer = Embedding(len(word_index)+1,dim,input_length=maximum,weights=[em])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(embedding_layer)\nmodel.add(Bidirectional(LSTM(30,return_sequences=True,dropout = 0.1 , recurrent_dropout = 0.1)))\nmodel.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(3))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(6, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"model.add(MaxPooling1D(4))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(150,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(6,activation='sigmoid'))\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_cross_val, Y_train,Y_cross_val = train_test_split(aX_train, labels_train,test_size=0.30,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, batch_size=800, epochs=1,validation_data=(X_cross_val, Y_cross_val),verbose=1, shuffle=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = model.predict([aX_test], batch_size=800, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mysubmission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\nmysubmission[class_names] = test_labels\nmysubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}