{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3c2353a2-711a-8ea7-527d-6b2b8fe5882c"},"source":"One more try with xgboost"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"072e4a41-2b57-c020-052c-f60c443c0d24"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7276a2f8-fd8b-9d14-d566-7825e1b508ae"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,roc_auc_score\n\ndef cleanPeople(people):\n    \n    people = people.drop(['date'],axis=1)\n    people['people_id'] = people['people_id'].apply(lambda x : x.split('_')[1])\n    people['people_id'] = pd.to_numeric(people['people_id']).astype(int)\n    \n    fields = list(people.columns)\n    cat_data = fields[1:11]\n    bool_data = fields[11:]\n    \n    for data in cat_data:\n        people[data] = people[data].fillna('type 0')\n        people[data] = people[data].apply(lambda x: x.split(' ')[1])\n        people[data] = pd.to_numeric(people[data]).astype(int)\n    \n    for data in bool_data:\n        people[data] = pd.to_numeric(people[data]).astype(int)\n        \n    \n    return people\n\ndef cleanAct(data, train=False):\n    \n    data = data.drop(['date'],axis = 1)\n    if train:\n        data = data.drop(['outcome'],axis=1)\n        \n    data['people_id'] = data['people_id'].apply(lambda x : x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    data['activity_id'] = data['activity_id'].apply(lambda x: x.split('_')[1])\n    data['activity_id'] = pd.to_numeric(data['activity_id']).astype(int)\n    \n    fields = list(data.columns)\n    cat_data = fields[2:13]\n    \n    for column in cat_data:\n        data[column] = data[column].fillna('type 0')\n        data[column] = data[column].apply(lambda x : x.split(' ')[1])\n        data[column] = pd.to_numeric(data[column]).astype(int)\n     \n    return data    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"662003b0-5485-63ed-844c-86baef0f5238"},"outputs":[],"source":"people = pd.read_csv(\"../input/people.csv\")\npeople = cleanPeople(people)\n\nact_train = pd.read_csv(\"../input/act_train.csv\",parse_dates=['date'])\nact_train_cleaned = cleanAct(act_train,train=True)\n\nact_test = pd.read_csv(\"../input/act_test.csv\",parse_dates=['date'])\nact_test_cleaned = cleanAct(act_test)\n\n\ntrain = act_train_cleaned.merge(people,on='people_id', how='left')\ntest = act_test_cleaned.merge(people, on='people_id', how='left')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"852f9e20-a40c-bced-754f-a7801f763bc0"},"outputs":[],"source":"train.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07432c80-8fdf-ccb3-2202-72e927589b4f"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"379f0b51-be8c-0df0-c91b-6a99b1047967"},"outputs":[],"source":"from sklearn.cross_validation import LabelKFold\n# LabelKFold is a sklearn function that creates train/validation folds over the data\n# The special thing about is that it will split in a way that the same label never appears in\n# both train and test.\n# This means that we can use it to split the training set based on people and get good validation.\n# Here I am making KFolds and then selecting the first one.\ntrain_mask, valid_mask = list(LabelKFold(train['people_id'], n_folds=10))[0]\n\nx_test = test.drop(['people_id','activity_id'],axis=1)\ny = act_train['outcome']\ntrain = train.drop(['people_id', 'activity_id'], axis=1)\n      \n\n#X_train, X_test, y_train, y_test = train_test_split(train,output, test_size=0.2, random_state =7)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f1174e0-ae23-6f89-4ece-e49063b90dd5"},"outputs":[],"source":"kklo=x_train = np.array(train)[train_mask]\ny_train = np.array(y)[train_mask]\n\nx_valid = np.array(train)[valid_mask]\ny_valid = np.array(y)[valid_mask]\n\nprint(x_train.shape)\nprint(x_valid.shape)\n\n# Parameters for XGBoost\nparams = {}\nparams['objective'] = 'binary:logistic'\nparams['eval_metric'] = 'auc'\nparams['eta'] = 0.1 # Learning rate, lower is usually better but takes longer\nparams['max_depth'] = 10\nparams['subsample'] = 0.9\nparams['colsample_bytree'] = 0.9\n\n# Convert to XGBoost DMatrix format\nd_train = xgb.DMatrix(x_train, label=y_train, missing=np.nan)\nd_valid = xgb.DMatrix(x_valid, label=y_valid, missing=np.nan)\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\nclf = xgb.train(params, d_train, 600, watchlist, early_stopping_rounds=40)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d1eb10a-e104-4fdf-06f6-93609193bf99"},"outputs":[],"source":"p_test = clf.predict(xgb.DMatrix(np.array(x_test)))\n\nsub = pd.DataFrame()\nsub['activity_id'] = test['activity_id']\nsub['outcome'] = p_test\nsub.to_csv('submission.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}