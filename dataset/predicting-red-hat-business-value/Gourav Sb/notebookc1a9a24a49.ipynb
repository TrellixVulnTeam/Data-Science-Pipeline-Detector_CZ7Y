{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2259a3bf-65f0-7289-d9f4-6b6c3e77b5e8"},"outputs":[],"source":"import numpy as np \nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef reduce_dimen(dataset,column,toreplace):\n    for index,i in dataset[column].duplicated(keep=False).iteritems():\n        if i==False:\n            dataset.set_value(index,column,toreplace)\n    return dataset\n    \ndef act_data_treatment(dsname):\n    dataset = dsname\n    \n    for col in list(dataset.columns):\n        if col not in ['people_id', 'activity_id', 'date', 'char_38', 'outcome']:\n            if dataset[col].dtype == 'object':\n                dataset[col].fillna('type 0', inplace=True)\n                dataset[col] = dataset[col].apply(lambda x: x.split(' ')[1]).astype(np.int32)\n            elif dataset[col].dtype == 'bool':\n                dataset[col] = dataset[col].astype(np.int8)\n    \n    dataset['year'] = dataset['date'].dt.year\n    dataset['month'] = dataset['date'].dt.month\n    dataset['day'] = dataset['date'].dt.day\n    dataset['isweekend'] = (dataset['date'].dt.weekday >= 5).astype(int)\n    dataset = dataset.drop('date', axis = 1)\n    \n    return dataset\n\nact_train_data = pd.read_csv(\"../input/act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\nact_test_data  = pd.read_csv(\"../input/act_test.csv\", dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\npeople_data    = pd.read_csv(\"../input/people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])\n\nact_train_data=act_train_data.drop('char_10',axis=1)\nact_test_data=act_test_data.drop('char_10',axis=1)\n\nprint(\"Train data shape: \" + format(act_train_data.shape))\nprint(\"Test data shape: \" + format(act_test_data.shape))\nprint(\"People data shape: \" + format(people_data.shape))\n\nact_train_data  = act_data_treatment(act_train_data)\nact_test_data   = act_data_treatment(act_test_data)\npeople_data = act_data_treatment(people_data)\n\ntrain = act_train_data.merge(people_data, on='people_id', how='left', left_index=True)\ntest  = act_test_data.merge(people_data, on='people_id', how='left', left_index=True)\n\ndel act_train_data\ndel act_test_data\ndel people_data\n\ntrain=train.sort_values(['people_id'], ascending=[1])\ntest=test.sort_values(['people_id'], ascending=[1])\n\ntrain_columns = train.columns.values\ntest_columns = test.columns.values\nfeatures = list(set(train_columns) & set(test_columns))\n\ntrain.fillna('NA', inplace=True)\ntest.fillna('NA', inplace=True)\n\ny = train.outcome\ntrain=train.drop('outcome',axis=1)\n\nwhole=pd.concat([train,test],ignore_index=True)\ncategorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\nfor category in categorical:\n    whole=reduce_dimen(whole,category,9999999)\n    \nX=whole[:len(train)]\nX_test=whole[len(train):]\n\ndel train\ndel whole\n    \nX=X.sort_values(['people_id'], ascending=[1])\n\nX = X[features].drop(['people_id', 'activity_id'], axis = 1)\nX_test = X_test[features].drop(['people_id', 'activity_id'], axis = 1)\n\ncategorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\nnot_categorical=[]\nfor category in X.columns:\n    if category not in categorical:\n        not_categorical.append(category)\n\nenc = OneHotEncoder(handle_unknown='ignore')\nenc=enc.fit(pd.concat([X[categorical],X_test[categorical]]))\nX_cat_sparse=enc.transform(X[categorical])\nX_test_cat_sparse=enc.transform(X_test[categorical])\n\nfrom scipy.sparse import hstack\nX_sparse=hstack((X[not_categorical], X_cat_sparse))\nX_test_sparse=hstack((X_test[not_categorical], X_test_cat_sparse))\n\nprint(\"Training data: \" + format(X_sparse.shape))\nprint(\"Test data: \" + format(X_test_sparse.shape))\nprint(\"###########\")\nprint(\"One Hot enconded Test Dataset Script\")\n\ndtrain = xgb.DMatrix(X_sparse,label=y)\ndtest = xgb.DMatrix(X_test_sparse)\n\nparam = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\nparam['nthread'] = 4\nparam['eval_metric'] = 'auc'\nparam['subsample'] = 0.7\nparam['colsample_bytree']= 0.7\nparam['min_child_weight'] = 0\nparam['booster'] = \"gblinear\"\n\nwatchlist  = [(dtrain,'train')]\nnum_round = 300\nearly_stopping_rounds=10\nbst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)\n\nypred = bst.predict(dtest)\nfor i in range(len(ypred)):\n    if(ypred[i]<0.5):ypred[i]=0\n    else:ypred[i] = 1\noutput = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\noutput.head()\noutput.to_csv('without_leak.csv', index = False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}