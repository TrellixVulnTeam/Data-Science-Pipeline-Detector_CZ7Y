{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f221481-e3b4-7870-020c-f1de31b74e0c"},"outputs":[],"source":"\n#dataloading etc adopted from @jeffd23 script\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Model\nfrom keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,ZeroPadding2D\nfrom keras.optimizers import Adam , RMSprop, Adadelta, SGD\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import backend as K\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten, MaxoutDense\nfrom keras.layers.advanced_activations import PReLU,ELU\n\n\nact_train = pd.read_csv('../input/act_train.csv')\nact_test = pd.read_csv('../input/act_test.csv')\npeople = pd.read_csv('../input/people.csv')\n\n# Save the test IDs for Kaggle submission\ntest_ids = act_test['activity_id']\n\ndef preprocess_acts(data, train_set=True):\n    \n    # Getting rid of data feature for now\n    data = data.drop(['date', 'activity_id'], axis=1)\n    if(train_set):\n        data = data.drop(['outcome'], axis=1)\n    \n    ## Split off _ from people_id\n    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    columns = list(data.columns)\n    \n    # Convert strings to ints\n    for col in columns[1:]:\n        data[col] = data[col].fillna('type 0')\n        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n        data[col] = pd.to_numeric(data[col]).astype(int)\n    return data\n\ndef preprocess_people(data):\n    \n    # TODO refactor this duplication\n    data = data.drop(['date'], axis=1)\n    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    #  Values in the people df is Booleans and Strings    \n    columns = list(data.columns)\n    bools = columns[11:]\n    strings = columns[1:11]\n    \n    for col in bools:\n        data[col] = pd.to_numeric(data[col]).astype(int)        \n    for col in strings:\n        data[col] = data[col].fillna('type 0')\n        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n        data[col] = pd.to_numeric(data[col]).astype(int)\n    return data\n    \n    # Preprocess each df\npeeps = preprocess_people(people)\nactions_train = preprocess_acts(act_train)\nactions_test = preprocess_acts(act_test, train_set=False)\n\n# Merege into a unified table\n\n# Training \nfeatures = actions_train.merge(peeps, how='left', on='people_id')\nlabels = act_train['outcome']\n\n# Testing\ntest = actions_test.merge(peeps, how='left', on='people_id')\n\n# Check it out...\nfeatures.sample(10)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86a1f018-bad1-1fce-9ce9-49171f7f3d8e"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5712376b-4077-393b-e44b-1a8aad71dcf8"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n\ndef create_model_v1( input_dim):\n    nb_classes = 1\n    # number of convolutional filters to use\n \n    model = Sequential()\n\n  \n    model.add(Dense(100,input_dim=input_dim,activation='relu'))\n   \n  \n    model.add(Dense(100,activation='relu'))\n  \n   \n    \n    model.add(Dense(nb_classes))\n    model.add(Activation('sigmoid'))\n\n    sgd = SGD(lr=0.05, decay=0, momentum=0.95, nesterov=True)\n    #sgd = SGD(lr=1e-2, decay=1e-6)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    return model\n\nfrom sklearn import preprocessing\n\n\nfrom sklearn.cross_validation import train_test_split\nfeatures = features.as_matrix()\nscaler = preprocessing.StandardScaler().fit(features)\nfeatures = scaler.transform(features)  \nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(features, labels.as_matrix(), test_size=num_test, random_state=1337)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a93bf0c7-4256-b80f-a04f-23dcee1b639c"},"outputs":[],"source":"print(features[0,:])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e3f12a8-0045-9e78-3ffe-ee6e149f6cbf"},"outputs":[],"source":"\n\nmodel_checkpoint = ModelCheckpoint('redhat1.hdf5', monitor='val_loss', save_best_only=True)\n\ninput_dim = X_train.shape[1]\n\nmodel= create_model_v1(input_dim)\n\nprint(\"Start fitting the model\")\n\nmodel.fit(X_train , y_train, batch_size=100, nb_epoch=10, validation_data =(X_test,y_test) ,\n          verbose=1, shuffle=True,callbacks=[model_checkpoint])\n\ntest= scaler.transform(test.as_matrix())\n\nmodel.load_weights('redhat1.hdf5') \nproba= model.predict(X_test, verbose=1)\ntest_proba = model.predict(test, verbose=1)\n\nprint(np.shape(proba))\n\n## Out of box random forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.grid_search import GridSearchCV\nprint(\"start predicting\")\n#clf = RandomForestClassifier()\n#clf.fit(X_train, y_train)\n\n#proba = clf.predict_proba(X_test)\npreds = proba\nscore = roc_auc_score(y_test, preds)\nprint(\"Area under ROC {0}\".format(score))\n\n\n#test_proba = clf.predict_proba(test)\ntest_preds = test_proba.flatten()\n\nprint(np.shape(test_preds))\n# Format for submission\noutput = pd.DataFrame({ 'activity_id' : test_ids, 'outcome': test_preds })\n\noutput.to_csv('redhat.csv', index = False)\n    \n    \n    "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}