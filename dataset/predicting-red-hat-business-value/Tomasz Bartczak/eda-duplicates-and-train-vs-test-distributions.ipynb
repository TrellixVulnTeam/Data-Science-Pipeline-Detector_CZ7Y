{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8dead67d-cf27-b39b-df9d-803de90089ea"},"source":"In this notebook I try to look at duplicate rows characteristics and on variables distributions - with regards to the outcome and between train and test and possible deduplication "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ccf6d9b-067d-e5f7-224a-cac067983ae8"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nbaseDir = \"../input/\"\npeople = pd.read_csv('{0}people.csv'.format(baseDir)).drop_duplicates()\nact_train = pd.read_csv('{0}act_train.csv'.format(baseDir)).drop_duplicates()\nact_test = pd.read_csv('{0}act_test.csv'.format(baseDir)).drop_duplicates()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b16e709-44e9-c04c-de6a-eda5a1cd688b"},"outputs":[],"source":"print(people.shape)\nprint(act_train.shape)\nprint(act_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c059617-f666-d681-6f32-ff3ea65d7c99"},"outputs":[],"source":"print(\"{0} duplicate people rows\".format(people.drop('people_id',axis=1).duplicated().sum()))\nprint(\"{0} duplicate people ids\".format(people['people_id'].duplicated().sum()))\nprint(\"{0} duplicate train rows\".format(act_train.drop('activity_id',axis=1).duplicated().sum()))\nprint(\"{0} duplicate train rows with different outcome\".format(\n        act_train.drop(['activity_id'],axis=1).drop_duplicates().drop('outcome',axis=1).duplicated().sum()))\nprint(\"{0} duplicate train activity id\".format(act_train['activity_id'].duplicated().sum()))\nprint(\"{0} duplicate test rows\".format(act_test.drop('activity_id',axis=1).duplicated().sum()))\nprint(\"{0} duplicate test activity id\".format(act_test['activity_id'].duplicated().sum()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"771fe72c-85f3-645f-8fb5-cb5859518114"},"outputs":[],"source":"unqTrain = act_train.drop(['activity_id','outcome'],axis=1).drop_duplicates()\nunqTest = act_test.drop(['activity_id'],axis=1).drop_duplicates()\ntotal = pd.concat([unqTrain,unqTest],axis=0)\nprint(\"{0} rows duplicated between train and test\".format(len(total) - len(total.drop_duplicates())))\nprint(\"{0} columns diff between train and test\".format([c for c in act_train.columns if c not in act_test.columns and c!='outcome']))"},{"cell_type":"markdown","metadata":{"_cell_guid":"e11bad3a-e59a-ff64-40c1-96ee38832943"},"source":"since column names are anonimized - let's give some explanatory names"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fac1b41-e85c-dc6f-9a29-e6e4c437279a"},"outputs":[],"source":"def addPrefix(df,suffix, exclude):\n    for c in df.columns:\n        if c not in exclude:\n            df.rename(columns={c:suffix+c},inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b531bc67-de24-fb7b-6c72-a95fd9af6437"},"outputs":[],"source":"addPrefix(people,'ppl_',['people_id'])\naddPrefix(act_train,'act_',['people_id','activity_id','activity_category','outcome'])\naddPrefix(act_test,'act_',['people_id','activity_id','activity_category'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"871744cc-181f-2c85-c20f-5f9eb6468fa1"},"outputs":[],"source":"train = pd.merge(act_train,people, on='people_id', how='left')\nprint(train.shape)\ntest = pd.merge(act_test,people, on='people_id', how='left')\nprint(test.shape)\nprint(train.columns)"},{"cell_type":"markdown","metadata":{"_cell_guid":"83831c23-cdcd-d63d-2419-170e9edb53f8"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81a26288-2310-2844-7f60-be54b228fcfc"},"outputs":[],"source":"trainUnique = train[~train.drop(['people_id','activity_id'],axis=1).duplicated()]\nprint(trainUnique.shape)\ntestUnique = test[~test.drop(['people_id','activity_id'],axis=1).duplicated()]\nprint(testUnique.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4345eb2-e819-1001-f81c-13f20d6d1b59"},"outputs":[],"source":"nonCategoricalColumns = ['people_id','activity_id','outcome','ppl_char_38','ppl_date','act_date']\nvalCounts = {}\ndef calcCountSuffix(df,exclude):\n    for c in df.columns:\n        if c not in exclude:\n            cnt = len(df[c].value_counts())\n            valCounts[c] = cnt\ncalcCountSuffix(trainUnique,nonCategoricalColumns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1bea29cd-2bee-7ebd-610c-3d77aaacf9aa"},"outputs":[],"source":"def addCountSuffix(df,exclude):\n    for c in df.columns:\n        if c not in exclude:\n            cnt = valCounts[c]\n            df.rename(columns={c:c+\"_cnt_\"+str(cnt)},inplace=True)\naddCountSuffix(train,nonCategoricalColumns)\naddCountSuffix(test,nonCategoricalColumns)\naddCountSuffix(trainUnique,nonCategoricalColumns)\naddCountSuffix(testUnique,nonCategoricalColumns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bacf7b7b-9ff8-882d-e0b7-9a4e059ceb06"},"outputs":[],"source":"def getColumnsBySuffix(df,minValue,maxValue,exclude):\n    return [c for c in df.columns if c not in exclude if int(c.split(\"_\")[-1])>=minValue and int(c.split(\"_\")[-1])<=maxValue]\ndef drawViolin(df, minCnt,maxCnt,indexFrom, indexTo, size=3.5):\n    g = sns.PairGrid(df,\n                 x_vars=getColumnsBySuffix(train,minCnt,maxCnt,nonCategoricalColumns)[indexFrom:indexTo],\n                 y_vars=[\"outcome\"],\n                 aspect=.75, size=size)\n    g.map(sns.violinplot, palette=\"pastel\");"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c512cbc4-30f6-d3d0-7446-9165794a0b1c"},"outputs":[],"source":"sam10k = trainUnique.sample(10000)\nsam100k = trainUnique.sample(100000)\nsam500k = trainUnique.sample(500000)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e6331bf1-ae49-0d08-d7ba-38afe4ac54aa"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fbb46d81-a602-6c0d-889d-489a12e1740f"},"outputs":[],"source":"drawViolin(sam10k,2,2,0,6)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2af99bc-c4a7-8cf4-7471-2f9465a49ee0"},"outputs":[],"source":"drawViolin(sam10k,2,2,6,11)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9203bef2-2ff3-44f7-d379-82d27cf3ea3b"},"outputs":[],"source":"drawViolin(sam10k,2,2,11,16)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf4229c8-72b4-dfe5-137a-29e1277287d3"},"outputs":[],"source":"drawViolin(sam10k,2,2,16,21)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cda2d979-888f-76c4-5065-40f8119617b8"},"outputs":[],"source":"drawViolin(sam10k,2,2,21,26)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a30c5d2-6f4f-bd5d-a51c-c7e13d881385"},"outputs":[],"source":"drawViolin(sam10k,2,2,26,31)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44ce33e6-5158-b19c-4a45-7c9ffe3caae8"},"outputs":[],"source":"drawViolin(sam100k,3,6,0,6,8.0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6fe66c3-1a68-386d-5178-bcaf395a5af1"},"outputs":[],"source":"drawViolin(sam100k,6,7,0,5,5.0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82357cb5-532e-4907-3bd4-305b18dfe0ee"},"outputs":[],"source":"drawViolin(sam100k,8,8,0,5,8.0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f4590d8-74b7-edfb-68ab-fef54f57fecc"},"outputs":[],"source":"drawViolin(sam100k,9,9,0,5,8.0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1cd2040d-954b-4d03-9c2a-44abd1159c0a"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5207d6ef-c6f0-9124-996a-b5e77be77cd5"},"outputs":[],"source":"getColumnsBySuffix(trainUnique,10,10000000,exclude=nonCategoricalColumns)"},{"cell_type":"markdown","metadata":{"_cell_guid":"39180b6b-5ab9-dcac-e724-76865597939c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81be37ee-eee3-55d6-aec7-65e9f5ac8d2e"},"outputs":[],"source":"def createDataForDistributionsPlot():\n    train['set'] = 'train'\n    trainUnique['set'] = 'trainUnique'\n    test['set'] = 'test'\n    return pd.concat([train,trainUnique,test],axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d16a02f-f818-0406-fb6d-74c7e209d733"},"outputs":[],"source":"trainAndTest = createDataForDistributionsPlot()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6117192c-e8a0-9bdc-0164-1a193f730a34"},"outputs":[],"source":"def drawDistributions(column):\n    gb = trainAndTest.groupby([c,'set'],as_index=False).count()[[c,'set','activity_id']]\n    gb['c_freq'] = gb['activity_id'] / np.where(gb['set'] == 'train',len(train),np.where(gb['set'] == 'trainUnique',len(trainUnique),len(test)))\n    sns.barplot(x=c, y='c_freq', hue='set', hue_order=['train','trainUnique','test'], data=gb)    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"742f7695-4dd2-4e95-43da-4aa262157950"},"outputs":[],"source":"import matplotlib.pyplot as plt\nfor c in getColumnsBySuffix(trainAndTest,2,2,exclude=nonCategoricalColumns + ['set']):\n    drawDistributions(c)\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"04749d12-aaff-fd99-9216-d0f4505cf44e"},"outputs":[],"source":"import matplotlib.pyplot as plt\nfor c in getColumnsBySuffix(trainAndTest,3,52,exclude=nonCategoricalColumns + ['set']):\n    drawDistributions(c)\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a313a111-cb52-85f2-f3cd-ad3be5fa98b4"},"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}