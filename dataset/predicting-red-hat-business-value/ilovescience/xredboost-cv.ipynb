{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f07e0789-e36c-6906-c678-d126c96c7497"},"outputs":[],"source":"import datetime\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cross_validation import KFold\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nimport random\nfrom operator import itemgetter\nimport time\nimport copy\n\nrandom.seed(2016)\n\n\ndef create_feature_map(features):\n    outfile = open('xgb.fmap', 'w')\n    for i, feat in enumerate(features):\n        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n    outfile.close()\n\n\ndef get_importance(gbm, features):\n    create_feature_map(features)\n    importance = gbm.get_fscore(fmap='xgb.fmap')\n    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n    return importance\n\n\ndef intersect(a, b):\n    return list(set(a) & set(b))\n\n\ndef run_single(train, test, features, target, random_state=0):\n    eta = 0.2\n    max_depth = 5\n    subsample = 0.8\n    colsample_bytree = 0.8\n    start_time = time.time()\n\n    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n    params = {\n        \"objective\": \"binary:logistic\",\n        \"booster\" : \"gbtree\",\n        \"eval_metric\": \"auc\",\n        \"eta\": eta,\n        \"tree_method\": 'exact',\n        \"max_depth\": max_depth,\n        \"subsample\": subsample,\n        \"colsample_bytree\": colsample_bytree,\n        \"silent\": 1,\n        \"seed\": random_state,\n    }\n    num_boost_round = 115\n    early_stopping_rounds = 10\n    test_size = 0.1\n\n    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n    print('Length train:', len(X_train.index))\n    print('Length valid:', len(X_valid.index))\n    y_train = X_train[target]\n    y_valid = X_valid[target]\n    dtrain = xgb.DMatrix(X_train[features], y_train)\n    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n\n    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n\n    print(\"Validating...\")\n    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration+1)\n    score = roc_auc_score(X_valid[target].values, check)\n    print('Check error value: {:.6f}'.format(score))\n\n    imp = get_importance(gbm, features)\n    print('Importance array: ', imp)\n\n    print(\"Predict test set...\")\n    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration+1)\n\n    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n    return test_prediction.tolist(), score\n\n\ndef run_kfold(nfolds, train, test, features, target, random_state=0):\n    eta = 0.2\n    max_depth = 5\n    subsample = 0.8\n    colsample_bytree = 0.8\n    start_time = time.time()\n\n    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n    params = {\n        \"objective\": \"binary:logistic\",\n        \"booster\" : \"gbtree\",\n        \"eval_metric\": \"auc\",\n        \"eta\": eta,\n        \"max_depth\": max_depth,\n        \"subsample\": subsample,\n        \"colsample_bytree\": colsample_bytree,\n        \"silent\": 1,\n        \"seed\": random_state\n    }\n    num_boost_round = 150\n    early_stopping_rounds = 10\n\n    yfull_train = dict()\n    yfull_test = copy.deepcopy(test[['activity_id']].astype(object))\n    kf = KFold(len(train.index), n_folds=nfolds, shuffle=True, random_state=random_state)\n    num_fold = 0\n    for train_index, test_index in kf:\n        num_fold += 1\n        print('Start fold {} from {}'.format(num_fold, nfolds))\n        X_train, X_valid = train[features].as_matrix()[train_index], train[features].as_matrix()[test_index]\n        y_train, y_valid = train[target].as_matrix()[train_index], train[target].as_matrix()[test_index]\n        X_test = test[features].as_matrix()\n\n        print('Length train:', len(X_train))\n        print('Length valid:', len(X_valid))\n\n        dtrain = xgb.DMatrix(X_train, y_train)\n        dvalid = xgb.DMatrix(X_valid, y_valid)\n\n        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n        gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n        \n        print(\"Validating...\")\n        yhat = gbm.predict(xgb.DMatrix(X_valid), ntree_limit=gbm.best_iteration+1)\n        score = roc_auc_score(y_valid.tolist(), yhat)\n        print('Check error value: {:.6f}'.format(score))\n\n        # Each time store portion of precicted data in train predicted values\n        for i in range(len(test_index)):\n            yfull_train[test_index[i]] = yhat[i]\n\n        imp = get_importance(gbm, features)\n        print('Importance array: ', imp)\n\n        print(\"Predict test set...\")\n        test_prediction = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration+1)\n        yfull_test['kfold_' + str(num_fold)] = test_prediction\n\n    # Copy dict to list\n    train_res = []\n    for i in sorted(yfull_train.keys()):\n        train_res.append(yfull_train[i])\n\n    score = roc_auc_score(train[target], np.array(train_res))\n    print('Check error value: {:.6f}'.format(score))\n\n    # Find mean for KFolds on test\n    merge = []\n    for i in range(1, nfolds+1):\n        merge.append('kfold_' + str(i))\n    yfull_test['mean'] = yfull_test[merge].mean(axis=1)\n\n    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n    return yfull_test['mean'].values, score\n\n\ndef create_submission(score, test, prediction):\n    now = datetime.datetime.now()\n    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n    print('Writing submission: ', sub_file)\n    f = open(sub_file, 'w')\n    f.write('activity_id,outcome\\n')\n    total = 0\n    for id in test['activity_id']:\n        str1 = str(id) + ',' + str(prediction[total])\n        str1 += '\\n'\n        total += 1\n        f.write(str1)\n    f.close()\n\n\ndef get_features(train, test):\n    trainval = list(train.columns.values)\n    testval = list(test.columns.values)\n    output = intersect(trainval, testval)\n    output.remove('people_id')\n    output.remove('activity_id')\n    return sorted(output)\n\n\ndef read_test_train():\n\n    print(\"Read people.csv...\")\n    people = pd.read_csv(\"../input/people.csv\",\n                       dtype={'people_id': np.str,\n                              'activity_id': np.str,\n                              'char_38': np.int32},\n                       parse_dates=['date'])\n\n    print(\"Load train.csv...\")\n    train = pd.read_csv(\"../input/act_train.csv\",\n                        dtype={'people_id': np.str,\n                               'activity_id': np.str,\n                               'outcome': np.int8},\n                        parse_dates=['date'])\n\n    print(\"Load test.csv...\")\n    test = pd.read_csv(\"../input/act_test.csv\",\n                       dtype={'people_id': np.str,\n                              'activity_id': np.str},\n                       parse_dates=['date'])\n\n    print(\"Process tables...\")\n    for table in [train, test]:\n        table['year'] = table['date'].dt.year\n        table['month'] = table['date'].dt.month\n        table['day'] = table['date'].dt.day\n        table.drop('date', axis=1, inplace=True)\n        table['activity_category'] = table['activity_category'].str.lstrip('type ').astype(np.int32)\n        for i in range(1, 11):\n            table['char_' + str(i)].fillna('type -999', inplace=True)\n            table['char_' + str(i)] = table['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n\n    people['year'] = people['date'].dt.year\n    people['month'] = people['date'].dt.month\n    people['day'] = people['date'].dt.day\n    people['weekday'] = people['date'].dt.weekday\n    people['weekend'] = ((people.weekday == 0) | (people.weekday == 6)).astype(int)\n    people.drop('date', axis=1, inplace=True)\n    people['group_1'] = people['group_1'].str.lstrip('group ').astype(np.int32)\n    for i in range(1, 10):\n        people['char_' + str(i)] = people['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n    for i in range(10, 38):\n        people['char_' + str(i)] = people['char_' + str(i)].astype(np.int32)\n\n    print(\"Merge...\")\n    train = pd.merge(train, people, how='left', on='people_id', left_index=True)\n    train.fillna(-999, inplace=True)\n    test = pd.merge(test, people, how='left', on='people_id', left_index=True)\n    test.fillna(-999, inplace=True)\n\n    features = get_features(train, test)\n    return train, test, features\n\n\ntrain, test, features = read_test_train()\nprint('Length of train: ', len(train))\nprint('Length of test: ', len(test))\nprint('Features [{}]: {}'.format(len(features), sorted(features)))\n\ntest_prediction, score = run_single(train, test, features, 'outcome')\nprint(type(test_prediction))\n#test_prediction, score = run_kfold(3, train, test, features, 'outcome')\ncreate_submission(score, test, test_prediction)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}