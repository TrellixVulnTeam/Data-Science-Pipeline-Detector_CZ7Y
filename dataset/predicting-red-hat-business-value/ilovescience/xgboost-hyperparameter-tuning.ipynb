{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e33663e-0fd0-fa5e-ec70-e99973b3256a"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport datetime\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cross_validation import KFold\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.grid_search import GridSearchCV\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nimport random\nfrom operator import itemgetter\nimport time\nimport copy\n\nrandom.seed(2016)\n\n\ndef create_feature_map(features):\n    outfile = open('xgb.fmap', 'w')\n    for i, feat in enumerate(features):\n        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n    outfile.close()\n\n\ndef get_importance(gbm, features):\n    create_feature_map(features)\n    importance = gbm.get_fscore(fmap='xgb.fmap')\n    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n    return importance\n\ndef create_submission(score, test, prediction):\n    now = datetime.datetime.now()\n    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n    print('Writing submission: ', sub_file)\n    f = open(sub_file, 'w')\n    f.write('activity_id,outcome\\n')\n    total = 0\n    for id in test['activity_id']:\n        str1 = str(id) + ',' + str(prediction[total])\n        str1 += '\\n'\n        total += 1\n        f.write(str1)\n    f.close()\n\n\ndef intersect(a, b):\n    return list(set(a) & set(b))\n\ndef get_features(train, test):\n    trainval = list(train.columns.values)\n    testval = list(test.columns.values)\n    output = intersect(trainval, testval)\n    output.remove('people_id')\n    return sorted(output)\n\ndef xgboost_model(train, test, features, target, random_state=0):\n    eta = 1.0\n    max_depth = 10\n    \n    subsample = 0.8\n    colsample_bytree = 0.8\n    start_time = time.time()\n\n    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n    params = {\n        \"objective\": \"binary:logistic\",\n        \"booster\" : \"gbtree\",\n        \"eval_metric\": \"auc\",\n        \"eta\": eta,\n        \"tree_method\": 'exact',\n        \"max_depth\": max_depth,\n        \"subsample\": subsample,\n        \"colsample_bytree\": colsample_bytree,\n        \"silent\": 1,\n        \"seed\": random_state,\n    }\n    num_boost_round = 115\n    early_stopping_rounds = 10\n    test_size = 0.1\n\n    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n    print('Length train:', len(X_train.index))\n    print('Length valid:', len(X_valid.index))\n    y_train = X_train[target]\n    y_valid = X_valid[target]\n    dtrain = xgb.DMatrix(X_train[features], y_train)\n    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n\n    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n\n    print(\"Validating...\")\n    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration+1)\n    score = roc_auc_score(X_valid[target].values, check)\n    print('Check error value: {:.6f}'.format(score))\n\n    imp = get_importance(gbm, features)\n    print('Importance array: ', imp)\n\n    print(\"Predict test set...\")\n    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration+1)\n\n    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n    return test_prediction.tolist(), score\n\n\ndef simple_load():\n\n    print(\"Read people.csv...\")\n    people = pd.read_csv(\"../input/people.csv\",\n                       dtype={'people_id': np.str,\n                              'activity_id': np.str,\n                              'char_38': np.int32},\n                       parse_dates=['date'])\n\n    print(\"Load train.csv...\")\n    train = pd.read_csv(\"../input/act_train.csv\",\n                        dtype={'people_id': np.str,\n                               'activity_id': np.str,\n                               'outcome': np.int8},\n                        parse_dates=['date'])\n\n    print(\"Load test.csv...\")\n    test = pd.read_csv(\"../input/act_test.csv\",\n                       dtype={'people_id': np.str,\n                              'activity_id': np.str},\n                       parse_dates=['date'])\n\n    print(\"Process tables...\")\n    for table in [train, test]:\n        table['activity_category'] = table['activity_category'].str.lstrip('type ').astype(np.int32)\n        for i in range(1, 11):\n            table['char_' + str(i)].fillna('type -999', inplace=True)\n            table['char_' + str(i)] = table['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n    people['group_1'] = people['group_1'].str.lstrip('group ').astype(np.int32)\n    for i in range(1, 10):\n        people['char_' + str(i)] = people['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n    for i in range(10, 38):\n        people['char_' + str(i)] = people['char_' + str(i)].astype(np.int32)\n\n    print(\"Merge...\")\n    train = train.merge(people, on=\"people_id\", suffixes=(\"_act\", \"\"))\n    test = test.merge(people, on=\"people_id\", suffixes=(\"_act\", \"\"))\n    \n    # Set index to activity id\n    train = train.set_index(\"activity_id\")\n    test = test.set_index(\"activity_id\")\n\n    # Correct some data types\n    for field in [\"date_act\", \"date\"]:\n        train[field] = pd.to_datetime(train[field])\n        test[field] = pd.to_datetime(test[field])\n\n    return train, test\n\n\ndef xgboost_process(train,test,features):\n    print(\"Process tables... \")\n    for table in [train, test]:\n        table['year'] = table['date'].dt.year\n        table['month'] = table['date'].dt.month\n        table['day'] = table['date'].dt.day\n        table.drop('date', axis=1, inplace=True)\n    features.remove('date')\n    features.remove('date_act')\n    return train, test, features\n    \n\ndef model():\n\n    # Load in the data set simply by merging together\n    train, test = simple_load()\n    \n    # Get features\n    features = get_features(train,test)\n    \n    # XGBoost processing\n    train, test, features = xgboost_process(train, test, features)\n    \n    #test_prediction, score = xgboost_model(train, test, features, 'outcome')\n    #create_submission(score, test, test_prediction)\n    \n    param_test1 = {\n        'max_depth':list(range(3,10,2)),\n        'min_child_weight':list(range(1,6,2))\n    }\n    gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n    gsearch1.fit(train[features],train['outcome'])\n    gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n    \n    \n    \n    \n\ndef main():\n\n    # Write a benchmark file to the submissions folder\n    model()\nif __name__ == \"__main__\":\n    main()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}