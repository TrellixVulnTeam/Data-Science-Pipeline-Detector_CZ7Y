{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f0c93eec-fbac-0070-1e97-8ffd6f9bada8"},"source":"The folding strategy based on people_id solves the overfitting implied by this feature but one may need to reproduce the fact that some groups in test are not in the train dataset.\nSo here is my folding strategy based on people group_1.  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e969f3eb-ee8d-8c98-d10a-d5d778d01c2b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"0662a049-72b0-b3c4-5267-3e44abc410c5"},"source":"# Read the files"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"746aa434-5db8-4c6b-78f8-bc574ff999e8"},"outputs":[],"source":"train_X = pd.read_csv(\"../input/act_train.csv\", sep=\",\")\npeople = pd.read_csv('../input/people.csv', sep=',')"},{"cell_type":"markdown","metadata":{"_cell_guid":"4cfc33e0-281a-e66c-9311-4cf646ec0671"},"source":"# Merge train and people data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9383a362-1dcc-12f9-0f95-8e26bce4d8cf"},"outputs":[],"source":"people.columns = ['people_id']+[f+'_ppl' for f in people.columns if f not in ['people_id']]\nfold_X = pd.merge(train_X, people, on='people_id', how='left', suffixes=['_act', ''])[['activity_id','group_1_ppl']]\ndel people\ndel train_X"},{"cell_type":"markdown","metadata":{"_cell_guid":"584e24d8-d8b6-d6fa-5834-9858fe3e0983"},"source":"# Compute group occurences"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"273c8e83-f831-1d17-2251-67e221268ce5"},"outputs":[],"source":"n_folds = 5\nfold_X.sort_values(by='group_1_ppl', inplace=True)\n# Check group_1 values occurences to drop groups that have less than n_folds occurences\ngroup_counts = fold_X.group_1_ppl.value_counts()\ngroup_counts_merge = group_counts.reset_index()\ngroup_counts_merge.columns = ['group_1_ppl','counts']\n# Merge occurences with data\nfold_X = pd.merge(fold_X, group_counts_merge, on='group_1_ppl', how='left')\nfold_X.sort_values(by='counts', inplace=True)\n# Make sure index is 0,1,2...n\nfold_X.reset_index(inplace=True, drop=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"80bf6ba3-5a98-8524-1df7-b3eefdcd75c0"},"source":"# Dispatch all samples in fold_X in 5 folds"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b0dceb8-540c-24a3-df1c-44a00fc502de"},"outputs":[],"source":"fold_X['fold'] = fold_X.index % 5\nfold_X['new_index'] = np.floor(fold_X.index/5).astype(int)\ntest_folds = fold_X.pivot(index = 'new_index', columns='fold', values='activity_id')\ntest_folds.drop(439458,axis=0,inplace=True) # The last row contains NaN"},{"cell_type":"markdown","metadata":{"_cell_guid":"7a4fb37c-a19d-3d8d-43ce-d4782c991f24"},"source":"# Start each fold with different groups\nfold_X is sorted by occurence. If we take 5 chunks of data at the start of fold_X they'll have almost no group in common "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"509e7305-0575-0dc7-25fc-12ea8dd0ef10"},"outputs":[],"source":"nogroup_len = 65000\nf_idx = fold_X.index\nfor i in range(n_folds):\n    test_folds.ix[:(nogroup_len-1),i] =  fold_X.ix[f_idx[nogroup_len*i:nogroup_len*(i+1)], \"activity_id\"].values"},{"cell_type":"markdown","metadata":{"_cell_guid":"89283917-332e-bbf9-bb99-bd8568d85550"},"source":"# Save folds"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fc6335f-6de9-9b8e-3a30-6b2677b032a9"},"outputs":[],"source":"print(test_folds.tail())\ntest_folds.to_csv('test_folds.csv', index=False, sep=',')"},{"cell_type":"markdown","metadata":{"_cell_guid":"2f8c772c-b767-ca3c-1655-df844d40a889"},"source":"# Create corresponding train folds"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5bd4d965-73a7-39ca-b40a-13332132c06a"},"outputs":[],"source":"nb_samples = len(test_folds)\ntrain_folds = pd.DataFrame(np.zeros((nb_samples * 4, 5)))\nfor i in range(5):\n    g = 0\n    for n in range(5):\n        if n != i:\n            train_folds.ix[g * nb_samples:(g + 1) * nb_samples - 1, i] = test_folds.ix[:, n].values\n            g += 1\ntrain_folds.to_csv('train_folds.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2bb7fc5-2c40-ed66-5613-e68459ef7505"},"outputs":[],"source":"train_folds.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75f5105d-df78-60e7-7b3f-851c93128f37"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}