{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8516a71c-fa10-0a15-600a-896276acbb63"},"source":"# Initialize Libraries"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7920e425-9f5c-90a3-c7b5-46253bd824e9"},"outputs":[],"source":"#Neural Net using binary data only\n\nprint(\"Initialize libraries\")\nimport pandas as pd\nimport sys\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import StratifiedKFold, KFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics as skmetrics\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom keras.layers.advanced_activations import PReLU\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import ensemble\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\nimport gc\nfrom scipy import sparse\nfrom sklearn.cross_validation import train_test_split, cross_val_score\nfrom sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest\nfrom sklearn import ensemble\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\n\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.cross_validation import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import log_loss"},{"cell_type":"markdown","metadata":{"_cell_guid":"c6373871-ce5e-1914-b1d5-e05055ea901d"},"source":"# Read data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80180db9-97da-fbc6-8d61-2d05076d8382"},"outputs":[],"source":"#------------------------------------------------ Read data from source files ------------------------------------\nseed = 700\nnp.random.seed(seed)\ndatadir = '../input'\n\nprint(\"### ----- PART 1 ----- ###\")\n\nprint(\"# Read people\")\npeople = pd.read_csv(os.path.join(datadir,'people.csv'), dtype={'char_10' : np.int,\n                                                               'char_11' : np.int,\n                                                               'char_12' : np.int,\n                                                               'char_13' : np.int,\n                                                               'char_14' : np.int,\n                                                               'char_15' : np.int,\n                                                               'char_16' : np.int,\n                                                               'char_17' : np.int,\n                                                               'char_18' : np.int,\n                                                               'char_19' : np.int,\n                                                               'char_20' : np.int,\n                                                               'char_21' : np.int,\n                                                               'char_22' : np.int,\n                                                               'char_23' : np.int,\n                                                               'char_24' : np.int,\n                                                               'char_25' : np.int,\n                                                               'char_26' : np.int,\n                                                               'char_27' : np.int,\n                                                               'char_28' : np.int,\n                                                               'char_29' : np.int,\n                                                               'char_30' : np.int,\n                                                               'char_31' : np.int,\n                                                               'char_32' : np.int,\n                                                               'char_33' : np.int,\n                                                               'char_33' : np.int,\n                                                               'char_34' : np.int,\n                                                               'char_35' : np.int,\n                                                               'char_36' : np.int,\n                                                               'char_37' : np.int})\npeople['date'] = pd.to_datetime(people['date'])\npeople['date_increment'] = people['date'] - people['date'].min()\npeople = people.sort_values('date_increment')\nprint(\"reduce dimensions\")\npeople.drop('char_2', axis=1, inplace=True) #duplicate of char_1\n# rename people columns\npeople.rename(columns = {'char_1':'ppl_char_1',\n                        'char_3':'ppl_char_3',\n                        'char_4':'ppl_char_4',\n                        'char_5':'ppl_char_5',\n                        'char_6':'ppl_char_6',\n                        'char_7':'ppl_char_7',\n                        'char_8':'ppl_char_8',\n                        'char_9':'ppl_char_9',\n                        'char_10':'ppl_char_10',\n                        'date':'ppl_date',\n                        'date_increment': 'ppl_date_increment'}, inplace = True)\nppl_table_logi = people['group_1'].value_counts() == 1\npeople.group_1[people.group_1.isin(ppl_table_logi[ppl_table_logi == 1].index)] = 'group unique'\n#people.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9be9264b-d025-5783-889e-1b33245b6e67"},"outputs":[],"source":"print(\"Read Train\")\ntrain = pd.read_csv(os.path.join(datadir,'act_train.csv'), dtype={'char_1' : np.str,\n                                                               'char_2' : np.str,\n                                                               'char_3' : np.str,\n                                                               'char_4' : np.str,\n                                                               'char_5' : np.str,\n                                                               'char_6' : np.str,\n                                                               'char_7' : np.str,\n                                                               'char_8' : np.str,\n                                                               'char_9' : np.str,\n                                                               'char_10' : np.str\n})\ntrain['date'] = pd.to_datetime(train['date'])\ntrain['date_increment'] = train['date'] - train['date'].min()\n#train.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f37a82b-5544-224d-d56d-d4c1a881ba5c"},"outputs":[],"source":"print(\"Read Test\")\ntest = pd.read_csv(os.path.join(datadir,'act_test.csv'), dtype={'char_1' : np.str,\n                                                               'char_2' : np.str,\n                                                               'char_3' : np.str,\n                                                               'char_4' : np.str,\n                                                               'char_5' : np.str,\n                                                               'char_6' : np.str,\n                                                               'char_7' : np.str,\n                                                               'char_8' : np.str,\n                                                               'char_9' : np.str,\n                                                               'char_10' : np.str\n})\ntest['date'] = pd.to_datetime(test['date'])\ntest['date_increment'] = test['date'] - test['date'].min()\n#test.head(5)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bb305f05-5154-9d56-bede-810e7714b86f"},"source":"# Reduce char_10"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"065fad4b-ecc1-7b20-aa08-c7ab03d3c3a4"},"outputs":[],"source":"print(\"reduce dimensions of train and test char_10\")\nuni_char_10 = train[['people_id', 'char_10']]\nuni_char_10 = uni_char_10.append(test[[\"people_id\", \"char_10\"]])\nx = uni_char_10.groupby('char_10').people_id.nunique()\nuni_char_10 = x.index[x == 1]\ntrain.char_10[train.char_10.isin(uni_char_10)] = 'type unique'\ntest.char_10[test.char_10.isin(uni_char_10)] = 'type unique'"},{"cell_type":"markdown","metadata":{"_cell_guid":"c37c0434-b158-713f-be61-f5219993c7f2"},"source":"# Merge Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4014623-56e1-ba51-221d-d3272f658853"},"outputs":[],"source":"split_len = len(train)\n\n# Group Labels\nY = train[\"outcome\"]\nlabel_outcome = LabelEncoder()\nY = label_outcome.fit_transform(Y)\nactivity_id = test[\"activity_id\"]\n\n# Merge train and test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ab622cf-7adc-67aa-8c50-79d4636eecda"},"outputs":[],"source":"#train = pd.merge(train, people, on = 'people_id',how='left')\n#train.drop('outcome', axis=1, inplace=True)\nDf = pd.concat([train, test])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81b04033-4380-2562-c104-3fe39e13fa52"},"outputs":[],"source":"Df = pd.merge(Df, people, on = 'people_id', how = 'left')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e67d04bd-993c-4285-1e65-79f5e265eb85"},"outputs":[],"source":"Df.fillna(\"type 0\", inplace=True)\n#Df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2256bf1f-c74e-1479-bcae-f5779421ca2c"},"outputs":[],"source":"#change date_increment to numeric\nDf['ppl_date_increment'] = Df.ppl_date_increment.astype(int) / 86400000000000\nDf['date_increment'] = Df.date_increment.astype(int) / 86400000000000"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"671538ab-ec7f-d509-d3b6-ce8dc9305ac9"},"outputs":[],"source":"not_categorical=[]\ncategorical=['activity_category',\n             #'group_1',\n             'char_1',\n             'char_2',\n             'char_3',\n             'char_4',\n             'char_5',\n             'char_6',\n             'char_7',\n             'char_8',\n             'char_9',\n             'char_10',\n             'ppl_char_1',\n             'ppl_char_3',\n             'ppl_char_4',\n             'ppl_char_5',\n             'ppl_char_6',\n             'ppl_char_7',\n             'ppl_char_8',\n             'ppl_char_9']\n\nfor category in Df.columns:\n    if category not in categorical:\n        not_categorical.append(category)\n        \n#not_categorical\n#CHAR_10 STILL HAD !4600 different types!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c6775bd-595b-9a7a-e246-03d06277eff9"},"outputs":[],"source":"Df_cats = Df[categorical]\nDf_cats.ix[:,0] = LabelEncoder().fit_transform(Df_cats.ix[:,0])\nDf_cats.ix[:,1] = LabelEncoder().fit_transform(Df_cats.ix[:,1])\nDf_cats.ix[:,2] = LabelEncoder().fit_transform(Df_cats.ix[:,2])\nDf_cats.ix[:,3] = LabelEncoder().fit_transform(Df_cats.ix[:,3])\nDf_cats.ix[:,4] = LabelEncoder().fit_transform(Df_cats.ix[:,4])\nDf_cats.ix[:,5] = LabelEncoder().fit_transform(Df_cats.ix[:,5])\nDf_cats.ix[:,6] = LabelEncoder().fit_transform(Df_cats.ix[:,6])\nDf_cats.ix[:,7] = LabelEncoder().fit_transform(Df_cats.ix[:,7])\nDf_cats.ix[:,8] = LabelEncoder().fit_transform(Df_cats.ix[:,8])\nDf_cats.ix[:,9] = LabelEncoder().fit_transform(Df_cats.ix[:,9])\nDf_cats.ix[:,10] = LabelEncoder().fit_transform(Df_cats.ix[:,10])\nDf_cats.ix[:,11] = LabelEncoder().fit_transform(Df_cats.ix[:,11])\nDf_cats.ix[:,12] = LabelEncoder().fit_transform(Df_cats.ix[:,12])\nDf_cats.ix[:,13] = LabelEncoder().fit_transform(Df_cats.ix[:,13])\nDf_cats.ix[:,14] = LabelEncoder().fit_transform(Df_cats.ix[:,14])\nDf_cats.ix[:,15] = LabelEncoder().fit_transform(Df_cats.ix[:,15])\nDf_cats.ix[:,16] = LabelEncoder().fit_transform(Df_cats.ix[:,16])\nDf_cats.ix[:,17] = LabelEncoder().fit_transform(Df_cats.ix[:,17])\nDf_cats.ix[:,18] = LabelEncoder().fit_transform(Df_cats.ix[:,18])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"553fd19b-4949-3963-1914-2b32e45917c1"},"outputs":[],"source":"Df_cats.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e13b6d48-cf34-47b7-bfbe-6fa58e11f7c9"},"outputs":[],"source":"#Df_cats.ix[:,0] =  (Df_cats.columns[0] + Df_cats.ix[:,0]).astype('category')\ndec = LabelEncoder().fit_transform(Df_cats[\"activity_category\"])\ndec"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4038b0c3-953d-f3a2-0a2b-008336fc1cc9"},"outputs":[],"source":"#Df_cats.drop('char_10', 1, inplace=True)\ndata = sp.sparse.csr_matrix(Df_cats[\"activity_category\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea6b8047-0ccc-fffc-7f20-17f4390bb335"},"outputs":[],"source":"device_ids = FLS[\"device_id\"].unique()\nfeature_cs = FLS[\"feature\"].unique()\n\ndata = np.ones(len(FLS))\nlen(data)\n\ndec = LabelEncoder().fit(FLS[\"device_id\"])\nrow = dec.transform(FLS[\"device_id\"])\ncol = LabelEncoder().fit_transform(FLS[\"feature\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cf4276b-5dae-9f3b-a9c2-5c85701881bf"},"outputs":[],"source":"Df_cats.shape[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed1a7c4f-8b95-e3b3-cfd2-7fc9f19e471a"},"outputs":[],"source":"data = np.ones(Df_cats.shape[0])\nrow = LabelEncoder().fit_transform(Df[\"activity_id\"])\nlen(data)\nrow\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abdad15a-66fb-b673-2abd-bef1f7a628b2"},"outputs":[],"source":"Df[\"activity_category\"].nunique()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4f5cda6-e36e-6d0d-077a-2fcc67a4837b"},"outputs":[],"source":"sparse_matrix = sparse.csr_matrix(\n    (data, (row, Df_cats[\"activity_category\"])), shape=(len(row), Df[\"activity_category\"].nunique()))\nsparse_matrix.shape\nsys.getsizeof(sparse_matrix)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40f2974b-8ed9-de2e-6e9d-25632611fccb"},"outputs":[],"source":"sparse_matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e96b78fe-2f4d-df43-1e93-04f54ea3ee52"},"outputs":[],"source":"###################\n#  Concat Feature\n###################\n\nprint(\"# Concat all features\")\n\nf1 = Df[[\"activity_id\", \"char_1\"]]\nf2 = Df[[\"activity_id\", \"char_2\"]]\nf3 = Df[[\"activity_id\", \"char_3\"]]\nf4 = Df[[\"activity_id\", \"char_4\"]]\nf5 = Df[[\"activity_id\", \"char_5\"]]\nf6 = Df[[\"activity_id\", \"char_6\"]]\nf7 = Df[[\"activity_id\", \"char_7\"]]\nf8 = Df[[\"activity_id\", \"char_8\"]]\nf9 = Df[[\"activity_id\", \"char_9\"]]\nf10 = Df[[\"activity_id\", \"char_10\"]]\nf11 = Df[[\"activity_id\", \"char_11\"]]\nf12 = Df[[\"activity_id\", \"char_12\"]]\nf13 = Df[[\"activity_id\", \"char_13\"]]\nf14 = Df[[\"activity_id\", \"char_14\"]]\nf15 = Df[[\"activity_id\", \"char_15\"]]\nf16 = Df[[\"activity_id\", \"char_16\"]]\nf17 = Df[[\"activity_id\", \"char_17\"]]\nf18 = Df[[\"activity_id\", \"char_18\"]]\nf19 = Df[[\"activity_id\", \"char_19\"]]\nf20 = Df[[\"activity_id\", \"char_20\"]]\nf21 = Df[[\"activity_id\", \"char_21\"]]\nf22 = Df[[\"activity_id\", \"char_22\"]]\nf23 = Df[[\"activity_id\", \"char_23\"]]\nf24 = Df[[\"activity_id\", \"char_24\"]]\nf25 = Df[[\"activity_id\", \"char_25\"]]\nf26 = Df[[\"activity_id\", \"char_26\"]]\nf27 = Df[[\"activity_id\", \"char_27\"]]\nf28 = Df[[\"activity_id\", \"char_28\"]]\nf29 = Df[[\"activity_id\", \"char_29\"]]\nf30 = Df[[\"activity_id\", \"char_30\"]]\nf31 = Df[[\"activity_id\", \"char_31\"]]\nf32 = Df[[\"activity_id\", \"char_32\"]]\nf33 = Df[[\"activity_id\", \"char_33\"]]\nf34 = Df[[\"activity_id\", \"char_34\"]]\nf35 = Df[[\"activity_id\", \"char_35\"]]\nf36 = Df[[\"activity_id\", \"char_36\"]]\nf37 = Df[[\"activity_id\", \"char_37\"]]\nf38 = Df[[\"activity_id\", \"char_38\"]]\nf39 = Df[[\"activity_id\", \"people_id\"]]\nf40 = Df[[\"activity_id\", \"activity_category\"]]\nf41 = Df[[\"activity_id\", \"ppl_char_1\"]]\n#f42 = Df[[\"activity_id\", \"ppl_char_2\"]]\nf42 = Df[[\"activity_id\", \"group_1\"]]\nf43 = Df[[\"activity_id\", \"ppl_char_3\"]]\nf44 = Df[[\"activity_id\", \"ppl_char_4\"]]\nf45 = Df[[\"activity_id\", \"ppl_char_5\"]]\nf46 = Df[[\"activity_id\", \"ppl_char_6\"]]\nf47 = Df[[\"activity_id\", \"ppl_char_7\"]]\nf48 = Df[[\"activity_id\", \"ppl_char_8\"]]\nf49 = Df[[\"activity_id\", \"ppl_char_9\"]]\nf50 = Df[[\"activity_id\", \"ppl_char_10\"]]\nf51 = Df[[\"activity_id\", \"date_increment\"]]\nf52 = Df[[\"activity_id\", \"ppl_date\"]]\nf53 = Df[[\"activity_id\", \"ppl_date_increment\"]]\n\nf1.columns.values[1] = \"feature\"\nf2.columns.values[1] = \"feature\"\nf3.columns.values[1] = \"feature\"\nf4.columns.values[1] = \"feature\"\nf5.columns.values[1] = \"feature\"\nf6.columns.values[1] = \"feature\"\nf7.columns.values[1] = \"feature\"\nf8.columns.values[1] = \"feature\"\nf9.columns.values[1] = \"feature\"\nf10.columns.values[1] = \"feature\"\nf11.columns.values[1] = \"feature\"\nf12.columns.values[1] = \"feature\"\nf13.columns.values[1] = \"feature\"\nf14.columns.values[1] = \"feature\"\nf15.columns.values[1] = \"feature\"\nf16.columns.values[1] = \"feature\"\nf17.columns.values[1] = \"feature\"\nf18.columns.values[1] = \"feature\"\nf19.columns.values[1] = \"feature\"\nf20.columns.values[1] = \"feature\"\nf21.columns.values[1] = \"feature\"\nf22.columns.values[1] = \"feature\"\nf23.columns.values[1] = \"feature\"\nf24.columns.values[1] = \"feature\"\nf25.columns.values[1] = \"feature\"\nf26.columns.values[1] = \"feature\"\nf27.columns.values[1] = \"feature\"\nf28.columns.values[1] = \"feature\"\nf29.columns.values[1] = \"feature\"\nf30.columns.values[1] = \"feature\"\nf31.columns.values[1] = \"feature\"\nf32.columns.values[1] = \"feature\"\nf33.columns.values[1] = \"feature\"\nf34.columns.values[1] = \"feature\"\nf35.columns.values[1] = \"feature\"\nf36.columns.values[1] = \"feature\"\nf37.columns.values[1] = \"feature\"\nf38.columns.values[1] = \"feature\"\nf39.columns.values[1] = \"feature\"\nf40.columns.values[1] = \"feature\"\nf41.columns.values[1] = \"feature\"\nf42.columns.values[1] = \"feature\"\nf43.columns.values[1] = \"feature\"\nf44.columns.values[1] = \"feature\"\nf45.columns.values[1] = \"feature\"\nf46.columns.values[1] = \"feature\"\nf47.columns.values[1] = \"feature\"\nf48.columns.values[1] = \"feature\"\nf49.columns.values[1] = \"feature\"\nf50.columns.values[1] = \"feature\"\nf51.columns.values[1] = \"feature\"\nf52.columns.values[1] = \"feature\"\nf53.columns.values[1] = \"feature\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b2aa1fe-4c94-661f-ea9d-5c40d8bb8d6f"},"outputs":[],"source":"FLS = pd.concat((f1, f2, f3, f4), axis=0, ignore_index=True)\nFLS.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5765ac9e-0202-046f-cf32-cfdb85b83d42"},"outputs":[],"source":"#FLS = pd.concat((f1, f2, f3, f4, f5, f6, f7, f8, f9, f10,\n#                f11, f12, f13, f14, f15, f16, f17, f18, f19, f20,\n#                f21, f22, f23, f24, f25, f26, f27, f28, f29, f30,\n#                f31, f32, f33, f34, f35, f36, f37, f38, f39, f40,\n#                f41, f42, f43, f44, f45, f46, f47, f48, f49, f50,\n#                f51, f52, f53), axis=0, ignore_index=True)\n#FLS.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b72c6ff1-8343-d635-a323-9714dac2cc81"},"outputs":[],"source":"FLS.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ff45bdd-b2dd-5a7d-471b-d04575def87c"},"outputs":[],"source":"feature_cs = FLS[\"feature\"].dropna()\nactivity_ids = Df[\"activity_id\"].unique()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79ca00aa-c6cc-391b-83d6-e47a8b89b213"},"outputs":[],"source":"sparse_matrix = sparse.csr_matrix(\n    (data, (row, col)), shape=(len(activity_ids), len(feature_cs)))\nsparse_matrix.shape\nsys.getsizeof(sparse_matrix)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}