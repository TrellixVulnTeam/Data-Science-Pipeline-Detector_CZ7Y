{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a82ff458-94a2-a319-5bb9-09d2074ec586"},"outputs":[],"source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nprint ('Loading input files..')\nprint ()\npeople = pd.read_csv('../input/people.csv',\n                       dtype={'people_id': np.str,\n                              'activity_id': np.str,\n                              'char_38': np.int32},\n                       parse_dates=['date'])\ntrain = pd.read_csv(r'../input/act_train.csv',\n                        dtype={'people_id': np.str,\n                               'activity_id': np.str,\n                               'outcome': np.int8},\n                        parse_dates=['date'])\ntest = pd.read_csv('../input/act_test.csv',\n                       dtype={'people_id': np.str,\n                              'activity_id': np.str},\n                       parse_dates=['date'])\n\nmissing_values = []\n\nprint ('Train set features')\nprint ('------------------')\nfor col in train:\n    unique = train[col].unique()\n    print (str(col) + ' has ' + str(unique.size) + ' unique values')\n    \n    if (True in pd.isnull(unique)):\n        print (str(col) + ' has ' + str(pd.isnull(train[col]).sum()) + ' missing values')\n    print ()\n    \nprint ()\n\nprint ('Processing the datasets..')\nprint ()\nfor data in [train,test]:\n    for i in range(1,11):\n        data['char_'+str(i)].fillna('type 0', inplace = 'true')\n        data['char_'+str(i)] = data['char_'+str(i)].str.lstrip('type ').astype(np.int32)\n        \n    data['activity_category'] = data['activity_category'].str.lstrip('type ').astype(np.int32)\n    \n    data['year'] = data['date'].dt.year\n    data['month'] = data['date'].dt.month\n    data['day'] = data['date'].dt.day\n    data.drop('date', axis=1, inplace=True)\n    \nfor i in range(1,10):\n    people['char_' + str(i)] = people['char_' + str(i)].str.lstrip('type ').astype(np.int32)\nfor i in range(10, 38):\n    people['char_' + str(i)] = people['char_' + str(i)].astype(np.int32)\n    \npeople['group_1'] = people['group_1'].str.lstrip('group ').astype(np.int32)\npeople['year'] = people['date'].dt.year\npeople['month'] = people['date'].dt.month\npeople['day'] = people['date'].dt.day\npeople.drop('date', axis=1, inplace=True)\n\nprint ('Merging the datasets..')\nprint ()\n\ntrain = pd.merge(train, people, how='left', on='people_id', left_index=True)\ntrain.fillna(-1, inplace=True)\ntest = pd.merge(test, people, how='left', on='people_id', left_index=True)\ntest.fillna(-1, inplace=True)\n\ntrain = train.drop(['people_id'], axis=1)\n\n#Separate label and data\nY = train['outcome']\nX = train.drop(['outcome'], axis=1)\nX = X.iloc[:,1:]\nX = X.drop(['group_1'], axis=1)\nX = X.drop(['char_1_x'], axis=1)\nX = X.drop(['char_3_x'], axis=1)\nX = X.drop(['char_4_x'], axis=1)\nX = X.drop(['char_5_x'], axis=1)\nX = X.drop(['char_9_x'], axis=1)\nX = X.drop(['char_10_x'], axis=1)\nX = X.drop(['day_x'], axis=1)\nX = X.drop(['day_y'], axis=1)\nX = X.drop(['char_31'] , axis=1)\nX = X.drop(['char_29'], axis=1)\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nrfc = LogisticRegression(max_iter=96)\n\n#print(\"cv\")\n#scores = cross_val_score(rfc, X, Y, cv=4)\n#print (\"Mean accuracy of Random Forest: \" + scores.mean())\nrfc = rfc.fit(X, Y)\n#drop the people_id\ntest = test.drop(['people_id'], axis=1)\n# Get the test data features, skipping the first column 'PassengerId'\ntest_x = test.iloc[:, 1:]\ntest_x = test_x.drop(['group_1'], axis=1)\ntest_x = test_x.drop(['char_1_x'], axis=1)\ntest_x = test_x.drop(['char_3_x'], axis=1)\ntest_x = test_x.drop(['char_4_x'], axis=1)\ntest_x = test_x.drop(['char_5_x'], axis=1)\ntest_x = test_x.drop(['char_9_x'], axis=1)\ntest_x = test_x.drop(['char_10_x'], axis=1)\ntest_x = test_x.drop(['day_x'], axis=1)\ntest_x = test_x.drop(['day_y'], axis=1)\ntest_x = test_x.drop(['char_31'] , axis=1)\ntest_x = test_x.drop(['char_29'], axis=1)\n\n\n# Predict the outcome values for the test data\ntest_y = list(map(int, rfc.predict(test_x)))\n#file for submission\ntest['outcome'] = test_y\ntest[['activity_id', 'outcome']] \\\n    .to_csv('results-rfc.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}