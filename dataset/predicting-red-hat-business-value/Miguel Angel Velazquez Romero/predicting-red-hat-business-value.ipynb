{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Content\n\n<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#ingenieria\">Data Engineering</a></li>          \n        <li><a href=\"#architecture\">Proposed architecture</a></li>\n        <li><a href=\"#evaluaion\">Model evaluation</a></li>\n    </ol>\n</div>\n<br>\n<hr> "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import the libraries\n\nimport pandas as pd\nimport numpy as np\nimport io ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dataset \n\npeople = pd.read_csv('../input/predicting-red-hat-business-value/people.csv.zip', sep = ',')\npeople.head()\n\n# We see much categorical data\n# The informacion is anonymized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activity = pd.read_csv('../input/predicting-red-hat-business-value/act_train.csv.zip', sep = ',')\nactivity.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <h1 id=\"ingenieria\">Data Engineering</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the shape\n\nprint(people.shape)\n\n# Show the null percent\n\n100*people.isnull().sum()/people.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We repet with the other dataset \n\nprint(activity.shape)\n100*activity.isnull().sum()/activity.shape[0]\n\n# We gonna delete the columns 90% null and fill ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activity.drop(columns=['char_1','char_2','char_3','char_4','char_5','char_6','char_7','char_8','char_9'],inplace=True)\n\nprint(activity.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activity.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill char_10 with the mode\n\nactivity['char_10'] = activity['char_10'].fillna(activity[\"char_10\"].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We data is clean of null dates\n\n100*activity.isnull().sum()/activity.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename the columns \n\nactivity = activity.rename(columns={\"date\":\"data_activity\",\"char_10\":\"activity_type\"})\nactivity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We gonna use merge to join the dataframes\n\nall_data = activity.merge(people,on=[\"people_id\"], how=\"inner\")\nall_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the target  \n\nall_data[\"outcome\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Show the distribucion in the target \n\n100*all_data[\"outcome\"].value_counts()/all_data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the type of variable \n\ntypes = pd.DataFrame(all_data.dtypes)\nprint(\"Types of variables: \", types.groupby(0).size())\n\n# We have to convert float to int ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = all_data.replace({False: 0, True: 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is ready\n\ntypes = pd.DataFrame(all_data.dtypes)\nprint(\"Types of variables replace: \", types.groupby(0).size()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We gonna apply one second replace, As the identifier people_id it consists of a prefix \"ppl_\" followed by a unique number per user. \n# In this case, it is enough to cut the prefix to transform this variable into a numeric one.\n\nall_data.people_id = all_data.people_id.str.slice(start=4).astype(float).astype(int)\n\ntypes = pd.DataFrame(all_data.dtypes)\nprint(\"Second replace: \",types.groupby(0).size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[[\"activity_id\", \"activity_category\", \"group_1\", \"activity_type\"]].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# And We have to do the same for those variables \n\nall_data.activity_id = all_data.activity_id.str.slice(start=5).astype(float).astype(int)\nall_data.activity_category = all_data.activity_category.str.slice(start=5).astype(float).astype(int)\nall_data.group_1 = all_data.group_1.str.slice(start=6).astype(float).astype(int)\nall_data.activity_type = all_data.activity_type.str.slice(start=5).astype(float).astype(int)\n\ntypes = pd.DataFrame(all_data.dtypes)\nprint(\"Thith\",types.groupby(0).size()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to evaluate the number of different variables\n\ncategorics = types.index[types[0] == 'O'].values \nfor line in categorics:\n    print(\"The variable \"+ line +\"contine: \", str(len(all_data[line].unique()))+\" distinct values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We gonna create stationary variables\n\n# convert the object variable to datetime \nall_data[\"date\"] = pd.to_datetime(all_data[\"date\"])\n\n# Create new variables \nall_data[\"day\"] = all_data[\"date\"].dt.day\nall_data[\"day_of_week\"] = all_data[\"date\"].dt.weekday\nall_data[\"week\"] = all_data[\"date\"].dt.week\nall_data[\"month\"] = all_data[\"date\"].dt.month\nall_data[\"trimester\"] = all_data[\"date\"].dt.quarter\nall_data[\"year\"] = all_data[\"date\"].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Repet the same but with data_activity\n\nall_data[\"data_activity\"] = pd.to_datetime(all_data[\"data_activity\"])\nall_data[\"activity_day\"] = all_data[\"data_activity\"].dt.day\nall_data[\"activity_day_of_week\"] = all_data[\"data_activity\"].dt.weekday\nall_data[\"activity_week\"] = all_data[\"data_activity\"].dt.week\nall_data[\"activity_month\"] = all_data[\"data_activity\"].dt.month\nall_data[\"activity_trimester\"] = all_data[\"data_activity\"].dt.quarter\nall_data[\"activity_year\"] = all_data[\"data_activity\"].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Delete the original date columns\n\ndel(all_data[\"date\"])\ndel(all_data[\"data_activity\"])\n\ntypes = pd.DataFrame(all_data.dtypes)\nprint(\"Types of variables later of 4to remplace\",types.groupby(0).size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to evaluate the number of different variables again \n\ncategorics = types.index[types[0] == 'O'].values \nfor line in categorics:\n    print(\"The variable \"+ line +\"contine: \", str(len(all_data[line].unique()))+\" distinct values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We gonna use one hot encoder for the rest of variables \n\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\n\n# Define dataframe's function and the column to return a dataframe later OHE\ndef crea_OneHotEncoding(df, column):\n  le = LabelEncoder()\n  le_ajustado=le.fit_transform(df[column]).reshape(-1,1)\n  encoder = OneHotEncoder(sparse=False)\n  column = [column+ \"_\"+ str(i) for i in le.classes_]\n  data = encoder.fit_transform(le_ajustado)\n  return(pd.DataFrame(data,columns =column))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_columns = list(set(types.index[types[0] ==\"int64\"].values) - set([\"outcome\"]))\nall_data_finish = all_data[numeric_columns]\nobjetive = all_data[\"outcome\"]\n\ncategories = types.index[types[0] == 'O'].values\nfor column in categories:\n  df = crea_OneHotEncoding(all_data,column)\n  all_data_finish = pd.concat([all_data_finish,df],axis=1)\n  print(\"Column \",column, \" tranform!\")\n\nprint(\"Finish size:\",all_data_finish.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_finish.dtypes.head(40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_data_finish['char_13'] = np.asarray(all_data_finish['char_13']).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = np.asarray(X).astype(np.float32)\n'''\nall_data_finish['char_25'] = np.asarray(all_data_finish['char_25']).astype(np.float32)\nall_data_finish['week'] = np.asarray(all_data_finish['week']).astype(np.float32)\nall_data_finish['activity_month'] = np.asarray(all_data_finish['activity_month']).astype(np.float32)\nall_data_finish['char_37'] = np.asarray(all_data_finish['char_37']).astype(np.float32)\nall_data_finish['activity_category'] = np.asarray(all_data_finish['activity_category']).astype(np.float32)\nall_data_finish['char_31'] = np.asarray(all_data_finish['char_31']).astype(np.float32)\nall_data_finish['char_19'] = np.asarray(all_data_finish['char_19']).astype(np.float32)\nall_data_finish['char_30'] = np.asarray(all_data_finish['char_30']).astype(np.float32)\nall_data_finish['day'] = np.asarray(all_data_finish['day']).astype(np.float32)\nall_data_finish['char_21'] = np.asarray(all_data_finish['char_21']).astype(np.float32)\nall_data_finish['char_10'] = np.asarray(all_data_finish['char_10']).astype(np.float32)\nall_data_finish['activity_week'] = np.asarray(all_data_finish['activity_week']).astype(np.float32)\nall_data_finish['char_12'] = np.asarray(all_data_finish['char_12']).astype(np.float32)\nall_data_finish['trimester'] = np.asarray(all_data_finish['trimester']).astype(np.float32)\n\nall_data_finish['char_24'] = np.asarray(all_data_finish['char_24']).astype(np.float32)\nall_data_finish['char_38'] = np.asarray(all_data_finish['char_38']).astype(np.float32)\nall_data_finish['activity_type'] = np.asarray(all_data_finish['activity_type']).astype(np.float32)\nall_data_finish['activity_id'] = np.asarray(all_data_finish['activity_id']).astype(np.float32)\nall_data_finish['day_of_week'] = np.asarray(all_data_finish['day_of_week']).astype(np.float32)\nall_data_finish['char_22'] = np.asarray(all_data_finish['char_22']).astype(np.float32)\nall_data_finish['char_27'] = np.asarray(all_data_finish['char_27']).astype(np.float32)\nall_data_finish['char_34'] = np.asarray(all_data_finish['char_34']).astype(np.float32)\nall_data_finish['activity_day_of_week'] = np.asarray(all_data_finish['activity_day_of_week']).astype(np.float32)\nall_data_finish['people_id'] = np.asarray(all_data_finish['people_id']).astype(np.float32)\nall_data_finish['char_36'] = np.asarray(all_data_finish['char_36']).astype(np.float32)\nall_data_finish['char_32'] = np.asarray(all_data_finish['char_32']).astype(np.float32)\nall_data_finish['month'] = np.asarray(all_data_finish['month']).astype(np.float32)\nall_data_finish['year'] = np.asarray(all_data_finish['year']).astype(np.float32)\nall_data_finish['char_14'] = np.asarray(all_data_finish['char_14']).astype(np.float32)\nall_data_finish['activity_year'] = np.asarray(all_data_finish['activity_year']).astype(np.float32)\nall_data_finish['activity_day'] = np.asarray(all_data_finish['activity_day']).astype(np.float32)\nall_data_finish['char_17'] = np.asarray(all_data_finish['char_17']).astype(np.float32)\nall_data_finish['char_14'] = np.asarray(all_data_finish['char_14']).astype(np.float32)\nall_data_finish['char_23'] = np.asarray(all_data_finish['char_23']).astype(np.float32)\nall_data_finish['char_16'] = np.asarray(all_data_finish['char_16']).astype(np.float32)\nall_data_finish['char_26'] = np.asarray(all_data_finish['char_26']).astype(np.float32)\nall_data_finish['char_20'] = np.asarray(all_data_finish['char_20']).astype(np.float32)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nall_data_finish['char_29'] = np.asarray(all_data_finish['char_29']).astype(np.float32)\nall_data_finish['char_11'] = np.asarray(all_data_finish['char_11']).astype(np.float32)\nall_data_finish['group_1'] = np.asarray(all_data_finish['group_1']).astype(np.float32) \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_finish.dtypes.head(40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"objetive.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_finish.dtypes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Separte train set and test set  \nx_train, x_test, y_train, y_test = train_test_split(all_data_finish,objetive, test_size=0.2,random_state=2020)\n\n# Create validation set\nx_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.1, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of x_train:\",x_train.shape)\nprint(\"Shape of x_test:\",x_test.shape)\nprint(\"Shape of x_val:\",x_val.shape)\nprint(\"Shape of y_train:\",y_train.shape)\nprint(\"Shape of y_test:\",y_test.shape)\nprint(\"Shape of y_val:\",y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <h1 id=\"architecture\">Proposed Architecture</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We gonna use binary_crossentropy like loss function, sigmoid like wake-up function and the metric for evaluation will be the precision \"accuracy\"\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import plot_model\n\n# Create the neuronal network \nmodel = Sequential()\nmodel.add(Dense(256,input_dim = x_train.shape[1],activation=\"relu\"))\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dense(1,activation = \"sigmoid\")) \nmodel.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n\nprint(model.summary()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='model.png',show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train, validation_data = (x_val,y_val),epochs=5, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Neuronal Network with Two Layers \nmodel = Sequential()\nmodel.add(Dense(512,input_dim = x_train.shape[1],activation=\"relu\"))\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dense(1,activation = \"sigmoid\"))\nmodel.compile(optimizer = \"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\nmodel.fit(x_train,y_train, validation_data = (x_val,y_val),epochs=3, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}