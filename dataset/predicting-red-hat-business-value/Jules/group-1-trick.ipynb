{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3dc058e5-e343-68d2-9919-a4de401aa8d1"},"source":"Hello, this is a notebook  analayze the __group_1__ trick\n\nFirstly, Let's focus on group_1 attribute"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c440a1b4-5326-0da8-8e93-d89448572016"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\ndata_path  = \"../input/\"\n\npeople = pd.read_csv(data_path + \"people.csv\",\n                     index_col=0, usecols=[\"people_id\", \"group_1\"])\ntrain = pd.read_csv(data_path + \"act_train.csv\",\n                    index_col=0, usecols=[\"people_id\", \"outcome\", \"date\"])\ntest = pd.read_csv(data_path + \"act_test.csv\",\n                   index_col=0, usecols=[\"people_id\", \"date\"])\ntrain = train.join(people)\ntrain = train[[\"group_1\", \"date\", \"outcome\"]]\ntrain[\"date\"] = pd.to_datetime(train[\"date\"])\ntrain.sort_values(['group_1', 'date'], inplace=True)\nprint(train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"019c4c27-2a96-9d5f-c6ab-ea134e54b248"},"source":"Then do some counting."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9b20eed-e5e6-20bc-f6b6-d2daa0acddca"},"outputs":[],"source":"c = train.groupby(\"group_1\", sort=False).count()\nprint(c.describe())\nprint(c[c.outcome > 10000])"},{"cell_type":"markdown","metadata":{"_cell_guid":"87c6cccb-ab46-fd02-9c0b-dec792bc2119"},"source":"min is 1, max is 799125! and 75% is only 38. The records of most groups are small."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f00a82b1-7432-f3f6-57da-927d3979ea4a"},"outputs":[],"source":"# the group with max activity reccords\ngroup_17304 = train[train['group_1'] == \"group 17304\"]\nprint(group_17304.count())\ngroup_17304.plot(ylim=(-1,1), x='date',y='outcome')"},{"cell_type":"markdown","metadata":{"_cell_guid":"8464e463-fbb1-c2ac-9c73-6bc63ef333b1"},"source":"799125 zeros...\nCould we safely predict the outcomes of group_17304 to be all zeros in the test set?"},{"cell_type":"markdown","metadata":{"_cell_guid":"f5eb9b8a-24c8-8411-0c25-22a399c959fe"},"source":"Look at another one"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fec77f38-0157-e788-6705-f1ed5f1be566"},"outputs":[],"source":"group_27940 = train[train['group_1'] == \"group 27940\"]\nprint(group_27940.count())\ngroup_27940.plot(ylim=(-2,2), x='date')"},{"cell_type":"markdown","metadata":{"_cell_guid":"93d0b633-2054-1f44-7603-6352a844f0b3"},"source":"The outcomes in group_27940 changed only once in the timeline.\n\nThat is the group_1 trick, it assumes that the outcome of one group changes occasionally, instead of changing every day. Then we could use this assumption to predict.\n\nhttps://www.kaggle.com/ijkilchenko/predicting-red-hat-business-value/python-ver-of-group-1-and-date-trick/code\n\n\nNow we want to quantify 'occasionally'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc2118b1-4105-6955-69cc-23a789a473b8"},"outputs":[],"source":"def counting_changes(outcome):\n    if outcome.shape[0] <= 1:\n        return 0\n    return np.sum(list(map(lambda x,y:x^y, outcome[1:], outcome[:-1])))\n\nc = train.groupby(\"group_1\", sort=False).agg({'outcome': counting_changes})\nprint(c.describe())\nc.outcome.hist()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f0e032fc-0440-dd15-2418-3888953052d6"},"source":"max is 3, mean is only 0.16. \n\nMost outcomes never changes."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef25cb22-9540-6292-099c-28cf97f11c8e"},"outputs":[],"source":"# group with change count 3\ntrain[train['group_1'] == \"group 12187\"].plot(ylim=(-2,2), x='date')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"877034f9-2599-0758-1839-c779b739722c"},"outputs":[],"source":"test = test.join(people)\ntest = test[[\"group_1\", \"date\"]]\ntest[\"date\"] = pd.to_datetime(test[\"date\"])\ntest.sort_values(['group_1', 'date'], inplace=True)\nt = test.groupby(\"group_1\", sort=False).count()\ntest_outcome_change_by_group = t.join(c)\n\ntest_outcome_change_by_group['outcome'].loc[np.isnan(test_outcome_change_by_group.outcome)] = -1.01 # to show the nan\n\ntest_outcome_change_by_group.outcome.hist()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f50d90b8-58c4-18f6-ae07-8a1c30c6983b"},"source":"4000 more rows in test.csv could not be predicted by group_1 trick.\n\nI will use char_38 trick to handle them."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}