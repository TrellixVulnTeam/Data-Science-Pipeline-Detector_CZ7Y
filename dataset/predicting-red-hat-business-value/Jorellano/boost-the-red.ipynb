{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6121640e-0c00-b0e9-e1bf-3bd045867108"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom scipy import sparse as ssp\nimport pylab as plt\nfrom sklearn.preprocessing import LabelEncoder,LabelBinarizer,MinMaxScaler,OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD,NMF,PCA,FactorAnalysis\nfrom sklearn.feature_selection import SelectFromModel,SelectPercentile,f_classif\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import log_loss,roc_auc_score\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.cross_validation import StratifiedKFold,KFold\nfrom keras.preprocessing import sequence\nfrom keras.callbacks import ModelCheckpoint,Callback\nfrom keras import backend as K\nfrom keras.layers import Input, Embedding, LSTM, Dense,Flatten, Dropout, merge,Convolution1D,MaxPooling1D,Lambda,AveragePooling1D,Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD\nfrom keras.layers.advanced_activations import PReLU,LeakyReLU,ELU,SReLU\nfrom keras.models import Model\n\nseed = 1\nnp.random.seed(seed)\ndim = 32\nhidden=64\n\npath = \"../input/\"\n\nclass AucCallback(Callback):  #inherits from Callback\n    \n    def __init__(self, validation_data=(), patience=25,is_regression=True,best_model_name='best_keras.mdl',feval='roc_auc_score',batch_size=1024*8):\n        super(Callback, self).__init__()\n        \n        self.patience = patience\n        self.X_val, self.y_val = validation_data  #tuple of validation X and y\n        self.best = -np.inf\n        self.wait = 0  #counter for patience\n        self.best_model=None\n        self.best_model_name = best_model_name\n        self.is_regression = is_regression\n        self.y_val = self.y_val#.astype(np.int)\n        self.feval = feval\n        self.batch_size = batch_size\n    def on_epoch_end(self, epoch, logs={}):\n        p = self.model.predict(self.X_val,batch_size=self.batch_size, verbose=0)#.ravel()\n        if self.feval=='roc_auc_score':\n            current = roc_auc_score(self.y_val,p)\n\n        if current > self.best:\n            self.best = current\n            self.wait = 0\n            self.model.save_weights(self.best_model_name,overwrite=True)\n            \n\n        else:\n            if self.wait >= self.patience:\n                self.model.stop_training = True\n                print('Epoch %05d: early stopping' % (epoch))\n                \n                \n            self.wait += 1 #incremental the number of times without improvement\n        print('Epoch %d Auc: %f | Best Auc: %f \\n' % (epoch,current,self.best))\n\n\ndef make_batches(size, batch_size):\n    nb_batch = int(np.ceil(size/float(batch_size)))\n    return [(i*batch_size, min(size, (i+1)*batch_size)) for i in range(0, nb_batch)]\n\n\n\ndef main():\n    train = pd.read_csv(path+'act_train.csv')\n    test = pd.read_csv(path+'act_test.csv')\n    people = pd.read_csv(path+'people.csv')\n    columns = people.columns\n    test['outcome'] = np.nan\n    data = pd.concat([train,test])\n    \n    data = pd.merge(data,people,how='left',on='people_id').fillna('missing')\n    train = data[:train.shape[0]]\n    test = data[train.shape[0]:]\n\n\n\n    columns = train.columns.tolist()\n    columns.remove('activity_id')\n    columns.remove('outcome')\n    data = pd.concat([train,test])\n    for c in columns:\n        data[c] = LabelEncoder().fit_transform(data[c].values)\n\n    train = data[:train.shape[0]]\n    test = data[train.shape[0]:]\n    \n    data = pd.concat([train,test])\n    columns = train.columns.tolist()\n    columns.remove('activity_id')\n    columns.remove('outcome')\n    flatten_layers = []\n    inputs = []\n    count=0\n    for c in columns:\n        \n        inputs_c = Input(shape=(1,), dtype='int32')\n\n        num_c = len(np.unique(data[c].values))\n\n        embed_c = Embedding(\n                        num_c,\n                        dim,\n                        dropout=0.2,\n                        input_length=1\n                        )(inputs_c)\n        flatten_c= Flatten()(embed_c)\n\n        inputs.append(inputs_c)\n        flatten_layers.append(flatten_c)\n        count+=1\n\n    flatten = merge(flatten_layers,mode='concat')\n    reshaped_flatten = Reshape((count,dim))(flatten)\n    \n    conv_1 = Convolution1D(nb_filter=16,\n                        filter_length=3,\n                        border_mode='same',\n                        activation='relu',\n                        subsample_length=1)(reshaped_flatten)\n    pool_1 = MaxPooling1D(pool_length=int(count/2))(conv_1)\n    \n    flatten = Flatten()(pool_1)\n    \n    \n    fc1 = Dense(hidden,activation='relu')(flatten)\n    dp1 = Dropout(0.5)(fc1)\n\n    outputs = Dense(1,activation='sigmoid')(dp1)\n\n    model = Model(input=inputs, output=outputs)\n    model.compile(\n                optimizer='adam',\n                loss='binary_crossentropy',\n              )\n\n    del data\n\n    X = train[columns].values\n    X_t = test[columns].values\n    y = train[\"outcome\"].values\n    people_id = train[\"people_id\"].values\n    activity_id = test['activity_id']\n    del train\n    del test\n\n    skf = StratifiedKFold(y, n_folds=4, shuffle=True, random_state=seed)\n    for ind_tr, ind_te in skf:\n        X_train = X[ind_tr]\n        X_test = X[ind_te]\n\n        y_train = y[ind_tr]\n        y_test = y[ind_te]\n        break\n    \n    X_train = [X_train[:,i] for i in range(X.shape[1])]\n    X_test = [X_test[:,i] for i in range(X.shape[1])]\n    \n    del X\n\n    model_name = 'mlp_residual_%s_%s.hdf5'%(dim,hidden)\n    model_checkpoint = ModelCheckpoint(model_name, monitor='val_loss', save_best_only=True)\n    auc_callback = AucCallback(validation_data=(X_test,y_test), patience=5,is_regression=True,best_model_name=path+'best_keras.mdl',feval='roc_auc_score')\n    \n    nb_epoch = 2\n\n    batch_size = 1024*8\n    load_model = False\n    \n    if load_model:\n        print('Load Model')\n        model.load_weights(path+model_name)\n        # model.load_weights(path+'best_keras.mdl')\n\n    model.fit(\n        X_train, \n        y_train,\n        batch_size=batch_size, \n        nb_epoch=nb_epoch, \n        verbose=1, \n        shuffle=True,\n        validation_data=[X_test,y_test],\n        # callbacks = [\n            # model_checkpoint,\n            # auc_callback,\n            # ],\n        )\n    \n    # model.load_weights(model_name)\n    # model.load_weights(path+'best_keras.mdl')\n    \n    y_preds = model.predict(X_test,batch_size=1024*8)\n    # print('auc',roc_auc_score(y_test,y_preds))\n    \n    # print('Make submission')\n    X_t = [X_t[:,i] for i in range(X_t.shape[1])]\n    outcome = model.predict(X_t,batch_size=1024*8)\n    submission = pd.DataFrame()\n    submission['activity_id'] = activity_id\n    submission['outcome'] = outcome\n    submission.to_csv('submission_residual_%s_%s.csv'%(dim,hidden),index=False)\n\nmain()\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"5d01e5c6-78af-a5dc-3941-3cbc63453974"},"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}