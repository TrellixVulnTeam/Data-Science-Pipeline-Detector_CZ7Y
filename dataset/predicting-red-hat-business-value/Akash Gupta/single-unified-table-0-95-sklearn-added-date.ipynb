{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"bd945280-90dc-41c1-8c3e-3c26ed649f0c"},"source":"## Preprocessing/Merging People and Activities\n\nThis script converts features in people and activities into integers, then merges everything into a single table. Makes it easy to drop into classifiers in Sklearn or XGBoost. \n\nConveniently, most of the data can be easily encoded to numeric values with simple string splitting. \n\nScored ~0.944 with Random Forest Classifier in Sklearn out of the box. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d21c882a-e26f-4e59-9c97-70983811df06"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport datetime\n\nact_train = pd.read_csv('../input/act_train.csv')\nact_test = pd.read_csv('../input/act_test.csv')\npeople = pd.read_csv('../input/people.csv')\npeople.sample(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b0e6de6-c2b2-048d-a33a-aa73ff0e8fb8"},"outputs":[],"source":"def process_dates(data,min_date):\n    #min_date=data.min()\n    min_date \n    data=data.apply(lambda x: (datetime.datetime.strptime(x,\"%Y-%m-%d\")\n                                    -datetime.datetime.strptime(min_date,\"%Y-%m-%d\")).days)\n    data\n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9282d2d9-6025-4a53-a609-1e434c4fa634"},"outputs":[],"source":"# Save the test IDs for Kaggle submission\ntest_ids = act_test['activity_id']\n\ndef preprocess_acts(data,min_date, train_set=True):\n    \n    # Getting rid of data feature for now\n    dates=data['date']\n    dates=process_dates(dates,min_date)\n    data = data.drop(['date', 'activity_id'], axis=1)\n    if(train_set):\n        data = data.drop(['outcome'], axis=1)\n    \n    ## Split off _ from people_id\n    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    columns = list(data.columns)\n    \n    # Convert strings to ints\n    for col in columns[1:]:\n        data[col] = data[col].fillna('type 0')\n        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n        data[col] = pd.to_numeric(data[col]).astype(int)\n#    for column in columns[1:]:\n#        dummies = pd.get_dummies(data[column])\n#        data[dummies.columns] = dummies\n    data['dates']=dates\n    return data\n\ndef preprocess_people(data,min_date):\n    dates=data['date']\n    dates=process_dates(dates,min_date)\n    # TODO refactor this duplication\n    data = data.drop(['date'], axis=1)\n    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n    \n    #  Values in the people df is Booleans and Strings    \n    columns = list(data.columns)\n    bools = columns[11:]\n    strings = columns[1:11]\n    \n    for col in bools:\n        data[col] = pd.to_numeric(data[col]).astype(int)        \n    for col in strings:\n        data[col] = data[col].fillna('type 0')\n        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n        data[col] = pd.to_numeric(data[col]).astype(int)\n    #data = data.drop(['group_1'], axis=1)\n#    for column in strings:\n#        dummies = pd.get_dummies(data[column])\n#        data[dummies.columns] = dummies\n    data['dates']=dates\n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2720c35-c9d0-ced4-ecad-90c4ed77a357"},"outputs":[],"source":"#find minimum date\nmin_date=pd.concat([people['date'],act_train['date'],act_test['date']]).min()\nmin_date"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7ff99fd-fc1f-49be-b2a4-03c87d86abb3"},"outputs":[],"source":"# Preprocess each df\nmin_date=pd.concat([people['date'],act_train['date'],act_test['date']]).min()\npeeps = preprocess_people(people,min_date)\nactions_train = preprocess_acts(act_train,min_date,train_set=True)\nactions_test = preprocess_acts(act_test,min_date,train_set=False)\nprint (peeps.columns)\nprint (actions_train.columns)\npeeps.sample(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cafceee7-05a8-71a1-2822-13a58a0ca0ce"},"outputs":[],"source":"actions_train.sample(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9ef4c2c-5883-014f-7db6-ae8f6a794a00"},"outputs":[],"source":"#run k-means to find the nearby groups"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d83dceb-51df-424d-9d17-45604cbef2b7"},"outputs":[],"source":"# Merege into a unified table\n\n# Training \nfeatures = actions_train.merge(peeps, how='left', on='people_id')\nfeatures=features.drop(['people_id'],axis=1)\nlabels = act_train['outcome']\n\n# Testing\ntest = actions_test.merge(peeps, how='left', on='people_id')\ntest=test.drop(['people_id'],axis=1)\n# Check it out...\nfeatures.sample(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1074d721-7cc0-272b-a1eb-21bbfcc1e2f5"},"outputs":[],"source":"columnss=list(features.columns)\ncolumnss\n#features['group_1'].nunique()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20358c0b-f085-4baa-8676-d046e1af2802"},"outputs":[],"source":"## Split Training Data\nfrom sklearn.cross_validation import train_test_split\n\nnum_test = 0.10\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=num_test, random_state=23)\n\n## Out of box random forest\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n#from sklearn.grid_search import GridSearchCV\n#clf=GradientBoostingClassifier()\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b2975bc-c934-4391-850e-da0d8bc54694"},"outputs":[],"source":"## Training Predictions\nproba = clf.predict_proba(X_test)\npreds = proba[:,1]\nscore = roc_auc_score(y_test, preds)\nprint(\"Area under ROC {0}\".format(score))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19991071-92ff-45ea-8be5-c5d12907a1c6"},"outputs":[],"source":"# Test Set Predictions\ntest_proba = clf.predict_proba(test)\ntest_preds = test_proba[:,1]\ntest_res=clf.predict(test)\n\n# Format for submission\noutput = pd.DataFrame({ 'activity_id' : test_ids, 'outcome': test_preds })\noutput1 = pd.DataFrame({ 'activity_id' : test_ids, 'outcome': test_res })\noutput.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29d9c8bc-36cc-ba20-cf80-b3bc8e106c4d"},"outputs":[],"source":"output.to_csv('redhat.csv', index = False)\noutput1.to_csv('redhat_noprpba.csv', index = False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}