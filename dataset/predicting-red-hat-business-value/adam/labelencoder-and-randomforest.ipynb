{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"365f75f0-91e0-f08d-ebd9-d82a8f615151"},"source":"### Kaggle Predicting Red Hat Business Value"},{"cell_type":"markdown","metadata":{"_cell_guid":"75364ee1-3685-dbfe-605f-e8d517435585"},"source":"As this my first kernel, I would very much appreciate some feedback.  While i'm confident that most of my process, particularly the initial clearning and transformation from cateogrical to numeric are correct, i'm more unsure about the steps I took in re: to train, test, split, etc.  \n\nThank you to everyone who contributes with tips and kernels of their own!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8247b89f-1e06-b57b-4900-849e429abd3d"},"outputs":[],"source":"# importing libraries\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, HTML\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d4c624e-c081-b36c-333e-7c95102fb96a"},"outputs":[],"source":"# reading in data\n\npeople = pd.read_csv('../input/people.csv')\nactivity_train = pd.read_csv('../input/act_train.csv')\nactivity_test = pd.read_csv('../input/act_test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c31f5f1b-44d7-d4ac-0b85-8cd775ecc026"},"outputs":[],"source":"# merging the dataframes into train, test\n\ndf = activity_train.merge(people, how='left', on='people_id' )\ndf_test = activity_test.merge(people, how='left', on='people_id' )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19648fdb-3613-10bd-11a0-d5133b640d92"},"outputs":[],"source":"# the shape of the dataframes\n\nprint (df.shape)\nprint (df_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1820388b-32de-699e-61c9-3a43d6cc7774"},"outputs":[],"source":"# filling NaN values first\n\ndf = df.fillna('0', axis=0)\ndf_test = df_test.fillna('0', axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47929a4c-d8c6-a526-be24-9247afa27bc1"},"outputs":[],"source":"# taking a look at the first few rows\n\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0763c2b3-f72d-53db-ec5d-3d6894c276f5"},"outputs":[],"source":"df_test.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"414e25ae-54d6-cd11-caa1-61381ca5664b"},"source":"### preprocessing"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1666455d-a2b0-6ba1-acca-08e0e890bc77"},"outputs":[],"source":"# a multi-column LabelEncoder()\n\n# this solution for applying LabelEncoder() across multiple columns was suggested in the following thread\n# http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n\n# I like this solution but is it the most efficient?  Would another method be more practical, particularly if \n# applied to different type of model \n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns \n\n    def fit(self,X,y=None):\n        return self\n\n    def transform(self,X):\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"079a6421-c271-ab52-0704-e2737390961a"},"outputs":[],"source":"# defining a processor \n\ndef processor(data):\n    data = MultiColumnLabelEncoder(columns = ['people_id','activity_id', 'activity_category', 'date_x', 'char_1_x', 'char_2_x',\n                                        'char_3_x', 'char_4_x', 'char_5_x', 'char_6_x', 'char_7_x', 'char_8_x', 'char_9_x',\n                                        'char_10_x', 'char_1_y', 'group_1', 'char_2_y', 'date_y', 'char_3_y', 'char_4_y',\n                                        'char_5_y', 'char_6_y', 'char_7_y', 'char_8_y', 'char_9_y']).fit_transform(df)\n    \n    bool_map = {True:1, False:0}\n\n    data = data.applymap(lambda x: bool_map.get(x,x))\n    \n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecf4e844-05ec-8807-0a00-1f2777487d91"},"outputs":[],"source":"# applying processor to training data\n\ndf_encoded = processor(df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"218ce148-8b8e-a67e-e196-6e067ba90bb5"},"outputs":[],"source":"df_encoded.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49025faf-bbdb-f416-8f79-f8d1a8c746fc"},"outputs":[],"source":"df_encoded.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7bb9b2b-fb5f-5663-6c8e-a507081f954d"},"outputs":[],"source":"# applying processor to test data\n\ndf_test_encoded = processor(df_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8099ffd3-67ff-6a2a-7225-0a422af39d8d"},"outputs":[],"source":"df_test_encoded.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd84c14e-f2e1-f240-46a1-1d7724f86735"},"outputs":[],"source":"df_test_encoded.dtypes"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0f47b63-aa60-dc45-855b-8b31326b63cf"},"source":"## modeling\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc4fefff-58cb-dc71-1298-6382144eb80f"},"outputs":[],"source":"# defining X and y (features and target label)\n\nX = df_encoded\ny = X.pop('outcome')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3af920d4-6b60-356c-c391-b77fdd1cb1dc"},"outputs":[],"source":"# shape of X and y\n\nprint (X.shape)\nprint (y.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"982b0669-74f9-20b2-7a34-57b42260a42c"},"outputs":[],"source":"'''\n\ntrain, test, split the data.  hold out 25% for test\n\ngenerally if not provided a test set, this would be the way to move forward.\nyet I feel something is off in my process and would love feedback!\n\n'''\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3995c761-6775-9222-4177-03e1d803ce17"},"outputs":[],"source":"# random forest classifier\n\nmodel = RandomForestClassifier(77, n_jobs=-1, random_state=7)\nmodel.fit(X_train, y_train)\nprint (\"model score \", model.score(X_test, y_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82ff7025-2a1f-bbac-0c69-ac3f9565ca85"},"outputs":[],"source":"# predicting test data\n\npred = model.predict(X_test)\npred"},{"cell_type":"markdown","metadata":{"_cell_guid":"d17fb93e-819d-b699-6542-372b013ce5ac"},"source":"### Final thoughts\n\nWhile the X_test a split of our traning data, as achieved through train, test, split, it is not the same as the actual test set provided in the data by kaggle.  For submission, this would be an issue.  For me, this competition is unique in although fairly straightforward, I haven't had to label encode categoricals on a provided test dataset.  Generally these are untouched until model prediction time.\n\nHopefully some other less experienced users such as myself can make some use of my inital sets in this process."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}