{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Here I'll show how you can build multiple models, ensemble but also evaluate each of them, this may help instead of just train random models and then blindly submit the results.\n\n#### This is another iteration of the amazing work of Chris Deotte [checkout here](https://www.kaggle.com/cdeotte/support-vector-machine-0-925)"},{"metadata":{},"cell_type":"markdown","source":"# Dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nprint('Train set shape:', train.shape)\nprint('Test set shape:', test.shape)\nprint('Train set overview:')\ndisplay(train.head())","execution_count":2,"outputs":[{"output_type":"stream","text":"Train set shape: (262144, 258)\nTest set shape: (131073, 257)\nTrain set overview:\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                                 id   ...    target\n0  707b395ecdcbb4dc2eabea00e4d1b179   ...         0\n1  5880c03c6582a7b42248668e56b4bdec   ...         0\n2  4ccbcb3d13e5072ff1d9c61afe2c4f77   ...         1\n3  e350f17a357f12a1941f0837afb7eb8d   ...         0\n4  a8f910ea6075b6376af079055965ff68   ...         0\n\n[5 rows x 258 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>muggy-smalt-axolotl-pembus</th>\n      <th>dorky-peach-sheepdog-ordinal</th>\n      <th>slimy-seashell-cassowary-goose</th>\n      <th>snazzy-harlequin-chicken-distraction</th>\n      <th>frumpy-smalt-mau-ordinal</th>\n      <th>stealthy-beige-pinscher-golden</th>\n      <th>chummy-cream-tarantula-entropy</th>\n      <th>hazy-emerald-cuttlefish-unsorted</th>\n      <th>nerdy-indigo-wolfhound-sorted</th>\n      <th>leaky-amaranth-lizard-sorted</th>\n      <th>ugly-tangerine-chihuahua-important</th>\n      <th>shaggy-silver-indri-fimbus</th>\n      <th>flaky-chocolate-beetle-grandmaster</th>\n      <th>squirrely-harlequin-sheep-sumble</th>\n      <th>freaky-tan-angelfish-noise</th>\n      <th>lousy-plum-penguin-sumble</th>\n      <th>bluesy-rose-wallaby-discard</th>\n      <th>baggy-copper-oriole-dummy</th>\n      <th>stealthy-scarlet-hound-fepid</th>\n      <th>greasy-cinnamon-bonobo-contributor</th>\n      <th>cranky-cardinal-dogfish-ordinal</th>\n      <th>snippy-auburn-vole-learn</th>\n      <th>greasy-sepia-coral-dataset</th>\n      <th>flabby-tangerine-fowl-entropy</th>\n      <th>lousy-smalt-pinscher-dummy</th>\n      <th>bluesy-brass-chihuahua-distraction</th>\n      <th>goopy-eggplant-indri-entropy</th>\n      <th>homey-sepia-bombay-sorted</th>\n      <th>homely-ruby-bulldog-entropy</th>\n      <th>hasty-blue-sheep-contributor</th>\n      <th>blurry-wisteria-oyster-master</th>\n      <th>snoopy-auburn-dogfish-expert</th>\n      <th>stinky-maroon-blue-kernel</th>\n      <th>bumpy-amaranth-armadillo-important</th>\n      <th>slaphappy-peach-oyster-master</th>\n      <th>dorky-tomato-ragdoll-dataset</th>\n      <th>messy-mauve-wolverine-ordinal</th>\n      <th>geeky-pumpkin-moorhen-important</th>\n      <th>crabby-teal-otter-unsorted</th>\n      <th>...</th>\n      <th>beady-mauve-frog-distraction</th>\n      <th>surly-brass-maltese-ordinal</th>\n      <th>beady-asparagus-opossum-expert</th>\n      <th>beady-rust-impala-dummy</th>\n      <th>droopy-amethyst-dachshund-hint</th>\n      <th>homey-crimson-budgerigar-grandmaster</th>\n      <th>droopy-cardinal-impala-important</th>\n      <th>woozy-apricot-moose-hint</th>\n      <th>paltry-sapphire-labradoodle-dummy</th>\n      <th>crappy-carmine-eagle-entropy</th>\n      <th>greasy-magnolia-spider-grandmaster</th>\n      <th>crabby-carmine-flounder-sorted</th>\n      <th>skimpy-copper-fowl-grandmaster</th>\n      <th>hasty-seashell-woodpecker-hint</th>\n      <th>snappy-purple-bobcat-important</th>\n      <th>thirsty-carmine-corgi-ordinal</th>\n      <th>homely-auburn-reindeer-unsorted</th>\n      <th>crappy-beige-tiger-fepid</th>\n      <th>cranky-auburn-swan-novice</th>\n      <th>chewy-bistre-buzzard-expert</th>\n      <th>skinny-cyan-macaque-pembus</th>\n      <th>slimy-periwinkle-otter-expert</th>\n      <th>snazzy-burgundy-clam-novice</th>\n      <th>cozy-ochre-gorilla-gaussian</th>\n      <th>homey-sangria-wolfhound-dummy</th>\n      <th>snazzy-asparagus-hippopotamus-contributor</th>\n      <th>paltry-red-hamster-sorted</th>\n      <th>zippy-dandelion-insect-golden</th>\n      <th>baggy-coral-bandicoot-unsorted</th>\n      <th>goopy-lavender-wolverine-fimbus</th>\n      <th>wheezy-myrtle-mandrill-entropy</th>\n      <th>wiggy-lilac-lemming-sorted</th>\n      <th>gloppy-cerise-snail-contributor</th>\n      <th>woozy-silver-havanese-gaussian</th>\n      <th>jumpy-thistle-discus-sorted</th>\n      <th>muggy-turquoise-donkey-important</th>\n      <th>blurry-buff-hyena-entropy</th>\n      <th>bluesy-chocolate-kudu-fepid</th>\n      <th>gamy-white-monster-expert</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>707b395ecdcbb4dc2eabea00e4d1b179</td>\n      <td>-2.070654</td>\n      <td>1.018160</td>\n      <td>0.228643</td>\n      <td>0.857221</td>\n      <td>0.052271</td>\n      <td>0.230303</td>\n      <td>-6.385090</td>\n      <td>0.439369</td>\n      <td>-0.721946</td>\n      <td>-0.227027</td>\n      <td>0.575964</td>\n      <td>1.541908</td>\n      <td>1.745286</td>\n      <td>-0.624271</td>\n      <td>3.600958</td>\n      <td>1.176489</td>\n      <td>-0.182776</td>\n      <td>-0.228391</td>\n      <td>1.682263</td>\n      <td>-0.833236</td>\n      <td>-4.377688</td>\n      <td>-5.372410</td>\n      <td>-0.477742</td>\n      <td>-0.179005</td>\n      <td>-0.516475</td>\n      <td>0.127391</td>\n      <td>-0.857591</td>\n      <td>-0.461500</td>\n      <td>2.160303</td>\n      <td>-2.118371</td>\n      <td>0.515493</td>\n      <td>-1.201493</td>\n      <td>-0.027377</td>\n      <td>-1.154024</td>\n      <td>0.753204</td>\n      <td>-0.179651</td>\n      <td>-0.807341</td>\n      <td>-1.663626</td>\n      <td>0.893806</td>\n      <td>...</td>\n      <td>-1.829848</td>\n      <td>2.347131</td>\n      <td>0.082462</td>\n      <td>-1.012654</td>\n      <td>0.593752</td>\n      <td>2.904654</td>\n      <td>-0.428974</td>\n      <td>-0.919979</td>\n      <td>2.849575</td>\n      <td>-0.906744</td>\n      <td>0.729459</td>\n      <td>0.386140</td>\n      <td>0.319814</td>\n      <td>-0.407682</td>\n      <td>-0.170667</td>\n      <td>-1.242919</td>\n      <td>-1.719046</td>\n      <td>-0.132395</td>\n      <td>-0.368991</td>\n      <td>-5.112553</td>\n      <td>-2.085988</td>\n      <td>-0.897257</td>\n      <td>1.080671</td>\n      <td>-0.273262</td>\n      <td>0.342824</td>\n      <td>0.640177</td>\n      <td>-0.415298</td>\n      <td>-0.483126</td>\n      <td>-0.080799</td>\n      <td>2.416224</td>\n      <td>0.351895</td>\n      <td>0.618824</td>\n      <td>-1.542423</td>\n      <td>0.598175</td>\n      <td>0.611757</td>\n      <td>0.678772</td>\n      <td>0.247059</td>\n      <td>-0.806677</td>\n      <td>-0.193649</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5880c03c6582a7b42248668e56b4bdec</td>\n      <td>-0.491702</td>\n      <td>0.082645</td>\n      <td>-0.011193</td>\n      <td>1.071266</td>\n      <td>-0.346347</td>\n      <td>-0.082209</td>\n      <td>0.110579</td>\n      <td>-0.382374</td>\n      <td>-0.229620</td>\n      <td>0.783980</td>\n      <td>-1.280579</td>\n      <td>-1.003480</td>\n      <td>-7.753201</td>\n      <td>-1.320547</td>\n      <td>0.919078</td>\n      <td>-1.036068</td>\n      <td>0.030213</td>\n      <td>0.910172</td>\n      <td>-0.905345</td>\n      <td>0.646641</td>\n      <td>-0.465291</td>\n      <td>-0.531735</td>\n      <td>-0.756781</td>\n      <td>0.193724</td>\n      <td>0.224277</td>\n      <td>-0.474412</td>\n      <td>1.885805</td>\n      <td>0.205439</td>\n      <td>-6.481422</td>\n      <td>1.035620</td>\n      <td>-0.453623</td>\n      <td>0.375936</td>\n      <td>-0.320670</td>\n      <td>-0.144646</td>\n      <td>-0.220129</td>\n      <td>0.577826</td>\n      <td>-0.360512</td>\n      <td>-0.600107</td>\n      <td>0.008111</td>\n      <td>...</td>\n      <td>0.982205</td>\n      <td>-1.161978</td>\n      <td>0.532269</td>\n      <td>1.133215</td>\n      <td>0.003503</td>\n      <td>-1.390962</td>\n      <td>0.158572</td>\n      <td>0.143794</td>\n      <td>-0.317185</td>\n      <td>1.017192</td>\n      <td>-0.395342</td>\n      <td>-0.642357</td>\n      <td>-0.627209</td>\n      <td>0.257271</td>\n      <td>-1.461564</td>\n      <td>0.325613</td>\n      <td>1.628369</td>\n      <td>0.640040</td>\n      <td>0.750735</td>\n      <td>1.164573</td>\n      <td>0.900373</td>\n      <td>0.063489</td>\n      <td>0.948158</td>\n      <td>0.273014</td>\n      <td>-1.269147</td>\n      <td>-0.251101</td>\n      <td>-2.271731</td>\n      <td>-0.044167</td>\n      <td>-0.443766</td>\n      <td>-1.144794</td>\n      <td>-0.645115</td>\n      <td>-1.246090</td>\n      <td>2.613357</td>\n      <td>-0.479664</td>\n      <td>1.581289</td>\n      <td>0.931258</td>\n      <td>0.151937</td>\n      <td>-0.766595</td>\n      <td>0.474351</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4ccbcb3d13e5072ff1d9c61afe2c4f77</td>\n      <td>-1.680473</td>\n      <td>0.860529</td>\n      <td>-1.076195</td>\n      <td>0.740124</td>\n      <td>3.678445</td>\n      <td>0.288558</td>\n      <td>0.515875</td>\n      <td>0.920590</td>\n      <td>-1.223277</td>\n      <td>-1.029780</td>\n      <td>-2.203397</td>\n      <td>-7.088717</td>\n      <td>0.438218</td>\n      <td>-0.848173</td>\n      <td>1.542666</td>\n      <td>-2.166858</td>\n      <td>-0.867670</td>\n      <td>-0.980947</td>\n      <td>0.567793</td>\n      <td>1.323430</td>\n      <td>-2.076700</td>\n      <td>-0.291598</td>\n      <td>-1.564816</td>\n      <td>-8.718695</td>\n      <td>0.340144</td>\n      <td>-0.566402</td>\n      <td>0.844324</td>\n      <td>0.816421</td>\n      <td>-1.019114</td>\n      <td>-0.881431</td>\n      <td>-2.285710</td>\n      <td>-0.090958</td>\n      <td>-0.898440</td>\n      <td>-0.584417</td>\n      <td>-0.143660</td>\n      <td>-0.182084</td>\n      <td>0.798516</td>\n      <td>0.010756</td>\n      <td>-0.347155</td>\n      <td>...</td>\n      <td>0.829467</td>\n      <td>0.588236</td>\n      <td>0.427946</td>\n      <td>-0.563037</td>\n      <td>-0.103990</td>\n      <td>-0.817698</td>\n      <td>1.251046</td>\n      <td>-0.977157</td>\n      <td>2.732600</td>\n      <td>1.997984</td>\n      <td>-0.214285</td>\n      <td>-0.389428</td>\n      <td>-1.007633</td>\n      <td>0.336435</td>\n      <td>-0.851292</td>\n      <td>-0.024184</td>\n      <td>0.455908</td>\n      <td>0.458753</td>\n      <td>-0.267230</td>\n      <td>-2.032402</td>\n      <td>0.203082</td>\n      <td>0.654107</td>\n      <td>-3.512338</td>\n      <td>-0.840937</td>\n      <td>0.519407</td>\n      <td>-0.028053</td>\n      <td>-1.621083</td>\n      <td>0.142132</td>\n      <td>1.514664</td>\n      <td>0.828815</td>\n      <td>0.516422</td>\n      <td>0.130521</td>\n      <td>-0.459210</td>\n      <td>2.028205</td>\n      <td>-0.093968</td>\n      <td>-0.218274</td>\n      <td>-0.163136</td>\n      <td>-0.870289</td>\n      <td>0.064038</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e350f17a357f12a1941f0837afb7eb8d</td>\n      <td>0.183774</td>\n      <td>0.919134</td>\n      <td>-0.946958</td>\n      <td>0.918492</td>\n      <td>0.862278</td>\n      <td>1.155287</td>\n      <td>0.911106</td>\n      <td>0.562598</td>\n      <td>-1.349685</td>\n      <td>-1.182729</td>\n      <td>0.003159</td>\n      <td>-0.626847</td>\n      <td>0.368980</td>\n      <td>1.560784</td>\n      <td>0.502851</td>\n      <td>-0.108050</td>\n      <td>0.633208</td>\n      <td>-0.411502</td>\n      <td>-3.201592</td>\n      <td>-0.710612</td>\n      <td>0.786816</td>\n      <td>0.500979</td>\n      <td>-1.040048</td>\n      <td>-1.369170</td>\n      <td>0.987666</td>\n      <td>-0.681838</td>\n      <td>-0.331372</td>\n      <td>2.254289</td>\n      <td>-0.009330</td>\n      <td>2.007067</td>\n      <td>1.203750</td>\n      <td>-2.003928</td>\n      <td>-0.566088</td>\n      <td>0.223452</td>\n      <td>0.434202</td>\n      <td>-1.203766</td>\n      <td>-0.103490</td>\n      <td>0.441111</td>\n      <td>1.818458</td>\n      <td>...</td>\n      <td>-2.231836</td>\n      <td>0.833236</td>\n      <td>-0.454226</td>\n      <td>-1.614694</td>\n      <td>0.159948</td>\n      <td>-0.150059</td>\n      <td>-1.570599</td>\n      <td>0.960839</td>\n      <td>0.102214</td>\n      <td>0.077236</td>\n      <td>0.852834</td>\n      <td>-1.265608</td>\n      <td>-3.219190</td>\n      <td>0.251194</td>\n      <td>0.215861</td>\n      <td>-0.009520</td>\n      <td>1.611203</td>\n      <td>1.679806</td>\n      <td>-0.008419</td>\n      <td>0.658384</td>\n      <td>-0.132437</td>\n      <td>-1.466823</td>\n      <td>-1.577080</td>\n      <td>-0.800346</td>\n      <td>1.960795</td>\n      <td>-4.042900</td>\n      <td>1.722143</td>\n      <td>-0.261888</td>\n      <td>-1.145005</td>\n      <td>-1.864582</td>\n      <td>-1.168967</td>\n      <td>1.385089</td>\n      <td>-0.353028</td>\n      <td>3.316150</td>\n      <td>-0.524087</td>\n      <td>-0.794327</td>\n      <td>3.936365</td>\n      <td>0.682989</td>\n      <td>-2.521211</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a8f910ea6075b6376af079055965ff68</td>\n      <td>-0.203933</td>\n      <td>-0.177252</td>\n      <td>0.368074</td>\n      <td>-0.701320</td>\n      <td>-1.104391</td>\n      <td>0.735760</td>\n      <td>0.894273</td>\n      <td>-1.375826</td>\n      <td>-5.144946</td>\n      <td>-2.048711</td>\n      <td>0.629773</td>\n      <td>-4.252669</td>\n      <td>-0.087420</td>\n      <td>-0.794367</td>\n      <td>-1.063963</td>\n      <td>0.115997</td>\n      <td>0.895180</td>\n      <td>3.184848</td>\n      <td>2.057840</td>\n      <td>-0.950821</td>\n      <td>0.961059</td>\n      <td>-1.837828</td>\n      <td>-0.437156</td>\n      <td>-0.828433</td>\n      <td>0.373747</td>\n      <td>-0.099787</td>\n      <td>-0.976280</td>\n      <td>-0.165921</td>\n      <td>3.297221</td>\n      <td>3.914132</td>\n      <td>-4.971376</td>\n      <td>-0.286520</td>\n      <td>-0.160133</td>\n      <td>-3.301453</td>\n      <td>-1.021032</td>\n      <td>-0.562744</td>\n      <td>0.574065</td>\n      <td>-0.368194</td>\n      <td>-0.507458</td>\n      <td>...</td>\n      <td>0.178099</td>\n      <td>-0.410396</td>\n      <td>-1.184236</td>\n      <td>1.681727</td>\n      <td>0.589606</td>\n      <td>0.064222</td>\n      <td>0.258885</td>\n      <td>0.560241</td>\n      <td>-1.545597</td>\n      <td>0.822283</td>\n      <td>1.518209</td>\n      <td>0.460143</td>\n      <td>0.822488</td>\n      <td>1.362718</td>\n      <td>0.218560</td>\n      <td>-1.038514</td>\n      <td>1.000763</td>\n      <td>-0.975878</td>\n      <td>-0.551268</td>\n      <td>-0.133044</td>\n      <td>-0.393092</td>\n      <td>1.236473</td>\n      <td>1.657100</td>\n      <td>0.833020</td>\n      <td>0.665379</td>\n      <td>-0.900025</td>\n      <td>0.291908</td>\n      <td>0.482727</td>\n      <td>0.552399</td>\n      <td>0.970496</td>\n      <td>-0.279168</td>\n      <td>1.544356</td>\n      <td>2.959727</td>\n      <td>1.641201</td>\n      <td>-0.130818</td>\n      <td>-0.264292</td>\n      <td>-0.748668</td>\n      <td>0.964218</td>\n      <td>0.087079</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Model\n\n## Model parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"N_FOLDS = 5","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You can find evaluation metrics for each model on each fold below on this cell output log. (It's hidden to keep the code clean)"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":false},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic', 'preds']]\ntest['target_knn'] = 0\ntrain['preds_knn'] = 0\ntest['target_mlp'] = 0\ntrain['preds_mlp'] = 0\ntest['target_svc'] = 0\ntrain['preds_svc'] = 0\ntest['target_nusvc'] = 0\ntrain['preds_nusvc'] = 0\ntest['target_qda'] = 0\ntrain['preds_qda'] = 0\n\n# BUILD 512 MODELS\nfor i in range(512):\n    print('wheezy-copper-turtle-magic {}\\n'.format(i))\n    \n    # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    \n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=N_FOLDS, random_state=0)\n    counter = 0\n\n    for train_index, val_index in skf.split(train3, train2['target']):\n        counter += 1\n        print('Fold {}\\n'.format(counter))\n        model_names = ['knn', 'mlp', 'svc', 'nusvc', 'qda']\n        models = [KNeighborsClassifier(n_neighbors=17, p=2.9), \n                  MLPClassifier(random_state=3, activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, )), \n                  SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42), \n                  NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053), \n                  QuadraticDiscriminantAnalysis(0.1)]\n        \n        for i in range(len(model_names)):\n            model = models[i]\n            model_name = model_names[i]\n            model.fit(train3[train_index,:], train2.loc[train_index]['target'])\n\n            train_predictions = model.predict(train3[train_index,:])\n            val_predictions = model.predict(train3[val_index,:])\n\n            train_auc = roc_auc_score(train2.loc[train_index]['target'], train_predictions) * 100\n            val_auc = roc_auc_score(train2.loc[val_index]['target'], val_predictions) * 100\n            train_precision = precision_score(train2.loc[train_index]['target'], train_predictions) * 100\n            val_precision = precision_score(train2.loc[val_index]['target'], val_predictions) * 100\n            train_recall = recall_score(train2.loc[train_index]['target'], train_predictions) * 100\n            val_recall = recall_score(train2.loc[val_index]['target'], val_predictions) * 100\n            print('-----%s - Train----------' % model_name)\n            print('AUC: %.2f Precision: %.2f Recall: %.2f \\n' % (train_auc, train_precision, train_recall))\n            print('-----%s - Validation-----' % model_name)\n            print('AUC: %.2f Precision: %.2f Recall: %.2f \\n' % (val_auc, val_precision, val_recall))\n\n            # Make predictions\n            train[('preds_%s' % model_name)].loc[idx1] += model.predict_proba(train3)[:,1] / N_FOLDS\n            test[('target_%s' % model_name)].loc[idx2] += model.predict_proba(test3)[:,1] / N_FOLDS","execution_count":4,"outputs":[{"output_type":"stream","text":"wheezy-copper-turtle-magic 0\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.51 Precision: 90.26 Recall: 83.81 \n\n-----knn - Validation-----\nAUC: 78.47 Precision: 87.50 Recall: 66.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.44 Precision: 82.35 Recall: 79.25 \n\n-----svc - Train----------\nAUC: 99.29 Precision: 100.00 Recall: 98.57 \n\n-----svc - Validation-----\nAUC: 75.57 Precision: 90.91 Recall: 56.60 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 78.37 Precision: 94.12 Recall: 60.38 \n\n-----qda - Train----------\nAUC: 97.65 Precision: 98.08 Recall: 97.14 \n\n-----qda - Validation-----\nAUC: 88.85 Precision: 90.20 Recall: 86.79 \n\nFold 2\n\n-----knn - Train----------\nAUC: 82.98 Precision: 90.59 Recall: 73.33 \n\n-----knn - Validation-----\nAUC: 85.92 Precision: 91.30 Recall: 79.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.08 Precision: 82.46 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 99.52 Precision: 100.00 Recall: 99.05 \n\n-----svc - Validation-----\nAUC: 77.36 Precision: 100.00 Recall: 54.72 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 73.60 Precision: 96.30 Recall: 49.06 \n\n-----qda - Train----------\nAUC: 97.43 Precision: 96.71 Recall: 98.10 \n\n-----qda - Validation-----\nAUC: 95.32 Precision: 96.15 Recall: 94.34 \n\nFold 3\n\n-----knn - Train----------\nAUC: 84.48 Precision: 87.11 Recall: 80.48 \n\n-----knn - Validation-----\nAUC: 85.95 Precision: 88.00 Recall: 83.02 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.02 Precision: 82.76 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 98.33 Precision: 100.00 Recall: 96.67 \n\n-----svc - Validation-----\nAUC: 84.92 Precision: 97.44 Recall: 71.70 \n\n-----nusvc - Train----------\nAUC: 99.52 Precision: 100.00 Recall: 99.05 \n\n-----nusvc - Validation-----\nAUC: 82.08 Precision: 100.00 Recall: 64.15 \n\n-----qda - Train----------\nAUC: 96.97 Precision: 96.24 Recall: 97.62 \n\n-----qda - Validation-----\nAUC: 98.11 Precision: 100.00 Recall: 96.23 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.53 Precision: 89.71 Recall: 86.73 \n\n-----knn - Validation-----\nAUC: 78.28 Precision: 78.43 Recall: 76.92 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.20 Precision: 78.57 Recall: 84.62 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.76 Precision: 90.91 Recall: 76.92 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.76 Precision: 90.91 Recall: 76.92 \n\n-----qda - Train----------\nAUC: 97.90 Precision: 97.64 Recall: 98.10 \n\n-----qda - Validation-----\nAUC: 88.64 Precision: 90.00 Recall: 86.54 \n\nFold 5\n\n-----knn - Train----------\nAUC: 85.67 Precision: 89.89 Recall: 80.09 \n\n-----knn - Validation-----\nAUC: 82.02 Precision: 83.67 Recall: 78.85 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.83 Precision: 87.50 Recall: 80.77 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.50 Precision: 97.62 Recall: 78.85 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 82.69 Precision: 100.00 Recall: 65.38 \n\n-----qda - Train----------\nAUC: 97.43 Precision: 97.17 Recall: 97.63 \n\n-----qda - Validation-----\nAUC: 92.38 Precision: 95.83 Recall: 88.46 \n\nwheezy-copper-turtle-magic 1\n\nFold 1\n\n-----knn - Train----------\nAUC: 89.65 Precision: 84.62 Recall: 95.41 \n\n-----knn - Validation-----\nAUC: 89.57 Precision: 83.05 Recall: 98.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.40 Precision: 86.79 Recall: 92.00 \n\n-----svc - Train----------\nAUC: 98.47 Precision: 100.00 Recall: 96.94 \n\n-----svc - Validation-----\nAUC: 78.23 Precision: 88.89 Recall: 64.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.34 Precision: 89.29 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 96.61 Precision: 95.05 Recall: 97.96 \n\n-----qda - Validation-----\nAUC: 94.17 Precision: 94.00 Recall: 94.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 92.20 Precision: 90.64 Recall: 93.40 \n\n-----knn - Validation-----\nAUC: 84.60 Precision: 78.95 Recall: 91.84 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.75 Precision: 74.58 Recall: 89.80 \n\n-----svc - Train----------\nAUC: 98.48 Precision: 100.00 Recall: 96.95 \n\n-----svc - Validation-----\nAUC: 72.76 Precision: 86.67 Recall: 53.06 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.15 Precision: 84.09 Recall: 75.51 \n\n-----qda - Train----------\nAUC: 97.36 Precision: 95.59 Recall: 98.98 \n\n-----qda - Validation-----\nAUC: 87.35 Precision: 84.62 Recall: 89.80 \n\nFold 3\n\n-----knn - Train----------\nAUC: 90.18 Precision: 84.51 Recall: 96.95 \n\n-----knn - Validation-----\nAUC: 92.30 Precision: 88.68 Recall: 95.92 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.19 Precision: 81.82 Recall: 73.47 \n\n-----svc - Train----------\nAUC: 96.70 Precision: 100.00 Recall: 93.40 \n\n-----svc - Validation-----\nAUC: 69.54 Precision: 91.30 Recall: 42.86 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.49 \n\n-----nusvc - Validation-----\nAUC: 89.01 Precision: 93.18 Recall: 83.67 \n\n-----qda - Train----------\nAUC: 97.11 Precision: 95.57 Recall: 98.48 \n\n-----qda - Validation-----\nAUC: 91.12 Precision: 91.67 Recall: 89.80 \n\nFold 4\n\n-----knn - Train----------\nAUC: 93.16 Precision: 92.04 Recall: 93.91 \n\n-----knn - Validation-----\nAUC: 88.53 Precision: 82.46 Recall: 95.92 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.48 Precision: 81.82 Recall: 91.84 \n\n-----svc - Train----------\nAUC: 97.72 Precision: 100.00 Recall: 95.43 \n\n-----svc - Validation-----\nAUC: 72.68 Precision: 89.29 Recall: 51.02 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.01 Precision: 93.18 Recall: 83.67 \n\n-----qda - Train----------\nAUC: 96.89 Precision: 94.66 Recall: 98.98 \n\n-----qda - Validation-----\nAUC: 90.10 Precision: 91.49 Recall: 87.76 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.95 Precision: 84.75 Recall: 95.94 \n\n-----knn - Validation-----\nAUC: 87.15 Precision: 86.00 Recall: 87.76 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.95 Precision: 90.70 Recall: 79.59 \n\n-----svc - Train----------\nAUC: 98.22 Precision: 100.00 Recall: 96.45 \n\n-----svc - Validation-----\nAUC: 79.77 Precision: 91.43 Recall: 65.31 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.13 Precision: 90.20 Recall: 93.88 \n\n-----qda - Train----------\nAUC: 97.13 Precision: 95.12 Recall: 98.98 \n\n-----qda - Validation-----\nAUC: 94.05 Precision: 93.88 Recall: 93.88 \n\nwheezy-copper-turtle-magic 2\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.48 Precision: 90.75 Recall: 80.93 \n\n-----knn - Validation-----\nAUC: 83.91 Precision: 86.67 Recall: 79.59 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.99 Precision: 85.71 Recall: 85.71 \n\n-----svc - Train----------\nAUC: 98.20 Precision: 100.00 Recall: 96.39 \n\n-----svc - Validation-----\nAUC: 73.51 Precision: 96.00 Recall: 48.98 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.75 Precision: 97.30 Recall: 73.47 \n\n-----qda - Train----------\nAUC: 97.48 Precision: 96.94 Recall: 97.94 \n\n-----qda - Validation-----\nAUC: 94.98 Precision: 95.83 Recall: 93.88 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.45 Precision: 92.73 Recall: 78.87 \n\n-----knn - Validation-----\nAUC: 86.85 Precision: 92.86 Recall: 79.59 \n\n","name":"stdout"},{"output_type":"stream","text":"-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.97 Precision: 85.42 Recall: 83.67 \n\n-----svc - Train----------\nAUC: 98.97 Precision: 100.00 Recall: 97.94 \n\n-----svc - Validation-----\nAUC: 74.61 Precision: 90.00 Recall: 55.10 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.96 Precision: 95.74 Recall: 91.84 \n\n-----qda - Train----------\nAUC: 98.23 Precision: 97.95 Recall: 98.45 \n\n-----qda - Validation-----\nAUC: 89.06 Precision: 86.54 Recall: 91.84 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.07 Precision: 88.65 Recall: 84.54 \n\n-----knn - Validation-----\nAUC: 77.73 Precision: 80.00 Recall: 73.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 73.76 Precision: 72.55 Recall: 75.51 \n\n-----svc - Train----------\nAUC: 98.97 Precision: 100.00 Recall: 97.94 \n\n-----svc - Validation-----\nAUC: 86.82 Precision: 90.91 Recall: 81.63 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.96 Precision: 87.04 Recall: 95.92 \n\n-----qda - Train----------\nAUC: 98.72 Precision: 99.48 Recall: 97.94 \n\n-----qda - Validation-----\nAUC: 87.90 Precision: 86.27 Recall: 89.80 \n\nFold 4\n\n-----knn - Train----------\nAUC: 83.48 Precision: 89.63 Recall: 75.38 \n\n-----knn - Validation-----\nAUC: 86.50 Precision: 97.30 Recall: 75.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.67 Precision: 93.02 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 98.97 Precision: 100.00 Recall: 97.95 \n\n-----svc - Validation-----\nAUC: 72.92 Precision: 100.00 Recall: 45.83 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.38 Precision: 100.00 Recall: 68.75 \n\n-----qda - Train----------\nAUC: 97.75 Precision: 96.50 Recall: 98.97 \n\n-----qda - Validation-----\nAUC: 92.79 Precision: 95.56 Recall: 89.58 \n\nFold 5\n\n-----knn - Train----------\nAUC: 83.96 Precision: 91.77 Recall: 74.36 \n\n-----knn - Validation-----\nAUC: 77.33 Precision: 84.21 Recall: 66.67 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.79 Precision: 84.31 Recall: 89.58 \n\n-----svc - Train----------\nAUC: 99.23 Precision: 100.00 Recall: 98.46 \n\n-----svc - Validation-----\nAUC: 73.96 Precision: 100.00 Recall: 47.92 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.25 Precision: 100.00 Recall: 62.50 \n\n-----qda - Train----------\nAUC: 96.98 Precision: 96.92 Recall: 96.92 \n\n-----qda - Validation-----\nAUC: 95.96 Precision: 94.00 Recall: 97.92 \n\nwheezy-copper-turtle-magic 3\n\nFold 1\n\n-----knn - Train----------\nAUC: 84.29 Precision: 78.91 Recall: 96.88 \n\n-----knn - Validation-----\nAUC: 77.01 Precision: 70.89 Recall: 98.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.04 Precision: 86.44 Recall: 89.47 \n\n-----svc - Train----------\nAUC: 93.41 Precision: 89.24 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 59.70 Precision: 57.73 Recall: 98.25 \n\n-----nusvc - Train----------\nAUC: 97.56 Precision: 95.73 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 67.39 Precision: 62.92 Recall: 98.25 \n\n-----qda - Train----------\nAUC: 98.60 Precision: 98.66 Recall: 98.66 \n\n-----qda - Validation-----\nAUC: 93.52 Precision: 93.10 Recall: 94.74 \n\nFold 2\n\n-----knn - Train----------\nAUC: 84.30 Precision: 78.99 Recall: 96.89 \n\n-----knn - Validation-----\nAUC: 83.72 Precision: 77.46 Recall: 98.21 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.34 Precision: 86.79 Recall: 82.14 \n\n-----svc - Train----------\nAUC: 96.34 Precision: 93.75 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 62.57 Precision: 59.14 Recall: 98.21 \n\n-----nusvc - Train----------\nAUC: 98.29 Precision: 96.98 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 72.18 Precision: 66.27 Recall: 98.21 \n\n-----qda - Train----------\nAUC: 98.42 Precision: 99.55 Recall: 97.33 \n\n-----qda - Validation-----\nAUC: 93.48 Precision: 92.98 Recall: 94.64 \n\nFold 3\n\n-----knn - Train----------\nAUC: 85.40 Precision: 80.83 Recall: 95.56 \n\n-----knn - Validation-----\nAUC: 80.39 Precision: 73.68 Recall: 100.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.70 Precision: 78.79 Recall: 92.86 \n\n-----svc - Train----------\nAUC: 97.33 Precision: 95.34 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 67.65 Precision: 62.92 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.56 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 74.51 Precision: 68.29 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.63 Precision: 99.10 Recall: 98.22 \n\n-----qda - Validation-----\nAUC: 93.40 Precision: 92.98 Recall: 94.64 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.30 Precision: 79.71 Recall: 97.78 \n\n-----knn - Validation-----\nAUC: 83.60 Precision: 79.10 Recall: 94.64 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.19 Precision: 88.46 Recall: 82.14 \n\n-----svc - Train----------\nAUC: 96.36 Precision: 93.75 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 71.57 Precision: 65.88 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.51 Precision: 99.12 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.40 Precision: 78.57 Recall: 98.21 \n\n-----qda - Train----------\nAUC: 99.07 Precision: 99.11 Recall: 99.11 \n\n-----qda - Validation-----\nAUC: 87.24 Precision: 93.75 Recall: 80.36 \n\nFold 5\n\n-----knn - Train----------\nAUC: 88.01 Precision: 83.52 Recall: 96.89 \n\n-----knn - Validation-----\nAUC: 77.00 Precision: 73.53 Recall: 89.29 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.67 Precision: 87.93 Recall: 91.07 \n\n-----svc - Train----------\nAUC: 96.84 Precision: 94.54 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 62.75 Precision: 59.57 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.27 Precision: 98.68 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 73.62 Precision: 67.90 Recall: 98.21 \n\n-----qda - Train----------\nAUC: 98.63 Precision: 99.10 Recall: 98.22 \n\n-----qda - Validation-----\nAUC: 91.61 Precision: 92.73 Recall: 91.07 \n\nwheezy-copper-turtle-magic 4\n\nFold 1\n\n-----knn - Train----------\nAUC: 90.53 Precision: 90.05 Recall: 91.35 \n\n-----knn - Validation-----\nAUC: 83.63 Precision: 83.33 Recall: 84.91 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.64 Precision: 91.49 Recall: 81.13 \n\n-----svc - Train----------\nAUC: 98.53 Precision: 97.20 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 71.64 Precision: 65.38 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.52 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.44 Precision: 78.12 Recall: 94.34 \n\n-----qda - Train----------\nAUC: 96.85 Precision: 97.10 Recall: 96.63 \n\n-----qda - Validation-----\nAUC: 90.38 Precision: 90.57 Recall: 90.57 \n\nFold 2\n\n-----knn - Train----------\nAUC: 87.40 Precision: 86.85 Recall: 88.52 \n\n-----knn - Validation-----\nAUC: 91.29 Precision: 93.88 Recall: 88.46 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.54 Precision: 87.23 Recall: 78.85 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.05 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.33 Precision: 87.04 Recall: 90.38 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.25 Precision: 94.00 Recall: 90.38 \n\n-----qda - Train----------\nAUC: 97.33 Precision: 97.14 Recall: 97.61 \n\n-----qda - Validation-----\nAUC: 92.27 Precision: 95.83 Recall: 88.46 \n\nFold 3\n\n-----knn - Train----------\nAUC: 90.55 Precision: 90.48 Recall: 90.91 \n\n-----knn - Validation-----\nAUC: 88.33 Precision: 87.04 Recall: 90.38 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.50 Precision: 81.48 Recall: 84.62 \n\n","name":"stdout"},{"output_type":"stream","text":"-----svc - Train----------\nAUC: 99.02 Precision: 98.12 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 74.55 Precision: 67.57 Recall: 96.15 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.52 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.27 Precision: 83.33 Recall: 96.15 \n\n-----qda - Train----------\nAUC: 97.58 Precision: 98.07 Recall: 97.13 \n\n-----qda - Validation-----\nAUC: 89.29 Precision: 87.27 Recall: 92.31 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.59 Precision: 89.90 Recall: 89.47 \n\n-----knn - Validation-----\nAUC: 88.33 Precision: 87.04 Recall: 90.38 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.35 Precision: 80.33 Recall: 94.23 \n\n-----svc - Train----------\nAUC: 99.02 Precision: 98.12 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.35 Precision: 76.12 Recall: 98.08 \n\n-----nusvc - Train----------\nAUC: 99.51 Precision: 99.05 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.21 Precision: 85.00 Recall: 98.08 \n\n-----qda - Train----------\nAUC: 97.83 Precision: 98.54 Recall: 97.13 \n\n-----qda - Validation-----\nAUC: 93.17 Precision: 90.91 Recall: 96.15 \n\nFold 5\n\n-----knn - Train----------\nAUC: 91.07 Precision: 93.43 Recall: 88.52 \n\n-----knn - Validation-----\nAUC: 80.62 Precision: 83.33 Recall: 76.92 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.66 Precision: 80.00 Recall: 76.92 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.05 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.21 Precision: 90.74 Recall: 94.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.16 Precision: 92.59 Recall: 96.15 \n\n-----qda - Train----------\nAUC: 97.82 Precision: 98.08 Recall: 97.61 \n\n-----qda - Validation-----\nAUC: 92.23 Precision: 92.31 Recall: 92.31 \n\nwheezy-copper-turtle-magic 5\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.23 Precision: 92.31 Recall: 81.16 \n\n-----knn - Validation-----\nAUC: 72.35 Precision: 73.47 Recall: 69.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.97 Precision: 77.97 Recall: 88.46 \n\n-----svc - Train----------\nAUC: 98.09 Precision: 96.28 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 73.57 Precision: 65.38 Recall: 98.08 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 82.96 Precision: 76.56 Recall: 94.23 \n\n-----qda - Train----------\nAUC: 97.83 Precision: 98.53 Recall: 97.10 \n\n-----qda - Validation-----\nAUC: 85.72 Precision: 84.91 Recall: 86.54 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.52 Precision: 89.53 Recall: 82.61 \n\n-----knn - Validation-----\nAUC: 86.59 Precision: 93.18 Recall: 78.85 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.95 Precision: 78.95 Recall: 86.54 \n\n-----svc - Train----------\nAUC: 99.52 Precision: 99.04 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.06 Precision: 73.91 Recall: 98.08 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.44 Precision: 90.57 Recall: 92.31 \n\n-----qda - Train----------\nAUC: 97.35 Precision: 98.51 Recall: 96.14 \n\n-----qda - Validation-----\nAUC: 93.32 Precision: 94.12 Recall: 92.31 \n\nFold 3\n\n-----knn - Train----------\nAUC: 83.88 Precision: 89.77 Recall: 76.33 \n\n-----knn - Validation-----\nAUC: 80.77 Precision: 94.44 Recall: 65.38 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.65 Precision: 83.02 Recall: 84.62 \n\n-----svc - Train----------\nAUC: 99.52 Precision: 99.04 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 79.81 Precision: 71.83 Recall: 98.08 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.46 Precision: 84.48 Recall: 94.23 \n\n-----qda - Train----------\nAUC: 97.60 Precision: 98.05 Recall: 97.10 \n\n-----qda - Validation-----\nAUC: 85.58 Precision: 84.91 Recall: 86.54 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.31 Precision: 92.44 Recall: 76.81 \n\n-----knn - Validation-----\nAUC: 81.73 Precision: 92.31 Recall: 69.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.88 Precision: 79.59 Recall: 75.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.31 Precision: 92.31 Recall: 92.31 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 100.00 Recall: 99.52 \n\n-----nusvc - Validation-----\nAUC: 88.46 Precision: 90.00 Recall: 86.54 \n\n-----qda - Train----------\nAUC: 97.59 Precision: 98.52 Recall: 96.62 \n\n-----qda - Validation-----\nAUC: 92.31 Precision: 94.00 Recall: 90.38 \n\nFold 5\n\n-----knn - Train----------\nAUC: 86.33 Precision: 92.18 Recall: 79.33 \n\n-----knn - Validation-----\nAUC: 85.35 Precision: 92.86 Recall: 76.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.54 Precision: 82.00 Recall: 80.39 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.52 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.48 Precision: 82.14 Recall: 90.20 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.29 Precision: 91.67 Recall: 86.27 \n\n-----qda - Train----------\nAUC: 98.32 Precision: 99.02 Recall: 97.60 \n\n-----qda - Validation-----\nAUC: 90.25 Precision: 93.62 Recall: 86.27 \n\nwheezy-copper-turtle-magic 6\n\nFold 1\n\n-----knn - Train----------\nAUC: 89.77 Precision: 87.61 Recall: 93.40 \n\n-----knn - Validation-----\nAUC: 85.55 Precision: 85.19 Recall: 86.79 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.42 Precision: 92.16 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 99.01 Precision: 98.15 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.35 Precision: 77.61 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 95.10 Precision: 91.38 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.30 Precision: 98.12 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 94.30 Precision: 97.96 Recall: 90.57 \n\nFold 2\n\n-----knn - Train----------\nAUC: 92.01 Precision: 91.63 Recall: 92.92 \n\n-----knn - Validation-----\nAUC: 80.80 Precision: 82.35 Recall: 79.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.50 Precision: 85.45 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 99.01 Precision: 98.15 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.43 Precision: 76.12 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.23 Precision: 85.25 Recall: 98.11 \n\n-----qda - Train----------\nAUC: 98.56 Precision: 99.05 Recall: 98.11 \n\n-----qda - Validation-----\nAUC: 92.23 Precision: 89.47 Recall: 96.23 \n\nFold 3\n\n-----knn - Train----------\nAUC: 89.30 Precision: 87.50 Recall: 92.45 \n\n-----knn - Validation-----\nAUC: 86.53 Precision: 86.79 Recall: 86.79 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.38 Precision: 85.96 Recall: 92.45 \n\n-----svc - Train----------\nAUC: 99.01 Precision: 98.15 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.24 Precision: 81.54 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.14 Precision: 88.33 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.31 Precision: 98.58 Recall: 98.11 \n\n-----qda - Validation-----\nAUC: 95.14 Precision: 92.86 Recall: 98.11 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.56 Precision: 85.41 Recall: 93.87 \n\n-----knn - Validation-----\nAUC: 86.23 Precision: 83.05 Recall: 92.45 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.34 Precision: 88.68 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 97.29 Precision: 95.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 72.00 Precision: 65.43 Recall: 100.00 \n\n","name":"stdout"},{"output_type":"stream","text":"-----nusvc - Train----------\nAUC: 99.26 Precision: 98.60 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.00 Precision: 75.71 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.34 Precision: 97.18 Recall: 97.64 \n\n-----qda - Validation-----\nAUC: 96.17 Precision: 98.04 Recall: 94.34 \n\nFold 5\n\n-----knn - Train----------\nAUC: 92.00 Precision: 90.50 Recall: 94.34 \n\n-----knn - Validation-----\nAUC: 85.11 Precision: 79.69 Recall: 96.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.34 Precision: 82.46 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 98.77 Precision: 97.70 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 81.06 Precision: 74.29 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.06 Precision: 76.47 Recall: 98.11 \n\n-----qda - Train----------\nAUC: 98.80 Precision: 99.05 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 94.23 Precision: 96.08 Recall: 92.45 \n\nwheezy-copper-turtle-magic 7\n\nFold 1\n\n-----knn - Train----------\nAUC: 85.90 Precision: 87.24 Recall: 84.24 \n\n-----knn - Validation-----\nAUC: 83.33 Precision: 88.64 Recall: 76.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.41 Precision: 77.78 Recall: 82.35 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 100.00 Recall: 99.01 \n\n-----svc - Validation-----\nAUC: 78.43 Precision: 93.94 Recall: 60.78 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.51 \n\n-----nusvc - Validation-----\nAUC: 86.27 Precision: 95.12 Recall: 76.47 \n\n-----qda - Train----------\nAUC: 97.52 Precision: 97.54 Recall: 97.54 \n\n-----qda - Validation-----\nAUC: 87.25 Precision: 88.00 Recall: 86.27 \n\nFold 2\n\n-----knn - Train----------\nAUC: 85.15 Precision: 85.93 Recall: 84.24 \n\n-----knn - Validation-----\nAUC: 80.39 Precision: 76.27 Recall: 88.24 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.45 Precision: 83.33 Recall: 68.63 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 100.00 Recall: 99.01 \n\n-----svc - Validation-----\nAUC: 85.29 Precision: 92.86 Recall: 76.47 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.51 \n\n-----nusvc - Validation-----\nAUC: 85.29 Precision: 90.91 Recall: 78.43 \n\n-----qda - Train----------\nAUC: 97.53 Precision: 98.98 Recall: 96.06 \n\n-----qda - Validation-----\nAUC: 89.22 Precision: 88.46 Recall: 90.20 \n\nFold 3\n\n-----knn - Train----------\nAUC: 84.94 Precision: 86.22 Recall: 83.25 \n\n-----knn - Validation-----\nAUC: 82.22 Precision: 85.11 Recall: 78.43 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.16 Precision: 81.13 Recall: 84.31 \n\n-----svc - Train----------\nAUC: 99.26 Precision: 100.00 Recall: 98.52 \n\n-----svc - Validation-----\nAUC: 86.27 Precision: 100.00 Recall: 72.55 \n\n-----nusvc - Train----------\nAUC: 99.51 Precision: 100.00 Recall: 99.01 \n\n-----nusvc - Validation-----\nAUC: 87.22 Precision: 95.24 Recall: 78.43 \n\n-----qda - Train----------\nAUC: 97.04 Precision: 96.59 Recall: 97.54 \n\n-----qda - Validation-----\nAUC: 86.10 Precision: 83.64 Recall: 90.20 \n\nFold 4\n\n-----knn - Train----------\nAUC: 83.23 Precision: 89.47 Recall: 75.37 \n\n-----knn - Validation-----\nAUC: 81.27 Precision: 88.10 Recall: 72.55 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.22 Precision: 83.33 Recall: 78.43 \n\n-----svc - Train----------\nAUC: 99.26 Precision: 100.00 Recall: 98.52 \n\n-----svc - Validation-----\nAUC: 78.39 Precision: 93.94 Recall: 60.78 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.29 Precision: 94.74 Recall: 70.59 \n\n-----qda - Train----------\nAUC: 98.02 Precision: 98.03 Recall: 98.03 \n\n-----qda - Validation-----\nAUC: 91.14 Precision: 95.65 Recall: 86.27 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.21 Precision: 90.86 Recall: 82.84 \n\n-----knn - Validation-----\nAUC: 80.00 Precision: 81.25 Recall: 78.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.00 Precision: 78.43 Recall: 80.00 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 100.00 Recall: 99.02 \n\n-----svc - Validation-----\nAUC: 81.00 Precision: 94.29 Recall: 66.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.51 \n\n-----nusvc - Validation-----\nAUC: 86.00 Precision: 90.91 Recall: 80.00 \n\n-----qda - Train----------\nAUC: 97.54 Precision: 98.50 Recall: 96.57 \n\n-----qda - Validation-----\nAUC: 85.00 Precision: 84.31 Recall: 86.00 \n\nwheezy-copper-turtle-magic 8\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.69 Precision: 83.47 Recall: 92.49 \n\n-----knn - Validation-----\nAUC: 85.68 Precision: 85.45 Recall: 87.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.75 Precision: 85.19 Recall: 85.19 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 80.45 Precision: 73.61 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.36 Precision: 87.93 Recall: 94.44 \n\n-----qda - Train----------\nAUC: 98.07 Precision: 97.67 Recall: 98.59 \n\n-----qda - Validation-----\nAUC: 92.48 Precision: 96.00 Recall: 88.89 \n\nFold 2\n\n-----knn - Train----------\nAUC: 85.98 Precision: 83.26 Recall: 91.08 \n\n-----knn - Validation-----\nAUC: 86.60 Precision: 85.71 Recall: 88.89 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.75 Precision: 85.19 Recall: 85.19 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 78.43 Precision: 71.05 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.27 Precision: 79.41 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.61 Precision: 98.10 Recall: 97.18 \n\n-----qda - Validation-----\nAUC: 94.34 Precision: 96.15 Recall: 92.59 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.53 Precision: 87.16 Recall: 88.79 \n\n-----knn - Validation-----\nAUC: 73.97 Precision: 73.21 Recall: 77.36 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.74 Precision: 78.57 Recall: 83.02 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 86.39 Precision: 81.97 Recall: 94.34 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.27 Precision: 86.44 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 98.33 Precision: 98.59 Recall: 98.13 \n\n-----qda - Validation-----\nAUC: 90.46 Precision: 93.88 Recall: 86.79 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.94 Precision: 85.65 Recall: 92.06 \n\n-----knn - Validation-----\nAUC: 88.42 Precision: 87.27 Recall: 90.57 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.95 Precision: 88.37 Recall: 71.70 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 75.53 Precision: 68.42 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.31 Precision: 87.72 Recall: 94.34 \n\n-----qda - Train----------\nAUC: 98.81 Precision: 99.06 Recall: 98.60 \n\n-----qda - Validation-----\nAUC: 90.42 Precision: 92.16 Recall: 88.68 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.13 Precision: 89.22 Recall: 85.05 \n\n-----knn - Validation-----\nAUC: 79.74 Precision: 78.57 Recall: 83.02 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.65 Precision: 77.97 Recall: 86.79 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 81.37 Precision: 73.61 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.16 Precision: 86.89 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.80 Precision: 98.60 Recall: 99.07 \n\n-----qda - Validation-----\nAUC: 93.25 Precision: 92.59 Recall: 94.34 \n\n","name":"stdout"},{"output_type":"stream","text":"wheezy-copper-turtle-magic 9\n\nFold 1\n\n-----knn - Train----------\nAUC: 83.18 Precision: 75.93 Recall: 97.16 \n\n-----knn - Validation-----\nAUC: 74.53 Precision: 68.06 Recall: 92.45 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.19 Precision: 84.78 Recall: 73.58 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 80.19 Precision: 71.62 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.85 Precision: 79.69 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 98.10 Precision: 99.03 Recall: 97.16 \n\n-----qda - Validation-----\nAUC: 94.34 Precision: 94.34 Recall: 94.34 \n\nFold 2\n\n-----knn - Train----------\nAUC: 79.62 Precision: 72.08 Recall: 96.68 \n\n-----knn - Validation-----\nAUC: 71.70 Precision: 64.56 Recall: 96.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.08 Precision: 81.48 Recall: 83.02 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 77.36 Precision: 69.86 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 76.42 Precision: 68.92 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 97.63 Precision: 98.09 Recall: 97.16 \n\n-----qda - Validation-----\nAUC: 91.51 Precision: 94.00 Recall: 88.68 \n\nFold 3\n\n-----knn - Train----------\nAUC: 82.46 Precision: 75.66 Recall: 95.73 \n\n-----knn - Validation-----\nAUC: 80.19 Precision: 72.86 Recall: 96.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.91 Precision: 84.91 Recall: 84.91 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 93.40 Precision: 89.66 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.57 Precision: 86.44 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 97.39 Precision: 99.02 Recall: 95.73 \n\n-----qda - Validation-----\nAUC: 94.34 Precision: 92.73 Recall: 96.23 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.49 Precision: 81.30 Recall: 94.79 \n\n-----knn - Validation-----\nAUC: 79.25 Precision: 73.85 Recall: 90.57 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.02 Precision: 84.31 Recall: 81.13 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 87.74 Precision: 87.04 Recall: 88.68 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.68 Precision: 87.27 Recall: 90.57 \n\n-----qda - Train----------\nAUC: 97.87 Precision: 99.51 Recall: 96.21 \n\n-----qda - Validation-----\nAUC: 85.85 Precision: 88.00 Recall: 83.02 \n\nFold 5\n\n-----knn - Train----------\nAUC: 81.60 Precision: 74.81 Recall: 95.28 \n\n-----knn - Validation-----\nAUC: 82.69 Precision: 75.76 Recall: 96.15 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.65 Precision: 81.82 Recall: 86.54 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.46 Precision: 83.33 Recall: 96.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.46 Precision: 82.26 Recall: 98.08 \n\n-----qda - Train----------\nAUC: 96.93 Precision: 97.61 Recall: 96.23 \n\n-----qda - Validation-----\nAUC: 96.15 Precision: 98.00 Recall: 94.23 \n\nwheezy-copper-turtle-magic 10\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.57 Precision: 93.49 Recall: 80.61 \n\n-----knn - Validation-----\nAUC: 83.10 Precision: 88.37 Recall: 76.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.16 Precision: 84.91 Recall: 90.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 96.04 Precision: 96.00 Recall: 96.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.10 Precision: 90.00 Recall: 90.00 \n\n-----qda - Train----------\nAUC: 99.00 Precision: 98.48 Recall: 99.49 \n\n-----qda - Validation-----\nAUC: 95.06 Precision: 94.12 Recall: 96.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 87.63 Precision: 92.53 Recall: 81.73 \n\n-----knn - Validation-----\nAUC: 84.81 Precision: 92.50 Recall: 75.51 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.89 Precision: 81.82 Recall: 73.47 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.73 Precision: 97.22 Recall: 71.43 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.94 Precision: 97.83 Recall: 91.84 \n\n-----qda - Train----------\nAUC: 98.50 Precision: 97.99 Recall: 98.98 \n\n-----qda - Validation-----\nAUC: 96.98 Precision: 97.92 Recall: 95.92 \n\nFold 3\n\n-----knn - Train----------\nAUC: 89.68 Precision: 92.39 Recall: 86.29 \n\n-----knn - Validation-----\nAUC: 83.78 Precision: 88.37 Recall: 77.55 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.82 Precision: 81.63 Recall: 81.63 \n\n-----svc - Train----------\nAUC: 99.26 Precision: 98.50 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 81.00 Precision: 72.06 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.94 Precision: 86.79 Recall: 93.88 \n\n-----qda - Train----------\nAUC: 98.50 Precision: 97.99 Recall: 98.98 \n\n-----qda - Validation-----\nAUC: 89.88 Precision: 91.49 Recall: 87.76 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.94 Precision: 88.36 Recall: 84.77 \n\n-----knn - Validation-----\nAUC: 85.86 Precision: 85.71 Recall: 85.71 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.92 Precision: 84.91 Recall: 91.84 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.90 Precision: 91.67 Recall: 89.80 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.96 Precision: 94.00 Recall: 95.92 \n\n-----qda - Train----------\nAUC: 97.76 Precision: 96.53 Recall: 98.98 \n\n-----qda - Validation-----\nAUC: 91.90 Precision: 93.62 Recall: 89.80 \n\nFold 5\n\n-----knn - Train----------\nAUC: 91.21 Precision: 92.19 Recall: 89.85 \n\n-----knn - Validation-----\nAUC: 78.76 Precision: 80.43 Recall: 75.51 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.80 Precision: 76.47 Recall: 79.59 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.49 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.92 Precision: 78.95 Recall: 91.84 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.90 Precision: 89.80 Recall: 89.80 \n\n-----qda - Train----------\nAUC: 98.26 Precision: 97.03 Recall: 99.49 \n\n-----qda - Validation-----\nAUC: 90.90 Precision: 91.67 Recall: 89.80 \n\nwheezy-copper-turtle-magic 11\n\nFold 1\n\n-----knn - Train----------\nAUC: 92.28 Precision: 90.16 Recall: 94.05 \n\n-----knn - Validation-----\nAUC: 86.81 Precision: 81.48 Recall: 93.62 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.43 Precision: 80.85 Recall: 80.85 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.62 Precision: 91.11 Recall: 87.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.81 Precision: 88.00 Recall: 93.62 \n\n-----qda - Train----------\nAUC: 98.21 Precision: 97.34 Recall: 98.92 \n\n-----qda - Validation-----\nAUC: 91.74 Precision: 91.49 Recall: 91.49 \n\nFold 2\n\n-----knn - Train----------\nAUC: 90.11 Precision: 89.73 Recall: 89.73 \n\n-----knn - Validation-----\nAUC: 87.55 Precision: 88.89 Recall: 85.11 \n\n","name":"stdout"},{"output_type":"stream","text":"-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.55 Precision: 76.92 Recall: 85.11 \n\n-----svc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.46 \n\n-----svc - Validation-----\nAUC: 80.85 Precision: 100.00 Recall: 61.70 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.62 Precision: 97.62 Recall: 87.23 \n\n-----qda - Train----------\nAUC: 98.48 Precision: 97.35 Recall: 99.46 \n\n-----qda - Validation-----\nAUC: 93.74 Precision: 95.56 Recall: 91.49 \n\nFold 3\n\n-----knn - Train----------\nAUC: 92.95 Precision: 93.92 Recall: 91.40 \n\n-----knn - Validation-----\nAUC: 90.65 Precision: 89.36 Recall: 91.30 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.30 Precision: 77.55 Recall: 82.61 \n\n-----svc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.46 \n\n-----svc - Validation-----\nAUC: 72.91 Precision: 95.65 Recall: 47.83 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.91 Precision: 90.00 Recall: 97.83 \n\n-----qda - Train----------\nAUC: 98.42 Precision: 98.91 Recall: 97.85 \n\n-----qda - Validation-----\nAUC: 91.83 Precision: 88.00 Recall: 95.65 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.34 Precision: 89.62 Recall: 88.17 \n\n-----knn - Validation-----\nAUC: 92.65 Precision: 93.33 Recall: 91.30 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 91.48 Precision: 95.24 Recall: 86.96 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.87 Precision: 94.29 Recall: 71.74 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.74 Precision: 95.56 Recall: 93.48 \n\n-----qda - Train----------\nAUC: 98.17 Precision: 98.38 Recall: 97.85 \n\n-----qda - Validation-----\nAUC: 91.65 Precision: 91.30 Recall: 91.30 \n\nFold 5\n\n-----knn - Train----------\nAUC: 92.29 Precision: 90.21 Recall: 94.09 \n\n-----knn - Validation-----\nAUC: 91.65 Precision: 91.30 Recall: 91.30 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 92.57 Precision: 95.35 Recall: 89.13 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.48 Precision: 90.91 Recall: 86.96 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 95.91 Precision: 93.75 Recall: 97.83 \n\n-----qda - Train----------\nAUC: 97.14 Precision: 97.30 Recall: 96.77 \n\n-----qda - Validation-----\nAUC: 93.65 Precision: 95.45 Recall: 91.30 \n\nwheezy-copper-turtle-magic 12\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.36 Precision: 86.41 Recall: 89.00 \n\n-----knn - Validation-----\nAUC: 85.99 Precision: 86.27 Recall: 86.27 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.99 Precision: 86.27 Recall: 86.27 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.94 Precision: 90.74 Recall: 96.08 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.92 Precision: 87.27 Recall: 94.12 \n\n-----qda - Train----------\nAUC: 97.47 Precision: 97.50 Recall: 97.50 \n\n-----qda - Validation-----\nAUC: 95.06 Precision: 97.92 Recall: 92.16 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.04 Precision: 81.20 Recall: 94.53 \n\n-----knn - Validation-----\nAUC: 83.73 Precision: 78.33 Recall: 94.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.86 Precision: 86.54 Recall: 90.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 91.86 Precision: 87.50 Recall: 98.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.92 Precision: 92.45 Recall: 98.00 \n\n-----qda - Train----------\nAUC: 97.75 Precision: 99.48 Recall: 96.02 \n\n-----qda - Validation-----\nAUC: 97.98 Precision: 98.00 Recall: 98.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.58 Precision: 84.51 Recall: 95.02 \n\n-----knn - Validation-----\nAUC: 81.73 Precision: 77.59 Recall: 90.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.76 Precision: 77.78 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 80.63 Precision: 73.13 Recall: 98.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.88 Precision: 88.89 Recall: 96.00 \n\n-----qda - Train----------\nAUC: 98.51 Precision: 100.00 Recall: 97.01 \n\n-----qda - Validation-----\nAUC: 87.84 Precision: 85.19 Recall: 92.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.50 Precision: 79.27 Recall: 97.01 \n\n-----knn - Validation-----\nAUC: 79.63 Precision: 72.73 Recall: 96.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.69 Precision: 75.00 Recall: 90.00 \n\n-----svc - Train----------\nAUC: 98.21 Precision: 96.63 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 70.45 Precision: 64.00 Recall: 96.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 77.57 Precision: 70.00 Recall: 98.00 \n\n-----qda - Train----------\nAUC: 98.00 Precision: 98.98 Recall: 97.01 \n\n-----qda - Validation-----\nAUC: 93.96 Precision: 95.83 Recall: 92.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.06 Precision: 82.61 Recall: 94.53 \n\n-----knn - Validation-----\nAUC: 83.76 Precision: 79.31 Recall: 92.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.80 Precision: 81.13 Recall: 86.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 79.63 Precision: 72.73 Recall: 96.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.82 Precision: 84.48 Recall: 98.00 \n\n-----qda - Train----------\nAUC: 98.00 Precision: 98.98 Recall: 97.01 \n\n-----qda - Validation-----\nAUC: 92.96 Precision: 95.74 Recall: 90.00 \n\nwheezy-copper-turtle-magic 13\n\nFold 1\n\n-----knn - Train----------\nAUC: 85.16 Precision: 88.30 Recall: 80.32 \n\n-----knn - Validation-----\nAUC: 78.17 Precision: 80.95 Recall: 72.34 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.62 Precision: 87.23 Recall: 87.23 \n\n-----svc - Train----------\nAUC: 97.87 Precision: 100.00 Recall: 95.74 \n\n-----svc - Validation-----\nAUC: 69.21 Precision: 95.00 Recall: 40.43 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.43 Precision: 97.44 Recall: 80.85 \n\n-----qda - Train----------\nAUC: 97.95 Precision: 97.37 Recall: 98.40 \n\n-----qda - Validation-----\nAUC: 94.87 Precision: 93.75 Recall: 95.74 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.49 Precision: 88.64 Recall: 82.98 \n\n-----knn - Validation-----\nAUC: 88.49 Precision: 92.86 Recall: 82.98 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.81 Precision: 81.48 Recall: 93.62 \n\n-----svc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.47 \n\n-----svc - Validation-----\nAUC: 84.04 Precision: 100.00 Recall: 68.09 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.68 Precision: 100.00 Recall: 89.36 \n\n-----qda - Train----------\nAUC: 98.20 Precision: 97.88 Recall: 98.40 \n\n-----qda - Validation-----\nAUC: 95.87 Precision: 95.74 Recall: 95.74 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.52 Precision: 91.86 Recall: 84.04 \n\n-----knn - Validation-----\nAUC: 75.11 Precision: 76.74 Recall: 70.21 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.43 Precision: 90.48 Recall: 80.85 \n\n","name":"stdout"},{"output_type":"stream","text":"-----svc - Train----------\nAUC: 99.20 Precision: 100.00 Recall: 98.40 \n\n-----svc - Validation-----\nAUC: 74.53 Precision: 96.00 Recall: 51.06 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 82.04 Precision: 94.12 Recall: 68.09 \n\n-----qda - Train----------\nAUC: 97.94 Precision: 97.87 Recall: 97.87 \n\n-----qda - Validation-----\nAUC: 95.87 Precision: 95.74 Recall: 95.74 \n\nFold 4\n\n-----knn - Train----------\nAUC: 84.30 Precision: 90.00 Recall: 76.60 \n\n-----knn - Validation-----\nAUC: 83.23 Precision: 89.74 Recall: 74.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.49 Precision: 84.78 Recall: 82.98 \n\n-----svc - Train----------\nAUC: 98.67 Precision: 100.00 Recall: 97.34 \n\n-----svc - Validation-----\nAUC: 71.28 Precision: 100.00 Recall: 42.55 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 79.91 Precision: 93.75 Recall: 63.83 \n\n-----qda - Train----------\nAUC: 98.20 Precision: 97.88 Recall: 98.40 \n\n-----qda - Validation-----\nAUC: 91.74 Precision: 91.49 Recall: 91.49 \n\nFold 5\n\n-----knn - Train----------\nAUC: 88.13 Precision: 87.77 Recall: 87.77 \n\n-----knn - Validation-----\nAUC: 76.04 Precision: 80.00 Recall: 68.09 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.23 Precision: 81.40 Recall: 74.47 \n\n-----svc - Train----------\nAUC: 99.20 Precision: 100.00 Recall: 98.40 \n\n-----svc - Validation-----\nAUC: 75.53 Precision: 100.00 Recall: 51.06 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.98 Precision: 96.88 Recall: 65.96 \n\n-----qda - Train----------\nAUC: 98.22 Precision: 97.38 Recall: 98.94 \n\n-----qda - Validation-----\nAUC: 89.62 Precision: 91.11 Recall: 87.23 \n\nwheezy-copper-turtle-magic 14\n\nFold 1\n\n-----knn - Train----------\nAUC: 92.24 Precision: 91.76 Recall: 91.76 \n\n-----knn - Validation-----\nAUC: 81.94 Precision: 76.92 Recall: 86.96 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.62 Precision: 86.67 Recall: 84.78 \n\n-----svc - Train----------\nAUC: 99.45 Precision: 100.00 Recall: 98.90 \n\n-----svc - Validation-----\nAUC: 76.09 Precision: 100.00 Recall: 52.17 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.56 Precision: 95.24 Recall: 86.96 \n\n-----qda - Train----------\nAUC: 98.69 Precision: 98.90 Recall: 98.35 \n\n-----qda - Validation-----\nAUC: 91.56 Precision: 95.24 Recall: 86.96 \n\nFold 2\n\n-----knn - Train----------\nAUC: 91.46 Precision: 95.18 Recall: 86.81 \n\n-----knn - Validation-----\nAUC: 90.72 Precision: 91.11 Recall: 89.13 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.72 Precision: 91.11 Recall: 89.13 \n\n-----svc - Train----------\nAUC: 98.08 Precision: 100.00 Recall: 96.15 \n\n-----svc - Validation-----\nAUC: 62.08 Precision: 92.31 Recall: 26.09 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.38 Precision: 95.00 Recall: 82.61 \n\n-----qda - Train----------\nAUC: 99.51 Precision: 98.91 Recall: 100.00 \n\n-----qda - Validation-----\nAUC: 93.98 Precision: 91.67 Recall: 95.65 \n\nFold 3\n\n-----knn - Train----------\nAUC: 90.39 Precision: 86.73 Recall: 93.41 \n\n-----knn - Validation-----\nAUC: 89.05 Precision: 84.31 Recall: 93.48 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.79 Precision: 83.33 Recall: 86.96 \n\n-----svc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.45 \n\n-----svc - Validation-----\nAUC: 83.82 Precision: 96.97 Recall: 69.57 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.82 Precision: 95.56 Recall: 93.48 \n\n-----qda - Train----------\nAUC: 99.24 Precision: 98.91 Recall: 99.45 \n\n-----qda - Validation-----\nAUC: 92.89 Precision: 91.49 Recall: 93.48 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.34 Precision: 90.34 Recall: 86.89 \n\n-----knn - Validation-----\nAUC: 89.15 Precision: 94.87 Recall: 82.22 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.36 Precision: 84.44 Recall: 84.44 \n\n-----svc - Train----------\nAUC: 98.36 Precision: 100.00 Recall: 96.72 \n\n-----svc - Validation-----\nAUC: 61.24 Precision: 91.67 Recall: 24.44 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.46 Precision: 96.88 Recall: 68.89 \n\n-----qda - Train----------\nAUC: 98.97 Precision: 98.91 Recall: 98.91 \n\n-----qda - Validation-----\nAUC: 93.59 Precision: 95.35 Recall: 91.11 \n\nFold 5\n\n-----knn - Train----------\nAUC: 93.52 Precision: 93.89 Recall: 92.35 \n\n-----knn - Validation-----\nAUC: 86.21 Precision: 88.10 Recall: 82.22 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.31 Precision: 78.72 Recall: 82.22 \n\n-----svc - Train----------\nAUC: 96.99 Precision: 100.00 Recall: 93.99 \n\n-----svc - Validation-----\nAUC: 58.89 Precision: 100.00 Recall: 17.78 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.91 Precision: 97.22 Recall: 77.78 \n\n-----qda - Train----------\nAUC: 99.76 Precision: 99.46 Recall: 100.00 \n\n-----qda - Validation-----\nAUC: 93.59 Precision: 95.35 Recall: 91.11 \n\nwheezy-copper-turtle-magic 15\n\nFold 1\n\n-----knn - Train----------\nAUC: 90.05 Precision: 90.73 Recall: 89.42 \n\n-----knn - Validation-----\nAUC: 86.61 Precision: 89.80 Recall: 83.02 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.61 Precision: 89.80 Recall: 83.02 \n\n-----svc - Train----------\nAUC: 99.52 Precision: 100.00 Recall: 99.04 \n\n-----svc - Validation-----\nAUC: 89.47 Precision: 92.00 Recall: 86.79 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.36 Precision: 97.92 Recall: 88.68 \n\n-----qda - Train----------\nAUC: 97.33 Precision: 97.13 Recall: 97.60 \n\n-----qda - Validation-----\nAUC: 93.29 Precision: 94.23 Recall: 92.45 \n\nFold 2\n\n-----knn - Train----------\nAUC: 90.32 Precision: 90.82 Recall: 89.95 \n\n-----knn - Validation-----\nAUC: 84.43 Precision: 82.14 Recall: 88.46 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.27 Precision: 88.89 Recall: 92.31 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.52 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.22 Precision: 82.54 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 95.12 Precision: 92.73 Recall: 98.08 \n\n-----qda - Train----------\nAUC: 96.85 Precision: 97.12 Recall: 96.65 \n\n-----qda - Validation-----\nAUC: 95.14 Precision: 94.34 Recall: 96.15 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.81 Precision: 85.90 Recall: 93.30 \n\n-----knn - Validation-----\nAUC: 84.43 Precision: 82.14 Recall: 88.46 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.50 Precision: 84.31 Recall: 82.69 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.05 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 86.27 Precision: 78.79 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.23 Precision: 83.61 Recall: 98.08 \n\n-----qda - Train----------\nAUC: 98.56 Precision: 99.51 Recall: 97.61 \n\n-----qda - Validation-----\nAUC: 90.29 Precision: 90.38 Recall: 90.38 \n\nFold 4\n\n-----knn - Train----------\nAUC: 90.30 Precision: 89.30 Recall: 91.87 \n\n-----knn - Validation-----\nAUC: 85.48 Precision: 89.36 Recall: 80.77 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.52 Precision: 89.13 Recall: 78.85 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.35 Precision: 95.65 Recall: 84.62 \n\n","name":"stdout"},{"output_type":"stream","text":"-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.31 Precision: 100.00 Recall: 84.62 \n\n-----qda - Train----------\nAUC: 98.55 Precision: 98.56 Recall: 98.56 \n\n-----qda - Validation-----\nAUC: 94.19 Precision: 96.00 Recall: 92.31 \n\nFold 5\n\n-----knn - Train----------\nAUC: 91.01 Precision: 89.45 Recall: 93.30 \n\n-----knn - Validation-----\nAUC: 80.47 Precision: 75.00 Recall: 92.31 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.50 Precision: 84.31 Recall: 82.69 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.52 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.39 Precision: 75.76 Recall: 96.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.41 Precision: 81.03 Recall: 90.38 \n\n-----qda - Train----------\nAUC: 98.55 Precision: 99.03 Recall: 98.09 \n\n-----qda - Validation-----\nAUC: 89.29 Precision: 87.27 Recall: 92.31 \n\nwheezy-copper-turtle-magic 16\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.16 Precision: 85.85 Recall: 88.00 \n\n-----knn - Validation-----\nAUC: 87.80 Precision: 82.76 Recall: 94.12 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.66 Precision: 86.96 Recall: 78.43 \n\n-----svc - Train----------\nAUC: 98.00 Precision: 100.00 Recall: 96.00 \n\n-----svc - Validation-----\nAUC: 75.54 Precision: 96.43 Recall: 52.94 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----nusvc - Validation-----\nAUC: 89.38 Precision: 93.48 Recall: 84.31 \n\n-----qda - Train----------\nAUC: 97.56 Precision: 97.98 Recall: 97.00 \n\n-----qda - Validation-----\nAUC: 92.48 Precision: 89.09 Recall: 96.08 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.20 Precision: 80.69 Recall: 93.53 \n\n-----knn - Validation-----\nAUC: 79.96 Precision: 73.02 Recall: 92.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 74.91 Precision: 71.43 Recall: 80.00 \n\n-----svc - Train----------\nAUC: 98.76 Precision: 100.00 Recall: 97.51 \n\n-----svc - Validation-----\nAUC: 83.17 Precision: 92.31 Recall: 72.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.34 Precision: 88.24 Recall: 90.00 \n\n-----qda - Train----------\nAUC: 98.55 Precision: 98.51 Recall: 98.51 \n\n-----qda - Validation-----\nAUC: 91.40 Precision: 87.27 Recall: 96.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.62 Precision: 82.51 Recall: 91.54 \n\n-----knn - Validation-----\nAUC: 78.08 Precision: 70.77 Recall: 92.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.62 Precision: 80.36 Recall: 90.00 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----svc - Validation-----\nAUC: 88.00 Precision: 100.00 Recall: 76.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 95.17 Precision: 94.12 Recall: 96.00 \n\n-----qda - Train----------\nAUC: 96.88 Precision: 96.08 Recall: 97.51 \n\n-----qda - Validation-----\nAUC: 96.06 Precision: 97.92 Recall: 94.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.01 Precision: 85.39 Recall: 93.03 \n\n-----knn - Validation-----\nAUC: 88.51 Precision: 83.93 Recall: 94.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.40 Precision: 86.00 Recall: 86.00 \n\n-----svc - Train----------\nAUC: 98.76 Precision: 100.00 Recall: 97.51 \n\n-----svc - Validation-----\nAUC: 72.00 Precision: 100.00 Recall: 44.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.00 \n\n-----nusvc - Validation-----\nAUC: 84.00 Precision: 100.00 Recall: 68.00 \n\n-----qda - Train----------\nAUC: 97.82 Precision: 98.00 Recall: 97.51 \n\n-----qda - Validation-----\nAUC: 93.17 Precision: 93.88 Recall: 92.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 86.22 Precision: 80.43 Recall: 94.03 \n\n-----knn - Validation-----\nAUC: 79.79 Precision: 75.44 Recall: 86.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.40 Precision: 85.71 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.00 \n\n-----svc - Validation-----\nAUC: 89.06 Precision: 97.56 Recall: 80.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.17 Precision: 93.75 Recall: 90.00 \n\n-----qda - Train----------\nAUC: 98.33 Precision: 97.55 Recall: 99.00 \n\n-----qda - Validation-----\nAUC: 93.17 Precision: 93.88 Recall: 92.00 \n\nwheezy-copper-turtle-magic 17\n\nFold 1\n\n-----knn - Train----------\nAUC: 90.21 Precision: 91.22 Recall: 89.47 \n\n-----knn - Validation-----\nAUC: 82.57 Precision: 84.31 Recall: 81.13 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.34 Precision: 79.66 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 97.24 Precision: 95.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 75.11 Precision: 68.92 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 99.25 Precision: 98.58 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.11 Precision: 78.46 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 97.80 Precision: 98.08 Recall: 97.61 \n\n-----qda - Validation-----\nAUC: 95.17 Precision: 96.15 Recall: 94.34 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.65 Precision: 88.48 Recall: 91.87 \n\n-----knn - Validation-----\nAUC: 95.11 Precision: 94.44 Recall: 96.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.28 Precision: 87.27 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 97.74 Precision: 95.87 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 72.00 Precision: 65.43 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.25 Precision: 98.58 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.00 Precision: 80.30 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.04 Precision: 98.09 Recall: 98.09 \n\n-----qda - Validation-----\nAUC: 92.17 Precision: 90.91 Recall: 94.34 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.57 Precision: 90.95 Recall: 86.19 \n\n-----knn - Validation-----\nAUC: 82.38 Precision: 84.00 Recall: 80.77 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.23 Precision: 82.14 Recall: 88.46 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.12 Precision: 79.03 Recall: 94.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.12 Precision: 85.96 Recall: 94.23 \n\n-----qda - Train----------\nAUC: 98.52 Precision: 98.11 Recall: 99.05 \n\n-----qda - Validation-----\nAUC: 92.19 Precision: 94.00 Recall: 90.38 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.78 Precision: 90.20 Recall: 87.62 \n\n-----knn - Validation-----\nAUC: 87.31 Precision: 89.80 Recall: 84.62 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 93.15 Precision: 94.12 Recall: 92.31 \n\n-----svc - Train----------\nAUC: 96.98 Precision: 94.59 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 72.00 Precision: 65.00 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 99.06 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.04 Precision: 73.91 Recall: 98.08 \n\n-----qda - Train----------\nAUC: 98.04 Precision: 98.10 Recall: 98.10 \n\n-----qda - Validation-----\nAUC: 93.12 Precision: 92.45 Recall: 94.23 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.60 Precision: 92.82 Recall: 86.19 \n\n-----knn - Validation-----\nAUC: 82.34 Precision: 86.96 Recall: 76.92 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.30 Precision: 83.33 Recall: 76.92 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 94.00 Precision: 92.59 Recall: 96.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.03 Precision: 92.45 Recall: 94.23 \n\n-----qda - Train----------\nAUC: 98.54 Precision: 98.57 Recall: 98.57 \n\n-----qda - Validation-----\nAUC: 95.02 Precision: 94.34 Recall: 96.15 \n\n","name":"stdout"},{"output_type":"stream","text":"wheezy-copper-turtle-magic 18\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.82 Precision: 87.39 Recall: 91.51 \n\n-----knn - Validation-----\nAUC: 86.61 Precision: 89.80 Recall: 83.02 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.72 Precision: 89.36 Recall: 79.25 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 77.52 Precision: 70.83 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.31 Precision: 83.61 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 99.03 Precision: 99.06 Recall: 99.06 \n\n-----qda - Validation-----\nAUC: 93.29 Precision: 94.23 Recall: 92.45 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.59 Precision: 89.30 Recall: 90.57 \n\n-----knn - Validation-----\nAUC: 81.59 Precision: 78.33 Recall: 88.68 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.42 Precision: 87.27 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 98.27 Precision: 96.80 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 69.61 Precision: 63.10 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 99.07 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 80.43 Precision: 73.24 Recall: 98.11 \n\n-----qda - Train----------\nAUC: 99.04 Precision: 99.52 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 95.17 Precision: 94.44 Recall: 96.23 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.69 Precision: 88.52 Recall: 87.26 \n\n-----knn - Validation-----\nAUC: 86.42 Precision: 83.05 Recall: 92.45 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.61 Precision: 84.91 Recall: 84.91 \n\n-----svc - Train----------\nAUC: 99.26 Precision: 98.60 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 74.58 Precision: 68.00 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.39 Precision: 78.46 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 98.55 Precision: 98.58 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 89.36 Precision: 87.50 Recall: 92.45 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.86 Precision: 87.39 Recall: 91.51 \n\n-----knn - Validation-----\nAUC: 81.51 Precision: 81.48 Recall: 83.02 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.57 Precision: 81.13 Recall: 81.13 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.11 Precision: 83.61 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.11 Precision: 85.00 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 98.79 Precision: 98.59 Recall: 99.06 \n\n-----qda - Validation-----\nAUC: 96.17 Precision: 98.04 Recall: 94.34 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.40 Precision: 90.00 Recall: 89.15 \n\n-----knn - Validation-----\nAUC: 84.11 Precision: 78.46 Recall: 96.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.45 Precision: 83.33 Recall: 84.91 \n\n-----svc - Train----------\nAUC: 99.01 Precision: 98.15 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 72.00 Precision: 65.43 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.51 Precision: 99.07 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.00 Precision: 76.81 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 99.05 Precision: 99.52 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 97.06 Precision: 96.30 Recall: 98.11 \n\nwheezy-copper-turtle-magic 19\n\nFold 1\n\n-----knn - Train----------\nAUC: 89.76 Precision: 89.67 Recall: 90.09 \n\n-----knn - Validation-----\nAUC: 84.91 Precision: 84.91 Recall: 84.91 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.79 Precision: 85.45 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.68 Precision: 84.75 Recall: 94.34 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.51 Precision: 87.93 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 98.81 Precision: 98.59 Recall: 99.06 \n\n-----qda - Validation-----\nAUC: 90.57 Precision: 90.57 Recall: 90.57 \n\nFold 2\n\n-----knn - Train----------\nAUC: 90.49 Precision: 89.45 Recall: 91.98 \n\n-----knn - Validation-----\nAUC: 88.55 Precision: 87.27 Recall: 90.57 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.51 Precision: 88.89 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 99.04 Precision: 98.15 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 78.86 Precision: 71.23 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 99.52 Precision: 99.07 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.67 Precision: 76.47 Recall: 98.11 \n\n-----qda - Train----------\nAUC: 98.34 Precision: 98.58 Recall: 98.11 \n\n-----qda - Validation-----\nAUC: 88.53 Precision: 85.96 Recall: 92.45 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.85 Precision: 84.85 Recall: 92.45 \n\n-----knn - Validation-----\nAUC: 79.03 Precision: 78.18 Recall: 81.13 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.49 Precision: 92.16 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 98.80 Precision: 97.70 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 77.90 Precision: 70.27 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 99.52 Precision: 99.07 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.73 Precision: 73.61 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.39 Precision: 97.18 Recall: 97.64 \n\n-----qda - Validation-----\nAUC: 92.36 Precision: 90.91 Recall: 94.34 \n\nFold 4\n\n-----knn - Train----------\nAUC: 90.25 Precision: 89.40 Recall: 91.51 \n\n-----knn - Validation-----\nAUC: 80.91 Precision: 78.95 Recall: 84.91 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.63 Precision: 84.21 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 99.52 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.69 Precision: 74.65 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.46 Precision: 81.54 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.87 Precision: 98.56 Recall: 97.17 \n\n-----qda - Validation-----\nAUC: 91.38 Precision: 87.93 Recall: 96.23 \n\nFold 5\n\n-----knn - Train----------\nAUC: 90.01 Precision: 88.64 Recall: 91.98 \n\n-----knn - Validation-----\nAUC: 87.66 Precision: 91.67 Recall: 83.02 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.74 Precision: 88.00 Recall: 83.02 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.53 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.67 Precision: 82.76 Recall: 90.57 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.44 Precision: 87.72 Recall: 94.34 \n\n-----qda - Train----------\nAUC: 97.86 Precision: 97.21 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 92.42 Precision: 95.92 Recall: 88.68 \n\nwheezy-copper-turtle-magic 20\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.96 Precision: 87.69 Recall: 87.24 \n\n-----knn - Validation-----\nAUC: 83.44 Precision: 86.67 Recall: 78.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.52 Precision: 84.78 Recall: 78.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.22 Precision: 92.31 Recall: 72.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.44 Precision: 87.76 Recall: 86.00 \n\n-----qda - Train----------\nAUC: 97.82 Precision: 96.98 Recall: 98.47 \n\n-----qda - Validation-----\nAUC: 88.22 Precision: 93.18 Recall: 82.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 87.60 Precision: 91.53 Recall: 82.23 \n\n-----knn - Validation-----\nAUC: 77.15 Precision: 80.95 Recall: 69.39 \n\n","name":"stdout"},{"output_type":"stream","text":"-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.40 Precision: 80.39 Recall: 83.67 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.49 \n\n-----svc - Validation-----\nAUC: 80.92 Precision: 89.47 Recall: 69.39 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.12 Precision: 89.13 Recall: 83.67 \n\n-----qda - Train----------\nAUC: 98.06 Precision: 97.49 Recall: 98.48 \n\n-----qda - Validation-----\nAUC: 89.39 Precision: 85.19 Recall: 93.88 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.69 Precision: 88.65 Recall: 83.25 \n\n-----knn - Validation-----\nAUC: 77.07 Precision: 82.50 Recall: 67.35 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.01 Precision: 93.18 Recall: 83.67 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.49 \n\n-----svc - Validation-----\nAUC: 82.65 Precision: 100.00 Recall: 65.31 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.91 Precision: 95.12 Recall: 79.59 \n\n-----qda - Train----------\nAUC: 96.58 Precision: 96.45 Recall: 96.45 \n\n-----qda - Validation-----\nAUC: 89.39 Precision: 85.19 Recall: 93.88 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.19 Precision: 88.52 Recall: 82.23 \n\n-----knn - Validation-----\nAUC: 76.84 Precision: 88.24 Recall: 61.22 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.44 Precision: 81.13 Recall: 87.76 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.85 Precision: 94.74 Recall: 73.47 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.01 Precision: 95.65 Recall: 89.80 \n\n-----qda - Train----------\nAUC: 98.28 Precision: 98.47 Recall: 97.97 \n\n-----qda - Validation-----\nAUC: 94.26 Precision: 90.57 Recall: 97.96 \n\nFold 5\n\n-----knn - Train----------\nAUC: 88.45 Precision: 89.47 Recall: 86.29 \n\n-----knn - Validation-----\nAUC: 85.31 Precision: 84.00 Recall: 85.71 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.25 Precision: 82.98 Recall: 79.59 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.87 Precision: 94.87 Recall: 75.51 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.93 Precision: 97.73 Recall: 87.76 \n\n-----qda - Train----------\nAUC: 98.53 Precision: 98.48 Recall: 98.48 \n\n-----qda - Validation-----\nAUC: 90.03 Precision: 93.33 Recall: 85.71 \n\nwheezy-copper-turtle-magic 21\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.94 Precision: 85.71 Recall: 91.67 \n\n-----knn - Validation-----\nAUC: 85.94 Precision: 83.05 Recall: 90.74 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.80 Precision: 90.38 Recall: 87.04 \n\n-----svc - Train----------\nAUC: 99.04 Precision: 98.18 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 86.81 Precision: 80.30 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.75 Precision: 86.21 Recall: 92.59 \n\n-----qda - Train----------\nAUC: 98.12 Precision: 98.60 Recall: 97.69 \n\n-----qda - Validation-----\nAUC: 95.32 Precision: 94.55 Recall: 96.30 \n\nFold 2\n\n-----knn - Train----------\nAUC: 91.48 Precision: 89.47 Recall: 94.44 \n\n-----knn - Validation-----\nAUC: 83.14 Precision: 81.03 Recall: 87.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.40 Precision: 77.59 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 99.04 Precision: 98.18 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 79.30 Precision: 72.86 Recall: 94.44 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.86 Precision: 83.33 Recall: 92.59 \n\n-----qda - Train----------\nAUC: 97.41 Precision: 97.67 Recall: 97.22 \n\n-----qda - Validation-----\nAUC: 90.65 Precision: 90.74 Recall: 90.74 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.54 Precision: 83.26 Recall: 92.13 \n\n-----knn - Validation-----\nAUC: 86.61 Precision: 81.25 Recall: 96.30 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.79 Precision: 87.04 Recall: 87.04 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 87.71 Precision: 87.27 Recall: 88.89 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 95.26 Precision: 94.55 Recall: 96.30 \n\n-----qda - Train----------\nAUC: 97.66 Precision: 98.13 Recall: 97.22 \n\n-----qda - Validation-----\nAUC: 94.30 Precision: 92.86 Recall: 96.30 \n\nFold 4\n\n-----knn - Train----------\nAUC: 91.10 Precision: 92.38 Recall: 89.81 \n\n-----knn - Validation-----\nAUC: 87.86 Precision: 93.62 Recall: 81.48 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.82 Precision: 88.46 Recall: 85.19 \n\n-----svc - Train----------\nAUC: 99.77 Precision: 100.00 Recall: 99.54 \n\n-----svc - Validation-----\nAUC: 87.89 Precision: 95.56 Recall: 79.63 \n\n-----nusvc - Train----------\nAUC: 99.77 Precision: 100.00 Recall: 99.54 \n\n-----nusvc - Validation-----\nAUC: 92.52 Precision: 96.00 Recall: 88.89 \n\n-----qda - Train----------\nAUC: 97.89 Precision: 98.14 Recall: 97.69 \n\n-----qda - Validation-----\nAUC: 95.30 Precision: 96.23 Recall: 94.44 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.85 Precision: 87.45 Recall: 93.52 \n\n-----knn - Validation-----\nAUC: 86.75 Precision: 85.71 Recall: 88.89 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.08 Precision: 86.00 Recall: 79.63 \n\n-----svc - Train----------\nAUC: 99.52 Precision: 99.08 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 86.72 Precision: 84.48 Recall: 90.74 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.60 Precision: 92.31 Recall: 88.89 \n\n-----qda - Train----------\nAUC: 97.88 Precision: 97.70 Recall: 98.15 \n\n-----qda - Validation-----\nAUC: 91.56 Precision: 94.12 Recall: 88.89 \n\nwheezy-copper-turtle-magic 22\n\nFold 1\n\n-----knn - Train----------\nAUC: 91.01 Precision: 88.28 Recall: 95.48 \n\n-----knn - Validation-----\nAUC: 85.78 Precision: 81.54 Recall: 94.64 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.87 Precision: 89.29 Recall: 89.29 \n\n-----svc - Train----------\nAUC: 99.04 Precision: 98.22 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.65 Precision: 76.71 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.41 Precision: 87.30 Recall: 98.21 \n\n-----qda - Train----------\nAUC: 98.61 Precision: 99.09 Recall: 98.19 \n\n-----qda - Validation-----\nAUC: 94.30 Precision: 91.67 Recall: 98.21 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.06 Precision: 84.86 Recall: 96.38 \n\n-----knn - Validation-----\nAUC: 80.98 Precision: 75.71 Recall: 94.64 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 91.62 Precision: 91.23 Recall: 92.86 \n\n-----svc - Train----------\nAUC: 98.32 Precision: 96.93 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 76.92 Precision: 70.00 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.28 Precision: 98.66 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 78.85 Precision: 71.79 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.37 Precision: 98.64 Recall: 98.19 \n\n-----qda - Validation-----\nAUC: 94.44 Precision: 94.64 Recall: 94.64 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.55 Precision: 83.72 Recall: 97.30 \n\n-----knn - Validation-----\nAUC: 91.40 Precision: 87.10 Recall: 98.18 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.21 Precision: 93.48 Recall: 78.18 \n\n","name":"stdout"},{"output_type":"stream","text":"-----svc - Train----------\nAUC: 98.56 Precision: 97.37 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 76.98 Precision: 70.13 Recall: 98.18 \n\n-----nusvc - Train----------\nAUC: 99.52 Precision: 99.11 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.48 Precision: 84.38 Recall: 98.18 \n\n-----qda - Train----------\nAUC: 98.38 Precision: 98.64 Recall: 98.20 \n\n-----qda - Validation-----\nAUC: 95.35 Precision: 96.30 Recall: 94.55 \n\nFold 4\n\n-----knn - Train----------\nAUC: 91.02 Precision: 88.33 Recall: 95.50 \n\n-----knn - Validation-----\nAUC: 82.10 Precision: 80.00 Recall: 87.27 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.06 Precision: 81.36 Recall: 87.27 \n\n-----svc - Train----------\nAUC: 98.80 Precision: 97.80 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 72.12 Precision: 65.48 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 80.87 Precision: 74.65 Recall: 96.36 \n\n-----qda - Train----------\nAUC: 98.36 Precision: 98.21 Recall: 98.65 \n\n-----qda - Validation-----\nAUC: 93.48 Precision: 94.44 Recall: 92.73 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.20 Precision: 87.61 Recall: 92.34 \n\n-----knn - Validation-----\nAUC: 90.65 Precision: 90.91 Recall: 90.91 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.69 Precision: 89.29 Recall: 90.91 \n\n-----svc - Train----------\nAUC: 98.56 Precision: 97.37 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.74 Precision: 76.06 Recall: 98.18 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.55 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.49 Precision: 86.89 Recall: 96.36 \n\n-----qda - Train----------\nAUC: 99.08 Precision: 99.55 Recall: 98.65 \n\n-----qda - Validation-----\nAUC: 94.34 Precision: 92.98 Recall: 96.36 \n\nwheezy-copper-turtle-magic 23\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.79 Precision: 87.56 Recall: 86.32 \n\n-----knn - Validation-----\nAUC: 87.75 Precision: 88.68 Recall: 87.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.86 Precision: 86.79 Recall: 85.19 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 93.48 Precision: 97.96 Recall: 88.89 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.56 Precision: 97.92 Recall: 87.04 \n\n-----qda - Train----------\nAUC: 98.09 Precision: 99.04 Recall: 97.17 \n\n-----qda - Validation-----\nAUC: 94.34 Precision: 94.44 Recall: 94.44 \n\nFold 2\n\n-----knn - Train----------\nAUC: 88.16 Precision: 94.05 Recall: 81.69 \n\n-----knn - Validation-----\nAUC: 78.04 Precision: 84.09 Recall: 69.81 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.63 Precision: 83.33 Recall: 84.91 \n\n-----svc - Train----------\nAUC: 99.77 Precision: 100.00 Recall: 99.53 \n\n-----svc - Validation-----\nAUC: 81.13 Precision: 100.00 Recall: 62.26 \n\n-----nusvc - Train----------\nAUC: 99.77 Precision: 100.00 Recall: 99.53 \n\n-----nusvc - Validation-----\nAUC: 87.70 Precision: 97.62 Recall: 77.36 \n\n-----qda - Train----------\nAUC: 98.83 Precision: 100.00 Recall: 97.65 \n\n-----qda - Validation-----\nAUC: 88.38 Precision: 85.96 Recall: 92.45 \n\nFold 3\n\n-----knn - Train----------\nAUC: 89.30 Precision: 92.42 Recall: 85.92 \n\n-----knn - Validation-----\nAUC: 79.93 Precision: 84.78 Recall: 73.58 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 76.95 Precision: 78.43 Recall: 75.47 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.38 Precision: 85.96 Recall: 92.45 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.49 Precision: 90.20 Recall: 86.79 \n\n-----qda - Train----------\nAUC: 98.82 Precision: 99.52 Recall: 98.12 \n\n-----qda - Validation-----\nAUC: 92.30 Precision: 92.45 Recall: 92.45 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.92 Precision: 93.55 Recall: 81.69 \n\n-----knn - Validation-----\nAUC: 80.91 Precision: 86.67 Recall: 73.58 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.44 Precision: 85.71 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 81.06 Precision: 94.59 Recall: 66.04 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.70 Precision: 97.62 Recall: 77.36 \n\n-----qda - Train----------\nAUC: 98.34 Precision: 99.05 Recall: 97.65 \n\n-----qda - Validation-----\nAUC: 88.49 Precision: 90.20 Recall: 86.79 \n\nFold 5\n\n-----knn - Train----------\nAUC: 88.33 Precision: 91.00 Recall: 85.45 \n\n-----knn - Validation-----\nAUC: 82.80 Precision: 87.23 Recall: 77.36 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 75.18 Precision: 81.40 Recall: 66.04 \n\n-----svc - Train----------\nAUC: 99.77 Precision: 100.00 Recall: 99.53 \n\n-----svc - Validation-----\nAUC: 90.53 Precision: 97.78 Recall: 83.02 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.74 Precision: 93.18 Recall: 77.36 \n\n-----qda - Train----------\nAUC: 98.34 Precision: 99.05 Recall: 97.65 \n\n-----qda - Validation-----\nAUC: 96.15 Precision: 96.23 Recall: 96.23 \n\nwheezy-copper-turtle-magic 24\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.88 Precision: 84.06 Recall: 93.55 \n\n-----knn - Validation-----\nAUC: 88.20 Precision: 84.31 Recall: 91.49 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.01 Precision: 85.42 Recall: 87.23 \n\n-----svc - Train----------\nAUC: 95.16 Precision: 100.00 Recall: 90.32 \n\n-----svc - Validation-----\nAUC: 56.50 Precision: 87.50 Recall: 14.89 \n\n-----nusvc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.46 \n\n-----nusvc - Validation-----\nAUC: 79.91 Precision: 96.67 Recall: 61.70 \n\n-----qda - Train----------\nAUC: 98.48 Precision: 98.39 Recall: 98.39 \n\n-----qda - Validation-----\nAUC: 96.93 Precision: 97.83 Recall: 95.74 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.00 Precision: 89.50 Recall: 87.10 \n\n-----knn - Validation-----\nAUC: 83.60 Precision: 75.86 Recall: 93.62 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.08 Precision: 87.76 Recall: 91.49 \n\n-----svc - Train----------\nAUC: 96.24 Precision: 100.00 Recall: 92.47 \n\n-----svc - Validation-----\nAUC: 56.50 Precision: 87.50 Recall: 14.89 \n\n-----nusvc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.46 \n\n-----nusvc - Validation-----\nAUC: 74.59 Precision: 96.00 Recall: 51.06 \n\n-----qda - Train----------\nAUC: 98.27 Precision: 97.35 Recall: 98.92 \n\n-----qda - Validation-----\nAUC: 89.14 Precision: 86.00 Recall: 91.49 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.40 Precision: 93.67 Recall: 79.57 \n\n-----knn - Validation-----\nAUC: 81.26 Precision: 89.19 Recall: 70.21 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.85 Precision: 87.23 Recall: 87.23 \n\n-----svc - Train----------\nAUC: 94.62 Precision: 100.00 Recall: 89.25 \n\n-----svc - Validation-----\nAUC: 54.26 Precision: 100.00 Recall: 8.51 \n\n-----nusvc - Train----------\nAUC: 99.19 Precision: 100.00 Recall: 98.39 \n\n-----nusvc - Validation-----\nAUC: 66.06 Precision: 94.12 Recall: 34.04 \n\n-----qda - Train----------\nAUC: 98.75 Precision: 98.40 Recall: 98.92 \n\n-----qda - Validation-----\nAUC: 86.78 Precision: 86.96 Recall: 85.11 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.11 Precision: 91.72 Recall: 82.89 \n\n-----knn - Validation-----\nAUC: 84.20 Precision: 89.74 Recall: 76.09 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.80 Precision: 74.51 Recall: 82.61 \n\n-----svc - Train----------\nAUC: 96.26 Precision: 100.00 Recall: 92.51 \n\n-----svc - Validation-----\nAUC: 56.52 Precision: 100.00 Recall: 13.04 \n\n","name":"stdout"},{"output_type":"stream","text":"-----nusvc - Train----------\nAUC: 99.47 Precision: 100.00 Recall: 98.93 \n\n-----nusvc - Validation-----\nAUC: 68.48 Precision: 100.00 Recall: 36.96 \n\n-----qda - Train----------\nAUC: 98.48 Precision: 98.40 Recall: 98.40 \n\n-----qda - Validation-----\nAUC: 95.65 Precision: 100.00 Recall: 91.30 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.98 Precision: 92.05 Recall: 86.63 \n\n-----knn - Validation-----\nAUC: 82.02 Precision: 89.19 Recall: 71.74 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.51 Precision: 92.86 Recall: 84.78 \n\n-----svc - Train----------\nAUC: 93.85 Precision: 100.00 Recall: 87.70 \n\n-----svc - Validation-----\nAUC: 57.73 Precision: 88.89 Recall: 17.39 \n\n-----nusvc - Train----------\nAUC: 98.93 Precision: 100.00 Recall: 97.86 \n\n-----nusvc - Validation-----\nAUC: 66.43 Precision: 94.12 Recall: 34.78 \n\n-----qda - Train----------\nAUC: 99.05 Precision: 97.91 Recall: 100.00 \n\n-----qda - Validation-----\nAUC: 90.47 Precision: 95.12 Recall: 84.78 \n\nwheezy-copper-turtle-magic 25\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.70 Precision: 93.87 Recall: 82.26 \n\n-----knn - Validation-----\nAUC: 79.34 Precision: 84.62 Recall: 70.21 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.68 Precision: 78.26 Recall: 76.60 \n\n-----svc - Train----------\nAUC: 98.39 Precision: 100.00 Recall: 96.77 \n\n-----svc - Validation-----\nAUC: 67.12 Precision: 94.44 Recall: 36.17 \n\n-----nusvc - Train----------\nAUC: 99.46 Precision: 100.00 Recall: 98.92 \n\n-----nusvc - Validation-----\nAUC: 80.95 Precision: 96.77 Recall: 63.83 \n\n-----qda - Train----------\nAUC: 98.47 Precision: 98.39 Recall: 98.39 \n\n-----qda - Validation-----\nAUC: 89.87 Precision: 89.36 Recall: 89.36 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.78 Precision: 94.01 Recall: 84.41 \n\n-----knn - Validation-----\nAUC: 81.46 Precision: 85.37 Recall: 74.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.62 Precision: 77.78 Recall: 74.47 \n\n-----svc - Train----------\nAUC: 98.66 Precision: 100.00 Recall: 97.31 \n\n-----svc - Validation-----\nAUC: 76.60 Precision: 100.00 Recall: 53.19 \n\n-----nusvc - Train----------\nAUC: 99.46 Precision: 100.00 Recall: 98.92 \n\n-----nusvc - Validation-----\nAUC: 88.30 Precision: 100.00 Recall: 76.60 \n\n-----qda - Train----------\nAUC: 97.69 Precision: 97.84 Recall: 97.31 \n\n-----qda - Validation-----\nAUC: 94.99 Precision: 93.75 Recall: 95.74 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.33 Precision: 87.57 Recall: 83.33 \n\n-----knn - Validation-----\nAUC: 87.75 Precision: 88.89 Recall: 85.11 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.09 Precision: 82.69 Recall: 91.49 \n\n-----svc - Train----------\nAUC: 97.58 Precision: 100.00 Recall: 95.16 \n\n-----svc - Validation-----\nAUC: 67.12 Precision: 94.44 Recall: 36.17 \n\n-----nusvc - Train----------\nAUC: 99.46 Precision: 100.00 Recall: 98.92 \n\n-----nusvc - Validation-----\nAUC: 80.95 Precision: 96.77 Recall: 63.83 \n\n-----qda - Train----------\nAUC: 97.93 Precision: 98.37 Recall: 97.31 \n\n-----qda - Validation-----\nAUC: 89.67 Precision: 93.02 Recall: 85.11 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.25 Precision: 87.03 Recall: 86.10 \n\n-----knn - Validation-----\nAUC: 87.70 Precision: 85.42 Recall: 89.13 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.34 Precision: 86.05 Recall: 80.43 \n\n-----svc - Train----------\nAUC: 98.93 Precision: 100.00 Recall: 97.86 \n\n-----svc - Validation-----\nAUC: 76.19 Precision: 96.15 Recall: 54.35 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.32 Precision: 97.44 Recall: 82.61 \n\n-----qda - Train----------\nAUC: 97.67 Precision: 98.37 Recall: 96.79 \n\n-----qda - Validation-----\nAUC: 95.87 Precision: 95.65 Recall: 95.65 \n\nFold 5\n\n-----knn - Train----------\nAUC: 85.87 Precision: 92.36 Recall: 77.54 \n\n-----knn - Validation-----\nAUC: 86.19 Precision: 92.31 Recall: 78.26 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.50 Precision: 79.17 Recall: 82.61 \n\n-----svc - Train----------\nAUC: 98.40 Precision: 100.00 Recall: 96.79 \n\n-----svc - Validation-----\nAUC: 65.22 Precision: 100.00 Recall: 30.43 \n\n-----nusvc - Train----------\nAUC: 99.47 Precision: 100.00 Recall: 98.93 \n\n-----nusvc - Validation-----\nAUC: 80.43 Precision: 100.00 Recall: 60.87 \n\n-----qda - Train----------\nAUC: 97.89 Precision: 99.45 Recall: 96.26 \n\n-----qda - Validation-----\nAUC: 91.62 Precision: 93.18 Recall: 89.13 \n\nwheezy-copper-turtle-magic 26\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.56 Precision: 88.20 Recall: 83.51 \n\n-----knn - Validation-----\nAUC: 78.68 Precision: 80.00 Recall: 75.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.84 Precision: 78.00 Recall: 81.25 \n\n-----svc - Train----------\nAUC: 97.34 Precision: 100.00 Recall: 94.68 \n\n-----svc - Validation-----\nAUC: 56.31 Precision: 87.50 Recall: 14.58 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 65.69 Precision: 94.12 Recall: 33.33 \n\n-----qda - Train----------\nAUC: 98.21 Precision: 97.88 Recall: 98.40 \n\n-----qda - Validation-----\nAUC: 87.81 Precision: 89.13 Recall: 85.42 \n\nFold 2\n\n-----knn - Train----------\nAUC: 85.94 Precision: 84.90 Recall: 86.24 \n\n-----knn - Validation-----\nAUC: 79.47 Precision: 80.00 Recall: 76.60 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.18 Precision: 89.19 Recall: 70.21 \n\n-----svc - Train----------\nAUC: 97.35 Precision: 100.00 Recall: 94.71 \n\n-----svc - Validation-----\nAUC: 63.83 Precision: 100.00 Recall: 27.66 \n\n-----nusvc - Train----------\nAUC: 99.74 Precision: 100.00 Recall: 99.47 \n\n-----nusvc - Validation-----\nAUC: 69.23 Precision: 95.00 Recall: 40.43 \n\n-----qda - Train----------\nAUC: 98.46 Precision: 98.41 Recall: 98.41 \n\n-----qda - Validation-----\nAUC: 89.86 Precision: 87.76 Recall: 91.49 \n\nFold 3\n\n-----knn - Train----------\nAUC: 83.28 Precision: 84.44 Recall: 80.42 \n\n-----knn - Validation-----\nAUC: 80.62 Precision: 79.17 Recall: 80.85 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.88 Precision: 80.77 Recall: 89.36 \n\n-----svc - Train----------\nAUC: 96.83 Precision: 100.00 Recall: 93.65 \n\n-----svc - Validation-----\nAUC: 67.10 Precision: 94.44 Recall: 36.17 \n\n-----nusvc - Train----------\nAUC: 99.74 Precision: 100.00 Recall: 99.47 \n\n-----nusvc - Validation-----\nAUC: 84.13 Precision: 97.06 Recall: 70.21 \n\n-----qda - Train----------\nAUC: 97.69 Precision: 97.87 Recall: 97.35 \n\n-----qda - Validation-----\nAUC: 91.91 Precision: 89.80 Recall: 93.62 \n\nFold 4\n\n-----knn - Train----------\nAUC: 83.64 Precision: 89.38 Recall: 75.66 \n\n-----knn - Validation-----\nAUC: 84.30 Precision: 90.00 Recall: 76.60 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.55 Precision: 83.33 Recall: 85.11 \n\n-----svc - Train----------\nAUC: 94.97 Precision: 100.00 Recall: 89.95 \n\n-----svc - Validation-----\nAUC: 56.38 Precision: 100.00 Recall: 12.77 \n\n-----nusvc - Train----------\nAUC: 99.47 Precision: 100.00 Recall: 98.94 \n\n-----nusvc - Validation-----\nAUC: 63.83 Precision: 100.00 Recall: 27.66 \n\n-----qda - Train----------\nAUC: 97.43 Precision: 97.86 Recall: 96.83 \n\n-----qda - Validation-----\nAUC: 95.94 Precision: 93.88 Recall: 97.87 \n\nFold 5\n\n-----knn - Train----------\nAUC: 85.40 Precision: 85.87 Recall: 83.60 \n\n-----knn - Validation-----\nAUC: 88.68 Precision: 87.50 Recall: 89.36 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.74 Precision: 86.00 Recall: 91.49 \n\n-----svc - Train----------\nAUC: 97.35 Precision: 100.00 Recall: 94.71 \n\n-----svc - Validation-----\nAUC: 61.70 Precision: 100.00 Recall: 23.40 \n\n-----nusvc - Train----------\nAUC: 99.74 Precision: 100.00 Recall: 99.47 \n\n-----nusvc - Validation-----\nAUC: 82.98 Precision: 100.00 Recall: 65.96 \n\n-----qda - Train----------\nAUC: 97.45 Precision: 97.35 Recall: 97.35 \n\n-----qda - Validation-----\nAUC: 94.81 Precision: 95.65 Recall: 93.62 \n\n","name":"stdout"},{"output_type":"stream","text":"wheezy-copper-turtle-magic 27\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.68 Precision: 87.43 Recall: 84.21 \n\n-----knn - Validation-----\nAUC: 85.76 Precision: 92.50 Recall: 77.08 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 74.31 Precision: 73.91 Recall: 70.83 \n\n-----svc - Train----------\nAUC: 98.16 Precision: 100.00 Recall: 96.32 \n\n-----svc - Validation-----\nAUC: 66.67 Precision: 100.00 Recall: 33.33 \n\n-----nusvc - Train----------\nAUC: 99.21 Precision: 100.00 Recall: 98.42 \n\n-----nusvc - Validation-----\nAUC: 79.28 Precision: 96.67 Recall: 60.42 \n\n-----qda - Train----------\nAUC: 97.59 Precision: 95.92 Recall: 98.95 \n\n-----qda - Validation-----\nAUC: 92.94 Precision: 95.56 Recall: 89.58 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.49 Precision: 83.25 Recall: 88.95 \n\n-----knn - Validation-----\nAUC: 85.26 Precision: 82.35 Recall: 87.50 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.90 Precision: 83.72 Recall: 75.00 \n\n-----svc - Train----------\nAUC: 96.84 Precision: 100.00 Recall: 93.68 \n\n-----svc - Validation-----\nAUC: 64.68 Precision: 93.75 Recall: 31.25 \n\n-----nusvc - Train----------\nAUC: 98.95 Precision: 100.00 Recall: 97.89 \n\n-----nusvc - Validation-----\nAUC: 79.26 Precision: 96.67 Recall: 60.42 \n\n-----qda - Train----------\nAUC: 96.83 Precision: 95.38 Recall: 97.89 \n\n-----qda - Validation-----\nAUC: 91.86 Precision: 95.45 Recall: 87.50 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.25 Precision: 84.80 Recall: 91.05 \n\n-----knn - Validation-----\nAUC: 84.02 Precision: 84.78 Recall: 81.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.32 Precision: 80.77 Recall: 87.50 \n\n-----svc - Train----------\nAUC: 96.84 Precision: 100.00 Recall: 93.68 \n\n-----svc - Validation-----\nAUC: 70.83 Precision: 100.00 Recall: 41.67 \n\n-----nusvc - Train----------\nAUC: 98.68 Precision: 100.00 Recall: 97.37 \n\n-----nusvc - Validation-----\nAUC: 84.47 Precision: 97.14 Recall: 70.83 \n\n-----qda - Train----------\nAUC: 96.81 Precision: 95.85 Recall: 97.37 \n\n-----qda - Validation-----\nAUC: 92.90 Precision: 95.56 Recall: 89.58 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.22 Precision: 88.46 Recall: 84.29 \n\n-----knn - Validation-----\nAUC: 80.75 Precision: 81.82 Recall: 76.60 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.98 Precision: 77.08 Recall: 78.72 \n\n-----svc - Train----------\nAUC: 97.91 Precision: 100.00 Recall: 95.81 \n\n-----svc - Validation-----\nAUC: 66.20 Precision: 89.47 Recall: 36.17 \n\n-----nusvc - Train----------\nAUC: 99.21 Precision: 100.00 Recall: 98.43 \n\n-----nusvc - Validation-----\nAUC: 80.15 Precision: 91.18 Recall: 65.96 \n\n-----qda - Train----------\nAUC: 96.81 Precision: 95.88 Recall: 97.38 \n\n-----qda - Validation-----\nAUC: 91.15 Precision: 88.00 Recall: 93.62 \n\nFold 5\n\n-----knn - Train----------\nAUC: 86.27 Precision: 91.02 Recall: 79.58 \n\n-----knn - Validation-----\nAUC: 78.62 Precision: 80.95 Recall: 72.34 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.19 Precision: 82.35 Recall: 89.36 \n\n-----svc - Train----------\nAUC: 96.86 Precision: 100.00 Recall: 93.72 \n\n-----svc - Validation-----\nAUC: 56.86 Precision: 71.43 Recall: 21.28 \n\n-----nusvc - Train----------\nAUC: 98.69 Precision: 100.00 Recall: 97.38 \n\n-----nusvc - Validation-----\nAUC: 76.96 Precision: 90.32 Recall: 59.57 \n\n-----qda - Train----------\nAUC: 97.28 Precision: 96.88 Recall: 97.38 \n\n-----qda - Validation-----\nAUC: 87.01 Precision: 85.42 Recall: 87.23 \n\nwheezy-copper-turtle-magic 28\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.35 Precision: 88.73 Recall: 87.91 \n\n-----knn - Validation-----\nAUC: 77.78 Precision: 75.86 Recall: 81.48 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.48 Precision: 84.00 Recall: 77.78 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 86.11 Precision: 80.95 Recall: 94.44 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.89 Precision: 83.87 Recall: 96.30 \n\n-----qda - Train----------\nAUC: 98.37 Precision: 99.06 Recall: 97.67 \n\n-----qda - Validation-----\nAUC: 90.74 Precision: 90.74 Recall: 90.74 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.71 Precision: 84.96 Recall: 89.30 \n\n-----knn - Validation-----\nAUC: 76.85 Precision: 71.01 Recall: 90.74 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.26 Precision: 80.33 Recall: 90.74 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.19 Precision: 79.69 Recall: 94.44 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.11 Precision: 81.97 Recall: 92.59 \n\n-----qda - Train----------\nAUC: 97.44 Precision: 97.66 Recall: 97.21 \n\n-----qda - Validation-----\nAUC: 91.67 Precision: 92.45 Recall: 90.74 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.46 Precision: 81.78 Recall: 93.95 \n\n-----knn - Validation-----\nAUC: 86.11 Precision: 83.05 Recall: 90.74 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.89 Precision: 87.50 Recall: 90.74 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.81 Precision: 86.44 Recall: 94.44 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.04 Precision: 82.26 Recall: 94.44 \n\n-----qda - Train----------\nAUC: 98.37 Precision: 99.06 Recall: 97.67 \n\n-----qda - Validation-----\nAUC: 93.52 Precision: 96.08 Recall: 90.74 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.51 Precision: 83.69 Recall: 90.70 \n\n-----knn - Validation-----\nAUC: 87.86 Precision: 88.68 Recall: 87.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.90 Precision: 85.71 Recall: 88.89 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.74 Precision: 100.00 Recall: 81.48 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.44 Precision: 100.00 Recall: 88.89 \n\n-----qda - Train----------\nAUC: 97.67 Precision: 99.04 Recall: 96.28 \n\n-----qda - Validation-----\nAUC: 97.20 Precision: 98.11 Recall: 96.30 \n\nFold 5\n\n-----knn - Train----------\nAUC: 86.53 Precision: 83.76 Recall: 90.74 \n\n-----knn - Validation-----\nAUC: 80.19 Precision: 75.81 Recall: 88.68 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.08 Precision: 77.42 Recall: 90.57 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 78.30 Precision: 71.43 Recall: 94.34 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 78.30 Precision: 71.43 Recall: 94.34 \n\n-----qda - Train----------\nAUC: 97.68 Precision: 98.58 Recall: 96.76 \n\n-----qda - Validation-----\nAUC: 88.68 Precision: 88.68 Recall: 88.68 \n\nwheezy-copper-turtle-magic 29\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.16 Precision: 84.30 Recall: 94.00 \n\n-----knn - Validation-----\nAUC: 85.00 Precision: 85.71 Recall: 84.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.00 Precision: 92.86 Recall: 78.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.00 Precision: 97.56 Recall: 80.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.00 Precision: 95.74 Recall: 90.00 \n\n-----qda - Train----------\nAUC: 98.74 Precision: 98.51 Recall: 99.00 \n\n-----qda - Validation-----\nAUC: 92.00 Precision: 90.38 Recall: 94.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.38 Precision: 80.42 Recall: 96.50 \n\n-----knn - Validation-----\nAUC: 86.00 Precision: 83.33 Recall: 90.00 \n\n","name":"stdout"},{"output_type":"stream","text":"-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.00 Precision: 84.44 Recall: 76.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.00 Precision: 92.00 Recall: 92.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.00 Precision: 85.71 Recall: 96.00 \n\n-----qda - Train----------\nAUC: 98.24 Precision: 97.54 Recall: 99.00 \n\n-----qda - Validation-----\nAUC: 89.00 Precision: 89.80 Recall: 88.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.89 Precision: 81.09 Recall: 96.50 \n\n-----knn - Validation-----\nAUC: 84.00 Precision: 79.31 Recall: 92.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.00 Precision: 85.19 Recall: 92.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.00 Precision: 95.65 Recall: 88.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.00 Precision: 88.89 Recall: 96.00 \n\n-----qda - Train----------\nAUC: 97.49 Precision: 97.50 Recall: 97.50 \n\n-----qda - Validation-----\nAUC: 94.00 Precision: 95.83 Recall: 92.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.44 Precision: 80.93 Recall: 95.50 \n\n-----knn - Validation-----\nAUC: 81.67 Precision: 75.00 Recall: 96.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.84 Precision: 84.31 Recall: 86.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 87.86 Precision: 86.54 Recall: 90.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.90 Precision: 90.38 Recall: 94.00 \n\n-----qda - Train----------\nAUC: 98.75 Precision: 98.99 Recall: 98.50 \n\n-----qda - Validation-----\nAUC: 92.92 Precision: 92.16 Recall: 94.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.45 Precision: 83.48 Recall: 93.50 \n\n-----knn - Validation-----\nAUC: 79.63 Precision: 72.73 Recall: 96.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.84 Precision: 84.62 Recall: 88.00 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.50 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 93.96 Precision: 95.83 Recall: 92.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.82 Precision: 84.75 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.99 Precision: 98.00 Recall: 98.00 \n\n-----qda - Validation-----\nAUC: 95.94 Precision: 94.23 Recall: 98.00 \n\nwheezy-copper-turtle-magic 30\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.34 Precision: 89.57 Recall: 87.91 \n\n-----knn - Validation-----\nAUC: 78.81 Precision: 79.63 Recall: 79.63 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.81 Precision: 93.48 Recall: 79.63 \n\n-----svc - Train----------\nAUC: 98.72 Precision: 97.73 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 69.00 Precision: 63.53 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 76.07 Precision: 69.74 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.56 Precision: 99.06 Recall: 98.14 \n\n-----qda - Validation-----\nAUC: 93.44 Precision: 97.96 Recall: 88.89 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.64 Precision: 91.75 Recall: 87.91 \n\n-----knn - Validation-----\nAUC: 82.77 Precision: 87.50 Recall: 77.78 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.78 Precision: 82.00 Recall: 75.93 \n\n-----svc - Train----------\nAUC: 96.95 Precision: 94.71 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 63.27 Precision: 60.00 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 77.65 Precision: 71.62 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.08 Precision: 98.59 Recall: 97.67 \n\n-----qda - Validation-----\nAUC: 93.14 Precision: 92.73 Recall: 94.44 \n\nFold 3\n\n-----knn - Train----------\nAUC: 89.00 Precision: 88.64 Recall: 90.70 \n\n-----knn - Validation-----\nAUC: 84.24 Precision: 82.76 Recall: 88.89 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.44 Precision: 80.36 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 98.73 Precision: 97.73 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 68.46 Precision: 63.86 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 77.65 Precision: 71.62 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.77 Precision: 98.61 Recall: 99.07 \n\n-----qda - Validation-----\nAUC: 92.12 Precision: 91.07 Recall: 94.44 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.81 Precision: 89.30 Recall: 89.30 \n\n-----knn - Validation-----\nAUC: 87.59 Precision: 91.84 Recall: 83.33 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 76.74 Precision: 78.85 Recall: 75.93 \n\n-----svc - Train----------\nAUC: 98.73 Precision: 97.73 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 75.51 Precision: 69.23 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.87 Precision: 84.13 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.58 Precision: 99.53 Recall: 97.67 \n\n-----qda - Validation-----\nAUC: 95.09 Precision: 94.55 Recall: 96.30 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.32 Precision: 89.81 Recall: 89.81 \n\n-----knn - Validation-----\nAUC: 88.93 Precision: 85.00 Recall: 96.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.10 Precision: 89.09 Recall: 92.45 \n\n-----svc - Train----------\nAUC: 98.98 Precision: 98.18 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 65.31 Precision: 60.92 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.63 Precision: 74.65 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.85 Precision: 98.59 Recall: 97.22 \n\n-----qda - Validation-----\nAUC: 94.97 Precision: 92.86 Recall: 98.11 \n\nwheezy-copper-turtle-magic 31\n\nFold 1\n\n-----knn - Train----------\nAUC: 84.70 Precision: 85.57 Recall: 83.00 \n\n-----knn - Validation-----\nAUC: 76.77 Precision: 72.88 Recall: 84.31 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.75 Precision: 73.33 Recall: 86.27 \n\n-----svc - Train----------\nAUC: 98.75 Precision: 100.00 Recall: 97.50 \n\n-----svc - Validation-----\nAUC: 79.45 Precision: 94.12 Recall: 62.75 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.33 Precision: 95.00 Recall: 74.51 \n\n-----qda - Train----------\nAUC: 97.79 Precision: 97.04 Recall: 98.50 \n\n-----qda - Validation-----\nAUC: 90.31 Precision: 88.68 Recall: 92.16 \n\nFold 2\n\n-----knn - Train----------\nAUC: 85.03 Precision: 83.98 Recall: 86.07 \n\n-----knn - Validation-----\nAUC: 79.38 Precision: 79.59 Recall: 78.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.35 Precision: 82.00 Recall: 82.00 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.00 \n\n-----svc - Validation-----\nAUC: 81.04 Precision: 96.97 Recall: 64.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.08 Precision: 95.12 Recall: 78.00 \n\n-----qda - Train----------\nAUC: 97.55 Precision: 97.04 Recall: 98.01 \n\n-----qda - Validation-----\nAUC: 90.19 Precision: 90.00 Recall: 90.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 85.70 Precision: 88.24 Recall: 82.09 \n\n-----knn - Validation-----\nAUC: 80.31 Precision: 82.61 Recall: 76.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 74.38 Precision: 77.27 Recall: 68.00 \n\n","name":"stdout"},{"output_type":"stream","text":"-----svc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.00 \n\n-----svc - Validation-----\nAUC: 74.04 Precision: 96.15 Recall: 50.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----nusvc - Validation-----\nAUC: 80.08 Precision: 94.12 Recall: 64.00 \n\n-----qda - Train----------\nAUC: 97.55 Precision: 97.04 Recall: 98.01 \n\n-----qda - Validation-----\nAUC: 91.15 Precision: 91.84 Recall: 90.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.52 Precision: 86.41 Recall: 88.56 \n\n-----knn - Validation-----\nAUC: 76.16 Precision: 80.95 Recall: 68.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 73.27 Precision: 72.55 Recall: 74.00 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.00 \n\n-----svc - Validation-----\nAUC: 79.04 Precision: 93.94 Recall: 62.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.04 Precision: 95.56 Recall: 86.00 \n\n-----qda - Train----------\nAUC: 97.80 Precision: 97.52 Recall: 98.01 \n\n-----qda - Validation-----\nAUC: 92.12 Precision: 88.89 Recall: 96.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 84.74 Precision: 87.57 Recall: 80.60 \n\n-----knn - Validation-----\nAUC: 82.10 Precision: 88.10 Recall: 74.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.12 Precision: 87.50 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----svc - Validation-----\nAUC: 78.02 Precision: 96.67 Recall: 58.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.04 Precision: 94.59 Recall: 70.00 \n\n-----qda - Train----------\nAUC: 96.59 Precision: 95.17 Recall: 98.01 \n\n-----qda - Validation-----\nAUC: 92.08 Precision: 92.00 Recall: 92.00 \n\nwheezy-copper-turtle-magic 32\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.90 Precision: 83.66 Recall: 90.37 \n\n-----knn - Validation-----\nAUC: 79.62 Precision: 74.55 Recall: 87.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.68 Precision: 87.50 Recall: 89.36 \n\n-----svc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.47 \n\n-----svc - Validation-----\nAUC: 82.11 Precision: 91.67 Recall: 70.21 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.62 Precision: 91.11 Recall: 87.23 \n\n-----qda - Train----------\nAUC: 98.98 Precision: 98.41 Recall: 99.47 \n\n-----qda - Validation-----\nAUC: 91.81 Precision: 89.80 Recall: 93.62 \n\nFold 2\n\n-----knn - Train----------\nAUC: 85.12 Precision: 81.16 Recall: 89.84 \n\n-----knn - Validation-----\nAUC: 80.55 Precision: 76.92 Recall: 85.11 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.68 Precision: 82.35 Recall: 89.36 \n\n-----svc - Train----------\nAUC: 99.47 Precision: 100.00 Recall: 98.93 \n\n-----svc - Validation-----\nAUC: 85.17 Precision: 97.14 Recall: 72.34 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.74 Precision: 93.48 Recall: 91.49 \n\n-----qda - Train----------\nAUC: 98.23 Precision: 96.88 Recall: 99.47 \n\n-----qda - Validation-----\nAUC: 85.55 Precision: 85.11 Recall: 85.11 \n\nFold 3\n\n-----knn - Train----------\nAUC: 85.42 Precision: 80.66 Recall: 91.44 \n\n-----knn - Validation-----\nAUC: 81.36 Precision: 82.22 Recall: 78.72 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 75.91 Precision: 83.33 Recall: 63.83 \n\n-----svc - Train----------\nAUC: 96.52 Precision: 100.00 Recall: 93.05 \n\n-----svc - Validation-----\nAUC: 67.02 Precision: 100.00 Recall: 34.04 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 79.79 Precision: 100.00 Recall: 59.57 \n\n-----qda - Train----------\nAUC: 98.74 Precision: 97.40 Recall: 100.00 \n\n-----qda - Validation-----\nAUC: 91.68 Precision: 93.33 Recall: 89.36 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.42 Precision: 80.66 Recall: 91.44 \n\n-----knn - Validation-----\nAUC: 85.62 Precision: 83.67 Recall: 87.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.74 Precision: 89.58 Recall: 91.49 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.62 Precision: 91.11 Recall: 87.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.81 Precision: 83.02 Recall: 93.62 \n\n-----qda - Train----------\nAUC: 98.74 Precision: 97.40 Recall: 100.00 \n\n-----qda - Validation-----\nAUC: 94.00 Precision: 88.68 Recall: 100.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 86.45 Precision: 83.25 Recall: 89.89 \n\n-----knn - Validation-----\nAUC: 78.11 Precision: 73.58 Recall: 84.78 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.03 Precision: 80.43 Recall: 80.43 \n\n-----svc - Train----------\nAUC: 98.94 Precision: 100.00 Recall: 97.87 \n\n-----svc - Validation-----\nAUC: 77.37 Precision: 90.32 Recall: 60.87 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.16 Precision: 92.50 Recall: 80.43 \n\n-----qda - Train----------\nAUC: 98.98 Precision: 98.42 Recall: 99.47 \n\n-----qda - Validation-----\nAUC: 90.48 Precision: 91.11 Recall: 89.13 \n\nwheezy-copper-turtle-magic 33\n\nFold 1\n\n-----knn - Train----------\nAUC: 89.81 Precision: 90.14 Recall: 89.72 \n\n-----knn - Validation-----\nAUC: 83.94 Precision: 83.64 Recall: 85.19 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.01 Precision: 83.33 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 95.19 Precision: 91.45 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 67.31 Precision: 61.36 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.28 Precision: 98.62 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 77.92 Precision: 70.67 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 97.17 Precision: 98.10 Recall: 96.26 \n\n-----qda - Validation-----\nAUC: 87.68 Precision: 85.96 Recall: 90.74 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.56 Precision: 88.99 Recall: 90.65 \n\n-----knn - Validation-----\nAUC: 85.79 Precision: 84.21 Recall: 88.89 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.90 Precision: 82.46 Recall: 87.04 \n\n-----svc - Train----------\nAUC: 93.75 Precision: 89.17 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 64.42 Precision: 59.34 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 98.56 Precision: 97.27 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 72.15 Precision: 65.43 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 96.93 Precision: 97.63 Recall: 96.26 \n\n-----qda - Validation-----\nAUC: 91.56 Precision: 94.12 Recall: 88.89 \n\nFold 3\n\n-----knn - Train----------\nAUC: 90.73 Precision: 89.24 Recall: 92.99 \n\n-----knn - Validation-----\nAUC: 84.94 Precision: 86.54 Recall: 83.33 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 91.67 Precision: 100.00 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 95.43 Precision: 91.85 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 76.00 Precision: 68.83 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.54 Precision: 81.54 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 96.69 Precision: 97.17 Recall: 96.26 \n\n-----qda - Validation-----\nAUC: 95.37 Precision: 100.00 Recall: 90.74 \n\nFold 4\n\n-----knn - Train----------\nAUC: 90.08 Precision: 91.00 Recall: 89.30 \n\n-----knn - Validation-----\nAUC: 87.61 Precision: 87.04 Recall: 88.68 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.57 Precision: 88.68 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 96.15 Precision: 93.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 77.90 Precision: 70.27 Recall: 98.11 \n\n","name":"stdout"},{"output_type":"stream","text":"-----nusvc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.50 Precision: 83.61 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 96.94 Precision: 97.64 Recall: 96.28 \n\n-----qda - Validation-----\nAUC: 94.29 Precision: 94.34 Recall: 94.34 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.59 Precision: 89.40 Recall: 90.23 \n\n-----knn - Validation-----\nAUC: 84.81 Precision: 89.36 Recall: 79.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.93 Precision: 80.00 Recall: 83.02 \n\n-----svc - Train----------\nAUC: 97.12 Precision: 94.71 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 72.13 Precision: 65.00 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 99.52 Precision: 99.08 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 80.82 Precision: 74.63 Recall: 94.34 \n\n-----qda - Train----------\nAUC: 97.63 Precision: 97.24 Recall: 98.14 \n\n-----qda - Validation-----\nAUC: 93.34 Precision: 94.23 Recall: 92.45 \n\nwheezy-copper-turtle-magic 34\n\nFold 1\n\n-----knn - Train----------\nAUC: 82.54 Precision: 76.57 Recall: 99.10 \n\n-----knn - Validation-----\nAUC: 76.54 Precision: 72.86 Recall: 91.07 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.07 Precision: 85.19 Recall: 82.14 \n\n-----svc - Train----------\nAUC: 98.22 Precision: 96.93 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 64.00 Precision: 60.87 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.24 Precision: 98.66 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 69.32 Precision: 65.43 Recall: 94.64 \n\n-----qda - Train----------\nAUC: 98.53 Precision: 98.21 Recall: 99.10 \n\n-----qda - Validation-----\nAUC: 91.43 Precision: 91.23 Recall: 92.86 \n\nFold 2\n\n-----knn - Train----------\nAUC: 81.86 Precision: 76.33 Recall: 97.74 \n\n-----knn - Validation-----\nAUC: 83.11 Precision: 77.46 Recall: 98.21 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.86 Precision: 90.57 Recall: 85.71 \n\n-----svc - Train----------\nAUC: 95.94 Precision: 93.25 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 63.00 Precision: 60.22 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 98.73 Precision: 97.79 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 72.00 Precision: 66.67 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.85 Precision: 98.18 Recall: 97.74 \n\n-----qda - Validation-----\nAUC: 95.32 Precision: 96.36 Recall: 94.64 \n\nFold 3\n\n-----knn - Train----------\nAUC: 85.72 Precision: 80.44 Recall: 98.20 \n\n-----knn - Validation-----\nAUC: 78.57 Precision: 72.37 Recall: 100.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.25 Precision: 83.33 Recall: 90.91 \n\n-----svc - Train----------\nAUC: 97.47 Precision: 95.69 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 62.24 Precision: 59.78 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.55 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 75.51 Precision: 69.62 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.85 Precision: 99.54 Recall: 98.20 \n\n-----qda - Validation-----\nAUC: 93.99 Precision: 91.53 Recall: 98.18 \n\nFold 4\n\n-----knn - Train----------\nAUC: 82.99 Precision: 77.70 Recall: 97.30 \n\n-----knn - Validation-----\nAUC: 89.91 Precision: 85.71 Recall: 98.18 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.88 Precision: 88.00 Recall: 80.00 \n\n-----svc - Train----------\nAUC: 96.21 Precision: 93.67 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 71.43 Precision: 66.27 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.24 Precision: 98.67 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.63 Precision: 75.34 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.84 Precision: 97.76 Recall: 98.20 \n\n-----qda - Validation-----\nAUC: 93.41 Precision: 96.15 Recall: 90.91 \n\nFold 5\n\n-----knn - Train----------\nAUC: 82.96 Precision: 77.50 Recall: 97.75 \n\n-----knn - Validation-----\nAUC: 75.51 Precision: 69.62 Recall: 100.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.03 Precision: 81.25 Recall: 94.55 \n\n-----svc - Train----------\nAUC: 95.96 Precision: 93.28 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 57.14 Precision: 56.70 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 98.48 Precision: 97.37 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 64.29 Precision: 61.11 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.09 Precision: 98.20 Recall: 98.20 \n\n-----qda - Validation-----\nAUC: 94.90 Precision: 91.67 Recall: 100.00 \n\nwheezy-copper-turtle-magic 35\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.73 Precision: 80.97 Recall: 97.09 \n\n-----knn - Validation-----\nAUC: 84.19 Precision: 81.03 Recall: 90.38 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.54 Precision: 92.68 Recall: 73.08 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.52 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.00 Precision: 76.47 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.12 Precision: 89.09 Recall: 94.23 \n\n-----qda - Train----------\nAUC: 97.52 Precision: 97.12 Recall: 98.06 \n\n-----qda - Validation-----\nAUC: 97.08 Precision: 98.04 Recall: 96.15 \n\nFold 2\n\n-----knn - Train----------\nAUC: 87.54 Precision: 83.62 Recall: 94.17 \n\n-----knn - Validation-----\nAUC: 77.19 Precision: 72.31 Recall: 90.38 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.38 Precision: 80.77 Recall: 80.77 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 99.52 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.00 Precision: 74.29 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.04 Precision: 83.61 Recall: 98.08 \n\n-----qda - Train----------\nAUC: 97.76 Precision: 97.13 Recall: 98.54 \n\n-----qda - Validation-----\nAUC: 93.12 Precision: 92.45 Recall: 94.23 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.04 Precision: 84.35 Recall: 94.17 \n\n-----knn - Validation-----\nAUC: 80.08 Precision: 73.53 Recall: 96.15 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.42 Precision: 77.36 Recall: 78.85 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.00 Precision: 74.29 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.08 Precision: 84.75 Recall: 96.15 \n\n-----qda - Train----------\nAUC: 97.78 Precision: 98.05 Recall: 97.57 \n\n-----qda - Validation-----\nAUC: 89.27 Precision: 91.84 Recall: 86.54 \n\nFold 4\n\n-----knn - Train----------\nAUC: 90.06 Precision: 87.11 Recall: 94.69 \n\n-----knn - Validation-----\nAUC: 79.12 Precision: 75.00 Recall: 88.24 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.22 Precision: 86.96 Recall: 78.43 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.04 Precision: 85.96 Recall: 96.08 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.06 Precision: 88.89 Recall: 94.12 \n\n-----qda - Train----------\nAUC: 98.02 Precision: 97.61 Recall: 98.55 \n\n-----qda - Validation-----\nAUC: 92.12 Precision: 95.74 Recall: 88.24 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.36 Precision: 83.62 Recall: 93.72 \n\n-----knn - Validation-----\nAUC: 83.79 Precision: 78.69 Recall: 94.12 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.85 Precision: 79.31 Recall: 90.20 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.75 Precision: 77.78 Recall: 96.08 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.88 Precision: 85.96 Recall: 96.08 \n\n","name":"stdout"},{"output_type":"stream","text":"-----qda - Train----------\nAUC: 98.28 Precision: 98.54 Recall: 98.07 \n\n-----qda - Validation-----\nAUC: 90.00 Precision: 90.20 Recall: 90.20 \n\nwheezy-copper-turtle-magic 36\n\nFold 1\n\n-----knn - Train----------\nAUC: 85.83 Precision: 92.11 Recall: 77.35 \n\n-----knn - Validation-----\nAUC: 80.58 Precision: 96.67 Recall: 63.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.55 Precision: 79.55 Recall: 76.09 \n\n-----svc - Train----------\nAUC: 92.82 Precision: 100.00 Recall: 85.64 \n\n-----svc - Validation-----\nAUC: 57.61 Precision: 100.00 Recall: 15.22 \n\n-----nusvc - Train----------\nAUC: 98.62 Precision: 100.00 Recall: 97.24 \n\n-----nusvc - Validation-----\nAUC: 69.57 Precision: 100.00 Recall: 39.13 \n\n-----qda - Train----------\nAUC: 98.18 Precision: 98.33 Recall: 97.79 \n\n-----qda - Validation-----\nAUC: 90.65 Precision: 93.02 Recall: 86.96 \n\nFold 2\n\n-----knn - Train----------\nAUC: 81.37 Precision: 96.69 Recall: 64.64 \n\n-----knn - Validation-----\nAUC: 74.06 Precision: 95.83 Recall: 50.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.76 Precision: 82.61 Recall: 82.61 \n\n-----svc - Train----------\nAUC: 93.09 Precision: 100.00 Recall: 86.19 \n\n-----svc - Validation-----\nAUC: 52.32 Precision: 75.00 Recall: 6.52 \n\n-----nusvc - Train----------\nAUC: 98.07 Precision: 100.00 Recall: 96.13 \n\n-----nusvc - Validation-----\nAUC: 60.87 Precision: 100.00 Recall: 21.74 \n\n-----qda - Train----------\nAUC: 98.42 Precision: 98.88 Recall: 97.79 \n\n-----qda - Validation-----\nAUC: 94.05 Precision: 91.67 Recall: 95.65 \n\nFold 3\n\n-----knn - Train----------\nAUC: 84.01 Precision: 91.22 Recall: 74.18 \n\n-----knn - Validation-----\nAUC: 83.67 Precision: 94.12 Recall: 71.11 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.29 Precision: 79.07 Recall: 75.56 \n\n-----svc - Train----------\nAUC: 92.86 Precision: 100.00 Recall: 85.71 \n\n-----svc - Validation-----\nAUC: 57.78 Precision: 100.00 Recall: 15.56 \n\n-----nusvc - Train----------\nAUC: 98.63 Precision: 100.00 Recall: 97.25 \n\n-----nusvc - Validation-----\nAUC: 67.78 Precision: 100.00 Recall: 35.56 \n\n-----qda - Train----------\nAUC: 98.46 Precision: 98.35 Recall: 98.35 \n\n-----qda - Validation-----\nAUC: 94.95 Precision: 93.48 Recall: 95.56 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.49 Precision: 94.84 Recall: 80.77 \n\n-----knn - Validation-----\nAUC: 83.06 Precision: 87.18 Recall: 75.56 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.45 Precision: 77.78 Recall: 77.78 \n\n-----svc - Train----------\nAUC: 94.78 Precision: 100.00 Recall: 89.56 \n\n-----svc - Validation-----\nAUC: 60.17 Precision: 90.91 Recall: 22.22 \n\n-----nusvc - Train----------\nAUC: 99.73 Precision: 100.00 Recall: 99.45 \n\n-----nusvc - Validation-----\nAUC: 74.61 Precision: 95.83 Recall: 51.11 \n\n-----qda - Train----------\nAUC: 98.70 Precision: 98.90 Recall: 98.35 \n\n-----qda - Validation-----\nAUC: 86.73 Precision: 84.78 Recall: 86.67 \n\nFold 5\n\n-----knn - Train----------\nAUC: 82.93 Precision: 95.42 Recall: 68.68 \n\n-----knn - Validation-----\nAUC: 77.93 Precision: 96.30 Recall: 57.78 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.20 Precision: 81.40 Recall: 77.78 \n\n-----svc - Train----------\nAUC: 92.58 Precision: 100.00 Recall: 85.16 \n\n-----svc - Validation-----\nAUC: 55.56 Precision: 100.00 Recall: 11.11 \n\n-----nusvc - Train----------\nAUC: 99.18 Precision: 100.00 Recall: 98.35 \n\n-----nusvc - Validation-----\nAUC: 64.44 Precision: 100.00 Recall: 28.89 \n\n-----qda - Train----------\nAUC: 97.92 Precision: 98.33 Recall: 97.25 \n\n-----qda - Validation-----\nAUC: 94.59 Precision: 97.62 Recall: 91.11 \n\nwheezy-copper-turtle-magic 37\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.41 Precision: 86.94 Recall: 91.04 \n\n-----knn - Validation-----\nAUC: 83.90 Precision: 82.46 Recall: 87.04 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.86 Precision: 86.79 Recall: 85.19 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.72 Precision: 81.97 Recall: 92.59 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.61 Precision: 83.61 Recall: 94.44 \n\n-----qda - Train----------\nAUC: 98.80 Precision: 99.05 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 90.53 Precision: 89.29 Recall: 92.59 \n\nFold 2\n\n-----knn - Train----------\nAUC: 88.97 Precision: 88.48 Recall: 90.14 \n\n-----knn - Validation-----\nAUC: 86.57 Precision: 88.24 Recall: 84.91 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.50 Precision: 85.45 Recall: 88.68 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 94.27 Precision: 96.08 Recall: 92.45 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 98.08 Precision: 98.11 Recall: 98.11 \n\n-----qda - Train----------\nAUC: 98.31 Precision: 97.69 Recall: 99.06 \n\n-----qda - Validation-----\nAUC: 99.06 Precision: 100.00 Recall: 98.11 \n\nFold 3\n\n-----knn - Train----------\nAUC: 89.65 Precision: 87.61 Recall: 92.96 \n\n-----knn - Validation-----\nAUC: 86.46 Precision: 84.21 Recall: 90.57 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.70 Precision: 86.00 Recall: 81.13 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.07 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 82.43 Precision: 76.12 Recall: 96.23 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.29 Precision: 89.29 Recall: 94.34 \n\n-----qda - Train----------\nAUC: 98.80 Precision: 98.60 Recall: 99.06 \n\n-----qda - Validation-----\nAUC: 90.38 Precision: 90.57 Recall: 90.57 \n\nFold 4\n\n-----knn - Train----------\nAUC: 90.69 Precision: 91.83 Recall: 89.67 \n\n-----knn - Validation-----\nAUC: 87.62 Precision: 93.48 Recall: 81.13 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.55 Precision: 85.19 Recall: 86.79 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.49 Precision: 95.74 Recall: 84.91 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.36 Precision: 97.92 Recall: 88.68 \n\n-----qda - Train----------\nAUC: 97.85 Precision: 98.11 Recall: 97.65 \n\n-----qda - Validation-----\nAUC: 93.25 Precision: 92.59 Recall: 94.34 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.47 Precision: 89.67 Recall: 89.67 \n\n-----knn - Validation-----\nAUC: 83.56 Precision: 81.03 Recall: 88.68 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 77.71 Precision: 74.19 Recall: 86.79 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 91.29 Precision: 89.29 Recall: 94.34 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.25 Precision: 87.93 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 97.38 Precision: 98.10 Recall: 96.71 \n\n-----qda - Validation-----\nAUC: 95.21 Precision: 96.15 Recall: 94.34 \n\nwheezy-copper-turtle-magic 38\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.18 Precision: 85.43 Recall: 85.43 \n\n-----knn - Validation-----\nAUC: 84.96 Precision: 82.69 Recall: 86.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.07 Precision: 82.14 Recall: 92.00 \n\n-----svc - Train----------\nAUC: 94.72 Precision: 100.00 Recall: 89.45 \n\n-----svc - Validation-----\nAUC: 60.00 Precision: 100.00 Recall: 20.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 98.99 \n\n-----nusvc - Validation-----\nAUC: 78.00 Precision: 100.00 Recall: 56.00 \n\n-----qda - Train----------\nAUC: 98.29 Precision: 98.98 Recall: 97.49 \n\n-----qda - Validation-----\nAUC: 95.32 Precision: 94.12 Recall: 96.00 \n\n","name":"stdout"},{"output_type":"stream","text":"Fold 2\n\n-----knn - Train----------\nAUC: 90.67 Precision: 90.82 Recall: 89.45 \n\n-----knn - Validation-----\nAUC: 73.50 Precision: 72.00 Recall: 72.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 75.39 Precision: 74.00 Recall: 74.00 \n\n-----svc - Train----------\nAUC: 95.73 Precision: 100.00 Recall: 91.46 \n\n-----svc - Validation-----\nAUC: 60.11 Precision: 91.67 Recall: 22.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 98.99 \n\n-----nusvc - Validation-----\nAUC: 75.11 Precision: 96.30 Recall: 52.00 \n\n-----qda - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----qda - Validation-----\nAUC: 92.32 Precision: 93.75 Recall: 90.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.49 Precision: 84.80 Recall: 86.93 \n\n-----knn - Validation-----\nAUC: 86.96 Precision: 83.33 Recall: 90.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.75 Precision: 85.11 Recall: 80.00 \n\n-----svc - Train----------\nAUC: 94.72 Precision: 100.00 Recall: 89.45 \n\n-----svc - Validation-----\nAUC: 61.00 Precision: 100.00 Recall: 22.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----nusvc - Validation-----\nAUC: 76.00 Precision: 100.00 Recall: 52.00 \n\n-----qda - Train----------\nAUC: 98.77 Precision: 99.49 Recall: 97.99 \n\n-----qda - Validation-----\nAUC: 96.21 Precision: 96.00 Recall: 96.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.93 Precision: 85.71 Recall: 84.42 \n\n-----knn - Validation-----\nAUC: 86.55 Precision: 87.50 Recall: 84.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.73 Precision: 83.67 Recall: 82.00 \n\n-----svc - Train----------\nAUC: 93.97 Precision: 100.00 Recall: 87.94 \n\n-----svc - Validation-----\nAUC: 66.00 Precision: 100.00 Recall: 32.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 98.99 \n\n-----nusvc - Validation-----\nAUC: 75.00 Precision: 100.00 Recall: 50.00 \n\n-----qda - Train----------\nAUC: 98.80 Precision: 98.99 Recall: 98.49 \n\n-----qda - Validation-----\nAUC: 95.18 Precision: 95.92 Recall: 94.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.61 Precision: 92.43 Recall: 85.50 \n\n-----knn - Validation-----\nAUC: 74.81 Precision: 74.47 Recall: 71.43 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.48 Precision: 82.22 Recall: 75.51 \n\n-----svc - Train----------\nAUC: 95.50 Precision: 100.00 Recall: 91.00 \n\n-----svc - Validation-----\nAUC: 57.14 Precision: 100.00 Recall: 14.29 \n\n-----nusvc - Train----------\nAUC: 99.25 Precision: 100.00 Recall: 98.50 \n\n-----nusvc - Validation-----\nAUC: 64.51 Precision: 88.89 Recall: 32.65 \n\n-----qda - Train----------\nAUC: 98.30 Precision: 98.98 Recall: 97.50 \n\n-----qda - Validation-----\nAUC: 94.10 Precision: 95.74 Recall: 91.84 \n\nwheezy-copper-turtle-magic 39\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.72 Precision: 84.93 Recall: 93.47 \n\n-----knn - Validation-----\nAUC: 81.46 Precision: 78.18 Recall: 86.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.42 Precision: 78.43 Recall: 80.00 \n\n-----svc - Train----------\nAUC: 99.27 Precision: 98.51 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.54 Precision: 77.42 Recall: 96.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.27 Precision: 86.79 Recall: 92.00 \n\n-----qda - Train----------\nAUC: 98.76 Precision: 98.99 Recall: 98.49 \n\n-----qda - Validation-----\nAUC: 90.15 Precision: 91.67 Recall: 88.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 85.77 Precision: 81.90 Recall: 90.95 \n\n-----knn - Validation-----\nAUC: 85.38 Precision: 81.82 Recall: 90.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 90.08 Precision: 95.45 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.27 Precision: 87.50 Recall: 98.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.27 Precision: 87.27 Recall: 96.00 \n\n-----qda - Train----------\nAUC: 97.54 Precision: 97.01 Recall: 97.99 \n\n-----qda - Validation-----\nAUC: 91.15 Precision: 91.84 Recall: 90.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.29 Precision: 81.82 Recall: 94.97 \n\n-----knn - Validation-----\nAUC: 81.62 Precision: 74.60 Recall: 94.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.42 Precision: 78.85 Recall: 82.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 95.19 Precision: 90.91 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.23 Precision: 89.29 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 97.54 Precision: 97.01 Recall: 97.99 \n\n-----qda - Validation-----\nAUC: 95.15 Precision: 92.45 Recall: 98.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.18 Precision: 88.18 Recall: 89.95 \n\n-----knn - Validation-----\nAUC: 83.18 Precision: 82.35 Recall: 84.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.24 Precision: 77.78 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----svc - Validation-----\nAUC: 88.06 Precision: 93.18 Recall: 82.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.08 Precision: 91.49 Recall: 86.00 \n\n-----qda - Train----------\nAUC: 97.78 Precision: 97.98 Recall: 97.49 \n\n-----qda - Validation-----\nAUC: 91.10 Precision: 90.20 Recall: 92.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 86.38 Precision: 80.77 Recall: 94.50 \n\n-----knn - Validation-----\nAUC: 75.25 Precision: 69.35 Recall: 87.76 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.95 Precision: 82.98 Recall: 79.59 \n\n-----svc - Train----------\nAUC: 99.03 Precision: 98.04 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 71.57 Precision: 62.82 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.50 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 81.33 Precision: 72.73 Recall: 97.96 \n\n-----qda - Train----------\nAUC: 98.03 Precision: 98.00 Recall: 98.00 \n\n-----qda - Validation-----\nAUC: 88.04 Precision: 86.27 Recall: 89.80 \n\nwheezy-copper-turtle-magic 40\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.64 Precision: 85.12 Recall: 93.37 \n\n-----knn - Validation-----\nAUC: 88.00 Precision: 88.00 Recall: 88.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 91.00 Precision: 90.20 Recall: 92.00 \n\n-----svc - Train----------\nAUC: 97.99 Precision: 96.08 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 77.00 Precision: 69.01 Recall: 98.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 98.99 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.00 Precision: 84.48 Recall: 98.00 \n\n-----qda - Train----------\nAUC: 97.47 Precision: 96.97 Recall: 97.96 \n\n-----qda - Validation-----\nAUC: 93.00 Precision: 92.16 Recall: 94.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 84.88 Precision: 80.44 Recall: 91.88 \n\n-----knn - Validation-----\nAUC: 82.94 Precision: 76.67 Recall: 93.88 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.84 Precision: 87.23 Recall: 83.67 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 98.99 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.94 Precision: 77.97 Recall: 93.88 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.49 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.94 Precision: 86.79 Recall: 93.88 \n\n-----qda - Train----------\nAUC: 97.47 Precision: 97.95 Recall: 96.95 \n\n-----qda - Validation-----\nAUC: 88.88 Precision: 89.58 Recall: 87.76 \n\nFold 3\n\n-----knn - Train----------\nAUC: 85.66 Precision: 78.93 Recall: 96.95 \n\n-----knn - Validation-----\nAUC: 78.94 Precision: 71.88 Recall: 93.88 \n\n","name":"stdout"},{"output_type":"stream","text":"-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.78 Precision: 80.85 Recall: 77.55 \n\n-----svc - Train----------\nAUC: 95.98 Precision: 92.49 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 64.98 Precision: 58.54 Recall: 97.96 \n\n-----nusvc - Train----------\nAUC: 99.25 Precision: 98.50 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 70.96 Precision: 63.51 Recall: 95.92 \n\n-----qda - Train----------\nAUC: 97.48 Precision: 96.98 Recall: 97.97 \n\n-----qda - Validation-----\nAUC: 88.88 Precision: 89.58 Recall: 87.76 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.65 Precision: 82.43 Recall: 92.89 \n\n-----knn - Validation-----\nAUC: 83.98 Precision: 76.19 Recall: 97.96 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.88 Precision: 87.76 Recall: 87.76 \n\n-----svc - Train----------\nAUC: 99.25 Precision: 98.50 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.98 Precision: 76.19 Recall: 97.96 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.49 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.98 Precision: 80.00 Recall: 97.96 \n\n-----qda - Train----------\nAUC: 97.73 Precision: 97.96 Recall: 97.46 \n\n-----qda - Validation-----\nAUC: 93.94 Precision: 93.88 Recall: 93.88 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.20 Precision: 85.65 Recall: 93.91 \n\n-----knn - Validation-----\nAUC: 85.71 Precision: 85.71 Recall: 85.71 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.59 Precision: 80.85 Recall: 77.55 \n\n-----svc - Train----------\nAUC: 98.50 Precision: 97.04 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 80.61 Precision: 72.06 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.50 Precision: 98.99 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.80 Precision: 84.21 Recall: 97.96 \n\n-----qda - Train----------\nAUC: 96.98 Precision: 96.95 Recall: 96.95 \n\n-----qda - Validation-----\nAUC: 93.88 Precision: 95.74 Recall: 91.84 \n\nwheezy-copper-turtle-magic 41\n\nFold 1\n\n-----knn - Train----------\nAUC: 89.32 Precision: 88.64 Recall: 90.28 \n\n-----knn - Validation-----\nAUC: 79.63 Precision: 80.77 Recall: 77.78 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.41 Precision: 81.82 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 99.77 Precision: 99.54 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.33 Precision: 80.00 Recall: 88.89 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.74 Precision: 87.93 Recall: 94.44 \n\n-----qda - Train----------\nAUC: 97.68 Precision: 98.13 Recall: 97.22 \n\n-----qda - Validation-----\nAUC: 89.81 Precision: 92.16 Recall: 87.04 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.33 Precision: 91.67 Recall: 86.57 \n\n-----knn - Validation-----\nAUC: 85.19 Precision: 88.00 Recall: 81.48 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.26 Precision: 84.91 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 93.52 Precision: 89.83 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 94.44 Precision: 92.86 Recall: 96.30 \n\n-----qda - Train----------\nAUC: 97.91 Precision: 98.59 Recall: 97.22 \n\n-----qda - Validation-----\nAUC: 96.30 Precision: 94.64 Recall: 98.15 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.25 Precision: 90.86 Recall: 82.87 \n\n-----knn - Validation-----\nAUC: 83.33 Precision: 84.62 Recall: 81.48 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.96 Precision: 85.96 Recall: 90.74 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 83.33 Precision: 79.03 Recall: 90.74 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.81 Precision: 87.72 Recall: 92.59 \n\n-----qda - Train----------\nAUC: 97.68 Precision: 98.13 Recall: 97.22 \n\n-----qda - Validation-----\nAUC: 91.67 Precision: 90.91 Recall: 92.59 \n\nFold 4\n\n-----knn - Train----------\nAUC: 88.41 Precision: 91.50 Recall: 84.72 \n\n-----knn - Validation-----\nAUC: 87.96 Precision: 93.62 Recall: 81.48 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.70 Precision: 82.98 Recall: 72.22 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 87.96 Precision: 90.20 Recall: 85.19 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.74 Precision: 95.83 Recall: 85.19 \n\n-----qda - Train----------\nAUC: 98.14 Precision: 98.15 Recall: 98.15 \n\n-----qda - Validation-----\nAUC: 92.59 Precision: 97.92 Recall: 87.04 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.58 Precision: 89.04 Recall: 90.28 \n\n-----knn - Validation-----\nAUC: 83.23 Precision: 87.50 Recall: 77.78 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.21 Precision: 86.00 Recall: 79.63 \n\n-----svc - Train----------\nAUC: 99.77 Precision: 99.54 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 91.54 Precision: 88.14 Recall: 96.30 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 93.48 Precision: 96.08 Recall: 90.74 \n\n-----qda - Train----------\nAUC: 96.30 Precision: 96.73 Recall: 95.83 \n\n-----qda - Validation-----\nAUC: 91.63 Precision: 95.92 Recall: 87.04 \n\nwheezy-copper-turtle-magic 42\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.97 Precision: 87.23 Recall: 86.77 \n\n-----knn - Validation-----\nAUC: 87.37 Precision: 87.50 Recall: 87.50 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 83.11 Precision: 80.77 Recall: 87.50 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.62 Precision: 100.00 Recall: 81.25 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.66 Precision: 95.56 Recall: 89.58 \n\n-----qda - Train----------\nAUC: 98.13 Precision: 97.40 Recall: 98.94 \n\n-----qda - Validation-----\nAUC: 91.62 Precision: 95.45 Recall: 87.50 \n\nFold 2\n\n-----knn - Train----------\nAUC: 84.29 Precision: 82.50 Recall: 87.30 \n\n-----knn - Validation-----\nAUC: 85.26 Precision: 85.42 Recall: 85.42 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.26 Precision: 88.37 Recall: 79.17 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.52 Precision: 97.44 Recall: 79.17 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.64 Precision: 97.62 Recall: 85.42 \n\n-----qda - Train----------\nAUC: 98.14 Precision: 98.40 Recall: 97.88 \n\n-----qda - Validation-----\nAUC: 96.83 Precision: 95.92 Recall: 97.92 \n\nFold 3\n\n-----knn - Train----------\nAUC: 89.36 Precision: 87.13 Recall: 92.63 \n\n-----knn - Validation-----\nAUC: 76.60 Precision: 74.51 Recall: 80.85 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.17 Precision: 86.96 Recall: 85.11 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.04 Precision: 86.36 Recall: 80.85 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.17 Precision: 86.96 Recall: 85.11 \n\n-----qda - Train----------\nAUC: 98.94 Precision: 98.95 Recall: 98.95 \n\n-----qda - Validation-----\nAUC: 90.43 Precision: 88.00 Recall: 93.62 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.09 Precision: 81.31 Recall: 91.58 \n\n-----knn - Validation-----\nAUC: 78.72 Precision: 73.68 Recall: 89.36 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.04 Precision: 82.00 Recall: 87.23 \n\n","name":"stdout"},{"output_type":"stream","text":"-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.43 Precision: 89.58 Recall: 91.49 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.49 Precision: 86.79 Recall: 97.87 \n\n-----qda - Train----------\nAUC: 98.41 Precision: 98.42 Recall: 98.42 \n\n-----qda - Validation-----\nAUC: 93.62 Precision: 91.84 Recall: 95.74 \n\nFold 5\n\n-----knn - Train----------\nAUC: 85.95 Precision: 82.16 Recall: 92.11 \n\n-----knn - Validation-----\nAUC: 86.01 Precision: 85.42 Recall: 87.23 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.25 Precision: 89.36 Recall: 89.36 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.38 Precision: 95.24 Recall: 85.11 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.51 Precision: 95.45 Recall: 89.36 \n\n-----qda - Train----------\nAUC: 98.14 Precision: 97.41 Recall: 98.95 \n\n-----qda - Validation-----\nAUC: 92.46 Precision: 91.67 Recall: 93.62 \n\nwheezy-copper-turtle-magic 43\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.55 Precision: 84.72 Recall: 90.59 \n\n-----knn - Validation-----\nAUC: 83.99 Precision: 79.31 Recall: 90.20 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.08 Precision: 77.59 Recall: 88.24 \n\n-----svc - Train----------\nAUC: 98.51 Precision: 100.00 Recall: 97.03 \n\n-----svc - Validation-----\nAUC: 80.61 Precision: 89.74 Recall: 68.63 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.58 Precision: 88.00 Recall: 86.27 \n\n-----qda - Train----------\nAUC: 96.38 Precision: 96.52 Recall: 96.04 \n\n-----qda - Validation-----\nAUC: 89.60 Precision: 87.04 Recall: 92.16 \n\nFold 2\n\n-----knn - Train----------\nAUC: 88.19 Precision: 87.68 Recall: 88.12 \n\n-----knn - Validation-----\nAUC: 85.73 Precision: 84.62 Recall: 86.27 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.05 Precision: 78.00 Recall: 76.47 \n\n-----svc - Train----------\nAUC: 98.27 Precision: 100.00 Recall: 96.53 \n\n-----svc - Validation-----\nAUC: 77.56 Precision: 93.75 Recall: 58.82 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.46 Precision: 92.86 Recall: 76.47 \n\n-----qda - Train----------\nAUC: 95.69 Precision: 94.66 Recall: 96.53 \n\n-----qda - Validation-----\nAUC: 88.56 Precision: 88.24 Recall: 88.24 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.12 Precision: 83.93 Recall: 93.07 \n\n-----knn - Validation-----\nAUC: 89.29 Precision: 95.45 Recall: 82.35 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.39 Precision: 93.02 Recall: 78.43 \n\n-----svc - Train----------\nAUC: 98.51 Precision: 100.00 Recall: 97.03 \n\n-----svc - Validation-----\nAUC: 81.41 Precision: 97.06 Recall: 64.71 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.27 Precision: 97.56 Recall: 78.43 \n\n-----qda - Train----------\nAUC: 95.93 Precision: 95.12 Recall: 96.53 \n\n-----qda - Validation-----\nAUC: 90.27 Precision: 95.56 Recall: 84.31 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.82 Precision: 85.92 Recall: 87.19 \n\n-----knn - Validation-----\nAUC: 75.62 Precision: 76.60 Recall: 72.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.28 Precision: 88.64 Recall: 78.00 \n\n-----svc - Train----------\nAUC: 97.54 Precision: 100.00 Recall: 95.07 \n\n-----svc - Validation-----\nAUC: 75.06 Precision: 96.30 Recall: 52.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.17 Precision: 92.68 Recall: 76.00 \n\n-----qda - Train----------\nAUC: 95.68 Precision: 95.57 Recall: 95.57 \n\n-----qda - Validation-----\nAUC: 92.17 Precision: 93.75 Recall: 90.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.39 Precision: 84.09 Recall: 91.13 \n\n-----knn - Validation-----\nAUC: 84.79 Precision: 77.42 Recall: 96.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 78.79 Precision: 75.00 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 98.77 Precision: 100.00 Recall: 97.54 \n\n-----svc - Validation-----\nAUC: 86.17 Precision: 92.86 Recall: 78.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.34 Precision: 88.24 Recall: 90.00 \n\n-----qda - Train----------\nAUC: 95.23 Precision: 94.20 Recall: 96.06 \n\n-----qda - Validation-----\nAUC: 90.40 Precision: 87.04 Recall: 94.00 \n\nwheezy-copper-turtle-magic 44\n\nFold 1\n\n-----knn - Train----------\nAUC: 88.96 Precision: 97.14 Recall: 80.57 \n\n-----knn - Validation-----\nAUC: 84.51 Precision: 91.11 Recall: 77.36 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 76.73 Precision: 74.19 Recall: 86.79 \n\n-----svc - Train----------\nAUC: 98.94 Precision: 98.14 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 75.00 Precision: 68.83 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 99.74 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.62 Precision: 85.48 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.26 Precision: 98.57 Recall: 98.10 \n\n-----qda - Validation-----\nAUC: 91.86 Precision: 89.47 Recall: 96.23 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.24 Precision: 94.77 Recall: 77.25 \n\n-----knn - Validation-----\nAUC: 83.57 Precision: 90.91 Recall: 75.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.22 Precision: 86.27 Recall: 83.02 \n\n-----svc - Train----------\nAUC: 98.94 Precision: 98.14 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 77.08 Precision: 70.67 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 92.90 Precision: 91.07 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 98.47 Precision: 98.12 Recall: 99.05 \n\n-----qda - Validation-----\nAUC: 94.04 Precision: 94.34 Recall: 94.34 \n\nFold 3\n\n-----knn - Train----------\nAUC: 90.26 Precision: 90.95 Recall: 90.52 \n\n-----knn - Validation-----\nAUC: 85.37 Precision: 91.30 Recall: 79.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.14 Precision: 92.00 Recall: 86.79 \n\n-----svc - Train----------\nAUC: 98.42 Precision: 97.24 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 65.01 Precision: 61.90 Recall: 98.11 \n\n-----nusvc - Train----------\nAUC: 99.74 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 73.65 Precision: 68.92 Recall: 96.23 \n\n-----qda - Train----------\nAUC: 97.71 Precision: 97.20 Recall: 98.58 \n\n-----qda - Validation-----\nAUC: 97.17 Precision: 100.00 Recall: 94.34 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.89 Precision: 92.50 Recall: 87.68 \n\n-----knn - Validation-----\nAUC: 85.37 Precision: 91.30 Recall: 79.25 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.10 Precision: 82.00 Recall: 77.36 \n\n-----svc - Train----------\nAUC: 99.47 Precision: 99.06 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 68.09 Precision: 63.86 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.04 Precision: 77.94 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 98.00 Precision: 98.10 Recall: 98.10 \n\n-----qda - Validation-----\nAUC: 97.99 Precision: 98.11 Recall: 98.11 \n\nFold 5\n\n-----knn - Train----------\nAUC: 88.87 Precision: 90.73 Recall: 87.74 \n\n-----knn - Validation-----\nAUC: 84.86 Precision: 86.27 Recall: 84.62 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.99 Precision: 89.80 Recall: 84.62 \n\n-----svc - Train----------\nAUC: 99.21 Precision: 98.60 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 73.51 Precision: 68.00 Recall: 98.08 \n\n","name":"stdout"},{"output_type":"stream","text":"-----nusvc - Train----------\nAUC: 99.74 Precision: 99.53 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 84.25 Precision: 79.37 Recall: 96.15 \n\n-----qda - Train----------\nAUC: 98.97 Precision: 98.60 Recall: 99.53 \n\n-----qda - Validation-----\nAUC: 90.83 Precision: 90.57 Recall: 92.31 \n\nwheezy-copper-turtle-magic 45\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.50 Precision: 86.89 Recall: 87.75 \n\n-----knn - Validation-----\nAUC: 78.76 Precision: 80.85 Recall: 74.51 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.71 Precision: 82.00 Recall: 80.39 \n\n-----svc - Train----------\nAUC: 99.53 Precision: 99.03 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.74 Precision: 80.00 Recall: 94.12 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.42 Precision: 88.68 Recall: 92.16 \n\n-----qda - Train----------\nAUC: 96.64 Precision: 96.12 Recall: 97.06 \n\n-----qda - Validation-----\nAUC: 94.19 Precision: 95.92 Recall: 92.16 \n\nFold 2\n\n-----knn - Train----------\nAUC: 87.02 Precision: 86.41 Recall: 87.25 \n\n-----knn - Validation-----\nAUC: 82.69 Precision: 82.35 Recall: 82.35 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.72 Precision: 81.13 Recall: 84.31 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.51 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 84.76 Precision: 79.66 Recall: 92.16 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.53 Precision: 85.45 Recall: 92.16 \n\n-----qda - Train----------\nAUC: 96.89 Precision: 96.14 Recall: 97.55 \n\n-----qda - Validation-----\nAUC: 95.14 Precision: 97.92 Recall: 92.16 \n\nFold 3\n\n-----knn - Train----------\nAUC: 86.94 Precision: 89.89 Recall: 82.84 \n\n-----knn - Validation-----\nAUC: 84.50 Precision: 88.89 Recall: 78.43 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.72 Precision: 80.70 Recall: 90.20 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.22 Precision: 100.00 Recall: 78.43 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.23 Precision: 97.67 Recall: 82.35 \n\n-----qda - Train----------\nAUC: 96.40 Precision: 96.10 Recall: 96.57 \n\n-----qda - Validation-----\nAUC: 94.15 Precision: 97.87 Recall: 90.20 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.30 Precision: 85.45 Recall: 89.22 \n\n-----knn - Validation-----\nAUC: 80.87 Precision: 77.19 Recall: 86.27 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.59 Precision: 84.62 Recall: 86.27 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.57 Precision: 84.21 Recall: 94.12 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.42 Precision: 88.68 Recall: 92.16 \n\n-----qda - Train----------\nAUC: 97.59 Precision: 98.02 Recall: 97.06 \n\n-----qda - Validation-----\nAUC: 90.46 Precision: 87.27 Recall: 94.12 \n\nFold 5\n\n-----knn - Train----------\nAUC: 88.95 Precision: 88.35 Recall: 89.22 \n\n-----knn - Validation-----\nAUC: 79.93 Precision: 75.86 Recall: 86.27 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 88.49 Precision: 86.79 Recall: 90.20 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.51 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 89.51 Precision: 85.71 Recall: 94.12 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.46 Precision: 87.27 Recall: 94.12 \n\n-----qda - Train----------\nAUC: 97.83 Precision: 98.03 Recall: 97.55 \n\n-----qda - Validation-----\nAUC: 86.53 Precision: 86.27 Recall: 86.27 \n\nwheezy-copper-turtle-magic 46\n\nFold 1\n\n-----knn - Train----------\nAUC: 84.95 Precision: 87.57 Recall: 81.41 \n\n-----knn - Validation-----\nAUC: 84.10 Precision: 88.64 Recall: 78.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.12 Precision: 87.23 Recall: 82.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 94.00 Precision: 100.00 Recall: 88.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 95.02 Precision: 97.87 Recall: 92.00 \n\n-----qda - Train----------\nAUC: 96.74 Precision: 96.50 Recall: 96.98 \n\n-----qda - Validation-----\nAUC: 94.04 Precision: 95.83 Recall: 92.00 \n\nFold 2\n\n-----knn - Train----------\nAUC: 89.74 Precision: 92.02 Recall: 86.93 \n\n-----knn - Validation-----\nAUC: 85.00 Precision: 85.71 Recall: 84.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.00 Precision: 80.77 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----svc - Validation-----\nAUC: 84.00 Precision: 92.50 Recall: 74.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.00 Precision: 89.58 Recall: 86.00 \n\n-----qda - Train----------\nAUC: 98.00 Precision: 98.48 Recall: 97.49 \n\n-----qda - Validation-----\nAUC: 90.00 Precision: 87.04 Recall: 94.00 \n\nFold 3\n\n-----knn - Train----------\nAUC: 88.97 Precision: 93.79 Recall: 83.42 \n\n-----knn - Validation-----\nAUC: 79.00 Precision: 93.94 Recall: 62.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.00 Precision: 89.36 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 79.00 Precision: 93.94 Recall: 62.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.00 Precision: 97.56 Recall: 80.00 \n\n-----qda - Train----------\nAUC: 96.25 Precision: 95.54 Recall: 96.98 \n\n-----qda - Validation-----\nAUC: 94.00 Precision: 95.83 Recall: 92.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 87.97 Precision: 92.66 Recall: 82.41 \n\n-----knn - Validation-----\nAUC: 86.00 Precision: 87.50 Recall: 84.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.00 Precision: 80.39 Recall: 82.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 90.00 Precision: 95.45 Recall: 84.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.00 Precision: 88.68 Recall: 94.00 \n\n-----qda - Train----------\nAUC: 97.25 Precision: 97.00 Recall: 97.49 \n\n-----qda - Validation-----\nAUC: 90.00 Precision: 90.00 Recall: 90.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.52 Precision: 91.58 Recall: 87.00 \n\n-----knn - Validation-----\nAUC: 84.82 Precision: 86.96 Recall: 81.63 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.76 Precision: 86.05 Recall: 75.51 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 86.82 Precision: 90.91 Recall: 81.63 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 99.50 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.96 Precision: 87.04 Recall: 95.92 \n\n-----qda - Train----------\nAUC: 96.26 Precision: 96.02 Recall: 96.50 \n\n-----qda - Validation-----\nAUC: 93.94 Precision: 93.88 Recall: 93.88 \n\nwheezy-copper-turtle-magic 47\n\nFold 1\n\n-----knn - Train----------\nAUC: 89.73 Precision: 92.20 Recall: 87.50 \n\n-----knn - Validation-----\nAUC: 83.09 Precision: 87.76 Recall: 78.18 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 80.91 Precision: 81.82 Recall: 81.82 \n\n-----svc - Train----------\nAUC: 99.25 Precision: 98.63 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 75.27 Precision: 70.27 Recall: 94.55 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.36 Precision: 83.61 Recall: 92.73 \n\n","name":"stdout"},{"output_type":"stream","text":"-----qda - Train----------\nAUC: 98.57 Precision: 99.07 Recall: 98.15 \n\n-----qda - Validation-----\nAUC: 88.55 Precision: 89.09 Recall: 89.09 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.58 Precision: 88.15 Recall: 85.71 \n\n-----knn - Validation-----\nAUC: 79.04 Precision: 83.33 Recall: 74.07 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 75.89 Precision: 76.36 Recall: 77.78 \n\n-----svc - Train----------\nAUC: 96.48 Precision: 93.94 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 69.07 Precision: 63.86 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.07 Precision: 84.13 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.11 Precision: 99.06 Recall: 97.24 \n\n-----qda - Validation-----\nAUC: 94.15 Precision: 92.86 Recall: 96.30 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.64 Precision: 87.05 Recall: 89.86 \n\n-----knn - Validation-----\nAUC: 86.22 Precision: 82.26 Recall: 94.44 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.67 Precision: 81.82 Recall: 83.33 \n\n-----svc - Train----------\nAUC: 96.98 Precision: 94.76 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 62.07 Precision: 58.89 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 76.15 Precision: 70.27 Recall: 96.30 \n\n-----qda - Train----------\nAUC: 97.63 Precision: 98.59 Recall: 96.77 \n\n-----qda - Validation-----\nAUC: 94.30 Precision: 96.15 Recall: 92.59 \n\nFold 4\n\n-----knn - Train----------\nAUC: 86.53 Precision: 87.44 Recall: 86.64 \n\n-----knn - Validation-----\nAUC: 83.81 Precision: 87.76 Recall: 79.63 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 87.52 Precision: 88.68 Recall: 87.04 \n\n-----svc - Train----------\nAUC: 97.74 Precision: 96.02 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 69.00 Precision: 63.53 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 85.07 Precision: 79.10 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.39 Precision: 100.00 Recall: 96.77 \n\n-----qda - Validation-----\nAUC: 94.30 Precision: 96.15 Recall: 92.59 \n\nFold 5\n\n-----knn - Train----------\nAUC: 89.41 Precision: 89.50 Recall: 90.32 \n\n-----knn - Validation-----\nAUC: 87.02 Precision: 83.61 Recall: 94.44 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.43 Precision: 85.19 Recall: 85.19 \n\n-----svc - Train----------\nAUC: 96.75 Precision: 94.35 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 63.27 Precision: 60.00 Recall: 100.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 87.85 Precision: 82.81 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 97.41 Precision: 98.58 Recall: 96.31 \n\n-----qda - Validation-----\nAUC: 92.31 Precision: 94.23 Recall: 90.74 \n\nwheezy-copper-turtle-magic 48\n\nFold 1\n\n-----knn - Train----------\nAUC: 87.19 Precision: 86.55 Recall: 88.94 \n\n-----knn - Validation-----\nAUC: 87.87 Precision: 88.89 Recall: 87.27 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.29 Precision: 81.82 Recall: 81.82 \n\n-----svc - Train----------\nAUC: 99.51 Precision: 99.09 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 87.76 Precision: 86.21 Recall: 90.91 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.50 Precision: 89.66 Recall: 94.55 \n\n-----qda - Train----------\nAUC: 97.15 Precision: 96.80 Recall: 97.70 \n\n-----qda - Validation-----\nAUC: 95.35 Precision: 96.30 Recall: 94.55 \n\nFold 2\n\n-----knn - Train----------\nAUC: 86.32 Precision: 87.68 Recall: 85.25 \n\n-----knn - Validation-----\nAUC: 83.32 Precision: 87.76 Recall: 78.18 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.19 Precision: 89.80 Recall: 80.00 \n\n-----svc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 85.94 Precision: 85.71 Recall: 87.27 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 88.78 Precision: 89.09 Recall: 89.09 \n\n-----qda - Train----------\nAUC: 96.43 Precision: 95.91 Recall: 97.24 \n\n-----qda - Validation-----\nAUC: 92.62 Precision: 96.08 Recall: 89.09 \n\nFold 3\n\n-----knn - Train----------\nAUC: 87.15 Precision: 85.04 Recall: 91.28 \n\n-----knn - Validation-----\nAUC: 82.80 Precision: 77.27 Recall: 94.44 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 86.65 Precision: 82.26 Recall: 94.44 \n\n-----svc - Train----------\nAUC: 97.57 Precision: 95.61 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 76.99 Precision: 70.27 Recall: 96.30 \n\n-----nusvc - Train----------\nAUC: 99.76 Precision: 99.54 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 83.73 Precision: 77.61 Recall: 96.30 \n\n-----qda - Train----------\nAUC: 97.63 Precision: 97.27 Recall: 98.17 \n\n-----qda - Validation-----\nAUC: 91.49 Precision: 90.91 Recall: 92.59 \n\nFold 4\n\n-----knn - Train----------\nAUC: 89.59 Precision: 88.50 Recall: 91.74 \n\n-----knn - Validation-----\nAUC: 76.80 Precision: 72.73 Recall: 88.89 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.75 Precision: 79.66 Recall: 87.04 \n\n-----svc - Train----------\nAUC: 99.03 Precision: 98.20 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 76.53 Precision: 69.74 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 99.52 Precision: 99.09 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 86.33 Precision: 80.30 Recall: 98.15 \n\n-----qda - Train----------\nAUC: 98.33 Precision: 97.74 Recall: 99.08 \n\n-----qda - Validation-----\nAUC: 83.66 Precision: 81.36 Recall: 88.89 \n\nFold 5\n\n-----knn - Train----------\nAUC: 87.06 Precision: 87.56 Recall: 87.16 \n\n-----knn - Validation-----\nAUC: 86.71 Precision: 88.46 Recall: 85.19 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 89.49 Precision: 89.09 Recall: 90.74 \n\n-----svc - Train----------\nAUC: 99.03 Precision: 98.20 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 88.29 Precision: 82.81 Recall: 98.15 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.20 Precision: 84.38 Recall: 100.00 \n\n-----qda - Train----------\nAUC: 96.92 Precision: 96.38 Recall: 97.71 \n\n-----qda - Validation-----\nAUC: 94.17 Precision: 91.38 Recall: 98.15 \n\nwheezy-copper-turtle-magic 49\n\nFold 1\n\n-----knn - Train----------\nAUC: 86.50 Precision: 88.42 Recall: 83.58 \n\n-----knn - Validation-----\nAUC: 83.43 Precision: 88.64 Recall: 76.47 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 82.58 Precision: 78.95 Recall: 88.24 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.00 \n\n-----svc - Validation-----\nAUC: 85.31 Precision: 97.37 Recall: 72.55 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 89.23 Precision: 97.62 Recall: 80.39 \n\n-----qda - Train----------\nAUC: 98.04 Precision: 98.01 Recall: 98.01 \n\n-----qda - Validation-----\nAUC: 93.17 Precision: 95.83 Recall: 90.20 \n\nFold 2\n\n-----knn - Train----------\nAUC: 84.46 Precision: 90.59 Recall: 76.62 \n\n-----knn - Validation-----\nAUC: 82.41 Precision: 92.31 Recall: 70.59 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 81.56 Precision: 80.77 Recall: 82.35 \n\n-----svc - Train----------\nAUC: 99.25 Precision: 100.00 Recall: 98.51 \n\n-----svc - Validation-----\nAUC: 76.49 Precision: 96.55 Recall: 54.90 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----nusvc - Validation-----\nAUC: 84.33 Precision: 97.30 Recall: 70.59 \n\n-----qda - Train----------\nAUC: 98.53 Precision: 98.51 Recall: 98.51 \n\n-----qda - Validation-----\nAUC: 94.19 Precision: 92.45 Recall: 96.08 \n\n","name":"stdout"},{"output_type":"stream","text":"Fold 3\n\n-----knn - Train----------\nAUC: 87.49 Precision: 91.26 Recall: 82.67 \n\n-----knn - Validation-----\nAUC: 84.19 Precision: 88.64 Recall: 78.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 84.31 Precision: 84.00 Recall: 84.00 \n\n-----svc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----svc - Validation-----\nAUC: 92.23 Precision: 88.89 Recall: 96.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 91.12 Precision: 93.62 Recall: 88.00 \n\n-----qda - Train----------\nAUC: 97.81 Precision: 97.54 Recall: 98.02 \n\n-----qda - Validation-----\nAUC: 94.15 Precision: 92.31 Recall: 96.00 \n\nFold 4\n\n-----knn - Train----------\nAUC: 85.74 Precision: 92.35 Recall: 77.72 \n\n-----knn - Validation-----\nAUC: 84.15 Precision: 90.48 Recall: 76.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 85.23 Precision: 87.23 Recall: 82.00 \n\n-----svc - Train----------\nAUC: 98.76 Precision: 100.00 Recall: 97.52 \n\n-----svc - Validation-----\nAUC: 76.12 Precision: 90.62 Recall: 58.00 \n\n-----nusvc - Train----------\nAUC: 99.75 Precision: 100.00 Recall: 99.50 \n\n-----nusvc - Validation-----\nAUC: 86.15 Precision: 90.91 Recall: 80.00 \n\n-----qda - Train----------\nAUC: 98.53 Precision: 99.00 Recall: 98.02 \n\n-----qda - Validation-----\nAUC: 94.19 Precision: 90.74 Recall: 98.00 \n\nFold 5\n\n-----knn - Train----------\nAUC: 85.54 Precision: 89.07 Recall: 80.69 \n\n-----knn - Validation-----\nAUC: 79.42 Precision: 78.43 Recall: 80.00 \n\n-----mlp - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----mlp - Validation-----\nAUC: 79.23 Precision: 85.37 Recall: 70.00 \n\n-----svc - Train----------\nAUC: 99.50 Precision: 100.00 Recall: 99.01 \n\n-----svc - Validation-----\nAUC: 84.04 Precision: 97.22 Recall: 70.00 \n\n-----nusvc - Train----------\nAUC: 100.00 Precision: 100.00 Recall: 100.00 \n\n-----nusvc - Validation-----\nAUC: 90.08 Precision: 95.45 Recall: 84.00 \n\n-----qda - Train----------\nAUC: 97.80 Precision: 98.01 Recall: 97.52 \n\n-----qda - Validation-----\nAUC: 96.12 Precision: 94.23 Recall: 98.00 \n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble models\n\nHere you can ensemble any combination of models, and give the desired weight for each one."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['preds_svcs'] = (train['preds_svc'] * 0.5) + (train['preds_nusvc'] * 0.5)\ntest['target_svcs'] = (test['target_svc'] * 0.5) + (test['target_nusvc'] * 0.5)\n\ntrain['preds_avg'] = (train['preds_knn'] * 0.2) + (train['preds_mlp'] * 0.2) + (train['preds_svc'] * 0.2) + (train['preds_nusvc'] * 0.2) + (train['preds_qda'] * 0.2)\ntest['target_avg'] = (test['target_knn'] * 0.2) + (test['target_mlp'] * 0.2) + (test['target_svc'] * 0.2) + (test['target_nusvc'] * 0.2) + (test['target_qda'] * 0.2)\n\ntrain['preds_avg2'] = (train['preds_knn'] * 0.2) + (train['preds_mlp'] * 0.05) + (train['preds_svc'] * 0.05) + (train['preds_nusvc'] * 0.7)\ntest['target_avg2'] = (test['target_knn'] * 0.2) + (test['target_mlp'] * 0.05) + (test['target_svc'] * 0.05) + (test['target_nusvc'] * 0.7)\n","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model evaluation\n## Confusion matrix (averaged model)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.subplots(1, 1, figsize=(16, 5), sharex=True)\ntrain_cnf_matrix = confusion_matrix(train['target'], [np.round(x) for x in train['preds_avg']])\ntrain_cnf_matrix_norm = train_cnf_matrix / train_cnf_matrix.sum(axis=1)[:, np.newaxis]\ntrain_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=[0, 1], columns=[0, 1])\nsns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x360 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix (knn model)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.subplots(1, 1, figsize=(16, 5), sharex=True)\ntrain_cnf_matrix = confusion_matrix(train['target'], [np.round(x) for x in train['preds_knn']])\ntrain_cnf_matrix_norm = train_cnf_matrix / train_cnf_matrix.sum(axis=1)[:, np.newaxis]\ntrain_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=[0, 1], columns=[0, 1])\nsns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x360 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix (SVC model)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.subplots(1, 1, figsize=(16, 5), sharex=True)\ntrain_cnf_matrix = confusion_matrix(train['target'], [np.round(x) for x in train['preds_svc']])\ntrain_cnf_matrix_norm = train_cnf_matrix / train_cnf_matrix.sum(axis=1)[:, np.newaxis]\ntrain_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=[0, 1], columns=[0, 1])\nsns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x360 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Metrics ROC AUC"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('KNN AUC %.2f' % roc_auc_score(train['target'], train['preds_knn']))\nprint('MLP AUC %.2f' % roc_auc_score(train['target'], train['preds_mlp']))\nprint('SVC AUC %.2f' % roc_auc_score(train['target'], train['preds_svc']))\nprint('NuSVC AUC %.2f' % roc_auc_score(train['target'], train['preds_nusvc']))\nprint('QDA AUC %.2f' % roc_auc_score(train['target'], train['preds_qda']))\nprint('SVCs AUC %.2f' % roc_auc_score(train['target'], train['preds_svcs']))\nprint('Averaged AUC %.2f' % roc_auc_score(train['target'], train['preds_avg']))\nprint('Averaged 2 AUC %.2f' % roc_auc_score(train['target'], train['preds_avg2']))","execution_count":9,"outputs":[{"output_type":"stream","text":"KNN AUC 0.50\nMLP AUC 0.50\nSVC AUC 0.50\nNuSVC AUC 0.50\nQDA AUC 0.50\nSVCs AUC 0.50\nAveraged AUC 0.50\nAveraged 2 AUC 0.50\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Test set with all models predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['id', 'target_avg', 'target_avg2', 'target_svcs', 'target_knn', 'target_mlp', 'target_svc', 'target_nusvc', 'target_qda']].head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                 id     ...      target_qda\n0  1c13f2701648e0b0d46d8a2a5a131a53     ...        0.000000\n1  ba88c155ba898fc8b5099893036ef205     ...        0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77     ...        0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0     ...        0.168574\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7     ...        0.000000\n\n[5 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target_avg</th>\n      <th>target_avg2</th>\n      <th>target_svcs</th>\n      <th>target_knn</th>\n      <th>target_mlp</th>\n      <th>target_svc</th>\n      <th>target_nusvc</th>\n      <th>target_qda</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.377118</td>\n      <td>0.556601</td>\n      <td>0.606916</td>\n      <td>0.470588</td>\n      <td>0.032597</td>\n      <td>0.598199</td>\n      <td>0.615634</td>\n      <td>0.168574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Test predictions\nNow you can output predictions for each individual model and the ensembled models as well.\n\n#### Averaged models submission"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"submission = test[['id', 'target_avg']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_avg.csv', index=False)\nsubmission.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.377118\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.377118</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Averaged 2 models submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test[['id', 'target_avg2']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_avg2.csv', index=False)\nsubmission.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.556601\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.556601</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### SVCs models submission"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = test[['id', 'target_svcs']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_svcs.csv', index=False)\nsubmission.head()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.606916\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.606916</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### KNN model submission"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = test[['id', 'target_knn']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_knn.csv', index=False)\nsubmission.head()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.470588\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.470588</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### KNN model submission"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = test[['id', 'target_mlp']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_mlp.csv', index=False)\nsubmission.head()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.032597\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.032597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### SVC model submission"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = test[['id', 'target_svc']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_svc.csv', index=False)\nsubmission.head()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.598199\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.598199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### NuSVC model submission"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = test[['id', 'target_nusvc']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_nusvc.csv', index=False)\nsubmission.head()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.615634\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.615634</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### QDA model submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test[['id', 'target_qda']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_qda.csv', index=False)\nsubmission.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"                                 id    target\n0  1c13f2701648e0b0d46d8a2a5a131a53  0.000000\n1  ba88c155ba898fc8b5099893036ef205  0.000000\n2  7cbab5cea99169139e7e6d8ff74ebb77  0.000000\n3  ca820ad57809f62eb7b4d13f5d4371a0  0.168574\n4  7baaf361537fbd8a1aaa2c97a6d4ccc7  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1c13f2701648e0b0d46d8a2a5a131a53</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ba88c155ba898fc8b5099893036ef205</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7cbab5cea99169139e7e6d8ff74ebb77</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ca820ad57809f62eb7b4d13f5d4371a0</td>\n      <td>0.168574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7baaf361537fbd8a1aaa2c97a6d4ccc7</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}