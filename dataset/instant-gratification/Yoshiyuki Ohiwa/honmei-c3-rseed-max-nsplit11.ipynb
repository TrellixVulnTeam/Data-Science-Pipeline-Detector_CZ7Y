{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.offline import init_notebook_mode, iplot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.covariance import GraphicalLasso\n\nfrom scipy import linalg\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom matplotlib import colors\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.decomposition import PCA\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, ShuffleSplit\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.pipeline import Pipeline\nfrom tqdm import tqdm_notebook\nimport warnings\nimport multiprocessing\nfrom scipy.optimize import minimize  \nimport time\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom sklearn.mixture import GaussianMixture\nimport warnings\nwarnings.simplefilter('ignore')\ninit_notebook_mode()\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#\n# QDA (Grid Search) and create oof, preds\n#\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\nparams = [{'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n\n# 512 models\nreg_params = np.zeros(512)\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=11, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        qda = QuadraticDiscriminantAnalysis()\n        clf = GridSearchCV(qda, params, cv=4)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        reg_params[i] = clf.best_params_['reg_param']\n        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc = roc_auc_score(train['target'], oof)\nprint(f'AUC: {auc:.5}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for itr in range(4):\n    test['target'] = preds\n    test.loc[test['target'] > 0.955, 'target'] = 1 # initial 94\n    test.loc[test['target'] < 0.045, 'target'] = 0 # initial 06\n    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n    print(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\n    new_train.loc[oof > 0.995, 'target'] = 1 # initial 98\n    new_train.loc[oof < 0.005, 'target'] = 0 # initial 02\n    preds = np.zeros(len(test))\n    for i in tqdm_notebook(range(512)):\n\n        train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n        test2 = test[test['wheezy-copper-turtle-magic']==i]\n        idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n        idx2 = test2.index\n        train2.reset_index(drop=True,inplace=True)\n\n        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n        pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n        data2 = pipe.fit_transform(data[cols])\n        train3 = data2[:train2.shape[0]]\n        test3 = data2[train2.shape[0]:]\n\n        skf = StratifiedKFold(n_splits=11, random_state=time.time)\n        for train_index, test_index in skf.split(train2, train2['target']):\n            oof_test_index = [t for t in test_index if t < len(idx1)]\n            \n            clf = QuadraticDiscriminantAnalysis(reg_params[i])\n            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n            if len(oof_test_index) > 0:\n                oof[idx1[oof_test_index]] = clf.predict_proba(train3[oof_test_index,:])[:,1]\n            preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n    auc = roc_auc_score(train['target'], oof)\n    print(f'AUC: {auc:.5}')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = test.copy()\nt['target'] = preds\nt.loc[t['target'] > 0.955, 'target'] = 1 # initial 94\nt.loc[t['target'] < 0.045, 'target'] = 0 # initial 06\nusefull_test = t[(t['target'] == 1) | (t['target'] == 0)]\nnew_train = pd.concat([train, usefull_test]).reset_index(drop=True)\nprint(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\nnew_train.loc[oof > 0.995, 'target'] = 1 # initial 98\nnew_train.loc[oof < 0.005, 'target'] = 0 # initial 02\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#\n# clustering evaluation\n#\nrandom_state=42\nCLUSTER_NUM = 3\n\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# for i in tqdm_notebook([100,101,102]):\nfor i in tqdm_notebook(range(512)):\n    train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n    # test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index;\n    # idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n    # data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    # data2 = pipe.fit_transform(data[cols])\n    # train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    \n    #\n    # ここから target ごとに pipe したものから 教師なし分類a\n    #\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n\n    X_train_0_df = train2[train2['target'] == 0]\n    X_train_1_df = train2[train2['target'] == 1]\n    X_train_0 = sel.transform(X_train_0_df[cols])\n    X_train_1 = sel.transform(X_train_1_df[cols])\n\n\n    # ----- X_train_0 -----\n    var_r_list = []\n    for r in range(42,52):\n        gm = GaussianMixture(n_components=CLUSTER_NUM,\n                             init_params='kmeans',\n                             covariance_type='full', \n                             max_iter=100,\n                             n_init=1,\n                             random_state=r,\n                        )\n        gm.fit(X_train_0)\n        X_train_0_df['cluster'] = gm.predict(X_train_0)\n        var = X_train_0_df.cluster.value_counts().var()\n        var_r_list.append((var, r))\n\n    _, r = min(var_r_list)\n    gm = GaussianMixture(n_components=CLUSTER_NUM,\n                         init_params='kmeans',\n                         covariance_type='full', \n                         max_iter=100,\n                         n_init=1,\n                         random_state=r,\n                        )\n    gm.fit(X_train_0)\n    X_train_0_df['cluster'] = gm.predict(X_train_0)\n    means0 = gm.means_\n    co0 = gm.covariances_\n\n    # ----- X_train_1 -----\n    var_r_list = []\n    for r in range(42,52):\n        gm = GaussianMixture(n_components=CLUSTER_NUM,\n                             init_params='kmeans',\n                             covariance_type='full', \n                             max_iter=100,\n                             n_init=1,\n                             random_state=r,\n                        )\n        gm.fit(X_train_1)\n        X_train_1_df['cluster'] = gm.predict(X_train_1)\n        var = X_train_1_df.cluster.value_counts().var()\n        var_r_list.append((var, r))\n\n    _, r = min(var_r_list)\n    gm = GaussianMixture(n_components=CLUSTER_NUM,\n                         init_params='kmeans',\n                         covariance_type='full', \n                         max_iter=100,\n                         n_init=1,\n                         random_state=r,\n                        )\n    gm.fit(X_train_1)\n    X_train_1_df['cluster'] = CLUSTER_NUM + gm.predict(X_train_1)\n    means1 = gm.means_\n    co1 = gm.covariances_\n    \n    # ----- concat -----\n\n    X_train_with_c_df = pd.concat([X_train_0_df, X_train_1_df])\n    means01 = np.concatenate((means0,means1))\n    co01 = np.concatenate((co0,co1))\n    \n    # plt.figure(figsize=(16,6))\n    # plt.subplot(1,2,1)\n    # plt.hist(X_train_with_c_df.cluster)\n    # plt.title('cluster distribution')\n\n    \n    #\n    # ----- gmm fitting for all data !!!! \n    #\n    gm2 = GaussianMixture(n_components=CLUSTER_NUM * 2,\n                          # init_params='random',\n                          covariance_type='full', \n                          max_iter=100,\n                          n_init=1,\n                          means_init=means01,\n                          precisions_init=np.linalg.inv(co01),\n                         random_state=random_state,\n                          )\n    # ここから gmm コピペ\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n\n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=random_state, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        gm2.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n        # oof[idx1[test_index]] = gm2.predict_proba(train3[test_index,:])[:,0]\n        oof[idx1[test_index]] = np.array([sum(x[CLUSTER_NUM:]) for x in gm2.predict_proba(train3[test_index,:])])\n        preds[idx2] += np.array([sum(x[CLUSTER_NUM:]) for x in gm2.predict_proba(test3)]) / skf.n_splits\n\n\n    \"\"\"\n    X_train_with_c = pipe.fit_transform(X_train_with_c_df[cols])\n    gm2.fit(X_train_with_c)\n    print('iter: ', gm2.n_iter_)\n\n    oof_cluster = gm2.predict(X_train_with_c)\n    plt.subplot(1,2,2)\n    plt.hist(oof_cluster)\n\n    print(X_train_with_c_df.cluster.values[:10])\n    print(oof_cluster[:10])\n    print(\"cluster accuracy: \",\n        len(X_train_with_c_df[X_train_with_c_df['cluster'] == oof_cluster]) / len(X_train_with_c_df))\n\n    oof = np.array([0 if x < CLUSTER_NUM else 1 for x in oof_cluster])\n    auc = roc_auc_score(X_train_with_c_df['target'],oof)\n    print('GMM scores CV =',round(auc,5))\n\n    clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n    clf.fit(X_train_with_c, X_train_with_c_df['target'])\n    oof = clf.predict(X_train_with_c)\n    auc = roc_auc_score(X_train_with_c_df['target'],oof)\n    print('QDA scores CV =',round(auc,5))\n    \"\"\"\n\n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof)\nprint('QDA scores CV =',round(auc,5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = preds\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}