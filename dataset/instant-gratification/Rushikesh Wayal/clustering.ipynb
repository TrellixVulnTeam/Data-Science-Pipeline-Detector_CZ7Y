{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm, tqdm_notebook\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport sympy \nfrom sklearn import svm, neighbors, linear_model, neural_network\nfrom xgboost import XGBClassifier\nfrom sklearn.covariance import *\nfrom sklearn.utils.validation import check_random_state\nfrom sklearn.mixture import *\nfrom sklearn.cluster import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsub = pd.read_csv('../input/sample_submission.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dist(array, centre):\n    x=float(0)\n    for i in range(len(array)):\n        x += ((array[i]-centre[i])*(array[i]-centre[i]))\n    return x\n\ndef get_c(data):\n    data.drop('labels', axis=1, inplace=True)\n    centre = [1]*data.shape[1]\n    for i in range(data.shape[1]):\n        if data[i].mean() < 0:\n            centre[i] = -1\n    return (centre)\n\ndef my_min(a, b, c):\n#     return 1\n    if a<b:\n        if a<c: return a\n        return c\n    if b<c: return b\n    return c\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify(data, val, test, y):\n    data = pd.DataFrame(train3)\n    data['target'] = y\n    zero = data[data['target'] == 1]\n    one = data[data['target'] == 0]\n    zero.drop('target', axis=1, inplace=True)\n    one.drop('target', axis=1, inplace=True)\n    \n    clf = KMeans(n_clusters=3)\n    labels = clf.fit_predict(zero)\n    zero['labels'] = labels\n    zero_0 = (zero[zero['labels'] == 0])\n    zero_1 = (zero[zero['labels'] == 1])\n    zero_2 = (zero[zero['labels'] == 2])\n    \n    clf = KMeans(n_clusters=3)\n    labels = clf.fit_predict(one)\n    one['labels'] = labels\n    one_0 = (one[one['labels'] == 0])\n    one_1 = (one[one['labels'] == 1])\n    one_2 = (one[one['labels'] == 2])\n    \n    c_z_0 = get_c(zero_0)\n    c_z_1 = get_c(zero_1)\n    c_z_2 = get_c(zero_2)\n    \n    c_o_0 = get_c(one_0)\n    c_o_1 = get_c(one_1)\n    c_o_2 = get_c(one_2)\n    \n    pred_val = [0]*val.shape[0]\n    for i in range(val.shape[0]):\n        array = val.loc[i]\n        dist0_0 = dist(array, c_z_0)\n        dist0_1 = dist(array, c_z_1)\n        dist0_2 = dist(array, c_z_2)\n        \n        dist1_0 = dist(array, c_o_0)\n        dist1_1 = dist(array, c_o_1)\n        dist1_2 = dist(array, c_o_2)\n\n        \n        aggr = (dist0_0+dist0_1+dist0_2  +dist1_0+dist1_1+dist1_2)/3\n#         dist1 = my_min(dist1_0, dist1_1, dist1_2, dist1_3)\n#         dist0 = my_min(dist0_0, dist0_1, dist0_2, dist0_3)\n        \n        dist1 = (dist1_0+dist1_1+dist1_2) / 3\n        dist0 = (dist0_0+dist0_1+dist0_2) / 3\n        pred_val[i] = 1-1/np.exp(dist1/aggr)\n        \n    pred_test = [0]*test.shape[0]\n    for i in range(test.shape[0]):\n        array = test.loc[i]\n        dist0_0 = dist(array, c_z_0)\n        dist0_1 = dist(array, c_z_1)\n        dist0_2 = dist(array, c_z_2)\n        \n        dist1_0 = dist(array, c_o_0)\n        dist1_1 = dist(array, c_o_1)\n        dist1_2 = dist(array, c_o_2)\n\n        \n        aggr = (dist0_0+dist0_1+dist0_2  +dist1_0+dist1_1+dist1_2)/4\n#         dist1 = my_min(dist1_0, dist1_1, dist1_2, dist1_3)\n#         dist0 = my_min(dist0_0, dist0_1, dist0_2, dist0_3)\n        \n        dist1 = (dist1_0+dist1_1+dist1_2) / 3\n        dist0 = (dist0_0+dist0_1+dist0_2) / 3\n        \n        pred_test[i] = 1-1/np.exp(dist1/aggr)\n\n    return np.array(pred_val), np.array(pred_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(train))\npreds = np.zeros(len(test))\ncols = [c for c in train.columns if c not in ['id', 'target']]\n\n\nfor k in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==k]\n    test2 = test[test['wheezy-copper-turtle-magic']==k]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = VarianceThreshold(threshold=2).fit_transform(data[cols])\n\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n\n    for i, (train_index, test_index) in enumerate(skf.split(train3, train2['target'])):\n\n\n        oof[idx1[test_index]], test_pred = classify(pd.DataFrame(train3[train_index,:]), pd.DataFrame(train3[test_index,:]), pd.DataFrame(test3), train2.loc[train_index]['target'])\n        \n        preds[idx2] += test_pred / skf.n_splits\n\n        print(roc_auc_score(train2.loc[test_index]['target'], oof[idx1[test_index]]))\n    \n    if k==5: break\n\nauc = roc_auc_score(train['target'], oof)\nprint(f'AUC: {auc:.5}')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}