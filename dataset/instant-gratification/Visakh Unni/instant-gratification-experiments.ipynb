{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# import the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the dataset\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print shape of datasets\nprint('Shape of the train dataset : ', train_data.shape)\nprint('Shape of the test dataset : ', test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First things first, Let's handle the missing values from dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check that if there is missing values in the dataset\nprint('Missing Values in Train Dataset : ', train_data.isnull().sum().sum())\nprint('Missing Values in Test Dataset : ', test_data.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Distribution Of Classes In Label Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.target.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graph it is clear that there is no class imbalance problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are 258 attributes in the train dataset, which is infact not desirable\n# we need to select only a subset of columns (dimensionality reduction)\n# for that let's check that if there strong correlation exist between them\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = train_data.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# handlng the categorical features\ntrain_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"]).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train_data['target']\ntrain_data = train_data.drop(['id','target'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Which shows that there is no correlation at all. Hmm, so what are the hidden patterns that I'm looking at!\n"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us try a logistic regression model on the dataset\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_data, labels, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, y_pred)\nprint('ROC AUC for LR =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"It is ~ 0.5, which says the model will predict an ouput with 50% confidence. <br>\nInfact a random value generator can perform better than this. <br>\nWhich shows that this is the worst case that can happen. <br>\nWhy do we get such a kind of result ? Does it have anything to do with the results of the correlation matrix ?"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### Step back and Start again"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['target'] = labels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the medians of columns when we group the data by 'target' feature\ntarget_medians = train_data.groupby(\"target\").median()\ntarget_medians","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's calculate the difference b/w row-1 and row-2\nsorted_target_distance = np.abs(target_medians.iloc[0]-target_medians.iloc[1]).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_target_distance.head() # they do posses large difference b/w the medians","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_target_distance.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Zero! What's happening here?"},{"metadata":{},"cell_type":"markdown","source":"To understand the effect of these distribution let us comapare the 2nd attribute and last one to the attribute in 1st solution."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2,figsize=(20,10))\nsns.distplot(train_data.loc[train_data.target==0, \"wheezy-myrtle-mandrill-entropy\"], color=\"Blue\", ax=ax[0,0])\nsns.distplot(train_data.loc[train_data.target==1, \"wheezy-myrtle-mandrill-entropy\"], color=\"Red\", ax=ax[0,0])\nsns.distplot(train_data.loc[train_data.target==0, \"wheezy-copper-turtle-magic\"], color=\"Blue\", ax=ax[0,1])\nsns.distplot(train_data.loc[train_data.target==1, \"wheezy-copper-turtle-magic\"], color=\"Red\", ax=ax[0,1])\nax[1,0].scatter(train_data[\"wheezy-myrtle-mandrill-entropy\"].values,\n                train_data[\"skanky-carmine-rabbit-contributor\"].values, c=train_data.target.values,\n                cmap=\"coolwarm\", s=1, alpha=0.5)\nax[1,0].set_xlabel(\"wheezy-myrtle-mandrill-entropy\")\nax[1,0].set_ylabel(\"skanky-carmine-rabbit-contributor\")\nax[1,1].scatter(train_data[\"wheezy-myrtle-mandrill-entropy\"].values,\n                train_data[\"wheezy-copper-turtle-magic\"].values, c=train_data.target.values,\n                cmap=\"coolwarm\", s=1, alpha=0.5)\nax[1,1].set_xlabel(\"wheezy-myrtle-mandrill-entropy\")\nax[1,1].set_ylabel(\"wheezy-copper-turtle-magic\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 2nd and 4th graph shows that the distribution of <b>wheezy-copper-turtle-magic</b> is spread across the space around it."},{"metadata":{},"cell_type":"markdown","source":"### The effect of 'wheezy-copper-turtle-magic'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# consider the distribution of first three attributes from above list\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfeat1 = \"wheezy-myrtle-mandrill-entropy\"\nfeat2 = \"skanky-carmine-rabbit-contributor\"\nfeat3 = \"thirsty-carmine-corgi-ordinal\"\n\nN = 10000\n\ntrace1 = go.Scatter3d(\n    x=train_data[feat1].values[0:N], \n    y=train_data[feat2].values[0:N],\n    z=train_data[feat3].values[0:N],\n    mode='markers',\n    marker=dict(\n        color=train_data.target.values[0:N],\n        colorscale = \"Jet\",\n        opacity=0.3,\n        size=2\n    )\n)\n\nfigure_data = [trace1]\nlayout = go.Layout(\n    title = 'The turtle place',\n    scene = dict(\n        xaxis = dict(title=feat1),\n        yaxis = dict(title=feat2),\n        zaxis = dict(title=feat3),\n    ),\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0\n    ),\n    showlegend=True\n)\n\nfig = go.Figure(data=figure_data, layout=layout)\npy.iplot(fig, filename='simple-3d-scatter')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# consider the distribution of first two attributes and the last one 'wheezy-copper-turtle-magic' from above list\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfeat1 = \"wheezy-myrtle-mandrill-entropy\"\nfeat2 = \"skanky-carmine-rabbit-contributor\"\nfeat3 = \"wheezy-copper-turtle-magic\"\n\nN = 10000\n\ntrace1 = go.Scatter3d(\n    x=train_data[feat1].values[0:N], \n    y=train_data[feat2].values[0:N],\n    z=train_data[feat3].values[0:N],\n    mode='markers',\n    marker=dict(\n        color=train_data.target.values[0:N],\n        colorscale = \"Jet\",\n        opacity=0.3,\n        size=2\n    )\n)\n\nfigure_data = [trace1]\nlayout = go.Layout(\n    title = 'The turtle place',\n    scene = dict(\n        xaxis = dict(title=feat1),\n        yaxis = dict(title=feat2),\n        zaxis = dict(title=feat3),\n    ),\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0\n    ),\n    showlegend=True\n)\n\nfig = go.Figure(data=figure_data, layout=layout)\npy.iplot(fig, filename='simple-3d-scatter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Previous LR model does not consider the interactions between the attributes. It treats the attributes as Independant Variables. <br> So we need to create an LR model by considering the interactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the distribution of 'wheezy-copper-turtle-magic'\ntrain_data['wheezy-copper-turtle-magic'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['wheezy-copper-turtle-magic'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of <b>wheezy-copper-turtle-magic</b> is between (0, 512)"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression With Interactions"},{"metadata":{},"cell_type":"markdown","source":"We will create seperate 512 model for the unique values of the <b>wheezy-copper-turtle-magic</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train_data.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\ninteractions = np.zeros((512,255))\noof = np.zeros(len(train_data))\npreds = np.zeros(len(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n# BUILD 512 SEPARATE MODELS\nfor i in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train_data[train_data['wheezy-copper-turtle-magic']==i]\n    test2 = test_data[test_data['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    test2.reset_index(drop=True,inplace=True)\n    \n    skf = StratifiedKFold(n_splits=25, random_state=42)\n    for train_index, test_index in skf.split(train2.iloc[:,1:-1], train2['target']):\n        # LOGISTIC REGRESSION MODEL\n        clf = LogisticRegression()\n        clf.fit(train2.loc[train_index][cols],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train2.loc[test_index][cols])[:,1]\n        preds[idx2] += clf.predict_proba(test2[cols])[:,1] / 25.0\n        # RECORD INTERACTIONS\n        for j in range(255):\n            if clf.coef_[0][j]>0: interactions[i,j] = 1\n            elif clf.coef_[0][j]<0: interactions[i,j] = -1\n    if i%25==0: print(i)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train_data['target'],oof)\nprint('LR with interactions scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit results\ntest_data['target'] = preds\nresult_data = test_data[['id', 'target']]\nresult_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_data.to_csv('sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}