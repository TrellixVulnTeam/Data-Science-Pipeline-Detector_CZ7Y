{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Use BGMM to see how many clusters[](http://) are there.  \nhttps://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html\n"},{"metadata":{},"cell_type":"markdown","source":"Use BGMM(BayesianGaussianMixtureModel), n_components = 4  \nIf 2 clusters (1 cluster for each class), clusters will shrink. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.mixture import BayesianGaussianMixture\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import VarianceThreshold\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# READ DATA\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 1\nmake 4 clusters and see distribution"},{"metadata":{},"cell_type":"markdown","source":"Competition dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_compe_data = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n\n    # FIT BGMM\n    X = np.concatenate([train3, test3], axis=0)\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X)\n    clusters = gmm.predict(X)\n    cnt_compe_data[i*4:(i+1)*4] = pd.value_counts(clusters).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_compe_data, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Simulation 1 (n_clusters_per_class = 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(71)\ncnt_dummy_2 = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=1, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_2[i*4:(i+1)*4] = pd.value_counts(clusters_sim).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_dummy_2, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Simulation 2 (n_clusters_per_class = 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(71)\ncnt_dummy_4 = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=2, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_4[i*4:(i+1)*4] = pd.value_counts(clusters_sim).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_dummy_4, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Simulation 3 (n_clusters_per_class = 3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(71)\ncnt_dummy_6 = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=3, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_6[i*4:(i+1)*4] = pd.value_counts(clusters_sim).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_dummy_6, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OH..."},{"metadata":{},"cell_type":"markdown","source":"# Part 2\n6 clusters"},{"metadata":{},"cell_type":"markdown","source":"competition dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_compe_data = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n\n    # FIT BGMM\n    X = np.concatenate([train3, test3], axis=0)\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X)\n    clusters = gmm.predict(X)\n    cnt_compe_data[i*6:(i+1)*6] = pd.value_counts(clusters).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_compe_data, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Simulation 1 (n_clusters_per_class = 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(71)\ncnt_dummy_2 = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=1, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_2[i*6:(i+1)*6] = pd.value_counts(clusters_sim).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_dummy_2, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Simulation 2 (n_clusters_per_class = 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(71)\ncnt_dummy_4 = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=2, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_4[i*6:(i+1)*6] = pd.value_counts(clusters_sim).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_dummy_4, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Simulation 3 (n_clusters_per_class = 3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(71)\ncnt_dummy_6 = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=3, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_6[i*6:(i+1)*6] = pd.value_counts(clusters_sim).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cnt_dummy_6, bins=np.arange(0, 800, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}