{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport subprocess\nimport re\nimport sys\nimport glob\nimport ctypes\nimport collections\nimport os\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\nos.environ[\"MKL_NUM_THREADS\"] = \"1\"\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\nos.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n\nimport numpy as np, pandas as pd, gc\nimport random as rn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.preprocessing import *\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import AgglomerativeClustering\nfrom copy import copy, deepcopy\n\nfrom scipy.stats import probplot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm import tqdm, tqdm_notebook\n\n%matplotlib inline\n\npd.options.display.max_rows = 10000\npd.options.display.max_columns = 10000\npd.options.display.max_colwidth = 1000\n\nfrom IPython.display import display\n\n_MKL_ = 'mkl'\n_OPENBLAS_ = 'openblas'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"class BLAS:\n    def __init__(self, cdll, kind):\n        if kind not in (_MKL_, _OPENBLAS_):\n            raise ValueError(f'kind must be {MKL} or {OPENBLAS}, got {kind} instead.')\n        \n        self.kind = kind\n        self.cdll = cdll\n        \n        if kind == _MKL_:\n            self.get_n_threads = cdll.MKL_Get_Max_Threads\n            self.set_n_threads = cdll.MKL_Set_Num_Threads\n        else:\n            self.get_n_threads = cdll.openblas_get_num_threads\n            self.set_n_threads = cdll.openblas_set_num_threads\n            \n\ndef get_blas(numpy_module):\n    LDD = 'ldd'\n    LDD_PATTERN = r'^\\t(?P<lib>.*{}.*) => (?P<path>.*) \\(0x.*$'\n\n    NUMPY_PATH = os.path.join(numpy_module.__path__[0], 'core')\n    MULTIARRAY_PATH = glob.glob(os.path.join(NUMPY_PATH, '_multiarray_umath.*so'))[0]\n    ldd_result = subprocess.run(\n        args=[LDD, MULTIARRAY_PATH], \n        check=True,\n        stdout=subprocess.PIPE, \n        universal_newlines=True\n    )\n\n    output = ldd_result.stdout\n\n    if _MKL_ in output:\n        kind = _MKL_\n    elif _OPENBLAS_ in output:\n        kind = _OPENBLAS_\n    else:\n        return\n\n    pattern = LDD_PATTERN.format(kind)\n    match = re.search(pattern, output, flags=re.MULTILINE)\n\n    if match:\n        lib = ctypes.CDLL(match.groupdict()['path'])\n        return BLAS(lib, kind)\n    \n\nclass single_threaded:\n    def __init__(self, numpy_module=None):\n        if numpy_module is not None:\n            self.blas = get_blas(numpy_module)\n        else:\n            import numpy\n            self.blas = get_blas(numpy)\n\n    def __enter__(self):\n        if self.blas is not None:\n            self.old_n_threads = self.blas.get_n_threads()\n            self.blas.set_n_threads(1)\n        else:\n            warnings.warn(\n                'No MKL/OpenBLAS found, assuming NumPy is single-threaded.'\n            )\n\n    def __exit__(self, *args):\n        if self.blas is not None:\n            self.blas.set_n_threads(self.old_n_threads)\n            if self.blas.get_n_threads() != self.old_n_threads:\n                message = (\n                    f'Failed to reset {self.blas.kind} '\n                    f'to {self.old_n_threads} threads (previous value).'\n                )\n                raise RuntimeError(message)\n    \n    def __call__(self, func):\n        def _func(*args, **kwargs):\n            self.__enter__()\n            func_result = func(*args, **kwargs)\n            self.__exit__()\n            return func_result\n        return _func","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nN_FOLDS = 11\nV_THRES = 1.5\nMODIFY_THRES = 0.99999\nPSEUDO_LABEL_THRES = 0.99\n\nnp.random.seed(SEED)\nrn.seed(SEED)\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def execute_classifier(n_folds=N_FOLDS, v_thres=V_THRES, start_seed=SEED, seed_range=4, verbose=None, magic_range=512):\n    \n    # INITIALIZE VARIABLES\n    oof = np.zeros(len(train))\n    fake_oof = np.zeros(len(train))\n    fake_preds = np.zeros(len(test))\n    \n    cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n    \n    # BUILD 512 SEPARATE NON-LINEAR MODELS\n    for i in tqdm_notebook(range(magic_range), f'{magic_range} models..'):\n        \n        for seed in range(start_seed, start_seed+seed_range):\n            fix_clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=seed, nu=0.7, coef0=0.05)\n\n            # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS I\n            train2 = train[train['wheezy-copper-turtle-magic'] == i]\n            test2 = test[test['wheezy-copper-turtle-magic'] == i]\n            idx1 = train2.index\n            idx2 = test2.index\n            train2.reset_index(drop=True, inplace=True)\n\n            train3, test3 = gmm_fe(train2[cols], test2[cols], v_thres=v_thres, seed=seed)\n\n            # pre_clf\n            pre_clf_oof, pre_clf_preds = pre_clf(train3, train2['target'], test3, fix_clf=fix_clf, n_folds=n_folds, seed=seed)\n            oof[idx1] += pre_clf_oof\n\n            # outlier replace\n            train4 = outlier_replace(pre_clf_oof, np.concatenate([train3, np.array(train2['target']).reshape(-1, 1)], axis=1))\n            # pseudo labeling\n            train4 = pseudo_labeling(pre_clf_preds, train4, test3, rows_ratio=0.2)\n\n            clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=seed, nu=0.6, coef0=0.05)\n\n            # modeling\n            skf = StratifiedKFold(n_splits=n_folds, random_state=seed, shuffle=True)\n            for (_, val_idx), (train_idx, _) in zip(skf.split(train2, train2['target']), skf.split(train4, train4.iloc[:, -1])):\n                clf.fit(train4.iloc[train_idx, :-1], train4.iloc[train_idx, -1])\n                fake_oof[idx1[val_idx]] += clf.predict_proba(train3[val_idx])[:, 1]\n                fake_preds[idx2] += clf.predict_proba(test3)[:, 1] / skf.n_splits\n        \n        # scaling\n        fake_oof[idx1] = StandardScaler().fit_transform(fake_oof[idx1].reshape(-1,1)).ravel()\n        fake_preds[idx2] = StandardScaler().fit_transform(fake_preds[idx2].reshape(-1,1)).ravel()\n        \n    return oof, fake_oof, fake_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_clf(train, y, test, fix_clf=True, n_folds=N_FOLDS, seed=SEED):\n    \n    oof = np.zeros(len(train))\n    preds = np.zeros(len(test))\n    \n    skf = StratifiedKFold(n_splits=n_folds, random_state=seed, shuffle=True)\n    for train_index, valid_index in skf.split(train, y):\n        fix_clf.fit(train[train_index], y[train_index])\n        oof[valid_index] = fix_clf.predict_proba(train[valid_index])[:, 1]\n        preds += fix_clf.predict_proba(test)[:, 1] / skf.n_splits\n    \n    return oof, preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_replace(oof, train, modify_threshold=MODIFY_THRES):\n    \n    # type change\n    oof = pd.Series(oof)\n    train = pd.DataFrame(train)\n    y = train.iloc[:, -1]\n    \n    # index extract\n    oof2 = oof[(oof>modify_threshold) | (oof<1-modify_threshold)]\n    oof2[oof2>0.5]=1\n    oof2[oof2<0.5]=0\n    oof_index = oof2[oof2 != y[oof2.index]].index\n    \n    # outlier로 판단 - replace\n    train.iloc[oof_index, -1] = 1 - train.iloc[oof_index, -1]\n    \n    return train\n\ndef pseudo_labeling(preds, train, test, pseudo_label_thresold=0.99, rows_ratio=0.01):\n\n    preds = pd.Series(preds)\n    test = pd.DataFrame(test)\n    \n    preds = preds.sort_values()\n    rows = np.round(len(preds)*rows_ratio, 0).astype(int)\n    \n    upper_index = preds[:rows].index\n    lower_index = preds[-rows:].index\n    \n    # Pseudo labeling\n#     preds = preds[(preds>pseudo_label_thresold) | (preds<1-pseudo_label_thresold)]\n#     preds[preds>0.5] = 1\n#     preds[preds<0.5] = 0\n#     test = pd.concat([test.loc[preds.index], preds], axis=1)\n\n    # using ratio\n    _index = np.concatenate([upper_index, lower_index])\n    preds = preds[_index]\n    preds[preds>=0.5] = 1\n    preds[preds<0.5] = 0\n    test = pd.concat([test.loc[_index], preds], axis=1)\n\n    # complete\n    test.columns = train.columns\n    train = pd.concat([train, test], ignore_index=True).reset_index(drop=True)\n    \n    return train\n\ndef gmm_fe(train, test, v_thres=V_THRES, seed=SEED):\n    std_col = pd.concat([train, test]).std()\n    feat_mask = std_col > v_thres       \n    \n    train1 = train.loc[:, feat_mask].values\n    test1 = test.loc[:, feat_mask].values\n\n    data = np.concatenate([train1, test1], axis=0)\n    data2 = KernelPCA(n_components=data.shape[1], kernel='cosine', random_state=seed, n_jobs=1).fit_transform(data)\n    \n    c = AgglomerativeClustering(n_clusters=2)\n    c_data = c.fit_predict(data).reshape(-1, 1)\n    \n    gmm_data1 = GaussianMixture(n_components=5, n_init=4, random_state=seed).fit(data2).predict_proba(data2)\n    gmm_data2 = GaussianMixture(n_components=4, n_init=3, random_state=seed).fit(data2).predict_proba(data2)\n    \n    data2 = np.concatenate([data2, gmm_data1, gmm_data2, c_data], axis=1)\n    data2 = StandardScaler().fit_transform(data2)\n    \n    train2 = data2[:train.shape[0]]\n    test2 = data2[train.shape[0]:]\n    \n    return train2, test2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith single_threaded(np):\n    oof, fake_oof, preds = execute_classifier(start_seed=SEED, seed_range=4, magic_range=10) # change (magic_range=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = preds\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}