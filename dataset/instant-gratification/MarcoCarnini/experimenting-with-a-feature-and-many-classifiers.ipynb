{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Building a model\n\nThis is a fork from [nvnn's kernel](https://www.kaggle.com/nvnnghia/svm-knn-0-943) supplemented with [Chris Deotte's idea for feature selection](https://www.kaggle.com/c/instant-gratification/discussion/92930):"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\nsubmission=test[[\"id\"]].copy()\nsubmission[\"target\"] = -1.0\nperformance_report = pd.DataFrame({\n    \"segment\": range(512),\n    \"mean\": 0,\n    \"std\": 0\n})\n\nfor i in range(10,11):\n    Y = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, \"target\"]\n    X = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"target\", \"wheezy-copper-turtle-magic\"], axis=1)\n    X_te = test.loc[test[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"wheezy-copper-turtle-magic\"], axis=1)\n    selected_columns = X.columns[(X.std(axis=0)>2).values]\n    X = X.loc[:, selected_columns]\n    X_te = X_te[selected_columns]\n    \n    model = RandomForestClassifier(n_estimators=100, random_state=1)\n    scores_rf = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n    print(np.mean(scores_rf), \"+/-\", np.std(scores_rf))\n    \n    model = svm.SVC(kernel='poly', degree=4, probability=True, gamma='auto', random_state=1)\n    scores_svm = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n    print(np.mean(scores_svm), \"+/-\", np.std(scores_svm))\n    \n    model = LogisticRegression(solver='liblinear', penalty=\"l1\", random_state=1)\n    scores_lr = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n    print(np.mean(scores_lr), \"+/-\", np.std(scores_lr))\n    \n    model = KNeighborsClassifier(n_neighbors=12)\n    scores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n    print(np.mean(scores_knn), \"+/-\", np.std(scores_knn))\n    \n    print(np.mean(scores_lr+scores_knn+scores_svm+scores_rf)/4)\n#    performance_report.loc[i, \"mean\"] = np.mean(scores_rf)\n#    performance_report.loc[i, \"std\"] = np.std(scores_rf)\n#    model = RandomForestClassifier(n_estimators=100, n_jobs=-1).fit(X, Y)\n#    submission.loc[test[\"wheezy-copper-turtle-magic\"]==i, \"target\"] =  model.predict_proba(X_te)[:,1]","execution_count":124,"outputs":[{"output_type":"stream","text":"(498, 46)\n0.8593323076923076 +/- 0.05603340189396544\n0.9256169230769231 +/- 0.03979160996743073\n0.8384641025641024 +/- 0.05233782069732335\n0.9114225641025641 +/- 0.035877471074526525\n0.8837089743589743\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_report.to_csv(\"performance.csv\", index=False)\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":71,"outputs":[{"output_type":"stream","text":"SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=4, gamma='auto_deprecated',\n  kernel='poly', max_iter=-1, probability=True, random_state=None,\n  shrinking=True, tol=0.001, verbose=False)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, \"target\"]\nX = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"target\", \"wheezy-copper-turtle-magic\"], axis=1)\nX_te = test.loc[test[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"wheezy-copper-turtle-magic\"], axis=1)","execution_count":125,"outputs":[{"output_type":"stream","text":"0.7705384615384616 +/- 0.06904833113749462\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import mixture\n\ndpgmm = mixture.BayesianGaussianMixture(n_components=X.shape[1], covariance_type='full').fit(X)\nprint(len(set(dpgmm.predict(X))))","execution_count":88,"outputs":[{"output_type":"stream","text":"255\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dpgmm.weights_)","execution_count":89,"outputs":[{"output_type":"stream","text":"[6.01197723e-03 5.99988079e-03 7.98367988e-03 5.97558977e-03\n 1.39145878e-02 5.95107382e-03 7.91830306e-03 7.90177229e-03\n 5.91387905e-03 3.93426841e-03 3.92595079e-03 9.79408291e-03\n 3.90926222e-03 5.85133692e-03 1.55700094e-02 5.82600525e-03\n 5.81322903e-03 3.86694978e-03 9.64603385e-03 7.69964053e-03\n 1.72853481e-02 5.17376525e-02 9.55779201e-03 9.53436627e-03\n 9.51076658e-03 9.48698990e-03 7.57042647e-03 9.43895437e-03\n 5.64881397e-03 3.75614513e-03 1.87320714e-02 5.60471542e-03\n 3.72651312e-03 5.57482392e-03 1.48262347e-02 1.10892114e-02\n 1.10584084e-02 1.83787639e-02 1.09953880e-02 3.65438127e-03\n 3.64363322e-03 5.44932774e-03 7.24421042e-03 1.26394125e-02\n 1.26008782e-02 3.58907014e-03 8.94472342e-03 5.34990419e-03\n 8.88820096e-03 3.54384876e-03 1.23634600e-02 3.52079749e-03\n 3.50917785e-03 3.49755820e-03 8.71484640e-03 3.47420155e-03\n 3.46246454e-03 3.45072752e-03 3.43899051e-03 6.85450700e-03\n 6.83087109e-03 5.10530285e-03 5.08738976e-03 3.37960891e-03\n 1.68381232e-02 5.03293380e-03 6.68581648e-03 3.33043488e-03\n 6.63592306e-03 4.95809052e-03 3.29277786e-03 3.28016204e-03\n 3.26754623e-03 3.25493041e-03 4.86347189e-03 3.22964949e-03\n 6.43396879e-03 3.20421878e-03 3.19145317e-03 4.76803134e-03\n 1.10805467e-02 3.15278858e-03 7.84926670e-03 3.12645919e-03\n 3.11321170e-03 6.19992843e-03 7.71650631e-03 7.68266257e-03\n 3.05934623e-03 4.56844114e-03 4.54776983e-03 3.01800275e-03\n 3.00415895e-03 5.98063030e-03 2.97634197e-03 2.96236879e-03\n 4.42259342e-03 2.93435590e-03 4.38047427e-03 7.26552160e-03\n 4.33783893e-03 2.87750537e-03 2.86311813e-03 8.54619265e-03\n 4.25107050e-03 2.81928664e-03 2.80452628e-03 4.18464888e-03\n 2.77492705e-03 2.76008818e-03 2.74524931e-03 2.73041044e-03\n 2.71557157e-03 2.70073269e-03 2.68589382e-03 2.67105495e-03\n 2.65621608e-03 2.64137721e-03 3.93980751e-03 3.91742274e-03\n 2.59660621e-03 5.16319454e-03 2.56641175e-03 2.55122624e-03\n 2.53604072e-03 2.52085521e-03 3.75850454e-03 2.49039158e-03\n 2.47511347e-03 2.45983537e-03 3.66683589e-03 2.42918306e-03\n 2.41380887e-03 2.39843467e-03 2.38306048e-03 8.28690199e-03\n 5.87949047e-03 2.33557734e-03 2.31935850e-03 2.30313965e-03\n 2.28692081e-03 2.27070196e-03 2.25448312e-03 2.23826427e-03\n 2.22204543e-03 2.20582658e-03 2.18960774e-03 2.17338889e-03\n 3.23575507e-03 3.21124250e-03 2.12436092e-03 2.10789351e-03\n 3.13713914e-03 2.07482799e-03 2.05822989e-03 3.06244767e-03\n 2.02489763e-03 2.00816348e-03 1.99142934e-03 3.94939037e-03\n 1.95767253e-03 1.94064987e-03 6.73269524e-03 1.90581649e-03\n 2.83200867e-03 1.87002544e-03 2.77806766e-03 2.75083275e-03\n 1.81555033e-03 1.79721217e-03 1.77887400e-03 1.76053584e-03\n 2.61329651e-03 2.58549664e-03 1.70492974e-03 1.68619506e-03\n 1.66746037e-03 1.64872569e-03 1.62999100e-03 3.22251264e-03\n 1.59207559e-03 1.57289486e-03 1.55371414e-03 2.30180012e-03\n 1.51510990e-03 1.49568639e-03 1.47626288e-03 1.45683937e-03\n 1.43741586e-03 1.41799235e-03 1.39856884e-03 1.37914534e-03\n 1.35972183e-03 1.34029832e-03 1.98131221e-03 1.30116141e-03\n 1.28144802e-03 1.26173462e-03 1.24202122e-03 1.22230783e-03\n 1.20259443e-03 1.18288104e-03 1.16316764e-03 1.14345425e-03\n 1.12374085e-03 1.10402746e-03 1.08431406e-03 1.06460067e-03\n 1.04488727e-03 1.02517387e-03 1.50819072e-03 9.85352846e-04\n 9.65245214e-04 9.45137581e-04 9.25029949e-04 9.04922316e-04\n 8.84814684e-04 8.64707051e-04 8.44599419e-04 8.24491786e-04\n 8.04384154e-04 7.84276521e-04 7.64168889e-04 7.44061256e-04\n 7.23953624e-04 1.05576899e-03 6.83147026e-04 6.62448061e-04\n 6.41749095e-04 6.21050130e-04 6.00351165e-04 5.79652200e-04\n 5.58953234e-04 5.38254269e-04 7.76332956e-04 4.95994023e-04\n 4.74432741e-04 4.52871460e-04 6.46965268e-04 6.12921491e-04\n 3.84583734e-04 3.60553141e-04 3.36522547e-04 3.12491953e-04\n 2.88461360e-04 2.64430766e-04 2.40400173e-04 2.16369579e-04\n 1.92338986e-04 1.68308392e-04 1.44277799e-04 1.20247205e-04\n 9.62166117e-05 1.08279027e-04 3.61636412e-05]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.distplot(dpgmm.weights_)","execution_count":94,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f1a8c890128>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHdxJREFUeJzt3XmQnPV95/H3t4/pnns0l9A1Gl0YBBgZZASJAxhsB+x1RNZZTNgyrMtbOA6ujbec2sWxt+xNVbL21uawy1l7SeKYbBk7vmLYBdux5YOQBWEJgw4LWYMEQkLSXNJoeo7u6enf/tFPi/Ywozn6euZ5Pq+qrul5+vo+jOYzP77P7/k95pxDRESCK1LrAkREpLIU9CIiAaegFxEJOAW9iEjAKehFRAJOQS8iEnAKehGRgFPQi4gEnIJeRCTgYrUuAKCzs9P19vbWugwRkWVl7969g865rvme54ug7+3tZc+ePbUuQ0RkWTGzlxfyPLVuREQCTkEvIhJwCnoRkYBT0IuIBJyCXkQk4BT0IiIBp6AXEQk4Bb2ISMAp6EVEAs4XZ8YuBw/vPj7r9rt39FS5EhGRxdGIXkQk4BT0IiIBp6AXEQk4Bb2ISMAp6EVEAk5BLyIScAp6EZGAU9CLiAScgl5EJODmDXozW2dmPzazX5jZQTP7A297u5n9wMyOeF9XeNvNzD5nZn1mts/Mrqn0ToiIyNwWMqLPAh91zm0FrgfuN7OtwAPALufcFmCX9z3A7cAW73Yf8IWyVy0iIgs2b9A7504555717o8Ch4A1wE7gIe9pDwF3ePd3An/v8p4G2sxsVdkrFxGRBVlUj97MeoE3AbuBlc65U95Dp4GV3v01wCtFLzvhbRMRkRpYcNCbWRPwLeAjzrnzxY855xzgFvPBZnafme0xsz0DAwOLeamIiCzCgoLezOLkQ/4rzrlve5vPFFoy3td+b/tJYF3Ry9d6236Fc+5B59x259z2rq6updYvIiLzWMisGwP+FjjknPvzooceBe717t8LPFK0/R5v9s31wEhRi0dERKpsIRce+XXgfcB+M3vO2/ZHwKeBr5vZB4CXgTu9xx4H3gn0AePA+8tasYiILMq8Qe+cexKwOR6+dZbnO+D+EusSEZEy0ZmxIiIBp6AXEQk4Bb2ISMAp6EVEAk5BLyIScAp6EZGAU9CLiAScgl5EJOAU9CIiAaegFxEJOAW9iEjAKegXIJdz7D85wvmJqVqXIiKyaAr6ebw8NMZdDz7NV585zncPaLVlEVl+FrJMcWgdODnCnf/rKaJmrGmr59DpUaamc8Sj+vsoIsuHEusiHnnuJNlpx/f/442844qVZLI5jpwZrXVZIiKLoqC/iKeODvGmnjZWt9WzsbOJhroo+0+O1LosEZFFCXXr5uHdx2fdfveOHs6NZzj46nk+cuulAEQjxhWrW3j+xIjaNyKyrCit5rD72DDOwQ2bOi5su3JNq9o3IrLsKOjn8NSLQyTjEa5e13phm9o3IrIcKejn8PTRIbavbycRi17YFo0Yl69q4fCZUfKXxhUR8T8F/SyGUmleOD36K22bgktakkxO5RjPTNegMhGRxVPQz+Lpo8MAswZ9R2MdAMNjmarWJCKyVAr6WTx1dJDGuihXrWl93WPtXtAPjaWrXZaIyJKEenrlXH78wgCrWuv5xp4Tr3tsRWMdBgxpRC8iy4RG9LMYHsvQ0VQ362PxaISW+jjDKQW9iCwPCvoZJjLTTExNs6Jh9qCHfJ9eI3oRWS4U9DOcHc8HeKEXP5t2Bb2ILCMK+hkKs2lWXCToO5oSjKWzpKc0xVJE/E9BP8OFEf1FWjevzbzRqF5E/E9BP8PwWIZkPEJ9XXTO53Qo6EVkGVHQz3B2PHPR/jwUnTSV0lx6EfE/Bf0Mw2NTF51xA5CIR2lMxDSiF5FlQUFfJOfcgkb0oCmWIrJ8KOiLjE5mmc65eUf0kA96rXcjIsuBgr5IIbgXMqJvb6pjZGKKSU2xFBGfU9AXWcjUyoLCAdlXhscrWpOISKkU9EWGxzIY0NYQn/e57Y0JAF4eUtCLiL8p6IucHcvQUh8ntoALf7fW5/8YnBmdrHRZIiIlUdAXGR7PLOhALEBTIr/C88Co5tKLiL8p6IucHcvQ3jh/2wby149tqIvSr6AXEZ+bN+jN7Etm1m9mB4q2fcrMTprZc97tnUWPfczM+szssJn9ZqUKL7ep6RznJ7MXXcxspuZkTCN6EfG9hYzovwzcNsv2v3DObfNujwOY2VbgLuAK7zX/08zmXjTGR0bGpwAW3LoBaE7GFfQi4nvzBr1z7glgeIHvtxP4mnMu7Zw7BvQB15VQX9WMprMAtCQX1roBaE5oRC8i/ldKj/7DZrbPa+2s8LatAV4pes4Jb9vrmNl9ZrbHzPYMDAyUUEZ5jHlB35hY+P+ANHmtG+dcpcoSESnZUoP+C8AmYBtwCvizxb6Bc+5B59x259z2rq6uJZZRPikv6AuzaRaiORknM53j/ES2UmWJiJRsSUHvnDvjnJt2zuWAv+a19sxJYF3RU9d623yvMKJvqFtE0BemWKY0l15E/GtJQW9mq4q+/W2gMCPnUeAuM0uY2QZgC/BMaSVWRyqdpT4eJRqxBb+mKZkP+v7z6tOLiH/NO3w1s68CNwOdZnYC+CRws5ltAxzwEvBBAOfcQTP7OvALIAvc75xbFqt+jaWzi2rbQPGIXkEvIv41b7I55353ls1/e5Hn/wnwJ6UUVQup9DSNiw16b4aOZt6IiJ/pzFhPfkS/uCn/yXiEulhEZ8eKiK8p6D2pdHbRI3ozo6spoRG9iPiagh6YzjkmpqYX3aMH6G5R0IuIvynogbFM4WSpxQe9RvQi4ncKel6bQ7+UEX1Xc4J+rUkvIj6moAfG0vkZoEsa0TcnODs+RSabK3dZIiJloaBnacsfFHQ3JwEYGlP7RkT8SUFP6a0b0NmxIuJfCnryI/qI5efFL1Yh6HVAVkT8SkHPa8sfmC18nZuC7kLQaxkEEfEpBT1LO1mqoKMpf0UqtW5ExK8U9ORH9EsN+kQsSltDXEsVi4hvKejJj+iXciC2oLs5oRG9iPiWgp78PPrGuqVfw7yzKcHQWKaMFYmIlE/ogz6TzZGZzpU0ou9oSjCog7Ei4lOhD/rXLgq+9KDvbKpjUNMrRcSnQh/0pZwVW9DZlGAsM81EZllcTEtEQib0QV+uET2g9o2I+JKCPlOeET2gA7Ii4kuhD/pUCStXFnR4Qa8+vYj4UeiDfiydJR416mJL/09RaN1oBUsR8aPQB/14Jktj3dJH8/Ba62YwpdaNiPiPgj4zTX0JJ0sBJONRmhIxHYwVEV9S0Jch6CG/uJlG9CLiR6EP+onMNA3x0oO+synBkEb0IuJDoQ/68alpGkrs0YN3dqyCXkR8KNRB75xjIpMtU+smwZBaNyLiQ6EO+nQ2R85BQxmCvrMpwfB4hux0rgyViYiUT6iDvrA2TXmCvg7n4Oz4VMnvJSJSTqEO+vGpfNDXx8vRoy/MpVefXkT8JdxB761zU5YefaMWNhMRfwp10Je1ddPsLWymA7Ii4jOhDvrxsvbo1boREX8KddBPXOjRlx70LckYddGIzo4VEd8p/SjkMjaezlIXjRCLLv3v3cO7j1+4X18X5Zljwzy8+zh37+gpR4kiIiUL/Yi+HG2bgsZE9MIVq0RE/CLUQV+uBc0KmhKxC9egFRHxCwW9gl5EAi7UQV+ulSsLCkHvnCvbe4qIlGreoDezL5lZv5kdKNrWbmY/MLMj3tcV3nYzs8+ZWZ+Z7TOzaypZfKnKtXJlQWMixnTOkc5qvRsR8Y+FjOi/DNw2Y9sDwC7n3BZgl/c9wO3AFu92H/CF8pRZfuVcubKgOZn/o3F+UuvdiIh/zBv0zrkngOEZm3cCD3n3HwLuKNr+9y7vaaDNzFaVq9hySqWzZVu5sqAlGQfg/IT69CLiH0vt0a90zp3y7p8GVnr31wCvFD3vhLftdczsPjPbY2Z7BgYGlljG0p3zVpksZ9C31ntBrxG9iPhIyQdjXf7I46KPPjrnHnTObXfObe/q6iq1jEUbmciHcTlWrixoKQT9hIJeRPxjqUF/ptCS8b72e9tPAuuKnrfW2+Y7Z8fzSxWUs0cfj0aoj0cv/BEREfGDpQb9o8C93v17gUeKtt/jzb65HhgpavH4SiVaNwAt9THOT6pHLyL+MW/fwsy+CtwMdJrZCeCTwKeBr5vZB4CXgTu9pz8OvBPoA8aB91eg5rI4N1GhoE/G1boREV+ZN+idc787x0O3zvJcB9xfalHVcG7Ma92U8YQpyB+QPX1+sqzvKSJSitCeGXtuYqrklStn01IfJzWZZUoXCRcRnwhv0I9Plb1tA/nWjQMGRnUBEhHxh9AG/chEpqwzbgpa6vPdMLVvRMQvQhv0Z8enKhP03tmxZ0YU9CLiD6EN+nPjmbKuXFlQODv2lIJeRHwitEE/MjFV1pUrCxrqosQixhm1bkTEJ0IZ9M45zlWodWNmNCdj6tGLiG+EMuhT6SzZnKvIrBvIT7E8rdaNiPhEKIO+UssfFLQk42rdiIhvhDLoK7FyZbHW+jinRiZ1SUER8YVQBn0lVq4s1lIfJ53NaRVLEfGFUAZ95Vs3OmlKRPwjnEFfoZUrCwpz6XVAVkT8IJxBX6GVKwsKZ8cq6EXED8IZ9BP5Bc3KvXJlQXN9DDOdHSsi/hDOoB+fYkVDXcXePxaJsKatnqODYxX7DBGRhQpl0I9MZC700StlS3cTff2pin6GiMhChDLoz45P0dZQ4aBf2cyLAymmc5pLLyK1FcqgPzeeqWjrBmBzdxOZbI5Xhscr+jkiIvMJZdCPTEzRWukRfXcTAEfUvhGRGgtd0BdWrmyrcI9+04WgH63o54iIzCd0QV9YubLSPfqWZJxLWpL0ndGIXkRqK3RBX1j+oK3CPXqALSub6BtQ0ItIbYUu6AsLjVW6dQP5A7J9/SlymnkjIjUUuqAvrFxZlRF9dzPjmWleHZmo+GeJiMwldEFfaN2sqHCPHvKtG9DMGxGprfAFvde6qfT0SoDNXfmg1wFZEaml8AW9t3JlpZdAAFjRWEdnU52mWIpITYUv6L2VKxOxyixRPNNmrXkjIjUWvqCv8MqVM112SQuHTo2Szk5X7TNFRIqFMOgrv3JlsZsu7WJiaprdR4er9pkiIsXCF/QTlV+5stgNmzpIxiP86IX+qn2miEix8AV9FVauLJaMR3nL5k52vXAG53TilIhUX+iCvhorV850y2UreWV4QgdlRaQmQhX01Vq5cqa3XtYFwC61b0SkBmK1LqCaqrVy5UyrWuvZuqqFHx3qpyX5+s++e0dPVesRkXAJ1Yi+mitXznTr5d3sPX6W8Uy26p8tIuEWzqCvcusG4G2Xr2Q659h/cqTqny0i4RauoJ+o3sqVM71xbStXr2vjn48M6oLhIlJVJQW9mb1kZvvN7Dkz2+NtazezH5jZEe/rivKUWrqzF1o31R/RmxkfumkTw2MZDr6qUb2IVE85RvRvdc5tc85t975/ANjlnNsC7PK+94XB0TQAnU2Jmnz+O7aupLMpwRO/HNCcehGpmkq0bnYCD3n3HwLuqMBnLMlAKk08ajXp0QNEIsaNWzp5dWRSc+pFpGpKDXoH/JOZ7TWz+7xtK51zp7z7p4GVJX5G2fSfT9PZlCASsZrVsK2njZZkjB8fHqhZDSISLqUG/Vucc9cAtwP3m9mNxQ+6fH9i1h6Fmd1nZnvMbM/AQHVCbyCVpru5Nm2bglgkwo2XdvHS0BhHdeFwEamCkoLeOXfS+9oP/CNwHXDGzFYBeF9nPR3UOfegc267c257V1dXKWUs2MBomq4aBz3Am3vbaU7GdKasiFTFkoPezBrNrLlwH3gHcAB4FLjXe9q9wCOlFlkuA6OTdDUna10G8WiEmy7t4tigRvUiUnmljOhXAk+a2fPAM8BjzrnvAZ8G3m5mR4C3ed/XXHY6x9BYxhcjetCoXkSqZ8lr3TjnjgJXz7J9CLi1lKIqYWgsg3P4JugLo/r/u+8UT704xA2bOmpdkogEVGjOjB3w5tDX+mBsscKo/rO7flnrUkQkwEKzemX/6CRQvRH9w7uPz/uceDTCjVu6eGz/KZ4+OsT1GzWqF5Hy04i+xq7b0E5Xc4LP/vBIrUsRkYAKXdDXavmDucSjET500yaeOjrE00eHal2OiARQaIK+fzRNa32cZDxa61Je5+4dPaxsSfCnjx8ip5UtRaTMQhP0fjlZajbJeJQHbr+MfSdG+NazJ2pdjogETGiCvn80TZfP2jbF7ti2hmt62vjM9w4zOjlV63JEJEBCE/QDo2m6W/wb9GbGJ999BYOpNJ//UV+tyxGRAAlF0Dvn6B+d9PWIHuDqdW3cuX0tf/PkMX720nCtyxGRgAhF0KfSWSancr4e0Rf8l3+1lbUr6vkPX/05Z8cytS5HRAIgFEFfmFrp14OxxZqTcf7q7msYSmX46Dee1ywcESlZKM6M7b9wslTtV65ciCvXtPLxd13OJx89yL/7u59x25WXLOh1d+/oqXBlIrIcaUTvU/fcsJ7rett54sgATx7R1ahEZOlCNqJfPkFvZvzWttWMZ7I8fuA09XVRrl3fXuuyRGQZCs2IPh41Wmt0UfCliphx5/Z1bO5u4tvPnmT3MS2RICKLF5IRfX5qpVntLgp+MRdb6TIWjfC+69fz8O7jPPLcq0xlc7xlS3UuvSgiwRCaEf1y6s/PFI9G+LfX93Dl6hYeP3CaXS+cIX/ddRGR+YUi6I8NjtHT0VjrMkoSi0R475t7eNO6NnYd6uf7B08r7EVkQQIf9BOZaU6em2BzV1OtSylZNGK859q1XLehnSeODPL9g6drXZKILAOB79EfHUzhHGzqXt4j+oKIGTuvXo0BTxwZpDkZ59c3d9a6LBHxscAHfV9/CoDN3ct/RF9gZrz76tWMTmZ5fP8pmpMx3ri2rdZliYhPBb518+LAGBGD3mXeo58pYsZ737yOnvYGvvXsCU6fn6x1SSLiU8EP+v4U69obfHllqVLFoxHu3tFDIhblq88cZzyTrXVJIuJDgQ/6vv5UIA7EzqU5GefO7esYHE3zyUcO1rocEfGhQAf9dM5xbHAsUP352WzubuLmN3Tzjb0n+LYuRSgiMwQ66F8ZHicznWNTgEf0Bbdc1s11G9r5xHcO8OJAqtbliIiPBDroCzNuNgV8RA/5Ofafu+tNJGIR7v/Ks0xOTde6JBHxiUAHfWFkG+QefbFLWpP8+Z3beOH0KJ/4zgGdOSsiQMCDvq8/RWdTgtaG5bVqZSneelk3H3nbFr659wSf+d7hWpcjIj4Q6BOm+gZSbA7IGbGL8Qe3bmFgNM0Xf/oiLw2OceOlr1/tUlejEgmPwAa9c46+/hQ7t62udSlVZ2b88c4rOTcxxWP7TnF2PMO7rlpFLBro/4ETkTkENuj7R9OMTmZD05+fKRox/vK92zg/PsU/9w1y4uwE/+batXS3LI/r5opI+QQ26H/8Qj8A23vDe/m9eDTC7VetYn1HI9989hU+u+sI16xfwa2Xdc95sRO1dESCJ7BB/9j+U6zvaOCK1S21LqXmtq5u4aMdb+Anh/t5+tgwPz9+lq2rW7lhYwe9HQ2+vfKWiJRHIIN+eCzD/3txiPtu3KgQ8zQmYrzrjav5tc2dPP3iEHtePsuBkyNc0pLk+o0dbFvXRl1MPXyRIApk0P/TwdNM5xzvumpVrUvxnRUNddx+1SpuvXwl+06c46mjQ3znuZN87+Apru1ZwQ2bOtjQGb6ZSiJBFsigV9tmfnWxCNt727l2/QqOD4/z1NEhnjo6xFv/x0+46dIu7rlhPTde2kW8wjN1dKxApPICF/SFts0H1bZZEDNjfUcj6zsaOX/VFOmpHF/Z/TIfeGgPjXVRtve2c/W6Ni5pSdLVnKChLkoyHiUZj1Afj1JfFyUZy2+bdo5MNkdqMstAKs1gKs1QKuN9TTOYyjCazlIXjZCMR1jX3sBQKs26FQ10NC3fi7eL+F3ggv7/PP8q0znHO9W2WbSWZJy7b+rh99+6iR+90M+TRwZ56ugQTxwZoNTVFFrr43Q01dGcjDOVzTGeyfK9A6fJ5vJvvKatnjeubeXanhU0JAL3z1Kkpir2G2VmtwGfBaLA3zjnPl2pzyp49vhZ/tt3D3FNT1so2zZztUGW+h6Xr2rh8lUtTOccqXSW1GSWzHSOqQs39yv3I5afv5+IRWlKxPK3ZIzGRJRY5PUtoGwux2AqQ9+ZUfadHOG7B07zw0NnuKZnBddvbGdjSM+BEH+b7ffM763GigS9mUWBvwLeDpwAfmZmjzrnflGJzwM4OpDiA1/+GStbkjx4z3a1bcooGjFa6+O01pd3zaBYJMIlLUkuaUnyli1dnDk/yb/0DbL35bPc8mc/5W2Xd3Pvr/Vyw8YOndUrvpFzjoHRNK+em2B4PMN4eppnj5+lrT5OR1OCjV2NXLWmlVWtSd/kUKVG9NcBfc65owBm9jVgJ1DWoJ/OOXYfG+Lx/ad4bN8pzIyH3n8dner3LksrW5L862vW8vatKxnPTPO/n36ZHx56htb6ODe/oYur17axZWUTq1rraaiL0lCXP0ZQF4345hdKFm6u1VUv1iac66GLrdQ692vm/pzpnGN0coqRiSleHZnk+PA4fWdGOfDqefadOMfU9GsvTsYjvDQ0xtnxDJNTuQvbOxrruHJNK1euaWFDZxM97Q10NydoTsZoTMSIRQwzI2JU/N9vpYJ+DfBK0fcngB3l/pBv7T3Bf/rWPurjUW65rJsP37KZXk0NXPaak3E+eNMmPnTzJn5yuJ8f/KKfn/6yn0eee3XW58ciRjQy+y/KXL8/xuKeP5e5wsLNGS9LC7KLvN2cn+WHwAyShrooV6xu4c297axuq2d1Wz2dTXXEIpELrZtUOsvh06McODnCgZMj7D85wpN9g0zn5v6P9MGbNvKx2y+vaO1WiTXLzex3gNucc//e+/59wA7n3IeLnnMfcJ/37RuAWqyp2wkM1uBzK0n7tHwEcb+0T9W13jn3+uVpZ6jUiP4ksK7o+7Xetguccw8CD1bo8xfEzPY457bXsoZy0z4tH0HcL+2TP1XqCNfPgC1mtsHM6oC7gEcr9FkiInIRFRnRO+eyZvZh4Pvkp1d+yTl3sBKfJSIiF1exefTOuceBxyv1/mVS09ZRhWiflo8g7pf2yYcqcjBWRET8Q2ehiIgEXCCD3sxuM7PDZtZnZg/M8njCzP7Be3y3mfUWPfYxb/thM/vNatY9n6Xul5l1mNmPzSxlZp+vdt0XU8I+vd3M9prZfu/rLdWufS4l7NN1Zvacd3vezH672rXPpZTfKe/xHu/f3x9Wq+aFKOFn1WtmE0U/ry9Wu/ZFcc4F6kb+4O+LwEagDnge2DrjOb8PfNG7fxfwD979rd7zE8AG732itd6nMuxXI/AW4PeAz9d6X8q0T28CVnv3rwRO1np/yrBPDUDMu78K6C98v1z3qejxbwLfAP6w1vtTpp9VL3Cg1vuw0FsQR/QXll9wzmWAwvILxXYCD3n3vwncavlzkHcCX3POpZ1zx4A+7/38YMn75Zwbc849CUxWr9wFKWWffu6cK5wqexCoNzM/rH1Ryj6NO+ey3vYkFz0ftqpK+Z3CzO4AjpH/OflJSfu1nAQx6GdbfmHNXM/xfrFGgI4FvrZWStkvvyrXPr0HeNY5l65QnYtR0j6Z2Q4zOwjsB36vKPhracn7ZGZNwH8G/msV6lysUv/9bTCzn5vZT83sNypdbCm08Lcsa2Z2BfAZ4B21rqUcnHO7gSvM7HLgITP7rnPOb/8nthifAv7COZdahgPhizkF9DjnhszsWuA7ZnaFc+58rQubTRBH9PMuv1D8HDOLAa3A0AJfWyul7JdflbRPZrYW+EfgHufcixWvdmHK8nNyzh0CUuSPP9RaKfu0A/jvZvYS8BHgj7yTKf1gyfvltXeHAJxze8n3+i+teMVLFMSgX8jyC48C93r3fwf4kcsfYXkUuMs70r4B2AI8U6W651PKfvnVkvfJzNqAx4AHnHP/UrWK51fKPm3wwgQzWw9cBrxUnbIvasn75Jz7Dedcr3OuF/hL4E+dc36Z+VXKz6rL8tfdwMw2ks+Ko1Wqe/FqfTS4EjfgncAvyf+V/bi37Y+B3/LuJ8nPAOgjH+Qbi177ce91h4Hba70vZdyvl4Bh8qPEE8yYXbDc9gn4BDAGPFd06671/pS4T+8jf8DyOeBZ4I5a70s5/u0Vvcen8NGsmxJ/Vu+Z8bN6d6335WI3nRkrIhJwQWzdiIhIEQW9iEjAKehFRAJOQS8iEnAKehGRgFPQi4gEnIJeRCTgFPQiIgH3/wH/HTCUk5mWwwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.95)))","execution_count":98,"outputs":[{"output_type":"stream","text":"13\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dpgmm = mixture.BayesianGaussianMixture(n_components=X.shape[1], covariance_type='full', random_state=2019).fit(X)\ndpgmm = mixture.BayesianGaussianMixture(n_components=np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.95)), \n                                        covariance_type='full', random_state=2019).fit(X)","execution_count":150,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters = pd.DataFrame({\n    \"cluster_name\": dpgmm.predict(X),\n    \"Y\": Y\n})\ndic = clusters.groupby(\"cluster_name\").mean()","execution_count":160,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dic.iloc[1,0]","execution_count":164,"outputs":[{"output_type":"execute_result","execution_count":164,"data":{"text/plain":"0.76"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Using nearest neighbours"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbors=3)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":153,"outputs":[{"output_type":"stream","text":"0.892178717948718 +/- 0.05602891193937103\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=4)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":154,"outputs":[{"output_type":"stream","text":"0.9080287179487179 +/- 0.048117300211240784\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=10)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":155,"outputs":[{"output_type":"stream","text":"0.9172041025641026 +/- 0.04611708958304699\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=15)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":156,"outputs":[{"output_type":"stream","text":"0.915403076923077 +/- 0.041509737738911166\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=12)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":157,"outputs":[{"output_type":"stream","text":"0.9174066666666667 +/- 0.04237298588961886\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=8)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":158,"outputs":[{"output_type":"stream","text":"0.907411794871795 +/- 0.053871691284880695\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Classifiers with new column\n\nNow, comparing all the classifiers with the new column (and trying to fine tune the amount of components to be considered in the clustering):"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, \"target\"]\nX = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"target\", \"wheezy-copper-turtle-magic\"], axis=1)\nX_te = test.loc[test[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"wheezy-copper-turtle-magic\"], axis=1)\n\nselected_columns = X.columns[(X.std(axis=0)>2).values]\nX = X.loc[:, selected_columns]\nX_te = X_te[selected_columns]\n\ndpgmm = mixture.BayesianGaussianMixture(n_components=X.shape[1], covariance_type='full', random_state=2019).fit(X)\ndpgmm = mixture.BayesianGaussianMixture(n_components=np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.95)), \n                                        covariance_type='full', random_state=2019).fit(X)\ndic = pd.DataFrame({\"cluster_name\": dpgmm.predict(X), \"Y\": Y}).groupby(\"cluster_name\").mean()\n\ncolumn_train = [dic.iloc[i, 0] for i in dpgmm.predict(X)]\ncolumn_test = [dic.iloc[i, 0] for i in dpgmm.predict(X_te)]\n\nX[\"train_column\"] = column_train\nX_te[\"train_column\"] = column_test\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nscores_rf = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_rf), \"+/-\", np.std(scores_rf))\n\nmodel = svm.SVC(kernel='poly', degree=4, probability=True, gamma='auto', random_state=1)\nscores_svm = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_svm), \"+/-\", np.std(scores_svm))\n    \nmodel = LogisticRegression(solver='liblinear', penalty=\"l1\", random_state=1)\nscores_lr = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_lr), \"+/-\", np.std(scores_lr))\n    \nmodel = KNeighborsClassifier(n_neighbors=12)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":182,"outputs":[{"output_type":"stream","text":"0.8725889743589743 +/- 0.05371748644376091\n0.9262574358974358 +/- 0.03968764451505268\n0.8381564102564102 +/- 0.05233166334852297\n0.910672564102564 +/- 0.03597762188996562\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, \"target\"]\nX = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"target\", \"wheezy-copper-turtle-magic\"], axis=1)\nX_te = test.loc[test[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"wheezy-copper-turtle-magic\"], axis=1)\n\ndpgmm = mixture.BayesianGaussianMixture(n_components=X.shape[1], covariance_type='full', random_state=2019).fit(X)\ndpgmm = mixture.BayesianGaussianMixture(n_components=np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.95)), \n                                        covariance_type='full', random_state=2019).fit(X)\ndic = pd.DataFrame({\"cluster_name\": dpgmm.predict(X), \"Y\": Y}).groupby(\"cluster_name\").mean()\n\ncolumn_train = [dic.iloc[i, 0] for i in dpgmm.predict(X)]\ncolumn_test = [dic.iloc[i, 0] for i in dpgmm.predict(X_te)]\n\nX[\"train_column\"] = column_train\nX_te[\"train_column\"] = column_test\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nscores_rf = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_rf), \"+/-\", np.std(scores_rf))\n\nmodel = svm.SVC(kernel='poly', degree=4, probability=True, gamma='auto', random_state=1)\nscores_svm = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_svm), \"+/-\", np.std(scores_svm))\n    \nmodel = LogisticRegression(solver='liblinear',random_state=1)\nscores_lr = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_lr), \"+/-\", np.std(scores_lr))\n    \nmodel = KNeighborsClassifier(n_neighbors=12)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":183,"outputs":[{"output_type":"stream","text":"0.7597635897435897 +/- 0.06643442513188137\n0.9557241025641027 +/- 0.024170192715627772\n0.7634015384615385 +/- 0.06425126662245965\n0.9174066666666667 +/- 0.04237298588961886\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, \"target\"]\nX = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"target\", \"wheezy-copper-turtle-magic\"], axis=1)\nX_te = test.loc[test[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"wheezy-copper-turtle-magic\"], axis=1)\n\ndpgmm = mixture.BayesianGaussianMixture(n_components=X.shape[1], covariance_type='full', random_state=2019).fit(X)\ndpgmm = mixture.BayesianGaussianMixture(n_components=np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.90)), \n                                        covariance_type='full', random_state=2019).fit(X)\ndic = pd.DataFrame({\"cluster_name\": dpgmm.predict(X), \"Y\": Y}).groupby(\"cluster_name\").mean()\n\ncolumn_train = [dic.iloc[i, 0] for i in dpgmm.predict(X)]\ncolumn_test = [dic.iloc[i, 0] for i in dpgmm.predict(X_te)]\n\nX[\"train_column\"] = column_train\nX_te[\"train_column\"] = column_test\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nscores_rf = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_rf), \"+/-\", np.std(scores_rf))\n\nmodel = svm.SVC(kernel='poly', degree=4, probability=True, gamma='auto', random_state=1)\nscores_svm = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_svm), \"+/-\", np.std(scores_svm))\n    \nmodel = LogisticRegression(solver='liblinear',random_state=1)\nscores_lr = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_lr), \"+/-\", np.std(scores_lr))\n    \nmodel = KNeighborsClassifier(n_neighbors=12)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":188,"outputs":[{"output_type":"stream","text":"0.8440938461538462 +/- 0.07794952530114954\n0.9557241025641027 +/- 0.024170192715627772\n0.7709507692307692 +/- 0.06083755869576362\n0.9174066666666667 +/- 0.04237298588961886\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, \"target\"]\nX = train.loc[train[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"target\", \"wheezy-copper-turtle-magic\"], axis=1)\nX_te = test.loc[test[\"wheezy-copper-turtle-magic\"]==i, :].drop([\"id\", \"wheezy-copper-turtle-magic\"], axis=1)\n\ndpgmm = mixture.BayesianGaussianMixture(n_components=X.shape[1], covariance_type='full', random_state=2019).fit(X)\ndpgmm = mixture.BayesianGaussianMixture(n_components=np.sum(dpgmm.weights_ > np.quantile(dpgmm.weights_, 0.85)), \n                                        covariance_type='full', random_state=2019).fit(X)\ndic = pd.DataFrame({\"cluster_name\": dpgmm.predict(X), \"Y\": Y}).groupby(\"cluster_name\").mean()\n\ncolumn_train = [dic.iloc[i, 0] for i in dpgmm.predict(X)]\ncolumn_test = [dic.iloc[i, 0] for i in dpgmm.predict(X_te)]\n\nX[\"train_column\"] = column_train\nX_te[\"train_column\"] = column_test\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=1)\nscores_rf = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_rf), \"+/-\", np.std(scores_rf))\n\nmodel = svm.SVC(kernel='poly', degree=4, probability=True, gamma='auto', random_state=1)\nscores_svm = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_svm), \"+/-\", np.std(scores_svm))\n    \nmodel = LogisticRegression(solver='liblinear',random_state=1)\nscores_lr = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_lr), \"+/-\", np.std(scores_lr))\n    \nmodel = KNeighborsClassifier(n_neighbors=12)\nscores_knn = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_knn), \"+/-\", np.std(scores_knn))","execution_count":189,"outputs":[{"output_type":"stream","text":"0.8547328205128204 +/- 0.04637716760379711\n0.9555641025641026 +/- 0.024167836658068896\n0.7799184615384616 +/- 0.06072440980219664\n0.9174066666666667 +/- 0.04237298588961886\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Basically, the SVM seems slightly better with the feature. It should added to the others."},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting\n\nTrying algorithms that uses gradient boosting to assess the performance (without fine-tuning):"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier()\nscores_xgb = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_xgb), \"+/-\", np.std(scores_xgb))","execution_count":186,"outputs":[{"output_type":"stream","text":"0.836582564102564 +/- 0.06404839968879468\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nmodel = LGBMClassifier()\nscores_gbm = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\nprint(np.mean(scores_gbm), \"+/-\", np.std(scores_gbm))","execution_count":187,"outputs":[{"output_type":"stream","text":"0.835346153846154 +/- 0.0522229364241173\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}