{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\n# 多行输出\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom fastai.tabular import *\nfrom fastai.callbacks import EarlyStoppingCallback\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import svm, neighbors\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda = LinearDiscriminantAnalysis(solver='svd', n_components=40, shrinkage=None)\npca = PCA(n_components=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fastai"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"root = Path(\"../input\")\ntrain_df = pd.read_csv(root/'train.csv')\ntest_df = pd.read_csv(root/'test.csv')\ntrain_df['wheezy-copper-turtle-magic'] = train_df['wheezy-copper-turtle-magic'].astype('category')\ntest_df['wheezy-copper-turtle-magic'] = test_df['wheezy-copper-turtle-magic'].astype('category')\nsubmission = pd.read_csv(root/'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y = train_df.groupby('target').count().iloc[:, 0]\n# y\n# wt = y.values/sum(y.values)\n# wt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# procs = [FillMissing, Categorify, Normalize]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### split validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_idx = range(round(len(train_df) * 0.9), len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df.groupby('wheezy-copper-turtle-magic').count().iloc[:, :1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 16))\nplt.bar(y.index, y['id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_cols = test_df.columns\ndep_var = 'target'\ncat_names = ['wheezy-copper-turtle-magic']\ncont_names = list(set(all_cols) - set(['id', 'wheezy-copper-turtle-magic']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = (TabularList.from_df(train_df, cat_names=cat_names, cont_names=cont_names, procs=procs)\n#         .split_by_rand_pct(0.1, seed=123)\n#         .label_from_df(cols=dep_var)\n#         .add_test(test)\n#         .databunch(path='.', device=torch.device('cuda: 0'))\n#        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.show_batch(rows=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(data.test_ds.cont_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = tabular_learner(data, layers=[512, 128], ps=[0.001, 0.001], metrics=accuracy, emb_drop=0.001,\n#                         callback_fns=[partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.0001, patience=5)]).to_fp16()\n# learn = tabular_learner(data, layers=[2000, 1000, 500, 100], ps=[0.3, 0.3, 0.2, 0.2], metrics=accuracy, emb_drop=0.01,\n#                         callback_fns=[partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.0001, patience=5)]).to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.opt_func","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.loss_func","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.lr_find()\n# learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr = 1e-2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.fit_one_cycle(100, slice(lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds, _ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = preds[:, 1].numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save"},{"metadata":{},"cell_type":"markdown","source":"LB acc: 0.70948"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission1.csv', index=None, encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## multi-model"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ = np.zeros(len(test_df))\npreds_train = np.zeros(len(train_df))\nprocs1 = [FillMissing, Normalize]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in range(512):\n    train1 = train_df[(train_df[cat_names]==cat).values.reshape(-1,)]\n    test1 = test_df[(test_df[cat_names]==cat).values.reshape(-1,)]\n    idx = test1.index\n    idx1 = train1.index\n        \n    # feature selection\n    fs = VarianceThreshold(threshold=1.5).fit(train1[cont_names])\n    train2 = fs.transform(train1[cont_names])\n    test2 = fs.transform(test1[cont_names])\n    cols = []\n    for i in range(len(cont_names)):\n        if fs.variances_[i] > 1.5:\n            cols.append(cont_names[i])\n    train3 = pd.DataFrame(train2, columns=cols)\n    test3 = pd.DataFrame(test2, columns=cols)\n    train3[dep_var] = train1[dep_var].values  # keep same index\n    \n    # reset index\n    train3.reset_index(drop=True, inplace=True)\n    # Do not reset test set's index\n    \n    # cv\n    folds = 10\n    cv = StratifiedKFold(n_splits=folds, random_state=42)\n    for train_idx, val_idx in cv.split(train2, train3[dep_var]):\n        # make data\n        data = (TabularList.from_df(train3.iloc[train_idx, :], cat_names=None, cont_names=cols, procs=procs1)\n            .split_by_rand_pct(0.1, seed=123)\n            .label_from_df(cols=dep_var)\n            .add_test(TabularList.from_df(test3, cat_names=None, cont_names=cols))\n            .databunch(path='.', device=torch.device('cuda: 0'))\n           )\n    \n        # model\n        learn = tabular_learner(data, layers=[256, 128], ps=[0.00, 0.0], metrics=accuracy, emb_drop=0.001,\n                            callback_fns=[partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.001, patience=3)]).to_fp16()\n        learn.fit_one_cycle(100, slice(1e-3))\n\n        # predict\n        preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n        preds_[idx] += preds.numpy()[:,1]/folds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = preds_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission.csv', index=None, encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## LGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_train = train_df[cat_names + cont_names]\n# new_test = test_df[cat_names + cont_names]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data, target = new_train.values, train_df['target'].values\n# X_train, X_valid, y_train, y_valid = train_test_split(data, target, test_size=0.1, random_state=123)\n# X_test = test_df[cat_names + cont_names].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params = {\n#     'boosting_type': 'gbdt',\n#     'objective': 'binary',\n#     'metric': ['auc', 'binary_logloss'],\n#     'num_leaves': 31,\n#     'learning_rate': 0.08,\n#     'n_estimators': 2000,\n# #     'slient': True,\n# #     'reg_alpha': 0.001\n# }\n\n# gbm = lgb.LGBMClassifier(**params)\n# feature_names = cat_names + cont_names\n\n# # 训练\n# gbm.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], \n#         feature_name=feature_names, categorical_feature=cat_names,\n#         eval_metric=['binary_logloss', 'auc'], early_stopping_rounds=15, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ys = gbm.predict_proba(X_valid, num_iteration=gbm.best_iteration_)\n# roc_auc_score(y_valid, ys[:, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict\n# y_pred = gbm.predict(X_valid, num_iteration=gbm.best_iteration_)\n# print(accuracy_score(y_valid, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LGB Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = gbm.predict_proba(X_test, num_iteration=gbm.best_iteration_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = y_pred[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save"},{"metadata":{},"cell_type":"markdown","source":"- auc 0.70133\n- LB auc: 0.70433"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission.csv', index=None, encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multi LGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds_test = np.zeros(len(test_df))\n# preds_train = np.zeros(len(train_df))\n# params = {\n#     'boosting_type': 'gbdt',\n#     'objective': 'binary',\n#     'metric': ['auc', 'binary_logloss'],\n#     'num_leaves': 31,\n#     'learning_rate': 0.08,\n#     'n_estimators': 2000,\n#     'slient': True\n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for cat in range(512):\n#     train1 = train_df[(train_df[cat_names]==cat).values.reshape(-1,)]\n#     test1 = test_df[(test_df[cat_names]==cat).values.reshape(-1,)]\n#     idx = test1.index\n#     idx1 = train1.index\n    \n#     # feature selection\n#     fs = VarianceThreshold(threshold=1.5).fit(train1[cont_names])\n#     train2 = fs.transform(train1[cont_names])\n#     test2 = fs.transform(test1[cont_names])\n    \n    \n#     cols = []\n#     for i in range(len(cont_names)):\n#         if fs.variances_[i] > 1.5:\n#             cols.append(cont_names[i])\n#     train3 = pd.DataFrame(train2, columns=cols)\n#     test3 = pd.DataFrame(test2, columns=cols)\n#     train3[dep_var] = train1[dep_var].values  # keep same index\n    \n#     # reset index for cv\n#     train3.reset_index(drop=True, inplace=True)\n#     # Do not reset test set's index\n    \n#     # cv\n#     folds, aucs = 10, []\n#     cv = StratifiedKFold(n_splits=folds, random_state=42)\n#     for train_idx, val_idx in cv.split(train2, train3[dep_var].values):\n#         # make data\n#         gbm = lgb.LGBMClassifier(**params)\n#         _ = gbm.fit(train2[train_idx], train3[dep_var].values[train_idx], eval_set=[(train2[val_idx], train3[dep_var].values[val_idx])], \n#         feature_name=cols, eval_metric=['binary_logloss', 'auc'], early_stopping_rounds=5, verbose=False)\n        \n#         # predict\n#         preds = gbm.predict_proba(test2, num_iteration=gbm.best_iteration_)\n#         preds_test[idx] += preds[:,1]/folds\n        \n#         # eval\n#         preds_train[idx1[val_idx]] = gbm.predict_proba(train2[val_idx,:], num_iteration=gbm.best_iteration_)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for cat in range(512):\n#     train1 = train_df[(train_df[cat_names]==cat).values.reshape(-1,)]\n#     test1 = test_df[(test_df[cat_names]==cat).values.reshape(-1,)]\n#     idx = test1.index\n#     idx1 = train1.index\n#     # reset index for cv\n#     train1.reset_index(drop=True, inplace=True)\n#     # Do not reset test set's index\n    \n#     # feature selection\n#     fs = pca.fit(train1[cont_names])\n#     train2 = fs.transform(train1[cont_names])\n#     test2 = fs.transform(test1[cont_names])\n    \n# #     fs = lda.fit(train1[cont_names], train1[dep_var])\n# #     train2 = fs.transform(train1[cont_names])\n# #     test2 = fs.transform(test1[cont_names])\n# #     print(train2.shape, test2.shape)\n    \n   \n#     # cv\n#     folds, aucs = 10, []\n#     cv = StratifiedKFold(n_splits=folds, random_state=42)\n#     for train_idx, val_idx in cv.split(train2, train1[dep_var].values):\n#         # make data\n#         gbm = lgb.LGBMClassifier(**params)\n#         _ = gbm.fit(train2[train_idx], train1[dep_var].values[train_idx], eval_set=[(train2[val_idx], train1[dep_var].values[val_idx])], \n#                     eval_metric=['binary_logloss', 'auc'], early_stopping_rounds=5, verbose=False)\n        \n#         # predict\n#         preds = gbm.predict_proba(test2, num_iteration=gbm.best_iteration_)\n#         preds_test[idx] += preds[:,1]/folds\n        \n#         # eval\n#         preds_train[idx1[val_idx]] = gbm.predict_proba(train2[val_idx,:], num_iteration=gbm.best_iteration_)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc_auc_score(train_df[dep_var], preds_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = preds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Save"},{"metadata":{},"cell_type":"markdown","source":"- cv auc 0.84  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission1.csv', index=None, encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 构建模型\n# config = {\n#     'iterations': 2000,\n#     'learning_rate': 1,\n#     'custom_loss': ['AUC', 'Accuracy'],\n#     'max_depth': 5,\n#     'loss_function': 'Logloss',\n#     'random_seed': 120,\n#     'leaf_estimation_method': 'Gradient',\n#     'l2_leaf_reg': 1e-3,\n#     'max_leaves': 31\n# }\n\n# model = CatBoostClassifier(**config)\n\n# # train\n# model.fit(X_train, y_train, use_best_model=True, plot=True, \n#           early_stopping_rounds=15, cat_features=[0], eval_set=(X_valid, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds_class = model.predict(X_valid, prediction_type='Class')\n# # acc\n# accuracy_score(y_valid, preds_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds = model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = preds[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission3.csv', index=None, encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test1 = np.zeros(len(test_df))\npreds_train = np.zeros(len(train_df))\nall_aucs = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in range(512):\n    train1 = train_df[(train_df[cat_names]==cat).values.reshape(-1,)]\n    test1 = test_df[(test_df[cat_names]==cat).values.reshape(-1,)]\n    idx = test1.index\n    idx1 = train1.index\n    \n    # feature selection\n    fs = VarianceThreshold(threshold=1.5).fit(train1[cont_names])\n    train2 = fs.transform(train1[cont_names])\n    test2 = fs.transform(test1[cont_names])\n    \n    # scale\n    scaler = StandardScaler().fit(train2)\n    train2 = scaler.transform(train2)\n    test2 = scaler.transform(test2)\n    \n    cols = []\n    for i in range(len(cont_names)):\n        if fs.variances_[i] > 1.5:\n            cols.append(cont_names[i])\n    train3 = pd.DataFrame(train2, columns=cols)\n    test3 = pd.DataFrame(test2, columns=cols)\n    train3[dep_var] = train1[dep_var].values  # keep same index\n    \n    # reset index for cv\n    train3.reset_index(drop=True, inplace=True)\n    # Do not reset test set's index\n    \n    # cv\n    folds, aucs = 10, []\n    cv = StratifiedKFold(n_splits=folds, random_state=42)\n    for train_idx, val_idx in cv.split(train2, train3[dep_var].values):\n        # make data\n        svnu = svm.NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=123, nu=0.6);\n        _ = svnu.fit(train2[train_idx], train3[dep_var].values[train_idx]);\n        p1 = svnu.predict_proba(train2[val_idx]);\n        auc = roc_auc_score(train3[dep_var].values[val_idx], p1[:, 1])\n        aucs.append(auc)\n#         print(auc)\n        \n        # predict\n        preds = svnu.predict_proba(test2)\n        preds_test1[idx] += preds[:,1]/folds\n        \n        # eval\n        preds_train[idx1[val_idx]] = svnu.predict_proba(train2[val_idx,:])[:,1]\n    all_aucs[cat] = np.mean(aucs)\n#     print(f'mean auc {cat}', np.mean(aucs))\n# print(sorted(all_aucs.items(), key=lambda x: x[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for cat in range(512):\n#     train1 = train_df[(train_df[cat_names]==cat).values.reshape(-1,)]\n#     test1 = test_df[(test_df[cat_names]==cat).values.reshape(-1,)]\n#     idx = test1.index\n#     idx1 = train1.index\n#     # reset index for cv\n#     train1.reset_index(drop=True, inplace=True)\n#     # Do not reset test set's index\n    \n#     # feature selection\n#     fs = pca.fit(train1[cont_names])\n#     train2 = fs.transform(train1[cont_names])\n#     test2 = fs.transform(test1[cont_names])\n    \n# #     fs = lda.fit(train1[cont_names], train1[dep_var])\n# #     train2 = fs.transform(train1[cont_names])\n# #     test2 = fs.transform(test1[cont_names])\n# #     print(train2.shape, test2.shape)\n    \n#     # cv\n#     folds, aucs = 10, []\n#     cv = StratifiedKFold(n_splits=folds, random_state=42)\n#     for train_idx, val_idx in cv.split(train2, train1[dep_var].values):\n#         # make data\n#         svnu = svm.NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=123, nu=0.6);\n#         _ = svnu.fit(train2[train_idx], train1[dep_var].values[train_idx]);\n#         p1 = svnu.predict_proba(train2[val_idx]);\n#         auc = roc_auc_score(train1[dep_var].values[val_idx], p1[:, 1])\n#         aucs.append(auc)\n        \n#         # predict\n#         preds = svnu.predict_proba(test2)\n#         preds_test1[idx] += preds[:,1]/folds\n        \n#         # eval\n#         preds_train[idx1[val_idx]] = svnu.predict_proba(train2[val_idx,:])[:,1]\n#     all_aucs[cat] = np.mean(aucs)\n# #     print(f'mean auc {cat}', np.mean(aucs))\n# print(sorted(all_aucs.items(), key=lambda x: x[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(train_df[dep_var], preds_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble\n1. multi LGB\n2. multi nusvm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission['target'] = preds_test1 * 0.6 + preds_test * 0.2 + preds_ * 0.2\n# submission['target'] = preds_test1 * 0.7 + preds_test * 0.3\nsubmission['target'] = preds_test1 * 0.8 + preds_ * 0.2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=None, encoding='utf-8')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}