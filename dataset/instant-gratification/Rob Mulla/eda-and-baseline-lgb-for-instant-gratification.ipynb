{"cells":[{"metadata":{},"cell_type":"markdown","source":"# lets get some instant gratification\nOverview of competition:\n- First kaggle competition to use \"Synchronous KO\" which allows for running kernels through public and private LB data prior to the deadline.\n- While this may seem like \"instant gratification\" it does require that the kernel runs first for the initial commit, and then again when submitting for a LB score- doubling the usual runtime before you can see a public LB score.\n- This does remove the need for a 2-stage competition and at the compeition deadline the final results can be revealed with no delay.\n- It's also important to note from the rules that \"submissions that result in an error--either within the kernel or within the process of scoring--will count against your daily submission limit and will not return the specific error message.\""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nimport matplotlib.pylab as plt\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\ny_train = train_df['target'].copy()\nid_train = train_df['id'].copy()\nX_train = train_df.drop(['target', 'id'], axis=1)\nid_text = test_df['id'].copy()\nX_test = test_df.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One of these things is not like the others...\n- When we display summary statistics of each feature we notice that one feature `wheezy-copper-turtle-magic` stands out."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['wheezy-copper-turtle-magic'].plot(kind='hist', bins=500, figsize=(15, 5), title='Distribution of Feature wheezy-copper-turtle-magic')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This feature is more categorical than continious\ntrain_df['wheezy-copper-turtle-magic'] = train_df['wheezy-copper-turtle-magic'].astype('category')\ntest_df['wheezy-copper-turtle-magic'] = test_df['wheezy-copper-turtle-magic'].astype('category')\nX_train['wheezy-copper-turtle-magic'] = X_train['wheezy-copper-turtle-magic'].astype('category')\nX_test['wheezy-copper-turtle-magic'] = X_test['wheezy-copper-turtle-magic'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets look at some summary statistics of features\n- Removing `wheezy-copper-turtle-magic` from this analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n\ntrain_df.drop(['target', 'wheezy-copper-turtle-magic'], axis=1). \\\n    describe().T\\\n    .sort_values('mean', ascending=False)\\\n    .drop('count', axis=1)\\\n    .T.style.background_gradient(cmap, axis=1)\\\n    .set_precision(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.drop(['wheezy-copper-turtle-magic'], axis=1). \\\n    describe().T\\\n    .sort_values('mean', ascending=False)\\\n    .drop('count', axis=1)\\\n    .T.style.background_gradient(cmap, axis=1)\\\n    .set_precision(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target in the training set is almost 50/50 Split positive/negative"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 257 Features with some interesting names.\n- stealthy-beige-pinscher-golden?\n- nerdy-indigo-wolfhound-sorted?\n\nThis data looks simulated. And the names are funny but will just require a lot of useless typing..\n\nIf we want to we could rename the columns for those of us who worked on santander... :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns = ['var_{}'.format(x) for x in range(0, 256)]\nX_test.columns = ['var_{}'.format(x) for x in range(0, 256)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_of_feat = train_df.groupby('target').agg(['mean']).T.reset_index().rename(columns={'level_0':'feature'}).drop('level_1', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_of_feat['pos_neg_diff'] = np.abs(average_of_feat[0] - average_of_feat[1])\naverage_of_feat.sort_values('pos_neg_diff', ascending=True) \\\n    .tail(20).set_index('feature')['pos_neg_diff'].plot(kind='barh',\n                                                        title='Top 20 feature with biggest difference in mean between positive and negative class',\n                                                       figsize=(15, 7),\n                                                       color='grey')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot positive vs negative feature distributions\n..pretty boring - or is it?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(10, 2, figsize=(20, 30))\ntop20_diff = average_of_feat.sort_values('pos_neg_diff', ascending=True).tail(20)['feature'].values\nax_position = 0\nfor var in top20_diff:\n    if var not in ['target','id']:\n        for i, d in train_df.groupby('target'):\n            d[var].plot(kind='hist', bins=100, alpha=0.5, title=var, label='target={}'.format(i), ax=axes.flat[ax_position])\n        axes.flat[ax_position].legend()\n        ax_position += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline LightGBM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\n\nparam = {\n    'bagging_freq': 3,\n    'bagging_fraction': 0.8,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.9,\n    'learning_rate': 0.01,\n    'max_depth': 8,  \n    'metric':'auc',\n    'min_data_in_leaf': 82,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 10,\n    'objective': 'binary', \n    'verbosity': 1\n}\nN_FOLDS = 5\nfolds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=529)\noof = np.zeros(len(X_train))\npredictions = np.zeros(len(X_test))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n    val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n\n    num_round = 1000000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 300)\n    oof[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = X_train.columns\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(y_train, oof)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save The Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv('../input/sample_submission.csv')\nss['target'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nrun_id = \"{:%m%d_%H%M}\".format(datetime.now())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save Submission\nsubmission_csv = 'submission_{:0.2f}CV_{}Folds_{}.csv'.format(roc_auc_score(y_train, oof), N_FOLDS, run_id)\nprint('Saving submission as {}'.format(submission_csv))\nss.to_csv(submission_csv, index=False)\nss.to_csv('submission.csv', index=False)\n# Save Feature Importance\nfeature_importance_csv = 'fi_{:0.2f}CV_{}Folds_{}.csv'.format(roc_auc_score(y_train, oof), N_FOLDS, run_id)\nprint('Saving feature importance as {}'.format(feature_importance_csv))\nfeature_importance_df.to_csv(feature_importance_csv, index=False)\n\n# Save OOF\noof_df = pd.DataFrame()\noof_df['oof'] = oof\noof_df['id'] = id_train\noof_df['target'] = y_train\noof_csv = 'oof_{:0.2f}CV_{}Folds_{}.csv'.format(roc_auc_score(y_train, oof), N_FOLDS, run_id)\nprint('Saving out-of-fold predictions as {}'.format(oof_csv))\noof_df.to_csv(oof_csv, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}