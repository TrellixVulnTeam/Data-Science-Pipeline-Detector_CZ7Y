{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Graphing Utility\n\nI just made this yesterday and I wanted to see how useful it is on a real project. I'm pretty happy with it, but the colors are a bit confusing."},{"metadata":{"trusted":true},"cell_type":"code","source":"def hist2D(x,y,bins,r,c,norm=False,gain=1):\n    h = np.histogram2d(x,y,bins,range=r)[0].T.reshape((bins,bins,1))\n    H = np.concatenate((h*c[0],h*c[1],h*c[2]),axis=2)\n    \n    if norm:\n        H = (H/H.max())**(1/gain)\n        H[H>1]=1\n        return H\n    return H\n\ndef histplot(x, \n             y, \n             labels, \n             bins=100, \n             normalize_each_label=False, \n             range=None, \n             colors=[[1,0,0],[0,1,0]],\n             gain = 1):\n    \n    # If Range is not specified set it to the min and max of x and y respectively\n    if range==None:\n        range=np.array(((x.min(),x.max()),(y.min(),y.max())))\n    else:\n        range = np.array(range)\n        if not range.shape == (2,2):\n            raise ValueError('range should be array-like with shape (2,2). {} is not valid'.format(range))\n    \n    \n    # Initiallize RGB image to zeros\n    H = np.zeros((bins,bins,3))\n    \n    \n    # Add each label's histogram to H\n    for i,l in enumerate(list(set(labels))):\n        idxs = np.where(labels==l)[0]\n        H = H + hist2D(x[idxs],\n                       y[idxs],\n                       bins,\n                       range,\n                       colors[l],\n                       normalize_each_label,\n                       gain\n                      )\n    \n    # Normalize and apply gain\n    im = H/H.max()\n    im[im.sum(2)==0]=1\n    \n    # Plot image\n    plt.imshow(np.flip(im,0)) # Must be flipped because vertex is at top left for images\n    \n    \n    # Draw axes\n    range_x = np.round(np.linspace(range[0][0],range[0][1],bins),2)\n    range_y = np.round(np.linspace(range[1][0],range[1][1],bins),2)\n    _ = np.arange(0,bins-1,(bins-1)//5)\n    plt.xticks(_, range_x[_])\n    plt.yticks(_, range_y[-_-1])\n    \n    # Show image\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wheezy Column\nFrom looking through other kernels I noticed a lot of people grouping data on this wheezy column. After looking into it in here I saw that it was one of 2 columns containing integer data and spanned $[0,511]$. I suppose one would have discovered this through looking at the csv, but I cheated a bit."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.loc[:10,'wheezy-copper-turtle-magic'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = df.loc[:,'wheezy-copper-turtle-magic']\nprint(w.min(),w.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = df.columns[1:-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"n=0\nm=1\n\nx = df[column_names[n]].values\ny = df[column_names[m]].values\nt = df['target'].values\n\n\nhistplot(\n    x,\n    y,\n    t,\n    bins=500,\n#     range=((-3,3.2),(-3,3)),\n    normalize_each_label=True,\n    colors = [\n        [1,0,0],\n        [0,1,1]],\n    gain=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The star shape is interesting\nIt looks like deviation along one axis decreases the likelyhood of deviation along another axis. Meaning they might __Not__ be Independent Random Variables. Lets zoom into the center to see if we're missing anything interesting"},{"metadata":{"trusted":true},"cell_type":"code","source":"histplot(\n    x,\n    y,\n    t,\n    bins=500,\n    range=((-3,3.2),(-3,3)),\n    normalize_each_label=True,\n    colors = [\n        [1,0,0],\n        [0,1,1]],\n    gain=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Doesn't look too interesting, though its a bit odd that the star pattern is not apparent at this level\n\nLet's try grouping by wheezy as the others had and see where that leads"},{"metadata":{"trusted":true},"cell_type":"code","source":"cond = df['wheezy-copper-turtle-magic'].values\nq = 0\n\n\nnew_x = x[np.where(cond==q)[0]]\nnew_y = y[np.where(cond==q)[0]]\nnew_t = t[np.where(cond==q)[0]]\n\nhistplot(\n    x,\n    y,\n    t,\n    bins=500,\n#     range=((-3,3.2),(-3,3)),\n    normalize_each_label=True,\n    colors = [\n        [1,0,0],\n        [0,1,1]],\n    gain=20)\n\n\nfor i in range(20):\n    q = i\n\n\n    new_x = x[np.where(cond==q)[0]]\n    new_y = y[np.where(cond==q)[0]]\n    new_t = t[np.where(cond==q)[0]]\n    \n    histplot(\n        new_x,\n        new_y,\n        new_t,\n        bins=100,\n        range=((-15,15),(-15,15)),\n        normalize_each_label=False,\n        colors = [\n            [1,0,0],\n            [0,1,0]],\n        gain=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thats Odd\n1. Most of the variation is attributed to a small set of values for the 'wheezy' column\n2. Clearly this is important, but there are still no obvious trends in any of the graphs.\n\n### Speculation\nMy first thought after seeing the above graphs was 'that looks oddly digital', the variation is either -15 to 15 or -3 to 3. There may be a pattern to see if we plot the 256 columns against the 512 values of 'wheezy'."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cond.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STDs = []\n\nfor j in column_names:\n    std = []\n    x = df[j].values\n    for i in range(512):\n        x_q = x[np.where(cond==i)[0]]\n        std.append(x_q.std())\n    STDs.append(std)\n\nSTDs = np.array(STDs)\nplt.imshow(STDs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bright spots correspond to high variance for a given value in 'wheezy'(x) and a given column(y)"},{"metadata":{},"cell_type":"markdown","source":"__Well I see no pattern here__<br/>\nSo it is unlikely that wheezy represents some cyclic property like day of the week. So, I think its probably a safe bet to say the test set will also span 0-511\n\nLets check to see if the _digital_ behaviour is consistent for all columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(STDs.reshape(-1,),bins =100)\n# plt.ylim(0,40)\nplt.title('Standard Deviation for a given Variable and Wheezy value')\nplt.xlabel('Standard Deviation')\nplt.ylabel('# of combinations with std=x')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ok that looks good\nI expected to get to this point eventually, but anticipated needing to scale each column. So, I'm glad I didn't need to do that. I still don't know what it means though.\nGiven the riddle \"... _careful how you __pick__ and slice_ ...\", maybe we need to pick one of these groups to train with. Though I would feel more confident if it read \"_careful how you group and pick_\", since we grouped by Wheezy and pick one of the two distribution shapes. Or maybe we __pick__ the distribution and __slice__ the feature matrix accordingly?\n\n__One interesting note__<br/>\nWhen we plotted the values of columns 0 and 1, we found that each column spanned either (-3,3) or (-15,15), so the ratio is about 5.\n\nHere, we see the same exact proportionality between the width of the peaks for the two groups, i.e. the peak on the right is about 5 times wider than the one on the left. To me, this suggests that the root cause is hidden deeper, but perhaps it is just a property of the random variables.\n\n### Lets take a closer look at these peaks before we pick one"},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stats\n\npeak_1 = STDs.reshape(-1,)[np.where(STDs.reshape(-1,)<2)[0]]\npeak_1 = peak_1[np.where(peak_1>0)[0]]\npeak_2 = STDs.reshape(-1,)[np.where(STDs.reshape(-1,)>2)[0]]\n\n\n\nh,bins = np.histogram(peak_1,bins =500)\nh = h/h.max()\nplt.plot(bins[1:],h)\n\nplt.title('Peak 1')\nplt.xlabel('Standard Deviation')\nplt.ylabel('# of combinations with std=x')\n\nx = np.linspace(0.9,1.1,500)\ny = stats.norm.pdf(x, peak_1.mean(), peak_1.std())\ny = y/y.max()\n\nplt.plot(x,y,color='orange')\nplt.show()\n\n\nh,bins = np.histogram(peak_2,bins =500)\nh = h/h.max()\nplt.plot(bins[1:],h)\n\nplt.title('Peak 2')\nplt.xlabel('Standard Deviation')\nplt.ylabel('# of combinations with std=x')\n\nx = np.linspace(2.9,4.6,500)\ny = stats.norm.pdf(x, peak_2.mean(), peak_2.std())\ny = y/y.max()\n\nplt.plot(x,y,color='orange')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pick & Slice\nStarting from the position that one of these distributions contains non-random data, maybe we'll start with the one that looks slightly less random, i.e. peak_2 which corresponds to the columns which vary from $[-15,15]$ for any given wheezy"},{"metadata":{"trusted":true},"cell_type":"code","source":"m=4\nidxs_w_0 = np.where(cond==m)[0]\nx_w_0 = df.loc[idxs_w_0,column_names[STDs[:,m]>2]].values\ny_w_0 = df.loc[idxs_w_0,'target'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model (wheezy = 0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import normalize\nfrom sklearn.svm import SVC\n\nx_w_0 = normalize(x_w_0, norm='max', axis=0, copy=False, return_norm=False)\nx_train, x_test, y_train, y_test = train_test_split(x_w_0, y_w_0, test_size=0.1,random_state=42)\n\nmodel = SVC(C=5.0, \n            kernel='rbf',\n            gamma='scale',\n            shrinking=True, \n            probability=False, \n            tol=0.001, \n            cache_size=200,\n            max_iter=-1, \n            decision_function_shape='ovr')\n\n\nmodel.fit(x_train,y_train)\ny_pred = model.predict(x_test)\nacc = accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\nprint(acc)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That looks promising. I also tried the other peak, as well as all 256 columns just to be safe. Sure enough, both performed poorly as the riddle suggests. Additionally I tried a number of other models (GMM, RandomForest, MLP,...), SVC performed the best out of the ones I tried.\n\n## 512 Separate Models (1 for each wheezy)\nInitially I included a test_train_split so that I could check the overall accuracy and coarsly tune the SVC parameters, and removed it to maximize the number of training examples before subitting my predictions. Though, you can probably do better if you gridsearch for each Wheezy to find the best params for each individual model. For SVC only the penalty parameter `C` seemed to make any significant difference."},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {}\naccs = []\nfor i in tqdm(range(512)):\n    idxs = np.where(cond==i)[0]\n    c = column_names[STDs[:,i]>2]\n    \n    x_w = df.loc[idxs, c].values\n    y = df.loc[idxs,'target'].values\n    \n    x, s = normalize(x_w, norm='max', axis=0, copy=False, return_norm=True)\n    \n    model = SVC(C=2, \n            kernel='rbf',\n            gamma='scale',\n            shrinking=False, \n            probability=False)\n\n    model.fit(x,y)\n    models[i] = [model,s,c]\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Test data and Submit Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = []\npredictions = []\nfor i in tqdm(range(512)):\n    x_df = test_df.loc[test_df['wheezy-copper-turtle-magic'] == i]\n    ids = ids + x_df.loc[:,'id'].values.tolist()\n    m,s,c = models[i]\n    x = x_df.loc[:,c].values\n    x = np.divide(x,s)\n    p = m.predict(x).tolist()\n    predictions = predictions+p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(ids),len(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'id': ids,\n                   'target': predictions})\ndf.to_csv('submission.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}