{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Pseudo Labelling + Lasso + Gaussian Mixture + PCA + QDA"},{"metadata":{},"cell_type":"markdown","source":"This notebook is a merge of  [Pseudo labelling with PCA-QDA](http://https://www.kaggle.com/rdekou/pseudo-labelling-with-pca-qda) and [GraphicalLasso + GaussianMixture](http://https://www.kaggle.com/christofhenkel/graphicallasso-gaussianmixture). Thanks to the original authors for their work. First QDA model is replaced with Lasso and Gaussian Mixture which slightly boosts the score on the LB."},{"metadata":{},"cell_type":"markdown","source":"\n## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom tqdm import tqdm\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.covariance import GraphicalLasso\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.mixture import GaussianMixture\n# from sklearn.pipeline import Pipeline\n\nfrom sklearn.svm import NuSVC\nfrom sklearn import svm, neighbors, linear_model, neural_network\nfrom sklearn.ensemble import RandomForestClassifier\nfrom tqdm import tqdm_notebook\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mean_cov(x,y):\n    model = GraphicalLasso()\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    model.fit(x2)\n    p1 = model.precision_\n    m1 = model.location_\n    \n    onesb = (y==0).astype(bool)\n    x2b = x[onesb]\n    model.fit(x2b)\n    p2 = model.precision_\n    m2 = model.location_\n    \n    ms = np.stack([m1,m2])\n    ps = np.stack([p1,p2])\n    return ms,ps\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        # MODEL AND PREDICT WITH QDA\n        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n        \n        gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n        gm.fit(np.concatenate([train3,test3],axis = 0))\n        oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n        preds[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof)\nprint('QDA scores CV =',round(auc,5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_dict = dict()\n\n# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\n\nfor i in range(512):\n\n    \n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    \n    \n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n        \n    cat_dict[i] = train3.shape[1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(list(cat_dict.items()))[1].value_counts().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add pseudo label data from PCA-QDA and run a new model Variance-QDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# INITIALIZE VARIABLES\ntest['target'] = preds\noof_qda = np.zeros(len(train))\npreds_qda = np.zeros(len(test))\noof_knn = np.zeros(len(train))\npreds_knn = np.zeros(len(test))\noof_svnu = np.zeros(len(train))\npreds_svnu = np.zeros(len(test))\noof_svc = np.zeros(len(train))\npreds_svc = np.zeros(len(test))\noof_rf = np.zeros(len(train))\npreds_rf = np.zeros(len(test))\noof_mlp = np.zeros(len(train))\npreds_mlp = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor k in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==k] \n    train2p = train2.copy(); idx1 = train2.index \n    test2 = test[test['wheezy-copper-turtle-magic']==k]\n    \n    # ADD PSEUDO LABELED DATA\n    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n    train2p = pd.concat([train2p,test2p],axis=0)\n    train2p.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    pca = PCA(n_components=cat_dict[k], random_state= 1234)\n    pca.fit(train2p[cols])\n    train3p = pca.transform(train2p[cols])\n    train3 = pca.transform(train2[cols])\n    test3 = pca.transform(test2[cols])\n    \n    # STRATIFIED K FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3p, train2p['target']):\n        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n        \n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_qda[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_qda[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = neighbors.KNeighborsClassifier(n_neighbors=17, p=2.9)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_knn[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_knn[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_svnu[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_svnu[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = svm.SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_svc[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_svc[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = RandomForestClassifier(n_estimators=100,random_state=1)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_rf[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_rf[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, ))\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_mlp[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_mlp[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n       \n       \n    if k%32==0: print(k)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof_qda)\nprint('Pseudo Labeled QDA scores CV =',round(auc,5)) #0.97035 #0.96917..?why different?\nauc = roc_auc_score(train['target'],oof_knn)\nprint('Pseudo Labeled KNN scores CV =',round(auc,5))\nauc = roc_auc_score(train['target'],oof_svnu)\nprint('Pseudo Labeled SVNU scores CV =',round(auc,5)) #0.9578\nauc = roc_auc_score(train['target'],oof_svc) #0.96004\nprint('Pseudo Labeled SVC scores CV =',round(auc,5))\nauc = roc_auc_score(train['target'],oof_rf) #0.87847\nprint('Pseudo Labeled RF scores CV =',round(auc,5))\nauc = roc_auc_score(train['target'],oof_mlp)\nprint('Pseudo Labeled MLP scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 3 & 4 - Add pseudo label data and build second mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ntest['target'] = preds\noof_qda2 = np.zeros(len(train))\npreds_qda2 = np.zeros(len(test))\noof_knn2 = np.zeros(len(train)) \npreds_knn2 = np.zeros(len(test))\noof_svnu2 = np.zeros(len(train)) \npreds_svnu2 = np.zeros(len(test))\noof_svc2 = np.zeros(len(train)) \npreds_svc2 = np.zeros(len(test))\noof_rf2 = np.zeros(len(train)) \npreds_rf2 = np.zeros(len(test))\noof_mlp2 = np.zeros(len(train)) \npreds_mlp2 = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor k in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==k] \n    train2p = train2.copy(); idx1 = train2.index \n    test2 = test[test['wheezy-copper-turtle-magic']==k]\n    \n    # ADD PSEUDO LABELED DATA\n    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n    train2p = pd.concat([train2p,test2p],axis=0)\n    train2p.reset_index(drop=True,inplace=True)\n\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n    train3p = sel.transform(train2p[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n           \n        \n    # STRATIFIED K FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3p, train2p['target']):\n        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n        \n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_qda2[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_qda2[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        # Model add svnu, svc, rf\n        clf = neighbors.KNeighborsClassifier(n_neighbors=17, p=2.9)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_knn2[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_knn2[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_svnu2[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_svnu2[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = svm.SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_svc2[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_svc2[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = RandomForestClassifier(n_estimators=100,random_state=1)\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_rf2[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_rf2[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, ))\n        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_mlp2[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n        preds_mlp2[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n        \n       \n    if k%32==0: print(k)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof_qda2) #0.97033\nprint('Pseudo Labeled QDA scores CV =',round(auc,5))\nprint('----------------')\nprint('knn', roc_auc_score(train['target'], oof_knn2)) \nprint('svc', roc_auc_score(train['target'], oof_svc2)) #0.9457979278710315\nprint('svnu', roc_auc_score(train['target'], oof_svnu2)) #0.9607969615628373\nprint('rf', roc_auc_score(train['target'], oof_rf2)) #0.8681422696974617\nprint('mlp', roc_auc_score(train['target'], oof_mlp2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final model accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# auc = roc_auc_score(train['target'],0.5*(oof_var+ oof_var2) )\n# print('Pseudo Labeled QDA scores CV =',round(auc,5)) #0.96959\n\n# auc = roc_auc_score(train['target'],0.5*(oof_svnu+ oof_svnu2) )\n# print('Pseudo Labeled SVNU scores CV =',round(auc,5)) #0.96067","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc = roc_auc_score(train['target'],oof_qda2*0.6+oof_svnu2*0.25 + oof_svc2*0.05 +oof_rf2*0.1)\nprint('Pseudo Labeled BLEND scores CV =',round(auc,5)) #0.96858","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc = roc_auc_score(train['target'],oof_qda2*0.5+oof_svnu2*0.3 + oof_svc2*0.05 +  oof_knn2*0.025 + oof_rf2*0.1 +  oof_mlp2*0.025)\nprint('Pseudo Labeled BLEND2 scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\n# sub['target'] = 0.5* preds_var + 0.5*preds_var2\nsub['target'] = preds_qda2\nsub.to_csv('submission.csv',index=False)\n\nimport matplotlib.pyplot as plt\nplt.hist(preds,bins=100)\nplt.title('Final Test.csv predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\n# sub['target'] = 0.6*+preds_var2 + 0.4*preds_svnu2\nsub['target'] = preds_qda2*0.6+preds_svnu2*0.25 + preds_svc2*0.05 +preds_rf2*0.1\nsub.to_csv('submission_blend.csv',index=False)\n\nimport matplotlib.pyplot as plt\nplt.hist(preds,bins=100)\nplt.title('Blend Test.csv predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\n# oof_qda2*0.5+oof_svnu2*0.3 + oof_svc2*0.05 +  oof_knn2*0.025 + oof_rf2*0.1 +  oof_mlp2*0.025\nsub['target'] = preds_qda2*0.5+preds_svnu2*0.3 + preds_svc2*0.05 +  preds_knn2*0.025 + preds_rf2*0.1 +  preds_mlp2*0.025\nsub.to_csv('submission_blend2.csv',index=False)\n\nimport matplotlib.pyplot as plt\nplt.hist(preds,bins=100)\nplt.title('Blend2 Test.csv predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}