{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom scipy.stats import norm\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index('id', drop=True, inplace=True)\ntarget = train.target\ntrain.drop('target', axis=1, inplace=True)\ntest.set_index('id', drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all columns are float64, let's see if any is not actually float."},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in train.columns:\n    if train[column].dtype != np.float64:\n        print(column, train[column].dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['wheezy-copper-turtle-magic'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a column, which as many has figured out is probably not relevant to the data, but rathen an index.\nIf has values from 0 to 511, only integers. One idea is to create 512 distinct classifier, and depending on wheezy-copper-turtle-magic value, you would use the classifier trained for it. If this provided better accuracy scores than ignoring this value all together and using 1 classifier only then our initial idea could possibly be correct.\n\nI will plot all other float columns on a kdeplot just to see how the data looks like and if there is any significant other columns that we should consider."},{"metadata":{"trusted":true},"cell_type":"code","source":"float_features = list(train.columns)\nfloat_features.remove('wheezy-copper-turtle-magic')\n\nplt.figure(figsize=(10,4))\nfor feature in float_features:\n    g = sns.kdeplot(train[feature], shade=True)\n    g.legend().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the features, more or less, appear to have similar distribution. Gaussian or not?\nWe can try to plot a perfect Gaussian having the same mean and std to decide."},{"metadata":{"trusted":true},"cell_type":"code","source":"mu = np.mean(train[float_features[0]])\nsigma = np.std(train[float_features[0]])\n\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\nplt.plot(x, norm.pdf(x, mu, sigma))\nsns.kdeplot(train[float_features[0]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So no, they are not Gaussian indeed. They are much taller and thinner than Gaussian distribution having same mean and standard deviation. \nDoes this really matter for our model? That depends on which classifier/kernel you decided to choose. Some kernels/classifiers are designed to work best with Gaussian data, others don't really care (decsion trees as an example)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature selection -- To be implemented later on\nfeatures = train.columns\n\n# Splitting into train sets and test sets\nx_train, x_test, y_train, y_test = train_test_split(train[features], target, \n                                                    train_size=0.8, test_size=0.2,\n                                                    random_state=555)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Naive Model:\nI will just drop the turtle magic column, create a single classifier, and see the results. I will approach it using SVM and Decsion Trees for now. \nGiven the number of rows, it would be impractical to use the RBF kernel on the whole data as training time will be very large.\nWe can however explore the possibility of using the Nystroem transformer or poly kernel directly if we see any hope.\nI would just use the first 2.5K rows to see how things are going."},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = SVC(kernel = 'rbf')\nclassifier.fit(x_train[:2500].drop('wheezy-copper-turtle-magic', axis=1), y_train[:2500])\nprint(classifier.score(x_test.drop('wheezy-copper-turtle-magic', axis=1), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = DecisionTreeClassifier(criterion='entropy', random_state=555)\nclassifier.fit(x_train[:2500].drop('wheezy-copper-turtle-magic', axis=1), y_train[:2500])\nprint(classifier.score(x_test.drop('wheezy-copper-turtle-magic', axis=1), y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is obvious that things are pretty much going nowhere using this approach... The data could indeed be meaningless if combined together and turtle-magic is the secret column in this competition. So, Let's try and train distinct 512 classifier!"},{"metadata":{},"cell_type":"markdown","source":"# A Corrected Approach:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('wheezy-copper-turtle-magic').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)/512","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 512 subsets of around 512 rows per subset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classify using turtle-magic as index for datasets without any parameter tuning...\nscore_trees = []\nscore_svm = []\n\nfor i in range(512):\n    sub_train = x_train[x_train['wheezy-copper-turtle-magic'] == i]\n    sub_target_train = target.loc[sub_train.index]\n    sub_test = x_test[x_test['wheezy-copper-turtle-magic'] == i]\n    sub_target_test = target.loc[sub_test.index]\n    \n    classifier = DecisionTreeClassifier(criterion='entropy', random_state=555)\n    classifier.fit(sub_train, sub_target_train)\n    score_trees.append(classifier.score(sub_test, sub_target_test))\n    \n    classifier = SVC(kernel = 'rbf')\n    classifier.fit(sub_train, sub_target_train)\n    score_svm.append(classifier.score(sub_test, sub_target_test))\n    if i % 40 == 0: print('Completed: {:.1f}%'.format(i*100/512))\nprint('Trees:', np.mean(score_trees))\nprint('SVM:', np.mean(score_svm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The SVM score looks promising! We still did not try to tune the gamma or C parameters or use any feature selection.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection, Grid Search with cross-validation for every turtle-magic\n# This will take a  long time.. \nscore_svm = []\nbest_c = []\nbest_gamma = []\nbest_features_mask = []\n\nfor i in range(512):\n    sub_train = train[train['wheezy-copper-turtle-magic'] == i]\n    sub_target_train = target.loc[sub_train.index]\n    \n    sel = VarianceThreshold(threshold=3) # returns around 40 features +- ..\n    \n    sub_train = sel.fit_transform(sub_train)\n    best_features_mask.append(sel.get_support())\n\n    C_range = [0.75, 1.5, 3]\n    gamma_range = [0.0012, 0.0016, 0.002, 0.0024, 0.0028, 0.0032, 0.0036]\n    param_grid = dict(gamma=gamma_range, C=C_range)\n    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.075)\n    grid = GridSearchCV(SVC(kernel = 'rbf'), param_grid=param_grid, cv=cv)\n    grid.fit(sub_train, sub_target_train)\n\n    best_c.append(grid.best_params_['C'])\n    best_gamma.append(grid.best_params_['gamma'])\n\n    if i % 15 == 0: print(\"Best parameters for turtle-magic {}: (C: {} & gamma: {}) - Best score of {:.3f} - Picked n_features = {}\".format(i, grid.best_params_['C'], grid.best_params_['gamma'], grid.best_score_, sub_train.shape[1]))\n    if i % 15 == 0: print('Completed: {:.1f}%'.format(i*100/512))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission.set_index('id', drop=False, inplace=True)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(512):\n\n    sub_train = train[train['wheezy-copper-turtle-magic'] == i]\n    sub_target_train = target.loc[sub_train.index]\n    \n    sub_test = test[test['wheezy-copper-turtle-magic'] == i]\n    \n    sub_features = sub_train.columns[best_features_mask[i]]\n    \n    classifier = SVC(kernel = 'rbf', C=best_c[i], gamma=best_gamma[i])\n    classifier.fit(sub_train[sub_features], sub_target_train)\n    \n    prediction = classifier.predict(sub_test[sub_features])\n    df = pd.DataFrame({'id': sub_test.index, 'target': prediction})\n    df.set_index('id', inplace=True)\n    submission.update(df)\n    if i % 40 == 0: print('Completed: {:.1f}%'.format(i*100/512))\nsubmission.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}