{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nfrom sklearn.covariance import LedoitWolf, OAS\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.cluster import KMeans, Birch\nfrom sklearn.pipeline import Pipeline\nfrom scipy.stats import multivariate_normal\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom scipy.stats import rankdata\nfrom scipy.optimize import minimize\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install MulticoreTSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from MulticoreTSNE import MulticoreTSNE as TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modif_list =  [7, 24, 27,28, 36, 42,49,52,54, 71,72, 79,\n    81, 85,87,89,92, 93, 94, 95, 96, 102, 103,\n    104, 107,109, 114, 125, 129, 130, 131, 143,\n    149,151, 152, 162,166, 177, 182,187, 193,194, 195,\n    197, 198, 206,207, 208,211, 213, 220,\n    221, 222, 230,233, 234, 235, 242,244,251,\n    252,258, 262, 263, 264, 266, 268, 270, 271, 273,\n    287, 289,293,308, 310, 312,313, 315,320, 321,\n    328, 329, 332, 333, 335, 342,344,345,346,\n    349, 335, 356, 357, 369, 372, 373,374, 375, 377,\n    380, 381, 383, 384, 386, 387, 388, 393, 394, 404,\n    411, 412, 415, 419, 422, 425, 426,427, 431,433,\n    435, 436, 437, 443, 449, 451, 457, 458, 465, 471,\n    486,487, 489, 490, 491,495, 498, 499, 501, 508, 509, 510]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n7: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n24: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n27: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n28: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n36: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n42: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n49: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n52: {'init_params': 'random', 'n_init': 1, 'reg_covar': 1e-06},\n54: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n71: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n72: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n79: {'init_params': 'kmeans', 'n_init': 5, 'reg_covar': 1e-08},\n81: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n85: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n87: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n89: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n92: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n93: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n94: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n95: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n96: {'init_params': 'random', 'n_init': 10, 'reg_covar': 0.01},\n102: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1}, \n103: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n104: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 1e-08},\n107: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 1e-06},\n109: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 0.0001},\n114: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n125: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n129: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n130: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n131: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n143: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n149: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n151: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n152: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n162: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n166: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 1e-08},\n177: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n182: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n187: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n193: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n194: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n195: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-08},\n197: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 0.0001},\n198: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 1e-08},\n206: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 1e-08},\n207: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n208: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n211: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 1e-06},\n213: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 1e-06},\n220: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n221: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.1},\n222: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n230: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n233: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n234: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n235: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n242: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-08},\n244: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n251: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.0001},\n252: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n258: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06}, \n262: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n263: {'init_params': 'kmeans', 'n_init': 5, 'reg_covar': 0.01},\n264: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n266: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n268: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n270: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n271: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n273: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.0001},\n287: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n289: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 1e-06},\n293: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n308: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n310: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n312: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06},\n313: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n315: {'init_params': 'random', 'n_init': 30, 'reg_covar': 0.0001},\n320: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n321: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n328: {'init_params': 'random', 'n_init': 1, 'reg_covar': 0.0001},\n329: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n332: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n333: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n335: {'init_params': 'random', 'n_init': 20, 'reg_covar': 0.01},\n342: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n344: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n345: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n346: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n349: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n356: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06},\n357: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n369: {'init_params': 'random', 'n_init': 30, 'reg_covar': 0.0001},\n372: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 1e-06},\n373: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n374: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n375: {'init_params': 'kmeans', 'n_init': 5, 'reg_covar': 0.0001},\n377: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n380: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06},\n381: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n383: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.01},\n384: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n386: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 1e-08},\n387: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-08},\n388: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.1},\n393: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06},\n394: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 1e-06},\n404: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n411: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.0001},\n412: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 0.0001},\n415: {'init_params': 'random', 'n_init': 1, 'reg_covar': 0.0001},\n419: {'init_params': 'random', 'n_init': 30, 'reg_covar': 0.0001},\n422: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n425: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n426: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n427: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n431: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-08},\n433: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n435: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n436: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-08},\n437: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06},\n443: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 1e-06},\n449: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n451: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n457: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 0.1},\n458: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.01},\n465: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.1},\n471: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.1},\n486: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01},\n487: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n489: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.0001},\n490: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 1e-06},\n491: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n495: {'init_params': 'kmeans', 'n_init': 5, 'reg_covar': 0.01},\n498: {'init_params': 'kmeans', 'n_init': 1, 'reg_covar': 0.0001},\n499: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.0001},\n501: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.0001},\n508: {'init_params': 'kmeans', 'n_init': 20, 'reg_covar': 0.1},\n509: {'init_params': 'kmeans', 'n_init': 10, 'reg_covar': 0.1},\n510: {'init_params': 'kmeans', 'n_init': 30, 'reg_covar': 0.01}}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof    = np.zeros((len(train),4))\npreds  = np.zeros((len(test) ,4))\noof2   = np.zeros((len(train),4))\npreds2 = np.zeros((len(test) ,4))\noof3   = np.zeros((len(train),1))\npreds3 = np.zeros((len(test) ,1))\nooff   = np.zeros((len(train),4))\npredsf = np.zeros((len(test) ,4))\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    #pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler',  RobustScaler(quantile_range=(25, 75)))])\n    pipe = Pipeline([('vt', VarianceThreshold(threshold=1.5)), ('scaler',  RobustScaler(quantile_range=(35, 65)))])\n    sel = pipe.fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    print(train3.shape)\n\n    # embeddings1 = TSNE(n_jobs=4,\n    #                    n_components=5,\n    #                    perplexity=30.0,\n    #                    early_exaggeration=12.0,\n    #                    learning_rate=20.0,\n    #                    n_iter=1000,\n    #                    n_iter_without_progress=50\n    #                   ).fit_transform( np.concatenate([train3,test3],axis = 0) )\n    # train3 = np.hstack( (train3, embeddings1[:train3.shape[0],:]) )\n    # test3  = np.hstack( ( test3, embeddings1[train3.shape[0]:,:]) )\n\n    # km = KMeans(n_clusters=8, n_jobs=4 )\n    # km = km.fit_transform( np.concatenate([train3,test3],axis = 0) )\n    # train3 = np.hstack( (train3, km[:train3.shape[0],:]) )\n    # test3  = np.hstack( ( test3, km[train3.shape[0]:,:]) )\n    # print(train3.shape)\n\n    NK = 2\n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        oof_test_index = [t for t in test_index if t < len(idx1)]\n\n        x = train3[train_index]\n        y = train2.loc[train_index,'target'].values\n        x1 = x[(y==1).astype(bool)]\n        cc1 = Birch(threshold=0.5, branching_factor=150, n_clusters=NK, compute_labels=True).fit_predict(x1)\n        x11 = x1[cc1==0]\n        x12 = x1[cc1==1]\n        model11 = OAS(assume_centered =False).fit(x11)\n        p11 = model11.precision_\n        m11 = model11.location_ \n        model12 = OAS(assume_centered =False).fit(x12)\n        p12 = model12.precision_\n        m12 = model12.location_ \n\n        x2 = x[(y==0).astype(bool)]\n        cc2 = Birch(threshold=0.5, branching_factor=150, n_clusters=NK, compute_labels=True).fit_predict(x2)\n        x21 = x2[cc2==0]\n        x22 = x2[cc2==1]\n        model21 =  OAS(assume_centered =False).fit(x21)\n        p21 = model21.precision_\n        m21 = model21.location_ \n        model22 =  OAS(assume_centered =False).fit(x22)\n        p22 = model22.precision_\n        m22 = model22.location_ \n\n        ms = np.stack([m11,m12,m21,m22])\n        ps = np.stack([p11,p12,p21,p22])\n\n        gm = GaussianMixture(n_components=4,random_state=42, covariance_type='full', means_init=ms, precisions_init=ps, tol=0.000001, max_iter=1000 )\n        gm.fit(np.concatenate([train3[train_index],test3],axis = 0))\n        oof[idx1[oof_test_index]] = gm.predict_proba(train3[oof_test_index,:])\n        preds[idx2] += gm.predict_proba(test3) / skf.n_splits\n\n        x = train3[train_index[:int(0.95*len(train_index))]]\n        y = train2.loc[train_index[:int(0.95*len(train_index))],'target'].values\n        x1 = x[(y==1).astype(bool)]\n        cc1 = Birch(threshold=0.5, branching_factor=150, n_clusters=NK, compute_labels=True).fit_predict(x1)\n        x11 = x1[cc1==0]\n        x12 = x1[cc1==1]\n        model11 = OAS(assume_centered =False).fit(x11)\n        p11 = model11.precision_\n        m11 = model11.location_ \n        model12 = OAS(assume_centered =False).fit(x12)\n        p12 = model12.precision_\n        m12 = model12.location_ \n\n        x2 = x[(y==0).astype(bool)]\n        cc2 = Birch(threshold=0.5, branching_factor=150, n_clusters=NK, compute_labels=True).fit_predict(x2)\n        x21 = x2[cc2==0]\n        x22 = x2[cc2==1]\n        model21 =  OAS(assume_centered =False).fit(x21)\n        p21 = model21.precision_\n        m21 = model21.location_ \n        model22 =  OAS(assume_centered =False).fit(x22)\n        p22 = model22.precision_\n        m22 = model22.location_ \n\n        ms = np.stack([m11,m12,m21,m22])\n        ps = np.stack([p11,p12,p21,p22])    \n\n        gm = GaussianMixture(n_components=4,random_state=43, covariance_type='full', means_init=ms, precisions_init=ps, tol=0.000001, max_iter=500 )\n        gm.fit(np.concatenate([train3[train_index[:int(0.95*len(train_index))]],test3[:int(0.95*test3.shape[0])]],axis = 0))\n        oof[idx1[oof_test_index]] += gm.predict_proba(train3[oof_test_index,:])\n        preds[idx2] += gm.predict_proba(test3) / skf.n_splits\n\n\n\n        x = train3[train_index[int(0.15*len(train_index)):]]\n        y = train2.loc[train_index[int(0.15*len(train_index)):],'target'].values\n        x1 = x[(y==1).astype(bool)]\n        cc1 = Birch(threshold=0.5, branching_factor=150, n_clusters=NK, compute_labels=True).fit_predict(x1)\n        x11 = x1[cc1==0]\n        x12 = x1[cc1==1]\n        model11 = OAS(assume_centered =False).fit(x11)\n        p11 = model11.precision_\n        m11 = model11.location_ \n        model12 = OAS(assume_centered =False).fit(x12)\n        p12 = model12.precision_\n        m12 = model12.location_ \n\n        x2 = x[(y==0).astype(bool)]\n        cc2 = Birch(threshold=0.5, branching_factor=150, n_clusters=NK, compute_labels=True).fit_predict(x2)\n        x21 = x2[cc2==0]\n        x22 = x2[cc2==1]\n        model21 =  OAS(assume_centered =False).fit(x21)\n        p21 = model21.precision_\n        m21 = model21.location_ \n        model22 =  OAS(assume_centered =False).fit(x22)\n        p22 = model22.precision_\n        m22 = model22.location_ \n\n        ms = np.stack([m11,m12,m21,m22])\n        ps = np.stack([p11,p12,p21,p22])      \n\n        gm = GaussianMixture(n_components=4,random_state=44, covariance_type='full', means_init=ms, precisions_init=ps, tol=0.000001, max_iter=500 )\n        gm.fit(np.concatenate([train3[train_index[int(0.15*len(train_index)):]],test3[int(0.15*test3.shape[0]):]],axis = 0))\n        oof[idx1[oof_test_index]] += gm.predict_proba(train3[oof_test_index,:])\n        preds[idx2] += gm.predict_proba(test3) / skf.n_splits\n\n#         clf = LGBMClassifier(num_leaves=7,\n#                              max_depth=-1,\n#                              learning_rate=0.01,\n#                              n_estimators=1000,\n#                              min_child_samples=50,\n#                              subsample=0.34,\n#                              subsample_freq=1,\n#                              colsample_bytree=0.67,\n#                              reg_alpha=0.1)\n#         train_index2 = train_index[ int(0.05*len(train_index)): ] \n#         clf.fit(train3[train_index2,:],train2.loc[train_index2]['target'])\n#         oof3[idx1[test_index],0] += clf.predict_proba(train3[oof_test_index,:])[:,1]\n#         preds3[idx2,0]           += clf.predict_proba(test3)[:,1] / skf.n_splits\n\n        train_index2 = train_index[ :int(0.95*len(train_index)) ] \n        clf = KNeighborsClassifier(n_neighbors=50, metric='braycurtis' )\n        clf.fit(train3[train_index2,:],train2.loc[train_index2]['target'])\n        oof3[idx1[test_index],0] += clf.predict_proba(train3[oof_test_index,:])[:,1]\n        preds3[idx2,0]           += clf.predict_proba(test3)[:,1] / skf.n_splits\n\n\n\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1] ) )\n    # print('Optimize')\n    # for train_index, test_index in skf.split(train3, train2['target']):\n    #     def min_func( k ):\n    #         tmp = ( oof[idx1[train_index],0]*k[0])\n    #         tmp+= ( oof[idx1[train_index],1]*k[1])\n    #         sc = roc_auc_score( train2['target'].values[train_index], tmp  )\n    #         return -sc\n    #     k = minimize(min_func, [1.,1.] , method='Nelder-Mead', tol=1e-6,  options={'maxiter': 100} ).x\n    #     tmp = ( oof[idx1[test_index],0]*k[0])\n    #     tmp+= ( oof[idx1[test_index],1]*k[1])\n    #     ooff[idx1[test_index],0] = tmp\n\n    # print( roc_auc_score(train2['target'], ooff[idx1,0]) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+0.10*oof3[idx1,0] ) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+0.20*oof3[idx1,0] ) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+0.40*oof3[idx1,0] ) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+0.50*oof3[idx1,0] ) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+0.60*oof3[idx1,0] ) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+0.80*oof3[idx1,0] ) )\n    print( roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1]+1.00*oof3[idx1,0] ) )\n\n    px = np.where( train['wheezy-copper-turtle-magic']<=i )[0]\n    print( roc_auc_score(train['target'].values[px], oof[px,0]+oof[px,1]+0.10*oof3[px,0] ) )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof    = np.zeros((len(train),4))\npreds  = np.zeros((len(test) ,4))\noof2   = np.zeros((len(train),4))\npreds2 = np.zeros((len(test) ,4))\noof3   = np.zeros((len(train),1))\npreds3 = np.zeros((len(test) ,1))\nooff   = np.zeros((len(train),4))\npredsf = np.zeros((len(test) ,4))\nK2=[]\nK3=[]\nK4=[]\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    #pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler',  RobustScaler(quantile_range=(25, 75)))])\n    pipe = Pipeline([('vt', VarianceThreshold(threshold=1.5)), ('scaler',  RobustScaler(quantile_range=(35, 65)))])\n    sel = pipe.fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    print(train3.shape)\n\n    NK = 2\n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=16, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        oof_test_index = [t for t in test_index if t < len(idx1)]\n\n        x = train3[train_index]\n        y = train2.loc[train_index,'target'].values\n        x1 = x[(y==1).astype(bool)]\n        cc1 = Birch(threshold=0.5, branching_factor=100, n_clusters=NK, compute_labels=True).fit_predict(x1)\n        x11 = x1[cc1==0]\n        x12 = x1[cc1==1]\n        model11 = OAS(assume_centered =False).fit(x11)\n        p11 = model11.precision_\n        m11 = model11.location_ \n        model12 = OAS(assume_centered =False).fit(x12)\n        p12 = model12.precision_\n        m12 = model12.location_ \n\n        x2 = x[(y==0).astype(bool)]\n        cc2 = Birch(threshold=0.5, branching_factor=100, n_clusters=NK, compute_labels=True).fit_predict(x2)\n        x21 = x2[cc2==0]\n        x22 = x2[cc2==1]\n        model21 =  OAS(assume_centered =False).fit(x21)\n        p21 = model21.precision_\n        m21 = model21.location_ \n        model22 =  OAS(assume_centered =False).fit(x22)\n        p22 = model22.precision_\n        m22 = model22.location_ \n\n        ms = np.stack([m11,m12,m21,m22])\n        ps = np.stack([p11,p12,p21,p22])\n\n        gm = GaussianMixture(n_components=4,random_state=42, covariance_type='full', means_init=ms, precisions_init=ps, tol=0.000001, max_iter=1000 )\n        gm.fit(np.concatenate([train3[train_index],test3],axis = 0))\n        oof[idx1[oof_test_index]] = gm.predict_proba(train3[oof_test_index,:])\n        #preds[idx2] += gm.predict_proba(test3) / skf.n_splits\n    sc2 = roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1] )\n\n    \n    NK = 3\n    # STRATIFIED K-FOLD\n    for train_index, test_index in skf.split(train3, train2['target']):\n        oof_test_index = [t for t in test_index if t < len(idx1)]\n\n        x = train3[train_index]\n        y = train2.loc[train_index,'target'].values\n        x1 = x[(y==1).astype(bool)]\n        cc1 = Birch(threshold=0.5, branching_factor=100, n_clusters=NK, compute_labels=True).fit_predict(x1)\n        x11 = x1[cc1==0]\n        x12 = x1[cc1==1]\n        model11 = OAS(assume_centered =False).fit(x11)\n        p11 = model11.precision_\n        m11 = model11.location_ \n        model12 = OAS(assume_centered =False).fit(x12)\n        p12 = model12.precision_\n        m12 = model12.location_ \n\n        x2 = x[(y==0).astype(bool)]\n        cc2 = Birch(threshold=0.5, branching_factor=100, n_clusters=NK, compute_labels=True).fit_predict(x2)\n        x21 = x2[cc2==0]\n        x22 = x2[cc2==1]\n        model21 =  OAS(assume_centered =False).fit(x21)\n        p21 = model21.precision_\n        m21 = model21.location_ \n        model22 =  OAS(assume_centered =False).fit(x22)\n        p22 = model22.precision_\n        m22 = model22.location_ \n\n        ms = np.stack([m11,m12,m21,m22])\n        ps = np.stack([p11,p12,p21,p22])\n\n        gm = GaussianMixture(n_components=4,random_state=42, covariance_type='full', means_init=ms, precisions_init=ps, tol=0.000001, max_iter=1000 )\n        gm.fit(np.concatenate([train3[train_index],test3],axis = 0))\n        oof[idx1[oof_test_index]] = gm.predict_proba(train3[oof_test_index,:])\n        #preds[idx2] += gm.predict_proba(test3) / skf.n_splits\n    sc3 = roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1] )\n\n    NK = 4\n    # STRATIFIED K-FOLD\n    for train_index, test_index in skf.split(train3, train2['target']):\n        oof_test_index = [t for t in test_index if t < len(idx1)]\n\n        x = train3[train_index]\n        y = train2.loc[train_index,'target'].values\n        x1 = x[(y==1).astype(bool)]\n        cc1 = Birch(threshold=0.5, branching_factor=100, n_clusters=NK, compute_labels=True).fit_predict(x1)\n        x11 = x1[cc1==0]\n        x12 = x1[cc1==1]\n        model11 = OAS(assume_centered =False).fit(x11)\n        p11 = model11.precision_\n        m11 = model11.location_ \n        model12 = OAS(assume_centered =False).fit(x12)\n        p12 = model12.precision_\n        m12 = model12.location_ \n\n        x2 = x[(y==0).astype(bool)]\n        cc2 = Birch(threshold=0.5, branching_factor=100, n_clusters=NK, compute_labels=True).fit_predict(x2)\n        x21 = x2[cc2==0]\n        x22 = x2[cc2==1]\n        model21 =  OAS(assume_centered =False).fit(x21)\n        p21 = model21.precision_\n        m21 = model21.location_ \n        model22 =  OAS(assume_centered =False).fit(x22)\n        p22 = model22.precision_\n        m22 = model22.location_ \n\n        ms = np.stack([m11,m12,m21,m22])\n        ps = np.stack([p11,p12,p21,p22])\n\n        gm = GaussianMixture(n_components=4,random_state=42, covariance_type='full', means_init=ms, precisions_init=ps, tol=0.000001, max_iter=1000 )\n        gm.fit(np.concatenate([train3[train_index],test3],axis = 0))\n        oof[idx1[oof_test_index]] = gm.predict_proba(train3[oof_test_index,:])\n        #preds[idx2] += gm.predict_proba(test3) / skf.n_splits\n    sc4 = roc_auc_score(train2['target'], oof[idx1,0]+oof[idx1,1] )\n\n        \n    K2.append(sc2)\n    K3.append(sc3)\n    K4.append(sc4)\n\n    print( sc2,sc3,sc4 )\n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( ','.join(K2) )\nprint( ','.join(K3) )\nprint( ','.join(K4) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}