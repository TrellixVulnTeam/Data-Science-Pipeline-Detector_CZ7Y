{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pickle\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.mixture import GaussianMixture, BayesianGaussianMixture\nfrom scipy.special import comb, logsumexp, expit\nfrom scipy.stats import rankdata\nfrom tqdm import tqdm_notebook\nnp.random.seed(1111)\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/instant-gratification/train.csv')\ntest = pd.read_csv('../input/instant-gratification/test.csv')\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gm_list = pickle.load(open('../input/models-v5/gm_models_v5.pkl', 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyGM(GaussianMixture):\n    \n    def __init__(self, n_components=1, covariance_type='full', tol=1e-3,\n                 reg_covar=1e-6, max_iter=100, n_init=1, init_params='kmeans',\n                 weights_init=None, means_init=None, precisions_init=None,\n                 random_state=None, warm_start=False,\n                 verbose=0, verbose_interval=10, init_clusters=None, y=None):\n        super().__init__(\n            n_components=n_components, tol=tol, reg_covar=reg_covar,\n            max_iter=max_iter, n_init=n_init, init_params=init_params,\n            random_state=random_state, warm_start=warm_start,\n            verbose=verbose, verbose_interval=verbose_interval)\n        self.init_clusters_ = np.asarray(init_clusters).astype('int')\n        self.y = y\n        \n    def _initialize_parameters(self, X, random_state):\n        \"\"\"Initialize the model parameters.\n        Parameters\n        ----------\n        X : array-like, shape  (n_samples, n_features)\n        random_state : RandomState\n            A random number generator instance.\n        \"\"\"\n        n_samples, _ = X.shape\n\n        if self.init_params == 'kmeans':\n            resp = np.zeros((n_samples, self.n_components))\n            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n                                   random_state=random_state).fit(X).labels_\n            resp[np.arange(n_samples), label] = 1\n        elif self.init_params == 'random':\n            resp = random_state.rand(n_samples, self.n_components)\n            resp /= resp.sum(axis=1)[:, np.newaxis]\n        elif self.init_params == 'clusters':\n            resp = np.zeros((n_samples, self.n_components))\n            resp[np.arange(self.init_clusters_.shape[0]), self.init_clusters_] = 1\n        else:\n            raise ValueError(\"Unimplemented initialization method '%s'\"\n                             % self.init_params)\n\n        self._initialize(X, resp)\n     \n    def estimate_log_ratio(self, X):\n            weighted_log_prob = self._estimate_weighted_log_prob(X)\n            return logsumexp(weighted_log_prob[:, 1::2], axis=1) - logsumexp(weighted_log_prob[:, 0::2], axis=1)\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyBGM(BayesianGaussianMixture):\n\n    \n    def __init__(self, n_components=1, covariance_type='full', tol=1e-3,\n                 reg_covar=1e-6, max_iter=100, n_init=1, init_params='kmeans',\n                 weight_concentration_prior_type='dirichlet_process',\n                 weight_concentration_prior=None,\n                 mean_precision_prior=None, mean_prior=None,\n                 degrees_of_freedom_prior=None, covariance_prior=None,\n                 random_state=None, warm_start=False, verbose=0,\n                 verbose_interval=10, init_clusters=None):\n        super().__init__(\n                n_components=n_components, covariance_type=covariance_type, tol=tol,\n                 reg_covar=reg_covar, max_iter=max_iter, n_init=n_init, init_params=init_params,\n                 weight_concentration_prior_type=weight_concentration_prior_type,\n                 weight_concentration_prior=weight_concentration_prior,\n                 mean_precision_prior=mean_precision_prior, mean_prior=mean_prior,\n                 degrees_of_freedom_prior=degrees_of_freedom_prior, covariance_prior=covariance_prior,\n                 random_state=random_state, warm_start=warm_start, verbose=verbose,\n                 verbose_interval=verbose_interval)\n        self.init_clusters_ = np.asarray(init_clusters).astype('int')\n        \n        \n    def _initialize_parameters(self, X, random_state):\n        \"\"\"Initialize the model parameters.\n        Parameters\n        ----------\n        X : array-like, shape  (n_samples, n_features)\n        random_state : RandomState\n            A random number generator instance.\n        \"\"\"\n        n_samples, _ = X.shape\n\n        if self.init_params == 'kmeans':\n            resp = np.zeros((n_samples, self.n_components))\n            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n                                   random_state=random_state).fit(X).labels_\n            resp[np.arange(n_samples), label] = 1\n        elif self.init_params == 'random':\n            resp = random_state.rand(n_samples, self.n_components)\n            resp /= resp.sum(axis=1)[:, np.newaxis]\n        elif self.init_params == 'clusters':\n            resp = np.zeros((n_samples, self.n_components))\n            resp[np.arange(self.init_clusters_.shape[0]), self.init_clusters_] = 1\n        elif self.init_params == 'proba':\n            resp = self.init_proba_.copy()\n            resp[np.arange(self.init_clusters_.shape[0]), self.init_clusters_] = 1\n            resp /= resp.sum(axis=1)[:, np.newaxis]\n        else:\n            raise ValueError(\"Unimplemented initialization method '%s'\"\n                             % self.init_params)\n\n        self._initialize(X, resp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_covar=1.986808882\ntol=0.012220889\n#tol=0.05\ngm_list_save = []\nif True:\n    oof_preds = np.zeros(train.shape[0])\n    test_preds = np.zeros(test.shape[0])\n    n_random = 5\n    for RANDOM_STATE in tqdm_notebook(range(n_random)):\n        for i in tqdm_notebook(range(512)):\n            train2 = train[train['wheezy-copper-turtle-magic']==i]\n            test2 = test[test['wheezy-copper-turtle-magic']==i]\n            idx1 = train2.index\n            idx2 = test2.index\n            train2.reset_index(drop=True,inplace=True)\n            sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n            train3 = sel.transform(train2[cols])\n            test3 = sel.transform(test2[cols])\n\n            train_cls = gm_list[i].predict(train3)\n            pred_org = pd.crosstab(train_cls, train2['target']).values\n            pred = pred_org[:, 1] / pred_org.sum(axis=1)\n\n            skf = StratifiedKFold(n_splits=11, random_state=42 + RANDOM_STATE, shuffle=True)\n\n            for train_index, test_index in skf.split(train3, train_cls):\n\n                # concat train and test\n                train_test3 = np.concatenate([train3[train_index], test3], axis=0)\n                train_test_cls = gm_list[i].predict(train_test3)\n\n                gm_all = MyGM(\n                    n_components=6, init_params='clusters', init_clusters=train_test_cls, \n                    weights_init=[1/6, 1/6, 1/6, 1/6, 1/6, 1/6],  \n                    reg_covar=reg_covar, tol=tol\n                )\n                _ = gm_all.fit(train_test3)\n                gm_list_save.append(gm_all)\n                if False:\n                    oof_pred6 = gm_all.predict_proba(train3[test_index])\n                    oof_preds[idx1[test_index]] += oof_pred6[:, pred>0.5].sum(axis=1)\n                    test_pred6 = gm_all.predict_proba(test3)\n                    test_preds[idx2] += test_pred6[:, pred>0.5].sum(axis=1)\n                else:\n                    oof_pred6 = gm_all._estimate_weighted_log_prob(train3[test_index])\n                    oof_preds[idx1[test_index]] += logsumexp(oof_pred6[:, pred>0.5], axis=1) - logsumexp(oof_pred6[:, pred<=0.5], axis=1)\n                    test_pred6 = gm_all._estimate_weighted_log_prob(test3)\n                    test_preds[idx2] += logsumexp(test_pred6[:, pred>0.5], axis=1) - logsumexp(test_pred6[:, pred<=0.5], axis=1)\n                \n        print(roc_auc_score(train[\"target\"], oof_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = plt.hist(test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = plt.hist(oof_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(train[\"target\"], oof_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/instant-gratification/sample_submission.csv')\nsub['target'] = test_preds\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}