{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Bayesian modeling by PyMC3\nThis Kernel is not practilcal because of run-time is too long. Then cannot be used for submission."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train.shape={}'.format(df_train.shape), 'test_shape={}'.format(df_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n## Modeling\nIt is based on the below official documents.  \nhttps://docs.pymc.io/notebooks/gaussian_mixture_model.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"wcrms = df_train['wheezy-copper-turtle-magic'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I assumed covariance matrix has only diagonal factors.\n# I tried including off-diagonal factors, but failed.\n\n\nimport pymc3 as pm\nimport theano.tensor as tt\n\n\nclass BayesianClassifier(object):\n    def __init__(self, n_categories=2):\n        self.n_categories = n_categories\n        self.model = pm.Model()\n    \n    \n    def predict(self, X=None):\n        # input X is just a dummy for keep API the same.\n        y_pred = self.trace['z'][:,self.n_trains:].mean(axis=0)\n        return y_pred\n    \n    \n    def fit(self, X_train, y_train, X_test):\n        # initial value for mu and tau can be improved by GaussianMixture of sklearn.\n        X = np.concatenate([X_train, X_test], axis=0)\n        self.n_features = X.shape[1]\n        self.n_trains = X_train.shape[0]\n        default_mu = 0.1 * np.random.randn(self.n_categories, self.n_features)\n        with self.model:\n            p = pm.Dirichlet('p', a=np.array([1.]*self.n_categories), shape=self.n_categories)\n            z = pm.Categorical('z', p=p, shape=len(X))\n            p_min_potential = pm.Potential('p_min_potential', tt.switch(tt.min(p)<0.1, -np.inf,0))\n\n            mu = pm.Normal('mu', mu=default_mu, tau=1/1**2, shape=(self.n_categories, self.n_features))    \n            sd = pm.Uniform('sd', lower=0.01, upper=5, shape=(self.n_categories, self.n_features))\n            \n            z_obs = pm.Normal('z_obs', mu=z[:len(y_train)], tau=100, observed=y_train.ravel())\n            X_obs = pm.Normal('X_obs', mu=mu[z,:], tau=1/sd[z,:], observed=X)\n            \n            self.trace = pm.sample(3000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BaseClassifier(object):\n    # just a lapper object.\n    def __init__(self, n_folds=10):\n        self.clf = BayesianClassifier(2)\n        \n    \n    def fit(self, X_train, y_train, X_test, n_folds=5):\n        X_train = self._apply_feature_mask(X_train)\n        X_test = self._apply_feature_mask(X_test)\n        self.clf.fit(X_train, y_train, X_test)\n        \n    \n    def predict(self, X=None):\n        return self.clf.predict(X)\n    \n    \n    def fit_feature_mask(self, X, threshold=1-45/256):\n        stds = X.std(axis=0)\n        split = np.quantile(stds, threshold)\n        self.feature_mask = (split<=stds)\n        \n        \n    def _apply_feature_mask(self, X):\n        return X[:, self.feature_mask]\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n## Evaluation\nLet's evaluate Bayesian classifier to QDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nsample_df = df_train[df_train['wheezy-copper-turtle-magic']==wcrms[3]]\nX_train_sample = sample_df.drop(['id', 'target', 'wheezy-copper-turtle-magic'], axis=1).values\ny_train_sample = sample_df['target'].values\n\nX_train_sample, X_val_sample, y_train_sample, y_val_sample = \\\n    train_test_split(X_train_sample, y_train_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bc = BaseClassifier()\nbc.fit_feature_mask(X_train_sample)\n# It may take much time starting sampling...\nbc.fit(X_train_sample, y_train_sample, X_val_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import roc_auc_score\n\nqda = QuadraticDiscriminantAnalysis(2, reg_param=0.8)\nqda.fit(X_train_sample, y_train_sample)\nprint('AUC of QDA is : ', roc_auc_score(y_val_sample, qda.predict_proba(X_val_sample)[:,1]), '.')\nprint('AUC of Baysean is : ', roc_auc_score(y_val_sample, bc.predict(X_val_sample)), '.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\nBelow code are for final submission, but it cannot end in the time."},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConsolEstimator(object):\n    def __init__(self, ids):\n        self.clfs = {}\n        self.id_column = 'wheezy-copper-turtle-magic'\n        self.ids = ids\n        \n        \n    def predict(self, df_X):\n        y_pred = np.zeros(shape=(len(df_X)))\n        for id in df_X[self.id_column].unique():\n            id_rows = (df_X[self.id_column]==id)\n            X = df_X.drop(['id', self.id_column], axis=1).values[id_rows]\n            y_pred[id_rows] = self.clfs[id].predict(X)\n        return y_pred\n            \n        \n    def fit(self, df_train, df_test):\n        for i, id in enumerate(self.ids):\n            print(i, 'th training...')\n            df_train_id = df_train[df_train[self.id_column]==id]\n            df_test_id = df_test[df_test[self.id_column]==id]\n            if len(df_train_id)==0 or len(df_test_id)==0:\n                continue\n            \n            X_train = df_train_id.drop(['id', 'target', self.id_column], axis=1).values\n            y_train = df_train_id['target'].values\n            X_test = df_test_id.drop(['id', self.id_column], axis=1).values\n            \n            self.clfs[id] = BaseClassifier()\n            self.clfs[id].fit_feature_mask(np.vstack([X_train, X_test]))\n            self.clfs[id].fit(X_train, y_train, X_test)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing code\n#df_train_sample = df_train[df_train['wheezy-copper-turtle-magic'].isin(wcrms[:10])]\n#df_test_sample = df_test[df_test['wheezy-copper-turtle-magic'].isin(wcrms[:10])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ce = ConsolEstimator(ids=wcrms)\n#ce.fit(df_train_sample, df_test_sample)\n\n# final run.\n#ce.fit(df_train, df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred = ce.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_submission = pd.concat([df_test['id'], pd.Series(y_pred, name='target')], axis=1)\n#df_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}