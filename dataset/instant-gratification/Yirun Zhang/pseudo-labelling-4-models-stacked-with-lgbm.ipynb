{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# LOAD LIBRARIES\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport sklearn.gaussian_process.kernels as ker\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np, pandas as pd, os, gc\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.covariance import GraphicalLasso\nfrom sklearn.mixture import GaussianMixture","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mean_cov(x,y):\n    model = GraphicalLasso()\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    model.fit(x2)\n    p1 = model.precision_\n    m1 = model.location_\n    \n    onesb = (y==0).astype(bool)\n    x2b = x[onesb]\n    model.fit(x2b)\n    p2 = model.precision_\n    m2 = model.location_\n    \n    ms = np.stack([m1,m2])\n    ps = np.stack([p1,p2])\n    return ms,ps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Reading Train Data...')\ntrain = pd.read_csv('../input/train.csv')\nprint('Reading Test Data...')\ntest = pd.read_csv('../input/test.csv')\nprint('Finish Reading.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\noof_GMM = np.zeros(len(train))\npreds_GMM = np.zeros(len(test))\n\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n\n# BUILD 512 SEPARATE NON-LINEAR MODELS\nfor i in tqdm_notebook(range(512)):\n    \n    # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n        \n    # STRATIFIED K FOLD (Using splits=25 scores 0.002 better but is slower)\n    skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        # MODEL WITH GMM\n        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values) \n        gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n        oof_GMM[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n        preds_GMM[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n        \n    if i%64==0:     \n        print(i, 'GMM oof auc : ', round(roc_auc_score(train['target'][idx1], oof_GMM[idx1]), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_GMM = roc_auc_score(train['target'],oof_GMM)\nprint('GMM scores CV: ',round(auc_GMM, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ntest['target'] = preds_GMM\noof_QDA = np.zeros(len(train))\npreds_QDA = np.zeros(len(test))\n\noof_NuSVC = np.zeros(len(train))\npreds_NuSVC = np.zeros(len(test))\n\noof_KNN = np.zeros(len(train))\npreds_KNN = np.zeros(len(test))\n\noof_MLP = np.zeros(len(train))\npreds_MLP = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor k in tqdm_notebook(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==k] \n    train2p = train2.copy(); idx1 = train2.index \n    test2 = test[test['wheezy-copper-turtle-magic']==k]\n    idx2 = test2.index \n    \n    # ADD PSEUDO LABEL DATA\n    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n    train2p = pd.concat([train2p,test2p],axis=0)\n    train2p.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n    train3p = sel.transform(train2p[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    pca = PCA(svd_solver='full',n_components='mle').fit(train2p[cols])\n    train4p = pca.transform(train2p[cols])\n    train4 = pca.transform(train2[cols])\n    test4 = pca.transform(test2[cols])\n    sc1 = StandardScaler()\n    train4p = sc1.fit_transform(train4p)\n    train4 = sc1.transform(train4)\n    test4 = sc1.transform(test4)\n    \n    poly = PolynomialFeatures().fit(train3p)\n    train5p = poly.transform(train3p)\n    train5 = poly.transform(train3)\n    test5 = poly.transform(test3)\n    sc2 = StandardScaler()\n    train5p = sc2.fit_transform(train5p)\n    train5 = sc2.transform(train5)\n    test5 = sc2.transform(test5)\n        \n    # STRATIFIED K FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3p, train2p['target']):\n        test_index3 = test_index[ test_index<len(train3) ] # ignore psuedo in oof\n        \n        # MODEL AND PREDICT WITH QDA\n        clf_QDA = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf_QDA.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_QDA[idx1[test_index3]] = clf_QDA.predict_proba(train3[test_index3,:])[:,1]\n        preds_QDA[idx2] += clf_QDA.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf_NuSVC = NuSVC(probability=True,kernel='poly',degree=4,gamma='auto',nu=0.59, coef0=0.053)\n        clf_NuSVC.fit(train4p[train_index,:],train2p.loc[train_index]['target'])\n        oof_NuSVC[idx1[test_index3]] = clf_NuSVC.predict_proba(train4[test_index3,:])[:,1]\n        preds_NuSVC[idx2] += clf_NuSVC.predict_proba(test4)[:,1] / skf.n_splits\n        \n        clf_KNN = KNeighborsClassifier(n_neighbors=10,weights='distance',p=2)\n        clf_KNN.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n        oof_KNN[idx1[test_index3]] = clf_KNN.predict_proba(train3[test_index3,:])[:,1]\n        preds_KNN[idx2] += clf_KNN.predict_proba(test3)[:,1] / skf.n_splits\n        \n        clf_MLP = MLPClassifier(activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250,), random_state=42)\n        clf_MLP.fit(train5p[train_index,:],train2p.loc[train_index]['target'])\n        oof_MLP[idx1[test_index3]] = clf_MLP.predict_proba(train5[test_index3,:])[:,1]\n        preds_MLP[idx2] += clf_MLP.predict_proba(test5)[:,1] / skf.n_splits\n        \n    if k%64==0:     \n        print(k, 'QDA oof auc : ', round(roc_auc_score(train['target'][idx1], oof_QDA[idx1]), 5))\n        print(k, 'NuSVC oof auc : ', round(roc_auc_score(train['target'][idx1], oof_NuSVC[idx1]), 5))\n        print(k, 'KNN oof auc : ', round(roc_auc_score(train['target'][idx1], oof_KNN[idx1]), 5))\n        print(k, 'MLP oof auc : ', round(roc_auc_score(train['target'][idx1], oof_MLP[idx1]), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PRINT CV AUC\nauc_QDA = roc_auc_score(train['target'],oof_QDA)\nprint('Pseudo Labeled QDA scores CV: ',round(auc_QDA,5))\n\nauc_NuSVC = roc_auc_score(train['target'],oof_NuSVC)\nprint('Pseudo Labeled NuSVC scores CV: ',round(auc_NuSVC,5))\n\nauc_KNN = roc_auc_score(train['target'],oof_KNN)\nprint('Pseudo Labeled KNN scores CV: ',round(auc_KNN,5))\n\nauc_MLP = roc_auc_score(train['target'],oof_MLP)\nprint('Pseudo Labeled MLP scores CV: ',round(auc_MLP,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = pd.DataFrame(np.concatenate((oof_NuSVC.reshape(-1,1),oof_KNN.reshape(-1,1),oof_QDA.reshape(-1,1),oof_MLP.reshape(-1,1)), axis=1))\ntest_new = pd.DataFrame(np.concatenate((preds_NuSVC.reshape(-1,1),preds_KNN.reshape(-1,1),preds_QDA.reshape(-1,1),preds_MLP.reshape(-1,1)), axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'bagging_freq': 3,\n    'bagging_fraction': 0.8,\n    'boost_from_average':'False',\n    'boost': 'gbdt',\n    'feature_fraction': 1,\n    'learning_rate': 0.05,\n    'max_depth': 10,\n    'metric':'auc',\n    'min_data_in_leaf': 82,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 10,\n    'objective': 'binary', \n    'verbosity': 1,\n    'seed': 42\n}\n\nimport lightgbm as lgb\nN = 5\nskf_lgb = StratifiedKFold(n_splits=N, random_state=42)\n\noof_lgb = np.zeros(train_new.shape[0])\npred_stack = np.zeros(len(test_new))\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf_lgb.split(train_new, train['target'])):\n    print(\"Fold {}\".format(fold_+1))\n    x_train, y_train = train_new.iloc[trn_idx], train['target'].iloc[trn_idx]\n    x_val, y_val = train_new.iloc[val_idx], train['target'].iloc[val_idx]\n    x_train.head()\n    \n    trn_data = lgb.Dataset(x_train, label=y_train)\n    val_data = lgb.Dataset(x_val, label=y_val)\n    classifier = lgb.train(param, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 200)\n\n    val_pred = classifier.predict(x_val, num_iteration=classifier.best_iteration)\n    oof_lgb[val_idx] = val_pred\n    pred_stack += classifier.predict(test_new, num_iteration=classifier.best_iteration) / N\n    print(roc_auc_score(y_val, val_pred))\n\nauc_lgb = roc_auc_score(train['target'],oof_lgb)\nprint('LGB auc: ',round(auc_lgb,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_stack = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission_stack['target'] = pred_stack\nsubmission_stack.head()\nsubmission_stack.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.to_csv('train_new.csv', index=False)\ntest_new.to_csv('test_new.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}