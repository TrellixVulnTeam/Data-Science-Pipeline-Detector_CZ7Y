{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.layers import Dropout\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\nfrom keras import backend as K\n\nclass CyclicLR(Callback):\n    def __init__(\n            self,base_lr=0.001,\n            max_lr=0.006,step_size=2000.,\n            mode='triangular',gamma=1.,\n            scale_fn=None,scale_mode='cycle'):\n        \n        super(CyclicLR, self).__init__()\n\n        if mode not in ['triangular', 'triangular2','exp_range']:\n            raise KeyError(\"mode must be one of 'triangular', \"\n                           \"'triangular2', or 'exp_range'\")\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.step_size = step_size\n        self.mode = mode\n        self.gamma = gamma\n        if scale_fn is None:\n            if self.mode == 'triangular':\n                self.scale_fn = lambda x: 1.\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = lambda x: 1 / (2.**(x - 1))\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = lambda x: gamma ** x\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        self.clr_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None,\n               new_step_size=None):\n        if new_base_lr is not None:\n            self.base_lr = new_base_lr\n        if new_max_lr is not None:\n            self.max_lr = new_max_lr\n        if new_step_size is not None:\n            self.step_size = new_step_size\n        self.clr_iterations = 0.\n        \n    def clr(self):\n        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n        if self.scale_mode == 'cycle':\n            return self.base_lr + (self.max_lr - self.base_lr) * \\\n                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n        else:\n            return self.base_lr + (self.max_lr - self.base_lr) * \\\n                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n\n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())\n\n    def on_batch_end(self, epoch, logs=None):\n\n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n        K.set_value(self.model.optimizer.lr, self.clr())\n\n        self.history.setdefault(\n            'lr', []).append(\n            K.get_value(\n                self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv', index_col=0)\ntest_df = pd.read_csv('../input/test.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop(['target'],axis=1)\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_s=scaler.fit_transform(X)\nX_test_s=scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.DataFrame(X_s)\nX_test=pd.DataFrame(X_test_s)\nX_test.index=test_df.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 7\nnp.random.seed(seed)\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = optimizers.adam\nmodel = Sequential()\nmodel.add(Dense(64, input_shape=(256,1),\n                kernel_initializer='normal',\n                activation=\"relu\"))\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation=\"sigmoid\"))\nmodel.compile(loss=\"binary_crossentropy\", optimizer='adam',metrics=['accuracy'])\n\nclr = CyclicLR(base_lr=0.001, max_lr=0.006,step_size=400., mode='triangular')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nc = 0\noof_preds = np.zeros((len(X), 1))\n\nfor train, valid in cv.split(X, y):\n    print(\"VAL %s\" % c)\n    X_train = np.reshape(X.iloc[train].values, (-1, 256, 1))\n    y_train_ = y.iloc[train].values\n    X_valid = np.reshape(X.iloc[valid].values, (-1, 256, 1))\n    y_valid = y.iloc[valid].values\n    early = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=20)\n    model.fit(X_train, y_train_, validation_data=(X_valid, y_valid), epochs=200, verbose=2, batch_size=1024,\n              callbacks=[early,clr])\n    X_test1 = np.reshape(X_test.values, (131073, 256, 1))\n    curr_preds = model.predict(X_test1, batch_size=1024)\n    oof_preds[valid] = model.predict(X_valid)\n    preds.append(curr_preds)\n    c += 1\nauc = roc_auc_score(y, oof_preds)\nprint(\"CV_AUC: {}\".format(auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.asarray(preds)\npreds = preds.reshape((5, 131073))\npreds_final = np.mean(preds.T, axis=1)\nsubmission = pd.read_csv('./../input/sample_submission.csv')\nsubmission['target'] = preds_final\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}