{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Summary\n\n\n**Most of us have been using a constant threshold based on variance for feature  selection. The current kernel investigates a possible alternative through  a varying threshold  per 'wheezy-copper-turtle-magic' category. The threshold is selected so as to maximise the accuracy on each category dataset.** \n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"\n## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictions with default threshold of 1.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        # MODEL AND PREDICT WITH QDA\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        \n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n       \n    #if i%64==0: print(i)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Predcictions with a lower threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof_b = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.1).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        # MODEL AND PREDICT WITH QDA\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        \n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_b[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n       \n    #if i%64==0: print(i)\n        \n# PRINT CV AUC\nauc_b = roc_auc_score(train['target'],oof_b)\nprint('QDA scores CV =',round(auc_b,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categories for wich using a lower threshold have boosted the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"val = [] \nfor i in range(512):\n\n  auc = roc_auc_score(train.loc[train['wheezy-copper-turtle-magic']==i]['target'], oof[train.loc[train['wheezy-copper-turtle-magic']==i].index])\n  auc_b = roc_auc_score(train.loc[train['wheezy-copper-turtle-magic']==i]['target'], oof_b[train.loc[train['wheezy-copper-turtle-magic']==i].index])\n  \n  if auc_b > auc:\n   print(i, 'QDA scores difference CV =',round(auc_b-auc,5))\n   val.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adapting the threshold per category"},{"metadata":{"trusted":true},"cell_type":"code","source":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in range(512):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    \n    if i in val: \n        sel = VarianceThreshold(threshold=1.1).fit(train2[cols])\n        train3 = sel.transform(train2[cols])\n        test3 = sel.transform(test2[cols])\n    else:    \n        sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n        train3 = sel.transform(train2[cols])\n        test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        # MODEL AND PREDICT WITH QDA\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        \n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n       \n    #if i%64==0: print(i)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The auc is improved from 0.96541 to 0.96548"},{"metadata":{},"cell_type":"markdown","source":"# Perspectives\n\nI did not found any improvement on QDA (with pseudo labels) models. Feel free to investigate the technique on more models and contribute.  "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}