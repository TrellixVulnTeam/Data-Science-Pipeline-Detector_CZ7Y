{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Search 'useless columns'\n\nIn this kernel, suggest 'useless' columns.\nI believe these should be drop but may not be correct.\n\n\nbased on [LR great kernel](https://www.kaggle.com/cdeotte/logistic-regression-0-800).\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\ntrain = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## feature histgram"},{"metadata":{},"cell_type":"markdown","source":"plot code from [this kernel](https://www.kaggle.com/donariumdebbie/explore-funny-column-names#Target-distribution-of-group-of-column-names)\n\nThat kernel revealed <b>wheezy-copper-turtle-magic</b> columns shows different pattern.\n\nIn this cell, restrict only <b>wheezy-copper-turtle-magic</b>==0. Fix the axis and show histgram.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train2=train[train['wheezy-copper-turtle-magic']==0]\n\nfeats = [f for f in train2.columns if f not in ['id','target']]\ndef plot_feature_distribution(df1, df2, label1, label2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(64,4,figsize=(15,100))\n\n    for feature in features:\n        i += 1\n        plt.subplot(32,8,i)\n        sns.distplot(df1[feature], hist=False,label=label1)\n        sns.distplot(df2[feature], hist=False,label=label2)\n        \n        plt.xlabel(feature, fontsize=9)\n        plt.xlim(-30,30)\n        plt.ylim(0,1)\n        \n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n        plt.tick_params(axis='y', which='major', labelsize=6)\n    plt.show();\n    \nt0 = train2[feats].loc[train['target'] == 0]\nt1 = train2[feats].loc[train['target'] == 1]\nfeatures = train2[feats].columns.values\nplot_feature_distribution(t0, t1, '0', '1', features);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some plots show different from other. It looks like the range or variance is different.\n\nPlot these range and variance."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train2=train[train['wheezy-copper-turtle-magic']==0]\nmin_max = []\nfor x in train2.columns[1:-1][train2.columns[1:-1]!='wheezy-copper-turtle-magic']:\n    min_max.append(train2[x].values.max()-train2[x].values.min())        \nsns.distplot(min_max);\nplt.title('range histgram (wheezy-copper-turtle-magic=0)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"var = []\nfor x in train2.columns[1:-1][train2.columns[1:-1]!='wheezy-copper-turtle-magic']:\n    var.append(train2[x].var())        \nsns.distplot(var);\nplt.title('variance histgram (wheezy-copper-turtle-magic=0)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict with reduction\nCan I drop these cells?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(train))\npreds = np.zeros(len(test))\nn_split = 5\n\nfor i in range(512):\n    cols = [c for c in train.columns if c not in ['id', 'target']]\n    cols.remove('wheezy-copper-turtle-magic')\n    train2 = train[train['wheezy-copper-turtle-magic']==i].copy()\n    test2 = test[test['wheezy-copper-turtle-magic']==i].copy()\n    \n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    test2.reset_index(drop=True,inplace=True)\n\n    skf = StratifiedKFold(n_splits=n_split, random_state=42)\n    for train_index, test_index in skf.split(train2[train2.columns[train2.columns!='target']], train2['target']):\n\n        clf = LogisticRegression(solver='sag',penalty='l2',C=0.001)\n        clf.fit(train2.loc[train_index][cols],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train2.loc[test_index][cols])[:,1]\n        preds[idx2] += clf.predict_proba(test2[cols])[:,1] / n_split\n\nauc = roc_auc_score(train['target'],oof)\nprint('LR scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dimension reduction by data range\n\nFirst, I drop columns whose data range is upper 15.\n(The number 15 is from looking plots shown earlier)"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(train))\npreds = np.zeros(len(test))\nn_split = 5\nprint('drop columnss whose data range is upper 15.')\nfor i in range(512):\n    cols = [c for c in train.columns if c not in ['id', 'target']]\n    cols.remove('wheezy-copper-turtle-magic')\n    train2 = train[train['wheezy-copper-turtle-magic']==i].copy()\n    test2 = test[test['wheezy-copper-turtle-magic']==i].copy()\n    \n    ##  Reduction by Range\n    for x in cols:\n        if train2[x].values.max()-train2[x].values.min() >= 15:\n            train2 = train2.drop([x],axis=1)\n            test2 = test2.drop([x],axis=1)\n            cols.remove(x)\n    \n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    test2.reset_index(drop=True,inplace=True)\n\n    skf = StratifiedKFold(n_splits=n_split, random_state=42)\n    for train_index, test_index in skf.split(train2[train2.columns[train2.columns!='target']], train2['target']):\n\n        clf = LogisticRegression(solver='sag',penalty='l2',C=0.001)\n        clf.fit(train2.loc[train_index][cols],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train2.loc[test_index][cols])[:,1]\n        preds[idx2] += clf.predict_proba(test2[cols])[:,1] / n_split\n\nauc = roc_auc_score(train['target'],oof)\nprint('LR with dimention reduction by data range scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, I drop columns whose data range is under 15."},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(train))\npreds = np.zeros(len(test))\nn_split = 5\nprint('drop columns whose data range is under 15.')\nfor i in range(512):\n    cols = [c for c in train.columns if c not in ['id', 'target']]\n    cols.remove('wheezy-copper-turtle-magic')\n    train2 = train[train['wheezy-copper-turtle-magic']==i].copy()\n    test2 = test[test['wheezy-copper-turtle-magic']==i].copy()\n    \n    ##  Reduction by Range\n    for x in cols:\n        if train2[x].values.max()-train2[x].values.min() < 15:\n            train2 = train2.drop([x],axis=1)\n            test2 = test2.drop([x],axis=1)\n            cols.remove(x)\n    \n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    test2.reset_index(drop=True,inplace=True)\n\n    skf = StratifiedKFold(n_splits=n_split, random_state=42)\n    for train_index, test_index in skf.split(train2[train2.columns[train2.columns!='target']], train2['target']):\n\n        clf = LogisticRegression(solver='sag',penalty='l2',C=0.001)\n        clf.fit(train2.loc[train_index][cols],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train2.loc[test_index][cols])[:,1]\n        preds[idx2] += clf.predict_proba(test2[cols])[:,1] / n_split\n\nauc = roc_auc_score(train['target'],oof)\nprint('LR with dimention reduction by data range scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'useless' columns are revealed?"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}