{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\n### The Purpose of this Kernel\n\nIt has been firmly established that the competion data set was made with the help of the `make_classification()` utility (see for example [this beautiful kernel](https://www.kaggle.com/mhviraf/synthetic-data-for-next-instant-gratification) by mhviraf. But one question still remains open: what value was used in the data preparation process for the number of clusters per class? The default value of this parameter is 2 but, on the other hand, the QDA algorithm is working very well on this data set and, since QDA assumes only one cluster per class, many of us use it as a standard assumption. But is this assumption correct? To answer this question we will need to take a little bit closer look at the data. \n\nI hope you find this kernel useful. Don't forget to kindly upvote it and leave great comments!\n\n### The Main Idea\n\nIn our analysis, we will be using a simple data augmentation idea that was nicely explained in [this discussion topic](https://www.kaggle.com/c/instant-gratification/discussion/94128#latest-549171) by TripleLift and in [this kernel](https://www.kaggle.com/nroman/augmentation-explained) by Roman. The idea is simple: if all the data in a given class, say 1, belong to a single cluster then we can easily augment our train set by adding to it new points computed from the following formula: $2(X_1)_\\text{center} - X_1$, where $X_1$ is the class 1 train set data and $(X_1)_\\text{center}$ is the 'centroid', or the mean point of $X_1$ (each coordinate of this point is equal to the average value of the coordinates of $X_1$). Some people tried to apply this idea, some even claimed that they got a moderate boost to their score but it did not work very well for many others, myself included -- I observe a slight decrease in my local CV score when I tried implementing this method. What I realized recently is that this data augmentation idea can be used to detect the presence of multiple clusters for a given class. \n\nLet me explain how it works. First of all we will need to abandon some widespread misconceptions. The data augmentation method described above is often presented as a mean to improve the LB score. But if you think about it, you realize that this expectation is not justified -- by augmenting your data set in this way, you are not adding any useful information to your QDA algorithm: quick inspection of the mathematical definitions of the mean and covariance shows that both of this quantities are not going to change under the described data augmentation operation (assuming large enough number of points, so that the difference between $N$ and $N-1$ is irrelvant) and for QDA the mean and covariance is all that matters. On the other hand, the performance of QDA is not supposed to suffer either because for the augmented data set it will compute the same mean and covariance. And if the performance suffers, it means that there is something wrong with our understanding of the properties of the data set. This is the main idea of the method implemented below."},{"metadata":{},"cell_type":"markdown","source":"## Setting Things Up\n\n### Loading Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\n\npath = Path('../input')\n\ntrain = pd.read_csv(path/'train.csv')\ntest = pd.read_csv(path/'test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing\n\nIn this part, we will collect and preprocess data from all 512 model (one model per one value of the `'wheezy-copper-turtle-magic'` categorical variable as was explained by Chris Deotte [here](https://www.kaggle.com/cdeotte/support-vector-machine-0-925)). Later we will be able to load all these data from a single dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"magic_max=train['wheezy-copper-turtle-magic'].max()\nmagic_min=train['wheezy-copper-turtle-magic'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(train=train, test=test):\n       \n    prepr = {} \n    \n    #PREPROCESS 512 SEPARATE MODELS\n    for i in range(magic_min, magic_max+1):\n\n        # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS i     \n        X = train[train['wheezy-copper-turtle-magic']==i].copy()\n        Y = X.pop('target').values\n        X_test = test[test['wheezy-copper-turtle-magic']==i].copy()\n        idx_train = X.index \n        idx_test = X_test.index\n        X.reset_index(drop=True,inplace=True)\n\n        cols = np.array([c for c in X.columns if c not in ['id', 'wheezy-copper-turtle-magic']])\n\n        l=len(X)\n        X_all = pd.concat([X[cols], X_test[cols]], ignore_index=True)\n        \n        sel = VarianceThreshold(threshold=2)\n        X_vt = sel.fit_transform(X_all)               # np.ndarray\n        \n        prepr['vt_' + str(i)] = X_vt\n        prepr['n_vt' + str(i)] = X_vt.shape[1]\n        prepr['feats_vt' + str(i)] = cols[sel.get_support(indices=True)]        \n        prepr['train_size_' + str(i)] = l\n        prepr['idx_train_' + str(i)] = idx_train\n        prepr['idx_test_' + str(i)] = idx_test\n        prepr['target_' + str(i)] = Y\n        \n    return prepr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndata = preprocess()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And here is a handy function to get data for any value of `i`."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(i, data):\n    \n    l = data['train_size_' + str(i)]\n    \n    X_all = data['vt_' + str(i)]                \n\n    X = X_all[:l, :]\n    X_test = X_all[l:, :]\n\n    Y = data['target_' + str(i)]\n\n    idx_train = data['idx_train_' + str(i)]\n    idx_test = data['idx_test_' + str(i)]\n    \n    return X, X_test, Y, idx_train, idx_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's define a very useful function initializing storage arrays for our cross-validation results: AUC, out-of-fold predictions, and test set prediction (actually, we won't be producing any submission file in this kernel, so keeping track of test set prediction is a bit redundant but let's keep it for the sake of completeness). "},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_cv():\n    auc = np.array([])\n    oof = np.zeros(len(train))\n    preds = np.zeros(len(test)) \n    return auc, oof, preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And another useful function to report the result of the cross-validation procedure."},{"metadata":{"trusted":true},"cell_type":"code","source":"def report_results(oof, auc_all, clf_name='QDA'):\n    # PRINT VALIDATION CV AUC FOR THE CLASSFIER\n    print(f'The result summary for the {clf_name} classifier:')\n    auc_combo = roc_auc_score(train['target'].values, oof)\n    auc_av = np.mean(auc_all)\n    std = np.std(auc_all)/(np.sqrt(NFOLDS)*np.sqrt(magic_max+1))\n\n    print(f'The combined CV score is {round(auc_combo, 5)}.')    \n    print(f'The folds average CV score is {round(auc_av, 5)}.')\n    print(f'The standard deviation is {round(std, 5)}.\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define the number of folds and random seed."},{"metadata":{"trusted":true},"cell_type":"code","source":"NFOLDS = 5\nRS = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline: One Cluster per Class"},{"metadata":{},"cell_type":"markdown","source":"Now, let's establish a baseline by runnig an unaugmented QDA algorithm once. This will give us a good reference score for comparison. Also, the algorithm will compute the mean values of the relevant variables for both the positive and negative classes and for all 512 values of the magic variable `'wheezy-copper-turtle-magic'`. These mean values will be stored in a dictionary called `means`."},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_all, oof, preds = initialize_cv() \n\nmeans = {}\n\n#TRAIN 512 SEPARATE MODELS\nfor i in tqdm(range(magic_min, magic_max+1)):\n\n    X, X_test, Y, idx_train, idx_test = get_data(i=i, data=data)      \n\n    # STRATIFIED K FOLD    \n    folds = StratifiedKFold(n_splits=NFOLDS, random_state=RS)\n\n    auc_folds = np.array([])\n\n    for train_index, val_index in folds.split(X, Y):     \n\n        X_train, Y_train = X[train_index, :], Y[train_index]\n        X_val, Y_val = X[val_index, :], Y[val_index]\n\n        #BUILDING THE PIPELINE FOR THE CURRENT CLASSIFIER\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n        \n        clf.fit(X_train, Y_train)\n        \n        means[str(i)] = clf.means_\n\n        oof[idx_train[val_index]] = clf.predict_proba(X_val)[:,1]\n        preds[idx_test] += clf.predict_proba(X_test)[:,1]/NFOLDS\n\n        auc = roc_auc_score(Y_val, oof[idx_train[val_index]])\n        auc_folds = np.append(auc_folds, auc)\n\n    auc_all = np.append(auc_all, np.mean(auc_folds))\n\nreport_results(oof, auc_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, the combined AUC score is 0.96278. Now, let's see how the same algorithm will do after data augmentation. For coordinates of the clusters' centroids we will be using the mean values computed in the previous step and stored in the `means` dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_all, oof, preds = initialize_cv() \n\n#TRAIN 512 SEPARATE MODELS\nfor i in tqdm(range(magic_min, magic_max+1)):\n\n    X, X_test, Y, idx_train, idx_test = get_data(i=i, data=data)      \n\n    # STRATIFIED K FOLD    \n    folds = StratifiedKFold(n_splits=NFOLDS, random_state=RS)\n\n    auc_folds = np.array([])\n\n    for train_index, val_index in folds.split(X, Y):     \n\n        X_train, Y_train = X[train_index, :], Y[train_index]\n        X_val, Y_val = X[val_index, :], Y[val_index]\n        \n        X_aug_0 = 2*means[str(i)][0] - X_train[Y_train==0]\n        Y_aug_0 = np.zeros(len(X_aug_0)).reshape(-1, 1)\n\n        X_aug_1 = 2*means[str(i)][1] - X_train[Y_train==1]\n        Y_aug_1 = np.zeros(len(X_aug_1)).reshape(-1, 1)\n\n        X_aug=np.vstack((X_train, X_aug_0, X_aug_1))\n        Y_aug=np.vstack((Y_train.reshape(-1, 1), Y_aug_0, Y_aug_1))\n\n        perms = np.random.permutation(len(X_aug))\n\n        X_aug = X_aug[perms]\n        Y_aug = Y_aug[perms]\n\n        #BUILDING THE PIPELINE FOR THE CURRENT CLASSIFIER\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n        \n        clf.fit(X_aug, Y_aug.ravel())\n\n        oof[idx_train[val_index]] = clf.predict_proba(X_val)[:,1]\n        preds[idx_test] += clf.predict_proba(X_test)[:,1]/NFOLDS\n\n        auc = roc_auc_score(Y_val, oof[idx_train[val_index]])\n        auc_folds = np.append(auc_folds, auc)\n\n    auc_all = np.append(auc_all, np.mean(auc_folds))\n\nreport_results(oof, auc_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What Does It Tell Us?\n\nThe new combined AUC score is 0.94964 which is significantly lower than the 0.96278 AUC that we got without augmentation. This is not supposed to happen if our understanding of the data set is correct! The augmentation that we have performed does not change the mean or covariance values, so the performance of QDA is not supposed to suffer. But it does. \n\n## Two Clusters per Class\n\nOne possible explanation of this phenomenon is that we actually have more than one cluster per class in the data set. If this is true, then we need to use the centroids of the clusters rathen than the mean values of positive and negative class as our 'pivoting points' for data augmentation. But what is the number of clusters? The simplest guess would be 2 because this is the default value of `make_classification()`. Let's investigate this possibility. To do that, we will use Gaussian Mixture Model (similar to the one introduced in [the great Dieter's kernel](https://www.kaggle.com/christofhenkel/graphicallasso-gaussianmixture)) to label 2 clusters for class 0 and 2 other clusters for class 1 (4 clusters in total). Then we will augment data using the centroids of the identified clusters as our 'pivoting points'."},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_all, oof, preds = initialize_cv() \n\n#TRAIN 512 SEPARATE MODELS\nfor i in tqdm(range(magic_min, magic_max+1)):\n\n    X, X_test, Y, idx_train, idx_test = get_data(i=i, data=data)      \n\n    # STRATIFIED K FOLD    \n    folds = StratifiedKFold(n_splits=NFOLDS, random_state=RS)\n\n    auc_folds = np.array([])\n\n    for train_index, val_index in folds.split(X, Y):     \n\n        X_train, Y_train = X[train_index, :], Y[train_index]\n        X_val, Y_val = X[val_index, :], Y[val_index]\n        \n        X_train_0 = X_train[Y_train==0]\n        Y_train_0 = Y_train[Y_train==0].reshape(-1, 1)\n\n        X_train_1 = X_train[Y_train==1]\n        Y_train_1 = Y_train[Y_train==1].reshape(-1, 1)\n\n\n        params={'n_components' : 2,          # 2 clusters per class\n                'init_params': 'random', \n                'covariance_type': 'full', \n                'tol':0.001, \n                'reg_covar': 0.001,#0.001, \n                'max_iter': 100, \n                'n_init': 10, \n               }\n\n        clf = GaussianMixture(**params)\n\n        clf.fit(X_train_0)\n        labels_0 = clf.predict(X_train_0)\n        means_0 = clf.means_\n\n        clf.fit(X_train_1)\n        labels_1 = clf.predict(X_train_1)\n        means_1 = clf.means_\n\n        X_aug_00 = 2*means_0[0] - X_train_0[labels_0==0]\n        Y_aug_00 = np.zeros(len(X_aug_00)).reshape(-1, 1)\n\n        X_aug_01 = 2*means_0[1] - X_train_0[labels_0==1]\n        Y_aug_01 = np.zeros(len(X_aug_01)).reshape(-1, 1)\n\n        X_aug_10 = 2*means_1[0] - X_train_1[labels_1==0]\n        Y_aug_10 = np.ones(len(X_aug_10)).reshape(-1, 1)\n\n        X_aug_11 = 2*means_1[1] - X_train_1[labels_1==1]\n        Y_aug_11 = np.ones(len(X_aug_11)).reshape(-1, 1)\n\n        X_aug=np.vstack((X_train_0, X_train_1, X_aug_00, X_aug_01, X_aug_10, X_aug_11))\n        Y_aug=np.vstack((Y_train_0, Y_train_1, Y_aug_00, Y_aug_01, Y_aug_10, Y_aug_11))\n\n        perms = np.random.permutation(len(X_aug))\n\n        X_aug = X_aug[perms]\n        Y_aug = Y_aug[perms]\n\n        #BUILDING THE PIPELINE FOR THE CURRENT CLASSIFIER\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n        \n        clf.fit(X_aug, Y_aug.ravel())\n\n        oof[idx_train[val_index]] = clf.predict_proba(X_val)[:,1]\n        preds[idx_test] += clf.predict_proba(X_test)[:,1]/NFOLDS\n\n        auc = roc_auc_score(Y_val, oof[idx_train[val_index]])\n        auc_folds = np.append(auc_folds, auc)\n\n    auc_all = np.append(auc_all, np.mean(auc_folds))\n\nreport_results(oof, auc_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The combined AUC score is 0.96278 which is exactly the same as the score that we got without any data augmentation. This strongly suggests that the actual number of clusters per class in the data set is not one but two.\n\n## Could it Be Three?\n\nIt it possible that the nuber of clusters is 3? Let's try it out using the same strategy."},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_all, oof, preds = initialize_cv() \n\n#TRAIN 512 SEPARATE MODELS\nfor i in tqdm(range(magic_min, magic_max+1)):\n\n    X, X_test, Y, idx_train, idx_test = get_data(i=i, data=data)      \n\n    # STRATIFIED K FOLD    \n    folds = StratifiedKFold(n_splits=NFOLDS, random_state=RS)\n\n    auc_folds = np.array([])\n\n    for train_index, val_index in folds.split(X, Y):     \n\n        X_train, Y_train = X[train_index, :], Y[train_index]\n        X_val, Y_val = X[val_index, :], Y[val_index]\n        \n        X_train_0 = X_train[Y_train==0]\n        Y_train_0 = Y_train[Y_train==0].reshape(-1, 1)\n\n        X_train_1 = X_train[Y_train==1]\n        Y_train_1 = Y_train[Y_train==1].reshape(-1, 1)\n\n\n        params={'n_components' : 3,          # 3 clusters per class\n                'init_params': 'random', \n                'covariance_type': 'full', \n                'tol':0.001, \n                'reg_covar': 0.001,#0.001, \n                'max_iter': 100, \n                'n_init': 10, \n               }\n\n        clf = GaussianMixture(**params)\n\n        clf.fit(X_train_0)\n        labels_0 = clf.predict(X_train_0)\n        means_0 = clf.means_\n\n        clf.fit(X_train_1)\n        labels_1 = clf.predict(X_train_1)\n        means_1 = clf.means_\n\n        X_aug_00 = 2*means_0[0] - X_train_0[labels_0==0]\n        Y_aug_00 = np.zeros(len(X_aug_00)).reshape(-1, 1)\n\n        X_aug_01 = 2*means_0[1] - X_train_0[labels_0==1]\n        Y_aug_01 = np.zeros(len(X_aug_01)).reshape(-1, 1)\n        \n        X_aug_02 = 2*means_0[2] - X_train_0[labels_0==2]\n        Y_aug_02 = np.zeros(len(X_aug_02)).reshape(-1, 1)\n\n        X_aug_10 = 2*means_1[0] - X_train_1[labels_1==0]\n        Y_aug_10 = np.ones(len(X_aug_10)).reshape(-1, 1)\n\n        X_aug_11 = 2*means_1[1] - X_train_1[labels_1==1]\n        Y_aug_11 = np.ones(len(X_aug_11)).reshape(-1, 1)\n        \n        X_aug_12 = 2*means_1[2] - X_train_1[labels_1==2]\n        Y_aug_12 = np.zeros(len(X_aug_12)).reshape(-1, 1)\n\n        X_aug=np.vstack((X_train_0, X_train_1, X_aug_00, X_aug_01, X_aug_02, X_aug_10, X_aug_11, X_aug_12,))\n        Y_aug=np.vstack((Y_train_0, Y_train_1, Y_aug_00, Y_aug_01, Y_aug_02, Y_aug_10, Y_aug_11, Y_aug_12))\n\n        perms = np.random.permutation(len(X_aug))\n\n        X_aug = X_aug[perms]\n        Y_aug = Y_aug[perms]\n\n        #BUILDING THE PIPELINE FOR THE CURRENT CLASSIFIER\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n        \n        clf.fit(X_aug, Y_aug.ravel())\n\n        oof[idx_train[val_index]] = clf.predict_proba(X_val)[:,1]\n        preds[idx_test] += clf.predict_proba(X_test)[:,1]/NFOLDS\n\n        auc = roc_auc_score(Y_val, oof[idx_train[val_index]])\n        auc_folds = np.append(auc_folds, auc)\n\n    auc_all = np.append(auc_all, np.mean(auc_folds))\n\nreport_results(oof, auc_all)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, the AUC corresponding to 3 clusters per class is 0.95421. This result is better than what we had for 1 cluster per class (0.94964) but worse than for 2 clusters per class (0.96278). It does not look very surprising -- with 3 clusters there is more flexibility (less rigid bias) that with one and it is good for the score. But, if the right number of clusters is 2 than fitting the data with 3 clusters leads to too much flexibility -- our bias is too flexible and it is bad for the score. So, our empirical demostration suggests that the right number of clusters per class should be two. "},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nThe evidence we collected strongly suggest that the actual number of clusters per class in the data set is not one (or three) but two. And this must be taken into account in the model building process -- in order for your model to be successful it must have the optimal bias which is most consistent with the structure of your data. This will help you to boost you score and move to a higher position on the leaderboard. Good luck!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}