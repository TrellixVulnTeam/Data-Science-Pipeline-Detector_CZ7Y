{"cells":[{"metadata":{},"cell_type":"markdown","source":"UPDATED!!!\n\n## The Purpose of This Notebook\n\nIn earlier versions of the notebook we were investigating the question of parameter tuning for the QDA model. Now, after the power of pseudolabeling was finally revealed the question becomes: What would be the best values of the QDA parameters with pseudolabeling? This notebook does not answer this question completely but it gives you the right tool to do this investigation on your own. \n\n## Short Description of the Method\n\nOur method is very simple: we generate 100 random values for the QDA parameter `reg_param` and then train 100 different models: one model for each value of `reg_param`. Then the value that maximizes ROC AUC score is identified and the results are visualized in the form of the AUC vs `reg_parm` scatter plot.\n\nHere is the list of our assumptions:\n\n* If you remember how pseudolableing with QDA works (which was very well explained in [Roman's](https://www.kaggle.com/nroman/i-m-overfitting-and-i-know-it) and [Chris's](https://www.kaggle.com/cdeotte/psuedo-labeling-qda-0-969) kernels) then you remember that we need to train QDA twice: one time without pseudolableing and the other with pseudolabeling. In what follows we will assume for simplicity that for both of these trainings the same value of `reg_param` is used. It is not difficult to modify the code below if you want to explore non-equal values of the parameters. \n\n* We also use `lowest=0.01`, `highest=0.99`, the same values as in Chris's notebook. Those can be easily adjusted as well. \n\n* In this notebook, we will do 100 trials with 5-fold cross-validation each. This can be easily adjusted by modifying the values of the parameter `NTRIALS` and `NFODS` below.\n\nEnjoy!"},{"metadata":{},"cell_type":"markdown","source":"## Preparatory Work"},{"metadata":{},"cell_type":"markdown","source":"### Loading Libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import time\nimport warnings\nimport multiprocessing\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"%%time\n\npath=Path('../input')\n\ndef load_data(data):\n    return pd.read_csv(data)\n\nwith multiprocessing.Pool() as pool:\n    train, test, sub = pool.map(load_data, [path/'train.csv', \n                                            path/'test.csv', \n                                            path/'sample_submission.csv'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Things for Cross-Validation"},{"metadata":{},"cell_type":"markdown","source":"Defining the optional parameters."},{"metadata":{"trusted":false},"cell_type":"code","source":"NFOLDS=5\nNTRIALS=100\nRS=42\ndebug=0\n\nlowest=0.01\nhighest=0.99","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking and handling the debuging mode (low values of `magic_max` and `NFOLDS` save a lot of time; the latter breaks cross-validation):"},{"metadata":{"trusted":false},"cell_type":"code","source":"if debug:\n    magic_max=2\n    magic_min=0\n    NFOLDS=2\n    NTRIALS=2\nelse:\n    magic_max=train['wheezy-copper-turtle-magic'].max()\n    magic_min=train['wheezy-copper-turtle-magic'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define the preprocessing function applying variance threshold to data grouped by the values of the `wheezy-copper-turtle-magic` variable."},{"metadata":{"trusted":false},"cell_type":"code","source":"def preprocess(clfs=['QDA'], train=train, test=test, magic_min=magic_min, magic_max=magic_max):\n    \n    prepr = {}\n    \n    #PREPROCESS 512 SEPARATE MODELS\n    for i in range(magic_min, magic_max+1):\n\n        # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS i     \n        X = train[train['wheezy-copper-turtle-magic']==i].copy()\n        Y = X.pop('target').values\n        X_test = test[test['wheezy-copper-turtle-magic']==i].copy()\n        idx_train = X.index \n        idx_test = X_test.index\n        X.reset_index(drop=True,inplace=True)\n\n        cols = [c for c in X.columns if c not in ['id', 'wheezy-copper-turtle-magic']]\n\n        l=len(X)\n        X_all = pd.concat([X[cols], X_test[cols]], ignore_index=True)\n\n        X_vt = VarianceThreshold(threshold=1.5).fit_transform(X_all)              # np.ndarray\n        \n        prepr['vt_' + str(i)] = X_vt        \n        prepr['train_size_' + str(i)] = l\n        prepr['idx_train_' + str(i)] = idx_train\n        prepr['idx_test_' + str(i)] = idx_test\n        prepr['target_' + str(i)] = Y\n        \n    return prepr","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n\ndata = preprocess()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_data(i, data):\n    \n    l = data['train_size_' + str(i)]    \n\n    X_all = data['vt_' + str(i)]                \n\n    X = X_all[:l, :]\n    X_test = X_all[l:, :]\n\n    Y = data['target_' + str(i)]\n\n    idx_train = data['idx_train_' + str(i)]\n    idx_test = data['idx_test_' + str(i)]\n    \n    return X, X_test, Y, idx_train, idx_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def pseudolabeling(X_train, X_test, Y_train, Y_pseudo, \n                   idx_test, lowest=lowest, highest=highest, test=test):\n    \n    assert len(test) == len(Y_pseudo), \"The length of test does not match that of Y_pseudo!\"\n    \n    #SELECT ONLY THE PSEUDOLABLES CORRESPONDING TO THE CURRENT VALUES OF 'wheezy-copper-turtle-magic'\n    Y_aug = Y_pseudo[idx_test]\n    \n    assert len(Y_aug) == len(X_test), \"The length of Y_aug does not match that of X_test!\"\n\n    Y_aug[Y_aug > highest] = 1\n    Y_aug[Y_aug < lowest] = 0\n    \n    mask = (Y_aug == 1) | (Y_aug == 0)\n    \n    Y_useful = Y_aug[mask]\n    X_test_useful = X_test[mask]\n    \n    X_train_aug = np.vstack((X_train, X_test_useful))\n    Y_train_aug = np.vstack((Y_train.reshape(-1, 1), Y_useful.reshape(-1, 1)))\n    \n    return X_train_aug, Y_train_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_classifier(clf_name, clfs, data=data, train=train, test=test, \n                     debug=debug, NFOLDS=NFOLDS, RS=RS, Y_pseudo=None,\n                     magic_min=magic_min, magic_max=magic_max,\n                     lowest=lowest, highest=highest, verbose=1):\n    \n    auc_all = np.array([])\n    oof = np.zeros(len(train))\n    preds = np.zeros(len(test))    \n    \n    #TRAIN 512 SEPARATE MODELS\n    for i in range(magic_min, magic_max+1):\n        \n        X, X_test, Y, idx_train, idx_test = get_data(i=i, data=data)      \n   \n        # STRATIFIED K FOLD    \n        folds = StratifiedKFold(n_splits=NFOLDS, random_state=RS)\n        \n        auc_folds = np.array([])\n        \n        for train_index, val_index in folds.split(X, Y):     \n\n            X_train, Y_train = X[train_index, :], Y[train_index]\n            X_val, Y_val = X[val_index, :], Y[val_index]\n            \n            if Y_pseudo is not None:\n                X_train_aug, Y_train_aug = pseudolabeling(X_train, X_test, \n                                                          Y_train, Y_pseudo, idx_test, \n                                                          lowest=lowest, highest=highest, \n                                                          test=test)\n                clfs[clf_name].fit(X_train_aug, Y_train_aug)                \n            else:\n                clfs[clf_name].fit(X_train, Y_train)\n\n            oof[idx_train[val_index]] = clfs[clf_name].predict_proba(X_val)[:,1]\n            preds[idx_test] += clfs[clf_name].predict_proba(X_test)[:,1]/NFOLDS\n\n            auc = roc_auc_score(Y_val, oof[idx_train[val_index]])\n            auc_folds = np.append(auc_folds, auc)\n                 \n        auc_all = np.append(auc_all, np.mean(auc_folds))\n        \n    auc_combo = roc_auc_score(train['target'].values, oof)\n    auc_av = np.mean(auc_all)\n    std = np.std(auc_all)/(np.sqrt(NFOLDS)*np.sqrt(magic_max+1))\n    \n    if verbose:    \n        # PRINT VALIDATION CV AUC FOR THE CLASSFIER\n        print(f'The result summary for the {clf_name} classifier:')\n        print(f'The combined CV score is {round(auc_combo, 5)}.')    \n        print(f'The folds average CV score is {round(auc_av, 5)}.')\n        print(f'The standard deviation is {round(std, 5)}.\\n')\n    \n    return preds, auc_combo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameter Search\n\n### Trying Different Values of the Parameters"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n\nresults = {}\nresults['rp']=np.array([])\nresults['auc']=np.array([])\n        \nnp.random.seed(RS)\n\nfor j in range(NTRIALS):\n\n    rp=10**(-2*np.random.rand()) # sampling values between 0.01 and 1\n       \n    # KEY: NAME, VALUE: [CLASSIFIER, DO_RANKING]\n    clfs_init={'QDA': QuadraticDiscriminantAnalysis(reg_param=rp)}\n\n    clfs={'QDA': QuadraticDiscriminantAnalysis(reg_param=rp)}\n\n    Y_pseudo, _ = train_classifier('QDA', clfs=clfs_init, verbose=0)\n\n    _, auc = train_classifier('QDA', clfs=clfs, Y_pseudo=Y_pseudo, verbose=0)\n        \n    results['rp']=np.append(results['rp'], rp)\n    results['auc']=np.append(results['auc'], auc)\n        \n    print(f\"Trial number {j}: AUC = {round(auc, 5)}, rp={round(rp, 5)}.\\n\")   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Summary of the Results"},{"metadata":{"trusted":false},"cell_type":"code","source":"auc_max = np.max(results['auc'])\ni_max = np.argmax(results['auc'])\nrp_best = results['rp'][i_max]\n\nprint(f\"The highest AUC achived is {round(auc_max, 5)} for rp={round(rp_best, 5)}.\")\n\nauc_min = np.min(results['auc'])\ni_min = np.argmin(results['auc'])\n\nprint(f\"The lowest AUC achived is {round(auc_min, 5)} for rp={round(results['rp'][i_min], 5)}.\")\n\n#CHECK IF THE BEST VALUE IS ON THE BOUNDARY\nprint(f\"The smallest value of `reg_param` that was explored during the search is {round(np.min(results['rp']), 5)}.\")\nprint(f\"The larges value of `reg_param` that was explored during the search is {round(np.max(results['rp']), 5)}.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the Results of the Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.scatter(results['rp'], results['auc'], s=4)\nplt.xlabel('reg_param')\nplt.ylabel('ROC AUC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission\n\n### Training the Classifier with the Best Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"clfs_best = {'QDA': QuadraticDiscriminantAnalysis(reg_param=rp_best)}\n\npreds_best, auc_best = train_classifier('QDA', clfs=clfs_best, Y_pseudo=Y_pseudo, verbose=0)\n\nprint(f\"AUC: {auc_best}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating the Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_best\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}