{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Random Ensembling as a Single Parallel Model\n\nHello, this is my first ever kernel in my first ever competition, so bear with me.\nI'm planning to make a simple fully-connected feed forward ensamble, randomly generated.\nTo do this I'll be using the Keras Functional API with a tensorflow backend.\n"},{"metadata":{},"cell_type":"markdown","source":"First, the imports. Nothing to non-standard:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\n\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here's the training data:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":21,"outputs":[{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We need to be able to ensamble a large group of model-blocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_random_model_block(layer_inp, out_dim):\n    depth = random.randint(1, 8)\n\n    x = layer_inp\n    layer = None\n    for __ in range(depth):\n        layer = random.choice(\n             [\"Dense\"] # + \n#             ([\"Dropout\"] if layer is not \"Dropout\" else []) +\n#             ([\"BatchNormalization\"] if layer is not \"BatchNormalization\" else [])\n        )\n    \n        if layer == \"Dense\":\n            units = 2 ** random.randint(1, 11)\n            activation = random.choice([\"tanh\", \"sigmoid\", \"relu\", \"selu\", None])\n            x = Dense(units, activation=\"relu\")(x)\n            \n        if layer == \"Dropout\":\n            dropout_rate = random.random()\n            x = Dropout(dropout_rate)(x)\n        \n        if layer == \"BatchNormalization\":\n            x = BatchNormalization()(x)\n    \n    out = Dense(out_dim, activation=\"sigmoid\")(x)\n        \n    return out","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to build a nice parallell model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_parallel_model(inp_shape, out_dim, models=16):\n    inp = Input(shape=inp_shape)\n\n    models = [build_random_model_block(inp, out_dim) for __ in range(models)]\n    ensemble = Concatenate()(models)\n    \n    out = Dense(out_dim, activation=\"sigmoid\")(ensemble)\n    \n    model = Model(inp, out)\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n    \n    return model","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training time!"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_parallel_model((len(cols),), 1)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array([train[col] for col in cols]).T\nprint(x.shape)\ny = np.array([[target] for target in train[\"target\"]])\nprint(y.shape)\nprint(len(cols))\nmodel.fit(x, y, batch_size=128, epochs=5)\nprint(model.evaluate(x, y, batch_size=128))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array([test[col] for col in cols]).T\nprint(x_test.shape)\nprint(len(cols))\npredictions = model.predict(x_test, batch_size=128)\n\nsub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = predictions\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}