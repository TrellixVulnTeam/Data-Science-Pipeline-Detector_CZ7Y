{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook as tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.covariance import GraphicalLasso\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models, weights = None):\n        self.models = models\n        self.weights = weights\n        assert len(self.models) == len(self.weights),  ('Len models != len weights')\n        assert abs(np.sum(self.weights) - 1) < 0.01,  ('weight sum != 1')\n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n                model.fit(X, y)\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict_proba(X)[:,1] for model in self.models_\n        ])\n        if self.weights:\n            return np.sum(predictions * self.weights, axis=1)\n        else:\n            return np.mean(predictions, axis=1)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predicts_with_validate(model, X, Y, n_folds = 3, X_test=[]):\n    kf = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 42)\n    scores = list()\n    #kf.get_n_splits(X,Y)\n    out_of_fold_predictions = np.zeros((X.shape[0]))\n    predicts_list = list()\n    for train_index, test_index in kf.split(X,Y):\n        X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n        Y_train, Y_valid = Y.iloc[train_index], Y.iloc[test_index]\n        model.fit(X_train,Y_train)\n        predicts = model.predict(X_valid)\n        out_of_fold_predictions[test_index] = predicts\n        scores.append(roc_auc_score(Y_valid, predicts))\n        if len(X_test) >0:\n            test_predicts = model.predict(X_test)\n            predicts_list.append(test_predicts)\n    return out_of_fold_predictions, scores, np.mean(predicts_list, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Func for get mean and preccision init per cluster (2 cluster per class)\n\n\n\ndef get_mean_cov(x,y):\n    model = GraphicalLasso()\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    try:\n        #Some times fall down, because bad clustering, and we give second chance for clustering\n        kmeans_ = KMeans(3)\n        clusters = kmeans_.fit_predict(x2)\n        p1_list = list()\n        m1_list = list()\n        for i in range(3):\n            model.fit(x2[np.where(clusters == i)[0]])\n            p1_list.append(model.precision_)\n            m1_list.append(model.location_)\n\n        onesb = (y==0).astype(bool)\n        x2b = x[onesb]\n        kmeans_ = KMeans(3)\n        clusters = kmeans_.fit_predict(x2b)\n        for i in range(3):\n            model.fit(x2b[np.where(clusters == i)[0]])\n            p1_list.append(model.precision_)\n            m1_list.append(model.location_)\n        n_clusters = 3\n    except:\n        print('!!!')\n        kmeans_ = KMeans(2)\n        clusters = kmeans_.fit_predict(x2)\n        p1_list = list()\n        m1_list = list()\n        for i in range(2):\n            model.fit(x2[np.where(clusters == i)[0]])\n            p1_list.append(model.precision_)\n            m1_list.append(model.location_)\n\n        onesb = (y==0).astype(bool)\n        x2b = x[onesb]\n        kmeans_ = KMeans(2)\n        clusters = kmeans_.fit_predict(x2b)\n        for i in range(2):\n            model.fit(x2b[np.where(clusters == i)[0]])\n            p1_list.append(model.precision_)\n            m1_list.append(model.location_)\n        n_clusters = 2\n    ms = np.stack(m1_list)\n    ps = np.stack(p1_list)\n    return ms,ps, n_clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# QDA for drop flip and pseudo labeling\nQDA = QuadraticDiscriminantAnalysis(reg_param=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# QDA for drop flips\ncols = [c for c in train_df.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\npreds = np.zeros(len(train_df))\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train_df[train_df['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index;\n    train2.reset_index(drop=True,inplace=True)\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    models = [QDA]\n    averaged_models = AveragingModels(models=models, weights=[1])\n    out_of_fold_predictions, scores,_ = get_predicts_with_validate(averaged_models, pd.DataFrame(train3), train2['target'], 11)\n    preds[idx1] = out_of_fold_predictions\n# PRINT CV AUC\nauc = roc_auc_score(train_df['target'], preds)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop flips\ntrain_df['preds'] = preds\nprint(len(train_df[((train_df['target']==0) & (train_df['preds']>=0.95)) | ((train_df['target']==1) & (train_df['preds']<=0.05))]))\ntrain_df = train_df[((train_df['target']==0) & (train_df['preds']<=0.95)) | ((train_df['target']==1) & (train_df['preds']>=0.05))]\ntrain_df.drop(['preds'], axis=1, inplace=True)\ntrain_df.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# QDA for Pseudo labeling\ncols = [c for c in train_df.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\npreds = np.zeros(len(train_df))\ntest_preds = np.zeros(len(test))\n\npreds_gm = np.zeros(len(train_df))\ntest_preds_gm = np.zeros(len(test))\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train_df[train_df['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    models = [QDA]\n    averaged_models = AveragingModels(models=models, weights=[1])\n    out_of_fold_predictions, scores, test_predicts = get_predicts_with_validate(averaged_models, pd.DataFrame(train3), train2['target'], 11, test3)\n    preds[idx1] = out_of_fold_predictions\n    test_preds[idx2] = test_predicts\n    \npreds = preds \ntest_preds = test_preds\n# PRINT CV AUC\nauc = roc_auc_score(train_df['target'], preds)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get len of feature pseudo labeling data\ntest['target'] = test_preds\nprint(len(test[(test['target']<=0.01) | (test['target']>=0.99)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.zeros(len(train_df))\ntest_preds_ = np.zeros(len(test))\npreds_gm = np.zeros(len(train_df))\ntest_preds_gm = np.zeros(len(test))\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train_df[train_df['wheezy-copper-turtle-magic']==i]\n    train2p = train2.copy(); idx1 = train2.index \n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    #train2.reset_index(drop=True,inplace=True)\n    max_predicts_count = len(train2p)\n     # ADD PSEUDO LABELED DATA\n    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n    train2p = pd.concat([train2p,test2p],axis=0)\n    train2p.reset_index(drop=True,inplace=True)\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n    train3p = sel.transform(train2p[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # Get means and precisions for Gaussian Mixture (4 - components [ two for zeroes class and two for ones class])\n    ms, ps, n_clusters = get_mean_cov(train3p,train2p['target'].values)\n    gm = GaussianMixture(n_components=n_clusters * 2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n    gm.fit(np.concatenate([train3,test3],axis = 0))\n    predicts = gm.predict_proba(train3)\n    preds_gm[idx1] = np.sum(predicts[:,:n_clusters], axis=1)\n    predicts = gm.predict_proba(test3)\n    test_preds_[idx2] = np.sum(predicts[:,:n_clusters], axis=1)\nauc = roc_auc_score(train_df['target'], preds_gm)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = test_preds_\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}