{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/denoising-dirty-documents/test.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/denoising-dirty-documents/train.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/denoising-dirty-documents/train_cleaned.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filenames = os.listdir('train')\ntrain_cleaned_filenames = os.listdir('train_cleaned')\ntest_filenames = os.listdir('test')\nprint(\"Train files: {}\".format(len(train_filenames)))\nprint(\"Test files: {}\".format(len(test_filenames)))\nprint(\"Cleaned Train files: {}\".format(len(train_cleaned_filenames)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ntrain_images = [cv2.imread(os.path.join('train', file), 0) for file in train_filenames if file.endswith('.png')]\ncleaned_train_images = [cv2.imread(os.path.join('train_cleaned', file), 0) for file in train_cleaned_filenames if file.endswith('.png')]\ntest_images = [cv2.imread(os.path.join('test', file), 0) for file in test_filenames if file.endswith('.png')]\n\ntrain_images = [cv2.resize(img, (540, 260)) for img in train_images]\ncleaned_train_images = [cv2.resize(img, (540, 260)) for img in cleaned_train_images]\ntest_images = [cv2.resize(img, (540, 260)) for img in test_images]\n\nprint(len(train_images))\nprint(len(cleaned_train_images))\nprint(len(test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.imshow(train_images[10], cmap='gray')\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(cleaned_train_images[10], cmap='gray')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nindex = np.random.randint(0, len(train_images))\nplt.subplot(1, 2, 1)\nplt.imshow(train_images[index], cmap='gray')\nplt.subplot(1, 2, 2)\nplt.imshow(cv2.threshold(train_images[index], 120, 255, cv2.THRESH_BINARY)[1], cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = np.stack(train_images, axis=0).astype('float32')/255.\ncleaned_train_images = np.stack(cleaned_train_images, axis=0).astype('float32')/255.\ntest_images = np.stack(test_images, axis=0).astype('float32')/255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\nfrom tensorflow.keras.models import Model\n\ndef encoder(input_img):\n  x = Conv2D(32, (3, 3), activation='relu', padding='same', name='encoder_conv1')(input_img)\n  x = MaxPool2D((2, 2), padding='same', name='encoder_pool1')(x)\n  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='encoder_conv2')(x)\n  x = MaxPool2D((2, 2), padding='same', name='encoder_pool2')(x)\n  encoded = Conv2D(128, (3, 3), activation='relu', padding='same', name='encoder_conv3')(x)\n  return encoded\n\n\ndef decoder(encoded):\n  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_conv1')(encoded)\n  x = UpSampling2D((2, 2), name='decoder_upsample1')(x)\n  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_conv2')(x)\n  x = UpSampling2D((2, 2), name='decoder_upsample2')(x)\n  x = Conv2D(32, (3, 3), activation='relu', padding='same', name='decoder_conv3')(x)\n  decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='decoder_conv4')(x)\n  return decoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input(shape=(260, 540, 1))\n\n#create autoencoder model\nautoencoder = Model(input_img, decoder(encoder(input_img)))\n#complile model\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nearlyStop = EarlyStopping(monitor='loss', patience=10, mode='min')\nchkPoint = ModelCheckpoint(filepath='best_weights.h5', monitor='loss', mode='min', save_best_only=True)\ntrain_history = autoencoder.fit(np.expand_dims(train_images, 3), np.expand_dims(cleaned_train_images, 3),\n                epochs=500,\n                batch_size=32,\n                shuffle=True,\n                callbacks = [chkPoint, chkPoint]\n               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.load_weights('best_weights.h5')\n\ntest_image = test_images[60]\ntest_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], 1))\nprediected_img = autoencoder.predict(test_image)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.imshow(test_image[0, :, :, 0], cmap='gray')\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(prediected_img[0, :, :, 0], cmap='gray')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}