{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <h1>Denoising using Autoencoder model</h1>\n\nDataset from: https://github.com/kwcckw/shabby_data_normal_quality","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# import libraries\n\nimport numpy as np\nimport cv2\nimport random\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport glob\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:35:31.769827Z","iopub.execute_input":"2022-06-19T10:35:31.770649Z","iopub.status.idle":"2022-06-19T10:35:40.181104Z","shell.execute_reply.started":"2022-06-19T10:35:31.770553Z","shell.execute_reply":"2022-06-19T10:35:40.180351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1> Data Preparation</h1>","metadata":{}},{"cell_type":"code","source":"# create dirs\n\ntrain_input_path = '/kaggle/working/train/input_images/'\ntrain_target_path = '/kaggle/working/train/target_images/'\n\nval_input_path = '/kaggle/working/val/input_images/'\nval_target_path = '/kaggle/working/val/target_images/'\n\ntest_input_path = '/kaggle/working/test/input_images/'\ntest_target_path = '/kaggle/working/test/target_images/'\n\nos.makedirs(train_input_path)\nos.makedirs(train_target_path)\n\nos.makedirs(val_input_path)\nos.makedirs(val_target_path)\n\nos.makedirs(test_input_path)\nos.makedirs(test_target_path)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:35:40.183035Z","iopub.execute_input":"2022-06-19T10:35:40.183355Z","iopub.status.idle":"2022-06-19T10:35:40.192666Z","shell.execute_reply.started":"2022-06-19T10:35:40.183289Z","shell.execute_reply":"2022-06-19T10:35:40.191412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# move data into the correct dirs\n\n# train\n!cp -ar /kaggle/input/shabby-data-normal-quality/images_normal_quality/cropped/train/ /kaggle/working/train/input_images/\n!cp -ar /kaggle/input/shabby-data-normal-quality/images_normal_quality/cropped/train_cleaned/ /kaggle/working/train/target_images/\n\n# validate\n!cp -ar /kaggle/input/shabby-data-normal-quality/images_normal_quality/cropped/validate/ /kaggle/working/val/input_images/\n!cp -ar /kaggle/input/shabby-data-normal-quality/images_normal_quality/cropped/validate_cleaned/ /kaggle/working/val/target_images/\n\n# test\n# !cp -ar /kaggle/input/shabby-data-normal-quality/images_low_quality/cropped/test/ /kaggle/working/test/input_images/\n# !cp -ar /kaggle/input/shabby-data-normal-quality/images_low_quality/cropped/test_cleaned/ /kaggle/working/test/target_images/","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:35:40.195614Z","iopub.execute_input":"2022-06-19T10:35:40.196208Z","iopub.status.idle":"2022-06-19T10:36:06.968164Z","shell.execute_reply.started":"2022-06-19T10:35:40.196165Z","shell.execute_reply":"2022-06-19T10:36:06.966846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add new data\n\nos.makedirs('/kaggle/working/denoising-dirty-documents/')\n\n!unzip /kaggle/input/denoising-dirty-documents/train_cleaned.zip -d /kaggle/working/denoising-dirty-documents/\n!unzip /kaggle/input/denoising-dirty-documents/train.zip -d /kaggle/working/denoising-dirty-documents/\n\n!cp -ar /kaggle/working/denoising-dirty-documents/train/* /kaggle/working/train/input_images/train\n!cp -ar /kaggle/working/denoising-dirty-documents/train_cleaned/* /kaggle/working/train/target_images/train_cleaned\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training params\n\nbatch_size = 32\nepoch_size = 150","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:36:10.985848Z","iopub.execute_input":"2022-06-19T10:36:10.986668Z","iopub.status.idle":"2022-06-19T10:36:10.992352Z","shell.execute_reply.started":"2022-06-19T10:36:10.986622Z","shell.execute_reply":"2022-06-19T10:36:10.991377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create training generators\n\ntrain_input_data_gen = ImageDataGenerator(rescale=1./255)\ntrain_target_data_gen = ImageDataGenerator(rescale=1./255)\n\ntrain_input_image_generator = train_input_data_gen.flow_from_directory(\n    train_input_path,\n    batch_size=batch_size,\n    color_mode = 'grayscale',\n    target_size=(400, 400),\n    class_mode=None,\n    shuffle=False,\n    seed=0)\n\ntrain_target_image_generator = train_target_data_gen.flow_from_directory(\n    train_target_path,\n    batch_size=batch_size,\n    color_mode = 'grayscale',\n    target_size=(400, 400),\n    class_mode=None,\n    shuffle=False,\n    seed=0)\n\ntrain_generator = zip(train_input_image_generator, train_target_image_generator)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:36:10.99373Z","iopub.execute_input":"2022-06-19T10:36:10.99458Z","iopub.status.idle":"2022-06-19T10:36:11.21352Z","shell.execute_reply.started":"2022-06-19T10:36:10.99454Z","shell.execute_reply":"2022-06-19T10:36:11.21264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create validation generator\n\nval_input_data_gen = ImageDataGenerator(rescale=1./255)\nval_target_data_gen = ImageDataGenerator(rescale=1./255)\n\nval_input_image_generator = val_input_data_gen.flow_from_directory(\n    val_input_path,\n    batch_size=batch_size,\n    color_mode = 'grayscale',\n    target_size=(400, 400),\n    class_mode=None,\n    shuffle=False,\n    seed=0)\n\nval_target_image_generator = val_target_data_gen.flow_from_directory(\n    val_target_path,\n    batch_size=batch_size,\n    color_mode = 'grayscale',\n    target_size=(400, 400),\n    class_mode=None,\n    shuffle=False,\n    seed=0)\n\nval_generator = zip(val_input_image_generator, val_target_image_generator)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:36:11.215056Z","iopub.execute_input":"2022-06-19T10:36:11.215548Z","iopub.status.idle":"2022-06-19T10:36:11.428498Z","shell.execute_reply.started":"2022-06-19T10:36:11.215507Z","shell.execute_reply":"2022-06-19T10:36:11.427645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some training images and target images\n\nfrom matplotlib import pyplot as plt\n\nn = 0\nfor train, target in zip(train_input_image_generator, train_target_image_generator):\n    plt.figure()\n    plt.subplot(121)\n    plt.imshow((train[0][:,:,0]*255).astype('uint8'),cmap='gray')\n    plt.subplot(122)\n    plt.imshow((target[0][:,:,0]*255).astype('uint8'),cmap='gray')\n    n+=1\n    if n >5:\n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:36:11.431271Z","iopub.execute_input":"2022-06-19T10:36:11.432Z","iopub.status.idle":"2022-06-19T10:36:14.78435Z","shell.execute_reply.started":"2022-06-19T10:36:11.431955Z","shell.execute_reply":"2022-06-19T10:36:14.783523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1> Create and train model </h1>","metadata":{}},{"cell_type":"code","source":"# Create model\n\ndef autoencoder():\n\n    model = Sequential()\n\n    # input layer\n    model.add(layers.Input(shape=(400,400, 1)))\n\n    # encoder section\n    model.add(layers.Conv2D(32, (3, 3), activation='relu',strides=2,padding='same'))\n    model.add(layers.Conv2D(64, (3, 3), activation='relu',strides=2,padding='same'))\n    model.add(layers.BatchNormalization())\n    \n\n    # decoder section\n    model.add(layers.Conv2DTranspose(64, (3, 3), activation='relu',strides=2,padding='same'))\n    model.add(layers.Conv2DTranspose(32, (3, 3), activation='relu',strides=2,padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Conv2DTranspose(1, (3, 3), activation='sigmoid',strides=1, padding='same'))\n\n    # compile model\n    model.compile(optimizer='adam' , loss='mean_squared_error', metrics=['mae'])\n\n    #print model summary\n    model.summary()\n\n    return model\n\n# create model\nmodel = autoencoder()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:36:14.785812Z","iopub.execute_input":"2022-06-19T10:36:14.786211Z","iopub.status.idle":"2022-06-19T10:36:18.268858Z","shell.execute_reply.started":"2022-06-19T10:36:14.78616Z","shell.execute_reply":"2022-06-19T10:36:18.267124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit model\n\ntraining_sample = train_input_image_generator.samples\nvalidate_sample = val_input_image_generator.samples\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n\n\nmodel.fit(\n        train_generator,\n        steps_per_epoch=np.ceil(training_sample/batch_size),\n        epochs=epoch_size,\n        validation_data=val_generator,\n        validation_steps=np.ceil(validate_sample/batch_size),\n        callbacks=[callback]\n        )\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:40:29.660296Z","iopub.execute_input":"2022-06-19T11:40:29.660751Z","iopub.status.idle":"2022-06-19T11:45:31.337959Z","shell.execute_reply.started":"2022-06-19T11:40:29.660677Z","shell.execute_reply":"2022-06-19T11:45:31.337179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1> Predict clean image and get submission file</h1>","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:53:04.772873Z","iopub.execute_input":"2022-06-19T10:53:04.773152Z","iopub.status.idle":"2022-06-19T10:53:04.782399Z","shell.execute_reply.started":"2022-06-19T10:53:04.773113Z","shell.execute_reply":"2022-06-19T10:53:04.780378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/kwcckw/shabby_images/","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:53:04.784067Z","iopub.execute_input":"2022-06-19T10:53:04.78463Z","iopub.status.idle":"2022-06-19T10:53:20.111127Z","shell.execute_reply.started":"2022-06-19T10:53:04.784584Z","shell.execute_reply":"2022-06-19T10:53:20.110208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input_path = \"/kaggle/working/shabby_images/Datasets/test\"","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:53:20.112954Z","iopub.execute_input":"2022-06-19T10:53:20.114529Z","iopub.status.idle":"2022-06-19T10:53:20.11941Z","shell.execute_reply.started":"2022-06-19T10:53:20.114485Z","shell.execute_reply":"2022-06-19T10:53:20.118353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(path):\n\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = np.asarray(img, dtype=\"float32\")\n    img = img/255.0 #Scaling the pixel values\n    \n    return img.reshape(400,400,1)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:53:20.121285Z","iopub.execute_input":"2022-06-19T10:53:20.121927Z","iopub.status.idle":"2022-06-19T10:53:20.130611Z","shell.execute_reply.started":"2022-06-19T10:53:20.121884Z","shell.execute_reply":"2022-06-19T10:53:20.129441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get testing image\n\nimg_test_path = sorted(glob.glob(test_input_path+'/input/*'))\n\ntest_imgs = []\nfor file_path in img_test_path:\n    test_imgs.append(preprocess(file_path))\ntest_imgs = np.asarray(test_imgs)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T10:53:20.132108Z","iopub.execute_input":"2022-06-19T10:53:20.132554Z","iopub.status.idle":"2022-06-19T10:53:21.826558Z","shell.execute_reply.started":"2022-06-19T10:53:20.132514Z","shell.execute_reply":"2022-06-19T10:53:21.825712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get cleaned images using trained model\n\nimg_predicted = model.predict(test_imgs, batch_size=2)\nfor i, (predicted, testing_path) in enumerate(zip(img_predicted, img_test_path)):\n    predicted_sequeeze = (np.squeeze(predicted) * 255).astype(\"uint8\")\n    cv2.imwrite(test_target_path+os.path.basename(testing_path), predicted_sequeeze)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:50:20.902147Z","iopub.execute_input":"2022-06-19T11:50:20.902739Z","iopub.status.idle":"2022-06-19T11:50:54.20034Z","shell.execute_reply.started":"2022-06-19T11:50:20.902697Z","shell.execute_reply":"2022-06-19T11:50:54.199407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get cleaned images (optional)\n\nfrom IPython.display import FileLink\n\n!zip -r output_images.zip /kaggle/working/test/target_images/\nFileLink(r'output_images.zip')","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:50:54.202263Z","iopub.execute_input":"2022-06-19T11:50:54.202659Z","iopub.status.idle":"2022-06-19T11:50:56.101889Z","shell.execute_reply.started":"2022-06-19T11:50:54.202615Z","shell.execute_reply":"2022-06-19T11:50:56.100956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some input testing image and cleaned image from the model\n\nfrom matplotlib import pyplot as plt\n\nn = 0\nfor noisy_path in img_test_path:\n    \n    clean_path = test_target_path + os.path.basename(noisy_path)\n    \n    img_noisy = cv2.imread(noisy_path, cv2.IMREAD_GRAYSCALE)\n    img_clean = cv2.imread(clean_path, cv2.IMREAD_GRAYSCALE)\n    \n    plt.figure()\n    plt.subplot(121)\n    plt.imshow(img_noisy,cmap='gray')\n    plt.subplot(122)\n    plt.imshow(img_clean,cmap='gray')\n    n+=1\n    if n >5:\n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:50:56.103613Z","iopub.execute_input":"2022-06-19T11:50:56.104217Z","iopub.status.idle":"2022-06-19T11:50:59.222135Z","shell.execute_reply.started":"2022-06-19T11:50:56.104172Z","shell.execute_reply":"2022-06-19T11:50:59.221195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create submission file\n\n\ncleaned_images_dir = '/kaggle/working/test/target_images/'\n\ndef select_pixels(img):\n    y,x = img.shape\n\n    pixels = list()\n\n    for i in range(10000):\n        pixel = (random.randrange(y), random.randrange(x))\n\n        if pixel not in pixels:\n            pixels.append(pixel)\n\n    return pixels\n\n\nrandom.seed(0)\n\ncleaned_images = sorted(os.listdir(cleaned_images_dir))\n\nwith open(\"submission.csv\", \"w\") as submission_file:\n    submission_file.write(\"id,predicted\\n\")\n\n    print(\"Processing images...\")\n    filenum = 1\n    for image in tqdm(cleaned_images):\n        \n        img = cv2.imread(cleaned_images_dir + image, cv2.IMREAD_GRAYSCALE)\n        pixels = select_pixels(img)\n\n        for pixel in pixels:\n            y,x = pixel\n            submission_file.write(\"{}_{}_{},{}\\n\".format(filenum, y, x, img[y][x]/255.0))\n\n        filenum += 1\n    print('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:50:59.224387Z","iopub.execute_input":"2022-06-19T11:50:59.224774Z","iopub.status.idle":"2022-06-19T11:58:00.188101Z","shell.execute_reply.started":"2022-06-19T11:50:59.224721Z","shell.execute_reply":"2022-06-19T11:58:00.187299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get submission file\n\nfrom IPython.display import FileLink\n\nFileLink(r'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-19T11:59:57.121663Z","iopub.execute_input":"2022-06-19T11:59:57.121963Z","iopub.status.idle":"2022-06-19T11:59:57.129395Z","shell.execute_reply.started":"2022-06-19T11:59:57.121925Z","shell.execute_reply":"2022-06-19T11:59:57.128378Z"},"trusted":true},"execution_count":null,"outputs":[]}]}