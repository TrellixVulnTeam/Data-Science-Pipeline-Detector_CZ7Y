{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unzipping the files**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/denoising-dirty-documents/train.zip\n!unzip /kaggle/input/denoising-dirty-documents/test.zip\n!unzip /kaggle/input/denoising-dirty-documents/train_cleaned.zip\n!unzip /kaggle/input/denoising-dirty-documents/sampleSubmission.csv.zip","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import the required packages**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.layers import Input, Dense,Conv2D,MaxPooling2D,UpSampling2D,BatchNormalization\nfrom keras.models import Model,Sequential\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize few images that we are going to deal with."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 2))\nfor root, dirs, files in os.walk('/kaggle/working/train'):\n    for i in range(5):\n        ax = plt.subplot(1, 5, i+1)\n        img = cv2.imread(os.path.join(root,files[i]))\n        resized = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n        plt.imshow(resized)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 2))\nfor root, dirs, files in os.walk('/kaggle/working/train_cleaned'):\n    for i in range(5):\n        ax = plt.subplot(1, 5, i+1)\n        img = cv2.imread(os.path.join(root,files[i]))\n        resized = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n        plt.imshow(resized)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load our train an test images and preprocess them to make them appropriate for modelling"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load train and train_cleaned data\ntrain_data = []\ntrain_data_cleaned = []\ntrain_path = '/kaggle/working/train'\ntrain_cleaned_path = '/kaggle/working/train_cleaned'\n\n\n\nfor filename in os.listdir(train_path):\n    train_img = cv2.imread(os.path.join(train_path,filename))\n    train_img = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n    train_img = cv2.resize(train_img,(540, 258),interpolation = cv2.INTER_AREA)\n    train_img = train_img.astype('float32')\n    train_img = train_img/255.0\n    train_data.append(train_img)\n    train_cleaned_img = cv2.imread(os.path.join(train_cleaned_path,filename))\n    train_cleaned_img = cv2.cvtColor(train_cleaned_img, cv2.COLOR_BGR2GRAY)\n    train_cleaned_img = cv2.resize(train_cleaned_img,(540, 258),interpolation = cv2.INTER_AREA)\n    train_cleaned_img = train_cleaned_img.astype('float32')\n    train_cleaned_img = train_cleaned_img/255.0\n    train_data_cleaned.append(train_cleaned_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's stack the images\ntrain_data = np.stack(train_data)\ntrain_data_cleaned = np.stack(train_data_cleaned)\n\n# Reshaping the data for model\ntrain_data = train_data.reshape(train_data.shape[0],train_data.shape[1],train_data.shape[2],1)\ntrain_data_cleaned = train_data_cleaned.reshape(train_data_cleaned.shape[0],train_data_cleaned.shape[1],train_data_cleaned.shape[2],1)\n\n\n\nx_train,x_val,y_train,y_val = train_test_split(train_data,train_data_cleaned,test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a autoencoder using keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model\ninput_img = Input(shape=(258,540,1))\nencoder = Conv2D(filters=64,kernel_size=(3,3),padding='same',activation='elu')(input_img)\nencoder = MaxPooling2D((2,2))(encoder)\ndecoder = Conv2D(64,kernel_size=(3,3),padding='same',activation='elu')(encoder)\ndecoder = UpSampling2D((2,2))(decoder)\ndecoder = Conv2D(1,kernel_size=(3,3),padding='same',activation='sigmoid')(decoder)\nautoencoder = Model(input_img,decoder)\nautoencoder.compile(loss='binary_crossentropy',optimizer='adam',metrics=['mse'])\n\nautoencoder.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's define the callbacks for our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = autoencoder.fit(x_train,y_train,epochs=100,batch_size=20,validation_data=(x_val,y_val),callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Model Loss')\nplt.legend(['Train', 'Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = autoencoder.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_0 = preds[0].reshape(preds.shape[1],preds.shape[2])\nx_val_0 = x_val[0].reshape(x_val.shape[1],x_val.shape[2])\nplt.imshow(preds_0,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_1= preds[1].reshape(preds.shape[1],preds.shape[2])\nx_val_1 = x_val[1].reshape(x_val.shape[1],x_val.shape[2])\nplt.imshow(preds_1,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the test data and make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_test(path):\n    test_data= []\n    test_keys= []\n    for filename in os.listdir(path):\n        test_key = filename.split('.')[0]\n        img = cv2.imread(os.path.join(path,filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img,(540, 258),interpolation = cv2.INTER_AREA)\n        img = img.astype('float32')\n        img = img/255.0\n        test_data.append(img)\n        test_keys.append(test_key)\n    return test_data,test_keys\n\ntest_path = '/kaggle/working/test'\ntest_data,test_keys = load_test(test_path)\ntest_data = np.stack(test_data)\ntest_data = test_data.reshape(test_data.shape[0],test_data.shape[1],test_data.shape[2],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = autoencoder.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds_1= test_preds[1].reshape(test_preds.shape[1],test_preds.shape[2])\ntest_data_1 = test_data[1].reshape(test_data.shape[1],test_data.shape[2])\nplt.imshow(test_data_1,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(test_preds_1,cmap='gray')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}