{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport os\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,UpSampling2D,InputLayer,Reshape\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import array_to_img\nimport matplotlib.pyplot as plt\n\n#%% Data receive functions, receive datas from folders\n\ndef getData(pathd,shape):\n    #file i/o çalışılmalı\n    os.chdir(pathd)\n    Alldatas=[]\n    img_data=[]\n    img_data=os.listdir(\".\")\n    for image in img_data:\n        _,extension = os.path.splitext(image)\n        if(extension==\".jpg\" or extension==\".jpeg\" or extension==\".png\"):\n            img=load_img(image)\n            img=img.resize((shape[0],shape[1]))\n            x=img_to_array(img)\n           # x=x.reshape((1,) + x.shape)\n            Alldatas.append(x)\n    return Alldatas\nscale=(540,258)\nall_img=getData(\"/kaggle/input/cleaning-dirty-documents-unzipped/train\",scale)\nall_img_y=getData(\"/kaggle/input/cleaning-dirty-documents-unzipped/train_cleaned\",scale)\n#%%\nall_img=tf.image.rgb_to_grayscale(all_img)\nall_img_y=tf.image.rgb_to_grayscale(all_img_y)\n#%%\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def prepare(arr,flatten=True):\n    arr=np.asarray(arr,dtype=\"float32\")\n    arr2=arr/255-0.5\n    if(flatten):\n        Count=arr2.shape[0]\n        arr2=arr2.flatten()\n        shap=int(arr2.shape[0]/Count)\n        arr2=arr2.reshape(Count,shap)\n    return arr2\n        \n# EDIT DATASET AND RESHAPE\ntrain = prepare(all_img,flatten=False)\ntrain_y = prepare(all_img_y,flatten=False)\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(train,train_y,test_size=0.1,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Creating Convolutional Autoencoder","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#CREATE AUTOENCODER\n\nfrom keras.layers import Activation\nfrom keras import optimizers\ndef cust(x):\n    return tf.keras.backend.sigmoid(x)-0.5\n\nopt = optimizers.RMSprop(learning_rate=0.001)\nmodel = Sequential()\nmodel.add(Conv2D(128, (3, 3), padding='same',input_shape=(258,540,1),data_format=\"channels_last\"))\nmodel.add(MaxPooling2D((2, 2), padding='same')) \nmodel.add(UpSampling2D((2, 2))) #SIGMOID TO EASILY GENERATE IMAGES IN WIDE RANGE\nmodel.add(Conv2D(1, (3, 3), activation=cust, padding='same'))\nmodel.compile(loss=\"mean_squared_error\",optimizer=opt)\nprint(model.summary())\n\n    \nmodel.fit(x_train,\n          y_train,\n          epochs = 600,\n          batch_size = 7,\n          validation_data = (x_test,y_test),\n          verbose=1)\n\n#%% Check difference between test images\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Showing, Visualizing Noised and Denoised image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,9):\n    check=x_test[i]\n    matrix=model.predict(check.reshape((1,)+check.shape)).reshape(258,540,1)\n    \n    #Show real image and generated image from autoencoder\n    plt.figure(figsize=(50,50))\n    plt.subplot(10,10,1)\n    plt.imshow(array_to_img(check+0.5),cmap=\"gray\")\n    plt.subplot(10,10,2)\n    plt.imshow(array_to_img(matrix+0.5),cmap=\"gray\")\n\n#%%\n#Plot Loss\nplt.figure(figsize=(10,10))\n\nplt.plot(model.history.history['loss'])\nplt.plot(model.history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n#%% Vısualizing Model\nfrom keras.utils.vis_utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}