{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Pick a Dataset you might be interested in.\n#  Say, all airline-safety files...\nimport zipfile\nimport os \n\ntrain_dataset = \"train\"\nclean_dataset = \"train_cleaned\"\ntest_dataset = \"test\"\n\nbase_path = \"/kaggle/input/denoising-dirty-documents/\"\n\ndef extract_files(base_path,dataset):\n    full = os.path.join(base_path,dataset)\n    # Will unzip the files so that you can see them..\n    with zipfile.ZipFile(full+\".zip\",\"r\") as z:\n        z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in [train_dataset, clean_dataset, test_dataset]:\n    extract_files(base_path, dataset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for folder in [\"test\", \"train\", \"train_cleaned\"]:\n    base_dir = \"/kaggle/working/\"\n    txt_dir = os.path.join(base_dir, folder, \"text\")\n    mv_dir = os.path.join(base_dir, folder)\n    !mkdir -p  $txt_dir\n    !mv $mv_dir/*.png $txt_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndir_to_scan = \"/kaggle/working/train/text\"\ndata_dir = Path(dir_to_scan)\nimage_count = len(list(data_dir.glob('*.png')))\nimage_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nIMG_HEIGHT = 420\nIMG_WIDTH = 540","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All images will be rescaled by 1./255\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(directory=\"/kaggle/working/train\",\n                                                     batch_size=BATCH_SIZE,\n                                                     #shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), \n                                                     color_mode='grayscale',\n                                                     class_mode='input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_generator = valid_datagen.flow_from_directory(directory=str(\"/kaggle/working/train_cleaned\"),\n                                                     batch_size=BATCH_SIZE,\n                                                     #shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     color_mode='grayscale',    \n                                                     class_mode='input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(directory=str(\"/kaggle/working/test\"),\n                                                     batch_size=BATCH_SIZE,\n                                                     shuffle=False,\n                                                     color_mode='grayscale',\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     class_mode='input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_encoder():\n\n    input_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1)) \n    \n    # Encoding Layers\n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n    encoded = MaxPooling2D((2, 2), padding='same')(x)\n    \n    # Decoding Layers \n    x = Conv2DTranspose(filters=32,kernel_size=3,strides=(2, 2),padding=\"same\",activation='relu')(encoded)\n    x = Conv2DTranspose(filters=32,kernel_size=3,strides=(2, 2),padding=\"same\",activation='relu')(x)\n    decoded = Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"same\", activation='sigmoid')(x)\n    \n    return Model(input_img, decoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder = build_encoder()\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\nautoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = autoencoder.fit(\n      x=train_generator,\n      epochs=100,\n      validation_data = validation_generator,\n      callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_graphs(history, 'mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_graphs(history, 'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = autoencoder.predict(test_generator)\n#preds = np.squeeze(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_preds(test, preds,n=1):\n    plt.figure(figsize=(30, 20))\n    for i in range(n):\n        # display original\n        ax = plt.subplot(2, n, i + 1)\n        test = test *  255.0\n        plt.imshow(test.reshape((420,540)),cmap='gray')\n        #plt.imshow(np.squeeze(test), cmap='gray')\n\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        # display reconstruction\n        ax = plt.subplot(2, n, i + 1 + n)\n        preds = preds* 255.0\n        plt.imshow(preds.reshape((420,540)), cmap='gray')\n        #plt.imshow(np.squeeze(preds), cmap='gray')\n        \n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator[0][0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_preds(test_generator[0][0][15], preds[15],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndir_to_scan = \"/kaggle/working/test/text\"\ndata_dir = Path(dir_to_scan)\ntest_imgs = sorted(list(data_dir.glob('*.png')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = image.imread(str(test_imgs[0]))\nheight, width = im.shape\nend_im = cv2.resize(preds[0], (width, height))\nrows, cols = end_im.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"submissions.csv\", \"w\") as file1:\n    file1.write(\"id,value\\n\")\n    for i, test_img in enumerate(test_imgs):\n        id = test_img.stem\n        im = image.imread(str(test_img))\n        height, width = im.shape\n        end_im = cv2.resize(preds[i], (width, height))\n        rows, cols = end_im.shape\n        for row in range(rows):\n            for col in range(cols):\n                file1.write(\"{}_{}_{},{}\\n\".format(id,row+1,col+1, end_im[row][col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat submissions.csv | wc -l ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head submissions.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('submissions.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.id == '100_1_1']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}