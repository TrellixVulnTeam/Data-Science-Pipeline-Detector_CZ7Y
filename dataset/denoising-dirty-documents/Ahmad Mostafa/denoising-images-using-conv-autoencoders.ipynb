{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, Conv2DTranspose, Input\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-29T05:32:01.631847Z","iopub.execute_input":"2021-10-29T05:32:01.632337Z","iopub.status.idle":"2021-10-29T05:32:01.63795Z","shell.execute_reply.started":"2021-10-29T05:32:01.632297Z","shell.execute_reply":"2021-10-29T05:32:01.636853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path to zipped & working directories\npath_zip = '/kaggle/input/denoising-dirty-documents/'\npath = '/kaggle/working/'\n\n# unzip files first to working directory\n# We could use also unzipped data source, but why not to learn something new?\nwith zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)\n\nwith zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  ","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:16:19.24109Z","iopub.execute_input":"2021-10-29T05:16:19.243329Z","iopub.status.idle":"2021-10-29T05:16:21.662879Z","shell.execute_reply.started":"2021-10-29T05:16:19.243289Z","shell.execute_reply":"2021-10-29T05:16:21.662086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# store image names in list for later use\ntrain_img = sorted(os.listdir(path + '/train'))\ntrain_cleaned_img = sorted(os.listdir(path + '/train_cleaned'))\ntest_img = sorted(os.listdir(path + '/test'))","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:16:21.664643Z","iopub.execute_input":"2021-10-29T05:16:21.665059Z","iopub.status.idle":"2021-10-29T05:16:21.670601Z","shell.execute_reply.started":"2021-10-29T05:16:21.665022Z","shell.execute_reply":"2021-10-29T05:16:21.669907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare function\ndef process_image(path):\n    img = cv2.imread(path)\n    img = np.asarray(img, dtype=\"float32\")\n    img = cv2.resize(img, (540, 420))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img/255.0\n    img = np.reshape(img, (420, 540, 1))\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:16:21.672788Z","iopub.execute_input":"2021-10-29T05:16:21.673079Z","iopub.status.idle":"2021-10-29T05:16:21.680721Z","shell.execute_reply.started":"2021-10-29T05:16:21.673023Z","shell.execute_reply":"2021-10-29T05:16:21.680023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess images\ntrain = []\ntrain_cleaned = []\ntest = []\n\nfor f in sorted(os.listdir(path + 'train/')):\n    train.append(process_image(path + 'train/' + f))\n\nfor f in sorted(os.listdir(path + 'train_cleaned/')):\n    train_cleaned.append(process_image(path + 'train_cleaned/' + f))\n   \nfor f in sorted(os.listdir(path + 'test/')):\n    test.append(process_image(path + 'test/' + f))","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:16:21.682097Z","iopub.execute_input":"2021-10-29T05:16:21.682363Z","iopub.status.idle":"2021-10-29T05:16:23.962103Z","shell.execute_reply.started":"2021-10-29T05:16:21.682328Z","shell.execute_reply":"2021-10-29T05:16:23.961301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train[i][:,:,0], cmap='gray')\n    plt.title('Noise image: {}'.format(train_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')\n    plt.title('Denoised image: {}'.format(train_img[i]))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:16:23.963197Z","iopub.execute_input":"2021-10-29T05:16:23.963431Z","iopub.status.idle":"2021-10-29T05:16:24.942317Z","shell.execute_reply.started":"2021-10-29T05:16:23.963401Z","shell.execute_reply":"2021-10-29T05:16:24.941398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert list to numpy array\nX_train = np.asarray(train)\ny_train = np.asarray(train_cleaned)\nX_test = np.asarray(test)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:16:24.943393Z","iopub.execute_input":"2021-10-29T05:16:24.943676Z","iopub.status.idle":"2021-10-29T05:16:25.135158Z","shell.execute_reply.started":"2021-10-29T05:16:24.943615Z","shell.execute_reply":"2021-10-29T05:16:25.134327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_autoencoder = Sequential()\n\n# Encoder\nconv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(420,540,1), activation='relu', padding='same'))\nconv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))\nconv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n\n\n\n# Decoder\nconv_autoencoder.add(Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'))\nconv_autoencoder.add(Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'))\n\n\n# Output\nconv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same'))\n\nconv_autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:33:22.069691Z","iopub.execute_input":"2021-10-29T05:33:22.070014Z","iopub.status.idle":"2021-10-29T05:33:22.167587Z","shell.execute_reply.started":"2021-10-29T05:33:22.069977Z","shell.execute_reply":"2021-10-29T05:33:22.166922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n\nearly_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\nhistory= conv_autoencoder.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=200, batch_size=16, callbacks= [early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:36:50.160922Z","iopub.execute_input":"2021-10-29T05:36:50.161462Z","iopub.status.idle":"2021-10-29T05:39:12.954689Z","shell.execute_reply.started":"2021-10-29T05:36:50.161423Z","shell.execute_reply":"2021-10-29T05:39:12.953851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how loss & mae went down\nepoch_loss = history.history['loss']\nepoch_val_loss = history.history['val_loss']\nepoch_mae = history.history['mae']\nepoch_val_mae = history.history['val_mae']\n\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nplt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\nplt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\nplt.title('Evolution of loss on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\nplt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MAE')\nplt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MAE')\nplt.title('Evolution of MAE on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:39:12.956704Z","iopub.execute_input":"2021-10-29T05:39:12.956981Z","iopub.status.idle":"2021-10-29T05:39:13.339548Z","shell.execute_reply.started":"2021-10-29T05:39:12.956945Z","shell.execute_reply":"2021-10-29T05:39:13.33889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = conv_autoencoder.predict(X_test, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:39:13.340643Z","iopub.execute_input":"2021-10-29T05:39:13.341395Z","iopub.status.idle":"2021-10-29T05:39:14.208818Z","shell.execute_reply.started":"2021-10-29T05:39:13.341356Z","shell.execute_reply":"2021-10-29T05:39:14.207007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i][:,:,0], cmap='gray')\n    plt.title('Noisy image: {}'.format(test_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(y_pred[i][:,:,0], cmap='gray')\n    plt.title('Denoised by autoencoder: {}'.format(test_img[i]))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:39:14.214887Z","iopub.execute_input":"2021-10-29T05:39:14.215154Z","iopub.status.idle":"2021-10-29T05:40:45.997268Z","shell.execute_reply.started":"2021-10-29T05:39:14.21512Z","shell.execute_reply":"2021-10-29T05:40:45.996583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# it will take a while!\nids = []\nvals = []\nfor i, f in enumerate(test_img):\n    file = path + 'test/' + f\n    imgid = int(f[:-4])\n    img = cv2.imread(file, 0)\n    img_shape = img.shape\n    # print('Processing image: {} \\tinto size: {}'.format(f, img_shape))    # uncomment to see progress\n    preds_reshaped = cv2.resize(y_pred[i], (img_shape[1], img_shape[0]))\n\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nsubmission = pd.DataFrame({'id': ids, 'value': vals})\nsubmission.to_csv('submission.csv',index = False)\n\nprint('Results saved to submission.csv!')\n\n# quick check if length of IDs is OK\n# we should get there number 14230080\nprint('Length of IDs: {}'.format(len(ids)))","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:40:45.998467Z","iopub.execute_input":"2021-10-29T05:40:45.998822Z","iopub.status.idle":"2021-10-29T05:41:52.261499Z","shell.execute_reply.started":"2021-10-29T05:40:45.99879Z","shell.execute_reply":"2021-10-29T05:41:52.260608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check first few rows of submission\nmy_submission = pd.read_csv('submission.csv')\nmy_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T05:41:52.26284Z","iopub.execute_input":"2021-10-29T05:41:52.263561Z","iopub.status.idle":"2021-10-29T05:42:00.409705Z","shell.execute_reply.started":"2021-10-29T05:41:52.263519Z","shell.execute_reply":"2021-10-29T05:42:00.409044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}