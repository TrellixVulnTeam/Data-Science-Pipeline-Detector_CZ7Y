{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Background Removal using Fastai Unet learner\n## Purpose\nThe purpose of the notebook is to demonstrate Fastai library usage to perform background removal in images.\n\n## Methodology\nThe dataset consists of:-\n1. Train Folder: Consists of images which possess some kind of corruption such as paper wrinkles or coffee stains.\n2. Train_cleaned Folder: Consists of cleaned images\n3. Test Folder: Corrupt images that needs to be cleaned using the model for performance verification.\n"},{"metadata":{},"cell_type":"markdown","source":"# Setup\n## Library import"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nimport fastai\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.utils.mem import *\n\nfrom torchvision.models import vgg16_bn\nfrom subprocess import check_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data import"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = pathlib.Path('/kaggle/input/denoising-dirty-documents')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = check_output([\"ls\", \"../input/denoising-dirty-documents\"]).decode(\"utf8\")\nitems = items.split('\\n'); items.pop(); items","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n\nfor item in items:\n    # Will unzip the files so that you can see them..\n    print(item)\n    with zipfile.ZipFile(path/item,\"r\") as z:\n        z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs,size=4,128\narch = models.resnet34\npath_train = pathlib.Path(\"/kaggle/working/train\")\npath_train_cleaned = pathlib.Path(\"/kaggle/working/train_cleaned\")\npath_test = pathlib.Path(\"/kaggle/working/test\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"src = ImageImageList.from_folder(path_train).split_by_rand_pct(0.2, seed=42)\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(bs,size):\n    data = (src.label_from_func(lambda x: path_train_cleaned/x.name)\n           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n           .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n\n    data.c = 3\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_data(bs,size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(ds_type=DatasetType.Valid, rows=2, figsize=(9,9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"t = data.valid_ds[0][1].data\nt = torch.stack([t,t])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gram_matrix(x):\n    n,c,h,w = x.size()\n    x = x.view(n, c, -1)\n    return (x @ x.transpose(1,2))/(c*h*w)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram_matrix(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_loss = F.l1_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_m = vgg16_bn(True).features.cuda().eval()\nrequires_grad(vgg_m, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\nblocks, [vgg_m[i] for i in blocks]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FeatureLoss(nn.Module):\n    def __init__(self, m_feat, layer_ids, layer_wgts):\n        super().__init__()\n        self.m_feat = m_feat\n        self.loss_features = [self.m_feat[i] for i in layer_ids]\n        self.hooks = hook_outputs(self.loss_features, detach=False)\n        self.wgts = layer_wgts\n        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n\n    def make_features(self, x, clone=False):\n        self.m_feat(x)\n        return [(o.clone() if clone else o) for o in self.hooks.stored]\n    \n    def forward(self, input, target):\n        out_feat = self.make_features(target, clone=True)\n        in_feat = self.make_features(input)\n        self.feat_losses = [base_loss(input,target)]\n        self.feat_losses += [base_loss(f_in, f_out)*w\n                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n        return sum(self.feat_losses)\n    \n    def __del__(self): self.hooks.remove()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"wd = 1e-3\nlearn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics,\n                     blur=True, norm_type=NormType.Weight)\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model_dir  ='/kaggle/working/models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.valid_ds.items)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_fit(save_name, lrs=slice(lr), pct_start=0.9):\n    learn.fit_one_cycle(10, lrs, pct_start=pct_start)\n    learn.save(save_name)\n    learn.show_results(rows=1, imgsize=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_fit('1a', slice(lr*10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_fit('1b', slice(1e-5,lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_data(12,size*2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.data = data\nlearn.freeze()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('1b');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_fit('2a')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_fit('2b', slice(1e-6,1e-4), pct_start=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"fn = data.valid_ds.x.items[10]; fn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = open_image(fn); img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p,img_pred,b = learn.predict(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image(img, figsize=(8,5), interpolation='nearest');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(img_pred).show(figsize=(8,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = Path(\"/kaggle/working/export.pkl\")\nlearn.export(file = model_path)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}