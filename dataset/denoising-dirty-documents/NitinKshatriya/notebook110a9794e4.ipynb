{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport zipfile, cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers, callbacks\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nDATA_DIR = '../input/denoising-dirty-documents/'\npath = '/kaggle/working/'\nIMG_SIZE = (420, 540)\nBS = 12","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(DATA_DIR + 'train.zip') as zip_file:\n    zip_file.extractall(path)\n    \nwith zipfile.ZipFile(DATA_DIR + 'train_cleaned.zip') as zip_file:\n    zip_file.extractall(path)\n    \nwith zipfile.ZipFile(DATA_DIR + 'test.zip') as zip_file:\n    zip_file.extractall(path)\n\nwith zipfile.ZipFile(DATA_DIR + 'sampleSubmission.csv.zip') as zip_file:\n    zip_file.extractall(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = sorted(os.listdir(path + 'train'))\ntrain_cleaned_img = sorted(os.listdir(path + 'train_cleaned'))\ntest_img = sorted(os.listdir(path + 'test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(path, single_img=False):\n    img = cv2.imread(path)\n    if single_img:\n        img = cv2.resize(img, IMG_SIZE)\n    else:\n        img = cv2.resize(img, IMG_SIZE[::-1])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img / 255.0\n    img = np.reshape(img, (*IMG_SIZE, 1))\n    return img\n\nimg = preprocess_image(os.path.join(path, 'train', '2.png'))\nplt.imshow(img.squeeze(axis=2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = []\ntrain_cleaned = []\ntest = []\n\nfor f in train_img:\n    train.append(preprocess_image(os.path.join(path, 'train', f)))\n    \nfor f in train_cleaned_img:\n    train_cleaned.append(preprocess_image(os.path.join(path, 'train_cleaned', f)))\n    \nfor f in test_img:\n    test.append(preprocess_image(os.path.join(path, 'test', f)))\n    \ntrain = np.asarray(train)\ntrain_cleaned = np.asarray(train_cleaned)\ntest = np.asarray(test)\n\ntrain.shape, train_cleaned.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Image Augmentation is skipped for now so as to get base model fast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DenoiseModel(Model):\n    def __init__(self):\n        super(DenoiseModel, self).__init__()\n        self.encoder = tf.keras.Sequential([\n            layers.Input(shape=(*IMG_SIZE, 1)), \n            layers.Conv2D(48, (3, 3), activation='relu', padding='same'),\n            layers.Conv2D(72, (3, 3), activation='relu', padding='same'),\n            layers.Conv2D(144, (3, 3), activation='relu', padding='same'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D((2, 2), padding='same'),\n            layers.Dropout(0.5),\n        ])\n        \n        self.decoder = tf.keras.Sequential([\n            layers.Conv2D(144, (3, 3), activation='relu', padding='same'),\n            layers.Conv2D(72, (3, 3), activation='relu', padding='same'),\n            layers.Conv2D(48, (3, 3), activation='relu', padding='same'),\n            layers.BatchNormalization(),\n            layers.UpSampling2D((2, 2)),\n            layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n        ])\n        \n    def call(self, x):\n        encoder = self.encoder(x)\n        decoder = self.decoder(encoder)\n        return decoder\n    \nautoencoder = DenoiseModel()\nautoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = callbacks.EarlyStopping(monitor='loss', patience=30, verbose=1, restore_best_weights=True)\nhistory = autoencoder.fit(\n    train, train_cleaned,\n    shuffle=True,\n    callbacks=[es],\n    epochs=200,\n    batch_size=BS\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = preprocess_image(os.path.join(path, 'test', '1.png'))\nplt.imshow(temp.squeeze(axis=2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_out = autoencoder.predict(np.expand_dims(temp, axis=0))\ntemp_out = temp_out.squeeze(axis=0).squeeze(axis=2)\nplt.imshow(temp_out)\n# print(temp_out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = []\nvals = []\nfor i, f in tqdm(enumerate(test_img)):\n    file = path + 'test/' + f\n    imgid = int(f[:-4])\n    img = cv2.imread(file, 0)\n    img_shape = img.shape\n    decoded_img = np.squeeze(autoencoder.decoder(autoencoder.encoder(test[i:i+1]).numpy()).numpy())\n    preds_reshaped = cv2.resize(decoded_img, (img_shape[1], img_shape[0]))\n\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nprint('Length of IDs: {}'.format(len(ids)))            \npd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv',index=False)\nprint('Results saved to submission.csv!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}