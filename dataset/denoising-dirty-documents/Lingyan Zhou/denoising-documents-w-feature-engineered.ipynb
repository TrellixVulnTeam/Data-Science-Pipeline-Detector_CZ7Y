{"cells":[{"metadata":{"_uuid":"3bb1eac519df0ac301f6ca4119a3672f9104e8a4"},"cell_type":"markdown","source":"# Feature Engineered\n * vertial marginal distribution in approximity\n * Morph Gradient"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np \nimport scipy as sp \nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport glob \nimport cv2\nimport sklearn\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nimport tensorflow as tf\n\ntrain_imgs = glob.glob(\"../input/train/*.png\")\ntrain_imgs.sort()\ntrain_cleaned_imgs = glob.glob(\"../input/train_cleaned/*.png\")\ntrain_cleaned_imgs.sort()\ntest_imgs= glob.glob(\"../input/test/*.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4efa201ff8fc6183db2d51d9bcf70297b939265","collapsed":true},"cell_type":"code","source":"def total_batches(files):\n    total = 0\n    for f in files:\n        total += cv2.imread(f, cv2.IMREAD_GRAYSCALE).shape[0]\n    return total\ntotal_ttrain_pixels = total_batches(train_imgs)\ntotal_test_pixels = total_batches(test_imgs)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"PATCH_WIDTH_HALF = 4\nPATCH_WIDTH = PATCH_WIDTH_HALF * 2 + 1\n\ndef train_patch_generator(train_imgs, train_cleaned_imgs, augments=5, epochs = 5):\n    for _ in range(epochs):\n        for train_file, train_cleaned_file in zip(train_imgs, train_cleaned_imgs):\n            train_img = cv2.imread(train_file, cv2.IMREAD_GRAYSCALE)\n            train_cleaned_img = cv2.imread(train_cleaned_file, cv2.IMREAD_GRAYSCALE)\n            train_cleaned_img = cv2.threshold(train_cleaned_img, 200, 255,cv2.THRESH_BINARY)[1]\n            train_img_ext = cv2.copyMakeBorder(train_img, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, cv2.BORDER_REPLICATE)\n            mean_vert_ext = np.mean(train_img_ext, axis=1)\n            #thresholded_img_ext = cv2.adaptiveThreshold(train_img_ext,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n            #                             cv2.THRESH_BINARY,31,30) \n            morph_grad_ext = cv2.morphologyEx(train_img_ext, cv2.MORPH_GRADIENT, np.ones((5,5),np.uint8))\n            for i in range(train_img.shape[0]):\n                patches = []\n                labels = []\n                weights = []\n                vert_margins = []\n                features = []\n                for j in range(train_img.shape[1]):\n                    label = train_cleaned_img[i][j]\n                    patch_c1 = train_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255.\n                    vert_margin = mean_vert_ext[i:i+PATCH_WIDTH].astype(np.float32)/255.\n                    #patches.append(np.expand_dims(patch_c1, axis=2))\n                    weight = morph_grad_ext[i+PATCH_WIDTH_HALF, j+PATCH_WIDTH_HALF]/255.*0.5+0.5\n                    vert_margins.append(vert_margin)\n                    #patches.append(np.stack((patch_c1, patch_c2), axis=2))\n                    patches.append(np.expand_dims(patch_c1, axis=2))\n                    labels.append(label / 255.)\n                    weights.append(weight)\n                    for _ in range(augments):\n                        #patches.append(np.expand_dims(patch_c1, axis=2))\n                        vert_margins.append(vert_margin)\n                        #patches.append(np.stack((patch_c1, patch_c2), axis=2))\n                        patches.append(np.expand_dims(patch_c1+np.random.normal(scale=0.2, size=patch_c1.shape), axis=2))\n                        labels.append(label / 255.)\n                        weights.append(weight)\n                patches = np.array(patches)# patches.shape\n                vert_margins = np.array(vert_margins) # \n                labels = np.array(labels) # labels.shape\n                weights = np.array(weights) #\n                yield ([patches , vert_margins], labels, weights)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff08cdae11a7248ab280d7aec5b125b69072a319","collapsed":true},"cell_type":"code","source":"x1 = tf.keras.layers.Input(name='patch', shape=(PATCH_WIDTH, PATCH_WIDTH, 1))\ndr1 = tf.keras.layers.Dropout(rate=0.1)(x1)\ncv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(dr1)\nmp1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(cv1)\nf1 = tf.keras.layers.Flatten()(mp1)\nx2 = tf.keras.layers.Input(name='vert_margin', shape=(PATCH_WIDTH,))\ncc = tf.keras.layers.concatenate([f1, x2])\nd1 = tf.keras.layers.Dense(1024, activation='relu')(cc)\nd2 = tf.keras.layers.Dense(512, activation='relu')(d1)\nd3 = tf.keras.layers.Dense(256, activation='relu')(d2)\ndr2 = tf.keras.layers.Dropout(rate=0.5)(d3)\nout = tf.keras.layers.Dense(1, activation='sigmoid')(dr2)\n\nmodel = tf.keras.models.Model(inputs=[x1,x2], outputs=out)\nmodel.compile(loss=tf.keras.losses.binary_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n              metrics=['mse'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d6cf3fc7d9f977c16d883abc32b8f1599d076ea","scrolled":true,"collapsed":true},"cell_type":"code","source":"EPOCHS=2\nAUGMENTS = 2\nmodel.fit_generator(train_patch_generator(train_imgs, train_cleaned_imgs, AUGMENTS, EPOCHS), epochs=EPOCHS, steps_per_epoch=total_batches(train_imgs), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7411329c28f09a1ca06598dca5d51e103529f2e","collapsed":true},"cell_type":"code","source":"def test_patch_generator(test_imgs):\n    for test_file in test_imgs:\n        test_img = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n        test_img_ext = cv2.copyMakeBorder(test_img, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, PATCH_WIDTH_HALF, cv2.BORDER_REPLICATE)\n        mean_vert_ext = np.mean(test_img_ext, axis=1)\n        #thresholded_img_ext = cv2.adaptiveThreshold(test_img_ext,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n        #                                            cv2.THRESH_BINARY,31,30) \n        #eroded_img_ext = cv2.erode(train_img_ext, np.ones((3,3),np.uint8), 1)\n        #eroded_thresh_ext = cv2.erode(thresholded_img_ext, np.ones((3,3),np.uint8), 1)\n        for i in range(test_img.shape[0]):\n            patches = []\n            vert_margins = []\n            for j in range(test_img.shape[1]):\n                patch_c1 = test_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32) / 255.\n                vert_margin = mean_vert_ext[i:i+PATCH_WIDTH].astype(np.float32)/255.\n                #patch_c3 = eroded_img_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255..\n                #patch_c4 = eroded_thresh_ext[i:i+PATCH_WIDTH, j:j+PATCH_WIDTH].astype(np.float32)/255..\n                patches.append(np.expand_dims(patch_c1, axis=2))\n                #patches.append(np.stack((patch_c1, patch_c2), axis=2))\n                vert_margins.append(vert_margin)\n            patches = np.array(patches)\n            vert_margins = np.array(vert_margins)\n            yield [patches, vert_margins]\n\ndef test_patch_id_generator(test_imgs):\n    pids = []\n    for test_file in test_imgs:\n        id = test_file.replace('../input/test/', '').replace('.png', '')\n        test_img = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n        for i in range(test_img.shape[0]):\n            for j in range(test_img.shape[1]):\n                pids.append(id + '_' + str(i+1) + '_' + str(j+1)) \n    yield pids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5618336a1c981746aa907a10e1c0678e74992b13","scrolled":false,"collapsed":true},"cell_type":"code","source":"for idx in [8]:\n    img = cv2.imread(train_imgs[idx], cv2.IMREAD_GRAYSCALE)\n    cleaned_img = cv2.imread(train_cleaned_imgs[idx], cv2.IMREAD_GRAYSCALE)\n    th_mask = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n                                                    cv2.THRESH_BINARY,31,30) \n    predicted_mask = model.predict_generator(\n        generator=test_patch_generator([train_imgs[idx]]),\n        steps=total_batches([train_cleaned_imgs[idx]])).reshape(img.shape).clip(0, 1).round().astype(np.uint8)\n    background = np.full(img.shape, 255, dtype=np.uint8)\n    predicted = cv2.bitwise_or(img, 0, dst=background, mask=(1-predicted_mask))\n    plt.figure(figsize=(60,30))\n    plt.subplot(2,2,1)\n    plt.imshow(img, 'gray');\n    plt.title('Uncleaned')\n    plt.subplot(2,2,2)\n    plt.imshow(cleaned_img, 'gray');\n    plt.title('Manually Cleaned')\n    plt.subplot(2,2,3)\n    plt.imshow(predicted, 'gray');\n    plt.title('Auto Cleaned')\n    plt.subplot(2,2,4)\n    plt.imshow(cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,31,30), 'gray');\n    plt.title('Adaptive Threshold Cleaned')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f044e00b41fa36d1c7d0df5f7793e11dc7e76f14","collapsed":true},"cell_type":"code","source":"for i, f in enumerate(test_imgs):\n    img = cv2.imread(f, cv2.IMREAD_GRAYSCALE) \n    predicted_mask = model.predict_generator(\n        generator=test_patch_generator([f]),\n        steps=img.shape[0]).reshape(img.shape).clip(0, 1).round().astype(np.uint8)\n    background = np.full(img.shape, 255, dtype=np.uint8)\n    predicted = cv2.bitwise_or(img, 0, dst=background, mask=(1-predicted_mask))\n    predicted = predicted/255.\n    df = pd.DataFrame({'id': [], 'value': []})\n    df['id'] = next(test_patch_id_generator([f]))\n    df['value'] = predicted.flatten()\n    if i == 0:\n        df.to_csv('submission.csv', header=True, index=False)\n    else:\n        df.to_csv('submission.csv', header=False, mode='a', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}