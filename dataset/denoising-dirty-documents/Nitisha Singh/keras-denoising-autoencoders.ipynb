{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#extracting all zipped files\n\nimport zipfile\n\nwith zipfile.ZipFile(\"/kaggle/input/denoising-dirty-documents/train.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"/kaggle/input/denoising-dirty-documents/test.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"/kaggle/input/denoising-dirty-documents/train_cleaned.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"/kaggle/input/denoising-dirty-documents/sampleSubmission.csv.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_path = './train'\ntrain_cleaned_path = './train_cleaned'\ntest_images_path  = './test'\n\ntrain_images = sorted(os.listdir(train_images_path))\ntrain_cleaned = sorted(os.listdir(train_cleaned_path))\ntest_images = sorted(os.listdir(test_images_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nsamples = train_images[:4] + train_cleaned[:4]\n\nf, ax = plt.subplots(2, 4, figsize=(20,10))\nfor i, img in enumerate(samples):\n    img = mpimg.imread(os.path.join(train_images_path, img))\n    ax[i//4, i%4].imshow(img, cmap='gray')\n    ax[i//4, i%4].axis('off')\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data into X and y arrays\nfrom keras.preprocessing.image import load_img, img_to_array\nX = []\ny = []\n\nfor img in train_images:\n    img_path = os.path.join(train_images_path, img)\n    im = load_img(img_path, color_mode = 'grayscale', target_size = (540, 260))\n    im = img_to_array(im).astype('float32')/255\n    X.append(im)\nfor img in train_cleaned:\n    img_path = os.path.join(train_cleaned_path, img)\n    im = load_img(img_path, color_mode = 'grayscale', target_size = (540, 260))\n    im = img_to_array(im).astype('float32')/255\n    y.append(im)\n    \nX = np.array(X)\ny = np.array(y)\n\nprint('Shape of X: ', X.shape)\nprint('Shape of y: ', y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split dataset into training and validation\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state = 42)\n\nprint('Number of training examples, ', X_train.shape[0])\nprint('Number of validation examples, ', X_valid.shape[0])\nprint(y_train.shape)\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import Input\n# create autoencoder model\ndef autoencoder():\n    '''function to return an autoencoder model'''\n    input_img = Input(shape=(540, 260, 1))\n    #encoder\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Conv_1')(input_img)\n    x = MaxPooling2D((2, 2), padding='same', name = 'MaxPool_1')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Conv_2')(x)\n    encoded = MaxPooling2D((2, 2), padding='same', name = 'MaxPool_2')(x)\n    #decoder\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Conv_3')(encoded)\n    x = UpSampling2D((2, 2), name = 'UpSample_1')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Conv_4')(x)\n    x = UpSampling2D((2, 2), name = 'UpSample_2')(x)\n    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n    autoencoder = Model(input_img, decoded)\n    autoencoder.compile(optimizer='adamax', loss='binary_crossentropy')\n    return autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get model\nautoencoder_model = autoencoder()\nautoencoder_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(autoencoder_model, to_file='autoencoder_model.png', show_layer_names = True,show_shapes = True, dpi = 96)\nimg = mpimg.imread('autoencoder_model.png')\nplt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(img, interpolation = 'nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#callbacks\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nes = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='min', restore_best_weights=True)\nrlr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit model\nhistory = autoencoder_model.fit(X_train, y_train, epochs = 200, batch_size = 8, validation_data = (X_valid, y_valid), verbose = True, callbacks = [es,rlr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss(history, x = 'loss', y = 'val_loss'):\n    '''function to plot training and validation error'''\n    fig, ax = plt.subplots( figsize=(20,10))\n    ax.plot(history.history[x])\n    ax.plot(history.history[y])\n    plt.title('Model Loss')\n    plt.ylabel(y)\n    plt.xlabel(x)\n    plt.legend(['Train', 'Val'], loc='upper left')\n    ax.grid(color='black')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#viewing a sample from the test set and it's prediction\nsample_test = load_img(os.path.join(test_images_path, test_images[7]), color_mode = 'grayscale', target_size=(540, 260))\nsample_test = img_to_array(sample_test)\nsample_test_img = sample_test.astype('float32')/255.\nsample_test_img = np.expand_dims(sample_test, axis=0)\n\n# Get the predition\npredicted_label = np.squeeze(autoencoder_model.predict(sample_test_img))\n\nf, ax = plt.subplots(1,2, figsize=(10,10))\nax[0].imshow(np.squeeze(sample_test), cmap='gray')\nax[1].imshow(np.squeeze(predicted_label.astype('int8')), cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = []\nfor img in test_images:\n    img_path = os.path.join(test_images_path, img)\n    im = load_img(img_path, color_mode = 'grayscale', target_size = (540, 260))\n    im = img_to_array(im).astype('float32')/255\n    X_test.append(im)\n    \nX_test = np.array(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = autoencoder_model.predict(X_test)\nprint(preds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfor img in preds:\n    img = cv2.resize(img, (540, 258))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nTEST_IMAGES = glob.glob('./test/*.png')\nids = []\nvals = []\nfor i, f in enumerate(TEST_IMAGES):\n    file = os.path.basename(f)\n    imgid = int(file[:-4])\n    test_img = cv2.imread(f, 0)\n    img_shape = test_img.shape\n    preds_reshaped = cv2.resize(preds[i], (img_shape[1], img_shape[0]))\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\npd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}