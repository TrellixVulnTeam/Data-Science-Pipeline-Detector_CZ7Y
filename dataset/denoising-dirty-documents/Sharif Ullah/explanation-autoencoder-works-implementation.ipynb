{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\n\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Why   this  kernel  ?******"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/sabihaprova/oka.png\")\nfrom IPython.display import Image\nImage(\"../input/provathebeauty/ok.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PROBLEM SATEMENT:**\n> suppose you are given a dirty document(like above image)/noisy image, you have to make a clean document/image, so how will you do that?\n\n**SOLUTION**\n> you can use** AutoEncoder** to solve this problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/provathebeauty/okkk.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> \n\n> 1. **An auto encoder is neural network consisting of hidden layer and it has two part encoder and decoder**\n> > 2. **It is simply like an identity function like f(x)=x where it makes same size output as like as imput by removing noise**"},{"metadata":{},"cell_type":"markdown","source":"**How denosing Auto Encoder works\n?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/provathebeauty/o.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Quick explanation**:\n\n>       Lets suppose:\n                  x=  input\n                  y=  hidden layer output\n                  z=  output of autoencoder\n                  L=  Loss function\n                  so, it first set missing  some  nodes in input layers. then forwarded to hidden layer then hidden layer output goes to loss function. then by calculation loss function ,backpropagate and update weights.then by using weights it approximate the output"},{"metadata":{},"cell_type":"markdown","source":"**Question:**\n\n>           what is the difference between dropout and autoencoder as both of them set off the nodes? \n\n**Answer:**\n\n>          Main difference is in dropout(regularization technique for reducing overfitting)use dropout(set off) nodes            in every layer in neural network,where autoencoder set off some nodes in only in input layer\n           "},{"metadata":{},"cell_type":"markdown","source":"**How   to  implement  Denosing  Auto  Encoder?**\n\n>          we know that in CNN, frist few layers are used for feature extraction like: finding shape of object, edge detection. and after convolution layer we used pooling layer. so by using these layer we extract just features by removing the redundant information.and these feature represent the input object. so here we just find compact representation of this input object. this is like encoding.\n\n>        so in the Next layers we just perform the reverse operation of pooling .this reverse pooling is called Upsampling. this is called decodidng.\n\n>  so Denosing Auto encoder consist of Two part like:\n                                1. Encoder\n                                2. Decoder.\n                                \n                                \n> Implementation in keras is given below:\n\n>     def autoencoder(input_img):\n>     #encoder\n>     #input = 28 x 28 x 1 (wide and thin)\n>     conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n>     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n>     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n>     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n>     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n> \n>     #decoder\n>     conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n>     up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n>     conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n>     up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n>     decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n>     return decoded\n                                \n                                \n                                \n\n"},{"metadata":{},"cell_type":"markdown","source":"**Source**:\n      *Medical image denosing using convolutional denosing encoder by Lovedeep Gondara*"},{"metadata":{},"cell_type":"markdown","source":"**Now  solve the Denosing Dirty Document problem:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets define a function for rading train and test images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install python-resize-image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread('../input/denoising-dirty-documents/test/1.png', 0)\nplt.imshow(img,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom resizeimage import resizeimage\n\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        if filename == \"train\":\n            continue\n        if filename == \"test\":\n            continue\n        if filename == \"train_cleaned\":\n            continue\n        img = cv2.imread(os.path.join(folder,filename))\n        img = np.array(img)\n        s = img.shape\n        s = np.array(s)\n        if  s[0] == 258:\n            img1 = Image.open(os.path.join(folder,filename))\n            new1 = resizeimage.resize_contain(img1, [540, 420, 3])\n            new1 = np.array(new1, dtype='uint8')\n            images.append(new1)\n        else:\n            img1 = Image.open(os.path.join(folder,filename))\n            images.append(img)\n    return images\n\ntrain = load_images_from_folder(\"../input/denoising-dirty-documents/train\")\ntest = load_images_from_folder(\"../input/denoising-dirty-documents/test\")\ntrain_cleaned = load_images_from_folder(\"../input/denoising-dirty-documents/train_cleaned\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#now convert these image list into array and then convert values in range o-1\ntrain = np.array(train)\ntest = np.array(test)\ntrain_cleaned = np.array(train_cleaned)\n\ntrain = train.astype('float32') / 255\ntest = test.astype('float32') / 255\ntrain_cleaned = train_cleaned.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding\nfrom keras.layers import SpatialDropout1D, Conv2D, MaxPooling2D, UpSampling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(420, 540, 3,))) \nmodel.add(MaxPooling2D((2, 2), padding='same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D((2, 2), padding='same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n\nmodel.summary() \n\nmodel.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train, train_cleaned, epochs=100, batch_size=52, shuffle=True, validation_data=(train, train_cleaned))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array=np.array(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in array:\n    plt.show()\n    plt.imshow(img,cmap='gray')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}