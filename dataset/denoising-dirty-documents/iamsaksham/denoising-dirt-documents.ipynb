{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport cv2\nfrom matplotlib import pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_path = glob.glob(\"/kaggle/input/denoising-dirty-documents/train/*.png\")\ny_train_path = glob.glob(\"/kaggle/input/denoising-dirty-documents/train_cleaned/*.png\")\nX_test_path = glob.glob(\"/kaggle/input/denoising-dirty-documents/test/*.png\")\n\ninput_shape = (258, 540, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img = cv2.imread(X_train_path[0], cv2.IMREAD_GRAYSCALE)\n# plt.imshow(img)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(path):\n    image_list = []\n    for pth in path:\n        img = cv2.imread(pth, 0) # read grayscale image\n        img = cv2.resize(img, (input_shape[1], input_shape[0]))\n        img = img / 255.\n        img = np.expand_dims(img, axis=-1)\n        image_list.append(img)\n    return image_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X_train_all = load_images(X_train_path)\ny_train_all = load_images(y_train_path)\nX_test = load_images(X_test_path)\n\n# convert list of images to np array\nX_train_all = np.array(X_train_all)\ny_train_all = np.array(y_train_all)\nX_test = np.array(X_test)\n\nprint(X_train_all.shape)\nprint(y_train_all.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(X_train_all[0].shape)\n# plt.imshow(X_train_all[44])\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train val split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.3, random_state=0)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\ntf.keras.backend.clear_session()  # For easy reset of notebook state.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\n\n# add convolutional layer to the model with relu activation\n# 32 convolution filters used each of size 3x3\nmodel.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\nmodel.add(layers.MaxPooling2D(2, padding='same'))\nmodel.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(layers.UpSampling2D((2,2)))\nmodel.add(layers.Conv2D(1, (3,3), activation='sigmoid', padding='same'))\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mean_squared_error',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 100\n# batch size -Total number of training examples present in a single batch.\nbatch_size = 8\nhistory = model.fit(X_train, y_train, epochs=num_epochs,\n                    batch_size=batch_size, \n                    verbose=1,\n                    validation_data=(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose=0)\nprint('Test loss:', score[0]) #Test loss: 0.0296396646054\nprint('Test accuracy:', score[1]) #Test accuracy: 0.9904\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_0 = final_predictions[10] * 255.0\npreds_0 = preds_0.reshape(258, 540)\nx_test_0 = X_test[10] * 255.0\nx_test_0 = x_test_0.reshape(258, 540)\nplt.imshow(x_test_0, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(preds_0, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions = final_predictions.reshape(-1, 258, 540)\n\nids = []\nvals = []\nfor i, f in enumerate(X_test_path):\n    file = os.path.basename(f)\n    imgid = int(file[:-4])\n    test_img = cv2.imread(f, 0)\n    img_shape = test_img.shape\n    print('processing: {}'.format(imgid))\n    print(img_shape)\n    preds_reshaped = cv2.resize(final_predictions[i], (img_shape[1], img_shape[0]))\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nprint('Writing to csv file')\npd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}