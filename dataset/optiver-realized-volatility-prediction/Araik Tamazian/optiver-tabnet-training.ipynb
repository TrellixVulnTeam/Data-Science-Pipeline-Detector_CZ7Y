{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:15:38.178626Z","iopub.execute_input":"2021-06-29T20:15:38.179243Z","iopub.status.idle":"2021-06-29T20:15:46.005266Z","shell.execute_reply.started":"2021-06-29T20:15:38.179164Z","shell.execute_reply":"2021-06-29T20:15:46.004259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom glob import glob\nfrom joblib import Parallel, delayed\nfrom sklearn.model_selection import KFold, train_test_split\nfrom pytorch_tabnet.metrics import Metric\nfrom pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T20:25:27.218166Z","iopub.execute_input":"2021-06-29T20:25:27.218506Z","iopub.status.idle":"2021-06-29T20:25:27.224122Z","shell.execute_reply.started":"2021-06-29T20:25:27.218461Z","shell.execute_reply":"2021-06-29T20:25:27.223178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/optiver-realized-volatility-prediction'\nSEED = 42\nMAX_EPOCH=1","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:15:47.970557Z","iopub.execute_input":"2021-06-29T20:15:47.970842Z","iopub.status.idle":"2021-06-29T20:15:47.97515Z","shell.execute_reply.started":"2021-06-29T20:15:47.970816Z","shell.execute_reply":"2021-06-29T20:15:47.974219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"book_testparquet = pd.read_parquet(\"../input/optiver-realized-volatility-prediction/book_test.parquet/stock_id=0\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:15:47.976857Z","iopub.execute_input":"2021-06-29T20:15:47.977214Z","iopub.status.idle":"2021-06-29T20:15:48.088787Z","shell.execute_reply.started":"2021-06-29T20:15:47.97718Z","shell.execute_reply":"2021-06-29T20:15:48.088039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:15:48.090002Z","iopub.execute_input":"2021-06-29T20:15:48.090322Z","iopub.status.idle":"2021-06-29T20:15:48.096373Z","shell.execute_reply.started":"2021-06-29T20:15:48.090288Z","shell.execute_reply":"2021-06-29T20:15:48.095474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stock_stat(stock_id : int, dataType = 'train'):\n    \n    book_train_subset = pd.read_parquet(os.path.join(ROOT_DIR, f'book_{dataType}.parquet/stock_id={stock_id}/'))\n    book_train_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    book_train_subset['bas'] = (book_train_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n                                / book_train_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n                                - 1)                               \n\n    \n    book_train_subset['wap'] = (book_train_subset['bid_price1'] * book_train_subset['ask_size1'] +\n                            book_train_subset['ask_price1'] * book_train_subset['bid_size1']) / (\n                            book_train_subset['bid_size1']+ book_train_subset['ask_size1'])\n\n    book_train_subset['log_return'] = (book_train_subset.groupby(by = ['time_id'])['wap'].\n                                       apply(log_return).\n                                       reset_index(drop = True).\n                                       fillna(0)\n                                      )\n    \n    stock_stat = pd.merge(\n        book_train_subset.groupby(by = ['time_id'])['log_return'].agg(realized_volatility).reset_index(),\n        book_train_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    stock_stat['stock_id'] = stock_id\n    \n    return stock_stat\n\ndef get_dataset(stock_ids : list, dataType = 'train'):\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n\n    return stock_stat_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:15:48.097759Z","iopub.execute_input":"2021-06-29T20:15:48.098103Z","iopub.status.idle":"2021-06-29T20:15:48.108215Z","shell.execute_reply.started":"2021-06-29T20:15:48.098068Z","shell.execute_reply":"2021-06-29T20:15:48.107504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(ROOT_DIR, 'train.csv'))\ntest = pd.read_csv(os.path.join(ROOT_DIR, 'test.csv'))\n\ntrain_stock_stat_df = get_dataset(stock_ids = train['stock_id'].unique(), dataType = 'train')\ntrain_dataset = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:15:48.109523Z","iopub.execute_input":"2021-06-29T20:15:48.11Z","iopub.status.idle":"2021-06-29T20:19:52.218963Z","shell.execute_reply.started":"2021-06-29T20:15:48.109964Z","shell.execute_reply":"2021-06-29T20:19:52.217835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_dataset['target'].values.reshape(-1,1)\nX = train_dataset.drop(['stock_id', 'time_id', 'target'], axis = 1)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42)\nX_train = X_train.values#reset_index(drop=True)\nX_valid = X_valid.values#reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:19:52.220565Z","iopub.execute_input":"2021-06-29T20:19:52.220927Z","iopub.status.idle":"2021-06-29T20:19:52.253674Z","shell.execute_reply.started":"2021-06-29T20:19:52.220883Z","shell.execute_reply":"2021-06-29T20:19:52.252911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmspe(y_true, y_pred):\n    '''\n    Compute Root Mean Square Percentage Error between two arrays.\n    '''\n    \n    if (y_true == 0).any():\n        raise ValueError(\"Root Mean Square Percentage Error cannot be used when \"\n                         \"targets contain zero values.\")\n        \n    loss = np.sqrt(np.mean(np.square(((y_true - y_pred) / y_true)), axis=0)).item()\n\n    return loss\n\nclass RMSPE(Metric):\n    def __init__(self):\n        self._name = \"rmspe\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_score):\n        return rmspe(y_true, y_score)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:25:55.187951Z","iopub.execute_input":"2021-06-29T20:25:55.18835Z","iopub.status.idle":"2021-06-29T20:25:55.197145Z","shell.execute_reply.started":"2021-06-29T20:25:55.188316Z","shell.execute_reply":"2021-06-29T20:25:55.196309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tabnet_params = dict(\n    n_d = 32,\n    n_a = 32,\n    n_steps = 1,\n    gamma = 1.3,\n    lambda_sparse = 0,\n    optimizer_fn = optim.Adam,\n    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n    mask_type = \"entmax\",\n    scheduler_params = dict(\n        mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n    scheduler_fn = ReduceLROnPlateau,\n    seed = SEED,\n    verbose = 10\n)\n\nclf = TabNetRegressor(**tabnet_params)\nclf.fit(\n    X_train, y_train,\n    eval_set=[(X_valid, y_valid)],\n    eval_name = [\"val\"],\n    eval_metric=[RMSPE],\n    max_epochs = MAX_EPOCH,\n    patience = 20,\n    batch_size = 1024, \n    virtual_batch_size = 32,\n    num_workers = 4,\n    drop_last = False,\n)\n\nclf.save_model('optiver_tabnet_model')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T20:25:55.19878Z","iopub.execute_input":"2021-06-29T20:25:55.199238Z","iopub.status.idle":"2021-06-29T20:25:55.541772Z","shell.execute_reply.started":"2021-06-29T20:25:55.199203Z","shell.execute_reply":"2021-06-29T20:25:55.539487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r optiver_tabnet_model.zip /kaggle/working/ --exclude *.ipynb","metadata":{},"execution_count":null,"outputs":[]}]}