{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Optimal variable extraction: 12X TIMES FASTER !\n\n**August 2021**\n\n**If you use parts of this notebook in your scripts/notebooks, giving  some kind of credit would be very much appreciated :)  You can for instance link back to this `notebook`, and `upvote it`. Thanks!**\n\n\n\nIn this notebook, I implement my numpy's version of `realized_volatility_per_time_id` function, a crucial function for prediction, using only `numpy` array. My implemtation shows great performance as It performs 12 times faster than original Optiver's pandas implementation.\n\n**Results of the numpy implementation is showed below at the end.**","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nimport numpy as np\nimport plotly.express as px\nwarnings.filterwarnings('ignore')\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T20:51:48.471646Z","iopub.execute_input":"2021-09-09T20:51:48.47202Z","iopub.status.idle":"2021-09-09T20:51:48.634022Z","shell.execute_reply.started":"2021-09-09T20:51:48.471989Z","shell.execute_reply":"2021-09-09T20:51:48.633287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_order_book_file_train = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:51:48.6352Z","iopub.execute_input":"2021-09-09T20:51:48.63559Z","iopub.status.idle":"2021-09-09T20:51:48.641407Z","shell.execute_reply.started":"2021-09-09T20:51:48.635549Z","shell.execute_reply":"2021-09-09T20:51:48.640289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_id_unique = np.unique(list_order_book_file_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:51:48.643195Z","iopub.execute_input":"2021-09-09T20:51:48.643468Z","iopub.status.idle":"2021-09-09T20:51:48.652972Z","shell.execute_reply.started":"2021-09-09T20:51:48.643442Z","shell.execute_reply":"2021-09-09T20:51:48.651907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas function ( original implementation of the tutorial notebook )","metadata":{}},{"cell_type":"code","source":"def log_return(wap):\n    return np.log(wap).diff()\n\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef wap_1(df):\n    df['wap1'] =(df['bid_price1'] * df['ask_size1']+df['ask_price1'] * df['bid_size1'])  / (\n                              df['bid_size1']+ df['ask_size1'])\n    return df['wap1']\ndef wap_2(df):\n    df['wap2'] =(df['bid_price2'] * df['ask_size2']+df['ask_price2'] * df['bid_size2'])  / (\n                              df['bid_size2']+ df['ask_size2'])\n    return df['wap2'] \n\n\ndef wap_logreturn(df,index):\n    df['log_return{}'.format(index)] = df.groupby(['time_id'])['wap{}'.format(index)].apply(log_return)\n    df = df[~df['log_return{}'.format(index)].isnull()]\n    \n    ## Compute the realized volatility of the stock per time id \n    df_realized_vol_per_stock =  pd.DataFrame(df.groupby(['time_id'])['log_return{}'.format(index)].agg(realized_volatility)).reset_index()\n\n    return df_realized_vol_per_stock['log_return{}'.format(index)]\n\n\n\ndef realized_volatility_per_time_id(file_path):\n    df = pd.read_parquet(file_path)\n    df_realized_vol_per_stock = pd.DataFrame()\n\n\n    ## Calculate WAP\n    df['wap1'] = wap_1(df)\n    df['wap2'] = wap_2(df)\n    \n    ## Apply log return after grouping by id ( 5 then 6 then 7 ..... ) in order to apply the log return lag correctly\n    df_realized_vol_per_stock['rv1'] = wap_logreturn(df,1)\n    df_realized_vol_per_stock['rv2'] = wap_logreturn(df,2)\n    df_realized_vol_per_stock['time_id'] =  np.unique(np.array(df)[:,0]).flatten().astype(int)\n\n\n    ## Extract the stock index / indice\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id','rv1','rv2']]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:51:48.655396Z","iopub.execute_input":"2021-09-09T20:51:48.656202Z","iopub.status.idle":"2021-09-09T20:51:48.672227Z","shell.execute_reply.started":"2021-09-09T20:51:48.656152Z","shell.execute_reply":"2021-09-09T20:51:48.671468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time p = realized_volatility_per_time_id(list_order_book_file_train[0])\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:51:48.673815Z","iopub.execute_input":"2021-09-09T20:51:48.674686Z","iopub.status.idle":"2021-09-09T20:51:54.689129Z","shell.execute_reply.started":"2021-09-09T20:51:48.674643Z","shell.execute_reply":"2021-09-09T20:51:54.68797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numpy Implementation ","metadata":{}},{"cell_type":"code","source":"## I use this package to exploit the groupby function under numpy\n!pip3 install numpy_indexed\nimport numpy_indexed as npi\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:51:54.690821Z","iopub.execute_input":"2021-09-09T20:51:54.691246Z","iopub.status.idle":"2021-09-09T20:52:01.664634Z","shell.execute_reply.started":"2021-09-09T20:51:54.691203Z","shell.execute_reply":"2021-09-09T20:52:01.663415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I re-implement the computation of log return as well as realized volatility because it seems that aggregation and applied function on groupby data slowed down the execution of the process.\n- The function is pretty simple, I took advantage of list and numpy array to extract the realized volatility using the `wap_logreturn_numpy` function.\n    - `index` argument was used to select the respective wap for each of `wap1` and `wap2`.\n    \n","metadata":{}},{"cell_type":"code","source":"def wap_logreturn_numpy(df,index):\n    np_df = np.array(df).astype(np.float32)\n    np_df_unique_id = np.unique(np_df[:,0]).reshape(-1,1)\n    #rv = np.array([])\n\n    wap_grouby_timeid_flatten = npi.group_by(np_df[:, 0]).split(np_df[:, -2 + index]) \n    for i in range(len(wap_grouby_timeid_flatten)):\n        wap_grouby_timeid_flatten[i] = np.diff(np.log(wap_grouby_timeid_flatten[i]))\n\n    rv_list = []\n    for i in range(len(wap_grouby_timeid_flatten)):\n        rv_list.append(realized_volatility(wap_grouby_timeid_flatten[i]))\n      \n    rv_array = np.array(rv_list).reshape(-1,1)\n    rv = np.concatenate((np_df_unique_id,rv_array),axis=1)\n    return  rv","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:52:01.666722Z","iopub.execute_input":"2021-09-09T20:52:01.66705Z","iopub.status.idle":"2021-09-09T20:52:01.675354Z","shell.execute_reply.started":"2021-09-09T20:52:01.667016Z","shell.execute_reply":"2021-09-09T20:52:01.674402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" - `numpy_realized_volatility_per_time_id`is a global function that calls  `wap1` and `wap2`function, as well as   the previous one `wap_logreturn_numpy`.\n\n- Path name `split` was handled using simple list comprehension loop. ","metadata":{}},{"cell_type":"code","source":"def numpy_realized_volatility_per_time_id(file_path):\n    df = pd.read_parquet(file_path)\n    np_df_unique_id = np.unique(np.array(df)[:,0]).flatten()\n\n    df_realized_vol_per_stock = pd.DataFrame()\n    ## Calculate WAP\n    df['wap1'] = wap_1(df)\n    df['wap2'] = wap_2(df)\n    \n    ## Apply log return after grouping by id ( 5 then 6 then 7 ..... ) in order to apply the log return lag correctly\n    df_realized_vol_per_stock['rv1'] = wap_logreturn_numpy(df,0)[:,-1]\n    df_realized_vol_per_stock['rv2'] = wap_logreturn_numpy(df,1)[:,-1]\n\n    ## Extract the stock index / indice    \n    stock_id = np.int(file_path.split('=')[1])\n    \n    list_of_index = []\n    for i in range(len(np.unique(np_df_unique_id))):\n        list_of_index.append(f'{stock_id}-{np.int(np_df_unique_id[i])}')\n\n    df_realized_vol_per_stock['row_id'] = list_of_index\n\n    return df_realized_vol_per_stock[['row_id','rv1','rv2']]\n\ndf = pd.read_parquet(list_order_book_file_train[0])\ndf['wap1'] = wap_1(df)\ndf['wap2'] = wap_2(df)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:52:01.676874Z","iopub.execute_input":"2021-09-09T20:52:01.677171Z","iopub.status.idle":"2021-09-09T20:52:01.837369Z","shell.execute_reply.started":"2021-09-09T20:52:01.677142Z","shell.execute_reply":"2021-09-09T20:52:01.836479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time n = numpy_realized_volatility_per_time_id(list_order_book_file_train[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:52:01.839432Z","iopub.execute_input":"2021-09-09T20:52:01.839773Z","iopub.status.idle":"2021-09-09T20:52:02.550244Z","shell.execute_reply.started":"2021-09-09T20:52:01.839717Z","shell.execute_reply":"2021-09-09T20:52:02.549234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n[['row_id','rv1','rv2']] == p[['row_id','rv1','rv2']]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T20:52:02.551641Z","iopub.execute_input":"2021-09-09T20:52:02.551938Z","iopub.status.idle":"2021-09-09T20:52:02.571695Z","shell.execute_reply.started":"2021-09-09T20:52:02.551909Z","shell.execute_reply":"2021-09-09T20:52:02.570734Z"},"trusted":true},"execution_count":null,"outputs":[]}]}