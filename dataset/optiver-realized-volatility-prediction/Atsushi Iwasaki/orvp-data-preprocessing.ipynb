{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os\nimport os.path as osp\nimport pickle\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import QuantileTransformer","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:44:29.167403Z","iopub.execute_input":"2021-09-27T10:44:29.167771Z","iopub.status.idle":"2021-09-27T10:44:30.577194Z","shell.execute_reply.started":"2021-09-27T10:44:29.167681Z","shell.execute_reply":"2021-09-27T10:44:30.575834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = \"../usr/lib/orvp_table_data_generator/train_df.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:44:30.579414Z","iopub.execute_input":"2021-09-27T10:44:30.579829Z","iopub.status.idle":"2021-09-27T10:44:30.587327Z","shell.execute_reply.started":"2021-09-27T10:44:30.579779Z","shell.execute_reply":"2021-09-27T10:44:30.585918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:44:30.589167Z","iopub.execute_input":"2021-09-27T10:44:30.589482Z","iopub.status.idle":"2021-09-27T10:46:20.895467Z","shell.execute_reply.started":"2021-09-27T10:44:30.589449Z","shell.execute_reply":"2021-09-27T10:46:20.894543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# クラスターリスト作成","metadata":{}},{"cell_type":"code","source":"cluster_list = train_df.groupby('stock_id')[['c1']].agg(np.mean).reset_index()\ncluster_list.to_csv(\"cluster_list.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:46:20.89859Z","iopub.execute_input":"2021-09-27T10:46:20.89888Z","iopub.status.idle":"2021-09-27T10:46:20.951157Z","shell.execute_reply.started":"2021-09-27T10:46:20.898849Z","shell.execute_reply":"2021-09-27T10:46:20.950261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 高相関特徴量特定","metadata":{}},{"cell_type":"code","source":"def get_fe_remove(df, threshold=0.95):\n    corr_df = df.corr().abs()\n    features = corr_df.columns.tolist()\n    \n    fe_remove = []\n\n    for i, feature in enumerate(features):\n        if feature in fe_remove: continue\n        temp_series = corr_df.iloc[i+1:, i]\n        corr_idx = temp_series > threshold\n\n        series = temp_series.loc[corr_idx]\n        fe_corr = series.index.tolist()\n        if fe_corr!=[]:\n            if feature not in ['stock_id', 'fold', 'oof', 'row_id', 'target', 'time_id']:\n                fe_remove += fe_corr\n                \n    fe_remove = list(set(fe_remove))\n    return fe_remove","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:46:20.952799Z","iopub.execute_input":"2021-09-27T10:46:20.95316Z","iopub.status.idle":"2021-09-27T10:46:20.961405Z","shell.execute_reply.started":"2021-09-27T10:46:20.9531Z","shell.execute_reply":"2021-09-27T10:46:20.960586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fe_remove = get_fe_remove(train_df, threshold=0.97)\n\nfe_remove_ = [fe for fe in fe_remove if fe not in ['c1', 'stock_id']]\ntrain_df = train_df.drop(fe_remove_, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:46:20.962941Z","iopub.execute_input":"2021-09-27T10:46:20.963429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fe_remove_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 数値的補完関数作成","metadata":{}},{"cell_type":"code","source":"x = train_df.drop(['row_id', 'target'], axis=1)\ny = train_df['target']\n\ncols_drop = ['time_id']\ncols_cat = ['stock_id', 'c1']\n\n# Transform stock id to a numeric value\nfor fe in cols_cat:\n    x[fe] = x[fe].astype(int)\n\nx = x.replace([np.inf, -np.inf], np.nan)\nx = x.fillna(method='ffill')\nx_num = x.drop(cols_cat + cols_drop, axis=1).values\nx_cat = x.loc[:, cols_cat].values\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(x_num)\n\nscaler = QuantileTransformer(n_quantiles=2000, random_state=28, output_distribution='normal')\nscaler.fit(x_num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"imputer.pkl\", \"wb\") as f:\n    pickle.dump(imputer, f)\n    \nwith open(\"scaler.pkl\", \"wb\") as f:\n    pickle.dump(scaler, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# カテゴリー的補完関数作成","metadata":{}},{"cell_type":"code","source":"cat_dims = []\nfor i, col in enumerate(cols_cat):\n    le = LabelEncoder()\n    le.fit(x.loc[:, col])\n    cat_dims.append(len(le.classes_))\n    \n    with open(f\"le_{col}.pkl\", \"wb\") as f:\n        pickle.dump(le, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_dims  # stock_id, c1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"train_preprocessed.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}