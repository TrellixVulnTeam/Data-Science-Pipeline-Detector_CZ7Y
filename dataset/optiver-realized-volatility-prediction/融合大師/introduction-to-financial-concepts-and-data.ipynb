{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### A glimpse of our trading floor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"![work_at_optiver](https://www.optiver.com/wp-content/uploads/2020/11/WorkingAtOptiver_Hero.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Optiver Realized Volatility Prediction","metadata":{}},{"cell_type":"markdown","source":"# Introduction\nIn order to make Kagglers better prepared for this competition, Optiver's data scientists have created a tutorial notebook looping through some financial concepts covered in this particular trading challenge. Also, the data structure and the example code submission will also be presented in this notebook. ","metadata":{}},{"cell_type":"markdown","source":"# Order book\nThe term order book refers to an electronic list of buy and sell orders for a specific security or financial instrument organized by price level. An order book lists the number of shares being bid on or offered at each price point.\n\nBelow is a snapshot of an order book of a stock (let's call it stock A), as you can see, all intended buy orders are on the left side of the book displayed as \"bid\" while all intended sell orders are on the right side of the book displayed as \"offer/ask\"\n","metadata":{}},{"cell_type":"markdown","source":"![order_book_1](https://www.optiver.com/wp-content/uploads/2021/05/OrderBook3.png)\n\nAn actively traded financial instrument always has a dense order book (A liquid book). As the order book data is a continous representation of market demand/supply it is always considered as the number one data source for market research. ","metadata":{}},{"cell_type":"markdown","source":"# Trade\nAn order book is a representation of trading intention on the market, however the market needs a buyer and seller at the **same** price to make the trade happen. Therefore, sometimes when someone wants to do a trade in a stock, they check the order book and find someone with counter-interest to trade with. \n\nFor example, imagine you want to buy 20 shares of a stock A when you have the order book in the previous paragraph. Then you need to find some people who are willing to trade against you by selling 20 shares or more in total. You check the **offer** side of the book starting from the lowest price: there are 221 shares of selling interest on the level of 148. You can **lift** 20 shares for a price of 148 and **guarantee** your execution. This will be the resulting order book of stock A after your trade:","metadata":{}},{"cell_type":"markdown","source":"![order_book2](https://www.optiver.com/wp-content/uploads/2021/05/OrderBook4.png)\n\nIn this case, the seller(s) sold 20 shares and buyer bought 20 shares, the exchange will match the order between seller(s) and buyer and one trade message will be broadcast to public:\n\n- 20 shares of stock A traded on the market at price of 148.","metadata":{}},{"cell_type":"markdown","source":"Similar to order book data, trade data is also extremely crucial to Optiver's data scientists, as it reflects how active the market is. Actually, some commonly seen technical signals of the financial market are derived from trade data directly, such as high-low or total traded volume.","metadata":{}},{"cell_type":"markdown","source":"# Market making and market efficiency\nImagine, on another day, stock A's order book becomes below shape, and you, again, want to buy 20 shares from all the intentional sellers. As you can see the book is not as dense as the previous one, and one can say, compared with the previous one, this book is **less liquid**.","metadata":{}},{"cell_type":"markdown","source":"![order_book_3](https://www.optiver.com/wp-content/uploads/2021/05/OrderBook5.png)","metadata":{}},{"cell_type":"markdown","source":"You could insert an order to buy at 148. However, there is nobody currently willing to sell to you at 148, so your order will be sitting in the book, waiting for someone to trade against it. If you get unlucky, the price goes up, and others start bidding at 149, and you never get to buy at all. Alternatively, you could insert an order to buy at 155. The exchange would match this order against the outstanding sell order of one share at 149, so you buy 1 lot at 149. Similarly, you'd buy 12 shares at a price of 150, and 7 shares at 151. Compared to trying to buy at 148, there is no risk of not getting the trade that you wanted, but you do end up buying at a higher price.","metadata":{}},{"cell_type":"markdown","source":"You can see that in such an inefficient market it is difficult to trade, as trading will be more expensive, and if you want quality execution of your orders, you need to deal with higher market risk. That is why investors love liquidity, and market makers like Optiver are there to provide it, no matter how extreme market conditions are.","metadata":{}},{"cell_type":"markdown","source":"A market maker is a firm or individual who actively quotes two-sided markets in a security, providing bids and offers (known as asks) along with the market size of each. As a market maker will show both bid and offer orders, an order book with the presence of market maker will be more liquid, therefore a more efficient market will be provided to end investors to trade freely without concern on executions.","metadata":{}},{"cell_type":"markdown","source":"# Order book statistics\nThere are a lot of statistics Optiver data scientist can derive from raw order book data to reflect market liquidity and stock valuation. These stats are proven to be fundamental inputs of any market prediction algorithms. Below we would like to list some common stats to inspire Kagglers mining more valuable signals from the order book data.\n\nLet's come back to the original order book of stock A","metadata":{}},{"cell_type":"markdown","source":"![order_book_1](https://www.optiver.com/wp-content/uploads/2021/05/OrderBook3.png)","metadata":{}},{"cell_type":"markdown","source":"**bid/ask spread**\n\nAs different stocks trade on different level on the market we take the ratio of best offer price and best bid price to calculate the bid-ask spread. \n\nThe formula of bid/ask spread can be written in below form:\n$$BidAskSpread = BestOffer/BestBid -1$$","metadata":{}},{"cell_type":"markdown","source":"**Weighted averaged price**\n\nThe order book is also one of the primary source for stock valuation. A fair book-based valuation must take two factors into account: the level and the size of orders. In this competition we used weighted averaged price, or WAP, to calculate the instantaneous stock valuation and calculate realized volatility as our target. \n\nThe formula of WAP can be written as below, which takes the top level price and volume information into account:\n\n$$ WAP = \\frac{BidPrice_{1}*AskSize_{1} + AskPrice_{1}*BidSize_{1}}{BidSize_{1} + AskSize_{1}} $$\n\nAs you can see, if two books have both bid and ask offers on the same price level respectively, the one with more offers in place will generate a lower stock valuation, as there are more intended seller in the book, and more seller implies a fact of more supply on the market resulting in a lower stock valuation.\n\nNote that in most of cases, during the continuous trading hours, an order book should not have the scenario when bid order is higher than the offer, or ask, order. In another word, most likely, the bid and ask should never be **in cross.**\n\nIn this competition the target is constructed from the WAP. The WAP of the order book snapshot is 147.5317797.","metadata":{}},{"cell_type":"markdown","source":"# Log returns\n\n**How can we compare the price of a stock between yesterday and today?**\n\nThe easiest method would be to just take the difference. This is definitely the most intuitive way, however **price differences** are not always comparable across stocks. For example, let's assume that we have invested $\\$$1000 dollars in both stock A and stock B and that stock A moves from $\\$$100 to $\\$$102 and stock B moves from $\\$$10 to $\\$$11. We had a total of 10 shares of A ($\\$1000 \\ / \\ \\$100 = 10$) which led to a profit of $10 \\cdot (\\$102 - \\$100) = \\$20$ and a total of 100 shares of B that yielded \\$100. So the price increase was larger for stock **A**, although the move was proportionally much larger for stock B.\n\nWe can solve the above problem by dividing the move by the starting price of the stock, effectively computing the percentage change in price, also known as the **stock return**. In our example, the return for stock A was $\\frac{\\$102 - \\$100 }{\\$100} = 2\\%$, while for stock B it was $\\frac{\\$11 - \\$10 }{\\$10} = 10\\%$. The stock return coincides with the percentage change in our invested capital.\n\nReturns are widely used in finance, however **log returns** are preferred whenever some mathematical modelling is required. Calling $S_t$ the price of the stock $S$ at time $t$, we can define the log return between $t_1$ and $t_2$ as:\n$$\nr_{t_1, t_2} = \\log \\left( \\frac{S_{t_2}}{S_{t_1}} \\right)\n$$\nUsually, we look at log returns over fixed time intervals, so with 10-minute log return we mean $r_t = r_{t - 10 min, t}$.\n\nLog returns present several advantages, for example:\n- they are additive across time $r_{t_1, t_2} + r_{t_2, t_3} = r_{t_1, t_3}$\n- regular returns cannot go below -100%, while log returns are not bounded","metadata":{}},{"cell_type":"markdown","source":"# Realized volatility\nWhen we trade options, a valuable input to our models is the standard deviation of the stock log returns. The standard deviation will be different for log returns computed over longer or shorter intervals, for this reason it is usually normalized to a 1-year period and the annualized standard deviation is called **volatility**. \n\nIn this competition, you will be given 10 minutes of book data and we ask you to predict what the volatility will be in the following 10 minutes. Volatility will be measured as follows:\n\nWe will compute the log returns over all consecutive book updates and we define the **realized volatility, $\\sigma$,** as the squared root of the sum of squared log returns.\n$$\n\\sigma = \\sqrt{\\sum_{t}r_{t-1, t}^2}\n$$\nWhere we use **WAP** as price of the stock to compute log returns.\n\nWe want to keep definitions as simple and clear as possible, so that Kagglers without financial knowledge will not be penalized. So we are not annualizing the volatility and we are assuming that log returns have 0 mean.","metadata":{}},{"cell_type":"markdown","source":"# Competition data\nIn this competition, Kagglers are challenged to generate a series of short-term signals from the book and trade data of a fixed 10-minute window to predict the realized volatility of the next 10-minute window. The target, which is given in train/test.csv, can be linked with the raw order book/trade data by the same **time_id** and **stock_id**. There is no overlap between the feature and target window.","metadata":{}},{"cell_type":"markdown","source":"Note that the competition data will come with partitioned parquet file. You can find a tutorial of parquet file handling in this [notebook](https://www.kaggle.com/sohier/working-with-parquet)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:06.048823Z","iopub.execute_input":"2021-08-26T08:35:06.049428Z","iopub.status.idle":"2021-08-26T08:35:07.997541Z","shell.execute_reply.started":"2021-08-26T08:35:06.049341Z","shell.execute_reply":"2021-08-26T08:35:07.99621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking the first row of data, it implies that the realized vol of the **target bucket** for time_id 5, stock_id 0 is 0.004136. How does the book and trade data in **feature bucket** look like for us to build signals?","metadata":{}},{"cell_type":"code","source":"#book_example:讀訓練集股票0的order book信息\nbook_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')\n#trade_example:讀訓練集股票0的trade信息\ntrade_example =  pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')\n\nstock_id = '0'\n#book_example只包含time_id=5的數據\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:07.999485Z","iopub.execute_input":"2021-08-26T08:35:07.999861Z","iopub.status.idle":"2021-08-26T08:35:08.667842Z","shell.execute_reply.started":"2021-08-26T08:35:07.999827Z","shell.execute_reply":"2021-08-26T08:35:08.666588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**book data snapshot**","metadata":{}},{"cell_type":"code","source":"book_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:08.669926Z","iopub.execute_input":"2021-08-26T08:35:08.670296Z","iopub.status.idle":"2021-08-26T08:35:08.688855Z","shell.execute_reply.started":"2021-08-26T08:35:08.670264Z","shell.execute_reply":"2021-08-26T08:35:08.687555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**trade date snapshot**","metadata":{}},{"cell_type":"code","source":"trade_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:08.690561Z","iopub.execute_input":"2021-08-26T08:35:08.690998Z","iopub.status.idle":"2021-08-26T08:35:08.716228Z","shell.execute_reply.started":"2021-08-26T08:35:08.69096Z","shell.execute_reply":"2021-08-26T08:35:08.715052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Realized volatility calculation in python**","metadata":{}},{"cell_type":"markdown","source":"In this competition, our target is to predict short-term realized volatility. Although the order book and trade data for the target cannot be shared, we can still present the realized volatility calculation using the feature data we provided. \n\nAs realized volatility is a statistical measure of price changes on a given stock, to calculate the price change we first need to have a stock valuation at the fixed interval (1 second). We will use weighted averaged price, or WAP, of the order book data we provided.","metadata":{}},{"cell_type":"code","source":"#給book_example添加wap屬性,即在這一秒中的價格\nbook_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) / (\n                                       book_example['bid_size1']+ book_example['ask_size1'])\nbook_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:08.717849Z","iopub.execute_input":"2021-08-26T08:35:08.718182Z","iopub.status.idle":"2021-08-26T08:35:08.744588Z","shell.execute_reply.started":"2021-08-26T08:35:08.718151Z","shell.execute_reply":"2021-08-26T08:35:08.743392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The WAP of the stock is plotted below**","metadata":{}},{"cell_type":"code","source":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"wap\", title='WAP of stock_id_0, time_id_5')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:08.746334Z","iopub.execute_input":"2021-08-26T08:35:08.746803Z","iopub.status.idle":"2021-08-26T08:35:10.080335Z","shell.execute_reply.started":"2021-08-26T08:35:08.746755Z","shell.execute_reply":"2021-08-26T08:35:10.079107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To compute the log return, we can simply take **the logarithm of the ratio** between two consecutive **WAP**. The first row will have an empty return as the previous book update is unknown, therefore the empty return data point will be dropped.","metadata":{}},{"cell_type":"code","source":"#輸入是series，回傳也是series\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() ","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:10.081735Z","iopub.execute_input":"2021-08-26T08:35:10.082057Z","iopub.status.idle":"2021-08-26T08:35:10.087266Z","shell.execute_reply.started":"2021-08-26T08:35:10.082028Z","shell.execute_reply":"2021-08-26T08:35:10.086164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#給book_example多加了一列log_return\nbook_example.loc[:,'log_return'] = log_return(book_example['wap'])\n#第一個值為空,捨去index=0\nbook_example = book_example[~book_example['log_return'].isnull()]\nbook_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:10.089965Z","iopub.execute_input":"2021-08-26T08:35:10.090438Z","iopub.status.idle":"2021-08-26T08:35:10.125257Z","shell.execute_reply.started":"2021-08-26T08:35:10.090389Z","shell.execute_reply":"2021-08-26T08:35:10.12391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's plot the tick-to-tick return of this instrument over this time bucket**","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:01:53.679074Z","iopub.execute_input":"2021-06-09T15:01:53.679605Z","iopub.status.idle":"2021-06-09T15:01:53.686279Z","shell.execute_reply.started":"2021-06-09T15:01:53.67957Z","shell.execute_reply":"2021-06-09T15:01:53.684738Z"}}},{"cell_type":"code","source":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"log_return\", title='Log return of stock_id_0, time_id_5')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:10.126823Z","iopub.execute_input":"2021-08-26T08:35:10.12715Z","iopub.status.idle":"2021-08-26T08:35:10.203715Z","shell.execute_reply.started":"2021-08-26T08:35:10.127121Z","shell.execute_reply":"2021-08-26T08:35:10.202828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The realized vol of stock 0 in this feature bucket, will be:","metadata":{}},{"cell_type":"code","source":"#股票0在時間5的計算波動值\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\nprint(type(book_example['log_return']))\n\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:10.204888Z","iopub.execute_input":"2021-08-26T08:35:10.205283Z","iopub.status.idle":"2021-08-26T08:35:10.212986Z","shell.execute_reply.started":"2021-08-26T08:35:10.205251Z","shell.execute_reply":"2021-08-26T08:35:10.212074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive prediction: using past realized volatility as target","metadata":{}},{"cell_type":"markdown","source":"A commonly known fact about volatility is that it tends to be autocorrelated. We can use this property to implement a naive model that just \"predicts\" realized volatility by using whatever the realized volatility was in the initial 10 minutes.\n\nLet's calculate the past realized volatility across the training set to see how predictive a single naive signal can be.","metadata":{}},{"cell_type":"code","source":"import os\nfrom sklearn.metrics import r2_score\nimport glob\n#包含所有訓練order book信息的文件路徑的list\nlist_order_book_file_train = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')\nlist_order_book_file_train[:5]","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:10.214394Z","iopub.execute_input":"2021-08-26T08:35:10.214735Z","iopub.status.idle":"2021-08-26T08:35:11.13439Z","shell.execute_reply.started":"2021-08-26T08:35:10.21469Z","shell.execute_reply":"2021-08-26T08:35:11.133237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the data is partitioned by stock_id in this competition to allow Kagglers better manage the memory, we try to calculcate realized volatility stock by stock and combine them into one submission file. Note that the stock id as the partition column is not present if we load the single file so we will remedy that manually. We will reuse the log return and realized volatility functions defined in the previous session.\n\n**先算一下訓練集,即book_train.parquet中，每隻股票在每個time_id的波動值，並假定這個波動值就是下一個十分鐘的預測值，和train.csv的target(即GT)做比較看看如何，算一算分數，也就是很暴力的直接把過去的值當做預測值。**","metadata":{}},{"cell_type":"code","source":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    #先算出wap\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    #增加了wap\n    ##print(\"增加了wap \\n\",df_book_data.head())\n    \n    #apply使用方法:https://www.cnblogs.com/gaoxing2580/p/13193459.html\n    #groupby介紹:https://zhuanlan.zhihu.com/p/101284491?utm_source=wechat_session\n    #groupby+apply用法:https://blog.csdn.net/qq_42138454/article/details/106434279\n    \n    ##print(list(df_book_data.groupby(['time_id'])['wap'])[:5])\n    #對每個group的series處理完後stack在一起，但本身不會修改到df_book_data，且會照原本的index，具體參照各種報告/group+apply-test.py\n    #對dfapply會回傳df，對seriesapply會回傳series\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return) #apply輸入輸出都是series\n    \n    ##print(type(df_book_data['log_return'].isnull()))#True or false的series，決定保留df中哪些index的樣本\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    \n    #agg用法說明：https://blog.csdn.net/weixin_42575020/article/details/107002156\n    #realized_volatility()輸入是某一個timeid的log return 的series，輸出則是一個數字，即realized_volatility的值。\n    \n    #coloumns分別為0和1的df，因為col0即原本的一個timeid對應多個col1即log return(series)，會很亂(並且還會有新的從0-n的index，index不在col之內)，應該是多重標籤\n    #print(pd.DataFrame(df_book_data.groupby(['time_id'])['log_return']))\n    \n    #加了.agg(realized_volatility)就不再是多重標籤了，因為一個timeid只對應一個realized_volatility，此時新的df也只有一個col即為realized_volatility,index則是timeid，和上面不一樣\n    #換而言之，如果pd.dataframe(groupby class)的series是一一對應的，則series的index依然是df的index，如果不一一對應，則series的index也會變成一個col，且出現多重標籤。\n    #df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)是一個series，index為time_id\n    #group+agg和group+apply的區別是，agg會用groupby的col當index，apply則不會使用而是直接用groupby前df的index\n    #print( pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)))\n \n    #index就是timeid,reset之後就是從0開始的連續數字了了，timeid沒有被洗掉(因為它原本是index)，而是變成了新的column\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    #不管是agg還是apply，它們都不會修改本來的df，需要用new_df=df.agg（or apply）\n    \n    #單純把logreturn更名\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    \n    #獲得股票id數字\n    stock_id = file_path.split('=')[1]\n    \n    #對series的apply和df不同：https://www.cnblogs.com/liulangmao/p/9231804.html\n    #row_id=stockid-time_id\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    #只选取某几列：\"如果需要选取多列，传给 DataFrame 一个包含列名的 list\"                                                                  \n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:11.135634Z","iopub.execute_input":"2021-08-26T08:35:11.135925Z","iopub.status.idle":"2021-08-26T08:35:11.146223Z","shell.execute_reply.started":"2021-08-26T08:35:11.135895Z","shell.execute_reply":"2021-08-26T08:35:11.145081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looping through each individual stocks, we can get the past realized volatility as prediction for each individual stocks.","metadata":{}},{"cell_type":"code","source":"r'''\n#跑一個路徑測試\ndf_past_realized = pd.DataFrame()\ndf_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=97','pred')])\n\ndf_past_realized.head()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:11.147713Z","iopub.execute_input":"2021-08-26T08:35:11.148164Z","iopub.status.idle":"2021-08-26T08:35:11.163986Z","shell.execute_reply.started":"2021-08-26T08:35:11.148119Z","shell.execute_reply":"2021-08-26T08:35:11.162774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        #pd.concat([df1,df2,df3...])\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\ndf_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:35:11.16552Z","iopub.execute_input":"2021-08-26T08:35:11.165914Z","iopub.status.idle":"2021-08-26T08:42:07.670249Z","shell.execute_reply.started":"2021-08-26T08:35:11.165837Z","shell.execute_reply":"2021-08-26T08:42:07.669185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's join the output dataframe with train.csv to see the performance of the naive prediction on training set.","metadata":{}},{"cell_type":"code","source":"train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\n#外部合併：http://debussy.im.nuu.edu.tw/sjchen/Database/Final/Ch08.pdf\ndf_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')\nprint(df_joined.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:54:46.768397Z","iopub.execute_input":"2021-08-26T08:54:46.768881Z","iopub.status.idle":"2021-08-26T08:54:48.696103Z","shell.execute_reply.started":"2021-08-26T08:54:46.768847Z","shell.execute_reply":"2021-08-26T08:54:48.694916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will evaluate the naive prediction result by two metrics: RMSPE and R squared. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n#R2:https://zh.wikipedia.org/wiki/%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0\n#输入两个series，输出一个数字\nR2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nRMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:57:59.163691Z","iopub.execute_input":"2021-08-26T08:57:59.164107Z","iopub.status.idle":"2021-08-26T08:57:59.187586Z","shell.execute_reply.started":"2021-08-26T08:57:59.164072Z","shell.execute_reply":"2021-08-26T08:57:59.186067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The performance of the naive model is not amazing but as a benchmark it is a reasonable start.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"As a last step, we will make a submission via the tutorial notebook -- through a file written to output folder.  The naive submission scored a RMSPE 0.327 on public LB, the room of improvement is big for sure!","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:25:51.891717Z","iopub.execute_input":"2021-06-09T15:25:51.89209Z","iopub.status.idle":"2021-06-09T15:25:51.898582Z","shell.execute_reply.started":"2021-06-09T15:25:51.892059Z","shell.execute_reply":"2021-06-09T15:25:51.89729Z"}}},{"cell_type":"code","source":"list_order_book_file_test = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*')\ndf_naive_pred_test = past_realized_volatility_per_stock(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target')\ndf_naive_pred_test.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T18:31:41.736646Z","iopub.execute_input":"2021-06-22T18:31:41.737029Z","iopub.status.idle":"2021-06-22T18:31:41.768867Z","shell.execute_reply.started":"2021-06-22T18:31:41.736997Z","shell.execute_reply":"2021-06-22T18:31:41.767699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that in this competition, there will be only few rows of test data that can be downloaded. The actual evaluation program will run in background after you commit the notebook and manually submit the output. Please check to [code requirement](https://www.kaggle.com/c/optiver-realized-volatility-prediction/overview/code-requirements) for more explanation.","metadata":{}},{"cell_type":"markdown","source":"The private leaderboard will be built against the real market data collected after the training period, therefore the public and private leaderboard data will have zero overlap. It will be exciting to get your model tested against the live market! As this competition will provide a very rich dataset representing market microstructure, there is unlimited amount of signals one can come up with. It is all on you, good luck! We at Optiver are really looking forward to learn from the talented Kaggle community!\n\nIf you have any question about this notebook or the financial concepts behind it, feel free to ask in the comment section and we will make sure your questions get answered. \n\nGood luck!","metadata":{}}]}