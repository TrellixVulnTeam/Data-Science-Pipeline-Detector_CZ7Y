{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport plotly.express as px\nimport glob\n\ntrain = pd.read_csv('/kaggle/input/optiver-realized-volatility-prediction/train.csv')\nsub = pd.read_csv('/kaggle/input/optiver-realized-volatility-prediction/sample_submission.csv')\n\n# Some Constants\nTRAIN_BOOK_PATHS = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*\")\nTEST_BOOK_PATHS  = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*\")\nTRAIN_TRADE_PATHS = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/*\")\nTEST_TRADE_PATHS  = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/trade_test.parquet/*\")\n\ndef submit(prediction):\n    sub.drop(sub.index, inplace=True)\n    sub['row_id'] = test_data['row_id']\n    sub['target'] = prediction\n    sub.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T05:35:29.214416Z","iopub.execute_input":"2021-07-05T05:35:29.215076Z","iopub.status.idle":"2021-07-05T05:35:30.939799Z","shell.execute_reply.started":"2021-07-05T05:35:29.21493Z","shell.execute_reply":"2021-07-05T05:35:30.938521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The data file for each sotck_id will be imported from book_train folder, the ids go from 0 to 126.\n\n## Preprocessing\n\nData will be categorized by the time-id, meaning the modeling will happen for each time-id individually. Hence, statistical measures for a given time-id should be extracted and fed into a model.\n\n- Get the wap for each row\n- Drp seconds_in_bucket","metadata":{}},{"cell_type":"code","source":"class DataManager:\n    def __init__(self, train=True):\n        self._train = train\n        self._book_file_list = TRAIN_BOOK_PATHS if train else TEST_BOOK_PATHS\n        self._trade_file_list = TRAIN_TRADE_PATHS if train else TEST_TRADE_PATHS\n        self.measures_list = []\n        \n    def _log_return(self, stock_prices):\n        return np.log(stock_prices).diff()\n    \n    def _traverse_book(self):\n        \"\"\" Goes through each of the training files. \"\"\"\n        for book_file_path, trade_file_path in zip(self._book_file_list, self._trade_file_list):\n            stock_id = book_file_path.split(\"=\")[1]\n            \n            book = pd.read_parquet(book_file_path)\n            book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1']+ book['ask_size1'])\n            book['log_return'] = book.groupby(['time_id'])['wap'].apply(self._log_return)\n            book = book[~book['log_return'].isnull()]\n            \n            trade = pd.read_parquet(trade_file_path)\n            \n            book_stock_slice = train[train['stock_id'] == int(stock_id)]\n            \n            for time_id in book['time_id'].unique():\n                book_slice = book[book['time_id'] == time_id]\n                \n                dic = {\n                    'row_id': f\"{stock_id}-{time_id}\", # Fixing row-id from here\n                    'wap_mean': book_slice['wap'].mean(),\n                    'wap_std':book_slice['wap'].std(),\n                    'log_return_mean': book_slice['log_return'].mean(),\n                    'log_return_std':book_slice['log_return'].std(),\n                    'ask_size_mean': book_slice['ask_size1'].mean(),\n                    'ask_size_std': book_slice['ask_size1'].std(),\n                    'ask_price_mean': book_slice['ask_price1'].mean(),\n                    'ask_price_std': book_slice['ask_price1'].std(),\n                    'bid_size_mean': book_slice['bid_size1'].mean(),\n                    'bid_size_std': book_slice['bid_size1'].std(),\n                    'bid_price_mean': book_slice['bid_price1'].mean(),\n                    'bid_price_std': book_slice['bid_price1'].std(),\n                    'actual_price_mean': trade['price'].mean(),\n                    'actual_price_std': trade['price'].std(),\n                    'size_mean': trade['size'].mean(),\n                    'size_std': trade['size'].std(),\n                    'order_count_mean': trade['order_count'].mean(),\n                    'order_count_std': trade['order_count'].std(),\n                }\n                \n                if self._train: dic['target'] = book_stock_slice[book_stock_slice['time_id'] == time_id]['target'].values[0]\n                \n                self.measures_list.append(dic)\n    \n    def get_processed(self):\n        self._traverse_book()\n        \n        return pd.DataFrame(self.measures_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:35:30.942157Z","iopub.execute_input":"2021-07-05T05:35:30.942605Z","iopub.status.idle":"2021-07-05T05:35:30.957459Z","shell.execute_reply.started":"2021-07-05T05:35:30.94256Z","shell.execute_reply":"2021-07-05T05:35:30.956364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing different pre-processing techniques","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error as mae\n\ndata = pd.read_csv('/kaggle/input/processedbooktrade/train_v1.csv')\n\ny = data['target']\nX = data.iloc[:,2:-1]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\ntest_data = DataManager(train=False).get_processed()\nX_test = test_data.iloc[:,1:]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:35:30.959686Z","iopub.execute_input":"2021-07-05T05:35:30.960314Z","iopub.status.idle":"2021-07-05T05:35:32.420631Z","shell.execute_reply.started":"2021-07-05T05:35:30.960271Z","shell.execute_reply":"2021-07-05T05:35:32.419562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(X_train)) # 6128row 18 columns \nprint(type(y_train))# 6128\n#回归任务","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:35:32.422354Z","iopub.execute_input":"2021-07-05T05:35:32.42283Z","iopub.status.idle":"2021-07-05T05:35:32.431307Z","shell.execute_reply.started":"2021-07-05T05:35:32.422764Z","shell.execute_reply":"2021-07-05T05:35:32.430314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling","metadata":{"execution":{"iopub.status.busy":"2021-07-03T06:09:04.200055Z","iopub.execute_input":"2021-07-03T06:09:04.200438Z","iopub.status.idle":"2021-07-03T06:09:04.204533Z","shell.execute_reply.started":"2021-07-03T06:09:04.200402Z","shell.execute_reply":"2021-07-03T06:09:04.203503Z"}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n#data转tensor\ndef pandas_to_tensor(x):\n    x=np.array(x)\n    x=torch.tensor(x)\n    return x\n\nX_train=pandas_to_tensor(X_train)\ny_train=pandas_to_tensor(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:35:32.433799Z","iopub.execute_input":"2021-07-05T05:35:32.434409Z","iopub.status.idle":"2021-07-05T05:35:33.773993Z","shell.execute_reply.started":"2021-07-05T05:35:32.434371Z","shell.execute_reply":"2021-07-05T05:35:33.773074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Volatility_prediction(nn.Module):\n    def __init__(self):\n        super(Volatility_prediction,self).__init__()\n        self.predict = nn.Sequential(\n            nn.Linear(18, 200),\n            nn.ReLU(),\n            nn.Linear(200, 50),\n            nn.ReLU(),\n            nn.Linear(50,1),\n            nn.Softmax(dim=0)\n        )\n\n    def forward(self, x):\n        prediction = self.predict(x)\n        return prediction\n\n\nnet =Volatility_prediction()\noptimizer = torch.optim.SGD(net.parameters(), lr=0.05)\nloss_func = nn.MSELoss()\n\nfor epoch in range(50000):\n    out = net(X_train.to(torch.float32))\n    loss = loss_func(out.squeeze(1),y_train.to(torch.float32))\n#     print(out,y_train.to(torch.float32))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \ntorch.save(net, '\\model.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:35:33.777615Z","iopub.execute_input":"2021-07-05T05:35:33.777925Z","iopub.status.idle":"2021-07-05T05:43:57.87235Z","shell.execute_reply.started":"2021-07-05T05:35:33.777897Z","shell.execute_reply":"2021-07-05T05:43:57.871422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_test(X):\n    model = torch.load('\\model.pkl')\n    model.eval()\n\n    output=0\n    times=0\n    for data in pandas_to_tensor(X):\n        output=model(data.to(torch.float32))\n        if times==0:\n            times+=1\n            outputs=output\n        else:\n            outputs=torch.cat((outputs,output),0)\n        \n    outputs=pd.Series(outputs.to(torch.float64).detach().numpy())\n    return outputs\n\noutputs=model_test(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:43:57.873518Z","iopub.execute_input":"2021-07-05T05:43:57.874011Z","iopub.status.idle":"2021-07-05T05:43:58.300332Z","shell.execute_reply.started":"2021-07-05T05:43:57.873978Z","shell.execute_reply":"2021-07-05T05:43:58.299197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae(outputs, y_val)\n\n# from sklearn import tree\n# import matplotlib.pyplot as plt\n\n# fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n# tree.plot_tree(rfg.estimators_[10],\n#                feature_names = X.columns, \n#                filled = True);\n\n# fig.savefig('rf_individualtree.png')","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:43:58.301849Z","iopub.execute_input":"2021-07-05T05:43:58.302138Z","iopub.status.idle":"2021-07-05T05:43:58.310799Z","shell.execute_reply.started":"2021-07-05T05:43:58.302112Z","shell.execute_reply":"2021-07-05T05:43:58.309904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submissiong process","metadata":{}},{"cell_type":"code","source":"submit(model_test(X_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T06:11:47.510022Z","iopub.execute_input":"2021-07-05T06:11:47.51041Z","iopub.status.idle":"2021-07-05T06:11:47.527687Z","shell.execute_reply.started":"2021-07-05T06:11:47.51038Z","shell.execute_reply":"2021-07-05T06:11:47.52673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from joblib import dump, load\ndump(net, 'rfg_1000_10_train_v1.joblib') \n# clf = load('rfg_1000_10.joblib') ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:43:58.334323Z","iopub.execute_input":"2021-07-05T05:43:58.334685Z","iopub.status.idle":"2021-07-05T05:43:58.347942Z","shell.execute_reply.started":"2021-07-05T05:43:58.334654Z","shell.execute_reply":"2021-07-05T05:43:58.346944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.read_csv('/kaggle/working/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:43:58.349709Z","iopub.execute_input":"2021-07-05T05:43:58.350273Z","iopub.status.idle":"2021-07-05T05:43:58.354272Z","shell.execute_reply.started":"2021-07-05T05:43:58.350226Z","shell.execute_reply":"2021-07-05T05:43:58.353246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clf.get_params()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T05:43:58.355731Z","iopub.execute_input":"2021-07-05T05:43:58.35617Z","iopub.status.idle":"2021-07-05T05:43:58.367667Z","shell.execute_reply.started":"2021-07-05T05:43:58.35613Z","shell.execute_reply":"2021-07-05T05:43:58.366743Z"},"trusted":true},"execution_count":null,"outputs":[]}]}