{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 匯入之前notebook的Output file, 需要再add data處選擇Output file，在選擇該Notebook進行匯入。匯入的資料會跑到Input資料夾。 Output資料夾每次開啟必定清空","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport time\nimport gc\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.express as px\n\nfrom IPython import display\nimport sklearn\nimport gc\nimport time\n\ngc.collect()\n\nprint('Library imported.')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T06:12:52.21607Z","iopub.execute_input":"2021-08-06T06:12:52.216594Z","iopub.status.idle":"2021-08-06T06:12:54.807856Z","shell.execute_reply.started":"2021-08-06T06:12:52.216487Z","shell.execute_reply":"2021-08-06T06:12:54.806606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntest = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n\ngc.collect()\n\n#df_join = pd.read_csv('../input/volatility-prediction/df_joined.csv')\n\nprint('Data imported.')\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:12:54.809728Z","iopub.execute_input":"2021-08-06T06:12:54.810138Z","iopub.status.idle":"2021-08-06T06:12:55.274664Z","shell.execute_reply.started":"2021-08-06T06:12:54.810092Z","shell.execute_reply":"2021-08-06T06:12:55.273458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('訓練集的樣子: 實際的stock_id, time_id與目標值realized_volatility')\nprint(train.head())\nprint('測試集的樣子: ')\nprint(test.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:12:55.277069Z","iopub.execute_input":"2021-08-06T06:12:55.27751Z","iopub.status.idle":"2021-08-06T06:12:55.298272Z","shell.execute_reply.started":"2021-08-06T06:12:55.27746Z","shell.execute_reply":"2021-08-06T06:12:55.297286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 每個stock_id在特定的時間區段time_id內都有一個目標realized vol. 值，如stock_id= 0在time_id = 5時的target即為0.004136\n\n#### time_id代表某個時間區段的代號ID, target代表此time_id**未來10分鐘後的feature data計算出來的值**, 也就是我們要預測的目標。\n\n#### 每個time_id時間區段內歷經長度為10分鐘, 即seconds_in_bucket的值會由0~600秒(但不一定每一秒都有紀錄)\n\n#### 我們要用**現在的time_id, stock_id對應的order book, trade資料**建立數學模型，預測未來10分鐘的realized volatility","metadata":{}},{"cell_type":"code","source":"book_train = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet')\nbook_test = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_test.parquet')\n\ngc.collect()\n\nprint(\"訓練集的order book: 包含bid price和ask price\")\nprint(book_train.head()) # seconds in bucket 可視為時間特徵\nprint('測試集的order book: ')\nprint(book_test.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:12:55.299825Z","iopub.execute_input":"2021-08-06T06:12:55.300127Z","iopub.status.idle":"2021-08-06T06:13:10.633835Z","shell.execute_reply.started":"2021-08-06T06:12:55.300094Z","shell.execute_reply":"2021-08-06T06:13:10.632707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ","metadata":{}},{"cell_type":"code","source":"gc.collect()\ntrade_train = pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet')\ntrade_test = pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_test.parquet')\n\ngc.collect()\n\nprint('訓練集的實際交易:')\nprint(trade_train.head())\n\nprint('測試集的實際交易:')\nprint(trade_test.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:10.635037Z","iopub.execute_input":"2021-08-06T06:13:10.635345Z","iopub.status.idle":"2021-08-06T06:13:12.970534Z","shell.execute_reply.started":"2021-08-06T06:13:10.635313Z","shell.execute_reply":"2021-08-06T06:13:12.969431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 為節省RAM，先不讀test data近來\ndel book_test, trade_test, test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:12.972005Z","iopub.execute_input":"2021-08-06T06:13:12.97241Z","iopub.status.idle":"2021-08-06T06:13:13.116838Z","shell.execute_reply.started":"2021-08-06T06:13:12.972375Z","shell.execute_reply":"2021-08-06T06:13:13.114227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print('book_train 總共包含 {} 種不同股票'.format(book_train['stock_id'].nunique()))\n#print('book_train 總共包含 {} 個不同時間區段'.format(book_train['time_id'].nunique()))\n#gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.11865Z","iopub.execute_input":"2021-08-06T06:13:13.119124Z","iopub.status.idle":"2021-08-06T06:13:13.126911Z","shell.execute_reply.started":"2021-08-06T06:13:13.119081Z","shell.execute_reply":"2021-08-06T06:13:13.125619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### book_train 總共包含 112 種不同股票\n#### book_train 總共包含 3830 個不同時間區段","metadata":{}},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    # Give series of stock price, 計算每時段與下一筆資料間的log return\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    # Give log return, 計算realized volatility\n    return np.sqrt(np.sum(series_log_return**2))\n\n\n# 計算每個stock_id-time_id單位範圍內的realized volatility\ndef compute_realized_vol(file_path, realized_vol_colname):\n    # file_path: \n    # realized_vol:\n    df_book_data = pd.read_parquet(file_path)\n    # 用公式計算order book資料的WAP\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']\n                          +df_book_data['ask_price1'] * df_book_data['bid_size1'])/  \\\n                            (df_book_data['bid_size1'] + \n                             df_book_data['ask_size1'])\n    # 用WAP計算log return\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    # 去除 log return 的NULL值\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    # 用公式計算realized volatility\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':realized_vol_colname})\n    stock_id = file_path.split('=')[1]\n    # 建立新欄位: stock_id-time_id 即每個樣本的index\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',realized_vol_colname]]\n\n\ndef generate_realized_vol(list_file,realized_vol_colname):\n    # Give list of order book files( ../stock_id/filename.parquet), generate realized vol.\n    # and return Dataframe for each stock_id\n    # list_file: list of filepath for multiple stock_id files\n    # realized_vol_colname: column name for calculated realized_vol. value\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     compute_realized_vol(file,realized_vol_colname)])\n    return df_past_realized\n\nimport glob\n#order_book_list = glob.glob('../input/optiver-realized-volatility-prediction/book_train.parquet/*')\n\n#df_train = generate_realized_vol(list_file=order_book_list, realized_vol_colname='realized_vol')\nprint('必要function已經設定完成')\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.129795Z","iopub.execute_input":"2021-08-06T06:13:13.130092Z","iopub.status.idle":"2021-08-06T06:13:13.264016Z","shell.execute_reply.started":"2021-08-06T06:13:13.130062Z","shell.execute_reply":"2021-08-06T06:13:13.262885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndf_join = pd.read_csv('../input/volatility-predict/df_joined.csv')\n# row_id 組成為: stock_id-time_id\ndf_join['stock_id'] = df_join['row_id'].apply(lambda value: int(value.split('-')[0]))\ndf_join['time_id'] = df_join['row_id'].apply(lambda value: int(value.split('-')[1]))\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.266978Z","iopub.execute_input":"2021-08-06T06:13:13.267298Z","iopub.status.idle":"2021-08-06T06:13:13.283455Z","shell.execute_reply.started":"2021-08-06T06:13:13.267269Z","shell.execute_reply":"2021-08-06T06:13:13.282476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 預測未來的Realized volatility(流動率): 什麼因素會影響**未來10分鐘的Order book**?","metadata":{}},{"cell_type":"code","source":"# add more features\n\n# 定義整個資料預處理\n\ndef preprocess_trade(trade_data):\n    # current number of traders and current trading price\n    # mean price\n    # transform() 可讓groupby的aggregate結果和原column進行align，建立新column\n    trade_data['mean_price'] = trade_data.groupby(['stock_id', 'time_id'])\\\n         ['price'].transform('mean')\n    \n    trade_data['max_price'] = trade_data.groupby(['stock_id', 'time_id'])\\\n         ['price'].transform('max')\n    # total number of traders in same time_id for each stock_id\n    trade_data['total_trader'] = trade_data.groupby(['stock_id', 'time_id'])\\\n         ['order_count'].transform('sum')\n    # total sold: price * size\n    trade_data['total_sold'] = trade_data['price']*trade_data['size']\n    trade_data['mean_totalsold'] = trade_data.groupby(['stock_id', 'time_id'])\\\n        ['total_sold'].transform('mean')\n    trade_data['max_totalsold'] = trade_data.groupby(['stock_id', 'time_id'])\\\n        ['total_sold'].transform('max')\n    \n    trade_data.drop('total_sold', axis = 1, inplace = True)\n    \n    return trade_data\n    \n\n#trade_train = preprocess_trade(trade_train)\n\nprint('trade_train 新feature建立完畢。等等加入訓練資料作為新特徵。')\ngc.collect()\n\n#trade_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.284757Z","iopub.execute_input":"2021-08-06T06:13:13.285029Z","iopub.status.idle":"2021-08-06T06:13:13.41552Z","shell.execute_reply.started":"2021-08-06T06:13:13.285003Z","shell.execute_reply":"2021-08-06T06:13:13.41445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add more features: \n'''\nadd_feature = trade_train[['stock_id', 'time_id', 'mean_price', \\\n                           'max_price', 'total_trader',\\\n                           'mean_totalsold', 'max_totalsold'\n                          ]]\nadd_feature.drop_duplicates(inplace = True)\ndf_join = df_join.merge(add_feature, on = ['stock_id', 'time_id'],\\\n                       how = 'left')\n\ngc.collect()\n#print(df_join.head())\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.416793Z","iopub.execute_input":"2021-08-06T06:13:13.417056Z","iopub.status.idle":"2021-08-06T06:13:13.423035Z","shell.execute_reply.started":"2021-08-06T06:13:13.417029Z","shell.execute_reply":"2021-08-06T06:13:13.421875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data cleaning: Missing value or Infinite values\n'''\ndf_join.replace([np.inf, -np.inf], np.nan, inplace = True)\n\nprint('缺失值: ')\nprint(df_join.isnull().sum())\n\ndf_join.fillna(method='ffill', inplace = True)\n\nprint('缺失值經過處理後: ')\nprint(df_join.isnull().sum())\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.425794Z","iopub.execute_input":"2021-08-06T06:13:13.426104Z","iopub.status.idle":"2021-08-06T06:13:13.437175Z","shell.execute_reply.started":"2021-08-06T06:13:13.426074Z","shell.execute_reply":"2021-08-06T06:13:13.435873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Save memory: float64 -> float32\ndf_join['realized_vol'], df_join['total_trader'] = df_join['realized_vol'].astype('float32'), df_join['total_trader'].astype('int32')\n\ny = df_join['target']\nx = df_join.drop(['target', 'stock_id', 'time_id'], axis = 1)\ngc.collect()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.438276Z","iopub.execute_input":"2021-08-06T06:13:13.438838Z","iopub.status.idle":"2021-08-06T06:13:13.452068Z","shell.execute_reply.started":"2021-08-06T06:13:13.438801Z","shell.execute_reply":"2021-08-06T06:13:13.451108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build model\n# Candidate regression model: generalized linear model, GBM, ligthgbm, random forest\n# neural net, linear regression\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\n\n\nlr = LinearRegression()\n\nprint('Model configuration 建立完畢')\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:13.454277Z","iopub.execute_input":"2021-08-06T06:13:13.454691Z","iopub.status.idle":"2021-08-06T06:13:14.106206Z","shell.execute_reply.started":"2021-08-06T06:13:13.454646Z","shell.execute_reply":"2021-08-06T06:13:14.105105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndf_join.reset_index(drop = True, inplace = True)\nx.reset_index(drop = True, inplace = True)\ny.reset_index(drop = True, inplace = True)\nprint('df join: \\n')\nprint(df_join.head())\nprint('X: ')\nprint(x.head())\nprint('Y:')\nprint(y.head())\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.107482Z","iopub.execute_input":"2021-08-06T06:13:14.1078Z","iopub.status.idle":"2021-08-06T06:13:14.113404Z","shell.execute_reply.started":"2021-08-06T06:13:14.107768Z","shell.execute_reply":"2021-08-06T06:13:14.112436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split model into train/validation set\n\"\"\"\n# split by time scan: first sort data by time_id\ndf_join.sort_values('time_id', axis = 0, ascending = True, inplace = True)\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import r2_score\n\ntscv = TimeSeriesSplit(n_splits = 5)\ni = 1\n\ntest_size = int(0.2*len(df_join))\nx_train, x_valid = x[0:(len(df_join)-test_size)], x[test_size:]\ny_train, y_valid = y[0:(len(df_join)-test_size)], y[test_size:]\n\ngc.collect()\n\n\nmodel = lgbm\nmodel.fit(x_train, y_train)\n\nmodel_score = r2_score(y_valid, model.predict(x_valid))\nbaseline_score = r2_score(y_valid, x_valid['realized_vol'])\nprint('Split {}'.format(i))\nprint('Model score: {}, Baseline score: {}'.format(model_score, baseline_score))\n\n\"\"\"\n\"\"\"\nfor train_id, valid_id in tscv.split(x):\n    x_train, x_valid = x[train_id], x[valid_id]\n    y_train, y_valid = y[train_id], y[valid_id]\n    \n    lgbm.fit(x_train, y_train)\n    \n    model_score = r2_score(y_valid, lgbm.predict(x_valid))\n    baseline_score = r2_score(y_valid, x_valid['realized_vol'])\n    print('Split {}'.format(i))\n    print('Model score: {}, Baseline score: {}'.format(model_score, baseline_score))\n    \n    del x_train, x_valid, y_train, y_valid\n    gc.collect()\n    \n    i += 1\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.114642Z","iopub.execute_input":"2021-08-06T06:13:14.114931Z","iopub.status.idle":"2021-08-06T06:13:14.126797Z","shell.execute_reply.started":"2021-08-06T06:13:14.114903Z","shell.execute_reply":"2021-08-06T06:13:14.125784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\nprint('RMSPE 定義完畢。')\nprint('計算model metrics: ')\n#R2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\n#RMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\n#print(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.128076Z","iopub.execute_input":"2021-08-06T06:13:14.128373Z","iopub.status.idle":"2021-08-06T06:13:14.143895Z","shell.execute_reply.started":"2021-08-06T06:13:14.128347Z","shell.execute_reply":"2021-08-06T06:13:14.142787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Linear Regression\nlr.fit(x_train, y_train)\n\nmodel = lr\n\nmodel_score = r2_score(y_valid, model.predict(x_valid))\nbaseline_score = r2_score(y_valid, x_valid['realized_vol'])\nprint('LinearRegression 模型表現: ')\nprint('Model score: {}, Baseline score: {}'.format(model_score, baseline_score))\n\nRMSPE = round(rmspe(y_valid, model.predict(x_valid)), 3)\nprint('LR model RMSPE: ', RMSPE)\n\n\n# Decision Tree\nfrom sklearn.tree import DecisionTreeRegressor\n\nforest_params = {\n    'n_estimators':80,\n    'criterion':'mse',\n    'max_depth':20,\n    'random_state':99\n}\nforest = RandomForestRegressor(**forest_params)\n\n%time\nforest.fit(x_train, y_train)\nmodel = forest\n\nmodel_score = r2_score(y_valid, model.predict(x_valid))\nbaseline_score = r2_score(y_valid, x_valid['realized_vol'])\nprint('模型表現: '.format(i))\nprint('Model score: {}, Baseline score: {}'.format(model_score, baseline_score))\n\nRMSPE = round(rmspe(y_valid, forest.predict(x_valid)), 3)\nprint('Forest model RMSPE: ', RMSPE)\n\n\n# LightGBM\nlgb_params = {\n    \"num_leaves\":128,\n    'max_depth':50,\n    'learning_rate':1e-3,\n    'n_estimators':1000,\n    'reg_lambda':0.01,\n    'random_state':99\n}\nlgbm = lgb.LGBMRegressor(**lgb_params)\n\n%time\nlgbm.fit(x_train, y_train)\nmodel = lgbm\n\nmodel_score = r2_score(y_valid, model.predict(x_valid))\nbaseline_score = r2_score(y_valid, x_valid['realized_vol'])\nprint('模型表現: '.format(i))\nprint('Model score: {}, Baseline score: {}'.format(model_score, baseline_score))\n\nRMSPE = round(rmspe(y_valid, model.predict(x_valid)), 3)\nprint('LGBM model RMSPE: ', RMSPE)\n\n# GBM\ngbm_params = {\n    'learning_rate':1e-2,\n    'n_estimators':300,\n    'max_depth':30,\n    'min_samples_leaf':10,\n    'verbose':10\n}\n\ngbm = GradientBoostingRegressor(**gbm_params)\ngbm.fit(x_train, y_train)\nmodel = gbm\n\nmodel_score = r2_score(y_valid, model.predict(x_valid))\nbaseline_score = r2_score(y_valid, x_valid['realized_vol'])\nprint('模型表現: '.format(i))\nprint('Model score: {}, Baseline score: {}'.format(model_score, baseline_score))\n\nRMSPE = round(rmspe(y_valid, model.predict(x_valid)), 3)\nprint('GradientBoostingMachine model RMSPE: ', RMSPE)\n\n# GBM + LR\ngbm_output = gbm.predict(x_train)\n\nlr = LinearRegression()\nlr.fit(gbm_output.reshape(-1, 1), y_train)\nprediction = lr.predict(gbm.predict(x_valid).reshape(-1, 1))\n\nRMSPE = round(rmspe(y_valid, prediction), 3)\nprint('RMSPE for boosting: GBM + LR =  ', RMSPE)\n\nimport pickle\n\nlr.fit(x, y)\nwith open('forest.pickle', 'wb') as file:\n    pickle.dump(forest, file)\n    \ngc.collect()\nlgbm.fit(x, y)\nwith open('lgbm.pickle', 'wb') as file:\n    pickle.dump(lgbm, file)\ngc.collect()\n\ngbm.fit(x, y)\nwith open('gbm.pickle', 'wb') as file:\n    pickle.dump(gbm, file)\n    \nbagging_prediction = gbm.predict(x)\nlr_booster = LinearRegression()\n\nlr_booster.fit(bagging_prediction.reshape(-1, 1), y)\nwith open('lr_booster.pickle', 'wb') as file:\n    pickle.dump(lr_booster, file)\n    \n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.145042Z","iopub.execute_input":"2021-08-06T06:13:14.145432Z","iopub.status.idle":"2021-08-06T06:13:14.158367Z","shell.execute_reply.started":"2021-08-06T06:13:14.145399Z","shell.execute_reply":"2021-08-06T06:13:14.157078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start using test data to make predictions\n'''\norder_book_list = glob.glob('../input/optiver-realized-volatility-prediction/book_test.parquet/*')\ndf_test = generate_realized_vol(list_file=order_book_list, realized_vol_colname='realized_vol')\ngc.collect()\n# df_test contains row_id, realized_vol \n\ntrade_test = pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_test.parquet')\ngc.collect()\ntrade_test = preprocess_trade(trade_test)\ngc.collect()\n\n# Create row_id column\ntrade_test['row_id'] = trade_test['stock_id'].astype(str) + '-' + trade_test['time_id'].astype(str)\ntrade_test.head()\n\n# Aggregate useful features\nadd_feature = trade_test[['row_id', 'mean_price', \\\n                           'max_price', 'total_trader',\\\n                           'mean_totalsold', 'max_totalsold'\n                          ]]\nadd_feature.drop_duplicates(inplace = True)\ndf_test = df_test.merge(add_feature, on = 'row_id',\\\n                       how = 'left')\n\n# Data cleaning: Missing value or Infinite values\ndf_test.replace([np.inf, -np.inf], np.nan, inplace = True)\ndf_test.fillna(method='ffill', inplace = True)\n\ndf_test['realized_vol'], df_test['total_trader'] = df_test['realized_vol'].astype('float32'), df_test['total_trader'].astype('int32')\n\ngc.collect()\nprint('帶預測的資料準備完畢。')\n\nfeatures = ['realized_vol', 'mean_price', 'max_price', 'total_trader', 'mean_totalsold', 'max_totalsold']\ndf_test['target'] = forest.predict(df_test[features])\nsubmission = df_test[['row_id', 'target']]\nsubmission.to_csv('submission.csv', index = False)\n\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.160222Z","iopub.execute_input":"2021-08-06T06:13:14.160909Z","iopub.status.idle":"2021-08-06T06:13:14.172207Z","shell.execute_reply.started":"2021-08-06T06:13:14.160863Z","shell.execute_reply":"2021-08-06T06:13:14.171469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 接續之前的預訓練模型繼續訓練","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport time\nimport gc\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.express as px\n\nfrom IPython import display\nimport sklearn\nimport gc\nimport time\n\ngc.collect()\n\nprint('Library imported.')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.173114Z","iopub.execute_input":"2021-08-06T06:13:14.173495Z","iopub.status.idle":"2021-08-06T06:13:14.30997Z","shell.execute_reply.started":"2021-08-06T06:13:14.173467Z","shell.execute_reply":"2021-08-06T06:13:14.309265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定義整個資料預處理\n\ndef preprocess_trade(trade_data):\n\n    trade_data['mean_price'] = trade_data.groupby(['stock_id', 'time_id'])\\\n         ['price'].transform('mean')\n    \n    trade_data['max_price'] = trade_data.groupby(['stock_id', 'time_id'])\\\n         ['price'].transform('max')\n    # total number of traders in same time_id for each stock_id\n    trade_data['total_trader'] = trade_data.groupby(['stock_id', 'time_id'])\\\n         ['order_count'].transform('sum')\n    # total sold: price * size\n    trade_data['total_sold'] = trade_data['price']*trade_data['size']\n    trade_data['mean_totalsold'] = trade_data.groupby(['stock_id', 'time_id'])\\\n        ['total_sold'].transform('mean')\n    trade_data['max_totalsold'] = trade_data.groupby(['stock_id', 'time_id'])\\\n        ['total_sold'].transform('max')\n    \n    trade_data.drop('total_sold', axis = 1, inplace = True)\n    \n    return trade_data\n    \ndef log_return(list_stock_prices):\n    # Give series of stock price, 計算每時段與下一筆資料間的log return\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    # Give log return, 計算realized volatility\n    return np.sqrt(np.sum(series_log_return**2))\n\n\n# 計算每個stock_id-time_id單位範圍內的realized volatility\ndef compute_realized_vol(file_path, realized_vol_colname):\n    # file_path: \n    # realized_vol:\n    df_book_data = pd.read_parquet(file_path)\n    # 用公式計算order book資料的WAP\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']\n                          +df_book_data['ask_price1'] * df_book_data['bid_size1'])/  \\\n                            (df_book_data['bid_size1'] + \n                             df_book_data['ask_size1'])\n    # 用WAP計算log return\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    # 去除 log return 的NULL值\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    # 用公式計算realized volatility\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':realized_vol_colname})\n    stock_id = file_path.split('=')[1]\n    # 建立新欄位: stock_id-time_id 即每個樣本的index\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',realized_vol_colname]]\n\n\ndef generate_realized_vol(list_file,realized_vol_colname):\n    # Give list of order book files( ../stock_id/filename.parquet), generate realized vol.\n    # and return Dataframe for each stock_id\n    # list_file: list of filepath for multiple stock_id files\n    # realized_vol_colname: column name for calculated realized_vol. value\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     compute_realized_vol(file,realized_vol_colname)])\n    return df_past_realized\n\nimport glob\norder_book_list = glob.glob('../input/optiver-realized-volatility-prediction/book_train.parquet/*')\n\nif os.path.exists('../input/train-processed/train_processed.csv'):\n    df_train = pd.read_csv('../input/train-processed/train_processed.csv')\nelse:\n    df_train = generate_realized_vol(list_file=order_book_list, realized_vol_colname='realized_vol')\n\nprint('必要function已經設定完成')\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:14.310982Z","iopub.execute_input":"2021-08-06T06:13:14.311411Z","iopub.status.idle":"2021-08-06T06:13:15.332958Z","shell.execute_reply.started":"2021-08-06T06:13:14.31138Z","shell.execute_reply":"2021-08-06T06:13:15.332018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:15.33432Z","iopub.execute_input":"2021-08-06T06:13:15.334605Z","iopub.status.idle":"2021-08-06T06:13:15.354704Z","shell.execute_reply.started":"2021-08-06T06:13:15.334577Z","shell.execute_reply":"2021-08-06T06:13:15.353424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start using test data to make predictions\n\n\n# dataframe contains row_id, realized_vol \n'''\ntrade_train = pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet')\ngc.collect()\ntrade_train = preprocess_trade(trade_train)\ngc.collect()\n\n# Create row_id column\ntrade_train['row_id'] = trade_train['stock_id'].astype(str) + '-' + trade_train['time_id'].astype(str)\n\n# Aggregate useful features\nadd_feature = trade_train[['row_id', 'mean_price', \\\n                           'max_price', 'total_trader',\\\n                           'mean_totalsold', 'max_totalsold'\n                          ]]\nadd_feature.drop_duplicates(inplace = True)\n\n\ndf_train = df_train.merge(add_feature, on = 'row_id',\\\n                       how = 'left')\n\nprint(df_train.head())\nstop\n\n# Data cleaning: Missing value or Infinite values\ndf_train.replace([np.inf, -np.inf], np.nan, inplace = True)\ndf_train.fillna(method='ffill', inplace = True)\n\ndf_train['realized_vol'], df_train['total_trader'] = \\\ndf_train['realized_vol'].astype('float32'), df_train['total_trader'].astype('int32')\n\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ndf_train = train.merge(df_train, on = 'row_id',\\\n                       how = 'left')\n\ndf_train.to_csv('train_processed.csv', index = False)\n'''\n\nif os.path.exists('../input/volatiltiy-prediction2/train_processed.csv'):\n\n    print('待預測的資料準備完畢。')\n    \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:15.358877Z","iopub.execute_input":"2021-08-06T06:13:15.359188Z","iopub.status.idle":"2021-08-06T06:13:15.491441Z","shell.execute_reply.started":"2021-08-06T06:13:15.359143Z","shell.execute_reply":"2021-08-06T06:13:15.490244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\nprint('RMSPE 定義完畢。')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:15.493151Z","iopub.execute_input":"2021-08-06T06:13:15.493498Z","iopub.status.idle":"2021-08-06T06:13:15.506012Z","shell.execute_reply.started":"2021-08-06T06:13:15.493464Z","shell.execute_reply":"2021-08-06T06:13:15.504808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\n# Define RMSPE as objective loss function\n# set RMSPE**2 as custom loss\ndef gradient(y_true, y_pred):\n    # gradient for loss function\n    \n    return np.sqrt(-2*np.mean((y_true - y_pred)/y_true))\n\ndef hessian(y_true, y_pred):\n    \n    return (2*np.mean(1/y_true))\n\ndef rmspe_loss(y_true, y_pred):\n    # grad: 1-order derivative for each sample point\n    # hess: 2-order derivative for each sample point\n    grad = gradient(y_true, y_pred)\n    hess = hessian(y_true, y_pred)\n    \n    return grad, hess\n\n\nxgb_params = {\n    \"n_estimators\":300,\n    \"max_depth\":30,\n    \"min_samples_leaf\":10,\n    #\"verbosity\":3,\n    \"learning_rate\":1e-2,\n    \"booster\":\"gbtree\",\n    \"reg_lambda\":0.01,\n    \"random_state\":99\n   # \"objective\":rmspe_loss\n}\nxgbm = xgb.XGBRegressor(**xgb_params)\n\nprint('Model 建議完畢。')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:15.507646Z","iopub.execute_input":"2021-08-06T06:13:15.50806Z","iopub.status.idle":"2021-08-06T06:13:15.601456Z","shell.execute_reply.started":"2021-08-06T06:13:15.508015Z","shell.execute_reply":"2021-08-06T06:13:15.600311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport lightgbm as lgb\nfrom scipy.stats import randint as sp_randint\nfrom sklearn.metrics import make_scorer\n\nmu = 1e-9\n\ndef gradient(y_true, y_pred):\n    # gradient for loss function\n    # y_true: (n_samples)\n    \n    return -2*((y_true - y_pred)/(y_true + mu))\n\ndef hessian(y_true, y_pred):\n    \n    return 2/(y_true + mu)\n\ndef rmspe_loss(y_true, y_pred):\n    # grad: 1-order derivative for each sample point\n    # hess: 2-order derivative for each sample point\n    grad = gradient(y_true, y_pred)\n    hess = hessian(y_true, y_pred)\n    \n    return grad, hess\n\n# lgb parameters for grid search\nlgb_params_grid = {\n    \"num_leaves\":[64, 128, 256, 512],\n    \"min_data_in_leaf\":np.arange(100, 600, 100),\n    'learning_rate':[1e-2, 1e-3, 1e-4],\n    'n_estimators':[1000, 2000, 3000, 5000],\n    'reg_alpha':[0, 0.1, 0.01, 1, 5],\n    'reg_lambda':[0, 0.1, 0.01, 1, 2, 7],\n    'random_state':[99],\n    'silent':[True],\n    'objective':[rmspe_loss],\n    'n_jobs':3\n}\n\nlgb_params = {\n    \"num_leaves\":769,\n    \"min_data_in_leaf\":300,\n    \"n_estimators\":5000,\n    \"learning_rate\":1e-2,\n    \"reg_alpha\":1,\n    \"reg_lambda\":1,\n    \"objective\":rmspe_loss,\n    \"n_jobs\":-1,\n    \"random_state\":99,\n    \"verbosity\":-1,\n    \"max_depth\":3\n}\n\nseed = 99\nparams = {\n        'learning_rate': 0.13572437900113307,        \n        'lambda_l1': 2.154360665259325,\n        'lambda_l2': 6.711089761523827,\n        'num_leaves': 769,\n        'min_sum_hessian_in_leaf': 20.44437160769411,\n        'feature_fraction': 0.7921473067441019,\n        'feature_fraction_bynode': 0.8083803860191322,\n        'bagging_fraction': 0.9726755660563261,\n        'bagging_freq': 42,\n        'min_data_in_leaf': 690,\n        'max_depth': 3,\n        'random_state': seed,\n        'feature_fraction_seed': seed,\n        'bagging_seed': seed,\n        'drop_seed': seed,\n        'data_random_seed': seed,\n        'objective': rmspe_loss,\n        'boosting': 'gbdt',\n        'verbosity': -1,\n        'n_jobs': -1,\n    }\n\n# custom scorer (RMSPE)\ncustom_score = make_scorer(rmspe, greater_is_better = False)\n\n\n\nprint('LGBM Model parameter 搜尋池建立完畢.')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:15.602646Z","iopub.execute_input":"2021-08-06T06:13:15.602902Z","iopub.status.idle":"2021-08-06T06:13:15.617506Z","shell.execute_reply.started":"2021-08-06T06:13:15.602875Z","shell.execute_reply":"2021-08-06T06:13:15.616315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n\n\nlgbm = lgb.LGBMRegressor(**params)\n\n\ny = df_train['target']\nx = df_train[['realized_vol', 'mean_price', 'max_price', \\\n              'total_trader', 'mean_totalsold', 'max_totalsold']]\n\ntime_cv = TimeSeriesSplit(n_splits = 5)\nval_metric = []\n'''\n# hyperparameter tuning\ngrid_search = GridSearchCV(\n    estimator = lgbm,\n    param_grid = lgb_params_grid,\n    cv = time_cv,\n    scoring = custom_score,\n    verbose = 100\n)\n\n\ngrid_search.fit(x, y,\n               #eval_set = [x, y],\n               #eval_metric = rmspe_loss,\n               #eval_names = ['rmspe_metric'],\n               verbose = 1000)\n\n'''\nlr = LinearRegression()\n\nfor train_id, valid_id in time_cv.split(df_train):\n\n    x_train, y_train = x.loc[train_id], y.loc[train_id]\n    x_valid, y_valid = x.loc[valid_id], y.loc[valid_id]\n    \n    print(x_train.shape)\n    print(x_valid.shape)\n\n    lgbm.fit(x_train, y_train,\n             verbose = 500\n            )\n    \n    #lr.fit(lgbm.predict(x_train).reshape(-1, 1), y_train) # LR model boosting\n    # Calculate performance metric\n    \n    RMSPE = rmspe(y_valid, lgbm.predict(x_valid))\n    \n    val_metric.append(RMSPE)\n    print('RMSPE metric: ', RMSPE)\n    \n\nprint('Mean validate metric: ', np.mean(val_metric))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:13:15.620337Z","iopub.execute_input":"2021-08-06T06:13:15.620635Z","iopub.status.idle":"2021-08-06T06:13:21.21783Z","shell.execute_reply.started":"2021-08-06T06:13:15.620597Z","shell.execute_reply":"2021-08-06T06:13:21.216766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom sklearn.linear_model import LinearRegression\n\nlgbm2 = lgb.LGBMRegressor(**lgb_params)\n\nlr = LinearRegression()\n\nfor train_id, valid_id in time_cv.split(df_train):\n\n    x_train, y_train = x.loc[train_id], y.loc[train_id]\n    x_valid, y_valid = x.loc[valid_id], y.loc[valid_id]\n    \n    print(x_train.shape)\n    print(x_valid.shape)\n\n    lgbm2.fit(x_train, y_train,\n             verbose = 500\n            )\n    \n    lr.fit(lgbm2.predict(x_train).reshape(-1, 1), y_train) # LR model boosting\n    \n    # Calculate performance metric\n    lgb_pred = lgbm2.predict(x_valid)\n    lr_pred = lr.predict(lgb_pred.reshape(-1, 1))\n    RMSPE = rmspe(y_valid, lr_pred)\n    val_metric.append(RMSPE)\n    print('RMSPE metric: ', RMSPE)\n    \n\nprint('Mean validate metric: ', np.mean(val_metric))\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:15:34.274837Z","iopub.execute_input":"2021-08-06T06:15:34.275236Z","iopub.status.idle":"2021-08-06T06:15:34.280586Z","shell.execute_reply.started":"2021-08-06T06:15:34.275195Z","shell.execute_reply":"2021-08-06T06:15:34.279861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n# save best model as output\nwith open('lgbm_best_param.pickle', 'wb') as file:\n    pickle.dump(lgbm, file)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:15:01.807841Z","iopub.execute_input":"2021-08-06T06:15:01.808294Z","iopub.status.idle":"2021-08-06T06:15:01.820518Z","shell.execute_reply.started":"2021-08-06T06:15:01.808248Z","shell.execute_reply":"2021-08-06T06:15:01.81941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LGBM performance for: num_leaves=128,n_estimators = 1500, l2_loss => val_RMSPE = 0.4447 \n#### LGBM performance for: num_leaves=128,n_estimators = 1500, rmspe**2 loss => val_RMSPE = 0.3047","metadata":{}},{"cell_type":"code","source":"'''\nRMSPE = rmspe(y_train, lgbm.predict(x_train))\nprint('Training performance RMSPE:', RMSPE)\n\nlgb.plot_metric(lgbm)\nplt.title('LGBM leaning curve:')\n'''","metadata":{"execution":{"iopub.status.busy":"2021-08-06T06:15:20.241116Z","iopub.execute_input":"2021-08-06T06:15:20.241502Z","iopub.status.idle":"2021-08-06T06:15:20.247633Z","shell.execute_reply.started":"2021-08-06T06:15:20.241468Z","shell.execute_reply":"2021-08-06T06:15:20.246554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}