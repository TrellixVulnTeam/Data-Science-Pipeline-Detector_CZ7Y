{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob\nfrom tqdm import tqdm\nfrom numba import njit, jit\n\n\ndef rmspe(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\ndef weighted_average_price(df, N=1):\n    if N==1:\n        return (df.bid_price1 * df.ask_size1 + df.bid_size1 * df.ask_price1) / (df.bid_size1 + df.ask_size1)\n    elif N==2:\n        return (df.bid_price2 * df.ask_size2 + df.bid_size2 * df.ask_price2) / (df.bid_size2 + df.ask_size2)\n    else:\n        assert False, 'Super duper sumo!'\n\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff()\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2021-09-23T13:59:12.484765Z","iopub.execute_input":"2021-09-23T13:59:12.485097Z","iopub.status.idle":"2021-09-23T13:59:12.495939Z","shell.execute_reply.started":"2021-09-23T13:59:12.485066Z","shell.execute_reply":"2021-09-23T13:59:12.494852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aggregation by per stock per time-id Explanation\n\n- The book table must be aggregated to calculate the `realized_volatility`, also to have the same aggregation level as the submission file.\n- When aggregating, we lose the row level data for all columns.\n- To reduce loss of information, we add a few statistical functions for each column.\n- The feature dictionary below defines which statistical aggregation we will use for each column from book table.","metadata":{}},{"cell_type":"code","source":"base_agg = [np.mean, np.std]\n\nfeature_dictionary = {\n    'bid_price1': base_agg,\n    'bid_price2': base_agg,\n    'ask_price1': base_agg,\n    'ask_price2': base_agg,\n    'bid_size1': base_agg,\n    'bid_size2': base_agg,\n    'ask_size1': base_agg,\n    'ask_size2': base_agg,\n    'wap1': base_agg,\n    'wap2': base_agg,\n    'log_return1': base_agg + [realized_volatility],\n    'log_return2': base_agg + [realized_volatility]\n}\n\n\ndef calculate_features(file_list):\n    lst = []\n    # read the training data file for book\n    for g in tqdm(file_list):\n        df = pd.read_parquet(g)\n        # calculate wap and add as a column\n        df['wap1'] = weighted_average_price(df)\n        df['wap2'] = weighted_average_price(df, N=2)\n        # calculate log-return and add as a column\n        df['log_return1'] = log_return(df.wap1)\n        df['log_return2'] = log_return(df.wap2)\n        # remove null values created from 'diff' and log\n        df = df[~df.log_return1.isnull()]\n\n        # calculate aggregation; rv=realized_volatility\n        rv_per_stock_timeid = df.groupby('time_id').agg(feature_dictionary)\n        # groupby with multiple aggregations create multi-index columns\n        # flatten them\n        rv_per_stock_timeid.columns = ['-'.join(x) for x in rv_per_stock_timeid.columns]\n        # add row-id\n        rv_per_stock_timeid['row_id'] = [f'{g.split(\"=\")[-1]}-{time_id}' for time_id in rv_per_stock_timeid.index]\n        # drop the index which is time-id\n        rv_per_stock_timeid.reset_index(drop=True, inplace=True)\n\n        lst.append(rv_per_stock_timeid)\n\n    return pd.concat(lst)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T14:19:29.424008Z","iopub.execute_input":"2021-09-23T14:19:29.424277Z","iopub.status.idle":"2021-09-23T14:19:29.436831Z","shell.execute_reply.started":"2021-09-23T14:19:29.42425Z","shell.execute_reply":"2021-09-23T14:19:29.435819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rv_per_stock_timeid = calculate_features(\n    glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Training Target Values","metadata":{}},{"cell_type":"code","source":"%%time\n# get the target values; cast type since we don't need the ids to be floats\ntarget = pd.read_csv(\n    '../input/optiver-realized-volatility-prediction/train.csv',\n    dtype={'stock_id':str, 'time_id':str, 'target':float}\n)\n# create row_id\ntarget['row_id'] = [f'{r.stock_id}-{r.time_id}' for _,r in target.iterrows()]\n# keep only the necessary columns\ntarget = target.loc[:,['row_id','target']]","metadata":{"execution":{"iopub.status.busy":"2021-09-23T14:05:29.547212Z","iopub.execute_input":"2021-09-23T14:05:29.547474Z","iopub.status.idle":"2021-09-23T14:05:56.93639Z","shell.execute_reply.started":"2021-09-23T14:05:29.547446Z","shell.execute_reply":"2021-09-23T14:05:56.935154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xy dataframe is the merged result of the features dataframe and target dataframe\nxy = rv_per_stock_timeid.merge(\n    right = target,\n    how = 'left',\n    on = 'row_id'\n)\nprint(xy.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T14:05:56.940406Z","iopub.execute_input":"2021-09-23T14:05:56.94096Z","iopub.status.idle":"2021-09-23T14:05:57.514522Z","shell.execute_reply.started":"2021-09-23T14:05:56.940925Z","shell.execute_reply":"2021-09-23T14:05:57.513373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xy.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T13:57:56.987933Z","iopub.status.idle":"2021-09-23T13:57:56.988299Z","shell.execute_reply.started":"2021-09-23T13:57:56.98811Z","shell.execute_reply":"2021-09-23T13:57:56.988138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building, Evaluation and Prediction","metadata":{}},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"xtrain, xtest, ytrain, ytest = train_test_split(\n    xy.loc[:,[c for c in xy.columns if c not in ['row_id','target']]],\n    xy.target,\n    test_size=0.1,\n    random_state=42\n)\nprint(len(xtrain), len(xtest))\n\nmdl = LGBMRegressor(random_state=42)\nmdl.fit(xtrain, ytrain)\nprint('rmspe:', rmspe(ytest, mdl.predict(xtest)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T14:16:35.563337Z","iopub.execute_input":"2021-09-23T14:16:35.563713Z","iopub.status.idle":"2021-09-23T14:16:39.668441Z","shell.execute_reply.started":"2021-09-23T14:16:35.563682Z","shell.execute_reply":"2021-09-23T14:16:39.667439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"list_order_book_file_test = glob('/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*')\nprint(len(list_order_book_file_test))\nsub = calculate_features(list_order_book_file_test)\nfeats = sub.loc[:,[c for c in sub.columns if c not in ['row_id','target']]]\npred = mdl.predict(feats)\nresult = pd.DataFrame({\n    'row_id': sub.row_id,\n    'target': pred\n})\nresult.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T14:24:02.965978Z","iopub.execute_input":"2021-09-23T14:24:02.966346Z","iopub.status.idle":"2021-09-23T14:24:03.02145Z","shell.execute_reply.started":"2021-09-23T14:24:02.966311Z","shell.execute_reply":"2021-09-23T14:24:03.020718Z"},"trusted":true},"execution_count":null,"outputs":[]}]}