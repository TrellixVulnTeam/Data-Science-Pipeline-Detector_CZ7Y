{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport pickle\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport random\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-18T13:05:30.931958Z","iopub.execute_input":"2021-08-18T13:05:30.932559Z","iopub.status.idle":"2021-08-18T13:05:32.327717Z","shell.execute_reply.started":"2021-08-18T13:05:30.932472Z","shell.execute_reply":"2021-08-18T13:05:32.326729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(s):\n    random.seed(s)\n    np.random.seed(s)\n    torch.manual_seed(s)\n    torch.cuda.manual_seed_all(s)\n    torch.cuda.manual_seed(s)\n    torch.backends.cudnn.deterministic=True\n    \nseed_everything(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:05:32.329391Z","iopub.execute_input":"2021-08-18T13:05:32.32966Z","iopub.status.idle":"2021-08-18T13:05:32.338817Z","shell.execute_reply.started":"2021-08-18T13:05:32.329635Z","shell.execute_reply":"2021-08-18T13:05:32.337986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset Modified : \nhttps://www.kaggle.com/narendra/optiver-features-dataset/log?scriptVersionId=71337174\n\n\n1. Version:9 --> Added Penalization loss for the Negative outputs\n2. Version:10 --> Added Featuers for individual Buckets & Made TimeSlices: 30 seconds\n3. Version : 13 --> Added std features for price movements.\n4. Version : 24 --> Added rv1, rv2 to the dataset","metadata":{}},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:05:32.343082Z","iopub.execute_input":"2021-08-18T13:05:32.34361Z","iopub.status.idle":"2021-08-18T13:05:32.351624Z","shell.execute_reply.started":"2021-08-18T13:05:32.343569Z","shell.execute_reply":"2021-08-18T13:05:32.350757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain=pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain_features=pd.read_pickle('../input/optiverdataset/features.pkl')\ntrain=train.merge(train_features)\n\ndel train_features\ngc.collect()\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:05:32.353057Z","iopub.execute_input":"2021-08-18T13:05:32.353613Z","iopub.status.idle":"2021-08-18T13:05:37.632963Z","shell.execute_reply.started":"2021-08-18T13:05:32.353579Z","shell.execute_reply":"2021-08-18T13:05:37.631995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:05:37.634326Z","iopub.execute_input":"2021-08-18T13:05:37.634616Z","iopub.status.idle":"2021-08-18T13:05:37.640152Z","shell.execute_reply.started":"2021-08-18T13:05:37.634588Z","shell.execute_reply":"2021-08-18T13:05:37.639444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONFIG","metadata":{}},{"cell_type":"code","source":"class config:\n    num_buckets= 20\n    num_features= 26\n    epochs=30","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:05:37.641187Z","iopub.execute_input":"2021-08-18T13:05:37.641633Z","iopub.status.idle":"2021-08-18T13:05:37.654057Z","shell.execute_reply.started":"2021-08-18T13:05:37.6416Z","shell.execute_reply":"2021-08-18T13:05:37.653175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class OptiverDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.df=df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row=self.df.iloc[idx]\n        bucket_num=row.bucket_num\n        bucket_features=row.bucket_features\n        \n        X=torch.zeros((config.num_buckets, config.num_features), dtype=torch.float32)\n        y=row.target\n        for i, bucket_id in enumerate(bucket_num):\n            X[bucket_id] = torch.tensor(bucket_features[i], dtype=torch.float32)\n        y=torch.tensor(y, dtype=torch.float32)\n        Xmax, _=torch.max(X, dim=0)\n        Xmax=Xmax.view(1, -1)\n        Xmax[Xmax==0]=1\n        X_norm=X*(1/Xmax)\n        return (X_norm, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:50.032969Z","iopub.execute_input":"2021-08-18T13:07:50.033355Z","iopub.status.idle":"2021-08-18T13:07:50.042012Z","shell.execute_reply.started":"2021-08-18T13:07:50.033322Z","shell.execute_reply":"2021-08-18T13:07:50.041237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self, sz):\n        super().__init__()\n        self.linear=nn.Linear(sz, sz)\n        self.bn=nn.BatchNorm1d(sz)\n        self.silu=nn.SiLU()\n        self.dropout=nn.Dropout(0.1)\n        \n    def forward(self, x):\n        x=self.bn(x)\n        x=self.silu(x)\n        x=self.dropout(x)\n        x=self.linear(x)\n        \n        return x\n    \nclass OptiverModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        hsize=150\n        self.pre_bn=nn.BatchNorm1d(config.num_buckets , config.num_features)\n        self.gru=nn.GRU(config.num_features, hsize, 2, batch_first=True, dropout=0.1)\n        \n        self.ffn1=FFN(hsize)\n        self.ffn2=FFN(hsize)\n        self.out=nn.Linear(hsize, 1)\n        \n    def forward(self, x):\n        x=self.pre_bn(x)\n        _, h=self.gru(x)\n        h=h[1].squeeze(0)\n        \n        y=self.ffn1(h)\n        y=self.ffn2(h)\n        \n        yout=self.out(y)\n        yout=yout.view(-1)\n        return y, yout","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:59.298145Z","iopub.execute_input":"2021-08-18T13:07:59.298472Z","iopub.status.idle":"2021-08-18T13:07:59.308983Z","shell.execute_reply.started":"2021-08-18T13:07:59.298445Z","shell.execute_reply":"2021-08-18T13:07:59.308287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=OptiverModel()\nmodel=model.to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:59.327957Z","iopub.execute_input":"2021-08-18T13:07:59.328601Z","iopub.status.idle":"2021-08-18T13:07:59.338632Z","shell.execute_reply.started":"2021-08-18T13:07:59.328567Z","shell.execute_reply":"2021-08-18T13:07:59.337544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:59.340049Z","iopub.execute_input":"2021-08-18T13:07:59.340369Z","iopub.status.idle":"2021-08-18T13:07:59.430508Z","shell.execute_reply.started":"2021-08-18T13:07:59.340341Z","shell.execute_reply":"2021-08-18T13:07:59.429468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_idx=train.sample(frac=0.8, random_state=20).index\nval_idx=train[~train.index.isin(train_idx)].index\n\nprint(len(train_idx), len(val_idx))\n\ntrain_df=train[train.index.isin(train_idx)].copy()\nval_df=train[train.index.isin(val_idx)].copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:59.431798Z","iopub.execute_input":"2021-08-18T13:07:59.432074Z","iopub.status.idle":"2021-08-18T13:07:59.705272Z","shell.execute_reply.started":"2021-08-18T13:07:59.432049Z","shell.execute_reply":"2021-08-18T13:07:59.704213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset=OptiverDataset(train_df)\nval_dataset=OptiverDataset(val_df)\n\n\ntrain_dataloader=torch.utils.data.DataLoader(train_dataset,\n                                             batch_size=512,\n                                             shuffle=True,\n                                             drop_last=True,\n                                             pin_memory=True)\n\nval_dataloader=torch.utils.data.DataLoader(val_dataset,\n                                           batch_size=2048,\n                                           shuffle=False,\n                                           drop_last=False)\n\nprint(len(train_dataloader), len(val_dataloader))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:59.707258Z","iopub.execute_input":"2021-08-18T13:07:59.707663Z","iopub.status.idle":"2021-08-18T13:07:59.714975Z","shell.execute_reply.started":"2021-08-18T13:07:59.707612Z","shell.execute_reply":"2021-08-18T13:07:59.71385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Losses","metadata":{}},{"cell_type":"code","source":"def MSE(y, yhat):\n    yerr=y-yhat\n    yerr=torch.square(yerr)\n    return yerr.mean()\n\ndef RMSE(y, yhat):\n    return torch.sqrt( torch.mean((y-yhat)**2) )\n\ndef RMSPE(y, yhat):\n    err=(y-yhat)\n    err/=y\n    err=torch.square(err)\n    return torch.sqrt( torch.mean(err) )","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:07:59.716389Z","iopub.execute_input":"2021-08-18T13:07:59.7167Z","iopub.status.idle":"2021-08-18T13:07:59.725979Z","shell.execute_reply.started":"2021-08-18T13:07:59.716663Z","shell.execute_reply":"2021-08-18T13:07:59.724935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, epochs, model, train_dataloader, val_dataloader):\n        self.epochs=epochs\n        self.model=model\n        self.train_dataloader=train_dataloader\n        self.val_dataloader=val_dataloader\n        \n        self.optimizer=torch.optim.AdamW(model.parameters(), lr=7e-5, weight_decay=1e-5)\n        self.schedular=torch.optim.lr_scheduler.OneCycleLR(self.optimizer, \n                                                           max_lr=7e-5,\n                                                           epochs=self.epochs,\n                                                           steps_per_epoch=len(train_dataloader))\n        \n        self.best_rmse=None\n        self.best_rmspe=None\n    \n    def evaluate(self):\n        ytrue=[]\n        ypred=[]\n        for X, y in self.val_dataloader:\n            X=X.to(device)\n            with torch.no_grad():\n                _, yhat=self.model(X)\n                yhat=yhat.detach().cpu().tolist()\n                ypred+=yhat\n                ytrue+=y.cpu().tolist()\n        \n        ytrue=torch.tensor(ytrue)\n        ypred=torch.tensor(ypred)\n        eval_rmse=RMSE(ytrue, ypred)\n        eval_rmspe=RMSPE(ytrue, ypred)\n        return (eval_rmse.item(), eval_rmspe.item())\n    \n    def train_ops(self, X, y):\n        _,yhat =self.model(X)\n        rmse_loss=RMSE(y, yhat)\n        rmspe_loss=RMSPE(y.detach(), yhat.detach())\n        \n        self.optimizer.zero_grad()\n        rmse_loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n        self.optimizer.step()\n        self.schedular.step()\n        \n        return (rmse_loss.item(), rmspe_loss.item())\n                \n    def train(self):\n        for e in range(self.epochs):\n            train_epoch_rmse=[]\n            train_epoch_rmspe=[]\n            \n            self.model.train()\n            for i, (X,y) in enumerate(self.train_dataloader):\n                X=X.to(device)\n                y=y.to(device)\n                \n                rmse_loss, rmspe_loss=self.train_ops(X, y)\n                train_epoch_rmse.append(rmse_loss)\n                train_epoch_rmspe.append(rmspe_loss)\n                \n            (eval_rmse, eval_rmspe) = self.evaluate()\n\n            if (self.best_rmse is None) or (self.best_rmse > eval_rmse):\n                torch.save(self.model, 'best_rmse.pt')\n            if (self.best_rmspe is None) or (self.best_rmspe > eval_rmspe):\n                torch.save(self.model, 'best_rmspe.pt')\n\n            print(\"epoch:{} - Train RMSE Loss:{:.4f} | Train RMSPE Loss:{:.4f}\".format(e, np.mean(train_epoch_rmse),\n                                                                                       np.mean(train_epoch_rmspe)))\n            print(\"Val RMSE:{:.4f} | Val RMSPE:{:.4f}\".format(eval_rmse, eval_rmspe))\n        \n    \n    def lr_range_test(self):\n        min_lr=1e-6\n        max_lr=1e-3\n        optimizer=torch.optim.AdamW(self.model.parameters(), lr=min_lr, weight_decay=1e-5)\n        scheduler=torch.optim.lr_scheduler.StepLR(optimizer, 1, 1.02)\n        \n        losses=[]\n        lrs=[]\n        self.model.train()\n        for _ in range(50):\n            for i, (X, y) in enumerate(self.train_dataloader):\n                optimizer.zero_grad()\n                _, yhat=self.model(X)\n                mse_loss=RMSE(y, yhat)\n                \n                loss=mse_loss\n                loss.backward()\n\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n                optimizer.step()\n                scheduler.step()\n\n                losses.append(loss.item())\n                lrs.append(scheduler.get_last_lr()[0])\n\n                if i%10==0:\n                    print(i, '-->', lrs[-1], losses[-1])\n                if lrs[-1] > max_lr:\n                    break\n            if lrs[-1] > max_lr:\n                break\n        return lrs, losses","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:24:15.087078Z","iopub.execute_input":"2021-08-18T13:24:15.087661Z","iopub.status.idle":"2021-08-18T13:24:15.114099Z","shell.execute_reply.started":"2021-08-18T13:24:15.087609Z","shell.execute_reply":"2021-08-18T13:24:15.113261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel=OptiverModel()\nmodel=model.to(device)\n\n\ntrainer=Trainer(config.epochs, model, train_dataloader, val_dataloader)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:24:18.93027Z","iopub.execute_input":"2021-08-18T13:24:18.930629Z","iopub.status.idle":"2021-08-18T14:20:28.120963Z","shell.execute_reply.started":"2021-08-18T13:24:18.930602Z","shell.execute_reply":"2021-08-18T14:20:28.120177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model=OptiverModel()\n#print(model)\n#trainer=Trainer(5, model, train_dataloader, val_dataloader)\n#lrs, losses=trainer.lr_range_test()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:23:56.756003Z","iopub.execute_input":"2021-08-18T13:23:56.756413Z","iopub.status.idle":"2021-08-18T13:23:56.760473Z","shell.execute_reply.started":"2021-08-18T13:23:56.756377Z","shell.execute_reply":"2021-08-18T13:23:56.759436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lmt=390\n#plt.plot(lrs[:lmt], losses[:lmt])\n#plt.xticks(rotation=45)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T13:23:49.874213Z","iopub.execute_input":"2021-08-18T13:23:49.87456Z","iopub.status.idle":"2021-08-18T13:23:49.88132Z","shell.execute_reply.started":"2021-08-18T13:23:49.874531Z","shell.execute_reply":"2021-08-18T13:23:49.88033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}