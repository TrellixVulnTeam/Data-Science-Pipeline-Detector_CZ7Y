{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport pickle\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport random\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nprint(torch.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T08:26:09.311465Z","iopub.execute_input":"2021-09-02T08:26:09.311899Z","iopub.status.idle":"2021-09-02T08:26:11.330131Z","shell.execute_reply.started":"2021-09-02T08:26:09.311791Z","shell.execute_reply":"2021-09-02T08:26:11.328841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_TPU=False\n\nif USE_TPU:\n    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n\n\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp   \n    import torch_xla.debug.metrics as met\n\n    device=xm.xla_device()\nelse:\n    device=torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:26:11.331401Z","iopub.execute_input":"2021-09-02T08:26:11.331645Z","iopub.status.idle":"2021-09-02T08:26:11.341265Z","shell.execute_reply.started":"2021-09-02T08:26:11.33162Z","shell.execute_reply":"2021-09-02T08:26:11.339986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(s):\n    random.seed(s)\n    np.random.seed(s)\n    torch.manual_seed(s)\n    torch.cuda.manual_seed_all(s)\n    torch.cuda.manual_seed(s)\n    torch.backends.cudnn.deterministic=True\n    \nseed_everything(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:26:11.343554Z","iopub.execute_input":"2021-09-02T08:26:11.344034Z","iopub.status.idle":"2021-09-02T08:26:11.354659Z","shell.execute_reply.started":"2021-09-02T08:26:11.343994Z","shell.execute_reply":"2021-09-02T08:26:11.353786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef load_numpy(filename):\n    folder_path=\"../input/optiverdatasetmultitaskwitharrays\"\n    data_path=os.path.join(folder_path, filename)\n    arr=np.load(data_path)\n    return arr\nbucket=load_numpy('bucket.npy')\nfeatures=load_numpy('features.npy')\ntarget=load_numpy('target.npy')\n\nprint(bucket.shape)\nprint(features.shape)\nprint(target.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:26:11.356196Z","iopub.execute_input":"2021-09-02T08:26:11.356478Z","iopub.status.idle":"2021-09-02T08:27:00.985761Z","shell.execute_reply.started":"2021-09-02T08:26:11.356453Z","shell.execute_reply":"2021-09-02T08:27:00.984615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    num_buckets= 60\n    num_features= 28\n    batch_size=128\n    epochs=10","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:00.987186Z","iopub.execute_input":"2021-09-02T08:27:00.987472Z","iopub.status.idle":"2021-09-02T08:27:00.991023Z","shell.execute_reply.started":"2021-09-02T08:27:00.987442Z","shell.execute_reply":"2021-09-02T08:27:00.990391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class OptiverDataset(torch.utils.data.Dataset):\n    def __init__(self, indices, bucket, features, target):\n        self.indices=indices\n        self.bucket=bucket\n        self.features=features\n        self.target=target\n        \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        i=self.indices[idx]\n        \n        bucket_num=self.bucket[i]\n        bucket_features=self.features[i]\n        y=self.target[i]\n        \n        X=torch.zeros((config.num_buckets, config.num_features), dtype=torch.float32)\n        ywap1=torch.zeros((config.num_buckets, 1), dtype=torch.float32)\n        ybid1=torch.zeros((config.num_buckets, 1), dtype=torch.float32)\n        yask1=torch.zeros((config.num_buckets, 1), dtype=torch.float32)\n        \n        \n        for i, bucket_id in enumerate(bucket_num):\n            X[bucket_id] = torch.tensor(bucket_features[i], dtype=torch.float32)\n            \n            ybid1[bucket_id] = torch.tensor( bucket_features[i][0], dtype=torch.float32)\n            yask1[bucket_id] = torch.tensor( bucket_features[i][1], dtype=torch.float32)\n            ywap1[bucket_id]=torch.tensor( bucket_features[i][19], dtype=torch.float32)\n\n        y=torch.tensor(y, dtype=torch.float32)\n        return {\n            'X': X,\n            'yprimary': y,\n            'ybid1': ybid1,\n            'yask1': yask1,\n            'ywap1': ywap1\n        }","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:00.99202Z","iopub.execute_input":"2021-09-02T08:27:00.99243Z","iopub.status.idle":"2021-09-02T08:27:01.005856Z","shell.execute_reply.started":"2021-09-02T08:27:00.992403Z","shell.execute_reply":"2021-09-02T08:27:01.005162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(0)\nindices=np.arange(bucket.shape[0])\nrandom.shuffle(indices)\n\ntrain_idx=indices[:int(len(indices) * 0.8)]\nvalid_idx=indices[int(len(indices) * 0.8):]","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.006683Z","iopub.execute_input":"2021-09-02T08:27:01.007068Z","iopub.status.idle":"2021-09-02T08:27:01.432849Z","shell.execute_reply.started":"2021-09-02T08:27:01.007041Z","shell.execute_reply":"2021-09-02T08:27:01.431828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset=OptiverDataset(train_idx, bucket, features, target)\nvalid_dataset=OptiverDataset(valid_idx, bucket, features, target)\n\n\ntrain_dataloader=torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=128,\n    shuffle=True,\n    drop_last=True,\n    pin_memory=True,\n    num_workers=2\n)\n\nvalid_dataloader=torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=128,\n    shuffle=False,\n    drop_last=False,\n    pin_memory=True,\n    num_workers=0\n)\n\nprint(len(train_dataloader), len(valid_dataloader))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.435218Z","iopub.execute_input":"2021-09-02T08:27:01.435492Z","iopub.status.idle":"2021-09-02T08:27:01.441981Z","shell.execute_reply.started":"2021-09-02T08:27:01.435465Z","shell.execute_reply":"2021-09-02T08:27:01.440989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_activation_fn(activation):\n    if activation=='gelu':\n        return nn.GELU()\n    elif activation=='relu':\n        return nn.ReLU()\n    \ndef attention(query, key, value, dropout=None):\n    d_k=query.size(-1)\n    scores=torch.matmul( query, key.transpose(-1, -2) )/np.sqrt(d_k)\n    scores=torch.tril(scores)\n    scores=scores.masked_fill(scores == 0, -1e9)\n    p_attn=torch.softmax(scores, dim=-1)\n    \n    x_attn=torch.matmul(p_attn, value)\n    \n    if dropout:\n        x_attn=dropout(x_attn)\n    return p_attn, x_attn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, dmodel, nhead,activation,norm,dropout):\n        super().__init__()\n        self.dmodel=dmodel\n        self.nhead=nhead\n        self.d_k=dmodel//nhead #Size\n        \n        self.activation=activation\n        self.norm=norm\n        self.dropout=dropout\n        \n        self.Q=nn.Linear(dmodel, dmodel)\n        self.K=nn.Linear(dmodel, dmodel)\n        self.V=nn.Linear(dmodel, dmodel)\n        self.W=nn.Linear(dmodel, dmodel)\n        \n    def forward(self, x):\n        bsize=x.size(0)\n        query=self.Q(x).view(bsize, -1, self.nhead, self.d_k)\n        key=self.K(x).view(bsize, -1, self.nhead, self.d_k)\n        value=self.V(x).view(bsize, -1, self.nhead, self.d_k)\n        \n        p_attn, x_attn=attention(query, key, value, self.dropout)\n        x_attn=x_attn.view(bsize, -1, self.nhead*self.d_k)\n        x_attn=self.W(x_attn)\n        x=self.norm(x+x_attn)\n        return x\n\nclass TimeSeriesAttentionLayer(nn.Module):\n    def __init__(self,\n                 dmodel=128,\n                 nhead=4,\n                 dim_feed_forward=512,\n                 activation='gelu', \n                 dropout=0.1):\n        \n        super().__init__()\n        self.dmodel=dmodel\n        self.nhead=nhead\n        self.dim_feed_forward=dim_feed_forward\n        self.activation=get_activation_fn(activation)\n        self.norm=nn.LayerNorm(dmodel)\n        self.dropout=nn.Dropout(dropout)\n        \n        self.multihead_attn=MultiHeadAttention(dmodel,\n                                               nhead,\n                                               self.activation,\n                                               self.norm,\n                                               self.dropout)\n        \n        self.linear1=nn.Linear(dmodel, dim_feed_forward)\n        self.linear2=nn.Linear(dim_feed_forward, dmodel)\n        \n    def forward(self, x):\n        x=self.multihead_attn(x)\n        x_ffn=self.linear2(self.dropout(self.activation(self.linear1(x))))\n        x=self.norm(x+x_ffn)\n        return x\n\nclass FeatureExtractor(nn.Module):\n    def __init__(self, sz):\n        super().__init__()\n        self.pre_bn=nn.BatchNorm1d(config.num_buckets , config.num_features)\n        \n        self.linear1=nn.Linear(config.num_features, 2*sz)\n        self.bn1=nn.BatchNorm1d(config.num_buckets, 2*sz)\n        \n        self.linear2=nn.Linear(2*sz, sz)\n        self.bn2=nn.BatchNorm1d(config.num_buckets, sz)\n        \n        self.dropout=nn.Dropout(0.2)\n        self.activation=nn.GELU()\n    def forward(self, x):\n        x=self.pre_bn(x)\n        x=self.dropout( self.bn1( self.activation(self.linear1(x)) ) )\n        x=self.dropout( self.bn2( self.activation(self.linear2(x)) ) )\n        return x\n    \n    \nclass FeatureExtractorWith1DConv(nn.Module):\n    def __init__(self, sz):\n        super().__init__()\n        self.pre_bn=nn.BatchNorm1d(config.num_buckets , config.num_features)\n        \n        self.conv1=nn.Conv1d(config.num_features, sz, 3, padding=1)\n        self.bn1=nn.BatchNorm1d(config.num_buckets, sz)\n        \n        \n        self.conv2=nn.Conv1d(sz, sz, 3, padding=1)\n        self.bn2=nn.BatchNorm1d(config.num_buckets, sz)\n        \n        self.activation=nn.ReLU()\n        \n    def forward(self, x):\n        x=self.pre_bn(x)\n        x=self.activation( self.bn1( self.conv1(x.transpose(1, 2)).transpose(1, 2) ))\n        #x=self.activation( self.bn2( self.conv2(x.transpose(1, 2)).transpose(1, 2) ))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.443243Z","iopub.execute_input":"2021-09-02T08:27:01.443495Z","iopub.status.idle":"2021-09-02T08:27:01.565209Z","shell.execute_reply.started":"2021-09-02T08:27:01.443471Z","shell.execute_reply":"2021-09-02T08:27:01.564098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Auxilary_FFN(nn.Module):\n    def __init__(self, sz):\n        super().__init__()\n        self.linear=nn.Linear(sz, sz)\n        self.bn=nn.BatchNorm1d(config.num_buckets , sz)\n        self.activation=nn.GELU()\n        self.dropout=nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x=self.bn(x)\n        x=self.activation(x)\n        x=self.dropout(x)\n        x=self.linear(x)\n        return x\n\n\nclass FFN(nn.Module):\n    def __init__(self, sz):\n        super().__init__()\n        self.linear=nn.Linear(sz, sz)\n        self.bn=nn.BatchNorm1d(sz)\n        self.activation=nn.GELU()\n        self.dropout=nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x=self.bn(x)\n        x=self.activation(x)\n        x=self.dropout(x)\n        x=self.linear(x)    \n        return x\n\n\nclass AttentionHead(nn.Module):\n    def __init__(self, dmodel, dropout):\n        super().__init__()\n        self.dropout=dropout\n        self.W=nn.Linear(dmodel, 1)\n    def forward(self, x):\n        scores=self.W(x).squeeze(-1)\n        p_attn=torch.softmax(scores, dim=-1)\n        \n        if self.dropout:\n            p_attn=self.dropout(p_attn)\n        x_attn=torch.matmul(p_attn, x)\n        x_attn=x_attn.sum(dim=1)\n        return p_attn, x_attn","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.566468Z","iopub.execute_input":"2021-09-02T08:27:01.566739Z","iopub.status.idle":"2021-09-02T08:27:01.580911Z","shell.execute_reply.started":"2021-09-02T08:27:01.566712Z","shell.execute_reply":"2021-09-02T08:27:01.579858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PrimaryHead(nn.Module):\n    def __init__(self, hsize):\n        super().__init__()\n        self.hsize=hsize\n        self.attn_dropout=nn.Dropout(0.1)\n        self.attn_head=AttentionHead(hsize, self.attn_dropout)\n        self.ffn=nn.ModuleList(\n            [FFN(hsize) for _ in range(3)]\n        )\n        self.primary_out=nn.Linear(hsize, 1)\n        \n    def forward(self, x):\n        p_attn, x=self.attn_head(x)\n        for i, _ in enumerate(self.ffn):\n            if i==0:\n                continue\n            x=self.ffn[i](x + self.ffn[i-1](x))\n        y=self.primary_out(x)\n        return p_attn, y\n\nclass AuxilaryHead(nn.Module):\n    def __init__(self, hsize):\n        super().__init__()\n        self.hsize=hsize\n        self.ffn=nn.ModuleList(\n            [Auxilary_FFN(hsize) for _ in range(3)]\n        )\n        self.aux_out=nn.Linear(hsize, 1)\n    def forward(self, x):\n        for i, _ in enumerate(self.ffn):\n            if i==0:\n                continue\n            x=self.ffn[i](x + self.ffn[i-1](x))\n        y=self.aux_out(x)\n        return y","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.582374Z","iopub.execute_input":"2021-09-02T08:27:01.58265Z","iopub.status.idle":"2021-09-02T08:27:01.596708Z","shell.execute_reply.started":"2021-09-02T08:27:01.582621Z","shell.execute_reply":"2021-09-02T08:27:01.595683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OptiverModel(nn.Module):\n    def __init__(self, model_size=128):\n        super().__init__()\n        self.model_size=model_size\n        self.feature_extractor=FeatureExtractorWith1DConv(model_size)\n        self.pos_embeddings=nn.Embedding(config.num_buckets, model_size, max_norm=1)\n        self.positions=torch.arange(config.num_buckets, dtype=torch.long).to(device)\n        self.attn_layers=nn.ModuleList([TimeSeriesAttentionLayer() for _ in range(5)])\n        \n        self.primary_model=PrimaryHead(model_size)\n        self.auxilary_ask1=AuxilaryHead(model_size)\n        self.auxilary_bid1=AuxilaryHead(model_size)\n        self.auxilary_wap1=AuxilaryHead(model_size)\n        \n    def forward(self, x):\n        x=self.feature_extractor(x)\n        x=x+(self.pos_embeddings(self.positions).unsqueeze(0)/np.sqrt(self.model_size))\n        for attn_layer in self.attn_layers:\n            x=attn_layer(x)\n            \n        p_attn, yprimary=self.primary_model(x)\n        yaux_ask1=self.auxilary_ask1(x)\n        yaux_bid1=self.auxilary_bid1(x)\n        yaux_wap1=self.auxilary_wap1(x)\n        \n        return {\n            'p_attn': p_attn,\n            'yprimary': yprimary,\n            'yask1': yaux_ask1,\n            'ybid1': yaux_bid1,\n            'ywap1': yaux_wap1\n        }","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.598011Z","iopub.execute_input":"2021-09-02T08:27:01.598263Z","iopub.status.idle":"2021-09-02T08:27:01.612803Z","shell.execute_reply.started":"2021-09-02T08:27:01.598237Z","shell.execute_reply":"2021-09-02T08:27:01.611891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# custom losses","metadata":{}},{"cell_type":"code","source":"class CustomLosses:\n    @staticmethod\n    def MSE(y, yhat):\n        yerr=y-yhat\n        yerr=torch.square(yerr)\n        return yerr.mean()\n\n    @staticmethod\n    def RMSE(y, yhat):\n        err=(y-yhat)\n        return torch.sqrt( torch.mean(err**2) )\n\n    @staticmethod\n    def RMSPE(y, yhat):\n        err=(y-yhat)\n        err/=y\n        err=torch.square(err)\n        return torch.sqrt( torch.mean(err) )\n\n    \n    @staticmethod\n    def get_auxilary_loss(y, yhat):\n        y=y[:, 1:config.num_buckets].squeeze(-1)\n        yhat=yhat[:, 0: config.num_buckets-1].squeeze(-1)\n\n        #Validating only the last 20 time-steps\n        y=y[:, -20:]\n        yhat=yhat[:, -20:]\n\n        yerr=100 * (y - yhat)/y\n        yerr=torch.square(yerr).view(-1).mean()\n        yerr=torch.sqrt(yerr)\n        return yerr","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.613829Z","iopub.execute_input":"2021-09-02T08:27:01.6141Z","iopub.status.idle":"2021-09-02T08:27:01.627724Z","shell.execute_reply.started":"2021-09-02T08:27:01.614073Z","shell.execute_reply":"2021-09-02T08:27:01.626715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainer","metadata":{}},{"cell_type":"code","source":"class Evaluator:\n    def __init__(self, model, val_dataloader):\n        self.model=model\n        self.dataloader=val_dataloader\n        \n    def evaluate(self):\n        self.model.eval()\n        print(\"Evaluating\")\n        yprimary_true=[]; yprimary_pred=[]\n        for batchid, data in enumerate(self.dataloader):\n            if batchid%300 == 0:\n                print(batchid)\n            (X, yprimary, _, _, _)=(data['X'], data['yprimary'],data['yask1'], data['ybid1'], data['ywap1'])\n            X=X.to(device)\n            yprimary_true+=yprimary.cpu().tolist()\n            with torch.no_grad():\n                outputs=model(X)\n                yprimary_pred+=outputs['yprimary'].view(-1).cpu().tolist()\n        \n        yprimary_true=torch.tensor(yprimary_true, dtype=torch.float32)\n        yprimary_pred=torch.tensor(yprimary_pred, dtype=torch.float32)\n        \n        rmse_loss=CustomLosses.RMSE(yprimary_true, yprimary_pred)\n        rmspe_loss=CustomLosses.RMSPE(yprimary_true, yprimary_pred)\n        return (rmse_loss.item(), rmspe_loss.item())\n        \nclass Trainer:\n    def __init__(self, model, train_dataloader, val_dataloader,\n                 optimizer, schedular=None):\n        self.best_rmse=None\n        self.best_rmspe=None\n        self.evaluator=Evaluator(model, val_dataloader)\n        \n        self.train_dataloader=train_dataloader\n        self.val_dataloader=val_dataloader\n        \n        self.model=model\n        self.optimizer=optimizer\n        self.schedular=schedular\n    \n    def train_ops(self, data):\n        self.model.train()\n        (X, yprimary, yask1, ybid1, ywap1)=(data['X'], data['yprimary'],data['yask1'], data['ybid1'], data['ywap1'])\n        X=X.to(device)\n        \n        yprimary=yprimary.to(device)\n        yask1=yask1.to(device)\n        ybid1=ybid1.to(device)\n        ywap1=ywap1.to(device)\n        \n        outputs=self.model(X)\n        \n        \n        rmse_loss=CustomLosses.RMSE(yprimary, outputs['yprimary'].view(-1))\n        rmspe_loss=CustomLosses.RMSPE(yprimary, outputs['yprimary'].view(-1))\n        \n        ask1_loss=CustomLosses.get_auxilary_loss(yask1, outputs['yask1'])\n        bid1_loss=CustomLosses.get_auxilary_loss(ybid1, outputs['ybid1'])\n        wap1_loss=CustomLosses.get_auxilary_loss(ywap1, outputs['ywap1'])\n        \n        self.optimizer.zero_grad(set_to_none=True)\n        loss= (0.7 * rmspe_loss) + (0.3*(ask1_loss + bid1_loss+wap1_loss)/3)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n        self.optimizer.step()\n        \n        del outputs\n        if self.schedular:\n            self.schedular.step()\n            \n        return {\n            'loss': loss.item(),\n            'rmse_loss': rmse_loss.item(),\n            'rmspe_loss': rmspe_loss.item(),\n            'ask1_loss': ask1_loss.item(),\n            'bid1_loss': bid1_loss.item(),\n            'wap1_loss': wap1_loss.item()\n        }\n                \n    def train(self):\n        for e in range(config.epochs):\n            train_loss=[]\n            train_rmse_loss=[];train_rmspe_loss=[];train_bid1_loss=[]\n            train_ask1_loss=[]; train_wap1_loss=[];\n            \n            self.model.train()\n            for i, data in enumerate(self.train_dataloader):\n                losses=self.train_ops(data)\n                \n                loss=losses['loss']\n                rmse_loss=losses['rmse_loss']\n                rmspe_loss=losses['rmspe_loss']\n                \n                ask1_loss=losses['ask1_loss']\n                bid1_loss=losses['bid1_loss']\n                wap1_loss=losses['wap1_loss']\n                \n                if i%300==0:\n                    print(\"Iteration:{}|Loss:{:.3f}|RMSE:{:.3f}|RMSPE:{:.3f}\".format(i, loss, rmse_loss, rmspe_loss))\n                    print(\"ask1:{:.3f}|bid1:{:.3f}|wap1:{:.3f}\".format(ask1_loss, bid1_loss, wap1_loss))\n                \n                del losses\n                train_loss.append(loss)\n                train_rmse_loss.append(rmse_loss)\n                train_rmspe_loss.append(rmspe_loss)\n                \n                train_bid1_loss.append(bid1_loss)\n                train_ask1_loss.append(ask1_loss)\n                train_wap1_loss.append(wap1_loss)\n            \n            (eval_rmse, eval_rmspe) = self.evaluator.evaluate()\n            if (self.best_rmse is None) or (self.best_rmse > eval_rmse):\n                self.best_rmse=eval_rmse\n                torch.save(self.model, 'best_rmse.pt')\n            if (self.best_rmspe is None) or (self.best_rmspe > eval_rmspe):\n                self.best_rmspe=eval_rmspe\n                torch.save(self.model, 'best_rmspe.pt')\n\n            print()\n            print()\n            print(\"***************End of Epoch{}***************\".format(e))\n            print(\"epoch:{}-LOSS:{:.4f}|RMSE Loss:{:.4f} |RMSPE Loss:{:.4f}\".format(e,np.mean(train_loss),\n                                                                                    np.mean(train_rmse_loss),\n                                                                                    np.mean(train_rmspe_loss)))\n            \n            print(\"Train BID1:{:.4f} | Train ASK1:{:.4f} | Train WAP1:{:.4f}\".format(np.mean(train_bid1_loss),\n                                                                                     np.mean(train_ask1_loss),\n                                                                                     np.mean(train_wap1_loss)))\n            print(\"Val RMSE:{:.4f} | Val RMSPE:{:.4f}\".format(eval_rmse, eval_rmspe))\n    \n    def lr_range_test(self):\n        min_lr=5e-7\n        max_lr=1e-3\n        optimizer=torch.optim.AdamW(self.model.parameters(), lr=min_lr, weight_decay=1e-5)\n        scheduler=torch.optim.lr_scheduler.StepLR(optimizer, 1, 1.03)\n        \n        losses=[]\n        lrs=[]\n        self.model.train()\n        for _ in range(50):\n            for i, data in enumerate(self.train_dataloader):\n                (X, yprimary, yask1, ybid1, ywap1)=(data['X'], data['yprimary'],data['yask1'], data['ybid1'], data['ywap1'])\n                \n                outputs=self.model(X)\n                rmse_loss=CustomLosses.RMSE(yprimary, outputs['yprimary'])\n                rmspe_loss=CustomLosses.RMSPE(yprimary, outputs['yprimary'])\n\n                ask1_loss=CustomLosses.get_auxilary_loss(yask1, outputs['yask1'])\n                bid1_loss=CustomLosses.get_auxilary_loss(ybid1, outputs['ybid1'])\n                wap1_loss=CustomLosses.get_auxilary_loss(ywap1, outputs['ywap1'])\n\n                #loss=(rmspe_loss + (ask1_loss + bid1_loss+wap1_loss)/3)/2\n                \n                loss= (0.7 * rmspe_loss) + (0.3*(ask1_loss + bid1_loss+wap1_loss)/3)\n                \n                optimizer.zero_grad()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n                optimizer.step()\n                scheduler.step()\n\n                losses.append(loss.item())\n                lrs.append(scheduler.get_last_lr()[0])\n\n                if i%10==0:\n                    print(i, '-->', lrs[-1], losses[-1])\n                if lrs[-1] > max_lr:\n                    break\n            if lrs[-1] > max_lr:\n                break\n        return lrs, losses","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.629076Z","iopub.execute_input":"2021-09-02T08:27:01.629324Z","iopub.status.idle":"2021-09-02T08:27:01.655331Z","shell.execute_reply.started":"2021-09-02T08:27:01.629299Z","shell.execute_reply":"2021-09-02T08:27:01.654612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=OptiverModel()\nmodel=model.to(device)\n\n\nmax_lr=4.2e-4\noptimizer=torch.optim.AdamW(model.parameters(), lr=max_lr)\nschedular=torch.optim.lr_scheduler.OneCycleLR(optimizer,\n                                              max_lr=max_lr,\n                                              pct_start=0.1,\n                                              steps_per_epoch=len(train_dataloader),\n                                              epochs=config.epochs,\n                                              final_div_factor=1e3)\n\ntrainer=Trainer(model, train_dataloader, valid_dataloader, optimizer, schedular)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.656454Z","iopub.execute_input":"2021-09-02T08:27:01.656696Z","iopub.status.idle":"2021-09-02T08:27:01.742958Z","shell.execute_reply.started":"2021-09-02T08:27:01.656671Z","shell.execute_reply":"2021-09-02T08:27:01.74222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainer=Trainer(model, train_dataloader, valid_dataloader, optimizer, schedular)\n#lrs, losses=trainer.lr_range_test()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:27:01.743896Z","iopub.execute_input":"2021-09-02T08:27:01.744255Z","iopub.status.idle":"2021-09-02T08:32:07.287143Z","shell.execute_reply.started":"2021-09-02T08:27:01.744229Z","shell.execute_reply":"2021-09-02T08:32:07.286046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lmt=250\n#plt.plot(lrs[:lmt], losses[:lmt])","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:49:18.124392Z","iopub.execute_input":"2021-09-02T08:49:18.125057Z","iopub.status.idle":"2021-09-02T08:49:18.270195Z","shell.execute_reply.started":"2021-09-02T08:49:18.125007Z","shell.execute_reply":"2021-09-02T08:49:18.269523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}