{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:20.071718Z","iopub.execute_input":"2021-08-31T01:15:20.072165Z","iopub.status.idle":"2021-08-31T01:15:21.860589Z","shell.execute_reply.started":"2021-08-31T01:15:20.072071Z","shell.execute_reply":"2021-08-31T01:15:21.859561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking the first row of data, it implies that the realized vol of the **target bucket** for time_id 5, stock_id 0 is 0.004136. How does the book and trade data in **feature bucket** look like for us to build signals?","metadata":{}},{"cell_type":"code","source":"book_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')\ntrade_example =  pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:21.861974Z","iopub.execute_input":"2021-08-31T01:15:21.862286Z","iopub.status.idle":"2021-08-31T01:15:22.47595Z","shell.execute_reply.started":"2021-08-31T01:15:21.862255Z","shell.execute_reply":"2021-08-31T01:15:22.475195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**book data snapshot**","metadata":{}},{"cell_type":"code","source":"book_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:22.477654Z","iopub.execute_input":"2021-08-31T01:15:22.478231Z","iopub.status.idle":"2021-08-31T01:15:22.497331Z","shell.execute_reply.started":"2021-08-31T01:15:22.478194Z","shell.execute_reply":"2021-08-31T01:15:22.496268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**trade date snapshot**","metadata":{}},{"cell_type":"code","source":"trade_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:22.499057Z","iopub.execute_input":"2021-08-31T01:15:22.499389Z","iopub.status.idle":"2021-08-31T01:15:22.513944Z","shell.execute_reply.started":"2021-08-31T01:15:22.499356Z","shell.execute_reply":"2021-08-31T01:15:22.512563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Realized volatility calculation in python**","metadata":{}},{"cell_type":"markdown","source":"In this competition, our target is to predict short-term realized volatility. Although the order book and trade data for the target cannot be shared, we can still present the realized volatility calculation using the feature data we provided. \n\nAs realized volatility is a statistical measure of price changes on a given stock, to calculate the price change we first need to have a stock valuation at the fixed interval (1 second). We will use weighted averaged price, or WAP, of the order book data we provided.","metadata":{}},{"cell_type":"code","source":"book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) / (\n                                       book_example['bid_size1']+ book_example['ask_size1'])","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:22.516213Z","iopub.execute_input":"2021-08-31T01:15:22.517038Z","iopub.status.idle":"2021-08-31T01:15:22.528421Z","shell.execute_reply.started":"2021-08-31T01:15:22.516978Z","shell.execute_reply":"2021-08-31T01:15:22.527428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The WAP of the stock is plotted below**","metadata":{}},{"cell_type":"code","source":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"wap\", title='WAP of stock_id_0, time_id_5')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:22.530141Z","iopub.execute_input":"2021-08-31T01:15:22.531004Z","iopub.status.idle":"2021-08-31T01:15:23.718614Z","shell.execute_reply.started":"2021-08-31T01:15:22.530928Z","shell.execute_reply":"2021-08-31T01:15:23.717598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To compute the log return, we can simply take **the logarithm of the ratio** between two consecutive **WAP**. The first row will have an empty return as the previous book update is unknown, therefore the empty return data point will be dropped.","metadata":{}},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() ","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:23.720079Z","iopub.execute_input":"2021-08-31T01:15:23.720626Z","iopub.status.idle":"2021-08-31T01:15:23.725836Z","shell.execute_reply.started":"2021-08-31T01:15:23.720581Z","shell.execute_reply":"2021-08-31T01:15:23.724917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"book_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example = book_example[~book_example['log_return'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:23.728326Z","iopub.execute_input":"2021-08-31T01:15:23.728629Z","iopub.status.idle":"2021-08-31T01:15:23.744289Z","shell.execute_reply.started":"2021-08-31T01:15:23.728599Z","shell.execute_reply":"2021-08-31T01:15:23.743198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's plot the tick-to-tick return of this instrument over this time bucket**","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:01:53.679074Z","iopub.execute_input":"2021-06-09T15:01:53.679605Z","iopub.status.idle":"2021-06-09T15:01:53.686279Z","shell.execute_reply.started":"2021-06-09T15:01:53.67957Z","shell.execute_reply":"2021-06-09T15:01:53.684738Z"}}},{"cell_type":"code","source":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"log_return\", title='Log return of stock_id_0, time_id_5')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:23.746355Z","iopub.execute_input":"2021-08-31T01:15:23.74704Z","iopub.status.idle":"2021-08-31T01:15:23.835784Z","shell.execute_reply.started":"2021-08-31T01:15:23.746991Z","shell.execute_reply":"2021-08-31T01:15:23.834616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The realized vol of stock 0 in this feature bucket, will be:","metadata":{}},{"cell_type":"code","source":"def realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:23.837298Z","iopub.execute_input":"2021-08-31T01:15:23.837768Z","iopub.status.idle":"2021-08-31T01:15:23.845721Z","shell.execute_reply.started":"2021-08-31T01:15:23.837723Z","shell.execute_reply":"2021-08-31T01:15:23.844438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive prediction: using past realized volatility as target","metadata":{}},{"cell_type":"markdown","source":"A commonly known fact about volatility is that it tends to be autocorrelated. We can use this property to implement a naive model that just \"predicts\" realized volatility by using whatever the realized volatility was in the initial 10 minutes.\n\nLet's calculate the past realized volatility across the training set to see how predictive a single naive signal can be.","metadata":{}},{"cell_type":"code","source":"import os\nfrom sklearn.metrics import r2_score\nimport glob\nlist_order_book_file_train = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:23.847376Z","iopub.execute_input":"2021-08-31T01:15:23.848002Z","iopub.status.idle":"2021-08-31T01:15:24.703439Z","shell.execute_reply.started":"2021-08-31T01:15:23.847953Z","shell.execute_reply":"2021-08-31T01:15:24.702622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the data is partitioned by stock_id in this competition to allow Kagglers better manage the memory, we try to calculcate realized volatility stock by stock and combine them into one submission file. Note that the stock id as the partition column is not present if we load the single file so we will remedy that manually. We will reuse the log return and realized volatility functions defined in the previous session.","metadata":{}},{"cell_type":"code","source":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:24.704526Z","iopub.execute_input":"2021-08-31T01:15:24.704972Z","iopub.status.idle":"2021-08-31T01:15:24.713264Z","shell.execute_reply.started":"2021-08-31T01:15:24.704935Z","shell.execute_reply":"2021-08-31T01:15:24.71218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looping through each individual stocks, we can get the past realized volatility as prediction for each individual stocks.","metadata":{}},{"cell_type":"code","source":"def past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\ndf_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:15:24.714572Z","iopub.execute_input":"2021-08-31T01:15:24.714939Z","iopub.status.idle":"2021-08-31T01:22:31.899786Z","shell.execute_reply.started":"2021-08-31T01:15:24.714908Z","shell.execute_reply":"2021-08-31T01:22:31.899021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's join the output dataframe with train.csv to see the performance of the naive prediction on training set.","metadata":{}},{"cell_type":"code","source":"train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\ndf_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:22:31.901359Z","iopub.execute_input":"2021-08-31T01:22:31.902025Z","iopub.status.idle":"2021-08-31T01:22:33.630027Z","shell.execute_reply.started":"2021-08-31T01:22:31.901976Z","shell.execute_reply":"2021-08-31T01:22:33.62893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will evaluate the naive prediction result by two metrics: RMSPE and R squared. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\nR2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nRMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:22:33.631369Z","iopub.execute_input":"2021-08-31T01:22:33.631681Z","iopub.status.idle":"2021-08-31T01:22:33.652012Z","shell.execute_reply.started":"2021-08-31T01:22:33.631652Z","shell.execute_reply":"2021-08-31T01:22:33.650779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The performance of the naive model is not amazing but as a benchmark it is a reasonable start.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"As a last step, we will make a submission via the tutorial notebook -- through a file written to output folder.  The naive submission scored a RMSPE 0.327 on public LB, the room of improvement is big for sure!","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:25:51.891717Z","iopub.execute_input":"2021-06-09T15:25:51.89209Z","iopub.status.idle":"2021-06-09T15:25:51.898582Z","shell.execute_reply.started":"2021-06-09T15:25:51.892059Z","shell.execute_reply":"2021-06-09T15:25:51.89729Z"}}},{"cell_type":"code","source":"list_order_book_file_test = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*')\ndf_naive_pred_test = past_realized_volatility_per_stock(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target')\ndf_naive_pred_test.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:22:33.653373Z","iopub.execute_input":"2021-08-31T01:22:33.653724Z","iopub.status.idle":"2021-08-31T01:22:33.687156Z","shell.execute_reply.started":"2021-08-31T01:22:33.653692Z","shell.execute_reply":"2021-08-31T01:22:33.686238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that in this competition, there will be only few rows of test data that can be downloaded. The actual evaluation program will run in background after you commit the notebook and manually submit the output. Please check to [code requirement](https://www.kaggle.com/c/optiver-realized-volatility-prediction/overview/code-requirements) for more explanation.","metadata":{}},{"cell_type":"markdown","source":"The private leaderboard will be built against the real market data collected after the training period, therefore the public and private leaderboard data will have zero overlap. It will be exciting to get your model tested against the live market! As this competition will provide a very rich dataset representing market microstructure, there is unlimited amount of signals one can come up with. It is all on you, good luck! We at Optiver are really looking forward to learn from the talented Kaggle community!\n\nIf you have any question about this notebook or the financial concepts behind it, feel free to ask in the comment section and we will make sure your questions get answered. \n\nGood luck!","metadata":{}}]}