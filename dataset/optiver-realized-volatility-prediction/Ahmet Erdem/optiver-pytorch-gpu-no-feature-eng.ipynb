{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nfrom tqdm import tqdm\nimport sys, os\n\n\ndef load_data(mode, path=\"/kaggle/input/optiver-realized-volatility-prediction\"):\n    # mode = \"train\"/\"test\"\n    file_name = f'{path}/{mode}.csv'\n    return pd.read_csv(file_name)\n\ndf = load_data(\"test\")\nprint(df.shape, df[\"stock_id\"].max())\ndf.head()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.126427,"end_time":"2021-07-30T08:16:41.737453","exception":false,"start_time":"2021-07-30T08:16:41.611026","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:49.82354Z","iopub.execute_input":"2021-08-27T17:45:49.823871Z","iopub.status.idle":"2021-08-27T17:45:49.945707Z","shell.execute_reply.started":"2021-08-27T17:45:49.823796Z","shell.execute_reply":"2021-08-27T17:45:49.94473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SCALE = 100\nPATH = \"/kaggle/input/optiver-realized-volatility-prediction\"\n\norder_book_paths = glob.glob(f'{PATH}/book_test.parquet/*/*')\nlen(order_book_paths)","metadata":{"papermill":{"duration":0.028649,"end_time":"2021-07-30T08:16:41.774614","exception":false,"start_time":"2021-07-30T08:16:41.745965","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:49.947189Z","iopub.execute_input":"2021-08-27T17:45:49.947567Z","iopub.status.idle":"2021-08-27T17:45:49.96236Z","shell.execute_reply.started":"2021-08-27T17:45:49.94753Z","shell.execute_reply":"2021-08-27T17:45:49.961534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trade_paths = glob.glob(f'{PATH}/trade_test.parquet/*/*')\nlen(trade_paths)","metadata":{"papermill":{"duration":0.024934,"end_time":"2021-07-30T08:16:41.807671","exception":false,"start_time":"2021-07-30T08:16:41.782737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:49.964133Z","iopub.execute_input":"2021-08-27T17:45:49.964502Z","iopub.status.idle":"2021-08-27T17:45:49.976161Z","shell.execute_reply.started":"2021-08-27T17:45:49.964463Z","shell.execute_reply":"2021-08-27T17:45:49.975261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_books = dict()\n\n\nfor path in tqdm(order_book_paths):\n    stock_id = int(path.split(\"=\")[1].split(\"/\")[0])\n    book_df = pd.read_parquet(path)\n    books_by_time = dict()\n    \n    for time_id in book_df.time_id.unique():\n        books_by_time[time_id] = book_df[book_df[\"time_id\"] == time_id].reset_index(drop=True)\n    \n    order_books[stock_id] = books_by_time","metadata":{"papermill":{"duration":0.134884,"end_time":"2021-07-30T08:16:41.951492","exception":false,"start_time":"2021-07-30T08:16:41.816608","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:49.977802Z","iopub.execute_input":"2021-08-27T17:45:49.978133Z","iopub.status.idle":"2021-08-27T17:45:50.113836Z","shell.execute_reply.started":"2021-08-27T17:45:49.978098Z","shell.execute_reply":"2021-08-27T17:45:50.113042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trades = dict()\n\n\nfor path in tqdm(trade_paths):\n    stock_id = int(path.split(\"=\")[1].split(\"/\")[0])\n    trade_df = pd.read_parquet(path)\n    trade_by_time = dict()\n    \n    for time_id in trade_df.time_id.unique():\n        trade_by_time[time_id] = trade_df[trade_df[\"time_id\"] == time_id].reset_index(drop=True)\n    \n    trades[stock_id] = trade_by_time","metadata":{"papermill":{"duration":0.030291,"end_time":"2021-07-30T08:16:41.992509","exception":false,"start_time":"2021-07-30T08:16:41.962218","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:50.115042Z","iopub.execute_input":"2021-08-27T17:45:50.115618Z","iopub.status.idle":"2021-08-27T17:45:50.135247Z","shell.execute_reply.started":"2021-08-27T17:45:50.115581Z","shell.execute_reply":"2021-08-27T17:45:50.134467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\n\nmeans_order = torch.FloatTensor([  0.9997,   1.0003, 769.9902, 766.7346,   0.9995,   1.0005, 959.3417,\n        928.2203, 300])\nstds_order = torch.FloatTensor([3.6881e-03, 3.6871e-03, 5.3541e+03, 4.9549e+03, 3.7009e-03, 3.6991e-03,\n        6.6838e+03, 5.7353e+03, 300])\n\nmeans_trade = torch.FloatTensor([300, 1.0, 100, 3.0])\nstds_trade = torch.FloatTensor([300, 0.004, 153, 3.5])\n\n\n\nclass OptiverDataset(Dataset):\n    \n    def __init__(self, df, aug=False):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.aug = aug\n        self.seq_len = 600\n        self.order_features = ['bid_price1', 'ask_price1', 'bid_size1', 'ask_size1','bid_price2', \n                         'ask_price2', 'bid_size2', 'ask_size2', \"seconds_in_bucket\"]\n        self.trade_features = [\"seconds_in_bucket\", \"price\", \"size\", \"order_count\"]\n        \n    \n    def extract_features(self, data_dict, stock_id, time_id, features, means, stds):\n        X = -torch.ones((self.seq_len, len(features)))\n        try:\n            df = data_dict[stock_id][time_id]\n            feature_array = df[features].values\n            X[-feature_array.shape[0]:] = (torch.FloatTensor(feature_array) - means)/stds\n        except:\n            pass\n        return X\n\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        X1 = self.extract_features(order_books, row.stock_id, row.time_id, self.order_features,\n                                  means_order, stds_order)\n        try:\n            X2 = self.extract_features(trades, row.stock_id, row.time_id, self.trade_features,\n                                      means_trade, stds_trade) \n        except:\n            X2 = -torch.ones((self.seq_len, len(self.trade_features)))\n        target = torch.FloatTensor([0.0])\n        stock = torch.LongTensor([row.stock_id])\n        return X1, X2, stock, target\n\n    def __len__(self):\n        return self.df.shape[0]\n    \nds = OptiverDataset(df)\nds[1]","metadata":{"papermill":{"duration":1.217517,"end_time":"2021-07-30T08:16:43.221329","exception":false,"start_time":"2021-07-30T08:16:42.003812","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:50.136529Z","iopub.execute_input":"2021-08-27T17:45:50.13705Z","iopub.status.idle":"2021-08-27T17:45:51.306287Z","shell.execute_reply.started":"2021-08-27T17:45:50.137013Z","shell.execute_reply":"2021-08-27T17:45:51.305528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_dim, out_dim, kernel_size, stride=1):\n        super().__init__()\n        self.lin = nn.Conv1d(in_dim, out_dim, kernel_size, stride=stride)\n        self.bn = nn.BatchNorm1d(out_dim)\n        self.activation = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.lin(x)\n        x = self.bn(x)\n        return self.activation(x)\n        \n\nclass SubModel(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.convs1 = nn.Sequential(ConvBlock(in_dim, 16, 3),\n                                   ConvBlock(16, 32, 3))\n        self.stock_conv = ConvBlock(36, 64, 4, stride=4)\n        self.avg_pool = nn.AdaptiveAvgPool1d(8)\n        self.max_pool = nn.AdaptiveMaxPool1d(8)\n        self.convs2 = nn.Sequential(ConvBlock(128, 128, 2, stride=2),\n                                    ConvBlock(128, 32, 2, stride=2),\n                                    ConvBlock(32, 8, 2, stride=2))\n        \n    def forward(self, x, s):\n        x = self.convs1(x.transpose(2, 1))\n        x = self.stock_conv(torch.cat([x, s.repeat(1, 1, x.shape[2])], axis=1))\n        x = torch.cat([self.avg_pool(x), self.max_pool(x)], axis=1)\n        x = self.convs2(x).squeeze(-1)\n        return x\n    \n    \nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.order_model = SubModel(in_dim=9)\n        self.trade_model = SubModel(in_dim=4)\n        self.top = nn.Linear(16, 1)\n        self.stock_emb = nn.Embedding(127, 4)\n        \n    def forward(self, inputs):\n        x1, x2, s = inputs\n        s = self.stock_emb(s).transpose(2, 1)\n        \n        x1 = self.order_model(x1, s)\n        x2 = self.trade_model(x2, s)\n        x = self.top(torch.cat([x1, x2], axis=1))\n        return x\n    \n    \n","metadata":{"papermill":{"duration":4.3122,"end_time":"2021-07-30T08:16:47.544376","exception":false,"start_time":"2021-07-30T08:16:43.232176","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:45:51.309118Z","iopub.execute_input":"2021-08-27T17:45:51.309378Z","iopub.status.idle":"2021-08-27T17:45:51.322319Z","shell.execute_reply.started":"2021-08-27T17:45:51.309351Z","shell.execute_reply":"2021-08-27T17:45:51.321571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\ndef inference(model, loader, num_folds=5):\n    model.eval()\n    \n    tbar = tqdm(loader, file=sys.stdout)\n    \n    preds = []\n    \n    model_weights = {i: torch.load(f\"/kaggle/input/optiver-nn/optiver_nn_v01_{i}.pth\") for i in range(num_folds)}\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            model.load_state_dict(model_weights[0])\n            pred = model(inputs)/num_folds\n            for i in range(1, num_folds):\n                model.load_state_dict(model_weights[i])\n                pred += model(inputs)/num_folds\n\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(preds)\n\nNW = 4\nBS = 256\nloader = DataLoader(ds, batch_size=BS, shuffle=False, num_workers=NW, pin_memory=False, drop_last=False)\n\n\nmodel = Model()\nmodel = model.cuda()\n\ny = inference(model, loader)","metadata":{"papermill":{"duration":0.960826,"end_time":"2021-07-30T08:16:48.516543","exception":false,"start_time":"2021-07-30T08:16:47.555717","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:48:12.510885Z","iopub.execute_input":"2021-08-27T17:48:12.511209Z","iopub.status.idle":"2021-08-27T17:48:18.081548Z","shell.execute_reply.started":"2021-08-27T17:48:12.51118Z","shell.execute_reply":"2021-08-27T17:48:18.080139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"target\"] = np.clip(y, 0.0, None)/SCALE\n\ndf.to_csv(\"submission.csv\", index=False, columns=[\"row_id\", \"target\"])","metadata":{"papermill":{"duration":0.025102,"end_time":"2021-07-30T08:16:48.554062","exception":false,"start_time":"2021-07-30T08:16:48.52896","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:48:18.08343Z","iopub.execute_input":"2021-08-27T17:48:18.083791Z","iopub.status.idle":"2021-08-27T17:48:18.096588Z","shell.execute_reply.started":"2021-08-27T17:48:18.083751Z","shell.execute_reply":"2021-08-27T17:48:18.095573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"papermill":{"duration":0.011578,"end_time":"2021-07-30T08:16:48.57795","exception":false,"start_time":"2021-07-30T08:16:48.566372","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T17:48:18.099811Z","iopub.execute_input":"2021-08-27T17:48:18.100074Z","iopub.status.idle":"2021-08-27T17:48:18.115378Z","shell.execute_reply.started":"2021-08-27T17:48:18.100047Z","shell.execute_reply":"2021-08-27T17:48:18.114493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Required functions for training\n\n1 fold takes 1 hour on a laptop with Nvidia Quadro RTX 5000.","metadata":{}},{"cell_type":"code","source":"def adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 10:\n        lr = 1e-3\n    elif epoch < 27:\n        lr = 1e-4\n    else:\n        lr = 1e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n    \ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer\n\ndef rmspe(y_true, y_pred):\n    y_pred = np.clip(y_pred, 0, None)\n    return (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\n\ndef loss_func(y_pred, y_true):\n    return torch.mean(torch.square((y_true - y_pred) / y_true))\n\n\ndef validate(model, val_loader):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            pred = model(inputs)\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)\n\n\n\ndef train(model, train_loader, val_loader, epochs):\n    \n    optimizer = get_optimizer(model)\n    \n    for e in range(epochs):\n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        \n        lr = adjust_lr(optimizer, e)\n        \n        loss_list = []\n        preds = []\n        labels = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            optimizer.zero_grad()\n            pred = model(inputs)\n\n            loss = loss_func(pred, target)\n            loss.backward()\n            optimizer.step()\n            \n            loss_list.append(loss.detach().cpu().item())\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n            \n            avg_loss = np.round(np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n            \n        val_labels, val_preds = validate(model, val_loader)\n        val_metric = np.round(rmspe(val_labels, val_preds), 4)\n\n        train_metric = np.round(rmspe(np.concatenate(labels), np.concatenate(preds)), 4)\n        log_text = f\"Epoch {e+1}\\n Train metric: {train_metric}\\nValidation metric: {val_metric}\\n\"\n            \n        print(log_text)\n    return model, val_preds\n\n\n\ndef kfold_train(BS=512, NW=8, NUM_FOLDS=5):\n    oof_preds = np.zeros(df.shape[0])\n\n    for fold in range(NUM_FOLDS):\n        print(f\"Fold {fold + 1}\")\n        train_ind = np.where(df[\"time_id\"].values % NUM_FOLDS != fold)[0]\n        val_ind = np.where(df[\"time_id\"].values % NUM_FOLDS == fold)[0]\n\n        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n\n\n        train_ds = OptiverDataset(train_df, aug=False)\n        val_ds = OptiverDataset(val_df, aug=False)\n\n        train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n                                  pin_memory=False, drop_last=True)\n        val_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                                  pin_memory=False, drop_last=False)\n\n        model = Model()\n        model.cuda()\n        model, val_preds = train(model, train_loader, val_loader, epochs=30)\n\n        oof_preds[val_ind] = val_preds\n\n        torch.save(model.state_dict(), f\"models/optiver_nn_v01_{fold}.pth\")\n        \n    df[\"nn_pred\"] = oof_preds/SCALE\n    df.to_csv(\"cache/optiver_nn_v01_oof.csv\", index=False, columns=[\"stock_id\", \"time_id\", \"nn_pred\"])","metadata":{},"execution_count":null,"outputs":[]}]}