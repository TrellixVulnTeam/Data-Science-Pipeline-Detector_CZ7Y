{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nfrom sklearn.metrics import r2_score\nimport os\nimport glob\nfrom tqdm import tqdm\nimport lightgbm as lgbm\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import Ridge\n\nfrom joblib import Parallel, delayed","metadata":{"papermill":{"duration":2.883859,"end_time":"2021-07-02T05:37:48.17652","exception":false,"start_time":"2021-07-02T05:37:45.292661","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:26:13.201082Z","iopub.execute_input":"2021-07-10T12:26:13.20177Z","iopub.status.idle":"2021-07-10T12:26:16.165235Z","shell.execute_reply.started":"2021-07-10T12:26:13.201682Z","shell.execute_reply":"2021-07-10T12:26:16.164122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    data_dir = '../input/optiver-realized-volatility-prediction/'\n    nfolds = 5","metadata":{"papermill":{"duration":0.021362,"end_time":"2021-07-02T05:37:48.213841","exception":false,"start_time":"2021-07-02T05:37:48.192479","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:26:16.16668Z","iopub.execute_input":"2021-07-10T12:26:16.167011Z","iopub.status.idle":"2021-07-10T12:26:16.170672Z","shell.execute_reply.started":"2021-07-10T12:26:16.16696Z","shell.execute_reply":"2021-07-10T12:26:16.169941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{"papermill":{"duration":0.015459,"end_time":"2021-07-02T05:37:48.244767","exception":false,"start_time":"2021-07-02T05:37:48.229308","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef rv(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","metadata":{"papermill":{"duration":0.024647,"end_time":"2021-07-02T05:37:48.285139","exception":false,"start_time":"2021-07-02T05:37:48.260492","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:26:16.172191Z","iopub.execute_input":"2021-07-10T12:26:16.172608Z","iopub.status.idle":"2021-07-10T12:26:16.184218Z","shell.execute_reply.started":"2021-07-10T12:26:16.172565Z","shell.execute_reply":"2021-07-10T12:26:16.18319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stock_stat(stock_id : int, dataType = 'train'):\n    \n    df_book = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/book_{dataType}.parquet/stock_id={stock_id}/')\n    df_book.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    # compute different vwap\n    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']) / (\n                            df_book['bid_size1']+ df_book['ask_size1'])\n\n    # wap2\n    a = df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']\n    b = df_book['bid_size2']+ df_book['ask_size2']\n    df_book['wap2'] = a/b\n    \n    # wap3\n    a1 = df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']\n    a2 = df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']\n    b = df_book['bid_size1'] + df_book['ask_size1'] + df_book['bid_size2']+ df_book['ask_size2']    \n    df_book['wap3'] = (a1 + a2)/ b\n    \n    # wap4 \n    a = (df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']) / (\n                                       df_book['bid_size1']+ df_book['ask_size1'])\n    b = (df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']) / (\n                                       df_book['bid_size2']+ df_book['ask_size2'])\n    df_book['wap4'] = (a + b) / 2\n    \n    # Wap5,6,7, & 8 assumes the volatility to be Σ (price*size) / Σ volume where size belong to same book entry as price\n    # wap5 \n    df_book['wap5'] = (df_book['bid_price1'] * df_book['bid_size1'] + df_book['ask_price1'] * df_book['ask_size1']) / (\n                            df_book['bid_size1']+ df_book['ask_size1'])\n    \n    # wap6 \n    df_book['wap6'] = (df_book['bid_price2'] * df_book['bid_size2'] + df_book['ask_price2'] * df_book['ask_size2']) / (\n                            df_book['bid_size2']+ df_book['ask_size2'])\n    \n    # wap7 \n    a1 = df_book['bid_price1'] * df_book['bid_size1'] + df_book['ask_price1'] * df_book['ask_size1']\n    a2 = df_book['bid_price2'] * df_book['bid_size2'] + df_book['ask_price2'] * df_book['ask_size2']\n    b = df_book['bid_size1'] + df_book['ask_size1'] + df_book['bid_size2']+ df_book['ask_size2']    \n    df_book['wap7'] = (a1 + a2)/ b\n    \n    # wap8\n    a = (df_book['bid_price1'] * df_book['bid_size1'] + df_book['ask_price1'] * df_book['ask_size1']) / (\n                                       df_book['bid_size1']+ df_book['ask_size1'])\n    b = (df_book['bid_price2'] * df_book['bid_size2'] + df_book['ask_price2'] * df_book['ask_size2']) / (\n                                       df_book['bid_size2']+ df_book['ask_size2'])\n    df_book['wap8'] = (a + b) / 2\n                    \n    df_book['vol_wap1'] = (df_book.groupby(by = ['time_id'])['wap1'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap2'] = (df_book.groupby(by = ['time_id'])['wap2'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap3'] = (df_book.groupby(by = ['time_id'])['wap3'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap4'] = (df_book.groupby(by = ['time_id'])['wap4'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap5'] = (df_book.groupby(by = ['time_id'])['wap5'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap6'] = (df_book.groupby(by = ['time_id'])['wap6'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap7'] = (df_book.groupby(by = ['time_id'])['wap7'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap8'] = (df_book.groupby(by = ['time_id'])['wap8'].apply(log_return).reset_index(drop = True).fillna(0))\n                \n        \n    df_book['bas'] = (df_book[['ask_price1', 'ask_price2']].min(axis = 1)\n                                / df_book[['bid_price1', 'bid_price2']].max(axis = 1) - 1)                               \n\n    # different spreads\n    df_book['h_spread_l1'] = df_book['ask_price1'] - df_book['bid_price1']\n    df_book['h_spread_l2'] = df_book['ask_price2'] - df_book['bid_price2']\n    df_book['v_spread_b'] = df_book['bid_price1'] - df_book['bid_price2']\n    df_book['v_spread_a'] = df_book['ask_price1'] - df_book['bid_price2']\n    \n    # Calculating new wap values using spread parameters\n    df_book['spread_wap1'] = df_book['h_spread_l1'] / (df_book['v_spread_b'] + df_book['v_spread_a'])\n    df_book['spread_wap2'] = df_book['h_spread_l2'] / (df_book['v_spread_b'] + df_book['v_spread_a'])\n    \n    # attach volatitilies based on different VWAPs\n    stock_stat = pd.merge(\n        df_book.groupby(by = ['time_id'])['vol_wap1'].agg(rv).reset_index(),\n        df_book.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap2'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap3'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n        \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap4'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap5'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap6'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap7'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['vol_wap8'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    # spread summaries\n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['h_spread_l1'].agg(max).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )     \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['h_spread_l2'].agg(max).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )     \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['v_spread_b'].agg(max).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )   \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['v_spread_a'].agg(max).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    # spread waps\n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['spread_wap1'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat = pd.merge( \n        df_book.groupby(by = ['time_id'])['spread_wap2'].agg(rv).reset_index(),\n        stock_stat, \n        on = ['time_id'], \n        how = 'left'\n    )\n    \n    stock_stat['stock_id'] = stock_id\n    return stock_stat\n\n\ndef get_dataSet(stock_ids : list, dataType = 'train'):\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n    return stock_stat_df","metadata":{"papermill":{"duration":0.045374,"end_time":"2021-07-02T05:37:48.375915","exception":false,"start_time":"2021-07-02T05:37:48.330541","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:26:16.18576Z","iopub.execute_input":"2021-07-10T12:26:16.186247Z","iopub.status.idle":"2021-07-10T12:26:16.228635Z","shell.execute_reply.started":"2021-07-10T12:26:16.18621Z","shell.execute_reply":"2021-07-10T12:26:16.227694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{"papermill":{"duration":0.015285,"end_time":"2021-07-02T05:37:48.443354","exception":false,"start_time":"2021-07-02T05:37:48.428069","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = pd.read_csv(CFG.data_dir + 'train.csv')\ntrain.loc[train.stock_id == 0].head(3)","metadata":{"papermill":{"duration":0.302096,"end_time":"2021-07-02T05:37:48.760869","exception":false,"start_time":"2021-07-02T05:37:48.458773","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:26:16.230104Z","iopub.execute_input":"2021-07-10T12:26:16.230717Z","iopub.status.idle":"2021-07-10T12:26:16.546825Z","shell.execute_reply.started":"2021-07-10T12:26:16.230669Z","shell.execute_reply":"2021-07-10T12:26:16.545536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\ntrain_dataSet = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')","metadata":{"papermill":{"duration":601.503299,"end_time":"2021-07-02T05:47:50.28028","exception":false,"start_time":"2021-07-02T05:37:48.776981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:26:16.548145Z","iopub.execute_input":"2021-07-10T12:26:16.548476Z","iopub.status.idle":"2021-07-10T12:48:11.363796Z","shell.execute_reply.started":"2021-07-10T12:26:16.548442Z","shell.execute_reply":"2021-07-10T12:48:11.359798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntest = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n\ntest_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest_dataSet = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\n","metadata":{"papermill":{"duration":0.135192,"end_time":"2021-07-02T05:47:50.431358","exception":false,"start_time":"2021-07-02T05:47:50.296166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:48:11.365656Z","iopub.execute_input":"2021-07-10T12:48:11.366012Z","iopub.status.idle":"2021-07-10T12:48:11.537745Z","shell.execute_reply.started":"2021-07-10T12:48:11.365957Z","shell.execute_reply":"2021-07-10T12:48:11.536661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\n","metadata":{"papermill":{"duration":0.016072,"end_time":"2021-07-02T05:47:50.463741","exception":false,"start_time":"2021-07-02T05:47:50.447669","status":"completed"},"tags":[]}},{"cell_type":"code","source":"covariates = [f for f in train_dataSet.columns if f not in ['time_id', 'target']]","metadata":{"papermill":{"duration":0.022788,"end_time":"2021-07-02T05:47:50.50257","exception":false,"start_time":"2021-07-02T05:47:50.479782","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:48:11.541055Z","iopub.execute_input":"2021-07-10T12:48:11.541487Z","iopub.status.idle":"2021-07-10T12:48:11.546444Z","shell.execute_reply.started":"2021-07-10T12:48:11.541441Z","shell.execute_reply":"2021-07-10T12:48:11.545371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# taken from https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train\ndef my_metrics(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\ndef rmspe(y_true, y_pred):  \n    output = my_metrics(y_true, y_pred)\n    return 'rmspe', output, False","metadata":{"papermill":{"duration":0.023678,"end_time":"2021-07-02T05:47:50.543622","exception":false,"start_time":"2021-07-02T05:47:50.519944","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:48:11.547999Z","iopub.execute_input":"2021-07-10T12:48:11.548361Z","iopub.status.idle":"2021-07-10T12:48:11.559114Z","shell.execute_reply.started":"2021-07-10T12:48:11.548322Z","shell.execute_reply":"2021-07-10T12:48:11.558137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prval = np.zeros((train_dataSet.shape[0],1))\nprfull = np.zeros((test_dataSet.shape[0],1))\n\nxdat = train_dataSet[covariates].copy()\nydat = train_dataSet['target'].copy()\nxtest = test_dataSet[covariates].copy()\n\nparams = {'metric': 'rmse',\n          'reg_alpha': 0.9,  \n          'reg_lambda': 5.61, \n          'num_leaves': 56, \n          'learning_rate': 0.08, \n          'max_depth': 5, \n          'n_estimators': 1000, \n          'min_child_weight': 0.11, \n          'subsample': 0.7, \n          'colsample_bytree': 0.8,  \n          'min_child_samples': 28}\n\nkf = KFold(n_splits= CFG.nfolds, shuffle = True, random_state = 42)\nfor (ii, (id0, id1)) in enumerate(kf.split(train_dataSet)):\n    x0, x1 = xdat.loc[id0], xdat.loc[id1]\n    y0, y1 = ydat.loc[id0], ydat.loc[id1]\n    \n    model = lgbm.LGBMRegressor(**params)\n    \n    model.fit(x0, y0, eval_set=[(x0, y0), (x1, y1)], \n              eval_metric = rmspe,\n              early_stopping_rounds= 50,  \n              verbose= 250)\n    \n    prval[id1,0] = model.predict(x1)\n    prfull[:,0] += model.predict(xtest)/CFG.nfolds\n    \ndel x0,x1,y0,y1,id0,id1","metadata":{"papermill":{"duration":27.566414,"end_time":"2021-07-02T05:48:18.126341","exception":false,"start_time":"2021-07-02T05:47:50.559927","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:48:11.560587Z","iopub.execute_input":"2021-07-10T12:48:11.56094Z","iopub.status.idle":"2021-07-10T12:49:00.349052Z","shell.execute_reply.started":"2021-07-10T12:48:11.560911Z","shell.execute_reply":"2021-07-10T12:49:00.348223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm.plot_importance(model, max_num_features= 25)","metadata":{"papermill":{"duration":0.308174,"end_time":"2021-07-02T05:48:18.456461","exception":false,"start_time":"2021-07-02T05:48:18.148287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:49:00.350206Z","iopub.execute_input":"2021-07-10T12:49:00.350654Z","iopub.status.idle":"2021-07-10T12:49:00.675016Z","shell.execute_reply.started":"2021-07-10T12:49:00.350621Z","shell.execute_reply":"2021-07-10T12:49:00.673896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### New spread_wap parameters are playing prominent role in our model. Wap5 & 6 are also right there along with wap1 & 2 so other volatility formula also seems to have some merits","metadata":{}},{"cell_type":"code","source":"# feeding prval and ydat directly into the metric crashes the script due to memory consumption,\n# and I don't have the energy to fix it atm. \n\n# del train_dataSet\nxref = pd.DataFrame()\nxref['ydat'] = ydat\nxref['prval'] = prval\ndel xdat, ydat\n\nR2 = round(r2_score(y_true = xref['ydat'], y_pred = xref['prval']),3)\na = (xref['ydat'] - xref['prval'])/xref['ydat']\nRMSPE =  np.round((np.sqrt(np.mean(np.square(a )))) ,4)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"papermill":{"duration":0.093219,"end_time":"2021-07-02T05:48:18.570186","exception":false,"start_time":"2021-07-02T05:48:18.476967","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:49:00.676329Z","iopub.execute_input":"2021-07-10T12:49:00.676684Z","iopub.status.idle":"2021-07-10T12:49:00.753762Z","shell.execute_reply.started":"2021-07-10T12:49:00.676652Z","shell.execute_reply":"2021-07-10T12:49:00.752737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.020791,"end_time":"2021-07-02T05:48:18.611832","exception":false,"start_time":"2021-07-02T05:48:18.591041","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_dataSet['target'] = prfull\ntest_dataSet[['row_id', 'target']].to_csv('submission.csv', index = False)","metadata":{"papermill":{"duration":0.035708,"end_time":"2021-07-02T05:48:18.668551","exception":false,"start_time":"2021-07-02T05:48:18.632843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-10T12:49:00.755016Z","iopub.execute_input":"2021-07-10T12:49:00.755319Z","iopub.status.idle":"2021-07-10T12:49:00.767709Z","shell.execute_reply.started":"2021-07-10T12:49:00.755288Z","shell.execute_reply":"2021-07-10T12:49:00.766393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**References:**\n\nhttps://www.kaggle.com/konradb/we-need-to-go-deeper-and-validate","metadata":{}}]}