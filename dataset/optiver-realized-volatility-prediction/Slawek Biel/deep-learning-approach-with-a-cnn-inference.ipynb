{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastai.vision.all import *\nfrom tqdm.notebook import  tqdm\n\nPATH = Path('../input/optiver-realized-volatility-prediction')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-11T17:01:06.281538Z","iopub.execute_input":"2021-08-11T17:01:06.281895Z","iopub.status.idle":"2021-08-11T17:01:08.814898Z","shell.execute_reply.started":"2021-08-11T17:01:06.28182Z","shell.execute_reply":"2021-08-11T17:01:08.814064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**UPDATE Aug 11th**: I've cleaned up and simplified the model, now all it uses are 1D convolution instead the 5x1 2D convs. Also I experimented with numbers of layers and channels and managed to improve the score slightly. \nNote that still it only uses a single fold (80% of book data) and no trade data at all, so there's rooom for improvement.","metadata":{}},{"cell_type":"markdown","source":"# Solution overview\n\n### This notebook demonstrates an approach where a neural network is trained on the raw book data. I'm not adding any engineered features, so the network starts with no concept of prices, returns, volatility or logarithms.\n\n### Each input sample is simply a 600x8 tensor representing the 8 numerical columns of the book data at each second of the 10 minute window.","metadata":{}},{"cell_type":"markdown","source":"## The model\nI'm using a convolutional neural network with architecture inspired by ResNet. With a total of 65 1D convolutional layers, followed by a single dense layer.\n\nWith a small number of channels and 5x1 convolutions this is still fairly lightweight and doesn't take long to infere. Training took around 25 minutes on a single RTX3090 GPU.","metadata":{}},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    def __init__(self, ch):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Conv1d(ch, ch, kernel_size = 5, padding = 2, padding_mode='replicate'),\n            nn.BatchNorm1d(ch),\n            nn.ReLU(),\n            nn.Conv1d(ch, ch, kernel_size = 5, padding = 2, padding_mode='replicate'),\n            nn.BatchNorm1d(ch),\n        )\n        \n    def forward(self, x):\n        res = self.layers(x) + x\n        res = F.relu(res)\n        return res\n\nclass ResnetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        chan = 32\n        layers = [nn.Conv1d(8, chan, kernel_size=1)]\n        for _ in range(8):\n            layers += [ResBlock(chan), ResBlock(chan), ResBlock(chan), ResBlock(chan)\n                       , nn.AvgPool1d(2, padding=1),\n                      ]\n        layers += [Flatten(), nn.Dropout()]   \n        self.conv_layers = nn.Sequential(*layers)\n        self.classifier = nn.Linear(chan*4, 1)\n        \n    def forward(self, x):\n        feat = self.conv_layers(x)\n        res = self.classifier(feat)\n        return sigmoid_range(res, 0, .1).view(-1)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:02:39.714537Z","iopub.execute_input":"2021-08-09T13:02:39.714842Z","iopub.status.idle":"2021-08-09T13:02:39.728599Z","shell.execute_reply.started":"2021-08-09T13:02:39.714807Z","shell.execute_reply":"2021-08-09T13:02:39.72774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = PATH/'book_test.parquet'\nmodel_file = '../input/optiver-resnet-model/resnet_model2.pth'\nmodel = torch.load(model_file)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:02:39.730532Z","iopub.execute_input":"2021-08-09T13:02:39.731122Z","iopub.status.idle":"2021-08-09T13:02:43.273195Z","shell.execute_reply.started":"2021-08-09T13:02:39.731082Z","shell.execute_reply":"2021-08-09T13:02:43.272276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stats from the train data used for normalization:","metadata":{}},{"cell_type":"code","source":"means = tensor([  0.9997,   1.0003, 769.9902, 766.7346,   0.9995,   1.0005, 959.3417,\n        928.2203])\nstds = tensor([3.6881e-03, 3.6871e-03, 5.3541e+03, 4.9549e+03, 3.7009e-03, 3.6991e-03,\n        6.6838e+03, 5.7353e+03])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:10.778597Z","iopub.execute_input":"2021-07-14T15:09:10.779185Z","iopub.status.idle":"2021-07-14T15:09:10.825138Z","shell.execute_reply.started":"2021-07-14T15:09:10.779149Z","shell.execute_reply":"2021-07-14T15:09:10.824368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### See the discussion [here](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/251775)","metadata":{}},{"cell_type":"code","source":"def fix_offsets(data_df):\n    offsets = data_df.groupby(['time_id']).agg({'seconds_in_bucket':'min'})\n    offsets.columns = ['offset']\n    data_df = data_df.join(offsets, on='time_id')\n    data_df.seconds_in_bucket = data_df.seconds_in_bucket - data_df.offset\n    return data_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:10.826995Z","iopub.execute_input":"2021-07-14T15:09:10.82734Z","iopub.status.idle":"2021-07-14T15:09:10.832363Z","shell.execute_reply.started":"2021-07-14T15:09:10.827305Z","shell.execute_reply":"2021-07-14T15:09:10.831367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explained [here](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/251277)","metadata":{}},{"cell_type":"code","source":"def ffill(data_df):\n    data_df=data_df.set_index(['time_id', 'seconds_in_bucket'])\n    data_df = data_df.reindex(pd.MultiIndex.from_product([data_df.index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket']), method='ffill')\n    return data_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:10.834173Z","iopub.execute_input":"2021-07-14T15:09:10.834815Z","iopub.status.idle":"2021-07-14T15:09:10.843921Z","shell.execute_reply.started":"2021-07-14T15:09:10.834777Z","shell.execute_reply":"2021-07-14T15:09:10.842988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(fname):\n    data = pd.read_parquet(fname)\n    stock_id = str(fname).split('=')[1]\n    time_ids = data.time_id.unique()\n    row_ids = list(map(lambda x:f'{stock_id}-{x}', time_ids))\n    data = fix_offsets(data)\n    data = ffill(data)\n    data = data[['bid_price1', 'ask_price1', 'bid_size1', 'ask_size1','bid_price2', 'ask_price2', 'bid_size2', 'ask_size2']].to_numpy()\n    data = torch.tensor(data.astype('float32'))\n    data = (data - means) / stds\n    return data, row_ids","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:10.845355Z","iopub.execute_input":"2021-07-14T15:09:10.84585Z","iopub.status.idle":"2021-07-14T15:09:10.853084Z","shell.execute_reply.started":"2021-07-14T15:09:10.84579Z","shell.execute_reply":"2021-07-14T15:09:10.852073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(data, model):\n    data = data.view(-1,600,8).permute(0, 2, 1)\n    with torch.no_grad():\n        preds = model(data.cuda())\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:10.854749Z","iopub.execute_input":"2021-07-14T15:09:10.85528Z","iopub.status.idle":"2021-07-14T15:09:10.862013Z","shell.execute_reply.started":"2021-07-14T15:09:10.855232Z","shell.execute_reply":"2021-07-14T15:09:10.860876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nall_preds = []\nfor fname in tqdm(data_dir.ls()):\n    data, row_ids = load_data(fname)\n    preds = get_preds(data, model)\n    df_pred = pd.DataFrame(zip(row_ids, preds.tolist()),columns=['row_id', 'target'])\n    all_preds.append(df_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:10.8635Z","iopub.execute_input":"2021-07-14T15:09:10.863892Z","iopub.status.idle":"2021-07-14T15:09:10.934658Z","shell.execute_reply.started":"2021-07-14T15:09:10.863859Z","shell.execute_reply":"2021-07-14T15:09:10.93374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred = pd.concat(all_preds)\ndf_pred.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:53.380538Z","iopub.execute_input":"2021-07-14T15:09:53.380922Z","iopub.status.idle":"2021-07-14T15:09:53.386535Z","shell.execute_reply.started":"2021-07-14T15:09:53.380892Z","shell.execute_reply":"2021-07-14T15:09:53.385464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:09:54.579035Z","iopub.execute_input":"2021-07-14T15:09:54.579375Z","iopub.status.idle":"2021-07-14T15:09:54.594814Z","shell.execute_reply.started":"2021-07-14T15:09:54.579345Z","shell.execute_reply":"2021-07-14T15:09:54.59393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}