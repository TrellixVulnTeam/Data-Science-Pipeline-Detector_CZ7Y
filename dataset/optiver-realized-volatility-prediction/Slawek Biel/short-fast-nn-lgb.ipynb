{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook doesn't do anything novel in terms of features, nor architecture. Instead I want to show how you can structure your code and data to run experiments in a fast and concise manner. \n\nThe preprocessing code and LGB models were taken from [here](https://www.kaggle.com/tatudoug/stock-embedding-ffnn-features-of-the-best-lgbm) and based on [this](https://www.kaggle.com/ragnar123/optiver-realized-volatility-lgbm-baseline)\n\nThis is how it works:\n- The training set with features is cached and loaded from https://www.kaggle.com/slawekbiel/optiver-train-features\n- The code to generate those features is saved in an Utility Script: https://www.kaggle.com/slawekbiel/optiver-features and used to process the test data.\n- fast.ai library handles defining the NN model and preparing the data for it (normalization, embeddings, batching etc)\n- Both fastai nad LGB models are trained locally, serialized and then pushed to the dataset: https://www.kaggle.com/slawekbiel/optiver-models","metadata":{}},{"cell_type":"code","source":"from optiver_features import generate_test_df\nfrom fastai.tabular.all import *","metadata":{"_uuid":"4948c4b9-c7d7-4dd4-98eb-df1a8585ea70","_cell_guid":"6b8e3623-41e3-454b-8e4f-a2a273f0cf1e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = generate_test_df()\ntrain_df = pd.read_csv('../input/optiver-train-features/train_with_features.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_tabular_nn(train_df, test_df):\n    train_df = train_df.drop(['time_id', 'row_id'], axis=1).fillna(0)\n    train_df.stock_id = train_df.stock_id.astype('category')\n    cont_nn,cat_nn = cont_cat_split(train_df,  dep_var='target')\n    dls = TabularPandas(train_df, [Categorify, Normalize], cat_nn, cont_nn, y_names='target').dataloaders(2048)\n    test_dl = dls.test_dl(test_df.fillna(0))\n    learn = tabular_learner(dls, y_range=(0,.1), layers=[1000,500,200], n_out=1, path = '../input/optiver-models/')\n    res = torch.zeros(len(test_df))\n    for idx in range(5):\n        learn.load(f'nn_fold{idx}')\n        preds, _ = learn.get_preds(dl=test_dl)\n        res += preds.squeeze() / 5\n    return res.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_lgb(test_df):\n    test_df = test_df.drop(['row_id', 'time_id'], axis=1)\n    res = np.zeros(len(test_df))\n    for idx in range(10):\n        filename = f'../input/optiver-models/models/lgb_fold{idx}.pickle'\n        model = pickle.load(open(filename, 'rb'))\n        preds = model.predict(test_df)\n        res += preds / 10\n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds = pred_tabular_nn(train_df, test_df)\nlgb_preds = pred_lgb(test_df)\n\ntest_df['target']=(nn_preds+lgb_preds)/2\ntest_df[['row_id', 'target']].to_csv('submission.csv', index =False)\npd.read_csv('submission.csv').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}