{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h3 style='color:red'>Optiver Realized Volatility PyTorch Baseline</h3><br>KASSEM@ELCAISERI<HR></center>","metadata":{}},{"cell_type":"markdown","source":"In this notebook:\n* A simple PyTorch NN starter using stock Embedding.\n\n\nCredits to:\n* https://www.kaggle.com/jiashenliu/introduction-to-financial-concepts-and-data\n* https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250324\n* https://www.kaggle.com/lucasmorin/tf-keras-nn-with-stock-embedding\n\n**I hope it will be useful for beginners. By creating new variables you can easily improve this model.**\n\n\n## updates:\n**V4**\n* use RMSELoss as loss fuction\n* add scheduler\n* test the results.\n\n**V6**\n* change model hyperparmeters {emb_size=29, emb_drop_out=0.25}\n* Train for 5 folds && Test and submit for the 5 folds\n\n**V8**\n* Implement of 'SWISH' : a self-gated activation function\n* join main DF with Data Normalize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T17:50:17.731903Z","iopub.execute_input":"2021-07-05T17:50:17.732318Z","iopub.status.idle":"2021-07-05T17:50:19.647572Z","shell.execute_reply.started":"2021-07-05T17:50:17.732235Z","shell.execute_reply":"2021-07-05T17:50:19.646491Z"}}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\n\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport gc\n\nfrom joblib import Parallel, delayed\n\nfrom sklearn import preprocessing, model_selection\nfrom tqdm import tqdm\nimport random\n\nfrom sklearn.metrics import r2_score\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\npath_root = '../input/optiver-realized-volatility-prediction'\npath_data = '../input/optiver-realized-volatility-prediction'\npath_submissions = '/'\n\ntarget_name = 'target'\nscores_folds = {}\n\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:20:13.167215Z","iopub.execute_input":"2021-08-23T10:20:13.16761Z","iopub.status.idle":"2021-08-23T10:20:13.17582Z","shell.execute_reply.started":"2021-08-23T10:20:13.16758Z","shell.execute_reply":"2021-08-23T10:20:13.174984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\n\ndef get_stock_stat(stock_id : int, dataType = 'train'):\n    key = ['stock_id', 'time_id', 'seconds_in_bucket']\n    \n    #Book features\n    df_book = pd.read_parquet(os.path.join(path_data, 'book_{}.parquet/stock_id={}/'.format(dataType, stock_id)))\n    df_book['stock_id'] = stock_id\n    cols = key + [col for col in df_book.columns if col not in key]\n    df_book = df_book[cols]\n    \n    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] +\n                                    df_book['ask_price1'] * df_book['bid_size1']) / (df_book['bid_size1'] + df_book['ask_size1'])\n    df_book['wap2'] = (df_book['bid_price2'] * df_book['ask_size2'] +\n                                    df_book['ask_price2'] * df_book['bid_size2']) / (df_book['bid_size2'] + df_book['ask_size2'])\n    df_book['log_return1'] = df_book.groupby(by = ['time_id'])['wap1'].apply(log_return).fillna(0)\n    df_book['log_return2'] = df_book.groupby(by = ['time_id'])['wap2'].apply(log_return).fillna(0)\n    \n    features_to_apply_realized_volatility = ['log_return'+str(i+1) for i in range(2)]\n    stock_stat = df_book.groupby(by = ['stock_id', 'time_id'])[features_to_apply_realized_volatility]\\\n                        .agg(realized_volatility).reset_index()\n\n    #Trade features\n    trade_stat =  pd.read_parquet(os.path.join(path_data,'trade_{}.parquet/stock_id={}'.format(dataType, stock_id)))\n    trade_stat = trade_stat.sort_values(by=['time_id', 'seconds_in_bucket']).reset_index(drop=True)\n    trade_stat['stock_id'] = stock_id\n    cols = key + [col for col in trade_stat.columns if col not in key]\n    trade_stat = trade_stat[cols]\n    trade_stat['trade_log_return1'] = trade_stat.groupby(by = ['time_id'])['price'].apply(log_return).fillna(0)\n    trade_stat = trade_stat.groupby(by = ['stock_id', 'time_id'])[['trade_log_return1']]\\\n                           .agg(realized_volatility).reset_index()\n    #Joining book and trade features\n    stock_stat = stock_stat.merge(trade_stat, on=['stock_id', 'time_id'], how='left').fillna(-999)\n    \n    return stock_stat\n\ndef get_dataSet(stock_ids : list, dataType = 'train'):\n    \n    if DEBUG and dataType == 'train':\n        stock_ids = stock_ids[:10]\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n\n    return stock_stat_df\n\ndef feval_RMSPE(preds, train_data):\n    labels = train_data.get_label()\n    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:10:30.281295Z","iopub.execute_input":"2021-08-23T10:10:30.281569Z","iopub.status.idle":"2021-08-23T10:10:30.297132Z","shell.execute_reply.started":"2021-08-23T10:10:30.281542Z","shell.execute_reply":"2021-08-23T10:10:30.296247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and test datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(path_data, 'train.csv'))\n%time train_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\ntrain = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left').fillna(0)\nprint('Train shape: {}'.format(train.shape))\ndisplay(train.head(2))\n\ntest = pd.read_csv(os.path.join(path_data, 'test.csv'))\ntest_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left').fillna(0)\nprint('Test shape: {}'.format(test.shape))\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:10:30.299167Z","iopub.execute_input":"2021-08-23T10:10:30.29978Z","iopub.status.idle":"2021-08-23T10:11:24.352995Z","shell.execute_reply.started":"2021-08-23T10:10:30.299744Z","shell.execute_reply":"2021-08-23T10:11:24.352165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Normailze","metadata":{}},{"cell_type":"code","source":"scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n\ntrain_scaled = scaler.fit_transform(train.iloc[:, 3:])\ntrain_ = train.join(pd.DataFrame(train_scaled), how='left')\n\ntest_scaled = scaler.transform(test.iloc[:, 3:])\ntest_ = test.join(pd.DataFrame(test_scaled), how='left')\n\n\ntrain, test = train_, test_\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:24.354847Z","iopub.execute_input":"2021-08-23T10:11:24.355173Z","iopub.status.idle":"2021-08-23T10:11:24.406376Z","shell.execute_reply.started":"2021-08-23T10:11:24.355132Z","shell.execute_reply":"2021-08-23T10:11:24.405407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply Torch","metadata":{}},{"cell_type":"code","source":"## import libraries\n\n#PyTorch \n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils import data","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:24.407836Z","iopub.execute_input":"2021-08-23T10:11:24.408182Z","iopub.status.idle":"2021-08-23T10:11:25.761057Z","shell.execute_reply.started":"2021-08-23T10:11:24.408146Z","shell.execute_reply":"2021-08-23T10:11:25.760275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:25.762208Z","iopub.execute_input":"2021-08-23T10:11:25.76256Z","iopub.status.idle":"2021-08-23T10:11:25.767551Z","shell.execute_reply.started":"2021-08-23T10:11:25.762528Z","shell.execute_reply":"2021-08-23T10:11:25.766542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Torch DATASET","metadata":{}},{"cell_type":"code","source":"class OptiveDataset(Dataset):\n    def __init__(self, X, Y, emb_cols=['stock_id', 'time_id']):\n        X = X.copy()\n        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64) #categorical columns\n        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32) #numerical columns\n        self.y = Y\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        return (self.X1[idx], self.X2[idx]), self.y[idx]\n    \nclass OptiveDatasetTest(Dataset):\n    def __init__(self, X, emb_cols=['stock_id', 'time_id']):\n        X = X.copy()\n        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64) #categorical columns\n        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32) #numerical columns\n        \n    def __len__(self):\n        return len(self.X1)\n    \n    def __getitem__(self, idx):\n        return (self.X1[idx], self.X2[idx])","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:25.76899Z","iopub.execute_input":"2021-08-23T10:11:25.769491Z","iopub.status.idle":"2021-08-23T10:11:25.780683Z","shell.execute_reply.started":"2021-08-23T10:11:25.769454Z","shell.execute_reply":"2021-08-23T10:11:25.779583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = OptiveDataset(train.drop(['target', 'time_id'], axis=1), train['target'], emb_cols=['stock_id'])\ntrain_dl = DataLoader(train_dataset, batch_size=4, shuffle=True)\n\n#test the dataset class\nfor (emb, count), target in train_dl:\n    print((emb.shape, count.shape), target.shape)\n    break;","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:25.783653Z","iopub.execute_input":"2021-08-23T10:11:25.784132Z","iopub.status.idle":"2021-08-23T10:11:25.891982Z","shell.execute_reply.started":"2021-08-23T10:11:25.784096Z","shell.execute_reply":"2021-08-23T10:11:25.890969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# from https://discuss.pytorch.org/t/implementation-of-swish-a-self-gated-activation-function/8813/2\ndef swish(x):\n    return x * torch.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:25.893782Z","iopub.execute_input":"2021-08-23T10:11:25.894131Z","iopub.status.idle":"2021-08-23T10:11:25.900624Z","shell.execute_reply.started":"2021-08-23T10:11:25.894091Z","shell.execute_reply":"2021-08-23T10:11:25.89977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OptiverModel(nn.Module):\n    def __init__(self, embedding_sizes=16, num_embeddings=max(train['stock_id'])+1):\n        super().__init__()\n        self.emb = nn.Embedding(num_embeddings, embedding_sizes)\n        self.emb_drop = nn.Dropout(0.25)\n        \n        self.bn1 = nn.BatchNorm1d(6)\n        self.lin1 = nn.Linear(embedding_sizes+6, 32)\n        self.lin2 = nn.Linear(32, 128)\n        self.lin3 = nn.Linear(128, 64)\n        self.lin4 = nn.Linear(64, 32)\n        self.lin5 = nn.Linear(32, 1)    \n\n    def forward(self, x_cat, x_cont):\n        x1 = self.emb(x_cat)\n        x1 = torch.flatten(x1, end_dim=1)\n        #x1 = self.emb_drop(x1)\n        \n        x2 = self.bn1(x_cont)\n\n        x = torch.cat([x1, x2], 1)\n        x = swish(self.lin1(x))\n        x = swish(self.lin2(x))\n        x = swish(self.lin3(x))\n        x = swish(self.lin4(x))\n        x = self.lin5(x)\n        #x = torch.sigmoid(x)\n        \n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:25.901812Z","iopub.execute_input":"2021-08-23T10:11:25.902264Z","iopub.status.idle":"2021-08-23T10:11:25.961085Z","shell.execute_reply.started":"2021-08-23T10:11:25.902228Z","shell.execute_reply":"2021-08-23T10:11:25.960247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = OptiverModel(embedding_sizes=24,)\n#emb.shape, count.shape\nout = model(emb, count)\n\nprint(out, target)\n#model","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:25.962298Z","iopub.execute_input":"2021-08-23T10:11:25.96264Z","iopub.status.idle":"2021-08-23T10:11:26.06589Z","shell.execute_reply.started":"2021-08-23T10:11:25.962606Z","shell.execute_reply":"2021-08-23T10:11:26.065186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef RMSELoss(yhat,y):\n    return torch.sqrt(torch.mean((yhat-y)**2))\n\ndef RMSPELoss(y_pred, y_true):\n    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 ))\n\ndef train_epoch(train_dl, valid_dl, model, loss_fn, opt, sch, epoch, fold, device=device):\n    # taining loop\n    model.train()\n    running_loss_ = 0\n    \n    pbar = tqdm(enumerate(train_dl), total=len(train_dl))\n    for i, ((cats, counts), targets) in pbar:\n        cats, counts, targets = cats.to(device), counts.to(device), targets.unsqueeze(1).to(device)\n        \n        opt.zero_grad()\n        y_pred = model(cats, counts)\n        loss = loss_fn(y_pred.float(), targets.float())\n        \n        loss.backward()\n        opt.step()\n        \n        running_loss_ += loss.item()\n        if (i+1) % 100 == 0:\n            pbar.set_description(f\"running loss:{running_loss_ / (i+1): 0.6f}\")\n    \n    sch.step(loss)\n\n    epoch_loss = running_loss_ / len(train_dl)\n    #print(f'==> Epoch {epoch} TRAIN loss: {epoch_loss:.6f}')\n    \n    # Validation loop\n    model.eval()\n    valid_loss = 0\n    best_loss = np.inf\n    \n    for i, ((cats, counts), targets) in enumerate(valid_dl):\n        cats, counts, targets = cats.to(device), counts.to(device), targets.unsqueeze(1).to(device)\n        \n        with torch.no_grad():\n            y_pred = model(cats, counts)\n            val_loss = loss_fn(y_pred.float(), targets.float())\n            \n        valid_loss += val_loss.item() * targets.shape[0]\n    sch.step(valid_loss)\n    \n    valid_epoch_loss = valid_loss / len(valid_dl)\n    print(f'==>FOLD:{fold}, Epoch {epoch} VALID loss: {valid_epoch_loss:.8f}')\n    \n    #if valid_epoch_loss < best_loss:\n    #    best_loss = valid_epoch_loss\n    #    torch.save(model.state_dict(), f'FOLD{fold}_optive_model.pth')\n    \n    model.train()\n    return model, epoch_loss, valid_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:26.066946Z","iopub.execute_input":"2021-08-23T10:11:26.067248Z","iopub.status.idle":"2021-08-23T10:11:26.14107Z","shell.execute_reply.started":"2021-08-23T10:11:26.067216Z","shell.execute_reply":"2021-08-23T10:11:26.140043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perpare_dataset(train, valid, test=None, batch_size=128, drop_cols=['target', 'time_id'], emb_cols=['stock_id']):\n    train_dataset = OptiveDataset(train.drop(drop_cols, axis=1), train['target'], emb_cols=emb_cols)\n    valid_dataset = OptiveDataset(valid.drop(drop_cols, axis=1), valid['target'], emb_cols=emb_cols)    \n    \n    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n    \n    return train_dl, valid_dl","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:26.142438Z","iopub.execute_input":"2021-08-23T10:11:26.143007Z","iopub.status.idle":"2021-08-23T10:11:26.153027Z","shell.execute_reply.started":"2021-08-23T10:11:26.14297Z","shell.execute_reply":"2021-08-23T10:11:26.152269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 5\nepochs = 25\n\nkf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2021)\nseed_everything(42)\n\nfor fold_idx, (dev_index, val_index) in enumerate(kf.split(range(len(train)))):\n        \n    train_ = train.loc[dev_index,].reset_index(drop=True)\n    valid_ = train.loc[val_index, ].reset_index(drop=True)\n    \n    train_dl, valid_dl = perpare_dataset(train_, valid_)\n    \n    model = OptiverModel(embedding_sizes=24,).to(device)\n    #loss_fn = nn.MSELoss().to(device)\n    loss_fn = RMSELoss\n    \n    opt = optim.Adam(model.parameters(), lr=0.001)\n    sch = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.2, patience=4)\n    \n    bst_loss = np.inf\n    counter = 0\n    for epoch in range(epochs):\n        model, epoch_loss, valid_epoch_loss = train_epoch(train_dl, valid_dl, \n                                                                   model, loss_fn, opt, \n                                                                   sch, epoch, fold_idx, device=device)\n        \n        # simple early stop\n        if bst_loss < valid_epoch_loss:\n            counter += 1\n        else:\n            bst_loss = valid_epoch_loss\n            bst_epoch = epoch\n            counter = 0\n            torch.save(model.state_dict(), f'FOLD{fold_idx}_optive_model.pth')\n\n        \n        # break after 5 epochs\n        if counter > 7:\n            break\n        \n    print(f'FOLD: {fold_idx}, BEST EPOCH: {bst_epoch}, BEST LOSS: {bst_loss}')","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:11:26.156063Z","iopub.execute_input":"2021-08-23T10:11:26.156308Z","iopub.status.idle":"2021-08-23T10:19:50.686032Z","shell.execute_reply.started":"2021-08-23T10:11:26.156285Z","shell.execute_reply":"2021-08-23T10:19:50.683811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test and prediction","metadata":{}},{"cell_type":"code","source":"test_dataset = OptiveDatasetTest(test.drop(['row_id', 'time_id'], axis=1), emb_cols=['stock_id'])\ntest_dl = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\ntest_preds = []\nmodel_paths = glob.glob('./*.pth')\n\nfor model_path in model_paths:\n    #model_path = './FOLD0_optive_model.pth'\n    model.load_state_dict(torch.load(model_path))\n    model.to(torch.device('cpu'))\n    model.eval()\n\n    y_preds = []\n    with torch.no_grad():\n        for x_cat, x_cont in test_dl:\n            y_preds += [model(x_cat, x_cont).detach().cpu().numpy()[0][0]]\n    test_preds.append(y_preds)\n    \ny_preds = np.mean(test_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:19:53.334299Z","iopub.execute_input":"2021-08-23T10:19:53.334653Z","iopub.status.idle":"2021-08-23T10:19:53.359296Z","shell.execute_reply.started":"2021-08-23T10:19:53.334623Z","shell.execute_reply":"2021-08-23T10:19:53.358455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:19:54.433156Z","iopub.execute_input":"2021-08-23T10:19:54.43352Z","iopub.status.idle":"2021-08-23T10:19:54.43908Z","shell.execute_reply.started":"2021-08-23T10:19:54.433486Z","shell.execute_reply":"2021-08-23T10:19:54.438166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test__ = test.copy()\ntest__['target'] = y_preds\ntest__[['row_id', 'target']].to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:19:55.070755Z","iopub.execute_input":"2021-08-23T10:19:55.071056Z","iopub.status.idle":"2021-08-23T10:19:55.312832Z","shell.execute_reply.started":"2021-08-23T10:19:55.07103Z","shell.execute_reply":"2021-08-23T10:19:55.311806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test__[['row_id', 'target']]","metadata":{"execution":{"iopub.status.busy":"2021-08-23T10:19:57.554941Z","iopub.execute_input":"2021-08-23T10:19:57.555365Z","iopub.status.idle":"2021-08-23T10:19:57.568538Z","shell.execute_reply.started":"2021-08-23T10:19:57.555308Z","shell.execute_reply":"2021-08-23T10:19:57.567752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h3><span style='color:red'>UPVOTE</span> if you find it interesting</h3><hr>\nNotebook still under modification </center>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}