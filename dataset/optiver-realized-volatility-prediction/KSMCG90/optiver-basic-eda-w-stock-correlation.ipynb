{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom pathlib import Path \nfrom tqdm import tqdm\nimport re\nimport gc\nfrom pandas.api.types import is_integer_dtype\n# import lightgbm as lgb\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = '../input/optiver-realized-volatility-prediction'\nbase_path = Path(BASE_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"# OPTIMIZE MEMORY from Chris (https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68)\ndef reduce_memory(df,col):\n    mx = df[col].max()\n    if mx<256:\n            df[col] = df[col].astype('uint8')\n    elif mx<65536:\n        df[col] = df[col].astype('uint16')\n    else:\n        df[col] = df[col].astype('uint32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_parquet_df(path_list, train_df=None):\n    df_list = []\n    for path in tqdm(path_list):\n        df = pd.read_parquet(path)\n        stock_id = stock_key(path)\n        df['stock_id'] = stock_id\n        df['stock_id'] = df['stock_id'].astype(np.uint8)\n        ## Currently adding Targets ends in out of memory\n        if train_df is not None:\n            df = df.merge(train_df, on=['stock_id', 'time_id'])\n        df_list.append(df)\n    return pd.concat(df_list, ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{BASE_DIR}/train.csv\")\nreduce_memory(train_df, 'stock_id')\nreduce_memory(train_df, 'time_id')\ntrain_df.info()\ngc.collect()\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dtype = 'float32'\nprint(f\"Max error when converting target to {target_dtype}:\", (train_df['target'] - train_df['target'].astype(target_dtype)).max())\ntarget_dtype = 'float16'\nprint(f\"Max error when converting target to {target_dtype}:\", (train_df['target'] - train_df['target'].astype(target_dtype)).max())\n# train_df['target'] = train_df['target'].astype(target_dtype)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_books_paths = list(Path(base_path / 'book_train.parquet').rglob('*.parquet'))\ntrain_trades_paths = list(Path(base_path / 'trade_train.parquet').rglob('*.parquet'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_key = lambda path: int(re.findall(\"stock_id=(\\d*)\",str(path))[0])\ntrain_books_paths.sort(key = stock_key)\ntrain_trades_paths.sort(key = stock_key)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_books_df = make_parquet_df(train_books_paths[:10], train_df=None)\n# train_trades_df = make_parquet_df(train_trades_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train_books_df.columns:\n    if is_integer_dtype(train_books_df[col].dtype):\n        reduce_memory(train_books_df,col)\ngc.collect()\ntrain_books_df.info()\ntrain_books_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Validation","metadata":{}},{"cell_type":"code","source":"train_books_df['ask_price_diff'] = train_books_df['ask_price2'] - train_books_df['ask_price1']\ntrain_books_df['ask_size_diff'] = train_books_df['ask_size1'] - train_books_df['ask_size2']\ntrain_books_df['bid_price_diff'] = train_books_df['bid_price1'] - train_books_df['bid_price2']\ntrain_books_df['bid_size_diff'] = train_books_df['bid_size1'] - train_books_df['bid_size2']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'ask_price_diff'\nprint(f\"{col}: Maximum {train_books_df[col].max()} and Minimum {train_books_df[col].min()}\")\ncol = 'bid_price_diff'\nprint(f\"{col}: Maximum {train_books_df[col].max()} and Minimum {train_books_df[col].min()}\")\ncol = 'ask_size_diff'\nprint(f\"{col}: Maximum {train_books_df[col].max()} and Minimum {train_books_df[col].min()}\")\ncol = 'bid_size_diff'\nprint(f\"{col}: Maximum {train_books_df[col].max()} and Minimum {train_books_df[col].min()}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_time_ids = train_df['time_id'].nunique()\ntime_ids_per_stock = train_df.groupby('stock_id')['time_id'].nunique()\nprint(f\"There are {unique_time_ids} unique time ids in the training sample, the following stocks are missing some time_ids\")\ntime_ids_per_stock[time_ids_per_stock < unique_time_ids]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_stock_id = train_df['stock_id'].max()\nmissing_stock_ids = [idx for idx in range(max_stock_id) if idx not in train_df['stock_id'].unique()]\nmissing_stock_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Fact that some stocks are missing some of the time_ids, might be a sign that these would be part of the test set","metadata":{}},{"cell_type":"markdown","source":"# Stock Correlation","metadata":{}},{"cell_type":"markdown","source":"It seems many of the stocks volatility are highly correlated","metadata":{}},{"cell_type":"code","source":"stock_corr_df = pd.pivot(train_df, index='time_id', columns='stock_id', values='target').corr()\nstock_corr_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['rolled_target'] = train_df.groupby('stock_id')['target'].transform(lambda x: x.rolling(window=10, min_periods=5).mean())\nsubset_df = train_df[train_df['stock_id'].isin(range(0,15))]\nsubset_df = subset_df[subset_df['time_id'].isin(range(0,1000))]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Warning: Time_ids are not sequential, they have been randomly shuffled\nMore Info: https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249564\nThis high level of correlation does seem to imply that time_id are the same for all stocks as asked in the discussion","metadata":{}},{"cell_type":"code","source":"fig = px.line(subset_df, x='time_id', y='rolled_target', color='stock_id')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(data=subset_df, x='time_id', y='rolled_target', hue='stock_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}