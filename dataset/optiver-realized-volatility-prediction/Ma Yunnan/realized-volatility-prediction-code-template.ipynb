{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\n\nfrom joblib import Parallel, delayed\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('.'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T07:22:44.392335Z","iopub.execute_input":"2021-06-29T07:22:44.392702Z","iopub.status.idle":"2021-06-29T07:22:45.015232Z","shell.execute_reply.started":"2021-06-29T07:22:44.392605Z","shell.execute_reply":"2021-06-29T07:22:45.014136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:22:45.017208Z","iopub.execute_input":"2021-06-29T07:22:45.017699Z","iopub.status.idle":"2021-06-29T07:22:45.022966Z","shell.execute_reply.started":"2021-06-29T07:22:45.017655Z","shell.execute_reply":"2021-06-29T07:22:45.022093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stock_stat(stock_id : int, dataType = 'train'):\n    \n    book_train_subset = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/book_{dataType}.parquet/stock_id={stock_id}/')\n    book_train_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    book_train_subset['bas'] = (book_train_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n                                / book_train_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n                                - 1)                               \n\n    \n    book_train_subset['wap'] = (book_train_subset['bid_price1'] * book_train_subset['ask_size1'] +\n                            book_train_subset['ask_price1'] * book_train_subset['bid_size1']) / (\n                            book_train_subset['bid_size1']+ book_train_subset['ask_size1'])\n\n    book_train_subset['log_return'] = (book_train_subset.groupby(by = ['time_id'])['wap'].\n                                       apply(log_return).\n                                       reset_index(drop = True).\n                                       fillna(0)\n                                      )\n    \n    stock_stat = pd.merge(\n        book_train_subset.groupby(by = ['time_id'])['log_return'].agg(realized_volatility).reset_index(),\n        book_train_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    stock_stat['stock_id'] = stock_id\n    \n    return stock_stat","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:22:45.023984Z","iopub.execute_input":"2021-06-29T07:22:45.02429Z","iopub.status.idle":"2021-06-29T07:22:45.037256Z","shell.execute_reply.started":"2021-06-29T07:22:45.024262Z","shell.execute_reply":"2021-06-29T07:22:45.036406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataSet(stock_ids : list, dataType = 'train'):\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n\n    return stock_stat_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:22:45.038419Z","iopub.execute_input":"2021-06-29T07:22:45.038715Z","iopub.status.idle":"2021-06-29T07:22:45.052973Z","shell.execute_reply.started":"2021-06-29T07:22:45.038685Z","shell.execute_reply":"2021-06-29T07:22:45.051995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n\ntrain_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\ntrain_dataSet = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:22:45.054119Z","iopub.execute_input":"2021-06-29T07:22:45.054393Z","iopub.status.idle":"2021-06-29T07:25:38.234322Z","shell.execute_reply.started":"2021-06-29T07:22:45.054368Z","shell.execute_reply":"2021-06-29T07:25:38.232964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_dataSet['target']\nX_train = train_dataSet.drop(['stock_id', 'time_id', 'target'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:25:38.23767Z","iopub.execute_input":"2021-06-29T07:25:38.238113Z","iopub.status.idle":"2021-06-29T07:25:38.244787Z","shell.execute_reply.started":"2021-06-29T07:25:38.238069Z","shell.execute_reply":"2021-06-29T07:25:38.243945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = XGBRegressor(random_state = 0\n                   #,n_estimators = 200\n                   #,learning_rate = 0.1\n                   #,subsample = 0.8\n                   #,colsample_bytree = 0.8\n                   ,n_jobs= - 1)\n\nclf.fit(X_train,y_train.to_numpy().ravel())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:25:38.246081Z","iopub.execute_input":"2021-06-29T07:25:38.246382Z","iopub.status.idle":"2021-06-29T07:25:57.262525Z","shell.execute_reply.started":"2021-06-29T07:25:38.246354Z","shell.execute_reply":"2021-06-29T07:25:57.26171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n\ntest_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest_dataSet = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\ntest_dataSet = test_dataSet.drop(['stock_id', 'time_id'], axis = 1)\n\ny_pred = test_dataSet[['row_id']]\nX_test = test_dataSet.drop(['row_id'], axis = 1).fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:25:57.263546Z","iopub.execute_input":"2021-06-29T07:25:57.263942Z","iopub.status.idle":"2021-06-29T07:25:57.320476Z","shell.execute_reply.started":"2021-06-29T07:25:57.263914Z","shell.execute_reply":"2021-06-29T07:25:57.319507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = y_pred.assign(target = clf.predict(X_test))\ny_pred.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T07:25:57.321613Z","iopub.execute_input":"2021-06-29T07:25:57.321894Z","iopub.status.idle":"2021-06-29T07:25:57.334247Z","shell.execute_reply.started":"2021-06-29T07:25:57.321871Z","shell.execute_reply":"2021-06-29T07:25:57.333424Z"},"trusted":true},"execution_count":null,"outputs":[]}]}