{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#optiver volatility prediction\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport glob\nimport warnings\nimport seaborn as sns\nwarnings.filterwarnings('ignore')\npd.set_option(\"display.max_columns\", 50)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntest = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\norder_book = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')\ntrade_book = pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train first few rows\ntrain.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first few rows of order book stock = 0\norder_book.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first few rows of trade book stock = 0\ntrade_book.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create log diffs\ndef logDiff(stock_prices):\n    return np.log(stock_prices).diff()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create realized vols for each time / stock price\ndef realized_vol(log_diffs):\n    return np.sqrt(np.sum(log_diffs ** 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#process the order book file\ndef preprocess_order(orderPath):\n    stock = pd.read_parquet(orderPath)\n    stock_id = orderPath.split('=')[1]\n    stock['stock_id'] = stock_id\n    stock['wap'] = (stock['bid_price1'] * stock['ask_size1'] + stock['ask_price1'] * stock['bid_size1']) / (stock['bid_size1'] + stock['ask_size1'])\n    stock['wap2'] = (stock['bid_price2'] * stock['ask_size2'] + stock['ask_price2'] * stock['bid_size2']) / (stock['bid_size2'] + stock['ask_size2'])\n    stock['logDifferences'] = stock.groupby(['time_id'])['wap'].apply(logDiff)\n    stock['logDifferences2'] = stock.groupby(['time_id'])['wap2'].apply(logDiff)    \n    stock['volume_imbalance1'] = stock['bid_size1'] / stock['ask_size1']\n    stock['volume_imbalance2'] = stock['bid_size2'] / stock['ask_size2']\n    stock['spread'] = stock['ask_price1'] - stock['bid_price1']\n    stock['bid_spread'] = stock['bid_price1'] - stock['bid_price2']\n    stock['ask_spread'] = stock['ask_price2'] - stock['ask_price1']\n    \n    \n    return stock","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#glob glob the two file paths with all the trade and order files\norderPath = glob.glob('../input/optiver-realized-volatility-prediction/book_train.parquet/*')\ntradePath = glob.glob('../input/optiver-realized-volatility-prediction/trade_train.parquet/*')\nstock = preprocess_order(orderPath[0])\nstock.head()\n#let's see first few rows of stock = 0 after preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocess the orderbook with aggregate stats\ndef preprocess_order_agg(stk):\n    \n    agg_stats = {\n        'logDifferences':[realized_vol],\n        'logDifferences2':[realized_vol],\n        'wap': [np.mean, np.std],\n        'wap2':[np.mean, np.std],\n        'volume_imbalance1':[np.mean, np.std],\n        'spread':[np.mean, np.std, np.min, np.max],\n        'bid_spread':[np.mean, np.std],\n        'ask_spread':[np.mean, np.std]\n    }\n    \n    df_agg = pd.DataFrame(stk.groupby(['time_id']).agg(agg_stats)).reset_index()\n    df_agg.columns = ['_'.join(col) for col in df_agg.columns]\n    \n    return df_agg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create agg stats for stock\nagg_stats = preprocess_order_agg(stock)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agg_stats.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_trade(tradePath):\n    stk = pd.read_parquet(tradePath)\n    stock_id = tradePath.split('=')[1]\n    stk['stock_id'] = stock_id\n    \n    agg_stats = {\n        'price': [np.mean, np.std, np.min, np.max],\n        'size':[np.sum],\n        'order_count':[np.sum]\n    }\n    \n    df_agg = pd.DataFrame(stk.groupby(['time_id']).agg(agg_stats)).reset_index()\n    df_agg.columns = ['_'.join(col) for col in df_agg.columns]\n   \n    return df_agg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create agg stats for trade book\nagg_stats2 = preprocess_trade(tradePath[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agg_stats2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#time stats\n\ndef time_stats_agg(stk, time_in_seconds):\n    df = pd.DataFrame()\n    \n    agg_stats = {\n        'logDifferences':[realized_vol],\n        'logDifferences2':[realized_vol],\n        'wap': [np.mean, np.std],\n        'wap2':[np.mean, np.std],\n        'volume_imbalance1':[np.mean, np.std],\n        'spread':[np.mean, np.std, np.min, np.max],\n        'bid_spread':[np.mean, np.std],\n        'ask_spread':[np.mean, np.std]\n    }\n    \n    time_df = pd.DataFrame(stk.query(f'seconds_in_bucket > {time_in_seconds}').groupby(['time_id']).agg(agg_stats)).reset_index()\n    time_df.columns = ['_'.join(col) for col in time_df.columns]\n    time_df = time_df.add_suffix('_' + str(time_in_seconds))\n    \n    return time_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create time stats by different time amts\ntime_stats_0 = time_stats_agg(stock, time_in_seconds = 0)\ntime_stats_150 = time_stats_agg(stock, time_in_seconds = 150)\ntime_stats_300 = time_stats_agg(stock, time_in_seconds = 300)\ntime_stats_450 = time_stats_agg(stock, time_in_seconds = 450)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_stats_0.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge all dfs\ntime_stats = time_stats_0.merge(time_stats_150, how = 'left', left_on = 'time_id__0', right_on = 'time_id__150')\ntime_stats = time_stats.merge(time_stats_300, how = 'left', left_on = 'time_id__0', right_on = 'time_id__300')\ntime_stats = time_stats.merge(time_stats_450, how = 'left', left_on = 'time_id__0', right_on = 'time_id__450')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#see columns created\ntime_stats.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop unneccessary time columns and add row_id\nstock_id = orderPath[0].split('=')[1]\ntime_stats['row_id'] = time_stats['time_id__0'].apply(lambda x: f'{stock_id}-{x}')\ntime_stats.drop(['time_id__0','time_id__150', 'time_id__300', 'time_id__450'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_stats.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_stats.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the shape of df to see that it's correct\ntime_stats.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loop through all stocks\ni = 1\ndf_final = pd.DataFrame()\n\nfor (order, trade) in zip(orderPath, tradePath):\n    \n    stock = preprocess_order(order)\n    trade_agg = preprocess_trade(trade)\n    time_stats_0 = time_stats_agg(stock, time_in_seconds = 0)\n    time_stats_150 = time_stats_agg(stock, time_in_seconds = 150)\n    time_stats_300 = time_stats_agg(stock, time_in_seconds = 300)\n    time_stats_450 = time_stats_agg(stock, time_in_seconds = 450)\n    \n    #merge all dfs\n    time_stats = time_stats_0.merge(time_stats_150, how = 'left', left_on = 'time_id__0', right_on = 'time_id__150')\n    time_stats = time_stats.merge(time_stats_300, how = 'left', left_on = 'time_id__0', right_on = 'time_id__300')\n    time_stats = time_stats.merge(time_stats_450, how = 'left', left_on = 'time_id__0', right_on = 'time_id__450')\n    \n    df = time_stats.merge(trade_agg, how = 'left', left_on = 'time_id__0', right_on = 'time_id_')\n    \n    stock_id = order.split('=')[1]\n    df['stock_id'] = int(stock_id)\n    df['row_id'] = df['time_id__0'].apply(lambda x: f'{stock_id}-{x}')\n    \n    df.drop(['time_id__0','time_id__150', 'time_id__300', 'time_id__450'], axis = 1, inplace = True)\n    \n    df_final = pd.concat([df, df_final], axis = 0)\n    \n    if i%10 == 0:\n        print (i)\n    i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check shape of final df\ndf_final.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check first few rows of df_final\ndf_final.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final['stock_id'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.isnull().any().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lgb model\nimport lightgbm as lgb\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import train_test_split\n\nX = df_final.drop(['logDifferences_realized_vol_0', 'row_id'], axis = 1)\ny = df_final['logDifferences_realized_vol_0']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y)\nprint('Shape of X_test is {}'.format(X_test.shape))\nprint('Shape of X_train is {}'.format(X_train.shape))\nprint('Shape of y_test is {}'.format(y_test.shape))\nprint('Shape of y_train is {}'.format(y_train.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build lgb model. fit to train data\nmodel_lgb = lgb.LGBMRegressor()\nmodel_lgb.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make predictions\nypreds = model_lgb.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create RMSPE metric\ndef RMSPE(vols, truth):         \n    return np.sqrt(np.sum(np.mean(np.square((vols - truth)/truth))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check preds against values\nRMSPE(ypreds, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.model_selection import GridSearchCV\nparams = {\n    'num_leaves': [7, 14, 21, 28, 31, 50],\n    'learning_rate': [0.1, 0.03, 0.003],\n    'max_depth': [-1, 3, 5],\n    'n_estimators': [50, 100, 200, 500],\n}\n\ngrid = GridSearchCV(model_lgb, params, scoring='r2', cv = 5)\ngrid.fit(X_train, y_train)","metadata":{}},{"cell_type":"markdown","source":"params = grid.best_params_\n\n{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'num_leaves': 28}","metadata":{}},{"cell_type":"code","source":"#params from gridsearch\nparams = {\n    'learning_rate': 0.1, \n    'max_depth': 5, \n    'n_estimators': 500, \n    'num_leaves': 28\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rerun with new params\nmodel_lgb = lgb.LGBMRegressor(**params)\nmodel_lgb.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create new preds\nypreds = model_lgb.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RMSPE(ypreds, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create preds for test set\n#loop through all stocks\n#glob glob the two file paths with all the trade and order files\norderTest = glob.glob('../input/optiver-realized-volatility-prediction/book_test.parquet/*')\ntradeTest = glob.glob('../input/optiver-realized-volatility-prediction/trade_test.parquet/*')\n\ndf_final = pd.DataFrame()\n\nfor (order, trade) in zip(orderTest, tradeTest):\n    stock = preprocess_order(order)\n    trade_agg = preprocess_trade(trade)\n    time_stats_0 = time_stats_agg(stock, time_in_seconds = 0)\n    time_stats_150 = time_stats_agg(stock, time_in_seconds = 150)\n    time_stats_300 = time_stats_agg(stock, time_in_seconds = 300)\n    time_stats_450 = time_stats_agg(stock, time_in_seconds = 450)\n    \n    #merge all dfs\n    time_stats = time_stats_0.merge(time_stats_150, how = 'left', left_on = 'time_id__0', right_on = 'time_id__150')\n    time_stats = time_stats.merge(time_stats_300, how = 'left', left_on = 'time_id__0', right_on = 'time_id__300')\n    time_stats = time_stats.merge(time_stats_450, how = 'left', left_on = 'time_id__0', right_on = 'time_id__450')\n    \n    df = time_stats.merge(trade_agg, how = 'left', left_on = 'time_id__0', right_on = 'time_id_')\n    df['stock_id'] = int(trade.split('=')[1])\n    df['row_id'] = df['time_id__0'].apply(lambda x: f'{stock_id}-{x}')\n    \n    df.drop(['time_id__0','time_id__150', 'time_id__300', 'time_id__450'], axis = 1, inplace = True)\n    \n    df_final = pd.concat([df, df_final], axis = 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create model on test data\nX = df_final.drop(['logDifferences_realized_vol_0', 'row_id'], axis = 1)\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LGB model\nX['target'] = model_lgb.predict(X)\nX['row_id'] = X['stock_id'].apply(str) + '-' + (X['time_id_']).apply(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = X[['row_id', 'target']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}