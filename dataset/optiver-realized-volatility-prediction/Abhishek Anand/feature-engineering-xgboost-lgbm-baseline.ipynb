{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Feature Engineering\n\nWe have got the orde book and trade data. Here, i have tried to capture various relationships between teh bid, ask prices and the volumes.\nI have also included features from the following notebook https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train/data that capture features from the data. \n\nWill try to explore more features and further relationships between book and trade data. \n\nBasic XGBoost and LBGMRegressor models are used to test out the features and demonstrate their importance.\n\nReferences - \n1. https://www.kaggle.com/munumbutt/naive-optuna-tuned-stacked-ensemble\n2. https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train/data\n3. https://www.kaggle.com/konradb/we-need-to-go-deeper","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nimport os\nimport glob\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\nimport gc\n\nfrom sklearn.model_selection import train_test_split, KFold\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:10.125417Z","iopub.execute_input":"2021-06-30T14:13:10.12579Z","iopub.status.idle":"2021-06-30T14:13:12.568381Z","shell.execute_reply.started":"2021-06-30T14:13:10.125758Z","shell.execute_reply":"2021-06-30T14:13:12.567227Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    data_dir = '../input/optiver-realized-volatility-prediction/'\n    seed = 42","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:12.574492Z","iopub.execute_input":"2021-06-30T14:13:12.577426Z","iopub.status.idle":"2021-06-30T14:13:12.585767Z","shell.execute_reply.started":"2021-06-30T14:13:12.577377Z","shell.execute_reply":"2021-06-30T14:13:12.584722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(Config.data_dir + 'train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:12.593215Z","iopub.execute_input":"2021-06-30T14:13:12.596461Z","iopub.status.idle":"2021-06-30T14:13:12.800635Z","shell.execute_reply.started":"2021-06-30T14:13:12.596413Z","shell.execute_reply":"2021-06-30T14:13:12.799334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.stock_id.unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:12.802473Z","iopub.execute_input":"2021-06-30T14:13:12.802977Z","iopub.status.idle":"2021-06-30T14:13:12.817062Z","shell.execute_reply.started":"2021-06-30T14:13:12.802938Z","shell.execute_reply":"2021-06-30T14:13:12.815543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(Config.data_dir + 'test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:12.819291Z","iopub.execute_input":"2021-06-30T14:13:12.820085Z","iopub.status.idle":"2021-06-30T14:13:12.839589Z","shell.execute_reply.started":"2021-06-30T14:13:12.820036Z","shell.execute_reply":"2021-06-30T14:13:12.838152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.groupby('stock_id').size())\n\nprint(\"\\nUnique size values\")\ndisplay(train.groupby('stock_id').size().unique())","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:14.475178Z","iopub.execute_input":"2021-06-30T14:13:14.475645Z","iopub.status.idle":"2021-06-30T14:13:14.512853Z","shell.execute_reply.started":"2021-06-30T14:13:14.475611Z","shell.execute_reply":"2021-06-30T14:13:14.511422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"markdown","source":"#### File reading","metadata":{}},{"cell_type":"code","source":"def get_trade_and_book_by_stock_and_time_id(stock_id, time_id=None, dataType = 'train'):\n    book_example = pd.read_parquet(f'{Config.data_dir}book_{dataType}.parquet/stock_id={stock_id}')\n    trade_example =  pd.read_parquet(f'{Config.data_dir}trade_{dataType}.parquet/stock_id={stock_id}')\n    if time_id:\n        book_example = book_example[book_example['time_id']==time_id]\n        trade_example = trade_example[trade_example['time_id']==time_id]\n    book_example.loc[:,'stock_id'] = stock_id\n    trade_example.loc[:,'stock_id'] = stock_id\n    return book_example, trade_example","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:17.886601Z","iopub.execute_input":"2021-06-30T14:13:17.886982Z","iopub.status.idle":"2021-06-30T14:13:17.894637Z","shell.execute_reply.started":"2021-06-30T14:13:17.886931Z","shell.execute_reply":"2021-06-30T14:13:17.893269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature engineering","metadata":{}},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\ndef calculate_wap1(df):\n    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n    b1 = df['bid_size1'] + df['ask_size1']\n    a2 = df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']\n    b2 = df['bid_size2'] + df['ask_size2']\n    \n    x = (a1/b1 + a2/b2)/ 2\n    \n    return x\n\n\ndef calculate_wap2(df):\n        \n    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n    a2 = df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']\n    b = df['bid_size1'] + df['ask_size1'] + df['bid_size2']+ df['ask_size2']\n    \n    x = (a1 + a2)/ b\n    return x\n\ndef realized_volatility_per_time_id(file_path, prediction_column_name):\n\n    stock_id = file_path.split('=')[1]\n\n    df_book = pd.read_parquet(file_path)\n    df_book['wap1'] = calculate_wap1(df_book)\n    df_book['wap2'] = calculate_wap2(df_book)\n\n    df_book['log_return1'] = df_book.groupby(['time_id'])['wap1'].apply(log_return)\n    df_book['log_return2'] = df_book.groupby(['time_id'])['wap2'].apply(log_return)\n    df_book = df_book[~df_book['log_return1'].isnull()]\n\n    df_rvps =  pd.DataFrame(df_book.groupby(['time_id'])[['log_return1', 'log_return2']].agg(realized_volatility)).reset_index()\n    df_rvps[prediction_column_name] = 0.6 * df_rvps['log_return1'] + 0.4 * df_rvps['log_return2']\n\n    df_rvps['row_id'] = df_rvps['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    \n    return df_rvps[['row_id',prediction_column_name]]","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:18.470123Z","iopub.execute_input":"2021-06-30T14:13:18.470517Z","iopub.status.idle":"2021-06-30T14:13:18.488474Z","shell.execute_reply.started":"2021-06-30T14:13:18.470481Z","shell.execute_reply":"2021-06-30T14:13:18.487385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_agg_info(df):\n    agg_df = df.groupby(['stock_id', 'time_id']).agg(mean_sec_in_bucket = ('seconds_in_bucket', 'mean'), \n                                                     mean_price = ('price', 'mean'),\n                                                     mean_size = ('size', 'mean'),\n                                                     mean_order = ('order_count', 'mean'),\n                                                     max_sec_in_bucket = ('seconds_in_bucket', 'max'), \n                                                     max_price = ('price', 'max'),\n                                                     max_size = ('size', 'max'),\n                                                     max_order = ('order_count', 'max'),\n                                                     min_sec_in_bucket = ('seconds_in_bucket', 'min'), \n                                                     min_price = ('price', 'min'),\n                                                     #min_size = ('size', 'min'),\n                                                     #min_order = ('order_count', 'min'),\n                                                     median_sec_in_bucket = ('seconds_in_bucket', 'median'), \n                                                     median_price = ('price', 'median'),\n                                                     median_size = ('size', 'median'),\n                                                     median_order = ('order_count', 'median')\n                                                    ).reset_index()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:18.690908Z","iopub.execute_input":"2021-06-30T14:13:18.691308Z","iopub.status.idle":"2021-06-30T14:13:18.700496Z","shell.execute_reply.started":"2021-06-30T14:13:18.691268Z","shell.execute_reply":"2021-06-30T14:13:18.69922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Most of the feature engineering code","metadata":{}},{"cell_type":"code","source":"def get_stock_stat(stock_id : int, dataType = 'train'):\n    \n    book_subset, trade_subset = get_trade_and_book_by_stock_and_time_id(stock_id, dataType=dataType)\n    book_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    ## book data processing\n    \n    book_subset['bas'] = (book_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n                                / book_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n                                - 1)                               \n\n    \n    book_subset['wap1'] = calculate_wap1(book_subset)\n    book_subset['wap2'] = calculate_wap2(book_subset)\n    \n    book_subset['log_return_bid_price1'] = np.log(book_subset['bid_price1'].pct_change() + 1)\n    book_subset['log_return_ask_price1'] = np.log(book_subset['ask_price1'].pct_change() + 1)\n    # book_subset['log_return_bid_price2'] = np.log(book_subset['bid_price2'].pct_change() + 1)\n    # book_subset['log_return_ask_price2'] = np.log(book_subset['ask_price2'].pct_change() + 1)\n    book_subset['log_return_bid_size1'] = np.log(book_subset['bid_size1'].pct_change() + 1)\n    book_subset['log_return_ask_size1'] = np.log(book_subset['ask_size1'].pct_change() + 1)\n    # book_subset['log_return_bid_size2'] = np.log(book_subset['bid_size2'].pct_change() + 1)\n    # book_subset['log_return_ask_size2'] = np.log(book_subset['ask_size2'].pct_change() + 1)\n    book_subset['log_ask_1_div_bid_1'] = np.log(book_subset['ask_price1'] / book_subset['bid_price1'])\n    book_subset['log_ask_1_div_bid_1_size'] = np.log(book_subset['ask_size1'] / book_subset['bid_size1'])\n    \n\n    book_subset['log_return1'] = (book_subset.groupby(by = ['time_id'])['wap1'].\n                                  apply(log_return).\n                                  reset_index(drop = True).\n                                  fillna(0)\n                                 )\n    book_subset['log_return2'] = (book_subset.groupby(by = ['time_id'])['wap2'].\n                                  apply(log_return).\n                                  reset_index(drop = True).\n                                  fillna(0)\n                                 )\n    \n    stock_stat = pd.merge(\n        book_subset.groupby(by = ['time_id'])['log_return1'].agg(realized_volatility).reset_index(),\n        book_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_return2'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_return_bid_price1'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_return_ask_price1'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_return_bid_size1'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_return_ask_size1'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_ask_1_div_bid_1'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    stock_stat = pd.merge(\n        stock_stat,\n        book_subset.groupby(by = ['time_id'])['log_ask_1_div_bid_1_size'].agg(realized_volatility).reset_index(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    \n    stock_stat['stock_id'] = stock_id\n    \n    # Additional features that can be added. Referenced from https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train/data\n    \n    # trade_subset_agg = get_agg_info(trade_subset)\n    \n    #     stock_stat = pd.merge(\n    #         stock_stat,\n    #         trade_subset_agg,\n    #         on = ['stock_id', 'time_id'],\n    #         how = 'left'\n    #     )\n    \n    ## trade data processing \n    \n    return stock_stat\n\ndef get_data_set(stock_ids : list, dataType = 'train'):\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n\n    return stock_stat_df","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:18.938451Z","iopub.execute_input":"2021-06-30T14:13:18.938862Z","iopub.status.idle":"2021-06-30T14:13:18.961296Z","shell.execute_reply.started":"2021-06-30T14:13:18.938816Z","shell.execute_reply":"2021-06-30T14:13:18.959958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Metric","metadata":{}},{"cell_type":"code","source":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:21.962466Z","iopub.execute_input":"2021-06-30T14:13:21.962873Z","iopub.status.idle":"2021-06-30T14:13:21.975173Z","shell.execute_reply.started":"2021-06-30T14:13:21.962824Z","shell.execute_reply":"2021-06-30T14:13:21.973564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plotting","metadata":{}},{"cell_type":"code","source":"def plot_feature_importance(df, model):\n    feature_importances_df = pd.DataFrame({\n        'feature': df.columns,\n        'importance_score': model.feature_importances_\n    })\n    plt.rcParams[\"figure.figsize\"] = [10, 5]\n    ax = sns.barplot(x = \"feature\", y = \"importance_score\", data = feature_importances_df)\n    ax.set(xlabel=\"Features\", ylabel = \"Importance Score\")\n    plt.xticks(rotation=45)\n    plt.show()\n    return feature_importances_df","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:34.233143Z","iopub.execute_input":"2021-06-30T14:13:34.233518Z","iopub.status.idle":"2021-06-30T14:13:34.239852Z","shell.execute_reply.started":"2021-06-30T14:13:34.233488Z","shell.execute_reply":"2021-06-30T14:13:34.238713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Example of book and trade data","metadata":{}},{"cell_type":"code","source":"book_stock_1, trade_stock_1 = get_trade_and_book_by_stock_and_time_id(1, 5)\ndisplay(book_stock_1.shape)\ndisplay(trade_stock_1.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:37.684038Z","iopub.execute_input":"2021-06-30T14:13:37.684398Z","iopub.status.idle":"2021-06-30T14:13:37.917751Z","shell.execute_reply.started":"2021-06-30T14:13:37.684367Z","shell.execute_reply":"2021-06-30T14:13:37.916684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"book_stock_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:38.834479Z","iopub.execute_input":"2021-06-30T14:13:38.834838Z","iopub.status.idle":"2021-06-30T14:13:38.8521Z","shell.execute_reply.started":"2021-06-30T14:13:38.834809Z","shell.execute_reply":"2021-06-30T14:13:38.850948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trade_stock_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:13:39.720932Z","iopub.execute_input":"2021-06-30T14:13:39.721315Z","iopub.status.idle":"2021-06-30T14:13:39.734663Z","shell.execute_reply.started":"2021-06-30T14:13:39.721274Z","shell.execute_reply":"2021-06-30T14:13:39.733212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing Train and Test set for training and prediction with the desired features\nThe following cell takes around 25 mins for execution. You can also use the pickled data from the notebook output and build on that","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_stock_stat_df = get_data_set(train.stock_id.unique(), dataType = 'train')\ntrain_stock_stat_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:07:12.490288Z","iopub.execute_input":"2021-06-30T15:07:12.490741Z","iopub.status.idle":"2021-06-30T15:07:34.438596Z","shell.execute_reply.started":"2021-06-30T15:07:12.490708Z","shell.execute_reply":"2021-06-30T15:07:34.437356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_set = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\ntrain_data_set.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:07:38.757583Z","iopub.execute_input":"2021-06-30T15:07:38.757984Z","iopub.status.idle":"2021-06-30T15:07:38.896323Z","shell.execute_reply.started":"2021-06-30T15:07:38.757951Z","shell.execute_reply":"2021-06-30T15:07:38.894991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_set.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:23:37.904837Z","iopub.execute_input":"2021-06-30T14:23:37.905255Z","iopub.status.idle":"2021-06-30T14:23:37.931383Z","shell.execute_reply.started":"2021-06-30T14:23:37.905164Z","shell.execute_reply":"2021-06-30T14:23:37.930066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_stock_stat_df = get_data_set(test['stock_id'].unique(), dataType = 'test')\ntest_stock_stat_df","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:23:41.150901Z","iopub.execute_input":"2021-06-30T14:23:41.151282Z","iopub.status.idle":"2021-06-30T14:23:42.134646Z","shell.execute_reply.started":"2021-06-30T14:23:41.15125Z","shell.execute_reply":"2021-06-30T14:23:42.133565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_set = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\ntest_data_set.fillna(-999, inplace=True)\ntest_data_set","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:47:07.433432Z","iopub.execute_input":"2021-06-30T14:47:07.433838Z","iopub.status.idle":"2021-06-30T14:47:07.466241Z","shell.execute_reply.started":"2021-06-30T14:47:07.433807Z","shell.execute_reply":"2021-06-30T14:47:07.465045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Storing for later usages. Processing time for features took 25 mins\nYou can directly use this from the notebook output and build on that","metadata":{}},{"cell_type":"code","source":"train_data_set.to_pickle('train_features_df.pickle')\ntest_data_set.to_pickle('test_features_df.pickle')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:48:46.515769Z","iopub.execute_input":"2021-06-30T14:48:46.516207Z","iopub.status.idle":"2021-06-30T14:48:46.533472Z","shell.execute_reply.started":"2021-06-30T14:48:46.516177Z","shell.execute_reply":"2021-06-30T14:48:46.532119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:24:15.136794Z","iopub.execute_input":"2021-06-30T14:24:15.137182Z","iopub.status.idle":"2021-06-30T14:24:15.29324Z","shell.execute_reply.started":"2021-06-30T14:24:15.137153Z","shell.execute_reply":"2021-06-30T14:24:15.291958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_display = train_data_set.drop(['stock_id', 'time_id', 'target'], axis = 1)\nX = X_display.values\ny = train_data_set['target'].values\n\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:24:17.785519Z","iopub.execute_input":"2021-06-30T14:24:17.785993Z","iopub.status.idle":"2021-06-30T14:24:17.797993Z","shell.execute_reply.started":"2021-06-30T14:24:17.785961Z","shell.execute_reply":"2021-06-30T14:24:17.796735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=Config.seed, shuffle=False)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:24:19.325064Z","iopub.execute_input":"2021-06-30T14:24:19.325473Z","iopub.status.idle":"2021-06-30T14:24:19.3371Z","shell.execute_reply.started":"2021-06-30T14:24:19.325441Z","shell.execute_reply":"2021-06-30T14:24:19.335762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trying out basic Regression models without any tuning\n\n#### Basic XGB model","metadata":{}},{"cell_type":"code","source":"xgb = XGBRegressor(tree_method='gpu_hist', random_state = Config.seed, n_jobs= - 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:24:27.10641Z","iopub.execute_input":"2021-06-30T14:24:27.106835Z","iopub.status.idle":"2021-06-30T14:24:27.111739Z","shell.execute_reply.started":"2021-06-30T14:24:27.106805Z","shell.execute_reply":"2021-06-30T14:24:27.11027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nxgb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:24:27.725484Z","iopub.execute_input":"2021-06-30T14:24:27.72588Z","iopub.status.idle":"2021-06-30T14:24:28.375257Z","shell.execute_reply.started":"2021-06-30T14:24:27.72585Z","shell.execute_reply":"2021-06-30T14:24:28.374274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_preds = xgb.predict(X_test)\nR2 = round(r2_score(y_true = y_test, y_pred = xgb_preds), 6)\nRMSPE = round(rmspe(y_true = y_test, y_pred = xgb_preds), 6)\nprint(f'Performance of the naive XGBOOST prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:35:31.105243Z","iopub.execute_input":"2021-06-30T14:35:31.105643Z","iopub.status.idle":"2021-06-30T14:35:31.13242Z","shell.execute_reply.started":"2021-06-30T14:35:31.105612Z","shell.execute_reply":"2021-06-30T14:35:31.130641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature importance score for xgb model","metadata":{}},{"cell_type":"code","source":"plot_feature_importance(X_display, xgb)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:26:05.27037Z","iopub.execute_input":"2021-06-30T14:26:05.270749Z","iopub.status.idle":"2021-06-30T14:26:05.584136Z","shell.execute_reply.started":"2021-06-30T14:26:05.270719Z","shell.execute_reply":"2021-06-30T14:26:05.582764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Basic LGBMRegressor model","metadata":{}},{"cell_type":"code","source":"lgbm = LGBMRegressor(device='gpu', random_state=Config.seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:26:33.580901Z","iopub.execute_input":"2021-06-30T14:26:33.581444Z","iopub.status.idle":"2021-06-30T14:26:33.599176Z","shell.execute_reply.started":"2021-06-30T14:26:33.581399Z","shell.execute_reply":"2021-06-30T14:26:33.594141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlgbm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:26:35.16675Z","iopub.execute_input":"2021-06-30T14:26:35.167134Z","iopub.status.idle":"2021-06-30T14:26:35.927866Z","shell.execute_reply.started":"2021-06-30T14:26:35.167105Z","shell.execute_reply":"2021-06-30T14:26:35.926883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_preds = lgbm.predict(X_test)\nR2 = round(r2_score(y_true = y_test, y_pred = lgbm_preds),6)\nRMSPE = round(rmspe(y_true = y_test, y_pred = lgbm_preds),6)\nprint(f'Performance of the naive LIGHTGBM prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:35:44.842048Z","iopub.execute_input":"2021-06-30T14:35:44.842405Z","iopub.status.idle":"2021-06-30T14:35:44.88108Z","shell.execute_reply.started":"2021-06-30T14:35:44.842375Z","shell.execute_reply":"2021-06-30T14:35:44.879892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature importance score for xgb model","metadata":{}},{"cell_type":"code","source":"plot_feature_importance(X_display, lgbm)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:28:00.450804Z","iopub.execute_input":"2021-06-30T14:28:00.451168Z","iopub.status.idle":"2021-06-30T14:28:00.685121Z","shell.execute_reply.started":"2021-06-30T14:28:00.451138Z","shell.execute_reply":"2021-06-30T14:28:00.683921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above i have tried some experimental features. Will be trying out some other features as well and look to improve the score. Please leave down any suggestions in the comments","metadata":{}},{"cell_type":"code","source":"np.shape(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:43:31.942692Z","iopub.execute_input":"2021-06-30T14:43:31.943093Z","iopub.status.idle":"2021-06-30T14:43:31.950825Z","shell.execute_reply.started":"2021-06-30T14:43:31.94306Z","shell.execute_reply":"2021-06-30T14:43:31.949439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_set_final = test_data_set.drop(['stock_id', 'time_id'], axis = 1)\n\ny_pred = test_data_set_final[['row_id']]\nX_test = test_data_set_final.drop(['row_id'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:47:16.172212Z","iopub.execute_input":"2021-06-30T14:47:16.172631Z","iopub.status.idle":"2021-06-30T14:47:16.182183Z","shell.execute_reply.started":"2021-06-30T14:47:16.1726Z","shell.execute_reply":"2021-06-30T14:47:16.180459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:47:18.163813Z","iopub.execute_input":"2021-06-30T14:47:18.164326Z","iopub.status.idle":"2021-06-30T14:47:18.181812Z","shell.execute_reply.started":"2021-06-30T14:47:18.164264Z","shell.execute_reply":"2021-06-30T14:47:18.179913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"y_pred = y_pred.assign(target = lgbm.predict(X_test))\ny_pred.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:47:55.055918Z","iopub.execute_input":"2021-06-30T14:47:55.056369Z","iopub.status.idle":"2021-06-30T14:47:55.076391Z","shell.execute_reply.started":"2021-06-30T14:47:55.056314Z","shell.execute_reply":"2021-06-30T14:47:55.075348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}