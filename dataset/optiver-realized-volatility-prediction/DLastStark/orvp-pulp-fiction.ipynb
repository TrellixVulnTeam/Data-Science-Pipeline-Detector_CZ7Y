{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Experiment Log:**\n\n|Version |Models Used |CV Score |LB Score| Changes Made\n| --- | --- | --- | --- | --- |\n|v1 |LightGBM | 0.2963 | 0.29675 | Baseline\n|v2 |LightGBM | 0.2945 | 0.29298 | Feature Tools <br> Quantile Transformation\n|v3 |LightGBM | 0.2938 | NA | Trade data included\n|v4 |LightGBM, XGBoost | NA | NA | Ensemble model used\n|v5 | LightGBM, XGBoost | 0.307 | 0.30579 | Ensemble model used\n|v6 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2608 | 0.24344 | Ensemble models used <br> Poly features for log-return\n|v7 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | NA | NA | New features added\n|v8 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2536 | 0.23701 | Error Correction\n|v9 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2559 | 0.23454 | New features added\n|v10 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2545 | 0.22974 | New features added using expanding mean\n|v11 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.24651 | 0.22841 | Quantile transformation for feature scaling\n|v12 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2436 | 0.22758 | New features added\n|v13 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge <br> Voting Regressor | 0.24686 | 0.22779 | New lag features added\n|v14 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.24429 | 0.22805 | New lag features for realized volatility added\n|v15 | Linear Regression, GBR, XGBoost <br> LightGBM, Bayesian Ridge | 0.25574 | NA | New statistical features added\n|v16 | Linear Regression, GBR, XGBoost <br> LightGBM, Bayesian Ridge | 0.24618 | 0.22854 | Removed lag features\n|v17 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.24117 | 0.23223 | Quantile Transformation\n|v18 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2405 | 0.22852 | New features added\n|v19 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.2405 | NA | Capturing meta features for models blend\n|v20 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.24028 | NA | Architecture revamp\n|v21 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.23989 | 0.22832 | Architecture revamp\n|v22 | LightGBM, CatBoost, GBR | 0.2439 | NA | Architecture revamp\n|v23 | LightGBM, CatBoost, GBR | 0.24025 | 0.22821 | Architecture revamp\n|v24 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20982 | 0.21142 | Architecture revamp\n|v25 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20525 | 0.21081 | Models blend section added\n|v26 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20499 | 0.21051 | New features added\n|v27 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20437 | 0.21035 | FeatureTools\n|v28 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20325 | 0.21052 | DAE Features\n|v29 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20545 | 0.20934 | New features added\n|v30 | Linear Regression, GBR, XGB <br> LightGBM, Bayesian Ridge | 0.20552 | NA | New base model added\n|v31 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.19908 | 0.20939 | LGB Model Tuning\n|v32 | Linear Regression, GBR, CatBoost <br> LightGBM, Bayesian Ridge | 0.20048 | 0.21009 | New models added for blending\n|v33 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.1999| 0.21123 | New models added for blending\n|v34 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.19993 | 0.21130 | New models added for blending \n|v35 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20259 | 0.21156 | Tuned LGB Model\n|v36 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.19689 | 0.21041 | New models added for blending\n|v37 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.19840 | 0.21038 | Tuned LGB Model\n|v38 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.20545 | NA | Back to v29 Model design\n|v40 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.22461 | 0.21474 | New DAE Embeddings\n|v41 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.206095 | 11529167.26799 | FeatureTools removed <br> New features added\n|v42 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge | 0.195046 | 0.20733 | New K-Means features added <br> Quantile Transformation removed <br> Highly correlated features removed\n|v43 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge <br> Deep Neural Model | 0.194213 | 0.20736 | New Keras model added\n|v44 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge <br> Deep Neural Model | 0.193335 | 0.20736 | Modified LGB and Keras model\n|v45 | Linear Regression, GBR <br> LightGBM, Bayesian Ridge <br> Deep Neural Model | TBD | TBD | Removed meta model <br> Using weighted average ensemble","metadata":{"papermill":{"duration":0.032014,"end_time":"2021-08-02T11:39:46.867227","exception":false,"start_time":"2021-08-02T11:39:46.835213","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Import libraries","metadata":{"papermill":{"duration":0.031048,"end_time":"2021-08-02T11:39:46.929645","exception":false,"start_time":"2021-08-02T11:39:46.898597","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gc\nimport glob\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import QuantileTransformer\n\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import SpatialDropout1D\nfrom tensorflow.keras.layers import LeakyReLU, Reshape\nfrom tensorflow.keras.layers import Dropout, Concatenate\nfrom tensorflow.keras.layers import Embedding, Dense, Flatten\nfrom tensorflow.keras.layers import Input, BatchNormalization","metadata":{"papermill":{"duration":2.263313,"end_time":"2021-08-02T11:39:49.224073","exception":false,"start_time":"2021-08-02T11:39:46.96076","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:24:57.243744Z","iopub.execute_input":"2021-08-27T12:24:57.244403Z","iopub.status.idle":"2021-08-27T12:25:06.207712Z","shell.execute_reply.started":"2021-08-27T12:24:57.244286Z","shell.execute_reply":"2021-08-27T12:25:06.206839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{"papermill":{"duration":0.031584,"end_time":"2021-08-02T11:39:49.28819","exception":false,"start_time":"2021-08-02T11:39:49.256606","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def rmspe(y_true, y_pred):\n    return (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))","metadata":{"papermill":{"duration":0.039563,"end_time":"2021-08-02T11:39:49.359508","exception":false,"start_time":"2021-08-02T11:39:49.319945","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.209246Z","iopub.execute_input":"2021-08-27T12:25:06.209854Z","iopub.status.idle":"2021-08-27T12:25:06.214891Z","shell.execute_reply.started":"2021-08-27T12:25:06.209806Z","shell.execute_reply":"2021-08-27T12:25:06.213946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmspe_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, dtype=tf.float32)\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n    return (tf.math.sqrt(tf.reduce_mean(tf.math.square((y_true - y_pred) / y_true))))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:25:06.216614Z","iopub.execute_input":"2021-08-27T12:25:06.217069Z","iopub.status.idle":"2021-08-27T12:25:06.228232Z","shell.execute_reply.started":"2021-08-27T12:25:06.217031Z","shell.execute_reply":"2021-08-27T12:25:06.227188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff()","metadata":{"papermill":{"duration":0.037758,"end_time":"2021-08-02T11:39:49.430428","exception":false,"start_time":"2021-08-02T11:39:49.39267","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.230124Z","iopub.execute_input":"2021-08-27T12:25:06.230463Z","iopub.status.idle":"2021-08-27T12:25:06.240276Z","shell.execute_reply.started":"2021-08-27T12:25:06.230431Z","shell.execute_reply":"2021-08-27T12:25:06.239474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","metadata":{"papermill":{"duration":0.038131,"end_time":"2021-08-02T11:39:49.500562","exception":false,"start_time":"2021-08-02T11:39:49.462431","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.241367Z","iopub.execute_input":"2021-08-27T12:25:06.241831Z","iopub.status.idle":"2021-08-27T12:25:06.251425Z","shell.execute_reply.started":"2021-08-27T12:25:06.24179Z","shell.execute_reply":"2021-08-27T12:25:06.250668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_unique(series):\n    return len(np.unique(series))","metadata":{"papermill":{"duration":0.038212,"end_time":"2021-08-02T11:39:49.571066","exception":false,"start_time":"2021-08-02T11:39:49.532854","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.252531Z","iopub.execute_input":"2021-08-27T12:25:06.252969Z","iopub.status.idle":"2021-08-27T12:25:06.262819Z","shell.execute_reply.started":"2021-08-27T12:25:06.252927Z","shell.execute_reply":"2021-08-27T12:25:06.261799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stats_window(df, fe_dict, seconds_in_bucket, add_suffix = False):\n    df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n    df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n    \n    if add_suffix:\n        df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n    \n    return df_feature","metadata":{"papermill":{"duration":0.039633,"end_time":"2021-08-02T11:39:49.641427","exception":false,"start_time":"2021-08-02T11:39:49.601794","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.263896Z","iopub.execute_input":"2021-08-27T12:25:06.264312Z","iopub.status.idle":"2021-08-27T12:25:06.274248Z","shell.execute_reply.started":"2021-08-27T12:25:06.264268Z","shell.execute_reply":"2021-08-27T12:25:06.27323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_trade_data(trade_files):\n    \n    trade_df = pd.DataFrame()\n    \n    for file in tqdm(glob.glob(trade_files)):\n        \n        # Read source file\n        df_trade_data = pd.read_parquet(file)\n        \n        # Feature engineering\n        df_trade_data['log_return'] = df_trade_data.groupby('time_id')['price'].apply(log_return)\n        #df_trade_data.fillna(0, inplace=True)\n        \n        fet_engg_dict = {\n            'price': ['mean','std','sum'],\n            'size': ['mean','std','sum'],\n            'order_count': ['mean','std','sum'],\n            'seconds_in_bucket': [count_unique],\n            'log_return': [realized_volatility,'mean','std','sum']\n        }\n        \n        # Get the stats for different windows\n        df_feature = get_stats_window(df_trade_data, fet_engg_dict, seconds_in_bucket = 0, add_suffix = False)\n        df_feature_120 = get_stats_window(df_trade_data, fet_engg_dict, seconds_in_bucket = 120, add_suffix = True)\n        df_feature_240 = get_stats_window(df_trade_data, fet_engg_dict, seconds_in_bucket = 240, add_suffix = True)\n        df_feature_360 = get_stats_window(df_trade_data, fet_engg_dict, seconds_in_bucket = 360, add_suffix = True)\n        df_feature_480 = get_stats_window(df_trade_data, fet_engg_dict, seconds_in_bucket = 480, add_suffix = True)\n        \n        # Merge all\n        trade_agg_df = df_feature.merge(df_feature_120, how = 'left', left_on = 'time_id_', right_on = 'time_id__120')\n        trade_agg_df = trade_agg_df.merge(df_feature_240, how = 'left', left_on = 'time_id_', right_on = 'time_id__240')\n        trade_agg_df = trade_agg_df.merge(df_feature_360, how = 'left', left_on = 'time_id_', right_on = 'time_id__360')\n        trade_agg_df = trade_agg_df.merge(df_feature_480, how = 'left', left_on = 'time_id_', right_on = 'time_id__480')\n        trade_agg_df = trade_agg_df.add_prefix('trade_')\n        \n        # Generate row_id\n        stock_id = file.split('=')[1]\n        trade_agg_df['row_id'] = trade_agg_df['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n        trade_agg_df.drop(['trade_time_id_'], inplace=True, axis=1)\n        \n        # Merge with parent df\n        trade_df = pd.concat([trade_df, trade_agg_df])\n    \n    del df_trade_data, trade_agg_df, df_feature\n    del df_feature_120, df_feature_240\n    del df_feature_480, df_feature_360\n    gc.collect()\n    \n    return trade_df","metadata":{"papermill":{"duration":0.045552,"end_time":"2021-08-02T11:39:49.719329","exception":false,"start_time":"2021-08-02T11:39:49.673777","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.276896Z","iopub.execute_input":"2021-08-27T12:25:06.277203Z","iopub.status.idle":"2021-08-27T12:25:06.290715Z","shell.execute_reply.started":"2021-08-27T12:25:06.277174Z","shell.execute_reply":"2021-08-27T12:25:06.289679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_book_data(book_files):\n    \n    book_df = pd.DataFrame()\n    \n    for file in tqdm(glob.glob(book_files)):\n        \n        # Read source file\n        df_book_data = pd.read_parquet(file)\n        \n        # Feature engineering\n        df_book_data['wap1'] = (df_book_data['bid_price1'] *\n                                df_book_data['ask_size1'] +\n                                df_book_data['ask_price1'] *\n                                df_book_data['bid_size1'])  / (df_book_data['bid_size1'] +\n                                                               df_book_data['ask_size1'])\n\n        df_book_data['wap2'] = (df_book_data['bid_price2'] *\n                                df_book_data['ask_size2'] +\n                                df_book_data['ask_price2'] *\n                                df_book_data['bid_size2'])  / (df_book_data['bid_size2'] +\n                                                               df_book_data['ask_size2'])\n        \n        df_book_data['wap3'] = (df_book_data['bid_price1'] *\n                                df_book_data['bid_size1'] +\n                                df_book_data['ask_price1'] *\n                                df_book_data['ask_size1'])  / (df_book_data['bid_size1'] +\n                                                               df_book_data['ask_size1'])\n\n        df_book_data['wap4'] = (df_book_data['bid_price2'] *\n                                df_book_data['bid_size2'] +\n                                df_book_data['ask_price2'] *\n                                df_book_data['ask_size2'])  / (df_book_data['bid_size2'] +\n                                                               df_book_data['ask_size2'])\n\n        df_book_data['log_return1'] = df_book_data.groupby(['time_id'])['wap1'].apply(log_return)\n        df_book_data['log_return2'] = df_book_data.groupby(['time_id'])['wap2'].apply(log_return)\n        df_book_data['log_return3'] = df_book_data.groupby(['time_id'])['wap3'].apply(log_return)\n        df_book_data['log_return4'] = df_book_data.groupby(['time_id'])['wap4'].apply(log_return)\n        #df_book_data.fillna(0, inplace=True)\n        \n        df_book_data['wap_balance'] = abs(df_book_data['wap1'] - df_book_data['wap2'])\n        df_book_data['price_spread1'] = (df_book_data['ask_price1'] - df_book_data['bid_price1']) / ((df_book_data['ask_price1'] + df_book_data['bid_price1'])/2)\n        df_book_data['price_spread2'] = (df_book_data['ask_price2'] - df_book_data['bid_price2']) / ((df_book_data['ask_price2'] + df_book_data['bid_price2'])/2)\n        df_book_data['bid_spread'] = df_book_data['bid_price1'] - df_book_data['bid_price2']\n        df_book_data['ask_spread'] = df_book_data['ask_price1'] - df_book_data['ask_price2']\n        df_book_data['bid_ask_spread1'] = abs((df_book_data['bid_price1'] * df_book_data['bid_size1']) - (df_book_data['ask_price1'] * df_book_data['ask_size1']))\n        df_book_data['bid_ask_spread2'] = abs((df_book_data['bid_price2'] * df_book_data['bid_size2']) - (df_book_data['ask_price2'] * df_book_data['ask_size2']))\n        df_book_data['total_volume'] = (df_book_data['ask_size1'] + df_book_data['ask_size2']) + (df_book_data['bid_size1'] + df_book_data['bid_size2'])\n        df_book_data['volume_imbalance'] = abs((df_book_data['ask_size1'] + df_book_data['ask_size2']) - (df_book_data['bid_size1'] + df_book_data['bid_size2']))\n        \n        fet_engg_dict = {\n            'wap1': ['mean','std','sum'],\n            'wap2': ['mean','std','sum'],\n            'wap3': ['mean','std','sum'],\n            'wap4': ['mean','std','sum'],\n            'log_return1': [realized_volatility,'mean','std','sum'],\n            'log_return2': [realized_volatility,'mean','std','sum'],\n            'log_return3': [realized_volatility,'mean','std','sum'],\n            'log_return4': [realized_volatility,'mean','std','sum'],\n            'wap_balance': ['mean','std','sum'],\n            'price_spread1': ['mean','std','sum'],\n            'price_spread2': ['mean','std','sum'],\n            'bid_spread': ['mean','std','sum'],\n            'ask_spread': ['mean','std','sum'],\n            'bid_ask_spread1': ['mean','std','sum'],\n            'bid_ask_spread2': ['mean','std','sum'],\n            'total_volume': ['mean','std','sum'],\n            'volume_imbalance': ['mean','std','sum']\n        }\n        \n        # Get the stats for different windows\n        df_feature = get_stats_window(df_book_data, fet_engg_dict, seconds_in_bucket = 0, add_suffix = False)\n        df_feature_120 = get_stats_window(df_book_data, fet_engg_dict, seconds_in_bucket = 120, add_suffix = True)\n        df_feature_240 = get_stats_window(df_book_data, fet_engg_dict, seconds_in_bucket = 240, add_suffix = True)\n        df_feature_360 = get_stats_window(df_book_data, fet_engg_dict, seconds_in_bucket = 360, add_suffix = True)\n        df_feature_480 = get_stats_window(df_book_data, fet_engg_dict, seconds_in_bucket = 480, add_suffix = True)\n\n        # Merge all\n        book_agg_df = df_feature.merge(df_feature_120, how = 'left', left_on = 'time_id_', right_on = 'time_id__120')\n        book_agg_df = book_agg_df.merge(df_feature_240, how = 'left', left_on = 'time_id_', right_on = 'time_id__240')\n        book_agg_df = book_agg_df.merge(df_feature_360, how = 'left', left_on = 'time_id_', right_on = 'time_id__360')\n        book_agg_df = book_agg_df.merge(df_feature_480, how = 'left', left_on = 'time_id_', right_on = 'time_id__480')\n        book_agg_df = book_agg_df.add_prefix('book_')\n        \n        # Generate row_id\n        stock_id = file.split('=')[1]\n        book_agg_df['row_id'] = book_agg_df['book_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n        book_agg_df.drop(['book_time_id_'], inplace=True, axis=1)\n        \n        # Merge with parent df\n        book_df = pd.concat([book_df, book_agg_df])\n    \n    del df_book_data, book_agg_df, df_feature\n    del df_feature_120, df_feature_240\n    del df_feature_360, df_feature_480\n    gc.collect()\n    \n    return book_df","metadata":{"papermill":{"duration":0.072801,"end_time":"2021-08-02T11:39:49.83087","exception":false,"start_time":"2021-08-02T11:39:49.758069","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.292554Z","iopub.execute_input":"2021-08-27T12:25:06.292986Z","iopub.status.idle":"2021-08-27T12:25:06.319806Z","shell.execute_reply.started":"2021-08-27T12:25:06.292942Z","shell.execute_reply":"2021-08-27T12:25:06.318809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load training data","metadata":{"papermill":{"duration":0.032052,"end_time":"2021-08-02T11:39:49.895707","exception":false,"start_time":"2021-08-02T11:39:49.863655","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with open(\"../input/orvp-django-unchained/ORVP_Ready_Meatballs.txt\", 'rb') as handle: \n    data = handle.read()\n\nprocessed_data = pickle.loads(data)\ntrain_df = processed_data['train_df']\n\ndel processed_data\ngc.collect()","metadata":{"papermill":{"duration":15.949347,"end_time":"2021-08-02T11:40:05.876666","exception":false,"start_time":"2021-08-02T11:39:49.927319","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:06.320867Z","iopub.execute_input":"2021-08-27T12:25:06.321285Z","iopub.status.idle":"2021-08-27T12:25:20.629545Z","shell.execute_reply.started":"2021-08-27T12:25:06.321243Z","shell.execute_reply":"2021-08-27T12:25:20.628524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare testing data","metadata":{"papermill":{"duration":0.03257,"end_time":"2021-08-02T11:40:07.61776","exception":false,"start_time":"2021-08-02T11:40:07.58519","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Test data","metadata":{"papermill":{"duration":0.032102,"end_time":"2021-08-02T11:40:07.681507","exception":false,"start_time":"2021-08-02T11:40:07.649405","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\ntest_df['row_id'] = test_df['stock_id'].astype(str) + '-' + test_df['time_id'].astype(str)\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","metadata":{"papermill":{"duration":0.062053,"end_time":"2021-08-02T11:40:07.776386","exception":false,"start_time":"2021-08-02T11:40:07.714333","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:20.630786Z","iopub.execute_input":"2021-08-27T12:25:20.631065Z","iopub.status.idle":"2021-08-27T12:25:20.667829Z","shell.execute_reply.started":"2021-08-27T12:25:20.631039Z","shell.execute_reply":"2021-08-27T12:25:20.666701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trade data","metadata":{"papermill":{"duration":0.033805,"end_time":"2021-08-02T11:40:07.844489","exception":false,"start_time":"2021-08-02T11:40:07.810684","status":"completed"},"tags":[]}},{"cell_type":"code","source":"trade_test_df = process_trade_data('../input/optiver-realized-volatility-prediction/trade_test.parquet/*')\nprint(f\"trade_test_df: {trade_test_df.shape}\")\ntrade_test_df.head()","metadata":{"papermill":{"duration":0.397377,"end_time":"2021-08-02T11:40:08.274667","exception":false,"start_time":"2021-08-02T11:40:07.87729","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:20.669528Z","iopub.execute_input":"2021-08-27T12:25:20.669965Z","iopub.status.idle":"2021-08-27T12:25:21.141199Z","shell.execute_reply.started":"2021-08-27T12:25:20.669921Z","shell.execute_reply":"2021-08-27T12:25:21.140256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.merge(test_df, trade_test_df, \n                   how='left', on='row_id', \n                   sort=False)\n\n#test_df.fillna(0, inplace=True)\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","metadata":{"papermill":{"duration":0.087097,"end_time":"2021-08-02T11:40:08.398384","exception":false,"start_time":"2021-08-02T11:40:08.311287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:21.142414Z","iopub.execute_input":"2021-08-27T12:25:21.142689Z","iopub.status.idle":"2021-08-27T12:25:21.188111Z","shell.execute_reply.started":"2021-08-27T12:25:21.142662Z","shell.execute_reply":"2021-08-27T12:25:21.186856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Book data","metadata":{"papermill":{"duration":0.036901,"end_time":"2021-08-02T11:40:08.473507","exception":false,"start_time":"2021-08-02T11:40:08.436606","status":"completed"},"tags":[]}},{"cell_type":"code","source":"book_test_df = process_book_data('../input/optiver-realized-volatility-prediction/book_test.parquet/*')\nprint(f\"book_test_df: {book_test_df.shape}\")\nbook_test_df.head()","metadata":{"papermill":{"duration":0.443137,"end_time":"2021-08-02T11:40:08.954236","exception":false,"start_time":"2021-08-02T11:40:08.511099","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:21.189842Z","iopub.execute_input":"2021-08-27T12:25:21.190277Z","iopub.status.idle":"2021-08-27T12:25:21.751362Z","shell.execute_reply.started":"2021-08-27T12:25:21.19023Z","shell.execute_reply":"2021-08-27T12:25:21.750158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.merge(test_df, book_test_df, \n                   how='left', on='row_id', \n                   sort=False)\n\n#test_df.fillna(0, inplace=True)\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","metadata":{"papermill":{"duration":0.087941,"end_time":"2021-08-02T11:40:09.080302","exception":false,"start_time":"2021-08-02T11:40:08.992361","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:21.75312Z","iopub.execute_input":"2021-08-27T12:25:21.753568Z","iopub.status.idle":"2021-08-27T12:25:21.808238Z","shell.execute_reply.started":"2021-08-27T12:25:21.753521Z","shell.execute_reply":"2021-08-27T12:25:21.807226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Group features","metadata":{"papermill":{"duration":0.038003,"end_time":"2021-08-02T11:40:09.156289","exception":false,"start_time":"2021-08-02T11:40:09.118286","status":"completed"},"tags":[]}},{"cell_type":"code","source":"vol_cols = []\nfor col in test_df.columns:\n    if 'realized_volatility' in col:\n        vol_cols.append(col)\n\nlen(vol_cols)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:25:21.809399Z","iopub.execute_input":"2021-08-27T12:25:21.809713Z","iopub.status.idle":"2021-08-27T12:25:21.816917Z","shell.execute_reply.started":"2021-08-27T12:25:21.809682Z","shell.execute_reply":"2021-08-27T12:25:21.81578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stock_id = test_df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min','sum']).reset_index()\ndf_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\ndf_stock_id = df_stock_id.add_suffix('_stock')\ndf_stock_id.head()","metadata":{"papermill":{"duration":0.118687,"end_time":"2021-08-02T11:40:09.313357","exception":false,"start_time":"2021-08-02T11:40:09.19467","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:21.818063Z","iopub.execute_input":"2021-08-27T12:25:21.818341Z","iopub.status.idle":"2021-08-27T12:25:21.943648Z","shell.execute_reply.started":"2021-08-27T12:25:21.818314Z","shell.execute_reply":"2021-08-27T12:25:21.942618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_time_id = test_df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min','sum']).reset_index()\ndf_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\ndf_time_id = df_time_id.add_suffix('_time')\ndf_time_id.head()","metadata":{"papermill":{"duration":0.112994,"end_time":"2021-08-02T11:40:09.468929","exception":false,"start_time":"2021-08-02T11:40:09.355935","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:21.94504Z","iopub.execute_input":"2021-08-27T12:25:21.945623Z","iopub.status.idle":"2021-08-27T12:25:22.070857Z","shell.execute_reply.started":"2021-08-27T12:25:21.945581Z","shell.execute_reply":"2021-08-27T12:25:22.069879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.merge(df_stock_id, how='left', \n                          left_on=['stock_id'], \n                          right_on=['stock_id__stock'])\n\ntest_df = test_df.merge(df_time_id, how='left', \n                          left_on=['time_id'], \n                          right_on=['time_id__time'])\n\ntest_df.drop(['stock_id__stock', 'time_id__time'], \n              axis = 1, inplace = True)\n\ndel df_stock_id, df_time_id\ngc.collect()\n\n#test_df.fillna(0, inplace=True)\nprint(f\"test_df: {test_df.shape}\")","metadata":{"papermill":{"duration":0.195946,"end_time":"2021-08-02T11:40:09.709919","exception":false,"start_time":"2021-08-02T11:40:09.513973","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:25:22.071985Z","iopub.execute_input":"2021-08-27T12:25:22.07228Z","iopub.status.idle":"2021-08-27T12:25:22.320045Z","shell.execute_reply.started":"2021-08-27T12:25:22.072237Z","shell.execute_reply":"2021-08-27T12:25:22.318819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['size_tau'] = np.sqrt(1/test_df['trade_seconds_in_bucket_count_unique'])\ntest_df['size_tau_120'] = np.sqrt(1/test_df['trade_seconds_in_bucket_count_unique_120'])\ntest_df['size_tau_240'] = np.sqrt(1/test_df['trade_seconds_in_bucket_count_unique_240'])\ntest_df['size_tau_360'] = np.sqrt(1/test_df['trade_seconds_in_bucket_count_unique_360'])\ntest_df['size_tau_480'] = np.sqrt(1/test_df['trade_seconds_in_bucket_count_unique_480'])\n\ntest_df['size_tau2'] = np.sqrt(1/test_df['trade_order_count_sum'])\ntest_df['size_tau2_120'] = np.sqrt(0.8/test_df['trade_order_count_sum'])\ntest_df['size_tau2_240'] = np.sqrt(0.6/test_df['trade_order_count_sum'])\ntest_df['size_tau2_360'] = np.sqrt(0.4/test_df['trade_order_count_sum'])\ntest_df['size_tau2_480'] = np.sqrt(0.2/test_df['trade_order_count_sum'])\n\ntest_df['size_tau3'] = np.sqrt(1/test_df['trade_order_count_mean'])\ntest_df['size_tau3_120'] = np.sqrt(0.8/test_df['trade_order_count_mean'])\ntest_df['size_tau3_240'] = np.sqrt(0.6/test_df['trade_order_count_mean'])\ntest_df['size_tau3_360'] = np.sqrt(0.4/test_df['trade_order_count_mean'])\ntest_df['size_tau3_480'] = np.sqrt(0.2/test_df['trade_order_count_mean'])\n\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:25:22.321451Z","iopub.execute_input":"2021-08-27T12:25:22.321771Z","iopub.status.idle":"2021-08-27T12:25:22.380361Z","shell.execute_reply.started":"2021-08-27T12:25:22.32174Z","shell.execute_reply":"2021-08-27T12:25:22.379504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filter_cols = ['trade_time_id__120', 'trade_time_id__240', 'trade_time_id__360', \n               'trade_time_id__480', 'book_time_id__120', 'book_time_id__240', \n               'book_time_id__360', 'book_time_id__480']\n\ntest_df.drop(filter_cols, axis=1, inplace=True)\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:25:22.381531Z","iopub.execute_input":"2021-08-27T12:25:22.382002Z","iopub.status.idle":"2021-08-27T12:25:22.416542Z","shell.execute_reply.started":"2021-08-27T12:25:22.381959Z","shell.execute_reply":"2021-08-27T12:25:22.415451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional features","metadata":{}},{"cell_type":"code","source":"train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n\ncorr = train_p.corr()\nids = corr.index\n\nkmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n\nl = []\nfor n in range(7):\n    l.append([(x-1) for x in ((ids+1)*(kmeans.labels_ == n)) if x > 0])\n\nmat = []\nmatTest = []\n\nn = 0\nfor ind in tqdm(l):\n    newDf = train_df.loc[train_df['stock_id'].isin(ind)]\n    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n    newDf.loc[:,'stock_id'] = str(n)+'c1'\n    mat.append(newDf)\n    \n    newDf = test_df.loc[test_df['stock_id'].isin(ind) ]    \n    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n    newDf.loc[:,'stock_id'] = str(n)+'c1'\n    matTest.append(newDf)\n    \n    n+=1\n    \nmat1 = pd.concat(mat).reset_index()\nmat1.drop(columns=['target'],inplace=True)\nmat2 = pd.concat(matTest).reset_index()\n\nmat2 = pd.concat([mat2, mat1.loc[mat1.time_id==5]])\nmat1 = mat1.pivot(index='time_id', columns='stock_id')\nmat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\nmat1.reset_index(inplace=True)\n\nmat2 = mat2.pivot(index='time_id', columns='stock_id')\nmat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\nmat2.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:25:22.418004Z","iopub.execute_input":"2021-08-27T12:25:22.418492Z","iopub.status.idle":"2021-08-27T12:25:28.352471Z","shell.execute_reply.started":"2021-08-27T12:25:22.418455Z","shell.execute_reply":"2021-08-27T12:25:28.351354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nnn = [\n    'time_id',\n    'book_log_return1_realized_volatility_0c1',\n    'book_log_return1_realized_volatility_1c1',\n    'book_log_return1_realized_volatility_2c1',\n    'book_log_return1_realized_volatility_3c1',\n    'book_log_return1_realized_volatility_4c1',\n    'book_log_return1_realized_volatility_5c1',\n    'book_log_return1_realized_volatility_6c1',\n    'book_total_volume_sum_0c1',\n    'book_total_volume_sum_1c1',\n    'book_total_volume_sum_2c1',\n    'book_total_volume_sum_3c1',\n    'book_total_volume_sum_4c1',\n    'book_total_volume_sum_5c1',\n    'book_total_volume_sum_6c1',\n    'trade_size_sum_0c1',\n    'trade_size_sum_1c1',\n    'trade_size_sum_2c1',\n    'trade_size_sum_3c1',\n    'trade_size_sum_4c1',\n    'trade_size_sum_5c1',\n    'trade_size_sum_6c1',\n    'trade_order_count_sum_0c1',\n    'trade_order_count_sum_1c1',\n    'trade_order_count_sum_2c1',\n    'trade_order_count_sum_3c1',\n    'trade_order_count_sum_4c1',\n    'trade_order_count_sum_5c1',\n    'trade_order_count_sum_6c1',\n    'book_price_spread2_sum_0c1',\n    'book_price_spread2_sum_1c1',\n    'book_price_spread2_sum_2c1',\n    'book_price_spread2_sum_3c1',\n    'book_price_spread2_sum_4c1',\n    'book_price_spread2_sum_5c1',\n    'book_price_spread2_sum_6c1',\n    'book_bid_spread_sum_0c1',\n    'book_bid_spread_sum_1c1',\n    'book_bid_spread_sum_2c1',\n    'book_bid_spread_sum_3c1',\n    'book_bid_spread_sum_4c1',\n    'book_bid_spread_sum_5c1',\n    'book_bid_spread_sum_6c1',\n    'book_ask_spread_sum_0c1',\n    'book_ask_spread_sum_1c1',\n    'book_ask_spread_sum_2c1',\n    'book_ask_spread_sum_3c1',\n    'book_ask_spread_sum_4c1',\n    'book_ask_spread_sum_5c1',\n    'book_ask_spread_sum_6c1',\n    'book_volume_imbalance_sum_0c1',\n    'book_volume_imbalance_sum_1c1',\n    'book_volume_imbalance_sum_2c1',\n    'book_volume_imbalance_sum_3c1',\n    'book_volume_imbalance_sum_4c1',\n    'book_volume_imbalance_sum_5c1',\n    'book_volume_imbalance_sum_6c1',\n    'book_bid_ask_spread2_sum_120_0c1',\n    'book_bid_ask_spread2_sum_120_1c1',\n    'book_bid_ask_spread2_sum_120_2c1',\n    'book_bid_ask_spread2_sum_120_3c1',\n    'book_bid_ask_spread2_sum_120_4c1',\n    'book_bid_ask_spread2_sum_120_5c1',\n    'book_bid_ask_spread2_sum_120_6c1',\n    'size_tau2_0c1',\n    'size_tau2_1c1',\n    'size_tau2_2c1',\n    'size_tau2_3c1',\n    'size_tau2_4c1',\n    'size_tau2_5c1',\n    'size_tau2_6c1'\n]\n\ntrain_df = pd.merge(train_df, mat1[nnn], how='left', on='time_id')\ntest_df = pd.merge(test_df, mat2[nnn], how='left', on='time_id')\n\ndel mat1, mat2\ngc.collect()\n\ntrain_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:25:28.356427Z","iopub.execute_input":"2021-08-27T12:25:28.356788Z","iopub.status.idle":"2021-08-27T12:27:05.844558Z","shell.execute_reply.started":"2021-08-27T12:25:28.356756Z","shell.execute_reply":"2021-08-27T12:27:05.843446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation check","metadata":{}},{"cell_type":"code","source":"# Get highly correlated columns to remove\n# df = train_df.loc[:, train_df.columns != 'target'].copy()\n# cor_matrix = df.corr().abs()\n# upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n# print(f\"Number of columns to drop: {len(to_drop)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:27:05.846214Z","iopub.execute_input":"2021-08-27T12:27:05.846667Z","iopub.status.idle":"2021-08-27T12:36:01.209419Z","shell.execute_reply.started":"2021-08-27T12:27:05.846622Z","shell.execute_reply":"2021-08-27T12:36:01.208353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select_cols = [\n    'stock_id', 'time_id', 'row_id', 'trade_price_mean', 'trade_price_std', 'trade_price_sum', 'trade_size_mean', 'trade_size_std', 'trade_size_sum', \n    'trade_order_count_mean', 'trade_order_count_std', 'trade_order_count_sum', 'trade_log_return_realized_volatility', 'trade_log_return_mean', \n    'trade_log_return_std', 'trade_log_return_sum', 'trade_order_count_std_120', 'trade_log_return_mean_120', 'trade_log_return_sum_120', 'trade_price_std_240', \n    'trade_size_mean_240', 'trade_order_count_std_240', 'trade_log_return_mean_240', 'trade_log_return_sum_240', 'trade_price_std_360', 'trade_size_mean_360', \n    'trade_size_std_360', 'trade_order_count_mean_360', 'trade_order_count_std_360', 'trade_log_return_mean_360', 'trade_log_return_sum_360', 'trade_price_std_480', \n    'trade_size_mean_480', 'trade_size_std_480', 'trade_size_sum_480', 'trade_order_count_mean_480', 'trade_order_count_std_480', \n    'trade_log_return_realized_volatility_480', 'trade_log_return_mean_480', 'trade_log_return_std_480', 'trade_log_return_sum_480', 'book_wap1_sum', \n    'book_log_return1_realized_volatility', 'book_log_return1_mean', 'book_log_return3_mean', 'book_log_return4_mean', 'book_wap_balance_mean', \n    'book_wap_balance_sum', 'book_price_spread1_std', 'book_price_spread2_sum', 'book_bid_spread_mean', 'book_bid_spread_std', 'book_bid_spread_sum', \n    'book_ask_spread_mean', 'book_ask_spread_std', 'book_ask_spread_sum', 'book_bid_ask_spread1_mean', 'book_bid_ask_spread1_std', 'book_bid_ask_spread2_mean', \n    'book_bid_ask_spread2_std', 'book_total_volume_mean', 'book_total_volume_std', 'book_volume_imbalance_mean', 'book_log_return1_mean_120', \n    'book_log_return2_mean_120', 'book_log_return3_mean_120', 'book_log_return4_mean_120', 'book_log_return1_mean_240', 'book_log_return2_mean_240', \n    'book_log_return3_mean_240', 'book_log_return4_mean_240', 'book_log_return1_mean_360', 'book_log_return2_mean_360', 'book_log_return3_mean_360', \n    'book_log_return4_mean_360', 'book_bid_ask_spread1_std_360', 'book_bid_ask_spread2_std_360', 'book_total_volume_std_360', 'book_volume_imbalance_std_360', \n    'book_wap1_std_480', 'book_log_return1_mean_480', 'book_log_return1_sum_480', 'book_log_return2_mean_480', 'book_log_return2_sum_480', \n    'book_log_return3_mean_480', 'book_log_return3_sum_480', 'book_log_return4_mean_480', 'book_log_return4_sum_480', 'book_price_spread1_std_480', \n    'book_price_spread2_std_480', 'book_bid_spread_std_480', 'book_ask_spread_std_480', 'book_bid_ask_spread1_std_480', 'book_bid_ask_spread2_std_480', \n    'book_total_volume_std_480', 'book_volume_imbalance_std_480', 'trade_log_return_realized_volatility_mean_stock', \n    'trade_log_return_realized_volatility_std_stock', 'trade_log_return_realized_volatility_max_stock', 'trade_log_return_realized_volatility_min_stock', \n    'trade_log_return_realized_volatility_120_max_stock', 'trade_log_return_realized_volatility_120_min_stock', \n    'trade_log_return_realized_volatility_240_max_stock', 'trade_log_return_realized_volatility_240_min_stock', \n    'trade_log_return_realized_volatility_360_max_stock', 'trade_log_return_realized_volatility_360_min_stock', \n    'trade_log_return_realized_volatility_480_max_stock', 'trade_log_return_realized_volatility_480_min_stock', \n    'book_log_return1_realized_volatility_mean_stock', 'book_log_return1_realized_volatility_std_stock', \n    'book_log_return1_realized_volatility_max_stock', 'book_log_return1_realized_volatility_min_stock', \n    'book_log_return2_realized_volatility_max_stock', 'book_log_return2_realized_volatility_min_stock', \n    'book_log_return3_realized_volatility_max_stock', 'book_log_return3_realized_volatility_min_stock', \n    'book_log_return4_realized_volatility_max_stock', 'book_log_return4_realized_volatility_min_stock', \n    'book_log_return1_realized_volatility_120_max_stock', 'book_log_return2_realized_volatility_120_min_stock', \n    'book_log_return1_realized_volatility_240_min_stock', 'book_log_return2_realized_volatility_240_min_stock', \n    'book_log_return3_realized_volatility_240_min_stock', 'book_log_return1_realized_volatility_360_min_stock', \n    'book_log_return2_realized_volatility_360_min_stock', 'book_log_return3_realized_volatility_360_min_stock', \n    'book_log_return4_realized_volatility_360_min_stock', 'book_log_return1_realized_volatility_480_max_stock', \n    'book_log_return1_realized_volatility_480_min_stock', 'book_log_return2_realized_volatility_480_max_stock', \n    'book_log_return2_realized_volatility_480_min_stock', 'book_log_return3_realized_volatility_480_max_stock', \n    'book_log_return3_realized_volatility_480_min_stock', 'book_log_return4_realized_volatility_480_max_stock', \n    'book_log_return4_realized_volatility_480_min_stock', 'trade_log_return_realized_volatility_mean_time', \n    'trade_log_return_realized_volatility_std_time', 'trade_log_return_realized_volatility_max_time', \n    'trade_log_return_realized_volatility_min_time', 'trade_log_return_realized_volatility_360_min_time', \n    'trade_log_return_realized_volatility_480_max_time', 'trade_log_return_realized_volatility_480_min_time', \n    'book_log_return1_realized_volatility_std_time', 'book_log_return1_realized_volatility_min_time', \n    'book_log_return2_realized_volatility_480_min_time', 'size_tau', 'size_tau_480', 'size_tau2', 'size_tau3',\n    'book_log_return1_realized_volatility_1c1', 'book_log_return1_realized_volatility_2c1', 'book_log_return1_realized_volatility_5c1',\n    'book_total_volume_sum_0c1', 'book_total_volume_sum_1c1', 'book_total_volume_sum_2c1', 'book_total_volume_sum_3c1', 'book_total_volume_sum_4c1', \n    'book_total_volume_sum_5c1', 'book_total_volume_sum_6c1', 'trade_size_sum_0c1', 'trade_size_sum_1c1', 'trade_size_sum_2c1', 'trade_size_sum_3c1', \n    'trade_size_sum_4c1', 'trade_size_sum_5c1', 'trade_size_sum_6c1', 'trade_order_count_sum_1c1', 'trade_order_count_sum_2c1', 'trade_order_count_sum_4c1', \n    'trade_order_count_sum_5c1', 'trade_order_count_sum_6c1', 'book_price_spread2_sum_2c1', 'book_price_spread2_sum_5c1', 'book_bid_spread_sum_1c1', \n    'book_bid_spread_sum_2c1', 'book_bid_spread_sum_5c1', 'book_ask_spread_sum_1c1', 'book_ask_spread_sum_2c1', 'book_ask_spread_sum_5c1', \n    'book_volume_imbalance_sum_0c1', 'book_volume_imbalance_sum_3c1', 'book_volume_imbalance_sum_4c1', 'book_volume_imbalance_sum_6c1', \n    'book_bid_ask_spread2_sum_120_0c1', 'book_bid_ask_spread2_sum_120_1c1', 'book_bid_ask_spread2_sum_120_2c1', 'book_bid_ask_spread2_sum_120_3c1', \n    'book_bid_ask_spread2_sum_120_4c1', 'book_bid_ask_spread2_sum_120_5c1', 'book_bid_ask_spread2_sum_120_6c1', 'size_tau2_0c1', 'size_tau2_1c1', \n    'size_tau2_2c1', 'size_tau2_3c1', 'size_tau2_4c1', 'size_tau2_5c1', 'size_tau2_6c1'\n]\n\nlen(select_cols)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:38:30.191339Z","iopub.execute_input":"2021-08-27T12:38:30.191894Z","iopub.status.idle":"2021-08-27T12:38:30.213185Z","shell.execute_reply.started":"2021-08-27T12:38:30.191851Z","shell.execute_reply":"2021-08-27T12:38:30.211834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain = train_df[select_cols].copy()\nYtrain = train_df['target'].copy()\nYtrain_strat = pd.qcut(train_df['target'].values, q=10, labels=range(0,10))\n\nXtrain.drop(['row_id'], axis=1, inplace=True)\nXtrain.replace([np.nan, np.inf, -np.inf], 0, inplace=True)\nprint(f\"Xtrain: {Xtrain.shape} \\nYtrain: {Ytrain.shape} \\nYtrain_strat: {Ytrain_strat.shape}\")\n\ndel train_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:38:32.944559Z","iopub.execute_input":"2021-08-27T12:38:32.945078Z","iopub.status.idle":"2021-08-27T12:38:33.859555Z","shell.execute_reply.started":"2021-08-27T12:38:32.945031Z","shell.execute_reply":"2021-08-27T12:38:33.858567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtest = test_df[select_cols].copy()\nXtest.drop(['row_id'], axis=1, inplace=True)\nXtest.replace([np.nan, np.inf, -np.inf], 0, inplace=True)\nprint(f\"Xtest: {Xtest.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:38:35.702341Z","iopub.execute_input":"2021-08-27T12:38:35.702771Z","iopub.status.idle":"2021-08-27T12:38:35.718929Z","shell.execute_reply.started":"2021-08-27T12:38:35.702735Z","shell.execute_reply":"2021-08-27T12:38:35.717726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = ['stock_id','time_id']\n\nXtrain[cat_cols] = Xtrain[cat_cols].astype(int)\nXtest[cat_cols] = Xtest[cat_cols].astype(int)\ncat_cols_indices = [Xtrain.columns.get_loc(col) for col in cat_cols]\nprint(cat_cols_indices)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:38:38.642419Z","iopub.execute_input":"2021-08-27T12:38:38.64301Z","iopub.status.idle":"2021-08-27T12:38:38.662864Z","shell.execute_reply.started":"2021-08-27T12:38:38.642973Z","shell.execute_reply":"2021-08-27T12:38:38.661646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_list = []\ndf = Xtrain.copy()\ndf['target'] = Ytrain.ravel()\nfor col in df.columns:\n    corr = df[col].corr(df['target'])\n    corr_list.append([col, corr])\n\ndf = pd.DataFrame(corr_list, columns=['Column','Correlation'])\ndf['Correlation'] = np.round(df['Correlation'], 2)\ndf = df.sort_values(by='Correlation', ascending=False).head(20).copy()\n\nplt.figure(figsize=(12, 10))\nsns.barplot(x='Correlation', y='Column', data=df)\nplt.title(\"Top-20 features with high correlation with target\", pad=20);","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:38:40.732869Z","iopub.execute_input":"2021-08-27T12:38:40.733328Z","iopub.status.idle":"2021-08-27T12:38:42.268114Z","shell.execute_reply.started":"2021-08-27T12:38:40.733281Z","shell.execute_reply":"2021-08-27T12:38:42.266985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:38:42.571861Z","iopub.execute_input":"2021-08-27T12:38:42.572298Z","iopub.status.idle":"2021-08-27T12:38:42.764253Z","shell.execute_reply.started":"2021-08-27T12:38:42.572242Z","shell.execute_reply":"2021-08-27T12:38:42.76332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Base models\n\n* **BayesianRidge**\n* **HistGradientBoostingRegressor**\n* **Linear Regression**\n* **LightGBM**","metadata":{"papermill":{"duration":0.202373,"end_time":"2021-08-02T11:53:56.860499","exception":false,"start_time":"2021-08-02T11:53:56.658126","status":"completed"},"tags":[]}},{"cell_type":"code","source":"FOLD = 10\nSEEDS = [2018, 2020]\nCOUNTER = 0\n\noof_score_ridge = 0\noof_score_gbr = 0\noof_score_lgb = 0\noof_score_lr = 0\n\ny_pred_final_ridge = 0\ny_pred_final_gbr = 0\ny_pred_final_lgb = 0\ny_pred_final_lr = 0\n\ny_pred_meta_ridge = np.zeros((Xtrain.shape[0], 1))\ny_pred_meta_gbr = np.zeros((Xtrain.shape[0], 1))\ny_pred_meta_lgb = np.zeros((Xtrain.shape[0], 1))\ny_pred_meta_lr = np.zeros((Xtrain.shape[0], 1))","metadata":{"papermill":{"duration":0.195128,"end_time":"2021-08-02T11:53:57.242673","exception":false,"start_time":"2021-08-02T11:53:57.047545","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:38:48.802407Z","iopub.execute_input":"2021-08-27T12:38:48.802889Z","iopub.status.idle":"2021-08-27T12:38:48.814717Z","shell.execute_reply.started":"2021-08-27T12:38:48.802848Z","shell.execute_reply":"2021-08-27T12:38:48.813555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Model Name  \\tSeed \\tFold \\tOOF Score \\tAggregate OOF Score\")\nprint(\"=\"*68)\n\nfor sidx, seed in enumerate(SEEDS):\n    seed_score_ridge = 0\n    seed_score_gbr = 0\n    seed_score_lgb = 0\n    seed_score_lr = 0\n    \n    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n    for idx, (train, val) in enumerate(kfold.split(Xtrain, Ytrain_strat)):\n        COUNTER += 1\n\n        train_x, train_y = Xtrain.iloc[train], Ytrain.iloc[train]\n        val_x, val_y = Xtrain.iloc[val], Ytrain.iloc[val]\n        weights = 1/np.square(train_y)\n        \n        \n        #====================================================================\n        #                          Linear Regression\n        #====================================================================\n        \n        lr_model = LinearRegression()\n        lr_model.fit(train_x, train_y, sample_weight = weights)\n        \n        y_pred = lr_model.predict(val_x)\n        y_pred_meta_lr[val] += np.array([y_pred]).T\n        y_pred_final_lr += lr_model.predict(Xtest)\n        \n        score = rmspe(val_y, y_pred)\n        oof_score_lr += score\n        seed_score_lr += score\n        print(f\"LR        \\t{seed} \\t{idx+1} \\t{round(score,5)}\")\n        \n        \n        #====================================================================\n        #                           Bayesian Ridge\n        #====================================================================\n        \n        ridge_model = BayesianRidge(n_iter=1000)\n        ridge_model.fit(train_x, train_y, sample_weight = weights)\n        \n        y_pred = ridge_model.predict(val_x)\n        y_pred_meta_ridge[val] += np.array([y_pred]).T\n        y_pred_final_ridge += ridge_model.predict(Xtest)\n        \n        score = rmspe(val_y, y_pred)\n        oof_score_ridge += score\n        seed_score_ridge += score\n        print(f\"Bayesian Ridge \\t{seed} \\t{idx+1} \\t{round(score,5)}\")\n        \n        \n        #====================================================================\n        #                     HistGradientBoostingRegressor\n        #====================================================================\n        \n        gbr_model = HistGradientBoostingRegressor(\n            max_depth=7,\n            learning_rate=0.05,\n            max_iter=1000,\n            max_leaf_nodes=72, \n            early_stopping=True,\n            n_iter_no_change=100,\n            random_state=0\n        )\n        gbr_model.fit(train_x, train_y, sample_weight = weights)\n        \n        y_pred = gbr_model.predict(val_x)\n        y_pred_meta_gbr[val] += np.array([y_pred]).T\n        y_pred_final_gbr += gbr_model.predict(Xtest)\n        \n        score = rmspe(val_y, y_pred)\n        oof_score_gbr += score\n        seed_score_gbr += score\n        print(f\"GBR        \\t{seed} \\t{idx+1} \\t{round(score,5)}\")\n        \n        \n        #====================================================================\n        #                              LightGBM\n        #====================================================================\n        \n        lgb_model = LGBMRegressor(\n            boosting_type='gbdt', \n            num_leaves=72, \n            max_depth=7, \n            learning_rate=0.02, \n            n_estimators=1000, \n            objective='regression', \n            importance_type='gain',\n            min_child_samples=20, \n            subsample=0.65, \n            subsample_freq=10, \n            colsample_bytree=0.75, \n            reg_lambda=0.05, \n            random_state=0\n        )\n        \n        lgb_model.fit(train_x, train_y, eval_metric='rmse',\n                      eval_set=(val_x, val_y),\n                      early_stopping_rounds=100, \n                      categorical_feature=cat_cols_indices, \n                      sample_weight = weights, verbose=False)\n        \n        y_pred = lgb_model.predict(val_x, num_iteration=lgb_model.best_iteration_)\n        y_pred_meta_lgb[val] += np.array([y_pred]).T\n        y_pred_final_lgb += lgb_model.predict(Xtest, num_iteration=lgb_model.best_iteration_)\n        \n        score = rmspe(val_y, y_pred)\n        oof_score_lgb += score\n        seed_score_lgb += score\n        print(f\"LightGBM    \\t{seed} \\t{idx+1} \\t{round(score,5)}\\n\")\n        \n        \n    print(\"=\"*68)\n    print(f\"Bayesian Ridge \\t{seed} \\t\\t\\t\\t{round(seed_score_ridge / FOLD, 5)}\")\n    print(f\"GBR            \\t{seed} \\t\\t\\t\\t{round(seed_score_gbr / FOLD, 5)}\")\n    print(f\"LR             \\t{seed} \\t\\t\\t\\t{round(seed_score_lr / FOLD, 5)}\")\n    print(f\"LightGBM       \\t{seed} \\t\\t\\t\\t{round(seed_score_lgb / FOLD, 5)}\")\n    print(\"=\"*68)","metadata":{"papermill":{"duration":9978.561146,"end_time":"2021-08-02T14:40:15.984936","exception":false,"start_time":"2021-08-02T11:53:57.42379","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:43:38.915931Z","iopub.execute_input":"2021-08-27T12:43:38.916624Z","iopub.status.idle":"2021-08-27T12:45:49.55614Z","shell.execute_reply.started":"2021-08-27T12:43:38.91657Z","shell.execute_reply":"2021-08-27T12:45:49.554523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_final_ridge = y_pred_final_ridge / float(COUNTER)\ny_pred_final_gbr = y_pred_final_gbr / float(COUNTER)\ny_pred_final_lr = y_pred_final_lr / float(COUNTER)\ny_pred_final_lgb = y_pred_final_lgb / float(COUNTER)\n\ny_pred_meta_ridge = y_pred_meta_ridge / float(len(SEEDS))\ny_pred_meta_gbr = y_pred_meta_gbr / float(len(SEEDS))\ny_pred_meta_lr = y_pred_meta_lr / float(len(SEEDS))\ny_pred_meta_lgb = y_pred_meta_lgb / float(len(SEEDS))\n\noof_score_ridge /= float(COUNTER)\noof_score_gbr /= float(COUNTER)\noof_score_lr /= float(COUNTER)\noof_score_lgb /= float(COUNTER)\n\nprint(f\"Bayesian Ridge | Aggregate OOF Score: {round(oof_score_ridge,5)}\")\nprint(f\"GradientBoostingRegressor | Aggregate OOF Score: {round(oof_score_gbr,5)}\")\nprint(f\"Linear Regression | Aggregate OOF Score: {round(oof_score_lr,5)}\")\nprint(f\"LightGBM | Aggregate OOF Score: {round(oof_score_lgb,5)}\")","metadata":{"papermill":{"duration":0.317772,"end_time":"2021-08-02T14:40:16.527863","exception":false,"start_time":"2021-08-02T14:40:16.210091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T07:13:36.62516Z","iopub.execute_input":"2021-08-27T07:13:36.625822Z","iopub.status.idle":"2021-08-27T07:13:36.64165Z","shell.execute_reply.started":"2021-08-27T07:13:36.625774Z","shell.execute_reply":"2021-08-27T07:13:36.640131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deep Neural Model","metadata":{}},{"cell_type":"code","source":"num_cols = [col for col in Xtrain.columns if col not in cat_cols]\nlen(cat_cols), len(num_cols)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:46:05.890569Z","iopub.execute_input":"2021-08-27T12:46:05.890981Z","iopub.status.idle":"2021-08-27T12:46:05.897982Z","shell.execute_reply.started":"2021-08-27T12:46:05.890949Z","shell.execute_reply":"2021-08-27T12:46:05.89724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in tqdm(num_cols):\n    transformer = QuantileTransformer(n_quantiles=5000, \n                                      random_state=2020, \n                                      output_distribution=\"normal\")\n    \n    vec_len = len(Xtrain[col].values)\n    vec_len_test = len(Xtest[col].values)\n\n    raw_vec = Xtrain[col].values.reshape(vec_len, 1)\n    test_vec = Xtest[col].values.reshape(vec_len_test, 1)\n    transformer.fit(raw_vec)\n    \n    Xtrain[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    Xtest[col] = transformer.transform(test_vec).reshape(1, vec_len_test)[0]\n\nprint(f\"Xtrain: {Xtrain.shape} \\nXtest: {Xtest.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:46:07.070173Z","iopub.execute_input":"2021-08-27T12:46:07.070532Z","iopub.status.idle":"2021-08-27T12:46:36.592611Z","shell.execute_reply.started":"2021-08-27T12:46:07.070501Z","shell.execute_reply":"2021-08-27T12:46:36.591431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dnn_model(data, catcols, numcols):\n    \n    num_inp = Input(shape=(numcols,))\n    \n    inputs = []\n    outputs = []\n    \n    for c in catcols:\n        num_unique_values = int(data[c].max())\n        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n        inp = Input(shape=(1,))\n        out = Embedding(input_dim=num_unique_values + 1, \n                        output_dim=embed_dim, \n                        embeddings_initializer='lecun_normal', \n                        name=c)(inp)\n        out = SpatialDropout1D(rate=0.2)(out)\n        out = Reshape(target_shape=(embed_dim, ))(out)\n        inputs.append(inp)\n        outputs.append(out)\n    \n    outputs.append(num_inp)\n    x = Concatenate()(outputs)\n    x = BatchNormalization()(x)\n    x = Dropout(rate=0.25)(x)\n    \n    x = Dense(units=128, kernel_initializer='lecun_normal', \n                kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    x = Dropout(rate=0.35)(x)\n    \n    x = Dense(units=32, kernel_initializer='lecun_normal', \n                kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    x = Dropout(rate=0.25)(x)\n\n    x_output = Dense(units=1, kernel_initializer='lecun_normal')(x)\n\n    model = Model(inputs=[inputs, num_inp], outputs=x_output, \n                  name='DNN_Model')\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:46:36.594163Z","iopub.execute_input":"2021-08-27T12:46:36.594719Z","iopub.status.idle":"2021-08-27T12:46:36.608684Z","shell.execute_reply.started":"2021-08-27T12:46:36.594674Z","shell.execute_reply":"2021-08-27T12:46:36.607536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = dnn_model(Xtrain, cat_cols, len(num_cols))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:46:36.610952Z","iopub.execute_input":"2021-08-27T12:46:36.611429Z","iopub.status.idle":"2021-08-27T12:46:36.852186Z","shell.execute_reply.started":"2021-08-27T12:46:36.611363Z","shell.execute_reply":"2021-08-27T12:46:36.851052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLD = 10\nVERBOSE = 0\nBATCH_SIZE = 2048\nSEEDS = [2018, 2020]\n\noof_score = 0\ny_pred_meta_dnn = np.zeros((Xtrain.shape[0], 1))\ny_pred_final_dnn = 0\ncounter = 0\n\n\nfor sidx, seed in enumerate(SEEDS):\n    seed_score = 0\n    \n    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n    for idx, (train, val) in enumerate(kfold.split(Xtrain, Ytrain_strat)):\n        counter += 1\n\n        train_x, train_y = Xtrain.iloc[train], Ytrain.iloc[train]\n        val_x, val_y = Xtrain.iloc[val], Ytrain.iloc[val]\n\n        tf.random.set_seed(seed)\n        model = dnn_model(Xtrain, cat_cols, len(num_cols))\n        model.compile(loss=rmspe_loss, optimizer=Adamax(lr=1e-2))\n\n        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n                              restore_best_weights=True, \n                              patience=15, verbose=VERBOSE)\n\n        reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n                                      min_lr=1e-5, patience=4, \n                                      verbose=VERBOSE, mode='min')\n\n        history = model.fit(\n            [[train_x[col] for col in cat_cols], train_x[num_cols]], train_y, \n            batch_size=BATCH_SIZE,\n            epochs=100, \n            verbose=VERBOSE, \n            callbacks=[reduce_lr, early], \n            validation_data=([[val_x[col] for col in cat_cols], val_x[num_cols]], val_y)\n        )\n\n        y_pred = model.predict([[val_x[col] for col in cat_cols], val_x[num_cols]], batch_size=BATCH_SIZE)\n        y_pred_meta_dnn[val] += y_pred\n        y_pred_final_dnn += model.predict([[Xtest[col] for col in cat_cols], Xtest[num_cols]], batch_size=BATCH_SIZE)\n        \n        score = rmspe(val_y, y_pred.ravel())\n        oof_score += score\n        seed_score += score\n        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n    \n    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n\n\ny_pred_meta_dnn = y_pred_meta_dnn / float(len(SEEDS))\ny_pred_final_dnn = y_pred_final_dnn / float(counter)\noof_score /= float(counter)\nprint(\"Aggregate OOF Score: {}\".format(oof_score))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T12:46:45.516474Z","iopub.execute_input":"2021-08-27T12:46:45.516889Z","iopub.status.idle":"2021-08-27T12:52:42.870663Z","shell.execute_reply.started":"2021-08-27T12:46:45.516855Z","shell.execute_reply":"2021-08-27T12:52:42.867639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Weighted Average Ensemble","metadata":{"papermill":{"duration":0.224074,"end_time":"2021-08-02T14:40:16.977409","exception":false,"start_time":"2021-08-02T14:40:16.753335","status":"completed"},"tags":[]}},{"cell_type":"code","source":"y_pred_final_gbr = np.array([y_pred_final_gbr]).T\ny_pred_final_lgb = np.array([y_pred_final_lgb]).T\ny_pred_final_dnn = y_pred_final_dnn.clip(0, 1e10)\n\ny_pred_final = (y_pred_final_lgb * 0.6) + (y_pred_final_gbr * 0.2) + (y_pred_final_dnn * 0.2)","metadata":{"papermill":{"duration":0.232469,"end_time":"2021-08-02T14:40:17.436263","exception":false,"start_time":"2021-08-02T14:40:17.203794","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:53:34.441476Z","iopub.execute_input":"2021-08-27T12:53:34.441912Z","iopub.status.idle":"2021-08-27T12:53:34.448216Z","shell.execute_reply.started":"2021-08-27T12:53:34.441877Z","shell.execute_reply":"2021-08-27T12:53:34.447043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create submission file","metadata":{"papermill":{"duration":0.225545,"end_time":"2021-08-02T14:40:20.457848","exception":false,"start_time":"2021-08-02T14:40:20.232303","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submit_df = pd.DataFrame()\nsubmit_df['row_id'] = test_df['row_id']\nsubmit_df['target'] = y_pred_final.ravel()\nsubmit_df.to_csv(\"./submission.csv\", index=False)\nsubmit_df.head()","metadata":{"papermill":{"duration":0.261779,"end_time":"2021-08-02T14:40:20.946804","exception":false,"start_time":"2021-08-02T14:40:20.685025","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-27T12:55:08.421423Z","iopub.execute_input":"2021-08-27T12:55:08.421836Z","iopub.status.idle":"2021-08-27T12:55:08.444497Z","shell.execute_reply.started":"2021-08-27T12:55:08.421802Z","shell.execute_reply":"2021-08-27T12:55:08.442801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.228058,"end_time":"2021-08-02T14:40:21.406925","exception":false,"start_time":"2021-08-02T14:40:21.178867","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}