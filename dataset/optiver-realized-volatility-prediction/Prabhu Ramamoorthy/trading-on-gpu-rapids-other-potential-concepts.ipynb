{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Accelerating Trading on GPU via RAPIDS\n## Best scoring CPU kernel is accelerated on GPU. 3.5x Speedup!!!\n\n","metadata":{"papermill":{"duration":0.014217,"end_time":"2021-07-08T14:58:35.236592","exception":false,"start_time":"2021-07-08T14:58:35.222375","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Based on a GPU accelerated version with other potential items & considerations that can be done on the GPU.\n","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport cudf\nimport cuml\nimport glob\nfrom tqdm import tqdm\n\ncudf.__version__","metadata":{"papermill":{"duration":4.333354,"end_time":"2021-07-08T14:58:39.584138","exception":false,"start_time":"2021-07-08T14:58:35.250784","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:13:26.840843Z","iopub.execute_input":"2021-09-27T20:13:26.84187Z","iopub.status.idle":"2021-09-27T20:13:28.507905Z","shell.execute_reply.started":"2021-09-27T20:13:26.841747Z","shell.execute_reply":"2021-09-27T20:13:28.507196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/optiver-realized-volatility-prediction\"\n\n\ndef load_data(mode, path=\"/kaggle/input/optiver-realized-volatility-prediction\"):\n    # mode = \"train\"/\"test\"\n    file_name = f'{path}/{mode}.csv'\n    return cudf.read_csv(file_name)\n\ndev_df = load_data(\"train\", path=PATH)\ndev_df.head()","metadata":{"papermill":{"duration":3.829788,"end_time":"2021-07-08T14:58:43.427608","exception":false,"start_time":"2021-07-08T14:58:39.59782","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:13:29.967307Z","iopub.execute_input":"2021-09-27T20:13:29.967592Z","iopub.status.idle":"2021-09-27T20:13:31.36388Z","shell.execute_reply.started":"2021-09-27T20:13:29.967546Z","shell.execute_reply":"2021-09-27T20:13:31.363087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SCALE = 100\ndev_df[\"target\"] *= SCALE\n\nstock_ids = dev_df[\"stock_id\"].unique()\nlen(stock_ids)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T20:13:34.416825Z","iopub.execute_input":"2021-09-27T20:13:34.417434Z","iopub.status.idle":"2021-09-27T20:13:34.429507Z","shell.execute_reply.started":"2021-09-27T20:13:34.417396Z","shell.execute_reply":"2021-09-27T20:13:34.428568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_book_training = glob.glob(f'{PATH}/book_train.parquet/*/*')\norder_book_test = glob.glob(f'{PATH}/book_test.parquet/*/*')\n\nlen(order_book_training), len(order_book_test)","metadata":{"papermill":{"duration":0.207773,"end_time":"2021-07-08T14:58:43.649518","exception":false,"start_time":"2021-07-08T14:58:43.441745","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:13:35.65179Z","iopub.execute_input":"2021-09-27T20:13:35.652114Z","iopub.status.idle":"2021-09-27T20:13:35.737506Z","shell.execute_reply.started":"2021-09-27T20:13:35.652081Z","shell.execute_reply":"2021-09-27T20:13:35.736851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trades_training = glob.glob(f'{PATH}/trade_train.parquet/*/*')\ntrades_test = glob.glob(f'{PATH}/trade_test.parquet/*/*')\n\nlen(trades_training), len(trades_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T20:13:36.49024Z","iopub.execute_input":"2021-09-27T20:13:36.490979Z","iopub.status.idle":"2021-09-27T20:13:36.549499Z","shell.execute_reply.started":"2021-09-27T20:13:36.490943Z","shell.execute_reply":"2021-09-27T20:13:36.548335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using rapids-kaggle-utils for missing cuDF aggregation functions","metadata":{"papermill":{"duration":0.014186,"end_time":"2021-07-08T14:58:43.677748","exception":false,"start_time":"2021-07-08T14:58:43.663562","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%cd /kaggle/input/rapids-kaggle-utils/","metadata":{"papermill":{"duration":0.023081,"end_time":"2021-07-08T14:58:43.714941","exception":false,"start_time":"2021-07-08T14:58:43.69186","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:13:38.139919Z","iopub.execute_input":"2021-09-27T20:13:38.140861Z","iopub.status.idle":"2021-09-27T20:13:38.148935Z","shell.execute_reply.started":"2021-09-27T20:13:38.140823Z","shell.execute_reply":"2021-09-27T20:13:38.14811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cu_utils.transform as cutran\n\n\n\ndef log_diff(df, in_col, null_val):\n    df[\"logx\"] = df[in_col].log()\n    df[\"logx_shifted\"] = (df[[\"time_id\", \"logx\"]].groupby(\"time_id\")\n                             .apply_grouped(cutran.get_cu_shift_transform(shift_by=1, null_val=null_val),\n                                            incols={\"logx\": 'x'},\n                                            outcols=dict(y_out=cp.float32),\n                                            tpb=32)[\"y_out\"])\n    df[\"keep_row\"] = df[f\"logx_shifted\"] != null_val\n    return df[\"logx\"] - df[\"logx_shifted\"]\n\n\n\ndef extract_raw_book_features(df, null_val=-9999):\n    for n in range(1, 3):\n        p1 = df[f\"bid_price{n}\"]\n        p2 = df[f\"ask_price{n}\"]\n        s1 = df[f\"bid_size{n}\"]\n        s2 = df[f\"ask_size{n}\"]\n        df[f\"wap{n}\"] = (p1*s2 + p2*s1) / (s1 + s2)\n        df[f\"log_return{n}\"] = log_diff(df, in_col=f\"wap{n}\", null_val=null_val)\n        df[f\"realized_vol{n}\"] = df[f\"log_return{n}\"]**2\n        \n    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    df[\"c\"] = 1\n    \n    df = df[df[\"keep_row\"]]\n    return df\n\n\ndef extract_raw_trade_features(df, null_val=-9999):\n    df[\"realized_vol_trade\"] = log_diff(df, in_col=f\"price\", null_val=null_val)**2\n    df = df[df[\"keep_row\"]]\n    return df\n\n\ndef agg(df, feature_dict):\n    agg_df = df.groupby(\"time_id\").agg(feature_dict).reset_index()\n    def f(x):\n        if x[1] == \"\":\n            return x[0]\n        return x[0] + \"_\" + x[1]\n    \n    agg_df.columns = [f(x) for x in agg_df.columns]\n    return agg_df    \n\n\ndef extract_book_stats(df):\n    default_stats = [\"sum\", \"mean\", \"std\"]\n    feature_dict = {\n        'wap1': default_stats,\n        'wap2': default_stats,\n        'log_return1': default_stats,\n        'log_return2': default_stats,\n        'wap_balance': default_stats,\n        'price_spread': default_stats,\n        'bid_spread': default_stats,\n        'ask_spread': default_stats,\n        'total_volume': default_stats,\n        'volume_imbalance': default_stats,\n        'c': [\"sum\"],\n        'realized_vol1': [\"sum\"],\n        'realized_vol2': [\"sum\"],\n    }\n    \n    return agg(df, feature_dict)\n    \n\n    \n    \ndef extract_trade_stats(df):\n    feature_dict = {\n        'realized_vol_trade': [\"sum\"],\n        'seconds_in_bucket':[\"count\"],\n        'size': [\"sum\"],\n        'order_count': [\"mean\"],\n    }\n    \n    return agg(df, feature_dict)\n\n\ndef time_constraint_fe(df, stats_df, last_sec, fe_function, cols):\n    sub_df = df[df[\"seconds_in_bucket\"] >= (600 - last_sec)].reset_index(drop=True)\n    if sub_df.shape[0] > 0:\n        sub_stats = fe_function(sub_df)\n    else:\n        sub_stats = cudf.DataFrame(columns=cols)\n    return stats_df.merge(sub_stats, on=\"time_id\", how=\"left\", suffixes=('', f'_{last_sec}'))    \n    \n\ndef feature_engineering(book_path, trade_path):\n    book_df = cudf.read_parquet(book_path)\n    book_df = extract_raw_book_features(book_df)\n    book_stats = extract_book_stats(book_df)\n    book_cols = book_stats.columns\n    \n    trade_df = cudf.read_parquet(trade_path)\n    trade_df = extract_raw_trade_features(trade_df)\n    trade_stats = extract_trade_stats(trade_df)\n    trade_cols = trade_stats.columns\n    \n    for last_sec in [150, 300, 450]:\n        book_stats = time_constraint_fe(book_df, book_stats, last_sec, extract_book_stats, book_cols) \n        trade_stats = time_constraint_fe(trade_df, trade_stats, last_sec, extract_trade_stats, trade_cols) \n\n    return book_stats.merge(trade_stats, on=\"time_id\", how=\"left\")\n\n\ndef process_data(order_book_paths, trade_paths, stock_ids):\n    stock_dfs = []\n    for book_path, trade_path in tqdm(list(zip(order_book_paths, trade_paths))):\n        stock_id = int(book_path.split(\"=\")[1].split(\"/\")[0])\n\n        df = feature_engineering(book_path, trade_path)\n        df[\"stock_id\"] = stock_id\n        stock_dfs.append(df)\n    return cudf.concat(stock_dfs)","metadata":{"papermill":{"duration":0.044884,"end_time":"2021-07-08T14:58:43.774168","exception":false,"start_time":"2021-07-08T14:58:43.729284","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:13:39.596552Z","iopub.execute_input":"2021-09-27T20:13:39.597497Z","iopub.status.idle":"2021-09-27T20:13:39.629316Z","shell.execute_reply.started":"2021-09-27T20:13:39.597445Z","shell.execute_reply":"2021-09-27T20:13:39.628088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"past_volatility = process_data(order_book_training, trades_training, stock_ids)\npast_test_volatility = process_data(order_book_test, trades_test, stock_ids)\n\npast_volatility.shape, past_test_volatility.shape","metadata":{"papermill":{"duration":128.128858,"end_time":"2021-07-08T15:00:51.917263","exception":false,"start_time":"2021-07-08T14:58:43.788405","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:13:43.027633Z","iopub.execute_input":"2021-09-27T20:13:43.028312Z","iopub.status.idle":"2021-09-27T20:15:58.554435Z","shell.execute_reply.started":"2021-09-27T20:13:43.028274Z","shell.execute_reply":"2021-09-27T20:15:58.553498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Usually the time seconds provided for each window can be evaluated whether it is stationary or not\n\nTime series stationarity and creating features based on ADF test can be potential areas be accelerated on the GPU.\nThese features can be added to below features to see if they add predictive power to the XGBOOST model below.\nIn addition based on the stationary, there could be other time series models which could be done on the GPU. \nTypically if time series is non-stationary, we could look at Differencing (integer or GPU fractinal differencing) to look at such time series data. Time series libraries have become popular (looking at stationarity, seasonality and aspects of an ARIMA pdq model).","metadata":{}},{"cell_type":"markdown","source":"Additonal neural net models can be stacked to the XGBOOST below.","metadata":{}},{"cell_type":"markdown","source":"GPUs when a lot of data can also be used to create metrics such as Hurst exponent (similar to the time series other statistics) so can work on large amount of data parallely. Few of these measures can be done in C++ and also Cupy (GPU version of Numpy providing similar features)/Numba (LLVM GPU compilation)","metadata":{}},{"cell_type":"markdown","source":"Another area is when the data is bigger. A GPU with higer memory would be able to run such calcs aboove parallely so check if faster speedups for data processing, transformation and backtesting in bigger data sets.  Considreing that Markets are random walk and have high signal to noise ratio with many areas being simulated, GPUs are great for the simulation of synthetic data (MonteCarlo, Bootstrapping, GAN etc) if you want to generate more data from the pipeline of data and train your model based on it. Here we continue to proceed below with XGBOOST which is accelerated on the GPU but those are above potential areas which could be analyzed at a later time to support trading on GPUs. We will discuss the above in a separate thread when examining those areas closely","metadata":{}},{"cell_type":"markdown","source":"XGBOOST feature engineering below","metadata":{}},{"cell_type":"code","source":"def stock_time_fe(df):\n    cols = ['realized_vol1_sum', 'realized_vol2_sum', 'realized_vol_trade_sum',\n            'realized_vol1_sum_150', 'realized_vol2_sum_150', 'realized_vol_trade_sum_150',\n            'realized_vol1_sum_300', 'realized_vol2_sum_300', 'realized_vol_trade_sum_300',\n            'realized_vol1_sum_450', 'realized_vol2_sum_450', 'realized_vol_trade_sum_450']\n    \n    for agg_col in [\"stock_id\", \"time_id\"]:\n        for agg_func in [\"mean\", \"max\", \"std\", \"min\"]:\n            agg_df = df.groupby(agg_col)[cols].agg(agg_func)\n            agg_df.columns = [f\"{agg_col}_{agg_func}_{col}\" for col in agg_df.columns]\n            df = df.merge(agg_df.reset_index(), on=agg_col, how=\"left\")\n    \n    return df\n\npast_volatility[\"is_test\"] = False\npast_test_volatility[\"is_test\"] = True\nall_df = past_volatility.append(past_test_volatility).reset_index(drop=True)\n\nall_df = stock_time_fe(all_df)\n\npast_volatility = all_df[~all_df[\"is_test\"]]\npast_test_volatility = all_df[all_df[\"is_test\"]]","metadata":{"execution":{"iopub.status.busy":"2021-09-27T20:27:38.210493Z","iopub.execute_input":"2021-09-27T20:27:38.211265Z","iopub.status.idle":"2021-09-27T20:27:39.628971Z","shell.execute_reply.started":"2021-09-27T20:27:38.211225Z","shell.execute_reply":"2021-09-27T20:27:39.628206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_df = dev_df.merge(past_volatility, on=[\"stock_id\", \"time_id\"], how=\"left\")\n\nfeatures = [col for col in list(dev_df.columns)\n            if col not in {\"stock_id\", \"time_id\", \"target\", \"is_test\"}]\nlen(features)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T20:27:39.746124Z","iopub.execute_input":"2021-09-27T20:27:39.746885Z","iopub.status.idle":"2021-09-27T20:27:39.841533Z","shell.execute_reply.started":"2021-09-27T20:27:39.746839Z","shell.execute_reply":"2021-09-27T20:27:39.840819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train XGBoost model on GPU","metadata":{"papermill":{"duration":0.043524,"end_time":"2021-07-08T15:00:52.944345","exception":false,"start_time":"2021-07-08T15:00:52.900821","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import xgboost as xgb\n\ndef rmspe(y_true, y_pred):\n    return (cp.sqrt(cp.mean(cp.square((y_true - y_pred) / y_true))))\n\n\ndef rmspe_xgb(pred, dtrain):\n    y = dtrain.get_label()\n    return 'rmspe', rmspe(cp.array(y), cp.array(pred))\n\n\nNUM_FOLDS = 5\nparam = {'objective': 'reg:squarederror',\n         'learning_rate': 0.1,\n         'max_depth': 3,\n         \"min_child_weight\": 200,\n         \"reg_alpha\": 10.0,\n         \"tree_method\": 'gpu_hist', \"gpu_id\": 0,\n         'disable_default_eval_metric': 1\n    }\n\ntarget = \"target\"\n\noof_preds = cp.zeros(dev_df.shape[0])\ntest_preds = cp.zeros(past_test_volatility.shape[0])\n\nfor fold in range(NUM_FOLDS):\n    print(\"Fold\", fold)\n    train_ind = cp.where(dev_df[\"time_id\"].values % NUM_FOLDS != fold)[0]\n    val_ind = cp.where(dev_df[\"time_id\"].values % NUM_FOLDS == fold)[0]\n        \n    train_df, val_df = dev_df.iloc[train_ind], dev_df.iloc[val_ind]\n\n    d_train = xgb.DMatrix(train_df[features], train_df[target], weight=1/cp.square(train_df[target]))\n    d_val = xgb.DMatrix(val_df[features], val_df[target], weight=1/cp.square(val_df[target]))\n\n    model = xgb.train(param, d_train, evals=[(d_train, \"train\"), (d_val, \"val\")], \n                      num_boost_round=5000, verbose_eval=50, feval=rmspe_xgb,\n                      early_stopping_rounds=200)\n    \n    oof_preds[val_ind] = model.predict(d_val)\n    test_preds += cp.array(model.predict(xgb.DMatrix(past_test_volatility[features].astype(\"float\")))/NUM_FOLDS)","metadata":{"papermill":{"duration":2.208351,"end_time":"2021-07-08T15:00:55.197509","exception":false,"start_time":"2021-07-08T15:00:52.989158","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:27:54.104463Z","iopub.execute_input":"2021-09-27T20:27:54.104756Z","iopub.status.idle":"2021-09-27T20:29:05.391804Z","shell.execute_reply.started":"2021-09-27T20:27:54.104718Z","shell.execute_reply":"2021-09-27T20:29:05.391007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_df[\"pred\"] = oof_preds\nprint(f'The RMSPE score of XGB is {rmspe(dev_df[\"target\"], dev_df[\"pred\"])}')","metadata":{"papermill":{"duration":0.572203,"end_time":"2021-07-08T15:00:55.816575","exception":false,"start_time":"2021-07-08T15:00:55.244372","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:33:55.407702Z","iopub.execute_input":"2021-09-27T20:33:55.408009Z","iopub.status.idle":"2021-09-27T20:33:55.422382Z","shell.execute_reply.started":"2021-09-27T20:33:55.407964Z","shell.execute_reply":"2021-09-27T20:33:55.421523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"past_test_volatility[\"row_id\"] = past_test_volatility[\"stock_id\"].astype(str) + \"-\" + past_test_volatility[\"time_id\"].astype(str) \npast_test_volatility[\"target\"] = test_preds.clip(0.0, 100.0)/SCALE","metadata":{"papermill":{"duration":0.074496,"end_time":"2021-07-08T15:00:56.774602","exception":false,"start_time":"2021-07-08T15:00:56.700106","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:33:56.97433Z","iopub.execute_input":"2021-09-27T20:33:56.974593Z","iopub.status.idle":"2021-09-27T20:33:56.990658Z","shell.execute_reply.started":"2021-09-27T20:33:56.974564Z","shell.execute_reply":"2021-09-27T20:33:56.989968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"papermill":{"duration":0.055862,"end_time":"2021-07-08T15:00:56.879004","exception":false,"start_time":"2021-07-08T15:00:56.823142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:33:58.269494Z","iopub.execute_input":"2021-09-27T20:33:58.269768Z","iopub.status.idle":"2021-09-27T20:33:58.275176Z","shell.execute_reply.started":"2021-09-27T20:33:58.269731Z","shell.execute_reply":"2021-09-27T20:33:58.274344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = load_data(\"test\", path=PATH).merge(past_test_volatility[[\"row_id\", \"target\"]], \n                                            on=\"row_id\", how=\"left\").fillna(0.0)\n\nsub_df.to_csv(\"submission.csv\", index=False, columns=[\"row_id\", \"target\"])","metadata":{"papermill":{"duration":0.056971,"end_time":"2021-07-08T15:00:56.98449","exception":false,"start_time":"2021-07-08T15:00:56.927519","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:33:59.123604Z","iopub.execute_input":"2021-09-27T20:33:59.124192Z","iopub.status.idle":"2021-09-27T20:33:59.149083Z","shell.execute_reply.started":"2021-09-27T20:33:59.124152Z","shell.execute_reply":"2021-09-27T20:33:59.148336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudf.read_csv(\"submission.csv\")","metadata":{"papermill":{"duration":0.071088,"end_time":"2021-07-08T15:00:57.103829","exception":false,"start_time":"2021-07-08T15:00:57.032741","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T20:34:00.325852Z","iopub.execute_input":"2021-09-27T20:34:00.326635Z","iopub.status.idle":"2021-09-27T20:34:00.34957Z","shell.execute_reply.started":"2021-09-27T20:34:00.32658Z","shell.execute_reply":"2021-09-27T20:34:00.348638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}