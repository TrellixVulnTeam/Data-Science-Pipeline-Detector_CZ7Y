{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom numba import njit\nfrom multiprocessing import Pool\nfrom sklearn.metrics import r2_score\n\nimport torch\nimport wandb\nimport torch.nn as nn\nimport torch.optim as optim\n# from torchsummary import summary\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer","metadata":{"_uuid":"4eb26f51-6b23-4ef0-9be8-c5ae8d0039e0","_cell_guid":"94818387-d33e-4644-a2c7-7a241a5bd27c","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:25.389832Z","iopub.execute_input":"2021-07-24T16:19:25.39049Z","iopub.status.idle":"2021-07-24T16:19:29.795944Z","shell.execute_reply.started":"2021-07-24T16:19:25.390447Z","shell.execute_reply":"2021-07-24T16:19:29.794541Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets = pd.read_csv(\"../input/optiver-realized-volatility-prediction/train.csv\")\ntrain_targets['row_id'] = train_targets['stock_id'].astype(str) + '-' + train_targets['time_id'].astype(str)\ntrain_targets = train_targets[['row_id','target']].set_index(\"row_id\")\ntrain_files = glob(\"../input/optiver-realized-volatility-prediction/book_train.parquet/*\")","metadata":{"_uuid":"684594df-bbcf-4123-8e77-9e1e1897f3c0","_cell_guid":"bd85a0b3-f09d-4758-a774-94a44e21b3d7","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:29.797805Z","iopub.execute_input":"2021-07-24T16:19:29.798335Z","iopub.status.idle":"2021-07-24T16:19:31.507884Z","shell.execute_reply.started":"2021-07-24T16:19:29.798292Z","shell.execute_reply":"2021-07-24T16:19:31.5065Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_names = [\n    \"time_id\",           # 0\n    \"seconds_in_bucket\", # 1\n    \"bid_price1\",        # 2\n    \"ask_price1\",        # 3\n    \"bid_price2\",        # 4\n    \"ask_price2\",        # 5\n    \"bid_size1\",         # 6\n    \"ask_size1\",         # 7\n    \"bid_size2\",         # 8\n    \"ask_size2\"          # 9\n]","metadata":{"_uuid":"d6bb6bb6-55aa-47f6-b235-1c1703f9aaef","_cell_guid":"1aded18c-1099-45fe-97b7-9815d9e217f1","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.510282Z","iopub.execute_input":"2021-07-24T16:19:31.511002Z","iopub.status.idle":"2021-07-24T16:19:31.517284Z","shell.execute_reply.started":"2021-07-24T16:19:31.51094Z","shell.execute_reply":"2021-07-24T16:19:31.515379Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@njit\ndef fill_array(book_data, filled_data):\n    filled_data[0] = book_data[0]\n    last_read_idx = 0\n    for row_idx in range(1, 600):\n        # print(row_idx, last_read_idx, int(book_data[last_read_idx + 1][1]), int(book_data[last_read_idx + 1][1]) == row_idx)\n        if int(book_data[last_read_idx + 1][1]) == row_idx:\n            last_read_idx += 1\n        filled_data[row_idx] = book_data[last_read_idx]\n        filled_data[row_idx][1] = row_idx","metadata":{"_uuid":"fd9fd3a8-48c9-499e-876b-fbec3c7f1258","_cell_guid":"c0d708bf-a882-49f6-a1ba-e41c57065431","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.51977Z","iopub.execute_input":"2021-07-24T16:19:31.520861Z","iopub.status.idle":"2021-07-24T16:19:31.541807Z","shell.execute_reply.started":"2021-07-24T16:19:31.520767Z","shell.execute_reply":"2021-07-24T16:19:31.540069Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@njit\ndef calculate_features(filled_data):\n    filled_data = filled_data.transpose()\n    \n    trade_vols1 = (filled_data[6] + filled_data[7])[1:]\n    trade_vols2 = (filled_data[8] + filled_data[9])[1:]\n    trade_diffs1 = (filled_data[7] - filled_data[6])[1:]\n    trade_diffs2 = (filled_data[9] - filled_data[8])[1:]\n    \n    spreads1 = ((filled_data[2] / filled_data[3]) - 1)[1:]\n    spreads2 = ((filled_data[4] / filled_data[5]) - 1)[1:]\n    \n    waps1 = (filled_data[2] * filled_data[7] + filled_data[3] * filled_data[6]) / (filled_data[6] + filled_data[7])\n    waps2 = (filled_data[4] * filled_data[9] + filled_data[5] * filled_data[8]) / (filled_data[8] + filled_data[9])\n    \n    logs1 = np.diff(np.log(waps1))[1:]\n    logs2 = np.diff(np.log(waps2))[1:]\n    \n    waps1 = waps1[1:]\n    waps2 = waps2[1:]\n    \n    return [\n        waps1.mean(), \n        waps2.mean(),\n        waps1[450:500].mean(),\n        waps1[500:550].mean(),\n        waps1[550:].mean(),\n        waps2[450:500].mean(),\n        waps2[500:550].mean(),\n        waps2[550:].mean(),\n        waps1.std(),\n        waps2.std(),\n        waps1[550:].std(),\n        waps2[550:].std(),\n        logs1.mean(),\n        logs2.mean(),\n        logs1[450:500].mean(),\n        logs1[500:550].mean(),\n        logs1[550:].mean(),\n        logs2[450:500].mean(),\n        logs2[500:550].mean(),\n        logs2[550:].mean(),\n        trade_vols1.mean(),\n        trade_vols2.mean(),\n        trade_vols1[550:].mean(),\n        trade_vols2[550:].mean(),\n        trade_diffs1.mean(),\n        trade_diffs2.mean(),\n        trade_diffs1[550:].mean(),\n        trade_diffs2[550:].mean(),\n        np.sqrt(np.sum(logs1 ** 2)), # Essentially volatility1\n        np.sqrt(np.sum(logs2 ** 2)), # Essentially volatility2\n        int(filled_data[0][0])\n    ]","metadata":{"_uuid":"86db8280-0f34-4ab4-a944-ba5334d44efd","_cell_guid":"6a3fb41e-04d8-4f21-bceb-2e6a78d1a08f","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.54378Z","iopub.execute_input":"2021-07-24T16:19:31.544459Z","iopub.status.idle":"2021-07-24T16:19:31.569463Z","shell.execute_reply.started":"2021-07-24T16:19:31.54441Z","shell.execute_reply":"2021-07-24T16:19:31.567474Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@njit\ndef process_groups(dataset, stock_id):\n    ret_lis = []\n    last_split_pos = 0\n    filled_data = np.zeros((600, 10), dtype=np.float32)\n    for split_pos in np.nonzero(np.diff(dataset[:,0]))[0]:\n        data_split = dataset[last_split_pos:split_pos]\n        fill_array(data_split, filled_data)\n        features = calculate_features(filled_data)\n        ret_lis.append(features + [stock_id])\n        last_split_pos = split_pos\n    data_split = dataset[last_split_pos:]\n    fill_array(data_split, filled_data)\n    features = calculate_features(filled_data)\n    ret_lis.append(features + [stock_id])\n    return ret_lis","metadata":{"_uuid":"fd59eed6-8bbb-418b-9672-522601c5bf67","_cell_guid":"60313f7a-b399-45cd-a4ec-6e682af39e9a","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.571747Z","iopub.execute_input":"2021-07-24T16:19:31.572305Z","iopub.status.idle":"2021-07-24T16:19:31.592358Z","shell.execute_reply.started":"2021-07-24T16:19:31.57225Z","shell.execute_reply":"2021-07-24T16:19:31.590761Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_columns = [\n    \"wap1\", \"wap2\", \"wap1_1\", \"wap1_2\", \"wap1_3\", \"wap2_1\", \"wap2_2\", \"wap2_3\", \"wap1_std\", \"wap2_std\", \"wap1l_std\", \"wap2l_std\", \"log1\", \"log2\", \"log1_1\", \"log1_2\", \"log1_3\", \"log2_1\", \"log2_2\", \"log2_3\", \"volume1\", \"volume2\", \"volume1l\", \"volume2l\", \"diff1\", \"diff2\", \"diff1l\", \"diff2l\", \"vol1\", \"vol2\", \"time_id\", \"stock_id\"\n]","metadata":{"_uuid":"ffd0ab03-0c27-4f85-b829-fc9acca80913","_cell_guid":"47b21fb4-3aac-4e58-ac67-73617b43dbbf","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.596339Z","iopub.execute_input":"2021-07-24T16:19:31.596888Z","iopub.status.idle":"2021-07-24T16:19:31.613422Z","shell.execute_reply.started":"2021-07-24T16:19:31.596829Z","shell.execute_reply":"2021-07-24T16:19:31.611871Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_single_stock(file_path):\n    book = pd.read_parquet(file_path, engine=\"pyarrow\").sort_values([\"time_id\", \"seconds_in_bucket\"]).to_numpy(dtype=np.float32)\n    group_features = process_groups(book, int(file_path.split('=')[1]))\n    return group_features","metadata":{"_uuid":"cce86a57-ba1f-45df-a4c7-d5c91b519a10","_cell_guid":"2ccb2973-8ca7-4ee2-ac5c-5a99755b94dc","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.616297Z","iopub.execute_input":"2021-07-24T16:19:31.617031Z","iopub.status.idle":"2021-07-24T16:19:31.627835Z","shell.execute_reply.started":"2021-07-24T16:19:31.616974Z","shell.execute_reply":"2021-07-24T16:19:31.626269Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(file_list):\n    worker_pool = Pool(processes=None)\n    full_feature_list_matrix = worker_pool.map(process_single_stock, file_list)\n    worker_pool.close()\n    worker_pool.join()\n    return_feature_list = []\n    for feature_list in full_feature_list_matrix:\n        return_feature_list += feature_list\n    return pd.DataFrame(return_feature_list, columns=feature_columns)","metadata":{"_uuid":"1ea49209-6337-477e-855a-2ed014584172","_cell_guid":"77c83f22-db48-42e5-89d2-4575c3373078","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.630754Z","iopub.execute_input":"2021-07-24T16:19:31.631366Z","iopub.status.idle":"2021-07-24T16:19:31.641657Z","shell.execute_reply.started":"2021-07-24T16:19:31.631306Z","shell.execute_reply":"2021-07-24T16:19:31.640066Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = preprocess_data(train_files)\ndataset[\"row_id\"] = dataset.apply(lambda x: f\"{int(x['stock_id'])}-{int(x['time_id'])}\", axis=1)\ndataset_cleaned = dataset.drop(columns=[\"time_id\"])\ndataset_merged = dataset_cleaned.merge(train_targets, \"left\", \"row_id\")\ndataset_merge_cleaned = dataset_merged.drop(columns=[\"row_id\"])","metadata":{"_uuid":"1a00af5a-f18d-476d-b386-1d094bf1d8df","_cell_guid":"4b06a48a-48a6-440a-a0aa-5babcf2b0fc7","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:19:31.643399Z","iopub.execute_input":"2021-07-24T16:19:31.644003Z","iopub.status.idle":"2021-07-24T16:20:42.003342Z","shell.execute_reply.started":"2021-07-24T16:19:31.643967Z","shell.execute_reply":"2021-07-24T16:20:42.001961Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmspe(y_true, y_pred):\n    return torch.sqrt(torch.mean(((y_true - y_pred) / y_true) ** 2))","metadata":{"_uuid":"79008bcc-1720-4e25-9b2e-567a6e13afba","_cell_guid":"271db39a-51a2-47e9-b50d-fa2e5c813059","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:20:42.005316Z","iopub.execute_input":"2021-07-24T16:20:42.005844Z","iopub.status.idle":"2021-07-24T16:20:42.011932Z","shell.execute_reply.started":"2021-07-24T16:20:42.005783Z","shell.execute_reply":"2021-07-24T16:20:42.010497Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nbatch_size = 1024\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nsplit_size = 0.15\nfeature_size = len(feature_columns) - 1\nlr = 3e-3\nlr_gamma = 0.9\nbetas = (0.5, 0.5)","metadata":{"_uuid":"09d93382-106e-4345-bd47-26281a4788f4","_cell_guid":"656ba2dd-10e8-4377-93be-83b774ff58cc","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:20:42.014507Z","iopub.execute_input":"2021-07-24T16:20:42.015007Z","iopub.status.idle":"2021-07-24T16:20:42.031065Z","shell.execute_reply.started":"2021-07-24T16:20:42.014954Z","shell.execute_reply":"2021-07-24T16:20:42.029844Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeatureDataset(Dataset):\n    def __init__(self, in_dataframe):\n        self.feature_standardizer = StandardScaler()\n        self.target_boxcox = PowerTransformer(method='box-cox', standardize=False)\n        self.target_scaler = MinMaxScaler()\n        \n        dataframe = in_dataframe.copy()\n        self.stocks_target_mean_val = dataframe.groupby(\"stock_id\")[\"target\"].mean()\n        dataframe.insert(loc=dataframe.shape[1] - 3, column=\"stock_target_mean\", value=dataframe['stock_id'].map(self.stocks_target_mean_val).values)\n        X = self.feature_standardizer.fit_transform(dataframe.iloc[:, :-3].to_numpy())\n        y = self.target_scaler.fit_transform(self.target_boxcox.fit_transform(dataframe.iloc[:, -1].to_numpy().reshape(-1, 1)))\n        # y = dataframe.iloc[:, -1].to_numpy()\n        \n        self.X_train = torch.tensor(X, dtype=torch.float32)\n        self.y_train = torch.tensor(y, dtype=torch.float32)\n        \n    def inverse_scale_transform(self, x):\n        if not torch.is_tensor(x):\n            x = torch.tensor(x, dtype=torch.float32)\n        \n        # Invert the 0-1 Scaler\n        x_mult = x * torch.tensor(self.target_scaler.data_max_ - self.target_scaler.data_min_, dtype=torch.float32, requires_grad=False)\n        x_scaled = x_mult + torch.tensor(self.target_scaler.data_min_, dtype=torch.float32, requires_grad=False)\n        \n        # Invert the Box-Cox Scaler\n        lda = torch.tensor(self.target_boxcox.lambdas_[0], dtype=torch.float32, requires_grad=False)\n        x_bcox_inv = torch.exp(torch.log(1 + lda * x_scaled) / lda)\n        return x_bcox_inv\n    \n    def __len__(self):\n        return len(self.y_train)\n    \n    def __getitem__(self, idx):\n        return self.X_train[idx], self.y_train[idx]\n\nfeature_set = FeatureDataset(dataset_merged)\nval_size = int(split_size * len(feature_set))\ntrain_set, val_set = torch.utils.data.random_split(feature_set, [len(feature_set) - val_size, val_size])\n\nprint(f\"{len(train_set)} training samples\")\nprint(f\"{len(val_set)} validation samples\")\n\ntrain_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_set, shuffle=True, batch_size=batch_size)","metadata":{"_uuid":"fb710029-1187-498d-ab94-d48ee8fb1eef","_cell_guid":"1fce0075-16d7-4db7-97ce-8c83e728403f","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:20:42.033442Z","iopub.execute_input":"2021-07-24T16:20:42.033951Z","iopub.status.idle":"2021-07-24T16:20:43.861131Z","shell.execute_reply.started":"2021-07-24T16:20:42.033894Z","shell.execute_reply":"2021-07-24T16:20:43.859708Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(feature_size, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"_uuid":"02172644-8522-4e5b-bcfc-bc77f65d781c","_cell_guid":"e3cd9b6f-83f2-4cfc-8729-00cd3f42aa38","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2021-07-24T16:20:43.863145Z","iopub.execute_input":"2021-07-24T16:20:43.863624Z","iopub.status.idle":"2021-07-24T16:20:43.870441Z","shell.execute_reply.started":"2021-07-24T16:20:43.863567Z","shell.execute_reply":"2021-07-24T16:20:43.869184Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)\n# summary(model, (batch_size, feature_size))\n\ncriterion = nn.MSELoss()\ncriterion = rmspe\n# optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas)\noptimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer, lr_gamma)\n# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, min_lr=3e-6, factor=0.1)","metadata":{"_uuid":"d809ccca-5b5a-407a-9a39-d59f5f3666d0","_cell_guid":"29d88fb5-8042-4cdc-84ea-511213ccc9b2","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T16:20:43.872105Z","iopub.execute_input":"2021-07-24T16:20:43.872761Z","iopub.status.idle":"2021-07-24T16:20:43.89973Z","shell.execute_reply.started":"2021-07-24T16:20:43.87271Z","shell.execute_reply":"2021-07-24T16:20:43.898501Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    train_loss = 0.0\n    train_r2 = 0.0\n    for features, values in train_loader:\n        features = features.to(device)\n        values = values.to(device)\n        output = model(features)\n        \n        # Invert the scaling of the outputs\n        values_scaled = feature_set.inverse_scale_transform(values.cpu())\n        output_scaled = feature_set.inverse_scale_transform(output.cpu())\n        \n        loss = criterion(values_scaled, output_scaled)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # train_loss += rmspe(values, output).item()\n        train_loss += loss.item()\n        train_r2 += r2_score(values_scaled.cpu(), output_scaled.detach().cpu())\n    \n    model.eval()\n    val_loss = 0.0\n    val_r2 = 0.0\n    for features, values in val_loader:\n        features = features.to(device)\n        values = values.to(device)\n        output = model(features)\n        \n        # Invert the scaling of the outputs\n        values_scaled = feature_set.inverse_scale_transform(values.cpu())\n        output_scaled = feature_set.inverse_scale_transform(output.cpu())\n        \n        loss = criterion(values_scaled, output_scaled)\n        val_loss += loss.item()\n        val_r2 += r2_score(values_scaled.cpu(), output_scaled.cpu().detach())\n    scheduler.step()\n    \n    print(f\"Iteration {epoch}, Train RMSPE: {train_loss / len(train_loader)}, Val RMSPE: {val_loss / len(val_loader)}, Train R2: {train_r2 / len(train_loader)}, Val R2: {val_r2 / len(val_loader)}\")","metadata":{"_uuid":"631ccf61-2fa8-4251-bea7-a43db69614f8","_cell_guid":"a7075be3-382b-460e-a335-9c3d0172eed5","collapsed":false,"execution":{"iopub.status.busy":"2021-07-24T09:21:21.147662Z","iopub.execute_input":"2021-07-24T09:21:21.148035Z","iopub.status.idle":"2021-07-24T09:22:49.697879Z","shell.execute_reply.started":"2021-07-24T09:21:21.148005Z","shell.execute_reply":"2021-07-24T09:22:49.696823Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{"_uuid":"043464ad-058f-4ea2-aaec-6653834dfaa3","_cell_guid":"88bb0d9b-38e0-4a01-8eca-6268c56b0e93","trusted":true}},{"cell_type":"code","source":"def process_stock(test_queries):\n    features_set = process_single_stock(\"/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/stock_id=\" + str(test_queries[\"stock_id\"][0]))\n    features_dset = pd.DataFrame(features_set, columns=feature_columns)\n    features_dset.insert(loc=features_dset.shape[1] - 3, column=\"stock_target_mean\", value=features_dset['stock_id'].map(feature_set.stocks_target_mean_val).values)\n    testing_data = test_queries.merge(features_dset, how=\"left\", on=[\"time_id\", \"stock_id\"]).fillna(method=\"ffill\")\n    testing_data_cleaned = testing_data.drop(columns=[\"time_id\", \"stock_id\"])\n    \n    with torch.no_grad():\n        X = torch.tensor(testing_data_cleaned.iloc[:, 1:].to_numpy(dtype=np.float32), dtype=torch.float32)\n        model_out = model(X)\n        model_out_scaled = feature_set.inverse_scale_transform(model_out).cpu().numpy().reshape(-1, )\n    test_queries[\"target\"] = model_out_scaled\n    test_queries_cleaned = test_queries.drop(columns=[\"time_id\", \"stock_id\"])\n    return test_queries_cleaned","metadata":{"execution":{"iopub.status.busy":"2021-07-24T17:01:55.317554Z","iopub.execute_input":"2021-07-24T17:01:55.318079Z","iopub.status.idle":"2021-07-24T17:01:55.328887Z","shell.execute_reply.started":"2021-07-24T17:01:55.318036Z","shell.execute_reply":"2021-07-24T17:01:55.327242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_file = pd.read_csv(\"../input/optiver-realized-volatility-prediction/test.csv\")\ntesting_file = testing_file.groupby(\"stock_id\").apply(process_stock)\ntesting_file = testing_file.fillna(0.001)\ntesting_file.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T17:01:55.349665Z","iopub.execute_input":"2021-07-24T17:01:55.350062Z","iopub.status.idle":"2021-07-24T17:01:55.391916Z","shell.execute_reply.started":"2021-07-24T17:01:55.350028Z","shell.execute_reply":"2021-07-24T17:01:55.390617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"4cddf23e-64fe-4b45-ae9f-faae76ce116c","_cell_guid":"f4938af3-7168-4cf6-adc2-737d0c1d596a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}