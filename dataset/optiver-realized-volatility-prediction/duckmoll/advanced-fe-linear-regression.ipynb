{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-05T23:28:39.992595Z","iopub.execute_input":"2021-08-05T23:28:39.993384Z","iopub.status.idle":"2021-08-05T23:28:40.706367Z","shell.execute_reply.started":"2021-08-05T23:28:39.993271Z","shell.execute_reply":"2021-08-05T23:28:40.705036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stock id, randomly shuffled time_Id, realized volatility for the next 10 minutes\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:28:40.707962Z","iopub.execute_input":"2021-08-05T23:28:40.70825Z","iopub.status.idle":"2021-08-05T23:28:41.106002Z","shell.execute_reply.started":"2021-08-05T23:28:40.708223Z","shell.execute_reply":"2021-08-05T23:28:41.105094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_vol(df):\n    temp = np.log(df).diff()\n    # vol\n    return np.sqrt(np.sum(temp**2))","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:28:41.107575Z","iopub.execute_input":"2021-08-05T23:28:41.107862Z","iopub.status.idle":"2021-08-05T23:28:41.115143Z","shell.execute_reply.started":"2021-08-05T23:28:41.107836Z","shell.execute_reply":"2021-08-05T23:28:41.113949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\norder_book_training = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')\norder_ft = pd.DataFrame()\nfor i in order_book_training:\n    # finding the stock_id\n    temp_stock = int(i.split(\"=\")[1])\n    book = pd.read_parquet(i)\n    \n    book['bid_volume1'] = book['bid_price1'] * book['bid_size1']\n    book['bid_volume2'] = book['bid_price2'] * book['bid_size2']\n    book['bid_volume'] = book['bid_volume1'] + book['bid_volume2']\n    book['ask_volume1'] = book['ask_price1'] * book['ask_size1']\n    book['ask_volume2'] = book['ask_price2'] * book['ask_size2']\n    book['ask_volume'] = book['ask_volume1'] + book['ask_volume2']\n    \n    book['wap1'] = (book['bid_price1']*book['ask_size1'] + book['ask_price1']*book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n    book['wap2'] = (book['bid_price2']*book['ask_size2'] + book['ask_price2']*book['bid_size2']) / (book['bid_size2'] + book['ask_size2'])\n    book['wap_total1'] = (book['wap1'] + book['wap2']) / 2\n    book['wap_total2'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1'] + book['bid_price2'] * book['ask_size2'] + book['ask_price2'] * book['bid_size2']) / (book['bid_size1'] + book['ask_size1'] + book['bid_size2']+ book['ask_size2'])\n    book['wap_balance'] = abs(book['wap1'] - book['wap2'])\n    \n    book['price_spread'] = (book['ask_price1'] - book['bid_price1']) / (book['ask_price1'] + book['bid_price1'])\n    book['bid_spread'] = book['bid_price1'] - book['bid_price2']\n    book['ask_spread'] = book['ask_price1'] - book['ask_price2']\n    book['total_size'] = (book['ask_size1'] + book['ask_size2']) + (book['bid_size1'] + book['bid_size2'])\n    book['total_volume'] = (book['ask_size1'] * book['ask_price1'] + book['ask_size2'] * book['ask_price2']) + (book['bid_size1'] * book['bid_price1'] + book['bid_size2'] * book['bid_price2'])\n    book['size_imbalance'] = abs((book['ask_size1'] + book['ask_size2']) - (book['bid_size1'] + book['bid_size2']))\n    book['size_imbalance_spread'] = book['size_imbalance'] / book['total_size']\n    book['volume_imbalance'] = abs((book['ask_size1'] * book['ask_price1'] + book['ask_size2'] * book['ask_price2']) - (book['bid_size1'] * book['bid_price1'] + book['bid_size2'] * book['bid_price2']))\n    book['volume_imbalance_spread'] = book['volume_imbalance'] / book['total_volume']\n    \n    #dict for aggregate\n    create_feature_dict = {\n        'bid_price1': [np.mean],\n        'bid_size1': [np.mean],\n        'ask_price1': [np.mean],\n        'ask_size1': [np.mean],\n        'bid_price2': [np.mean],\n        'bid_size2': [np.mean],\n        'ask_price2': [np.mean],\n        'ask_size2': [np.mean],\n        'bid_volume1': [np.mean],\n        'bid_volume2': [np.mean],\n        'ask_volume1': [np.mean],\n        'ask_volume2': [np.mean],\n        'bid_volume': [np.mean],\n        'ask_volume': [np.mean],\n        'wap1':[calc_vol],\n        'wap2':[calc_vol],\n        'wap_total1':[calc_vol],\n        'wap_total2':[calc_vol],\n        'wap_balance':[np.mean],\n        'price_spread':[np.mean],\n        'bid_spread':[np.mean],\n        'ask_spread':[np.mean],\n        'total_size': [np.mean],\n        'total_volume':[np.mean],\n        'size_imbalance':[np.mean],\n        'size_imbalance_spread':[np.mean],\n        'volume_imbalance':[np.mean],\n        'volume_imbalance_spread':[np.mean],\n            }\n    df_feature = pd.DataFrame(book.groupby(['time_id']).agg(create_feature_dict)).reset_index()\n    df_feature['stock_id'] = temp_stock\n    order_ft = order_ft.append(df_feature)\norder_ft.columns = ['_'.join(col) for col in order_ft.columns.values]\norder_ft = order_ft.rename(columns={\"time_id_\": \"time_id\", \"stock_id_\": \"stock_id\"})\norder_ft.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:28:41.116876Z","iopub.execute_input":"2021-08-05T23:28:41.117383Z","iopub.status.idle":"2021-08-05T23:49:14.827635Z","shell.execute_reply.started":"2021-08-05T23:28:41.117333Z","shell.execute_reply":"2021-08-05T23:49:14.826471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_agg_info(df):\n    df[\"size_all\"] = df[\"size\"] * df[\"order_count\"]\n    df[\"volume\"] = df[\"price\"] * df[\"size_all\"]\n    agg_df = df.groupby(['time_id']).agg(mean_sec_in_bucket = ('seconds_in_bucket', 'mean'), \n                                                     mean_price = ('price', 'mean'),\n                                                     mean_size = ('size', 'mean'),\n                                                     mean_order = ('order_count', 'mean'),\n                                                     mean_size_all = ('size_all', 'mean'),\n                                                     mean_volume = ('volume', 'mean'),\n                                                     max_sec_in_bucket = ('seconds_in_bucket', 'max'), \n                                                     max_price = ('price', 'max'),\n                                                     max_size = ('size', 'max'),\n                                                     max_order = ('order_count', 'max'),\n                                                     max_size_all = ('size_all', 'max'),\n                                                     max_volume = ('volume', 'max'),\n                                                     min_sec_in_bucket = ('seconds_in_bucket', 'min'), \n                                                     min_price = ('price', 'min'),\n                                                     min_size = ('size', 'min'),\n                                                     min_order = ('order_count', 'min'),\n                                                     min_size_all = ('size_all', 'min'),\n                                                     min_volume = ('volume', 'min'),\n                                                     median_sec_in_bucket = ('seconds_in_bucket', 'median'), \n                                                     median_price = ('price', 'median'),\n                                                     median_size = ('size', 'median'),\n                                                     median_order = ('order_count', 'median'),\n                                                     median_size_all = ('size_all', 'median'),\n                                                     median_volume = ('volume', 'median'),\n                                                     sum_size = ('size', 'sum'),\n                                                     sum_order = ('order_count', 'sum'),\n                                                     sum_size_all = ('size_all', 'sum'),\n                                                     sum_volume = ('volume', 'sum')\n                                                    ).reset_index()\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:14.829469Z","iopub.execute_input":"2021-08-05T23:49:14.829821Z","iopub.status.idle":"2021-08-05T23:49:14.841268Z","shell.execute_reply.started":"2021-08-05T23:49:14.829789Z","shell.execute_reply":"2021-08-05T23:49:14.840005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trade_book_training = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/*')\ntrade_stat = pd.DataFrame()\nfor i in trade_book_training:\n    temp_stock = int(i.split(\"=\")[1])\n    trade = pd.read_parquet(i)\n    trade_val = get_agg_info(trade)\n    trade_val[\"stock_id\"] = temp_stock\n    trade_stat = trade_stat.append(trade_val)\nstats = order_ft.merge(trade_stat, on=[\"stock_id\", \"time_id\"], how=\"left\")\nstats.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:14.84262Z","iopub.execute_input":"2021-08-05T23:49:14.84295Z","iopub.status.idle":"2021-08-05T23:49:47.006113Z","shell.execute_reply.started":"2021-08-05T23:49:14.842912Z","shell.execute_reply":"2021-08-05T23:49:47.005028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats['trade_bid_price_spread1'] = abs(stats['mean_price'] - stats['bid_price1_mean'])\nstats['trade_bid_price_spread2'] = abs(stats['mean_price'] - stats['bid_price2_mean'])\nstats['trade_ask_price_spread1'] = abs(stats['mean_price'] - stats['ask_price1_mean'])\nstats['trade_ask_price_spread2'] = abs(stats['mean_price'] - stats['ask_price2_mean'])\nstats['trade_bid_size_spread1'] = abs(stats['mean_size_all'] - stats['bid_size1_mean'])\nstats['trade_bid_size_spread2'] = abs(stats['mean_size_all'] - stats['bid_size2_mean'])\nstats['trade_ask_size_spread1'] = abs(stats['mean_size_all'] - stats['ask_size1_mean'])\nstats['trade_ask_size_spread2'] = abs(stats['mean_size_all'] - stats['ask_size2_mean'])\nstats['trade_bid_volume_spread1'] = abs(stats['mean_volume'] - stats['bid_volume1_mean'])\nstats['trade_bid_volume_spread2'] = abs(stats['mean_volume'] - stats['bid_volume2_mean'])\nstats['trade_ask_volume_spread1'] = abs(stats['mean_volume'] - stats['ask_volume1_mean'])\nstats['trade_ask_volume_spread2'] = abs(stats['mean_volume'] - stats['ask_volume2_mean'])\nstats['trade_bid_volume_spread'] = abs(stats['mean_volume'] - stats['bid_volume_mean'])\nstats['trade_ask_volume_spread'] = abs(stats['mean_volume'] - stats['ask_volume_mean'])\nstats.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:47.007447Z","iopub.execute_input":"2021-08-05T23:49:47.00774Z","iopub.status.idle":"2021-08-05T23:49:47.05494Z","shell.execute_reply.started":"2021-08-05T23:49:47.007713Z","shell.execute_reply":"2021-08-05T23:49:47.054104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joined = train.merge(stats, on = [\"stock_id\",\"time_id\"], how = \"left\").dropna()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:47.057458Z","iopub.execute_input":"2021-08-05T23:49:47.057779Z","iopub.status.idle":"2021-08-05T23:49:49.369677Z","shell.execute_reply.started":"2021-08-05T23:49:47.05775Z","shell.execute_reply":"2021-08-05T23:49:49.368803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 100)\njoined[joined.columns[2:]].corr()['target'][:-1].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:49.371657Z","iopub.execute_input":"2021-08-05T23:49:49.371944Z","iopub.status.idle":"2021-08-05T23:49:55.575173Z","shell.execute_reply.started":"2021-08-05T23:49:49.371916Z","shell.execute_reply":"2021-08-05T23:49:55.574126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(stats.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:55.576579Z","iopub.execute_input":"2021-08-05T23:49:55.576869Z","iopub.status.idle":"2021-08-05T23:49:55.582837Z","shell.execute_reply.started":"2021-08-05T23:49:55.576842Z","shell.execute_reply":"2021-08-05T23:49:55.581714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = joined.drop(\"target\", axis=1)\ny = joined[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:55.584315Z","iopub.execute_input":"2021-08-05T23:49:55.584654Z","iopub.status.idle":"2021-08-05T23:49:55.662821Z","shell.execute_reply.started":"2021-08-05T23:49:55.584625Z","shell.execute_reply":"2021-08-05T23:49:55.662024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\nkf = KFold(n_splits=10, random_state=133, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:55.663843Z","iopub.execute_input":"2021-08-05T23:49:55.66426Z","iopub.status.idle":"2021-08-05T23:49:56.66714Z","shell.execute_reply.started":"2021-08-05T23:49:55.66423Z","shell.execute_reply":"2021-08-05T23:49:56.665952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 100)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:56.668733Z","iopub.execute_input":"2021-08-05T23:49:56.669129Z","iopub.status.idle":"2021-08-05T23:49:56.674267Z","shell.execute_reply.started":"2021-08-05T23:49:56.669095Z","shell.execute_reply":"2021-08-05T23:49:56.672878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:56.675968Z","iopub.execute_input":"2021-08-05T23:49:56.67628Z","iopub.status.idle":"2021-08-05T23:49:56.798097Z","shell.execute_reply.started":"2021-08-05T23:49:56.676249Z","shell.execute_reply":"2021-08-05T23:49:56.796984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:56.799455Z","iopub.execute_input":"2021-08-05T23:49:56.799781Z","iopub.status.idle":"2021-08-05T23:49:58.105287Z","shell.execute_reply.started":"2021-08-05T23:49:56.799748Z","shell.execute_reply":"2021-08-05T23:49:58.104264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n# calculate the correlation matrix\nplt.figure(figsize=(20,20))\ncorr = joined.corr()\n\n# plot the heatmap\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:49:58.106846Z","iopub.execute_input":"2021-08-05T23:49:58.107291Z","iopub.status.idle":"2021-08-05T23:50:08.646692Z","shell.execute_reply.started":"2021-08-05T23:49:58.107246Z","shell.execute_reply":"2021-08-05T23:50:08.645662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# calculate the correlation matrix\nplt.figure(figsize=(20,20))\ncorr = joined[['trade_bid_price_spread1',\n       'trade_bid_price_spread2', 'trade_ask_price_spread1',\n       'trade_ask_price_spread2', 'trade_bid_size_spread1',\n       'trade_bid_size_spread2', 'trade_ask_size_spread1',\n       'trade_ask_size_spread2', 'trade_bid_volume_spread1',\n       'trade_bid_volume_spread2', 'trade_ask_volume_spread1',\n       'trade_ask_volume_spread2', 'trade_bid_volume_spread',\n       'trade_ask_volume_spread', ]].corr()\n\n# plot the heatmap\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:50:08.648205Z","iopub.execute_input":"2021-08-05T23:50:08.648777Z","iopub.status.idle":"2021-08-05T23:50:09.501163Z","shell.execute_reply.started":"2021-08-05T23:50:08.648718Z","shell.execute_reply":"2021-08-05T23:50:09.500426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# calculate the correlation matrix\nplt.figure(figsize=(20,20))\ncorr = joined[['trade_bid_price_spread1',\n       'trade_ask_price_spread1',\n       'trade_bid_size_spread1']].corr()\nprint(corr)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:50:09.502472Z","iopub.execute_input":"2021-08-05T23:50:09.503109Z","iopub.status.idle":"2021-08-05T23:50:09.540308Z","shell.execute_reply.started":"2021-08-05T23:50:09.50306Z","shell.execute_reply":"2021-08-05T23:50:09.539311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(corr)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:50:09.54192Z","iopub.execute_input":"2021-08-05T23:50:09.542521Z","iopub.status.idle":"2021-08-05T23:50:09.551019Z","shell.execute_reply.started":"2021-08-05T23:50:09.542473Z","shell.execute_reply":"2021-08-05T23:50:09.550186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joined[['trade_bid_price_spread1',\n       'trade_bid_price_spread2', 'trade_ask_price_spread1',\n       'trade_ask_price_spread2', 'trade_bid_size_spread1',\n       'trade_bid_size_spread2', 'trade_ask_size_spread1',\n       'trade_ask_size_spread2', 'trade_bid_volume_spread1',\n       'trade_bid_volume_spread2', 'trade_ask_volume_spread1',\n       'trade_ask_volume_spread2', 'trade_bid_volume_spread',\n       'trade_ask_volume_spread', ]]","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:50:09.552073Z","iopub.execute_input":"2021-08-05T23:50:09.552482Z","iopub.status.idle":"2021-08-05T23:50:09.594951Z","shell.execute_reply.started":"2021-08-05T23:50:09.552453Z","shell.execute_reply":"2021-08-05T23:50:09.594115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stock by stock traing using all features\nall_df = pd.DataFrame()\nfor stock in list(set(joined[\"stock_id\"])):\n    stock_joined = joined[joined[\"stock_id\"] == stock]\n    X = stock_joined.drop([\"target\", \"stock_id\", \"time_id\"], axis=1)\n    X = X[['bid_price1_mean', 'bid_size1_mean', 'ask_price1_mean',\n       'ask_size1_mean', 'bid_price2_mean', 'bid_size2_mean',\n       'ask_price2_mean', 'ask_size2_mean', 'bid_volume1_mean',\n       'bid_volume2_mean', 'ask_volume1_mean', 'ask_volume2_mean',\n       'bid_volume_mean', 'ask_volume_mean', 'wap1_calc_vol', 'wap2_calc_vol',\n       'wap_total1_calc_vol', 'wap_total2_calc_vol', 'wap_balance_mean',\n       'price_spread_mean', 'bid_spread_mean', 'ask_spread_mean',\n       'total_size_mean', 'total_volume_mean', 'size_imbalance_mean',\n       'size_imbalance_spread_mean', 'volume_imbalance_mean',\n       'volume_imbalance_spread_mean', 'mean_sec_in_bucket', 'mean_price',\n       'mean_size', 'mean_order', 'mean_size_all', 'mean_volume',\n       'max_sec_in_bucket', 'max_price', 'max_size', 'max_order',\n       'max_size_all', 'max_volume', 'min_sec_in_bucket', 'min_price',\n       'min_size', 'min_order', 'min_size_all', 'min_volume',\n       'median_sec_in_bucket', 'median_price', 'median_size', 'median_order',\n       'median_size_all', 'median_volume', 'sum_size', 'sum_order',\n       'sum_size_all', 'sum_volume', 'trade_bid_price_spread1',\n       'trade_bid_price_spread2', 'trade_ask_price_spread1',\n       'trade_ask_price_spread2']]\n    y = stock_joined[\"target\"]\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(X)):\n        # create dataset\n        X_train, X_valid = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_valid = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model = LinearRegression()\n        weights = 1/np.square(y_train)\n        model.fit(X_train, y_train, sample_weight=weights)\n        # validation \n        y_pred = model.predict(X_valid)\n        fold_df = pd.DataFrame()\n        fold_df[\"y_valid\"] = y_valid\n        fold_df[\"y_pred\"] = y_pred\n        fold_df[\"stock\"] = stock\n        fold_df[\"fold\"] = fold\n        all_df = all_df.append(fold_df)\nscores = []\nfor fold in range(0, 10):\n    fold_score = all_df[all_df[\"fold\"] == fold]\n    RMSPE = round(rmspe(y_true = fold_score[\"y_valid\"], y_pred = fold_score[\"y_pred\"]),3)\n    scores.append(RMSPE)\nprint(scores)\nprint(sum(scores)/10)\n\n[0.494, 0.246, 0.244, 0.332, 0.265, 0.252, 0.251, 0.243, 0.252, 0.249]\n0.2828\n","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:50:09.596081Z","iopub.execute_input":"2021-08-05T23:50:09.596483Z","iopub.status.idle":"2021-08-05T23:50:56.934192Z","shell.execute_reply.started":"2021-08-05T23:50:09.596453Z","shell.execute_reply":"2021-08-05T23:50:56.932376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stock by stock traing using all features\nall_df = pd.DataFrame()\nfor stock in list(set(joined[\"stock_id\"])):\n    stock_joined = joined[joined[\"stock_id\"] == stock]\n    X = stock_joined.drop([\"target\", \"stock_id\", \"time_id\"], axis=1)\n    X = X[['bid_price1_mean', 'bid_size1_mean', 'ask_price1_mean',\n       'ask_size1_mean', 'bid_price2_mean', 'bid_size2_mean',\n       'ask_price2_mean', 'ask_size2_mean', 'bid_volume1_mean',\n       'bid_volume2_mean', 'ask_volume1_mean', 'ask_volume2_mean',\n       'bid_volume_mean', 'ask_volume_mean', 'wap1_calc_vol', 'wap2_calc_vol',\n       'wap_total1_calc_vol', 'wap_total2_calc_vol', 'wap_balance_mean',\n       'price_spread_mean', 'bid_spread_mean', 'ask_spread_mean',\n       'total_size_mean', 'total_volume_mean', 'size_imbalance_mean',\n       'size_imbalance_spread_mean', 'volume_imbalance_mean',\n       'volume_imbalance_spread_mean', 'mean_sec_in_bucket', 'mean_price',\n       'mean_size', 'mean_order', 'mean_size_all', 'mean_volume',\n       'max_sec_in_bucket', 'max_price', 'max_size', 'max_order',\n       'max_size_all', 'max_volume', 'min_sec_in_bucket', 'min_price',\n       'min_size', 'min_order', 'min_size_all', 'min_volume',\n       'median_sec_in_bucket', 'median_price', 'median_size', 'median_order',\n       'median_size_all', 'median_volume', 'sum_size', 'sum_order',\n       'sum_size_all', 'sum_volume', 'trade_bid_price_spread1',\n       'trade_bid_price_spread2', 'trade_ask_price_spread1',\n       'trade_ask_price_spread2', 'trade_bid_size_spread1',\n       'trade_bid_size_spread2', 'trade_ask_size_spread1',\n       'trade_ask_size_spread2', 'trade_bid_volume_spread1',\n       'trade_bid_volume_spread2', 'trade_ask_volume_spread1',\n       'trade_ask_volume_spread2', 'trade_bid_volume_spread',\n       'trade_ask_volume_spread', ]]\n    y = stock_joined[\"target\"]\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(X)):\n        # create dataset\n        X_train, X_valid = X.iloc[trn_idx], X.iloc[val_idx]\n        y_train, y_valid = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model = LinearRegression()\n        weights = 1/np.square(y_train)\n        model.fit(X_train, y_train, sample_weight=weights)\n        # validation \n        y_pred = model.predict(X_valid)\n        fold_df = pd.DataFrame()\n        fold_df[\"y_valid\"] = y_valid\n        fold_df[\"y_pred\"] = y_pred\n        fold_df[\"stock\"] = stock\n        fold_df[\"fold\"] = fold\n        all_df = all_df.append(fold_df)\nscores = []\nfor fold in range(0, 10):\n    fold_score = all_df[all_df[\"fold\"] == fold]\n    RMSPE = round(rmspe(y_true = fold_score[\"y_valid\"], y_pred = fold_score[\"y_pred\"]),3)\n    scores.append(RMSPE)\nprint(scores)\nprint(sum(scores)/10)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:50:56.936004Z","iopub.execute_input":"2021-08-05T23:50:56.936467Z","iopub.status.idle":"2021-08-05T23:51:49.068961Z","shell.execute_reply.started":"2021-08-05T23:50:56.936422Z","shell.execute_reply":"2021-08-05T23:51:49.066137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nnp.set_printoptions(threshold=sys.maxsize)\nX.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:51:49.073687Z","iopub.execute_input":"2021-08-05T23:51:49.074492Z","iopub.status.idle":"2021-08-05T23:51:49.085191Z","shell.execute_reply.started":"2021-08-05T23:51:49.074435Z","shell.execute_reply":"2021-08-05T23:51:49.084038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stock by stock training each feature\nfeature_df = pd.DataFrame()\nfor feature in ['bid_price1_mean', 'bid_size1_mean', 'ask_price1_mean',\n       'ask_size1_mean', 'bid_price2_mean', 'bid_size2_mean',\n       'ask_price2_mean', 'ask_size2_mean', 'bid_volume1_mean',\n       'bid_volume2_mean', 'ask_volume1_mean', 'ask_volume2_mean',\n       'bid_volume_mean', 'ask_volume_mean', 'wap1_calc_vol', 'wap2_calc_vol',\n       'wap_total1_calc_vol', 'wap_total2_calc_vol', 'wap_balance_mean',\n       'price_spread_mean', 'bid_spread_mean', 'ask_spread_mean',\n       'total_size_mean', 'total_volume_mean', 'size_imbalance_mean',\n       'size_imbalance_spread_mean', 'volume_imbalance_mean',\n       'volume_imbalance_spread_mean', 'mean_sec_in_bucket', 'mean_price',\n       'mean_size', 'mean_order', 'mean_size_all', 'mean_volume',\n       'max_sec_in_bucket', 'max_price', 'max_size', 'max_order',\n       'max_size_all', 'max_volume', 'min_sec_in_bucket', 'min_price',\n       'min_size', 'min_order', 'min_size_all', 'min_volume',\n       'median_sec_in_bucket', 'median_price', 'median_size', 'median_order',\n       'median_size_all', 'median_volume', 'sum_size', 'sum_order',\n       'sum_size_all', 'sum_volume', 'trade_bid_price_spread1',\n       'trade_bid_price_spread2', 'trade_ask_price_spread1',\n       'trade_ask_price_spread2', 'trade_bid_size_spread1',\n       'trade_bid_size_spread2', 'trade_ask_size_spread1',\n       'trade_ask_size_spread2', 'trade_bid_volume_spread1',\n       'trade_bid_volume_spread2', 'trade_ask_volume_spread1',\n       'trade_ask_volume_spread2', 'trade_bid_volume_spread',\n       'trade_ask_volume_spread', ]:\n    all_df = pd.DataFrame()\n    for stock in list(set(joined[\"stock_id\"])):\n        stock_joined = joined[joined[\"stock_id\"] == stock]\n        X = stock_joined.drop([\"target\", \"stock_id\", \"time_id\"], axis=1)\n        X = X[[feature]]\n        y = stock_joined[\"target\"]\n        for fold, (trn_idx, val_idx) in enumerate(kf.split(X)):\n            # create dataset\n            X_train, X_valid = X.iloc[trn_idx], X.iloc[val_idx]\n            y_train, y_valid = y.iloc[trn_idx], y.iloc[val_idx]\n\n            model = LinearRegression()\n            weights = 1/np.square(y_train)\n            model.fit(X_train, y_train, sample_weight=weights)\n            # validation \n            y_pred = model.predict(X_valid)\n            fold_df = pd.DataFrame()\n            fold_df[\"y_valid\"] = y_valid\n            fold_df[\"y_pred\"] = y_pred\n            fold_df[\"stock\"] = stock\n            fold_df[\"fold\"] = fold\n            all_df = all_df.append(fold_df)\n    scores = []\n    for fold in range(0, 5):\n        fold_score = all_df[all_df[\"fold\"] == fold]\n        RMSPE = round(rmspe(y_true = fold_score[\"y_valid\"], y_pred = fold_score[\"y_pred\"]),3)\n        scores.append(RMSPE)\n    print(feature, sum(scores)/5)\n    feature_df = feature_df.append(pd.DataFrame({\"feature\": [feature], \"score\":[sum(scores)/5]}))","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:51:49.087461Z","iopub.execute_input":"2021-08-05T23:51:49.088294Z","iopub.status.idle":"2021-08-06T00:07:03.569853Z","shell.execute_reply.started":"2021-08-05T23:51:49.088228Z","shell.execute_reply":"2021-08-06T00:07:03.568814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_df.sort_values(\"score\", ascending=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:07:03.571554Z","iopub.execute_input":"2021-08-06T00:07:03.572146Z","iopub.status.idle":"2021-08-06T00:07:03.595491Z","shell.execute_reply.started":"2021-08-06T00:07:03.5721Z","shell.execute_reply":"2021-08-06T00:07:03.594553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_parquet(\"/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:07:03.596877Z","iopub.execute_input":"2021-08-06T00:07:03.597438Z","iopub.status.idle":"2021-08-06T00:07:03.638723Z","shell.execute_reply.started":"2021-08-06T00:07:03.597396Z","shell.execute_reply":"2021-08-06T00:07:03.637767Z"},"trusted":true},"execution_count":null,"outputs":[]}]}