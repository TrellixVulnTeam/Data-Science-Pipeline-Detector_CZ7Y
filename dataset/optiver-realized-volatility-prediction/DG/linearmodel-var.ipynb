{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This notebook estimates a linear regression over the past volatilities computed over different windows over the total 600 seconds considered.\n\n# Functions\nimport sys\nimport pandas as pd\nimport numpy as np\nimport glob\nimport re\n\ndata_path = \"/kaggle/input/optiver-realized-volatility-prediction/\"\ndata      = \"/kaggle/input/optiver/\"\n\ndef add_score_time_ids(df):\n    new_col = df.stock_id.astype(str).values + '-' + df.time_id.astype(str).values\n    df['id_row'] = new_col\n    co = ['id_row','stock_id','time_id']\n    return df[co+[c for c in df.columns if c not in co]]\n\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef add_wap_lr(df):\n    df['wap'] = (df['bid_price1'] * df['ask_size1']+df['ask_price1'] * df['bid_size1'])  / (df['bid_size1']+ df['ask_size1'])\n    df['log_return'] = df.groupby(['time_id'])['wap'].apply(log_return)\n    df = df[~df['log_return'].isnull()]\n    return df\n\ndef add_past_vol(df):\n    df = df[~df['log_return'].isnull()]\n    vol = pd.DataFrame(df.groupby(['time_id','stock_id'])['log_return'].agg(realized_volatility)).reset_index()\n    vol = add_score_time_ids(vol).set_index('id_row')\n    return pd.concat((df,pd.DataFrame({'past_vol':vol['log_return']},index=df.index)),axis=1)\n\ndef treatment(df):\n    df = add_wap_lr(df)\n    df = add_score_time_ids(df)\n    return df.set_index('id_row')\n\ndef lighten(df,cols):\n    return df.drop(columns=cols)\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\ncols = ['bid_price1',\t'ask_price1',\t'bid_price2',\t'ask_price2',\t'bid_size1',\t'ask_size1',\t'bid_size2',\t'ask_size2',\t'wap',]\ndef make_light_book(file_,cols):\n    df = pd.DataFrame()\n    book = pd.read_parquet(file_)\n    book['stock_id'] = re.findall('stock_id=(.*)/',file_)[0]\n    df = pd.concat((df,lighten(treatment(book),cols)),axis=0)\n    return df\n\ndef make_volatility(df,Train,lags=4):\n    volatilities = pd.DataFrame()    \n    for i in map(str,range(1,lags)):\n        volatilities['t'+i] = df.query('seconds_in_bucket <' + i + '00').groupby(['time_id','stock_id'])['log_return'].agg(realized_volatility)\n\n    volatilities['t_all'] = df.groupby(['time_id','stock_id'])['log_return'].agg(realized_volatility)\n    volatilities = add_score_time_ids(volatilities.reset_index()).set_index('id_row')\n\n    if Train:\n        y = add_score_time_ids(pd.read_csv(data_path+'train.csv')).set_index('id_row')\n        volatilities['target'] = y.loc[volatilities.index]['target']\n\n    floats = volatilities.select_dtypes(include=np.float64).columns\n    volatilities[floats] = volatilities[floats]#.astype(np.float32)\n    return volatilities\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T13:49:25.145842Z","iopub.execute_input":"2021-09-09T13:49:25.146189Z","iopub.status.idle":"2021-09-09T13:49:25.167155Z","shell.execute_reply.started":"2021-09-09T13:49:25.146161Z","shell.execute_reply":"2021-09-09T13:49:25.165913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make Dataset\nfrom joblib import Parallel, delayed\nbook_files_train = glob.glob(data_path+'book_train.parquet/stock_id=*/*')\nbook_files_test  = glob.glob(data_path+'book_test.parquet/stock_id=*/*')\n\n# Use parallel api to call paralle for loop\nfor_joblib = lambda file_: make_volatility(make_light_book(file_, cols),Train=1)\n\ndf = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(file_) for file_ in book_files_train)\n# Concatenate all the dataframes that return from Parallel\ntrain = pd.concat(df, ignore_index = True)\n\nfor_joblib = lambda file_: make_volatility(make_light_book(file_, cols),Train=False)\ndf = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(file_) for file_ in book_files_test)\n# Concatenate all the dataframes that return from Parallel\ntest = pd.concat(df, ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T13:49:25.168621Z","iopub.execute_input":"2021-09-09T13:49:25.168922Z","iopub.status.idle":"2021-09-09T13:58:32.912364Z","shell.execute_reply.started":"2021-09-09T13:49:25.168893Z","shell.execute_reply":"2021-09-09T13:58:32.910847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Estimation\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\nlr = LinearRegression()\nX = train.select_dtypes(include=[np.float64,np.float32]).apply(np.log)\nX = X.replace([np.inf,-np.inf],np.nan).dropna()\ny = X[['target']]\nX = X.drop(columns='target')\n\nX_fit, y_fit = X, y\nlr.fit(X_fit,y_fit)\n\n# Compute score over the train set\ny_pred = lr.predict(X)\ny_true, y_pred = np.exp(y.values), np.exp(y_pred)\nscore = rmspe(y_true=y_true,y_pred=y_pred)\nprint('\\nScore obtained for linear regression is {:.3}.\\nR2 is {:.3}.'.format(score,r2_score(y_true=y_true,y_pred=y_pred)))\n\n# Prediction\nX_test = test.select_dtypes(include=[np.float64,np.float32]).apply(np.log)\nX_test = X_test.replace([np.inf,np.nan,-np.inf],0.0)\n\ntest['target'] = np.exp(lr.predict(X_test))\ntest[\"row_id\"] = test[\"stock_id\"].astype(str) + \"-\" + test[\"time_id\"].astype(str)\nprint(test[['row_id', 'target']].head(3))\ntest[['row_id', 'target']].to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T19:33:18.730956Z","iopub.execute_input":"2021-09-09T19:33:18.731588Z","iopub.status.idle":"2021-09-09T19:33:19.936495Z","shell.execute_reply.started":"2021-09-09T19:33:18.731497Z","shell.execute_reply":"2021-09-09T19:33:19.935258Z"},"trusted":true},"execution_count":null,"outputs":[]}]}