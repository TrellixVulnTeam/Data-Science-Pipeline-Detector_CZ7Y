{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Explanations of the Market Maker, Statistics retained from the explanation tutorial for reference.\n\n## A market maker provides liquidity to the market by selling and buying in a market. \n\nMarket Maker is a firm, individual or a Program (automated MM) who actively quotes two-sided markets in a security, providing bids and offers (known as asks) along with the market size of each. As a market maker will show both bid and offer orders, an order book with the presence of market maker will be more liquid, therefore a more efficient market will be provided to end investors to trade freely without concern on executions.","metadata":{}},{"cell_type":"markdown","source":"\n# Order book statistics\nThere are a lot of statistics Optiver data scientist can derive from raw order book data to reflect market liquidity and stock valuation. These stats are proven to be fundamental inputs of any market prediction algorithms. Below we would like to list some common stats to inspire Kagglers mining more valuable signals from the order book data.\n\nLet's come back to the original order book of stock A","metadata":{}},{"cell_type":"markdown","source":"**bid/ask spread**\n\nAs different stocks trade on different level on the market we take the ratio of best offer price and best bid price to calculate the bid-ask spread. \n\nThe formula of bid/ask spread can be written in below form:\n$$BidAskSpread = BestOffer/BestBid -1$$","metadata":{}},{"cell_type":"markdown","source":"**Weighted averaged price**\n\nThe order book is also one of the primary source for stock valuation. A fair book-based valuation must take two factors into account: the level and the size of orders. In this competition we used weighted averaged price, or WAP, to calculate the instantaneous stock valuation and calculate realized volatility as our target. \n\nThe formula of WAP can be written as below, which takes the top level price and volume information into account:\n\n$$ WAP = \\frac{BidPrice_{1}*AskSize_{1} + AskPrice_{1}*BidSize_{1}}{BidSize_{1} + AskSize_{1}} $$\n","metadata":{}},{"cell_type":"markdown","source":"# Log returns\n\n**How can we compare the price of a stock between yesterday and today?**\n\nWe can solve the above problem of comparing two price movements, by dividing the move by the starting price of the stock, effectively computing the percentage change in price, also known as the **stock return**. \n\nLog returns present several advantages, for example:\n- they are additive across time $r_{t_1, t_2} + r_{t_2, t_3} = r_{t_1, t_3}$\n- regular returns cannot go below -100%, while log returns are not bounded","metadata":{}},{"cell_type":"markdown","source":"# Realized volatility\nCompute the log returns over all consecutive book updates and we define the **realized volatility, $\\sigma$,** as the squared root of the sum of squared log returns.\n$$\n\\sigma = \\sqrt{\\sum_{t}r_{t-1, t}^2}\n$$\nWhere we use **WAP** as price of the stock to compute log returns.\n","metadata":{}},{"cell_type":"markdown","source":"# Competition data\nIn this competition, Kagglers are challenged to generate a series of short-term signals from the book and trade data of a fixed 10-minute window to predict the realized volatility of the next 10-minute \nwindow. Being an Avid Option trading enthusiast, and reading copious books on this topic has got me excited about this competition. \n\n# So Why calculate the Realized Volatility?\n\nThe calculation of the Realized volality will help to decide the market maker, which option strategies to maintain. In the real market, the option trader must maintain a hedge in another instrument to reduce their risks. The Risk are calculated by the people in the firm. We are going to support them.\n\n# Target Data is Realized Volatility:\n\nThe target, which is given in train/test.csv, can be linked with the raw order book/trade data by the same **time_id** and **stock_id**. There is no overlap between the feature and target window.","metadata":{}},{"cell_type":"markdown","source":"Some musings about the data and the steps to be taken... \n## What is the meaning of short term signals? \n\n## In case of train.csv there is Realized Vol given. The below notes uses the WAP of the order book data to generate the same and compared with the score. \n\n1) How might I improve on the predictions that were done based on the WAP technique, in turn have better R2 and RSMPE score\n\n    Bring in the Bid/Ask spread, and tie it in to somehow to improved the prediction\n    \n    There are two ask and bid prices, and the 2nd prices can be used to create additional WAP\n    \n    Using both WAP, aggregated WAP and from that new Target can be calculated\n    \n2) How might I use the \"Trade book\" data to improve the prediction\n\n    Take the trade book data WAP, and then mix it with the B/A spread and then generate the predictions\n    \n    Trade book is where the price of the stock got decided finally. So there WAP and actual traded price can be calculated\n\n3) How might I use the test.csv which contains only row_id, and no volality values\n\n4) How might I create the signals from the realized volatilty calculations?\n\n    When the volatility falls below a certain probability then give a buy or sell order\n    \n    Signal to a market maker, is which side of the market he should be in. On the buy side or sell side","metadata":{}},{"cell_type":"markdown","source":"Note that the competition data will come with partitioned parquet file. You can find a tutorial of parquet file handling in this [notebook](https://www.kaggle.com/sohier/working-with-parquet)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:56:33.250069Z","iopub.execute_input":"2021-08-08T12:56:33.250455Z","iopub.status.idle":"2021-08-08T12:56:33.410627Z","shell.execute_reply.started":"2021-08-08T12:56:33.250422Z","shell.execute_reply":"2021-08-08T12:56:33.409822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking the first row of data, it implies that the realized vol of the **target bucket** for time_id 5, stock_id 0 is 0.004136. How does the book and trade data in **feature bucket** look like for us to build signals?","metadata":{}},{"cell_type":"code","source":"book_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')\ntrade_example =  pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==11]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==11]\ntrade_example.loc[:,'stock_id'] = stock_id","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:20:41.089798Z","iopub.execute_input":"2021-08-08T11:20:41.09038Z","iopub.status.idle":"2021-08-08T11:20:41.250919Z","shell.execute_reply.started":"2021-08-08T11:20:41.090225Z","shell.execute_reply":"2021-08-08T11:20:41.249904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**book data snapshot**","metadata":{}},{"cell_type":"code","source":"book_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:20:44.889571Z","iopub.execute_input":"2021-08-08T11:20:44.889983Z","iopub.status.idle":"2021-08-08T11:20:44.906822Z","shell.execute_reply.started":"2021-08-08T11:20:44.889941Z","shell.execute_reply":"2021-08-08T11:20:44.905844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating Bid/Ask spread, will take multiple row of a particular time_id and then aggregate the bid/ask spread. \n#define bid_ask_spread(time_id,)\nid0_BASpread = min(book_example.ask_price1)/max(book_example.bid_price1) - 1\nid0_BASpread1 = min(book_example.ask_price2)/max(book_example.bid_price2) - 1\nprint(\"spread1:\", id0_BASpread)\nprint(\"spread2:\", id0_BASpread1)\n# The spread2 is higher compared to spread 1, and it is correct since spread 2 is 2nd best","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:24:47.520477Z","iopub.execute_input":"2021-08-08T11:24:47.521272Z","iopub.status.idle":"2021-08-08T11:24:47.529867Z","shell.execute_reply.started":"2021-08-08T11:24:47.521208Z","shell.execute_reply":"2021-08-08T11:24:47.52873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**trade date snapshot**","metadata":{}},{"cell_type":"code","source":"trade_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T09:50:53.379419Z","iopub.execute_input":"2021-08-08T09:50:53.37995Z","iopub.status.idle":"2021-08-08T09:50:53.393294Z","shell.execute_reply.started":"2021-08-08T09:50:53.379889Z","shell.execute_reply":"2021-08-08T09:50:53.39255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Realized volatility calculation in python**","metadata":{}},{"cell_type":"markdown","source":"## Our Objective \n\nto predict short-term realized volatility. Although the order book and trade data for the target cannot be shared, we can still present the realized volatility calculation using the feature data we provided. \n\n## Tactics\nAs realized volatility is a statistical measure of price changes on a given stock, \n\n1) We use the WAP calculated from two Bid/Ask spread data. The use the WAP to calculate the RV. \n\n2) Bring the trade price data and use the RV of that data also. \n\n3) Finally take the mean of predictions to submit","metadata":{}},{"cell_type":"code","source":"book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) / (\n                                       book_example['bid_size1']+ book_example['ask_size1'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:25:55.245351Z","iopub.execute_input":"2021-08-08T11:25:55.245753Z","iopub.status.idle":"2021-08-08T11:25:55.255326Z","shell.execute_reply.started":"2021-08-08T11:25:55.245715Z","shell.execute_reply":"2021-08-08T11:25:55.253804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"book_example['wap2'] = (book_example['bid_price2'] * book_example['ask_size2'] +\n                                book_example['ask_price2'] * book_example['bid_size2']) / (\n                                       book_example['bid_size2']+ book_example['ask_size2'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:25:56.709456Z","iopub.execute_input":"2021-08-08T11:25:56.709814Z","iopub.status.idle":"2021-08-08T11:25:56.718753Z","shell.execute_reply.started":"2021-08-08T11:25:56.709782Z","shell.execute_reply":"2021-08-08T11:25:56.717425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The WAP of the stock is plotted below**","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(16,10), sharex=False)\nline1 = axs.plot(trade_example[\"seconds_in_bucket\"],trade_example[\"price\"])\nline1 = axs.plot(book_example[\"seconds_in_bucket\"],book_example[\"wap\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:26:12.515186Z","iopub.execute_input":"2021-08-08T11:26:12.515555Z","iopub.status.idle":"2021-08-08T11:26:12.722109Z","shell.execute_reply.started":"2021-08-08T11:26:12.515525Z","shell.execute_reply":"2021-08-08T11:26:12.721262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(16,10), sharex=False)\nline1 = axs.plot(trade_example[\"seconds_in_bucket\"],trade_example[\"price\"])\nline1 = axs.plot(book_example[\"seconds_in_bucket\"],book_example[\"wap2\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:26:14.749816Z","iopub.execute_input":"2021-08-08T11:26:14.750517Z","iopub.status.idle":"2021-08-08T11:26:14.972813Z","shell.execute_reply.started":"2021-08-08T11:26:14.750476Z","shell.execute_reply":"2021-08-08T11:26:14.971033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(book_example.wap,book_example.wap2)\nprint(book_example[['wap','wap2']].corr())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:26:27.91108Z","iopub.execute_input":"2021-08-08T11:26:27.911502Z","iopub.status.idle":"2021-08-08T11:26:28.105573Z","shell.execute_reply.started":"2021-08-08T11:26:27.911467Z","shell.execute_reply":"2021-08-08T11:26:28.104244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Couple of Observations\n\nWap and wap2 seem to be correlated by 52% with each other.\n\nTrade price execution, wap and Wap2 price transitions can be linked to generate signals\n\nThis opens up the idea for using wap2 and trading prices to collect two more realized volatility and check their relationships ","metadata":{}},{"cell_type":"markdown","source":"To compute the log return, we can simply take **the logarithm of the ratio** between two consecutive **WAP**. The first row will have an empty return as the previous book update is unknown, therefore the empty return data point will be dropped.","metadata":{}},{"cell_type":"code","source":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() ","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:27:09.539497Z","iopub.execute_input":"2021-08-08T11:27:09.540048Z","iopub.status.idle":"2021-08-08T11:27:09.54456Z","shell.execute_reply.started":"2021-08-08T11:27:09.540014Z","shell.execute_reply":"2021-08-08T11:27:09.543257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"book_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example.loc[:,'log_return2'] = log_return(book_example['wap2'])\ntrade_example.loc[:,'log_return'] = log_return(trade_example['price'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:37:42.635783Z","iopub.execute_input":"2021-08-08T11:37:42.636183Z","iopub.status.idle":"2021-08-08T11:37:42.654428Z","shell.execute_reply.started":"2021-08-08T11:37:42.636126Z","shell.execute_reply":"2021-08-08T11:37:42.648686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"book_example = book_example[~book_example['log_return'].isnull()]\nbook_example = book_example[~book_example['log_return2'].isnull()]\ntrade_example = trade_example[~trade_example['log_return'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:38:16.650546Z","iopub.execute_input":"2021-08-08T11:38:16.651262Z","iopub.status.idle":"2021-08-08T11:38:16.660965Z","shell.execute_reply.started":"2021-08-08T11:38:16.651221Z","shell.execute_reply":"2021-08-08T11:38:16.659934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(book_example.shape)\nprint(trade_example.shape)\n#The rows, or inputs in trade file is lower, since these are actual traded prices, not estimated WAPs","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:38:36.087276Z","iopub.execute_input":"2021-08-08T11:38:36.088053Z","iopub.status.idle":"2021-08-08T11:38:36.097587Z","shell.execute_reply.started":"2021-08-08T11:38:36.088012Z","shell.execute_reply":"2021-08-08T11:38:36.096509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's plot the tick-to-tick return of this instrument over this time bucket**","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:01:53.679074Z","iopub.execute_input":"2021-06-09T15:01:53.679605Z","iopub.status.idle":"2021-06-09T15:01:53.686279Z","shell.execute_reply.started":"2021-06-09T15:01:53.67957Z","shell.execute_reply":"2021-06-09T15:01:53.684738Z"}}},{"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(16,10), sharex=False)\nline1 = axs.plot(book_example[\"seconds_in_bucket\"],book_example[\"log_return\"])\nline1 = axs.plot(book_example[\"seconds_in_bucket\"],book_example[\"log_return2\"])\n#Log return2 looks more volatile than the log return1","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:29:11.886623Z","iopub.execute_input":"2021-08-08T11:29:11.886996Z","iopub.status.idle":"2021-08-08T11:29:12.113337Z","shell.execute_reply.started":"2021-08-08T11:29:11.886966Z","shell.execute_reply":"2021-08-08T11:29:12.112116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(16,10), sharex=False)\nline1 = axs.plot(trade_example[\"seconds_in_bucket\"],trade_example[\"log_return\"])\n#Log return2 looks more volatile than the log return1","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:40:36.13722Z","iopub.execute_input":"2021-08-08T11:40:36.137802Z","iopub.status.idle":"2021-08-08T11:40:36.352851Z","shell.execute_reply.started":"2021-08-08T11:40:36.137749Z","shell.execute_reply":"2021-08-08T11:40:36.352049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The realized vol of stock 0 in this feature bucket, will be:","metadata":{}},{"cell_type":"code","source":"def realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\n#To calculate the realized volatility of one time_id, time_id 5\nrealized_vol = realized_volatility(book_example['log_return'])\nrealized_vol_2 = realized_volatility(book_example['log_return2'])\nrealized_vol_trade = realized_volatility(trade_example['log_return'])\n\nprint(f'Realized volatility_1 for stock_id 0 on time_id 5 is {realized_vol}')\nprint(f'Realized volatility_2 for stock_id 0 on time_id 5 is {realized_vol_2}')\nprint(f'Trade Realized volatility for stock_id 0 on time_id 5 is {realized_vol_trade}')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:41:53.145218Z","iopub.execute_input":"2021-08-08T11:41:53.145582Z","iopub.status.idle":"2021-08-08T11:41:53.15551Z","shell.execute_reply.started":"2021-08-08T11:41:53.145552Z","shell.execute_reply":"2021-08-08T11:41:53.154306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Volatility during the trade activity, there is marked reduction in the realized volatility. \n\nWhat might cause such a reduction? \n\nThe graphs of Log_returns show the volatility change, between the 1st best and 2nd best bid/ask spreads ","metadata":{}},{"cell_type":"markdown","source":"# Improving on the Naive prediction: using past period realized volatility calculated from 2 bid/ask prices as target and aggregating them","metadata":{}},{"cell_type":"markdown","source":"A commonly known fact about volatility is that it tends to be autocorrelated. We can use this property to implement a naive model that just \"predicts\" realized volatility by using whatever the realized volatility was in theinitial 10 minutes.\n\nLet's calculate the past realized volatility across the training set to see how predictive a single naive signal can be.","metadata":{}},{"cell_type":"code","source":"import os\nfrom sklearn.metrics import r2_score\nimport glob\nlist_order_book_file_train = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')\nlist_trade_book_file_train = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/*')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:34:33.085889Z","iopub.execute_input":"2021-08-08T11:34:33.086297Z","iopub.status.idle":"2021-08-08T11:34:34.165653Z","shell.execute_reply.started":"2021-08-08T11:34:33.086264Z","shell.execute_reply":"2021-08-08T11:34:34.16442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(list_order_book_file_train))\nprint(len(list_trade_book_file_train))\n# Both training parquet files have \n#1) 112 stock IDs\n#2) 2 sets of Bid / Ask prices and quantity\n#3) Trading parquets have only traded prices","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:36:36.131012Z","iopub.execute_input":"2021-08-08T11:36:36.13141Z","iopub.status.idle":"2021-08-08T11:36:36.138198Z","shell.execute_reply.started":"2021-08-08T11:36:36.131378Z","shell.execute_reply":"2021-08-08T11:36:36.136975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the data is partitioned by stock_id in this competition to allow Kagglers better manage the memory, we try to calculcate realized volatility stock by stock and combine them into one submission file. Note that the stock id as the partition column is not present if we load the single file so we will remedy that manually. We will reuse the log return and realized volatility functions defined in the previous session.","metadata":{}},{"cell_type":"code","source":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    #Reads the book order data, for stock id\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    #calculates the wap for that book data, For each time_id, since volatility for each time id is reqd\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    \n    #Below command takes log returns of each time_id and aggregates it realized volatiity function.\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    \n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    #here we get the id of the stock as a number\n    stock_id = file_path.split('=')[1]\n    \n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:46:15.350691Z","iopub.execute_input":"2021-08-08T11:46:15.35112Z","iopub.status.idle":"2021-08-08T11:46:15.359575Z","shell.execute_reply.started":"2021-08-08T11:46:15.351084Z","shell.execute_reply":"2021-08-08T11:46:15.358609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def realized_volatility_2_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    #Reads the book order data, for stock id\n    df_book_data['wap2'] =(df_book_data['bid_price2'] * df_book_data['ask_size2']+df_book_data['ask_price2'] * df_book_data['bid_size2'])  / (\n                                      df_book_data['bid_size2']+ df_book_data[\n                                  'ask_size2'])\n    #calculates the wap for that book data, For each time_id, since volatility for each time id is reqd\n    df_book_data['log_return2'] = df_book_data.groupby(['time_id'])['wap2'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return2'].isnull()]\n    \n    #Below command takes log returns of each time_id and aggregates it realized volatiity function.\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return2'].agg(realized_volatility)).reset_index()\n    \n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return2':prediction_column_name})\n    #here we get the id of the stock as a number\n    stock_id = file_path.split('=')[1]\n    \n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:03:44.031027Z","iopub.execute_input":"2021-08-08T12:03:44.031423Z","iopub.status.idle":"2021-08-08T12:03:44.039876Z","shell.execute_reply.started":"2021-08-08T12:03:44.031392Z","shell.execute_reply":"2021-08-08T12:03:44.039096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def realized_volatility_trade_per_time_id(file_path, prediction_column_name):\n    df_trade_data = pd.read_parquet(file_path)\n    #Reads the book order data, for stock id\n    df_trade_data['log_return'] = df_trade_data.groupby(['time_id'])['price'].apply(log_return)\n    df_trade_data = df_trade_data[~df_trade_data['log_return'].isnull()]\n    \n    #Below command takes log returns of each time_id and aggregates it realized volatiity function.\n    df_realized_vol_per_stock =  pd.DataFrame(df_trade_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    \n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    #here we get the id of the stock as a number\n    stock_id = file_path.split('=')[1]\n    \n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:40:21.875468Z","iopub.execute_input":"2021-08-08T12:40:21.875883Z","iopub.status.idle":"2021-08-08T12:40:21.884025Z","shell.execute_reply.started":"2021-08-08T12:40:21.875848Z","shell.execute_reply":"2021-08-08T12:40:21.883171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looping through each individual stocks, we can get the past realized volatility as prediction for each individual stocks.","metadata":{}},{"cell_type":"code","source":"def past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\n\ndef past_realized_volatility_per_stock_2(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_2_per_time_id(file,prediction_column_name)])\n    return df_past_realized","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:03:51.165429Z","iopub.execute_input":"2021-08-08T12:03:51.165954Z","iopub.status.idle":"2021-08-08T12:03:51.172686Z","shell.execute_reply.started":"2021-08-08T12:03:51.16592Z","shell.execute_reply":"2021-08-08T12:03:51.171396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def past_order_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_trade_per_time_id(file,prediction_column_name)])\n    return df_past_realized","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:41:57.384552Z","iopub.execute_input":"2021-08-08T12:41:57.385102Z","iopub.status.idle":"2021-08-08T12:41:57.389725Z","shell.execute_reply.started":"2021-08-08T12:41:57.385069Z","shell.execute_reply":"2021-08-08T12:41:57.388716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_past_realized_train_1 = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred')\ndf_past_realized_train_2 = past_realized_volatility_per_stock_2(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred2')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:21:37.506798Z","iopub.execute_input":"2021-08-08T12:21:37.507209Z","iopub.status.idle":"2021-08-08T12:34:02.358678Z","shell.execute_reply.started":"2021-08-08T12:21:37.507172Z","shell.execute_reply":"2021-08-08T12:34:02.357839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_past_realized_train_3 = past_order_realized_volatility_per_stock(list_file=list_trade_book_file_train,\n                                                           prediction_column_name='trade_Pred')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:44:09.908893Z","iopub.execute_input":"2021-08-08T12:44:09.909261Z","iopub.status.idle":"2021-08-08T12:49:20.925398Z","shell.execute_reply.started":"2021-08-08T12:44:09.909231Z","shell.execute_reply":"2021-08-08T12:49:20.924295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_past_realized_train_1.info())\nprint(df_past_realized_train_2.info())\nprint(df_past_realized_train_3.info())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:05:07.424403Z","iopub.execute_input":"2021-08-08T13:05:07.424782Z","iopub.status.idle":"2021-08-08T13:05:07.593863Z","shell.execute_reply.started":"2021-08-08T13:05:07.42475Z","shell.execute_reply":"2021-08-08T13:05:07.592778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's join the output dataframe with train.csv to see the performance of the naive prediction on training set.","metadata":{}},{"cell_type":"code","source":"train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\ndf_joined_1 = train.merge(df_past_realized_train_1[['row_id','pred']], on = ['row_id'], how = 'left')\ndf_joined_2 = df_joined_1.merge(df_past_realized_train_2[['row_id','pred2']], on = ['row_id'], how = 'left')\ndf_joined_3 = df_joined_2.merge(df_past_realized_train_3[['row_id','trade_Pred']], on = ['row_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:56:41.129186Z","iopub.execute_input":"2021-08-08T12:56:41.12953Z","iopub.status.idle":"2021-08-08T12:56:44.053343Z","shell.execute_reply.started":"2021-08-08T12:56:41.1295Z","shell.execute_reply":"2021-08-08T12:56:44.052349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_joined_3)\nprint(df_joined_3.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:59:05.226019Z","iopub.execute_input":"2021-08-08T12:59:05.226688Z","iopub.status.idle":"2021-08-08T12:59:05.24082Z","shell.execute_reply.started":"2021-08-08T12:59:05.226636Z","shell.execute_reply":"2021-08-08T12:59:05.239772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_joined_3['mean_pred'] = (df_joined_3.pred + df_joined_3.pred2 + df_joined_3.trade_Pred)/3","metadata":{"execution":{"iopub.status.busy":"2021-08-08T12:58:59.865115Z","iopub.execute_input":"2021-08-08T12:58:59.865535Z","iopub.status.idle":"2021-08-08T12:58:59.875528Z","shell.execute_reply.started":"2021-08-08T12:58:59.865501Z","shell.execute_reply":"2021-08-08T12:58:59.874609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_joined_3.mean_pred.isnull().sum())\ndf_joined_3.fillna(0,inplace=True)\n\n#The trade data is available only for 428,852 while the rest of the order book data are 428,932. There is gap of 80 data. \n#It is harmless in replacing these 80 mean preds to 0","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:07:55.529866Z","iopub.execute_input":"2021-08-08T13:07:55.530418Z","iopub.status.idle":"2021-08-08T13:07:55.590476Z","shell.execute_reply.started":"2021-08-08T13:07:55.530385Z","shell.execute_reply":"2021-08-08T13:07:55.589436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will evaluate the naive prediction result by two metrics: RMSPE and R squared. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\nR2_i = round(r2_score(y_true = df_joined_3['target'], y_pred = df_joined_3['pred']),3)\nRMSPE_i = round(rmspe(y_true = df_joined_3['target'], y_pred = df_joined_3['pred']),3)\n\nR2 = round(r2_score(y_true = df_joined_3['target'], y_pred = df_joined_3['mean_pred']),3)\nRMSPE = round(rmspe(y_true = df_joined_3['target'], y_pred = df_joined_3['mean_pred']),3)\n\nprint(f'Performance of the naive prediction: R2 score: {R2_i}, RMSPE: {RMSPE_i}')\n\nprint(f'Performance of the updated prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:10:09.404832Z","iopub.execute_input":"2021-08-08T13:10:09.405233Z","iopub.status.idle":"2021-08-08T13:10:09.434399Z","shell.execute_reply.started":"2021-08-08T13:10:09.405195Z","shell.execute_reply":"2021-08-08T13:10:09.433233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The performance of the updated model is worse than the original baseline. Have to work on a different method.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"df_improved_naive_pred_test = df_joined_3[['row_id','mean_pred']].rename(columns = {'mean_pred':\"target\"})","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:51:54.78438Z","iopub.execute_input":"2021-08-08T13:51:54.784742Z","iopub.status.idle":"2021-08-08T13:51:54.807735Z","shell.execute_reply.started":"2021-08-08T13:51:54.78471Z","shell.execute_reply":"2021-08-08T13:51:54.806806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_improved_naive_pred_test.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:51:56.843835Z","iopub.execute_input":"2021-08-08T13:51:56.844181Z","iopub.status.idle":"2021-08-08T13:51:58.22271Z","shell.execute_reply.started":"2021-08-08T13:51:56.844139Z","shell.execute_reply":"2021-08-08T13:51:58.221651Z"},"trusted":true},"execution_count":null,"outputs":[]}]}