{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a rather high scoring RAPIDS notebook that I was working on at the beginning of the competition. I decided to share it because it shows a couple of important ideas. Most importantly, it achieves a rather high score in only 20 minutes.\n\n1. I create my own unique features. In particular resonance and vibration (I just came up with those)\n2. I use a FAST ICA to divide the analysis into categorical groups - The thinking here is to have 125 fast ICA components. n-1 the number of stocks in the sample (There were less, but at the time I wrote the notebook I thought I had 126)\n3. Use of RAPIDS.","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport cudf\nimport cuml\nimport glob\nfrom tqdm import tqdm\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nimport random\nimport pickle\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.decomposition import FastICA\nfrom sklearn.decomposition import PCA\nimport pandas as pd\nimport gc\nimport xgboost as xgb\nimport pickle\nfrom collections import Counter","metadata":{"papermill":{"duration":4.451265,"end_time":"2021-08-22T23:55:59.051256","exception":false,"start_time":"2021-08-22T23:55:54.599991","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:28.102572Z","iopub.execute_input":"2021-08-30T23:44:28.103033Z","iopub.status.idle":"2021-08-30T23:44:32.53477Z","shell.execute_reply.started":"2021-08-30T23:44:28.102944Z","shell.execute_reply":"2021-08-30T23:44:32.533892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"REMAKE_TRAINING = False","metadata":{"papermill":{"duration":0.037728,"end_time":"2021-08-22T23:55:59.120569","exception":false,"start_time":"2021-08-22T23:55:59.082841","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-09-27T22:00:46.007926Z","iopub.execute_input":"2021-09-27T22:00:46.00853Z","iopub.status.idle":"2021-09-27T22:00:46.018849Z","shell.execute_reply.started":"2021-09-27T22:00:46.008442Z","shell.execute_reply":"2021-09-27T22:00:46.017839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/optiver-realized-volatility-prediction\"\ndef load_data(mode, path=\"/kaggle/input/optiver-realized-volatility-prediction\"):\n    # mode = \"train\"/\"test\"\n    file_name = f'{path}/{mode}.csv'\n    return cudf.read_csv(file_name)\n\ndev_df = load_data(\"train\", path=PATH)\ndev_df.head()","metadata":{"papermill":{"duration":3.624967,"end_time":"2021-08-22T23:56:02.776434","exception":false,"start_time":"2021-08-22T23:55:59.151467","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:32.543062Z","iopub.execute_input":"2021-08-30T23:44:32.543614Z","iopub.status.idle":"2021-08-30T23:44:36.131406Z","shell.execute_reply.started":"2021-08-30T23:44:32.543576Z","shell.execute_reply":"2021-08-30T23:44:36.130639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SCALE = 100\ndev_df[\"target\"] *= SCALE\n\nstock_ids = dev_df[\"stock_id\"].unique()\nlen(stock_ids)","metadata":{"papermill":{"duration":3.713187,"end_time":"2021-08-22T23:56:06.524273","exception":false,"start_time":"2021-08-22T23:56:02.811086","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:36.134626Z","iopub.execute_input":"2021-08-30T23:44:36.13489Z","iopub.status.idle":"2021-08-30T23:44:40.334348Z","shell.execute_reply.started":"2021-08-30T23:44:36.134863Z","shell.execute_reply":"2021-08-30T23:44:40.333566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_book_training = glob.glob(f'{PATH}/book_train.parquet/*/*')\norder_book_test = glob.glob(f'{PATH}/book_test.parquet/*/*')\n\nlen(order_book_training), len(order_book_test)","metadata":{"papermill":{"duration":0.221966,"end_time":"2021-08-22T23:56:06.778489","exception":false,"start_time":"2021-08-22T23:56:06.556523","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:40.33695Z","iopub.execute_input":"2021-08-30T23:44:40.337214Z","iopub.status.idle":"2021-08-30T23:44:40.55515Z","shell.execute_reply.started":"2021-08-30T23:44:40.337188Z","shell.execute_reply":"2021-08-30T23:44:40.554441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trades_training = glob.glob(f'{PATH}/trade_train.parquet/*/*')\ntrades_test = glob.glob(f'{PATH}/trade_test.parquet/*/*')\n\nlen(trades_training), len(trades_test)","metadata":{"papermill":{"duration":0.190759,"end_time":"2021-08-22T23:56:07.001766","exception":false,"start_time":"2021-08-22T23:56:06.811007","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:40.55646Z","iopub.execute_input":"2021-08-30T23:44:40.55683Z","iopub.status.idle":"2021-08-30T23:44:40.742347Z","shell.execute_reply.started":"2021-08-30T23:44:40.556795Z","shell.execute_reply":"2021-08-30T23:44:40.741368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using rapids-kaggle-utils for missing cuDF aggregation functions","metadata":{"papermill":{"duration":0.031223,"end_time":"2021-08-22T23:56:07.064981","exception":false,"start_time":"2021-08-22T23:56:07.033758","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%cd /kaggle/input/rapids-kaggle-utils/","metadata":{"papermill":{"duration":0.041035,"end_time":"2021-08-22T23:56:07.138138","exception":false,"start_time":"2021-08-22T23:56:07.097103","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:40.74385Z","iopub.execute_input":"2021-08-30T23:44:40.744201Z","iopub.status.idle":"2021-08-30T23:44:40.751619Z","shell.execute_reply.started":"2021-08-30T23:44:40.744164Z","shell.execute_reply":"2021-08-30T23:44:40.750613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cu_utils.transform as cutran\n\ndef log_diff(df, in_col, null_val):\n    df[\"logx\"] = df[in_col].log()\n    df[\"logx_shifted\"] = (df[[\"time_id\", \"logx\"]].groupby(\"time_id\", method='cudf')\n                             .apply_grouped(cutran.get_cu_shift_transform(shift_by=1, null_val=null_val),\n                                            incols={\"logx\": 'x'},\n                                            outcols=dict(y_out=cp.float32),\n                                            tpb=32)[\"y_out\"])\n    df[\"keep_row\"] = df[f\"logx_shifted\"] != null_val\n    return df[\"logx\"] - df[\"logx_shifted\"]\n\ndef extract_raw_book_features(df, null_val=-9999):\n    for n in range(1, 3):\n        p1 = df[f\"bid_price{n}\"]\n        p2 = df[f\"ask_price{n}\"]\n        s1 = df[f\"bid_size{n}\"]\n        s2 = df[f\"ask_size{n}\"]\n        df[f\"wap{n}\"] = (p1*s2 + p2*s1) / (s1 + s2)\n        df[f\"log_return{n}\"] = 100 * log_diff(df, in_col=f\"wap{n}\", null_val=null_val)\n        df[f\"realized_vol{n}\"] = 100 * df[f\"log_return{n}\"] ** 2\n    \n    n2 = 0.99\n    df['bid_size1_vibration'] = (df['bid_size1'] * (df['seconds_in_bucket'] / 300).exp())/10000000\n    df['full_wap'] = (df['wap1'] * (df['bid_size1'] + df['ask_size1']) + df['wap2'] * n2 * (df['bid_size2'] + df['ask_size2']))/ (df['bid_size1'] + df['ask_size1'] + n2 * df['bid_size2'] + n2 * df['ask_size2'])\n    df['log_full_return'] = 100 * log_diff(df, in_col = \"full_wap\", null_val=null_val)\n    df['realized_full_vol'] = 100 * df['log_full_return'] ** 2\n    df['resonance'] = df['realized_full_vol'] * df['seconds_in_bucket']\n    df['exp_resonance'] = 1000 * df['realized_full_vol'] * (df['seconds_in_bucket'] / 600).exp()\n    df[\"skewness\"] = 10 * df[f\"log_full_return\"] ** 3\n    df['realized_full_abs'] = abs(df['log_full_return'])\n    df['wap_balance'] = 10000 * abs(df['wap1'] - df['wap2'])\n    #df['wap_balance_return'] = 10 * log_diff(df, in_col=\"wap_balance\", null_val=null_val)\n    df['wap_balance_rel'] = 10000 * abs(df['wap1'] - df['wap2']) / (df['wap1'] + df['wap2'])\n    df['price_spread'] = 10000 * (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n    # Include price_spread TWO? No. It's already included there indirectly\n    df['bid_spread'] = 10000 * (df['bid_price1'] - df['bid_price2'])\n    df['bid_spread_rel'] = df['bid_spread'] / df['bid_price1']\n    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n    df['ask_spread_rel'] = 1000 * df['ask_spread'] / df['ask_price2']\n    df['total_volume'] = ((df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])) / 10000\n    df['volume_imbalance'] = 0.001 * abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2'])) / df['total_volume']\n    df['real_action_imbalance'] = 0.001 * (abs(df['ask_size1'] + df['bid_size1']) - abs(df['ask_size2'] + df['bid_size2'])) / df['total_volume']\n    df['quad_volume_vibration'] = df['total_volume'] * (df['seconds_in_bucket'] / 600) ** 2\n    df['exp_volume_vibration'] = df['total_volume'] * ((df['seconds_in_bucket'] - 300) / 300).exp()\n    df['volume_vibration'] = df['total_volume'] * df['seconds_in_bucket'] / 10000\n    df['volume_imbalance_vibration'] = df['volume_imbalance'] * (df['seconds_in_bucket'] / 600).exp()\n    df[\"c\"] = 1\n    df = df[df[\"keep_row\"]]\n    df['bid_size1'] /= 1000000\n    return df\n\ndef extract_raw_trade_features(df, null_val=-9999):\n    df['per_order'] = df['size'] / (df['order_count'] + 1)\n    df['per_order_vibration'] = df['per_order'] * (df['seconds_in_bucket'] / 1200).exp()\n    df['realized_price'] = log_diff(df, in_col=f\"price\", null_val=null_val)\n    df[\"realized_vol_trade\"] = df['realized_price']**2\n    df[\"realized_abs_trade\"] = abs(df['realized_price'])\n    df[\"exp_vibration\"] = (df['seconds_in_bucket'] / 600).exp() * df['size']\n    df[\"vibration\"] = df['seconds_in_bucket'] * df['size']\n    df['order_count_vibration'] = (df['seconds_in_bucket'] / 400).exp() * df['order_count']\n    df = df[df[\"keep_row\"]]\n    return df\n\n\ndef agg(df, feature_dict):\n    agg_df = df.groupby(\"time_id\").agg(feature_dict).reset_index()\n    def f(x):\n        if x[1] == \"\":\n            return x[0]\n        return x[0] + \"_\" + x[1]\n    \n    agg_df.columns = [f(x) for x in agg_df.columns]\n    return(agg_df)\n\ndef extract_book_stats(df):\n    default_stats = [\"mean\", \"std\", \"var\"]\n    feature_dict = {\n        'bid_size1': [\"mean\", \"std\"],\n        'bid_size1_vibration': [\"mean\"],\n        'bid_price1': [\"mean\", \"std\", \"var\"],\n        'log_return1': [\"mean\", \"std\"],\n        'log_return2': [\"mean\", \"std\"],\n        'realized_vol1': [\"mean\", \"std\", \"sum\", \"var\"],\n        'realized_vol2': [\"mean\", \"std\", \"sum\"],\n        'wap1': [\"mean\", \"std\"],\n        'wap2': [\"mean\", \"std\"],\n        'full_wap': [\"sum\", \"mean\", \"std\", \"max\", \"min\"],\n        'log_full_return': [\"mean\", \"std\"],\n        'realized_full_vol': [\"mean\", \"std\"],\n        'skewness': [\"mean\"],\n        'realized_full_abs': [\"mean\"],\n        'wap_balance': [\"mean\", \"std\"],\n        #'wap_balance_return': default_stats,\n        'wap_balance_rel': default_stats,\n        'price_spread': default_stats,\n        'bid_spread': default_stats,\n        'ask_spread': default_stats,\n        'bid_spread_rel': default_stats,\n        'ask_spread_rel': default_stats,\n        'total_volume': default_stats,\n        'volume_imbalance': default_stats,\n        'real_action_imbalance': default_stats,\n        'volume_vibration': [\"mean\", \"var\", \"std\"],\n        'volume_imbalance_vibration': default_stats,\n        'c': [\"sum\"],\n        # Include sum of kurtosis? - I should because vol of \n        # Include a measure of amplitude (look at the rmspe definition below for an example)\n    }\n    all_df = agg(df, feature_dict)\n    sum_df = extract_book_sum_stats(df)\n    all_df = all_df.merge(sum_df, on=\"time_id\", how=\"left\")\n    return(all_df)\n\ndef extract_book_sum_stats(df):\n    # This one extracts the sums that cause trouble, because of missing values (I fill with zeros)\n    feature_dict = {\n        'bid_size1': [\"sum\"],\n        'bid_size1_vibration': [\"sum\"],\n        'bid_price1': [\"sum\"],\n        'log_return1': [\"sum\"],\n        'log_return2': [\"sum\"],\n        'log_full_return': [\"sum\"],\n        'realized_full_vol': [\"sum\"],\n        'wap1': [\"sum\"],\n        'wap2': [\"sum\"],\n        'skewness': [\"sum\"],\n        'realized_full_abs': [\"sum\"],\n        'wap_balance': [\"sum\"],\n        'wap_balance_rel': [\"sum\"],\n        'price_spread': [\"sum\"],\n        'bid_spread': [\"sum\"],\n        'ask_spread': [\"sum\"],\n        'bid_spread_rel': [\"sum\"],\n        'ask_spread_rel': [\"sum\"],\n        'total_volume': [\"sum\"],\n        'volume_imbalance': [\"sum\"],\n        'real_action_imbalance': [\"sum\"],\n        'volume_vibration': [\"sum\"],\n        'volume_imbalance_vibration': [\"sum\"],\n        'exp_volume_vibration': [\"sum\"],\n        'quad_volume_vibration': [\"sum\"],\n        'exp_resonance': [\"sum\"],\n        'resonance': [\"sum\"]\n        # Include sum of kurtosis? - I should because vol of \n        # Include a measure of amplitude (look at the rmspe definition below for an example)\n    }\n    dfzero = df[[\"time_id\"] + list(feature_dict.keys())]\n    dfzero.fillna(0.0)\n    return agg(dfzero, feature_dict)\n    \ndef extract_trade_stats(df):\n    feature_dict = {\n        'realized_vol_trade': [\"sum\", \"std\"],\n        'realized_abs_trade': [\"sum\", \"var\"],\n        'seconds_in_bucket':[\"count\", \"sum\"], #Include count unique? Review!\n        'size': [\"mean\", \"sum\"],\n        'order_count': [\"mean\"],\n        'vibration': [\"mean\"],\n        'order_count_vibration': [\"mean\"],\n        'exp_vibration': [\"mean\"],\n        'price': [\"mean\", \"std\"],\n        'per_order':[\"mean\", \"std\"],\n        'per_order_vibration': [\"mean\"]\n    }\n    return agg(df, feature_dict)\n\ndef time_constraint_fe(df, stats_df, last_sec, fe_function, cols):\n    sub_df = df[df[\"seconds_in_bucket\"] >= (600 - last_sec)].reset_index(drop=True)\n    if sub_df.shape[0] > 0:\n        sub_stats = fe_function(sub_df)\n    else:\n        sub_stats = cudf.DataFrame(columns=cols)\n    return stats_df.merge(sub_stats, on=\"time_id\", how=\"left\", suffixes=('', f'_{last_sec}'))\n\ndef feature_engineering(book_path, trade_path):\n    book_df = cudf.read_parquet(book_path)\n    book_df = extract_raw_book_features(book_df)\n    book_stats = extract_book_stats(book_df)\n    book_cols = book_stats.columns\n    \n    trade_df = cudf.read_parquet(trade_path)\n    trade_df = extract_raw_trade_features(trade_df)\n    trade_stats = extract_trade_stats(trade_df)\n    trade_cols = trade_stats.columns\n    \n    for last_sec in [150, 300, 450]:\n        book_stats = time_constraint_fe(book_df, book_stats, last_sec, extract_book_stats, book_cols) \n        trade_stats = time_constraint_fe(trade_df, trade_stats, last_sec, extract_trade_stats, trade_cols)\n    return book_stats.merge(trade_stats, on=\"time_id\", how=\"left\")\n\ndef last_touches(a):\n    # Create the oscillations\n    plus_signs = [n for n in a.columns if 'max' in n]\n    minus_signs = [n.replace('max', 'min') for n in plus_signs]\n    new_sign = [n.replace('max', 'oscillation') for n in plus_signs]\n    for i, j, new_name in zip(plus_signs, minus_signs, new_sign):\n        a[new_name] = (a[i] - a[j]) / a[j]\n        a.drop([i, j], axis = 1, inplace = True)\n    \ndef process_data(order_book_paths, trade_paths, stock_ids):\n    stock_dfs = []\n    for book_path, trade_path in tqdm(list(zip(order_book_paths, trade_paths))):\n        stock_id = int(book_path.split(\"=\")[1].split(\"/\")[0])\n\n        df = feature_engineering(book_path, trade_path)\n        df[\"stock_id\"] = stock_id\n        stock_dfs.append(df)\n    smat = cudf.concat(stock_dfs)\n    #smat = last_touches(smat)\n    return(smat)","metadata":{"papermill":{"duration":0.097233,"end_time":"2021-08-22T23:56:07.267294","exception":false,"start_time":"2021-08-22T23:56:07.170061","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:40.754365Z","iopub.execute_input":"2021-08-30T23:44:40.754756Z","iopub.status.idle":"2021-08-30T23:44:40.826321Z","shell.execute_reply.started":"2021-08-30T23:44:40.754705Z","shell.execute_reply":"2021-08-30T23:44:40.825235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"past_test_volatility = process_data(order_book_test, trades_test, stock_ids)\nif REMAKE_TRAINING:\n    past_volatility = process_data(order_book_training, trades_training, stock_ids)\n    past_volatility.shape, past_test_volatility.shape\n    pickle.dump(past_volatility.to_pandas(), open(\"/kaggle/working/pastVolatility.pickle\", \"wb\"))\nelse:\n    past_volatility = cudf.from_pandas(pickle.load(open(\"/kaggle/input/optiver-trainingmatrix/pastVolatility.pickle\", \"rb\")))","metadata":{"papermill":{"duration":578.428989,"end_time":"2021-08-23T00:05:45.729292","exception":false,"start_time":"2021-08-22T23:56:07.300303","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:44:40.830286Z","iopub.execute_input":"2021-08-30T23:44:40.830644Z","iopub.status.idle":"2021-08-30T23:45:12.551426Z","shell.execute_reply.started":"2021-08-30T23:44:40.830599Z","shell.execute_reply":"2021-08-30T23:45:12.550557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stock_time_fe(df):\n    cols = ['realized_vol1_sum', 'realized_vol2_sum', 'realized_vol_trade_sum',\n            'realized_vol1_sum_150', 'realized_vol2_sum_150', 'realized_vol_trade_sum_150',\n            'realized_vol1_sum_300', 'realized_vol2_sum_300', 'realized_vol_trade_sum_300',\n            'realized_vol1_sum_450', 'realized_vol2_sum_450', 'realized_vol_trade_sum_450',\n            'order_count_mean', 'real_action_imbalance_mean', \n            'volume_imbalance_mean', 'skewness_mean', 'volume_imbalance_mean_150',\n            'full_wap_mean', 'real_action_imbalance_mean_300',\n            'real_action_imbalance_mean_450', 'volume_imbalance_mean_450',\n            'full_wap_mean_300', 'volume_vibration_mean', 'vibration_mean',\n            'volume_imbalance_vibration_sum',\n            'volume_imbalance_vibration_sum_450', 'order_count_vibration_mean', 'exp_resonance_sum_450',\n            'exp_resonance_sum', 'resonance_sum', 'exp_vibration_mean', 'quad_volume_vibration_sum',\n            'per_order_vibration_mean', 'bid_size1_std'\n           ] \n    #Include others here?\n    for agg_col in [\"stock_id\", \"time_id\"]:\n        for agg_func in [\"mean\", \"max\", \"std\", \"min\"]:\n            agg_df = df.groupby(agg_col)[cols].agg(agg_func)\n            agg_df.columns = [f\"{agg_col}_{agg_func}_{col}\" for col in agg_df.columns]\n            df = df.merge(agg_df.reset_index(), on=agg_col, how=\"left\")\n    \n    return df\nprint(past_volatility.shape)\npast_volatility[\"is_test\"] = False\npast_test_volatility[\"is_test\"] = True\nall_df = past_volatility.append(past_test_volatility).reset_index(drop=True)\nall_df = stock_time_fe(all_df)\nall_df.dropna(axis=1, how='all', inplace = True) # Drop columns with all positions NAN\n\n#Convert stock_id to categorical using one-hot encoding (Choose only a few that work since they're not that useful.\n# Candidates are on version 123)\n# codes = all_df['stock_id'].unique()\n# all_df = all_df.one_hot_encoding('stock_id', 'dummy_id', codes)\n# di = [f for f in all_df.columns if 'dummy_id' in f]\n# all_df[di] = all_df[di].astype('int8') # Reduce memory size\npickle.dump(all_df.columns, open(\"/kaggle/working/stayingcolumns.pickle\", \"wb\"))\npast_volatility = all_df[~all_df[\"is_test\"]]\npast_test_volatility = all_df[all_df[\"is_test\"]]\ndel all_df\ngc.collect()\npast_volatility.shape","metadata":{"papermill":{"duration":5.548582,"end_time":"2021-08-23T00:05:51.365447","exception":false,"start_time":"2021-08-23T00:05:45.816865","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:45:12.552901Z","iopub.execute_input":"2021-08-30T23:45:12.55323Z","iopub.status.idle":"2021-08-30T23:45:16.839786Z","shell.execute_reply.started":"2021-08-30T23:45:12.553196Z","shell.execute_reply":"2021-08-30T23:45:16.838807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Just drop the features that have NANs from any analysis","metadata":{"papermill":{"duration":0.107186,"end_time":"2021-08-23T00:05:51.663","exception":false,"start_time":"2021-08-23T00:05:51.555814","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fs = set(pickle.load(open(\"/kaggle/input/optiver-trainingmatrix/featureschampion.pickle\", \"rb\"))[1])\npickle.dump(fs, open(\"/kaggle/working/fslist.pickle\", \"wb\"))\nfspv = set([col for col in list(past_volatility.columns) if col not in {\"time_id\", \"stock_id\", \"target\", \"is_test\"}])\npickle.dump(fspv, open(\"/kaggle/working/fspvlist.pickle\", \"wb\"))\nprint('tools that I erased', fs - fspv)\nprint('tools that I created that are new', len(fspv - fs))\nprint(len(fs), len(fspv))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:40:52.368997Z","iopub.execute_input":"2021-08-30T23:40:52.369315Z","iopub.status.idle":"2021-08-30T23:40:53.051244Z","shell.execute_reply.started":"2021-08-30T23:40:52.369286Z","shell.execute_reply":"2021-08-30T23:40:53.050127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features_PCA will be deleted\nfeatures_PCA = list(fspv - fs)\nlen(features_PCA)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:39:52.478883Z","iopub.execute_input":"2021-08-30T23:39:52.479335Z","iopub.status.idle":"2021-08-30T23:39:52.485163Z","shell.execute_reply.started":"2021-08-30T23:39:52.479292Z","shell.execute_reply":"2021-08-30T23:39:52.484222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('are there columns with some missing values?', past_volatility.isna().any().any())\nprint('are there columns with all missing values?', past_volatility.isna().all().any())","metadata":{"papermill":{"duration":0.759189,"end_time":"2021-08-23T00:05:52.5277","exception":false,"start_time":"2021-08-23T00:05:51.768511","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-30T23:41:20.88111Z","iopub.execute_input":"2021-08-30T23:41:20.881459Z","iopub.status.idle":"2021-08-30T23:41:21.475718Z","shell.execute_reply.started":"2021-08-30T23:41:20.881403Z","shell.execute_reply":"2021-08-30T23:41:21.470214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_PCA","metadata":{"execution":{"iopub.status.busy":"2021-08-30T23:41:56.817279Z","iopub.execute_input":"2021-08-30T23:41:56.817639Z","iopub.status.idle":"2021-08-30T23:41:56.832173Z","shell.execute_reply.started":"2021-08-30T23:41:56.817606Z","shell.execute_reply":"2021-08-30T23:41:56.831221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mydicts = Counter()\n# for i in range(5):\n#     thismodel = pickle.load(open(\"/kaggle/input/optiver-trainingmatrix/modelv1-fold-\" + str(i) + \".pickle\", \"rb\"))\n#     mydicts += Counter(thismodel[3])\n# # The features below are the features with less information. These will build the PCA\n# features_PCA = list(set([item[0] for item in mydicts.most_common()[-350:]]).intersection(set(past_volatility.columns)))\n# print(len(features_PCA))\n# features_PCA[:5]","metadata":{"papermill":{"duration":39.899949,"end_time":"2021-08-23T00:06:32.591082","exception":false,"start_time":"2021-08-23T00:05:52.691133","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:40.863561Z","iopub.execute_input":"2021-08-29T19:08:40.863856Z","iopub.status.idle":"2021-08-29T19:08:40.869337Z","shell.execute_reply.started":"2021-08-29T19:08:40.863825Z","shell.execute_reply":"2021-08-29T19:08:40.867826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change data type\n# di = [[f, 'float32'] for f in past_volatility.columns if past_volatility[f].dtype == 'float64']\n# past_volatility = past_volatility.astype(dict(di))\n# print([f for f in past_volatility.columns if past_volatility[f].dtype == 'float64'])\n\n# di = [[f, 'float32'] for f in past_test_volatility.columns if past_test_volatility[f].dtype == 'float64']\n# past_test_volatility = past_test_volatility.astype(dict(di))\n# print([f for f in past_test_volatility.columns if past_test_volatility[f].dtype == 'float64'])\n\n# di = [f for f in past_test_volatility.columns if past_test_volatility[f].dtype == 'float64']\n# for f in di:\n#     print('statistics for', f)\n#     print(past_volatility[f].min(), past_volatility[f].mean(), past_volatility[f].max())\n# print('list the features with memory float64')","metadata":{"papermill":{"duration":0.069764,"end_time":"2021-08-23T00:06:32.726228","exception":false,"start_time":"2021-08-23T00:06:32.656464","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:40.87139Z","iopub.execute_input":"2021-08-29T19:08:40.871848Z","iopub.status.idle":"2021-08-29T19:08:40.881398Z","shell.execute_reply.started":"2021-08-29T19:08:40.871807Z","shell.execute_reply":"2021-08-29T19:08:40.879763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keep a record of the features for the PCA analysis for later, in case I want to review in a cheap CPU\n# pickle.dump(past_volatility[features_PCA].to_pandas(), open(\"/kaggle/working/pastVolatility4PCA.pickle\", \"wb\"))","metadata":{"papermill":{"duration":2.798586,"end_time":"2021-08-23T00:06:35.587967","exception":false,"start_time":"2021-08-23T00:06:32.789381","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:40.883484Z","iopub.execute_input":"2021-08-29T19:08:40.884012Z","iopub.status.idle":"2021-08-29T19:08:40.894383Z","shell.execute_reply.started":"2021-08-29T19:08:40.883967Z","shell.execute_reply":"2021-08-29T19:08:40.893307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's move to the pandas world to run PCA\npv_pandas = past_volatility.to_pandas()\nptv_pandas = past_test_volatility.to_pandas()","metadata":{"papermill":{"duration":6.086427,"end_time":"2021-08-23T00:06:41.738849","exception":false,"start_time":"2021-08-23T00:06:35.652422","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:40.896056Z","iopub.execute_input":"2021-08-29T19:08:40.89663Z","iopub.status.idle":"2021-08-29T19:08:47.079779Z","shell.execute_reply.started":"2021-08-29T19:08:40.896547Z","shell.execute_reply":"2021-08-29T19:08:47.078726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_means_dict = dict(pv_pandas[features_PCA].median())\npickle.dump(column_means_dict, open(\"/kaggle/working/column_means_dict.pickle\", \"wb\"))\n#print(len(column_means_dict), column_means_dict)","metadata":{"papermill":{"duration":1.90687,"end_time":"2021-08-23T00:06:43.71488","exception":false,"start_time":"2021-08-23T00:06:41.80801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:47.085159Z","iopub.execute_input":"2021-08-29T19:08:47.087614Z","iopub.status.idle":"2021-08-29T19:08:49.475717Z","shell.execute_reply.started":"2021-08-29T19:08:47.087567Z","shell.execute_reply":"2021-08-29T19:08:49.47456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fill NAs","metadata":{"papermill":{"duration":0.154073,"end_time":"2021-08-23T00:06:43.94711","exception":false,"start_time":"2021-08-23T00:06:43.793037","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print('are there columns with some missing values?', pv_pandas[features_PCA].isna().any().any())\nprint('are there columns with all missing values?', pv_pandas[features_PCA].isna().all().any())","metadata":{"papermill":{"duration":1.057654,"end_time":"2021-08-23T00:06:45.28279","exception":false,"start_time":"2021-08-23T00:06:44.225136","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:49.477429Z","iopub.execute_input":"2021-08-29T19:08:49.477812Z","iopub.status.idle":"2021-08-29T19:08:50.451775Z","shell.execute_reply.started":"2021-08-29T19:08:49.47777Z","shell.execute_reply":"2021-08-29T19:08:50.450615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pv_pandas[features_PCA] = pv_pandas[features_PCA].fillna(column_means_dict)\nptv_pandas[features_PCA] = ptv_pandas[features_PCA].fillna(column_means_dict)","metadata":{"papermill":{"duration":1.177684,"end_time":"2021-08-23T00:06:46.525909","exception":false,"start_time":"2021-08-23T00:06:45.348225","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:50.453623Z","iopub.execute_input":"2021-08-29T19:08:50.454014Z","iopub.status.idle":"2021-08-29T19:08:51.981477Z","shell.execute_reply.started":"2021-08-29T19:08:50.453973Z","shell.execute_reply":"2021-08-29T19:08:51.980402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('are there columns with some missing values?', pv_pandas[features_PCA].isna().any().any())\nprint('are there columns with all missing values?', pv_pandas[features_PCA].isna().all().any())","metadata":{"papermill":{"duration":0.905864,"end_time":"2021-08-23T00:06:47.498092","exception":false,"start_time":"2021-08-23T00:06:46.592228","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:51.982921Z","iopub.execute_input":"2021-08-29T19:08:51.98338Z","iopub.status.idle":"2021-08-29T19:08:52.94157Z","shell.execute_reply.started":"2021-08-29T19:08:51.983338Z","shell.execute_reply":"2021-08-29T19:08:52.939486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create the PCA columns","metadata":{"papermill":{"duration":0.11956,"end_time":"2021-08-23T00:06:47.748123","exception":false,"start_time":"2021-08-23T00:06:47.628563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"NCOMP = 2\npca = PCA(n_components = NCOMP)\npca.fit(pv_pandas[features_PCA])\nprint(pca.explained_variance_ratio_)\ncolumns_pca = ['pc_' + str(i) for i in range(NCOMP)]\npc = pd.DataFrame(pca.transform(pv_pandas[features_PCA]), columns = columns_pca)\nptc = pd.DataFrame(pca.transform(ptv_pandas[features_PCA]), columns = columns_pca)\n\nNFPCA = 125\nfpca = FastICA(n_components = NFPCA)\nfpca.fit(pv_pandas[features_PCA])\ncolumns_fastica = ['fpca_' + str(i) for i in range(NFPCA)]\nfpc = pd.DataFrame(fpca.transform(pv_pandas[features_PCA]), columns = columns_fastica)\nfptc = pd.DataFrame(fpca.transform(ptv_pandas[features_PCA]), columns = columns_fastica)\n\npickle.dump(pca, open(\"/kaggle/working/pca.pickle\", \"wb\"))\npickle.dump(fpca, open(\"/kaggle/working/fpca.pickle\", \"wb\"))","metadata":{"papermill":{"duration":62.123221,"end_time":"2021-08-23T00:07:49.989621","exception":false,"start_time":"2021-08-23T00:06:47.8664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:08:52.943311Z","iopub.execute_input":"2021-08-29T19:08:52.943781Z","iopub.status.idle":"2021-08-29T19:16:17.634261Z","shell.execute_reply.started":"2021-08-29T19:08:52.943735Z","shell.execute_reply":"2021-08-29T19:16:17.632878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fptc.head()","metadata":{"papermill":{"duration":0.080878,"end_time":"2021-08-23T00:07:50.188523","exception":false,"start_time":"2021-08-23T00:07:50.107645","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:17.640692Z","iopub.execute_input":"2021-08-29T19:16:17.641568Z","iopub.status.idle":"2021-08-29T19:16:17.681515Z","shell.execute_reply.started":"2021-08-29T19:16:17.641525Z","shell.execute_reply":"2021-08-29T19:16:17.680402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cocatenate the results","metadata":{"papermill":{"duration":0.067808,"end_time":"2021-08-23T00:07:50.32417","exception":false,"start_time":"2021-08-23T00:07:50.256362","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from __future__ import print_function  # for Python2\n# import sys\n\n# local_vars = list(locals().items())\n# for var, obj in local_vars:\n#     print(var, sys.getsizeof(obj))","metadata":{"papermill":{"duration":0.073797,"end_time":"2021-08-23T00:07:50.465136","exception":false,"start_time":"2021-08-23T00:07:50.391339","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:17.683913Z","iopub.execute_input":"2021-08-29T19:16:17.684548Z","iopub.status.idle":"2021-08-29T19:16:17.689569Z","shell.execute_reply.started":"2021-08-29T19:16:17.684488Z","shell.execute_reply":"2021-08-29T19:16:17.688191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove the columns from pandas. Make sure that they get replaced by the PCA and fastICA columns","metadata":{"papermill":{"duration":0.066232,"end_time":"2021-08-23T00:07:50.598803","exception":false,"start_time":"2021-08-23T00:07:50.532571","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pv_pandas.drop(features_PCA, axis = 1, inplace = True)\nptv_pandas.drop(features_PCA, axis = 1, inplace = True)\ndel column_means_dict\ndel past_volatility\ndel past_test_volatility\ngc.collect()","metadata":{"papermill":{"duration":1.101924,"end_time":"2021-08-23T00:07:51.767513","exception":false,"start_time":"2021-08-23T00:07:50.665589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:17.69158Z","iopub.execute_input":"2021-08-29T19:16:17.692258Z","iopub.status.idle":"2021-08-29T19:16:18.537335Z","shell.execute_reply.started":"2021-08-29T19:16:17.692018Z","shell.execute_reply":"2021-08-29T19:16:18.536166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pv_pandas = pd.concat([pv_pandas.reset_index(), pc.reset_index(), fpc.reset_index()], axis = 1).drop('index', axis = 1)\nptv_pandas = pd.concat([ptv_pandas.reset_index(), ptc.reset_index(), fptc.reset_index()], axis = 1).drop('index', axis = 1)","metadata":{"papermill":{"duration":2.336886,"end_time":"2021-08-23T00:07:54.169197","exception":false,"start_time":"2021-08-23T00:07:51.832311","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:18.538864Z","iopub.execute_input":"2021-08-29T19:16:18.539348Z","iopub.status.idle":"2021-08-29T19:16:22.117582Z","shell.execute_reply.started":"2021-08-29T19:16:18.539312Z","shell.execute_reply":"2021-08-29T19:16:22.116482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pv_pandas.head()","metadata":{"papermill":{"duration":0.095797,"end_time":"2021-08-23T00:07:54.333958","exception":false,"start_time":"2021-08-23T00:07:54.238161","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:22.119218Z","iopub.execute_input":"2021-08-29T19:16:22.119671Z","iopub.status.idle":"2021-08-29T19:16:22.151098Z","shell.execute_reply.started":"2021-08-29T19:16:22.119628Z","shell.execute_reply":"2021-08-29T19:16:22.149574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ptv_pandas.head()","metadata":{"papermill":{"duration":0.087058,"end_time":"2021-08-23T00:07:54.493264","exception":false,"start_time":"2021-08-23T00:07:54.406206","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:22.152966Z","iopub.execute_input":"2021-08-29T19:16:22.153663Z","iopub.status.idle":"2021-08-29T19:16:22.182959Z","shell.execute_reply.started":"2021-08-29T19:16:22.153617Z","shell.execute_reply":"2021-08-29T19:16:22.181611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# di = [[f, 'float32'] for f in pv_pandas.columns if pv_pandas[f].dtype == 'float64']\n# pv_pandas = pv_pandas.astype(dict(di))\n# print([f for f in pv_pandas.columns if pv_pandas[f].dtype == 'float64'])\n\n# di = [[f, 'float32'] for f in ptv_pandas.columns if ptv_pandas[f].dtype == 'float64']\n# ptv_pandas = ptv_pandas.astype(dict(di))\n# print([f for f in ptv_pandas.columns if ptv_pandas[f].dtype == 'float64'])","metadata":{"execution":{"iopub.status.busy":"2021-08-29T19:16:22.184738Z","iopub.execute_input":"2021-08-29T19:16:22.185229Z","iopub.status.idle":"2021-08-29T19:16:22.189765Z","shell.execute_reply.started":"2021-08-29T19:16:22.185184Z","shell.execute_reply":"2021-08-29T19:16:22.18856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"past_volatility = cudf.DataFrame(pv_pandas)\npast_test_volatility = cudf.DataFrame(ptv_pandas)","metadata":{"papermill":{"duration":1.691517,"end_time":"2021-08-23T00:07:56.250848","exception":false,"start_time":"2021-08-23T00:07:54.559331","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:22.191642Z","iopub.execute_input":"2021-08-29T19:16:22.192459Z","iopub.status.idle":"2021-08-29T19:16:24.358668Z","shell.execute_reply.started":"2021-08-29T19:16:22.192388Z","shell.execute_reply":"2021-08-29T19:16:24.357507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del pv_pandas\ndel ptv_pandas\ndel pc\ndel ptc\ndel fpc\ndel fptc\ngc.collect()","metadata":{"papermill":{"duration":0.474414,"end_time":"2021-08-23T00:07:56.794928","exception":false,"start_time":"2021-08-23T00:07:56.320514","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:24.360226Z","iopub.execute_input":"2021-08-29T19:16:24.360679Z","iopub.status.idle":"2021-08-29T19:16:24.565686Z","shell.execute_reply.started":"2021-08-29T19:16:24.360637Z","shell.execute_reply":"2021-08-29T19:16:24.564503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_df = dev_df.merge(past_volatility, on=[\"stock_id\", \"time_id\"], how=\"left\")\nfeatures = [col for col in list(dev_df.columns)\n            if col not in {\"stock_id\", \"target\", \"is_test\"}]\nlen(features)","metadata":{"papermill":{"duration":0.196205,"end_time":"2021-08-23T00:07:57.059811","exception":false,"start_time":"2021-08-23T00:07:56.863606","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:24.567264Z","iopub.execute_input":"2021-08-29T19:16:24.567943Z","iopub.status.idle":"2021-08-29T19:16:24.763278Z","shell.execute_reply.started":"2021-08-29T19:16:24.567894Z","shell.execute_reply":"2021-08-29T19:16:24.76224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train XGBoost model on GPU","metadata":{"papermill":{"duration":0.069189,"end_time":"2021-08-23T00:07:57.196751","exception":false,"start_time":"2021-08-23T00:07:57.127562","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Optuna regression setup","metadata":{"papermill":{"duration":0.068373,"end_time":"2021-08-23T00:07:57.332861","exception":false,"start_time":"2021-08-23T00:07:57.264488","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pd_df_full = dev_df.to_pandas()\n#limit the fine-tuning to only a seventh of the data\n#num1 = random.randint(0, 4)\n#pd_df = pd_df_full[pd_df_full[\"time_id\"].values % 5 == num1]\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n","metadata":{"papermill":{"duration":2.047154,"end_time":"2021-08-23T00:07:59.448527","exception":false,"start_time":"2021-08-23T00:07:57.401373","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:24.764808Z","iopub.execute_input":"2021-08-29T19:16:24.765238Z","iopub.status.idle":"2021-08-29T19:16:28.414669Z","shell.execute_reply.started":"2021-08-29T19:16:24.765205Z","shell.execute_reply":"2021-08-29T19:16:28.413193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Long Model\n# def objective(trial):\n#     num1 = 3 #random.randint(0, 4)\n#     #limit the fine-tuning to only a seventh of the data\n#     train_x, test_x, train_y, test_y = train_test_split(pd_df_full[features], pd_df_full['target'], test_size=0.22, random_state=42)\n#     # To select which parameters to optimize, please look at the XGBoost documentation:\n#     # https://xgboost.readthedocs.io/en/latest/parameter.html\n#     param = {\n#         'booster': trial.suggest_categorical('booster', ['gbtree']),\n#         'tree_method':'gpu_hist',  # Use GPU acceleration\n#         'lambda': trial.suggest_loguniform(\n#             'lambda', 0.0001, 0.15\n#         ),\n#         'alpha': trial.suggest_loguniform(\n#             'alpha', 5e-1, 10.0\n#         ),\n#         'colsample_bytree': trial.suggest_float(\n#             'colsample_bytree', 0.6, 0.85 #Default is 1.0\n#         ),\n#         'colsample_bylevel': trial.suggest_float(\n#             'colsample_bylevel', 0.6, 0.8 #Default is 1.0\n#         ),\n#         'colsample_bynode': trial.suggest_float(\n#             'colsample_bynode', 0.65, 0.99 #Default is 1.0\n#         ),\n#         'subsample': trial.suggest_float(\"subsample\", 0.6,  0.95),\n#         'learning_rate': trial.suggest_float(\n#             'learning_rate', 0.002, 0.07\n#         ),\n#         'n_estimators': trial.suggest_categorical(\t\n#             \"n_estimators\", [3000, 3500]\n#         ),\n#         'max_depth': trial.suggest_int(\n#             'max_depth', 22, 27\n#         ),\n#         'random_state': 42,\n#         'min_child_weight': trial.suggest_int(\n#             'min_child_weight', 55, 160\n#         ),\n#     }\n#     model = XGBRegressor(**param)\n    \n#     model.fit(train_x,train_y,eval_set=[(test_x,test_y)], early_stopping_rounds = 50, verbose=False)\n    \n#     preds = model.predict(test_x)\n#     #rmse = mean_squared_error(test_y, preds, squared=False)\n#     rmspeval = rmspe(test_y, preds)\n#     return rmspeval\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials = 90)\n\n# print(\"Number of finished trials: \", len(study.trials))\n# print(\"Best trial:\")\n# trial = study.best_trial\n\n# print(\"  Value: {}\".format(trial.value))\n# print(\"  Params: \")\n# for key, value in trial.params.items():\n#     print(\"    {}: {}\".format(key, value))\n\n# fig = optuna.visualization.plot_param_importances(study)\n# fig.show()\n\n# # Assign best model\n# best_params = study.best_params\n# best_params['tree_method'] = 'gpu_hist'\n# best_params['random_state'] = 42\n\n# best_params = {\n#          \"booster\": 'gbtree',\n#          \"objective\": 'reg:squarederror',\n#          \"lambda\": 0.003692070094677976,\n#          \"alpha\": 0.843665639617332,\n#          \"colsample_bytree\": 0.6890567485273894,\n#          \"colsample_bylevel\": 0.7522102593718745,\n#          \"colsample_bynode\": 0.6643596703827361,\n#          \"subsample\": 0.8033471108457755,\n#          \"learning_rate\": 0.027930261435649854,\n#          \"max_depth\": 26,\n#          \"min_child_weight\": 127,\n#          #\"reg_alpha\": 10.0,\n#          \"tree_method\": 'gpu_hist', \"gpu_id\": 0,\n#          'disable_default_eval_metric': 1\n#     }","metadata":{"execution":{"iopub.status.busy":"2021-08-29T19:16:28.41996Z","iopub.execute_input":"2021-08-29T19:16:28.420433Z","iopub.status.idle":"2021-08-29T19:16:28.432367Z","shell.execute_reply.started":"2021-08-29T19:16:28.42039Z","shell.execute_reply":"2021-08-29T19:16:28.431212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Short Model\n# def objective(trial):\n#     num1 = 3 #random.randint(0, 4)\n#     #limit the fine-tuning to only a seventh of the data\n#     pd_df = pd_df_full\n#     train_x, test_x, train_y, test_y = train_test_split(pd_df[features], pd_df['target'], test_size=0.22, random_state=42)\n#     # To select which parameters to optimize, please look at the XGBoost documentation:\n#     # https://xgboost.readthedocs.io/en/latest/parameter.html\n#     param = {\n#         'booster': trial.suggest_categorical('booster', ['gbtree']),\n#         'tree_method':'gpu_hist',  # Use GPU acceleration\n#         'lambda': trial.suggest_loguniform(\n#             'lambda', 0.0001, 0.5\n#         ),\n#         'alpha': trial.suggest_loguniform(\n#             'alpha', 5e-1, 20.0\n#         ),\n#         'reg_alpha': trial.suggest_float(\n#             'reg_alpha', 5e-1, 20.0\n#         ),\n#         'colsample_bytree': trial.suggest_float(\n#             'colsample_bytree', 0.7, 0.9 #Default is 1.0\n#         ),\n#         'colsample_bylevel': trial.suggest_float(\n#             'colsample_bylevel', 0.75, 0.99 #Default is 1.0\n#         ),\n#         'colsample_bynode': trial.suggest_float(\n#             'colsample_bynode', 0.9, 1.0 #Default is 1.0\n#         ),\n#         'subsample': trial.suggest_float(\"subsample\", 0.6,  0.95),\n#         'learning_rate': trial.suggest_float(\n#             'learning_rate', 0.002, 0.06\n#         ),\n#         'n_estimators': trial.suggest_categorical(\t\n#             \"n_estimators\", [3500, 5000]\n#         ),\n#         'max_depth': trial.suggest_int(\n#             'max_depth', 6, 10\n#         ),\n#         'random_state': 42,\n#         'min_child_weight': trial.suggest_int(\n#             'min_child_weight', 80, 200\n#         ),\n#     }\n#     model = XGBRegressor(**param)\n    \n#     model.fit(train_x,train_y,eval_set=[(test_x,test_y)], early_stopping_rounds = 50, verbose=False)\n    \n#     preds = model.predict(test_x)\n#     #rmse = mean_squared_error(test_y, preds, squared=False)\n#     rmspeval = rmspe(test_y, preds)\n#     return rmspeval\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials = 50)\n\n# print(\"Number of finished trials: \", len(study.trials))\n# print(\"Best trial:\")\n# trial = study.best_trial\n\n# print(\"  Value: {}\".format(trial.value))\n# print(\"  Params: \")\n# for key, value in trial.params.items():\n#     print(\"    {}: {}\".format(key, value))\n\n# fig = optuna.visualization.plot_param_importances(study)\n# fig.show()\n\n# # Assign best model\n# best_params = study.best_params\n# best_params['tree_method'] = 'gpu_hist'\n# best_params['random_state'] = 43\n\n# best_params = {\n#          \"booster\": 'gbtree',\n#          \"objective\": 'reg:squarederror',\n#          \"lambda\": 0.3900133957228146,\n#          \"alpha\": 1.6143973425818008,\n#          \"colsample_bytree\": 0.8240236558740445,\n#          \"colsample_bylevel\": 0.7055628112659318,\n#          \"colsample_bynode\": 0.9858168527166616,\n#          \"subsample\": 0.8164845919960058,\n#          \"learning_rate\": 0.023404748889126782,\n#          \"max_depth\": 16,\n#          \"min_child_weight\": 187,    \n#          \"reg_alpha\": 5.0,\n#          \"tree_method\": 'gpu_hist', \"gpu_id\": 0,\n#          'disable_default_eval_metric': 1\n#     }\n\n# best_params = {\n#          \"booster\": 'gbtree',\n#          \"objective\": 'reg:squarederror',\n#          \"max_depth\": 7,\n#          \"min_child_weight\": 156,    \n#          \"lambda\": 0.006654377522518237,\n#          \"alpha\": 3.398238828590107,\n#          \"colsample_bytree\": 0.6,\n#          \"subsample\": 0.9134709113526331,\n#          \"learning_rate\": 0.010751601995412153,\n#          \"reg_alpha\": 10.0,\n#          \"tree_method\": 'gpu_hist', \"gpu_id\": 0,\n#          'disable_default_eval_metric': 1\n#     }\n# # This is 22092\nbest_params = {\n         \"booster\": 'gbtree',\n         \"objective\": 'reg:squarederror',\n         \"lambda\": 0.000120494603280191,\n         \"alpha\": 4.655248899194473,\n         \"reg_alpha\": 5.75750136407511,\n         \"colsample_bytree\": 0.7033853760069456,\n         \"colsample_bylevel\": 0.9241863146227871,\n         \"colsample_bynode\": 0.9902499881033184,\n         \"subsample\": 0.926724493495993,\n         \"learning_rate\": 0.059258258818345,\n         \"max_depth\": 10,\n         \"min_child_weight\": 97,    \n         \"tree_method\": 'gpu_hist', \"gpu_id\": 0,\n         'disable_default_eval_metric': 1\n    }\n\nbest_params = {\n         \"booster\": 'dart',\n         \"rate_drop\": 0.10,\n         \"skip_drop\": 0.5,\n         \"objective\": 'reg:squarederror',\n         \"max_depth\": 9,\n         \"min_child_weight\": 147,    \n         \"lambda\": 0.006654377522518237,\n         \"alpha\": 3.398238828590107,\n         \"colsample_bytree\": 0.7033853760069456,\n         \"colsample_bylevel\": 0.9241863146227871,\n         \"colsample_bynode\": 0.9902499881033184,\n         \"subsample\": 0.9134709113526331,\n         \"learning_rate\": 0.012751601995412153,\n         \"reg_alpha\": 10.0,\n         \"tree_method\": 'gpu_hist', \"gpu_id\": 0,\n         'disable_default_eval_metric': 1\n    }","metadata":{"papermill":{"duration":0.078485,"end_time":"2021-08-23T00:07:59.594793","exception":false,"start_time":"2021-08-23T00:07:59.516308","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T19:16:28.43787Z","iopub.execute_input":"2021-08-29T19:16:28.440618Z","iopub.status.idle":"2021-08-29T20:19:08.53553Z","shell.execute_reply.started":"2021-08-29T19:16:28.440572Z","shell.execute_reply":"2021-08-29T20:19:08.532294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"optuna selection","metadata":{"papermill":{"duration":0.067151,"end_time":"2021-08-23T00:07:59.729008","exception":false,"start_time":"2021-08-23T00:07:59.661857","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Change data type and save some memory\n# di = [[f, 'float32'] for f in pd_df_full.columns if pd_df_full[f].dtype == 'float64']\n# pd_df_full = pd_df_full.astype(dict(di))\n# print([f for f in pd_df_full.columns if pd_df_full[f].dtype == 'float64'])\n# gc.collect()","metadata":{"papermill":{"duration":0.072371,"end_time":"2021-08-23T00:08:00.013696","exception":false,"start_time":"2021-08-23T00:07:59.941325","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T20:19:08.536581Z","iopub.status.idle":"2021-08-29T20:19:08.537094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\ndef get_xgb_imp(xgb, feat_names):\n    from numpy import array\n    imp_vals = xgb.get_booster().get_fscore()\n    imp_dict = {feat_names[i]:float(imp_vals.get('f'+str(i),0.)) for i in range(len(feat_names))}\n    total = array(imp_dict.values()).sum()\n    return {k:v/total for k,v in imp_dict.items()}\n\ndef rmspe(y_true, y_pred):\n    return (cp.sqrt(cp.mean(cp.square((y_true - y_pred) / y_true))))\n\n\ndef rmspe_xgb(pred, dtrain):\n    y = dtrain.get_label()\n    return 'rmspe', rmspe(cp.array(y), cp.array(pred))\n\n\nNUM_FOLDS = 5\n\ntarget = \"target\"\n\noof_preds = cp.zeros(dev_df.shape[0])\ntest_preds = cp.zeros(past_test_volatility.shape[0])\nkfold = GroupKFold(n_splits = NUM_FOLDS)\n\nfor fold, (train_ind, val_ind) in enumerate(kfold.split(pd_df_full[features], pd_df_full[target].values, pd_df_full[\"time_id\"].values)):\n    print(\"Fold\", fold)    \n    train_df, val_df = dev_df.iloc[train_ind], dev_df.iloc[val_ind]\n    \n    d_train = xgb.DMatrix(train_df[features], train_df[target], weight=1/cp.square(train_df[target]))\n    d_val = xgb.DMatrix(val_df[features], val_df[target], weight=1/cp.square(val_df[target]))\n    \n    model = xgb.train(best_params, d_train, evals = [(d_train, \"train\"), (d_val, \"val\")], \n                      num_boost_round = 3500, \n                      verbose_eval = 50, feval = rmspe_xgb,\n                      early_stopping_rounds = 200)\n    importances = {k: v for k, v in sorted(model.get_fscore().items(), key=lambda item: item[1], reverse = True)}\n    print('Importances for this iteration:', importances)\n    \n    pickle.dump({\"model\": model, \"features\": features, \"best_params\": best_params, \"importances\":importances, \n                 \"features_PCA\": features_PCA, \"pca\": pca, \"fpca\": fpca}, \n                open(\"/kaggle/working/modelv2-fold-\" + str(fold) + \".pickle\", \"wb\"))\n    \n    oof_preds[val_ind] = model.predict(d_val)\n    test_preds += cp.array(model.predict(xgb.DMatrix(past_test_volatility[features].astype(\"float\")))/NUM_FOLDS)","metadata":{"papermill":{"duration":304.432678,"end_time":"2021-08-23T00:13:04.515264","exception":true,"start_time":"2021-08-23T00:08:00.082586","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T20:19:08.538628Z","iopub.status.idle":"2021-08-29T20:19:08.539507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_df[\"pred\"] = oof_preds\nprint(f'The RMSPE score of XGB is {rmspe(dev_df[\"target\"], dev_df[\"pred\"])}')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2021-08-29T18:55:35.834015Z","iopub.execute_input":"2021-08-29T18:55:35.834364Z","iopub.status.idle":"2021-08-29T18:55:35.846292Z","shell.execute_reply.started":"2021-08-29T18:55:35.834333Z","shell.execute_reply":"2021-08-29T18:55:35.845345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"past_test_volatility[\"row_id\"] = past_test_volatility[\"stock_id\"].astype(str) + \"-\" + past_test_volatility[\"time_id\"].astype(str) \npast_test_volatility[\"target\"] = test_preds.clip(0.0, 100.0)/SCALE","metadata":{"execution":{"iopub.execute_input":"2021-08-22T02:54:22.516366Z","iopub.status.busy":"2021-08-22T02:54:22.516049Z","iopub.status.idle":"2021-08-22T02:54:23.134108Z","shell.execute_reply":"2021-08-22T02:54:23.132824Z","shell.execute_reply.started":"2021-08-22T02:54:22.516338Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.execute_input":"2021-08-22T02:54:25.273735Z","iopub.status.busy":"2021-08-22T02:54:25.273385Z","iopub.status.idle":"2021-08-22T02:54:25.279562Z","shell.execute_reply":"2021-08-22T02:54:25.278264Z","shell.execute_reply.started":"2021-08-22T02:54:25.273703Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = load_data(\"test\", path=PATH).merge(past_test_volatility[[\"row_id\", \"target\"]], on=\"row_id\", how=\"left\")\nsub_df['target'] = sub_df['target'].fillna(0.00373)\nsub_df.to_csv(\"submission.csv\", index=False, columns=[\"row_id\", \"target\"])","metadata":{"execution":{"iopub.execute_input":"2021-08-22T02:54:28.701442Z","iopub.status.busy":"2021-08-22T02:54:28.701126Z","iopub.status.idle":"2021-08-22T02:54:32.899683Z","shell.execute_reply":"2021-08-22T02:54:32.89885Z","shell.execute_reply.started":"2021-08-22T02:54:28.701413Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudf.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.execute_input":"2021-08-22T02:54:32.902358Z","iopub.status.busy":"2021-08-22T02:54:32.901841Z","iopub.status.idle":"2021-08-22T02:54:32.927195Z","shell.execute_reply":"2021-08-22T02:54:32.926273Z","shell.execute_reply.started":"2021-08-22T02:54:32.902319Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}