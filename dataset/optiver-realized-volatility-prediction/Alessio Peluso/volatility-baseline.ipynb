{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T09:06:01.154123Z","iopub.execute_input":"2021-07-10T09:06:01.154752Z","iopub.status.idle":"2021-07-10T09:06:01.167889Z","shell.execute_reply.started":"2021-07-10T09:06:01.154628Z","shell.execute_reply":"2021-07-10T09:06:01.166903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First thing first, let's read the train set. \n\nIt contains 3 columns:\n1. stock_id: ID code for the stock\n2. time_id: ID code for the time bucket\n3. target: The realized volatility computed over the 10 minute window following the feature data under the same stock/time_id.\n\nWe want to predict the last feature in the following ten minutes window.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T09:06:01.169263Z","iopub.execute_input":"2021-07-10T09:06:01.169697Z","iopub.status.idle":"2021-07-10T09:06:01.623218Z","shell.execute_reply.started":"2021-07-10T09:06:01.169651Z","shell.execute_reply":"2021-07-10T09:06:01.62197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's load the parquet files also.","metadata":{}},{"cell_type":"code","source":"import glob\n\norder_book_training = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T16:54:50.618166Z","iopub.execute_input":"2021-07-09T16:54:50.61882Z","iopub.status.idle":"2021-07-09T16:54:50.625758Z","shell.execute_reply.started":"2021-07-09T16:54:50.618779Z","shell.execute_reply":"2021-07-09T16:54:50.624835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here two useful functions too calculate the **WAP** and the **rel_volatility** ","metadata":{}},{"cell_type":"code","source":"def calc_wap(df):\n    temp = np.log(df).diff()\n    return np.sqrt(np.sum(temp**2))\n\ndef rel_vol_time_id(path):\n    book = pd.read_parquet(path) \n    # calculating WAP\n    p1 = book['bid_price1']\n    p2 = book['ask_price1']\n    s1 = book['bid_size1']\n    s2 = book['ask_size1']\n    \n    book['wap'] = (p1*s2 + p2*s1) / (s1 + s2)\n    transbook = book.groupby('time_id')['wap'].agg(calc_wap)\n    return transbook","metadata":{"execution":{"iopub.status.busy":"2021-07-09T16:54:52.476193Z","iopub.execute_input":"2021-07-09T16:54:52.476534Z","iopub.status.idle":"2021-07-09T16:54:52.484032Z","shell.execute_reply.started":"2021-07-09T16:54:52.476505Z","shell.execute_reply":"2021-07-09T16:54:52.482823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code chunk will take a while, for each stock_id finds the realized volatility for all time_id of temp_stock\n","metadata":{}},{"cell_type":"code","source":"%%time \nstock_id = []\ntime_id = []\nrelvol = []\nfor i in order_book_training:\n    # finding the stock_id\n    temp_stock = int(i.split(\"=\")[1])\n    # find the realized volatility for all time_id of temp_stock\n    temp_relvol = rel_vol_time_id(i)\n    stock_id += [temp_stock]*temp_relvol.shape[0]\n    time_id += list(temp_relvol.index)\n    relvol += list(temp_relvol)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T16:54:54.172682Z","iopub.execute_input":"2021-07-09T16:54:54.173075Z","iopub.status.idle":"2021-07-09T17:00:58.427191Z","shell.execute_reply.started":"2021-07-09T16:54:54.17304Z","shell.execute_reply":"2021-07-09T17:00:58.426137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a pandas df","metadata":{}},{"cell_type":"code","source":"past_volatility = pd.DataFrame({\"stock_id\": stock_id, \"time_id\": time_id, \"volatility\": relvol})","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:02:32.931806Z","iopub.execute_input":"2021-07-09T17:02:32.932185Z","iopub.status.idle":"2021-07-09T17:02:33.42113Z","shell.execute_reply.started":"2021-07-09T17:02:32.93215Z","shell.execute_reply":"2021-07-09T17:02:33.419992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's calculate the baseline R2 and RMSE:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\njoined = train.merge(past_volatility, on = [\"stock_id\",\"time_id\"], how = \"left\")\nR2 = round(r2_score(y_true = joined['target'], y_pred = joined['volatility']),3)\nprint(f'R2 score: {R2}')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:03:24.781891Z","iopub.execute_input":"2021-07-09T17:03:24.782525Z","iopub.status.idle":"2021-07-09T17:03:25.88436Z","shell.execute_reply.started":"2021-07-09T17:03:24.782489Z","shell.execute_reply":"2021-07-09T17:03:25.883202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n\nrmspe = rmspe(joined['target'], joined['volatility'])\nprint(f'RMSPE: {rmspe}')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:03:33.037633Z","iopub.execute_input":"2021-07-09T17:03:33.038045Z","iopub.status.idle":"2021-07-09T17:03:33.049929Z","shell.execute_reply.started":"2021-07-09T17:03:33.038011Z","shell.execute_reply":"2021-07-09T17:03:33.048893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After all the preprocessing now it's the turn for our baseline model, we'll use the Polynomial Features of the sklear preprocessing.\n\nThe Polynomial regression extends the linear model by adding extra predictors, obtained by raising each of the original predictors to a power. For example, a cubic regression uses three variables, X, X2, and X3, as predictors. This approach provides a simple way to provide a non-linear fit to data.\n\n**The degree is a parameter to be tuned.**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# for training\ndef linear_training(X,y,degree):\n    # instantiating polynomial features\n    polyfeat = PolynomialFeatures(degree = degree)\n    linreg = LinearRegression()\n    # preprocessing the training data\n    x = np.array(X).reshape(-1,1)\n    # creating the polynomial features\n    X_ = polyfeat.fit_transform(x)\n    # training the model\n    weights = 1/np.square(y)\n    return linreg.fit(X_, np.array(y).reshape(-1,1), sample_weight = weights)\n\n\nstock_id_train = train.stock_id.unique() # all stock_id for the train set\nmodels = {} # dictionary for holding trained models for each stock_id\ndegree = 2\nfor i in stock_id_train:\n    temp = joined[joined[\"stock_id\"]==i]\n    X = temp[\"volatility\"]\n    y = temp[\"target\"]\n    models[i] = linear_training(X,y,degree)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:37:12.352825Z","iopub.execute_input":"2021-07-09T17:37:12.353376Z","iopub.status.idle":"2021-07-09T17:37:13.835422Z","shell.execute_reply.started":"2021-07-09T17:37:12.353335Z","shell.execute_reply":"2021-07-09T17:37:13.834365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# listing all test order books\norder_book_test = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:06:08.147144Z","iopub.execute_input":"2021-07-09T17:06:08.147532Z","iopub.status.idle":"2021-07-09T17:06:08.157168Z","shell.execute_reply.started":"2021-07-09T17:06:08.147499Z","shell.execute_reply":"2021-07-09T17:06:08.155835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nstock_id = []\ntime_id = []\nrelvol = []\nfor i in order_book_test:\n    # finding the stock_id\n    temp_stock = int(i.split(\"=\")[1])\n    # find the realized volatility for all time_id of temp_stock\n    temp_relvol = rel_vol_time_id(i)\n    stock_id += [temp_stock]*temp_relvol.shape[0]\n    time_id += list(temp_relvol.index)\n    relvol += list(temp_relvol)\n    \npast_test_volatility = pd.DataFrame({\"stock_id\": stock_id, \"time_id\": time_id, \"volatility\": relvol})","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:37:20.382534Z","iopub.execute_input":"2021-07-09T17:37:20.382932Z","iopub.status.idle":"2021-07-09T17:37:20.40811Z","shell.execute_reply.started":"2021-07-09T17:37:20.382899Z","shell.execute_reply":"2021-07-09T17:37:20.407134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Last two steps are the predictions and the submissions.","metadata":{}},{"cell_type":"code","source":"# for inference\ndef linear_inference(models, stock_id, past_volatility, degree):\n    model = models[stock_id]\n    polyfeat = PolynomialFeatures(degree = degree)\n    return model.predict(polyfeat.fit_transform([[past_volatility]]))[0][0]","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:37:26.298279Z","iopub.execute_input":"2021-07-09T17:37:26.298627Z","iopub.status.idle":"2021-07-09T17:37:26.303973Z","shell.execute_reply.started":"2021-07-09T17:37:26.298597Z","shell.execute_reply":"2021-07-09T17:37:26.303037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'row_id' : [], 'target' : []})  \nsubmission['row_id'] = past_test_volatility.apply(lambda x: str(int(x.stock_id)) + '-' + str(int(x.time_id)), axis=1)\nsubmission['target'] = past_test_volatility.apply(lambda x: linear_inference(models,\\\n                                                                            x.stock_id,\\\n                                                                            x.volatility,\\\n                                                                            degree), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:37:35.326473Z","iopub.execute_input":"2021-07-09T17:37:35.32699Z","iopub.status.idle":"2021-07-09T17:37:35.420556Z","shell.execute_reply.started":"2021-07-09T17:37:35.326956Z","shell.execute_reply":"2021-07-09T17:37:35.418996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T17:07:26.639792Z","iopub.execute_input":"2021-07-09T17:07:26.64017Z","iopub.status.idle":"2021-07-09T17:07:26.648968Z","shell.execute_reply.started":"2021-07-09T17:07:26.640139Z","shell.execute_reply":"2021-07-09T17:07:26.647888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hope you liked this basic notebook and hope it would be helpful, more advanced are coming! Please upvote! :)  ","metadata":{}}]}