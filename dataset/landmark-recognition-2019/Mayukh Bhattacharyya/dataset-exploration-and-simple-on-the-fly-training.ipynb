{"cells":[{"metadata":{},"cell_type":"markdown","source":"Everyone is busy downloading and there was no kernel that kind of does the initial exploration to see how the images look like and how would a simple work on this dataset. Hence I went forward and created one. This kernel does not save any file locally and just uses them on the fly during training using a keras generator. Time ranges around ~240secs for an epoch with total 1280 images on a ResNet50 (with very minimal number of classes). There may be a few mistakes, you never know.\n\nHappy Kaggling!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import requests\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport threading\nimport urllib\nimport cv2\nimport time\n\nimport keras\nfrom keras.applications import ResNet50\nfrom keras import backend as K\nfrom keras import regularizers\nfrom keras.engine.topology import Input\nfrom keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, Flatten, GlobalMaxPooling2D, \\\n    Lambda, MaxPooling2D, Reshape\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import Sequence\nfrom sklearn.model_selection import train_test_split\n\nfrom collections import Counter\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def check_size(url):\n    r = requests.get(url, stream=True)\n    return int(r.headers['Content-Length'])\n\ndef download_file(url, filename, bar=True):\n    \"\"\"\n    Helper method handling downloading large files from `url` to `filename`. Returns a pointer to `filename`.\n    \"\"\"\n    try:\n        chunkSize = 1024\n        r = requests.get(url, stream=True)\n        with open(filename, 'wb') as f:\n            if bar:\n                pbar = tqdm( unit=\"B\", total=int( r.headers['Content-Length'] ) )\n            for chunk in r.iter_content(chunk_size=chunkSize): \n                if chunk: # filter out keep-alive new chunks\n                    if bar: \n                        pbar.update (len(chunk))\n                    f.write(chunk)\n        return filename\n    except Exception as e:\n        print(e)\n        return\n    \ndef download_image_cv2_urllib(url):\n    \"\"\"\n    Modifying the url to download the 360p or 720p version actually slows it down. \n    \"\"\"\n    try:\n        resp = urllib.request.urlopen(url)\n        foo = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n        foo = cv2.imdecode(foo, cv2.IMREAD_COLOR)\n        foo = cv2.resize(foo,(128, 128), interpolation=cv2.INTER_AREA)\n        return foo\n    except:\n        return np.array([])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's download the train set first."},{"metadata":{"trusted":true},"cell_type":"code","source":"download_file(\"https://s3.amazonaws.com/google-landmark/metadata/train.csv\", \"train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"train.csv\")\nprint(train.head())\nprint(train.shape)\nprint(\"Number of classes {}\".format(len(train.landmark_id.unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there are a whopping ~200k landmarks in this dataset. My house is probably also listed here. Now I don't want to use all these 200k categories. Majority of them will have very examples of it. So I'll exclude categories that have less than a certain threshold number of images to it's name."},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_THRESHOLD = 250\n\ncounts = dict(Counter(train['landmark_id']))\nlandmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD}\nNUM_CLASSES = len(landmarks_dict)\nprint(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n\ni = 0\nlandmark_to_idx = {}\nidx_to_landmark = []\nfor k in landmarks_dict:\n    landmark_to_idx[k] = i\n    idx_to_landmark.append(k)\n    i += 1\n\nall_urls = train['url'].tolist()\nall_landmarks = train['landmark_id'].tolist()\nvalid_urls_dict = {x[0].split(\"/\")[-1]:landmark_to_idx[x[1]] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict}\nvalid_urls_list = [x[0] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict]\n\nNUM_EXAMPLES = len(valid_urls_list)\nprint(\"Total number of valid examples: {}\".format(NUM_EXAMPLES))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us check a few sample images from the dataset. First we'll check a few images overall. In the next plot, we'll see how similar are the images from the same categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"w=20\nh=20\nfig=plt.figure(figsize=(16, 16))\ncolumns = 4\nrows = 4\ni = 1\nfor url in valid_urls_list[:16]:\n    im = download_image_cv2_urllib(url)\n    if im.size != 0:\n        fig.add_subplot(rows, columns, i)\n        plt.title(\"Landmark: \"+str(idx_to_landmark[valid_urls_dict[url.split(\"/\")[-1]]]))\n        plt.imshow(im)\n        i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w=20\nh=20\nfig=plt.figure(figsize=(16, 16))\ncolumns = 5\nrows = 4\nlandmarks = [idx_to_landmark[valid_urls_dict[x]] for x in random.sample(valid_urls_dict.keys(), rows)]\nfor i in range(rows):\n    landmark = landmarks[i]\n    urls = [x[0] for x in zip(all_urls, all_landmarks) if x[1]==landmark]\n    for j in range(columns):\n        im = download_image_cv2_urllib(urls[j])\n        if im.size != 0:\n            fig.add_subplot(rows, columns, i*columns+j+1)\n            plt.title(\"Landmark: \"+str(landmark))\n            plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, it is quite a noisy dataset. It is difficult to understand correctly how one image is connected to other in some categories.\n\nNot worrying about the noise in the data, let's proceed. Now we will create a train and validation set from the valid examples."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_urls, validation_urls = train_test_split(valid_urls_list, test_size=1.5*NUM_CLASSES/NUM_EXAMPLES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_images = []\nvalidation_y = []\nfor url in validation_urls:\n    im = download_image_cv2_urllib(url)\n    if im.size != 0:\n        validation_images.append(im)\n        validation_y.append(valid_urls_dict[url.split(\"/\")[-1]])\n\nvalid_x = np.array(validation_images)\nvalid_y = np.zeros((len(validation_images), NUM_CLASSES))\n        \nfor i in range(len(validation_y)):\n    valid_y[i,validation_y[i]] = 1.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass DataGen(Sequence):\n    def __init__(self, data, batch_size=24, verbose=1):\n        self.batch_size=batch_size\n        self.data_urls = data\n\n    def normalize(self,data):\n        return data\n    \n    def __getitem__(self, index):\n        batch_urls = random.sample(self.data_urls, self.batch_size)\n        \n        output = []\n        y_classes = []\n        for url in batch_urls:\n            im = download_image_cv2_urllib(url)\n            if im.size != 0:\n                output.append(im)\n                y_classes.append(valid_urls_dict[url.split(\"/\")[-1]])\n        \n        x = np.array(output)\n        y = np.zeros((len(output), NUM_CLASSES))\n        \n        for i in range(len(y_classes)):\n            y[i,y_classes[i]] = 1.\n        \n        return x,y\n            \n    def on_epoch_end(self):\n        return\n\n    def __len__(self):\n        #return len(valid_urls_list) // self.batch_size\n        return 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_class(y_true, y_pred):\n    true = K.argmax(y_true, axis=1)\n    pred = K.argmax(y_pred, axis=1)\n    matches = K.equal(true, pred)\n    return K.mean(matches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = ResNet50(include_top=False, weights='imagenet', input_shape=(128, 128, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in res.layers[:120]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = Flatten()(res.output)\nout = Dense(NUM_CLASSES, activation='softmax')(out)\nmodel = Model(res.input, out)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"opt = Adam(0.0001)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class])\nmodel.fit_generator(generator=DataGen(train_urls, batch_size=128),\n                    validation_data=[valid_x, valid_y],\n                    epochs=80,\n                    use_multiprocessing=True,\n                    workers=8,\n                    verbose=1)","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Adam' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7f879e3334cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit_generator(generator=DataGen(train_urls, batch_size=128),\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}