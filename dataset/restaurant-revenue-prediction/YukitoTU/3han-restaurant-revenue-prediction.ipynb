{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nimport matplotlib.pyplot as pylab\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import (GridSearchCV, RandomizedSearchCV)\nfrom sklearn.metrics import (mean_squared_error, mean_absolute_error)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import ExtraTreesClassifier # Used for imputing rare / missing values\n\n# Regressors considered:\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Ridge # only model used for final submission\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T04:10:04.310268Z","iopub.execute_input":"2021-07-05T04:10:04.310953Z","iopub.status.idle":"2021-07-05T04:10:04.323658Z","shell.execute_reply.started":"2021-07-05T04:10:04.310915Z","shell.execute_reply":"2021-07-05T04:10:04.322537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kaggle added approximately 311.5 \"fake\" data points to the test for each real data point. \n# Dividing by this number gives more accurate counts of the \"real\" data in the test set.\nFAKE_DATA_RATIO = 311.5\n# Set a Random Seed\nSEED = 0\n# Read Kaggle Provided Data\ntrain = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/train.csv.zip', index_col = 0, parse_dates=[1])\ntest = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/test.csv.zip', index_col = 0, parse_dates=[1])\nprint (\"Train Dimensions:\")\nprint (train.shape)\nprint (\"Test Dimensions:\")\nprint (test.shape)\n\n# Concatenate train and test together to pre-process and featurize both consistently.\ndf = pd.concat((test, train), ignore_index=True)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:04.326312Z","iopub.execute_input":"2021-07-05T04:10:04.326746Z","iopub.status.idle":"2021-07-05T04:10:05.007927Z","shell.execute_reply.started":"2021-07-05T04:10:04.326704Z","shell.execute_reply":"2021-07-05T04:10:05.00701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert date strings to \"days open\" numerical value\ndf[\"Open Date\"] = df[\"Open Date\"].apply(pd.to_datetime)\nlast_date = df[\"Open Date\"].max()\ndf[\"Open Date\"] = last_date - df[\"Open Date\"] # This becomes a datetime delta object\ndf[\"Open Date\"] = df[\"Open Date\"].dt.days + 1 # converts the delta object to an int\n\n# Scale \"days since opened\" so that the marginal impact decreases over time\n# This and the similar log transform of City Count below are the modifications that \n# were not in our official competition submission\ndf[\"Log Days Opened\"] = df[\"Open Date\"].apply(np.log)\ndf = df.drop([\"Open Date\"], axis=1)\npylab.rcParams['figure.figsize'] = (8, 6) # Resizes plots\ndf[[\"Log Days Opened\", \"revenue\"]].plot(x=\"Log Days Opened\", y=\"revenue\", kind='scatter', title=\"Log (Days Opened) vs Revenue\")","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:05.011521Z","iopub.execute_input":"2021-07-05T04:10:05.011842Z","iopub.status.idle":"2021-07-05T04:10:05.946422Z","shell.execute_reply.started":"2021-07-05T04:10:05.01181Z","shell.execute_reply":"2021-07-05T04:10:05.945376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lin noticed that a certain set of columns are either all zero or all non-zero.  \n# We added a feature to mark this  - The \"zeros\" feature will be 17 for these rows\n# and 0 or 1 for the rows which are never or rarely zero.\n\n# The features with the notable zero behavior:\nzero_cols = ['P14', 'P15', 'P16', 'P17', 'P18', 'P24', 'P25', 'P26', 'P27', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37']\n\n# We make a feature that holds this count of zero columns in the above list\ndf['zeros'] = (df[zero_cols] == 0).sum(1)\n\npylab.rcParams['figure.figsize'] = (20, 8)\nfig, axs = plt.subplots(1,2)\n\nprint (\"Distribution of new Zeros features:\")\n# We find there is only 1 row with a zero count between 0 and 17 in the train set, \ndf['zeros'].loc[pd.notnull(df.revenue)].value_counts().plot(title=\"Train Set\", kind='bar', ax=axs[0])\n\n# But in the test set there are many rows with an intermediate count of zeros. \n# This is probably an artifact of how the fake test data was generated (conditional \n# dependence between columns was not preserved).\ndf['zeros'].loc[pd.isnull(df.revenue)].value_counts().plot(title=\"Test Set\", kind='bar', ax=axs[1], color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:05.947548Z","iopub.execute_input":"2021-07-05T04:10:05.947808Z","iopub.status.idle":"2021-07-05T04:10:06.301383Z","shell.execute_reply.started":"2021-07-05T04:10:05.947783Z","shell.execute_reply":"2021-07-05T04:10:06.300261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we convert two categorical variables, \"Restaurant Type\" and \"City Group (Size)\" \n# to dummy variables\npylab.rcParams['figure.figsize'] = (6, 4) # Resizes plots\n\n# The two categories of City Group both appear very frequently\ntrain[\"City Group\"].value_counts().plot(title=\"City Group Distribution in the Train Set\", kind='bar')\nplt.show()\n\n# But two of the four Restaurant Types (DT and FC), are extremely rare\ntrain[\"Type\"].value_counts().plot(title=\"Restaurant Type Distribution in the Train Set\", kind='bar')\nplt.show()\n\n(test[\"Type\"].value_counts() / FAKE_DATA_RATIO).plot(title=\"Approximate Restaurant Type Distribution in True Test Set\", kind='bar', color='Red')\nplt.show()\n\ndf = df.join(pd.get_dummies(df['City Group'], prefix=\"CG\"))\ndf = df.join(pd.get_dummies(df['Type'], prefix=\"T\"))\n\n# Since only n-1 columns are needed to binarize n categories, drop one of the new columns.  \n# And drop the original columns.\n# And also drop the extremely rare restaurant types (which we handleed especially below)\ndf = df.drop([\"City Group\", \"Type\", \"CG_Other\", \"T_MB\", \"T_DT\"], axis=1)\nprint (df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:06.303968Z","iopub.execute_input":"2021-07-05T04:10:06.304274Z","iopub.status.idle":"2021-07-05T04:10:06.787385Z","shell.execute_reply.started":"2021-07-05T04:10:06.304244Z","shell.execute_reply":"2021-07-05T04:10:06.786121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace city names with\n# count of their frequency in the train + estimated frequency in the test set.\ncity_counts = (test[\"City\"].value_counts() / FAKE_DATA_RATIO).add(train[\"City\"].value_counts(), fill_value=0)\ndf[\"City\"] = df[\"City\"].replace(city_counts)\nprint (\"Some example estimated counts of restaurants per city:\")\nprint (city_counts.head())\n\n# Take log of city count so that the marginal effect decreases\ndf[\"Log City Count\"] = df[\"City\"].apply(np.log) \ndf = df.drop([\"City\"], axis=1)\n\n# That last vertical spread of points are restaurants from Istanbul.\npylab.rcParams['figure.figsize'] = (8, 6) # Resizes plots\ndf[[\"Log City Count\", \"revenue\"]].plot(x=\"Log City Count\", y=\"revenue\", kind='scatter', title=\"Log City Count vs Revenue\")","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:06.789105Z","iopub.execute_input":"2021-07-05T04:10:06.789533Z","iopub.status.idle":"2021-07-05T04:10:07.362484Z","shell.execute_reply.started":"2021-07-05T04:10:06.789492Z","shell.execute_reply":"2021-07-05T04:10:07.361355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Impute values for the very rare restaurant types. \n# Instead of trying to predict with values that appear only 1 or 0 times in the train set, \n# we will replace them with one of the other commonly appearing categories by fitting a \n# model that predicts which common category they \"should\" be.\n\n# tofit are the rows in the train set that belong to one of the common restaurnat types\ntofit = df.loc[((df.T_FC==1) | (df.T_IL==1)) & (pd.notnull(df.revenue))]\n# tofill are rows in either train or test that belong to one of the rare types\ntofill = df.loc[((df.T_FC==0) & (df.T_IL==0))]\n\nprint('type training set shape:'), tofit.shape\nprint('data to impute:'), tofill.shape\n\n# Resaruants with type FC are labeled 1, those with type IL are labeled 0.\ny = tofit.T_FC\n# Drop the label columns and revenue (which is not in the test set, so can't be used here)\nX = tofit.drop([\"T_FC\", \"T_IL\", \"revenue\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:07.364143Z","iopub.execute_input":"2021-07-05T04:10:07.364491Z","iopub.status.idle":"2021-07-05T04:10:07.381819Z","shell.execute_reply.started":"2021-07-05T04:10:07.364447Z","shell.execute_reply":"2021-07-05T04:10:07.380701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define and train a model to impute restaurant type\n# The grid below just has a range of values that I've found commonly\n# work well with random forest type models (of which ExtraTrees is one).\nmodel_grid = {'max_depth': [None, 8], 'min_samples_split': [4,9,16], 'min_samples_leaf':[1,4], 'max_features':['sqrt', 0.5, None]}\ntype_model = ExtraTreesClassifier(n_estimators=25, random_state=SEED)\n\ngrid = RandomizedSearchCV(type_model, model_grid, n_iter=10, cv=5, scoring=\"roc_auc\")\ngrid.fit(X, y)\n\nprint(\"Best parameters for Type Model:\")\nprint(grid.best_params_)\n\ntype_model.set_params(**grid.best_params_)\ntype_model.fit(X, y)\n\nimputations = type_model.predict(tofill.drop([\"T_FC\", \"T_IL\", \"revenue\"], axis=1))\ndf.loc[(df.T_FC==0) & (df.T_IL==0), \"T_FC\"] = imputations\ndf = df.drop([\"T_IL\"], axis=1)\n\nprint (\"% labeled FC in the training set:\"), df.T_FC.mean()\nprint (\"% of imputed values labeled FC:\"), np.mean(imputations)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:07.383542Z","iopub.execute_input":"2021-07-05T04:10:07.383955Z","iopub.status.idle":"2021-07-05T04:10:09.690157Z","shell.execute_reply.started":"2021-07-05T04:10:07.38391Z","shell.execute_reply":"2021-07-05T04:10:09.689367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now binarize the \"P\" columns with dummy variables\nprint (\"Pre-binarizing columns:\"), len(df.columns)\nfor col in df.columns:\n    if col[0] == 'P':\n        print (col), len(df[col].unique()), \"unique values\"\n        df = df.join(pd.get_dummies(df[col], prefix=col))\n        df = df.drop([col, df.columns[-1]], axis=1)\nprint (\"Post-binarizing columns:\"), len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:09.691666Z","iopub.execute_input":"2021-07-05T04:10:09.691959Z","iopub.status.idle":"2021-07-05T04:10:11.511826Z","shell.execute_reply.started":"2021-07-05T04:10:09.69193Z","shell.execute_reply":"2021-07-05T04:10:11.510987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale all input features to between 0 and 1, critical to do this for KNN or SVR models.\nmin_max_scaler = MinMaxScaler()\n# Don't scale the output - drop it temporarily\nrev = df.revenue\ndf = df.drop(['revenue'], axis=1)\n\ndf = pd.DataFrame(data = min_max_scaler.fit_transform(df), columns = df.columns, index=df.index)\ndf = df.join(rev)\n\n# Done with preprocessing. Let's take a last look at the data before modeling with it.\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:11.513244Z","iopub.execute_input":"2021-07-05T04:10:11.513669Z","iopub.status.idle":"2021-07-05T04:10:13.334031Z","shell.execute_reply.started":"2021-07-05T04:10:11.513631Z","shell.execute_reply":"2021-07-05T04:10:13.332991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recover original train/train rows based on revenue (which is null for test rows)\ntrain = df.loc[pd.notnull(df.revenue)]\ntest = df.loc[pd.isnull(df.revenue)].drop(['revenue'], axis=1)\n\n# Scale revenue by sqrt. \n# The purpose is to decrease the influence of the few very large revenue values.\ny = train.revenue.apply(np.sqrt)\nX = train.drop([\"revenue\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:13.335543Z","iopub.execute_input":"2021-07-05T04:10:13.335936Z","iopub.status.idle":"2021-07-05T04:10:13.510859Z","shell.execute_reply.started":"2021-07-05T04:10:13.335893Z","shell.execute_reply":"2021-07-05T04:10:13.509827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now define and train a Ridge Regression model. We tested others from the sklearn package:\n# SVR, RandomForest, K-nearest Neighbors, but found Ridge consistantly gave the strongest \n# leaderboard results. When training data is small, simplest is often best.\nmodel_grid = [{'normalize': [True, False], 'alpha': np.logspace(0,10)}]\nmodel = Ridge()\n\n# Use a grid search and leave-one-out CV on the train set to find the best regularization parameter to use.\n# (might take a minute or two)\ngrid = GridSearchCV(model, model_grid, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\ngrid.fit(X, y)\nprint(\"Best parameters set found on development set:\")\nprint(grid.best_params_)\n\n# Re-train on full training set using the best parameters found in the last step.\nmodel.set_params(**grid.best_params_)\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:10:13.51213Z","iopub.execute_input":"2021-07-05T04:10:13.512451Z","iopub.status.idle":"2021-07-05T04:16:42.370126Z","shell.execute_reply.started":"2021-07-05T04:10:13.512422Z","shell.execute_reply":"2021-07-05T04:16:42.369016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the test set with the trained model.\nsubmission = pd.DataFrame(columns=['Prediction'],index=test.index, data=model.predict(test))\n# Convert back to revenue from sqrt(revenue)\nsubmission.Prediction = submission.Prediction.apply(np.square)\n# Add required column name for Kaggle's submission parser:\nsubmission.index.name='Id'\n# Write out the submission\nsubmission.to_csv(\"TFI_Ridge.csv\")\n# Quick sanity check on the submission\nsubmission.describe().astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:16:42.37229Z","iopub.execute_input":"2021-07-05T04:16:42.373278Z","iopub.status.idle":"2021-07-05T04:16:42.917548Z","shell.execute_reply.started":"2021-07-05T04:16:42.373228Z","shell.execute_reply":"2021-07-05T04:16:42.916553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Revenue from train set for comparison\ntrain[['revenue']].describe().astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:16:42.918828Z","iopub.execute_input":"2021-07-05T04:16:42.919116Z","iopub.status.idle":"2021-07-05T04:16:42.933622Z","shell.execute_reply.started":"2021-07-05T04:16:42.919089Z","shell.execute_reply":"2021-07-05T04:16:42.932582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another quick comparision. Note the x-axis scale change: the predictions are \n# more conservative and tend to be closer to the mean than the real revenues. \n# This is pretty standard behavior when using RMSE - there are big penalties for \n# being very wrong, so the model will tend towards more moderate predictions.\ntrain[['revenue']].plot(kind='kde', title=\"Train Revenue Distribution\")\nsubmission.columns = [\"predicted revenue\"]\nsubmission.plot(kind='kde', title=\"Prediction Revenue Distribution\", color='r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T04:16:42.936212Z","iopub.execute_input":"2021-07-05T04:16:42.936525Z","iopub.status.idle":"2021-07-05T04:16:45.508255Z","shell.execute_reply.started":"2021-07-05T04:16:42.936496Z","shell.execute_reply":"2021-07-05T04:16:45.507447Z"},"trusted":true},"execution_count":null,"outputs":[]}]}