{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-14T04:59:54.876169Z","iopub.execute_input":"2021-07-14T04:59:54.876676Z","iopub.status.idle":"2021-07-14T04:59:54.891085Z","shell.execute_reply.started":"2021-07-14T04:59:54.876567Z","shell.execute_reply":"2021-07-14T04:59:54.889694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nimport matplotlib.pyplot as pylab\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import (GridSearchCV, RandomizedSearchCV)\nfrom sklearn.metrics import (mean_squared_error, mean_absolute_error)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import ExtraTreesClassifier # Used for imputing rare / missing values\n\n# Regressors considered:\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Ridge # only model used for final submission\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T04:59:57.976093Z","iopub.execute_input":"2021-07-14T04:59:57.976622Z","iopub.status.idle":"2021-07-14T04:59:59.337238Z","shell.execute_reply.started":"2021-07-14T04:59:57.976575Z","shell.execute_reply":"2021-07-14T04:59:59.336258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nFAKE_DATA_RATIO = 112141\n# Set a Random Seed\nSEED = 777\n# Read Kaggle Provided Data\ntrain = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/train.csv.zip', index_col = 0, parse_dates=[1])\ntest = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/test.csv.zip', index_col = 0, parse_dates=[1])\nprint (\"Train Dimensions:\")\nprint (train.shape)\nprint (\"Test Dimensions:\")\nprint (test.shape)\n\n# Concatenate train and test together to pre-process and featurize both consistently.\ndf = pd.concat((test, train), ignore_index=True)\ndf.describe()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:01:20.866849Z","iopub.execute_input":"2021-07-14T05:01:20.867308Z","iopub.status.idle":"2021-07-14T05:01:22.000626Z","shell.execute_reply.started":"2021-07-14T05:01:20.86727Z","shell.execute_reply":"2021-07-14T05:01:21.999143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Open Date\"] = df[\"Open Date\"].apply(pd.to_datetime)\nlast_date = df[\"Open Date\"].max()\ndf[\"Open Date\"] = last_date - df[\"Open Date\"] # This becomes a datetime delta object\ndf[\"Open Date\"] = df[\"Open Date\"].dt.days + 1 # converts the delta object to an int\n\n# Scale \"days since opened\" so that the marginal impact decreases over time\n# This and the similar log transform of City Count below are the modifications that \n# were not in our official competition submission\ndf[\"Log Days Opened\"] = df[\"Open Date\"].apply(np.log)\ndf = df.drop([\"Open Date\"], axis=1)\npylab.rcParams['figure.figsize'] = (8, 6) # Resizes plots\ndf[[\"Log Days Opened\", \"revenue\"]].plot(x=\"Log Days Opened\", y=\"revenue\", kind='scatter', title=\"Log (Days Opened) vs Revenue\")","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:01:25.253728Z","iopub.execute_input":"2021-07-14T05:01:25.254205Z","iopub.status.idle":"2021-07-14T05:01:26.402672Z","shell.execute_reply.started":"2021-07-14T05:01:25.254169Z","shell.execute_reply":"2021-07-14T05:01:26.401642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero_cols = ['P14', 'P15', 'P16', 'P17', 'P18', 'P24', 'P25', 'P26', 'P27', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37']\n\n# We make a feature that holds this count of zero columns in the above list\ndf['zeros'] = (df[zero_cols] == 0).sum(1)\n\npylab.rcParams['figure.figsize'] = (20, 8)\nfig, axs = plt.subplots(1,2)\n\nprint (\"Distribution of new Zeros features:\")\n# We find there is only 1 row with a zero count between 0 and 17 in the train set, \ndf['zeros'].loc[pd.notnull(df.revenue)].value_counts().plot(title=\"Train Set\", kind='bar', ax=axs[0])\n\n# But in the test set there are many rows with an intermediate count of zeros. \n# This is probably an artifact of how the fake test data was generated (conditional \n# dependence between columns was not preserved).\ndf['zeros'].loc[pd.isnull(df.revenue)].value_counts().plot(title=\"Test Set\", kind='bar', ax=axs[1], color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:01:31.505636Z","iopub.execute_input":"2021-07-14T05:01:31.506263Z","iopub.status.idle":"2021-07-14T05:01:31.911156Z","shell.execute_reply.started":"2021-07-14T05:01:31.506222Z","shell.execute_reply":"2021-07-14T05:01:31.909813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\npylab.rcParams['figure.figsize'] = (6, 4) # Resizes plots\n\n# The two categories of City Group both appear very frequently\ntrain[\"City Group\"].value_counts().plot(title=\"City Group Distribution in the Train Set\", kind='bar')\nplt.show()\n\n# But two of the four Restaurant Types (DT and FC), are extremely rare\ntrain[\"Type\"].value_counts().plot(title=\"Restaurant Type Distribution in the Train Set\", kind='bar')\nplt.show()\n\n(test[\"Type\"].value_counts() / FAKE_DATA_RATIO).plot(title=\"Approximate Restaurant Type Distribution in True Test Set\", kind='bar', color='Red')\nplt.show()\n\ndf = df.join(pd.get_dummies(df['City Group'], prefix=\"CG\"))\ndf = df.join(pd.get_dummies(df['Type'], prefix=\"T\"))\n\n# Since only n-1 columns are needed to binarize n categories, drop one of the new columns.  \n# And drop the original columns.\n# And also drop the extremely rare restaurant types (which we handleed especially below)\ndf = df.drop([\"City Group\", \"Type\", \"CG_Other\", \"T_MB\", \"T_DT\"], axis=1)\nprint (df.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:01:53.478911Z","iopub.execute_input":"2021-07-14T05:01:53.479322Z","iopub.status.idle":"2021-07-14T05:01:54.026524Z","shell.execute_reply.started":"2021-07-14T05:01:53.479287Z","shell.execute_reply":"2021-07-14T05:01:54.025547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace city names with\n# count of their frequency in the train + estimated frequency in the test set.\ncity_counts = (test[\"City\"].value_counts() / FAKE_DATA_RATIO).add(train[\"City\"].value_counts(), fill_value=0)\ndf[\"City\"] = df[\"City\"].replace(city_counts)\nprint (\"Some example estimated counts of restaurants per city:\")\nprint (city_counts.head())\n\n# Take log of city count so that the marginal effect decreases\ndf[\"Log City Count\"] = df[\"City\"].apply(np.log) \ndf = df.drop([\"City\"], axis=1)\n\n# That last vertical spread of points are restaurants from Istanbul.\npylab.rcParams['figure.figsize'] = (8, 6) # Resizes plots\ndf[[\"Log City Count\", \"revenue\"]].plot(x=\"Log City Count\", y=\"revenue\", kind='scatter', title=\"Log City Count vs Revenue\")","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:02:04.525157Z","iopub.execute_input":"2021-07-14T05:02:04.52552Z","iopub.status.idle":"2021-07-14T05:02:05.144988Z","shell.execute_reply.started":"2021-07-14T05:02:04.525487Z","shell.execute_reply":"2021-07-14T05:02:05.143842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Impute values for the very rare restaurant types. \n# Instead of trying to predict with values that appear only 1 or 0 times in the train set, \n# we will replace them with one of the other commonly appearing categories by fitting a \n# model that predicts which common category they \"should\" be.\n\n# tofit are the rows in the train set that belong to one of the common restaurnat types\ntofit = df.loc[((df.T_FC==1) | (df.T_IL==1)) & (pd.notnull(df.revenue))]\n# tofill are rows in either train or test that belong to one of the rare types\ntofill = df.loc[((df.T_FC==0) & (df.T_IL==0))]\n\nprint('type training set shape:'), tofit.shape\nprint('data to impute:'), tofill.shape\n\n# Resaruants with type FC are labeled 1, those with type IL are labeled 0.\ny = tofit.T_FC\n# Drop the label columns and revenue (which is not in the test set, so can't be used here)\nX = tofit.drop([\"T_FC\", \"T_IL\", \"revenue\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:02:18.942112Z","iopub.execute_input":"2021-07-14T05:02:18.942622Z","iopub.status.idle":"2021-07-14T05:02:18.956675Z","shell.execute_reply.started":"2021-07-14T05:02:18.942589Z","shell.execute_reply":"2021-07-14T05:02:18.955737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define and train a model to impute restaurant type\n# The grid below just has a range of values that I've found commonly\n# work well with random forest type models (of which ExtraTrees is one).\nmodel_grid = {'max_depth': [None, 8], 'min_samples_split': [4,9,16], 'min_samples_leaf':[1,4], 'max_features':['sqrt', 0.5, None]}\ntype_model = ExtraTreesClassifier(n_estimators=25, random_state=SEED)\n\ngrid = RandomizedSearchCV(type_model, model_grid, n_iter=10, cv=5, scoring=\"roc_auc\")\ngrid.fit(X, y)\n\nprint(\"Best parameters for Type Model:\")\nprint(grid.best_params_)\n\ntype_model.set_params(**grid.best_params_)\ntype_model.fit(X, y)\n\nimputations = type_model.predict(tofill.drop([\"T_FC\", \"T_IL\", \"revenue\"], axis=1))\ndf.loc[(df.T_FC==0) & (df.T_IL==0), \"T_FC\"] = imputations\ndf = df.drop([\"T_IL\"], axis=1)\n\nprint (\"% labeled FC in the training set:\"), df.T_FC.mean()\nprint (\"% of imputed values labeled FC:\"), np.mean(imputations)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:02:31.862327Z","iopub.execute_input":"2021-07-14T05:02:31.862732Z","iopub.status.idle":"2021-07-14T05:02:34.302658Z","shell.execute_reply.started":"2021-07-14T05:02:31.862684Z","shell.execute_reply":"2021-07-14T05:02:34.301731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Now binarize the \"P\" columns with dummy variables\nprint (\"Pre-binarizing columns:\"), len(df.columns)\nfor col in df.columns:\n    if col[0] == 'P':\n        print (col), len(df[col].unique()), \"unique values\"\n        df = df.join(pd.get_dummies(df[col], prefix=col))\n        df = df.drop([col, df.columns[-1]], axis=1)\nprint (\"Post-binarizing columns:\"), len(df.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:02:43.632247Z","iopub.execute_input":"2021-07-14T05:02:43.632609Z","iopub.status.idle":"2021-07-14T05:02:46.095712Z","shell.execute_reply.started":"2021-07-14T05:02:43.632579Z","shell.execute_reply":"2021-07-14T05:02:46.094652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale all input features to between 0 and 1, critical to do this for KNN or SVR models.\nmin_max_scaler = MinMaxScaler()\n# Don't scale the output - drop it temporarily\nrev = df.revenue\ndf = df.drop(['revenue'], axis=1)\n\ndf = pd.DataFrame(data = min_max_scaler.fit_transform(df), columns = df.columns, index=df.index)\ndf = df.join(rev)\n\n# Done with preprocessing. Let's take a last look at the data before modeling with it.\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:02:58.950887Z","iopub.execute_input":"2021-07-14T05:02:58.951503Z","iopub.status.idle":"2021-07-14T05:03:01.417919Z","shell.execute_reply.started":"2021-07-14T05:02:58.951447Z","shell.execute_reply":"2021-07-14T05:03:01.416883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recover original train/train rows based on revenue (which is null for test rows)\ntrain = df.loc[pd.notnull(df.revenue)]\ntest = df.loc[pd.isnull(df.revenue)].drop(['revenue'], axis=1)\n\n# Scale revenue by sqrt. \n# The purpose is to decrease the influence of the few very large revenue values.\ny = train.revenue.apply(np.sqrt)\nX = train.drop([\"revenue\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:03:10.881931Z","iopub.execute_input":"2021-07-14T05:03:10.882363Z","iopub.status.idle":"2021-07-14T05:03:11.072733Z","shell.execute_reply.started":"2021-07-14T05:03:10.882322Z","shell.execute_reply":"2021-07-14T05:03:11.07145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now define and train a Ridge Regression model. We tested others from the sklearn package:\n# SVR, RandomForest, K-nearest Neighbors, but found Ridge consistantly gave the strongest \n# leaderboard results. When training data is small, simplest is often best.\nmodel_grid = [{'normalize': [True, False], 'alpha': np.logspace(0,10)}]\nmodel = Ridge()\n\n# Use a grid search and leave-one-out CV on the train set to find the best regularization parameter to use.\n# (might take a minute or two)\ngrid = GridSearchCV(model, model_grid, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\ngrid.fit(X, y)\nprint(\"Best parameters set found on development set:\")\nprint(grid.best_params_)\n\n# Re-train on full training set using the best parameters found in the last step.\nmodel.set_params(**grid.best_params_)\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:03:19.819093Z","iopub.execute_input":"2021-07-14T05:03:19.819509Z","iopub.status.idle":"2021-07-14T05:08:51.446207Z","shell.execute_reply.started":"2021-07-14T05:03:19.819471Z","shell.execute_reply":"2021-07-14T05:08:51.444145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the test set with the trained model.\nsubmission = pd.DataFrame(columns=['Prediction'],index=test.index, data=model.predict(test))\n# Convert back to revenue from sqrt(revenue)\nsubmission.Prediction = submission.Prediction.apply(np.square)\n# Add required column name for Kaggle's submission parser:\nsubmission.index.name='Id'\n# Write out the submission\nsubmission.to_csv(\"TFI_Ridge.csv\")\n# Quick sanity check on the submission\nsubmission.describe().astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:09:10.834973Z","iopub.execute_input":"2021-07-14T05:09:10.835406Z","iopub.status.idle":"2021-07-14T05:09:11.364047Z","shell.execute_reply.started":"2021-07-14T05:09:10.835366Z","shell.execute_reply":"2021-07-14T05:09:11.362994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Revenue from train set for comparison\ntrain[['revenue']].describe().astype(int)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:09:33.398449Z","iopub.execute_input":"2021-07-14T05:09:33.398851Z","iopub.status.idle":"2021-07-14T05:09:33.416785Z","shell.execute_reply.started":"2021-07-14T05:09:33.398803Z","shell.execute_reply":"2021-07-14T05:09:33.415659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Another quick comparision. Note the x-axis scale change: the predictions are \n# more conservative and tend to be closer to the mean than the real revenues. \n# This is pretty standard behavior when using RMSE - there are big penalties for \n# being very wrong, so the model will tend towards more moderate predictions.\ntrain[['revenue']].plot(kind='kde', title=\"Train Revenue Distribution\")\nsubmission.columns = [\"predicted revenue\"]\nsubmission.plot(kind='kde', title=\"Prediction Revenue Distribution\", color='r')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:09:41.916176Z","iopub.execute_input":"2021-07-14T05:09:41.916643Z","iopub.status.idle":"2021-07-14T05:09:44.499261Z","shell.execute_reply.started":"2021-07-14T05:09:41.916599Z","shell.execute_reply":"2021-07-14T05:09:44.497769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"fake data ratio値を311.5から112141に変更しただけ。⑬（⑰）の数値が微変、結果変わらず。⑧をいじる？","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}