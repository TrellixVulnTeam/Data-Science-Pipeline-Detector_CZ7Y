{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn import ensemble\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/train.csv.zip')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = data.pop('revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(data.columns[[0, 1,2,3,4]], axis=1)\nx_train=data[:]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor()\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nlearning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n#learing_rates=[]\ntrain_results = []\ntest_results = []\n#beta=range(.05,1.05,.05)\nfor eta in learning_rates:\n   #learning_rates.append(eta)\n   model = GradientBoostingRegressor(learning_rate=eta)\n   model.fit(x_train, y_train)\n   from sklearn.metrics import mean_squared_error, r2_score\n   model_score = model.score(x_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\n   y_predicted_train=model.predict(x_train)\n   train_results.append(mean_squared_error(y_train, y_predicted_train))\n   print('R2 sq: ',model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(learning_rates, train_results, 'b', label=\"Training MSE\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('Mean Squared Error')\nplt.xlabel('Learning Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nn_estimators = [ 1, 2, 4, 8, 16, 32, 64, 100, 200, 500, 1000, 2000]\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n   model = GradientBoostingRegressor(n_estimators=estimator)\n   model.fit(x_train, y_train)\n   from sklearn.metrics import mean_squared_error, r2_score\n   model_score = model.score(x_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\n   y_predicted_train=model.predict(x_train)\n   train_results.append(mean_squared_error(y_train, y_predicted_train))\n   print('R2 sq: ',model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(n_estimators, train_results, 'b', label=\"Training MSE\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('Mean Squared Error')\nplt.xlabel('Number of Estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n#min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\nmin_samples_splits=[2,3,4,5,6,7,8,9,10]\ntrain_results = []\ntest_results = []\nfor min_samples_split in min_samples_splits:\n   model = GradientBoostingRegressor(min_samples_split=min_samples_split)\n   model.fit(x_train, y_train)\n   from sklearn.metrics import mean_squared_error, r2_score\n   model_score = model.score(x_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\n   y_predicted_train=model.predict(x_train)\n   train_results.append(mean_squared_error(y_train, y_predicted_train))\n   print('R2 sq: ',model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Training MSE\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('Mean Squared Error')\nplt.xlabel('Min Samples Split')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nmax_depths = [1,2,3,4,5,6,7,8,9,10]\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n   model = GradientBoostingRegressor(max_depth=max_depth)\n   model.fit(x_train, y_train)\n   from sklearn.metrics import mean_squared_error, r2_score\n   model_score = model.score(x_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\n   y_predicted_train=model.predict(x_train)\n   train_results.append(mean_squared_error(y_train, y_predicted_train))\n   print('R2 sq: ',model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_depths, train_results, 'b', label=\"Training MSE\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('Mean Squared Error')\nplt.xlabel('No. of Depth')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n#min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\nmin_samples_leafs = [1,2,3,4,5,6,7,8,9,10]\ntrain_results = []\ntest_results = []\nfor min_samples_leaf in min_samples_leafs:\n   model = GradientBoostingRegressor(min_samples_leaf=min_samples_leaf)\n   model.fit(x_train, y_train)\n   from sklearn.metrics import mean_squared_error, r2_score\n   model_score = model.score(x_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\n   y_predicted_train=model.predict(x_train)\n   train_results.append(mean_squared_error(y_train, y_predicted_train))\n   print('R2 sq: ',model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(min_samples_leafs, train_results, 'b', label=\"Training MSE\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('Mean Squared Error')\nplt.xlabel('No. of Samples Leaf')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nmax_features = list(range(1,data.shape[1]))\ntrain_results = []\ntest_results = []\nfor max_feature in max_features:\n   model = GradientBoostingRegressor(max_features=max_feature)\n   model.fit(x_train, y_train)\n   from sklearn.metrics import mean_squared_error, r2_score\n   model_score = model.score(x_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\n   y_predicted_train=model.predict(x_train)\n   train_results.append(mean_squared_error(y_train, y_predicted_train))\n   print('R2 sq: ',model_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_features, train_results, 'b', label=\"Training MSE\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('Mean Squared Error')\nplt.xlabel('No. of Feature')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = pd.read_csv('/kaggle/input/restaurant-revenue-prediction/test.csv.zip')\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=data1.drop(data1.columns[[0, 1,2,3,4]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample =pd.read_csv('/kaggle/input/restaurant-revenue-prediction/sampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'n_estimators': 225, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.25, 'loss': 'ls','max_features':10,\n             'min_samples_leaf':2}\nmodel = ensemble.GradientBoostingRegressor(**params)\nmodel.fit(x_train, y_train)\nsample[\"Prediction\"] = model.predict(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}