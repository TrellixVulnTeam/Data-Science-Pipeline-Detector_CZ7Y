{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport catboost\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainval_filename = '/kaggle/input/restaurant-revenue-prediction/train.csv.zip'\ntest_filename = '/kaggle/input/restaurant-revenue-prediction/test.csv.zip'\ndf_trainval = pd.read_csv(trainval_filename)\ndf_test = pd.read_csv(test_filename)\n#X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1,test_size=0.1)\nprint(df_trainval.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_trainval = df_trainval['revenue']\ndel df_trainval['revenue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_trainval[['City Group','Type']].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([df_trainval,df_test],axis=0)\ndf_all['Open Date'] = pd.to_datetime(df_all[\"Open Date\"])\ndf_all['Year'] = df_all['Open Date'].apply(lambda x:x.year)\ndf_all['Month'] = df_all['Open Date'].apply(lambda x:x.month)\ndf_all['Day'] = df_all['Open Date'].apply(lambda x:x.day)\ndf_all['week_name'] = df_all['Open Date'].apply(lambda x:x.weekday_name)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf_all['City'] = le.fit_transform(df_all['City'])\ndf_all['City Group'] = df_all['City Group'].map({'Other':0,'Big Cities':1}) #There are only 'Other' or 'Big city'\ndf_all[\"Type\"] = df_all[\"Type\"].map({\"FC\":0, \"IL\":1, \"DT\":2, \"MB\":3}) #There are only 'FC' or 'IL' or 'DT' or 'MB'\nprint(df_all.head())\ndf_all[\"week_name\"] = df_all[\"week_name\"].map({\"Sunday\":0, \"Monday\":1, \"Tuesday\":2, \"Wednesday\":3,\"Thursday\":4,\"Friday\":5,\"Saturday\":6}) #There are only 'FC' or 'IL' or 'DT' or 'MB'\nprint(df_all.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trainval = df_all.iloc[:df_trainval.shape[0]]\ndf_test = df_all.iloc[df_trainval.shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_col = [col for col in df_trainval.columns if col not in ['Id','Open Date']]\ndf_trainval = df_trainval[df_train_col]\ndf_test = df_test[df_train_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nclass Model1Xgb:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        xgb_params = {'objective': 'reg:squarederror', #binary:logistic #multi:softprob,\n                  'random_state': 10,\n                  #'eval_metric': 'rmse'\n                     }\n        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n        dvalid = xgb.DMatrix(va_x, label=va_y)\n        evals = [(dtrain, 'train'), (dvalid, 'eval')]\n        self.model = xgb.train(xgb_params, dtrain, num_boost_round=10000,early_stopping_rounds=50, evals=evals)\n\n    def predict(self, x):\n        data = xgb.DMatrix(x)\n        pred = self.model.predict(data)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nclass Model1lgb:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        lgb_params = {'objective': 'rmse',\n                  'random_state': 10,\n                  'metric': 'rmse'}\n        lgb_train = lgb.Dataset(tr_x, label=tr_y)\n        lgb_eval = lgb.Dataset(va_x, label=va_y,reference=lgb_train)\n        self.model = lgb.train(lgb_params, lgb_train, valid_sets=lgb_eval, num_boost_round=10000,early_stopping_rounds=50)\n\n    def predict(self, x):\n        pred = self.model.predict(x,num_iteration=self.model.best_iteration)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import catboost\nclass Model1catboost:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        #https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n        #catb = catboost.CatBoostClassifier(\n        catb = catboost.CatBoostRegressor(\n                                    iterations=10000, \n                                    use_best_model=True, \n                                    random_seed=10, \n                                    l2_leaf_reg=3,\n                                    depth=6,\n                                    loss_function=\"RMSE\",#\"CrossEntropy\",\n                                    #eval_metric = \"RMSE\", #'AUC',\n                                    #classes_coun=3\n                                  )\n        self.model = catb.fit(tr_x,tr_y,eval_set=(va_x,va_y),early_stopping_rounds=50)\n        print(self.model.score(va_x,va_y))\n    def predict(self, x):\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nfrom keras.callbacks import EarlyStopping\n\nclass Model1NN:\n\n    def __init__(self):\n        self.model = None\n        self.scaler = None\n    '''\n    def weight_variable(self,shape,name):\n        initial =tf.truncated_normal(shape,stddev=0.1)\n        return tf.Variable(initial, name=name)\n\n    def bias_variable(self,shape,name):\n        initial = tf.constant(0.1,shape=shape)\n        return tf.Variable(initial, name=name)\n    '''    \n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        \n        batch_size = 128\n        epochs = 10000\n        \n        tr_x = self.scaler.transform(tr_x)\n        va_x = self.scaler.transform(va_x)\n        \n        early_stopping =  EarlyStopping(\n                            monitor='val_loss',\n                            min_delta=0.0,\n                            patience=20,\n        )\n\n        model = Sequential()\n        model.add(Dense(32, activation='relu', input_shape=(tr_x.shape[1],)))\n        model.add(Dropout(0.5))\n        model.add(Dense(32, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(1, activation='sigmoid'))\n\n        model.compile(loss='mean_squared_error', #'categorical_crossentropy',#categorical_crossentropy\n                      optimizer='adam')\n\n        history = model.fit(tr_x, tr_y,\n                            batch_size=batch_size, epochs=epochs,\n                            verbose=1,\n                            validation_data=(va_x, va_y),\n                            callbacks=[early_stopping])\n        self.model = model\n\n    def predict(self, x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict_proba(x).reshape(-1)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVR\n\nclass Model1LinearSVR:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        #params = {\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n        self.model = LinearSVR(max_iter=1000,\n                               random_state=10,\n                               C = 1.0, #損失の係数（正則化係数の逆数）\n                               epsilon = 5.0\n                               \n                              )\n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\nclass Model1KernelSVR:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        #params = {\"kernel\":['rbf'],\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n        self.model = SVR(kernel='rbf',\n                         gamma='auto',\n                         max_iter=1000,\n                         C = 1.0, #損失の係数（正則化係数の逆数）\n                         epsilon = 5.0\n                         \n                              )\n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nclass Model1Lasso:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        self.model = Lasso(\n            alpha=1, #L1係数\n            fit_intercept=True,\n            )\n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nclass Model1Ridge:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        self.model = Ridge(\n                            alpha=1, #L2係数\n                              )\n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\n\nclass Model1ElasticNet:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        '''1 / (2 * n_samples) * ||y - Xw||^2_2\n        + alpha * l1_ratio * ||w||_1\n        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n       ref)  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n        '''\n        \n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        self.model = ElasticNet(\n            alpha=1, #L1係数\n            l1_ratio=0.5,\n                              )\n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nclass Model1RF:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        self.model = RandomForestRegressor(\n            max_depth=5,\n            n_estimators=100,\n            random_state=10,\n        )\n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nclass Model1KNN:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        #params = {\"kernel\":['rbf'],\"C\":np.logspace(0,1,params_cnt), \"epsilon\":np.logspace(-1,1,params_cnt)}\n        self.model = KNeighborsRegressor(n_neighbors=5,\n                                         #weights='uniform'\n                                        )\n        \n        self.model.fit(tr_x,tr_y)\n        \n    def predict(self,x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nclass Model2Linear:\n\n    def __init__(self):\n        self.model = None\n        self.scaler = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n        tr_x = self.scaler.transform(tr_x)\n        self.model = LinearRegression()\n        self.model.fit(tr_x, tr_y)\n\n    def predict(self, x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_cv(model, train_x, train_y, test_x):\n    preds = []\n    preds_test = []\n    va_idxes = []\n\n    kf = KFold(n_splits=4, shuffle=True, random_state=10)\n\n    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n        model.fit(tr_x, tr_y, va_x, va_y)\n        pred = model.predict(va_x)\n        preds.append(pred)\n        pred_test = model.predict(test_x)\n        preds_test.append(pred_test)\n        va_idxes.append(va_idx)\n\n    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n    va_idxes = np.concatenate(va_idxes)\n    preds = np.concatenate(preds, axis=0)\n    order = np.argsort(va_idxes)\n    pred_train = preds[order]\n\n    # テストデータに対する予測値の平均をとる\n    preds_test = np.mean(preds_test, axis=0)\n\n    return pred_train, preds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1a = Model1Xgb()\npred_train_1a, pred_test_1a = predict_cv(model_1a, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1b = Model1lgb()\npred_train_1b, pred_test_1b = predict_cv(model_1b, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1c = Model1NN()\npred_train_1c, pred_test_1c = predict_cv(model_1c, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1d = Model1LinearSVR()\npred_train_1d, pred_test_1d = predict_cv(model_1d, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1e = Model1KernelSVR()\npred_train_1e, pred_test_1e = predict_cv(model_1e, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1f = Model1catboost()\npred_train_1f, pred_test_1f = predict_cv(model_1f, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1g = Model1KNN()\npred_train_1g, pred_test_1g = predict_cv(model_1g, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1h = Model1Lasso()\npred_train_1h, pred_test_1h = predict_cv(model_1h, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1i = Model1Ridge()\npred_train_1i, pred_test_1i = predict_cv(model_1i, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1j = Model1ElasticNet()\npred_train_1j, pred_test_1j = predict_cv(model_1j, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1k = Model1RF()\npred_train_1k, pred_test_1k = predict_cv(model_1k, df_trainval, y_trainval, df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nprint(f'a LGBM mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1a):.4f}')\nprint(f'b XGBoostmean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1b):.4f}')\nprint(f'c MLP mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1c):.4f}')\nprint(f'd LinearSVR mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1d):.4f}')\nprint(f'e KernelSVR mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1e):.4f}')\nprint(f'f Catboost mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1f):.4f}')\nprint(f'g KNN mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1g):.4f}')\nprint(f'h Lasso mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1h):.4f}')\nprint(f'i Ridge mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1i):.4f}')\nprint(f'j ElasticNet mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1j):.4f}')\nprint(f'k RandomForest mean_absolute_error: {mean_absolute_error(y_trainval,pred_train_1k):.4f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a,\n                          'pred_1b': pred_train_1b,\n                          'pred_1c': pred_train_1c,\n                          #'pred_1d': pred_train_1d,\n                          'pred_1e': pred_train_1e,\n                          'pred_1f': pred_train_1f,\n                          'pred_1g': pred_train_1g,\n                          'pred_1h': pred_train_1h,\n                          'pred_1i': pred_train_1i,\n                          'pred_1j': pred_train_1j,\n                          'pred_1k': pred_train_1k,\n                         })\ntest_x_2 = pd.DataFrame({'pred_1a': pred_test_1a,\n                          'pred_1b': pred_test_1b,\n                          'pred_1c': pred_test_1c,\n                          #'pred_1d': pred_test_1d,\n                          'pred_1e': pred_test_1e,\n                          'pred_1f': pred_test_1f,\n                          'pred_1g': pred_test_1g,\n                          'pred_1h': pred_test_1h,\n                          'pred_1i': pred_test_1i,\n                          'pred_1j': pred_test_1j,\n                          'pred_1k': pred_test_1k\n                         })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = Model2Linear()\npred_train_2, pred_test_2 = predict_cv(model2, train_x_2, y_trainval, test_x_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'mean_absolute_error: {mean_absolute_error(y_trainval, pred_train_2):.4f}')\nprint('best a,b,c,e,f,g,h,i,j,k')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(test_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id':df_test['Id'],'Prediction':pred_test_2})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('./submission200214_fold４_10models.csv',index=False)\n!ls && pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}