{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option(\"max_columns\", None) #Showing only two columns\npd.set_option(\"max_rows\", None)\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!unzip -o /kaggle/input/restaurant-revenue-prediction/test.csv.zip\n!unzip -o /kaggle/input/restaurant-revenue-prediction/train.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/working/train.csv')\ndf_test = pd.read_csv('/kaggle/working/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train Dataset is very small compared to test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As per the description of the dataset,\n1. There are 42 independent variables and 1 dependent variable (revenue). \n2. ID column represents serial number so it may not have any significance in the desired target variable.\n3. 'Open Date', 'City', 'City Group', 'Type' columns are of datatype Object. Other columns are of type integer or float.\n4. There are no null values in the train dataset although we'll explore more insights."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Number of Unique Values in Each Feature\nprint('Total Number of Unique Values in Columns:')\nfor features in df_train:\n  if(features != 'revenue'):\n    print(str(features)+ ': (Datatype: ' + str(df_train[features].dtype) +') : ' + str(len(df_train[features].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorizing Discrete and Continuous Features w.r.t. column datatype (Discrete=>'Object' and Continuous=>'Integer and Float')\ndiscrete_features = [feature for feature in df_train.columns if df_train[feature].dtype == 'O']\ncontinuous_features = list(set(df_train.columns) - set(discrete_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(discrete_features)\nprint(continuous_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of Unique values of each continuous features\nfor i in continuous_features:\n    print('{} has unique values {}'.format(i,df_train[i].unique()),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although P1-P37 features are numeric in nature but values of these features are discrete."},{"metadata":{},"cell_type":"markdown","source":"## Missing Vaules Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"List of Missing Values in Train Dataset: \")\nprint(df_train.isnull().sum())\nprint(\"\\n\\nList of Missing Values in Test Dataset: \")\nprint(df_test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in the train or test dataset"},{"metadata":{},"cell_type":"markdown","source":"## Numerical Feature Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Numerical Variables with skewness\nfig = plt.figure(figsize=(12,18))\nfor i in range(len(continuous_features)):\n    fig.add_subplot(10,4,i+1)\n    sns.distplot(df_train[continuous_features[i]], kde_kws={'bw': 0.1})\n    plt.title('Skew : %.2f' % df_train[continuous_features[i]].skew())\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of the Target Variable (Revenue)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target Variable is positively skewed and there are some outliers present in the dataset. So we may have to transform the target variable when modelling."},{"metadata":{},"cell_type":"markdown","source":"## Discrete Feature Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating days open for each restaurant\n\ndf_train['Open Date'] = pd.to_datetime(df_train['Open Date'], format='%m/%d/%Y')   \ndf_test['Open Date'] = pd.to_datetime(df_test['Open Date'], format='%m/%d/%Y')\n\ndf_train['OpenDays']=\"\"\ndf_test['OpenDays']=\"\"\n\ndateLastTrain = pd.DataFrame({'Date':np.repeat(['01/01/2015'],[len(df_train)]) })\ndateLastTrain['Date'] = pd.to_datetime(dateLastTrain['Date'], format='%m/%d/%Y')  \ndateLastTest = pd.DataFrame({'Date':np.repeat(['01/01/2015'],[len(df_test)]) })\ndateLastTest['Date'] = pd.to_datetime(dateLastTest['Date'], format='%m/%d/%Y')  \n\ndf_train['OpenDays'] = dateLastTrain['Date'] - df_train['Open Date']\ndf_test['OpenDays'] = dateLastTest['Date'] - df_test['Open Date']\n\ndf_train['OpenDays'] = df_train['OpenDays'].astype('timedelta64[D]').astype(int)\ndf_test['OpenDays'] = df_test['OpenDays'].astype('timedelta64[D]').astype(int)\n\ndf_train = df_train.drop('Open Date', axis=1)\ndf_test = df_test.drop('Open Date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['City Group'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting values of cities\ndf_train['City'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"City column has too many discrete values which are not feasible to transform using One Hot Encoding because then the feature list will become big. So this feature need to be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop('City',axis=1)\ndf_test = df_test.drop('City',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# concat train and test data for feature engineering\ndf = pd.concat([df_train,df_test],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding of Categorical features in train and test dataset.\nohe_cols = ['City Group', 'Type']\nfor col in ohe_cols:\n    df = pd.concat([df, pd.get_dummies(df[col], prefix=col, drop_first=True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping categorical variables\ndf = df.drop('City Group', axis=1)\ndf = df.drop('Type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating Train and Test Dataset\ndf_train_pp = df.dropna(axis=0)\ndf_test_pp = df[df['revenue'].isna()]\ndf_test_pp = df_test_pp.drop('revenue', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train_pp.shape)\nprint(df_test_pp.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_pp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_pp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50, 50))\ncorr_mat = df_train_pp.corr()\nsns.heatmap(corr_mat, xticklabels = corr_mat.columns, yticklabels = corr_mat.columns, annot=True, cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = corr_mat.unstack()\nso = s.sort_values(kind=\"quicksort\").drop_duplicates()\n\n#0.1 to 0.3 Slightly Correlated\nres1 = so[so>=0.1]\nres1 = res1[res1<0.3]\nprint(res1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# o.4 to 0.6 is moderately correlated features\nres2 = so[so>=0.4]\nres2 = res2[res2<0.6]\nprint(res2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Above 0.6 is highly correlated features\nres3 = so[so>=0.6]\nprint(res3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features correlated with target variable \"Revenue\"\ncorr_mat['revenue'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating X and Y for Modelling by using mostly correllated features of target variable \"Revenue\"\n\nrelated_cols = ['OpenDays','P2','P28','P6','Type_FC','P21','City Group_Other','P29','P13','Type_IL']\nX = df_train_pp[related_cols]\n\n\n# As Target variable is skewed, log transformation is used to make it normal distribution\n\nY = np.log(df_train_pp.revenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Regressor\n\nmodel = RandomForestRegressor(n_estimators=150)\nmodel.fit(X, Y)\n\ntest_predicted = pd.DataFrame()\ntest_predicted['Id'] = df_test_pp.Id\n#test_predicted['Prediction'] = model.predict(df_test_pp.drop('Id', axis=1))\n#test_predicted['Prediction'] = model.predict(df_test_pp[topfeatures])\ntest_predicted['Prediction'] = np.exp(model.predict(df_test_pp[related_cols]))\ntest_predicted.to_csv('submission-rf-regressor.csv', index=False)\ntest_predicted.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBOOST Regressor\n\nmodel = xgb.XGBRegressor()\nmodel.fit(X, Y)\n\ntest_predicted = pd.DataFrame()\ntest_predicted['Id'] = df_test_pp.Id\n#test_predicted['Prediction'] = model.predict(df_test_pp.drop('Id', axis=1))\n#test_predicted['Prediction'] = model.predict(df_test_pp[topfeatures])\ntest_predicted['Prediction'] = np.exp(model.predict(df_test_pp[related_cols]))\ntest_predicted.to_csv('submission-xgb-regressor.csv', index=False)\ntest_predicted.describe()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}