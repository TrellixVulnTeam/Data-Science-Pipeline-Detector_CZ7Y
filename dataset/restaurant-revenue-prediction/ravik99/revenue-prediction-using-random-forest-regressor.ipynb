{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PROJECT : Restaurant revenue prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Submitted By:\n\nRAVI KUMAR (1BG18CS097);\n    YASH ASHOK AGRAWAL (1BG18CS127);\n    VISHAL (1BG18CS126);\n    RAJDEEP CHAUHAN (1BG18CS091);\n    SATYAM KESHERWANI (1BG18CS104);","execution_count":null},{"metadata":{"_uuid":"d9bafb46b282c49158684ced77385a1d19815f8e"},"cell_type":"markdown","source":"## 1. Importing required libraries","execution_count":null},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"49b85bf9cf77147e6659f4275ff2e869d0ac3627"},"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nimport numpy as np \nimport pandas as pd \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Reading Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData = pd.read_csv('../input/dataset/train.csv')\n\ntrainData.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a96bf8e625a699aa3886e33696480bf0a374286f"},"cell_type":"markdown","source":"## 3. Pre-Processing & Some Analysis <a name=\"pre\"></a>","execution_count":null},{"metadata":{"_uuid":"a900866dd13aacab4fecb3c2f560428f0d22eb32"},"cell_type":"markdown","source":"### Converting Open Date column to Open Days; day count of the restaurant since the beginning and dropping the Open Date Columns","execution_count":null},{"metadata":{"trusted":true,"_uuid":"722bd06c020aedd5f79b6a850fbef5e636bb456d"},"cell_type":"code","source":"trainData['Open Date'] = pd.to_datetime(trainData['Open Date'], format='%m/%d/%Y')   \ntrainData['OpenDays']=\"\"\n\ndateLastTrain = pd.DataFrame({'Date':np.repeat(['01/01/2018'],[len(trainData)]) })\ndateLastTrain['Date'] = pd.to_datetime(dateLastTrain['Date'], format='%m/%d/%Y')  \n\ntrainData['OpenDays'] = dateLastTrain['Date'] - trainData['Open Date']\ntrainData['OpenDays'] = trainData['OpenDays'].astype('timedelta64[D]').astype(int)\n\ntrainData = trainData.drop('Open Date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36539535fdfe869759f8d4435779d19729e15213"},"cell_type":"markdown","source":"### Comparing the revenues of big cities and other cities","execution_count":null},{"metadata":{"trusted":true,"_uuid":"27eacc7a17217d96c18d317ed98a52a9bc0f5ddb"},"cell_type":"code","source":"cityPerc = trainData[[\"City Group\", \"revenue\"]].groupby(['City Group'],as_index=False).mean()\n\nsns.barplot(x='City Group', y='revenue', data=cityPerc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3dc445a25a66f20a62b28f29d2409a1c6aff671"},"cell_type":"markdown","source":"# 4. Plots\n### Sorting the cities by revenue; getting the max earned cities","execution_count":null},{"metadata":{"trusted":true,"_uuid":"b76b5909dc39183bc2cec87f0c76418dc2d80e74"},"cell_type":"code","source":"cityPerc = trainData[[\"City\", \"revenue\"]].groupby(['City'],as_index=False).mean()\n\nnewDF = cityPerc.sort_values([\"revenue\"],ascending= False)\nsns.barplot(x='City', y='revenue', data=newDF.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b00ef2cd5c3ec60e21c4da401d2d6b5f9d8d6a5"},"cell_type":"code","source":"cityPerc = trainData[[\"City\", \"revenue\"]].groupby(['City'],as_index=False).mean()\nnewDF = cityPerc.sort_values([\"revenue\"],ascending= True)\nsns.barplot(x='City', y='revenue', data=newDF.head(10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71c4bdd6b340cd8da560cccd9fad485c518385b9"},"cell_type":"markdown","source":"### Getting an insight of which restaurant type earns more","execution_count":null},{"metadata":{"trusted":true,"_uuid":"8be5860dd3f012dd4d1832a7243986ea035b9ade"},"cell_type":"code","source":"cityPerc = trainData[[\"Type\", \"revenue\"]].groupby(['Type'],as_index=False).mean()\nsns.barplot(x='Type', y='revenue', data=cityPerc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db7674ea44b25311fea241fdb9733fb0452c16cd"},"cell_type":"markdown","source":"### Plot about working days of specific restaurant types","execution_count":null},{"metadata":{"trusted":true,"_uuid":"8588979a16f54ccf67887499fa223f4dab938564"},"cell_type":"code","source":"cityPerc = trainData[[\"Type\", \"OpenDays\"]].groupby(['Type'],as_index=False).mean()\nsns.barplot(x='Type', y='OpenDays', data=cityPerc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f37ee62d3b4bddf516668bae5952b416e410679f"},"cell_type":"markdown","source":"### Dropping the Id and Type columns since they are irrevelant for our predictions","execution_count":null},{"metadata":{"trusted":true,"_uuid":"001297e2fd8a83237c00572a7d0927d801eb7f5f"},"cell_type":"code","source":"trainData = trainData.drop('Id', axis=1)\ntrainData = trainData.drop('Type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0759726836d04e3020ed6e3dd5490d7d76fb6ba"},"cell_type":"markdown","source":"### Creating dummy variables to represent City Groups. After doing dummy variables for City Group we dropped it","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5b5df0d937608e966497a0717f847af71a211b78"},"cell_type":"code","source":"citygroupDummy = pd.get_dummies(trainData['City Group'])\ntrainData = trainData.join(citygroupDummy)\n\n\ntrainData = trainData.drop('City Group', axis=1)\n\ntrainData = trainData.drop('City', axis=1)\n\ntempRev = trainData['revenue']\ntrainData = trainData.drop('revenue', axis=1)\n\n\ntrainData = trainData.join(tempRev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"607259e6bae618e72252d8ef445f0bba25b7accf"},"cell_type":"code","source":"trainData.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45ab4acb047f744febffd87f3eb97c75b5ba3f03"},"cell_type":"markdown","source":"# 5. Train and  Test Split for RandomForestClassifier <a name=\"class\"></a>\n\n### Using SKLEARN's train test split library for splitting train data","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5acd4312ce5a1c4497f1dcab721e04114fbb3196"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX, y = trainData.iloc[:, 1:40].values, trainData.iloc[:, 40].values\n\nX_trainForBestFeatures, X_testForBestFeatures, y_trainForBestFeatures, y_testForBestFeatures =\\\n    train_test_split(X, y, \n                     test_size=0.3, \n                     random_state=0, \n                )\n    \nX_trainForBestFeatures.shape, X_testForBestFeatures.shape, y_trainForBestFeatures.shape, y_testForBestFeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffd793db1cd030b061b7a41174f66e2438dc102e"},"cell_type":"code","source":"y[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"397802ac051095a80b0bca156b9879376eb3e2ac"},"cell_type":"code","source":"y_trainForBestFeatures[:20]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3e6b582601bd2c5b26c15b41033e94c838f39da"},"cell_type":"markdown","source":"### For finding best features among others. We used random forest classifier in order to get the best features. We observed that using the first 19 features give us the best results","execution_count":null},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b90bf7ab1864355ce684ac141abd4925f38aa374"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n#To label our features form best to wors \nfeat_labels = trainData.columns[1:40]\n\nforest = RandomForestClassifier(n_estimators=500,\n                                random_state=1)\nforest.fit(X_trainForBestFeatures, y_trainForBestFeatures)\n\n\n\nimportances = forest.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n\nfor f in range(X_trainForBestFeatures.shape[1]):\n    print(\"%2d) %-*s %f\" % (f + 1, 30, \n                            feat_labels[indices[f]], \n                            importances[indices[f]]))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fb5fc33c747989ffa029532e54ab347490d1450"},"cell_type":"markdown","source":"### Plotting the importance of the features in a barplot","execution_count":null},{"metadata":{"trusted":true,"_uuid":"8b53f1340901002a85f51816d57751c1b892ebc7"},"cell_type":"code","source":"plt.title('Feature Importance')\nplt.bar(range(X_trainForBestFeatures.shape[1]), \n        importances[indices],\n        align='center')\n\nplt.xticks(range(X_trainForBestFeatures.shape[1]), \n           feat_labels[indices], rotation=90)\nplt.xlim([-1, X_trainForBestFeatures.shape[1]])\nplt.tight_layout()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a6a07c3722b6c068d40a32bc6568c468dcaa417"},"cell_type":"code","source":"trainData[feat_labels[indices[0:39]]].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"064455a70cfd2af6349410700500e519a60bb624"},"cell_type":"markdown","source":"### We take the natural logarithm of the OpenDays column in order to make it more easy for model to predict","execution_count":null},{"metadata":{"trusted":true,"_uuid":"ad7006a7aa5b3605bdf3d2b94b6f6dcb50a98570"},"cell_type":"code","source":"import numpy as numpy \nopenDaysLog = trainData[feat_labels[indices[0:1]]].apply(numpy.log)\nopenDaysLog.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dbef664a2bbb74ed4e8fff291e7033e8e7cdf95"},"cell_type":"markdown","source":"### Test and Train model created over best 19 features.\n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"8ba1466df5cf70b0a321b7b7ed94f8e76f64cafb"},"cell_type":"code","source":"bestDataFeaturesTrain = trainData[feat_labels[indices[1:19]]]\n\n#insert after takeing log of OpenDays feature.\nbestDataFeaturesTrain.insert(loc=0, column='OpenDays', value=openDaysLog)\n\nbestDataFeaturesTrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc1ce2ad2f62635e5902e9f093db428a23a36e6b"},"cell_type":"markdown","source":"# 6. Model will predict output by using best 19 features.\ntrain_test_split method of sklearn is used to split data into %30 of Test and %70 of Train data","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5062323b2062f971f869172503770551fc653f65"},"cell_type":"code","source":"# take the natural logarithm of the 'revenue' column in order to make it more easy for model to predict\ny = trainData['revenue'].apply(numpy.log)\n\nfrom sklearn.model_selection import train_test_split\n\nX, y = trainData.iloc[:, 1:40].values, trainData.iloc[:, 40].values\n\nX_train, X_test, y_train, y_test =\\\n    train_test_split(bestDataFeaturesTrain, y, \n                     test_size=0.3, \n                     random_state=0, \n                )\n\n\n\n    \nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60dba26417005e88431b61ed74650d65a65f1ca5"},"cell_type":"markdown","source":"# 7. Standardize features by removing the mean and scaling to unit variance\n<a name=\"std\"></a>\n### Standart Scaling for model efficiency","execution_count":null},{"metadata":{"trusted":true,"_uuid":"f7aaf1df8b4fb9ff104f516973a9c676a3df9ce4"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler(with_std  = True ,with_mean = True, copy = True)\nX_train_std = sc.fit_transform(X_train)\nX_test_std = sc.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18cb503857a98dc2be1add4dfbf1875b99980cc0"},"cell_type":"code","source":"X_train_std[:1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fca71555cfefd7530608b715a0480e9574edd49b"},"cell_type":"markdown","source":"# 8. PCA is used due to dimension reduction <a name=\"pca\"></a>\n### Applied PCA in order to make it more efficient and reducing te dimentions","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5f2de055d5d3ceba0c9ba1e750cfec8e2d2dc627"},"cell_type":"code","source":"from sklearn.decomposition import PCA,KernelPCA\n\npca = PCA(n_components=2,svd_solver='full')\nX_train_pca = pca.fit_transform(X_train_std)\nX_test_pca = pca.transform(X_test_std)\npca.explained_variance_ratio_\n\nkpca = KernelPCA(kernel=\"rbf\", gamma=1)\nX_kpca_train = kpca.fit_transform(X_train_pca)\nX_kpca_test = kpca.transform(X_test_pca)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f8b3680493234b2596dfd7432713e03ce93bfa2"},"cell_type":"markdown","source":"# 9. RBF is applied for linearity (since we have non-linear data) <a name=\"rbf\"></a>\n\n### After RBF, increase in sample variance can be observed (blue plot)","execution_count":null},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"2cfaeaeaeaead3b2362d0f3947d653a016eacc9b"},"cell_type":"code","source":"X_train_pca[:1]\nfig, ax = plt.subplots(nrows=1,ncols=2, figsize=(10,5))\nax[0].scatter(X_train_pca[:, 0], X_train_pca[:, 1],color='red',marker='o')\nax[1].scatter(X_kpca_train[:, 0], X_kpca_train[:, 1])\nax[0].set_xlabel('Before RBF')\nax[1].set_yticks([])\nax[1].set_xlabel('After RBF')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"649612ca79fd404ba647093534fa487abdd1bebe"},"cell_type":"code","source":"X_test_pca[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97d030d8f8cd4a7b358a40fe81feccd9f00bb81a"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"e1954834cb8f05dd31d9b2a61dafd111eda4a75a"},"cell_type":"code","source":"X_train_std[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a686f94c9fefde1c4a437f4f8a50d31a7121c38"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b50d1e4c02e68e10780738d6634c5e2ea1198f41"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"666d0443e205682dcb2531264360e9e36298924a"},"cell_type":"code","source":"y_test[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"906cf64d83b8bcf8703cf46c0d6ee07bc7077178"},"cell_type":"markdown","source":"# 10. RandomForestRegressor is used to predict \"revenues\" <a name=\"rnd\"></a>\n\n### Finally after pre-processing now we can begin to predict with RandomForestRegressor.\n\n#### Our model works on 86% accuracy.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"44444bfb59967eaa7a449e8e8fd4300931628e4b"},"cell_type":"code","source":"\nimport numpy\nfrom sklearn import linear_model\ncls = RandomForestRegressor(n_estimators=250, criterion='mse', max_depth=30)#cls = RandomForestRegressor(n_estimators=150)\n\ncls.fit(X_kpca_train, y_train)#We are training the model with RBF'ed data\n\nscoreOfModel = cls.score(X_kpca_train, y_train)\n\n\nprint(\"Score is calculated as: \",scoreOfModel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f79693128f84d354b988bc9450ee34dc40fc35bd"},"cell_type":"code","source":"pred = cls.predict(X_kpca_test)\n\npred","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}