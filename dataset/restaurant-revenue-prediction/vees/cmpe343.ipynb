{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"14c634607c1c625455e01c295bc4438cd7b787b6"},"cell_type":"code","source":"#CMPE353-FinalProject\n#Bihter Ã‡AKAL\n#Veyis Egemen ERDEN","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n#dropped id \ntrain = train.drop('Id', axis=1)\ntest = test.drop('Id', axis=1)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"83ca200b77c629389203bbf3cd740b9182643565"},"cell_type":"code","source":"#The section we used to calculate how many years ago the restaurant was opened.\n#converted opendate format for to process\ntrain['Open Date'] = pd.to_datetime(train['Open Date'], format='%m/%d/%Y')\n#Train dataFrame\ndateLastTrain = pd.DataFrame({'Date':np.repeat(['05/19/2018'],[len(train)]) })\ndateLastTrain['Date'] = pd.to_datetime(dateLastTrain['Date'], format='%m/%d/%Y')\n#converted day to year\ntrain['Years'] = (dateLastTrain['Date'] - train['Open Date']) / 365\ntrain['Years'] = train['Years'].astype('timedelta64[D]').astype(int)\n#we do not need Open Date column anymore.           \ntrain = train.drop('Open Date', axis=1)\n\n#Test dataFrame\ntest['Open Date'] = pd.to_datetime(test['Open Date'], format='%m/%d/%Y')\ntest['Years']=\"\"\n#converted day to year\ndateLastTest = pd.DataFrame({'Date':np.repeat(['05/19/2018'],[len(test)]) })\ndateLastTest['Date'] = pd.to_datetime(dateLastTest['Date'], format='%m/%d/%Y')  \n        \ntest['Years'] = (dateLastTest['Date'] - test['Open Date']) / 365\ntest['Years'] = test['Years'].astype('timedelta64[D]').astype(int)\n#we do not need Open Date column anymore.                      \ntest = test.drop('Open Date', axis=1)\n\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a05726c4eae5fce82099eb55ac615fbae462ed78"},"cell_type":"code","source":"#converted categorical data to numaric data for process.\n#Train dataframe\ncityGrouptoNumaricTypeTrain = pd.get_dummies(train['City Group'])\ntrain = train.join(cityGrouptoNumaricTypeTrain)\n#Test dataframe\ncityGrouptoNumaricTypeTest = pd.get_dummies(test['City Group'])\ntest = test.join(cityGrouptoNumaricTypeTest)\n\ntrain = train.drop('City Group', axis=1)\ntest = test.drop('City Group', axis=1)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dec540d6b2c739607bbd294db1906dd32e792559"},"cell_type":"code","source":"#converted categorical data to numaric data for process.\n#Train dataframe\ncityTypetoNumaricTypeTrain = pd.get_dummies(train['Type'])\ntrain = train.join(cityTypetoNumaricTypeTrain)\n\ntrain = train.drop('Type', axis=1)\n#Test dataframe\ncityTypetoNumaricTypeTest = pd.get_dummies(test['Type'])\ntest = test.join(cityTypetoNumaricTypeTest)\n\ntest = test.drop('Type', axis=1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f5c8574a1e38804ce7c329bbf2545c4be0cb87ce"},"cell_type":"code","source":"#Standardization Features we use for features P-1 to P-37 and the points of the properties are summed and written as a new column\nfrom sklearn import preprocessing\n\n#Train dataFrame\nx = train.iloc[:, 1:38] #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x).sum(axis=1) \ntrain['sumOfFeatures']= x_scaled\n\n#Test dataFrame\nx = test.iloc[:, 1:38] #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\ny_scaled = min_max_scaler.fit_transform(x).sum(axis=1) \ntest['sumOfFeatures']= y_scaled\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3bc0c9b5e529714f6078cf326930cd3afd94c4e8"},"cell_type":"code","source":"import seaborn as sns\n#the earnings of restaurants according to their age.\nyearRevenue = train[[\"Years\",\"revenue\"]].groupby(['Years'],as_index=False).mean()\ndata = yearRevenue.sort_values([\"revenue\"],ascending= False)\nsns.barplot(x='Years', y='revenue', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e8260a992071162cdfaa887ee10afd375e6ae560"},"cell_type":"code","source":"#the earnings of restaurants according to where the restaurants are.\ncityRevenue = train[[\"City\",\"revenue\"]].groupby(['City'],as_index=False).mean()\ndata = cityRevenue.sort_values([\"revenue\"],ascending= False)\n#the first six\nsns.barplot(x='City', y='revenue', data=data.head(6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a69f12ccb04903f72c3c438e686707247fa2403e"},"cell_type":"code","source":"#the last six\nsns.barplot(x='City', y='revenue', data=data.tail(6)).invert_xaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"53f9d20726a743876716f0fc678e7314936b2e02"},"cell_type":"code","source":"#Normalized\n#from sklearn import preprocessing\n\n\n#x = train.iloc[:, 1:38]\n\n#X_normalized = preprocessing.Normalizer().fit(x) \n#train.loc[:,'ColumnA']= X_normalized.transform(x).sum(axis=1) \n\n#y = test.iloc[:, 1:38]\n#y_normalized = preprocessing.Normalizer().fit(y) \n#test.loc[:,'ColumnA']= y_normalized.transform(y).sum(axis=1) \n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fdf603ddcab9fbfa3fb2629b54c9c4f1cc77faf0"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nimport matplotlib.pyplot as plt\n\n#created dataframe with Year,(FC,IL)Type,ColumnA(sum of features P-1 to P-37),Big Cities,Other\nimport numpy\nxTrain = pd.DataFrame({'Years':train['Years'],'FC':train['FC'],'IL':train['IL'],'sumOfFeatures':train['sumOfFeatures'],\n                      'Big Cities':train['Big Cities'], 'Other':train['Other']})\n\nyTrain = train['revenue'].apply(numpy.log)\nxTest = pd.DataFrame({'Years':test['Years'],'FC':test['FC'],'IL':test['IL'],'sumOfFeatures':test['sumOfFeatures'],\n                      'Big Cities':test['Big Cities'], 'Other':test['Other']})\n\n\n#create model estimators 230 it works better\ncls = RandomForestRegressor(n_estimators=230)\ncls.fit(xTrain, yTrain)\n\npred = cls.predict(xTest)\n\npred = numpy.exp(pred)\n\ncls.score(xTrain, yTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"df0db2d6c84a064cd6a10971928140246b823ed6"},"cell_type":"code","source":"test['revenue']=pred.astype(int)\ntest.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}