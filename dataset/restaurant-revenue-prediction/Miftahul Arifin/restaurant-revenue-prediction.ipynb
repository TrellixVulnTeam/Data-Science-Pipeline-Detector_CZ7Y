{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Restaurant Revenue Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Outline\n1. Import Libraries\n2. Load Data\n3. Exploratory Data Analysis\n<br>&nbsp;3.1 Preliminary Observations\n<br>&nbsp;3.2 Exploring Numerical Data\n<br>&nbsp;3.3 Exploring Categorical Data\n4. Data Cleaning and Preprocessing\n<br>&nbsp;4.1 Handling Skew\n5. Feature Selection and Engineering\n<br>&nbsp;5.1 Feature Selection\n<br>&nbsp;5.2 Feature Engineering\n6. Modelling\n<br>&nbsp;6.1 Cross Validate Model\n<br>&nbsp;6.2 Hyperparameter Tuning\n<br>&nbsp;6.3 Learning Curves\n<br>&nbsp;6.4 Feature Importance\n7. Prediction\n<br>&nbsp;7.1 Preprocess Data Test\n<br>&nbsp;7.2 Predict","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Import Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Core\nimport pandas as pd\nimport numpy as np\n\n# Data Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npd.options.display.max_columns = None\npd.options.display.max_rows = 80\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Load Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '/kaggle/input/restaurantrevenue/train.csv'\ntest_path = '/kaggle/input/restaurantrevenue/test.csv'\n\ndata_train = pd.read_csv(train_path)\ndata_test = pd.read_csv(test_path)\nIDtest = data_test['Id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Data fields**\n- **Id :** Restaurant id. \n- **Open Date :** opening date for a restaurant\n- **City :** City that the restaurant is in. Note that there are unicode in the names. \n- **City Group :** Type of the city. Big cities, or Other. \n- **Type :** Type of the restaurant. FC: Food Court, IL: Inline, DT: Drive Thru, MB: Mobile\n- **P1, P2 - P37 :** There are three categories of these obfuscated data. Demographic data are gathered from third party providers with GIS systems. These include population in any given area, age and gender distribution, development scales. Real estate data mainly relate to the m2 of the location, front facade of the location, car park availability. Commercial data mainly include the existence of points of interest including schools, banks, other QSR operators.\n- **Revenue :** The revenue column indicates a (transformed) revenue of the restaurant in a given year and is the target of predictive analysis. Please note that the values are transformed so they don't mean real dollar values. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Preliminary Observations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerical columns\nnum_col = data_train.select_dtypes(exclude=['object']).drop(['Id'], axis=1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical columns\ncat_col = data_train.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Exploring Numerical Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe data train\ndata_train[num_col].describe().round(decimals=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot skew\nfig = plt.figure(figsize=(12,18))\nfor i in range(len(num_col)):\n    fig.add_subplot(10,4,i+1)\n    sns.distplot(data_train[num_col[i]], kde_kws={'bw': 0.1})\n    plt.title('Skew : %.2f' % data_train[num_col[i]].skew())\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Revenue with log\nsns.distplot(np.log(data_train['revenue']))\nplt.title('Skew : %.2f' % np.log(data_train['revenue']).skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes : Revenue could be log transformed**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis - boxplot\nfig = plt.figure(figsize=(12,18))\nfor i in range(len(num_col)):\n    fig.add_subplot(10,4,i+1)\n    sns.boxplot(y=data_train[num_col[i]])\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bivariate analysis - scatterplot\nfig = plt.figure(figsize=(12,18))\nfor i in range(len(num_col)):\n    fig.add_subplot(10,4,i+1)\n    sns.scatterplot(data_train[num_col[i]], data_train['revenue'])\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation\ncorrelation = data_train[num_col].corr()\n\nf, ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation of numerical attributes', size=16)\nsns.heatmap(correlation)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation['revenue'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes: Pick correlated features (P2, P28, P6, P13, P29)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing value\ndata_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Exploring Categorical Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train[cat_col].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bivariate analysis - box plot\nf, ax = plt.subplots(figsize=(12,8))\nsns.boxplot(y=data_train['revenue'], x=data_train['Type'])\nplt.xticks(rotation=40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bivariate analysis - box plot\nf, ax = plt.subplots(figsize=(12,8))\nsns.boxplot(y=data_train['revenue'], x=data_train['City Group'])\nplt.xticks(rotation=40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform Open date to age\nfrom datetime import datetime\n\ndef count_years(open_date):\n    date_parse = datetime.strptime(open_date, '%m/%d/%Y')\n    date_now = datetime.now()\n    return date_now.year - date_parse.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"open_years = []\nfor i in data_train['Open Date']:\n    open_years.append(count_years(i))\n\ndf_open_years = pd.DataFrame({ 'open_years' : open_years } )\ngroup_years = df_open_years['open_years'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Barplot open years\nsns.barplot(x=group_years.index, y=group_years.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes : Feature transform Open Year -> value years from now**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# City\ncity_most = data_train['City'].value_counts()[data_train['City'].value_counts() > 2].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_transform = []\n\nfor i in data_train['City']:\n    if i in city_most:\n        city_transform.append(i)\n    else:\n        city_transform.append('other')\n        \ndf_city_transform = pd.DataFrame({ 'city_transform' : city_transform } )\ngroup_city = df_city_transform['city_transform'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Barplot cgroup city\nsns.barplot(x=group_city.index, y=group_city.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes : Transform city less than 2 to other**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> All Notes for Data Cleaning and Preprocessing\n- Handle skew : Revenue could be log transformed\n- Feature Selection : Pick correlated features (P2, P28, P6, P13, P29)\n- Feature Engineering : Transform  Open Year -> value years from now\n- Feature Engineering : Transform city less than 2 to other\n- No missing value and outlier to be handled","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Cleaning and Preprocessing\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Handling Skew","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_copy = data_train.copy()\ndata_train_copy['revenue_log'] = np.log(data_train_copy['revenue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_copy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Feature Selection and Engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_corr = data_train_copy.corr()\nplt.figure(figsize=(12,10))\nsns.heatmap(transformed_corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Feature Selection\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"attr_select = ['Open Date', 'City', 'City Group', 'Type', 'P2', 'P6', 'P13', 'P28', 'P29', 'revenue_log']\ntrain_select = data_train_copy[attr_select]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.2 Feature Engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform Open Year\nopen_years = []\nfor i in train_select['Open Date']:\n    open_years.append(count_years(i))\n    \ndf_open_years = pd.DataFrame({ 'open_years' : open_years } )\ngroup_years = df_open_years['open_years'].value_counts()\n\n# Transform City\ncity_most = train_select['City'].value_counts()[train_select['City'].value_counts() > 2].index\ncity_transform = []\n\nfor i in train_select['City']:\n    if i in city_most:\n        city_transform.append(i)\n    else:\n        city_transform.append('other')\n        \ndf_city_transform = pd.DataFrame({ 'city_transform' : city_transform } )\ngroup_city = df_city_transform['city_transform'].value_counts()\n\ntrain_final = pd.concat([train_select, df_open_years, df_city_transform], axis=1).drop(['Open Date', 'City'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprare data\nX = train_final.drop(['revenue_log'], axis=1)\ny = train_final['revenue_log']\n\nX = pd.get_dummies(X)\n\nX = np.array(X)\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.1 Cross Validate Model\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 2\nclassifiers = []\nclassifiers.append(Lasso(random_state=random_state))\nclassifiers.append(LinearRegression())\nclassifiers.append(Ridge(random_state=random_state))\nclassifiers.append(ElasticNet(random_state=random_state))\nclassifiers.append(KNeighborsRegressor())\nclassifiers.append(SVR())\nclassifiers.append(RandomForestRegressor(random_state=random_state))\nclassifiers.append(GradientBoostingRegressor())\nclassifiers.append(AdaBoostRegressor(random_state = random_state))\nclassifiers.append(DecisionTreeRegressor())\nclassifiers.append(XGBRegressor())\n\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X, y, scoring='neg_mean_squared_error', cv =10, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"Lasso\",\"LinearRegression\",\"Ridge\",\n\"ElasticNet\",\"KNeighborsRegressor\",\"SVR\",\"RandomForestRegressor\",\"GradientBoostingRegressor\",\"AdaBoostRegressor\",\"DecisionTreeRegressor\", \"XGBRegressor\"]})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_res.sort_values(ascending=False, by='CrossValMeans')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes: best model SVR, AdaBoostRegressor (ABR), RandomForestRegressor (RFR), KNeighborsRegressor(KNR), GradientBoosting Regressor (GBR)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 6.2 Hyperparameter Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVR\nmodel = SVR()\n\n# Search grid for optimal parameters\nex_param_grid = {\n    'kernel': ['rbf'],\n    'gamma': [1e-4, 1e-3, 0.01, 0.1],\n    'C': [1, 10, 100]\n}\n\ngsSVR = GridSearchCV(model, \n                     param_grid = ex_param_grid, \n                     cv=10, \n                     scoring=\"neg_mean_squared_error\")\n\ngsSVR.fit(X, y)\nSVR_best = gsSVR.best_estimator_\n\n# Best score\nprint('SVR')\nprint('Best score : ', gsSVR.best_score_)\nprint('Best params : ', gsSVR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoostRegressor\nmodel = AdaBoostRegressor(random_state = random_state)\n\n# Search grid for optimal parameters\nex_param_grid = {\n    'n_estimators': [50, 100],\n    'learning_rate' : [0.01,0.05,0.1,0.3,1],\n    'loss' : ['linear', 'square', 'exponential']\n}\n\ngsABR = GridSearchCV(model, \n                     param_grid = ex_param_grid, \n                     cv=10, \n                     scoring=\"neg_mean_squared_error\")\n\ngsABR.fit(X, y)\nABR_best = gsABR.best_estimator_\n\n# Best score\nprint('ABR')\nprint('Best score : ', gsABR.best_score_)\nprint('Best params : ', gsABR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestRegressor\nmodel = RandomForestRegressor(random_state = random_state)\n\n# Search grid for optimal parameters\nex_param_grid = {\n    'n_estimators'      : [10,20,30,40,50],\n    'max_features'      : [\"auto\", \"sqrt\", \"log2\"],\n    'min_samples_split' : [2,4,8,10,12,14,16]\n}\n\ngsRFR = GridSearchCV(model, \n                     param_grid = ex_param_grid, \n                     cv=10, \n                     scoring=\"neg_mean_squared_error\")\n\ngsRFR.fit(X, y)\nRFR_best = gsRFR.best_estimator_\n\n# Best score\nprint('RFR')\nprint('Best score : ', gsRFR.best_score_)\nprint('Best params : ', gsRFR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNeighborsRegressor\nmodel = KNeighborsRegressor()\n\n# Search grid for optimal parameters\nex_param_grid = {\n    'n_neighbors': [4,6,8,10],\n    'leaf_size': [30,40,50,60],\n    'weights': ['uniform','distance']\n}\n\ngsKNR = GridSearchCV(model, \n                     param_grid = ex_param_grid, \n                     cv=10, \n                     scoring=\"neg_mean_squared_error\")\n\ngsKNR.fit(X, y)\nKNR_best = gsKNR.best_estimator_\n\n# Best score\nprint('KNR')\nprint('Best score : ', gsKNR.best_score_)\nprint('Best params : ', gsKNR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GradientBoostingRegressor\nmodel = GradientBoostingRegressor(random_state = random_state)\n\n# Search grid for optimal parameters\nex_param_grid = {\n    'learning_rate': [0.25, 0.1, 0.05, 0.01],\n    'n_estimators': [50,100,200,300],\n    'max_depth': [3,5,7]\n}\n\ngsGBR = GridSearchCV(model, \n                     param_grid = ex_param_grid, \n                     cv=10, \n                     scoring=\"neg_mean_squared_error\")\n\ngsGBR.fit(X, y)\nGBR_best = gsGBR.best_estimator_\n\n# Best score\nprint('GBR')\nprint('Best score : ', gsGBR.best_score_)\nprint('Best params : ', gsGBR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.3 Learning Curves","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = plot_learning_curve(SVR_best,\"SVR\",X, y,cv=10)\ng = plot_learning_curve(ABR_best,\"AdaBoost\",X, y,cv=10)\ng = plot_learning_curve(RFR_best,\"RandomForest\",X, y,cv=10)\ng = plot_learning_curve(KNR_best,\"KNeighbors\",X, y,cv=10)\ng = plot_learning_curve(GBR_best,\"GradientBoosting\",X, y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.4 Feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot Feature Importance of Random Forest\n\nplt.figure(figsize=(10,10))\nnames_classifiers = [(\"RFR\",RFR_best)]\nnclassifier = 0\nname = names_classifiers[nclassifier][0]\nclassifier = names_classifiers[nclassifier][1]\nindices = np.argsort(classifier.feature_importances_)[::-1][:40]\n\ntrain_dummies = pd.get_dummies(train_final.drop(['revenue_log'], axis=1))\n\ng = sns.barplot(y=train_dummies.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h')\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=12)\ng.tick_params(labelsize=9)\ng.set_title(name + \" feature importance\")   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot Feature Importance of Gradient Boosting\n\nplt.figure(figsize=(10,10))\nnames_classifiers = [(\"GBR\",GBR_best)]\nnclassifier = 0\nname = names_classifiers[nclassifier][0]\nclassifier = names_classifiers[nclassifier][1]\nindices = np.argsort(classifier.feature_importances_)[::-1][:40]\n\ntrain_dummies = pd.get_dummies(train_final.drop(['revenue_log'], axis=1))\n\ng = sns.barplot(y=train_dummies.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h')\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=12)\ng.tick_params(labelsize=9)\ng.set_title(name + \" feature importance\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Prediction\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 7.1 Preprocess Data Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attr_select = ['Open Date', 'City', 'City Group', 'Type', 'P2', 'P6', 'P13', 'P28', 'P29']\ntest_select = data_test[attr_select]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform Open Year\nopen_years = []\nfor i in test_select['Open Date']:\n    open_years.append(count_years(i))\n    \ndf_open_years = pd.DataFrame({ 'open_years' : open_years } )\ngroup_years = df_open_years['open_years'].value_counts()\n\n# Transform City\ncity_most = train_select['City'].value_counts()[train_select['City'].value_counts() > 2].index\ncity_transform = []\n\nfor i in test_select['City']:\n    if i in city_most:\n        city_transform.append(i)\n    else:\n        city_transform.append('other')\n        \ndf_city_transform = pd.DataFrame({ 'city_transform' : city_transform } )\ngroup_city = df_city_transform['city_transform'].value_counts()\n\ntest_final = pd.concat([test_select, df_open_years, df_city_transform], axis=1).drop(['Open Date', 'City'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.get_dummies(test_final).drop(['Type_MB'], axis=1)\ntest = pd.get_dummies(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.2 Predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_type_SVR = pd.Series(SVR_best.predict(test), name=\"SVR\")\ntest_type_ABR = pd.Series(ABR_best.predict(test), name=\"ABR\")\ntest_type_RFR = pd.Series(RFR_best.predict(test), name=\"RFR\")\ntest_type_KNR = pd.Series(KNR_best.predict(test), name=\"KNR\")\ntest_type_GBR = pd.Series(GBR_best.predict(test), name=\"GBR\")\n\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_type_SVR, test_type_ABR, test_type_RFR, test_type_KNR, test_type_GBR],axis=1)\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Voting Regressor\nfrom sklearn.ensemble import VotingRegressor\n\nvotingR = VotingRegressor(estimators=[('svr', SVR_best), ('abr', ABR_best),\n('gbr', GBR_best), ('rfr', RFR_best), ('knr', KNR_best)], n_jobs=4)\n\nvotingR = votingR.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test = pd.Series(np.exp(votingR.predict(test)), name=\"Prediction\")\nresults = pd.concat([IDtest, predict_test],axis=1)\nresults.to_csv(\"my_prediction.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}