{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installing modin for pandas query acceleration:-\n!pip install modin;\n\n# General imports:-\nimport numpy as np;\nfrom scipy.stats import iqr, mode, kurtosis;\nfrom termcolor import colored;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\nfrom gc import collect;\n\nimport matplotlib.pyplot as plt;\n%matplotlib inline\nimport seaborn as sns;\n\n# Using pandas modin extension:-\nfrom pandas import DataFrame, merge as pdmerge;\nimport modin.pandas as pd;\nfrom ray import init;\ninit(ignore_reinit_error=True);\n\npd.set_option(\"precision\", 4);","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:01:09.70585Z","iopub.execute_input":"2022-05-09T19:01:09.706533Z","iopub.status.idle":"2022-05-09T19:01:28.057535Z","shell.execute_reply.started":"2022-05-09T19:01:09.706478Z","shell.execute_reply":"2022-05-09T19:01:28.055994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model specifics:-\nfrom sklearnex import patch_sklearn;\npatch_sklearn()\n\nfrom sklearn_pandas import gen_features, DataFrameMapper;\nfrom sklearn.base import TransformerMixin, BaseEstimator;\nfrom sklearn.pipeline import Pipeline, make_pipeline;\nfrom sklearn.preprocessing import FunctionTransformer, RobustScaler, StandardScaler;\nfrom sklearn.feature_selection import SequentialFeatureSelector as SFS;\nfrom sklearn.model_selection import GroupKFold, cross_val_score;\nfrom sklearn.metrics import roc_auc_score, roc_curve;\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier as HGBMC;","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:02:18.331553Z","iopub.execute_input":"2022-05-09T19:02:18.332717Z","iopub.status.idle":"2022-05-09T19:02:19.438269Z","shell.execute_reply.started":"2022-05-09T19:02:18.332663Z","shell.execute_reply":"2022-05-09T19:02:19.437624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tabular Playground Series- April 2022:- \n\nThis is a time series classification involving 13 sensor readings along nearly 26,000 training sequences on 671 training subjects to elicit the biological state as a classification/ prediction. Each sequence contains 60 steps (1 min totally and 1 step per second) to elicit 1 state over the 60 steps.\n\nI have prepared this notebook from the work done by AmbroseM using the modin extension for pandas and intel sklearn extensions as a learning experience.","metadata":{}},{"cell_type":"code","source":"# Loading and visualizing the data:-\nxtrain = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv', \n                           encoding = 'utf8');\nxtest = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv', \n                          encoding = 'utf8');\nytrain = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv', \n                    encoding = 'utf8');\nSubFl = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv', \n                    encoding = 'utf8');\n\nprint(colored(f\"\\nTrain data\\n\", color= 'blue', attrs= ['dark', 'bold']));\ndisplay(xtrain.head(5));\n\nprint(colored(f\"\\nTarget data\\n\", color= 'blue', attrs= ['dark', 'bold']));\ndisplay(ytrain.head(5));\n\nprint(colored(f\"\\nTest data\\n\", color= 'blue', attrs= ['dark', 'bold']));\ndisplay(xtest.head(5));\n\nprint(colored(f\"\\nSubmission data\\n\", color= 'blue', attrs= ['dark', 'bold']));\ndisplay(SubFl.head(5));\n\nsensor_col_lst = list(xtrain.iloc[0:2, :].\\\ncolumns[xtrain.iloc[0:2,:].columns.str.startswith('sensor_')]);\nprint(colored(f\"\\nSensor columns\\n\", color= 'blue', attrs= ['dark', 'bold']));\nprint(colored(f\"{sensor_col_lst}\", color = 'blue'));\n\ncollect();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:02:23.002566Z","iopub.execute_input":"2022-05-09T19:02:23.003573Z","iopub.status.idle":"2022-05-09T19:02:33.017432Z","shell.execute_reply.started":"2022-05-09T19:02:23.003498Z","shell.execute_reply":"2022-05-09T19:02:33.01628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data preprocessing and visualization\n\nIn this section, we reduce the train-test set memory usage, develop basic distribution plots and study feature interaction metrics to elicit better development endeavors.","metadata":{}},{"cell_type":"code","source":"# Performing data preprocessing:-\nprint(colored(f\"\\nTrain data information\\n\", color= 'blue', attrs= ['dark', 'bold']));\nprint(f\"{xtrain.info()}\");\n\nprint(colored(f\"\\nTest data information\\n\", color= 'blue', attrs= ['dark', 'bold']));\nprint(f\"{xtest.info()}\");","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:00:50.373396Z","iopub.status.idle":"2022-05-09T19:00:50.37391Z","shell.execute_reply.started":"2022-05-09T19:00:50.37364Z","shell.execute_reply":"2022-05-09T19:00:50.373666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if the target class is balanced/ imbalanced:-\nfig, ax= plt.subplots(1,1, figsize= (4,6));\nsns.barplot(y= ytrain.state.value_counts(normalize= False).values, \n            x= ytrain.state.unique(), palette= 'Blues',saturation= 0.90, ax=ax);\nax.set_title(f\"Target column distribution for (im)balanced classes\\n\", color= 'tab:blue', fontsize= 12);\nax.set_yticks(range(0,14001,1000));\nax.set_xlabel('Target Class');\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T16:59:20.390295Z","iopub.execute_input":"2022-05-09T16:59:20.391005Z","iopub.status.idle":"2022-05-09T16:59:20.709446Z","shell.execute_reply.started":"2022-05-09T16:59:20.390957Z","shell.execute_reply":"2022-05-09T16:59:20.707998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Development Plan:-\n\nThese tables are structured as below-\n1. xtrain:- This encapsulates the training features only. Each sequence number is associated with 60 time steps with numerical readings for that sequence number from 13 sensors on a unique subject number for the sequence.\n2. ytrain:- This is the target table, with sequence numbers and class labels for the sequence. This data is balanced, as seen in the previous cell target distribution, hence, no over-sampling is needed\n3. xtest:- This continues the sequences from the train-set but we are unaware of the classification state\n\nModel development requires feature engineering with new features encapsulating the sensor readings' descriptive statistics over the sequence number. \nNew columns including the mean, std, skewness, kurtosis, IQR, median, etc. can be created across all 13 sensors and their efficacy in the model development may be assessed for inclusion. \nClassifier models like an LSTM/ ML models could be used after eliciting relevant features and pre-processing","metadata":{}},{"cell_type":"code","source":"# Reducing memory usage for train-test sets:-\ndef ReduceMemory(df:pd.DataFrame):\n    \"\"\"\n    This function assigns new dtypes to the relevant dataset attributes and reduces memory usage.\n    The relevant data-type is determined from the description seen earlier in the kernel.\n    \n    Input:- df (dataframe):- Analysis dataframe\n    Returns:- df (dataframe):- Modified dataframe\n    \"\"\"; \n    \n    df[['subject']] = df[['subject']].astype(np.int16);\n    df[['sequence']] = df[['sequence']].astype(np.int32);\n    df[['step']] = df[['step']].astype(np.int8);\n    \n    #  selecting all sensor float columns and reassigning data-types:-   \n    global sensor_col_lst;\n    df[sensor_col_lst] = df[sensor_col_lst].astype(np.float32);\n    \n    return df; ","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:02:39.402238Z","iopub.execute_input":"2022-05-09T19:02:39.402626Z","iopub.status.idle":"2022-05-09T19:02:39.409628Z","shell.execute_reply.started":"2022-05-09T19:02:39.402585Z","shell.execute_reply":"2022-05-09T19:02:39.408573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Developing the single step pipeline for memory reduction:-\nMemReducer = Pipeline(steps= [('ReduceMemory', FunctionTransformer(ReduceMemory))]);\nxtrain = MemReducer.fit_transform(xtrain, ytrain.state.values);\nxtest = MemReducer.transform(xtest);\n\n# Performing memory reduction in the target table:-\nytrain['sequence'] = ytrain['sequence'].astype(np.int16);\nytrain['state'] = ytrain['state'].astype(np.int8);\n\n# Performing data preprocessing after memory reduction:-\nprint(colored(f\"\\nTrain data information after memory reduction\\n\", \n              color= 'blue', attrs= ['dark', 'bold']));\nprint(f\"{xtrain.info()}\");\n\nprint(colored(f\"\\nTest data information after memory reduction\\n\", \n              color= 'blue', attrs= ['dark', 'bold']));\nprint(f\"{xtest.info()}\");\n\n# Merging the target with the features to form a single train dataframe:-\nxytrain = xtrain.merge(ytrain, how= 'left', left_on= 'sequence', right_on= 'sequence',\n                       suffixes = ('',''));\ndel xtrain, ytrain, MemReducer;\n\ncollect();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:02:42.976752Z","iopub.execute_input":"2022-05-09T19:02:42.97722Z","iopub.status.idle":"2022-05-09T19:02:47.940369Z","shell.execute_reply.started":"2022-05-09T19:02:42.977158Z","shell.execute_reply":"2022-05-09T19:02:47.939169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting correlation heatmap for the train data sensor readings:-\nfig, ax= plt.subplots(1,1, figsize= (18,10));\nsns.heatmap(data= xytrain.loc[:, sensor_col_lst].corr(), \n            vmin= 0.0, vmax=1.00, annot= True, fmt= '.1%',\n            cmap= sns.color_palette('Spectral_r'), linecolor='black', linewidth= 1.00,\n            ax=ax);\n\nax.set_title('Correlation heatmap for the train-set sensor data\\n', fontsize=12, color= 'black');\nplt.yticks(rotation= 0, fontsize= 9);\nplt.xticks(rotation= 0, fontsize= 9);\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T16:59:24.784157Z","iopub.execute_input":"2022-05-09T16:59:24.784452Z","iopub.status.idle":"2022-05-09T16:59:30.02872Z","shell.execute_reply.started":"2022-05-09T16:59:24.784413Z","shell.execute_reply":"2022-05-09T16:59:30.028122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting sensor readings with the target to elicit mutual information and importance:-\nfig, ax= plt.subplots(1,1, figsize= (12,6));\nxytrain.drop(['sequence', 'subject', 'step'], axis=1).corr()[['state']].drop('state').plot.bar(ax= ax);\n\nax.set_title(\"Correlation analysis for all sensor columns\\n\", color= 'tab:blue', fontsize= 12);\nax.grid(visible= True, which= 'both', color= 'grey', linestyle= '--', linewidth= 0.50);\nax.set_xlabel('\\nColumns', color= 'black');\nax.set_ylabel('Correlation', color= 'black');\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T16:59:30.02986Z","iopub.execute_input":"2022-05-09T16:59:30.030561Z","iopub.status.idle":"2022-05-09T16:59:35.237657Z","shell.execute_reply.started":"2022-05-09T16:59:30.030526Z","shell.execute_reply":"2022-05-09T16:59:35.236825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting boxplots to study the column distributions:-\n\nfig, ax= plt.subplots(1,1, figsize= (18,10));\nxytrain.loc[:, sensor_col_lst].plot.box(ax=ax, color = 'blue');\nax.set_title(f\"Distribution analysis for sensor data in train-set\\n\", color= 'tab:blue', fontsize= 12);\nax.set_yticks(range(-700,701,100));\nax.grid(visible=True, which='both', color= 'lightgrey', linestyle= '--');\nax.set_xlabel('\\nSensor Columns\\n', fontsize= 12, color= 'tab:blue');\nax.set_ylabel(f'Sensor Readings\\n', fontsize= 12, color= 'tab:blue');\n\nplt.xticks(rotation= 90);\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T16:59:35.239023Z","iopub.execute_input":"2022-05-09T16:59:35.239814Z","iopub.status.idle":"2022-05-09T16:59:38.780115Z","shell.execute_reply.started":"2022-05-09T16:59:35.239771Z","shell.execute_reply":"2022-05-09T16:59:38.77917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Subject analysis:- \n\nThis sub-section elicits key insights derived from the train-test set subjects as below-\n1. We plan to study the common subject characteristics for state\n2. We also plan to develop descriptive statistics of sensor readings based on subjects \n3. We will check if data leakage exists between the train-test subjects for any manual adjustments over the model results at the end of the assignment","metadata":{}},{"cell_type":"code","source":"# Analyzing subject characteristics with an interim subject profile object:-\n\nsub_prf_train= \\\nxytrain[['subject', 'sequence', 'state']].drop_duplicates().set_index('sequence').\\\npivot_table(index= 'subject', values= 'state', aggfunc= [np.size, np.sum]);\nsub_prf_train.columns= ['Nb_Min', 'Nb_S1'];\nsub_prf_train['Nb_S0'] = sub_prf_train['Nb_Min'] - sub_prf_train['Nb_S1'];\nsub_prf_train['S1_Rate'] = sub_prf_train['Nb_S1']/ sub_prf_train['Nb_Min'];\n\nsub_prf_train.sort_values(['S1_Rate'], ascending= False);","metadata":{"execution":{"iopub.status.busy":"2022-05-09T16:59:38.781431Z","iopub.execute_input":"2022-05-09T16:59:38.781714Z","iopub.status.idle":"2022-05-09T16:59:57.132371Z","shell.execute_reply.started":"2022-05-09T16:59:38.781668Z","shell.execute_reply":"2022-05-09T16:59:57.131579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing subject details from xytrain and subject profile objects:-\nprint(colored(f\"\\nTrain set subject inferences:-\", color= 'red', attrs= ['bold', 'dark']));\nprint(colored(f\"Number of train-set subjects = {len(sub_prf_train)}\", color = 'blue'));\nprint(colored(f\"Number of train-set subjects never going to state 1 = {len(sub_prf_train.query('S1_Rate == 0.0'))}\", \n              color = 'blue'));\nprint(colored(f\"Number of train-set subjects never going to state 0 = {len(sub_prf_train.query('S1_Rate == 1.0'))}\", \n              color = 'blue'));\n\nprint(colored(f\"\\nDescriptive summary statistics for the training subjects\\n\", color = 'red', attrs= ['bold']));\ndisplay(sub_prf_train.iloc[:,:-1].describe().transpose().style.format('{:.1f}'));\n\nprint(colored(f\"\\nDescriptive summary statistics for the test-set subjects\\n\", color = 'red', attrs= ['bold']));\ndisplay(xtest[['sequence', 'subject']].drop_duplicates().groupby(['subject']).\\\nagg(Nb_Min = pd.NamedAgg('sequence', np.size)).describe().transpose().style.format('{:.1f}'));\n\nprint(colored(f\"\\nDescriptive summary statistics for the training subjects never in state 1\\n\", \n              color = 'red', attrs= ['bold']));\ndisplay(sub_prf_train.loc[sub_prf_train.S1_Rate== 0.0].describe().transpose().style.format('{:.1f}'));\n\nprint(colored(f\"\\nSensor summary statistics for the training subjects never in state 1\\n\", \n              color = 'red', attrs= ['bold']));\ndisplay(xytrain.loc[xytrain.subject.isin(sub_prf_train.loc[sub_prf_train.S1_Rate== 0.0].index), sensor_col_lst].\\\n        describe().transpose().style.format('{:,.1f}'));\n\nprint(colored(f\"\\nSensor summary statistics for the training subjects in state 1 and 0\\n\", \n              color = 'red', attrs= ['bold']));\ndisplay(xytrain.loc[xytrain.subject.isin(sub_prf_train.loc[sub_prf_train.S1_Rate > 0.0].index),sensor_col_lst].\\\n        describe().transpose().style.format('{:,.1f}'));\n\nprint(colored(f\"\\nSensor summary statistics for all training subjects\\n\", color = 'red', attrs= ['bold']));\ndisplay(xytrain.loc[:,sensor_col_lst].describe().transpose().style.format('{:,.1f}'));","metadata":{"execution":{"iopub.status.busy":"2022-05-09T16:59:57.13375Z","iopub.execute_input":"2022-05-09T16:59:57.133992Z","iopub.status.idle":"2022-05-09T17:00:10.80088Z","shell.execute_reply.started":"2022-05-09T16:59:57.133955Z","shell.execute_reply":"2022-05-09T17:00:10.799993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting unique sequences per subject:-\n\n_ = xytrain[['sequence', 'subject', 'state']].drop_duplicates().\\\n             groupby(['subject','state'])['sequence'].nunique().reset_index().\\\n             pivot_table(index= 'subject', columns= 'state', values= 'sequence', aggfunc= [np.sum]);\n_.columns = ['Nb_Unq_Seq0', 'Nb_Unq_Seq1'];\n\nfig, ax= plt.subplots(2,1, figsize= (18,15));\n\nsns.lineplot(data= _.values , palette= 'rainbow', ax= ax[0], linestyle= '-');\nax[0].set_title(f\"Number of unique sequences per subject in the training set\\n\", color= 'black', fontsize= 12);\nax[0].legend(loc= 'upper right', fontsize= 8);\nax[0].set_xlabel('Subjects\\n', color= 'black', fontsize= 10);\nax[0].set_ylabel('Sequences', color= 'black', fontsize= 10);\nax[0].grid(visible= True, which= 'both', linestyle= '-', color= 'lightgrey');\nax[0].set_xticks(range(0, 680, 25));\nax[0].set_yticks(range(0, 181, 15));\n\nsns.lineplot(data=_.loc[sub_prf_train.loc[sub_prf_train.S1_Rate== 0.0].index][['Nb_Unq_Seq0']].values, \n             palette= 'Dark2',ax= ax[1]);\nax[1].set_title(f\"\\nNumber of unique sequences per subject in the training set never in state1\\n\",\n                color= 'black', fontsize= 12);\nax[1].grid(visible= True, which= 'both', linestyle= '-', color= 'lightgrey');\nax[1].set_xticks(range(0, 65, 5));\nplt.show();\n\ndel _;","metadata":{"execution":{"iopub.status.busy":"2022-05-09T17:00:10.802562Z","iopub.execute_input":"2022-05-09T17:00:10.802815Z","iopub.status.idle":"2022-05-09T17:00:29.486997Z","shell.execute_reply.started":"2022-05-09T17:00:10.802785Z","shell.execute_reply":"2022-05-09T17:00:29.485884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the distributions of the sensor readings across state:-\nfor col in sensor_col_lst:\n    fig, ax= plt.subplots(1,1, figsize = (12,3.5));\n    sns.kdeplot(data=xytrain[[col, 'state']], x= col, hue=\"state\", \n                multiple=\"stack\", palette = 'rainbow', ax= ax);\n    ax.grid(visible= True, which= 'both', color= 'lightgrey', linestyle= '--');\n    ax.set_xlabel('');\n    ax.set_title(f'\\n{col}\\n');\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T17:00:29.48878Z","iopub.execute_input":"2022-05-09T17:00:29.489127Z","iopub.status.idle":"2022-05-09T17:01:47.772302Z","shell.execute_reply.started":"2022-05-09T17:00:29.489085Z","shell.execute_reply":"2022-05-09T17:01:47.771512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing the univariate characteristics for all sensors across the states:-\n\nprint(colored(f\"\\nState 0 descriptions\\n\", color= 'blue', attrs= ['bold', 'dark'])); \ndisplay(xytrain.loc[xytrain.state == 0, sensor_col_lst].describe().transpose()\\\n        .style.format('{:,.2f}'));\nprint();\n\nprint(colored(f\"\\nState 1 descriptions\\n\", color= 'blue', attrs= ['bold', 'dark'])); \ndisplay(xytrain.loc[xytrain.state == 1, sensor_col_lst].describe().transpose().\\\n        style.format('{:,.2f}'));","metadata":{"execution":{"iopub.status.busy":"2022-05-09T17:01:47.773454Z","iopub.execute_input":"2022-05-09T17:01:47.773652Z","iopub.status.idle":"2022-05-09T17:01:50.983328Z","shell.execute_reply.started":"2022-05-09T17:01:47.773627Z","shell.execute_reply":"2022-05-09T17:01:50.982482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deleting interim tables after usage:-\ndel sub_prf_train;\ncollect();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T17:01:50.984492Z","iopub.execute_input":"2022-05-09T17:01:50.984718Z","iopub.status.idle":"2022-05-09T17:01:51.130638Z","shell.execute_reply.started":"2022-05-09T17:01:50.98469Z","shell.execute_reply":"2022-05-09T17:01:51.129621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Feature Engineering\n\nIn this section, we create features based on descriptive statistics, remove outliers and shortlist important features for further model development. We will create custom functions and classes and assemble a pipeline for the same.","metadata":{}},{"cell_type":"code","source":"# Creating new features based on descriptive statistics and sequences per subject:-\ndef MakeFeatures(df: pd.DataFrame):\n    \"\"\"\n    This function creates summary stats based features for the model development grouped by sensor using-\n    1. mean\n    2. std\n    3. iqr\n    4. kurtosis\n    5. std/ absolute mean\n    6. up-down passes for sensor 2- special sensor from EDA\n    7. number of unique sequences per subject\n    \"\"\";\n    \n    global sensor_col_lst; \n    \n    # Creating grouper object with all sensor features:-\n    grouper = df.groupby(['sequence'])[sensor_col_lst];\n    \n    # Creating model dataframe with the summary features:-\n    mdl_df = \\\n    pd.concat((\n        grouper.mean().add_prefix('mean_'),\n        grouper.std().add_prefix('std_'),\n        np.clip(grouper.std()/ np.abs(grouper.mean()), a_min= -1e30, a_max= 1e30).add_prefix('stdvsmean_')\n    ),axis=1);\n    del grouper;\n\n    # Adding kurtosis and IQR of each sensor to the model dataframe:-\n    for col in sensor_col_lst:\n        mdl_df = \\\n        pd.concat((mdl_df,\n                   df[['sequence',col]].groupby(['sequence']).agg({col: kurtosis}).add_prefix('kutosis_'),\n                   df[['sequence',col]].groupby(['sequence']).agg({col: iqr}).add_prefix('iqr_')),\n                  axis=1);\n    \n    # Creating transpose for sensor 2 readings:-    \n    _ = df[['sequence', 'step','sensor_02']].pivot(index= 'sequence', columns = 'step', values= 'sensor_02');\n\n    # Creating additional features for sensor 2:-   \n    mdl_df['up_sensor_02'] = (_.diff(axis=1) > 0.0).sum(axis=1);\n    mdl_df['down_sensor_02'] = (_.diff(axis=1) < 0.0).sum(axis=1);\n    mdl_df['upsum_sensor_02'] = _.diff(axis=1).clip(0.0, None).sum(axis=1);\n    mdl_df['downsum_sensor_02'] = _.diff(axis=1).clip(None, 0.0).sum(axis=1);\n    mdl_df['upmax_sensor_02'] = _.diff(axis=1).max(axis=1);\n    mdl_df['downmax_sensor_02'] = _.diff(axis=1).min(axis=1);\n    mdl_df['upmean_sensor_02'] = np.nan_to_num(mdl_df['upsum_sensor_02'] / mdl_df['up_sensor_02'], \n                                               posinf=40);\n    mdl_df['downmean_sensor_02'] = np.nan_to_num(mdl_df['downsum_sensor_02'] / mdl_df['down_sensor_02'], \n                                                 neginf=-40)\n\n    del _;\n    \n    # Creating sequences per subject:-\n    mdl_df = mdl_df.merge(df[['sequence', 'subject']].drop_duplicates(),\n                          how= 'left', left_index= True, right_on = 'sequence', suffixes= ('',''));\n    mdl_df = mdl_df.merge(df[['subject', 'sequence']].drop_duplicates().groupby('subject').\\\n                          agg(nb_seq_per_sub = pd.NamedAgg('sequence', np.size)),\n                          how = 'left', on = 'subject', suffixes= ('',''));\n    mdl_df.set_index(['sequence', 'subject'], inplace= True);\n    \n    print(colored(f\"\\nColumns in the dataset= {len(mdl_df.columns):.0f}\\n\", color= 'blue'));\n    global Ftre_Lst;\n    Ftre_Lst = list(mdl_df.columns);\n    return mdl_df;","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:02:57.453102Z","iopub.execute_input":"2022-05-09T19:02:57.453822Z","iopub.status.idle":"2022-05-09T19:02:57.470672Z","shell.execute_reply.started":"2022-05-09T19:02:57.453749Z","shell.execute_reply":"2022-05-09T19:02:57.469485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing outliers from the feature engineered dataset:-\nclass OutlierRemover(BaseEstimator, TransformerMixin):\n    \"This class removes outliers based on IQR multiplier (usually 1.5*IQR)\";\n    \n    def __init__(self, iqr_mult:float = 1.50):\n        \"This function initializes the IQR multiplier for the outlier removal\";\n        self.iqr_mult_ = iqr_mult;\n        \n    def fit(self, X, y=None, **fit_params):\n        \"This function calculates the cutoff for outlier removal on the train-data\";\n        X_iqr = iqr(X, axis=0);\n        self.OtlrLB_ = np.percentile(X.values, 25, axis=0) - self.iqr_mult_* X_iqr;\n        self.OtlrUB_ = np.percentile(X.values, 75, axis=0) + self.iqr_mult_* X_iqr;\n        del X_iqr;\n        return self;\n    \n    def transform(self, X, y= None, **transform_params):\n        \"This function clips the outliers off the data-set and returns a pandas dataframe\";\n        return DataFrame(data= np.clip(X.values, a_min= self.OtlrLB_, a_max= self.OtlrUB_), \n                         index= X.index, columns= X.columns);","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:03:00.9836Z","iopub.execute_input":"2022-05-09T19:03:00.984569Z","iopub.status.idle":"2022-05-09T19:03:00.993763Z","shell.execute_reply.started":"2022-05-09T19:03:00.984497Z","shell.execute_reply":"2022-05-09T19:03:00.992027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shortlisting features based on univariate dependency:-\nclass FeatureSelector(BaseEstimator, TransformerMixin):\n    \"This class reduces features from the engineered data based on the dependency with the target\";\n    \n    def __init__(self,iqr_cutoff:np.float16 = 0.0, train_obs_pct:np.float16= 0.05):\n        \"\"\"\n        This function initializes the parameters for the class.\n        This including iqr cutoff and train percent for rolling window\n        \"\"\";\n        self.iqr_cutoff = iqr_cutoff;\n        self.train_obs_pct = train_obs_pct;\n    \n    def fit(self, X:pd.DataFrame, y= None, **fit_params):\n        \"\"\"\n        This function calculates the dependency as below-\n        1. Development of target dataframe and 1 column from the engineered data\n        2. Shuffle the interim table with a random seed for reproducability\n        3. Sort the data with the column value\n        4. Develop a rolling mean across 5% training set length for the target column\n        5. Plot the rolling mean vs index and store the describe() output in a global dataframe\n        6. Shortlist columns with an IQR of rolling mean >= cutoff (self.iqr_cutoff)\n        \"\"\";\n        \n        #  Creating function parameters and output univariate profile to store the dependency results:-      \n        len_window= np.int32(self.train_obs_pct*len(y));\n        ftre_lst = list(X.columns);\n        ncols= 5;\n        nrows= np.int16(np.ceil(len(ftre_lst)/ncols));\n        Unv_Prf = pd.DataFrame();\n        \n        # Creating global feature selection storage object:-\n        global Ftre_Sel_Lst;\n        Ftre_Sel_Lst = [];\n        \n        X = pd.DataFrame(data= X.values, index= X.index, columns= X.columns);\n        \n        fig, ax= plt.subplots(nrows=nrows, ncols=ncols, figsize= (ncols*4, nrows*4)); \n        for i, col in enumerate(ftre_lst):\n            df= y.merge(X[[col]].droplevel('subject'),\n                        how= 'left',left_on= 'sequence',right_on= 'sequence',suffixes= ('',''));\n            df= df.sample(frac=1.0, random_state= 10).sort_values([col], ascending= True); \n            df.reset_index(inplace= True);\n            df['RollMean'] = df.state.rolling(len_window).mean();\n            \n            Unv_Prf = pd.concat((Unv_Prf, \n                                 df[['RollMean']].describe().\\\n                                 rename({'RollMean': col}, axis=1).transpose()[['25%', '75%', 'std']]),\n                               axis=0, ignore_index= False);\n            \n            # Developing feature dependency plot:-                                    \n            plt.subplot(nrows, ncols, i+1);\n            sns.scatterplot(y=df.RollMean.values, x= df.index, palette= 'Blues', alpha= 0.60,\n                            ax= ax[i//ncols,i%ncols]);\n            ax[i//ncols, i%ncols].set_title(f'\\n{col}\\n', color= 'black', fontsize=9);\n            ax[i//ncols, i%ncols].grid(visible= True,which= 'both',linestyle= '--',color='lightgrey');\n            ax[i//ncols, i%ncols].set_xticks(range(0, 25001,5000));\n        \n        plt.xticks(fontsize=7.5);\n        plt.tight_layout();\n        plt.show();\n        \n        # Developing feature shortlist:-\n        self.sel_ftre = list(Unv_Prf.loc[Unv_Prf['75%']-Unv_Prf['25%'] >=self.iqr_cutoff].index);\n        Ftre_Sel_Lst = self.sel_ftre;\n        \n        return self;\n    \n    def transform(self, X:pd.DataFrame, y=None, **transform_params):\n        \"This function returns a truncated dataset with the shortlisted features\";\n        X1= X.copy();\n        return X1[self.sel_ftre];\n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:03:04.530961Z","iopub.execute_input":"2022-05-09T19:03:04.531306Z","iopub.status.idle":"2022-05-09T19:03:04.550359Z","shell.execute_reply.started":"2022-05-09T19:03:04.531271Z","shell.execute_reply":"2022-05-09T19:03:04.549148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recreating target training set from the combined xytrain data:-\nytrain = xytrain[['sequence','state']].drop_duplicates().set_index('sequence');\n\n# Initializing global parameters for the data transformer pipeline:-\niqr_cutoff= 0.10;\ntrain_obs_pct = 0.05;\nFtre_Lst= [];\n\n# Initializing the data processor pipeline:-\nData_Processor=\\\nPipeline(verbose= True, steps= \n        [('MakeFeatures', FunctionTransformer(MakeFeatures)),\n         ('RemoveOutliers', OutlierRemover(iqr_mult=1.5)),\n         ('Standardize', DataFrameMapper(input_df= True, df_out= True, default=None, drop_cols=None,\n                                        features= gen_features(columns= np.expand_dims(Ftre_Lst, axis=1),\n                                                              classes= [RobustScaler])\n                                        )\n         ),\n         ('SelectFeatures', FeatureSelector(iqr_cutoff=iqr_cutoff, train_obs_pct=train_obs_pct))\n        ]);\n\n# Implementing the transformer pipeline on the training data:-\nXtrain = Data_Processor.fit_transform(xytrain.drop('state', axis=1), ytrain);\nXtest = Data_Processor.transform(xtest);\n\nprint(colored(f\"Train-set size after feature processing is {Xtrain.shape}\", \n              color= 'blue', attrs= ['bold', 'dark']));\nprint(colored(f\"Test-set size after feature processing is {Xtest.shape}\", \n              color= 'blue', attrs= ['bold', 'dark']));\nprint(colored(f\"\\nData-type of pipeline output = {type(Xtrain)}\", \n              color = 'blue', attrs= ['bold', 'dark']));\n\ncollect();","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:03:08.5281Z","iopub.execute_input":"2022-05-09T19:03:08.528402Z","iopub.status.idle":"2022-05-09T19:07:14.475135Z","shell.execute_reply.started":"2022-05-09T19:03:08.528369Z","shell.execute_reply":"2022-05-09T19:07:14.474188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model training:-\n\nIn this section, we aim to create n-classifiers using standard ML algorithms on a specific (large) sample of the train set (say 90%) with varying random seeds. This closely follows bootstrapping sampling with replacement from the training data. We finally calculate the central tendency of the trained classifiers and prepare the submission file for the competition\n","metadata":{}},{"cell_type":"code","source":"# Initializing other global parameters for the model training:-\nnb_mdl = 100;\ntrain_frac = 0.95;\n\n# Initializing output dataframe to store the test set predictions:-\nMdl_Pred_Prf = pd.DataFrame(data= None, index= SubFl.sequence, \n                            columns = ['State'+str(i) for i in range(nb_mdl)],dtype= np.float32);\n\n# Fitting the classifiers and collating test predictions:-\nprint(colored(f\"Model training and prediction collation\", color= 'red', attrs= ['bold', 'dark']));\nfor seed in range(nb_mdl):\n    print(colored(f\"Current seed = {seed}\", color= 'blue', attrs= ['bold']));\n    \n    # Initializing the model instance:-\n    model = HGBMC(learning_rate=0.10, max_leaf_nodes= 25, max_iter=1000, \n                  min_samples_leaf= 500, validation_fraction= (1-train_frac),\n                  l2_regularization=1, max_bins=63, random_state= seed, verbose= 0,\n                  early_stopping = True, scoring= 'roc_auc', n_iter_no_change= 50);\n    # Fitting the model on the train-set:-    \n    model.fit(Xtrain, ytrain.values);\n    # Collating the test predictions:-   \n    Mdl_Pred_Prf[f\"State{seed}\"] = model.predict_proba(Xtest)[:,1];","metadata":{"execution":{"iopub.status.busy":"2022-05-09T20:00:48.391993Z","iopub.execute_input":"2022-05-09T20:00:48.392528Z","iopub.status.idle":"2022-05-09T20:07:36.856127Z","shell.execute_reply.started":"2022-05-09T20:00:48.392477Z","shell.execute_reply":"2022-05-09T20:07:36.855079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the submission file:-\npd.DataFrame(data=Mdl_Pred_Prf.mean(axis=1), columns= ['state']).\\\nreset_index().rename({'index': 'sequence'}, axis=1).to_csv('submission.csv', index= False)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T20:07:40.406197Z","iopub.execute_input":"2022-05-09T20:07:40.406446Z","iopub.status.idle":"2022-05-09T20:07:42.02025Z","shell.execute_reply.started":"2022-05-09T20:07:40.406419Z","shell.execute_reply":"2022-05-09T20:07:42.019132Z"},"trusted":true},"execution_count":null,"outputs":[]}]}