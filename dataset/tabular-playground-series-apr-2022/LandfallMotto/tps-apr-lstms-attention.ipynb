{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"text_cell_render border-box-sizing rendered_html\">\n<div style=\"background-color:rgba(0, 167, 255, 0.6);border-radius:5px;display:fill\">\n<h1><center>Tabular Playground Series - Apr 2022</center></h1></div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GroupKFold\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport tensorflow as tf\ntf.get_logger().setLevel('ERROR')\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.layers import *\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n\ntrain = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\nsubs = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:12:56.805215Z","iopub.execute_input":"2022-04-26T18:12:56.805557Z","iopub.status.idle":"2022-04-26T18:13:13.827935Z","shell.execute_reply.started":"2022-04-26T18:12:56.805477Z","shell.execute_reply":"2022-04-26T18:13:13.82714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:13:13.829669Z","iopub.execute_input":"2022-04-26T18:13:13.829926Z","iopub.status.idle":"2022-04-26T18:13:13.856511Z","shell.execute_reply.started":"2022-04-26T18:13:13.82989Z","shell.execute_reply":"2022-04-26T18:13:13.85576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing = pd.DataFrame({\n    'train_miss' : train.isna().sum(),\n    'test_miss' : test.isna().sum(),\n})\nprint(\"Missing Value :\")\nmissing.T","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:13:13.857927Z","iopub.execute_input":"2022-04-26T18:13:13.858184Z","iopub.status.idle":"2022-04-26T18:13:13.939908Z","shell.execute_reply.started":"2022-04-26T18:13:13.858148Z","shell.execute_reply":"2022-04-26T18:13:13.939221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Install Keras Self Attention","metadata":{}},{"cell_type":"code","source":"!pip install keras-self-attention","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:13:13.941957Z","iopub.execute_input":"2022-04-26T18:13:13.942457Z","iopub.status.idle":"2022-04-26T18:13:25.305858Z","shell.execute_reply.started":"2022-04-26T18:13:13.942421Z","shell.execute_reply":"2022-04-26T18:13:25.305028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Credits https://www.kaggle.com/code/dmitryuarov/sensors-deep-analysis-0-98#Preprocessing\nfeatures = train.columns.tolist()[3:]\n\ndef sub_imp(x):\n    if x < 25:\n        return 0\n    elif x > 95:\n        return 2\n    else:\n        return 1\n\ndef prep(df):\n    for feature in features:\n        df[feature+'_lag1'] = df.groupby('sequence')[feature].shift(1)\n        df[feature+'_back_lag1'] = df.groupby('sequence')[feature].shift(-1)\n        \n        df.fillna(0, inplace=True)\n        df[feature+'_diff1'] = df[feature] - df[feature+'_lag1']\n        #'''\n        # New features\n        #for window in [3,6,12]:\n        for window in [3]:\n            df[feature+'_roll_'+str(window)+'_mean'] = df.groupby('sequence')[feature]\\\n            .rolling(window=window, min_periods=1).mean().reset_index(level=0,drop=True)\n            \n            df[feature+'_roll_'+str(window)+'_std'] = df.groupby('sequence')[feature]\\\n            .rolling(window=window, min_periods=1).std().reset_index(level=0,drop=True)\n            \n            df[feature+'_roll_'+str(window)+'_sum'] = df.groupby('sequence')[feature]\\\n            .rolling(window=window, min_periods=1).sum().reset_index(level=0,drop=True)\n        #'''\n    '''  \n    # Experemental features\n    df['sens_00_06'] = df['sensor_00'] * df['sensor_06']\n    df['sens_03_07'] = df['sensor_03'] * df['sensor_07']\n    df['sens_03_11'] = df['sensor_03'] * df['sensor_11']\n\n    for feature in ['sens_00_06', 'sens_03_07', 'sens_03_11']:\n        df[feature + '_lag1'] = df.groupby('sequence')[feature].shift(1)\n    df.fillna(0, inplace=True)\n    '''\n    df.fillna(0, inplace=True)\n    # Subject feature\n    sub_stat = df[['sequence', 'subject']].drop_duplicates().groupby('subject').agg({'sequence': 'count'})\\\n    .rename(columns={'sequence': 'count'}).reset_index()\n    df = df.merge(sub_stat, on='subject', how='left')\n    df['sub_imp'] = df['count'].apply(lambda x: sub_imp(x))\n    df.drop('count', axis=1, inplace=True)\n\n     \nprep(train)\nprep(test)\n\nfeatures = train.columns.tolist()[3:]\nsc = StandardScaler()\ntrain[features] = sc.fit_transform(train[features])\ntest[features] = sc.transform(test[features])\n\ngroups = train[\"sequence\"]\nlabels = train_labels[\"state\"]\n\ntrain = train.drop([\"sequence\", \"subject\", \"step\"], axis=1).values\ntrain = train.reshape(-1, 60, train.shape[-1])\n\ntest = test.drop([\"sequence\", \"subject\", \"step\"], axis=1).values\ntest = test.reshape(-1, 60, test.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:13:25.316338Z","iopub.execute_input":"2022-04-26T18:13:25.316855Z","iopub.status.idle":"2022-04-26T18:15:39.459492Z","shell.execute_reply.started":"2022-04-26T18:13:25.316819Z","shell.execute_reply":"2022-04-26T18:15:39.458674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:15:39.460668Z","iopub.execute_input":"2022-04-26T18:15:39.461106Z","iopub.status.idle":"2022-04-26T18:15:39.651046Z","shell.execute_reply.started":"2022-04-26T18:15:39.46107Z","shell.execute_reply":"2022-04-26T18:15:39.649943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"from keras_self_attention import SeqSelfAttention\n\ndef lstm_att_model(bin_data):\n\n    x_input = Input(shape=(train.shape[-2:]))\n    \n    x = Bidirectional(LSTM(512, return_sequences=True), name='BiLSTM1')(x_input)\n    x = Bidirectional(LSTM(384, return_sequences=True), name='BiLSTM2')(x)\n    x = SeqSelfAttention(attention_activation='sigmoid',name='attention_weight')(x)\n    l1 = GlobalAveragePooling1D()(x)\n    \n    \n  \n    x1 = Conv1D(filters=128, kernel_size=8,activation='relu')(x_input)\n    x1 = BatchNormalization()(x1)\n    x1 = Activation('relu')(x1)\n    x1 = Conv1D(filters=256, kernel_size=5,activation='relu')(x1)\n    x1 = BatchNormalization()(x1)\n    x1 = Activation('relu')(x1)\n    x1 = Conv1D(filters=128, kernel_size=3,activation='relu')(x1)\n    x1 = BatchNormalization()(x1)\n    cl = Activation('relu')(x1)\n    l2 = GlobalAveragePooling1D()(cl)\n    \n    con_layer = Concatenate()([l1,l2])\n    \n    x_output = Dense(units=1, activation=\"sigmoid\")(con_layer)\n    \n    model = Model(inputs=x_input, outputs=x_output, name='alstm_model')\n    \n    return model\n\nmodel = lstm_att_model(train)\n\nplot_model(\n    model, \n    to_file='Att_Model.png', \n    show_shapes=False,\n    show_layer_names=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:15:39.652698Z","iopub.execute_input":"2022-04-26T18:15:39.653198Z","iopub.status.idle":"2022-04-26T18:15:44.422445Z","shell.execute_reply.started":"2022-04-26T18:15:39.653158Z","shell.execute_reply":"2022-04-26T18:15:44.421594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomCallback(tf.keras.callbacks.Callback):\n    def __init__(self, X_val, y_val,fold, history):\n        self.x_test = X_val\n        self.y_test = y_val\n        self.fold = fold\n        \n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x_test)\n        history[self.fold,epoch] = y_pred\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:15:44.423819Z","iopub.execute_input":"2022-04-26T18:15:44.424073Z","iopub.status.idle":"2022-04-26T18:15:44.43156Z","shell.execute_reply.started":"2022-04-26T18:15:44.424029Z","shell.execute_reply":"2022-04-26T18:15:44.430705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 256\nVERBOSE = False\nhistory = {}\npredictions, scores = [], []\nk = GroupKFold(n_splits = 5)\nfor fold, (train_idx, val_idx) in enumerate(k.split(train, labels, groups.unique())):\n    print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n\n    X_train, X_val = train[train_idx], train[val_idx]\n    y_train, y_val = labels.iloc[train_idx].values, labels.iloc[val_idx].values\n    \n    model = lstm_att_model(X_train)\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics='AUC')\n\n    lr = ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, \n                           patience=2, verbose=VERBOSE, mode=\"max\")\n\n    es = EarlyStopping(monitor=\"val_auc\", patience=7, \n                       verbose=VERBOSE, mode=\"max\", \n                       restore_best_weights=True)\n    \n    chk_point = ModelCheckpoint(f'./TPS_model_2022_{fold+1}C.h5', \n                                monitor='val_auc', verbose=VERBOSE, \n                                save_best_only=True, mode='max')\n    custom_cb = CustomCallback(X_val, y_val, fold, history)\n    \n    model.fit(X_train, y_train, \n              validation_data=(X_val, y_val), \n              epochs=20,\n              verbose=VERBOSE,\n              batch_size=BATCH_SIZE, \n              callbacks=[lr, chk_point, es, custom_cb])\n    \n    model = load_model(f'./TPS_model_2022_{fold+1}C.h5', custom_objects=SeqSelfAttention.get_custom_objects())\n    \n    y_pred = model.predict(X_val, batch_size=BATCH_SIZE).squeeze()\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    predictions.append(model.predict(test, batch_size=BATCH_SIZE).squeeze())\n    print(f\"Fold-{fold+1} | OOF Score: {score}\")\n\nprint(f'Mean AUC on {k.n_splits} folds - {np.mean(scores)}')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:15:44.434878Z","iopub.execute_input":"2022-04-26T18:15:44.435748Z","iopub.status.idle":"2022-04-26T18:37:42.217256Z","shell.execute_reply.started":"2022-04-26T18:15:44.435698Z","shell.execute_reply":"2022-04-26T18:37:42.214201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"subs[\"state\"] = sum(predictions)/k.n_splits \nsubs.to_csv('submission.csv', index=False)\nsubs.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:39:24.001113Z","iopub.execute_input":"2022-04-26T18:39:24.001816Z","iopub.status.idle":"2022-04-26T18:39:24.056198Z","shell.execute_reply.started":"2022-04-26T18:39:24.001778Z","shell.execute_reply":"2022-04-26T18:39:24.055391Z"},"trusted":true},"execution_count":null,"outputs":[]}]}