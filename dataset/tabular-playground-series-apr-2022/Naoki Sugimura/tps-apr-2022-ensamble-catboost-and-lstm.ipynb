{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\nlabel = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"Inspired by [Early EDA and insights](https://www.kaggle.com/code/abdulravoofshaik/early-eda-and-insights)","metadata":{}},{"cell_type":"code","source":"def each_sensor_value(seq = 0):\n    df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\n    label = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\n    df = pd.merge(left = df, right = label, how = 'left')\n    df = df.drop(['sequence', 'subject', 'step'], axis = 1)\n    sensor_data = df.iloc[60*seq: 60*(seq + 1), :13]\n    state = df.iloc[60*seq: 60*(seq + 1), 13].unique().item()\n    print(f'-----sequence:{seq}-----')\n    print(f'-----state:{state}-----')\n    sensor_data.plot(subplots=True, sharex=True, figsize=(18, 1.5*13));\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"each_sensor_value(seq = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:26:44.850364Z","iopub.execute_input":"2022-04-04T04:26:44.85067Z","iopub.status.idle":"2022-04-04T04:26:44.855444Z","shell.execute_reply.started":"2022-04-04T04:26:44.850637Z","shell.execute_reply":"2022-04-04T04:26:44.854281Z"}}},{"cell_type":"markdown","source":"Inspired by [stats + XGBoost = score 83%](https://www.kaggle.com/code/desitancheva/stats-xgboost-score-83)","metadata":{}},{"cell_type":"code","source":"def feat_eng(train = True):\n    if train:\n        df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\n        label = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\n        train_data = pd.DataFrame()\n        train_data['sequence'] = df['sequence'].unique()\n        for sensor in range(13):\n            sensor_name = f\"sensor_{sensor:02d}\"\n            train_data[f'{sensor_name}''_max'] = df.groupby('sequence')[f'{sensor_name}'].max()\n            train_data[f'{sensor_name}''_min'] = df.groupby('sequence')[f'{sensor_name}'].min()\n            train_data[f'{sensor_name}''_mean'] = df.groupby('sequence')[f'{sensor_name}'].mean()\n            train_data[f'{sensor_name}''_std'] = df.groupby('sequence')[f'{sensor_name}'].std()\n            train_data[f'{sensor_name}''_median'] = df.groupby('sequence')[f'{sensor_name}'].median()\n            \n        train_data = pd.merge(left = train_data, right = label, how = 'left')\n        train_x = train_data.drop(['sequence', 'state'], axis = 1)\n        train_y = train_data['state']\n        return train_x, train_y\n    \n    else:\n        df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\n        test_data = pd.DataFrame()\n        for sensor in range(13):\n            sensor_name = f\"sensor_{sensor:02d}\"\n            test_data[f'{sensor_name}''_max'] = df.groupby('sequence')[f'{sensor_name}'].max()\n            test_data[f'{sensor_name}''_min'] = df.groupby('sequence')[f'{sensor_name}'].min()\n            test_data[f'{sensor_name}''_mean'] = df.groupby('sequence')[f'{sensor_name}'].mean()\n            test_data[f'{sensor_name}''_std'] = df.groupby('sequence')[f'{sensor_name}'].std()\n            test_data[f'{sensor_name}''_median'] = df.groupby('sequence')[f'{sensor_name}'].median()\n        return test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, train_y = feat_eng(train = True)\ntest_x = feat_eng(train = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# from catboost import CatBoostClassifier\n\n\n# model_list = []\n# mae_list = []\n\n# # fold5\n# kf = KFold(n_splits = 5, shuffle = True, random_state = 70)\n\n# # modeling and training\n# for fold, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n#     print(f'--------fold:{fold+1}--------')\n#     fold+=1\n#     tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n#     tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    \n#     params = {\n#         'loss_function' : 'Logloss',\n#         'task_type' : 'GPU', \n#         'grow_policy' : 'SymmetricTree',\n#         'learning_rate': 0.3,\n#         'l2_leaf_reg' : 0.2,\n#         'random_state': 0\n#      }\n                  \n#     model = CatBoostClassifier(**params)\n#     # Training the model\n    \n#     model.fit(tr_x,\n#               tr_y,\n#               eval_set=[(va_x, va_y)])\n    \n#     val_pred = model.predict(va_x)\n#     print(f' ROC: {roc_auc_score(va_y, val_pred)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_x, train_y, df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"pred_1 = model.predict(test_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NN\n","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor, Lambda\nfrom torchvision.io import read_image\nimport torchvision.transforms as transforms\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass TPSAprDataset(Dataset):\n    def __init__(self, transform = None):\n        self.data = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\n        self.label = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\n        self.df = pd.merge(left = self.data, right = self.label, how = 'left')\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)//60\n\n    def __getitem__(self, idx):\n        self.target = self.df.iloc[60*idx: 60*(idx+1),]\n        self.inp = self.target.drop(['sequence', 'subject', 'step', 'state'], axis = 1)\n        self.inp = self.inp.values\n        self.label = self.target['state'].unique().item()\n        \n        if self.transform:\n            self.inp = self.transform(self.inp)\n        self.label = torch.tensor(self.label)\n        \n        return self.inp, self.label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_data = TPSAprDataset()\ntrainloader = DataLoader(train_data, batch_size=64, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CUDA_LAUNCH_BLOCKING=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\n\n\nclass TPSNet(nn.Module):\n    def __init__(self,\n         seq_num = 60,\n         input_dim = 13,\n         lstm_dim = 512,\n         num_layers = 1,\n         num_classes = 1\n    ):\n        super().__init__()\n\n        self.lstm = nn.LSTM(input_dim, lstm_dim, num_layers, batch_first=True, bidirectional=True)\n        \n        self.lstm1 = nn.LSTM(2 * lstm_dim, lstm_dim, num_layers, batch_first=True, bidirectional=True)\n        \n        self.lstm2 = nn.LSTM(2 * lstm_dim, lstm_dim, num_layers, batch_first=True, bidirectional=True)\n        \n        self.logits = nn.Sequential(\n            nn.ReLU(),\n            nn.Linear(lstm_dim * seq_num * 2, num_classes),\n        )\n\n    def forward(self, x):\n        features, _ = self.lstm(x)\n        features, _ = self.lstm1(features)\n        features, _ = self.lstm2(features)\n        features = features.reshape(features.shape[0], -1)\n        pred = self.logits(features)\n        return pred\n\n\nnet = TPSNet()\nnet = net.to(device)\nprint(net)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.MSELoss()\nlr = 1e-4\noptimizer = torch.optim.Adam(model.parameters(), lr = lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  for epoch in range(5): \n    print(f'----{epoch+1}---')\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(trainloader, 0):\n        inputs = inputs.to(device)\n        inputs = inputs.to(torch.float32)\n        labels = labels.to(device)\n        labels = labels.to(torch.float32)\n        labels = labels.unsqueeze(1)\n\n        optimizer.zero_grad()\n        \n\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 200 == 199:\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 200))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\ndata = test_df.drop(['sequence','subject', 'step'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Testset(Dataset):\n    def __init__(self, transform = None):\n        self.df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\n        self.df = self.df.drop(['sequence','subject', 'step'], axis = 1)\n\n    def __len__(self):\n        return len(self.df)//60\n\n    def __getitem__(self, idx):\n        self.target = self.df.iloc[60*idx: 60*(idx+1),]\n        self.target = self.target.values\n        self.target = torch.tensor(self.target)\n        return self.target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = Testset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loader = DataLoader(data, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net.eval()\npreds = []\nwith torch.no_grad():\n    for data in loader:\n        data = data.to(device)\n        pred = net(data.float())\n        preds.append(pred.detach().cpu().numpy())\n\npreds = np.concatenate(preds, 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')\npred_2 = preds.squeeze(1)\nans = pred_2\n# for i, j in enumerate(ans):\n#     if j>0.5:\n#         ans[i] = 1\n#     else:\n#         ans[i] = 0\nsub['state'] = ans","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(ans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}