{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <span style=\"color:#7A5197;\">***TPS APR 22***<span>\n\n\n### <span style=\"color:#7A5197;\">*Table of content*<span>\n<a id=\"table-of-contents\"></a>\n- [1. Introduction](#1)\n    - [1.1 Storytelling](#1.1)\n    - [1.2 Evaluation](#1.2)\n- [2. Preparations](#2)\n- [3. Dataset Overview](#3)\n    - [3.1 Train Dataset](#3.1)\n        - [3.1.1 Quick view](#3.1.1)\n        - [3.1.2 Data types](#3.1.2)\n        - [3.1.3 Basic Statistics](#3.1.3)\n        - [3.1.4 Target Column](#3.1.4)\n    - [3.2 Test Dataset](#3.2)\n        - [3.2.1 Quick view](#3.2.1)\n        - [3.2.2 Data types](#3.2.2)\n        - [3.2.3 Basic Statistics](#3.2.3)\n    - [3.3 Submission](#3.3)\n- [4. Explore Data Analisys](#4)\n    - [4.1 Target](#4.1)\n    - [4.2 Sequence distribution by subject](#4.2)\n    - [4.3 Features distribution](#4.3)\n    - [4.4 Selected Time Series](#4.4)\n    - [4.5 Profile per step with Quantiles](#4.5)\n    - [4.6 Profile per Subject with Quantiles](#4.6)\n    - [4.7 Scatter plot features](#4.7)\n    - [4.8 Correlations](#4.8)\n- [5. LSTM](#5)\n- [6. Reference](#6)\n","metadata":{"papermill":{"duration":0.050036,"end_time":"2022-03-29T07:49:31.115868","exception":false,"start_time":"2022-03-29T07:49:31.065832","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"1\"></a>\n# **<span style=\"color:#7A5197;\">1. Introduction</span>**\n<a id=\"1.1\"></a>\n## **<span style=\"color:#7A5197;\">1.1 Storytelling</span>**\n\nWelcome to the April edition of the 2022 Tabular Playground Series! This month's challenge is a time series classification problem.\n\nYou've been provided with thousands of sixty-second sequences of biological sensor data recorded from several hundred participants who could have been in either of two possible activity states. Can you determine what state a participant was in from the sensor data?\n\n<a id=\"1.2\"></a>\n## **<span style=\"color:#7A5197;\">1.2 Evaluation</span>**\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.","metadata":{}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"2\"></a>\n# **<span style=\"color:#7A5197;\">2. Preparations</span>**\n\nPreparing packages and data that will be used in the analysis process. Packages that will be loaded are mainly for data manipulation, data visualization and modeling. There are 2 datasets that are used in the analysis, they are train and test dataset. The main use of train dataset is to train models and use it to predict test dataset. While sample submission file is used to informed participants on the expected submission for the competition. (to see the details, please expand)\n","metadata":{"papermill":{"duration":0.048124,"end_time":"2022-03-29T07:49:31.314167","exception":false,"start_time":"2022-03-29T07:49:31.266043","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%reset -sf\n\n# import packages\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# setting up options\nimport warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nwarnings.filterwarnings('ignore')\nfrom cycler import cycler\nfrom IPython.core.display import HTML\n\n\n!pip install bloxs\nfrom bloxs import B\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n\n\n# read datasets\ntrain_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\nssub = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')\n\nfeatures = [col for col in test_df if col not in ['PassengerId']]\n\ndef multi_table(table_list):\n    return HTML(\n        f\"<table><tr> {''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list])} </tr></table>\")\n\ndef formatter(v):\n    if type(v) is str:\n        return v\n    if pd.isna(v) or v <= 0:\n        return ''\n    if v == int(v):\n        return f'{v:.0f}'\n    return f'{v:.1f}'\n\nfrom numpy import float64, float32, int64, int32, dtype\n\nf'From {train_df.memory_usage().sum() / 1000000:,.2f}Mbs...'\n\ndef reduce_mem(df):\n    df = df.copy()\n    \n    map_dtypes = {'int': dtype(int64), 'float': dtype(float32)}\n    \n    for col in df:\n        if df[col].dtype == dtype(int64):\n            df[col] = df[col].astype(int32)\n        if df[col].dtype == dtype(float64):\n            df[col] = df[col].astype(float32)\n    return df\n\ntrain_df = reduce_mem(train_df)\ntest_df = reduce_mem(test_df)\n        \nf'...to just {train_df.memory_usage().sum() / 1000000:,.2f}Mbs. Nice!'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.293738,"end_time":"2022-03-29T07:49:32.657412","exception":false,"start_time":"2022-03-29T07:49:31.363674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:13.317757Z","iopub.execute_input":"2022-04-02T17:55:13.318329Z","iopub.status.idle":"2022-04-02T17:55:39.363113Z","shell.execute_reply.started":"2022-04-02T17:55:13.318238Z","shell.execute_reply":"2022-04-02T17:55:39.36219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3\"></a>\n# **<span style=\"color:#7A5197;\">3. Dataset Overview</span>**\n\nThe intend of the overview is to get a feel of the data and its structure in train, test and submission file. An overview on train and test datasets will include a quick analysis on missing values and basic statistics, while sample submission will be loaded to see the expected submission.\n\n|Variable|Definition|\n|------|---|\n| sequence | a unique id for each sequence |\n| subject |  a unique id for the subject in the experiment |\n| step | time step of the recording, in one second intervals |\n| sensor_00 - sensor_12 | the value for each of the thirteen sensors at that time step |\n\n[back to top](#table-of-contents)\n<a id=\"3\"></a>\n### **<span style=\"color:#7A5197;\">3.1 Train Dataset</span>**\n\nAs stated before, train dataset is mainly used to train predictive model as there is an available target variable in this set. This dataset is also used to explore more on the data itself including find a relation between each predictors and the target variable.\n","metadata":{"papermill":{"duration":0.047924,"end_time":"2022-03-29T07:49:32.756053","exception":false,"start_time":"2022-03-29T07:49:32.708129","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.1.1\"></a>\n#### **<span style=\"color:#7A5197;\">3.1.1 Quick view</span>**\n","metadata":{"papermill":{"duration":0.048984,"end_time":"2022-03-29T07:49:32.854146","exception":false,"start_time":"2022-03-29T07:49:32.805162","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\nB(train_df['subject'].nunique(), 'Subjects')\nB(train_df['sequence'].nunique(), 'Sequences')\nB(train_df['step'].nunique(), 'Steps')\n\ntrain_df.head()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.084907,"end_time":"2022-03-29T07:49:32.988051","exception":false,"start_time":"2022-03-29T07:49:32.903144","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:39.365047Z","iopub.execute_input":"2022-04-02T17:55:39.365289Z","iopub.status.idle":"2022-04-02T17:55:39.424259Z","shell.execute_reply.started":"2022-04-02T17:55:39.365259Z","shell.execute_reply":"2022-04-02T17:55:39.423479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {train_df.shape[0]};  Number of columns: {train_df.shape[1]}; No of missing values: {sum(train_df.isna().sum())}')\n\ntrain_df.isna().sum()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.084932,"end_time":"2022-03-29T07:49:33.123719","exception":false,"start_time":"2022-03-29T07:49:33.038787","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:39.425751Z","iopub.execute_input":"2022-04-02T17:55:39.426226Z","iopub.status.idle":"2022-04-02T17:55:39.51952Z","shell.execute_reply.started":"2022-04-02T17:55:39.426186Z","shell.execute_reply":"2022-04-02T17:55:39.518728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.1.2\"></a>\n#### **<span style=\"color:#7A5197;\">3.1.2 Data types</span>**\n","metadata":{"papermill":{"duration":0.050746,"end_time":"2022-03-29T07:49:33.226612","exception":false,"start_time":"2022-03-29T07:49:33.175866","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df.dtypes","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.062167,"end_time":"2022-03-29T07:49:33.346495","exception":false,"start_time":"2022-03-29T07:49:33.284328","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:39.521896Z","iopub.execute_input":"2022-04-02T17:55:39.52237Z","iopub.status.idle":"2022-04-02T17:55:39.53024Z","shell.execute_reply.started":"2022-04-02T17:55:39.52233Z","shell.execute_reply":"2022-04-02T17:55:39.529692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.1.3\"></a>\n#### **<span style=\"color:#7A5197;\">3.1.3 Basic Statistics</span>**\nBelow is the basic statistics for each variables which contain information on count, mean, standard deviation, minimum, 1st quartile, median, 3rd quartile and maximum.","metadata":{"papermill":{"duration":0.052578,"end_time":"2022-03-29T07:49:33.449088","exception":false,"start_time":"2022-03-29T07:49:33.39651","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df.describe()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.096883,"end_time":"2022-03-29T07:49:33.597442","exception":false,"start_time":"2022-03-29T07:49:33.500559","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:39.531099Z","iopub.execute_input":"2022-04-02T17:55:39.531419Z","iopub.status.idle":"2022-04-02T17:55:40.406815Z","shell.execute_reply.started":"2022-04-02T17:55:39.531394Z","shell.execute_reply":"2022-04-02T17:55:40.406002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.1.3\"></a>\n#### **<span style=\"color:#7A5197;\">3.1.4 Target Column</span>**\n","metadata":{"papermill":{"duration":0.051822,"end_time":"2022-03-29T07:49:33.701636","exception":false,"start_time":"2022-03-29T07:49:33.649814","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print('Target column basic statistics:')\ntrain_labels['state'].describe()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.069317,"end_time":"2022-03-29T07:49:33.822138","exception":false,"start_time":"2022-03-29T07:49:33.752821","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.408202Z","iopub.execute_input":"2022-04-02T17:55:40.4085Z","iopub.status.idle":"2022-04-02T17:55:40.419807Z","shell.execute_reply.started":"2022-04-02T17:55:40.408463Z","shell.execute_reply":"2022-04-02T17:55:40.418815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Frequency of each target classes:')\ntrain_labels['state'].value_counts()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.064471,"end_time":"2022-03-29T07:49:33.941039","exception":false,"start_time":"2022-03-29T07:49:33.876568","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.421045Z","iopub.execute_input":"2022-04-02T17:55:40.421828Z","iopub.status.idle":"2022-04-02T17:55:40.430809Z","shell.execute_reply.started":"2022-04-02T17:55:40.421783Z","shell.execute_reply":"2022-04-02T17:55:40.430028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.2\"></a>\n### **<span style=\"color:#7A5197;\">3.2 Test Dataset</span>**\nTest dataset is used to make a prediction based on the model that has previously trained. Exploration in this dataset is also needed to see how the data is structured and especially on it’s similiarity with the train dataset.\n\n","metadata":{"papermill":{"duration":0.052098,"end_time":"2022-03-29T07:49:34.048483","exception":false,"start_time":"2022-03-29T07:49:33.996385","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.2.1\"></a>\n#### **<span style=\"color:#7A5197;\">3.2.1 Quick view</span>**\n","metadata":{"papermill":{"duration":0.052088,"end_time":"2022-03-29T07:49:34.153138","exception":false,"start_time":"2022-03-29T07:49:34.10105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\nB(test_df['subject'].nunique(), '(Subjects)')\nB(test_df['sequence'].nunique(), '(Sequences)')\nB(test_df['step'].nunique(), 'Steps')\n\n#test_df.head()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.077785,"end_time":"2022-03-29T07:49:34.283359","exception":false,"start_time":"2022-03-29T07:49:34.205574","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.431968Z","iopub.execute_input":"2022-04-02T17:55:40.432337Z","iopub.status.idle":"2022-04-02T17:55:40.458843Z","shell.execute_reply.started":"2022-04-02T17:55:40.432304Z","shell.execute_reply":"2022-04-02T17:55:40.458023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.2.2\"></a>\n#### **<span style=\"color:#7A5197;\">3.2.2 Data types</span>**","metadata":{"papermill":{"duration":0.0529,"end_time":"2022-03-29T07:49:34.390482","exception":false,"start_time":"2022-03-29T07:49:34.337582","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df.dtypes","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.064525,"end_time":"2022-03-29T07:49:34.509723","exception":false,"start_time":"2022-03-29T07:49:34.445198","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.459997Z","iopub.execute_input":"2022-04-02T17:55:40.460221Z","iopub.status.idle":"2022-04-02T17:55:40.466998Z","shell.execute_reply.started":"2022-04-02T17:55:40.460195Z","shell.execute_reply":"2022-04-02T17:55:40.466028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3.2.3\"></a>\n#### **<span style=\"color:#7A5197;\">3.2.3 Basic Statistics</span>**\nBelow is the basic statistics for each variables which contain information on count, mean, standard deviation, minimum, 1st quartile, median, 3rd quartile and maximum.","metadata":{"papermill":{"duration":0.053514,"end_time":"2022-03-29T07:49:34.6163","exception":false,"start_time":"2022-03-29T07:49:34.562786","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df.describe()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.086788,"end_time":"2022-03-29T07:49:34.757101","exception":false,"start_time":"2022-03-29T07:49:34.670313","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.471289Z","iopub.execute_input":"2022-04-02T17:55:40.472148Z","iopub.status.idle":"2022-04-02T17:55:40.900452Z","shell.execute_reply.started":"2022-04-02T17:55:40.472104Z","shell.execute_reply":"2022-04-02T17:55:40.899672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3\"></a>\n### **<span style=\"color:#7A5197;\">3.3 Submission</span>**\nBelow is the first 5 rows of submission file:","metadata":{"papermill":{"duration":0.054672,"end_time":"2022-03-29T07:49:34.865871","exception":false,"start_time":"2022-03-29T07:49:34.811199","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ssub.head()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.066963,"end_time":"2022-03-29T07:49:34.987641","exception":false,"start_time":"2022-03-29T07:49:34.920678","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.901452Z","iopub.execute_input":"2022-04-02T17:55:40.901672Z","iopub.status.idle":"2022-04-02T17:55:40.910888Z","shell.execute_reply.started":"2022-04-02T17:55:40.901648Z","shell.execute_reply":"2022-04-02T17:55:40.910022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"4\"></a>\n# **<span style=\"color:#7A5197;\">4. Explore Data Analisys</span>**\n\n<a id=\"4.1\"></a>\n### **<span style=\"color:#7A5197;\">4.1 Target</span>**\n","metadata":{"papermill":{"duration":0.054126,"end_time":"2022-03-29T07:49:35.097676","exception":false,"start_time":"2022-03-29T07:49:35.04355","status":"completed"},"tags":[]}},{"cell_type":"code","source":"colors = ['#7A5197', '#BB5098', '#5344A9', '#F5C63C', '#F47F6B']\n\nplt.subplots(figsize=(25, 10), facecolor='#f6f5f5')\nplt.pie(train_labels['state'].value_counts(), startangle=90, wedgeprops={'width':0.3}, colors=['#F5C63C', '#7A5197'] )\nplt.title('Target Balance Pie Chart', loc='center', fontsize=24, color='#7A5197', fontweight='bold');\nplt.text(0, 0, f\"{train_labels['state'].value_counts()[0] / train_labels['state'].count() * 100:.2f}%\", ha='center', va='center', fontweight='bold', fontsize=42, color='#7A5197');\nplt.legend(train_labels['state'].value_counts().index, ncol=2, facecolor='#f6f5f5', edgecolor='#f6f5f5', loc='lower center', fontsize=16);\nplt.show();","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.309647,"end_time":"2022-03-29T07:49:35.461532","exception":false,"start_time":"2022-03-29T07:49:35.151885","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-02T17:55:40.912096Z","iopub.execute_input":"2022-04-02T17:55:40.912324Z","iopub.status.idle":"2022-04-02T17:55:41.108363Z","shell.execute_reply.started":"2022-04-02T17:55:40.912295Z","shell.execute_reply":"2022-04-02T17:55:41.107413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.2\"></a>\n### **<span style=\"color:#7A5197;\">4.2 Sequence distribution by subject</span>**\n","metadata":{}},{"cell_type":"code","source":"colors = ['#7A5197', '#BB5098', '#5344A9', '#F5C63C', '#F47F6B']\n\nplt.figure(figsize=(13, 4), facecolor='#f6f5f5')\nax = plt.subplot(1,1,1)\ntemp = train_df.subject.value_counts().sort_values() // 60\nax.bar(range(len(temp)), temp, width=1, color=colors[0], zorder=2);\nfor s in [\"top\",\"right\"]:\n    ax.spines[s].set_visible(False)\nax.set_facecolor('#f6f5f5') \n\nax.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\n\nplt.xlabel('subject');\nplt.ylabel('sequence count');\nplt.suptitle('Sequence distribution by subject', y=1.02, fontweight='bold');\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T17:55:41.109575Z","iopub.execute_input":"2022-04-02T17:55:41.109826Z","iopub.status.idle":"2022-04-02T17:55:42.724701Z","shell.execute_reply.started":"2022-04-02T17:55:41.109799Z","shell.execute_reply":"2022-04-02T17:55:42.723697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.3\"></a>\n### **<span style=\"color:#7A5197;\">4.3 Features distribution</span>**\n","metadata":{}},{"cell_type":"code","source":"FEATURES = [f'sensor_0{i+1}' for i in range(9)] + [f'sensor_{i+1}' for i in range(9, 12)]\ncolors = ['#7A5197', '#BB5098', '#5344A9', '#F5C63C', '#F47F6B']\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(15, 10), facecolor='#f6f5f5')\ngs = fig.add_gridspec(4, 3)\ngs.update(wspace=0.3, hspace=0.2)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 4):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        for s in [\"top\",\"right\", 'left']:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n        \n        \n\nrun_no = 0\nfor col in FEATURES:\n    sns.kdeplot(train_df[col], ax=locals()[\"ax\"+str(run_no)], shade=True, color=colors[0], \n                edgecolor='black', linewidth=0, alpha=1, zorder=3);\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\n    locals()[\"ax\"+str(run_no)].set_ylabel(col, fontsize=10, fontweight='bold').set_rotation(0);\n    locals()[\"ax\"+str(run_no)].yaxis.set_label_coords(1.1, 0);\n    locals()[\"ax\"+str(run_no)].set_xlabel('');\n    run_no += 1\n    \nplt.suptitle('Features distribution', fontweight='bold');\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T17:55:42.726365Z","iopub.execute_input":"2022-04-02T17:55:42.726688Z","iopub.status.idle":"2022-04-02T17:56:57.873163Z","shell.execute_reply.started":"2022-04-02T17:55:42.726649Z","shell.execute_reply":"2022-04-02T17:56:57.872466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.4\"></a>\n### **<span style=\"color:#7A5197;\">4.4 Selected Time Series</span>**\n","metadata":{}},{"cell_type":"code","source":"sequences = [0, 1, 2, 8364, 15404]\nfigure, axes = plt.subplots(13, len(sequences), sharex=True, figsize=(16, 16), facecolor='#f6f5f5')\ncolors = ['#7A5197', '#BB5098', '#5344A9', '#F5C63C', '#F47F6B']\n\nfor i, sequence in enumerate(sequences):\n    for sensor in range(13):\n        sensor_name = f\"sensor_{sensor:02d}\"\n        ax = plt.subplot(13, len(sequences), sensor * len(sequences) + i + 1)\n        for s in [\"top\",\"right\"]:\n                ax.spines[s].set_visible(False)\n        ax.set_facecolor('#f6f5f5')\n        plt.plot(range(60), train_df[train_df.sequence == sequence][sensor_name],\n                color=colors[i]);        #plt.rcParams['axes.prop_cycle'].by_key()['color'][i % 10])\n        if sensor == 0: plt.title(f\"Sequence {sequence}\");\n        if sequence == sequences[0]: plt.ylabel(sensor_name);\nfigure.tight_layout(w_pad=0.1)\nplt.suptitle('Selected Time Series', y=1.02, fontweight='bold');\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T17:56:57.874186Z","iopub.execute_input":"2022-04-02T17:56:57.877284Z","iopub.status.idle":"2022-04-02T17:57:13.409818Z","shell.execute_reply.started":"2022-04-02T17:56:57.877236Z","shell.execute_reply":"2022-04-02T17:57:13.409116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.5\"></a>\n### **<span style=\"color:#7A5197;\">4.5 Profile per step with Quantiles</span>**\n","metadata":{}},{"cell_type":"code","source":"train_df = pd.merge(train_df, train_labels, left_on='sequence', right_on='sequence')\n\n\n\nsensors = train_df.columns[train_df.columns.str.contains('sensor')]\n\n\nstate_0 = f\"{int(round((train_df['state']==0).sum() / len(train_df)*100))}\"\n#B('~'+state_0+'%', 'State 0', progress=state_0)\nstate_1 = f\"{int(round((train_df['state']==1).sum() / len(train_df)*100))}\"\n#B('~'+state_1+'%', 'State 1', progress=state_1)\n\nsteps_0 = train_df[train_df['state']==0].pivot_table(\n    index=['step'],\n    values=sensors,\n    aggfunc='mean'\n)\n\nsteps_1 = train_df[train_df['state']==1].pivot_table(\n    index=['step'],\n    values=sensors,\n    aggfunc='mean'\n)\n\nfig, ax = plt.subplots(1, 2, figsize=(15,8), sharey=True, constrained_layout=True, facecolor='#f6f5f5')\n_ = ax[0].plot(steps_0.median(axis=1), label='PCT 50%', c=colors[0])\n_ = ax[0].plot(steps_0.quantile(0.9, axis=1), label='PCT 90%', c=colors[0], alpha=0.25)\n_ = ax[0].plot(steps_0.quantile(0.8, axis=1), label='PCT 80%', c=colors[0], alpha=0.5)\n_ = ax[0].plot(steps_0.quantile(0.2, axis=1), label='PCT 20%', c=colors[0], alpha=0.5)\n_ = ax[0].plot(steps_0.quantile(0.1, axis=1), label='PCT 10%', c=colors[0], alpha=0.25)\n_ = ax[0].plot([0]*len(steps_0), c='black')\n_ = ax[0].legend(ncol=5, facecolor='#f6f5f5', edgecolor='#f6f5f5', loc='lower center')\n_ = ax[0].set_xlabel('Step')\n_ = ax[0].set_ylabel('Value')\n_ = ax[0].set_title('State 0')\nfor s in [\"top\",\"right\"]:\n    ax[0].spines[s].set_visible(False)\n_ = ax[0].set_facecolor('#f6f5f5')\n\n\n_ = ax[1].plot(steps_1.median(axis=1), label='PCT 50%', c=colors[1])\n_ = ax[1].plot(steps_1.quantile(0.9, axis=1), label='PCT 90%', c=colors[1], alpha=0.25)\n_ = ax[1].plot(steps_1.quantile(0.8, axis=1), label='PCT 80%', c=colors[1], alpha=0.5)\n_ = ax[1].plot(steps_1.quantile(0.2, axis=1), label='PCT 20%', c=colors[1], alpha=0.5)\n_ = ax[1].plot(steps_1.quantile(0.1, axis=1), label='PCT 10%', c=colors[1], alpha=0.25)\n_ = ax[1].plot([0]*len(steps_0), c='black')\n_ = ax[1].set_xlabel('Step')\n_ = ax[1].legend(ncol=5, facecolor='#f6f5f5', edgecolor='#f6f5f5', loc='lower center')\n#plt.legend(train_labels['state'].value_counts().index, ncol=2, facecolor='#f6f5f5', edgecolor='#f6f5f5', loc='lower center', fontsize=16);\n\n_ = ax[1].set_title('State 1')\nfor s in [\"top\",\"right\"]:\n    ax[1].spines[s].set_visible(False)\n_ = ax[1].set_facecolor('#f6f5f5')\n        \n\n_ = fig.suptitle('States 0|1 (mean) Profile per step with Quantiles', fontweight='bold')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T17:57:13.41085Z","iopub.execute_input":"2022-04-02T17:57:13.411567Z","iopub.status.idle":"2022-04-02T17:57:18.208972Z","shell.execute_reply.started":"2022-04-02T17:57:13.411533Z","shell.execute_reply":"2022-04-02T17:57:18.206185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.6\"></a>\n### **<span style=\"color:#7A5197;\">4.6 Profile per Subject with Quantiles</span>**\n","metadata":{}},{"cell_type":"code","source":"# Can we see that but through Subjects instead of Steps?\n\nsteps_0 = train_df[train_df['state']==0].pivot_table(\n    index=['subject'],\n    values=sensors,\n    aggfunc='mean'\n)\n\nsteps_1 = train_df[train_df['state']==1].pivot_table(\n    index=['subject'],\n    values=sensors,\n    aggfunc='mean'\n)\n\nfig, ax = plt.subplots(2, 1, figsize=(15,10), sharey=True, constrained_layout=True, facecolor='#f6f5f5')\n_ = ax[0].plot(steps_0.median(axis=1), label='PCT 50%', c=colors[0])\n_ = ax[0].plot(steps_0.quantile(0.9, axis=1), label='PCT 90%', c=colors[0], alpha=0.25)\n_ = ax[0].plot(steps_0.quantile(0.8, axis=1), label='PCT 80%', c=colors[0], alpha=0.5)\n_ = ax[0].plot(steps_0.quantile(0.2, axis=1), label='PCT 20%', c=colors[0], alpha=0.5)\n_ = ax[0].plot(steps_0.quantile(0.1, axis=1), label='PCT 10%', c=colors[0], alpha=0.25)\n_ = ax[0].plot([0]*len(steps_0), c='black')\n_ = ax[0].legend(ncol=5, facecolor='#f6f5f5', edgecolor='#f6f5f5', loc='lower center')\n_ = ax[0].set_ylabel('Value')\n_ = ax[0].set_title('State 0')\nfor s in [\"top\",\"right\"]:\n    ax[0].spines[s].set_visible(False)\n_ = ax[0].set_facecolor('#f6f5f5')\n\n\n_ = ax[1].plot(steps_1.median(axis=1), label='PCT 50%', c=colors[1])\n_ = ax[1].plot(steps_1.quantile(0.9, axis=1), label='PCT 90%', c=colors[1], alpha=0.25)\n_ = ax[1].plot(steps_1.quantile(0.8, axis=1), label='PCT 80%', c=colors[1], alpha=0.5)\n_ = ax[1].plot(steps_1.quantile(0.2, axis=1), label='PCT 20%', c=colors[1], alpha=0.5)\n_ = ax[1].plot(steps_1.quantile(0.1, axis=1), label='PCT 10%', c=colors[1], alpha=0.25)\n_ = ax[1].plot([0]*len(steps_0), c='black')\n_ = ax[1].set_ylabel('Value')\n_ = ax[1].set_xlabel('Subject')\n_ = ax[1].legend(ncol=5, facecolor='#f6f5f5', edgecolor='#f6f5f5', loc='lower center')\n_ = ax[1].set_title('State 1')\nfor s in [\"top\",\"right\"]:\n    ax[1].spines[s].set_visible(False)\n_ = ax[1].set_facecolor('#f6f5f5')\n\n_ = fig.suptitle('States 0|1 (mean) Profile per Subject with Quantiles', fontweight='bold')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T17:57:18.210683Z","iopub.execute_input":"2022-04-02T17:57:18.21098Z","iopub.status.idle":"2022-04-02T17:57:23.566484Z","shell.execute_reply.started":"2022-04-02T17:57:18.210946Z","shell.execute_reply":"2022-04-02T17:57:23.565467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.7\"></a>\n### **<span style=\"color:#7A5197;\">4.7 Scatter plot features</span>**\n","metadata":{}},{"cell_type":"code","source":"FEATURES = [f'sensor_0{i+1}' for i in range(9)] + [f'sensor_{i+1}' for i in range(9, 12)]\ncolors = ['#7A5197', '#BB5098', '#5344A9', '#F5C63C', '#F47F6B']\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(15, 10), facecolor='#f6f5f5')\ngs = fig.add_gridspec(4, 3)\ngs.update(wspace=0.3, hspace=0.2)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 4):\n    for col in range(0, 3):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        for s in [\"top\",\"right\", 'left']:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n        \n        \n\nrun_no = 0\nfor col in FEATURES:\n    sns.scatterplot(train_df[col], train_df.index, ax=locals()[\"ax\"+str(run_no)], color=colors[0], \n                edgecolor=None, linewidth=0, alpha=1, zorder=3);\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\n    locals()[\"ax\"+str(run_no)].set_ylabel(col, fontsize=10, fontweight='bold').set_rotation(0);\n    locals()[\"ax\"+str(run_no)].yaxis.set_label_coords(1.1, 0);\n    locals()[\"ax\"+str(run_no)].set_xlabel('');\n    run_no += 1\n    \nplt.suptitle('Features distribution', fontweight='bold');\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T17:57:23.567842Z","iopub.execute_input":"2022-04-02T17:57:23.56806Z","iopub.status.idle":"2022-04-02T18:01:58.149193Z","shell.execute_reply.started":"2022-04-02T17:57:23.568036Z","shell.execute_reply":"2022-04-02T18:01:58.147843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"4.8\"></a>\n### **<span style=\"color:#7A5197;\">4.8 Correlation</span>**\n","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(10, 10), facecolor='#f6f5f5')\nsns.heatmap(train_df.corr(), cmap='BuPu')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:01:58.150872Z","iopub.execute_input":"2022-04-02T18:01:58.151591Z","iopub.status.idle":"2022-04-02T18:02:01.967601Z","shell.execute_reply.started":"2022-04-02T18:01:58.151549Z","shell.execute_reply":"2022-04-02T18:02:01.966967Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"5\"></a>\n# **<span style=\"color:#7A5197;\">LSTM</span>**\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import GlobalMaxPooling1D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.layers import Concatenate, LSTM, GRU\nfrom tensorflow.keras.layers import Bidirectional, Multiply\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import KFold, GroupKFold","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:04:50.55501Z","iopub.execute_input":"2022-04-02T18:04:50.555819Z","iopub.status.idle":"2022-04-02T18:04:50.563628Z","shell.execute_reply.started":"2022-04-02T18:04:50.555776Z","shell.execute_reply":"2022-04-02T18:04:50.562799Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\nssub = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:04:50.741849Z","iopub.execute_input":"2022-04-02T18:04:50.742243Z","iopub.status.idle":"2022-04-02T18:04:59.850585Z","shell.execute_reply.started":"2022-04-02T18:04:50.742216Z","shell.execute_reply":"2022-04-02T18:04:59.849524Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train_df.columns.tolist()[3:]\ndef prep(df):\n    for feature in features:\n        df[feature + '_lag1'] = df.groupby('sequence')[feature].shift(1)\n        df.fillna(0, inplace=True)\n        df[feature + '_diff1'] = df[feature] - df[feature + '_lag1']    \n\nprep(train_df)\nprep(test_df)\n\nfeatures = train_df.columns.tolist()[3:]\nsc = StandardScaler()\ntrain_df[features] = sc.fit_transform(train_df[features])\ntest_df[features] = sc.transform(test_df[features])\n\ngroups = train_df[\"sequence\"]\nlabels = train_labels[\"state\"]\n\ntrain_df = train_df.drop([\"sequence\", \"subject\", \"step\"], axis=1).values\ntrain_df = train_df.reshape(-1, 60, train_df.shape[-1])\n\ntest_df = test_df.drop([\"sequence\", \"subject\", \"step\"], axis=1).values\ntest_df = test_df.reshape(-1, 60, test_df.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:04:59.852354Z","iopub.execute_input":"2022-04-02T18:04:59.852631Z","iopub.status.idle":"2022-04-02T18:05:09.140759Z","shell.execute_reply.started":"2022-04-02T18:04:59.852583Z","shell.execute_reply":"2022-04-02T18:05:09.139829Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n    print(\"Running on TPU:\", tpu.master())\n    print(f\"Batch Size: {BATCH_SIZE}\")\n    \nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE = 256\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    print(f\"Batch Size: {BATCH_SIZE}\")\n    \n    \ndef dnn_model():\n    \n    x_input = Input(shape=(train_df.shape[-2:]))\n    \n    x1 = Bidirectional(LSTM(units=512, return_sequences=True))(x_input)\n    x2 = Bidirectional(LSTM(units=256, return_sequences=True))(x1)\n    z1 = Bidirectional(GRU(units=256, return_sequences=True))(x1)\n    \n    c = Concatenate(axis=2)([x2, z1])\n    \n    x3 = Bidirectional(LSTM(units=128, return_sequences=True))(c)\n    \n    x4 = GlobalMaxPooling1D()(x3)\n    x5 = Dense(units=128, activation='selu')(x4)\n    x_output = Dense(1, activation='sigmoid')(x5)\n\n    model = Model(inputs=x_input, outputs=x_output, name='lstm_model')\n    \n    return model\n\nmodel = dnn_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:05:09.141909Z","iopub.execute_input":"2022-04-02T18:05:09.142144Z","iopub.status.idle":"2022-04-02T18:05:17.337627Z","shell.execute_reply.started":"2022-04-02T18:05:09.142115Z","shell.execute_reply":"2022-04-02T18:05:17.336802Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    VERBOSE = True\n    predictions, scores = [], []\n    k = GroupKFold(n_splits = 10)\n\n    for fold, (train_idx, val_idx) in enumerate(k.split(train_df, labels, groups.unique())):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n    \n        X_train, X_val = train_df[train_idx], train_df[val_idx]\n        y_train, y_val = labels.iloc[train_idx].values, labels.iloc[val_idx].values\n        \n        model = dnn_model()\n        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics='AUC')\n\n        lr = ReduceLROnPlateau(monitor=\"val_auc\", factor=0.6, \n                               patience=4, verbose=VERBOSE)\n\n        es = EarlyStopping(monitor=\"val_auc\", patience=7, \n                           verbose=VERBOSE, mode=\"max\", \n                           restore_best_weights=True)\n        \n        save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n        chk_point = ModelCheckpoint(f'./TPS_model_2022_{fold+1}C.h5', options=save_locally, \n                                    monitor='val_auc', verbose=VERBOSE, \n                                    save_best_only=True, mode='max')\n        \n        model.fit(X_train, y_train, \n                  validation_data=(X_val, y_val), \n                  epochs=15,\n                  verbose=VERBOSE,\n                  batch_size=BATCH_SIZE, \n                  callbacks=[lr, chk_point, es])\n        \n        load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n        model = load_model(f'./TPS_model_2022_{fold+1}C.h5', options=load_locally)\n        \n        y_pred = model.predict(X_val, batch_size=BATCH_SIZE).squeeze()\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        predictions.append(model.predict(test_df, batch_size=BATCH_SIZE).squeeze())\n        print(f\"Fold-{fold+1} | OOF Score: {score}\")\n    \n    print(f'Mean accuracy on {k.n_splits} folds - {np.mean(scores)}')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T18:06:19.515883Z","iopub.execute_input":"2022-04-02T18:06:19.516167Z","iopub.status.idle":"2022-04-02T18:21:53.89047Z","shell.execute_reply.started":"2022-04-02T18:06:19.516141Z","shell.execute_reply":"2022-04-02T18:21:53.889772Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ssub[\"state\"] = sum(predictions)/k.n_splits \nssub.to_csv('submition.csv', index=False)\nssub.head(3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-02T18:43:40.467491Z","iopub.execute_input":"2022-04-02T18:43:40.46786Z","iopub.status.idle":"2022-04-02T18:43:40.520525Z","shell.execute_reply.started":"2022-04-02T18:43:40.467826Z","shell.execute_reply":"2022-04-02T18:43:40.519698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<a id=\"6\"></a>\n# **<span style=\"color:#7A5197;\">References</span>**\n\n[@ambrosm](https://www.kaggle.com/code/ambrosm/tpsapr22-eda-which-makes-sense)\n\n[@torchme](https://www.kaggle.com/code/kartushovdanil/bird-eda-dark-charts)\n\n[@maulberto3](https://www.kaggle.com/code/maulberto3/tps-april-2022-easy-eda)\n\n[@javigallego](https://www.kaggle.com/code/javigallego/tps-apr22-eda-skewness-outliers-and-more)\n\n[@dmitryuarov](https://www.kaggle.com/code/dmitryuarov/tps-sensors-auc-0-964)","metadata":{}}]}