{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup, Data Import, Functions","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:08:14.482683Z","iopub.execute_input":"2022-04-13T16:08:14.482987Z","iopub.status.idle":"2022-04-13T16:08:14.488177Z","shell.execute_reply.started":"2022-04-13T16:08:14.482953Z","shell.execute_reply":"2022-04-13T16:08:14.486953Z"}}},{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all' #'last_expr'\n\nimport math, time, datetime as dt, os, sys \nfrom pathlib import Path\n\nimport pandas as pd\npd.options.display.max_columns = None\npd.options.display.max_colwidth = 999\npd.options.display.max_rows = 51\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# sns.set_theme()\n\nimport numpy as np\nnp.set_printoptions(edgeitems=5,linewidth=250)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GroupKFold\n\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\n\nRS = 336699 # Random State","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-13T17:09:26.97094Z","iopub.execute_input":"2022-04-13T17:09:26.971207Z","iopub.status.idle":"2022-04-13T17:09:26.980361Z","shell.execute_reply.started":"2022-04-13T17:09:26.971179Z","shell.execute_reply":"2022-04-13T17:09:26.97919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = '/kaggle/input/tabular-playground-series-apr-2022/'\ndf_train_lbl = pd.read_csv(f'{base_path}/train_labels.csv')\n'df_train_lbl.shape', df_train_lbl.shape\n\ndf_train = pd.read_csv(f'{base_path}/train.csv')\n'df_train.shape', df_train.shape\n\ndf_train = df_train.merge(df_train_lbl, on=['sequence'], how='left')\n'df_train.shape', df_train.shape\n\ntarget_col = 'state'\n'target_col', target_col\n\nsensor_cols = df_train.columns[3:-1].to_list()\n'sensor_cols', sensor_cols","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-13T17:09:27.112213Z","iopub.execute_input":"2022-04-13T17:09:27.112603Z","iopub.status.idle":"2022-04-13T17:09:31.317039Z","shell.execute_reply.started":"2022-04-13T17:09:27.112572Z","shell.execute_reply":"2022-04-13T17:09:31.315985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Intro","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:07:27.735879Z","iopub.execute_input":"2022-04-13T17:07:27.736146Z","iopub.status.idle":"2022-04-13T17:07:27.741129Z","shell.execute_reply.started":"2022-04-13T17:07:27.736118Z","shell.execute_reply":"2022-04-13T17:07:27.73975Z"}}},{"cell_type":"markdown","source":"<h3>Hi!, </h3>\n\nIn this Notebook i will present some feature engineering ideas and test them on 3 Gradient Boosting Models on GroupKFold.<br>\nFor now, I am using only 5 CVs and the models are not tunned.<br>\nWhen I'll run out of ideas for features, I will tune the models with Optuna and ensemble with stacking and/or voting. ","metadata":{}},{"cell_type":"code","source":"def score(models, X, y, groups):\n    # Iterates over models from `models' list and fit's each with GroupKFold with 5 splits\n    all_scores = []\n    for model in models:\n        \n        cv_scores = [] \n        for idx_train, idx_test in GroupKFold(n_splits=5).split(X, groups = groups):\n            X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n            y_train, y_test = y.iloc[idx_train], y.iloc[idx_test]\n\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            score = roc_auc_score(y_test, y_pred)\n            cv_scores.append(score)\n\n        cv_mean_std = f'{np.mean(cv_scores):.3f} +/- {np.std(cv_scores):.4f}'\n        all_scores.append(cv_mean_std)\n        print(f'{model.__class__.__name__} - {cv_mean_std}')\n\n    return all_scores\n\nmodels= [\n    LGBMClassifier(random_state=RS, ),\n    XGBClassifier(random_state=RS, use_label_encoder=False, verbosity=0, tree_method = 'gpu_hist'),\n    CatBoostClassifier(random_state=RS, silent=True, task_type = 'GPU'),\n        ]\n\ndf_scores = pd.DataFrame({\n    'models': [model.__class__.__name__ for model in models]\n})\n\nhighlight_cols = lambda  s: 'background-color: % s' % 'lightgreen'","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:09:31.31921Z","iopub.execute_input":"2022-04-13T17:09:31.319689Z","iopub.status.idle":"2022-04-13T17:09:31.335168Z","shell.execute_reply.started":"2022-04-13T17:09:31.319646Z","shell.execute_reply":"2022-04-13T17:09:31.333816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit: Raw Data - baseline","metadata":{}},{"cell_type":"code","source":"df = df_train\ny = df['state']\ny.shape\nX = df[ sensor_cols + ['step'] ]\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:09:31.337254Z","iopub.execute_input":"2022-04-13T17:09:31.337722Z","iopub.status.idle":"2022-04-13T17:09:31.460912Z","shell.execute_reply.started":"2022-04-13T17:09:31.33768Z","shell.execute_reply":"2022-04-13T17:09:31.459925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's train the GBMs on raw data to have a baseline to improve on.","metadata":{}},{"cell_type":"code","source":"%%time\ndf_scores['raw-data'] = score(models, X, y, df.subject)\ndf_scores.style.applymap(highlight_cols, subset=pd.IndexSlice[:, ['raw-data']])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:09:31.46316Z","iopub.execute_input":"2022-04-13T17:09:31.463696Z","iopub.status.idle":"2022-04-13T17:14:11.343528Z","shell.execute_reply.started":"2022-04-13T17:09:31.46365Z","shell.execute_reply":"2022-04-13T17:14:11.3427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Results of last training are highlighted in green. I will be adding columns to this dataframe with results as we go.","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:22:32.525301Z","iopub.execute_input":"2022-04-13T17:22:32.525697Z","iopub.status.idle":"2022-04-13T17:22:32.538129Z","shell.execute_reply.started":"2022-04-13T17:22:32.525665Z","shell.execute_reply":"2022-04-13T17:22:32.537095Z"}}},{"cell_type":"markdown","source":"# Fit: Aggregate All Sensor data for a Sequences","metadata":{}},{"cell_type":"markdown","source":"This will drastically reduce the number of features as we will replace data from 13 sensors with 5 columns and additionally aggregate by sequence which will reduce rows 60 folds.","metadata":{}},{"cell_type":"code","source":"X2 = df.groupby(['sequence', 'subject'])[sensor_cols].agg(['mean', 'std', 'skew', 'max', 'min']).reset_index()\nX2.columns = ['_'.join(col) for col in X2.columns]\nX2.shape\n\ny2 = df.groupby(['sequence']).state.min()\ny2.shape\n\ngroup2 = df.groupby(['sequence']).subject.min()\ngroup2.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:37:29.919217Z","iopub.execute_input":"2022-04-13T16:37:29.919715Z","iopub.status.idle":"2022-04-13T16:38:08.047544Z","shell.execute_reply.started":"2022-04-13T16:37:29.919672Z","shell.execute_reply":"2022-04-13T16:38:08.046801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_scores['aggregate-sensor'] = score(models, X2, y2, group2)\ndf_scores.style.applymap(highlight_cols, subset=pd.IndexSlice[:, ['aggregate-sensor']])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:38:08.049142Z","iopub.execute_input":"2022-04-13T16:38:08.049575Z","iopub.status.idle":"2022-04-13T16:38:45.511107Z","shell.execute_reply.started":"2022-04-13T16:38:08.049535Z","shell.execute_reply":"2022-04-13T16:38:45.510502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit: Add Subject Count","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:28:50.286001Z","iopub.execute_input":"2022-04-13T16:28:50.286265Z","iopub.status.idle":"2022-04-13T16:28:50.290767Z","shell.execute_reply.started":"2022-04-13T16:28:50.286237Z","shell.execute_reply":"2022-04-13T16:28:50.289955Z"}}},{"cell_type":"code","source":"subject_count = df.subject.value_counts()\nX3 = X2.merge(subject_count, left_on=['subject_'], right_index=True, how='left')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:38:45.514619Z","iopub.execute_input":"2022-04-13T16:38:45.516322Z","iopub.status.idle":"2022-04-13T16:38:45.543485Z","shell.execute_reply.started":"2022-04-13T16:38:45.516286Z","shell.execute_reply":"2022-04-13T16:38:45.542841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# we've just added a new column to X3, we can reuse y2 and group2\ndf_scores['agg+subject_count'] = score(models, X3, y2, group2)\ndf_scores.style.applymap(highlight_cols, subset=pd.IndexSlice[:, ['agg+subject_count']])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T17:32:02.944586Z","iopub.execute_input":"2022-04-13T17:32:02.944907Z","iopub.status.idle":"2022-04-13T17:32:02.969367Z","shell.execute_reply.started":"2022-04-13T17:32:02.944877Z","shell.execute_reply":"2022-04-13T17:32:02.968456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What's next :\n- explore other feature engineering ideas\n- optimise training:\n    - increase cv to 10+\n    - optimise models with Optuna\n    - stack multiple models\n    - explore voting","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}