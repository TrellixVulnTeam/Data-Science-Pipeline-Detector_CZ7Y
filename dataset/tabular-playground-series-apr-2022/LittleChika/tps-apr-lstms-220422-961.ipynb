{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import GlobalMaxPooling1D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.layers import Concatenate, LSTM, GRU\nfrom tensorflow.keras.layers import Bidirectional, Multiply\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import GroupKFold\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T11:47:50.502286Z","iopub.execute_input":"2022-04-22T11:47:50.503504Z","iopub.status.idle":"2022-04-22T11:47:50.524546Z","shell.execute_reply.started":"2022-04-22T11:47:50.503454Z","shell.execute_reply":"2022-04-22T11:47:50.523189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up tpu to acclerate model training >> not available\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:47:50.527279Z","iopub.execute_input":"2022-04-22T11:47:50.527689Z","iopub.status.idle":"2022-04-22T11:47:56.480799Z","shell.execute_reply.started":"2022-04-22T11:47:50.527638Z","shell.execute_reply":"2022-04-22T11:47:56.479786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/train.csv')\ndf_train_labels = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/train_labels.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/test.csv')\ndf_smpl = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:47:56.482282Z","iopub.execute_input":"2022-04-22T11:47:56.482642Z","iopub.status.idle":"2022-04-22T11:48:04.508351Z","shell.execute_reply.started":"2022-04-22T11:47:56.482587Z","shell.execute_reply":"2022-04-22T11:48:04.507592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add lagged feature and difference features\n\nfeatures = df_train.columns.tolist()[3:]\n\ndef preprocessing(df):\n    for feature in features:\n        df[feature + '_lag1'] = df.groupby('sequence')[feature].shift(1)\n        df.fillna(0, inplace=True)\n        df[feature + '_diff1'] = df[feature] - df[feature + '_lag1']\n        \n    #return df","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:04.511063Z","iopub.execute_input":"2022-04-22T11:48:04.511424Z","iopub.status.idle":"2022-04-22T11:48:04.519108Z","shell.execute_reply.started":"2022-04-22T11:48:04.511377Z","shell.execute_reply":"2022-04-22T11:48:04.517934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:04.521034Z","iopub.execute_input":"2022-04-22T11:48:04.521376Z","iopub.status.idle":"2022-04-22T11:48:12.001133Z","shell.execute_reply.started":"2022-04-22T11:48:04.521332Z","shell.execute_reply":"2022-04-22T11:48:12.000153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:12.002641Z","iopub.execute_input":"2022-04-22T11:48:12.002901Z","iopub.status.idle":"2022-04-22T11:48:15.245874Z","shell.execute_reply.started":"2022-04-22T11:48:12.002871Z","shell.execute_reply":"2022-04-22T11:48:15.244753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# minmax scaling \n\nfeatures = df_train.columns.tolist()[3:]\nsc = MinMaxScaler()\ndf_train[features] = sc.fit_transform(df_train[features])\ndf_test[features] = sc.transform(df_test[features])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:15.247552Z","iopub.execute_input":"2022-04-22T11:48:15.247996Z","iopub.status.idle":"2022-04-22T11:48:18.115999Z","shell.execute_reply.started":"2022-04-22T11:48:15.247943Z","shell.execute_reply":"2022-04-22T11:48:18.115005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standard scaling\n\nfeatures = df_train.columns.tolist()[3:]\nstd_sc = StandardScaler()\ndf_train[features] = std_sc.fit_transform(df_train[features])\ndf_test[features] = std_sc.transform(df_test[features])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:18.117437Z","iopub.execute_input":"2022-04-22T11:48:18.117771Z","iopub.status.idle":"2022-04-22T11:48:21.234908Z","shell.execute_reply.started":"2022-04-22T11:48:18.117729Z","shell.execute_reply":"2022-04-22T11:48:21.233967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape for lstm model input\n# The LSTM needs data with the format of [samples, time steps and features].\n\ngroups = df_train['sequence']\nlabels = df_train_labels['state']\n\ndf_train = df_train.drop(['sequence', 'subject', 'step'], axis=1).values\ndf_train = df_train.reshape(-1, 60, df_train.shape[-1])\n\ndf_test = df_test.drop(['sequence', 'subject', 'step'], axis=1).values\ndf_test = df_test.reshape(-1, 60, df_test.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:21.236305Z","iopub.execute_input":"2022-04-22T11:48:21.236553Z","iopub.status.idle":"2022-04-22T11:48:21.606149Z","shell.execute_reply.started":"2022-04-22T11:48:21.236525Z","shell.execute_reply":"2022-04-22T11:48:21.605326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model\n\ndef lstm_0422():\n    with tpu_strategy.scope():\n        x_input = Input(shape=(df_train.shape[-2:])) # (60,39)\n\n        x1 = Bidirectional(LSTM(units=512, return_sequences=True))(x_input)\n        x2 = Bidirectional(LSTM(units=256, return_sequences=True))(x1)\n        z1 = Bidirectional(GRU(units=256, return_sequences=True))(x1)\n\n        c = Concatenate(axis=2)([x2, z1])\n\n        x3 = Bidirectional(LSTM(units=128, return_sequences=True))(c)\n\n        x4 = GlobalMaxPooling1D()(x3)\n        x5 = Dense(units=128, activation='selu')(x4)\n        x_output = Dense(1, activation='sigmoid')(x5)\n\n        model = Model(inputs=x_input, outputs=x_output, name='lstm_model')\n        model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=[AUC(name = 'auc')])\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:21.655279Z","iopub.execute_input":"2022-04-22T11:48:21.656204Z","iopub.status.idle":"2022-04-22T11:48:21.66784Z","shell.execute_reply.started":"2022-04-22T11:48:21.65615Z","shell.execute_reply":"2022-04-22T11:48:21.666893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lstm_0422()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:21.669316Z","iopub.execute_input":"2022-04-22T11:48:21.670871Z","iopub.status.idle":"2022-04-22T11:48:24.103927Z","shell.execute_reply.started":"2022-04-22T11:48:21.670823Z","shell.execute_reply":"2022-04-22T11:48:24.10216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:24.128304Z","iopub.execute_input":"2022-04-22T11:48:24.128741Z","iopub.status.idle":"2022-04-22T11:48:24.498611Z","shell.execute_reply.started":"2022-04-22T11:48:24.128688Z","shell.execute_reply":"2022-04-22T11:48:24.497454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\ntest_preds = []\nkf = GroupKFold(n_splits=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:24.500758Z","iopub.execute_input":"2022-04-22T11:48:24.50131Z","iopub.status.idle":"2022-04-22T11:48:24.506201Z","shell.execute_reply.started":"2022-04-22T11:48:24.501253Z","shell.execute_reply":"2022-04-22T11:48:24.505208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold_idx, (train_idx, valid_idx) in enumerate(kf.split(df_train, df_train_labels, groups.unique())):\n    \n    print('\\n')\n    print('*'*15, f'↓ Fold {fold_idx+1} ↓', '*'*15)\n    \n    # Separate into train data and validation data\n    X_train, X_valid = df_train[train_idx], df_train[valid_idx]\n    y_train, y_valid = labels.iloc[train_idx].values, labels.iloc[valid_idx].values\n    \n    # Train the model\n    model = lstm_0422()\n    model.fit(X_train, y_train, \n              validation_data=(X_valid, y_valid), \n              epochs=15, \n              batch_size=256, \n              callbacks=[EarlyStopping(monitor='val_auc', patience=7, mode='max', \n                                       restore_best_weights=True),\n                         ReduceLROnPlateau(monitor='val_auc', factor=0.6, \n                                           patience=4, verbose=False)]\n             )\n    \n    # Save score\n    score = roc_auc_score(y_valid, model.predict(X_valid, batch_size=512).squeeze())\n    scores.append(score)\n    \n    # Predict\n    test_preds.append(model.predict(df_test, batch_size=512).squeeze())\n    \n    print(f'Fold {fold_idx+1} | Score: {score}')\n    print('*'*15, f'↑ Fold {fold_idx+1} ↑', '*'*15)\n    \nprint(f'Mean accuracy on {kf.n_splits} folds {np.mean(scores)}')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:48:24.508293Z","iopub.execute_input":"2022-04-22T11:48:24.508677Z","iopub.status.idle":"2022-04-22T11:53:47.617353Z","shell.execute_reply.started":"2022-04-22T11:48:24.508629Z","shell.execute_reply":"2022-04-22T11:53:47.616304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_0422 = df_smpl\n\nsubmission_0422['state'] = np.average(test_preds, axis = 0)\nsubmission_0422.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:02:36.75504Z","iopub.execute_input":"2022-04-22T12:02:36.756621Z","iopub.status.idle":"2022-04-22T12:02:36.808019Z","shell.execute_reply.started":"2022-04-22T12:02:36.756519Z","shell.execute_reply":"2022-04-22T12:02:36.807268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}