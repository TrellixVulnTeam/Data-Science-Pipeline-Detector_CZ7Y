{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Learned a lot from excellent others' notebooks.\n##### Please feel free to leave an upvote if you find it helpful.\n##### It will be my huge motivation. Appreciate it!","metadata":{}},{"cell_type":"markdown","source":"#### ideas have been testified\n#### 1. performed feature engineering by aggregation method >> the most effective method\n#### 2. exhausted popular gbdt algorithm: lightGBM, CatBoost, and XGBoost >> current best, catboost\n#### 3. created a pipeline to incorporate both scalers and the classifier\n#### 4. applied predict_prob rather than predict to output probabilites >> turns out to be effective\n\n#### ideas yet to be testified\n#### 1. hyperparameter tuning >> ongoing\n#### 2. stackCVClassifier >> not quite works\n#### 3. lagged features >> imrpoved a tiny bit\n#### 4. LSTM models >> ongoing","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport lightgbm as lgb\nimport catboost as cgb\n\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom skopt import BayesSearchCV\nfrom skopt.space import Real, Categorical, Integer\nfrom skopt.plots import plot_objective, plot_histogram\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T03:19:23.593775Z","iopub.execute_input":"2022-04-16T03:19:23.594085Z","iopub.status.idle":"2022-04-16T03:19:26.846356Z","shell.execute_reply.started":"2022-04-16T03:19:23.594006Z","shell.execute_reply":"2022-04-16T03:19:26.845634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/train.csv')\ndf_train_labels = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/train_labels.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/test.csv')\ndf_smpl = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:31.716981Z","iopub.execute_input":"2022-04-16T03:22:31.717233Z","iopub.status.idle":"2022-04-16T03:22:42.481587Z","shell.execute_reply.started":"2022-04-16T03:22:31.717205Z","shell.execute_reply":"2022-04-16T03:22:42.480867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_merged = df_train.merge(df_train_labels, on = 'sequence', how = 'left')\ndf_train_test = pd.concat([df_train_merged, df_test])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:42.483131Z","iopub.execute_input":"2022-04-16T03:22:42.483369Z","iopub.status.idle":"2022-04-16T03:22:42.778844Z","shell.execute_reply.started":"2022-04-16T03:22:42.483336Z","shell.execute_reply":"2022-04-16T03:22:42.778096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the feature of subject\n\n# each squence correspons to only one subject\n# but each subject does not correspons to only one squence\n\nplt.figure(figsize=(16, 5))\n\nplt.bar(df_train_test.subject.value_counts().index,\n            df_train_test.subject.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:42.781961Z","iopub.execute_input":"2022-04-16T03:22:42.78217Z","iopub.status.idle":"2022-04-16T03:22:43.906919Z","shell.execute_reply.started":"2022-04-16T03:22:42.782144Z","shell.execute_reply":"2022-04-16T03:22:43.906222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### no discernible pattern for the feature of subject","metadata":{}},{"cell_type":"code","source":"# check correlation of each pair of features\n\nfig, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(df_train_test.corr(),\n            linewidths=0.1,\n            annot=True, fmt='.2f', cmap='coolwarm', annot_kws={'size': 12},\n            mask=np.triu(df_train_test.corr()))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:43.908646Z","iopub.execute_input":"2022-04-16T03:22:43.908892Z","iopub.status.idle":"2022-04-16T03:22:48.156996Z","shell.execute_reply.started":"2022-04-16T03:22:43.908858Z","shell.execute_reply":"2022-04-16T03:22:48.156306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"correlated data:\nsequence, subject \nsensor00, sensor01, sensor06, 09; \nsensor01, 06, 09,11;\n03, 07,11;\n04,10;\n06,09;\n07,11","metadata":{}},{"cell_type":"code","source":"# check outliers\ndf_sensor = df_train_test.iloc[:,3: -1]\n\nfig, axs = plt.subplots(4, 4, figsize=(20, 12))\n\nfor ax, sensor in zip(axs.flat, range(13)):\n    label = format(sensor, '02')\n    sensor_label = ('sensor_%s' % (label))\n    ax.boxplot(df_sensor[sensor_label], vert=False)\n    ax.set_title(sensor_label)\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:48.158605Z","iopub.execute_input":"2022-04-16T03:22:48.158949Z","iopub.status.idle":"2022-04-16T03:22:53.070239Z","shell.execute_reply.started":"2022-04-16T03:22:48.158911Z","shell.execute_reply":"2022-04-16T03:22:53.069486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the data distribution\nfig, axs = plt.subplots(4, 4, figsize=(20, 12))\n\nfor ax, sensor in zip(axs.flat, range(13)):\n    label = format(sensor, '02')\n    sensor_label = ('sensor_%s' % (label))\n    ax.hist(\n        df_sensor[sensor_label], bins=100,\n        range=(df_sensor[sensor_label].quantile(0.05),\n               df_sensor[sensor_label].quantile(0.95))\n    )\n    ax.set_title(sensor_label)\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:53.07164Z","iopub.execute_input":"2022-04-16T03:22:53.07191Z","iopub.status.idle":"2022-04-16T03:22:57.341563Z","shell.execute_reply.started":"2022-04-16T03:22:53.071871Z","shell.execute_reply":"2022-04-16T03:22:57.34074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normality check\n\nimport statsmodels.api as sm\n\nfig, axs = plt.subplots(4, 4, figsize=(20, 12))\n\nfor ax, sensor in zip(axs.flat, range(13)):\n    label = format(sensor, '02')\n    sensor_label = ('sensor_%s' % (label))\n    sm.qqplot(\n        df_sensor[sensor_label], line='q', ax=ax\n    )\n    ax.set_title(sensor_label)\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:22:57.345285Z","iopub.execute_input":"2022-04-16T03:22:57.34552Z","iopub.status.idle":"2022-04-16T03:23:51.232054Z","shell.execute_reply.started":"2022-04-16T03:22:57.345492Z","shell.execute_reply":"2022-04-16T03:23:51.231342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# figure out the influence of each sensor data\n\nfrom sklearn.feature_selection import mutual_info_classif\n\nmi_score = mutual_info_classif(\n    df_train_merged.iloc[:, 3:-1], df_train_merged['state'])\n\nfig, ax = plt.subplots(figsize=(16,4))\n\nax.bar(df_sensor.columns , height = mi_score)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:23:51.233138Z","iopub.execute_input":"2022-04-16T03:23:51.233378Z","iopub.status.idle":"2022-04-16T03:26:16.83827Z","shell.execute_reply.started":"2022-04-16T03:23:51.233347Z","shell.execute_reply":"2022-04-16T03:26:16.837401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### use these sensor features directly results in quite low auc scores >> feature engineering is necessary","metadata":{}},{"cell_type":"code","source":"# add lagged features\n# for 5s and 15s >> not working\n# 1s and 5s >> not working\n# 1s and 10s >> works!\n\nsensor_list = df_train_test.columns[3:-1].tolist()\n\nfor sensor in sensor_list:\n    \n    lag_col_1 = sensor + '_lag_1'\n    lag_col_10 = sensor + '_lag_10'\n    \n    df_train_test[lag_col_1] = df_train_test[sensor].shift(1)\n    df_train_test[lag_col_10] = df_train_test[sensor].shift(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:26:16.840092Z","iopub.execute_input":"2022-04-16T03:26:16.840354Z","iopub.status.idle":"2022-04-16T03:26:17.115108Z","shell.execute_reply.started":"2022-04-16T03:26:16.840318Z","shell.execute_reply":"2022-04-16T03:26:17.114405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aggreagation method\n\ndf_copy = pd.concat([df_train_labels, df_smpl], axis=0).drop('state', axis = 1)\n\n# use basic statistics to perform feature engineering on sensor data\nstat_features = ['mean', 'std', 'skew', 'var', 'mad', 'min', 'max', 'median']\n\nfor feature in stat_features:\n\n    df_temp = df_train_test.groupby(['sequence', 'subject'], as_index=True).agg(\n        feature).drop(['step', 'state'], axis=1)\n\n    col_name = list()\n\n    for previous_col_name in df_temp.columns.to_list():\n        new_col_name = previous_col_name + '_' + feature\n        col_name.append(new_col_name)\n\n    df_temp.columns = col_name\n    df_temp.reset_index(inplace=True)\n    df_temp.drop('subject', axis=1, inplace=True)\n    df_copy = df_copy.merge(df_temp, on='sequence')\n    \ndf_copy = df_copy.merge(df_train_labels, on = 'sequence', how = 'outer')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:26:17.116538Z","iopub.execute_input":"2022-04-16T03:26:17.116772Z","iopub.status.idle":"2022-04-16T03:28:06.796192Z","shell.execute_reply.started":"2022-04-16T03:26:17.116739Z","shell.execute_reply":"2022-04-16T03:28:06.795483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data prep\n\ntrain_engineered = df_copy[df_copy['state'].isna() == False]\ntest_engineered = df_copy[df_copy['state'].isna()]\n\nX_train = train_engineered.drop(['state'], axis=1)\ny_train = train_engineered['state']\n\nX_test = test_engineered.drop(['state'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:28:06.797313Z","iopub.execute_input":"2022-04-16T03:28:06.79756Z","iopub.status.idle":"2022-04-16T03:28:06.912965Z","shell.execute_reply.started":"2022-04-16T03:28:06.797527Z","shell.execute_reply":"2022-04-16T03:28:06.912243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# lgb model\n\nsteps = []\nsteps.append(('minmax_scaler', MinMaxScaler()))\nsteps.append(('std_scaler', StandardScaler()))\n#steps.append(('robust_scaler', RobustScaler()))\n\nsteps.append(('model', lgb.LGBMClassifier(device='gpu')))\n\npipe_lgb = Pipeline(steps)\n\ncv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n\nscores = cross_val_score(\n    pipe_lgb,\n    X_train,\n    y_train,\n    scoring='roc_auc',\n    cv=cv,\n    n_jobs=-1\n)\n\nprint('mean score: %.3f' % scores.mean())\nprint('std: %.3f' % scores.std())","metadata":{"execution":{"iopub.status.busy":"2022-04-16T03:29:55.50358Z","iopub.execute_input":"2022-04-16T03:29:55.503834Z","iopub.status.idle":"2022-04-16T03:32:55.33515Z","shell.execute_reply.started":"2022-04-16T03:29:55.503806Z","shell.execute_reply":"2022-04-16T03:32:55.33431Z"}}},{"cell_type":"raw","source":"# cgb model\n\nsteps = []\nsteps.append(('minmax_scaler', MinMaxScaler()))\nsteps.append(('std_scaler', StandardScaler()))\nsteps.append(('model', cgb.CatBoostClassifier(verbose=False)))\n\npipe_cgb = Pipeline(steps)\n\ncv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n\nscores = cross_val_score(\n    pipe_cgb,\n    X_train,\n    y_train,\n    scoring='roc_auc',\n    cv=cv,\n    n_jobs=-1\n)\n\nprint('mean score: %.3f' % scores.mean())\nprint('std: %.3f' % scores.std())","metadata":{"execution":{"iopub.status.busy":"2022-04-16T04:01:02.464305Z","iopub.execute_input":"2022-04-16T04:01:02.465021Z","iopub.status.idle":"2022-04-16T04:46:06.937927Z","shell.execute_reply.started":"2022-04-16T04:01:02.464982Z","shell.execute_reply":"2022-04-16T04:46:06.9371Z"}}},{"cell_type":"raw","source":"# hyperparameter tuning on catboost piepline\n\nsearch_spaces = {\n    'model__iterations': Integer(10, 1000),\n    'model__depth': Integer(1, 8),\n    'model__learning_rate': Real(0.01, 1.0, 'log-uniform'),\n    'model__random_strength': Real(1e-9, 10, 'log-uniform'),\n    'model__bagging_temperature': Real(0.0, 1.0),\n    'model__border_count': Integer(1, 255),\n    'model__l2_leaf_reg': Integer(2, 30),\n    'model__scale_pos_weight': Real(0.01, 1.0, 'uniform')\n}\n\n#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2)\n\nopt = BayesSearchCV(pipe_cgb,\n                    search_spaces,\n                    scoring='roc_auc',\n                    cv=3,\n                    n_iter=15,\n                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n                    return_train_score=False,\n                    refit=True,\n                    optimizer_kwargs={'base_estimator': 'GP'},\n                    random_state=0)\n\nopt.fit(X_train, y_train)\n\nprint(\"val. score: %s\" % opt.best_score_)\n#print(\"test score: %s\" % opt.score(X_test, y_test))\nprint(\"best params: %s\" % str(opt.best_params_))","metadata":{"execution":{"iopub.status.busy":"2022-04-16T05:25:40.108472Z","iopub.execute_input":"2022-04-16T05:25:40.109015Z","iopub.status.idle":"2022-04-16T05:46:20.112081Z","shell.execute_reply.started":"2022-04-16T05:25:40.108977Z","shell.execute_reply":"2022-04-16T05:46:20.111342Z"}}},{"cell_type":"code","source":"# tuned cgb model\n\nsteps = []\nsteps.append(('minmax_scaler', MinMaxScaler()))\nsteps.append(('std_scaler', StandardScaler()))\nsteps.append(('model', cgb.CatBoostClassifier(\n    bagging_temperature = 0.14741981195117174,\n    border_count = 200,\n    depth=4,\n    iterations=461,\n    l2_leaf_reg = 25,\n    learning_rate = 0.22774253759183857,\n    random_strength = 0.2881729869911725,\n    scale_pos_weight = 0.32624480187205324,\n    verbose=False\n)))\n\ntuned_pipe_cgb = Pipeline(steps)\n\ncv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n\nscores = cross_val_score(\n    tuned_pipe_cgb,\n    X_train,\n    y_train,\n    scoring='roc_auc',\n    cv=cv,\n    n_jobs=-1\n)\n\nprint('mean score: %.3f' % scores.mean())\nprint('std: %.3f' % scores.std())","metadata":{"execution":{"iopub.status.busy":"2022-04-16T06:44:14.615684Z","iopub.execute_input":"2022-04-16T06:44:14.61594Z","iopub.status.idle":"2022-04-16T06:53:24.191969Z","shell.execute_reply.started":"2022-04-16T06:44:14.61591Z","shell.execute_reply":"2022-04-16T06:53:24.191147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# untuned model\n\npipe_cgb.fit(X_train, y_train)\npred = pipe_cgb.predict_proba(X_test) # use predict_prob instead of predict\ndf_smpl['state'] = pd.Series(pred[:, 1]) # pred per se is composed of two columns\n\ndf_smpl[['sequence','state']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T16:12:18.666013Z","iopub.execute_input":"2022-04-14T16:12:18.666741Z","iopub.status.idle":"2022-04-14T16:12:57.75837Z","shell.execute_reply.started":"2022-04-14T16:12:18.666694Z","shell.execute_reply":"2022-04-14T16:12:57.75728Z"}}},{"cell_type":"code","source":"tuned_pipe_cgb.fit(X_train, y_train)\npred = tuned_pipe_cgb.predict_proba(X_test) # use predict_prob instead of predict\ndf_smpl['state'] = pd.Series(pred[:, 1]) # pred per se is composed of two columns\n\ndf_smpl[['sequence','state']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T06:56:34.103858Z","iopub.execute_input":"2022-04-16T06:56:34.104135Z","iopub.status.idle":"2022-04-16T06:56:52.208756Z","shell.execute_reply.started":"2022-04-16T06:56:34.104104Z","shell.execute_reply":"2022-04-16T06:56:52.207678Z"},"trusted":true},"execution_count":null,"outputs":[]}]}