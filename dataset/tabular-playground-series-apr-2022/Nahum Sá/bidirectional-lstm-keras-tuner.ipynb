{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:43.394332Z","iopub.execute_input":"2022-04-19T23:16:43.394844Z","iopub.status.idle":"2022-04-19T23:16:43.418236Z","shell.execute_reply.started":"2022-04-19T23:16:43.39477Z","shell.execute_reply":"2022-04-19T23:16:43.417607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train.csv\")\nlabel_df = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train_labels.csv\")\ntest_df = pd.read_csv(\"../input/tabular-playground-series-apr-2022/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:43.41961Z","iopub.execute_input":"2022-04-19T23:16:43.419861Z","iopub.status.idle":"2022-04-19T23:16:54.058692Z","shell.execute_reply.started":"2022-04-19T23:16:43.419827Z","shell.execute_reply":"2022-04-19T23:16:54.057974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef get_sensor_cols(df):\n    return [col for col in df if col.startswith('sensor')]\n\ndef preprocessing_df(df):\n    sensor_cols = get_sensor_cols(df)\n    feature_df = df.copy()\n    n_lags = 2\n    for sensor in sensor_cols:\n        for lag in range(1, n_lags):\n            feature_df[sensor + f'_lag{lag}'] = df.groupby('sequence')[sensor].shift(lag)\n            feature_df[sensor + f'_diff{lag}'] = df.groupby('sequence')[sensor].diff(lag)\n            feature_df = feature_df.fillna(0)\n        \n        for window in [3, 6, 12]:\n            df[sensor + f'_roll_{window}_mean'] = df.groupby('sequence')[sensor]\\\n            .rolling(window=window, min_periods=1).mean().reset_index(level=0,drop=True)\n            \n            df[sensor + f'_roll_{window}_std'] = df.groupby('sequence')[sensor]\\\n            .rolling(window=window, min_periods=1).std().reset_index(level=0,drop=True)\n            \n            df[sensor + f'_roll_{window}_sum'] = df.groupby('sequence')[sensor]\\\n            .rolling(window=window, min_periods=1).sum().reset_index(level=0,drop=True)\n        \n    return feature_df","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:54.060529Z","iopub.execute_input":"2022-04-19T23:16:54.060828Z","iopub.status.idle":"2022-04-19T23:16:54.947975Z","shell.execute_reply.started":"2022-04-19T23:16:54.060792Z","shell.execute_reply":"2022-04-19T23:16:54.947265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = train_df['sequence']\nlabels = label_df['state']\n\nsc = StandardScaler()\n\nfeatures_train = preprocessing_df(train_df)\nfeature_cols = get_sensor_cols(features_train)\nfeatures_train[feature_cols] = sc.fit_transform(features_train[feature_cols])\nfeatures_train = features_train.drop(['sequence', 'subject', 'step'], axis=1).values\nfeatures_train = features_train.reshape(-1, 60, features_train.shape[-1])\n\nfeatures_test = preprocessing_df(test_df)\nfeature_cols = get_sensor_cols(features_test)\nfeatures_test[feature_cols] = sc.transform(features_test[feature_cols])\nfeatures_test = features_test.drop(['sequence', 'subject', 'step'], axis=1).values\nfeatures_test = features_test.reshape(-1, 60, features_test.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:54.94939Z","iopub.execute_input":"2022-04-19T23:16:54.949645Z","iopub.status.idle":"2022-04-19T23:24:09.26121Z","shell.execute_reply.started":"2022-04-19T23:16:54.949608Z","shell.execute_reply":"2022-04-19T23:24:09.260468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Bidirectional LSTM","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import (Input, Bidirectional, BatchNormalization,\n                                     Dense, Dropout, LSTM, GRU, Concatenate, Multiply,\n                                     GlobalMaxPooling1D)\nfrom tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau)\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:24:09.263109Z","iopub.execute_input":"2022-04-19T23:24:09.263353Z","iopub.status.idle":"2022-04-19T23:24:13.999657Z","shell.execute_reply.started":"2022-04-19T23:24:09.26332Z","shell.execute_reply":"2022-04-19T23:24:13.998924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_lstm():\n    x_input = Input(shape=(features_train.shape[-2:]))\n    l1 = Bidirectional(LSTM(units=512, return_sequences=True))(x_input)\n    l2 = Bidirectional(LSTM(units=256, return_sequences=True))(l1)\n    g1 = Bidirectional(GRU(units=256, return_sequences=True))(l1)\n    c1 = Concatenate(axis=2)([l2, g1])\n    l3 = Bidirectional(LSTM(units=256, return_sequences=True))(c1)\n\n    p1 = GlobalMaxPooling1D()(l3)\n\n    d1 = Dense(units=128, activation='selu')(p1)\n    \n    x_output = Dense(units=1, activation='sigmoid')(d1)\n\n    model = Model(inputs=x_input,\n                  outputs=x_output,\n                  name='lstm')\n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics='AUC')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:24:14.000986Z","iopub.execute_input":"2022-04-19T23:24:14.001409Z","iopub.status.idle":"2022-04-19T23:24:14.010872Z","shell.execute_reply.started":"2022-04-19T23:24:14.001369Z","shell.execute_reply":"2022-04-19T23:24:14.009004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\n\nBATCH_SIZE = 512\n\nk_fold = GroupKFold(n_splits=5)\nvalid_scores, predictions = [], []\n\nfor fold, (train_idx, valid_idx) in enumerate(k_fold.split(features_train,labels, sequences.unique())):\n    \n    X_train, X_valid = features_train[train_idx], features_train[valid_idx]\n    y_train, y_valid = labels.iloc[train_idx].values, labels.iloc[valid_idx].values\n    \n    model = create_lstm()\n    \n    lr = ReduceLROnPlateau(monitor='val_auc', factor=0.05,\n                          patience=5)\n    \n    es = EarlyStopping(monitor='val_auc', patience=10,\n                       mode='max', restore_best_weights=True)\n    \n    model.fit(X_train, y_train,\n              validation_data=(X_valid, y_valid),\n              epochs=20,\n              batch_size=BATCH_SIZE,\n              callbacks=[lr, es],\n              verbose=0)\n    \n    y_pred = model.predict(X_valid, batch_size=BATCH_SIZE).squeeze()\n    \n    roc_auc = roc_auc_score(y_valid, y_pred)\n    valid_scores.append(roc_auc)\n    predictions.append(model.predict(features_test, batch_size=BATCH_SIZE).squeeze())\n    \n    print(f'Fold-{fold + 1} ROC AUC: {roc_auc}')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:24:14.014667Z","iopub.execute_input":"2022-04-19T23:24:14.014894Z","iopub.status.idle":"2022-04-19T23:50:00.935244Z","shell.execute_reply.started":"2022-04-19T23:24:14.014864Z","shell.execute_reply":"2022-04-19T23:50:00.933545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')\nsubmission['state'] = sum(predictions) / k_fold.n_splits\nsubmission.to_csv('lstm.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:50:00.93693Z","iopub.execute_input":"2022-04-19T23:50:00.937194Z","iopub.status.idle":"2022-04-19T23:50:00.994571Z","shell.execute_reply.started":"2022-04-19T23:50:00.937156Z","shell.execute_reply":"2022-04-19T23:50:00.993903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Keras Tuner","metadata":{}},{"cell_type":"code","source":"def build_lstm(hp):\n    x_input = Input(shape=(features_train.shape[-2:]))\n    l1 = Bidirectional(LSTM(units=512,\n                            return_sequences=True))(x_input)\n    l2 = Bidirectional(LSTM(units=256,\n                                return_sequences=True))(l1)\n    \n    for i in range(hp.Int('n_layers_lstm', min_value=2, max_value=5)):\n        l2 = Bidirectional(LSTM(units=128,\n                                return_sequences=True))(l2)\n        \n    g1 = Bidirectional(GRU(units=256,\n                           return_sequences=True))(l1)\n    \n    for i in range(hp.Int('n_layers_gru', min_value=2, max_value=5)):\n        g1 = Bidirectional(GRU(units=128,\n                                return_sequences=True))(g1)\n        \n    c1 = Concatenate(axis=2)([l2, g1])\n\n    l3 = Bidirectional(LSTM(units=256, return_sequences=True))(c1)\n\n    p1 = GlobalMaxPooling1D()(l3)\n\n    d1 = Dense(units=512,\n               activation='selu')(p1)\n    \n    x_output = Dense(units=1, activation='sigmoid')(d1)\n\n    model = Model(inputs=x_input,\n                  outputs=x_output,\n                  name='lstm')\n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics='AUC')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:18.943325Z","iopub.status.idle":"2022-04-19T23:16:18.943917Z","shell.execute_reply.started":"2022-04-19T23:16:18.943661Z","shell.execute_reply":"2022-04-19T23:16:18.943695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras_tuner as kt\ntuner = kt.RandomSearch(\n    hypermodel=build_lstm,\n    objective=kt.Objective(\"val_auc\", direction=\"max\"),\n    max_trials=3,\n    executions_per_trial=2,\n    overwrite=True,\n    directory=\"kt\",\n    project_name='b_lstm'\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:18.945024Z","iopub.status.idle":"2022-04-19T23:16:18.945995Z","shell.execute_reply.started":"2022-04-19T23:16:18.945762Z","shell.execute_reply":"2022-04-19T23:16:18.94579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:18.946981Z","iopub.status.idle":"2022-04-19T23:16:18.947301Z","shell.execute_reply.started":"2022-04-19T23:16:18.947131Z","shell.execute_reply":"2022-04-19T23:16:18.947148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras_tuner as kt\n\nBATCH_SIZE = 512\n\nk_fold = GroupKFold(n_splits=3)\nvalid_scores, predictions = [], []\n\nfor fold, (train_idx, valid_idx) in enumerate(k_fold.split(features_train,labels, sequences.unique())):\n    \n    X_train, X_valid = features_train[train_idx], features_train[valid_idx]\n    y_train, y_valid = labels.iloc[train_idx].values, labels.iloc[valid_idx].values\n    \n    tuner = kt.RandomSearch(\n        hypermodel=build_lstm,\n        objective=kt.Objective(\"val_auc\", direction=\"max\"),\n        max_trials=3,\n        executions_per_trial=2,\n        overwrite=True,\n        directory=\"kt\",\n        project_name='b_lstm'\n    )\n    \n    lr = ReduceLROnPlateau(monitor='val_auc', factor=0.05,\n                          patience=5)\n    \n    es = EarlyStopping(monitor='val_auc', patience=5,\n                       mode='max', restore_best_weights=True)\n    \n    tuner.search(X_train, y_train,\n                 validation_data=(X_valid, y_valid),\n                 epochs=1,\n                 batch_size=BATCH_SIZE,\n                 callbacks=[lr, es],\n                 verbose=0)\n    \n    model = tuner.get_best_models(num_models=2)[0]\n    y_pred = model.predict(X_valid, batch_size=BATCH_SIZE).squeeze()\n    \n    roc_auc = roc_auc_score(y_valid, y_pred)\n    valid_scores.append(roc_auc)\n    predictions.append(model.predict(features_test, batch_size=BATCH_SIZE).squeeze())\n    \n    print(f'Fold-{fold + 1} ROC AUC: {roc_auc}')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:18.94841Z","iopub.status.idle":"2022-04-19T23:16:18.948726Z","shell.execute_reply.started":"2022-04-19T23:16:18.948561Z","shell.execute_reply":"2022-04-19T23:16:18.948577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')\nsubmission['state'] = sum(predictions) / k_fold.n_splits\nsubmission.to_csv('lstm_tuned.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T23:16:18.95001Z","iopub.status.idle":"2022-04-19T23:16:18.95035Z","shell.execute_reply.started":"2022-04-19T23:16:18.95016Z","shell.execute_reply":"2022-04-19T23:16:18.950177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}