{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-10T14:55:03.084786Z","iopub.execute_input":"2022-04-10T14:55:03.08512Z","iopub.status.idle":"2022-04-10T14:55:03.0934Z","shell.execute_reply.started":"2022-04-10T14:55:03.085087Z","shell.execute_reply":"2022-04-10T14:55:03.092604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and summarize the dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:03.102282Z","iopub.execute_input":"2022-04-10T14:55:03.103189Z","iopub.status.idle":"2022-04-10T14:55:08.281758Z","shell.execute_reply.started":"2022-04-10T14:55:03.103135Z","shell.execute_reply":"2022-04-10T14:55:08.281161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:08.283111Z","iopub.execute_input":"2022-04-10T14:55:08.283436Z","iopub.status.idle":"2022-04-10T14:55:09.202039Z","shell.execute_reply.started":"2022-04-10T14:55:08.2834Z","shell.execute_reply":"2022-04-10T14:55:09.20129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntrain_labels_df.tail(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.203201Z","iopub.execute_input":"2022-04-10T14:55:09.203578Z","iopub.status.idle":"2022-04-10T14:55:09.220748Z","shell.execute_reply.started":"2022-04-10T14:55:09.203549Z","shell.execute_reply":"2022-04-10T14:55:09.220139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summarize subject data for each sequence\n\nWe can look at the number of unique values to see that there are a lot more sequences than there are subjects in this dataset.","metadata":{}},{"cell_type":"code","source":"train_df[['sequence', 'subject']].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.222436Z","iopub.execute_input":"2022-04-10T14:55:09.22311Z","iopub.status.idle":"2022-04-10T14:55:09.263063Z","shell.execute_reply.started":"2022-04-10T14:55:09.223069Z","shell.execute_reply":"2022-04-10T14:55:09.262012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since each sequence has only one subject, we can use `drop_duplicates` on those two columns to get a dataframe with just the unique sequence/subject pairs. We'll merge in the labels dataframe so we can look at subject and state to see if there's any information in the subject column that we need to keep in our model.","metadata":{}},{"cell_type":"code","source":"subjects_df = train_df[['sequence', 'subject']].drop_duplicates()\nsubjects_df = subjects_df.merge(train_labels_df, on='sequence')\nsubjects_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.26442Z","iopub.execute_input":"2022-04-10T14:55:09.264736Z","iopub.status.idle":"2022-04-10T14:55:09.365038Z","shell.execute_reply.started":"2022-04-10T14:55:09.264692Z","shell.execute_reply":"2022-04-10T14:55:09.364049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped_sub = subjects_df.groupby('subject')\ngrouped_sub_states = grouped_sub['state'].agg([np.mean, len])\ngrouped_sub_states.plot.scatter(x='len', y='mean', figsize=(12, 6),\n                                title=\"Mean state vs. subject appearances\",\n                                xlabel='Number of sequences', ylabel='Mean state');","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.366367Z","iopub.execute_input":"2022-04-10T14:55:09.366689Z","iopub.status.idle":"2022-04-10T14:55:09.637913Z","shell.execute_reply.started":"2022-04-10T14:55:09.366655Z","shell.execute_reply":"2022-04-10T14:55:09.637002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this chart we can see there is a correlation between the number of times a subject appears in the dataset and the state of the sequence for that subject. The more times a subject appears, the more likely their sequence is in state 1. We should keep the subject id when we train our model. We'll also include the number of sequences for each subject, and the proportion of all sequences.","metadata":{}},{"cell_type":"code","source":"grouped_sub_states['prop'] = grouped_sub_states['len'] / grouped_sub_states['len'].sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.639216Z","iopub.execute_input":"2022-04-10T14:55:09.639443Z","iopub.status.idle":"2022-04-10T14:55:09.646353Z","shell.execute_reply.started":"2022-04-10T14:55:09.639417Z","shell.execute_reply":"2022-04-10T14:55:09.645664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_sub_dict = dict(zip(subjects_df['sequence'], subjects_df['subject']))\nsub_len_dict = dict(zip(grouped_sub_states.index, grouped_sub_states['len']))\nsub_prop_dict = dict(zip(grouped_sub_states.index, grouped_sub_states['prop']))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.647329Z","iopub.execute_input":"2022-04-10T14:55:09.647552Z","iopub.status.idle":"2022-04-10T14:55:09.670279Z","shell.execute_reply.started":"2022-04-10T14:55:09.647526Z","shell.execute_reply":"2022-04-10T14:55:09.669183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summarize sensor data for each sequence\n\nLet's try flattening all of the sensor data for each sequence into just a few summary statistics so we can have one row per sequence.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import iqr, kurtosis, skew\n\nsensor_columns = [\"sensor_{:02d}\".format(item) for item in range(0, 13)]\n\ngrouped = train_df.groupby('sequence')\ntrain_g = grouped[sensor_columns].agg([min, max, np.mean, np.std, np.median, iqr, kurtosis, skew])\n\n# flatten the multi-index that resulted from grouping\ntrain_g.columns = [\"_\".join(a) for a in train_g.columns.to_flat_index()]\n\n# add the subject column back\ntrain_g['subject'] = train_g.index.map(seq_sub_dict)\n\n# add the sequence count and proportion for each subject\ntrain_g['subject_seq_count'] = train_g['subject'].map(sub_len_dict)\ntrain_g['subjects_seq_prop'] = train_g['subject'].map(sub_prop_dict)\ntrain_g","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:55:09.671263Z","iopub.execute_input":"2022-04-10T14:55:09.671486Z","iopub.status.idle":"2022-04-10T14:57:35.748553Z","shell.execute_reply.started":"2022-04-10T14:55:09.671459Z","shell.execute_reply":"2022-04-10T14:57:35.747689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train_g\ny = train_labels_df['state']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:35.751682Z","iopub.execute_input":"2022-04-10T14:57:35.752442Z","iopub.status.idle":"2022-04-10T14:57:35.791498Z","shell.execute_reply.started":"2022-04-10T14:57:35.752402Z","shell.execute_reply":"2022-04-10T14:57:35.790375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build a model","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Define model. Specify a number for random_state to ensure same results each run\nmodel = XGBClassifier(random_state=1)\n\n# Fit model and make predictions\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:35.792977Z","iopub.execute_input":"2022-04-10T14:57:35.793312Z","iopub.status.idle":"2022-04-10T14:57:52.694032Z","shell.execute_reply.started":"2022-04-10T14:57:35.79327Z","shell.execute_reply":"2022-04-10T14:57:52.693342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Determine the score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nauc = roc_auc_score(y_test, y_pred)\nprint(\"AUC: %.5f\" % auc)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:52.695253Z","iopub.execute_input":"2022-04-10T14:57:52.695721Z","iopub.status.idle":"2022-04-10T14:57:52.70941Z","shell.execute_reply.started":"2022-04-10T14:57:52.695678Z","shell.execute_reply":"2022-04-10T14:57:52.70862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's not a great score given some of the other submissions already on the leaderboard, but it's not a bad baseline for a very simple model.","metadata":{}},{"cell_type":"markdown","source":"## Create a submission","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\n\n# create a sequence->subjects dictionary\nsubjects_test_df = test_df[['sequence', 'subject']].drop_duplicates()\n\ngrouped_test_sub = subjects_test_df.groupby('subject')\ngrouped_test_sub_counts = grouped_test_sub['sequence'].agg([len])\ngrouped_test_sub_counts['prop'] = grouped_test_sub_counts['len'] / grouped_test_sub_counts['len'].sum()\n\nseq_sub_test_dict = dict(zip(subjects_test_df['sequence'], subjects_test_df['subject']))\nsub_len_test_dict = dict(zip(grouped_test_sub_counts.index, grouped_test_sub_counts['len']))\nsub_prop_test_dict = dict(zip(grouped_test_sub_counts.index, grouped_test_sub_counts['prop']))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:52.711021Z","iopub.execute_input":"2022-04-10T14:57:52.71174Z","iopub.status.idle":"2022-04-10T14:57:55.077664Z","shell.execute_reply.started":"2022-04-10T14:57:52.711688Z","shell.execute_reply":"2022-04-10T14:57:55.076688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped_test_sub_counts","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:55.078924Z","iopub.execute_input":"2022-04-10T14:57:55.079274Z","iopub.status.idle":"2022-04-10T14:57:55.091909Z","shell.execute_reply.started":"2022-04-10T14:57:55.079226Z","shell.execute_reply":"2022-04-10T14:57:55.091089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = test_df.groupby('sequence')\ntest_g = grouped[sensor_columns].agg([min, max, np.mean, np.std, np.median, iqr, kurtosis, skew])\n\n# flatten the multi-index that resulted from grouping\ntest_g.columns = [\"_\".join(a) for a in test_g.columns.to_flat_index()]\ntest_g['subject'] = test_g.index.map(seq_sub_test_dict)\n\n# add the sequence count and proportion for each subject\ntest_g['subject_seq_count'] = test_g['subject'].map(sub_len_test_dict)\ntest_g['subjects_seq_prop'] = test_g['subject'].map(sub_prop_test_dict)\n\ntest_g.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:55.093289Z","iopub.execute_input":"2022-04-10T14:57:55.093871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit model to entire training dataset\nmodel.fit(X, y)\ny_pred = model.predict(test_g)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({'sequence': test_g.index, 'state': y_pred})\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}