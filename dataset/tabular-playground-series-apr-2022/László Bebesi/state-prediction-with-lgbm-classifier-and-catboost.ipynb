{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.display.float_format = '{:,.2f}'.format\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import kurtosis, skew\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib.ticker import PercentFormatter\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.inspection import permutation_importance\nfrom sklearn import metrics\nfrom scipy.fft import rfft\nfrom catboost import CatBoostClassifier\nimport scipy\n\n!pip install seglearn tsflex antropy catch22\nfrom seglearn.feature_functions import emg_features\nfrom tsflex.features.integrations import seglearn_feature_dict_wrapper\nfrom tsflex.features import MultipleFeatureDescriptors,FeatureCollection\nfrom catch22 import catch22_all\nimport antropy as ent\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T07:10:32.488291Z","iopub.execute_input":"2022-04-26T07:10:32.488748Z","iopub.status.idle":"2022-04-26T07:10:43.654892Z","shell.execute_reply.started":"2022-04-26T07:10:32.488715Z","shell.execute_reply":"2022-04-26T07:10:43.653699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0. Helper functions <a name=\"help\"></a>","metadata":{}},{"cell_type":"code","source":"def fit_model_using_classifier(alg,\n                               dtrain,\n                               predictors,\n                               target=\"state\",\n                               performCV=True, \n                               printFeatureImportance=True, \n                               cv_folds=3,\n                               repeat=5,\n                               scoring='roc_auc',\n                               only_top_x_feature=60\n                              ):\n    \"\"\"\n    I used the function found in this source\n    https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n    I modified the code slightly\n    \"\"\"\n\n    # Perform cross-validation:\n    cv_score=list()\n    if performCV:\n        for i in range(0,repeat):\n            cv_score_temp = cross_val_score(\n                            alg, \n                            dtrain[predictors], \n                            dtrain[target], \n                            cv=cv_folds, \n                            scoring=scoring)\n            cv_score=cv_score+list(cv_score_temp)\n    \n    # Fit the algorithm on the data\n    alg.fit(dtrain[predictors], dtrain[target])\n        \n    # Predict training set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]        \n    \n    # Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy : \" + str(round(metrics.accuracy_score(\n        dtrain[target].values, dtrain_predictions),4)))\n    print(\"AUC Score (Train): \" + str(round(\n        metrics.roc_auc_score(dtrain[target], dtrain_predprob),4)))\n    \n    if performCV:\n        print(\"\\n Cross validation summary (\"+scoring+\")\")\n        print(\"Average: \"+str(round(np.mean(cv_score),4)))\n        print(\"Std    : \"+str(round(np.std(cv_score),4)))\n        print(\"Min    : \"+str(round(np.min(cv_score),4)))\n        print(\"Max    : \"+str(round(np.max(cv_score),4)))\n                \n    # Print Feature Importance:\n    if printFeatureImportance and \"feature_importances_\" in dir(alg):\n        plt.figure(figsize=(20,6))\n        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n        feat_imp.head(only_top_x_feature).plot(kind='bar', title='Feature Importances',fontsize=12, color=\"#CBC3E3\")\n        plt.ylabel('Feature Importance Score')\n        return alg, feat_imp\n    else:\n        return alg, list()\n\ndef generate_features(df, metric_data, group_variables, sensor_identifiers, suffix=\"\"):\n    \"\"\"\n    Generates the features based on the provided metric_data map\n    \n    \"\"\"\n    all_metrics=pd.DataFrame(columns=group_variables)\n    for sensor_number in sensor_numbs:\n        sensor_v=\"sensor_\"+sensor_number\n        # I had to use this words solution because of list formatting\n        metrics = [ listv[0] \n                        for key, listv in metric_data.items()]\n        metric_cols=[key+sensor_number+suffix for key in metric_data.keys()]\n\n        temp_metrics=df.groupby(group_variables).agg({\n            sensor_v: metrics\n        }).reset_index()\n        temp_metrics.columns=group_variables+metric_cols\n        all_metrics=all_metrics.merge(temp_metrics,how=\"outer\",on=group_variables)\n\n    # finally we save down the variable names as well\n    generated_columns=list(set(all_metrics.columns)-set(group_variables))\n    generated_columns.sort()\n    return all_metrics, generated_columns\n\ndef create_frequencies(groups):\n    \"\"\"\n    Create frequencies up to frequency 30.\n    source https://www.kaggle.com/code/matanivanov/lgbm-with-fourier-transform\n    \"\"\"\n    return pd.concat(\n        [pd.Series(np.abs(rfft(groups[col].values)), \n                   index=[f'{col}_freq_{i}' for i in range(31)]) \n         for col in groups.columns if col not in ['sequence', 'subject', 'step']\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:35:03.455257Z","iopub.execute_input":"2022-04-26T13:35:03.455604Z","iopub.status.idle":"2022-04-26T13:35:03.485354Z","shell.execute_reply.started":"2022-04-26T13:35:03.455568Z","shell.execute_reply":"2022-04-26T13:35:03.484597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load and Explore data <a name=\"introduction\"></a>","metadata":{}},{"cell_type":"code","source":"train_labels=pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2022/train_labels.csv\")\ndisplay(train_labels.head())\ntrain=pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2022/train.csv\")\ndisplay(train.head())\ndisplay(train.describe())\n# At first glance no problem with missing variables\ndisplay(train.info())\ntest=pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2022/test.csv\")\ndisplay(test.head())\ndisplay(test.describe())\n# At first glance no problem with missing variables\ndisplay(test.info())","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:06:37.961597Z","iopub.execute_input":"2022-04-26T07:06:37.961959Z","iopub.status.idle":"2022-04-26T07:06:47.22162Z","shell.execute_reply.started":"2022-04-26T07:06:37.961912Z","shell.execute_reply":"2022-04-26T07:06:47.220527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let us define a list of sensors for convinience\nsensors=list(test.columns[3:16])\nsensor_numbs=[sensor[7:9] for sensor in sensors]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:06:47.223499Z","iopub.execute_input":"2022-04-26T07:06:47.223928Z","iopub.status.idle":"2022-04-26T07:06:47.229893Z","shell.execute_reply.started":"2022-04-26T07:06:47.223883Z","shell.execute_reply":"2022-04-26T07:06:47.228917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Variable construction <a name=\"vars\"></a>","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_freq = train.sort_values(['subject', 'sequence', 'step']).groupby(['sequence', 'subject']).apply(create_frequencies)\ntrain_freq.reset_index(inplace=True)\n\ntest_freq = test.sort_values(['subject', 'sequence', 'step']).groupby(['sequence', 'subject']).apply(create_frequencies)\ntest_freq.reset_index(inplace=True)\nfreq_columns=list(train_freq.columns[2:])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:06:47.233088Z","iopub.execute_input":"2022-04-26T07:06:47.233607Z","iopub.status.idle":"2022-04-26T07:09:08.536147Z","shell.execute_reply.started":"2022-04-26T07:06:47.233566Z","shell.execute_reply":"2022-04-26T07:09:08.534847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T07:09:08.538023Z","iopub.execute_input":"2022-04-26T07:09:08.538301Z","iopub.status.idle":"2022-04-26T07:09:08.544384Z","shell.execute_reply.started":"2022-04-26T07:09:08.538267Z","shell.execute_reply":"2022-04-26T07:09:08.54325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric_data_short={\n    \"mean_\": [np.nanmean],\n    \"std_\": [np.nanstd]\n}\n# mean and std achieves around 80-82% f1 score\n\n# lets extend these with new metrics\ndef auto_corr_1(x):\n    return np.corrcoef(x[1:],x[:-1])[0,1]\ndef auto_corr_2(x):\n    return np.corrcoef(x[2:],x[:-2])[0,1]\n\ndef p5(x):\n    return np.percentile(x,5)\ndef p10(x):\n    return np.percentile(x,10)\ndef p25(x):\n    return np.percentile(x,25)\ndef p75(x):\n    return np.percentile(x,75)\ndef p90(x):\n    return np.percentile(x,90)\ndef p95(x):\n    return np.percentile(x,95)\n\ndef diqr(x):\n    dd=x.diff().dropna()\n    return scipy.stats.iqr(dd)\n\ndef mean_diff(x):\n    dd=x.diff()\n    return np.nanmean(dd)\n\ndef std_diff(x):\n    dd=x.diff()\n    return np.nanstd(dd)\n\ndef auto_corr_1_diff(x):\n    dd=x.diff().dropna()\n    return np.corrcoef(dd[1:],dd[:-1])[0,1]\n\ndef auto_corr_2_diff(x):\n    dd=x.diff().dropna()\n    return np.corrcoef(dd[2:],dd[:-2])[0,1]\n\ndef skew_diff(x):\n    dd=x.diff().dropna()\n    return skew(dd)\n\ndef kurtosis_diff(x):\n    dd=x.diff().dropna()\n    return kurtosis(dd)\n\ndef dp5(x):\n    dd=x.diff().dropna()\n    return np.percentile(dd,5)\ndef dp10(x):\n    dd=x.diff().dropna()\n    return np.percentile(dd,10)\ndef dp25(x):\n    dd=x.diff().dropna()\n    return np.percentile(dd,25)\ndef dp75(x):\n    dd=x.diff().dropna()\n    return np.percentile(dd,75)\ndef dp90(x):\n    dd=x.diff().dropna()\n    return np.percentile(dd,90)\ndef dp95(x):\n    dd=x.diff().dropna()\n    return np.percentile(dd,95)\n\ndef dmin(x):\n    dd=x.diff().dropna()\n    return np.nanmin(dd)\n\ndef dmax(x):\n    dd=x.diff().dropna()\n    return np.nanmax(dd)\n\nmetric_data={\n    \"mean_\": [np.nanmean],\n    \"std_\": [np.nanstd],\n    \"median_\": [np.median],\n    \"p05_\": [p5],\n    \"p10_\": [p10],\n    \"p25_\": [p25],\n    \"p75_\": [p75],\n    \"p90_\": [p90],\n    \"p95_\": [p95],\n    \"min_\": [np.nanmin],\n    \"max_\": [np.nanmax],\n    \"iqr_\": [scipy.stats.iqr],\n    \"skew_\": [skew],\n    \"kurtosis_\": [kurtosis],\n    \"corr1_\": [auto_corr_1],\n    \"corr2_\": [auto_corr_2],\n    \"d_mean_\": [mean_diff],\n    \"d_std_\": [std_diff],\n    \"d_corr1_\": [auto_corr_1_diff],\n    \"d_corr2_\": [auto_corr_2_diff],\n    \"d_skew_\": [skew_diff],\n    \"d_kurtosis_\": [kurtosis_diff],\n    \"d_min_\": [dmin],\n    \"d_p05_\": [dp5],\n    \"d_p10_\": [dp10],\n    \"d_p25_\": [dp25],\n    \"d_p75_\": [dp75],\n    \"d_p90_\": [dp90],\n    \"d_p95_\": [dp95],\n    \"d_max_\": [dmax],\n    \"d_iqr_\": [diqr]\n}\n\nmetric_data_subj={\n    \"mean_\": [np.nanmean],\n    \"std_\": [np.nanstd],\n    \"median_\": [np.median],\n    \"p05_\": [p5],\n    \"p10_\": [p10],\n    \"p25_\": [p25],\n    \"p75_\": [p75],\n    \"p90_\": [p90],\n    \"p95_\": [p95],\n    \"min_\": [np.nanmin],\n    \"max_\": [np.nanmax],\n    \"skew_\": [skew],\n    \"kurtosis_\": [kurtosis]\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:30:10.082828Z","iopub.execute_input":"2022-04-26T08:30:10.083869Z","iopub.status.idle":"2022-04-26T08:30:10.119182Z","shell.execute_reply.started":"2022-04-26T08:30:10.083816Z","shell.execute_reply":"2022-04-26T08:30:10.117889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n    train_features, gen_col_train = generate_features(df=train, \n                                                      metric_data=metric_data, \n                                                      group_variables=[\"sequence\"], \n                                                      sensor_identifiers=sensor_numbs, \n                                                      suffix=\"\")\n    test_features, gen_col_test = generate_features(df=test, \n                                                    metric_data=metric_data, \n                                                    group_variables=[\"sequence\"], \n                                                    sensor_identifiers=sensor_numbs, \n                                                    suffix=\"\")\n\n    train_features_s, gen_col_train_s = generate_features(df=train, \n                                                      metric_data=metric_data_subj, \n                                                      group_variables=[\"subject\"], \n                                                      sensor_identifiers=sensor_numbs, \n                                                      suffix=\"_subj\")\n    test_features_s, gen_col_test_s = generate_features(df=test, \n                                                    metric_data=metric_data_subj, \n                                                    group_variables=[\"subject\"], \n                                                    sensor_identifiers=sensor_numbs, \n                                                    suffix=\"_subj\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:30:13.221921Z","iopub.execute_input":"2022-04-26T08:30:13.222806Z","iopub.status.idle":"2022-04-26T09:31:57.727163Z","shell.execute_reply.started":"2022-04-26T08:30:13.222749Z","shell.execute_reply":"2022-04-26T09:31:57.725816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:13:35.540371Z","iopub.execute_input":"2022-04-26T08:13:35.540726Z","iopub.status.idle":"2022-04-26T08:13:35.546704Z","shell.execute_reply.started":"2022-04-26T08:13:35.54068Z","shell.execute_reply":"2022-04-26T08:13:35.545926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ent = MultipleFeatureDescriptors(\n        functions=[ent.perm_entropy, ent.sample_entropy, ent.petrosian_fd, ent.svd_entropy],\n        series_names=sensors,\n        windows=60,\n        strides=60,\n    )\nent_collect = FeatureCollection(ent)\n\ntrain_ent= ent_collect.calculate(train.copy().astype(np.float32), show_progress=True, return_df=True, window_idx=\"begin\")\ntest_ent= ent_collect.calculate(test.copy().astype(np.float32), show_progress=True, return_df=True, window_idx=\"begin\")\ntest_ent.replace([np.inf, -np.inf], 0,inplace=True)\ntrain_ent.replace([np.inf, -np.inf], 0,inplace=True)\nent_cols=list(test_ent.columns).copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:13:35.548041Z","iopub.execute_input":"2022-04-26T08:13:35.549048Z","iopub.status.idle":"2022-04-26T08:14:25.450979Z","shell.execute_reply.started":"2022-04-26T08:13:35.549005Z","shell.execute_reply":"2022-04-26T08:14:25.450029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We use the emg_features from tsflex to generate more features so we can later experiment with these ones as well :) \nemg_feats = MultipleFeatureDescriptors(\n        functions=seglearn_feature_dict_wrapper(emg_features()),\n        series_names=sensors,\n        windows=60,\n        strides=60,\n    )\n\nemg_feature_collect = FeatureCollection(emg_feats)\ntrain_emg = emg_feature_collect.calculate(train.copy().astype(np.float32), show_progress=True, return_df=True, window_idx=\"begin\")\ntest_emg = emg_feature_collect.calculate(test.copy().astype(np.float32), show_progress=True, return_df=True, window_idx=\"begin\")\nemg_cols=list(test_emg.columns).copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:14:25.454307Z","iopub.execute_input":"2022-04-26T08:14:25.454666Z","iopub.status.idle":"2022-04-26T08:15:05.5204Z","shell.execute_reply.started":"2022-04-26T08:14:25.454628Z","shell.execute_reply":"2022-04-26T08:15:05.51928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_emg[\"sequence\"]=train_features[\"sequence\"].copy()\ntest_emg[\"sequence\"]=test_features[\"sequence\"].copy()\n\ntrain_ent[\"sequence\"]=train_features[\"sequence\"].copy()\ntest_ent[\"sequence\"]=test_features[\"sequence\"].copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:15:05.522355Z","iopub.execute_input":"2022-04-26T08:15:05.522698Z","iopub.status.idle":"2022-04-26T08:15:05.541127Z","shell.execute_reply.started":"2022-04-26T08:15:05.522659Z","shell.execute_reply":"2022-04-26T08:15:05.540055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Special features for sensor 2!","metadata":{}},{"cell_type":"code","source":"%%time\n# Standard deviation is among the most important features, so I extend the concept a little bit...\ndef poz_mean(x):\n    y=x.diff()\n    y=np.where(y>0,y,0)\n    return np.nanmean(y)\n\ndef neg_mean(x):\n    y=x.diff()\n    y=np.where(y<0,y,0)\n    return np.nanmean(y)\n\ndef poz_std(x):\n    y=x.diff()\n    y=np.where(y>0,y,0)\n    return np.nanmean(y)\n\ndef neg_std(x):\n    y=x.diff()\n    y=np.where(y<0,y,0)\n    return np.nanstd(y)\n\nmetric_data_s2={\n    \"poz_mean_\": [poz_mean],\n    \"neg_mean_\": [neg_mean],\n    \"poz_std_\": [poz_std],\n    \"neg_std_\": [neg_std]\n}\n\ntrain_features_s2, gen_col_train_s2 = generate_features(df=train, \n                                                      metric_data=metric_data_s2, \n                                                      group_variables=[\"sequence\"], \n                                                      sensor_identifiers=[\"02\"], \n                                                      suffix=\"\")\n\ntest_features_s2, gen_col_test_s2 = generate_features(df=test, \n                                                      metric_data=metric_data_s2, \n                                                      group_variables=[\"sequence\"], \n                                                      sensor_identifiers=[\"02\"], \n                                                      suffix=\"\")\n\ntrain_features_s2.replace([np.inf, -np.inf], 0,inplace=True)\ntest_features_s2.replace([np.inf, -np.inf], 0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:15:05.542402Z","iopub.execute_input":"2022-04-26T08:15:05.542675Z","iopub.status.idle":"2022-04-26T08:26:04.164609Z","shell.execute_reply.started":"2022-04-26T08:15:05.542646Z","shell.execute_reply":"2022-04-26T08:26:04.163571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features_s2.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T08:26:04.166372Z","iopub.execute_input":"2022-04-26T08:26:04.167029Z","iopub.status.idle":"2022-04-26T08:26:04.190832Z","shell.execute_reply.started":"2022-04-26T08:26:04.16697Z","shell.execute_reply":"2022-04-26T08:26:04.189879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of sequences per subject\ntrain_subj_len=train[[\"sequence\",\"subject\"]].groupby(\"subject\").count().reset_index()\ntrain_subj_len.columns=[\"subject\",\"sequence_len\"]\ntest_subj_len=test[[\"sequence\",\"subject\"]].groupby(\"subject\").count().reset_index()\ntest_subj_len.columns=[\"subject\",\"sequence_len\"]\n\n# merge the tables together for train and test\ntrain_feature_final=train_labels.merge(train[[\"subject\",\"sequence\"]].copy().drop_duplicates(),how=\"left\",on=\"sequence\")\ntrain_feature_final=train_feature_final.merge(train_features,how=\"left\",on=\"sequence\")\ntrain_feature_final=train_feature_final.merge(train_features_s,how=\"left\",on=\"subject\")\ntrain_feature_final=train_feature_final.merge(train_subj_len,how=\"left\",on=\"subject\")\ntrain_feature_final=train_feature_final.merge(train_emg,how=\"left\",on=\"sequence\")\ntrain_feature_final=train_feature_final.merge(train_ent,how=\"left\",on=\"sequence\")\ntrain_feature_final=train_feature_final.merge(train_features_s2,how=\"left\",on=\"sequence\")\ntrain_feature_final=train_feature_final.merge(train_freq,how=\"left\",on=['sequence', 'subject'])\n\n# creating the col list.\nexplanatory_variables=gen_col_train+gen_col_train_s+[\"sequence_len\"]+freq_columns+emg_cols+ent_cols+gen_col_test_s2\n\ntest_feature_final=test[[\"subject\",\"sequence\"]].copy().drop_duplicates()\ntest_feature_final=test_feature_final.merge(test_features,how=\"left\",on=\"sequence\")\ntest_feature_final=test_feature_final.merge(test_features_s,how=\"left\",on=\"subject\")\ntest_feature_final=test_feature_final.merge(test_subj_len,how=\"left\",on=\"subject\")\ntest_feature_final=test_feature_final.merge(test_emg,how=\"left\",on=\"sequence\")\ntest_feature_final=test_feature_final.merge(test_ent,how=\"left\",on=\"sequence\")\ntest_feature_final=test_feature_final.merge(test_features_s2,how=\"left\",on=\"sequence\")\ntest_feature_final=test_feature_final.merge(test_freq,how=\"left\",on=['sequence', 'subject'])\n\ntest_feature_final.fillna(0,inplace=True)\ntrain_feature_final.fillna(0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:31:57.729343Z","iopub.execute_input":"2022-04-26T09:31:57.729655Z","iopub.status.idle":"2022-04-26T09:31:59.613698Z","shell.execute_reply.started":"2022-04-26T09:31:57.729622Z","shell.execute_reply":"2022-04-26T09:31:59.612634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Transform train and test to 0-1 scale\nscaler = MinMaxScaler()\ntrain_feature_final.loc[:,explanatory_variables]=scaler.fit_transform(train_feature_final.loc[:,explanatory_variables])\ntest_feature_final.loc[:,explanatory_variables]=scaler.transform(test_feature_final.loc[:,explanatory_variables])\n\n# we have skewed distributions, we apply a sqrt functional form which translates the distribution to a least skewed one.\nfor var in explanatory_variables:\n    if (train_feature_final[var].skew()) > 3 and not train_feature_final[var].min()<0.0:\n        train_feature_final[var]=np.sqrt(train_feature_final[var])\n        test_feature_final[var]=np.sqrt(test_feature_final[var])\n        \ntest_feature_final.fillna(0,inplace=True)\ntrain_feature_final.fillna(0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:31:59.615284Z","iopub.execute_input":"2022-04-26T09:31:59.615523Z","iopub.status.idle":"2022-04-26T09:32:15.764296Z","shell.execute_reply.started":"2022-04-26T09:31:59.615496Z","shell.execute_reply":"2022-04-26T09:32:15.762484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features=[\"kurtosis_04\", \n                   \"sequence_len\",\n                   \"std_02\",\n                   \"kurtosis_10\",\n                   \"sensor_09_freq_0\",\n                   \"sensor_09_freq_1\",\n                   \"sensor_01_freq_0\",\n                   \"sensor_02_freq_2\",\n                   \"p05_09\",\n                   \"max_05\",\n                   \"p25_10\",\n                   \"p10_04\",\n                   \"poz_std_02\",\n                   \"neg_std_02\",\n                   \"poz_mean_02\",\n                   \"neg_mean_02\",\n                   \"d_mean_04\"\n                  ]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:32:15.766823Z","iopub.execute_input":"2022-04-26T09:32:15.767133Z","iopub.status.idle":"2022-04-26T09:32:15.774281Z","shell.execute_reply.started":"2022-04-26T09:32:15.767097Z","shell.execute_reply":"2022-04-26T09:32:15.773256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in selected_features:\n    plt.figure(figsize=(20,6))\n    plt.hist(train_feature_final[train_feature_final[\"state\"]<1][feature],bins=200, density=True, label='State : 0',color='#CBC3E3')\n    plt.hist(train_feature_final[train_feature_final[\"state\"]>0][feature],bins=200, density=True, label='State : 1',color='#F4B123', alpha = 0.5)\n    plt.ylabel('Frequency')\n    plt.title('Distribution of values for feature: '+feature, fontsize=15)\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:32:15.775668Z","iopub.execute_input":"2022-04-26T09:32:15.776884Z","iopub.status.idle":"2022-04-26T09:32:37.891661Z","shell.execute_reply.started":"2022-04-26T09:32:15.77683Z","shell.execute_reply":"2022-04-26T09:32:37.890644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Variable selection <a name=\"sel\"></a>","metadata":{}},{"cell_type":"code","source":"scoref=\"roc_auc\"\nrepeat_numb=5","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:33:01.728538Z","iopub.execute_input":"2022-04-26T09:33:01.728892Z","iopub.status.idle":"2022-04-26T09:33:01.734146Z","shell.execute_reply.started":"2022-04-26T09:33:01.728852Z","shell.execute_reply":"2022-04-26T09:33:01.733184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here I create a reduced list of variable\n# First I estimate a logit model with the unreduced set of var, then I estiamte the same model with the reduced set.","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:21:45.152358Z","iopub.execute_input":"2022-04-24T10:21:45.152901Z","iopub.status.idle":"2022-04-24T10:21:45.156635Z","shell.execute_reply.started":"2022-04-24T10:21:45.152861Z","shell.execute_reply":"2022-04-24T10:21:45.155624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlog0 =LogisticRegression(random_state=42,max_iter=12000, C=1.6)\n# here I increased iteration number from the low default value to avoid warnings\n# regularization param, arbitrarily decreased to respect large number of variables (default C = 1.0)\nlog0, feat_imp=fit_model_using_classifier(log0, \n                                          dtrain=train_feature_final, \n                                          predictors=explanatory_variables,\n                                          repeat=repeat_numb,\n                                          scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:21:46.994555Z","iopub.execute_input":"2022-04-24T10:21:46.994902Z","iopub.status.idle":"2022-04-24T10:29:36.197367Z","shell.execute_reply.started":"2022-04-24T10:21:46.994859Z","shell.execute_reply":"2022-04-24T10:29:36.19622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nperm_result = permutation_importance(log0, \n                                     X=train_feature_final[explanatory_variables],\n                                     y=train_feature_final[\"state\"], \n                                     n_repeats=10,\n                                     scoring=scoref,\n                                     random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:08:59.474306Z","iopub.execute_input":"2022-04-24T10:08:59.474517Z","iopub.status.idle":"2022-04-24T10:08:59.5773Z","shell.execute_reply.started":"2022-04-24T10:08:59.474492Z","shell.execute_reply":"2022-04-24T10:08:59.576546Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_select=pd.DataFrame({\n    \"variable\": explanatory_variables,\n    \"importances_mean\": perm_result.importances_mean*100,\n    \"importances_std\": perm_result.importances_std\n})\nres_select.sort_values(by=[\"importances_mean\"],inplace=True,ascending=False)\nres_select.to_csv(\"res_select.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:08:59.578498Z","iopub.execute_input":"2022-04-24T10:08:59.578692Z","iopub.status.idle":"2022-04-24T10:08:59.595767Z","shell.execute_reply.started":"2022-04-24T10:08:59.578668Z","shell.execute_reply":"2022-04-24T10:08:59.594842Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"super_short_list=list(res_select[res_select[\"importances_mean\"]>1][\"variable\"])\nshort_list=list(res_select[res_select[\"importances_mean\"]>0.1][\"variable\"])\nlonger_list=list(res_select[res_select[\"importances_mean\"]>0.05][\"variable\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:08:59.597304Z","iopub.status.idle":"2022-04-24T10:08:59.598025Z","shell.execute_reply.started":"2022-04-24T10:08:59.597738Z","shell.execute_reply":"2022-04-24T10:08:59.597768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Most important features\")\nprint(super_short_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:08:59.599375Z","iopub.status.idle":"2022-04-24T10:08:59.600346Z","shell.execute_reply.started":"2022-04-24T10:08:59.600102Z","shell.execute_reply":"2022-04-24T10:08:59.60013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original number of features: \"+str(len(explanatory_variables)))\nprint(\"Short list number of features: \"+str(len(short_list)))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:08:59.601105Z","iopub.status.idle":"2022-04-24T10:08:59.601976Z","shell.execute_reply.started":"2022-04-24T10:08:59.60179Z","shell.execute_reply":"2022-04-24T10:08:59.601813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. LGBM Classifier <a name=\"vars\"></a>","metadata":{}},{"cell_type":"code","source":"params_lgbm={\n    \"colsample_bytree\": 0.8,\n    \"n_estimators\": 500,\n    \"min_child_samples\":50, \n    #\"max_depth\":3,\n    \"learning_rate\":0.045\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:33:05.164198Z","iopub.execute_input":"2022-04-26T09:33:05.165071Z","iopub.status.idle":"2022-04-26T09:33:05.170242Z","shell.execute_reply.started":"2022-04-26T09:33:05.165023Z","shell.execute_reply":"2022-04-26T09:33:05.169167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlgbm0 =LGBMClassifier(random_state=42, metric=\"roc_auc\",objective=\"binary\",**params_lgbm)\n# I added some restrictions to avoid overfit.\nlgbm0, feat_imp=fit_model_using_classifier(lgbm0, \n                                           dtrain=train_feature_final, \n                                           predictors=explanatory_variables,\n                                           repeat=repeat_numb,\n                                           scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:33:07.01835Z","iopub.execute_input":"2022-04-26T09:33:07.018918Z","iopub.status.idle":"2022-04-26T09:37:41.173743Z","shell.execute_reply.started":"2022-04-26T09:33:07.018873Z","shell.execute_reply":"2022-04-26T09:37:41.172785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm0_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": lgbm0.predict(test_feature_final[explanatory_variables])})\nlgbm0_model_submission.to_csv(\"lgbm0_model_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:38:48.986958Z","iopub.execute_input":"2022-04-26T09:38:48.987869Z","iopub.status.idle":"2022-04-26T09:38:49.330761Z","shell.execute_reply.started":"2022-04-26T09:38:48.987814Z","shell.execute_reply":"2022-04-26T09:38:49.329836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm0_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": lgbm0.predict_proba(test_feature_final[explanatory_variables])[:,1]})\nlgbm0_model_submission.to_csv(\"lgbm0_model_prob_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:38:50.181891Z","iopub.execute_input":"2022-04-26T09:38:50.182418Z","iopub.status.idle":"2022-04-26T09:38:50.532203Z","shell.execute_reply.started":"2022-04-26T09:38:50.182367Z","shell.execute_reply":"2022-04-26T09:38:50.531479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlgbm2 =LGBMClassifier(random_state=42, metric=\"roc_auc\",objective=\"binary\",**params_lgbm)\n# I added some restrictions to avoid overfit.\nlgbm2, feat_imp=fit_model_using_classifier(lgbm2, \n                                           dtrain=train_feature_final, \n                                           predictors=longer_list,\n                                           repeat=repeat_numb,\n                                           scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:51:32.106349Z","iopub.execute_input":"2022-04-21T18:51:32.106597Z","iopub.status.idle":"2022-04-21T18:53:18.479253Z","shell.execute_reply.started":"2022-04-21T18:51:32.106567Z","shell.execute_reply":"2022-04-21T18:53:18.478237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm2_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": lgbm2.predict(test_feature_final[longer_list])})\nlgbm2_model_submission.to_csv(\"lgbm2_model_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:53:44.699706Z","iopub.execute_input":"2022-04-21T18:53:44.700673Z","iopub.status.idle":"2022-04-21T18:53:44.917126Z","shell.execute_reply.started":"2022-04-21T18:53:44.700612Z","shell.execute_reply":"2022-04-21T18:53:44.916106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm2_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": lgbm2.predict_proba(test_feature_final[longer_list])[:,1]})\nlgbm2_model_submission.to_csv(\"lgbm2_model_prob_submission.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Catboost classifier","metadata":{}},{"cell_type":"code","source":"cat_params={\n    \"iterations\":4000,\n    \"learning_rate\":0.025,\n    'loss_function' : 'Logloss',\n    \"eval_metric\":\"AUC\",\n    \"verbose\":False\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:39:08.642378Z","iopub.execute_input":"2022-04-26T09:39:08.643143Z","iopub.status.idle":"2022-04-26T09:39:08.648832Z","shell.execute_reply.started":"2022-04-26T09:39:08.643092Z","shell.execute_reply":"2022-04-26T09:39:08.647656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nclf = CatBoostClassifier(\n    **cat_params\n)\n\n# clf.fit(\n#     train_feature_final[explanatory_variables], \n#     train_feature_final[\"state\"], verbose=True\n# )\n\nclf, feat_imp=fit_model_using_classifier(clf, \n                                           dtrain=train_feature_final, \n                                           predictors=explanatory_variables,\n                                           repeat=repeat_numb,\n                                           scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T09:39:12.963321Z","iopub.execute_input":"2022-04-26T09:39:12.963636Z","iopub.status.idle":"2022-04-26T10:26:38.762719Z","shell.execute_reply.started":"2022-04-26T09:39:12.963606Z","shell.execute_reply":"2022-04-26T10:26:38.761511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features_cat=list(feat_imp[feat_imp>0.00].index)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:53:50.2084Z","iopub.execute_input":"2022-04-26T11:53:50.209448Z","iopub.status.idle":"2022-04-26T11:53:50.215274Z","shell.execute_reply.started":"2022-04-26T11:53:50.209393Z","shell.execute_reply":"2022-04-26T11:53:50.214262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": clf.predict(test_feature_final[explanatory_variables])})\nclf_model_submission.to_csv(\"clf_model_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:53:51.655886Z","iopub.execute_input":"2022-04-26T11:53:51.656343Z","iopub.status.idle":"2022-04-26T11:53:51.932286Z","shell.execute_reply.started":"2022-04-26T11:53:51.656312Z","shell.execute_reply":"2022-04-26T11:53:51.931153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": clf.predict_proba(test_feature_final[explanatory_variables])[:,1]})\nclf_model_submission.to_csv(\"clf_model_prob_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:53:52.844879Z","iopub.execute_input":"2022-04-26T11:53:52.8452Z","iopub.status.idle":"2022-04-26T11:53:53.089704Z","shell.execute_reply.started":"2022-04-26T11:53:52.845164Z","shell.execute_reply":"2022-04-26T11:53:53.088753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1 = CatBoostClassifier(\n    **cat_params\n)\n\nclf1, feat_imp=fit_model_using_classifier(clf1, \n                                           dtrain=train_feature_final, \n                                           predictors=selected_features_cat,\n                                           repeat=repeat_numb,\n                                           scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:53:54.634322Z","iopub.execute_input":"2022-04-26T11:53:54.63465Z","iopub.status.idle":"2022-04-26T12:29:10.123504Z","shell.execute_reply.started":"2022-04-26T11:53:54.634615Z","shell.execute_reply":"2022-04-26T12:29:10.122223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": clf1.predict(test_feature_final[selected_features_cat])})\nclf1_model_submission.to_csv(\"clf1_model_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:29:10.126726Z","iopub.execute_input":"2022-04-26T12:29:10.127171Z","iopub.status.idle":"2022-04-26T12:29:10.312528Z","shell.execute_reply.started":"2022-04-26T12:29:10.127121Z","shell.execute_reply":"2022-04-26T12:29:10.311298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": clf1.predict_proba(test_feature_final[selected_features_cat])[:,1]})\nclf1_model_submission.to_csv(\"clf1_model_prob_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:29:10.314145Z","iopub.execute_input":"2022-04-26T12:29:10.314527Z","iopub.status.idle":"2022-04-26T12:29:10.520067Z","shell.execute_reply.started":"2022-04-26T12:29:10.31448Z","shell.execute_reply":"2022-04-26T12:29:10.519054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# further decrease in variables\nselected_features_cat=list(feat_imp[feat_imp>0.1].index)\nselected_features_cat=list(set(longer_list).union(set(selected_features_cat)))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:29:10.523224Z","iopub.execute_input":"2022-04-26T12:29:10.523607Z","iopub.status.idle":"2022-04-26T12:29:10.53022Z","shell.execute_reply.started":"2022-04-26T12:29:10.52356Z","shell.execute_reply":"2022-04-26T12:29:10.528884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf2 = CatBoostClassifier(\n    **cat_params\n)\n\nclf2, feat_imp=fit_model_using_classifier(clf2, \n                                           dtrain=train_feature_final, \n                                           predictors=selected_features_cat,\n                                           repeat=repeat_numb,\n                                           scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:29:10.531619Z","iopub.execute_input":"2022-04-26T12:29:10.532213Z","iopub.status.idle":"2022-04-26T12:41:06.54761Z","shell.execute_reply.started":"2022-04-26T12:29:10.532172Z","shell.execute_reply":"2022-04-26T12:41:06.546835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf2_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": clf2.predict_proba(test_feature_final[selected_features_cat])[:,1]})\nclf2_model_submission.to_csv(\"clf2_model_prob_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:41:06.549204Z","iopub.execute_input":"2022-04-26T12:41:06.549476Z","iopub.status.idle":"2022-04-26T12:41:06.691054Z","shell.execute_reply.started":"2022-04-26T12:41:06.549443Z","shell.execute_reply":"2022-04-26T12:41:06.68954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(selected_features_cat)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:41:06.692783Z","iopub.execute_input":"2022-04-26T12:41:06.693425Z","iopub.status.idle":"2022-04-26T12:41:06.702468Z","shell.execute_reply.started":"2022-04-26T12:41:06.693369Z","shell.execute_reply":"2022-04-26T12:41:06.701171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. XGBoost  <a name=\"xg\"></a>","metadata":{}},{"cell_type":"code","source":"%%time\ngbm1 =GradientBoostingClassifier(random_state=42)\ngbm1, feat_imp=fit_model_using_classifier(gbm1, \n                                          dtrain=train_feature_final, \n                                          predictors=selected_features_cat,\n                                          repeat=repeat_numb,\n                                          scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:41:06.705072Z","iopub.execute_input":"2022-04-26T12:41:06.705971Z","iopub.status.idle":"2022-04-26T13:17:34.05435Z","shell.execute_reply.started":"2022-04-26T12:41:06.705903Z","shell.execute_reply":"2022-04-26T13:17:34.053321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": gbm1.predict_proba(test_feature_final[selected_features_cat])[:,1]})\nxgb_model_submission.to_csv(\"xgb_model_submission_select.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:17:34.056226Z","iopub.execute_input":"2022-04-26T13:17:34.056588Z","iopub.status.idle":"2022-04-26T13:17:34.179097Z","shell.execute_reply.started":"2022-04-26T13:17:34.056543Z","shell.execute_reply":"2022-04-26T13:17:34.178212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlgbm1 =LGBMClassifier(random_state=42, metric=\"roc_auc\",objective=\"binary\",**params_lgbm)\n# I added some restrictions to avoid overfit.\nlgbm1, feat_imp=fit_model_using_classifier(lgbm1, \n                                           dtrain=train_feature_final, \n                                           predictors=selected_features_cat,\n                                           repeat=repeat_numb,\n                                           scoring=scoref)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:17:34.181518Z","iopub.execute_input":"2022-04-26T13:17:34.181867Z","iopub.status.idle":"2022-04-26T13:18:44.903008Z","shell.execute_reply.started":"2022-04-26T13:17:34.181836Z","shell.execute_reply":"2022-04-26T13:18:44.902213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Ensemble  <a name=\"ens\"></a>","metadata":{}},{"cell_type":"code","source":"def get_models():\n    models = list()\n    models.append(('lgbm1', lgbm1))\n    models.append(('xgb', gbm1))\n    models.append(('clf2', clf2))\n    return models\n\ndef fit_ensemble(models, X_train, X_val, y_train, y_val, soft_vote=True):\n    \"\"\"\n    Fit all models on the training set and predict on hold out set\n    \"\"\"\n    meta_X = list()\n    if X_val is None:\n        X_val=X_train\n    if y_val is None:\n        y_val=y_train\n    \n    for name, model in models:\n        model.fit(X_train, y_train)\n        if soft_vote:\n            yhat = model.predict_proba(X_val)[:,1]\n        else:\n            yhat = model.predict(X_val)\n        yhat2 = yhat.reshape(len(yhat), 1)\n        meta_X.append(yhat2)\n        del yhat\n    meta_X = np.hstack(meta_X)\n    blender = CatBoostClassifier(verbose=False)\n    blender.fit(meta_X, y_val)\n    return blender, meta_X\n\ndef predict_ensemble(models, blender, X_test, soft_vote=True):\n    \"\"\"\n    Predict outcome using the set of models\n    \"\"\"\n    meta_X = list()\n    for name, model in models:\n        if soft_vote:\n            yhat = model.predict_proba(X_test)[:,1]\n        else:\n            yhat = model.predict(X_test)\n        yhat2 = yhat.reshape(len(yhat), 1)\n        del yhat\n        meta_X.append(yhat2)\n    meta_X = np.hstack(meta_X)\n    return blender.predict_proba(meta_X)[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:59:27.359674Z","iopub.execute_input":"2022-04-26T13:59:27.360013Z","iopub.status.idle":"2022-04-26T13:59:27.373166Z","shell.execute_reply.started":"2022-04-26T13:59:27.35998Z","shell.execute_reply":"2022-04-26T13:59:27.371981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor i in range(42,45):\n    train_in, train_out=train_test_split(train_feature_final,test_size=0.33, random_state=i)\n    blender, meta_X=fit_ensemble(models=get_models(),\n                     X_train=train_in[selected_features_cat],\n                     X_val=train_out[selected_features_cat],\n                     y_train=train_in[\"state\"],\n                     y_val=train_out[\"state\"], soft_vote=True)\n\n    pred_state=predict_ensemble(models=get_models(), blender=blender, X_test=train_out[selected_features_cat])\n    print(metrics.roc_auc_score(train_out[\"state\"],pred_state))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T13:59:29.020294Z","iopub.execute_input":"2022-04-26T13:59:29.020624Z","iopub.status.idle":"2022-04-26T14:08:43.406251Z","shell.execute_reply.started":"2022-04-26T13:59:29.020588Z","shell.execute_reply":"2022-04-26T14:08:43.405117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blender_final, _ =fit_ensemble(models=get_models(),\n             X_train=train_feature_final[selected_features_cat],\n             X_val=None,\n             y_train=train_feature_final[\"state\"],\n             y_val=None)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T14:08:43.408616Z","iopub.execute_input":"2022-04-26T14:08:43.409204Z","iopub.status.idle":"2022-04-26T14:13:06.817056Z","shell.execute_reply.started":"2022-04-26T14:08:43.409154Z","shell.execute_reply":"2022-04-26T14:13:06.815933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_model_submission=pd.DataFrame({\n    \"sequence\": test_feature_final[\"sequence\"],\n    \"state\": predict_ensemble(models=get_models(), blender=blender_final, X_test=test_feature_final[selected_features_cat])\n})\nens_model_submission.to_csv(\"ens_model_submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T14:13:06.818495Z","iopub.execute_input":"2022-04-26T14:13:06.818737Z","iopub.status.idle":"2022-04-26T14:13:07.174437Z","shell.execute_reply.started":"2022-04-26T14:13:06.81871Z","shell.execute_reply":"2022-04-26T14:13:07.17343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Acknowledgement  <a name=\"ack\"></a>","metadata":{}},{"cell_type":"code","source":"\"\"\"\n    I got the idea to use freuencies and Fourier transform by looking at Pavel Salikov's notebook\n    https://www.kaggle.com/code/matanivanov/lgbm-with-fourier-transform\n    \n    The fit_model_using_classifier function is based on this article\n    //www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n    \n    To create my ensemble solution I used this source:\n    https://machinelearningmastery.com/blending-ensemble-machine-learning-with-python/\n    \n    I got the idea to use LGBM classifier from Kelly Belcher's notebook\n    https://www.kaggle.com/code/kellibelcher/time-series-classification-with-lstms-sensor-eda\n\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html\n# https://www.kaggle.com/competitions/tabular-playground-series-apr-2022/discussion/318527\n# https://predict-idlab.github.io/tsflex/features/\n# https://www.kaggle.com/code/ahmetcelik158/tps-apr-22-lstm-with-pytorch#1.-Data-Preparation","metadata":{},"execution_count":null,"outputs":[]}]}