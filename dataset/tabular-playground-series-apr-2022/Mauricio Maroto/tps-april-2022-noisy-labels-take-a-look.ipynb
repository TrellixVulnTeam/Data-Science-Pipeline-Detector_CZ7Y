{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1>TPS April 2022</h1></center>\n<center><h1>Inspecting the Labels</h1></center>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Simple Setup","metadata":{}},{"cell_type":"code","source":"%reset -sf\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:21:43.873387Z","iopub.execute_input":"2022-04-07T23:21:43.873793Z","iopub.status.idle":"2022-04-07T23:21:45.076075Z","shell.execute_reply.started":"2022-04-07T23:21:43.873749Z","shell.execute_reply":"2022-04-07T23:21:45.075078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"from pandas import read_csv, DataFrame, Series, IndexSlice\n#from pathlib import Path\n#list(Path('/kaggle/input').rglob('*.*'))\n\ntrain = read_csv('/kaggle/input/tabular-playground-series-apr-2022/train.csv')\ny_train = read_csv('/kaggle/input/tabular-playground-series-apr-2022/train_labels.csv')\ntest = read_csv('/kaggle/input/tabular-playground-series-apr-2022/test.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:21:45.077757Z","iopub.execute_input":"2022-04-07T23:21:45.078041Z","iopub.status.idle":"2022-04-07T23:21:55.755616Z","shell.execute_reply.started":"2022-04-07T23:21:45.078007Z","shell.execute_reply":"2022-04-07T23:21:55.754692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce memory","metadata":{}},{"cell_type":"code","source":"from numpy import float64, float32, int64, int32, dtype\n\ndef reduce_mem(df):\n    df = df.copy()\n    \n    map_dtypes = {'int': dtype(int64), 'float': dtype(float32)}\n    \n    for col in df:\n        if df[col].dtype == dtype(int64):\n            df[col] = df[col].astype(int32)\n        if df[col].dtype == dtype(float64):\n            df[col] = df[col].astype(float32)\n    return df\n\ntrain = reduce_mem(train)\ntest = reduce_mem(test)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:21:55.757478Z","iopub.execute_input":"2022-04-07T23:21:55.757804Z","iopub.status.idle":"2022-04-07T23:21:56.575806Z","shell.execute_reply.started":"2022-04-07T23:21:55.757761Z","shell.execute_reply":"2022-04-07T23:21:56.574855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Labels","metadata":{}},{"cell_type":"markdown","source":"## <em>First, let's convert sequences into some scalar criteria, i.e.</em>","metadata":{}},{"cell_type":"code","source":"train_ = train.pivot_table(\n    index=['subject', 'sequence'],\n    aggfunc='median'\n)\n\nf'I decide to summarize sequences by using a simple median'","metadata":{"execution":{"iopub.status.busy":"2022-04-07T23:21:56.577265Z","iopub.execute_input":"2022-04-07T23:21:56.577534Z","iopub.status.idle":"2022-04-07T23:21:57.389675Z","shell.execute_reply.started":"2022-04-07T23:21:56.5775Z","shell.execute_reply":"2022-04-07T23:21:57.38883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>Second, let's project that data into 2 dimensions, for easy visualization</em>","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\ntrain_pca = pca.fit_transform(train_)\n\nf'These 2 components explain {pca.explained_variance_ratio_.sum()*100:.2f}% of original data variance'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:21:57.391245Z","iopub.execute_input":"2022-04-07T23:21:57.391488Z","iopub.status.idle":"2022-04-07T23:21:57.513374Z","shell.execute_reply.started":"2022-04-07T23:21:57.391457Z","shell.execute_reply":"2022-04-07T23:21:57.512327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>How does it look like?</em>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nsns.set_context('talk')\n\nfig, ax = plt.subplots(1, 1, figsize=(12,8), sharex=True, sharey=True, constrained_layout=True)\n\n_ = ax.scatter(train_pca[(y_train['state']==0),0], train_pca[(y_train['state']==0),1], facecolor='none', edgecolor='blue', alpha=0.5, label='State 0')\n_ = ax.scatter(train_pca[(y_train['state']==1),0], train_pca[(y_train['state']==1),1], facecolor='none', edgecolor='orange', alpha=0.5, label='State 1')\n_ = ax.legend()\n\nf'At this stage, it doesn\\'t seem like there is a clear distinction between states'\nf'So, let\\'s try non-linear decomposition'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:22:02.403978Z","iopub.execute_input":"2022-04-07T23:22:02.404267Z","iopub.status.idle":"2022-04-07T23:22:04.154968Z","shell.execute_reply.started":"2022-04-07T23:22:02.404239Z","shell.execute_reply":"2022-04-07T23:22:04.154088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>Non-Linear Decomposition</em>","metadata":{}},{"cell_type":"code","source":"import umap\n\nmani = umap.UMAP()\ntrain_umap = mani.fit_transform(train_)\n\nfig, ax = plt.subplots(1, 1, figsize=(12,8), sharex=True, sharey=True, constrained_layout=True)\n\n_ = ax.scatter(train_umap[(y_train['state']==0),0], train_umap[(y_train['state']==0),1], facecolor='none', edgecolor='blue', alpha=0.5, label='State 0')\n_ = ax.scatter(train_umap[(y_train['state']==1),0], train_umap[(y_train['state']==1),1], facecolor='none', edgecolor='orange', alpha=0.5, label='State 1')\n_ = ax.legend()\n\nf'Even with non-linear decomposition, it doesn\\'t seem like there is a clear distinction between states'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:27:52.810904Z","iopub.execute_input":"2022-04-07T23:27:52.811959Z","iopub.status.idle":"2022-04-07T23:28:21.506609Z","shell.execute_reply.started":"2022-04-07T23:27:52.811894Z","shell.execute_reply":"2022-04-07T23:28:21.505987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>Let's return to the sequences</em>","metadata":{}},{"cell_type":"code","source":"train__ = train.pivot_table(\n    index='sequence',\n    columns='step'\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T23:28:33.054701Z","iopub.execute_input":"2022-04-07T23:28:33.055317Z","iopub.status.idle":"2022-04-07T23:28:35.960313Z","shell.execute_reply.started":"2022-04-07T23:28:33.055273Z","shell.execute_reply":"2022-04-07T23:28:35.959315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>And apply PCA again</em>","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=2)\ntrain_pca = pca.fit_transform(train__)\n\nf'These 2 components explain {pca.explained_variance_ratio_.sum()*100:.2f}% of original data variance'\n\nfig, ax = plt.subplots(1, 1, figsize=(12,8), sharex=True, sharey=True, constrained_layout=True)\n\n_ = ax.scatter(train_pca[(y_train['state']==0),0], train_pca[(y_train['state']==0),1], facecolor='none', edgecolor='blue', alpha=0.5, label='State 0')\n_ = ax.scatter(train_pca[(y_train['state']==1),0], train_pca[(y_train['state']==1),1], facecolor='none', edgecolor='orange', alpha=0.5, label='State 1')\n_ = ax.legend()\n\nf'We may start to see some distinction between states'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:28:36.030559Z","iopub.execute_input":"2022-04-07T23:28:36.03103Z","iopub.status.idle":"2022-04-07T23:28:40.056824Z","shell.execute_reply.started":"2022-04-07T23:28:36.030991Z","shell.execute_reply":"2022-04-07T23:28:40.055899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em> And UMAP again</em>","metadata":{}},{"cell_type":"code","source":"mani = umap.UMAP()\ntrain_umap = mani.fit_transform(train_)\n\nfig, ax = plt.subplots(1, 1, figsize=(12,8), sharex=True, sharey=True, constrained_layout=True)\n\n_ = ax.scatter(train_umap[(y_train['state']==0),0], train_umap[(y_train['state']==0),1], facecolor='none', edgecolor='blue', alpha=0.5, label='State 0')\n_ = ax.scatter(train_umap[(y_train['state']==1),0], train_umap[(y_train['state']==1),1], facecolor='none', edgecolor='orange', alpha=0.5, label='State 1')\n_ = ax.legend()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-07T23:29:14.935053Z","iopub.execute_input":"2022-04-07T23:29:14.93541Z","iopub.status.idle":"2022-04-07T23:29:35.038995Z","shell.execute_reply.started":"2022-04-07T23:29:14.935374Z","shell.execute_reply":"2022-04-07T23:29:35.037867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>For the sake of comparison, let's see the same techniques over MNIST</em>","metadata":{}},{"cell_type":"code","source":"from torch import load\n\nmnist = load('/kaggle/input/pytorch-mnist/training.pt')\nm_train = mnist[0].reshape(-1, 784).numpy()[:10000, :]  # just 10000 images for quick\nm_y_train = mnist[1].numpy()[:10000]\n\npca = PCA(n_components=2)\nm_train_pca = pca.fit_transform(m_train)\n\nf'These 2 components explain {pca.explained_variance_ratio_.sum()*100:.2f}% of original data variance'\n\nfig, ax = plt.subplots(1, 1, figsize=(12,8), sharex=True, sharey=True, constrained_layout=True)\ncolors = ['blue', 'orange', 'red', 'purple', 'yellow', 'grey', 'green', 'brown', 'aquamarine', 'navy']\nfor i, c in zip(range(10), colors):\n    _ = ax.scatter(m_train_pca[m_y_train==i,0], m_train_pca[m_y_train==i,1], facecolor='none', edgecolor=c, alpha=0.25, label=f'Number {i}')\n_ = ax.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T23:32:06.427897Z","iopub.execute_input":"2022-04-07T23:32:06.428638Z","iopub.status.idle":"2022-04-07T23:32:09.221908Z","shell.execute_reply.started":"2022-04-07T23:32:06.428587Z","shell.execute_reply":"2022-04-07T23:32:09.221063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <em>And with UMAP</em>","metadata":{}},{"cell_type":"code","source":"mani = umap.UMAP()\ntrain_umap = mani.fit_transform(m_train)\n\nfig, ax = plt.subplots(1, 1, figsize=(12,8), sharex=True, sharey=True, constrained_layout=True)\ncolors = ['blue', 'orange', 'red', 'purple', 'yellow', 'grey', 'green', 'brown', 'aquamarine', 'navy']\nfor i, c in zip(range(10), colors):\n    _ = ax.scatter(train_umap[m_y_train==i,0], train_umap[m_y_train==i,1], \n                   facecolor='none', \n                   edgecolor=c, \n                   alpha=0.5, \n                   label=f'Number {i}')\n_ = ax.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T23:32:19.707983Z","iopub.execute_input":"2022-04-07T23:32:19.709004Z","iopub.status.idle":"2022-04-07T23:32:45.15238Z","shell.execute_reply.started":"2022-04-07T23:32:19.708956Z","shell.execute_reply":"2022-04-07T23:32:45.151269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\n### - There doesn't seem to be a clear distinction between States given the Features.\n### - What else could we do in order to assess this?\n### - Feel free to suggest. \n### - Bye.","metadata":{}},{"cell_type":"markdown","source":"## Feel free to upvote if you like. Thanks","metadata":{}}]}