{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabuler Playground seriese","metadata":{}},{"cell_type":"markdown","source":"This notebook introduces a new structure of neural networks","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Import modules","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom tqdm import tqdm\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('Active device：', device)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:03.244215Z","iopub.execute_input":"2022-04-11T14:42:03.244721Z","iopub.status.idle":"2022-04-11T14:42:05.6006Z","shell.execute_reply.started":"2022-04-11T14:42:03.244627Z","shell.execute_reply":"2022-04-11T14:42:05.599726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loads","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\ntrain_label_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:05.602881Z","iopub.execute_input":"2022-04-11T14:42:05.603314Z","iopub.status.idle":"2022-04-11T14:42:16.98866Z","shell.execute_reply.started":"2022-04-11T14:42:05.603272Z","shell.execute_reply":"2022-04-11T14:42:16.987846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape) \ntrain_df.head(70)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:16.989621Z","iopub.execute_input":"2022-04-11T14:42:16.98984Z","iopub.status.idle":"2022-04-11T14:42:17.031925Z","shell.execute_reply.started":"2022-04-11T14:42:16.989809Z","shell.execute_reply":"2022-04-11T14:42:17.031102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_label_df.shape) \ntrain_label_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:17.033334Z","iopub.execute_input":"2022-04-11T14:42:17.033801Z","iopub.status.idle":"2022-04-11T14:42:17.045105Z","shell.execute_reply.started":"2022-04-11T14:42:17.033743Z","shell.execute_reply":"2022-04-11T14:42:17.044131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the data","metadata":{}},{"cell_type":"code","source":"train_df.loc[:, 'sensor_00': 'sensor_12'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:17.047739Z","iopub.execute_input":"2022-04-11T14:42:17.048074Z","iopub.status.idle":"2022-04-11T14:42:17.946252Z","shell.execute_reply.started":"2022-04-11T14:42:17.048034Z","shell.execute_reply":"2022-04-11T14:42:17.945319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process data","metadata":{}},{"cell_type":"code","source":"ntrain = train_df.shape[0]\nall_data = pd.concat((train_df, test_df))#.reset_index(drop=True)\nprint(all_data.shape)\nall_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:17.947486Z","iopub.execute_input":"2022-04-11T14:42:17.947691Z","iopub.status.idle":"2022-04-11T14:42:18.066599Z","shell.execute_reply.started":"2022-04-11T14:42:17.947666Z","shell.execute_reply":"2022-04-11T14:42:18.065792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = all_data.columns.tolist()[3:]\nfor feature in features:\n    all_data[feature + '_lag1'] = all_data.groupby('sequence')[feature].shift(1)\n    all_data.fillna(0, inplace=True)\n    all_data[feature + '_diff1'] = all_data[feature] - all_data[feature + '_lag1']\n    all_data.drop(feature+'_lag1', axis=1, inplace=True)\nall_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:18.067735Z","iopub.execute_input":"2022-04-11T14:42:18.068062Z","iopub.status.idle":"2022-04-11T14:42:28.696421Z","shell.execute_reply.started":"2022-04-11T14:42:18.068029Z","shell.execute_reply":"2022-04-11T14:42:28.695629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = all_data[:ntrain]\ntest_df = all_data[ntrain:]\nprint(train_df.shape, test_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:28.697754Z","iopub.execute_input":"2022-04-11T14:42:28.698029Z","iopub.status.idle":"2022-04-11T14:42:28.725918Z","shell.execute_reply.started":"2022-04-11T14:42:28.698001Z","shell.execute_reply":"2022-04-11T14:42:28.725373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_num = train_df.groupby('sequence').count()['subject'].values\nprint(sequence_num)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:28.726708Z","iopub.execute_input":"2022-04-11T14:42:28.727346Z","iopub.status.idle":"2022-04-11T14:42:29.006338Z","shell.execute_reply.started":"2022-04-11T14:42:28.727309Z","shell.execute_reply":"2022-04-11T14:42:29.005538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training\n## Spritting data","metadata":{}},{"cell_type":"code","source":"test_rate = 0.2\ndef train_test_split(X, y, sequence_num, test_rate=0.2):\n    feature_size = X.shape[1]\n    id_seq = np.array([list(range(0, sequence_num[0]))])\n    num_1 = sequence_num[0]\n    for num in sequence_num[:-1]:\n        id_seq = np.vstack((id_seq, np.arange(num_1, num+num_1)))\n        num_1 += num\n    X_sequence = X[id_seq]\n    # \n    id_data = np.arange(len(id_seq))\n    np.random.seed(2022)\n    np.random.shuffle(id_data)\n    train_size = int(len(id_data)*(1-test_rate))\n    test_size = len(id_data) - train_size\n    X_train = X_sequence[id_data[:train_size]].reshape(-1, feature_size)\n    y_train = y[id_data[:train_size]]\n    X_test = X_sequence[id_data[train_size:]].reshape(-1, feature_size)\n    y_test = y[id_data[train_size:]]\n    sequence_num_train = sequence_num[id_data[:train_size]]\n    sequence_num_test = sequence_num[id_data[train_size:]]\n    return X_train, X_test, y_train, y_test, sequence_num_train, sequence_num_test\nX = train_df.values\ny = train_label_df.values\nX_train, X_test, y_train, y_test, sequence_num_train, sequence_num_test = train_test_split(X, y, sequence_num, test_rate)\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:29.007334Z","iopub.execute_input":"2022-04-11T14:42:29.007973Z","iopub.status.idle":"2022-04-11T14:42:52.437528Z","shell.execute_reply.started":"2022-04-11T14:42:29.007932Z","shell.execute_reply":"2022-04-11T14:42:52.436646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_size = 0.2\nX_train, X_valid, y_train, y_valid, sequence_num_train, sequence_num_valid = train_test_split(X_train, y_train, sequence_num_train, valid_size)\nprint(X_train.shape, X_valid.shape)\nprint(y_train.shape, y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:42:52.43877Z","iopub.execute_input":"2022-04-11T14:42:52.439067Z","iopub.status.idle":"2022-04-11T14:43:03.937Z","shell.execute_reply.started":"2022-04-11T14:42:52.439027Z","shell.execute_reply":"2022-04-11T14:43:03.936072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Standard scaler","metadata":{}},{"cell_type":"code","source":"stdsc = StandardScaler()\nprint(X_train[:, 0].reshape(-1, 1), stdsc.fit_transform(X_train[:, 1:]))\nX_train_std = np.hstack([X_train[:, 0].reshape(-1, 1), stdsc.fit_transform(X_train[:, 3:])])\nX_valid_std = np.hstack([X_valid[:, 0].reshape(-1, 1), stdsc.transform(X_valid[:, 3:])])\nX_test_std = np.hstack([X_test[:, 0].reshape(-1, 1), stdsc.transform(X_test[:, 3:])])\nprint(X_train_std.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:03.938271Z","iopub.execute_input":"2022-04-11T14:43:03.9385Z","iopub.status.idle":"2022-04-11T14:43:05.193628Z","shell.execute_reply.started":"2022-04-11T14:43:03.938472Z","shell.execute_reply":"2022-04-11T14:43:05.192693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create data sets and data loaders","metadata":{}},{"cell_type":"code","source":"# \nfrom torch.utils.data.sampler import SubsetRandomSampler\nclass MyDataset(torch.utils.data.Dataset):\n    def __init__(self, X, sequence_num, y=None, mode='train'):\n        self.data = X\n        self.teacher = y\n        self.sequence_num = sequence_num\n        self.mode = mode\n    def __len__(self):\n        return len(self.teacher)\n\n    def __getitem__(self, idx):\n        out_data = self.data[idx]\n        if self.mode == 'train':\n            out_label =  self.teacher[idx[0]//self.sequence_num]\n            return out_data, out_label\n        else:\n            return out_data\ndef create_dataset(dataset, dataset_num, sequence_num, input_size, batch_size, shuffle=False):\n    sampler = np.array([list(range(i*sequence_num, (i+1)*sequence_num)) for i in range(dataset_num//sequence_num)])\n    if shuffle == True:\n        np.random.shuffle(sampler)\n    dataloader = DataLoader(dataset, batch_size, sampler=sampler)\n    return dataloader\n# create dataloader\nbatch_size = 256\ndataset_train = MyDataset(X_train_std, sequence_num_train[0], y=y_train, mode='train')\ndataset_valid = MyDataset(X_valid_std, sequence_num_valid[0], y=y_valid, mode='train')\ndataset_test = MyDataset(X_test_std, sequence_num_test[0], y=y_test, mode='val')\ndataloader_train = create_dataset(dataset_train, X_train_std.shape[0], sequence_num_train[0], X_train_std.shape[1], batch_size=batch_size)\ndataloader_valid = create_dataset(dataset_valid, X_valid_std.shape[0], sequence_num_valid[0], X_valid_std.shape[1], batch_size=batch_size)\ndataloader_test = create_dataset(dataset_test, X_test_std.shape[0], sequence_num_test[0], X_test_std.shape[1], batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.194983Z","iopub.execute_input":"2022-04-11T14:43:05.195211Z","iopub.status.idle":"2022-04-11T14:43:05.576398Z","shell.execute_reply.started":"2022-04-11T14:43:05.195184Z","shell.execute_reply":"2022-04-11T14:43:05.575822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"class Net1(nn.Module):\n    def __init__(self, input_size, trial, num_layer, num_nodes, dropout_rate):\n        super(Net1, self).__init__()\n        self.activation = get_activation(trial)\n        # first layer\n        self.linears = nn.ModuleList([nn.Linear(input_size, num_nodes[0])])\n        # After 2nd layer\n        for i in range(1, num_layer):\n            self.linears.append(nn.Linear(num_nodes[i-1], num_nodes[i]))\n        # last layer\n        self.fc_last = nn.Linear(num_nodes[-1], 1)\n        self.dropout = nn.Dropout(dropout_rate)\n    def forward(self, x):\n        for i, linear in enumerate(self.linears):\n            x = self.activation(linear(x))\n            x = self.dropout(x)\n        x = self.fc_last(x)\n        return x\n\nclass Net2(nn.Module):\n    def __init__(self, input_size, trial, num_layer, num_nodes, dropout_rate):\n        super(Net2, self).__init__()\n        self.activation = get_activation(trial)\n        # first layer\n        self.linears = nn.ModuleList([nn.Linear(input_size, num_nodes[0])])\n        # After 2nd layer\n        for i in range(1, num_layer):\n            self.linears.append(nn.Linear(num_nodes[i-1], num_nodes[i]))\n        # last layer\n        self.fc_last = nn.Linear(num_nodes[-1], 1)\n        self.dropout = nn.Dropout(dropout_rate)\n    def forward(self, x):\n        for i, linear in enumerate(self.linears):\n            x = self.activation(linear(x))\n            x = self.dropout(x)\n        x = self.fc_last(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:01:15.970104Z","iopub.execute_input":"2022-04-11T14:01:15.970424Z","iopub.status.idle":"2022-04-11T14:01:15.984304Z","shell.execute_reply.started":"2022-04-11T14:01:15.970383Z","shell.execute_reply":"2022-04-11T14:01:15.98308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model1, model2, dataloader, optimizer1, optimizer2):\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    model1.train()\n    model2.train()\n    criterion = nn.MSELoss()\n    for data, target in dataloader:\n        data, target = data.to(torch.float32)[:, :, 1:], target.to(torch.float32)[:, 1]\n        # \n        data, target = data.to(device), target.to(device)\n        # \n        optimizer1.zero_grad()\n        optimizer2.zero_grad()\n        #\n        output1 = model1(data).view(-1, data.shape[1])\n        output2 = model2(output1)\n        # \n        loss = criterion(output2.view(-1, 1), target.view(-1, 1))\n        loss.backward()\n        optimizer1.step()\n        optimizer2.step()\ndef test(model1, model2, dataloader):\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    model1.eval()\n    model2.eval()\n    criterion = nn.MSELoss()\n    loss = 0\n    count = 0\n    with torch.no_grad():\n        for data, target in dataloader:\n            data, target = data.to(torch.float32)[:, :, 1:], target[:, 1]\n            data, target = data.to(device), target.to(device)\n            output1 = model1(data).view(-1, data.shape[1])\n            output2 = model2(output1)\n            loss += criterion(output2.view(-1, 1), target.view(-1, 1))\n            count += 1\n    loss /= count\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:01:15.986414Z","iopub.execute_input":"2022-04-11T14:01:15.987129Z","iopub.status.idle":"2022-04-11T14:01:16.003235Z","shell.execute_reply.started":"2022-04-11T14:01:15.986991Z","shell.execute_reply":"2022-04-11T14:01:16.002187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_optimizer(trial, model1, model2):\n    optimizer_names = ['MomentumSGD', 'Adam', 'Adagrad']\n    optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n    weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n    if optimizer_name == optimizer_names[0]: \n        momentum_sgd_lr = trial.suggest_loguniform('Momentum_SGD_lr', 1e-5, 1e-2)\n        optimizer1 = torch.optim.SGD(model1.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n        optimizer2 = torch.optim.SGD(model2.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n    elif optimizer_name == optimizer_names[1]:\n        adam_lr = trial.suggest_loguniform('Adam_lr', 1e-5, 1e-2)\n        optimizer1 = torch.optim.Adam(model1.parameters(), lr=adam_lr, weight_decay=weight_decay)\n        optimizer2 = torch.optim.Adam(model2.parameters(), lr=adam_lr, weight_decay=weight_decay)\n    elif optimizer_name == optimizer_names[2]:\n        adagrad_lr = trial.suggest_loguniform('Adagrad_lr', 1e-5, 1e-2)\n        optimizer1 = torch.optim.Adagrad(model1.parameters(), lr=adagrad_lr, weight_decay=weight_decay)\n        optimizer2 = torch.optim.Adagrad(model2.parameters(), lr=adagrad_lr, weight_decay=weight_decay)\n    return optimizer1, optimizer2\n\ndef loss_plot(logs_train, logs_test):\n    plt.plot(logs_train[0][1:], logs_train[1][1:], '-b', label='train')\n    plt.plot(logs_test[0][1:], logs_test[1][1:], '-r', label='test')\n    plt.xlabel('epoch', fontsize=15)\n    plt.ylabel('loss', fontsize=15)\n    plt.legend()\n#     plt.ylim(0, 100)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:01:16.005158Z","iopub.execute_input":"2022-04-11T14:01:16.005581Z","iopub.status.idle":"2022-04-11T14:01:16.02342Z","shell.execute_reply.started":"2022-04-11T14:01:16.005536Z","shell.execute_reply":"2022-04-11T14:01:16.022314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_activation(trial):\n    activation_names = ['ReLU', 'ELU', 'leaky_relu']\n    activation_name = trial.suggest_categorical('activation', activation_names)\n    if activation_name == activation_names[0]:\n        activation = F.relu\n    elif activation_name == activation_names[1]:\n        activation = F.elu\n    else:\n        activation = F.leaky_relu\n    return activation","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:01:16.025374Z","iopub.execute_input":"2022-04-11T14:01:16.025954Z","iopub.status.idle":"2022-04-11T14:01:16.038935Z","shell.execute_reply.started":"2022-04-11T14:01:16.025892Z","shell.execute_reply":"2022-04-11T14:01:16.037794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nbatch_size = 256\ndef objective(trial):\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    # 隠れ層の数\n    num_layer1 = trial.suggest_int('num_layer1', 2, 7)\n    num_layer2 = trial.suggest_int('num_layer2', 2, 7)\n    # 隠れ層のノード数\n    num_nodes1 = [int(trial.suggest_discrete_uniform('num_nodes_1_'+str(i), 16, 128, 16)) for i in range(num_layer1)]\n    num_nodes2 = [int(trial.suggest_discrete_uniform('num_nodes_2_'+str(i), 16, 128, 16)) for i in range(num_layer2)]\n    # dropout rate\n    dropout_rate1 =  trial.suggest_float('dropout_rate1', 0.0, 1.0)\n    dropout_rate2 =  trial.suggest_float('dropout_rate2', 0.0, 1.0)\n    # モデルのインスタンス化\n    model1 = Net1(dataloader_valid.dataset.data.shape[1]-1, trial, num_layer1, num_nodes1, dropout_rate1).to(device)\n    model2 = Net2(sequence_num[0], trial, num_layer2, num_nodes2, dropout_rate2).to(device)\n    optimizer1, optimizer2 = get_optimizer(trial, model1, model2)\n    error_rate = np.inf\n    for epoch in range(epochs):\n        train(model1, model2, dataloader_valid, optimizer1, optimizer2)\n    error_rate = test(model1, model2, dataloader_valid)\n    return error_rate","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:01:16.040478Z","iopub.execute_input":"2022-04-11T14:01:16.040873Z","iopub.status.idle":"2022-04-11T14:01:16.056229Z","shell.execute_reply.started":"2022-04-11T14:01:16.04083Z","shell.execute_reply":"2022-04-11T14:01:16.055175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n# TRIAL_SIZE = 100\n# study = optuna.create_study(study_name='aaa')\n# study.optimize(objective, n_trials=TRIAL_SIZE)\n# best_params = study.best_params\n# print(best_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.578562Z","iopub.execute_input":"2022-04-11T14:43:05.578961Z","iopub.status.idle":"2022-04-11T14:43:05.581891Z","shell.execute_reply.started":"2022-04-11T14:43:05.578905Z","shell.execute_reply":"2022-04-11T14:43:05.581373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from optuna.visualization import plot_optimization_history\n# plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.582913Z","iopub.execute_input":"2022-04-11T14:43:05.583253Z","iopub.status.idle":"2022-04-11T14:43:05.594151Z","shell.execute_reply.started":"2022-04-11T14:43:05.583214Z","shell.execute_reply":"2022-04-11T14:43:05.593584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = best_params\nparams = {'num_layer1': 7, 'num_layer2': 7, 'num_nodes_1_0': 128.0, 'num_nodes_1_1': 112.0, 'num_nodes_1_2': 128.0, 'num_nodes_1_3': 48.0, 'num_nodes_1_4': 64.0, 'num_nodes_1_5': 48.0, 'num_nodes_1_6': 128.0, 'num_nodes_2_0': 112.0, 'num_nodes_2_1': 128.0, 'num_nodes_2_2': 80.0, 'num_nodes_2_3': 128.0, 'num_nodes_2_4': 128.0, 'num_nodes_2_5': 128.0, 'num_nodes_2_6': 128.0, 'dropout_rate1': 0.2437830034858727, 'dropout_rate2': 0.017851001001991003, 'activation': 'ELU', 'optimizer': 'Adam', 'weight_decay': 3.66056306659787e-09, 'Adam_lr': 0.000670442196296899}","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.595218Z","iopub.execute_input":"2022-04-11T14:43:05.595564Z","iopub.status.idle":"2022-04-11T14:43:05.606047Z","shell.execute_reply.started":"2022-04-11T14:43:05.595523Z","shell.execute_reply":"2022-04-11T14:43:05.605449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training with tuned models","metadata":{}},{"cell_type":"code","source":"class Net1(nn.Module):\n    def __init__(self, input_size, num_layer, num_nodes, dropout_rate, activation_name):\n        super(Net1, self).__init__()\n        self.activation = get_activation(activation_name)\n        # first layer\n        self.linears = nn.ModuleList([nn.Linear(input_size, num_nodes[0])])\n        # After 2nd layer\n        for i in range(1, num_layer):\n            self.linears.append(nn.Linear(num_nodes[i-1], num_nodes[i]))\n        # last layer\n        self.fc_last = nn.Linear(num_nodes[-1], 1)\n        self.dropout = nn.Dropout(dropout_rate)\n    def forward(self, x):\n        for i, linear in enumerate(self.linears):\n            x = self.activation(linear(x))\n            x = self.dropout(x)\n        x = self.fc_last(x)\n        return x\n\nclass Net2(nn.Module):\n    def __init__(self, input_size, num_layer, num_nodes, dropout_rate, activation_name):\n        super(Net2, self).__init__()\n        self.activation = get_activation(activation_name)\n        # first layer\n        self.linears = nn.ModuleList([nn.Linear(input_size, num_nodes[0])])\n        # After 2nd layer\n        for i in range(1, num_layer):\n            self.linears.append(nn.Linear(num_nodes[i-1], num_nodes[i]))\n        # last layer\n        self.fc_last = nn.Linear(num_nodes[-1], 1)\n        self.dropout = nn.Dropout(dropout_rate)\n    def forward(self, x):\n        for i, linear in enumerate(self.linears):\n            x = self.activation(linear(x))\n            x = self.dropout(x)\n        x = self.fc_last(x)\n        return x\ndef get_activation(activation_name):\n    activation_names = ['ReLU', 'ELU', 'leaky_relu']\n    if activation_name == activation_names[0]:\n        activation = F.relu\n    elif activation_name == activation_names[1]:\n        activation = F.elu\n    else:\n        activation = F.leaky_relu\n    return activation","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.607136Z","iopub.execute_input":"2022-04-11T14:43:05.607358Z","iopub.status.idle":"2022-04-11T14:43:05.621735Z","shell.execute_reply.started":"2022-04-11T14:43:05.607331Z","shell.execute_reply":"2022-04-11T14:43:05.621047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model1, model2, dataloader, optimizer1, optimizer2):\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    model1.train()\n    model2.train()\n    criterion = nn.MSELoss()\n    epoch_loss = 0\n    iteration = 0\n    for data, target in dataloader:\n        data, target = data.to(torch.float32)[:, :, 1:], target.to(torch.float32)[:, 1]\n        # \n        data, target = data.to(device), target.to(device)\n        # \n        optimizer1.zero_grad()\n        optimizer2.zero_grad()\n        #\n        output1 = model1(data).view(-1, data.shape[1])\n        output2 = model2(output1)\n        # \n        loss = criterion(output2.view(-1, 1), target.view(-1, 1))\n        epoch_loss += loss.item()\n        loss.backward()\n        optimizer1.step()\n        optimizer2.step()\n        iteration += 1\n    epoch_loss /= iteration\n    return epoch_loss\n\ndef predict(model1, model2, dataloader):\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    model1.eval()\n    model2.eval()\n    y_pred = np.array([])\n    with torch.no_grad():\n        for data in dataloader:\n            data = data.to(torch.float32)[:, :, 1:]\n            data = data.to(device)\n            output1 = model1(data).view(-1, data.shape[1])\n            output2 = model2(output1)\n            y_pred = np.append(y_pred, output2.to('cpu'))\n    return y_pred\n\ndef get_optimizer(model1, model2, optimizer_name, lr, weight_decay):\n    optimizer_names = ['MomentumSGD', 'Adam', 'Adagrad']\n    if optimizer_name == optimizer_names[0]: \n        optimizer1 = torch.optim.SGD(model1.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n        optimizer2 = torch.optim.SGD(model2.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n    elif optimizer_name == optimizer_names[1]:\n        optimizer1 = torch.optim.Adam(model1.parameters(), lr=lr, weight_decay=weight_decay)\n        optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr, weight_decay=weight_decay)\n    elif optimizer_name == optimizer_names[2]:\n        optimizer1 = torch.optim.Adagrad(model1.parameters(), lr=lr, weight_decay=weight_decay)\n        optimizer2 = torch.optim.Adagrad(model2.parameters(), lr=lr, weight_decay=weight_decay)\n    return optimizer1, optimizer2\n\ndef loss_plot(logs_train, logs_test):\n    plt.plot(logs_train[0][1:], logs_train[1][1:], '-b', label='train')\n    plt.plot(logs_test[0][1:], logs_test[1][1:], '-r', label='test')\n    plt.xlabel('epoch', fontsize=15)\n    plt.ylabel('loss', fontsize=15)\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.623Z","iopub.execute_input":"2022-04-11T14:43:05.623417Z","iopub.status.idle":"2022-04-11T14:43:05.639736Z","shell.execute_reply.started":"2022-04-11T14:43:05.623378Z","shell.execute_reply":"2022-04-11T14:43:05.638987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nnum_epochs = 100\n# get parameter\nnum_layer1 = params['num_layer1']\nnum_layer2 = params['num_layer2']\nnum_nodes1 = [int(params[s]) for s in params.keys() if 'num_nodes_1_' in s]\nnum_nodes2 = [int(params[s]) for s in params.keys() if 'num_nodes_2_' in s]\ndropout_rate1 = params['dropout_rate1']\ndropout_rate2 = params['dropout_rate2']\nactivation_name = params['activation']\n# Model initialization\nmodel1 = Net1(dataloader_train.dataset.data.shape[1]-1, num_layer1, num_nodes1, dropout_rate1, activation_name)\nmodel2 = Net2(sequence_num[0], num_layer2, num_nodes2, dropout_rate2, activation_name)\nmodel1, model2 = model1.to(device), model2.to(device)\n# Define update method\noptimizer_name = params['optimizer']\nlr = params[optimizer_name+'_lr']\nweight_decay = params['weight_decay']\noptimizer1, optimizer2 = get_optimizer(model1, model2, optimizer_name, lr, weight_decay)\n# 学習\nlogs_train = [[0], [np.inf]]\nlogs_test = [[0], [np.inf]]\nfor epoch in tqdm(range(num_epochs)):\n    epoch_loss = train(model1, model2, dataloader_train, optimizer1, optimizer2)\n    test_pred = predict(model1, model2, dataloader_test)\n    test_loss = mean_squared_error(y_test[:, 1], test_pred)\n    if test_loss < min(logs_test[1]):\n        torch.save(model1.state_dict(), './model1')\n        torch.save(model2.state_dict(), './model2')\n    logs_train[0].append(epoch+1)\n    logs_train[1].append(epoch_loss)\n    logs_test[0].append(epoch+1)\n    logs_test[1].append(test_loss)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:43:05.640967Z","iopub.execute_input":"2022-04-11T14:43:05.641842Z","iopub.status.idle":"2022-04-11T14:54:51.771727Z","shell.execute_reply.started":"2022-04-11T14:43:05.641797Z","shell.execute_reply":"2022-04-11T14:54:51.770958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check learning curve","metadata":{}},{"cell_type":"code","source":"loss_plot(logs_train, logs_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:19.274026Z","iopub.execute_input":"2022-04-11T14:56:19.274353Z","iopub.status.idle":"2022-04-11T14:56:19.491802Z","shell.execute_reply.started":"2022-04-11T14:56:19.274319Z","shell.execute_reply":"2022-04-11T14:56:19.49085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_state_dict(torch.load('./model1'))\nmodel2.load_state_dict(torch.load('./model2'))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:23.802556Z","iopub.execute_input":"2022-04-11T14:56:23.803334Z","iopub.status.idle":"2022-04-11T14:56:23.814026Z","shell.execute_reply.started":"2022-04-11T14:56:23.803289Z","shell.execute_reply":"2022-04-11T14:56:23.813162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predict(model1, model2, dataloader_test)\nroc = roc_curve(y_test[:, 1], y_pred)\nprint(\"roc\", roc_auc_score(y_test[:, 1], y_pred))\nfpr, tpr, thresholds = roc\nplt.plot(fpr, tpr, marker='o')\nplt.xlabel('FPR: False positive rate')\nplt.ylabel('TPR: True positive rate')\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:25.063066Z","iopub.execute_input":"2022-04-11T14:56:25.06332Z","iopub.status.idle":"2022-04-11T14:56:25.87118Z","shell.execute_reply.started":"2022-04-11T14:56:25.063285Z","shell.execute_reply":"2022-04-11T14:56:25.870156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = MyDataset(X_train_std, sequence_num=sequence_num[0], mode='valid')\ndataloader_train = create_dataset(dataset_train, X_train_std.shape[0], sequence_num[0], X_train_std.shape[1], batch_size)\ny_pred_train = predict(model1, model2, dataloader_train)\nroc = roc_curve(y_train[:, 1], y_pred_train)\nprint(\"roc\", roc_auc_score(y_train[:, 1], y_pred_train))\nfpr, tpr, thresholds = roc\nplt.plot(fpr, tpr, marker='o')\nplt.xlabel('FPR: False positive rate')\nplt.ylabel('TPR: True positive rate')\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:29.054461Z","iopub.execute_input":"2022-04-11T14:56:29.054712Z","iopub.status.idle":"2022-04-11T14:56:31.312351Z","shell.execute_reply.started":"2022-04-11T14:56:29.054684Z","shell.execute_reply":"2022-04-11T14:56:31.311542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_submit = test_df.values\nX_submit_std = np.hstack([X_submit[:, 0].reshape(-1, 1), stdsc.transform(X_submit[:, 3:])])\ndataset_submit = MyDataset(X_submit_std, sequence_num=sequence_num[0], mode='valid')\ndataloader_submit = create_dataset(dataset_submit, X_submit_std.shape[0], sequence_num[0], X_submit_std.shape[1], batch_size)\ny_submit = predict(model1, model2, dataloader_submit)\nprint(y_submit.shape)\nplt.hist(y_submit, bins=30, density=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:38.01353Z","iopub.execute_input":"2022-04-11T14:56:38.014336Z","iopub.status.idle":"2022-04-11T14:56:40.252808Z","shell.execute_reply.started":"2022-04-11T14:56:38.014296Z","shell.execute_reply":"2022-04-11T14:56:40.251842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:40.254968Z","iopub.execute_input":"2022-04-11T14:56:40.255271Z","iopub.status.idle":"2022-04-11T14:56:40.276391Z","shell.execute_reply.started":"2022-04-11T14:56:40.25523Z","shell.execute_reply":"2022-04-11T14:56:40.275644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['state'] = pd.DataFrame(y_submit)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:40.277647Z","iopub.execute_input":"2022-04-11T14:56:40.277871Z","iopub.status.idle":"2022-04-11T14:56:40.286693Z","shell.execute_reply.started":"2022-04-11T14:56:40.277847Z","shell.execute_reply":"2022-04-11T14:56:40.286043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:56:40.402904Z","iopub.execute_input":"2022-04-11T14:56:40.403183Z","iopub.status.idle":"2022-04-11T14:56:40.438667Z","shell.execute_reply.started":"2022-04-11T14:56:40.403152Z","shell.execute_reply":"2022-04-11T14:56:40.437894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}