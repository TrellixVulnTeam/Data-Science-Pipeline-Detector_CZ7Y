{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom keras.preprocessing import sequence\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-09T22:05:39.322259Z","iopub.execute_input":"2022-04-09T22:05:39.322826Z","iopub.status.idle":"2022-04-09T22:05:39.329853Z","shell.execute_reply.started":"2022-04-09T22:05:39.322778Z","shell.execute_reply":"2022-04-09T22:05:39.328421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <h2> Given Data </h2> </center>\n\n***sequence*** -> a unique id for each sequence\n\n***subject*** -> a unique id for the subject in the experiment\n\n***step*** -> time step of the recording, in one second intervals\n\n***sensor_00 - sensor_12*** -> the value for each of the thirteen sensors at that time step.\n\n***What to do*** -> We are having 16 columns in train and test dataset with target column (state) in train_lables. We need to predict the state (train_label) for each sequence.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\n\nprint(f'Train', end='\\n')\nprint(f'Train shape is - {train.shape}')\ndisplay(train)\nprint(f'Test', end='\\n')\nprint(f'Test shape is - {test.shape}')\ndisplay(test.head())\nprint(f'Train_Labels', end='\\n')\nprint(f'Train label shape is - {train_labels.shape}')\ndisplay(train_labels.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:31:56.959981Z","iopub.execute_input":"2022-04-09T21:31:56.960805Z","iopub.status.idle":"2022-04-09T21:32:04.60108Z","shell.execute_reply.started":"2022-04-09T21:31:56.960751Z","shell.execute_reply":"2022-04-09T21:32:04.599919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <h2> Storyline/EDA </h2></center>\n\n***What are subjects and steps*** -> We are given the data of an experiment performed on almost 1000 (991 to be precise) experimental participants (subjects). The data collected from each subject is stored in the 13 sensors. For each subject, readings are taken for 1 min (60 sec) at every sec.\n\n***What is a sequence*** -> If only single experiments were taken for each subject then subjects would be equal to sequence. But, here each subjects have multiple experiments. Therefore, unique ID for each experiment is sequence and unique ID for each subject is subject.","metadata":{}},{"cell_type":"code","source":"# Almost 1000 subjects.\nlen(train['subject'].unique()) + len(test['subject'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:04.602773Z","iopub.execute_input":"2022-04-09T21:32:04.603005Z","iopub.status.idle":"2022-04-09T21:32:04.62603Z","shell.execute_reply.started":"2022-04-09T21:32:04.602977Z","shell.execute_reply":"2022-04-09T21:32:04.625351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Range of step, subject, \nprint(f'The step ranges from {train.step.min()} to {train.step.max()}')\nprint(f'The subject ranges from {train.subject.min()} to {train.subject.max()}')\nprint(f'The sequence ranges from {train.sequence.min()} to {train.sequence.max()}')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:04.627792Z","iopub.execute_input":"2022-04-09T21:32:04.628508Z","iopub.status.idle":"2022-04-09T21:32:04.654281Z","shell.execute_reply.started":"2022-04-09T21:32:04.62846Z","shell.execute_reply":"2022-04-09T21:32:04.652594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For each subject we are having multiple sequences.\ntrain[train['subject'] == 0]['sequence'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:04.656723Z","iopub.execute_input":"2022-04-09T21:32:04.657282Z","iopub.status.idle":"2022-04-09T21:32:04.670348Z","shell.execute_reply.started":"2022-04-09T21:32:04.657244Z","shell.execute_reply":"2022-04-09T21:32:04.669564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The number of rows given in train dataset is -> Number of sequences * Number of data points taken in each second for 1 min ----- {25968*60}')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:04.671675Z","iopub.execute_input":"2022-04-09T21:32:04.672764Z","iopub.status.idle":"2022-04-09T21:32:04.681078Z","shell.execute_reply.started":"2022-04-09T21:32:04.672716Z","shell.execute_reply":"2022-04-09T21:32:04.679502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**How many times a subject is repeating?**","metadata":{}},{"cell_type":"code","source":"train['subject'].value_counts().sort_values()/60","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:04.682701Z","iopub.execute_input":"2022-04-09T21:32:04.683017Z","iopub.status.idle":"2022-04-09T21:32:04.710222Z","shell.execute_reply.started":"2022-04-09T21:32:04.682974Z","shell.execute_reply":"2022-04-09T21:32:04.70941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sensors ->","metadata":{}},{"cell_type":"code","source":"list_sensor = train.columns[train.columns.str.contains('sensor')]\n\nplt.figure(figsize=(20, 10))\nfor i, value in enumerate(list_sensor):\n    plt.subplot(4,4,i+1)\n    sns.histplot(x=value, data=train, bins = 100, color='limegreen')\n    plt.title(value)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:04.711494Z","iopub.execute_input":"2022-04-09T21:32:04.712238Z","iopub.status.idle":"2022-04-09T21:32:12.171636Z","shell.execute_reply.started":"2022-04-09T21:32:04.712194Z","shell.execute_reply":"2022-04-09T21:32:12.170614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[list_sensor].describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:12.173241Z","iopub.execute_input":"2022-04-09T21:32:12.173842Z","iopub.status.idle":"2022-04-09T21:32:13.088571Z","shell.execute_reply.started":"2022-04-09T21:32:12.173793Z","shell.execute_reply":"2022-04-09T21:32:13.087175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations -**\n\n1. It seems like all the sensors have a central tendency of zero, except sensor 2, which differs slightly.\n2. Sensor 2 performs very differently from others, also it looks like it has larger variance than others. It might be possible that sensor 2 is collecting the data which is important for the model.","metadata":{}},{"cell_type":"markdown","source":"### Correlations ->","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 8))\nsns.heatmap(train.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:13.090504Z","iopub.execute_input":"2022-04-09T21:32:13.090898Z","iopub.status.idle":"2022-04-09T21:32:16.117004Z","shell.execute_reply.started":"2022-04-09T21:32:13.090854Z","shell.execute_reply":"2022-04-09T21:32:16.116066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Observations -** \n1. High correlation is not found between any sensors.\n2. Moderate correlation is found between:\n\n    a. (sensor_00, sensor_06), (sensor_00, sensor_09)\n    \n    b. (sensor_03, sensor_07), (sensor_03, sensor_11)","metadata":{}},{"cell_type":"markdown","source":"### Outlier Treatment ->","metadata":{}},{"cell_type":"code","source":"list_sensor = train.columns[train.columns.str.contains('sensor')]\n\nplt.figure(figsize=(20, 10))\nfor i, value in enumerate(list_sensor):\n    plt.subplot(4,4,i+1)\n    sns.boxplot(x=value, data=train, color='limegreen')\n    plt.title(value)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:16.120893Z","iopub.execute_input":"2022-04-09T21:32:16.121442Z","iopub.status.idle":"2022-04-09T21:32:27.109075Z","shell.execute_reply.started":"2022-04-09T21:32:16.121396Z","shell.execute_reply":"2022-04-09T21:32:27.107915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q1 = train.quantile(0.0045)\nQ3 = train.quantile(0.9955)\nIQR = Q3-Q1\nprint(IQR)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:27.110358Z","iopub.execute_input":"2022-04-09T21:32:27.110679Z","iopub.status.idle":"2022-04-09T21:32:28.019557Z","shell.execute_reply.started":"2022-04-09T21:32:27.110637Z","shell.execute_reply":"2022-04-09T21:32:28.018168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out = train[~((train < (Q1 - 1.5 * IQR)) |(train > (Q3 + 1.5 * IQR))).any(axis=1)]\ntrain_out","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:28.020988Z","iopub.execute_input":"2022-04-09T21:32:28.021346Z","iopub.status.idle":"2022-04-09T21:32:28.22352Z","shell.execute_reply.started":"2022-04-09T21:32:28.021303Z","shell.execute_reply":"2022-04-09T21:32:28.222305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation -**\n\nOutlier Treatment - InterQuantileRange\n1. Removing outlier decreased our train size significantly (1558080 -> 515505). \n2. The outliers can also carry important information regarding the data. So, whether we should remove outliers or not is very sensitive and depends largely on the domain knowledge.\n3. Though for EDA, I have plot the data after outlier treatment below, which shows perfect normal distribution for every sensor.\n\nUpdate - \n1. The number of sequence decreased from (25967 -> 22007) when we take outliers in inter quantile range (25% - 75%).\n2. We should try decreasing threshold value for handling outliers.\n3. New weights updated above.","metadata":{}},{"cell_type":"code","source":"list_sensor = train_out.columns[train_out.columns.str.contains('sensor')]\n\nplt.figure(figsize=(20, 10))\nfor i, value in enumerate(list_sensor):\n    plt.subplot(4,4,i+1)\n    sns.histplot(x=value, data=train_out, color='limegreen')\n    plt.title(value)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:32:28.225008Z","iopub.execute_input":"2022-04-09T21:32:28.225242Z","iopub.status.idle":"2022-04-09T21:36:16.496083Z","shell.execute_reply.started":"2022-04-09T21:32:28.225215Z","shell.execute_reply":"2022-04-09T21:36:16.495346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:16.497467Z","iopub.execute_input":"2022-04-09T21:36:16.498317Z","iopub.status.idle":"2022-04-09T21:36:17.468903Z","shell.execute_reply.started":"2022-04-09T21:36:16.498269Z","shell.execute_reply":"2022-04-09T21:36:17.467824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**\n\nAlmost every sensor contained outliers. Our data is converted to perfect normal distribution. However when we do model building we should try it with both data.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 8))\nsns.heatmap(train_out.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:17.470085Z","iopub.execute_input":"2022-04-09T21:36:17.470832Z","iopub.status.idle":"2022-04-09T21:36:20.406019Z","shell.execute_reply.started":"2022-04-09T21:36:17.470794Z","shell.execute_reply":"2022-04-09T21:36:20.405154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observation -\n1. Strong Correlation - (sensor_00,sensor_06), (sensor_03,sensor_07)\n2. Moderate Correlation - (sensor_00,sensor_07),  (sensor_00,sensor_09), (sensor_01,sensor_06), (sensor_01,sensor_11), (sensor_03,sensor_11), (sensor_03,sensor_06), (sensor_06,sensor_09)","metadata":{}},{"cell_type":"code","source":"train_out","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:20.407371Z","iopub.execute_input":"2022-04-09T21:36:20.40837Z","iopub.status.idle":"2022-04-09T21:36:20.435363Z","shell.execute_reply.started":"2022-04-09T21:36:20.408305Z","shell.execute_reply":"2022-04-09T21:36:20.434418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['sequence'].shape)\nprint(train_out['sequence'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:20.437456Z","iopub.execute_input":"2022-04-09T21:36:20.437726Z","iopub.status.idle":"2022-04-09T21:36:20.445585Z","shell.execute_reply.started":"2022-04-09T21:36:20.437697Z","shell.execute_reply":"2022-04-09T21:36:20.444615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['sequence'].nunique())\nprint(train_out['sequence'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:20.446606Z","iopub.execute_input":"2022-04-09T21:36:20.446828Z","iopub.status.idle":"2022-04-09T21:36:20.483964Z","shell.execute_reply.started":"2022-04-09T21:36:20.446793Z","shell.execute_reply":"2022-04-09T21:36:20.482987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_subject = train_out.groupby(['sequence'])['subject'] \\\n         .agg(['count']).reset_index() \\\n         .rename(columns = {'count':'subject_count'})","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:20.485226Z","iopub.execute_input":"2022-04-09T21:36:20.485457Z","iopub.status.idle":"2022-04-09T21:36:20.525012Z","shell.execute_reply.started":"2022-04-09T21:36:20.485428Z","shell.execute_reply":"2022-04-09T21:36:20.524302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out = train_out.groupby(['sequence']).sum().drop(['subject', 'step'], axis=1).reset_index()\ntrain_out = train_out.merge(count_subject, on=['sequence'], how='left')\ntrain_out = train_out.merge(train_labels, on=['sequence'], how='left')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:36:20.525991Z","iopub.execute_input":"2022-04-09T21:36:20.526452Z","iopub.status.idle":"2022-04-09T21:36:20.693273Z","shell.execute_reply.started":"2022-04-09T21:36:20.526418Z","shell.execute_reply":"2022-04-09T21:36:20.692533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_out","metadata":{"execution":{"iopub.status.busy":"2022-04-09T21:45:04.244506Z","iopub.execute_input":"2022-04-09T21:45:04.244868Z","iopub.status.idle":"2022-04-09T21:45:04.273354Z","shell.execute_reply.started":"2022-04-09T21:45:04.244835Z","shell.execute_reply":"2022-04-09T21:45:04.272365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_out.iloc[: , 1:-1]\ny = train_out['state']","metadata":{"execution":{"iopub.status.busy":"2022-04-09T22:04:56.39287Z","iopub.execute_input":"2022-04-09T22:04:56.393212Z","iopub.status.idle":"2022-04-09T22:04:56.40051Z","shell.execute_reply.started":"2022-04-09T22:04:56.393169Z","shell.execute_reply":"2022-04-09T22:04:56.399086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <h3>I will be updating this notebook soon. In the meanwhile, if you found this notebook helpful, please do upvote.</center> </h3>","metadata":{}},{"cell_type":"code","source":"# epochs= 20\n# batch_size= 10\n# time_steps= \n# features=  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kf = KFold(n_splits=10)\n# auc = []\n# test_preds = []\n# for fold, (train_idx, test_idx) in enumerate(kf.split(train, y):\n#     print(f\"** fold: {fold+1} ** ........training ...... \\n\")\n#     X_train, X_valid = train[train_idx], train[test_idx]\n#     y_train, y_valid = y[train_idx], y[test_idx]\n    \n#     model = Sequential()\n#     model.add(LSTM(100, dropout=0.2, input_shape = ()))\n#     history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=30, batch_size = 64, callbacks = [es,lr],verbose = False)\n    \n#     y_pred = model.predict(X_valid).squeeze()\n#     auc.append(roc_auc_score(y_valid, y_pred))\n#     print(f\"auc: {auc[fold]} \\n\")\n#     test_preds.append(model.predict(test).squeeze())\n#     plotHist(history)\n#     del X_train, X_valid, y_train, y_valid, model, history\n#     gc.collect()  ","metadata":{},"execution_count":null,"outputs":[]}]}