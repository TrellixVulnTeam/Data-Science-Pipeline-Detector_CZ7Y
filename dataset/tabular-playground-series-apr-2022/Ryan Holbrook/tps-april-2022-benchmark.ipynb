{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome to the Tabular Playground Series April 2022! #","metadata":{}},{"cell_type":"markdown","source":"This notebook outlines a way of applying traditional machine learning algorithms to time series classification problems by generating a set of features for each series with the `tsfresh` library, adapted from [this tutorial](https://tsfresh.readthedocs.io/en/latest/text/sklearn_transformers.html). There are many algorithms specific to this task, however, some of which you can read about on this [Time Series Classification](https://www.timeseriesclassification.com/algorithm.php) website.","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom IPython import get_ipython\n\nwarnings.filterwarnings('ignore')\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    titlesize=18,\n    titleweight=\"bold\",\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nget_ipython().config.InlineBackend.figure_format = 'retina'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-09T20:18:11.358494Z","iopub.execute_input":"2022-03-09T20:18:11.358858Z","iopub.status.idle":"2022-03-09T20:18:11.453966Z","shell.execute_reply.started":"2022-03-09T20:18:11.358762Z","shell.execute_reply":"2022-03-09T20:18:11.452887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data #","metadata":{}},{"cell_type":"code","source":"data_dir = Path('../input/tabular-playground-series-apr-2022')\ndf_train = pd.read_csv(data_dir / 'train.csv', index_col=['sequence', 'subject', 'step'])\nlabels_train = pd.read_csv(data_dir / 'train_labels.csv', index_col='sequence').squeeze()\n\ndisplay(df_train)\ndisplay(labels_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T20:18:11.456088Z","iopub.execute_input":"2022-03-09T20:18:11.456421Z","iopub.status.idle":"2022-03-09T20:18:21.013174Z","shell.execute_reply.started":"2022-03-09T20:18:11.45637Z","shell.execute_reply":"2022-03-09T20:18:21.012105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at sequence of sensor data.","metadata":{}},{"cell_type":"code","source":"SEQ = 0\ndf_train.loc[SEQ].plot(subplots=True, sharex=True, figsize=(18, 1.5*13));","metadata":{"execution":{"iopub.status.busy":"2022-03-09T20:18:21.014765Z","iopub.execute_input":"2022-03-09T20:18:21.015462Z","iopub.status.idle":"2022-03-09T20:18:23.517983Z","shell.execute_reply.started":"2022-03-09T20:18:21.015388Z","shell.execute_reply":"2022-03-09T20:18:23.516946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train #","metadata":{}},{"cell_type":"code","source":"def score(model, X_test, y_test, X_train=None, y_train=None, fitted=True):\n    from sklearn import metrics\n\n    if not fitted:\n        model.fit(X_train, y_train)\n    y_pred = model.predict_proba(X_test)[:, 1]\n\n    print('Acc\\t', metrics.accuracy_score(y_test, y_pred.round()))\n    print('AUC:\\t', metrics.roc_auc_score(y_test, y_pred))\n    print('AP:\\t', metrics.average_precision_score(y_test, y_pred))\n    print('Rec:\\t', metrics.recall_score(y_test, y_pred.round()))\n    print('Prec:\\t', metrics.precision_score(y_test, y_pred.round()))\n    print('F1:\\t', metrics.f1_score(y_test, y_pred.round()))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T20:18:23.520262Z","iopub.execute_input":"2022-03-09T20:18:23.521092Z","iopub.status.idle":"2022-03-09T20:18:23.53218Z","shell.execute_reply.started":"2022-03-09T20:18:23.521025Z","shell.execute_reply":"2022-03-09T20:18:23.530854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\n\nN_SEQS = 12000  # Only use a subset of the sequences for the sake of time\nTEST_SIZE = 0.2\n\nsequences, subjects = (\n    df_train\n    .reset_index()\n    .loc[:, ['sequence', 'subject']]\n    .drop_duplicates()\n    .to_numpy()\n    [:N_SEQS]\n    .T\n)\n\nsplitter = GroupShuffleSplit(test_size=TEST_SIZE, n_splits=1, random_state = 0)\nseq_train, seq_valid = next(splitter.split(sequences, groups=subjects))\n\nX_train, X_valid = df_train.loc[seq_train], df_train.loc[seq_valid]\ny_train, y_valid = labels_train.loc[seq_train], labels_train.loc[seq_valid]\n\ndisplay(X_train)\ndisplay(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T20:18:23.53386Z","iopub.execute_input":"2022-03-09T20:18:23.534113Z","iopub.status.idle":"2022-03-09T20:18:24.731098Z","shell.execute_reply.started":"2022-03-09T20:18:23.534083Z","shell.execute_reply":"2022-03-09T20:18:24.729996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom tsfresh.transformers import RelevantFeatureAugmenter\n\n# Format time series for tsfresh pipeline \nN_SENSORS = 2  # And only use a couple of the sensor readings\nfeatures = [f'sensor_{k:02d}' for k in range(N_SENSORS)]\nX_train = X_train.reset_index().loc[:, ['sequence', 'step'] + features]\nX_valid = X_valid.reset_index().loc[:, ['sequence', 'step'] + features]\n\n# Extra (non-time series) features go here.\n# There are none, so we'll create dummy frames to satisfy the arguments of the fit/predict methods.\nXtra_train = pd.DataFrame(np.zeros_like(y_train), index=y_train.index)\nXtra_valid = pd.DataFrame(np.zeros_like(y_valid), index=y_valid.index)\n\nmodel = Pipeline([\n    ('augmenter', RelevantFeatureAugmenter(column_id='sequence', column_sort='step')),\n    ('rf', RandomForestClassifier(n_jobs=-1)),\n])\nmodel.set_params(augmenter__timeseries_container=X_train)\nmodel.fit(Xtra_train, y_train)\n\nmodel.set_params(augmenter__timeseries_container=X_valid)\nscore(model, Xtra_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T20:18:24.73237Z","iopub.execute_input":"2022-03-09T20:18:24.732602Z","iopub.status.idle":"2022-03-09T20:20:56.803643Z","shell.execute_reply.started":"2022-03-09T20:18:24.732553Z","shell.execute_reply":"2022-03-09T20:20:56.802109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer #","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(data_dir / 'test.csv', index_col=['sequence', 'subject', 'step'])\nsample_submission = pd.read_csv(data_dir / 'sample_submission.csv', index_col=['sequence'])\n\nX_test = df_test.reset_index().loc[:, ['sequence', 'step'] + features]\nXtra_test = pd.DataFrame(np.zeros_like(sample_submission), index=sample_submission.index)\n\nmodel.set_params(augmenter__timeseries_container=X_test)\nsample_submission['state'] = model.predict_proba(Xtra_test)[:, 1]\n\nsample_submission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T20:20:56.806447Z","iopub.execute_input":"2022-03-09T20:20:56.806756Z","iopub.status.idle":"2022-03-09T20:21:30.42775Z","shell.execute_reply.started":"2022-03-09T20:20:56.806715Z","shell.execute_reply":"2022-03-09T20:21:30.364184Z"},"trusted":true},"execution_count":null,"outputs":[]}]}