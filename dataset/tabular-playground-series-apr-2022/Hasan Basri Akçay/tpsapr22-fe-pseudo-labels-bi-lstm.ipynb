{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! :)\n\nEDA was done in this [notebook](https://www.kaggle.com/code/hasanbasriakcay/tpsapr22-eda-fe-baseline)</br>\nPseudo Labeling was done in this [notebook](https://www.kaggle.com/code/hasanbasriakcay/tpsapr22-fe-pseudo-labels-baseline)</br>\nPrediction without NN is in this [notebook](https://www.kaggle.com/code/hasanbasriakcay/tpsapr22-optuna-lgbm-blend)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings \n\nwarnings.simplefilter(\"ignore\")\ntrain = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-apr-2022/test.csv\")\ntest_pseudo = pd.read_csv(\"../input/tpsapr22-pseudo-labels/pseudo_labeled_test.csv\")\ntrain_labels = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train_labels.csv\")\nsub = pd.read_csv(\"../input/tabular-playground-series-apr-2022/sample_submission.csv\")\n\ndisplay(train.head())\ndisplay(test.head())\ndisplay(train_labels.head())\ndisplay(sub.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:01:55.68082Z","iopub.execute_input":"2022-04-08T01:01:55.681195Z","iopub.status.idle":"2022-04-08T01:02:08.498954Z","shell.execute_reply.started":"2022-04-08T01:01:55.681105Z","shell.execute_reply":"2022-04-08T01:02:08.498149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"th = 0.95\ntest_pseudo_selected = test_pseudo.loc[((test_pseudo['state_proba']>=th) | (test_pseudo['state_proba']<=(1 - th))), \n                                      ['sequence', 'state_proba']]\ntest_pseudo_selected.columns = ['sequence', 'state']\ntest_pseudo_selected['state'] = test_pseudo_selected['state'].round()\ntest_pseudo_selected.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:08.501757Z","iopub.execute_input":"2022-04-08T01:02:08.502227Z","iopub.status.idle":"2022-04-08T01:02:08.526285Z","shell.execute_reply.started":"2022-04-08T01:02:08.502189Z","shell.execute_reply":"2022-04-08T01:02:08.525032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def create_new_features(df):\n    df['sensor_02_num'] = df['sensor_02'] > -15\n    df['sensor_02_num'] = df['sensor_02_num'].astype(int)\n    df['sensor_sum1'] = (df['sensor_00'] + df['sensor_09'] + df['sensor_06'] + df['sensor_01'])\n    df['sensor_sum2'] = (df['sensor_01'] + df['sensor_11'] + df['sensor_09'] + df['sensor_06'] + df['sensor_00'])\n    df['sensor_sum3'] = (df['sensor_03'] + df['sensor_11'] + df['sensor_07'])\n    df['sensor_sum4'] = (df['sensor_04'] + df['sensor_10'])\n    \n    sensors = ['sensor_'+'%02d'%i for i in range(0, 13)]\n    sensors.extend(['sensor_02_num', 'sensor_sum1', 'sensor_sum2', 'sensor_sum3', 'sensor_sum4'])\n    \n    for sensor in sensors:\n        df[sensor + '_lag1'] = df.groupby('sequence')[sensor].shift(1)\n        df.fillna(0, inplace=True)\n        df[sensor + '_diff1'] = df[sensor] - df[sensor + '_lag1'] \n    \n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-08T01:02:08.527626Z","iopub.execute_input":"2022-04-08T01:02:08.527882Z","iopub.status.idle":"2022-04-08T01:02:08.536927Z","shell.execute_reply.started":"2022-04-08T01:02:08.527847Z","shell.execute_reply":"2022-04-08T01:02:08.536202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = create_new_features(train)\ntest = create_new_features(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:08.539275Z","iopub.execute_input":"2022-04-08T01:02:08.539818Z","iopub.status.idle":"2022-04-08T01:02:20.120158Z","shell.execute_reply.started":"2022-04-08T01:02:08.539653Z","shell.execute_reply":"2022-04-08T01:02:20.119293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_test = test.loc[test['sequence'].isin(test_pseudo_selected['sequence']), :].copy()\nselected_test = selected_test.merge(test_pseudo_selected[['sequence', 'state']], on='sequence', how='left')\nselected_test.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:20.121429Z","iopub.execute_input":"2022-04-08T01:02:20.121696Z","iopub.status.idle":"2022-04-08T01:02:20.487503Z","shell.execute_reply.started":"2022-04-08T01:02:20.121663Z","shell.execute_reply":"2022-04-08T01:02:20.486773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(train, train_labels, how='left', on=\"sequence\")\ntrain = pd.concat([train, selected_test])\ngroups = train['sequence']","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:20.488616Z","iopub.execute_input":"2022-04-08T01:02:20.488874Z","iopub.status.idle":"2022-04-08T01:02:21.610702Z","shell.execute_reply.started":"2022-04-08T01:02:20.48883Z","shell.execute_reply":"2022-04-08T01:02:21.609991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Window = 60\ny = train['state'].to_numpy().reshape(-1, Window)\ntrain.drop([\"sequence\",\"step\",\"subject\",\"state\"], axis=1, inplace=True)\ntest.drop([\"sequence\",\"step\",\"subject\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:21.611791Z","iopub.execute_input":"2022-04-08T01:02:21.61203Z","iopub.status.idle":"2022-04-08T01:02:22.485344Z","shell.execute_reply.started":"2022-04-08T01:02:21.611996Z","shell.execute_reply":"2022-04-08T01:02:22.484561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nsc.fit(train)\nX_train = sc.transform(train)\nX_test = sc.transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:22.48981Z","iopub.execute_input":"2022-04-08T01:02:22.49178Z","iopub.status.idle":"2022-04-08T01:02:25.288156Z","shell.execute_reply.started":"2022-04-08T01:02:22.49174Z","shell.execute_reply":"2022-04-08T01:02:25.287423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape(-1, Window, X_train.shape[-1])\nX_test = X_test.reshape(-1, Window, X_test.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:25.289314Z","iopub.execute_input":"2022-04-08T01:02:25.289576Z","iopub.status.idle":"2022-04-08T01:02:25.29443Z","shell.execute_reply.started":"2022-04-08T01:02:25.289541Z","shell.execute_reply":"2022-04-08T01:02:25.293808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape, X_train.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:25.295516Z","iopub.execute_input":"2022-04-08T01:02:25.296107Z","iopub.status.idle":"2022-04-08T01:02:25.309616Z","shell.execute_reply.started":"2022-04-08T01:02:25.296071Z","shell.execute_reply":"2022-04-08T01:02:25.30882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:25.312952Z","iopub.execute_input":"2022-04-08T01:02:25.313156Z","iopub.status.idle":"2022-04-08T01:02:25.321212Z","shell.execute_reply.started":"2022-04-08T01:02:25.313132Z","shell.execute_reply":"2022-04-08T01:02:25.320524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_train = y[:, 0:2]\n#y_train[:, 0] = np.logical_not(y_train[:, 0]).astype(int)\n#y_train","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:25.323749Z","iopub.execute_input":"2022-04-08T01:02:25.324206Z","iopub.status.idle":"2022-04-08T01:02:25.327745Z","shell.execute_reply.started":"2022-04-08T01:02:25.324164Z","shell.execute_reply":"2022-04-08T01:02:25.326815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.metrics import AUC\n\ndef get_model():\n    input_layer = Input(shape=(X_train.shape[-2:]))\n    x1 = Bidirectional(LSTM(768, return_sequences=True))(input_layer)\n        \n    x21 = Bidirectional(LSTM(512, return_sequences=True))(x1)\n    x22 = Bidirectional(LSTM(512, return_sequences=True))(input_layer)\n    l2 = Concatenate(axis=2)([x21, x22])\n        \n    x31 = Bidirectional(LSTM(384, return_sequences=True))(l2)\n    x32 = Bidirectional(LSTM(384, return_sequences=True))(x21)\n    l3 = Concatenate(axis=2)([x31, x32])\n        \n    x41 = Bidirectional(LSTM(256, return_sequences=True))(l3)\n    x42 = Bidirectional(LSTM(128, return_sequences=True))(x32)\n    l4 = Concatenate(axis=2)([x41, x42])\n        \n    l5 = Concatenate(axis=2)([x1, l2, l3, l4])\n    x7 = Dense(128, activation='selu')(l5)\n    x8 = Dropout(0.3)(x7)\n    output_layer = Dense(units=1, activation=\"sigmoid\")(x8)\n    model = Model(inputs=input_layer, outputs=output_layer, name='DNN_Model')\n    model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[AUC(name = 'auc')])\n    \n    return model","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-08T01:02:25.329193Z","iopub.execute_input":"2022-04-08T01:02:25.32946Z","iopub.status.idle":"2022-04-08T01:02:30.624377Z","shell.execute_reply.started":"2022-04-08T01:02:25.329424Z","shell.execute_reply":"2022-04-08T01:02:30.623637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:30.625666Z","iopub.execute_input":"2022-04-08T01:02:30.625935Z","iopub.status.idle":"2022-04-08T01:02:37.863641Z","shell.execute_reply.started":"2022-04-08T01:02:30.625903Z","shell.execute_reply":"2022-04-08T01:02:37.862638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:37.866391Z","iopub.execute_input":"2022-04-08T01:02:37.866988Z","iopub.status.idle":"2022-04-08T01:02:38.720015Z","shell.execute_reply.started":"2022-04-08T01:02:37.866942Z","shell.execute_reply":"2022-04-08T01:02:38.719185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_hist(hist, metric='auc', ax=None, fold=0):\n    if ax==None:\n        plt.plot(hist.history[metric])\n        plt.plot(hist.history[\"val_\" + metric])\n        plt.title(f\"model performance fold {fold}\")\n        plt.ylabel(\"area_under_curve\")\n        plt.xlabel(\"epoch\")\n        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n        plt.show()\n        return\n    else:\n        ax.plot(hist.history[metric])\n        ax.plot(hist.history[\"val_\" + metric])\n        ax.set_title(f\"model performance fold {fold}\")\n        ax.set_ylabel(\"area_under_curve\")\n        ax.set_xlabel(\"epoch\")\n        ax.legend([\"train\", \"validation\"], loc=\"upper left\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-08T01:02:38.721375Z","iopub.execute_input":"2022-04-08T01:02:38.722004Z","iopub.status.idle":"2022-04-08T01:02:38.73148Z","shell.execute_reply.started":"2022-04-08T01:02:38.721955Z","shell.execute_reply":"2022-04-08T01:02:38.73034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score\nimport gc\n\ntest_preds = []\nauc = []\nnfold = 10\nncols = 5\nnrows = round(nfold / ncols)\nfig, axes = plt.subplots(nrows, ncols, figsize=(16, round(nrows*16/ncols)))\n\ncol, row = 0, 0\nkf = GroupKFold(n_splits=nfold)\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X_train, y_train, groups.unique())):\n    print(f\"Fold: {fold+1}\", end=' ')\n    X_train_part, X_valid = X_train[train_idx], X_train[test_idx]\n    y_train_part, y_valid = y_train[train_idx], y_train[test_idx]\n    \n    model = get_model()\n    lr = ReduceLROnPlateau(monitor=\"val_auc\", mode='max', factor=0.7, patience=4, verbose=False)\n    es = EarlyStopping(monitor='val_auc',mode='max', patience=10, verbose=False,restore_best_weights=True)\n    history = model.fit(X_train_part, y_train_part, validation_data=(X_valid, y_valid), epochs=30, batch_size=64, \n                        callbacks=[es,lr], verbose=False)\n    \n    y_pred = model.predict(X_valid).squeeze()\n    auc_score = roc_auc_score(y_valid, y_pred)\n    print(f'auc: {round(auc_score, 5)}')\n    test_preds.append(model.predict(X_test).squeeze())\n    auc.append(auc_score)\n    \n    plot_hist(history, metric='auc', ax=axes[row][col], fold=fold+1)\n    del X_train_part, X_valid, y_train_part, y_valid, model, history\n    gc.collect()\n    \n    col += 1\n    if col >= ncols:\n        row += 1\n        col = 0","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:02:38.733124Z","iopub.execute_input":"2022-04-08T01:02:38.73371Z","iopub.status.idle":"2022-04-08T01:30:13.905937Z","shell.execute_reply.started":"2022-04-08T01:02:38.733672Z","shell.execute_reply":"2022-04-08T01:30:13.904942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"the mean AUC for the {kf.n_splits} folds is : {round(np.mean(auc)*100,3)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_data = pd.read_csv(\"../input/tps-apr-2022-ensemble-solution/submission.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['state'] = sum(test_preds)/kf.n_splits \nsub['state'] = (sub['state'] * 0.35) + (sub_data['state'] * 0.65)\nsub.to_csv('submission.csv', index=False)\nsub  ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T01:30:13.906966Z","iopub.status.idle":"2022-04-08T01:30:13.908836Z","shell.execute_reply.started":"2022-04-08T01:30:13.908575Z","shell.execute_reply":"2022-04-08T01:30:13.908602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Referances:\n1. [notebook](https://www.kaggle.com/code/hamzaghanmi/tps-april-tensorflow-bi-lstm)\n2. [notebook](https://www.kaggle.com/code/cbeaud/tps-apr-2022-ensemble-solution/notebook)","metadata":{}}]}