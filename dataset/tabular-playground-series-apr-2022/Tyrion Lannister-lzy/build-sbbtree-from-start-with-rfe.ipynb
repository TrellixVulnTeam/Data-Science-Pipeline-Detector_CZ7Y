{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello Kagglers, in this Notebook I will try to Build a SBBTree and do faeature selection with RFE.\n\nHope to gain experience in writing this..\n\n> If this notebook is useful to you, please DO UPVOTE ðŸ—³","metadata":{}},{"cell_type":"markdown","source":"<h2>Competition Goal</h2>\n\nWith  the provided thousands of sixty-second sequences of sensor data recorded from several hundred participants who could have been in either of two possible activity states. \n\ndetermine what state a participant was in from the sensor data.","metadata":{}},{"cell_type":"markdown","source":"<h1>Importing Libraries</h1>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:31.99531Z","iopub.execute_input":"2022-04-25T05:35:31.99587Z","iopub.status.idle":"2022-04-25T05:35:34.656363Z","shell.execute_reply.started":"2022-04-25T05:35:31.995744Z","shell.execute_reply":"2022-04-25T05:35:34.655135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Loading Data</h2>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\nsubmission = pd.read_csv(\"../input/tabular-playground-series-apr-2022/sample_submission.csv\")\nlabels = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train_labels.csv\")\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:34.658762Z","iopub.execute_input":"2022-04-25T05:35:34.65913Z","iopub.status.idle":"2022-04-25T05:35:48.357222Z","shell.execute_reply.started":"2022-04-25T05:35:34.659081Z","shell.execute_reply":"2022-04-25T05:35:48.35609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Description from kaggle \n\ntrain.csv \n\n*  sequence - a unique id for each sequence\n\n* subject - a unique id for the subject in the experiment\n\n* step - time step of the recording, in one second intervals\n\n* sensor_00 - sensor_12 - the value for each of the thirteen sensors at that time step\n\n* state - the value for each of the thirteen sensors at that time step ##\n\n\ntrain_labels.csv - the class label for each sequence.\n\n* sequence - the unique id for each sequence.\n\n* state - the state associated to each sequence. This is the target which you are trying to predict.\n\n\ntest.csv - the test set. For each of the ~12,000 sequences, you should predict a value for that sequence's state.","metadata":{}},{"cell_type":"code","source":"# give you an quike insght into the train data \n# including count,mean,std,min,25%,50%,75% and max value\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:48.359171Z","iopub.execute_input":"2022-04-25T05:35:48.359518Z","iopub.status.idle":"2022-04-25T05:35:49.606512Z","shell.execute_reply.started":"2022-04-25T05:35:48.359472Z","shell.execute_reply":"2022-04-25T05:35:49.605191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run the code below to check if missing data exits\ntrain.isnull().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:49.609928Z","iopub.execute_input":"2022-04-25T05:35:49.610338Z","iopub.status.idle":"2022-04-25T05:35:49.668974Z","shell.execute_reply.started":"2022-04-25T05:35:49.610291Z","shell.execute_reply":"2022-04-25T05:35:49.667895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>adding labels to train data</h3>","metadata":{}},{"cell_type":"code","source":"labels.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:49.670271Z","iopub.execute_input":"2022-04-25T05:35:49.670879Z","iopub.status.idle":"2022-04-25T05:35:49.680596Z","shell.execute_reply.started":"2022-04-25T05:35:49.670841Z","shell.execute_reply":"2022-04-25T05:35:49.679665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train =train.merge(labels,how='left', on=[\"sequence\"])\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:49.681976Z","iopub.execute_input":"2022-04-25T05:35:49.682283Z","iopub.status.idle":"2022-04-25T05:35:49.940196Z","shell.execute_reply.started":"2022-04-25T05:35:49.682249Z","shell.execute_reply":"2022-04-25T05:35:49.939097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Feature Seeking bewteen Target and Sensors Data</h1>","metadata":{}},{"cell_type":"markdown","source":"\nbelow I will test the 'mean', 'max', 'min', 'var', 'mad', 'sum', 'median' value of the data hoping to dig anything valuable\n\n> the codes below are inspired by C4rl05/V with her work [https://www.kaggle.com/code/cv13j0/tps-apr-2022-xgboost-model](http://)","metadata":{}},{"cell_type":"code","source":"def aggregated_features(df, aggregation_cols = ['sequence'], prefix = ''):\n    agg_strategy = {'sensor_00': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_01': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_02': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_03': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_04': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_05': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_06': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_07': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_08': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_09': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_10': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_11': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                    'sensor_12': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median'],\n                   }\n    group = df.groupby(aggregation_cols).aggregate(agg_strategy)\n    group.columns = ['_'.join(col).strip() for col in group.columns]\n    group.columns = [str(prefix) + str(col) for col in group.columns]\n    group.reset_index(inplace = True)\n    \n    temp = (df.groupby(aggregation_cols).size().reset_index(name = str(prefix) + 'size'))\n    group = pd.merge(temp, group, how = 'left', on = aggregation_cols,)\n    return group","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:49.941633Z","iopub.execute_input":"2022-04-25T05:35:49.941851Z","iopub.status.idle":"2022-04-25T05:35:49.956595Z","shell.execute_reply.started":"2022-04-25T05:35:49.941824Z","shell.execute_reply":"2022-04-25T05:35:49.954866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merge_data = aggregated_features(train, aggregation_cols = ['sequence', 'subject'])\ntest_merge_data = aggregated_features(test, aggregation_cols = ['sequence', 'subject'])","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:35:49.958762Z","iopub.execute_input":"2022-04-25T05:35:49.959319Z","iopub.status.idle":"2022-04-25T05:40:30.962299Z","shell.execute_reply.started":"2022-04-25T05:35:49.959273Z","shell.execute_reply":"2022-04-25T05:40:30.96132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_subjects_merge_data = aggregated_features(train, aggregation_cols = ['subject'], prefix = 'subject_')\ntest_subjects_merge_data = aggregated_features(test, aggregation_cols = ['subject'], prefix = 'subject_')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:30.963987Z","iopub.execute_input":"2022-04-25T05:40:30.964335Z","iopub.status.idle":"2022-04-25T05:40:42.743529Z","shell.execute_reply.started":"2022-04-25T05:40:30.96429Z","shell.execute_reply":"2022-04-25T05:40:42.742138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"up to now we have a clear view of the values of sensors ","metadata":{}},{"cell_type":"code","source":"train_subjects_merge_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:42.746965Z","iopub.execute_input":"2022-04-25T05:40:42.747267Z","iopub.status.idle":"2022-04-25T05:40:42.77731Z","shell.execute_reply.started":"2022-04-25T05:40:42.747237Z","shell.execute_reply":"2022-04-25T05:40:42.776068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Merging the Datasets before Training</h3>","metadata":{}},{"cell_type":"code","source":"train_merge_data = train_merge_data.merge(labels, how = 'left', on = 'sequence')","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:42.779227Z","iopub.execute_input":"2022-04-25T05:40:42.780111Z","iopub.status.idle":"2022-04-25T05:40:42.807503Z","shell.execute_reply.started":"2022-04-25T05:40:42.780022Z","shell.execute_reply":"2022-04-25T05:40:42.806607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merge_data = train_merge_data.merge(train_subjects_merge_data, how = 'left', on = 'subject')\ntest_merge_data = test_merge_data.merge(test_subjects_merge_data, how = 'left', on = 'subject')\ntrain_merge_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:42.808808Z","iopub.execute_input":"2022-04-25T05:40:42.809616Z","iopub.status.idle":"2022-04-25T05:40:42.870634Z","shell.execute_reply.started":"2022-04-25T05:40:42.809554Z","shell.execute_reply":"2022-04-25T05:40:42.869694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_merge_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:42.872366Z","iopub.execute_input":"2022-04-25T05:40:42.872617Z","iopub.status.idle":"2022-04-25T05:40:42.901006Z","shell.execute_reply.started":"2022-04-25T05:40:42.872586Z","shell.execute_reply":"2022-04-25T05:40:42.900201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Post Processing the Information for the Model</h3>","metadata":{}},{"cell_type":"code","source":"ignore = ['sequence', 'state', 'subject']\nfeatures = [feat for feat in train_merge_data.columns if feat not in ignore]\ntarget_feature = 'state'","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:42.901982Z","iopub.execute_input":"2022-04-25T05:40:42.902829Z","iopub.status.idle":"2022-04-25T05:40:42.90756Z","shell.execute_reply.started":"2022-04-25T05:40:42.902794Z","shell.execute_reply":"2022-04-25T05:40:42.906525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Train - Test Split </h3>\n\nyou may do cross-validation too.","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import train_test_split\ntest_size_pct = 0.3\nX_train, X_valid, y_train, y_valid = train_test_split(\n                                train_merge_data[features], \n                                train_merge_data[target_feature], \n                                test_size = test_size_pct, \n                                random_state = 2022)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T05:40:42.90901Z","iopub.execute_input":"2022-04-25T05:40:42.909452Z","iopub.status.idle":"2022-04-25T05:40:43.214847Z","shell.execute_reply.started":"2022-04-25T05:40:42.909415Z","shell.execute_reply":"2022-04-25T05:40:43.21414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Build SBBTree Model","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:53:43.662703Z","iopub.execute_input":"2022-04-25T06:53:43.663028Z","iopub.status.idle":"2022-04-25T06:53:43.668731Z","shell.execute_reply.started":"2022-04-25T06:53:43.662988Z","shell.execute_reply":"2022-04-25T06:53:43.667959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SBBTree():\n    \"\"\"\n        SBBTree\n        Stacking,Bootstap,Bagging\n    \"\"\"\n    def __init__(\n                    self, \n                    params,\n                    stacking_num,\n                    bagging_num,\n                    bagging_test_size,\n                    num_boost_round,\n                    early_stopping_rounds\n                ):\n        \"\"\"\n            Initializes the SBBTree.\n            Args:\n              params : lgb params.\n              stacking_num : k_flod stacking.\n              bagging_num : bootstrap num.\n              bagging_test_size : bootstrap sample rate.\n              num_boost_round : boost num.\n              early_stopping_rounds : early_stopping_rounds.\n        \"\"\"\n        self.params = params\n        self.stacking_num = stacking_num\n        self.bagging_num = bagging_num\n        self.bagging_test_size = bagging_test_size\n        self.num_boost_round = num_boost_round\n        self.early_stopping_rounds = early_stopping_rounds\n\n        self.model = lgb\n        self.stacking_model = []\n        self.bagging_model = []\n\n    def fit(self, X, y):\n        \"\"\" fit model. \"\"\"\n        if self.stacking_num > 1:\n            layer_train = np.zeros((X.shape[0], 2))\n            self.SK = KFold(n_splits=self.stacking_num, shuffle=True, random_state=16)\n            for k,(train_index, test_index) in enumerate(self.SK.split(X, y)):\n                X_train = X.iloc[train_index]\n                y_train = y.iloc[train_index]\n                X_test = X.iloc[test_index]\n                y_test = y.iloc[test_index]\n\n                lgb_train = lgb.Dataset(X_train, y_train)\n                lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n                gbm = lgb.train(self.params,\n                            lgb_train,\n                            num_boost_round=self.num_boost_round,\n                            valid_sets=lgb_eval,\n                            early_stopping_rounds=self.early_stopping_rounds)\n\n                self.stacking_model.append(gbm)\n\n                pred_y = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n                layer_train[test_index, 1] = pred_y\n\n            X = np.hstack((X, layer_train[:,1].reshape((-1,1)))) \n        else:\n            pass\n        for bn in range(self.bagging_num):\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.bagging_test_size, random_state=bn)\n\n            lgb_train = lgb.Dataset(X_train, y_train)\n            lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n            gbm = lgb.train(self.params,\n                        lgb_train,\n                        num_boost_round=6000,\n                        valid_sets=lgb_eval,\n                        early_stopping_rounds=200)\n\n            self.bagging_model.append(gbm)\n\n    def predict(self, X_pred):\n        \"\"\" predict test data. \"\"\"\n        if self.stacking_num > 1:\n            test_pred = np.zeros((X_pred.shape[0], self.stacking_num))\n            for sn,gbm in enumerate(self.stacking_model):\n                pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n                test_pred[:, sn] = pred\n            X_pred = np.hstack((X_pred, test_pred.mean(axis=1).reshape((-1,1))))  \n        else:\n            pass \n        for bn,gbm in enumerate(self.bagging_model):\n            pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n            if bn == 0:\n                pred_out=pred\n            else:\n                pred_out+=pred\n        return pred_out/self.bagging_num","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:53:44.125177Z","iopub.execute_input":"2022-04-25T06:53:44.125857Z","iopub.status.idle":"2022-04-25T06:53:44.14837Z","shell.execute_reply.started":"2022-04-25T06:53:44.12581Z","shell.execute_reply":"2022-04-25T06:53:44.14753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>test the model with diff parameters here","metadata":{}},{"cell_type":"code","source":"\"\"\"\n    TEST CODE\n\"\"\"\n# from sklearn.datasets import make_classification\n# from sklearn.datasets import load_breast_cancer\n# from sklearn.datasets import make_gaussian_quantiles\n# from sklearn import metrics\n# from sklearn.metrics import f1_score\n# # X, y = make_classification(n_samples=1000, n_features=25, n_clusters_per_class=1, n_informative=15, random_state=1)\n# X, y = make_gaussian_quantiles(mean=None, cov=1.0, n_samples=1000, n_features=50, n_classes=2, shuffle=True, random_state=2)\n# # data = load_breast_cancer()\n# # X, y = data.data, data.target\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n# params = {\n#         'task': 'train',\n#         'boosting_type': 'gbdt',\n#         'objective': 'binary',\n#         'metric': 'auc',\n#         'num_leaves': 9,\n#         'learning_rate': 0.03,\n#         'feature_fraction_seed': 2,\n#         'feature_fraction': 0.9,\n#         'bagging_fraction': 0.8,\n#         'bagging_freq': 5,\n#         'min_data': 20,\n#         'min_hessian': 1,\n#         'verbose': 0,\n#         'silent': 0\n#         }\n# # test 1\n# model = SBBTree(params=params, stacking_num=2, bagging_num=1,  bagging_test_size=0.33, num_boost_round=10000, early_stopping_rounds=200)\n# model.fit(X,y)\n# X_pred = X[0].reshape((1,-1))\n# pred=model.predict(X_pred)\n# print('pred')\n# print(pred)\n# print('TEST 1 ok')\n\n\n# # test 1\n# model = SBBTree(params, stacking_num=1, bagging_num=1, bagging_test_size=0.33, num_boost_round=10000, early_stopping_rounds=200)\n# model.fit(X_train,y_train)\n# pred1=model.predict(X_test)\n\n# # test 2 \n# model = SBBTree(params, stacking_num=1, bagging_num=3, bagging_test_size=0.33, num_boost_round=10000, early_stopping_rounds=200)\n# model.fit(X_train,y_train)\n# pred2=model.predict(X_test)\n\n# # test 3 \n# model = SBBTree(params, stacking_num=5, bagging_num=1, bagging_test_size=0.33, num_boost_round=10000, early_stopping_rounds=200)\n# model.fit(X_train,y_train)\n# pred3=model.predict(X_test)\n\n# # test 4 \n# model = SBBTree(params, stacking_num=5, bagging_num=3, bagging_test_size=0.33, num_boost_round=10000, early_stopping_rounds=200)\n# model.fit(X_train,y_train)\n# pred4=model.predict(X_test)\n\n# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred1, pos_label=2)\n# print('auc: ',metrics.auc(fpr, tpr))\n\n# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred2, pos_label=2)\n# print('auc: ',metrics.auc(fpr, tpr))\n\n# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred3, pos_label=2)\n# print('auc: ',metrics.auc(fpr, tpr))\n\n# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred4, pos_label=2)\n# print('auc: ',metrics.auc(fpr, tpr))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:53:44.244568Z","iopub.execute_input":"2022-04-25T06:53:44.245102Z","iopub.status.idle":"2022-04-25T06:53:44.253555Z","shell.execute_reply.started":"2022-04-25T06:53:44.245065Z","shell.execute_reply":"2022-04-25T06:53:44.2529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',\n        'num_leaves': 2667,\n        'learning_rate': 0.03,\n        'feature_fraction_seed': 2,\n        'feature_fraction': 0.9,\n        'bagging_fraction': 0.8,\n        'bagging_freq': 5,\n        'min_data': 20,\n        'min_hessian': 1,\n        'verbose': 0,\n#         'silent': 0,\n        'n_estimators': 8126,\n        'max_depth': 6,\n        'subsample': 0.96,\n        'gamma': 1.40\n        }\n\nmodel = SBBTree(params=params,\n                stacking_num=7,\n                bagging_num=4,\n                bagging_test_size=0.25,\n                num_boost_round=8000,\n                early_stopping_rounds=256)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:53:44.456356Z","iopub.execute_input":"2022-04-25T06:53:44.456946Z","iopub.status.idle":"2022-04-25T06:53:44.46429Z","shell.execute_reply.started":"2022-04-25T06:53:44.456906Z","shell.execute_reply":"2022-04-25T06:53:44.463424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:53:44.469214Z","iopub.execute_input":"2022-04-25T06:53:44.469515Z","iopub.status.idle":"2022-04-25T06:53:44.481634Z","shell.execute_reply.started":"2022-04-25T06:53:44.469482Z","shell.execute_reply":"2022-04-25T06:53:44.480674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\nrfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=135)\nselector=rfe_selector.fit(X_train, y_train)\nprint(selector.support_)\nprint(selector.ranking_)\n# rfe_support = rfe_selector.get_support()\n# rfe_feature = X.loc[:,rfe_support].columns.tolist()\n# print(str(len(rfe_feature)), 'selected features')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:53:44.587166Z","iopub.execute_input":"2022-04-25T06:53:44.588335Z","iopub.status.idle":"2022-04-25T06:55:03.861776Z","shell.execute_reply.started":"2022-04-25T06:53:44.588268Z","shell.execute_reply":"2022-04-25T06:55:03.860833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_support = selector.get_support()\nrfe_feature = X_train.loc[:,rfe_support].columns.tolist()\nprint(str(len(rfe_feature)), 'selected features')\nrfe_feature","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:55:03.864209Z","iopub.execute_input":"2022-04-25T06:55:03.864871Z","iopub.status.idle":"2022-04-25T06:55:03.882015Z","shell.execute_reply.started":"2022-04-25T06:55:03.864822Z","shell.execute_reply":"2022-04-25T06:55:03.88117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train[rfe_feature], y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:55:03.883595Z","iopub.execute_input":"2022-04-25T06:55:03.89039Z","iopub.status.idle":"2022-04-25T06:57:00.036271Z","shell.execute_reply.started":"2022-04-25T06:55:03.890309Z","shell.execute_reply":"2022-04-25T06:57:00.035555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_merge_data[rfe_feature])","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:57:00.03832Z","iopub.execute_input":"2022-04-25T06:57:00.038826Z","iopub.status.idle":"2022-04-25T06:57:08.091024Z","shell.execute_reply.started":"2022-04-25T06:57:00.038789Z","shell.execute_reply":"2022-04-25T06:57:08.090313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:57:08.092563Z","iopub.execute_input":"2022-04-25T06:57:08.093107Z","iopub.status.idle":"2022-04-25T06:57:08.10007Z","shell.execute_reply.started":"2022-04-25T06:57:08.093069Z","shell.execute_reply":"2022-04-25T06:57:08.099223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['state'] = preds\nsubmission.to_csv('my_submission_ty.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T06:57:08.101818Z","iopub.execute_input":"2022-04-25T06:57:08.106723Z","iopub.status.idle":"2022-04-25T06:57:08.160068Z","shell.execute_reply.started":"2022-04-25T06:57:08.106659Z","shell.execute_reply":"2022-04-25T06:57:08.158872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"  ","metadata":{}}]}