{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib \nfrom matplotlib import gridspec\nimport seaborn as sns\nfrom scipy.stats import ks_2samp\n\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\nfrom matplotlib.patches import Patch\nfrom sklearn.model_selection import (\n    KFold,\n    GroupKFold,\n    StratifiedGroupKFold,\n)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# runtime configuration of matplotlib\nplt.style.use(\"Solarize_Light2\")\nplt.rc(\"figure\", \n    autolayout=True, \n    figsize=(20, 10)\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=20,\n    titlepad=10,\n)\n#!pip install mplcyberpunk\n#import mplcyberpunk","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:39:24.196943Z","iopub.execute_input":"2022-04-14T17:39:24.197492Z","iopub.status.idle":"2022-04-14T17:39:24.204815Z","shell.execute_reply.started":"2022-04-14T17:39:24.197457Z","shell.execute_reply":"2022-04-14T17:39:24.204081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%HTML\n<style type=\"text/css\">\n\ndiv.h2 {\n    background-color: #00b050; \n    color: white; \n    padding: 5px; \n    padding-right: 300px; \n    font-size: 25px;  \n    margin-top: 2px;\n    margin-bottom: 10px;\n}\n\ndiv.h3 {\n    background-color: white; \n    color: #fe0000; \n    padding: 5px; \n    padding-right: 300px; \n    font-size: 20px; \n    margin-top: 2px;\n    margin-bottom: 10px;\n}\n</style>","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:39:30.189421Z","iopub.execute_input":"2022-04-14T17:39:30.189689Z","iopub.status.idle":"2022-04-14T17:39:30.201109Z","shell.execute_reply.started":"2022-04-14T17:39:30.189657Z","shell.execute_reply":"2022-04-14T17:39:30.200039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n<div class=\"h2\">Introduction</div>\n\nIn this notebook I have performed an analysis of the sensor and subject data:\n\n   <a id=\"toc\"></a>\n   \n1. [Covariate Shift](#1)\n2. [Subject Analysis](#2)\n3. [Cross Validation Strategies](#3)\n4. [References](#4)\n\nI will keep adding content; its work in progress.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<div class=\"h2\">Covariate Shift</div>\n\nCovariate shift is the scholarly term for when the distribution of the data (i.e. our input features) changes. It is important to adress this issue since ignoring it could give poor predictive performance assuming there is a significant shift in the feature distribution. The reason being basically that the data the model is trained on is not representative of the future.\n\nThere are several ways to detect covariate shift like `Kullbackâ€“Leibler divergence` or `Kolmogorov-Smirnov test`. I have applied Kolmogorov-Smirnov test (`KS-test`). `KS-test` is a non-parametric test that compares the shape of two empirical distributions. It is sensitive to differences in both location and shape of the distributions.\n\nUnder the the `null-hypothesis` the covariates come from the same distribution and when the `p-value` is smaller than `0.05` then is the null-hypotheis rejected.\n\nWhat is the solution once the 'drift' is recognised? Well there are two solution:\n\n   1. Feature Removal\n   2. Importance reweighting\n","metadata":{}},{"cell_type":"code","source":"train_raw = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv',index_col='subject')\ntest_raw = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv',index_col='subject')\ntrain_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T17:39:34.0384Z","iopub.execute_input":"2022-04-14T17:39:34.038668Z","iopub.status.idle":"2022-04-14T17:39:45.254014Z","shell.execute_reply.started":"2022-04-14T17:39:34.038638Z","shell.execute_reply":"2022-04-14T17:39:45.253272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_data(data):\n    X = data.copy()#[train_raw.index==49].sort_values(by=[\"sequence\", \"step\"])\n    X = X.pivot(index='sequence', columns=['step'], values=[col for col in X.columns if 'sensor_' in col])\n\n    columns = []\n    for col in X.columns.values:\n        string = col[0]+\"_\"+ np.str(col[1])\n        columns.append(string)\n    X.columns = columns\n\n    return X\n\ntrain = parse_data(train_raw)\ntest = parse_data(test_raw)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:39:46.837036Z","iopub.execute_input":"2022-04-14T17:39:46.837615Z","iopub.status.idle":"2022-04-14T17:39:47.592743Z","shell.execute_reply.started":"2022-04-14T17:39:46.837574Z","shell.execute_reply":"2022-04-14T17:39:47.591994Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ks-test\ndef ks_test(df_train, df_test):\n    df_ks_test = pd.DataFrame(index=test.columns, columns=[\"p_value_ks\", \"statistics_ks\"])\n    p_value_ks = []\n    statistics_value_ks = []\n\n    for col in train.columns:\n        data1 = df_train[col]\n        data2 = df_test[col]\n        \n        #perform Kolmogorov-Smirnov test\n        statistics_value_ks.append(ks_2samp(data1, data2)[0])\n        p_value_ks.append(ks_2samp(data1, data2)[1])\n\n    df_ks_test[\"p_value_ks\"] = p_value_ks\n    df_ks_test[\"statistics_ks\"] = statistics_value_ks\n\n    filters = [\n    (df_ks_test.p_value_ks <= 0.05), (df_ks_test.p_value_ks > 0.05)\n    ]\n    values = [\"Different distribution\", \"Same distribution\"]\n\n    df_ks_test[\"category\"] = np.select(filters, values)\n    df_ks_test[\"flag\"]=1\n\n    return df_ks_test","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-04-14T17:39:50.506538Z","iopub.execute_input":"2022-04-14T17:39:50.506817Z","iopub.status.idle":"2022-04-14T17:39:50.513858Z","shell.execute_reply.started":"2022-04-14T17:39:50.506786Z","shell.execute_reply":"2022-04-14T17:39:50.513116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = parse_data(train_raw)\ntest = parse_data(test_raw)\ndf_ks_test = ks_test(train, test)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T17:39:57.420528Z","iopub.execute_input":"2022-04-14T17:39:57.420815Z","iopub.status.idle":"2022-04-14T17:40:10.128423Z","shell.execute_reply.started":"2022-04-14T17:39:57.420785Z","shell.execute_reply":"2022-04-14T17:40:10.127712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ks-plot\nfig = plt.figure(constrained_layout=False)\nspec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig, width_ratios=[3, 1])\n\nfig.suptitle(\"Kolmogorov-Smirnov Test\\n\", fontsize=25, fontproperties=\"bold\")\n\nsensors = [\"sensor_00_0\", \"sensor_01_0\",  \"sensor_02_0\", \"sensor_03_0\", \"sensor_04_0\",  \"sensor_05_0\",  \\\n    \"sensor_06_0\",  \"sensor_07_0\",  \"sensor_08_0\",  \"sensor_09_0\",  \"sensor_10_0\",  \"sensor_11_0\",  \"sensor_12_0\"]\n\nsensor_labels = [\"sensor 1\", \"sensor 2\", \"sensor 3\",\"sensor 4\",\"sensor 5\",\"sensor 6\",\"sensor 7\",\"sensor 8\",\"sensor 9\",\\\n    \"sensor 10\",\"sensor 11\",\"sensor 12\",\"sensor 13\"]\n\n# KS p-value\nax1 = fig.add_subplot(spec[0, 0])\nsns.scatterplot(y=\"p_value_ks\", x=df_ks_test.index, ax=ax1, data=df_ks_test)\nfor sensor, label in zip(sensors, sensor_labels):\n    plt.axvline(x = sensor, color = 'k', alpha=0.3)\n    ax1.text(sensor, 1.05, label, fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"normal\")\nax1.axhline(0.05, c=\"r\")\nax1.text(sensor, 0.1, \" p-value = 0.05\", fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\nax1.xaxis.set_ticks([])\nax1.set(xlabel=\"Steps(1-60)\", ylabel = \"value\")\nax1.set_title('P-Value', fontsize=15, fontproperties=\"semibold\")\nax1.set_xlim(\"sensor_00_0\", \"sensor_13_59\")\n\n# text\ntext = \"The Kolmogorov Smirnov test\\n statistic quantifies a distance \\n between two empirical \\n distributions.\"\nax2 = fig.add_subplot(spec[0, 1])\nax2.xaxis.set_ticks([])\nax2.yaxis.set_ticks([])\nax2.text(0.0, 0.65, text, fontsize=20, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"cursive\")\nax2.set_facecolor('cornsilk')\nax2.set_title('', fontsize=25, fontproperties=\"semibold\")\n\n# Kolmogorov test statistics\nax3 = fig.add_subplot(spec[1, 0])\nsns.scatterplot(y=\"statistics_ks\", x=df_ks_test.index, ax=ax3, data=df_ks_test)\nax3.xaxis.set_ticks([])\nax3.set(xlabel=\"Steps(1-60)\", ylabel = \"value\")\nax3.set_title('Test statistics', fontsize=15, fontproperties=\"semibold\")\nax3.set_xlim(\"sensor_00_0\", \"sensor_13_59\")\nfor sensor, label in zip(sensors, sensor_labels):\n    plt.axvline(x = sensor, color = 'k', alpha=0.3)\n    ax3.text(sensor, 0.0465, label, fontsize=10, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"cursive\", family=\"bold\")\nax3.text(sensor, 0.0165, \" Critical value\", fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\nax3.axhline(0.0145, c=\"r\")\n\n# Count of features\nax4 = fig.add_subplot(spec[1, 1])\nsns.countplot(x=\"category\", ax=ax4, data=df_ks_test)\nfor p in ax4.patches:\n    ax4.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), ha='center', va='top', color='white', size=18)\nax4.set(xlabel=\"\", ylabel = \"\")\nax4.set_title('Feature Distribution Similarity \\n (Train vs Test)', fontsize=18, fontproperties=\"semibold\")\nax4.yaxis.set_ticks([])\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:40:19.30544Z","iopub.execute_input":"2022-04-14T17:40:19.305702Z","iopub.status.idle":"2022-04-14T17:40:21.745076Z","shell.execute_reply.started":"2022-04-14T17:40:19.30567Z","shell.execute_reply":"2022-04-14T17:40:21.744353Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ’¡ **INSIGHTS**\n- From the first plot we can deduce that features of `sensor 5` and `sensor 13` have different distributions for the `train` and `test` set.\n- The third plot shows that the test statistics of `sensor 13` are significantly higher than the test statistics of other sensors. Does this mean that the `sensor 13` train features are more different than test `sensor 13` features compared to other features? I do not know yet. \n- The next step is to fit one model with all the features and another without `sensor 5` and `sensor 13` features and compare the model performances to know if the `drift` is consequential. \n- Based on a discussion with [@ambrosm](https://www.kaggle.com/ambrosm) and [@Pourchot](https://www.kaggle.com/pourchot) I have applied the KS-test on subject level. That is to see if the shift is on train test level or on subject level. So what I have done is that I compare train subjects with test subjects where the number of sequences are greater than 98 so that the test statistics is reliable. See the plot below for the results. ","metadata":{}},{"cell_type":"code","source":"# ks-plot\nfig = plt.figure(constrained_layout=False)\nspec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n\nfig.suptitle(\"Kolmogorov-Smirnov Test\\n P-Value\\n\", fontsize=25, fontproperties=\"bold\")\n\nsensors = [\"sensor_00_0\", \"sensor_01_0\",  \"sensor_02_0\", \"sensor_03_0\", \"sensor_04_0\",  \"sensor_05_0\",  \\\n    \"sensor_06_0\",  \"sensor_07_0\",  \"sensor_08_0\",  \"sensor_09_0\",  \"sensor_10_0\",  \"sensor_11_0\",  \"sensor_12_0\"]\n\nsensor_labels = [\"sensor 1\", \"sensor 2\", \"sensor 3\",\"sensor 4\",\"sensor 5\",\"sensor 6\",\"sensor 7\",\"sensor 8\",\"sensor 9\",\\\n    \"sensor 10\",\"sensor 11\",\"sensor 12\",\"sensor 13\"]\n\n# KS p-value\ntrain = parse_data(train_raw[train_raw.index==647])\ntest = parse_data(test_raw[test_raw.index==748])\ndf_ks_test = ks_test(train, test)\n\nax1 = fig.add_subplot(spec[0, 0])\nsns.scatterplot(y=\"p_value_ks\", x=df_ks_test.index, ax=ax1, data=df_ks_test)\nfor sensor, label in zip(sensors, sensor_labels):\n    plt.axvline(x = sensor, color = 'k', alpha=0.3)\n    ax1.text(sensor, 1.05, label, fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"normal\")\nax1.axhline(0.05, c=\"r\")\nax1.text(sensor, 0.1, \"\", fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\nax1.xaxis.set_ticks([])\nax1.set(xlabel=\"Steps(1-60)\", ylabel = \"value\")\nax1.set_title('(train_subject = 647, test_subject = 748)', fontsize=15, fontproperties=\"semibold\")\nax1.set_xlim(\"sensor_00_0\", \"sensor_13_59\")\n\ntrain = parse_data(train_raw[train_raw.index==196])\ntest = parse_data(test_raw[test_raw.index==682])\ndf_ks_test = ks_test(train, test)\n\n# KS p-value\nax2 = fig.add_subplot(spec[0, 1])\nsns.scatterplot(y=\"p_value_ks\", x=df_ks_test.index, ax=ax2, data=df_ks_test)\nfor sensor, label in zip(sensors, sensor_labels):\n    plt.axvline(x = sensor, color = 'k', alpha=0.3)\n    ax2.text(sensor, 0.85, label, fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"normal\")\nax2.axhline(0.05, c=\"r\")\nax2.text(sensor, 0.1, \"\", fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\nax2.xaxis.set_ticks([])\nax2.set(xlabel=\"Steps(1-60)\", ylabel = \"value\")\nax2.set_title('(train_subject = 196, test_subject = 682)', fontsize=15, fontproperties=\"semibold\")\nax2.set_xlim(\"sensor_00_0\", \"sensor_13_59\")\n\ntrain = parse_data(train_raw[train_raw.index==47])\ntest = parse_data(test_raw[test_raw.index==781])\ndf_ks_test = ks_test(train, test)\n\n# KS p-value\nax3 = fig.add_subplot(spec[1, 0])\nsns.scatterplot(y=\"p_value_ks\", x=df_ks_test.index, ax=ax3, data=df_ks_test)\nfor sensor, label in zip(sensors, sensor_labels):\n    plt.axvline(x = sensor, color = 'k', alpha=0.3)\n    ax3.text(sensor, 1.05, label, fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"normal\")\nax3.axhline(0.05, c=\"r\")\nax3.text(sensor, 0.1, \"\", fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\nax3.xaxis.set_ticks([])\nax3.set(xlabel=\"Steps(1-60)\", ylabel = \"value\")\nax3.set_title('(train_subject = 47, test_subject = 781)', fontsize=15, fontproperties=\"semibold\")\nax3.set_xlim(\"sensor_00_0\", \"sensor_13_59\")\n\ntrain = parse_data(train_raw[train_raw.index==125])\ntest = parse_data(test_raw[test_raw.index==865])\ndf_ks_test = ks_test(train, test)\n\n# KS p-value\nax4 = fig.add_subplot(spec[1, 1])\nsns.scatterplot(y=\"p_value_ks\", x=df_ks_test.index, ax=ax4, data=df_ks_test)\nfor sensor, label in zip(sensors, sensor_labels):\n    plt.axvline(x = sensor, color = 'k', alpha=0.3)\n    ax4.text(sensor, 1, label, fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"normal\")\nax4.axhline(0.05, c=\"r\")\nax4.text(sensor, 0.1, \"\", fontsize=8, verticalalignment='top', rotation=\"horizontal\", color=\"k\", fontproperties=\"bold\")\nax4.xaxis.set_ticks([])\nax4.set(xlabel=\"Steps(1-60)\", ylabel = \"value\")\nax4.set_title('(train_subject = 125, test_subject = 865)', fontsize=15, fontproperties=\"semibold\")\nax4.set_xlim(\"sensor_00_0\", \"sensor_13_59\")\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:40:26.745478Z","iopub.execute_input":"2022-04-14T17:40:26.745759Z","iopub.status.idle":"2022-04-14T17:40:41.675655Z","shell.execute_reply.started":"2022-04-14T17:40:26.745711Z","shell.execute_reply":"2022-04-14T17:40:41.675033Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ’¡ **INSIGHTS**\n- From the four plots we can see that `sensor 13` train features experience shift when compared to `sensor 13` test features.\n- `Sensor 5` seems to be behavouing differently per subject therefor we may conclude the results of KS-test for `sensor 5` is not significant.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<div class=\"h2\">Subject Analysis</div>\n\nNow that we have studied the sensors it is time to take a look at the (disjoint) subjects. [@ambrose](https://www.kaggle.com/ambrosm) has also studied this, see [notebook](https://www.kaggle.com/code/ambrosm/tpsapr22-eda-which-makes-sense).","metadata":{}},{"cell_type":"code","source":"def subject(dataframe):\n\n    X = dataframe.copy()\n    X.reset_index(inplace=True)\n    X = X[[\"subject\", \"sequence\"]].groupby([\"subject\", \"sequence\"]).count()\n    X.reset_index(inplace=True)\n    X = X.merge(train_labels, how=\"left\", left_on=\"sequence\", right_on=\"sequence\")\n    X = X.groupby([\"subject\"]).agg({\"sequence\":\"count\", \"state\":\"sum\"}).sort_values([\"subject\"])\n    X.reset_index(inplace=True)\n    X[\"percentage\"] = X[\"state\"]/X[\"sequence\"]\n\n    return X\n\ntrain_subject = subject(train_raw)\ntest_subject = subject(test_raw)\n\n# plot\nfig = plt.figure(constrained_layout=False)\nspec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n\nax1 = fig.add_subplot(spec[0, 0])\nsns.histplot(x=\"sequence\", ax=ax1, data=train_subject, color=\"y\", alpha=0.15, label=\"Train\")\nsns.histplot(x=\"sequence\", ax=ax1, data=test_subject, color=\"r\", label=\"Test\")\nax1.set(xlabel=\"Sequence count\", ylabel = \"Number of subjects\")\nax1.set_xlim(0, 200);\nax1.set_title('Histogram sequence count \\n(Train vs Test)', fontsize=12)\nax1.legend()\n\nax2 = fig.add_subplot(spec[0, 1])\nsns.kdeplot(x=\"sequence\", ax=ax2, data=train_subject, color=\"y\", alpha=1, label=\"Train\")\nsns.kdeplot(x=\"sequence\", ax=ax2, data=test_subject, color=\"r\", label=\"Train\")\nax2.set(xlabel=\"Sequence count\", ylabel = \"Density\")\nax2.set_xlim(0, 200);\nax2.set_title('Density sequence count \\n(Train vs Test)', fontsize=12)\nax2.legend()\n\nax3 = fig.add_subplot(spec[1, :])\nsns.scatterplot(x=\"sequence\", y=\"percentage\", ax=ax3, data=train_subject, color=\"g\")\nax3.set(xlabel=\"Sequence count\", ylabel = \"Probability State=1\")\nax3.set_title('Sequence count vs Probability State=1 \\n (Train)', fontsize=12)\n\nfig.suptitle(\"Subject Analysis\\n\", fontsize=25, fontproperties=\"bold\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:40:46.958442Z","iopub.execute_input":"2022-04-14T17:40:46.958707Z","iopub.status.idle":"2022-04-14T17:40:47.987225Z","shell.execute_reply.started":"2022-04-14T17:40:46.958676Z","shell.execute_reply":"2022-04-14T17:40:47.986581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ’¡ **INSIGHTS**\n- Based on the first plot we can conclude that the number of sequences per subject is right skewed for both `train` and `test`.\n- The second plot suggests that the number of sequences for both train and test have identical empirical density function.\n- The third plot is very interesting. What it says is; the higher the number of sequnces the higher the probablity for state 1. For example `(Number of sequences)>=100` implies `P(state=1)>=0.78`. We can try to assign `probablity>= 0.78` for test subjects that has more than 100 sequences and see how it performs.\n- This insight also has implications for the cross validation strategy. For reliable cross validation it is wise to apply `GroupKfold` approach. See discussion below with [@ambrose](https://www.kaggle.com/ambrosm).","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<div class=\"h2\">Cross Validation Strategy</div>\n\nIn this section I would like to layout the choice of cross validation strategy. As [@ambrose](https://www.kaggle.com/ambrosm) rightly mentions in his notebook that by applying `Kfold` strategy one introduces leak in the CV folds instead it is beter to chose `GroupKFold` strategy because every subject occurs just once in every fold. \n\nTo demonstrate the difference in strategies I have selected `8 subjects` for which I apply `Kfold`, `GroupKFold` and `StratifiedGroupKFold` with the number of `folds=5`. For example from the first plot one can observe that for the 4th iteration the the second last subject occurs in both training and validation set. This introduces a leak in the training set as a result we will get high CV results and eventually lower performance on the `LB`.\n\n`GroupKFold` and `StratifiedGroupKFold` are `K-fold` variant with non-overlapping groups. The difference between `GroupKFold` and `StratifiedGroupKFold` is that the former attempts to create balanced folds such that the number of distinct groups is approximately the same in each fold, whereas StratifiedGroupKFold attempts to create folds which preserve the percentage of samples for each class as much as possible given the constraint of non-overlapping groups between splits. \n\nIn the next section I have implemented `XGBoost` with `GroupKFold` and `StratifiedGroupKFold` and compared the reults. See below.","metadata":{}},{"cell_type":"code","source":"cmap_data = plt.cm.summer\ncmap_cv = plt.cm.coolwarm\nn_splits = 5\n\n#\nsubjects = train_subject.loc[(train_subject[\"sequence\"]<13) & (train_subject[\"percentage\"]>0),\"subject\"].values\n#\nX = train_raw.copy()\nX.reset_index(inplace=True)\nX = X[[\"subject\", \"sequence\"]].groupby([\"subject\", \"sequence\"]).count()\nX.reset_index(inplace=True)\nX = X.merge(train_labels, how=\"left\", left_on=\"sequence\", right_on=\"sequence\")\nX = X.loc[X[\"subject\"].isin(list(subjects)),:].sort_values(by=[\"subject\",\"sequence\"])\n\ndef plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n\n    # Generate the training/testing visualizations for each CV split\n    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n        # Fill in indices with the training/test groups\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(\n            range(len(indices)),\n            [ii + 0.5] * len(indices),\n            c=indices,\n            marker=\"_\",\n            lw=lw,\n            cmap=cmap_cv,\n            vmin=-0.2,\n            vmax=1.2,\n        )\n\n    # Plot the data classes and groups at the end\n    ax.scatter(\n        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=plt.cm.summer\n    )\n\n    ax.scatter(\n        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=plt.cm.prism_r\n    )\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + [\"state\", \"subject\"]\n    ax.set(\n        yticks=np.arange(n_splits + 2) + 0.5,\n        yticklabels=yticklabels,\n        xlabel=\"Sample index\",\n        ylabel=\"CV iteration\",\n        ylim=[n_splits + 2.2, -0.2],\n        xlim=[0, 75],\n    )\n    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n    return ax\n\nn_splits =5\n# plot\nfig = plt.figure(constrained_layout=True, figsize=(20,5))\nspec = gridspec.GridSpec(ncols=3, nrows=1, figure=fig)\n\nax1 = fig.add_subplot(spec[0, 0])\nplot_cv_indices(KFold(n_splits), X, X.state, X.subject, ax1, n_splits)\n\nax1.set(xlabel=\"Sequence\", ylabel = \"CV iteration\")\nax1.set_xlim(0, 75);\nax1.set_title('KFold', fontsize=12, fontproperties=\"semibold\")\nax1.annotate(\"Leak\", (60 , 6.6), (65, 8) , arrowprops={\"arrowstyle\": \"->\"},\\\n    fontproperties=\"cursive\", fontsize=10)\nax1.annotate(\"Split\", (59 , 4.5), (63, 6) , arrowprops={\"arrowstyle\": \"->\"},\\\n    fontproperties=\"cursive\", fontsize=10)\n\nax2 = fig.add_subplot(spec[0, 1])\nplot_cv_indices(GroupKFold(n_splits), X, X.state, X.subject, ax2, n_splits)\nax2.set(xlabel=\"Sequence\", ylabel = \"\")\nax2.set_xlim(0, 75);\nax2.set_title('GroupKFold', fontsize=12, fontproperties=\"semibold\")\n\nax3 = fig.add_subplot(spec[0, 2])\nplot_cv_indices(StratifiedGroupKFold(n_splits), X, X.state, X.subject, ax3, n_splits)\nax3.set(xlabel=\"Sequence\", ylabel = \"\")\nax3.set_xlim(0, 75);\nax3.set_title('StratifiedGroupKFold', fontsize=12, fontproperties=\"semibold\")\nax3.legend(\n    [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n    [\"Validation set\", \"Training set\"],\n    loc=(1.02, 0.8),\n)\n\nfig.suptitle(\"Validation Strategies\\n\", fontsize=25, fontproperties=\"bold\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:40:57.151927Z","iopub.execute_input":"2022-04-14T17:40:57.15247Z","iopub.status.idle":"2022-04-14T17:40:58.234257Z","shell.execute_reply.started":"2022-04-14T17:40:57.152434Z","shell.execute_reply":"2022-04-14T17:40:58.233597Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = parse_data(train_raw)\n\nX = train_raw[[\"sequence\"]].reset_index(drop=False)\nX = X.groupby([\"subject\", \"sequence\"]).count()\nX.reset_index(inplace=True)\nX = train.merge(X, how=\"left\", left_index=True, right_on=\"sequence\")\nX = X.merge(train_labels, how=\"left\", left_on=\"sequence\", right_on=\"sequence\")\n\nX.sort_values(by=[\"subject\",\"sequence\"])\nX.set_index([\"sequence\",\"subject\"], inplace=True)\n\ndef xgboost(X_train, y_train, X_val, y_val, n_estimators=5):\n    \n    model = XGBClassifier(n_estimators=n_estimators, n_jobs=-1,\n                      eval_metric=['logloss'],\n                      #max_depth=10,\n                      colsample_bytree=0.8,\n                      #gamma=1.4,\n                      reg_alpha=6, reg_lambda=1.5,\n                      tree_method='hist',\n                      learning_rate=0.03,\n                      verbosity=1,\n                      use_label_encoder=False, random_state=3)\n\n    model.fit(X_train.values, y_train, eval_set = [(X_val.values, y_val)], \n                eval_metric = ['auc'], early_stopping_rounds=30, verbose=10)\n    \n    return model.predict_proba(X_val.values)[:,1] \n\n####\nfeatures = [col for col in X.columns if col not in ['state',\"subject\", \"sequence\"]]\nscore_list = []\ngkf_score = pd.DataFrame()\ngkf = GroupKFold(n_splits=2)\nfor fold, (idx_train, idx_val) in enumerate(gkf.split(X, y=X.state, groups=X.index.get_level_values('subject'))):\n    X_train = X.iloc[idx_train][features]\n    X_val = X.iloc[idx_val][features]\n    y_train = X.iloc[idx_train].state\n    y_val = X.iloc[idx_val].state\n\n    y_val_pred = xgboost(X_train, y_train, X_val, y_val, 300)\n    \n    X_val[\"gkf_pred\"] = list(y_val_pred)\n    gkf_score = gkf_score.append(X_val)\n\n    score = roc_auc_score(y_val, y_val_pred)\n\n    print(f\"Fold {fold}: AUC = {score:.3f}\")\n    score_list.append(score)\n    \nprint(f\"OOF AUC:{np.mean(score_list):.3f}\")\n\nfeatures = [col for col in X.columns if col not in ['state',\"subject\", \"sequence\"]]\nscore_list = []\nsgkf_score = pd.DataFrame()\nsgkf = StratifiedGroupKFold(n_splits=2)\nfor fold, (idx_train, idx_val) in enumerate(sgkf.split(X, y=X.state, groups=X.index.get_level_values('subject'))):\n    X_train = X.iloc[idx_train][features]\n    X_val = X.iloc[idx_val][features]\n    y_train = X.iloc[idx_train].state\n    y_val = X.iloc[idx_val].state\n\n    y_val_pred = xgboost(X_train, y_train, X_val, y_val, 300)\n    \n    X_val[\"sgkf_pred\"] = list(y_val_pred)\n    sgkf_score = sgkf_score.append(X_val)\n\n    score = roc_auc_score(y_val, y_val_pred)\n\n    print(f\"Fold {fold}: AUC = {score:.3f}\")\n    score_list.append(score)\n    \nprint(f\"OOF AUC:{np.mean(score_list):.3f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:41:08.953548Z","iopub.execute_input":"2022-04-14T17:41:08.953955Z","iopub.status.idle":"2022-04-14T17:46:28.681675Z","shell.execute_reply.started":"2022-04-14T17:41:08.953915Z","shell.execute_reply":"2022-04-14T17:46:28.680886Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data = gkf_score.loc[:,[\"gkf_pred\"]].merge(sgkf_score.loc[:,[\"sgkf_pred\"]], how=\"left\", left_index=True, right_index=True)\nval_data.reset_index(inplace=True)\nval_data = val_data.merge(train_labels, how=\"left\", left_on=\"sequence\", right_on=\"sequence\")\nval_data = val_data.groupby([\"subject\"]).agg({\"sequence\":\"count\", \"state\":\"sum\", \"gkf_pred\":\"mean\", \"sgkf_pred\":\"mean\"}).sort_values([\"subject\"])\nval_data.reset_index(inplace=True)\nval_data[\"percentage\"] = val_data[\"state\"]/val_data[\"sequence\"]\nval_data\n# plot\nfig = plt.figure(constrained_layout=False)\nspec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n\nax1 = fig.add_subplot(spec[0, 0])\nsns.scatterplot(x=\"sequence\", y=\"gkf_pred\", ax=ax1, data=val_data, color=\"y\", label=\"GroupedKFold\")\nsns.scatterplot(x=\"sequence\", y=\"sgkf_pred\", ax=ax1, data=val_data, label=\"StratifiedGroupedKFold\")\nax1.set(xlabel=\"Sequence length\", ylabel = \"Probability State=1\")\nax1.set_xlim(0, 200);\nax1.set_title('Validation results', fontsize=12)\nax1.legend()\n\nax2 = fig.add_subplot(spec[0, 1])\nsns.kdeplot(x=\"gkf_pred\", ax=ax2, data=val_data, color=\"y\", cumulative=True, label=\"GroupedKFold\")\nsns.kdeplot(x=\"sgkf_pred\", ax=ax2, data=val_data, color=\"r\", cumulative=True, label=\"StratifiedGroupedKFold\")\nax2.set(xlabel=\"Probability\", ylabel = \"P(X<x)\")\nax2.set_title('Cumulative Distribution Function (CDF)', fontsize=12)\nax2.legend()\n\n\nax3 = fig.add_subplot(spec[1, 0])\nsns.scatterplot(x=\"sequence\", y=\"percentage\", ax=ax3, data=val_data, color=\"y\")\nax3.set(xlabel=\"Sequence length\", ylabel = \"Probability State=1\")\nax3.set_title('Sequence length vs Probability State=1 \\n (Train)', fontsize=12)\nax3.set_xlim(0, 200);\n\nax4 = fig.add_subplot(spec[1, 1])\nsns.histplot(x=\"gkf_pred\", ax=ax4, data=val_data, color=\"y\", alpha=0.15, label=\"GroupedKFold\")\nsns.histplot(x=\"sgkf_pred\", ax=ax4, data=val_data, color=\"r\", label=\"StratifiedGroupedKFold\")\nax4.set(xlabel=\"Probability\", ylabel = \"Count\")\nax4.set_title('Histogram prediction probability', fontsize=12)\nax4.legend()\n\nfig.suptitle(\"GroupedKFold vs StratifiedGroupedKFold\\n\", fontsize=25, fontproperties=\"bold\", alpha=1)\n#mplcyberpunk.make_scatter_glow()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-14T17:46:38.708213Z","iopub.execute_input":"2022-04-14T17:46:38.710672Z","iopub.status.idle":"2022-04-14T17:46:39.869468Z","shell.execute_reply.started":"2022-04-14T17:46:38.710624Z","shell.execute_reply":"2022-04-14T17:46:39.8688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ’¡ **INSIGHT**\n- Based on the first plot we can see there is not much difference between `GroupedKFold` and `StratifiedGroupedKFold`. \n- The second plot shows that both strategies give similar cumulative distribution function.\n- The fourth plot suggests that `GroupedKFold` has higher kurtosis and `StratifiedGroupedKFold` has thicker tails. I do not know if the results are statistically significant.\n- Comparing the first plot with the third plot one can conclude that there is still some work to do to improve the performance of the model.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<div class=\"h2\">References</div>\n\n### Domain Knowledge References\n\n1. https://towardsdatascience.com/new-features-of-scikit-learn-fbbfe7652bfb\n2. https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n\n### Kaggle Kernels for Inspiration\n1. https://www.kaggle.com/code/ambrosm/tpsapr22-eda-which-makes-sense\n2. https://www.kaggle.com/code/cv13j0/tps-apr-2022-xgboost-model\n3. https://www.kaggle.com/code/ambrosm/tpsapr22-best-model-without-nn\n4. https://www.kaggle.com/code/thedatabeast/where-to-invest-to-combat-air-pollution-in-india","metadata":{}}]}