{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install swifter","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:00:34.485802Z","iopub.execute_input":"2022-04-19T15:00:34.486087Z","iopub.status.idle":"2022-04-19T15:00:45.816498Z","shell.execute_reply.started":"2022-04-19T15:00:34.486052Z","shell.execute_reply":"2022-04-19T15:00:45.815797Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models,callbacks\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold\nfrom sklearn.metrics import roc_auc_score, auc\nfrom sklearn.decomposition import PCA\n\nfrom scipy.stats import boxcox\n\n#speed up pandas apply\nimport swifter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-19T15:13:23.481059Z","iopub.execute_input":"2022-04-19T15:13:23.481601Z","iopub.status.idle":"2022-04-19T15:13:23.487121Z","shell.execute_reply.started":"2022-04-19T15:13:23.481552Z","shell.execute_reply":"2022-04-19T15:13:23.486485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_original = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train.csv\")\ntest_original = pd.read_csv(\"../input/tabular-playground-series-apr-2022/test.csv\")\ntrain_lables = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train_labels.csv\")\nsub= pd.read_csv(\"../input/tabular-playground-series-apr-2022/sample_submission.csv\", index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:12.691733Z","iopub.execute_input":"2022-04-19T14:43:12.69202Z","iopub.status.idle":"2022-04-19T14:43:23.627845Z","shell.execute_reply.started":"2022-04-19T14:43:12.69199Z","shell.execute_reply":"2022-04-19T14:43:23.626885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 256\nEPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:23.628969Z","iopub.execute_input":"2022-04-19T14:43:23.629164Z","iopub.status.idle":"2022-04-19T14:43:23.63349Z","shell.execute_reply.started":"2022-04-19T14:43:23.62914Z","shell.execute_reply":"2022-04-19T14:43:23.632698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DROP_SENSOR = False\nPCA_RUN = True\n\nSHIFT_VALUES = False ","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:23.635212Z","iopub.execute_input":"2022-04-19T14:43:23.635503Z","iopub.status.idle":"2022-04-19T14:43:23.645462Z","shell.execute_reply.started":"2022-04-19T14:43:23.635472Z","shell.execute_reply":"2022-04-19T14:43:23.644721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"* Sequence is a unique ID  and the sequence of activity \n* Subject is the person involved in the experiment \n* Step is the timeseries step taken \n* Sensors are the biological measurements taken during the step for each subject \n\nIn each sequence there are 60 time steps for each subject ","metadata":{}},{"cell_type":"markdown","source":"Target is seperate to training dataset, this uses the sequence ID as a unique key to join lables and train ","metadata":{}},{"cell_type":"code","source":"train_lables.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:23.646692Z","iopub.execute_input":"2022-04-19T14:43:23.646913Z","iopub.status.idle":"2022-04-19T14:43:23.66869Z","shell.execute_reply.started":"2022-04-19T14:43:23.646887Z","shell.execute_reply":"2022-04-19T14:43:23.667733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_original.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:23.669999Z","iopub.execute_input":"2022-04-19T14:43:23.670522Z","iopub.status.idle":"2022-04-19T14:43:23.689969Z","shell.execute_reply.started":"2022-04-19T14:43:23.670478Z","shell.execute_reply":"2022-04-19T14:43:23.688998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_original.merge(train_lables, how = \"left\", on = \"sequence\")\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:23.691728Z","iopub.execute_input":"2022-04-19T14:43:23.692035Z","iopub.status.idle":"2022-04-19T14:43:23.968312Z","shell.execute_reply.started":"2022-04-19T14:43:23.691983Z","shell.execute_reply":"2022-04-19T14:43:23.967395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Descriptive info","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:23.969595Z","iopub.execute_input":"2022-04-19T14:43:23.970411Z","iopub.status.idle":"2022-04-19T14:43:24.040574Z","shell.execute_reply.started":"2022-04-19T14:43:23.970365Z","shell.execute_reply":"2022-04-19T14:43:24.039643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:24.041747Z","iopub.execute_input":"2022-04-19T14:43:24.041972Z","iopub.status.idle":"2022-04-19T14:43:24.096645Z","shell.execute_reply.started":"2022-04-19T14:43:24.041945Z","shell.execute_reply":"2022-04-19T14:43:24.095956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( \"Length train: \",len(train))\nprint( \"Length test: \",len(test_original))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:24.098722Z","iopub.execute_input":"2022-04-19T14:43:24.100601Z","iopub.status.idle":"2022-04-19T14:43:24.105613Z","shell.execute_reply.started":"2022-04-19T14:43:24.100554Z","shell.execute_reply":"2022-04-19T14:43:24.104972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:24.106537Z","iopub.execute_input":"2022-04-19T14:43:24.107354Z","iopub.status.idle":"2022-04-19T14:43:25.101806Z","shell.execute_reply.started":"2022-04-19T14:43:24.10732Z","shell.execute_reply":"2022-04-19T14:43:25.100952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target EDA","metadata":{}},{"cell_type":"code","source":"sns.countplot(x= train[\"state\"].value_counts())\nplt.title(\"Target (state) distribution\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:25.103531Z","iopub.execute_input":"2022-04-19T14:43:25.103853Z","iopub.status.idle":"2022-04-19T14:43:25.26235Z","shell.execute_reply.started":"2022-04-19T14:43:25.103815Z","shell.execute_reply":"2022-04-19T14:43:25.261227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will concatenate test and train ","metadata":{}},{"cell_type":"code","source":"all_df = pd.concat([train,test_original],axis =0)\nall_df","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:25.26405Z","iopub.execute_input":"2022-04-19T14:43:25.264472Z","iopub.status.idle":"2022-04-19T14:43:25.416768Z","shell.execute_reply.started":"2022-04-19T14:43:25.264425Z","shell.execute_reply":"2022-04-19T14:43:25.415917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sensor data exploration \n## Histograms","metadata":{}},{"cell_type":"markdown","source":"### Zoomed in on outliers","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,12))\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    plt.subplot(4, 4, sensor+1)\n    plt.hist(train[ (train[\"state\"]==1) & \n               (train[sensor_name]<=train[sensor_name].quantile(q= 0.1) )][sensor_name],bins =50,alpha= 0.7)\n    plt.hist(train[ (train[\"state\"]==0) & \n               (train[sensor_name]<=train[sensor_name].quantile(q= 0.1) )][sensor_name],bins =50,alpha= 0.7)\n    plt.title(f\"{sensor_name} histogram\")\nplt.tight_layout(pad=3.08)\nplt.suptitle('Sensor Histograms by target(state) - less than 0.1 quantile')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:45.131714Z","iopub.execute_input":"2022-04-19T14:43:45.132158Z","iopub.status.idle":"2022-04-19T14:43:49.696619Z","shell.execute_reply.started":"2022-04-19T14:43:45.13212Z","shell.execute_reply":"2022-04-19T14:43:49.695706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,12))\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    plt.subplot(4, 4, sensor+1)\n    plt.hist(train[ (train[\"state\"]==1) & \n               (train[sensor_name]>=train[sensor_name].quantile(q= 0.9) )][sensor_name],bins =50,alpha= 0.7)\n    plt.hist(train[ (train[\"state\"]==0) & \n               (train[sensor_name]>=train[sensor_name].quantile(q= 0.9) )][sensor_name],bins =50,alpha= 0.7)\n    plt.title(f\"{sensor_name} histogram\")\nplt.tight_layout(pad=3.08)\nplt.suptitle('Sensor Histograms by target(state) - greater than 0.9 quantile')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:49.697882Z","iopub.execute_input":"2022-04-19T14:43:49.69812Z","iopub.status.idle":"2022-04-19T14:43:55.035287Z","shell.execute_reply.started":"2022-04-19T14:43:49.698093Z","shell.execute_reply":"2022-04-19T14:43:55.034476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear plots \nAs our data has 'steps' (timeseries) lets see if we can find any changes over time \\\nWe therefore need to groupby timesteps and use an aggregator (i.e. mean, median etc..)  ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,12))\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    plt.subplot(4, 4, sensor+1)\n    train[train[\"state\"]==1].groupby(\"step\").std()[sensor_name].plot()\n    train[train[\"state\"]==0].groupby(\"step\").std()[sensor_name].plot()\n    plt.title(f\"{sensor_name} lineplot\")\nplt.tight_layout(pad=4.08)\nplt.suptitle('Standard Deviation of sensor data groupby step vs Target (state)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:43:55.036404Z","iopub.execute_input":"2022-04-19T14:43:55.036652Z","iopub.status.idle":"2022-04-19T14:44:01.604545Z","shell.execute_reply.started":"2022-04-19T14:43:55.036624Z","shell.execute_reply":"2022-04-19T14:44:01.603705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,12))\nfor sensor in range(13):\n    sensor_name = f\"sensor_{sensor:02d}\"\n    plt.subplot(4, 4, sensor+1)\n    train[train[\"state\"]==1].groupby(\"step\").mean()[sensor_name].plot()\n    train[train[\"state\"]==0].groupby(\"step\").mean()[sensor_name].plot()\n    plt.title(f\"{sensor_name} lineplot\")\nplt.tight_layout(pad=3.08)\nplt.suptitle('Standard Deviation of sensor data groupby step vs Target (state)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:44:01.605599Z","iopub.execute_input":"2022-04-19T14:44:01.606245Z","iopub.status.idle":"2022-04-19T14:44:07.801086Z","shell.execute_reply.started":"2022-04-19T14:44:01.606216Z","shell.execute_reply":"2022-04-19T14:44:07.799643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **mean** and **standard deviation** clear distinction for some sensor columns - we should include this in our features","metadata":{}},{"cell_type":"markdown","source":"# Subjects ","metadata":{}},{"cell_type":"code","source":"print(\"subjects train:\", train[\"subject\"].nunique())\nprint(\"subjects test:\", test_original[\"subject\"].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:44:07.802487Z","iopub.execute_input":"2022-04-19T14:44:07.802776Z","iopub.status.idle":"2022-04-19T14:44:07.8304Z","shell.execute_reply.started":"2022-04-19T14:44:07.802741Z","shell.execute_reply":"2022-04-19T14:44:07.829598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Subjects in train and test:\")\nprint ([col for col in train[\"subject\"].unique() if col in test_original[\"subject\"].unique() ])","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:44:07.831499Z","iopub.execute_input":"2022-04-19T14:44:07.831718Z","iopub.status.idle":"2022-04-19T14:44:10.751736Z","shell.execute_reply.started":"2022-04-19T14:44:07.831693Z","shell.execute_reply":"2022-04-19T14:44:10.750833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are any overlapping subjects between test and train, we can therefore ignore \"subject\" in training ur models","metadata":{}},{"cell_type":"markdown","source":"## Sensor Correlation ","metadata":{}},{"cell_type":"code","source":"corr_sensor = pd.concat([train, test_original]).iloc[:,3:-1].corr()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:44:10.753105Z","iopub.execute_input":"2022-04-19T14:44:10.753482Z","iopub.status.idle":"2022-04-19T14:44:12.262154Z","shell.execute_reply.started":"2022-04-19T14:44:10.753436Z","shell.execute_reply":"2022-04-19T14:44:12.261265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (25,12))\nsns.heatmap(corr_sensor, cmap= \"Spectral\", vmin= -1, vmax= 1, annot = True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:44:12.263378Z","iopub.execute_input":"2022-04-19T14:44:12.263639Z","iopub.status.idle":"2022-04-19T14:44:13.244008Z","shell.execute_reply.started":"2022-04-19T14:44:12.263609Z","shell.execute_reply":"2022-04-19T14:44:13.243209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_sensor[corr_sensor>=0.45]","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:44:13.245081Z","iopub.execute_input":"2022-04-19T14:44:13.245301Z","iopub.status.idle":"2022-04-19T14:44:13.270335Z","shell.execute_reply.started":"2022-04-19T14:44:13.245273Z","shell.execute_reply":"2022-04-19T14:44:13.269521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional Features\n\nWe will include a few additional features and processes","metadata":{}},{"cell_type":"code","source":"train[train[\"state\"]==1].groupby(\"step\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_vals_0 = train[train[\"state\"]==0].groupby(\"step\")[\"sensor_02\"].mean()\nmean_vals_1 = train[train[\"state\"]==1].groupby(\"step\")[\"sensor_02\"].mean()\n\nstd_vals_0  = train[train[\"state\"]==1].groupby(\"step\")[\"sensor_02\"].std()\nstd_vals_1  = train[train[\"state\"]==1].groupby(\"step\")[\"sensor_02\"].std()\n\n#std_vals = train.groupby(\"step\")[\"sensor_02\"].std()\nstd_vals_1[:5]","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:11:59.54838Z","iopub.execute_input":"2022-04-19T15:11:59.549177Z","iopub.status.idle":"2022-04-19T15:11:59.857341Z","shell.execute_reply.started":"2022-04-19T15:11:59.549134Z","shell.execute_reply":"2022-04-19T15:11:59.856447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### z-score","metadata":{}},{"cell_type":"code","source":"%%time\ndef z_score_0(x):\n    z_score = (x[1]-  mean_vals_0[mean_vals_0.index ==x[0]].values) / std_vals_0[std_vals_0.index ==x[0]].values\n    return z_score[0]\n\ndef z_score_1(x):\n    z_score = (x[1]-  mean_vals_1[mean_vals_1.index ==x[0]].values) / std_vals_1[std_vals_1.index ==x[0]].values\n    return z_score[0]\n\n\ntrain[\"z_score_0\"] = train[[\"step\",\"sensor_02\"]].swifter.apply(z_score_0, axis =1 )\ntest_original[\"z_score_0\"] = test_original[[\"step\",\"sensor_02\"]].swifter.apply(z_score_0, axis =1 )\n\ntrain[\"z_score_1\"] = train[[\"step\",\"sensor_02\"]].swifter.apply(z_score_1, axis =1 )\ntest_original[\"z_score_1\"] = test_original[[\"step\",\"sensor_02\"]].swifter.apply(z_score_1, axis =1 )\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:13:49.890585Z","iopub.execute_input":"2022-04-19T15:13:49.891321Z","iopub.status.idle":"2022-04-19T15:25:11.399792Z","shell.execute_reply.started":"2022-04-19T15:13:49.891283Z","shell.execute_reply":"2022-04-19T15:25:11.398673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shift Values","metadata":{}},{"cell_type":"code","source":"sensor_cols = [col for col in train.columns if \"sensor\" in col]\n\ndef shift_vals(df):\n    for col in sensor_cols:\n        df[f\"{col}_shift1\"] =df.groupby([\"sequence\",\"subject\"])[col].shift(1).bfill()\n        df[col + '_diff1'] = df[col] - df[f\"{col}_shift1\"]    \n\n    return df\n\nif SHIFT_VALUES:\n    print(\"Shifting\")\n    shift_vals(train_original)\n    shift_vals(test_original)\n    train_original","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:35.170986Z","iopub.execute_input":"2022-04-19T15:26:35.171727Z","iopub.status.idle":"2022-04-19T15:26:35.17836Z","shell.execute_reply.started":"2022-04-19T15:26:35.171674Z","shell.execute_reply":"2022-04-19T15:26:35.177485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_original.pivot(index = \"sequence\", columns =\"step\", values = sensor_cols)\ntest = test_original.pivot(index = \"sequence\", columns =\"step\", values = sensor_cols)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:35.318053Z","iopub.execute_input":"2022-04-19T15:26:35.318647Z","iopub.status.idle":"2022-04-19T15:26:36.155935Z","shell.execute_reply.started":"2022-04-19T15:26:35.318607Z","shell.execute_reply":"2022-04-19T15:26:36.154969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(df):\n    \n    for col in sensor_cols:\n        df[f\"mean_{col}\"] = df[col].mean(axis = 1)\n        df[f\"median_{col}\"] = df[col].median(axis = 1)\n        df[f\"std_{col}\"] = df[col].std(axis = 1)\n#         df[f\"variance_{col}\"] = df[col].std(axis = 1)\n#         df[f\"max_{col}\"] = df[col].max(axis = 1)\n#         df[f\"min_{col}\"] = df[col].min(axis = 1)\n#         df[f\"max-min_{col}\"] = df[col].max(axis = 1) - df[col].min(axis = 1)\n#         df[f\"q50_{col}\"] = df[col].quantile(q= 0.5, axis =1)\n#         df[f\"q25_{col}\"] = df[col].quantile(q= 0.25, axis =1) \n#         df[f\"q75_{col}\"] = df[col].quantile(q= 0.75, axis =1)\n#         df[f\"q95_{col}\"] = df[col].quantile(q= 0.95, axis =1)\n#         df[f\"q99_{col}\"] = df[col].quantile(q= 0.99, axis =1)\n#         df[f\"skew_{col}\"] =df[col].skew( axis =1)\n    return df\n\nadd_features(train)\nadd_features(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:36.157702Z","iopub.execute_input":"2022-04-19T15:26:36.157951Z","iopub.status.idle":"2022-04-19T15:26:43.745699Z","shell.execute_reply.started":"2022-04-19T15:26:36.157922Z","shell.execute_reply":"2022-04-19T15:26:43.745118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop the base sensor data\nWe will play around with dropping this data as we have numerous additional features ","metadata":{}},{"cell_type":"code","source":"if DROP_SENSOR:\n    train = train.drop(sensor_cols,axis =1)\n    test = test.drop(sensor_cols,axis =1)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:43.746879Z","iopub.execute_input":"2022-04-19T15:26:43.747262Z","iopub.status.idle":"2022-04-19T15:26:43.750868Z","shell.execute_reply.started":"2022-04-19T15:26:43.747234Z","shell.execute_reply":"2022-04-19T15:26:43.750337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = len(train.columns)\nprint([col for col in train.columns])","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:43.752548Z","iopub.execute_input":"2022-04-19T15:26:43.752792Z","iopub.status.idle":"2022-04-19T15:26:43.766139Z","shell.execute_reply.started":"2022-04-19T15:26:43.752764Z","shell.execute_reply":"2022-04-19T15:26:43.765239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"X = train\ny = train_lables[\"state\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:43.767366Z","iopub.execute_input":"2022-04-19T15:26:43.767596Z","iopub.status.idle":"2022-04-19T15:26:43.961524Z","shell.execute_reply.started":"2022-04-19T15:26:43.767544Z","shell.execute_reply":"2022-04-19T15:26:43.960785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler= StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_test_s = scaler.transform(X_test)\ntest_s = scaler.transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:43.962821Z","iopub.execute_input":"2022-04-19T15:26:43.963205Z","iopub.status.idle":"2022-04-19T15:26:44.357427Z","shell.execute_reply.started":"2022-04-19T15:26:43.963173Z","shell.execute_reply":"2022-04-19T15:26:44.356595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = models.Sequential()\n    model.add(layers.Input(shape=(X.shape[1],)))\n    model.add(layers.Dense(600,activation = \"selu\"))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(600,activation = \"selu\"))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(600,activation = \"selu\"))\n    model.add(layers.Dense(1,activation = \"sigmoid\"))\n    return model \n\nmodel = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:44.358514Z","iopub.execute_input":"2022-04-19T15:26:44.358957Z","iopub.status.idle":"2022-04-19T15:26:44.541359Z","shell.execute_reply.started":"2022-04-19T15:26:44.358925Z","shell.execute_reply":"2022-04-19T15:26:44.54045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:44.542571Z","iopub.execute_input":"2022-04-19T15:26:44.542766Z","iopub.status.idle":"2022-04-19T15:26:44.551197Z","shell.execute_reply.started":"2022-04-19T15:26:44.542742Z","shell.execute_reply":"2022-04-19T15:26:44.549825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=\"AUC\")\nmodel.fit(X_train_s,y_train,epochs= EPOCHS, \n          callbacks= [callbacks.EarlyStopping(patience=20,monitor='val_loss', mode = \"min\") ,\n                      callbacks.ReduceLROnPlateau(monitor=\"val_loss\",patience = 20, factor= 0.001)],\n          validation_data=(X_test_s,y_test), batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:26:44.552532Z","iopub.execute_input":"2022-04-19T15:26:44.552957Z","iopub.status.idle":"2022-04-19T15:27:40.032384Z","shell.execute_reply.started":"2022-04-19T15:26:44.552928Z","shell.execute_reply":"2022-04-19T15:27:40.031724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.history.history\nhistory = pd.DataFrame(history)\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:27:40.034411Z","iopub.execute_input":"2022-04-19T15:27:40.035287Z","iopub.status.idle":"2022-04-19T15:27:40.053024Z","shell.execute_reply.started":"2022-04-19T15:27:40.035241Z","shell.execute_reply":"2022-04-19T15:27:40.052151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = model.predict(X_test_s)\nval_preds","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:27:40.05446Z","iopub.execute_input":"2022-04-19T15:27:40.054956Z","iopub.status.idle":"2022-04-19T15:28:08.32874Z","shell.execute_reply.started":"2022-04-19T15:27:40.054913Z","shell.execute_reply":"2022-04-19T15:28:08.327829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preds = model.predict(X_train_s)\ntrain_preds","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:28:08.330175Z","iopub.execute_input":"2022-04-19T15:28:08.330804Z","iopub.status.idle":"2022-04-19T15:28:09.552914Z","shell.execute_reply.started":"2022-04-19T15:28:08.330752Z","shell.execute_reply":"2022-04-19T15:28:09.552072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Validation AUC:\" , roc_auc_score(y_test, val_preds))\nprint(\"Intrinsic AUC:\", roc_auc_score(y_train, train_preds))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:28:09.55432Z","iopub.execute_input":"2022-04-19T15:28:09.554805Z","iopub.status.idle":"2022-04-19T15:28:09.574913Z","shell.execute_reply.started":"2022-04-19T15:28:09.554761Z","shell.execute_reply":"2022-04-19T15:28:09.573862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history[[\"loss\",\"val_loss\"]].plot(figsize = (20,8))\nplt.title(\"Training vs Validation Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:28:09.576391Z","iopub.execute_input":"2022-04-19T15:28:09.576917Z","iopub.status.idle":"2022-04-19T15:28:09.827453Z","shell.execute_reply.started":"2022-04-19T15:28:09.576873Z","shell.execute_reply":"2022-04-19T15:28:09.826522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history[[\"auc\",\"val_auc\"]].plot(figsize = (20,8))\nplt.title(\"Training vs Validation AUC\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:28:09.828687Z","iopub.execute_input":"2022-04-19T15:28:09.828903Z","iopub.status.idle":"2022-04-19T15:28:10.054548Z","shell.execute_reply.started":"2022-04-19T15:28:09.828878Z","shell.execute_reply":"2022-04-19T15:28:10.053721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"FOLDS = 5\nkfold = GroupKFold(n_splits = FOLDS)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:28:10.055723Z","iopub.execute_input":"2022-04-19T15:28:10.055953Z","iopub.status.idle":"2022-04-19T15:28:10.0603Z","shell.execute_reply.started":"2022-04-19T15:28:10.055925Z","shell.execute_reply":"2022-04-19T15:28:10.059624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_original","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:28:10.061318Z","iopub.execute_input":"2022-04-19T15:28:10.061696Z","iopub.status.idle":"2022-04-19T15:28:10.095229Z","shell.execute_reply.started":"2022-04-19T15:28:10.061664Z","shell.execute_reply":"2022-04-19T15:28:10.094631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_val(X,y):\n    auc_cv = []\n    preds = []\n\n    for fold, (train_idx, val_idx) in enumerate (kfold.split(X,y, groups =train_original.sequence.unique())):\n\n        print(\"\\n\",\"#\"*10, f\"Fold {fold+1}\",\"#\"*10)\n        X_train, X_test = X.iloc[train_idx] , X.iloc[val_idx]\n        y_train , y_test = y[train_idx], y[val_idx]\n\n        scaler= StandardScaler()\n        X_train_s = scaler.fit_transform(X_train)\n        X_test_s = scaler.transform(X_test)\n        test_s = scaler.transform(test)\n\n        model = build_model()\n        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=\"AUC\")\n        model.fit(X_train_s,y_train,epochs= EPOCHS, \n                  callbacks= [callbacks.EarlyStopping(patience=10,monitor='val_auc', mode = \"max\") ,\n                              callbacks.ReduceLROnPlateau(monitor=\"val_auc\",patience = 10, factor= 0.001)],\n                  validation_data=(X_test_s,y_test), batch_size = BATCH_SIZE)\n\n        auc = roc_auc_score(y_test, (model.predict(X_test_s, batch_size=BATCH_SIZE)))\n        print(\"\\n Validation AUC:\" , auc)\n\n        auc_cv.append(auc)\n        preds.append(model.predict(test_s, batch_size=BATCH_SIZE).squeeze())\n\n    print(\"FINAL AUC: \", np.mean(auc_cv))\n    \n    return auc_cv, preds \n\nauc_cv, preds = cross_val(X,y)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T15:37:41.353019Z","iopub.execute_input":"2022-04-19T15:37:41.353315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = np.sum(preds,axis =0)/FOLDS\nsub[\"state\"] = final_preds\nsub.to_csv(\"submission.csv\")\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,8))\nsns.histplot(sub[\"state\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}