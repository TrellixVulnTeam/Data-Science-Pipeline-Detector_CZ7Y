{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground Series - April 2022","metadata":{}},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-competitions/kaggle/33104/logos/header.png)","metadata":{}},{"cell_type":"markdown","source":"## **Steps:**\n* Objectives\n* Data Understanding\n* Data Preprocessing\n* Model Generation\n* Optimization\n* Predictions and Submission","metadata":{}},{"cell_type":"markdown","source":"# **Objectives**\n* Objective is to determine what state a participant was in from the sensor data, a time series classification problem.","metadata":{}},{"cell_type":"markdown","source":"# **Data Understanding**\n\n* Sixty-second sequences of biological sensor data recorded from several hundred participants who could have been in either of two possible activity states\n\n**Files and Field Descriptions**\n\n* train.csv - the training set, comprising ~26,000 60-second recordings of thirteen biological sensors for almost one thousand experimental participants\n    1. sequence - a unique id for each sequence\n    2. subject - a unique id for the subject in the experiment\n    3. step - time step of the recording, in one second intervals\n    4. sensor_00 - sensor_12 - the value for each of the thirteen sensors at that time step\n\n\n* train_labels.csv - the class label for each sequence.\n    1. sequence - the unique id for each sequence.\n    2. state - the state associated to each sequence. This is the target which you are trying to predict.\n    \n\n* test.csv - the test set. For each of the ~12,000 sequences, you should predict a value for that sequence's state.\n* sample_submission.csv - a sample submission file in the correct format.","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import accuracy_score,f1_score,roc_auc_score\n\nimport optuna\n\nfrom warnings import simplefilter\nsimplefilter(\"ignore\")\n\nprint(\"Imported Necessary Libraries\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:02.908919Z","iopub.execute_input":"2022-04-13T15:44:02.909637Z","iopub.status.idle":"2022-04-13T15:44:02.921576Z","shell.execute_reply.started":"2022-04-13T15:44:02.909599Z","shell.execute_reply":"2022-04-13T15:44:02.920358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading file names\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:03.114886Z","iopub.execute_input":"2022-04-13T15:44:03.115631Z","iopub.status.idle":"2022-04-13T15:44:03.124434Z","shell.execute_reply.started":"2022-04-13T15:44:03.115587Z","shell.execute_reply":"2022-04-13T15:44:03.123289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting files to data frames\ntrain_labels_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/train_labels.csv')\ntrain_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:03.303227Z","iopub.execute_input":"2022-04-13T15:44:03.30399Z","iopub.status.idle":"2022-04-13T15:44:10.754581Z","shell.execute_reply.started":"2022-04-13T15:44:03.303942Z","shell.execute_reply":"2022-04-13T15:44:10.753862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample of train_labels data\ntrain_labels_data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:10.756108Z","iopub.execute_input":"2022-04-13T15:44:10.756492Z","iopub.status.idle":"2022-04-13T15:44:10.765626Z","shell.execute_reply.started":"2022-04-13T15:44:10.756454Z","shell.execute_reply":"2022-04-13T15:44:10.764992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample of train\ntrain_data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:10.766766Z","iopub.execute_input":"2022-04-13T15:44:10.767109Z","iopub.status.idle":"2022-04-13T15:44:10.862129Z","shell.execute_reply.started":"2022-04-13T15:44:10.767083Z","shell.execute_reply":"2022-04-13T15:44:10.861381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test data sample\ntest_data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:10.863861Z","iopub.execute_input":"2022-04-13T15:44:10.86423Z","iopub.status.idle":"2022-04-13T15:44:10.910949Z","shell.execute_reply.started":"2022-04-13T15:44:10.864201Z","shell.execute_reply":"2022-04-13T15:44:10.910077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data shapes\nprint(f'Train labels data shape: {train_labels_data.shape}')\nprint(f'Train data shape: {train_data.shape}')\nprint(f'Test data shape: {test_data.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:10.912505Z","iopub.execute_input":"2022-04-13T15:44:10.913038Z","iopub.status.idle":"2022-04-13T15:44:10.920979Z","shell.execute_reply.started":"2022-04-13T15:44:10.912994Z","shell.execute_reply":"2022-04-13T15:44:10.919739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train data info\ntrain_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:10.922305Z","iopub.execute_input":"2022-04-13T15:44:10.92264Z","iopub.status.idle":"2022-04-13T15:44:11.00887Z","shell.execute_reply.started":"2022-04-13T15:44:10.922601Z","shell.execute_reply":"2022-04-13T15:44:11.007457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Memory reduction of features\ntrain_data[train_data.select_dtypes(np.float64).columns] = train_data.select_dtypes(np.float64).astype(np.float32)\ntrain_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:11.010691Z","iopub.execute_input":"2022-04-13T15:44:11.011088Z","iopub.status.idle":"2022-04-13T15:44:11.659271Z","shell.execute_reply.started":"2022-04-13T15:44:11.011041Z","shell.execute_reply":"2022-04-13T15:44:11.658049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic Statistics of the train data\ntrain_data.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:11.66043Z","iopub.execute_input":"2022-04-13T15:44:11.660766Z","iopub.status.idle":"2022-04-13T15:44:12.557656Z","shell.execute_reply.started":"2022-04-13T15:44:11.660737Z","shell.execute_reply":"2022-04-13T15:44:12.556631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label chart\nplt.figure(figsize=(6,5))\nax = sns.countplot(data=train_labels_data,x='state')\nax.bar_label(ax.containers[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:12.558895Z","iopub.execute_input":"2022-04-13T15:44:12.559107Z","iopub.status.idle":"2022-04-13T15:44:12.735311Z","shell.execute_reply.started":"2022-04-13T15:44:12.559082Z","shell.execute_reply":"2022-04-13T15:44:12.734443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target classes/labels are balanced as there is minor difference between them","metadata":{}},{"cell_type":"code","source":"SEED = 5 # Seed value for reproducing he same data","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:12.739027Z","iopub.execute_input":"2022-04-13T15:44:12.739635Z","iopub.status.idle":"2022-04-13T15:44:12.744205Z","shell.execute_reply.started":"2022-04-13T15:44:12.739589Z","shell.execute_reply":"2022-04-13T15:44:12.74304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box Plot\n\nrandom.seed(SEED) # Set the seed for reproducibilty\nrandom_sequence = random.randint(train_data['sequence'].min(), train_data['sequence'].max())\n\ndf = train_data[train_data['sequence']==random_sequence]\n\nSENSOR_COUNT = 13 # Thirteen sensors used for measurements\nsubject_number = df['subject'].unique()[0] # Subject numbers seems unique for particlar sequence\n\nplt.figure(figsize=(16,14))\nfor i in range(SENSOR_COUNT):\n    plt.subplot(6,3,i+1)\n    sensor = 'sensor_'+str(i).zfill(2)\n    sns.boxplot(data=df,y=sensor)\nplt.suptitle(f'Box Plots of Sensors:{random_sequence} and Subject: {subject_number}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:12.745754Z","iopub.execute_input":"2022-04-13T15:44:12.746125Z","iopub.status.idle":"2022-04-13T15:44:13.835563Z","shell.execute_reply.started":"2022-04-13T15:44:12.746091Z","shell.execute_reply":"2022-04-13T15:44:13.834346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KDE Plots\n\nrandom.seed(SEED) # Set the seed for reproducibilty\nrandom_sequence = random.randint(train_data['sequence'].min(), train_data['sequence'].max())\n\ndf = train_data[train_data['sequence']==random_sequence]\n\nSENSOR_COUNT = 13 # Thirteen sensors used for measurements\nsubject_number = df['subject'].unique()[0] # Subject numbers seems unique for particlar sequence\n\nplt.figure(figsize=(16,24))\nfor i in range(SENSOR_COUNT):\n    plt.subplot(6,3,i+1,aspect='auto')\n    sensor = 'sensor_'+str(i).zfill(2)\n    sns.kdeplot(data=df,x=sensor)\nplt.suptitle(f'Kde Plots of Sensors:{random_sequence} and Subject: {subject_number}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:13.837165Z","iopub.execute_input":"2022-04-13T15:44:13.837482Z","iopub.status.idle":"2022-04-13T15:44:15.854511Z","shell.execute_reply.started":"2022-04-13T15:44:13.83744Z","shell.execute_reply":"2022-04-13T15:44:15.853359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time series chart for a particular sequence\n\nrandom.seed(SEED) # Set the seed for reproducibilty\nrandom_sequence = random.randint(train_data['sequence'].min(), train_data['sequence'].max())\n\ndf = train_data[train_data['sequence']==random_sequence]\n\nSENSOR_COUNT = 13 # Thirteen sensors used for measurements\nsubject_number = df['subject'].unique()[0] # Subject numbers seems unique for particlar sequence\n\nplt.figure(figsize=(16,12))\nfor i in range(SENSOR_COUNT):\n    plt.subplot(6,3,i+1)\n    sensor = 'sensor_'+str(i).zfill(2)\n    sns.lineplot(data=df,x='step',y=sensor)\nplt.suptitle(f'Time Series Chart of Sensors for Sequence:{random_sequence} and Subject: {subject_number}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:15.856241Z","iopub.execute_input":"2022-04-13T15:44:15.856587Z","iopub.status.idle":"2022-04-13T15:44:17.793168Z","shell.execute_reply.started":"2022-04-13T15:44:15.856522Z","shell.execute_reply":"2022-04-13T15:44:17.791998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time series chart for 5 random sequences\n\nrandom.seed(SEED) # Set the seed for reproducibilty\nrandom_sequence = [] # Empty list for random sequence\n\nfor i in range(5):\n    random_sequence.append(random.randint(train_data['sequence'].min(), train_data['sequence'].max()))\n\ndf = pd.DataFrame(train_data[train_data['sequence'].isin(random_sequence)])\n\nSENSOR_COUNT = 13 # Thirteen sensors used for measurements\n\nplt.figure(figsize=(26,24))\n\nindex=0\nfor i in range(SENSOR_COUNT):   \n    for j,sequence in enumerate(random_sequence):\n        sensor = 'sensor_'+str(i).zfill(2)\n        plt.subplot(13,5,index+j+1)\n        sns.lineplot(data=df[df['sequence']==sequence],x='step',y=sensor)\n    index=index+5\n\nplt.suptitle(f'Time Series Chart of Sensors for Sequence:{random_sequence}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:17.79443Z","iopub.execute_input":"2022-04-13T15:44:17.794736Z","iopub.status.idle":"2022-04-13T15:44:26.033188Z","shell.execute_reply.started":"2022-04-13T15:44:17.794705Z","shell.execute_reply":"2022-04-13T15:44:26.032285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"My understanding from the charts are that there is no particular relationship exits across sensors and seems they are independent in nature.","metadata":{}},{"cell_type":"code","source":"# Scatter plot between Subject and Sensor values\nplt.figure(figsize=(16,12))\nfor i in range(SENSOR_COUNT):\n    sensor = 'sensor_'+str(i).zfill(2)\n    plt.subplot(6,3,i+1)\n    sns.scatterplot(x=train_data.subject,y=train_data[sensor],hue=train_labels_data.state,palette='Dark2')\nplt.suptitle('Scatter Plot between Subject and Sensor Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:26.034808Z","iopub.execute_input":"2022-04-13T15:44:26.03526Z","iopub.status.idle":"2022-04-13T15:44:53.668244Z","shell.execute_reply.started":"2022-04-13T15:44:26.03522Z","shell.execute_reply":"2022-04-13T15:44:53.660527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot between Sequence and Sensor values\nplt.figure(figsize=(16,12))\nfor i in range(SENSOR_COUNT):\n    sensor = 'sensor_'+str(i).zfill(2)\n    plt.subplot(6,3,i+1)\n    sns.scatterplot(x=train_data.sequence,y=train_data[sensor],hue=train_labels_data.state,palette='Dark2')\nplt.suptitle('Scatter Plot between Sequence and Sensor Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:44:53.672585Z","iopub.execute_input":"2022-04-13T15:44:53.673791Z","iopub.status.idle":"2022-04-13T15:45:20.829402Z","shell.execute_reply.started":"2022-04-13T15:44:53.673708Z","shell.execute_reply":"2022-04-13T15:45:20.828057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Sensor_04, Sensor_05, Sensor_10 and Sensor_12 values seems to be scattered more , compared to others ","metadata":{}},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"# Checking for missing values\ntrain_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:20.831211Z","iopub.execute_input":"2022-04-13T15:45:20.831538Z","iopub.status.idle":"2022-04-13T15:45:20.884914Z","shell.execute_reply.started":"2022-04-13T15:45:20.831501Z","shell.execute_reply":"2022-04-13T15:45:20.88365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform the values with grouping strategy\nagg_strategy = ['mean','median','sum','max','var']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:20.886463Z","iopub.execute_input":"2022-04-13T15:45:20.886864Z","iopub.status.idle":"2022-04-13T15:45:20.893188Z","shell.execute_reply.started":"2022-04-13T15:45:20.88682Z","shell.execute_reply":"2022-04-13T15:45:20.892055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping the data thorugh 'sequence' and 'subject'\ngroup_df_train = train_data.groupby(['sequence','subject']).agg(agg_strategy)\ngroup_df_train.columns = [\"_\".join(x) for x in group_df_train.columns.ravel()]\ngroup_df_train = group_df_train.reset_index()\ngroup_df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:20.894763Z","iopub.execute_input":"2022-04-13T15:45:20.895585Z","iopub.status.idle":"2022-04-13T15:45:23.183722Z","shell.execute_reply.started":"2022-04-13T15:45:20.895507Z","shell.execute_reply":"2022-04-13T15:45:23.182814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features to drop\ncols_to_drop = ['sequence','subject']\nfor col in group_df_train.columns:\n    if 'step' in col:\n        cols_to_drop.append(col)\ncols_to_drop","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:23.184937Z","iopub.execute_input":"2022-04-13T15:45:23.185166Z","iopub.status.idle":"2022-04-13T15:45:23.194843Z","shell.execute_reply.started":"2022-04-13T15:45:23.185138Z","shell.execute_reply":"2022-04-13T15:45:23.193872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final features and target\nX = group_df_train.drop(cols_to_drop,axis=1)\ny = train_labels_data['state']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:23.196795Z","iopub.execute_input":"2022-04-13T15:45:23.197516Z","iopub.status.idle":"2022-04-13T15:45:23.211504Z","shell.execute_reply.started":"2022-04-13T15:45:23.197461Z","shell.execute_reply":"2022-04-13T15:45:23.210778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting test data to group form\ngroup_df_test = test_data.groupby(['sequence','subject']).agg(agg_strategy)\ngroup_df_test.columns = [\"_\".join(x) for x in group_df_test.columns.ravel()]\ngroup_df_test = group_df_test.reset_index()\n\nX_test_sequence = group_df_test.sequence # preserving sequence for adding in submission file\nX_test = group_df_test.drop(cols_to_drop,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:23.21553Z","iopub.execute_input":"2022-04-13T15:45:23.217873Z","iopub.status.idle":"2022-04-13T15:45:23.992306Z","shell.execute_reply.started":"2022-04-13T15:45:23.217829Z","shell.execute_reply":"2022-04-13T15:45:23.991276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data to train and test data\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.2,random_state=42,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:23.993622Z","iopub.execute_input":"2022-04-13T15:45:23.993842Z","iopub.status.idle":"2022-04-13T15:45:24.003378Z","shell.execute_reply.started":"2022-04-13T15:45:23.993818Z","shell.execute_reply":"2022-04-13T15:45:24.002395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shapes of train and test data\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_valid shape: {X_valid.shape}')\nprint(f'y_valid shape: {y_valid.shape}')\nprint(f'X_test shape: {X_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:24.00476Z","iopub.execute_input":"2022-04-13T15:45:24.00511Z","iopub.status.idle":"2022-04-13T15:45:24.012594Z","shell.execute_reply.started":"2022-04-13T15:45:24.005071Z","shell.execute_reply":"2022-04-13T15:45:24.011917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Generation**","metadata":{}},{"cell_type":"code","source":"# creating a function for model generation\ndef model_gen(model,model_name,X_train,X_valid,y_train,y_valid):\n    \n    mod = model\n    mod.fit(X_train,y_train)\n    \n    y_pred_train = mod.predict(X_train)\n    y_pred_valid = mod.predict(X_valid)\n    y_pred_train_prob = mod.predict_proba(X_train)\n    y_pred_valid_prob = mod.predict_proba(X_valid)\n    \n    score = cross_val_score(mod,X_train,y_train,cv=5,scoring='roc_auc')\n    \n    print(f'Model: {model_name}')\n    print('Training Data Scores:')\n    print(f\"Train data accuracy score: {round(accuracy_score(y_train,y_pred_train),4)}\")\n    print(f\"Train data f1 score: {round(f1_score(y_train,y_pred_train),4)}\")\n    print(f\"Area under the ROC curve for Train data Probability Predictions: {round(roc_auc_score(y_train,y_pred_train_prob[:,1]),4)}\")\n    \n    print('\\n')\n    print('Validation Data Scores:')\n    print(f\"Validation data accuracy score: {round(accuracy_score(y_valid,y_pred_valid),4)}\")\n    print(f\"Validation data f1 score: {round(f1_score(y_valid,y_pred_valid),4)}\")\n    print(f\"Area under the ROC curve for Validation data Probability Predictions: {round(roc_auc_score(y_valid,y_pred_valid_prob[:,1]),4)}\")\n   \n    print('\\n')\n    print('Cross Validation Scores on metric roc_auc:')\n    print(f'Mean value of scores: {round(np.mean(score),4)}')\n    print(f'Standard Deviation of scores: {round(np.std(score),4)}')\n    print('\\n********************************************************************************\\n')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:24.013721Z","iopub.execute_input":"2022-04-13T15:45:24.014161Z","iopub.status.idle":"2022-04-13T15:45:24.025605Z","shell.execute_reply.started":"2022-04-13T15:45:24.014131Z","shell.execute_reply":"2022-04-13T15:45:24.02462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting model scores of Random Forest, XGB and LGBM\nmodels = {'Random Forest Classifier':RandomForestClassifier(random_state=42),'XGB Classifier':XGBClassifier(random_state=42,verbosity=0),'LGBM Classifier':LGBMClassifier(random_state=42)}\n\nfor model_name,model in models.items():\n    model_name = model_gen(model=model,model_name=model_name,X_train=X_train,X_valid=X_valid,y_train=y_train,y_valid=y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:45:24.02682Z","iopub.execute_input":"2022-04-13T15:45:24.027061Z","iopub.status.idle":"2022-04-13T15:48:22.50888Z","shell.execute_reply.started":"2022-04-13T15:45:24.027032Z","shell.execute_reply":"2022-04-13T15:48:22.508048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using LGBM classifier for further tuning, as it seems not overfitting.","metadata":{}},{"cell_type":"markdown","source":"# **Optimization**","metadata":{}},{"cell_type":"code","source":"# Function for creating study\ndef train_model_for_study(model,X,y):\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,\\\n                                                          random_state=42,shuffle=False)\n    model.fit(X_train, \n        y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)], \n        verbose=-1\n    )\n    \n    y_pred_prob = model.predict_proba(X_valid)\n    return roc_auc_score(y_valid,y_pred_prob[:,1])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:48:22.510184Z","iopub.execute_input":"2022-04-13T15:48:22.511013Z","iopub.status.idle":"2022-04-13T15:48:22.518525Z","shell.execute_reply.started":"2022-04-13T15:48:22.510957Z","shell.execute_reply":"2022-04-13T15:48:22.517329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Objective function\ndef objective_lgbc(trial):\n    \n    params = {\n        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 10000),\n        'num_leaves':trial.suggest_int(\"num_leaves\",25,100),\n        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True),\n        'max_depth': trial.suggest_int(\"max_depth\", 2, 15),\n        'min_child_samples':trial.suggest_int(\"min_child_samples\",10,50),\n        'n_jobs':trial.suggest_int(\"n_jobs\",1,10)\n    }\n    \n    model = LGBMClassifier(\n        boosting_type='gbdt',\n        objective='binary',\n        random_state=42,\n    )\n    return train_model_for_study(model,X,y)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:48:22.523144Z","iopub.execute_input":"2022-04-13T15:48:22.52338Z","iopub.status.idle":"2022-04-13T15:48:22.537095Z","shell.execute_reply.started":"2022-04-13T15:48:22.523353Z","shell.execute_reply":"2022-04-13T15:48:22.535922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create study\nsampler = optuna.samplers.TPESampler(seed=1)\nstudy_lgbc = optuna.create_study(direction=\"maximize\",sampler = sampler,study_name='LGBC Optimizer')\nstudy_lgbc.optimize(objective_lgbc, n_trials=10)\nstudy_lgbc.best_params","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:48:22.539006Z","iopub.execute_input":"2022-04-13T15:48:22.539586Z","iopub.status.idle":"2022-04-13T15:48:44.814947Z","shell.execute_reply.started":"2022-04-13T15:48:22.539461Z","shell.execute_reply":"2022-04-13T15:48:44.813763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predictions and Submission**","metadata":{}},{"cell_type":"code","source":"# Final model with optimized parameters (LGBMC)\nfinal_model_lgbc = LGBMClassifier(boosting_type='gbdt',objective='binary',n_estimators=4228,\n                                  num_leaves=79,learning_rate=0.010005268542378308,\\\n                                  max_depth=6,min_child_samples=16,n_jobs=1)\n\nfinal_model_lgbc.fit(X,y,verbose=-1)\n\n#Final prediction probabilities\ny_pred_test_p_lgbc = final_model_lgbc.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:48:44.818457Z","iopub.execute_input":"2022-04-13T15:48:44.819473Z","iopub.status.idle":"2022-04-13T15:49:58.517906Z","shell.execute_reply.started":"2022-04-13T15:48:44.819434Z","shell.execute_reply":"2022-04-13T15:49:58.516971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Importance plot\nplt.figure(figsize=(16,20))\nsns.barplot(y=X_train.columns,x=final_model_lgbc.feature_importances_)\nplt.title('Feature Importance Chart')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:49:58.519407Z","iopub.execute_input":"2022-04-13T15:49:58.519694Z","iopub.status.idle":"2022-04-13T15:49:59.635116Z","shell.execute_reply.started":"2022-04-13T15:49:58.519663Z","shell.execute_reply":"2022-04-13T15:49:59.634297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submission file\nsubmission = pd.DataFrame({'sequence':X_test_sequence,'state':y_pred_test_p_lgbc[:,1]})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T15:49:59.636396Z","iopub.execute_input":"2022-04-13T15:49:59.636851Z","iopub.status.idle":"2022-04-13T15:49:59.685642Z","shell.execute_reply.started":"2022-04-13T15:49:59.63681Z","shell.execute_reply":"2022-04-13T15:49:59.684727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Thank You**","metadata":{}}]}