{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.style as style \nstyle.use('ggplot')\nimport random\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import accuracy_score,f1_score,roc_auc_score\n\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats import gaussian_kde\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T17:14:25.669789Z","iopub.execute_input":"2022-04-26T17:14:25.670228Z","iopub.status.idle":"2022-04-26T17:14:25.686065Z","shell.execute_reply.started":"2022-04-26T17:14:25.670196Z","shell.execute_reply":"2022-04-26T17:14:25.685434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"/kaggle/input/tabular-playground-series-apr-2022/\"\ntrainFeatures = pd.read_csv(PATH+\"train.csv\")\ntestData = pd.read_csv(PATH+\"test.csv\")\ntrainLabels = pd.read_csv(PATH+\"train_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:18:37.721881Z","iopub.execute_input":"2022-04-26T17:18:37.722467Z","iopub.status.idle":"2022-04-26T17:18:45.599843Z","shell.execute_reply.started":"2022-04-26T17:18:37.72243Z","shell.execute_reply":"2022-04-26T17:18:45.598955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Merging labels with sensor data\ntrainData = trainFeatures.merge(trainLabels, on = \"sequence\")\n\ndef exploreDataset(df):\n    df_copy = df.copy()\n    print(\"The {} contains {} rows with {} N/A values\".format(\"df\", df.shape[0], df_copy.isna().sum()))\n    \n\nexploreDataset(trainData)\nsensorData = [col for col in trainData.columns if col.startswith(\"sensor\")]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:18:51.203444Z","iopub.execute_input":"2022-04-26T17:18:51.203736Z","iopub.status.idle":"2022-04-26T17:18:51.599872Z","shell.execute_reply.started":"2022-04-26T17:18:51.203705Z","shell.execute_reply":"2022-04-26T17:18:51.599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation Plot for all the sensors in given dataset**","metadata":{}},{"cell_type":"code","source":"def drawCorrelationMatrix(df, method = 'pearson'):\n    \n    cmap = sns.diverging_palette(250, 15, s=75, l=40,\n                                 n=9, center=\"light\", as_cmap=True)\n    matrix = df.corr(method = method)\n    mask = np.triu(np.ones_like(matrix, dtype=bool))\n    plt.figure(figsize=(16,12))\n    plt.title(\"{} correlation heatmap between all sensors\".format(method))\n    fig = sns.heatmap(matrix, mask=mask, center=0, annot=True,\n                 fmt='.2f', square=True, cmap=cmap)\n    \ndrawCorrelationMatrix(trainData[sensorData])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:14:35.185537Z","iopub.execute_input":"2022-04-26T17:14:35.18653Z","iopub.status.idle":"2022-04-26T17:14:37.009912Z","shell.execute_reply.started":"2022-04-26T17:14:35.186483Z","shell.execute_reply":"2022-04-26T17:14:37.008913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drawCorrelationMatrix(trainData[sensorData],method = 'kendall')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:14:37.012278Z","iopub.execute_input":"2022-04-26T17:14:37.012761Z","iopub.status.idle":"2022-04-26T17:15:31.285841Z","shell.execute_reply.started":"2022-04-26T17:14:37.012718Z","shell.execute_reply":"2022-04-26T17:15:31.284875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the heat map we came to know that there is no correlation between sensor data except few. So all these sensors picks up value which are not correlated to one another","metadata":{}},{"cell_type":"code","source":"def getRedundantPairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef getTopAbsCorrelations(df, n=5, method = 'pearson'):\n    au_corr = df.corr(method = method).abs().unstack()\n    labels_to_drop = getRedundantPairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    print(\"Top {} Correlated features in given dataset\".format(n))\n    return au_corr[0:n]\n\ngetTopAbsCorrelations(traindata[sensorData], 4)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:15:31.287098Z","iopub.execute_input":"2022-04-26T17:15:31.287339Z","iopub.status.idle":"2022-04-26T17:15:32.240947Z","shell.execute_reply.started":"2022-04-26T17:15:31.287292Z","shell.execute_reply":"2022-04-26T17:15:32.240054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Histogram for 1st 60 Sequences**","metadata":{}},{"cell_type":"code","source":"SENSOR_COUNT = 13\nrandom_sequence = 10000\ndf = trainData[trainData['sequence']==10000]\nplt.figure(figsize=(16,24))\nfor i in range(SENSOR_COUNT):\n    plt.subplot(6,3,i+1,aspect='auto')\n    sensor = 'sensor_'+str(i).zfill(2)\n    sns.kdeplot(data=df,x=sensor)\nplt.suptitle(f'Kde Plots of Sensors:{random_sequence}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:15:32.24213Z","iopub.execute_input":"2022-04-26T17:15:32.242366Z","iopub.status.idle":"2022-04-26T17:15:33.999245Z","shell.execute_reply.started":"2022-04-26T17:15:32.242339Z","shell.execute_reply":"2022-04-26T17:15:33.998335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 10\nrandom.seed(SEED) # Set the seed for reproducibilty\nrandom_sequence = random.randint(trainData['sequence'].min(), traindata['sequence'].max())\n\ndf = trainData[trainData['sequence']==random_sequence]\n\nSENSOR_COUNT = 13 # Thirteen sensors used for measurements\nsubject_number = df['subject'].unique()[0] # Subject numbers seems unique for particlar sequence\n\nplt.figure(figsize=(16,12))\nfor i in range(SENSOR_COUNT):\n    plt.subplot(6,3,i+1)\n    sensor = 'sensor_'+str(i).zfill(2)\n    sns.lineplot(data=df,x='step',y=sensor)\nplt.suptitle(f'Time Series Chart of Sensors for Sequence:{random_sequence} and Subject: {subject_number}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:15:34.000435Z","iopub.execute_input":"2022-04-26T17:15:34.000665Z","iopub.status.idle":"2022-04-26T17:15:35.878427Z","shell.execute_reply.started":"2022-04-26T17:15:34.000638Z","shell.execute_reply":"2022-04-26T17:15:35.877379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the number of sensors are 13, We can use Principal component analysis to reduce the dimensity of data by taking pricipal components retaining 95% variance of data","metadata":{}},{"cell_type":"code","source":"trainFeatures.drop(['sequence', 'subject', 'step'], axis=1, inplace=True)\ntestData.drop(['sequence', 'subject', 'step'], axis=1, inplace=True)\ntrainLabels.drop('sequence', axis=1, inplace=True)\n\n# from sklearn.preprocessing import StandardScaler\n\n# scaler = StandardScaler()\n# train_features = scaler.fit_transform(trainFeatures)\n# test_data = scaler.transform(testData)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:19:02.817792Z","iopub.execute_input":"2022-04-26T17:19:02.81813Z","iopub.status.idle":"2022-04-26T17:19:02.926342Z","shell.execute_reply.started":"2022-04-26T17:19:02.818089Z","shell.execute_reply":"2022-04-26T17:19:02.925375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = trainFeatures.values.reshape(int(len(trainFeatures)/60), 60, 13)\ntest_df = testData.values.reshape(int(len(testData)/60), 60, 13)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:19:44.271051Z","iopub.execute_input":"2022-04-26T17:19:44.271544Z","iopub.status.idle":"2022-04-26T17:19:44.277915Z","shell.execute_reply.started":"2022-04-26T17:19:44.2715Z","shell.execute_reply":"2022-04-26T17:19:44.276826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(train_features, trainLabels)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:19:59.285767Z","iopub.execute_input":"2022-04-26T17:19:59.286097Z","iopub.status.idle":"2022-04-26T17:19:59.382134Z","shell.execute_reply.started":"2022-04-26T17:19:59.286061Z","shell.execute_reply":"2022-04-26T17:19:59.381151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Bidirectional, Input\nfrom keras.layers import Dropout,MaxPooling1D, GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(Input(shape=(60,13)))\nmodel.add(LSTM(128, return_sequences=True))\nmodel.add(MaxPooling1D())\nmodel.add(LSTM(512, return_sequences=True))\nmodel.add(MaxPooling1D())\nmodel.add(LSTM(256, return_sequences=True))\nmodel.add(MaxPooling1D())\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:20:02.241955Z","iopub.execute_input":"2022-04-26T17:20:02.242237Z","iopub.status.idle":"2022-04-26T17:20:09.979581Z","shell.execute_reply.started":"2022-04-26T17:20:02.242207Z","shell.execute_reply":"2022-04-26T17:20:09.976993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\nhistory = model.fit(X_train, y_train, batch_size=500, epochs=10, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:20:20.599694Z","iopub.execute_input":"2022-04-26T17:20:20.600649Z","iopub.status.idle":"2022-04-26T17:35:18.647126Z","shell.execute_reply.started":"2022-04-26T17:20:20.600599Z","shell.execute_reply":"2022-04-26T17:35:18.646377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model train vs validation loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:38:16.622711Z","iopub.execute_input":"2022-04-26T17:38:16.62374Z","iopub.status.idle":"2022-04-26T17:38:16.788986Z","shell.execute_reply.started":"2022-04-26T17:38:16.623684Z","shell.execute_reply":"2022-04-26T17:38:16.788066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tabular-playground-series-apr-2022/sample_submission.csv', index_col=0)\nsubmission['state'] = model.predict(test_df)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:38:21.358252Z","iopub.execute_input":"2022-04-26T17:38:21.358592Z","iopub.status.idle":"2022-04-26T17:38:52.889137Z","shell.execute_reply.started":"2022-04-26T17:38:21.358553Z","shell.execute_reply":"2022-04-26T17:38:52.888428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T17:59:59.822848Z","iopub.execute_input":"2022-04-26T17:59:59.82323Z","iopub.status.idle":"2022-04-26T17:59:59.869832Z","shell.execute_reply.started":"2022-04-26T17:59:59.823188Z","shell.execute_reply":"2022-04-26T17:59:59.868846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!echo \"qid,prediction\" > submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:04:49.927773Z","iopub.execute_input":"2022-04-26T18:04:49.928126Z","iopub.status.idle":"2022-04-26T18:04:50.705744Z","shell.execute_reply.started":"2022-04-26T18:04:49.928088Z","shell.execute_reply":"2022-04-26T18:04:50.704468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:05:06.675741Z","iopub.execute_input":"2022-04-26T18:05:06.676133Z","iopub.status.idle":"2022-04-26T18:05:06.683348Z","shell.execute_reply.started":"2022-04-26T18:05:06.676091Z","shell.execute_reply":"2022-04-26T18:05:06.68261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:02:07.164639Z","iopub.execute_input":"2022-04-26T18:02:07.165056Z","iopub.status.idle":"2022-04-26T18:02:07.982676Z","shell.execute_reply.started":"2022-04-26T18:02:07.165011Z","shell.execute_reply":"2022-04-26T18:02:07.981021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions submit -c tabular-playground-series-apr-2022 -f submission.csv -m \"Message\"","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:00:55.797558Z","iopub.execute_input":"2022-04-26T18:00:55.79802Z","iopub.status.idle":"2022-04-26T18:00:57.033027Z","shell.execute_reply.started":"2022-04-26T18:00:55.797979Z","shell.execute_reply":"2022-04-26T18:00:57.0316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}