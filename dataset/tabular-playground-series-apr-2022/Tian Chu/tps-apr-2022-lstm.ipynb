{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T04:21:22.004616Z","iopub.execute_input":"2022-04-05T04:21:22.005312Z","iopub.status.idle":"2022-04-05T04:21:22.036282Z","shell.execute_reply.started":"2022-04-05T04:21:22.005168Z","shell.execute_reply":"2022-04-05T04:21:22.035346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:21:56.476754Z","iopub.execute_input":"2022-04-05T04:21:56.477097Z","iopub.status.idle":"2022-04-05T04:21:56.481784Z","shell.execute_reply.started":"2022-04-05T04:21:56.477064Z","shell.execute_reply":"2022-04-05T04:21:56.480998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_train = '../input/tabular-playground-series-apr-2022/train.csv'\npath_train_labels = '../input/tabular-playground-series-apr-2022/train_labels.csv'\npath_test = '../input/tabular-playground-series-apr-2022/test.csv'\npath_submission = '../input/tabular-playground-series-apr-2022/sample_submission.csv'","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:22:55.155604Z","iopub.execute_input":"2022-04-05T04:22:55.155898Z","iopub.status.idle":"2022-04-05T04:22:55.161028Z","shell.execute_reply.started":"2022-04-05T04:22:55.155869Z","shell.execute_reply":"2022-04-05T04:22:55.159821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Data loading","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(path_train)\ndf_train_labels = pd.read_csv(path_train_labels)\ndf_test = pd.read_csv(path_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:22:56.572532Z","iopub.execute_input":"2022-04-05T04:22:56.572807Z","iopub.status.idle":"2022-04-05T04:23:09.128365Z","shell.execute_reply.started":"2022-04-05T04:22:56.572779Z","shell.execute_reply":"2022-04-05T04:23:09.127327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_train)\ndisplay(df_test)\ndisplay(df_train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.129986Z","iopub.execute_input":"2022-04-05T04:23:09.130221Z","iopub.status.idle":"2022-04-05T04:23:09.202068Z","shell.execute_reply.started":"2022-04-05T04:23:09.130194Z","shell.execute_reply":"2022-04-05T04:23:09.201107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data cleaning","metadata":{}},{"cell_type":"markdown","source":"### Missing data","metadata":{}},{"cell_type":"code","source":"print(df_train.isnull().sum())\nprint(df_test.isnull().sum())\nprint(df_train_labels.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.20353Z","iopub.execute_input":"2022-04-05T04:23:09.20387Z","iopub.status.idle":"2022-04-05T04:23:09.289507Z","shell.execute_reply.started":"2022-04-05T04:23:09.203825Z","shell.execute_reply":"2022-04-05T04:23:09.288256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no missing data.","metadata":{}},{"cell_type":"markdown","source":"### 'step' integrity\n\nFor each sequence, there should be 60 steps (from 0 to 59).","metadata":{}},{"cell_type":"code","source":"df_train.groupby('sequence')['step'].count().describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.292028Z","iopub.execute_input":"2022-04-05T04:23:09.292514Z","iopub.status.idle":"2022-04-05T04:23:09.351245Z","shell.execute_reply.started":"2022-04-05T04:23:09.292445Z","shell.execute_reply":"2022-04-05T04:23:09.350325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.groupby('sequence')['step'].count().describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.352632Z","iopub.execute_input":"2022-04-05T04:23:09.352857Z","iopub.status.idle":"2022-04-05T04:23:09.380323Z","shell.execute_reply.started":"2022-04-05T04:23:09.352831Z","shell.execute_reply":"2022-04-05T04:23:09.379355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Every sequence has data of 60 steps.","metadata":{}},{"cell_type":"markdown","source":"### Possible data cleaning\n\nAlthough we have perfect data here, it is possible that we need to handle with imperfect data in other cases. For example:\n* Missing data for target ('state').\n* Missing data for features ('sensor_xx').\n* Incomplete 'step' for some sequences.\n\nLet's delete some values to show some possible solutions.","metadata":{}},{"cell_type":"code","source":"# copy original data\ndf_train_dc = df_train.copy()\ndf_train_labels_dc = df_train_labels.copy()\n\n# delete some values\ndf_train_dc = df_train_dc.drop([0, 3, 100])\ndf_train_dc.loc[[1, 5, 7], ['sensor_00']] = None\ndf_train_labels_dc.loc[[1, 60, 100], ['state']] = None\n\ndisplay(df_train_dc)\ndisplay(df_train_labels_dc)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.381782Z","iopub.execute_input":"2022-04-05T04:23:09.382081Z","iopub.status.idle":"2022-04-05T04:23:09.717919Z","shell.execute_reply.started":"2022-04-05T04:23:09.382048Z","shell.execute_reply":"2022-04-05T04:23:09.717022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for missing values in 'state', we can simply drop them.\ndf_train_labels_dc = df_train_labels_dc[~df_train_labels_dc['state'].isnull()]\ndf_train_labels_dc","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.719119Z","iopub.execute_input":"2022-04-05T04:23:09.719466Z","iopub.status.idle":"2022-04-05T04:23:09.736822Z","shell.execute_reply.started":"2022-04-05T04:23:09.719431Z","shell.execute_reply":"2022-04-05T04:23:09.735912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for the training set, we only use the sequences which have 'state' results.\ndf_train_dc = df_train_dc[df_train_dc['sequence'].isin(df_train_labels_dc['sequence'])]\ndf_train_dc","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.73868Z","iopub.execute_input":"2022-04-05T04:23:09.739042Z","iopub.status.idle":"2022-04-05T04:23:09.885674Z","shell.execute_reply.started":"2022-04-05T04:23:09.739011Z","shell.execute_reply":"2022-04-05T04:23:09.884591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for missing values in training set, we need to resample the data \n# to make sure that each sequence has 60 steps and each feature 'sensor_xx'\n# has a value.\n\ndf_sequence = pd.DataFrame(df_train_dc['sequence'].unique(), columns=['sequence'])\ndf_step = pd.DataFrame(range(60), columns=['step'])\n\n# create 'temp' column to merge 'sequence' and 'step'\ndf_sequence['temp'] = 1\ndf_step['temp'] = 1\n\ndf = pd.merge(df_sequence, df_step, on='temp').drop(columns='temp')\ndf\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:09.886957Z","iopub.execute_input":"2022-04-05T04:23:09.887203Z","iopub.status.idle":"2022-04-05T04:23:10.000953Z","shell.execute_reply.started":"2022-04-05T04:23:09.887175Z","shell.execute_reply":"2022-04-05T04:23:10.00007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_dc = pd.merge(df, df_train_dc, on=['sequence', 'step'], how='left')\ndf_train_dc","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:10.003173Z","iopub.execute_input":"2022-04-05T04:23:10.003409Z","iopub.status.idle":"2022-04-05T04:23:10.627925Z","shell.execute_reply.started":"2022-04-05T04:23:10.003378Z","shell.execute_reply":"2022-04-05T04:23:10.626822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use .fillna to fill the missing values.\n# we can use the mean value group by the 'sequence'.\n# other options are 'ffill' or 'bfill'.\n\nfor i in range(13):\n    columnname = 'sensor_' + f'{i:02}'\n    df_train_dc[columnname] = df_train_dc[columnname].fillna(df_train_dc.groupby('sequence')[columnname].transform('mean'))\n\ndf_train_dc","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:10.629485Z","iopub.execute_input":"2022-04-05T04:23:10.630346Z","iopub.status.idle":"2022-04-05T04:23:11.276643Z","shell.execute_reply.started":"2022-04-05T04:23:10.630297Z","shell.execute_reply":"2022-04-05T04:23:11.275671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data wrangling","metadata":{}},{"cell_type":"code","source":"x = df_train.copy()\nx_test = df_test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:11.277821Z","iopub.execute_input":"2022-04-05T04:23:11.278037Z","iopub.status.idle":"2022-04-05T04:23:11.390678Z","shell.execute_reply.started":"2022-04-05T04:23:11.278011Z","shell.execute_reply":"2022-04-05T04:23:11.389957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# groupby 'sequence'\ngroups = x['sequence']","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:11.391728Z","iopub.execute_input":"2022-04-05T04:23:11.391954Z","iopub.status.idle":"2022-04-05T04:23:11.397126Z","shell.execute_reply.started":"2022-04-05T04:23:11.391927Z","shell.execute_reply":"2022-04-05T04:23:11.396231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the non-feature columns\nx = x.drop(['sequence', 'subject', 'step'], axis=1).values\nx_test = x_test.drop(['sequence', 'subject', 'step'], axis=1).values","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:11.398273Z","iopub.execute_input":"2022-04-05T04:23:11.398482Z","iopub.status.idle":"2022-04-05T04:23:11.507962Z","shell.execute_reply.started":"2022-04-05T04:23:11.398457Z","shell.execute_reply":"2022-04-05T04:23:11.506931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target column\ny = df_train_labels['state']","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:23:11.509207Z","iopub.execute_input":"2022-04-05T04:23:11.509587Z","iopub.status.idle":"2022-04-05T04:23:11.519207Z","shell.execute_reply.started":"2022-04-05T04:23:11.509555Z","shell.execute_reply":"2022-04-05T04:23:11.518579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#standardize\nstandardscaler = StandardScaler()\n\nx = standardscaler.fit_transform(x)\nx_test = standardscaler.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T04:25:16.132778Z","iopub.execute_input":"2022-04-05T04:25:16.133541Z","iopub.status.idle":"2022-04-05T04:25:16.499512Z","shell.execute_reply.started":"2022-04-05T04:25:16.133483Z","shell.execute_reply":"2022-04-05T04:25:16.498536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape the features\n# each sequence has 60 steps, each step has 13 sensor_xx values\n# so the shape is (-1, 60, 13)\nx = x.reshape(-1, 60, 13)\nx_test = x_test.reshape(-1, 60, 13)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T03:53:53.792681Z","iopub.execute_input":"2022-04-04T03:53:53.793413Z","iopub.status.idle":"2022-04-04T03:53:53.797783Z","shell.execute_reply.started":"2022-04-04T03:53:53.793369Z","shell.execute_reply":"2022-04-04T03:53:53.796968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def NN():\n    with tpu_strategy.scope():\n        model = keras.models.Sequential(\n            [\n                keras.layers.Input(shape=(60, 13)),\n                keras.layers.LSTM(500, return_sequences=True),\n                keras.layers.LSTM(400, return_sequences=True),\n                keras.layers.LSTM(300, return_sequences=True),\n                keras.layers.LSTM(200, return_sequences=True),\n                keras.layers.Conv1D(32, 3),\n                keras.layers.GlobalMaxPooling1D(),\n                keras.layers.Dense(128, activation='swish'),\n                keras.layers.Dense(64, activation='swish'),\n                keras.layers.Dense(1, activation='sigmoid')\n            ]\n        )\n\n        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:02:30.983613Z","iopub.execute_input":"2022-04-04T04:02:30.984613Z","iopub.status.idle":"2022-04-04T04:02:30.992042Z","shell.execute_reply.started":"2022-04-04T04:02:30.984573Z","shell.execute_reply":"2022-04-04T04:02:30.991231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T03:54:51.611463Z","iopub.execute_input":"2022-04-04T03:54:51.611751Z","iopub.status.idle":"2022-04-04T03:54:59.595977Z","shell.execute_reply.started":"2022-04-04T03:54:51.61172Z","shell.execute_reply":"2022-04-04T03:54:59.595234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_score = 0\ny_test_preds = []\nkf = GroupKFold(n_splits=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:03:19.947364Z","iopub.execute_input":"2022-04-04T04:03:19.947955Z","iopub.status.idle":"2022-04-04T04:03:19.955997Z","shell.execute_reply.started":"2022-04-04T04:03:19.947903Z","shell.execute_reply":"2022-04-04T04:03:19.954801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold_idx, (train_idx, cv_idx) in enumerate(kf.split(x, y, groups.unique())):\n    \n    print('*'*15, f'Fold {fold_idx+1}', '*'*15)\n\n    x_train, x_cv = x[train_idx], x[cv_idx]\n    y_train, y_cv = y.iloc[train_idx].values, y.iloc[cv_idx].values\n\n    model = NN()\n    model.fit(x_train, y_train, validation_data=(x_cv, y_cv), epochs=100, batch_size=2048,\n              callbacks=[keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)])\n    \n    cv_score += roc_auc_score(y_cv, model.predict(x_cv).squeeze())\n\n    y_test_preds.append(model.predict(x_test).squeeze())\n\nprint('*'*30)\nprint(cv_score/5)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:03:49.660215Z","iopub.execute_input":"2022-04-04T04:03:49.660513Z","iopub.status.idle":"2022-04-04T04:09:55.174654Z","shell.execute_reply.started":"2022-04-04T04:03:49.660484Z","shell.execute_reply":"2022-04-04T04:09:55.173715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame(df_test['sequence'].unique(), columns=['sequence'])\nsubmission['state'] = sum(y_test_preds) / 5\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:12:46.954819Z","iopub.execute_input":"2022-04-04T04:12:46.955332Z","iopub.status.idle":"2022-04-04T04:12:46.97694Z","shell.execute_reply.started":"2022-04-04T04:12:46.955298Z","shell.execute_reply":"2022-04-04T04:12:46.976234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"LSTM_V1.4.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:13:19.865604Z","iopub.execute_input":"2022-04-04T04:13:19.866351Z","iopub.status.idle":"2022-04-04T04:13:19.917309Z","shell.execute_reply.started":"2022-04-04T04:13:19.866307Z","shell.execute_reply":"2022-04-04T04:13:19.916309Z"},"trusted":true},"execution_count":null,"outputs":[]}]}