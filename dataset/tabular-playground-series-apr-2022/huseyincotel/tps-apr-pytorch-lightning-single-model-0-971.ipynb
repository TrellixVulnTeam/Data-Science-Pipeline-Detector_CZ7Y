{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThis notebook is created to have Pytorch Lightning version of the single BiLSTM models with addition of 2 CNN layer addition.\nHope it contributes in some sense.","metadata":{}},{"cell_type":"code","source":"##########################  Load Libraries  ####################################\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.callbacks import LearningRateMonitor, Callback\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch\nimport torchmetrics\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\nimport os\nimport gc\n\ngc.collect()\ntorch.cuda.empty_cache()\n\ndf_train = pd.read_csv(\"../input/tabular-playground-series-apr-2022/train.csv\")\nt_lbls = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\nss = pd.read_csv('../input/tabular-playground-series-apr-2022/sample_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-10T23:38:45.70529Z","iopub.execute_input":"2022-04-10T23:38:45.706171Z","iopub.status.idle":"2022-04-10T23:38:52.836205Z","shell.execute_reply.started":"2022-04-10T23:38:45.706067Z","shell.execute_reply":"2022-04-10T23:38:52.834864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_train.head())\ndisplay(t_lbls.head())\ndisplay(df_test.head())\ndisplay(ss.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:32.709504Z","iopub.execute_input":"2022-04-10T14:57:32.709758Z","iopub.status.idle":"2022-04-10T14:57:32.764755Z","shell.execute_reply.started":"2022-04-10T14:57:32.709727Z","shell.execute_reply":"2022-04-10T14:57:32.763744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Seed everything*","metadata":{}},{"cell_type":"code","source":"SEED = 22\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:32.766043Z","iopub.execute_input":"2022-04-10T14:57:32.766363Z","iopub.status.idle":"2022-04-10T14:57:32.774479Z","shell.execute_reply.started":"2022-04-10T14:57:32.766328Z","shell.execute_reply":"2022-04-10T14:57:32.77373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"features = df_train.columns.tolist()[3:]\ndef prep(df):\n    for feature in features:\n        df[feature + '_lag1'] = df.groupby('sequence')[feature].shift(1)\n        df[feature + '_lead1'] = df.groupby('sequence')[feature].shift(-1)\n        df.fillna(0, inplace=True)\n        df[feature + '_diff1'] = df[feature] - df[feature + '_lag1']\n\nprep(df_train)\nprep(df_test)\nfeatures = df_train.columns.tolist()[3:]\ndf_train = pd.merge(df_train, t_lbls, on=\"sequence\")\ndf_test['state'] = 0\n\n\nsc = StandardScaler()\ndf_train[features] = sc.fit_transform(df_train[features])\ndf_test[features] = sc.transform(df_test[features])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:57:32.776437Z","iopub.execute_input":"2022-04-10T14:57:32.776756Z","iopub.status.idle":"2022-04-10T14:58:14.771776Z","shell.execute_reply.started":"2022-04-10T14:57:32.776722Z","shell.execute_reply":"2022-04-10T14:58:14.770927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"F_train = df_train[features].values.reshape(df_train.shape[0] // 60, 60, len(features))\nF_test = df_test[features].values.reshape(df_test.shape[0] // 60, 60, len(features))\n\nindex_df_train = df_train[[\"sequence\", \"subject\", \"state\"]].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:14.772999Z","iopub.execute_input":"2022-04-10T14:58:14.773262Z","iopub.status.idle":"2022-04-10T14:58:15.120278Z","shell.execute_reply.started":"2022-04-10T14:58:14.77323Z","shell.execute_reply":"2022-04-10T14:58:15.119549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*MaxPool1d Implementation for Pytorch*","metadata":{}},{"cell_type":"code","source":"class GlobalMaxPooling1D(nn.Module):\n\n    def __init__(self, data_format='channels_last'):\n        super(GlobalMaxPooling1D, self).__init__()\n        self.data_format = data_format\n        self.step_axis = 1 if self.data_format == 'channels_last' else 2\n\n    def forward(self, input):\n        return torch.max(input, axis=self.step_axis).values\n\nclass GlobalAvgPooling1D(nn.Module):\n\n    def __init__(self, data_format='channels_last'):\n        super(GlobalAvgPooling1D, self).__init__()\n        self.data_format = data_format\n        self.step_axis = 1 if self.data_format == 'channels_last' else 2\n\n    def forward(self, input):\n        return torch.mean(input, dim=self.step_axis)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:15.121426Z","iopub.execute_input":"2022-04-10T14:58:15.122173Z","iopub.status.idle":"2022-04-10T14:58:15.129508Z","shell.execute_reply.started":"2022-04-10T14:58:15.122132Z","shell.execute_reply":"2022-04-10T14:58:15.128739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Net(pl.LightningModule):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.conv1 = nn.Conv1d(in_channels=13*4, out_channels=32, kernel_size=3)\n        self.conv2 = nn.Conv1d(in_channels=32, out_channels=128, kernel_size=3)\n        self.conv3 = nn.Conv1d(in_channels=128, out_channels=384, kernel_size=3)\n        \n        self.bi_lstm1 = nn.LSTM(384, 768, bidirectional=True, batch_first=True, dropout=0.2)\n        self.bi_lstm21 = nn.LSTM(768*2, 512, bidirectional=True, batch_first=True)\n        self.bi_lstm22 = nn.LSTM(384, 512, bidirectional=True, batch_first=True)\n        self.bi_lstm31 = nn.LSTM(2048, 384, bidirectional=True, batch_first=True)\n        self.bi_lstm32 = nn.LSTM(1024, 384, bidirectional=True, batch_first=True)\n\n        self.pool = GlobalMaxPooling1D()\n        self.dense = nn.Sequential(\n            nn.Linear(in_features=5120, out_features=128),\n            nn.SELU(),\n            nn.Dropout(0.2),\n            nn.Linear(in_features=128, out_features=1),\n            nn.Sigmoid()\n        )\n        self.bce = nn.BCELoss(reduce=True, reduction='mean')\n\n        self.train_auc = torchmetrics.AUROC()\n        self.val_auc = torchmetrics.AUROC()\n\n    def forward(self, x):\n        x = torch.transpose(x, 1, 2)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x_0 = self.conv3(x)\n        x_0 = torch.transpose(x_0, 1, 2)\n        x_1, _ = self.bi_lstm1(x_0)\n        x_21, _ = self.bi_lstm21(x_1)\n        x_22, _ = self.bi_lstm22(x_0)\n        x_2 = torch.cat([x_21, x_22], dim=2)\n\n        x_31, _ = self.bi_lstm31(x_2)\n        x_32, _ = self.bi_lstm32(x_21)\n        x_3 = torch.cat([x_31, x_32], dim=2)\n\n        # x_41, _ = self.bi_lstm41(x_3)\n        # x_42, _ = self.bi_lstm42(x_31)\n        # x_4 = torch.cat([x_41, x_42], dim=2)\n\n        x_5 = torch.cat([x_1, x_2, x_3], dim=2)\n        x_5 = self.pool(x_5)\n        output = self.dense(x_5)\n        return output\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=1e-3, betas=(0.9, 0.999), eps=1e-08)\n        scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.3, patience=2)\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"valid_auc_epoch\"}\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch[0], batch[1]\n        y_hat = self(x)\n        loss = self.bce(y_hat, y)\n        self.train_auc(y_hat, y.to(torch.int))\n        self.log('train_auc', self.train_auc, on_step=True, on_epoch=False, prog_bar=True)\n        return loss\n\n    def training_epoch_end(self, outputs):\n        self.train_auc.reset()\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch[0], batch[1]\n        y_hat = self(x)\n        loss = self.bce(y_hat, y)\n        self.val_auc(y_hat, y.to(torch.int))\n        self.log('val_auc', self.val_auc.compute(), on_step=True, on_epoch=False)\n        return loss\n\n    def validation_epoch_end(self, outputs):\n        self.log('valid_auc_epoch', self.val_auc.compute(), prog_bar=True)\n        self.val_auc.reset()\n\n    def predict_step(self, batch, batch_idx):\n        x, y = batch[0], batch[1]\n        return self(x)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:15.130875Z","iopub.execute_input":"2022-04-10T14:58:15.131267Z","iopub.status.idle":"2022-04-10T14:58:15.1529Z","shell.execute_reply.started":"2022-04-10T14:58:15.131233Z","shell.execute_reply":"2022-04-10T14:58:15.152054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TPSAprilDataset(Dataset):\n    def __init__(self, df, is_test=False):\n        if is_test:\n            self.indices = df['sequence'] - 25968\n        else:\n            self.indices = df['sequence']\n        self.targets = df['state']\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        if not self.is_test:\n            X = F_train[self.indices[idx]]\n        else:\n            X = F_test[self.indices[idx]]\n        y = self.targets[idx]\n        return torch.FloatTensor(X), torch.FloatTensor([y])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:15.15415Z","iopub.execute_input":"2022-04-10T14:58:15.154788Z","iopub.status.idle":"2022-04-10T14:58:15.165236Z","shell.execute_reply.started":"2022-04-10T14:58:15.154752Z","shell.execute_reply":"2022-04-10T14:58:15.164486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lightning DataModule","metadata":{}},{"cell_type":"code","source":"class TPSAprilDataLoader(pl.LightningDataModule):\n    def __init__(self, df, batch_size=64, fold=None):\n        super().__init__()\n        self.batch_size = batch_size\n        self.df = df\n        self.fold = fold\n\n    def prepare_data(self):\n        pass\n\n    def setup(self, stage=None):\n        pass\n\n    def train_dataloader(self):\n        dataset = TPSAprilDataset(self.df)\n        train_loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=8, shuffle=True, drop_last=False)\n        return train_loader\n\n    def valid_dataloader(self):\n        dataset = TPSAprilDataset(self.df)\n        valid_loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=8, shuffle=False, drop_last=False)\n        return valid_loader\n\n    def test_dataloader(self):\n        dataset = TPSAprilDataset(self.df, is_test=True)\n        test_loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=8, shuffle=False, drop_last=False)\n        return test_loader","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:15.166575Z","iopub.execute_input":"2022-04-10T14:58:15.167559Z","iopub.status.idle":"2022-04-10T14:58:15.178539Z","shell.execute_reply.started":"2022-04-10T14:58:15.1675Z","shell.execute_reply":"2022-04-10T14:58:15.177682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-fold Run","metadata":{}},{"cell_type":"code","source":"N_FOLDS = 10\n\ngkf = GroupKFold(N_FOLDS)\ny_oof = np.zeros(index_df_train.shape[0])\ny_test = np.zeros(ss.shape[0])\n\nix = 0\nfor train_ind, val_ind in gkf.split(index_df_train, index_df_train[\"state\"], groups=index_df_train[\"subject\"]):\n    print(f\"******* Fold {ix} ******* \")\n    train_df, val_df = index_df_train.iloc[train_ind].reset_index(drop=True), index_df_train.iloc[val_ind].reset_index(drop=True)\n\n    train_loader = TPSAprilDataLoader(train_df).train_dataloader()\n    val_loader = TPSAprilDataLoader(val_df).valid_dataloader()\n    test_loader = TPSAprilDataLoader(ss).test_dataloader()\n\n    model = Net()\n\n    early_stop_callback = EarlyStopping(monitor='valid_auc_epoch', min_delta=0.00, patience=5, verbose=True, mode='max')\n    trainer = pl.Trainer(limit_train_batches=0.5, callbacks=[early_stop_callback], max_epochs=50, gpus=1, accumulate_grad_batches=8)\n    trainer.fit(model, train_loader, val_loader)\n    val_pred_list = trainer.predict(model, val_loader)\n    val_pred = torch.cat(val_pred_list, dim=0).detach().cpu().numpy().ravel()\n    test_pred_list = trainer.predict(model, test_loader)\n    test_pred = torch.cat(test_pred_list, dim=0).detach().cpu().numpy().ravel()\n    y_oof[val_ind] = val_pred\n    y_test += test_pred / N_FOLDS\n    ix = ix + 1","metadata":{"execution":{"iopub.status.busy":"2022-04-10T14:58:15.181435Z","iopub.execute_input":"2022-04-10T14:58:15.182371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"cv_auc = np.round(roc_auc_score(index_df_train['state'].values, y_oof), 4)\nprint(\"CV Val AUC:\", cv_auc)\nss['state'] = y_test\nss.to_csv(f\"submission_{cv_auc}.csv\", sep=\",\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}