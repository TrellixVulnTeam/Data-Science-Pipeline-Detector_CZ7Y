{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Motivation","metadata":{}},{"cell_type":"markdown","source":"I recalled Jeremy Howard talking about a guy that did a project of time series classification in which he converted the series to images using Gramian Angular Field and apply a Resnet50 afterwards. You can read the topic in the Fastai forums [here](https://forums.fast.ai/t/share-your-work-here/27676/367). \n\nI wanted to test this cool approach with our dataset and it was a surprise that it can achieve pretty decent results. But the most important thing is that is very different from the other solutions (LSTMs, CNN1Ds, etc) so it can contribute to the final ensemble.","metadata":{}},{"cell_type":"markdown","source":"#### What is Gramian Angular Field Imaging?","metadata":{}},{"cell_type":"markdown","source":"This [blog](https://medium.com/analytics-vidhya/encoding-time-series-as-images-b043becbdbf3) post gives a good explanation about how the encoding using Gramian Angular Field works. Long story short, it perform a polar encoding of the data followed by a Gram Matrix like operation on the resulting angles. ","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/1378/1*A0yHZ8GD47cQd1OACTiz6Q.gif\">","metadata":{}},{"cell_type":"markdown","source":"Let's apply GAF transformation to some of our sensor time series to see how they look like.","metadata":{}},{"cell_type":"code","source":"!pip install pyts\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pyts.image import GramianAngularField","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:00:16.766292Z","iopub.execute_input":"2022-04-19T18:00:16.766708Z","iopub.status.idle":"2022-04-19T18:00:30.912845Z","shell.execute_reply.started":"2022-04-19T18:00:16.766604Z","shell.execute_reply":"2022-04-19T18:00:30.911726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the data\ndf_train = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2022/train.csv\")\ndf_train_labels = pd.read_csv(\"/kaggle/input/tabular-playground-series-apr-2022/train_labels.csv\")\nsensors = [f for f in df_train.columns if \"sensor_\" in f]\n\n# Pivot the dataframe to easy the access to the sequences\ndf_train_piv = df_train.pivot(\n    index = [\"sequence\", \"subject\"], \n    columns = \"step\", \n    values = sensors\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:00:30.914384Z","iopub.execute_input":"2022-04-19T18:00:30.914641Z","iopub.status.idle":"2022-04-19T18:00:40.556624Z","shell.execute_reply.started":"2022-04-19T18:00:30.914606Z","shell.execute_reply":"2022-04-19T18:00:40.555729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = df_train_labels[\"state\"].values\n\n# Choose 3 samples at random\nfor r in np.random.randint(0, len(labels), 3):\n    \n    # Choose 3 sensors at random\n    for s in np.random.choice(sensors, 3):\n\n        data = df_train_piv.loc[:, df_train_piv.columns.get_level_values(0) == s].values\n        \n        gasf = GramianAngularField(image_size=60, method=\"summation\")\n        data_gasf = gasf.fit_transform(data)\n\n        plt.matshow(data_gasf[r])\n        plt.title(f\"{s}, Label: {labels[r]}\")\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:24:08.642231Z","iopub.execute_input":"2022-04-19T14:24:08.642562Z","iopub.status.idle":"2022-04-19T14:24:20.091432Z","shell.execute_reply.started":"2022-04-19T14:24:08.642528Z","shell.execute_reply":"2022-04-19T14:24:20.090035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we are can convert our sensor time series to images, we can apply any computer vision model we want. In my case I used a model called SimpleNet from the paper *Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures* (2016). \n\nOn the other hand, as it has been said (I noticed it thanks to AmbrosM, as many other things), the number of times a subject appears in the data is well correlated with the target. Therefore, I concatenated that feature with those extracted by the SimpleNet in the neural network model.","metadata":{}},{"cell_type":"markdown","source":"![image](https://i.postimg.cc/sfhVTXMz/Image.png)","metadata":{}},{"cell_type":"markdown","source":"### **IMPORTANT!**","metadata":{}},{"cell_type":"markdown","source":"\nThe following code runs perfectly on my local machine but gives a RAM error on Kaggle notebooks at some point. I tried to fix it but I haven't found the solution yet. For that reason, I chose to directly append the models, oofs and the submission file generated locally to this notebook. Anyhow, the same code that I used in my local machine is commented below for those who want to use it :D.","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/tps-apr22-gaf-cnn2d-outputs/submission.csv\")\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:02:00.936226Z","iopub.execute_input":"2022-04-19T18:02:00.936991Z","iopub.status.idle":"2022-04-19T18:02:00.976166Z","shell.execute_reply.started":"2022-04-19T18:02:00.936935Z","shell.execute_reply":"2022-04-19T18:02:00.975448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The Code","metadata":{}},{"cell_type":"code","source":"# !pip install pyts","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:17.612134Z","iopub.execute_input":"2022-04-19T10:51:17.612576Z","iopub.status.idle":"2022-04-19T10:51:27.015534Z","shell.execute_reply.started":"2022-04-19T10:51:17.612478Z","shell.execute_reply":"2022-04-19T10:51:27.014475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Imports","metadata":{}},{"cell_type":"code","source":"# import os\n# import time\n# import random\n\n# from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n\n# import pandas as pd\n# import numpy as np\n\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import GroupKFold\n\n# from pyts.image import GramianAngularField\n\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch.utils.data import Dataset, DataLoader\n# from torch.optim import Adam\n# from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, OneCycleLR, ReduceLROnPlateau\n# from torch.cuda.amp import autocast, GradScaler\n\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# import gc\n# gc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:27.018241Z","iopub.execute_input":"2022-04-19T10:51:27.018602Z","iopub.status.idle":"2022-04-19T10:51:30.170381Z","shell.execute_reply.started":"2022-04-19T10:51:27.018557Z","shell.execute_reply":"2022-04-19T10:51:30.169538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Utils","metadata":{}},{"cell_type":"code","source":"# def set_seed(seed: int=42):\n#     random.seed(seed)\n#     np.random.seed(seed)\n#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed(seed)\n#     torch.backends.cudnn.deterministic = True\n#     torch.backends.cudnn.benchmark = False\n\n\n# def init_logger(logs_path):\n#     log_file = os.path.join(logs_path, \"train.log\")\n#     logger = getLogger(__name__)\n#     logger.setLevel(INFO)\n#     handler1 = StreamHandler()\n#     handler1.setFormatter(Formatter(\"%(message)s\"))\n#     handler2 = FileHandler(filename=log_file)\n#     handler2.setFormatter(Formatter(\"%(message)s\"))\n#     logger.addHandler(handler1)\n#     logger.addHandler(handler2)\n#     return logger\n\n\n# class AverageMeter(object):\n#     def __init__(self):\n#         self.reset()\n\n#     def reset(self):\n#         self.val = 0\n#         self.avg = 0\n#         self.sum = 0\n#         self.count = 0\n\n#     def update(self, val, n=1):\n#         self.val = val\n#         self.sum += val * n\n#         self.count += n\n#         self.avg = self.sum / self.count\n\n\n# def asMinutes(s):\n#     m = np.floor(s / 60)\n#     s -= m * 60\n#     return \"%dm %ds\" % (m, s)\n\n\n# def timeSince(since, percent):\n#     now = time.time()\n#     s = now - since\n#     es = s / (percent)\n#     rs = es - s\n#     return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T14:36:07.114599Z","iopub.execute_input":"2022-04-19T14:36:07.115019Z","iopub.status.idle":"2022-04-19T14:36:07.122225Z","shell.execute_reply.started":"2022-04-19T14:36:07.114978Z","shell.execute_reply":"2022-04-19T14:36:07.121243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Datasets","metadata":{}},{"cell_type":"code","source":"# class TrainDataset(Dataset):\n#     def __init__(self, X, counts, y):\n#         self.X = X\n#         self.counts = counts\n#         self.y = y\n    \n#     def __len__(self):\n#         return len(self.X)\n    \n#     def __getitem__(self, idx):\n        \n#         output = {\n#             \"X\": torch.tensor(self.X[idx], dtype=torch.float),\n#             \"counts\": torch.tensor(self.counts[idx], dtype=torch.float),\n#             \"y\": torch.tensor(self.y[idx], dtype=torch.float)\n#         }\n#         return output\n\n\n# class TestDataset(Dataset):\n#     def __init__(self, X, counts):\n#         self.X = X\n#         self.counts = counts\n    \n#     def __len__(self):\n#         return len(self.X)\n    \n#     def __getitem__(self, idx):\n        \n#         output = {\n#             \"X\": torch.tensor(self.X[idx], dtype=torch.float),\n#             \"counts\": torch.tensor(self.counts[idx], dtype=torch.float)\n#         }\n#         return output","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:30.186572Z","iopub.execute_input":"2022-04-19T10:51:30.188075Z","iopub.status.idle":"2022-04-19T10:51:30.198084Z","shell.execute_reply.started":"2022-04-19T10:51:30.188014Z","shell.execute_reply":"2022-04-19T10:51:30.19733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Pytorch model","metadata":{}},{"cell_type":"code","source":"# class simplenet(nn.Module):\n#     def __init__(self, classes=1):\n#         super(simplenet, self).__init__()\n#         self.features = self._make_layers() \n#         self.classifier = nn.Linear(256 + 1, classes)\n#         self.drp = nn.Dropout(0.1)\n\n#     def forward(self, x, sc):\n#         out = self.features(x)\n\n#         # Global Max Pooling\n#         out = F.max_pool2d(out, kernel_size=out.size()[2:]) \n#         # out = F.dropout2d(out, 0.1, training=True)\n#         out = self.drp(out)\n        \n#         out = out.view(out.size(0), -1)\n        \n#         out = torch.cat([out, sc.unsqueeze(dim=1)], axis=1)\n        \n#         out = self.classifier(out)\n#         return out\n\n#     def _make_layers(self):\n\n#         model = nn.Sequential(\n#                              nn.Conv2d(13, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(64, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n#                              nn.Dropout2d(p=0.1),\n\n#                              nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(128, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n#                              nn.Dropout2d(p=0.1),\n\n#                              nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n#                              nn.Dropout2d(p=0.1),\n\n#                              nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(512, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n#                              nn.Dropout2d(p=0.1),\n\n#                              nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), padding=(0, 0)),\n#                              nn.BatchNorm2d(2048, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.Conv2d(2048, 256, kernel_size=[1, 1], stride=(1, 1), padding=(0, 0)),\n#                              nn.BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                              nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False),\n#                              nn.Dropout2d(p=0.1),\n\n#                              nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1)),\n#                              nn.BatchNorm2d(256, eps=1e-05, momentum=0.05, affine=True),\n#                              nn.ReLU(inplace=True),\n\n#                             )\n#         for m in model.modules():\n#             if isinstance(m, nn.Conv2d):\n#                 nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n\n#         return model","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:30.200908Z","iopub.execute_input":"2022-04-19T10:51:30.201568Z","iopub.status.idle":"2022-04-19T10:51:30.233055Z","shell.execute_reply.started":"2022-04-19T10:51:30.201531Z","shell.execute_reply":"2022-04-19T10:51:30.232296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### NN boilerplate","metadata":{}},{"cell_type":"code","source":"# def get_scheduler(cfg, optimizer, trainloader=None):\n#     if cfg.scheduler == \"ReduceLROnPlateau\":\n#         scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=cfg.factor, patience=cfg.patience, verbose=True, eps=cfg.eps)\n#     elif cfg.scheduler == \"CosineAnnealingLR\":\n#         scheduler = CosineAnnealingLR(optimizer, T_max=cfg.T_max, eta_min=cfg.min_lr, last_epoch=-1)\n#     elif cfg.scheduler == \"CosineAnnealingWarmRestarts\":\n#         scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=cfg.T_0, T_mult=1, eta_min=cfg.min_lr, last_epoch=-1)\n#     elif cfg.scheduler == \"OneCycleLR\":\n#         scheduler = OneCycleLR(optimizer, pct_start=0.1, div_factor=1e3, max_lr=cfg.max_lr, epochs=cfg.epochs, steps_per_epoch=len(trainloader))\n#     return scheduler\n\n\n\n# def train_fn(cfg, train_dl, model, criterion, optimizer, epoch, scheduler):\n    \n#     if cfg.apex:\n#         scaler = GradScaler()\n    \n#     batch_time = AverageMeter()\n#     data_time = AverageMeter()\n#     losses = AverageMeter()\n    \n#     # switch to train mode\n#     model.train()\n#     start = end = time.time()\n#     global_step = 0\n#     preds = []\n    \n#     for step, data in enumerate(train_dl):\n#         # measure data loading time\n#         data_time.update(time.time() - end)\n        \n#         inputs = data[\"X\"].to(cfg.device)\n#         counts = data[\"counts\"].to(cfg.device)\n#         targets = data[\"y\"].to(cfg.device)\n#         batch_size = targets.size(0)\n        \n#         if cfg.apex:\n#             with autocast():\n#                 y_preds = model(inputs, counts)\n#                 loss = criterion(y_preds.view(-1), targets)\n#         else:\n#             y_preds = model(inputs, counts)\n#             loss = criterion(y_preds.view(-1), targets)\n            \n#         # record loss\n#         losses.update(loss.item(), batch_size)\n\n#         preds.append(y_preds.sigmoid().detach().cpu().numpy())\n        \n#         if cfg.gradient_accumulation_steps > 1:\n#             loss = loss / cfg.gradient_accumulation_steps\n            \n#         if cfg.apex:\n#             scaler.scale(loss).backward()\n#         else:\n#             loss.backward()\n            \n#         grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        \n#         if (step + 1) % cfg.gradient_accumulation_steps == 0:\n#             if cfg.apex:\n#                 scaler.step(optimizer)\n#                 scaler.update()\n#             else:\n#                 optimizer.step()\n\n#             if isinstance(scheduler, OneCycleLR):\n#                 scheduler.step()\n\n#             optimizer.zero_grad()\n#             global_step += 1\n\n#         # measure elapsed time\n#         batch_time.update(time.time() - end)\n#         end = time.time()\n        \n#         if step % cfg.print_freq == 0 or step == (len(train_dl)-1):\n#             print(\"Epoch: [{0}][{1}/{2}] \"\n#                   \"Elapsed {remain:s} \"\n#                   \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n#                   \"Grad: {grad_norm:.4f}  \"\n#                   \"LR: {lr:.6f}  \"\n#                   .format(epoch+1, step, len(train_dl), \n#                           remain = timeSince(start, float(step+1)/len(train_dl)),\n#                           loss = losses,\n#                           grad_norm = grad_norm,\n#                           lr = scheduler.get_lr()[0]))\n    \n#     predictions = np.concatenate(preds)\n    \n#     return losses.avg, predictions\n\n\n\n# def valid_fn(cfg, valid_dl, model, criterion):\n#     batch_time = AverageMeter()\n#     data_time = AverageMeter()\n#     losses = AverageMeter()\n    \n#     # switch to evaluation mode\n#     model.eval()\n#     preds = []\n#     start = end = time.time()\n#     for step, data in enumerate(valid_dl):\n#         # measure data loading time\n#         data_time.update(time.time() - end)\n        \n#         inputs = data[\"X\"].to(cfg.device)\n#         counts = data[\"counts\"].to(cfg.device)\n#         targets = data[\"y\"].to(cfg.device)\n#         batch_size = targets.size(0)\n        \n#         # compute loss\n#         with torch.no_grad():\n#             y_preds = model(inputs, counts)\n#         loss = criterion(y_preds.view(-1), targets)\n#         losses.update(loss.item(), batch_size)\n        \n#         preds.append(y_preds.sigmoid().detach().cpu().numpy())\n        \n#         if cfg.gradient_accumulation_steps > 1:\n#             loss = loss / cfg.gradient_accumulation_steps\n            \n#         # measure elapsed time\n#         batch_time.update(time.time() - end)\n#         end = time.time()\n        \n#         if step % cfg.print_freq == 0 or step == (len(valid_dl)-1):\n#             print(\"EVAL: [{0}/{1}] \"\n#                 \"Elapsed {remain:s} \"\n#                 \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n#                 .format(step, len(valid_dl),\n#                         loss=losses,\n#                         remain=timeSince(start, float(step+1)/len(valid_dl))))\n            \n#     predictions = np.concatenate(preds)\n    \n#     return losses.avg, predictions\n\n\n\n# def train_loop(cfg, logger, models_path, fold,\n#                X_train_cv, y_train_cv, counts_train_cv, counts_val_cv, X_val_cv, y_val_cv):\n\n#         train_cv_ds = TrainDataset(X_train_cv, counts_train_cv, y_train_cv)\n#         val_cv_ds = TrainDataset(X_val_cv, counts_val_cv, y_val_cv)\n        \n#         train_cv_dl = DataLoader(train_cv_ds,\n#                                 batch_size = cfg.batch_size, \n#                                 shuffle = True, \n#                                 num_workers = cfg.num_workers, pin_memory=True, drop_last=True)\n#         val_cv_dl = DataLoader(val_cv_ds, \n#                             batch_size = cfg.batch_size * 2, \n#                             shuffle = False, \n#                             num_workers = cfg.num_workers, pin_memory=True, drop_last=False)\n        \n#         model = simplenet()\n#         model.to(cfg.device)\n\n#         optimizer = Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, amsgrad=False)\n#         scheduler = get_scheduler(cfg, optimizer, train_cv_dl)\n        \n#         criterion = nn.BCEWithLogitsLoss()\n\n#         best_score = 0\n        \n#         for epoch in range(cfg.epochs):\n            \n#             start_time = time.time()\n            \n#             # train\n#             avg_loss, _ = train_fn(cfg, train_cv_dl, model, criterion, optimizer, epoch, scheduler)\n#             # eval\n#             avg_val_loss, preds_val_cv = valid_fn(cfg, val_cv_dl, model, criterion)\n            \n#             if isinstance(scheduler, ReduceLROnPlateau):\n#                 scheduler.step(avg_val_loss)\n#             elif isinstance(scheduler, CosineAnnealingLR):\n#                 scheduler.step()\n#             elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n#                 scheduler.step()\n\n#             # scoring\n#             score = get_score(y_val_cv, preds_val_cv)\n\n#             elapsed = time.time() - start_time\n\n#             logger.info(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\")\n#             logger.info(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n\n#             if score > best_score:\n#                 best_score = score\n#                 logger.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n#                 torch.save({\"model\": model.state_dict(), \n#                             \"preds\": preds_val_cv},\n#                             os.path.join(models_path, f\"model_best_score_fold{fold}.pth\"))\n            \n#         preds_val_cv = torch.load(os.path.join(models_path, f\"model_best_score_fold{fold}.pth\"), \n#                                   map_location = torch.device(\"cpu\"))[\"preds\"]\n\n#         return preds_val_cv","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:30.234494Z","iopub.execute_input":"2022-04-19T10:51:30.234768Z","iopub.status.idle":"2022-04-19T10:51:30.273128Z","shell.execute_reply.started":"2022-04-19T10:51:30.234731Z","shell.execute_reply":"2022-04-19T10:51:30.272434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Functions for validation and inference","metadata":{}},{"cell_type":"code","source":"# def create_folds(df_train_labels, n_splits):\n    \n#     cv = GroupKFold(n_splits=n_splits)\n#     df_train_labels[\"fold\"] = -1\n\n#     for fold, (_, val_idx) in enumerate(cv.split(df_train_labels, df_train_labels[\"state\"], groups=df_train_labels[\"subject\"])):\n#         df_train_labels.loc[val_idx, \"fold\"] = fold\n        \n#     return df_train_labels\n\n\n\n# def get_score(y_true, y_pred):\n#     score = roc_auc_score(y_true, y_pred)\n#     return score\n\n\n\n# def validate(cfg, logger, X_train, counts_train, y_train):\n    \n#     oofs_preds = y_train.copy()\n#     oofs_preds[\"preds\"] = 0\n    \n#     for fold in range(cfg.n_splits):\n        \n#         logger.info(f\"Fold: {fold}\")\n                    \n#         train_idx = y_train[\"fold\"] != fold\n#         val_idx = y_train[\"fold\"] == fold\n\n#         X_train_cv, X_val_cv = X_train[train_idx], X_train[val_idx]\n#         counts_train_cv, counts_val_cv = counts_train[train_idx], counts_train[val_idx]\n#         y_train_cv, y_val_cv = y_train.loc[train_idx, \"state\"].values, y_train.loc[val_idx, \"state\"].values\n        \n#         preds_val = train_loop(cfg, logger, models_path, fold,\n#                                X_train_cv, y_train_cv,\n#                                counts_train_cv, counts_val_cv, \n#                                X_val_cv, y_val_cv)\n        \n#         oofs_preds.loc[val_idx, \"preds\"] = preds_val\n\n#     score = get_score(y_train[\"state\"], oofs_preds[\"preds\"])\n#     logger.info(f\"Final Score: {score:.4f}\")\n    \n#     return oofs_preds\n\n\n        \n# def inference(cfg, X_test, counts_test):\n    \n#     test_ds = TestDataset(counts_test, X_test)\n#     test_dl = DataLoader(test_ds, \n#                          batch_size = cfg.batch_size * 2, \n#                          shuffle = False, \n#                          num_workers = cfg.num_workers, pin_memory=True, drop_last=False)\n    \n#     chkpts = [os.path.join(models_path, model) for model in os.listdir(models_path)]\n\n#     predictions = 0\n#     for c in chkpts:\n#         batch_time = AverageMeter()\n#         data_time = AverageMeter()\n        \n#         model = simplenet()\n#         model.load_state_dict(torch.load(c)[\"model\"])\n#         model.to(cfg.device)\n        \n#         model.eval()\n#         preds = []\n#         start = end = time.time()\n        \n#         for step, data in enumerate(test_dl):\n            \n#             data_time.update(time.time() - end)\n            \n#             inputs = data[\"X\"].to(cfg.device)\n#             counts = data[\"counts\"].to(cfg.device)\n            \n#             with torch.no_grad():\n#                 y_preds = model(inputs, counts)\n            \n#             preds.append(y_preds.sigmoid().detach().cpu().numpy())\n                            \n#             # measure elapsed time\n#             batch_time.update(time.time() - end)\n#             end = time.time()\n            \n#             if step % cfg.print_freq == 0 or step == (len(test_dl)-1):\n#                 print(\"EVAL: [{0}/{1}] \"\n#                     \"Elapsed {remain:s} \"\n#                     .format(step, len(test_dl),\n#                             remain = timeSince(start, float(step+1)/len(test_dl))))\n                \n#         predictions += np.concatenate(preds) / len(chkpts)\n    \n#     return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:30.274534Z","iopub.execute_input":"2022-04-19T10:51:30.275086Z","iopub.status.idle":"2022-04-19T10:51:30.294882Z","shell.execute_reply.started":"2022-04-19T10:51:30.275024Z","shell.execute_reply":"2022-04-19T10:51:30.294112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Config file","metadata":{}},{"cell_type":"code","source":"# class CFG:\n#     data_path = \"/kaggle/input/tabular-playground-series-apr-2022/\"\n#     work_path = \"/kaggle/working/\"\n#     sim_name = \"sim_1\"\n#     n_splits = 10\n#     img_size = 60\n#     seed = 42\n#     device = \"cuda:0\"\n#     apex = False\n#     print_freq = 100\n#     num_workers = 4\n#     scheduler = \"CosineAnnealingLR\" # [\"ReduceLROnPlateau\", \"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"]\n#     epochs = 10\n#     # factor = 0.2 # ReduceLROnPlateau\n#     # patience = 4 # ReduceLROnPlateau\n#     # eps = 1e-6 # ReduceLROnPlateau\n#     T_max = 10 # CosineAnnealingLR\n#     # T_0 = 3 # CosineAnnealingWarmRestarts\n#     lr = 1e-3\n#     min_lr = 1e-6\n#     # max_lr = 1e-4\n#     batch_size = 64\n#     weight_decay = 1e-6\n#     gradient_accumulation_steps = 1\n#     max_grad_norm = 1000","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:30.297466Z","iopub.execute_input":"2022-04-19T10:51:30.297957Z","iopub.status.idle":"2022-04-19T10:51:30.309472Z","shell.execute_reply.started":"2022-04-19T10:51:30.297918Z","shell.execute_reply":"2022-04-19T10:51:30.308385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Validation and inference","metadata":{}},{"cell_type":"code","source":"# oofs_path = os.path.join(CFG.work_path, \"oofs\", CFG.sim_name)\n# subs_path = os.path.join(CFG.work_path, \"subs\", CFG.sim_name)\n# models_path = os.path.join(CFG.work_path, \"models\", CFG.sim_name)\n# logs_path = os.path.join(CFG.work_path, \"logs\", CFG.sim_name)\n# os.makedirs(oofs_path, exist_ok=True)\n# os.makedirs(subs_path, exist_ok=True)\n# os.makedirs(models_path, exist_ok=True)\n# os.makedirs(logs_path, exist_ok=True)\n\n# LOGGER = init_logger(logs_path)\n# set_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:30.310959Z","iopub.execute_input":"2022-04-19T10:51:30.311295Z","iopub.status.idle":"2022-04-19T10:51:30.323646Z","shell.execute_reply.started":"2022-04-19T10:51:30.31126Z","shell.execute_reply":"2022-04-19T10:51:30.322785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_csv(os.path.join(CFG.data_path, \"train.csv\"))\n# df_test = pd.read_csv(os.path.join(CFG.data_path, \"test.csv\"))\n# df_train_labels = pd.read_csv(os.path.join(CFG.data_path, \"train_labels.csv\"))\n\n# df_train_labels[\"subject\"] = df_train.groupby(\"sequence\")[\"subject\"].head(1).values\n\n# df_train_labels = create_folds(df_train_labels, CFG.n_splits)\n\n# sensors = [f for f in df_train.columns if \"sensor_\" in f]","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:51:55.682209Z","iopub.execute_input":"2022-04-19T10:51:55.682832Z","iopub.status.idle":"2022-04-19T10:52:01.641542Z","shell.execute_reply.started":"2022-04-19T10:51:55.68279Z","shell.execute_reply":"2022-04-19T10:52:01.640641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_all = pd.concat([df_train, df_test], axis=0)\n\n# del df_train\n# del df_test\n# gc.collect()\n\n# df_all_piv = df_all.pivot(\n#     index = [\"sequence\", \"subject\"], \n#     columns = \"step\", \n#     values = sensors\n#     )","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:52:01.643506Z","iopub.execute_input":"2022-04-19T10:52:01.643796Z","iopub.status.idle":"2022-04-19T10:52:02.815742Z","shell.execute_reply.started":"2022-04-19T10:52:01.643757Z","shell.execute_reply":"2022-04-19T10:52:02.814931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# counts_dict = df_all.groupby(\"subject\")[\"sequence\"].count().to_dict()\n# counts_all = df_all_piv.index.get_level_values(\"subject\").to_series().map(counts_dict).values\n# counts_all = (counts_all - counts_all.min()) / (counts_all.max() - counts_all.min())\n# counts_train = counts_all[:len(df_train_labels)]\n# counts_test = counts_all[len(df_train_labels):]\n\n# del df_all\n# del counts_all\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:52:02.817275Z","iopub.execute_input":"2022-04-19T10:52:02.817568Z","iopub.status.idle":"2022-04-19T10:52:02.988064Z","shell.execute_reply.started":"2022-04-19T10:52:02.81753Z","shell.execute_reply":"2022-04-19T10:52:02.987227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gasf = GramianAngularField(image_size=CFG.img_size, method=\"summation\")\n# X_all = np.zeros((len(df_all_piv), len(sensors), CFG.img_size, CFG.img_size))\n# for c,s in enumerate(sensors):\n#     sensor_data = df_all_piv.loc[:, df_all_piv.columns.get_level_values(0) == s].values\n#     X_all[:,c,:,:] = gasf.fit_transform(sensor_data)\n    \n# X_train = X_all[:len(df_train_labels), :, :, :]    \n# X_test = X_all[len(df_train_labels):, :, :, :]\n# y_train = df_train_labels.copy()\n\n# del X_all\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:52:02.989825Z","iopub.execute_input":"2022-04-19T10:52:02.990158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oofs_predictions = validate(CFG, LOGGER, X_train, sensors, counts_train, y_train, gasf_list)\n# oofs_predictions.to_csv(os.path.join(oofs_path, \"oofs.csv\"), index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:44:41.172016Z","iopub.execute_input":"2022-04-19T10:44:41.172295Z","iopub.status.idle":"2022-04-19T10:44:41.175834Z","shell.execute_reply.started":"2022-04-19T10:44:41.172264Z","shell.execute_reply":"2022-04-19T10:44:41.175174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_predictions = inference(CFG, X_test, sensors, counts_test, gasf_list)\n# sub = pd.read_csv(os.path.join(CFG.path, \"data\", \"sample_submission.csv\"))\n# sub[\"state\"] = test_predictions\n# sub.to_csv(os.path.join(subs_path, \"submission.csv\"), index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T10:24:22.292515Z","iopub.status.idle":"2022-04-19T10:24:22.293242Z","shell.execute_reply.started":"2022-04-19T10:24:22.292979Z","shell.execute_reply":"2022-04-19T10:24:22.293007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}