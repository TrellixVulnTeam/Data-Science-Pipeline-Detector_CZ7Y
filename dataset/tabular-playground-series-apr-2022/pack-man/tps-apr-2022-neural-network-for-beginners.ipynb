{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***[TPS Apr 2022] Neural Network for Beginners***","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://deepage.net/img/post_nn_example/thumbnail.jpg\" width=\"500\">","metadata":{}},{"cell_type":"markdown","source":"In TPS Apr 2022, many notebooks that make predictions using Neural Networks such as LSTM are published. However, I think it is difficult for many beginners, including myself, to understand. The goal of this notebook is to explain Neural Networks so that even beginners can understand them.","metadata":{}},{"cell_type":"markdown","source":"*  There are some places where the explanation is insufficient, so I will update it from time to time.\n* I've just started learning about Neural Network, so if there are any mistakes please point out in the comments.\n* I'm not good at English, so my English may be wrong in some places.","metadata":{}},{"cell_type":"markdown","source":"# Reference Notebook\nAnd here are some great notebooks that I've refered when creating this notebook. Please check it out.\n* [Top 1% | TPS APR 22 EDA | LSTM](https://www.kaggle.com/code/kartushovdanil/top-1-tps-apr-22-eda-lstm)\n* [LSTM Baseline](https://www.kaggle.com/code/ryanbarretto/lstm-baseline)\n* [Tps April Tensorflow Bi-LSTM](https://www.kaggle.com/code/hamzaghanmi/tps-april-tensorflow-bi-lstm)","metadata":{}},{"cell_type":"markdown","source":"# Import each data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:04:45.88543Z","iopub.execute_input":"2022-04-13T01:04:45.885778Z","iopub.status.idle":"2022-04-13T01:04:45.921447Z","shell.execute_reply.started":"2022-04-13T01:04:45.885695Z","shell.execute_reply":"2022-04-13T01:04:45.918382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2022/train.csv')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:04:45.99492Z","iopub.execute_input":"2022-04-13T01:04:45.995396Z","iopub.status.idle":"2022-04-13T01:04:55.215346Z","shell.execute_reply.started":"2022-04-13T01:04:45.995337Z","shell.execute_reply":"2022-04-13T01:04:55.214455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/tabular-playground-series-apr-2022/train_labels.csv')\ntrain_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:04:55.217Z","iopub.execute_input":"2022-04-13T01:04:55.217227Z","iopub.status.idle":"2022-04-13T01:04:55.244297Z","shell.execute_reply.started":"2022-04-13T01:04:55.217201Z","shell.execute_reply":"2022-04-13T01:04:55.24348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/tabular-playground-series-apr-2022/test.csv')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:04:55.245749Z","iopub.execute_input":"2022-04-13T01:04:55.246094Z","iopub.status.idle":"2022-04-13T01:04:59.300579Z","shell.execute_reply.started":"2022-04-13T01:04:55.246054Z","shell.execute_reply":"2022-04-13T01:04:59.299864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"### 1. Create lag and difference features so that you can see amount of changes in each sensors. ","metadata":{}},{"cell_type":"code","source":"features = train_df.columns.tolist()[3:]\ndef preprocessing(df):\n    for feature in features:\n        df[feature + '_lag1'] = df.groupby('sequence')[feature].shift(1)\n        df.fillna(0, inplace=True)\n        df[feature + '_diff1'] = df[feature] - df[feature + '_lag1']    \n\npreprocessing(train_df)\npreprocessing(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:04:59.302129Z","iopub.execute_input":"2022-04-13T01:04:59.302549Z","iopub.status.idle":"2022-04-13T01:05:06.373119Z","shell.execute_reply.started":"2022-04-13T01:04:59.3025Z","shell.execute_reply":"2022-04-13T01:05:06.372005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. StanderdScaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfeatures = train_df.columns.tolist()[3:]\nsc = StandardScaler()\ntrain_df[features] = sc.fit_transform(train_df[features])\ntest_df[features] = sc.transform(test_df[features])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:05:06.374241Z","iopub.execute_input":"2022-04-13T01:05:06.374514Z","iopub.status.idle":"2022-04-13T01:05:09.996817Z","shell.execute_reply.started":"2022-04-13T01:05:06.374482Z","shell.execute_reply":"2022-04-13T01:05:09.995915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Reshape data","metadata":{}},{"cell_type":"code","source":"groups = train_df['sequence']\nlabels = train_labels['state']\n\ntrain_df = train_df.drop(['sequence', 'subject', 'step'], axis=1).values\ntrain_df = train_df.reshape(-1, 60, train_df.shape[-1])\n\ntest_df = test_df.drop(['sequence', 'subject', 'step'], axis=1).values\ntest_df = test_df.reshape(-1, 60, test_df.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:05:09.997976Z","iopub.execute_input":"2022-04-13T01:05:09.998653Z","iopub.status.idle":"2022-04-13T01:05:10.235391Z","shell.execute_reply.started":"2022-04-13T01:05:09.998617Z","shell.execute_reply":"2022-04-13T01:05:10.234474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I was taught a WEB page that shows how to difine the input shape in LSTM. Please take a look.\n[reshape input data LSTM](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/)","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"### 1. Import libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import GlobalMaxPooling1D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.layers import Concatenate, LSTM, GRU\nfrom tensorflow.keras.layers import Bidirectional, Multiply\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import GroupKFold","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-13T01:05:10.236715Z","iopub.execute_input":"2022-04-13T01:05:10.236953Z","iopub.status.idle":"2022-04-13T01:05:16.511584Z","shell.execute_reply.started":"2022-04-13T01:05:10.236926Z","shell.execute_reply":"2022-04-13T01:05:16.510603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Set  TPU","metadata":{}},{"cell_type":"markdown","source":"Neural networks take a lot of time to learn, so we use TPU. Open up the settings menu in the Notebook editor, and select ‘TPU v3-8’ in the Accelerator menu.","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-13T01:05:16.513109Z","iopub.execute_input":"2022-04-13T01:05:16.513389Z","iopub.status.idle":"2022-04-13T01:05:22.16295Z","shell.execute_reply.started":"2022-04-13T01:05:16.513324Z","shell.execute_reply":"2022-04-13T01:05:22.162205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Define model","metadata":{}},{"cell_type":"code","source":"def BuildNN():\n    with tpu_strategy.scope():\n        x_input = Input(shape=(train_df.shape[-2:]))\n    \n        x1 = Bidirectional(LSTM(units=512, return_sequences=True))(x_input)\n        x2 = Bidirectional(LSTM(units=256, return_sequences=True))(x1)\n        z1 = Bidirectional(GRU(units=256, return_sequences=True))(x1)\n    \n        c = Concatenate(axis=2)([x2, z1])\n    \n        x3 = Bidirectional(LSTM(units=128, return_sequences=True))(c)\n    \n        x4 = GlobalMaxPooling1D()(x3)\n        x5 = Dense(units=128, activation='selu')(x4)\n        x_output = Dense(1, activation='sigmoid')(x5)\n\n        model = Model(inputs=x_input, outputs=x_output, name='lstm_model')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:05:22.163859Z","iopub.execute_input":"2022-04-13T01:05:22.164093Z","iopub.status.idle":"2022-04-13T01:05:22.17405Z","shell.execute_reply.started":"2022-04-13T01:05:22.164066Z","shell.execute_reply":"2022-04-13T01:05:22.173096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **bidirectional** : Bidirectional wrapper for RNNs.\n* **LSTM** : Long Short-Term Memory\n* **Concatenate** : This takes as input a list of tensors, all of the same shape except for the concatenation axis, and returns a single tensor that is the concatenation of all inputs.\n* **GlobalMaxPooling1D** : Downsamples the input representation by taking the maximum value over the time dimension.\n* **Dence** : This is used to create fully connected layers, in which every output depends on every input.","metadata":{}},{"cell_type":"code","source":"model = BuildNN()\nmodel.compile(optimizer='adam',loss='binary_crossentropy', metrics='AUC')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:05:22.176555Z","iopub.execute_input":"2022-04-13T01:05:22.177323Z","iopub.status.idle":"2022-04-13T01:05:31.834815Z","shell.execute_reply.started":"2022-04-13T01:05:22.177282Z","shell.execute_reply":"2022-04-13T01:05:31.833871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* optimizer : Algorithm for efficient loss minimization (ex. 'adam', 'RMSProp')\n* loss : The difference between the expected outcome and the outcome produced by model  (ex. 'mean_squared_error', 'binary_crossentropy')\n* A function that is used to judge the performance of model (ex. 'MAE', 'ACC', 'AUC')\n\nIn this competition, submissions are evaluated on ***area under the ROC curve*** between the predicted probability and the observed target. So, you should set metrics to AUC.","metadata":{}},{"cell_type":"markdown","source":"### 4. Visualize model","metadata":{}},{"cell_type":"code","source":"%pip install pydot\n%pip install pydotplus","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-13T01:05:31.836341Z","iopub.execute_input":"2022-04-13T01:05:31.836611Z","iopub.status.idle":"2022-04-13T01:05:52.351781Z","shell.execute_reply.started":"2022-04-13T01:05:31.836583Z","shell.execute_reply":"2022-04-13T01:05:52.350741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:05:52.35339Z","iopub.execute_input":"2022-04-13T01:05:52.353682Z","iopub.status.idle":"2022-04-13T01:05:52.36705Z","shell.execute_reply.started":"2022-04-13T01:05:52.353646Z","shell.execute_reply":"2022-04-13T01:05:52.366343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:05:52.368899Z","iopub.execute_input":"2022-04-13T01:05:52.369129Z","iopub.status.idle":"2022-04-13T01:05:54.072959Z","shell.execute_reply.started":"2022-04-13T01:05:52.369103Z","shell.execute_reply":"2022-04-13T01:05:54.071756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Training the Model","metadata":{}},{"cell_type":"code","source":"scores = []\ntest_preds = []\nkf = GroupKFold(n_splits=10)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T01:08:18.665928Z","iopub.execute_input":"2022-04-13T01:08:18.666649Z","iopub.status.idle":"2022-04-13T01:08:18.671848Z","shell.execute_reply.started":"2022-04-13T01:08:18.666603Z","shell.execute_reply":"2022-04-13T01:08:18.670895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### GroupKFold\nGrouping the data by 'sequence' and performing KFold, the data will not be separated within the same 'sequence'.","metadata":{}},{"cell_type":"code","source":"for fold_idx, (train_idx, valid_idx) in enumerate(kf.split(train_df, train_labels, groups.unique())):\n    \n    print('\\n')\n    print('*'*15, f'↓ Fold {fold_idx+1} ↓', '*'*15)\n    \n    # Separate into train data and validation data\n    X_train, X_valid = train_df[train_idx], train_df[valid_idx]\n    y_train, y_valid = labels.iloc[train_idx].values, labels.iloc[valid_idx].values\n    \n    # Train the model\n    model.fit(X_train, y_train, \n              validation_data=(X_valid, y_valid), \n              epochs=15, \n              batch_size=1024, \n              callbacks=[EarlyStopping(monitor='val_auc', patience=7, mode='max', \n                                       restore_best_weights=True),\n                         ReduceLROnPlateau(monitor='val_auc', factor=0.6, \n                                           patience=4, verbose=False)]\n             )\n    \n    # Save score\n    score = roc_auc_score(y_valid, model.predict(X_valid, batch_size=512).squeeze())\n    scores.append(score)\n    \n    # Predict\n    test_preds.append(model.predict(test_df, batch_size=512).squeeze())\n    \n    print(f'Fold {fold_idx+1} | Score: {score}')\n    print('*'*15, f'↑ Fold {fold_idx+1} ↑', '*'*15)\n    \nprint(f'Mean accuracy on {kf.n_splits} folds {np.mean(scores)}')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-13T01:08:19.828688Z","iopub.execute_input":"2022-04-13T01:08:19.829449Z","iopub.status.idle":"2022-04-13T01:09:00.09251Z","shell.execute_reply.started":"2022-04-13T01:08:19.829412Z","shell.execute_reply":"2022-04-13T01:09:00.090528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Batch_size** : the number of samples that will be propagated through the network\n* **Epoch** : the number times that the learning will work through the entire training dataset.\n\nIncreasing the epoch causes overfitting, so I set EarlyStopping to stop learning before overfitting occurs.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-apr-2022/sample_submission.csv\")\n\nsubmission[\"state\"] = sum(test_preds)/kf.n_splits\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-04-08T05:16:38.818517Z","iopub.execute_input":"2022-04-08T05:16:38.818738Z","iopub.status.idle":"2022-04-08T05:16:38.881472Z","shell.execute_reply.started":"2022-04-08T05:16:38.818712Z","shell.execute_reply":"2022-04-08T05:16:38.880595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}