{"cells":[{"metadata":{},"cell_type":"markdown","source":"Using kenpom websites to make predictions creates problem of leakage because they update their stats after the tournament end. Therefore, in this notebook, I decided to scrap kenpom data before tournament for each year. I did it between 2011 to 2021. If you find archives for earlier years please put it in comment section.\n\nInspiration code source: https://www.kaggle.com/walterhan/scrape-kenpom-data"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install bs4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom bs4 import BeautifulSoup\nimport requests","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scraper"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"base_urls=[\n          'https://web.archive.org/web/20110311233233/http://www.kenpom.com/',\n          'https://web.archive.org/web/20120311165019/http://kenpom.com/',\n          'https://web.archive.org/web/20130318221134/http://kenpom.com/',\n          'https://web.archive.org/web/20140318100454/http://kenpom.com/',\n          'https://web.archive.org/web/20150316212936/http://kenpom.com/',\n          'https://web.archive.org/web/20160314134726/http://kenpom.com/',\n          'https://web.archive.org/web/20170312131016/http://kenpom.com/',\n          'https://web.archive.org/web/20180311122559/https://kenpom.com/',\n          'https://web.archive.org/web/20190317211809/https://kenpom.com/',\n            'https://kenpom.com/index.php'\n         ]\n\ndef scrap_archive(url,year):\n    \"\"\"\n    Imports raw data from a kenpom archive into a dataframe\n    \"\"\"\n    \n    page = requests.get(url)\n    soup = BeautifulSoup(page.text)\n    table_full = soup.find_all('table', {'id': 'ratings-table'})\n\n    thead = table_full[0].find_all('thead')\n    table = table_full[0]\n    \n    for weird in thead:\n        table = str(table).replace(str(weird), '')\n\n    df = pd.read_html(table)[0]\n    if year==2020:\n        df['year'] = 2021\n    else:\n        df['year'] = year\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scraping"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scraping(df,year):\n    \n    for url in base_urls:\n    \n        print(f'Scrapping: {url}')\n        archive=scrap_archive(url,year)\n        \n        df = pd.concat( (df, archive), axis=0) \n        year+=1\n    \n    df.columns = ['Rank', 'Team', 'Conference', 'W-L', 'Pyth', \n             'AdjustO', 'AdjustO Rank', 'AdjustD', 'AdjustD Rank',\n             'AdjustT', 'AdjustT Rank', 'Luck', 'Luck Rank', \n             'SOS Pyth', 'SOS Pyth Rank', 'SOS OppO', 'SOS OppO Rank',\n             'SOS OppD', 'SOS OppD Rank', 'NCSOS Pyth', 'NCSOS Pyth Rank', 'Year']\n    \n    df=df[[ 'Year', 'Team', 'AdjustO', 'AdjustD', 'Luck','Rank','Pyth']]\n    df.columns=[ 'Season', 'TeamName', 'adj_o', 'adj_d', 'luck','rank','pyth']\n\n    df.TeamName=df.TeamName.apply(lambda x: re.sub('\\d', '', x).strip()).replace('.','')\n             \n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=None\nyear=2011\ndf=scraping(df,year)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Put TeamID"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.TeamName=df.TeamName.apply(lambda x: x.replace('-',' '))\ndf.TeamName=df.TeamName.apply(lambda x: x.lower())\ndf.TeamName=df.TeamName.apply(lambda x: x.strip())\ndf.TeamName=df.TeamName.replace('mississippi valley st.','mississippi valley state')\n#df.TeamName=df.TeamName.replace('texas a&m corpus chris','texas a&m corpus christi')\ndf.TeamName=df.TeamName.replace('dixie st.','dixie st')\ndf.TeamName=df.TeamName.replace('st. francis pa','st francis pa')\ndf.TeamName=df.TeamName.replace('ut rio grande valley','texas rio grande valley')\ndf.TeamName=df.TeamName.replace('southeast missouri st.','southeast missouri state')\ndf.TeamName=df.TeamName.replace('tarleton st.','tarleton st')\ndf.TeamName=df.TeamName.replace('liu','liu brooklyn')\ndf.TeamName=df.TeamName.replace('cal st. bakersfield','cal state bakersfield')\n\ndf.TeamName=df.TeamName.replace('virginia military inst','virginia military\t')\ndf.TeamName=df.TeamName.replace('louisiana saint','louisiana state')\ndf.TeamName=df.TeamName.replace('nj inst of technology','njit')\n\ndf.TeamName=df.TeamName.replace('texas a&m corpus chris','texas a&m corpus')\ndf.TeamName=df.TeamName.replace('md baltimore county','maryland baltimore county')\n#-------------------------------------------------------\n# merge with spelling file to get the TeamID\nspelling=pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MTeamSpellings.csv',encoding='cp1252')\nspelling.columns=['TeamName','TeamID']\nspelling.TeamName=spelling.TeamName.apply(lambda x: x.replace('-',' '))\ndf.TeamName=df.TeamName.apply(lambda x: x.strip())\n\n\ndf=df.merge(spelling[['TeamName','TeamID']],on='TeamName',how='left')\n\ndf.TeamName=df.TeamName.apply(lambda x: x.replace('st.','saint'))\ndf.TeamName=df.TeamName.apply(lambda x: x.replace(';',''))\ndf.TeamName=df.TeamName.apply(lambda x: x.replace('\\t',''))\ndf.TeamName=df.TeamName.replace('texas a&m corpus chris','texas a&m corpus')\ndf.TeamName=df.TeamName.replace('louisiana saint','louisiana state')\n\ndf=df.merge(spelling[['TeamName','TeamID']],on='TeamName',how='left')\n\ndf.TeamID_x.fillna(df.TeamID_y, inplace=True)\n\ndf=df[['Season','TeamID_x','adj_o','adj_d','luck','rank','pyth']]\ndf.columns=['Season','TeamID','adj_o','adj_d','luck','rank','pyth']\ndf.TeamID=df.TeamID.astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns=['Season','TeamID','adj_o','adj_d','luck','rank','adj_em']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.Season==2021]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save the file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('kenpom_2021.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}