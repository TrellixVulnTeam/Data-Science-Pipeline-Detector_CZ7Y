{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"932ebb10-ffd5-4181-52ae-7ed367a85a6e"},"source":"This notebook shows how to build a linear model on features from apps, app labels, phone brands and device models. It uses LogisticRegression classifier from sklearn. \n\nIt also shows an efficient way of constructing bag-of-apps and bag-of-labels features without concatenating a bunch of strings."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10e55365-83e8-f7b6-a26e-aaa376cad62a"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.metrics import log_loss"},{"cell_type":"markdown","metadata":{"_cell_guid":"29ab3f35-c097-465e-e2a5-4efe1aa836aa"},"source":"## Load data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e76e779c-b6b2-d800-1150-b920c610e9ff"},"outputs":[],"source":"datadir = '../input'\ngatrain = pd.read_csv(os.path.join(datadir,'gender_age_train.csv'),\n                      index_col='device_id')\ngatest = pd.read_csv(os.path.join(datadir,'gender_age_test.csv'),\n                     index_col = 'device_id')\nphone = pd.read_csv(os.path.join(datadir,'phone_brand_device_model.csv'))\n# Get rid of duplicate device ids in phone\nphone = phone.drop_duplicates('device_id',keep='first').set_index('device_id')\nevents = pd.read_csv(os.path.join(datadir,'events.csv'),\n                     parse_dates=['timestamp'], index_col='event_id')\nappevents = pd.read_csv(os.path.join(datadir,'app_events.csv'), \n                        usecols=['event_id','app_id','is_active'],\n                        dtype={'is_active':bool})\napplabels = pd.read_csv(os.path.join(datadir,'app_labels.csv'))"},{"cell_type":"markdown","metadata":{"_cell_guid":"456cc4a1-26fc-0248-9cec-e786adcb35c7"},"source":"## Feature engineering\n\nThe features I'm going to use include:\n\n* phone brand\n* device model\n* installed apps\n* app labels\n\nI'm going to one-hot encode everything and sparse matrices will help deal with a very large number of features.\n\n### Phone brand\n\nAs preparation I create two columns that show which train or test set row a particular device_id belongs to."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f81678cf-e762-19b5-0a67-cf6430689886"},"outputs":[],"source":"gatrain['trainrow'] = np.arange(gatrain.shape[0])\ngatest['testrow'] = np.arange(gatest.shape[0])"},{"cell_type":"markdown","metadata":{"_cell_guid":"c8d7224e-7680-789a-fd8c-633ac1a9093b"},"source":"A sparse matrix of features can be constructed in various ways. I use this constructor:\n\n    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n    where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n    relationship ``a[row_ind[k], col_ind[k]] = data[k]``\n    \nIt lets me specify which values to put into which places in a sparse matrix. For phone brand data the `data` array will be all ones, `row_ind` will be the row number of a device and `col_ind` will be the number of brand."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e93897e-518c-8ea3-4e55-b204f0d08985"},"outputs":[],"source":"brandencoder = LabelEncoder().fit(phone.phone_brand)\nphone['brand'] = brandencoder.transform(phone['phone_brand'])\ngatrain['brand'] = phone['brand']\ngatest['brand'] = phone['brand']\nXtr_brand = csr_matrix((np.ones(gatrain.shape[0]), \n                       (gatrain.trainrow, gatrain.brand)))\nXte_brand = csr_matrix((np.ones(gatest.shape[0]), \n                       (gatest.testrow, gatest.brand)))\nprint('Brand features: train shape {}, test shape {}'.format(Xtr_brand.shape, Xte_brand.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7668f876-da68-06aa-d9ab-5317cfbd2329"},"source":"### Device model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"850876c4-f13a-7854-f875-9f68617a6333"},"outputs":[],"source":"m = phone.phone_brand.str.cat(phone.device_model)\nmodelencoder = LabelEncoder().fit(m)\nphone['model'] = modelencoder.transform(m)\ngatrain['model'] = phone['model']\ngatest['model'] = phone['model']\nXtr_model = csr_matrix((np.ones(gatrain.shape[0]), \n                       (gatrain.trainrow, gatrain.model)))\nXte_model = csr_matrix((np.ones(gatest.shape[0]), \n                       (gatest.testrow, gatest.model)))\nprint('Model features: train shape {}, test shape {}'.format(Xtr_model.shape, Xte_model.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"617f26d5-0bcb-1071-6cbc-02231e171c48"},"source":"### Installed apps features\n\nFor each device I want to mark which apps it has installed. So I'll have as many feature columns as there are distinct apps.\n\nApps are linked to devices through events. So I do the following:\n\n- merge `device_id` column from `events` table to `app_events`\n- group the resulting dataframe by `device_id` and `app` and aggregate\n- merge in `trainrow` and `testrow` columns to know at which row to put each device in the features matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4e074f1-a1cd-c69e-f2e1-d2ea6aae8a27"},"outputs":[],"source":"appencoder = LabelEncoder().fit(appevents.app_id)\nappevents['app'] = appencoder.transform(appevents.app_id)\nnapps = len(appencoder.classes_)\ndeviceapps = (appevents.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n                       .groupby(['device_id','app'])['app'].agg(['size'])\n                       .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n                       .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n                       .reset_index())\ndeviceapps.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"445dc656-f877-743e-6eec-f2c217404d78"},"source":"Now I can build a feature matrix where the `data` is all ones, `row_ind` comes from `trainrow` or `testrow` and `col_ind` is the label-encoded `app_id`."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74a7f87d-6eb8-7553-addb-d32b72382506"},"outputs":[],"source":"d = deviceapps.dropna(subset=['trainrow'])\nXtr_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)), \n                      shape=(gatrain.shape[0],napps))\nd = deviceapps.dropna(subset=['testrow'])\nXte_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)), \n                      shape=(gatest.shape[0],napps))\nprint('Apps data: train shape {}, test shape {}'.format(Xtr_app.shape, Xte_app.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c48ad7c3-e0c1-8b11-da35-11f4b7f2d6b2"},"source":"### App labels features\n\nThese are constructed in a way similar to apps features by merging `app_labels` with the `deviceapps` dataframe we created above."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9bd3b7c-9146-ae81-ef83-e92e5bcd6868"},"outputs":[],"source":"applabels = applabels.loc[applabels.app_id.isin(appevents.app_id.unique())]\napplabels['app'] = appencoder.transform(applabels.app_id)\nlabelencoder = LabelEncoder().fit(applabels.label_id)\napplabels['label'] = labelencoder.transform(applabels.label_id)\nnlabels = len(labelencoder.classes_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2f082a8-8e42-a914-aa0d-f1b53ca17788"},"outputs":[],"source":"devicelabels = (deviceapps[['device_id','app']]\n                .merge(applabels[['app','label']])\n                .groupby(['device_id','label'])['app'].agg(['size'])\n                .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n                .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n                .reset_index())\ndevicelabels.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c4897b6-877a-2dc4-a546-a61dda27eb65"},"outputs":[],"source":"d = devicelabels.dropna(subset=['trainrow'])\nXtr_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), \n                      shape=(gatrain.shape[0],nlabels))\nd = devicelabels.dropna(subset=['testrow'])\nXte_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), \n                      shape=(gatest.shape[0],nlabels))\nprint('Labels data: train shape {}, test shape {}'.format(Xtr_label.shape, Xte_label.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"4d900504-996c-3bf1-9ff6-251166b6dc36"},"source":"### Concatenate all features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31c19090-6cab-8935-c0dd-5dc7af47d5c9"},"outputs":[],"source":"Xtrain = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label), format='csr')\nXtest =  hstack((Xte_brand, Xte_model, Xte_app, Xte_label), format='csr')\nprint('All features: train shape {}, test shape {}'.format(Xtrain.shape, Xtest.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc5e2845-0597-4bab-18c2-75deace40f40"},"source":"## Cross-validation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"100a586a-d05b-5c3c-fb80-3cd20f07505e"},"outputs":[],"source":"targetencoder = LabelEncoder().fit(gatrain.group)\ny = targetencoder.transform(gatrain.group)\nnclasses = len(targetencoder.classes_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9751cdd-08c3-7e6c-c9fe-39346662a857"},"outputs":[],"source":"def score(clf, random_state = 0):\n    kf = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=random_state)\n    pred = np.zeros((y.shape[0],nclasses))\n    for itrain, itest in kf:\n        Xtr, Xte = Xtrain[itrain, :], Xtrain[itest, :]\n        ytr, yte = y[itrain], y[itest]\n        clf.fit(Xtr, ytr)\n        pred[itest,:] = clf.predict_proba(Xte)\n        # Downsize to one fold only for kernels\n        return log_loss(yte, pred[itest, :])\n        print(\"{:.5f}\".format(log_loss(yte, pred[itest,:])), end=' ')\n    print('')\n    return log_loss(y, pred)"},{"cell_type":"markdown","metadata":{"_cell_guid":"84d78bff-af59-8862-8898-9ed974551e06"},"source":"In order to make a good logistic regression model we need to choose a value for regularization constant C. Smaller values of C mean stronger regularization and its default value is 1.0. We probably have a lot of mostly useless columns (rare brands, models or apps), so we'd better look at stronger regularization than default."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1973a17-8c40-69a3-14de-1cf29605ee62"},"outputs":[],"source":"Cs = np.logspace(-3,0,4)\nres = []\nfor C in Cs:\n    res.append(score(LogisticRegression(C = C)))\nplt.semilogx(Cs, res,'-o');"},{"cell_type":"markdown","metadata":{"_cell_guid":"636bc986-feac-7785-132c-c55216b6e674"},"source":"Judging by the plot the best value for C is somewhere between 0.01 and 0.1."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f78cfac0-0da0-f74e-eb20-7b45748173ca"},"outputs":[],"source":"score(LogisticRegression(C=0.02))"},{"cell_type":"markdown","metadata":{"_cell_guid":"633066eb-4335-f824-0744-644498191872"},"source":"By default [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) classifier solves a multiclass classification problem in a one versus rest fashion. But it's also possible to fit a multinomial model that optimizes the multiclass logloss - exactly the metric we're evaluated on. Let's see if doing that improves our results:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3510577f-e668-7885-1560-16f80f9b1eb8"},"outputs":[],"source":"score(LogisticRegression(C=0.02, multi_class='multinomial',solver='lbfgs'))"},{"cell_type":"markdown","metadata":{"_cell_guid":"b6ef299f-901b-86f7-3b7c-c5b546af46d1"},"source":"Yes, it does!"},{"cell_type":"markdown","metadata":{"_cell_guid":"6cf9883e-62c3-27dd-71af-ef765c59bafb"},"source":"## Predict on test data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9a67b06-83ec-cbce-d810-1a4ce78f3a9d"},"outputs":[],"source":"clf = LogisticRegression(C=0.02, multi_class='multinomial',solver='lbfgs')\nclf.fit(Xtrain, y)\npred = pd.DataFrame(clf.predict_proba(Xtest), index = gatest.index, columns=targetencoder.classes_)\npred.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0481f7e3-e8fc-59ce-6f02-4975fa5ef71a"},"outputs":[],"source":"pred.to_csv('logreg_subm.csv',index=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ac0f998c-0093-ce33-31dc-d7c1e60da87f"},"source":"## What to try next\n\n- use some aggregates for apps and labels features. Maybe using them instead of simple indicators shown here will improve the score. For example:\n    - calculate the proportion of events where an app appears on each device\n    - calculate the mean of `is_active` field for each app on each device\n    - create some TFIDF-like weighting for apps or labels\n- add features based on event locations and times\n- add feature interactions\n- fit a nonlinear model (neural networks seem to work well here)\n- blend in the results of the [previous script](https://www.kaggle.com/dvasyukova/talkingdata-mobile-user-demographics/brand-and-model-based-benchmarks) for devices that have no events data\n\nShare your ideas in the comments, fork and improve =)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"672b5128-a74f-b6e5-8243-b98ac9dc4a8b"},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfTransformer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6bf19de-8a41-a28e-332d-78a8ac18725d"},"outputs":[],"source":"tfidf = TfidfTransformer()\ndevicelabelstfidf = devicelabels.groupby(['device_id','label'])['size'].agg(['sum']).unstack().fillna(0)\ntransformedlabels = tfidf.fit_transform(devicelabelstfidf)\ntransformedlabels = pd.DataFrame(transformedlabels.toarray())\ndev_id = devicelabels.groupby('device_id')['size'].size().reset_index()\ndev_id.drop(0,1,inplace=True)\ntransformedlabels = dev_id.join(transformedlabels)\ntransformedlabels = transformedlabels.merge(gatrain.reset_index()[['trainrow','device_id']], how='left',on='device_id').merge(gatest.reset_index()[['testrow','device_id']], how='left', on='device_id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a478f95d-2d03-6e7d-301d-6cdeafae706a"},"outputs":[],"source":"f = transformedlabels.dropna(subset=['trainrow'])\nf.drop(['testrow','device_id'], axis=1, inplace=True)\nf.set_index('trainrow',inplace=True)\nf.sort_index(inplace=True)\nnew_index=np.arange(0,74645)\nf = f.reindex(new_index).fillna(0)\nXtr_tfidflabel = csr_matrix(f)\ng=transformedlabels.dropna(subset=['testrow'])\ng.drop(['trainrow','device_id'], axis=1, inplace=True)\ng.set_index('testrow',inplace=True)\ng.sort_index(inplace=True)\nnew_index = np.arange(0,112071)\ng = g.reindex(new_index).fillna(0)\nXte_tfidflabel = csr_matrix(g)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f140505-f685-253f-49a1-73c0d0bca834"},"outputs":[],"source":"events['hour'] = events['timestamp'].map(lambda x:pd.to_datetime(x).hour)\nevents['hourbin'] = [1 if ((x>=1)&(x<=6)) else 2 if ((x>=7)&(x<=12)) else 3 if ((x>=13)&(x<=18)) else 4 for x in events['hour']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed01c5e6-53fd-5b04-9a33-67d937e67ede"},"outputs":[],"source":"tfidf = TfidfTransformer()\nhourbintfidf = events.groupby(['device_id','hourbin'])['hourbin'].agg(['size']).unstack().fillna(0)\nhourbintfidf = tfidf.fit_transform(hourbintfidf)\nhourbintfidf = pd.DataFrame(hourbintfidf.toarray())\ndev_id = events.groupby('device_id').size().reset_index()\ndev_id.drop(0,1,inplace=True)\nhourbintfidf = dev_id.join(hourbintfidf)\nhourbintfidf = hourbintfidf.merge(gatrain.reset_index()[['trainrow','device_id']], how='left',on='device_id').merge(gatest.reset_index()[['testrow','device_id']], how='left', on='device_id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d60a4ef8-714a-de62-a198-acfcad0f31a4"},"outputs":[],"source":"f = hourbintfidf.dropna(subset=['trainrow'])\nf.drop(['testrow','device_id'], axis=1, inplace=True)\nf.set_index('trainrow',inplace=True)\nf.sort_index(inplace=True)\nnew_index=np.arange(0,74645)\nf = f.reindex(new_index).fillna(0)\nXtr_tfidfhourbin = csr_matrix(f)\ng=hourbintfidf.dropna(subset=['testrow'])\ng.drop(['trainrow','device_id'], axis=1, inplace=True)\ng.set_index('testrow',inplace=True)\ng.sort_index(inplace=True)\nnew_index = np.arange(0,112071)\ng = g.reindex(new_index).fillna(0)\nXte_tfidfhourbin = csr_matrix(g)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52b17612-8820-77e1-ee4d-4a01dc5e4f7b"},"outputs":[],"source":"Xtrain = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label,Xtr_tfidfhourbin,Xtr_tfidflabel), format='csr')\nXtest =  hstack((Xte_brand, Xte_model, Xte_app, Xte_label,Xte_tfidfhourbin,Xte_tfidflabel), format='csr')\nprint('All features: train shape {}, test shape {}'.format(Xtrain.shape, Xtest.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa6ef0e5-ce02-b896-d5e1-5e874c3109e1"},"outputs":[],"source":"from sklearn.feature_selection import SelectKBest,chi2\nselector = SelectKBest(chi2, k=8000).fit(Xtrain, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5121941e-b259-ee6f-a6af-f763529f3140"},"outputs":[],"source":"Xtrainkb = selector.transform(Xtrain)\nXtestkb = selector.transform(Xtest)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"625192b3-afd2-0575-3e4d-95deb4506997"},"outputs":[],"source":"def batch_generator(X, y, batch_size, shuffle):\n    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n    number_of_batches = np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    if shuffle:\n        np.random.shuffle(sample_index)\n    while True:\n        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n        X_batch = X[batch_index,:].toarray()\n        y_batch = y[batch_index]\n        counter += 1\n        yield X_batch, y_batch\n        if (counter == number_of_batches):\n            if shuffle:\n                np.random.shuffle(sample_index)\n            counter = 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"218aad39-a262-a029-a9ed-0934660f4199"},"outputs":[],"source":"def batch_generatorp(X, batch_size, shuffle):\n    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    while True:\n        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n        X_batch = X[batch_index, :].toarray()\n        counter += 1\n        yield X_batch\n        if (counter == number_of_batches):\n            counter = 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c928320-bcad-be84-2b99-bd24c0486634"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\nfrom keras.layers.advanced_activations import PReLU"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcd694c1-c004-876d-7979-0636a47b8205"},"outputs":[],"source":"def baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(150, input_dim=Xtrainkb.shape[1], init='normal'))\n    model.add(PReLU())\n    model.add(Dropout(0.4))\n    model.add(Dense(50, input_dim=Xtrainkb.shape[1], init='normal'))\n    model.add(PReLU())\n    model.add(Dropout(0.2))\n    model.add(Dense(12, init='normal', activation='softmax'))\n    # Compile model\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a56433c-318d-a338-7ffb-ef91e22db05a"},"outputs":[],"source":"model=baseline_model()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaab362d-4c26-f89c-c74d-a0b74b74626f"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d69c079-81ed-a06b-fd2a-5bf228734225"},"outputs":[],"source":"X_train, X_val, y_train, y_val = train_test_split(Xtrainkb, y, train_size=.98, random_state=10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcad1f68-2502-5c3b-ea74-fbbe0aea9d34"},"outputs":[],"source":"fit= model.fit_generator(generator=batch_generator(X_train, y_train, 400, True),\n                         nb_epoch=15,\n                         samples_per_epoch=69984,\n                         validation_data=(X_val.todense(), y_val), verbose=2\n                         )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00239d9f-cf5b-d745-02f4-f1190c121e92"},"outputs":[],"source":"scores_val = model.predict_generator(generator=batch_generatorp(X_val, 400, False), val_samples=X_val.shape[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0485f2a5-cbe6-c2e8-cec0-8b9d61546123"},"outputs":[],"source":"print('logloss val {}'.format(log_loss(y_val, scores_val)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d38aebda-e63f-ab0a-6c44-6b3a6bbdb96e"},"outputs":[],"source":"model=baseline_model()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5087231d-d6b7-efa3-b52e-81c9299808f4"},"outputs":[],"source":"scores_val = model.predict_generator(generator=batch_generatorp(X_val, 400, False), val_samples=X_val.shape[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78e5957c-8eb8-7bb7-d11a-055c587d94c1"},"outputs":[],"source":"print('logloss val {}'.format(log_loss(y_val, scores_val)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c38c9c0-4576-af93-fa86-a03ed5ca8644"},"outputs":[],"source":"scores = model.predict_generator(generator=batch_generatorp(Xtestkb, 800, False), val_samples=Xtestkb.shape[0])\nresult = pd.DataFrame(scores , columns=targetencoder.classes_)\nresult[\"device_id\"] = device_id\nresult = result.set_index(\"device_id\")\nresult.to_csv('bagofappskeras', index=True, index_label='device_id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22dbdf09-a668-6686-4bd2-f25d9a1176d1"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a2e7eef-cd0d-8b80-78ab-005063d7a3b8"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48e4254e-37db-b9ff-4954-e360289be119"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc20cd11-3d8a-a48b-609a-3777b7a8fa0f"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7735781-d43c-4bfd-5f0b-0625f6c84892"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1cdb0880-5bd2-5ee1-3fc1-570da0615385"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b91e62b-c4a5-3795-f2ee-128de6015f43"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}