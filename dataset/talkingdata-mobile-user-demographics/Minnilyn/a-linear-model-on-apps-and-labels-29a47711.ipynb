{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"932ebb10-ffd5-4181-52ae-7ed367a85a6e"},"source":"original:  This notebook shows how to build a linear model on features from apps, app labels, phone brands and device models. It uses LogisticRegression classifier from sklearn.   It also shows an efficient way of constructing bag-of-apps and bag-of-labels features without concatenating a bunch of strings.\n\nmodified:  I grafted on the popular Keras script by Samarth Agarwal to the matrices DuneDweller created here, and then made a 2D autoencoder, which allows me to plot each class (gender+age) at the end of this."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10e55365-83e8-f7b6-a26e-aaa376cad62a"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.metrics import log_loss"},{"cell_type":"markdown","metadata":{"_cell_guid":"29ab3f35-c097-465e-e2a5-4efe1aa836aa"},"source":"## Load data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e76e779c-b6b2-d800-1150-b920c610e9ff","collapsed":true},"outputs":[],"source":"datadir = '../input'\ngatrain = pd.read_csv(os.path.join(datadir,'gender_age_train.csv'),\n                      index_col='device_id')\ngatest = pd.read_csv(os.path.join(datadir,'gender_age_test.csv'),\n                     index_col = 'device_id')\nphone = pd.read_csv(os.path.join(datadir,'phone_brand_device_model.csv'))\n# Get rid of duplicate device ids in phone\nphone = phone.drop_duplicates('device_id',keep='first').set_index('device_id')\nevents = pd.read_csv(os.path.join(datadir,'events.csv'),\n                     parse_dates=['timestamp'], index_col='event_id')\nappevents = pd.read_csv(os.path.join(datadir,'app_events.csv'), \n                        usecols=['event_id','app_id','is_active'],\n                        dtype={'is_active':bool})\napplabels = pd.read_csv(os.path.join(datadir,'app_labels.csv'))"},{"cell_type":"markdown","metadata":{"_cell_guid":"456cc4a1-26fc-0248-9cec-e786adcb35c7"},"source":"## Feature engineering\n\nThe features I'm going to use include:\n\n* phone brand\n* device model\n* installed apps\n* app labels\n\nI'm going to one-hot encode everything and sparse matrices will help deal with a very large number of features.\n\n### Phone brand\n\nAs preparation I create two columns that show which train or test set row a particular device_id belongs to."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f81678cf-e762-19b5-0a67-cf6430689886","collapsed":true},"outputs":[],"source":"gatrain['trainrow'] = np.arange(gatrain.shape[0])\ngatest['testrow'] = np.arange(gatest.shape[0])"},{"cell_type":"markdown","metadata":{"_cell_guid":"c8d7224e-7680-789a-fd8c-633ac1a9093b"},"source":"A sparse matrix of features can be constructed in various ways. I use this constructor:\n\n    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n    where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n    relationship ``a[row_ind[k], col_ind[k]] = data[k]``\n    \nIt lets me specify which values to put into which places in a sparse matrix. For phone brand data the `data` array will be all ones, `row_ind` will be the row number of a device and `col_ind` will be the number of brand."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e93897e-518c-8ea3-4e55-b204f0d08985"},"outputs":[],"source":"brandencoder = LabelEncoder().fit(phone.phone_brand)\nphone['brand'] = brandencoder.transform(phone['phone_brand'])\ngatrain['brand'] = phone['brand']\ngatest['brand'] = phone['brand']\nXtr_brand = csr_matrix((np.ones(gatrain.shape[0]), \n                       (gatrain.trainrow, gatrain.brand)))\nXte_brand = csr_matrix((np.ones(gatest.shape[0]), \n                       (gatest.testrow, gatest.brand)))\nprint('Brand features: train shape {}, test shape {}'.format(Xtr_brand.shape, Xte_brand.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7668f876-da68-06aa-d9ab-5317cfbd2329"},"source":"### Device model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"850876c4-f13a-7854-f875-9f68617a6333"},"outputs":[],"source":"m = phone.phone_brand.str.cat(phone.device_model)\nmodelencoder = LabelEncoder().fit(m)\nphone['model'] = modelencoder.transform(m)\ngatrain['model'] = phone['model']\ngatest['model'] = phone['model']\nXtr_model = csr_matrix((np.ones(gatrain.shape[0]), \n                       (gatrain.trainrow, gatrain.model)))\nXte_model = csr_matrix((np.ones(gatest.shape[0]), \n                       (gatest.testrow, gatest.model)))\nprint('Model features: train shape {}, test shape {}'.format(Xtr_model.shape, Xte_model.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"617f26d5-0bcb-1071-6cbc-02231e171c48"},"source":"### Installed apps features\n\nFor each device I want to mark which apps it has installed. So I'll have as many feature columns as there are distinct apps.\n\nApps are linked to devices through events. So I do the following:\n\n- merge `device_id` column from `events` table to `app_events`\n- group the resulting dataframe by `device_id` and `app` and aggregate\n- merge in `trainrow` and `testrow` columns to know at which row to put each device in the features matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4e074f1-a1cd-c69e-f2e1-d2ea6aae8a27"},"outputs":[],"source":"appencoder = LabelEncoder().fit(appevents.app_id)\nappevents['app'] = appencoder.transform(appevents.app_id)\nnapps = len(appencoder.classes_)\ndeviceapps = (appevents.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n                       .groupby(['device_id','app'])['app'].agg(['size'])\n                       .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n                       .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n                       .reset_index())\ndeviceapps.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"445dc656-f877-743e-6eec-f2c217404d78"},"source":"Now I can build a feature matrix where the `data` is all ones, `row_ind` comes from `trainrow` or `testrow` and `col_ind` is the label-encoded `app_id`."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74a7f87d-6eb8-7553-addb-d32b72382506"},"outputs":[],"source":"d = deviceapps.dropna(subset=['trainrow'])\nXtr_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)), \n                      shape=(gatrain.shape[0],napps))\nd = deviceapps.dropna(subset=['testrow'])\nXte_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)), \n                      shape=(gatest.shape[0],napps))\nprint('Apps data: train shape {}, test shape {}'.format(Xtr_app.shape, Xte_app.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c48ad7c3-e0c1-8b11-da35-11f4b7f2d6b2"},"source":"### App labels features\n\nThese are constructed in a way similar to apps features by merging `app_labels` with the `deviceapps` dataframe we created above."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9bd3b7c-9146-ae81-ef83-e92e5bcd6868","collapsed":true},"outputs":[],"source":"applabels = applabels.loc[applabels.app_id.isin(appevents.app_id.unique())]\napplabels['app'] = appencoder.transform(applabels.app_id)\nlabelencoder = LabelEncoder().fit(applabels.label_id)\napplabels['label'] = labelencoder.transform(applabels.label_id)\nnlabels = len(labelencoder.classes_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2f082a8-8e42-a914-aa0d-f1b53ca17788"},"outputs":[],"source":"devicelabels = (deviceapps[['device_id','app']]\n                .merge(applabels[['app','label']])\n                .groupby(['device_id','label'])['app'].agg(['size'])\n                .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n                .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n                .reset_index())\ndevicelabels.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c4897b6-877a-2dc4-a546-a61dda27eb65"},"outputs":[],"source":"d = devicelabels.dropna(subset=['trainrow'])\nXtr_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), \n                      shape=(gatrain.shape[0],nlabels))\nd = devicelabels.dropna(subset=['testrow'])\nXte_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), \n                      shape=(gatest.shape[0],nlabels))\nprint('Labels data: train shape {}, test shape {}'.format(Xtr_label.shape, Xte_label.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"4d900504-996c-3bf1-9ff6-251166b6dc36"},"source":"### Concatenate all features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31c19090-6cab-8935-c0dd-5dc7af47d5c9"},"outputs":[],"source":"Xtrain = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label), format='csr')\nXtest =  hstack((Xte_brand, Xte_model, Xte_app, Xte_label), format='csr')\nprint('All features: train shape {}, test shape {}'.format(Xtrain.shape, Xtest.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc5e2845-0597-4bab-18c2-75deace40f40"},"source":"## Neural network setup"},{"cell_type":"markdown","metadata":{"_cell_guid":"ad199ee6-f84b-f607-84e4-86d456577bd8"},"source":"happycube:  Now to pull in keras and friends - most of this code is based directly from https://www.kaggle.com/samarthagarwal23/talkingdata-mobile-user-demographics/bag-of-apps-keras-11-08-16/run/327685"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2026d47-9061-c630-6e9e-c8103b234476"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\n\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.cross_validation import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import log_loss\n\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.layers import GaussianDropout, GaussianNoise\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.callbacks import EarlyStopping\n#from keras.callbacks import ModelCheckpoint"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f83484d7-9aae-6b7b-a9b9-1974c750b510","collapsed":true},"outputs":[],"source":"def rstr(df): return df.dtypes, df.head(3) ,df.apply(lambda x: [x.unique()]), df.apply(lambda x: [len(x.unique())]),df.shape\n\ndef batch_generator(X, y, batch_size, shuffle):\n    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n    number_of_batches = np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    if shuffle:\n        np.random.shuffle(sample_index)\n    while True:\n        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n        X_batch = X[batch_index,:].toarray()\n        y_batch = y[batch_index]\n        counter += 1\n        yield X_batch, y_batch\n        if (counter == number_of_batches):\n            if shuffle:\n                np.random.shuffle(sample_index)\n            counter = 0\n\ndef batch_generatorp(X, batch_size, shuffle):\n    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    while True:\n        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n        X_batch = X[batch_index, :].toarray()\n        counter += 1\n        yield X_batch\n        if (counter == number_of_batches):\n            counter = 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"116cbb6d-8022-5eab-6ac2-5010aebbed0e"},"outputs":[],"source":"targetencoder = LabelEncoder().fit(gatrain.group)\ny = targetencoder.transform(gatrain.group)\nnclasses = len(targetencoder.classes_)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    Xtrain, y, train_size=.98, random_state=10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3d13efe2-f8b5-e320-da1f-99ae312554d8"},"source":"This is where the modifications start - a 2-neuron dense network with PReLU activation is added, with the PReLU layer broken out into it's own variable, so that we can hook into it later"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b05f069-5fdb-0d33-be53-8140e8e2341f"},"outputs":[],"source":"def baseline_model():\n    # create model\n    model = Sequential()\n\n    model.add(Dense(150, input_dim=X_train.shape[1], init='glorot_normal'))\n    model.add(PReLU())\n    model.add(Dropout(0.4))\n    \n    model.add(Dense(2, init='glorot_normal'))\n    pre = PReLU()\n    model.add(pre)\n\n    model.add(Dense(50, init='glorot_normal'))\n    model.add(PReLU())\n    model.add(Dropout(0.2))\n    \n    model.add(Dense(12, init='glorot_normal', activation='softmax'))\n    # Compile model\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n    return model,pre\n\nmodel,pre=baseline_model()\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\n\n#checkpoint = ModelCheckpoint(\"weights.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\nfit= model.fit_generator(generator=batch_generator(X_train, y_train, 400, True),\n                         nb_epoch=15,\n                         samples_per_epoch=X_train.shape[0],\n                         validation_data=(X_val.todense(), y_val), verbose=2,\n                         callbacks=[early_stopping])"},{"cell_type":"markdown","metadata":{"_cell_guid":"512f3254-e591-85d7-0c6e-29e36bada3a5"},"source":"From: https://github.com/julienr/ipynb_playground/blob/master/keras/convmnist/keras_cnn_mnist_v1.ipynb\n\nAnd Keras issue #431 - near the end where the more recent backend api is used"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fbc3577e-021a-ae0c-91d9-a0b68a097617"},"outputs":[],"source":"def tocoords(inp):\n    coords = np.zeros((inp.shape[0], 2), dtype=np.float32)\n    \n    for i in range(0, inp.shape[0], 400):\n        #print(i, inp.shape[0])\n        if i + 400 > inp.shape[0]:\n            j = inp.shape[0]\n        else:\n            j = i + 400\n\n        y = fpre([0] + [inp[i:j].todense()])   \n        #print(y[0])\n        coords[i:j] = y[0]\n\n    return coords\n\ncoords_train = tocoords(X_train)\ncoords_valid = tocoords(X_val)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a2309e77-57a3-ee68-f597-5b73a3e505c3"},"source":"Now that we have the coordinates, build the lines for each gender..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb66b0db-6e91-7a46-e8a9-1ba6547d0e74"},"outputs":[],"source":"fline = []\nfor c in range(0, 6):\n    mask = y_train == c\n    coords_masked = coords_train[np.where(mask)]\n    \n    fline.append([np.mean(coords_masked[:,0]), np.mean(coords_masked[:,1])])\n    #print(c, min(coords_masked[:,0]), min(coords_masked[:,1]), max(coords_masked[:,0]), max(coords_masked[:,1]))\n    print(targetencoder.classes_[c], np.mean(coords_masked[:,0]), np.mean(coords_masked[:,1]), np.std(coords_masked[:,0]), np.std(coords_masked[:,1]))\n    \nmline = []\nfor c in range(6, 12):\n    mask = y_train == c\n    coords_masked = coords_train[np.where(mask)]\n    \n    mline.append([np.mean(coords_masked[:,0]), np.mean(coords_masked[:,1])])\n    #print(c, min(coords_masked[:,0]), min(coords_masked[:,1]), max(coords_masked[:,0]), max(coords_masked[:,1]))\n    print(targetencoder.classes_[c], np.mean(coords_masked[:,0]), np.mean(coords_masked[:,1]), np.std(coords_masked[:,0]), np.std(coords_masked[:,1]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0adc19f-3946-f2c8-dbb0-c9253f9148dc"},"source":"... and now draw them"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5d31a25-4b97-1fc1-fbb0-7ba5d4480c3a"},"outputs":[],"source":"fline = np.array(fline)\nplt.plot(fline[:,0], fline[:,1], 'g')\n\nmline = np.array(mline)\nplt.plot(mline[:,0], mline[:,1], 'r'\n)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"750dcf29-dd71-9411-af43-a457f6243f8a","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}