{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Based on yibo's R script\n\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom scipy import sparse\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\nfrom sklearn.decomposition import TruncatedSVD, SparsePCA\nfrom sklearn.cross_validation import train_test_split, cross_val_score\nfrom sklearn.feature_selection import SelectPercentile, f_classif, chi2\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.metrics import log_loss"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Based on yibo's R script\n\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom scipy import sparse\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\nfrom sklearn.decomposition import TruncatedSVD, SparsePCA\nfrom sklearn.cross_validation import train_test_split, cross_val_score\nfrom sklearn.feature_selection import SelectPercentile, f_classif, chi2\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.metrics import log_loss\n\n# Create bag-of-apps in character string format\n# first by event\n# then merge to generate larger bags by device\n\n##################\n#   App Events\n##################\nprint(\"# Read App Events\")\napp_ev = pd.read_csv(\"../input/app_events.csv\", dtype={'device_id': np.str})\n# remove duplicates(app_id)\napp_ev = app_ev.groupby(\"event_id\")[\"app_id\"].apply(\n    lambda x: \" \".join(set(\"app_id:\" + str(s) for s in x)))\n\n##################\n#     Events\n##################\nprint(\"# Read Events\")\nevents = pd.read_csv(\"../input/events.csv\", dtype={'device_id': np.str})\nevents[\"app_id\"] = events[\"event_id\"].map(app_ev)\n\nevents = events.dropna()\n\ndel app_ev\n\nevents = events[[\"device_id\", \"app_id\"]]\n\n# remove duplicates(app_id)\nevents = events.groupby(\"device_id\")[\"app_id\"].apply(\n    lambda x: \" \".join(set(str(\" \".join(str(s) for s in x)).split(\" \"))))\nevents = events.reset_index(name=\"app_id\")\n\n# expand to multiple rows\nevents = pd.concat([pd.Series(row['device_id'], row['app_id'].split(' '))\n                    for _, row in events.iterrows()]).reset_index()\nevents.columns = ['app_id', 'device_id']\n\n##################\n#   Phone Brand\n##################\nprint(\"# Read Phone Brand\")\npbd = pd.read_csv(\"../input/phone_brand_device_model.csv\",\n                  dtype={'device_id': np.str})\npbd.drop_duplicates('device_id', keep='first', inplace=True)\n\n\n##################\n#  Train and Test\n##################\nprint(\"# Generate Train and Test\")\n\ntrain = pd.read_csv(\"../input/gender_age_train.csv\",\n                    dtype={'device_id': np.str})\ntrain.drop([\"age\", \"gender\"], axis=1, inplace=True)\n\ntest = pd.read_csv(\"../input/gender_age_test.csv\",\n                   dtype={'device_id': np.str})\ntest[\"group\"] = np.nan\n\n\nsplit_len = len(train)\n\n# Group Labels\nY = train[\"group\"]\nlable_group = LabelEncoder()\nY = lable_group.fit_transform(Y)\ndevice_id = test[\"device_id\"]\n\n# Concat\nDf = pd.concat((train, test), axis=0, ignore_index=True)\n\nDf = pd.merge(Df, pbd, how=\"left\", on=\"device_id\")\nDf[\"phone_brand\"] = Df[\"phone_brand\"].apply(lambda x: \"phone_brand:\" + str(x))\nDf[\"device_model\"] = Df[\"device_model\"].apply(\n    lambda x: \"device_model:\" + str(x))\n\n\n###################\n#  Concat Feature\n###################\n\nf1 = Df[[\"device_id\", \"phone_brand\"]]   # phone_brand\nf2 = Df[[\"device_id\", \"device_model\"]]  # device_model\nf3 = events[[\"device_id\", \"app_id\"]]    # app_id\n\ndel Df\n\nf1.columns.values[1] = \"feature\"\nf2.columns.values[1] = \"feature\"\nf3.columns.values[1] = \"feature\"\n\nFLS = pd.concat((f1, f2, f3), axis=0, ignore_index=True)\n\n\n###################\n# User-Item Feature\n###################\nprint(\"# User-Item-Feature\")\n\ndevice_ids = FLS[\"device_id\"].unique()\nfeature_cs = FLS[\"feature\"].unique()\n\ndata = np.ones(len(FLS))\ndec = LabelEncoder().fit(FLS[\"device_id\"])\nrow = dec.transform(FLS[\"device_id\"])\ncol = LabelEncoder().fit_transform(FLS[\"feature\"])\nsparse_matrix = sparse.csr_matrix(\n    (data, (row, col)), shape=(len(device_ids), len(feature_cs)))\n\nsparse_matrix = sparse_matrix[:, sparse_matrix.getnnz(0) > 0]\n\n##################\n#      Data\n##################\n\ntrain_row = dec.transform(train[\"device_id\"])\ntrain_sp = sparse_matrix[train_row, :]\n\ntest_row = dec.transform(test[\"device_id\"])\ntest_sp = sparse_matrix[test_row, :]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    train_sp, Y, train_size=.90, random_state=10)\n\n##################\n#   Feature Sel\n##################\nprint(\"# Feature Selection\")\nselector = SelectPercentile(f_classif, percentile=23)\n\nselector.fit(X_train, y_train)\n\nX_train = selector.transform(X_train)\nX_val = selector.transform(X_val)\n\ntrain_sp = selector.transform(train_sp)\ntest_sp = selector.transform(test_sp)\n\nprint(\"# Num of Features: \", X_train.shape[1])\n\n##################\n#  Build Model\n##################\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndvalid = xgb.DMatrix(X_val, y_val)\n\nparams = {\n    \"objective\": \"multi:softprob\",\n    \"num_class\": 12,\n    \"booster\": \"gblinear\",\n    \"max_depth\": 6,\n    \"eval_metric\": \"mlogloss\",\n    \"eta\": 0.07,\n    \"silent\": 1,\n    \"alpha\": 3,\n}\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]\ngbm = xgb.train(params, dtrain, 40, evals=watchlist,\n                early_stopping_rounds=25, verbose_eval=True)\n\nprint(\"# Train\")\ndtrain = xgb.DMatrix(train_sp, Y)\ngbm = xgb.train(params, dtrain, 40, verbose_eval=True)\ny_pre = gbm.predict(xgb.DMatrix(test_sp))\n\n# Write results\nresult = pd.DataFrame(y_pre, columns=lable_group.classes_)\nresult[\"device_id\"] = device_id\nresult = result.set_index(\"device_id\")\nresult.to_csv('fine_tune.gz', index=True,\n              index_label='device_id', compression=\"gzip\")\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}