{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdc08fd1-bec3-705a-6ec4-657513155847"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd7cfc75-e651-69d2-487c-f81c4e458357"},"outputs":[],"source":"# 把device_id作为行号，后面避免了搜索device的程序\n# 注意这里的ga_train和ga_test要一起处理，因为app_events等文件没有区分train和test，因此索引都是全部一起索引\nga_train = pd.read_csv('../input/gender_age_train.csv', index_col='device_id')\nga_test = pd.read_csv('../input/gender_age_test.csv', index_col='device_id') \n# 将行指标设置为event_id，这样就可以通过app_events找到app对应的event_id，然后通过event_id指标直接索引到device_id，最后通过ga_train将device_id的指标直接索引到gender和age\nevents = pd.read_csv('../input/events.csv', index_col='event_id', parse_dates=['timestamp']) \n# 所有的app的is_installed都为1，因此此列无效，将其删去\napp_events = pd.read_csv('../input/app_events.csv', usecols=['event_id','app_id','is_active'])\n# phone_brand里面有重复（对应同一个大品牌下面的不同device_model）\n##### 此处需要分析一下重复的数据\ndevice_brand = pd.read_csv('../input/phone_brand_device_model.csv')\ndevice_brand = device_brand.drop_duplicates('device_id').set_index('device_id')\napp_labels = pd.read_csv('../input/app_labels.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"e4f473b2-6742-d66a-3f2f-4b81de258386"},"source":"a = ga_train.gender.value_counts().sort_index(ascending=True)\na.plot(kind='bar')\na"},{"cell_type":"markdown","metadata":{"_cell_guid":"98e514d3-2e20-d088-7589-07b5acb00156"},"source":"ga_train.group.value_counts().sort_index(ascending=True).plot(kind='bar')"},{"cell_type":"markdown","metadata":{"_cell_guid":"9d85361b-c0c8-b239-872a-c07b41dcef5c"},"source":"top15brands = device_brand.phone_brand.value_counts().sort_values(ascending=False)\ntop15brands[:15].plot(kind='bar')\nprint(top15brands[:15])"},{"cell_type":"markdown","metadata":{"_cell_guid":"b824d112-4965-8817-9c04-a3a9eb4ff48d"},"source":"gender_device = device_brand.merge(ga_train[['gender']], how='left', left_index=True, right_index=True)\nfemale_device = gender_device[gender_device.gender=='F']\nmale_device = gender_device[gender_device.gender=='M']\n\ntop15brands_f = female_device.phone_brand.value_counts().sort_values(ascending=False)\ntop15brands_f[:15].plot(kind='bar')\nprint(top15brands_f[:15])"},{"cell_type":"markdown","metadata":{"_cell_guid":"152c46e3-aac2-e37d-ee7d-60194644e914"},"source":"top15brands_m = male_device.phone_brand.value_counts().sort_values(ascending=False)\ntop15brands_m[:15].plot(kind='bar')\nprint(top15brands_m[:15])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06a24d21-f6d6-0c44-6a7a-5fe3708313f0"},"outputs":[],"source":"ga_train['trainrow'] = np.arange(ga_train.shape[0])\nga_test['testrow'] = np.arange(ga_test.shape[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9621a2ce-6f82-6da1-98fb-f40762089eec"},"outputs":[],"source":"# 将brand编码成整数，可使用transform和inverse_transform进行brand和编码的转换\nbrand_encoder = LabelEncoder().fit(device_brand['phone_brand'])\ndevice_brand['brand'] = brand_encoder.transform(device_brand['phone_brand'])\nga_train['brand'] = device_brand['brand'] # 由于行标为device_id，因此device_id自动匹配\nga_test['brand'] = device_brand['brand']\n# 建立一个稀疏矩阵，行是device（对应的trainrow）,列是各个brand，值为1代表某个device对应是某个brand\nXtr_brand = csr_matrix((np.ones(ga_train.shape[0]), (ga_train['trainrow'], ga_train['brand'])))\nXte_brand = csr_matrix((np.ones(ga_test.shape[0]), (ga_test['testrow'], ga_test['brand'])))\nprint(Xtr_brand.shape, Xte_brand.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de1c7307-b719-aa19-54bf-0bcbb46485b7"},"outputs":[],"source":"m = device_brand.phone_brand.str.cat(device_brand.device_model)\nmodelencoder = LabelEncoder().fit(m)\ndevice_brand['model'] = modelencoder.transform(m)\nga_train['model'] = device_brand['model']\nga_test['model'] = device_brand['model']\nXtr_model = csr_matrix((np.ones(ga_train.shape[0]), \n                       (ga_train.trainrow, ga_train.model)))\nXte_model = csr_matrix((np.ones(ga_test.shape[0]), \n                       (ga_test.testrow, ga_test.model)))\nprint('Model features: train shape {}, test shape {}'.format(Xtr_model.shape, Xte_model.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f3e9fb4d-b0cf-3aaa-96eb-29d024159057"},"source":"gender_model = device_brand.merge(ga_train[['gender']], how='left', left_index=True, right_index=True)\nfemale_model = gender_model[gender_device.gender=='F']\nmale_model = gender_model[gender_device.gender=='M']\n\ntopmodel_f = female_model.device_model.value_counts().sort_index(ascending=False)\n#topmodel_f[:15].plot(kind='bar')\n#print(topmodel_f[:15])\ntopmodel_m = male_model.device_model.value_counts().sort_index(ascending=False)\n#topmodel_m[:15].plot(kind='bar')\n#print(topmodel_m[:15])\n\nratio = 47904/26741\n\ntopmodel_f = pd.DataFrame(topmodel_f)\ntopmodel_f['f'] = topmodel_f['device_model']\ntopmodel_m = pd.DataFrame(topmodel_m)\ntopmodel_m['m'] = topmodel_m['device_model']\ntopdiff = topmodel_f.merge(topmodel_m[['m']], how='left', left_index=True, right_index=True)\ndiff = (topmodel_f*ratio - topmodel_m) / (topmodel_f*ratio + topmodel_m)**0.5\ndiff = pd.DataFrame(diff)\ndiff['diff'] = diff['device_model']\nabsdiff = pd.DataFrame(absdiff)\nabsdiff = abs(topmodel_f*ratio - topmodel_m) / (topmodel_f*ratio + topmodel_m)**0.5\nabsdiff['absdiff'] = absdiff['device_model']\ntopdiff = topdiff.merge(absdiff[['absdiff']], how='left', left_index=True, right_index=True)\ntopdiff = topdiff.merge(diff[['diff']], how='left', left_index=True, right_index=True)\ntopdiff = topdiff.sort('absdiff', ascending=False)\ntopdiff[['diff']][:20].plot(kind='bar')\ntopdiff[['diff','f','m']][:20]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22c823a7-a545-082b-a359-c6a755c0ea8b"},"outputs":[],"source":"# 将所有的app编码\napp_encoder = LabelEncoder().fit(app_events['app_id'])\napp_events['app'] = app_encoder.transform(app_events['app_id'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e278597-4a84-bdb2-24fd-3f27f6b22503"},"outputs":[],"source":"# 将app_events与events合并\ndevice_apps = app_events.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n# 将相同的device合并，并记录每个device使用app的次数\ndevice_apps = device_apps.groupby(['device_id','app'])['app'].agg(['size'])\n# 将device_apps继续与ga_train和ga_test合并（仅合并行标），从而可以通过trainrow和testrow得到它们对应的分类\ndevice_apps = device_apps.merge(ga_train[['trainrow']], how='left', left_index=True, right_index=True)\ndevice_apps = device_apps.merge(ga_test[['testrow']], how='left', left_index=True, right_index=True)\ndevice_apps = device_apps.reset_index() # 原来是将device_id和app都设为行标，现在将其恢复为属性"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"700478df-4f97-702a-a48c-0dac0800f441"},"outputs":[],"source":"napps = len(app_encoder.classes_)\n# 建立一个稀疏矩阵，行是device（对应的trainrow/testrow）,列是各个app，值为1代表某个device对应安装了某个app\nd = device_apps.dropna(subset=['trainrow']) # 取出有trainrow（testrow为NaN）的数据\nXtr_app = csr_matrix((np.ones(d.shape[0]), (d['trainrow'], d['app'])), shape=[ga_train.shape[0],napps])\nd = device_apps.dropna(subset=['testrow']) \nXte_app = csr_matrix((np.ones(d.shape[0]), (d['testrow'], d['app'])), shape=[ga_test.shape[0],napps])\n# 对应有app信息的设备数量大于有品牌信息的设备数量，说明不是所有的device都有对应的brand\nprint(Xtr_app.shape, Xte_app.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ae15dcdd-295c-553f-38b9-46eaac1f5ab5"},"source":"e = e.merge(app_events1[['app']],how='left',left_index=True, right_index=True)\ne"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46fd6cdc-29e8-33c1-fcde-aa0067012084"},"outputs":[],"source":"# 将app编号加入到app_labels中\n# 因为app_labels里面有一些app是在events中没有出现的，因此只取出那些出现了的\napp_labels = app_labels.loc[app_labels.app_id.isin(app_events.app_id.unique())]\napp_labels['app'] = app_encoder.transform(app_labels['app_id'])\n# 将label重新编号\nlabel_encoder = LabelEncoder().fit(app_labels['label_id'])\napp_labels['label'] = label_encoder.transform(app_labels['label_id'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff0ac2b2-ff6c-8b58-d30a-bf20725d0724"},"outputs":[],"source":"# 有一个问题，如果只写下面这句，再查看结果，会发现同一个设备的同一个app对应了许多不同的Label？？？？？？？\n#device_labels = (device_apps[['device_id','app']]\n#                .merge(app_labels[['app','label']]))\ndevice_labels = (device_apps[['device_id','app']]\n                .merge(app_labels[['app','label']])\n                .groupby(['device_id','label'])['app'].agg(['size'])\n                .merge(ga_train[['trainrow']], how='left', left_index=True, right_index=True)\n                .merge(ga_test[['testrow']], how='left', left_index=True, right_index=True)\n                .reset_index())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32a28171-de14-74c5-fc05-b2b9852f323a"},"outputs":[],"source":"nlabels = len(label_encoder.classes_) # 下面csr_matrix后面要加一个shape，不然可能由于中间函数筛选的原因使得大小不一致\nd = device_labels.dropna(subset=['trainrow'])\nXtr_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), shape=(ga_train.shape[0],nlabels))\nd = device_labels.dropna(subset=['testrow'])\nXte_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), shape=(ga_test.shape[0],nlabels))\nprint(Xtr_label.shape, Xte_label.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99c1f889-eff8-201f-582f-896ab5a8a6b9"},"outputs":[],"source":"Xtrain = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label), format='csr')\nXtest =  hstack((Xte_brand, Xte_model, Xte_app, Xte_label), format='csr')\nprint(Xtrain.shape, Xtest.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d601ee24-b0b7-06a2-46b8-8d5578a78d6e"},"outputs":[],"source":"target_encoder = LabelEncoder().fit(ga_train['group'])\ny = target_encoder.transform(ga_train['group'])\nnclasses = len(target_encoder.classes_)\n#app_labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d3784eb-4f7b-786d-25a0-8ffdf8f474e8"},"outputs":[],"source":"#clf = LogisticRegression(C=0.02)\n#clf.fit(Xtrain, y)\n#clf.predict_proba(Xtrain[70000:], y[70000:])\n#log_loss(yte, pred[itest, :])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6fd9188c-7ff9-3f15-5dc4-23c85f161fb8"},"outputs":[],"source":"#pred = clf.predict_proba(Xtrain[70000:])\n#log_loss(y[70000:], pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9652bba6-dfe2-39c3-cec5-1b4dc15ee9e6"},"outputs":[],"source":"#pred = pd.DataFrame(clf.predict_proba(Xtest), index=ga_test.index, columns=target_encoder.classes_)\n#pred.head()\n#pred.to_csv('logreg_subm.csv',index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"817ae07e-5ef5-1226-5e8f-9c277fafe902"},"outputs":[],"source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nrdf = RandomForestClassifier(n_estimators=50, max_depth=None,\n      min_samples_split=2, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee2e7324-1f27-184d-39bb-05ab852587a6"},"outputs":[],"source":"rdf.fit(Xtrain[:70000], y[:70000])\npred = rdf.predict_proba(Xtrain[70001:])\nlog_loss(y[70001:], pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a51d0a8c-4440-008f-360e-3c2b1d441784"},"outputs":[],"source":"pred_rdf = rdf.predict(Xtrain[70001:])\nnp.mean(pred_rdf==y[70001:])"},{"cell_type":"markdown","metadata":{"_cell_guid":"eda14532-06c5-5461-bb4c-e30af5db67a4"},"source":"pred = pd.DataFrame(rdf.predict_proba(Xtest), index=ga_test.index, columns=target_encoder.classes_)\npred.head()\npred.to_csv('logreg_subm_randomforest.csv',index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"137d8dc6-9594-8cbe-ef0a-358411f1a36b"},"outputs":[],"source":"pred = pd.DataFrame(rdf.predict_proba(Xtrain[70001:]), index=ga_train.iloc[70001:].index, columns=target_encoder.classes_)\npred.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7cb6e861-ebe3-f407-9f8a-eb40d25083bd"},"outputs":[],"source":"predgroup = pd.DataFrame(y[70001:], index=ga_train.iloc[70001:].index)\npredgroup.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5eaa3b36-7cb0-3fbb-d205-2eee43d448d3"},"outputs":[],"source":"pred.to_csv('test_rf.csv',index=True)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}