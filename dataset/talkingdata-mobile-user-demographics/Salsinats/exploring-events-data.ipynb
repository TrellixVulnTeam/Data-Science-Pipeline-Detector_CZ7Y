{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline\n\nimport matplotlib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime as dt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nc = {'axes.titlesize': 24,\n     'axes.labelsize': 18,\n     'axes.suptitlesize': 20,\n     'legend.fontsize': 20,\n     'xtick.labelsize': 18,\n     'ytick.labelsize': 18,\n     'lines.linewidth': 3,\n     'lines.markersize': 10,\n     'axes.grid': False,\n     'pdf.fonttype': 42,\n     'ps.fonttype': 42}\n\n# events information\nevents = pd.read_csv(\"../input/events.csv\")\n\n# gender ager train/test data\ngender_age_train = pd.read_csv(\"../input/gender_age_train.csv\")\ngender_age_test = pd.read_csv(\"../input/gender_age_test.csv\")"},{"cell_type":"markdown","metadata":{},"source":"# Number of devices ?"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# devices in events dataset\nevents_devices = pd.unique(events.device_id)\nprint(\"# devices :\", len(events_devices))"},{"cell_type":"markdown","metadata":{},"source":"There are 60865 devices taken into account in the \"event.csv\" dataset. Many devices in training set are not in the events data set, as observed by previous posts. Same observation for testing set and events dataset."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"ga_train_devices = pd.unique(gender_age_train.device_id)\nga_test_devices = pd.unique(gender_age_test.device_id)\n\nmask_train = np.in1d(ga_train_devices, events_devices)\nmask_test = np.in1d(ga_test_devices, events_devices)\n\nid_train = np.where(mask_train)[0]\nid_test = np.where(mask_test)[0]\nprint(\"# devices in train:\", len(ga_train_devices))\nprint(\"# devices in train inter events:\", len(id_train))\n\nprint(\"\\n# devices in test :\", len(ga_test_devices))\nprint(\"# devices in test inter events:\", len(id_test))"},{"cell_type":"markdown","metadata":{},"source":"# Recording period ?\nThe events are recorded over a short period of time : nearly 10 days. See this post https://www.kaggle.com/uditsaini/talkingdata-mobile-user-demographics/exploring-talking-data for weekly and daily events analysis"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# start and end dates\ntimestamps = events[\"timestamp\"].values\nprint(\"beginning :\\t\", np.min(timestamps))\nprint(\"end :\\t\\t\", np.max(timestamps))"},{"cell_type":"markdown","metadata":{},"source":"# Events for one device ?\nLets have a look at one device in particular"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# We select the first device of the tab events\ni = events_devices[0]\n# We select now all the events corresponding to this device i\nevents_i = events[events.device_id == i]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"events_i.head()"},{"cell_type":"markdown","metadata":{},"source":"## Longitude and latitude ?\nWe can extract some statistics (mean and standard deviations (std) about the longitude and latitude of the events corresponding to this device i"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# stats about longitude\nm_i = np.mean(events_i[\"longitude\"].values)\ns_i = np.std(events_i[\"longitude\"].values)\nprint(\"mean longitude (std) : {:4.2f} ({:4.2f})\".format(m_i, s_i))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# stats about latitude\nm_i = np.mean(events_i[\"latitude\"].values)\ns_i = np.std(events_i[\"latitude\"].values)\nprint(\"mean longitude (std) : {:4.2f} ({:4.2f})\".format(m_i, s_i))"},{"cell_type":"markdown","metadata":{},"source":"Apparently the std for longitude and latitude seem quite large, especially with respect to the short period of record (10 days). We may have a closer look at this. We first sort the events with respect to time (increasing time)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"events_i = events_i.sort_values(by=\"timestamp\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"events_i.head()"},{"cell_type":"markdown","metadata":{},"source":"Along with previous posts, we notice that many lines have longitude and latitude equal to $0$ (https://www.kaggle.com/beyondbeneath/talkingdata-mobile-user-demographics/geolocation-visualisations) which seems to be weird regarding with the geography of this region."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# displays last recorded events for device i\nevents_i.tail(n=5)"},{"cell_type":"markdown","metadata":{},"source":"Here, we can also see that the presence of these $(long., lat) = (0, 0)$ points is strange with respect to time and location. Indeed, looking at the last events of the previous tab shows us that nearly few minutes the longitude and latitude of record jump from a position of $(121, 31)$ to $(0, 0)$. This strongly suggests to remove the (0, 0) points."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# remove the rows with (long. lat.) = (0, 0)\nevents_i_no0 = events_i[events_i.longitude != 0]"},{"cell_type":"markdown","metadata":{},"source":"We extract again stats about mean and std for the longitude and latitude of event locations"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# stats about longitude\nm_i = np.mean(events_i_no0[\"longitude\"].values)\ns_i = np.std(events_i_no0[\"longitude\"].values)\nprint(\"mean longitude (std) : {:4.2f} ({:4.2f})\".format(m_i, s_i))\n\n# stats about latitude\nm_i = np.mean(events_i_no0[\"latitude\"].values)\ns_i = np.std(events_i_no0[\"latitude\"].values)\nprint(\"mean longitude (std) : {:4.2f} ({:4.2f})\".format(m_i, s_i))"},{"cell_type":"markdown","metadata":{},"source":"The standard deviations look now nicer than before, or at least or more relevant."},{"cell_type":"markdown","metadata":{},"source":"## Time intervals between two events ?\nWe are now interested in looking at the time separating two events, and the distribution of this random variable."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# we first convert timestamps from string to date / time format and store the value in a new column \"time_f\"\ntime_t = lambda x: dt.strptime(x, \"%Y-%m-%d %H:%M:%S\")\nevents_i_no0[\"time_f\"] = events_i_no0[\"timestamp\"].map(time_t)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# we do that again store the value in the new column \"time_i\" and shift the row of 1 step\nevents_i_no0[\"time_i\"] = events_i_no0[\"timestamp\"].map(time_t)\nevents_i_no0[\"time_i\"] = events_i_no0[\"time_i\"].shift(1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"events_i_no0.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# we now define a function to compute the time interval between two timestamps in second and apply it to our dataframe\n\ndef time_interval(df):\n    \"\"\"\n    INPUTS:\n    - df: dataframe with columns 'time_f' and 'time_i'\n    \n    OUTPUTS:\n    - time in second between the two timestamps 'time_f' and 'time_i'\n    \"\"\"\n    return (df[\"time_f\"] - df[\"time_i\"]).total_seconds()\n\nevents_i_no0[\"time_interval\"] = events_i_no0.apply(time_interval, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"events_i_no0.head()"},{"cell_type":"markdown","metadata":{},"source":"We now plot the distribution of the time intervals between two events"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# first, we drop rows with nan\nevents_i_no0 = events_i_no0.dropna()\n\ntime_int_i = events_i_no0[\"time_interval\"].values\n\n# normalized histogram\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\", rc=c)\n\nplt.figure(figsize=(10, 10))\nbins = np.linspace(0, 10000, 30)\nh = plt.hist(time_int_i, bins, normed=1, color=\"b\", label=\"29182687948017175\", alpha=0.5)\n\nplt.legend()\nplt.xlabel(\"time in s\")\nplt.title(\"Time intervals between events\")"},{"cell_type":"markdown","metadata":{},"source":"The distribution of time intervals between two events has a pic near 0, which means that two events are likely to be close in time. However we notice some values above 7000 which means that several hours can separate two events."},{"cell_type":"markdown","metadata":{},"source":"# Time intervals for several devices\nWe can perform the same analysis for several devices"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# normalized histogram\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\", rc=c)\n\nfig = plt.figure(figsize=(10, 20))\n\nbins = np.linspace(0, 600000, 30)\n\nfor j in range(5):\n    ax = plt.subplot2grid((5, 1), (j, 0))\n    i = events_devices[j]\n    events_i = events[events.device_id == i]\n    events_i_no0 = events_i[events_i.longitude != 0]\n    events_i_no0[\"time_f\"] = events_i_no0[\"timestamp\"].map(time_t)\n    events_i_no0[\"time_i\"] = events_i_no0[\"timestamp\"].map(time_t)\n    events_i_no0[\"time_i\"] = events_i_no0[\"time_i\"].shift(1)\n    events_i_no0[\"time_interval\"] = events_i_no0.apply(time_interval, axis=1)\n    events_i_no0 = events_i_no0.dropna()\n    time_int_i = events_i_no0[\"time_interval\"].values\n    h = ax.hist(time_int_i, bins, normed=1, label=str(i), alpha=0.5)\n    ax.legend()\n    ax.set_xlabel(\"time in s\")\n    ax.set_ylim([0., 0.00003])\n\nfig.tight_layout()"},{"cell_type":"markdown","metadata":{},"source":"This brief analysis demonstrates that the time intervals between two events for different devices do no follow the same probability distribution in other word the device users do no use their phones in the same way."},{"cell_type":"markdown","metadata":{},"source":"# Conclusion and perspectives\n- This analysis may give information for the classification task to perform\n- it may be interesting to study the distribution of time intervals between two events for all users of a same phone brand, same gender...\n- furthermore, it might be insightful to cross this analysis with other data (app labels...)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}