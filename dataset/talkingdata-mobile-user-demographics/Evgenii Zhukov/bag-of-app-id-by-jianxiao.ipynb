{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom scipy import sparse\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\nfrom sklearn.decomposition import TruncatedSVD, SparsePCA\nfrom sklearn.cross_validation import train_test_split, cross_val_score\nfrom sklearn.feature_selection import SelectPercentile, f_classif, chi2\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.metrics import log_loss"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"# Read App Events\")\napp_ev = pd.read_csv(\"../input/app_events.csv\", dtype={'device_id': np.str})\n# remove duplicates(app_id)\napp_ev = app_ev.groupby(\"event_id\")[\"app_id\"].apply(\n    lambda x: \" \".join(set(\"app_id:\" + str(s) for s in x)))\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"# Read Events\")\nevents = pd.read_csv(\"../input/events.csv\", dtype={'device_id': np.str})\nevents[\"app_id\"] = events[\"event_id\"].map(app_ev)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"events = events.dropna()\n\ndel app_ev\n\nevents = events[[\"device_id\", \"app_id\"]]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# remove duplicates(app_id)\nevents = events.groupby(\"device_id\")[\"app_id\"].apply(\n    lambda x: \" \".join(set(str(\" \".join(str(s) for s in x)).split(\" \"))))\nevents = events.reset_index(name=\"app_id\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# expand to multiple rows\nevents = pd.concat([pd.Series(row['device_id'], row['app_id'].split(' '))\n                    for _, row in events.iterrows()]).reset_index()\nevents.columns = ['app_id', 'device_id']"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##################\n#   Phone Brand\n##################\nprint(\"# Read Phone Brand\")\npbd = pd.read_csv(\"../input/phone_brand_device_model.csv\",\n                  dtype={'device_id': np.str})\npbd.drop_duplicates('device_id', keep='first', inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##################\n#  Train and Test\n##################\nprint(\"# Generate Train and Test\")\n\ntrain = pd.read_csv(\"../input/gender_age_train.csv\",\n                    dtype={'device_id': np.str})\ntrain.drop([\"age\", \"gender\"], axis=1, inplace=True)\n\ntest = pd.read_csv(\"../input/gender_age_test.csv\",\n                   dtype={'device_id': np.str})\ntest[\"group\"] = np.nan\n\n\nsplit_len = len(train)\n\n# Group Labels\nY = train[\"group\"]\nlable_group = LabelEncoder()\nY = lable_group.fit_transform(Y)\ndevice_id = test[\"device_id\"]\n\n# Concat\nDf = pd.concat((train, test), axis=0, ignore_index=True)\n\nDf = pd.merge(Df, pbd, how=\"left\", on=\"device_id\")\nDf[\"phone_brand\"] = Df[\"phone_brand\"].apply(lambda x: \"phone_brand:\" + str(x))\nDf[\"device_model\"] = Df[\"device_model\"].apply(\n    lambda x: \"device_model:\" + str(x))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"###################\n#  Concat Feature\n###################\n\nf1 = Df[[\"device_id\", \"phone_brand\"]]   # phone_brand\nf2 = Df[[\"device_id\", \"device_model\"]]  # device_model\nf3 = events[[\"device_id\", \"app_id\"]]    # app_id\n\ndel Df\n\nf1.columns.values[1] = \"feature\"\nf2.columns.values[1] = \"feature\"\nf3.columns.values[1] = \"feature\"\n\nFLS = pd.concat((f1, f2, f3), axis=0, ignore_index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"###################\n# User-Item Feature\n###################\nprint(\"# User-Item-Feature\")\n\ndevice_ids = FLS[\"device_id\"].unique()\nfeature_cs = FLS[\"feature\"].unique()\n\ndata = np.ones(len(FLS))\ndec = LabelEncoder().fit(FLS[\"device_id\"])\nrow = dec.transform(FLS[\"device_id\"])\ncol = LabelEncoder().fit_transform(FLS[\"feature\"])\nsparse_matrix = sparse.csr_matrix(\n    (data, (row, col)), shape=(len(device_ids), len(feature_cs)))\n\nsparse_matrix = sparse_matrix[:, sparse_matrix.getnnz(0) > 0]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##################\n#      Data\n##################\n\ntrain_row = dec.transform(train[\"device_id\"])\ntrain_sp = sparse_matrix[train_row, :]\n\ntest_row = dec.transform(test[\"device_id\"])\ntest_sp = sparse_matrix[test_row, :]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    train_sp, Y, train_size=.90, random_state=10)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##################\n#   Feature Sel\n##################\nprint(\"# Feature Selection\")\nselector = SelectPercentile(f_classif, percentile=23)\n\nselector.fit(X_train, y_train)\n\nX_train = selector.transform(X_train)\nX_val = selector.transform(X_val)\n\ntrain_sp = selector.transform(train_sp)\ntest_sp = selector.transform(test_sp)\n\nprint(\"# Num of Features: \", X_train.shape[1])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##################\n#  Build Model\n##################\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndvalid = xgb.DMatrix(X_val, y_val)\n\nparams = {\n    \"objective\": \"multi:softprob\",\n    \"num_class\": 12,\n    \"booster\": \"gbtree\",\n    \"max_depth\": 6,\n    \"eval_metric\": \"mlogloss\",\n    \"eta\": 0.07,\n    \"silent\": 1,\n    \"alpha\": 3,\n}\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"gbm = xgb.train(params, dtrain, 40, evals=watchlist,\n                early_stopping_rounds=25, verbose_eval=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}