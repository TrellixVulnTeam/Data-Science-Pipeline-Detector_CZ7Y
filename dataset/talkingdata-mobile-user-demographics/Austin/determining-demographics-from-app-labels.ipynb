{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03aafa4d-49d4-4078-46c4-ba8c98f87e86"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os, math, collections\nfrom sklearn import cross_validation\nfrom sklearn import tree\n\n\ndatadir = '../input'\n\nN_ROWS = 200000\ngatrain = pd.read_csv(os.path.join(datadir,'gender_age_train.csv'), index_col=None, nrows=N_ROWS)\ngatest = pd.read_csv(os.path.join(datadir,'gender_age_test.csv'), index_col=None, nrows=N_ROWS)\n#phone = pd.read_csv(os.path.join(datadir,'phone_brand_device_model.csv'))\n# Get rid of duplicate device ids in phone\n#phone = phone.drop_duplicates('device_id',keep='first').set_index('device_id')\n\nevents = pd.read_csv(os.path.join(datadir,'events.csv'), parse_dates=['timestamp'], index_col=None, nrows=N_ROWS)\nappevents = pd.read_csv(os.path.join(datadir,'app_events.csv'), usecols=['event_id','app_id','is_active'], dtype={'is_active':bool}, nrows=N_ROWS)\napplabels = pd.read_csv(os.path.join(datadir,'app_labels.csv'), nrows=N_ROWS)\n\n\nappevents_merged_with_applabels = appevents.merge(applabels, on='app_id', how='outer').dropna()\n#print(appevents_merged_with_applabels)\n\nevents_merged_with_gatrain = events.merge(gatrain, on='device_id', how='outer').dropna()\n#print(events_merged_with_gatrain)\n\nlabel_for_each_event = events_merged_with_gatrain.merge(appevents_merged_with_applabels, on='event_id', how='outer').dropna()\n#print(label_for_each_event)\n\nall_device_ids = pd.unique(label_for_each_event['device_id'].ravel())\n#print(all_device_ids)\n\nall_demographic_groups = ['M39+', 'M22-', 'M27-28', 'M23-26', 'M32-38', 'F27-28', 'F29-32', 'M29-31', 'F43+', 'F33-42', 'F24-26', 'F23-']\n#pd.unique(label_for_each_event['group'].ravel()).tolist()\n\nprint(all_demographic_groups)\n\n\nall_user_dict = []\n\nfor deviceid in all_device_ids:\n    #select all events for a single device_id\n    all_events_for_single_device_id = label_for_each_event.loc[label_for_each_event['device_id'] == deviceid]\n    #tally up the app events for each app label\n    event_counts = all_events_for_single_device_id['label_id'].value_counts()\n    #using group as a key...\n    user_group_for_this_device_id = all_events_for_single_device_id.iloc[0]['group']\n    #...add the event count dictionary for this user to a larger dictionary\n    tuple_of_group_user_dict = (event_counts.to_dict(), user_group_for_this_device_id )\n    all_user_dict += [tuple_of_group_user_dict]\n\n    \n\n#print(all_user_dict)\n\n#new_inputs = []\n\n#for user_group, user_dict in all_user_dict.items():\n#    for key, value in user_dict.items():\n#        if value < 3:\n#            user_dict[key] = 'l'\n#        elif value < 6:\n#            user_dict[key] = 'm'\n#        elif value < 10:\n#           user_dict[key] = 'h'\n#        else:\n#            user_dict[key] = 's'\n#    new_inputs += [(user_dict, user_group)]\n#print(new_inputs)\n\n\n\n#munge data for sklearn\n\nsklearn_X = []\n\nsklearn_Y = []\n\ni=0\n\nfor user_dict, user_group in all_user_dict:\n    #print(user_dict)\n    sklearn_X_temp = []\n    for number in np.arange(1021):\n        if number in user_dict:\n            sklearn_X_temp += [user_dict[number]]\n        else:\n            sklearn_X_temp += [0]\n\n    #print(sklearn_X_temp)\n    sklearn_X += [sklearn_X_temp]\n    sklearn_Y += [all_demographic_groups.index(user_group)]\n    i+=1    \n\nprint(str(i))\n#print(sklearn_X)\n#print(sklearn_Y)\n\n\n### Using sklearn decision tree?\n\n#X data are event_counts of each app label for each user\n#app labels are features (the keys from the inner dicts)\n#Y target data are group_id's for each users list of event counts \n\nX_train, X_test, y_train, y_test = cross_validation.train_test_split(sklearn_X, sklearn_Y, test_size=0.3, random_state=0)\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\n\nprint(clf.score(X_test, y_test))\nprint(y_test)\nprint(clf.predict(X_test))\n\nprint(y_test-clf.predict(X_test))\n\n\n\n### Making decision tree classifier from scratch\n\n\n\ndef entropy(class_probabilities):\n    #given a list of class probabilities compute entropy\n    return sum([-p*math.log(p,2) for p in class_probabilities if p])\n\ndef class_probabilities(labels):\n    total_count = len(labels)\n    return [count/total_count for count in collections.Counter(labels).values()]\n\n\n\ndef data_entropy(labeled_data):\n    labels = [label for _, label in labeled_data]\n    #print(\"labels\")\n    #print(labels)\n    probabilities = class_probabilities(labels)\n    return entropy(probabilities)\n\n\n\ndef partition_entropy(subsets):\n    #find the entropy from this partition of data into subsets\n    #a subset is a list of list of labeled data\n    total_count = sum([len(subset) for subset in subsets])\n    #print(subsets)\n    return sum(data_entropy(subset)*len(subset)/total_count for subset in subsets)\n\n\ndef partition_by(inputs, attribute):\n    #each input is a key:value pair {label: {attribute_dict}}\n    #returns a dict\n\n    groups = defaultdict(list)\n    for input_row in inputs:\n        if attribute in input_row[0]:\n            key = input_row[0][attribute]\n            groups[key].append(input_row)\n    return groups\n\n\n\ndef partition_entropy_by(inputs, attribute):\n    #computes entropy corresponding to the given partition\n    partitions = partition_by(inputs, attribute)\n    return partition_entropy(partitions.values())\n\n    \n\nfor label_id in np.arange(1021):\n    sample = partition_entropy_by(new_inputs, label_id)\n    if sample != 0:\n        print(label_id, sample)\n\n      \n\ndef classify(tree, input):\n    #classify the input using the given decision tree\n    ##if tree is leaf node, return value\n    if tree in all_demographic_groups:\n        return tree\n    #otherwise this tree consists of an attribute to split on\n    #and a dictionary whose keys are values of that attribute\n    #and whose values of are subtrees to consider next\n    attribute, subtree_dict = tree\n    subtree_key = input.get(attribute)\n\n    if subtree_key not in subtree_dict:\n        subtree_key = None\n\n    subtree = subtree_dict[subtree_key]\n    return classify(subtree, input)\n\n\n\n#def build_tree_id3(inputs, split_candidates=None):"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}