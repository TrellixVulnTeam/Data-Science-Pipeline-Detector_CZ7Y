{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import ensemble, preprocessing\nimport xgboost as xgb\n# load training and test datasets\ntrain = pd.read_csv('../input/train_set.csv', parse_dates=[2,])\ntest = pd.read_csv('../input/test_set.csv', parse_dates=[3,])\ntube_data = pd.read_csv('../input/tube.csv')\nbill_of_materials_data = pd.read_csv('../input/bill_of_materials.csv')\nspecs_data = pd.read_csv('../input/specs.csv')\n\nprint(\"train columns\")\nprint(train.columns)\nprint(\"test columns\")\nprint(test.columns)\nprint(\"tube.csv df columns\")\nprint(tube_data.columns)\nprint(\"bill_of_materials.csv df columns\")\nprint(bill_of_materials_data.columns)\nprint(\"specs.csv df columns\")\nprint(specs_data.columns)\n\nprint(specs_data[2:3])\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.quote_date.unique()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.merge(train, tube_data, on ='tube_assembly_id')\ntrain = pd.merge(train, bill_of_materials_data, on ='tube_assembly_id')\ntest = pd.merge(test, tube_data, on ='tube_assembly_id')\ntest = pd.merge(test, bill_of_materials_data, on ='tube_assembly_id')\n\nprint(\"new train columns\")\nprint(train.columns)\nprint(train[1:10])\n#print(train.columns.to_series().groupby(train.dtypes).groups)\n\n# create some new features\ntrain['year'] = train.quote_date.dt.year\ntrain['month'] = train.quote_date.dt.month\n#train['dayofyear'] = train.quote_date.dt.dayofyear\n#train['dayofweek'] = train.quote_date.dt.dayofweek\n#train['day'] = train.quote_date.dt.day\n\ntest['year'] = test.quote_date.dt.year\ntest['month'] = test.quote_date.dt.month\n#test['dayofyear'] = test.quote_date.dt.dayofyear\n#test['dayofweek'] = test.quote_date.dt.dayofweek\n#test['day'] = test.quote_date.dt.day\n\n# drop useless columns and create labels\nidx = test.id.values.astype(int)\ntest = test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1)\nlabels = train.cost.values\n#'tube_assembly_id', 'supplier', 'bracket_pricing', 'material_id', 'end_a_1x', 'end_a_2x', 'end_x_1x', 'end_x_2x', 'end_a', 'end_x'\n#for some reason material_id cannot be converted to categorical variable\ntrain = train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis = 1)\n\ntrain['material_id'].replace(np.nan,' ', regex=True, inplace= True)\ntest['material_id'].replace(np.nan,' ', regex=True, inplace= True)\nfor i in range(1,9):\n    column_label = 'component_id_'+str(i)\n    print(column_label)\n    train[column_label].replace(np.nan,' ', regex=True, inplace= True)\n    test[column_label].replace(np.nan,' ', regex=True, inplace= True)\n\ntrain.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)\n\nprint(\"train columns\")\nprint(train.columns)\n\n# convert data to numpy array\ntrain = np.array(train)\ntest = np.array(test)\n\n\n# label encode the categorical variables\nfor i in range(train.shape[1]):\n    if i in [0,3,5,11,12,13,14,15,16,20,22,24,26,28,30,32,34]:\n        print(i,list(train[1:5,i]) + list(test[1:5,i]))\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train[:,i]) + list(test[:,i]))\n        train[:,i] = lbl.transform(train[:,i])\n        test[:,i] = lbl.transform(test[:,i])\n\n\n# object array to float\ntrain = train.astype(float)\ntest = test.astype(float)\n\n# i like to train on log(1+x) for RMSLE ;) \n# The choice is yours :)\nlabel_log = np.log1p(labels)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"###参数比较多，需要调试，相对来说LR的不是很多\nparams = {}\nparams[\"objective\"] = \"reg:linear\"\nparams[\"eta\"] = 0.05\nparams[\"min_child_weight\"] = 5\nparams[\"subsample\"] = 0.8\nparams[\"colsample_bytree\"] = 0.8\nparams[\"scale_pos_weight\"] = 1.0\n#params[\"silent\"] = 1\nparams[\"max_depth\"] = 7\nparams[\"eval_metric\"] =\"rmse\"\n\nplst = list(params.items())\n\nxgtrain = xgb.DMatrix(train, label=label_log)\nxgtest = xgb.DMatrix(test)\n\n\nnum_rounds = 800\nmodel = xgb.train(plst, xgtrain, num_rounds)\npreds1 = model.predict(xgtest)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"preds = np.expm1(preds1)\n\npreds = pd.DataFrame({\"id\": idx, \"cost\": preds})\npreds.to_csv('benchmark.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"preds.head()\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}