{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.signal import convolve2d\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom random import randint, random\nimport sys\nimport gc\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def life_step(X):\n    \"\"\"Game of life step using scipy tools\"\"\"\n    X_pad = np.zeros((X.shape[0], X.shape[1]+2, X.shape[2]+2))\n    N = np.zeros((X.shape[0], X.shape[1]+2, X.shape[2]+2))\n    X_pad[:,1:-1,1:-1] += X\n    \n    X_pad[:, 0, 1:-1] = X[:, -1, :]\n    X_pad[:, -1, 1:-1] = X[:, 0, :]\n    \n    X_pad[:, 1:-1, 0] = X[:, :, -1]\n    X_pad[:, 1:-1, -1] = X[:, :, 0]\n    \n    X_pad[:, 0, 0] = X[:, -1, -1]\n    X_pad[:, 0, -1] = X[:, -1, 0]\n    X_pad[:, -1, 0] = X[:, 0, -1]\n    X_pad[:, -1, -1] = X[:, 0, 0]\n    \n    N[:, 1:, 1:] += X_pad[:,:-1,:-1]\n    N[:, 1:, :] += X_pad[:,:-1,:]\n    N[:, 1:, :-1] += X_pad[:,:-1,1:]\n\n    N[:, :, 1:] += X_pad[:,:,:-1]\n    N[:, :, :-1] += X_pad[:,:,1:]\n\n    N[:, :-1, 1:] += X_pad[:,1:,:-1]\n    N[:, :-1, :] += X_pad[:,1:,:]\n    N[:, :-1, :-1] += X_pad[:,1:,1:]\n    \n    N = N[:,1:-1,1:-1]\n\n    return np.logical_or(N == 3, np.logical_and(X, N==2)).astype(np.uint8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/conways-reverse-game-of-life-2020/test.csv\", index_col='id').values\n\ntest_delta = test[:,0]\n\nX_test = test[:, 1:626].reshape((-1, 25, 25))\n\nprint(test_delta.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Na√Øve aproaches\n\n# Blank submission\nblank_score = X_test.mean(axis=(-2, -1))\n\n# Stop submission\nstop_scores = np.zeros_like(blank_score)\ncurrent_step = np.copy(X_test)\nfor i in range(5):\n    current_step = life_step(current_step)\n    stop_scores[test_delta==i+1] = 1 - (current_step[test_delta==i+1] == X_test[test_delta==i+1]).mean(axis=(-2, -1))\n\nprint(blank_score.mean())\nprint(stop_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"naive_submission = np.zeros_like(X_test)\nstop_best_mask = stop_scores < blank_score\nnaive_submission[stop_best_mask] = X_test[stop_best_mask]\nnaive_scores = np.copy(blank_score)\nnaive_scores[stop_best_mask] = stop_scores[stop_best_mask]\n    \nprint(naive_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"game_dim = 25\nbatch_size = 128\n\nINITIAL_CONV = 64\nRES_LAYERS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResnetIdentityBlock(keras.Model):\n  def __init__(self, kernel_size, filters):\n    super(ResnetIdentityBlock, self).__init__(name='')\n    filters1, filters2, filters3 = filters\n\ndef get_model(input_shape):\n  t_input = keras.layers.Input(input_shape)\n  x = keras.layers.Conv2D(INITIAL_CONV, 3, padding='same')(t_input)\n  x = keras.layers.BatchNormalization()(x)\n  x = keras.activations.relu(x)\n  for _ in range(RES_LAYERS):\n    x_input = x\n    x = keras.layers.Conv2D(INITIAL_CONV, 3, padding='same')(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = tf.nn.relu(x)\n\n    x = keras.layers.Conv2D(INITIAL_CONV, 3, padding='same')(x)\n    x = keras.layers.BatchNormalization()(x)\n\n    x += x_input\n    x = keras.layers.Conv2D(1, 3, padding='same')(x)\n    x = keras.activations.sigmoid(x)\n\n  return keras.models.Model(inputs=t_input, outputs=x)\n\ndef build_model():\n  return get_model((game_dim, game_dim, 7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\n\nmodel.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001, verbose=1)\n\nfile_path = 'best_model.hdf5'\n\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='val_loss',\n                                                    save_best_only=True)\n\ncallbacks = [reduce_lr, model_checkpoint]\n#callbacks = [model_checkpoint]\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('../input/iglolpartialmodel/best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p0 = 0.3058699275697248\nmax_delta = 5\ndef get_padded_version_n(X):\n    X_pad = np.zeros((X.shape[0], X.shape[-2] + 2, X.shape[-1] + 2), dtype=X.dtype)\n    X_pad[:, 1:-1,1:-1] += X\n    \n    X_pad[:, 0, 1:-1] = X[:, -1, :]\n    X_pad[:, -1, 1:-1] = X[:, 0, :]\n    \n    X_pad[:, 1:-1, 0] = X[:, :, -1]\n    X_pad[:, 1:-1, -1] = X[:, :, 0]\n    \n    X_pad[:, 0, 0] = X[:, -1, -1]\n    X_pad[:, 0, -1] = X[:, -1, 0]\n    X_pad[:, -1, 0] = X[:, 0, -1]\n    X_pad[:, -1, -1] = X[:, 0, 0]\n    \n    return X_pad\n\n\ndef solve(F, d):\n    sF = F\n    P = p0 * np.ones_like(F)\n    \n    F_pad = get_padded_version_n(F)\n    \n    N = np.zeros(F_pad.shape)\n    \n    N[:, 1:, 1:] += F_pad[:,:-1,:-1]\n    N[:, 1:, :] += F_pad[:,:-1,:]\n    N[:, 1:, :-1] += F_pad[:,:-1,1:]\n\n    N[:, :, 1:] += F_pad[:,:,:-1]\n    N[:, :, :-1] += F_pad[:,:,1:]\n\n    N[:, :-1, 1:] += F_pad[:,1:,:-1]\n    N[:, :-1, :] += F_pad[:,1:,:]\n    N[:, :-1, :-1] += F_pad[:,1:,1:]\n\n    N = N[:,1:-1,1:-1]\n    \n    P[np.logical_and(N==0, F==0)] = 0\n    \n    delta_indic = np.repeat(np.eye(max_delta)[d-1], F.shape[-2] * F.shape[-1], axis=0).reshape((F.shape[0], F.shape[-2], F.shape[-1], -1))\n    \n    print(\"Starting from\", np.logical_and(N==0, F==0).sum(axis=(-1, -2)) / (F.shape[-2] * F.shape[-1]))\n    \n    I = np.zeros_like(F)\n    global_mask = np.ones(F.shape[0]).astype(np.bool_)\n    \n    while len(F):\n        ts = time.time()\n        X = np.concatenate((np.expand_dims(F, axis=-1), np.expand_dims(P, axis=-1), delta_indic), axis=-1)\n        y = model.predict(X)[:, :, :, 0]\n        del X\n        p_0_mask = P==0.0\n        p_1_mask = P==1.0\n        y[p_0_mask] = 0.0\n        y[p_1_mask] = 1.0\n        H = abs(y - 0.5)\n        H[p_0_mask] = 0.0\n        H[p_1_mask] = 0.0\n        change_mask = H == np.repeat(H.max(axis=(-1, -2)), F.shape[-2] * F.shape[-1]).reshape(H.shape)\n        nP = y\n        nP[change_mask] = (np.round(nP[change_mask]) > 0.5).astype(np.float32)\n        qsure = ((nP==0.0).sum(axis=(-1, -2)) + (nP==1.0).sum(axis=(-1, -2))) / (F.shape[-2] * F.shape[-1])\n        local_continue_mask = qsure < 1.0\n        local_stop_mask = np.logical_not(local_continue_mask)\n        \n        if local_stop_mask.sum() > 0:\n            eq = (life_step(nP[local_stop_mask]) == F[local_stop_mask])\n            I[np.arange(len(I))[global_mask][local_stop_mask]] = nP[local_stop_mask]\n            d[np.arange(len(d))[global_mask][local_stop_mask]] -= 1\n            F[local_stop_mask] = nP[local_stop_mask]\n            \n            nF = F[local_stop_mask]\n            n_p = p0 * np.ones_like(nF)\n            nF_pad = get_padded_version_n(nF)\n\n            nN = np.zeros_like(nF_pad)\n\n            nN[:, 1:, 1:] += nF_pad[:,:-1,:-1]\n            nN[:, 1:, :] += nF_pad[:,:-1,:]\n            nN[:, 1:, :-1] += nF_pad[:,:-1,1:]\n\n            nN[:, :, 1:] += nF_pad[:,:,:-1]\n            nN[:, :, :-1] += nF_pad[:,:,1:]\n\n            nN[:, :-1, 1:] += nF_pad[:,1:,:-1]\n            nN[:, :-1, :] += nF_pad[:,1:,:]\n            nN[:, :-1, :-1] += nF_pad[:,1:,1:]\n\n            nN = nN[:,1:-1,1:-1]\n            \n            n_p[np.logical_and(nN==0, nF==0)] = 0.0\n            nP[local_stop_mask] = n_p\n            \n            delta_indic[local_stop_mask] = np.repeat(np.eye(max_delta)[d[global_mask][local_stop_mask]-1], F.shape[-2] * F.shape[-1], axis=0).reshape((local_stop_mask.sum(), F.shape[-2], F.shape[-1], -1))\n            \n            local_continue_mask[local_stop_mask] = d[global_mask][local_stop_mask] > 0\n            F = F[local_continue_mask]\n            nP = nP[local_continue_mask]\n            delta_indic = delta_indic[local_continue_mask]\n            \"\"\"\n            print(\"Done for {}, steps {}, continuing with {} items\".format(\n                np.arange(len(I))[global_mask][local_stop_mask],\n                d[global_mask][local_stop_mask],\n                local_continue_mask.sum()\n            ))\n            \"\"\"\n            global_mask[global_mask] = local_continue_mask\n            \n            del eq\n            del nN\n            del nF\n            del nF_pad\n        P = nP\n        print(\"{} items left scores: min={:.3f}, max={:.3f}, mean={:.3f} {:.3f}s\".format(\n            local_continue_mask.sum(),\n            qsure.min(),\n            qsure.max(),\n            qsure.mean(),\n            time.time() - ts\n        ))\n        del y\n        del H\n        del change_mask\n        del qsure\n        del local_continue_mask\n        del local_stop_mask\n        gc.collect()\n\n    return I","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_optimized_solution_and_score(y, delta, labels, naive_submission, naive_scores):\n    print(\"Scores from prediction\")\n    res = np.zeros_like(y)\n    scores = []\n    current_step = np.copy(y)\n    for i in range(5):\n        current_step = life_step(current_step)\n        scores.append(current_step[delta==i+1] == labels[delta==i+1])\n        print(\"Actual score for delta={}: {}\".format(i+1, scores[-1].mean()))\n        res[delta == i+1] = current_step[delta == i+1]\n    print(\"Actual LB score = \", 1 - (res == labels).mean())\n    y_scores = 1 - (labels == res).mean(axis=(-2, -1))\n    naive_mask = naive_scores < y_scores\n    y_final = np.copy(y)\n    y_final[naive_mask] = naive_submission[naive_mask]\n    f_score = np.copy(y_scores)\n    f_score[naive_mask] = naive_scores[naive_mask]\n    print(\"LB score estimation = \", f_score.mean())\n    return y_final, f_score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = solve(X_test, np.copy(test_delta))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final, score = get_optimized_solution_and_score(y, test_delta, X_test, naive_submission, naive_scores)\nprint(score, naive_scores.mean() - score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/conways-reverse-game-of-life-2020/sample_submission.csv\", index_col='id')\nsubmission_values = y_final.reshape((len(submission), 625))\nfor i, col in enumerate(submission.columns):\n    submission[col].values[:] = submission_values[:, i]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}