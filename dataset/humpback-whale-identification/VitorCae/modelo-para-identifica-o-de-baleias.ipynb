{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"#### **Nomes:**\n* Fernando Teixeira\n* Flavio Freire\n* Marcio Eggers\n* Vitor Caetano\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Objetivo\nEste Trabalho tem como objetivo analisar o banco de dados da Happywhale com mais de 25.000 imagens, coletadas de instituições de pesquisa e colaboradores públicos e elaborar um  algoritmo para identificar baleias individuais em imagens de suas caldas.\nEsses dados de treinamento contêm milhares de imagens de solha de baleia jubarte. As baleias individuais foram identificadas pelos pesquisadores e receberam um ID. O desafio é prever o ID das imagens e verificar sob quais condições de algoritimo tem a melhor acuracia do modelo alterando o número de iterações e o tamanho dos lotes.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Importação das Bibliotecas a Serem Usadas**","execution_count":null},{"metadata":{"trusted":true,"_uuid":"2e5529de3bd3acdbe0f016f41895f64fd2fc6e34"},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nimport numpy as np\nimport torch\nfrom torchvision import transforms\n\n\nimport tensorflow as tf\nimport random\nimport time\nimport cv2\n\nfrom skimage import io #Pacote para ler e gravar imagens em vários formatos.\nfrom pylab import rcParams \n\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\nfrom skimage import data, color\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D,BatchNormalization,AveragePooling2D\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import (\n    random_rotation, random_shift, random_shear, random_zoom,\n    random_channel_shift,img_to_array, ImageDataGenerator)\n\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nfrom glob import glob\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78cd867f785b8ae911ddbe52e1aa0c09b8b51d5f"},"cell_type":"code","source":"img_treino= \"../input/humpback-whale-identification/train/\"\n#img_test= \"../input/test-foto/\"\nbase_treino=\"../input/humpback-whale-identification/train.csv\"\nIMG_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aquisição e Tratamento das Bases","execution_count":null},{"metadata":{"trusted":true,"_uuid":"6fcd52fc94ae13f011050fe19c7e7a29b1a44350"},"cell_type":"code","source":"#carrega a base em csv de treino\ndf_treino = pd.read_csv(base_treino) \n\n# encontra os elementos distintos de uma matriz\nid_dist = np.unique(df_treino[['Id']].values) \n\n#Elaboração da variável classe_dist \nclasse_dist = {}\n\n#Elaboração da variável classe_id_dist \nclasse_id_dist = {}\n\n#Preenchimento das variaveis criando um dicionário na classe_dist e classe_id_dist\nfor i in range(len(id_dist)):\n    classe_dist[id_dist[i]] = i\n    classe_id_dist[i] = id_dist[i]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6a3c88cae1c6bb53326558eae5fd9f94627e183"},"cell_type":"code","source":"# Adiciona um nova coluna chamada class_id na tabela  df_treino  contendo os id criados\ndf_treino['classes_id'] = df_treino.apply (lambda row: classe_dist.get(row['Id']),axis=1)\ndf_treino.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e30962384a1e0e8c7cf479669e6e62aba64d02d7"},"cell_type":"code","source":"# Criação da Função para plotar as imagens\ndef show_img(image):\n    plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7dbb7f9cc910d54f1a0888a2f7672c7a89c4785"},"cell_type":"code","source":"#Criação da Função que plota as imagens carregaas em show_img\ndef plot_img(images):\n    \n    #Define o tamanho da imagem\n    #rcParams['figure.figsize'] = 13, 8\n    rcParams['figure.figsize'] = 14, 8\n    \n    #Insere o Mapa de Cores\n    #plt.jet()\n    plt.gray()\n    \n    fig = plt.figure()\n    \n    #Loop elaborado para retornar a menor valor em 9 iterações\n    for i in range(min(9, images.shape[0])):\n        fig.add_subplot(3, 3, i+1)\n        show_img(images[i])\n    plt.show()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bcc0161b76a9e043c324a83bae3e36cf168b151"},"cell_type":"code","source":"#Função para redimencionar o tamanho das imagens\ndef LoadImage(img_path):\n    \n    #Carregar uma imagem do arquivo e cria uma escala de cinza \n    image = color.rgb2gray(io.imread(img_path))\n    \n    #Redimencionar o tamanho das imagens\n    image_resized = resize(image,(IMG_SIZE,IMG_SIZE))\n    return image_resized[:,:] / 255.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee6509dca39f19e9fd8fe685fcef72e95d22f97a"},"cell_type":"code","source":"#Função para carregar os  dados de imagens e identificação de classes\ndef LoadImageData(path):\n    xs = []\n    ys = []\n    #for ex_paths in paths:\n    for index, row in df_treino.iterrows(): \n        \n        #Armazena o caminha de cada uma das imagens\n        img_path = path+row['Image']\n        \n        #Carega a imagem que tem seu caminho armazenado na variável acima\n        igm = LoadImage(img_path)\n        \n        #Add os  elementos na lista xs\n        xs.append(igm)\n        \n        #Add os elementos na lista ys\n        ys.append(row['classes_id'])\n        \n    return np.array(xs),np.array(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03e9bbd70cbbc1e83e6fc3c67ebc9b01e655e030"},"cell_type":"code","source":"#Carrega em X_train as imagens contidas em xs e a classe delas em Y_train contidas em ys\nX_train,Y_train = LoadImageData(img_treino)\nprint(\"Base Carregada\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37a54e9b3991e31f2faff4916bc94fdef743e694"},"cell_type":"code","source":"#Verificação do  número de elementos em cada dimensão\nprint(\"X_train \",X_train.shape)\nprint(\"Y_train \",Y_train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec6c6c032b0ad503830c87374897f7162e104005"},"cell_type":"code","source":"#Verificação  aleatótia das imagens\nxs = [random.randint(0, X_train.shape[0]-1) for _ in range(9)]   \nprint(\"XS \",xs)\nplot_img(X_train[xs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0496a4e356070669086788c2937d1f17f38bbae"},"cell_type":"code","source":"\n\nX_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\n\n#Mudança da Classe_dist dos id para 0 e 1 em seus formatos \nY_train = keras.utils.to_categorical(Y_train,num_classes=len(classe_dist))\n\nprint(np.shape(X_train))\nprint(np.shape(Y_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Elaboração do Modelo","execution_count":null},{"metadata":{"trusted":true,"_uuid":"c788a88980403fd908870f2d0b1a52babf2cae2a"},"cell_type":"code","source":"#Criação da função para rodar o modelo CNN\ndef cnn():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), strides = (1, 1), input_shape = (IMG_SIZE, IMG_SIZE, 1)))\n    model.add(BatchNormalization(axis = 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), strides = (1,1)))\n    model.add(Activation('relu'))\n    model.add(AveragePooling2D((3, 3)))\n    model.add(Flatten())\n    model.add(Dense(500, activation=\"relu\"))\n    model.add(Dropout(0.6))\n    model.add(Dense(5005, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fac76efddf20dc84b1188a9771ccf6318bd30707"},"cell_type":"code","source":"#Primeiro modelo com 100 Epocas e batch_size de aproximadamente 20% do tamanho da base\nmodel1 = cnn()\nhistory1 = model1.fit(X_train, Y_train, epochs=100, batch_size=500, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Segun  modelo com 100 Epocas e batch_size de aproximadamente 10% do tamanho da base\nmodel2 = cnn()\nhistory2 = model2.fit(X_train, Y_train, epochs=100, batch_size=250, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Terceiro  modelo com 100 Epocas e batch_size de aproximadamente 5% do tamanho da base\nmodel3 = cnn()\nhistory3 = model3.fit(X_train, Y_train, epochs=100, batch_size=127, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sexto  modelo com 100 Epocas e batch_size de aproximadamente 2,5% do tamanho da base\nmodel6 = cnn()\nhistory6 = model6.fit(X_train, Y_train, epochs=100, batch_size=60, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quarto  modelo com 100 Epocas e batch_size de aproximadamente 1,62% do tamanho da base\nmodel4 = cnn()\nhistory4 = model4.fit(X_train, Y_train, epochs=100, batch_size=30, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quinto  modelo com 100 Epocas e batch_size de aproximadamente 0,5% do tamanho da base\nmodel5 = cnn()\nhistory5 = model5.fit(X_train, Y_train, epochs=100, batch_size=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 0,25% do tamanho da base\nmodel61 = cnn()\nhistory61 = model61.fit(X_train, Y_train, epochs=100, batch_size=5, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setimo  modelo com 200 Epocas e batch_size de aproximadamente 5% do tamanho da base\nmodel7 = cnn()\nhistory7 = model7.fit(X_train, Y_train, epochs=200, batch_size=127, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Oitavo  modelo com 200 Epocas e batch_size de aproximadamente 2,5% do tamanho da base\nmodel8 = cnn()\nhistory8 = model8.fit(X_train, Y_train, epochs=200, batch_size=60, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Nono  modelo com 200 Epocas e batch_size de aproximadamente 0,31% do tamanho da base\nmodel9 = cnn()\nhistory9 = model9.fit(X_train, Y_train, epochs=200, batch_size=30, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 0,31% do tamanho da base\nmodel10 = cnn()\nhistory10 = model10.fit(X_train, Y_train, epochs=200, batch_size=250, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 0,31% do tamanho da base\nmodel101 = cnn()\nhistory101 = model101.fit(X_train, Y_train, epochs=200, batch_size=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Verificação da Acurácia","execution_count":null},{"metadata":{"trusted":true,"_uuid":"e052f4a13d80abe818f482c787b37bd37d99fea2"},"cell_type":"code","source":"plt.plot(history1.history['acc'], color='blue', linewidth = 2, label=\"batch_size=500\") \nplt.plot(history2.history['acc'], color='red', linewidth = 2, label=\"batch_size=250\") \nplt.plot(history3.history['acc'], color='green', linewidth = 2, label=\"batch_size=125\") \nplt.plot(history6.history['acc'], color='black', linewidth = 2, label=\"batch_size=60\")\nplt.plot(history4.history['acc'], color='orange', linewidth = 2, label=\"batch_size=30\") \nplt.plot(history61.history['acc'], color='gray', linewidth = 2, label=\"batch_size=10\")\nplt.plot(history5.history['acc'], color='yellow', linewidth = 2, label=\"batch_size=5\")\nplt.rcParams['figure.figsize']=(10,10)\nplt.title('Acurácia do Modelo CNN - 100 Épocas')\nplt.ylabel('Acurácia')\nplt.xlabel('Épocas')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history7.history['acc'], color='blue', linewidth = 2, label=\"batch_size=250\") \nplt.plot(history8.history['acc'], color='red', linewidth = 2, label=\"batch_size=125\") \nplt.plot(history9.history['acc'], color='green', linewidth = 2, label=\"batch_size=60\")\nplt.plot(history10.history['acc'], color='yellow', linewidth = 2, label=\"batch_size=30\")\nplt.plot(history101.history['acc'], color='black', linewidth = 2, label=\"batch_size=10\")\nplt.rcParams['figure.figsize']=(10,10)\nplt.title('Acurácia do Modelo CNN - 200 Épocas')\nplt.ylabel('Acurácia')\nplt.xlabel('Épocas')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history1.history['loss'], color='blue', linewidth = 2, label=\"batch_size=500\") \nplt.plot(history2.history['loss'], color='red', linewidth = 2, label=\"batch_size=250\") \nplt.plot(history3.history['loss'], color='green', linewidth = 2, label=\"batch_size=125\") \nplt.plot(history6.history['loss'], color='black', linewidth = 2, label=\"batch_size=60\")\nplt.plot(history4.history['loss'], color='orange', linewidth = 2, label=\"batch_size=30\") \nplt.plot(history5.history['loss'], color='yellow', linewidth = 2, label=\"batch_size=10\")\nplt.plot(history61.history['loss'], color='gray', linewidth = 2, label=\"batch_size=5\")\nplt.rcParams['figure.figsize']=(10,10)\nplt.legend()\nplt.title('Perda do Modelo CNN - 100 Épocas')\nplt.xlabel('Épocas')\nplt.ylabel('Loss')\nplt.xlabel('Épocas')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history7.history['loss'], color='blue', linewidth = 2, label=\"batch_size=250\") \nplt.plot(history8.history['loss'], color='red', linewidth = 2, label=\"batch_size=125\") \nplt.plot(history9.history['loss'], color='green', linewidth = 2, label=\"batch_size=60\") \nplt.plot(history10.history['loss'], color='yellow', linewidth = 2, label=\"batch_size=30\") \nplt.plot(history101.history['loss'], color='yellow', linewidth = 2, label=\"batch_size=10\")\nplt.rcParams['figure.figsize']=(10,10)\nplt.legend()\nplt.title('Perda do Modelo CNN - 200 Épocas')\nplt.ylabel('Loss')\nplt.xlabel('Épocas')\nplt.xlabel('Épocas')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criação da função para rodar o modelo CNN\ndef cnn1():\n    modelo = Sequential()\n    modelo.add(Conv2D(filters = 16, kernel_size = (5,5), padding = 'Same', activation = 'relu', input_shape = (IMG_SIZE, IMG_SIZE, 1)))\n    modelo.add(Conv2D(filters = 16, kernel_size = (5,5), padding = 'Same', activation = 'relu'))\n    modelo.add(MaxPool2D(pool_size = (2,2)))\n    modelo.add(Dropout(0.25))\n    modelo.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n    modelo.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n    modelo.add(MaxPool2D(pool_size = (2,2), strides=(2,2)))\n    modelo.add(Dropout(0.25))\n    modelo.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n    modelo.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n    modelo.add(MaxPool2D(pool_size = (2,2), strides=(2,2)))\n    modelo.add(Dropout(0.25))\n    modelo.add(Flatten())\n    modelo.add(Dense(256, activation = 'relu'))\n    modelo.add(BatchNormalization())\n    modelo.add(Dense(Y_train.shape[1], activation = \"softmax\"))\n    modelo.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    modelo.summary()\n    return modelo   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 10% do tamanho da base\nmodelo11 = cnn1()\nhistory11 = modelo11.fit(X_train, Y_train, epochs=100, batch_size=250, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 5% do tamanho da base\nmodelo12 = cnn1()\nhistory12 = modelo12.fit(X_train, Y_train, epochs=100, batch_size=125, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 2,5% do tamanho da base\nmodelo13 = cnn1()\nhistory13 = modelo13.fit(X_train, Y_train, epochs=100, batch_size=60, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 1,62% do tamanho da base\nmodelo14 = cnn1()\nhistory14 = modelo14.fit(X_train, Y_train, epochs=100, batch_size=30, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 0,5% do tamanho da base\nmodelo15 = cnn1()\nhistory15 = modelo15.fit(X_train, Y_train, epochs=100, batch_size=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decimo modelo com 200 Epocas e batch_size de aproximadamente 0,5% do tamanho da base\nmodelo16 = cnn1()\nhistory16 = modelo16.fit(X_train, Y_train, epochs=100, batch_size=500, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history16.history['acc'], color='gray', linewidth = 2, label=\"batch_size=500\")\nplt.plot(history11.history['acc'], color='blue', linewidth = 2, label=\"batch_size=250\") \nplt.plot(history12.history['acc'], color='red', linewidth = 2, label=\"batch_size=125\") \nplt.plot(history13.history['acc'], color='green', linewidth = 2, label=\"batch_size=60\")\nplt.plot(history14.history['acc'], color='yellow', linewidth = 2, label=\"batch_size=30\")\nplt.plot(history15.history['acc'], color='black', linewidth = 2, label=\"batch_size=10\")\nplt.title('Acurácia do Modelo CNN - 100 Épocas e 16 camadas')\nplt.legend()\nplt.xlabel('Épocas')\nplt.ylabel('Acurácia')\nplt.xlabel('Épocas')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history16.history['loss'], color='blue', linewidth = 2, label=\"batch_size=500\") \nplt.plot(history11.history['loss'], color='blue', linewidth = 2, label=\"batch_size=250\") \nplt.plot(history12.history['loss'], color='red', linewidth = 2, label=\"batch_size=125\") \nplt.plot(history13.history['loss'], color='green', linewidth = 2, label=\"batch_size=60\") \nplt.plot(history14.history['loss'], color='yellow', linewidth = 2, label=\"batch_size=30\") \nplt.plot(history15.history['loss'], color='black', linewidth = 2, label=\"batch_size=10\") \nplt.title('Perda do Modelo CNN - 100 Épocas - 16 Camadas')\nplt.legend()\nplt.xlabel('Épocas')\nplt.ylabel('Loss')\nplt.xlabel('Épocas')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history4.history['acc'], color='orange', linewidth = 2, label=\"batch_size - 1,62% -  11 L\") \nplt.plot(history8.history['acc'], color='red', linewidth = 2, label=\"batch_size - 2,5% - 11 L\") \nplt.plot(history13.history['acc'], color='green', linewidth = 2, label=\"batch_size -2,5% - 14 L\")\nplt.legend()\nplt.title('Acurácia dos melhores Modelos')\nplt.xlabel('Épocas')\nplt.ylabel('Acurácia')\nplt.xlabel('Épocas')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}