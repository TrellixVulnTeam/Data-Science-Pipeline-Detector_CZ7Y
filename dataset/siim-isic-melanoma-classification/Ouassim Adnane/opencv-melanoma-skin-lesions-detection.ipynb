{"cells":[{"metadata":{},"cell_type":"markdown","source":"# OpenCV Skin Lesions Detection \n<a href=\"https://www.linkedin.com/in/ouassim-adnane/\">Ouassim Adnane</a> 15 July 2020","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://codeloop.org/wp-content/uploads/2019/04/opencv_color_trackbar.png\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2>In my way to learning more about OpenCV, I've tried a couple of ideas on the sample images to extract skin marks and liked to share them. Acknowledgment to the hair removal <a href=\"https://www.kaggle.com/vatsalparsaniya/melanoma-hair-remove\" target=\"_blank\">kernel </a>and ProgrammingKnowledge OpenCV <a href=\"https://www.youtube.com/playlist?list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K\" target=\"_blank\">playlist.</a> </h2>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I've taken some sample with hair and others without 21 benign and 21 malignant","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Path = '../input/siim-isic-melanoma-classification'\nimages =['ISIC_0078712','ISIC_0080817','ISIC_0082348',\"ISIC_0098198\", \"ISIC_2601107\",\"ISIC_5086676\",  \"ISIC_7563283\",\n\"ISIC_5086349\",  \"ISIC_7562764\", \"ISIC_0098784\",  \"ISIC_2601114\" , \n\"ISIC_5086403\",  \"ISIC_7563168\",\"ISIC_0099474\",  \"ISIC_2601156\" , \n\"ISIC_0099546\" , \"ISIC_2601166\",  \"ISIC_5086709\" , \"ISIC_7563371\",\n\"ISIC_0100550\" , \"ISIC_2601537\",  \"ISIC_5087331\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(Path+\"/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train_df.loc[train_df.target==1,\"image_name\"][:20]:\n    images.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=train_df[train_df.image_name.isin(images)].target\ntarget.index = list(range(0,len(target)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def hair_remove(image):\n    \n    # convert image to grayScale\n    grayScale = cv2.cvtColor(image_resize, cv2.COLOR_RGB2GRAY)\n    \n    # kernel for morphologyEx\n    kernel = cv2.getStructuringElement(1,(17,17))\n    \n    # apply MORPH_BLACKHAT to grayScale image\n    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n    \n    # apply thresholding to blackhat\n    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n    \n    # inpaint with original image and threshold image\n    final_image = cv2.inpaint(image_resize,threshold,1,cv2.INPAINT_TELEA)\n    \n    final_image = cv2.medianBlur(final_image,5)\n    \n    return final_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding an approximate estimate of the skin mark","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,image_name in enumerate(images):\n    \n    # Set Up matplotlib figure size\n    plt.figure(figsize=(20,2.5))\n    \n    # read and reduce the image size to 512 by 512 pixels \n    image = cv2.imread(Path + '/jpeg/train/' + image_name+\".jpg\")\n    image_resize = cv2.resize(image,(512,512))\n\n    # original image plot \n    plt.subplot(1, 6, 1)\n    plt.imshow(cv2.cvtColor(image_resize, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Original : '+\" T :\" + str(target[i]))\n \n\n    # Create an Edge detection Laplacian filter\n    lap = cv2.Laplacian(image_resize,cv2.CV_64F)\n    lap = np.uint8(np.absolute(lap))\n    \n    plt.subplot(1, 6, 2)\n    plt.imshow(cv2.cvtColor(lap, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Edge detection '+ \" T :\" + str(target[i]))\n    \n    # Hair removal and adaptive threshold \n    final_image = hair_remove(image_resize)\n    gray = cv2.cvtColor(final_image,cv2.COLOR_BGR2GRAY)\n    thresh = cv2.adaptiveThreshold(gray,256,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,73,7)\n    \n    # ploting the threshold \n    plt.subplot(1, 6, 3)\n    plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('processed image : '+\" T :\" + str(target[i]))\n\n    \n    # finding the contours on the image \n    c,h=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE) \n    cv2.drawContours(image_resize,c,-1,(0,255,0),3)\n    \n\n    # ploting the contours \n    plt.subplot(1, 6, 4)\n    plt.imshow(cv2.cvtColor(image_resize, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Skin Marks detections v1:' +\" T  :\" + str(target[i]))\n    \n    \n    # creating dilate with 2 by 2 kernel \n    kernel = np.ones((2,2),np.uint8)\n    dial1 = cv2.dilate(thresh,kernel,iterations=3)\n    \n    # create a morphologyEx it's like the dilate but sharper\n    kernel = np.ones((2,2),np.uint8)\n    dial = cv2.morphologyEx(thresh,cv2.MORPH_ELLIPSE,kernel)\n    \n    # create the final image \n    img1=cv2.bitwise_and(final_image, final_image, mask=dial1)\n    img2=cv2.bitwise_and(final_image, final_image, mask=dial)\n    \n    #ploting the Lesions extraction \n    plt.subplot(1, 6, 5)\n    plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Lesions extraction v1'+ \" T :\" + str(target[i]))\n    \n    plt.subplot(1, 6,6)\n    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Lesions extraction v2'+ \" T :\" + str(target[i]))\n    \n    plt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Colors Histogram  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,image_name in enumerate(images):\n    \n    # Set Up matplotlib figure size\n    plt.figure(figsize=(20,2.5))\n    \n    # read and reduce the image size to 512 by 512 pixels \n    image = cv2.imread(Path + '/jpeg/train/' + image_name+\".jpg\")\n    image_resize = cv2.resize(image,(512,512))\n\n    final_image = hair_remove(image_resize)\n    # original image plot \n    plt.subplot(1, 4, 1)\n    plt.imshow(cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Original : '+\" T :\" + str(target[i]))\n    \n    # colors in the image histogram \n    hist= cv2.calcHist([final_image],[0],None,[256],[0,256])\n    hist2=cv2.calcHist([final_image],[1],None,[256],[0,256])\n    hist3=cv2.calcHist([final_image],[2],None,[256],[0,256])\n\n    plt.subplot(1, 4, 2)\n    plt.plot(hist)   \n    plt.axis('off')\n    plt.title('Hist Blue : '+\" T :\" + str(target[i]))\n    \n    plt.subplot(1, 4, 3)\n    plt.plot(hist2,color=\"green\")   \n    plt.axis('off')\n    plt.title('Hist Green : '+\" T :\" + str(target[i]))\n\n    plt.subplot(1, 4, 4)\n    plt.plot(hist3,color=\"red\")   \n    plt.axis('off')\n    plt.title('Hist Red : '+\" T :\" + str(target[i]))\n\n    plt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}