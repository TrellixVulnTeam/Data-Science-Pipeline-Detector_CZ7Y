{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T13:15:48.984248Z","iopub.execute_input":"2022-05-12T13:15:48.984508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn on GPU\n# Add image data set\n# we will use resized image  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import all required libraries\nimport os\nimport cv2\nimport numpy as np\nimport random as rn\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:24:32.473106Z","iopub.execute_input":"2022-05-12T19:24:32.473381Z","iopub.status.idle":"2022-05-12T19:24:32.652802Z","shell.execute_reply.started":"2022-05-12T19:24:32.473352Z","shell.execute_reply":"2022-05-12T19:24:32.652047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import all tensorflow library\nimport tensorflow as tf\nimport keras\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras import backend as k\nfrom keras.activations import elu\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Layer, InputSpec\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout, MaxPooling2D, BatchNormalization, GlobalMaxPooling2D\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:24:38.863495Z","iopub.execute_input":"2022-05-12T19:24:38.863788Z","iopub.status.idle":"2022-05-12T19:24:44.692355Z","shell.execute_reply.started":"2022-05-12T19:24:38.863757Z","shell.execute_reply":"2022-05-12T19:24:44.691613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set seed for reproducability\nseed=1234\nrn.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nos.environ[\"PYTHONHASHSEED\"]=str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:24:46.618725Z","iopub.execute_input":"2022-05-12T19:24:46.619202Z","iopub.status.idle":"2022-05-12T19:24:46.627852Z","shell.execute_reply.started":"2022-05-12T19:24:46.61916Z","shell.execute_reply":"2022-05-12T19:24:46.625641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Downloading basic model\n#                           Model name           input shape                          pretained weight       \nbase_model =tf.keras.applications.MobileNetV2(input_shape=(256,256,3),include_top=False,weights=\"imagenet\")\n\n# if you use bigger model give more accuracy but you will get less from rate\n# if you use small model gives less accuracy but you will get high from rate\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:07.487201Z","iopub.execute_input":"2022-05-12T19:25:07.487464Z","iopub.status.idle":"2022-05-12T19:25:08.417157Z","shell.execute_reply.started":"2022-05-12T19:25:07.487434Z","shell.execute_reply":"2022-05-12T19:25:08.416405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set all layers trainable\nfor layer in base_model.layers:\n    layer.trainable=True\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:09.458092Z","iopub.execute_input":"2022-05-12T19:25:09.458593Z","iopub.status.idle":"2022-05-12T19:25:09.46834Z","shell.execute_reply.started":"2022-05-12T19:25:09.458538Z","shell.execute_reply":"2022-05-12T19:25:09.467603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# build model according to your output\ndef build_model():\n    model= Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.3))   #change dropout to get better result\n    model.add(Dense(1,activation=\"sigmoid\")) # output is 0 or 1 binary\n    \n    # now complie model\n    #we are using adam we can use another one to optimize better\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005,beta_1=.9,beta_2=0.999,amsgrad=False)\n    #number of positive image  is less than the number og negative images\n    #we use AUC metrics\n    metrics = tf.keras.metrics.AUC(name=\"auc\")\n    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=metrics)\n    print(model.summary())\n    return model\nmodel =build_model()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:11.357977Z","iopub.execute_input":"2022-05-12T19:25:11.358234Z","iopub.status.idle":"2022-05-12T19:25:11.734943Z","shell.execute_reply.started":"2022-05-12T19:25:11.358205Z","shell.execute_reply":"2022-05-12T19:25:11.734238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/jpeg-melanoma-256x256/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:18.582631Z","iopub.execute_input":"2022-05-12T19:25:18.583313Z","iopub.status.idle":"2022-05-12T19:25:18.671841Z","shell.execute_reply.started":"2022-05-12T19:25:18.583275Z","shell.execute_reply":"2022-05-12T19:25:18.671118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df     # we will use only image_name and target\n\n# Total number of dataset images is 33126","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:20.410528Z","iopub.execute_input":"2022-05-12T19:25:20.411174Z","iopub.status.idle":"2022-05-12T19:25:20.442547Z","shell.execute_reply.started":"2022-05-12T19:25:20.411122Z","shell.execute_reply":"2022-05-12T19:25:20.441845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's see the number of positive and negative image\na,b=np.unique(df[\"target\"],return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:24.502332Z","iopub.execute_input":"2022-05-12T19:25:24.502766Z","iopub.status.idle":"2022-05-12T19:25:24.511757Z","shell.execute_reply.started":"2022-05-12T19:25:24.502726Z","shell.execute_reply":"2022-05-12T19:25:24.510782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:31.165016Z","iopub.execute_input":"2022-05-12T19:25:31.165288Z","iopub.status.idle":"2022-05-12T19:25:31.172754Z","shell.execute_reply.started":"2022-05-12T19:25:31.165258Z","shell.execute_reply":"2022-05-12T19:25:31.171872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b    #32542 negative images and only 584 positive image\n\n# That is why we use \" metrics = tf.keras.metrics.AUC(name=\"auc\")\"\n# because number of negative images is grater","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:32.954186Z","iopub.execute_input":"2022-05-12T19:25:32.954464Z","iopub.status.idle":"2022-05-12T19:25:32.960167Z","shell.execute_reply.started":"2022-05-12T19:25:32.954434Z","shell.execute_reply":"2022-05-12T19:25:32.95938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split training dataframe into train and validation","metadata":{"execution":{"iopub.status.busy":"2022-05-12T15:28:08.911966Z","iopub.execute_input":"2022-05-12T15:28:08.91249Z","iopub.status.idle":"2022-05-12T15:28:08.916222Z","shell.execute_reply.started":"2022-05-12T15:28:08.91245Z","shell.execute_reply":"2022-05-12T15:28:08.915556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain,valid=train_test_split(df,test_size=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:36.911635Z","iopub.execute_input":"2022-05-12T19:25:36.912158Z","iopub.status.idle":"2022-05-12T19:25:37.718478Z","shell.execute_reply.started":"2022-05-12T19:25:36.91212Z","shell.execute_reply":"2022-05-12T19:25:37.71774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now split train to get some image for testing\ntrain,test=train_test_split(train,test_size=.01)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:53.14929Z","iopub.execute_input":"2022-05-12T19:25:53.149547Z","iopub.status.idle":"2022-05-12T19:25:53.162063Z","shell.execute_reply.started":"2022-05-12T19:25:53.149518Z","shell.execute_reply":"2022-05-12T19:25:53.161313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:55.353315Z","iopub.execute_input":"2022-05-12T19:25:55.354257Z","iopub.status.idle":"2022-05-12T19:25:55.374721Z","shell.execute_reply.started":"2022-05-12T19:25:55.354205Z","shell.execute_reply":"2022-05-12T19:25:55.374045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:25:57.727504Z","iopub.execute_input":"2022-05-12T19:25:57.727931Z","iopub.status.idle":"2022-05-12T19:25:57.77742Z","shell.execute_reply.started":"2022-05-12T19:25:57.727888Z","shell.execute_reply":"2022-05-12T19:25:57.776757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:26:05.929044Z","iopub.execute_input":"2022-05-12T19:26:05.929325Z","iopub.status.idle":"2022-05-12T19:26:05.951108Z","shell.execute_reply.started":"2022-05-12T19:26:05.929296Z","shell.execute_reply":"2022-05-12T19:26:05.950277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add a new column to train,test, and valid tables, containing image name+\".jpg\"\ntrain[\"image_name_jpg\"]=train[\"image_name\"]+\".jpg\"\ntest[\"image_name_jpg\"]=test[\"image_name\"]+\".jpg\"\nvalid[\"image_name_jpg\"]=valid[\"image_name\"]+\".jpg\"","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:26:08.358674Z","iopub.execute_input":"2022-05-12T19:26:08.358941Z","iopub.status.idle":"2022-05-12T19:26:08.372986Z","shell.execute_reply.started":"2022-05-12T19:26:08.358911Z","shell.execute_reply":"2022-05-12T19:26:08.372191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert target column to string\ntrain[\"target\"]=train[\"target\"].astype(str)\ntest[\"target\"]=test[\"target\"].astype(str)\nvalid[\"target\"]=valid[\"target\"].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:26:15.371371Z","iopub.execute_input":"2022-05-12T19:26:15.371648Z","iopub.status.idle":"2022-05-12T19:26:15.408792Z","shell.execute_reply.started":"2022-05-12T19:26:15.371616Z","shell.execute_reply":"2022-05-12T19:26:15.408055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train_generator and validation_generator\n# We can add other augmentation for example vertical_flip, random cropping, etc to get better accuracy\ntrain_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1/255,\n    horizontal_flip=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:26:17.356807Z","iopub.execute_input":"2022-05-12T19:26:17.357074Z","iopub.status.idle":"2022-05-12T19:26:17.36147Z","shell.execute_reply.started":"2022-05-12T19:26:17.357038Z","shell.execute_reply":"2022-05-12T19:26:17.360519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we divide by 255 for testing in android app\ntest_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n ","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:26:19.896386Z","iopub.execute_input":"2022-05-12T19:26:19.896655Z","iopub.status.idle":"2022-05-12T19:26:19.901329Z","shell.execute_reply.started":"2022-05-12T19:26:19.896625Z","shell.execute_reply":"2022-05-12T19:26:19.900654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator=train_datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=\"../input/jpeg-melanoma-256x256/train/\",\n    x_col=\"image_name_jpg\",    # name+\".jpg\"\n    y_col=\"target\",\n    target_size=(255,255),\n    batch_size=32,\n    class_mode=\"binary\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:26:23.426991Z","iopub.execute_input":"2022-05-12T19:26:23.427664Z","iopub.status.idle":"2022-05-12T19:27:33.941653Z","shell.execute_reply.started":"2022-05-12T19:26:23.427627Z","shell.execute_reply":"2022-05-12T19:27:33.939989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_generator=test_datagen.flow_from_dataframe(\n    dataframe=valid,\n    directory=\"../input/jpeg-melanoma-256x256/train/\",\n    x_col=\"image_name_jpg\",\n    y_col=\"target\",\n    target_size=(255,255),\n    batch_size=32,\n    class_mode=\"binary\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:27:39.362407Z","iopub.execute_input":"2022-05-12T19:27:39.363137Z","iopub.status.idle":"2022-05-12T19:27:57.052115Z","shell.execute_reply.started":"2022-05-12T19:27:39.363096Z","shell.execute_reply":"2022-05-12T19:27:57.051363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\nmodel.fit_generator(\n    train_generator,\n    epochs=3,   # you have to set or use early stopping to stop before overfiting\n    shuffle=True,\n    validation_data=validation_generator\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T19:50:32.332736Z","iopub.execute_input":"2022-05-12T19:50:32.333162Z","iopub.status.idle":"2022-05-12T20:00:03.426695Z","shell.execute_reply.started":"2022-05-12T19:50:32.333121Z","shell.execute_reply":"2022-05-12T20:00:03.425811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After 3 epoch it start to overfit\n#train it 3 epoch only\n# When the trainging is done save model in tflite format which is faster but accuracy decreases\n\nconverter =tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model=converter.convert()\n# save model\nwith open (\"model.tflite\",\"wb\") as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T20:41:52.756024Z","iopub.execute_input":"2022-05-12T20:41:52.756324Z","iopub.status.idle":"2022-05-12T20:42:22.566352Z","shell.execute_reply.started":"2022-05-12T20:41:52.756291Z","shell.execute_reply":"2022-05-12T20:42:22.565532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}