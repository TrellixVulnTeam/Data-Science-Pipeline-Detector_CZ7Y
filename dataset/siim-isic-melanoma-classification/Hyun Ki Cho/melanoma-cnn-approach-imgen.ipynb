{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#started again because i suspected there was a problem in my data with all the overcomplicated bs i was doing with my numpy arrays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read data\ntrain_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\ntest_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\ntrain = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create df for malignant and benign samples\nmal_train = train[train['target']==1]\nben_train = train[train['target']==0].sample(n=2000, random_state = 316)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine and change image_name to directory values\ntotal_train =  pd.concat([mal_train, ben_train], ignore_index=True, sort =False)\ntotal_train['image_name'] = train_dir + total_train['image_name'] + '.jpg'\n\n#remove unnecessary columns\ntotal_train = total_train.drop(['patient_id', 'sex', 'age_approx', 'anatom_site_general_challenge', 'diagnosis', 'benign_malignant'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split into validation and train\nx_train, x_val, y_train, y_val = train_test_split(total_train['image_name'], total_train['target'], test_size = 0.2, shuffle = True, random_state = 316)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating dataframes to feed into ImageDataGenerator with flow_from_dataframe\ntrain_gen = pd.DataFrame({'image_dir': x_train, 'target': y_train})\nval_gen = pd.DataFrame({'image_dir': x_val, 'target': y_val})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert all the directories to strings\ntrain_gen['image_dir'].astype(str)\nval_gen['image_dir'].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (Compose,\n                            IAAAdditiveGaussianNoise, IAAAffine, IAAPerspective, IAASharpen, \n                            IAASuperpixels, CenterCrop, ChannelDropout, ChannelShuffle,\n                           CLAHE, CoarseDropout, Downscale, ElasticTransform, Equalize,\n                           FancyPCA, Flip, GaussianBlur, GaussNoise, GlassBlur,\n                           GridDistortion, GridDropout, Posterize, RandomBrightness,\n                           RandomContrast, RandomFog, RandomGamma, RandomGridShuffle, RandomRain, RandomRotate90,\n                           RandomShadow, RandomSnow, RandomSunFlare, Transpose)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image augmentations --> will try CLAHE p=1 first\n#IAAAdditiveGaussianNoise, IAAAffine, IAASuperpixels, CLAHE, CoarseDropout Elastic Transform, Equalize, FancyPCA, Flip, GaussianBlur\n#GaussNoise, GlassBlur, GridDistortion, RandomGamma RandomRotate90\n\nAUGMENTATIONS = Compose([IAAAdditiveGaussianNoise(loc=0, p=0.2),\n                        IAAAffine(p=0.2),\n                        IAASuperpixels(p=0.2),\n                        CLAHE(p=1),\n                        #CoarseDropout(max_holes=5, max_height=24, max_width=40, min_holes = 2, min_height = 10, min_width = 30, fill_value=0), no p so remove\n                        ElasticTransform(alpha=1, sigma=50, alpha_affine=50, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, approximate=False, p=0.2),\n                        #Equalize(mode='cv', by_channels=True, mask=None, mask_params=()),\n                        FancyPCA(alpha=0.1, p=0.2),\n                        Flip(p=0.2),\n                        GaussianBlur(blur_limit=7, p=0.2),\n                        GaussNoise(var_limit=(10.0, 50.0), mean=0, p=0.2),\n                        #GlassBlur(sigma=0.7, max_delta=4, iterations=2, mode='fast'), took out for now cuz no p=0.2\n                        GridDistortion(num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, value=None, mask_value=None, p=0.2),\n                        RandomGamma(gamma_limit=(80,120), eps=None, p=0.1),\n                        RandomRotate90(p=0.3),\n                        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image augments in imagedatagenerator --> https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n#https://www.curiousily.com/posts/image-data-augmentation-for-tensorflow-2-keras-and-pytorch-with-albumentations-in-python/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ImageDataAugmentor.image_data_augmentor import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_Generator = ImageDataAugmentor(rescale=1./255, \n                             #horizontal_flip = True, \n                             #rotation_range = 40, \n                             #shear_range = 0.1, \n                             #width_shift_range=0.2, \n                             #height_shift_range=0.2,\n                             augment = AUGMENTATIONS,\n                             preprocess_input=None)\n\nVal_Generator = ImageDataGenerator(rescale=1./255)\n\nTrain_Data = Train_Generator.flow_from_dataframe(dataframe = train_gen, \n                                              x_col = 'image_dir', \n                                              y_col = 'target', \n                                              class_mode = 'raw', \n                                              target_size = (224, 224),\n                                              color_mode = 'rgb', \n                                              batch_size = 8, \n                                              seed = 316, \n                                              shuffle = True)\n\nVal_Data = Val_Generator.flow_from_dataframe(dataframe = val_gen, \n                                              x_col = 'image_dir', \n                                              y_col = 'target', \n                                              class_mode = 'raw', \n                                              target_size = (224, 224),\n                                              color_mode = 'rgb', \n                                              batch_size = 8, \n                                              seed = 316, \n                                              shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom keras.metrics import AUC\nfrom keras.activations import sigmoid\nfrom keras.optimizers import SGD, Adam, Adamax\nfrom keras import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import efficientnet.tfkeras as efn \n#library somebody built on efficientnet implementations on keras --> https://github.com/qubvel/efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import vgg16 and add last layer to it\nenb6 = efn.EfficientNetB6(weights='noisy-student', include_top=False, input_shape=(256, 256, 3), pooling = 'avg')\nx = tf.keras.layers.Flatten()(enb6.output)\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = tf.keras.Model(enb6.input, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"https://www.google.com/search?q=sw+%EA%B0%9C%EB%B0%9C%EB%B3%91&oq=sw+%EA%B0%9C%EB%B0%9C%EB%B3%91&aqs=chrome..69i57j69i61.6026j0j7&client=ubuntu&sourceid=chrome&ie=UTF-8#future improvements?? --> https://www.tensorflow.org/tutorials/structured_data/imbalanced_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(lr = 1e-5)\nmodel.compile(loss=focal_loss(), metrics=[tf.keras.metrics.AUC()],optimizer=opt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epochs = 100\nbatch_size=8\nnb_train_steps = train_gen.shape[0]//batch_size\nnb_val_steps=val_gen.shape[0]//batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install livelossplot\nfrom livelossplot.inputs.tf_keras import PlotLossesCallback","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_logger = tf.keras.callbacks.CSVLogger('training.log', separator=',', append=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#callback for early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 10, verbose = 1, restore_best_weights = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bottlneck in imagedatagenerator\n#https://medium.com/@joelognn/improving-cnn-training-times-in-keras-7405baa50e09\n#might want to use tpus instead like the dude that finished calc in 2 minutes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit_generator is better for larger, more complex data --> https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/\n#fit_generator vs fit --> https://medium.com/difference-engine-ai/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2\ncb=[PlotLossesCallback(), csv_logger, early_stopping] #only csv_logger since we already instantiated CSVLogger beforehand\nmodel.fit_generator(\n    Train_Data,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=Val_Data,\n    callbacks=cb,\n    validation_steps=nb_val_steps) #workers is number of cpu cores, which is 2 here for a gpu kernel, 4 for a only cpu kernel #gpu def helps lmaooo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving model thru tf\nmodel_filename = 'saved_model.tf'\nmodel.save(model_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_data = pd.read_csv('training.log', sep=',', engine='python')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission column\n\ntest_list = test['image_name'].tolist()\ntest_path = '../input/siim-isic-melanoma-classification/jpeg/test/'\nfinal_target = []\ntest_img = []\nsize = 256, 256\n\n\n'''\nfor name in image_list:\n    pholder = Image.open(base_path + name + '.jpg')\n    pholder = pholder.resize(size) #resizes image w/ pillow\n    pholder = np.asarray(pholder)\n    train_img.append(pholder)\n'''\nfor name in test_list:\n    pholder1 = Image.open(test_path + name + '.jpg')\n    pholder1 = pholder1.resize(size) #resizes image w/ pillow\n    pholder1 = np.asarray(pholder1)\n    pholder1 = pholder1.astype('float32') \n    pholder1 /= 255.0 #normalize\n    pholder1 = [pholder1]\n    pholder1 = np.asarray(pholder1)\n    pholder1 = model.predict(pholder1)\n    pholder1 = pholder1[0][0]\n    final_target.append(pholder1)\n    \n    \n    \n    \ntest_list = np.asarray(test_list)\nfinal_target = np.asarray(final_target)\nsubmission = pd.DataFrame({'image_name':test_list, 'target':final_target})\n\n    #pholder = [pholder]\n    #pholder = np.asarray(pholder)\n    #pholder = mel_model.predict(pholder)\n    #pholder = pholder[0][0] #to get value out of double bracket array\n    \n'''test_img = np.asarray(test_img)    \nprediction = mel_model.predict(test_img)    \n\nprediction = np.asarray(prediction)\nfinal_target = np.asarray(final_target)\n\n#submission = pd.DataFrame({'image_name':test_list, 'target':final_target})'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}