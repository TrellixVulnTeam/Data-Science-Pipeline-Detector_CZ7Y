{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport cv2\nimport skimage.io as io\nimport os\nfrom tqdm import tqdm\nimport random\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.models as models\n\n\nimport torchvision.transforms as transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\ntorch.set_printoptions(linewidth=120)\ntorch.set_grad_enabled(True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = \"/kaggle/input/siim-isic-melanoma-classification/\"\n\nmeta_data = pd.read_csv(BASE_DIR + 'train.csv')\nmeta_data.columns = [\"image_name\", \"patient_id\", \"sex\", \"age\", \"anatom\", \"diagnosis\", \"bening_m\", \"target\"]\nmeta_data.sort_values(by=['image_name'], inplace=True)\n\n\nimages_name, targets =meta_data.image_name, meta_data.target\n\n\nneg_values = sum(meta_data['target'] == 0)\npos_values = sum(meta_data['target'] == 1)\n\ntargets = targets.to_numpy()\nlen(targets) == (neg_values + pos_values)\nprint(\"ratios: Neg Class : \", neg_values/len(targets), \" Pos Class : \", pos_values/len(targets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_0 = np.where(targets == 0)\ntargets_1 = np.where(targets == 1)\n\nprint(len(targets_0[0]), len(targets_1[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def hair_remove(image):\n    # convert image to grayScale\n    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    \n    # kernel for morphologyEx\n    kernel = cv2.getStructuringElement(1,(17,17))\n    \n    # apply MORPH_BLACKHAT to grayScale image\n    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n    \n    # apply thresholding to blackhat\n    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n    \n    # inpaint with original image and threshold image\n    final_image = cv2.inpaint(image,threshold,1,cv2.INPAINT_TELEA)\n    \n    return final_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomLoader:\n    \n    def __init__(self, target_0, target_1, batch_size = 64):\n        self.Path = \"../input/resize-jpg-siimisic-melanoma-classification/300x300/\"\n        self.dataset = torchvision.datasets.ImageFolder(root = self.Path,\n                        transform=transforms.Compose([ transforms.Resize((256,256)),\n                        transforms.RandomAffine(degrees = random.randint(0, 360), translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n                        transforms.RandomCrop(size = 224, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'),\n                        transforms.RandomHorizontalFlip(p=0.5),\n                        transforms.RandomRotation(degrees = random.randint(0, 360), resample=False, expand=False, center=None, fill=None),\n                        transforms.RandomVerticalFlip(p=0.5),\n                        \n                        transforms.ToTensor(), \n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                    ]))\n        self.target_0 = target_0[0]\n        self.target_1 = target_1[0]\n        self.batch_size = batch_size\n        self.labels = [0]*batch_size\n        \n        for x in range(int(batch_size/2), batch_size):\n            self.labels[x] = 1\n\n    def get_minibatch(self ):\n        \n        \n        indices_0 = random.sample(range(0, len(self.target_0)), int(self.batch_size/2))\n        indices_1 = random.sample(range(0, len(self.target_1)), int(self.batch_size/2))\n\n        comb_indices = [0]*self.batch_size\n        \n        test_size = len(self.dataset) - (len(self.target_0) + len(self.target_1))\n        \n        for x in range(self.batch_size):\n            if x < int(self.batch_size/2):\n                comb_indices[x] = self.target_0[indices_0[x]] + test_size\n            else:\n                comb_indices[x] = self.target_1[indices_1[x - int(self.batch_size)]] + test_size\n\n        # Creating  data samplers and loaders:\n        subset = torch.utils.data.Subset(self.dataset, comb_indices)\n        train_loader = torch.utils.data.DataLoader(subset, batch_size=64, num_workers = 4, )\n                                         \n        return train_loader, self.labels\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_dataset_loader = CustomLoader(targets_0, targets_1)\ntrain_loader,labels= custom_dataset_loader.get_minibatch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m,l = next(iter(train_loader))\nprint(m.shape)\nimg = m[0]\nprint(img.shape)\nnpimg = img.numpy()\nplt.imshow(np.transpose(npimg, (1, 2, 0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MyNetwork = models.alexnet(pretrained=True)\n#Frozen the weights of the cnn layers towards the beginning \nlayers_to_freeze = [MyNetwork.features[0],MyNetwork.features[3],MyNetwork.features[6]]\nfor layer in layers_to_freeze:\n    for params in layer.parameters():\n        params.requires_grad = False\nMyNetwork.classifier[0] = nn.Dropout(p = 0.2, inplace = False)\nMyNetwork.classifier[3] = nn.Dropout(p = 0.2, inplace = False)\nMyNetwork.classifier[6] = nn.Linear(in_features=4096, out_features=2, bias=True)\n\nMyNetwork.classifier = nn.Sequential(*list(MyNetwork.classifier) + [nn.LogSoftmax(dim=1)])\nprint(MyNetwork)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cal_acc(pred, labels):\n    countLab_1, countLab_0, count_pred_1, count_pred_0 = 0, 0, 0, 0\n    for i in range(len(labels)):\n        if labels[i] == 1:\n            countLab_1 += 1\n        else:\n            countLab_0 += 1\n        if pred[i] == labels[i] and labels[i] == 1:\n            count_pred_1 += 1\n        elif pred[i] == labels[i] and labels[i] == 0:\n            count_pred_0 += 1\n    \n    if countLab_1 == 0:\n        countLab_1 = 1\n    if countLab_0 == 0:\n        countLab_0 = 1\n    return countLab_1, countLab_0, count_pred_1, count_pred_0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network = MyNetwork\nuse_cuda = True\nif use_cuda and torch.cuda.is_available():\n    network.cuda()\n    print('cuda')\n\n\noptimizer = optim.SGD(network.parameters(), lr=0.001, momentum=0.9)\n# weights = [pos_values/len(targets), neg_values/len(targets)]\n# class_weights = torch.FloatTensor(weights).cuda()\nLossFunc = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_loss = 0\ntotal_correct_0, total_correct_1 = 0, 0\nx = 0\ntotal_val_0, total_val_1= 0, 0\ntotal_train_0, total_train_1 = 0, 0\n\nfor batches in range(300*15,6000):\n        \n    train_loader, labels = custom_dataset_loader.get_minibatch()\n    images, _ = next(iter(train_loader))\n    labels = torch.tensor(labels)\n    if use_cuda and torch.cuda.is_available():\n        images = images.cuda()\n        labels = labels.cuda()\n\n    pred = network(images)\n    #print(torch.sigmoid(pred), labels)\n    loss = LossFunc(torch.sigmoid(pred),labels)\n    optimizer.zero_grad() # because each time its adds gradients into previous gradients\n    loss.backward() # calculating gradient\n    optimizer.step() # update weights / thetas\n\n\n\n\n    total_loss += loss.item()\n\n    tt1, tt0, tc1, tc0  = cal_acc(pred.argmax(dim = 1), labels)\n    total_train_1, total_train_0, total_correct_1, total_correct_0 = total_train_1 + tt1, total_train_0 + tt0, total_correct_1 + tc1, total_correct_0 + tc0\n\n    if batches % 300 == 0 and batches != 0:\n        print(\"epoch : \",batches/300,\"Traning Accuracy of class 1 : \",total_correct_1,'/',total_train_1,'  ',total_correct_1*1.0/total_train_1 )\n        print(\"epoch : \",batches/300,\"Traning Accuracy of class 0 : \",total_correct_0,'/',total_train_0,'  ',total_correct_0*1.0/total_train_0,\"Train Loss : \",total_loss*1.0/(len(train_loader)*300) )\n        total_loss = 0\n        total_correct_0, total_correct_1 = 0, 0\n        x = 0\n        total_val_0, total_val_1= 0, 0\n        total_train_0, total_train_1 = 0, 0\n        \n    torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_data = pd.read_csv(BASE_DIR + 'test.csv')\nmeta_data.columns = [\"image_name\", \"patient_id\", \"sex\", \"age\", \"anatom\"]\n\nimages_name = meta_data.image_name\nprint(len(images_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_indices = list(range(len(images_name)))\nsubset = torch.utils.data.Subset(custom_dataset_loader.dataset, test_indices)\ntest_loader = torch.utils.data.DataLoader(subset, batch_size=64, num_workers = 4, )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\nx = 0\nwith open(\"sample_submission.csv\", 'w') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"image_name\",\"target\"])\n    for i,(data) in enumerate(test_loader):\n        images,_ = data\n        images = images.cuda()\n        # forward + backward + optimize\n        Output = network(images)\n        Output = Output.argmax(dim = 1)\n        for out in Output:\n            writer.writerow([images_name[x],str(out.item())])\n            x += 1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}