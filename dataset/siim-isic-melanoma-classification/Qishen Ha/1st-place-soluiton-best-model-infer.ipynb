{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1st Place Solution Best Model Inference Code\n\nHi, all\n\nSome of our friends want to try our trained models on their own moles ;)\n\nSo we decide to publish this kernel.\n\nThis is our infernce code for one of our best single model (Effnet-B7 w/ input size 640),\nwhich have a cv auc_all around `0.975` (validation on both 18,19,20) using chris's splits.\n\n(To see this auc_all score you only need to set `DEBUG = False` then rerun this kernel, it takes around 7h~ to compute the whole oof on kaggle kernel)\n\n\n# Usage\n\nOne can use this kernel to check your own moles by:\n\n* Take some pictures on your moles by your phone or camera.\n* Upload it to Kaggle Datasets (remember to make it private)\n* Fork this kernel\n* Add your uploaded dataset\n* Modify `Predict` Section to predict on your own pictures!\n\n# Thanks","metadata":{}},{"cell_type":"code","source":"DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:21.773998Z","iopub.execute_input":"2021-05-27T13:13:21.774355Z","iopub.status.idle":"2021-05-27T13:13:21.779194Z","shell.execute_reply.started":"2021-05-27T13:13:21.774302Z","shell.execute_reply":"2021-05-27T13:13:21.778234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip -q install geffnet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-27T13:13:21.781258Z","iopub.execute_input":"2021-05-27T13:13:21.781917Z","iopub.status.idle":"2021-05-27T13:13:30.408788Z","shell.execute_reply.started":"2021-05-27T13:13:21.78188Z","shell.execute_reply":"2021-05-27T13:13:30.407964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport albumentations as A\nimport geffnet\n\ndevice = torch.device('cuda')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-05-27T13:13:30.41039Z","iopub.execute_input":"2021-05-27T13:13:30.410832Z","iopub.status.idle":"2021-05-27T13:13:33.169586Z","shell.execute_reply.started":"2021-05-27T13:13:30.410788Z","shell.execute_reply":"2021-05-27T13:13:33.168761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_type = '9c_b7ns_1e_640_ext_15ep'\nimage_size = 640\nuse_amp = False\ndata_dir = '../input/jpeg-melanoma-768x768'\ndata_dir2 = '../input/jpeg-isic2019-768x768'\nmodel_dir = '../input/melanoma-winning-models'\nenet_type = 'efficientnet-b7'\nbatch_size = 16\nnum_workers = 4\nout_dim = 9\n\nuse_meta = False\nuse_external = '_ext' in kernel_type","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.170931Z","iopub.execute_input":"2021-05-27T13:13:33.171282Z","iopub.status.idle":"2021-05-27T13:13:33.179495Z","shell.execute_reply.started":"2021-05-27T13:13:33.171248Z","shell.execute_reply":"2021-05-27T13:13:33.178795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read CSV","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_test['filepath'] = df_test['image_name'].apply(lambda x: os.path.join(data_dir, 'test', f'{x}.jpg'))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.184066Z","iopub.execute_input":"2021-05-27T13:13:33.184382Z","iopub.status.idle":"2021-05-27T13:13:33.256705Z","shell.execute_reply.started":"2021-05-27T13:13:33.184355Z","shell.execute_reply":"2021-05-27T13:13:33.256071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_train = df_train[df_train['tfrecord'] != -1].reset_index(drop=True)\n# df_train['fold'] = df_train['tfrecord'] % 5\ntfrecord2fold = {\n    2:0, 4:0, 5:0,\n    1:1, 10:1, 13:1,\n    0:2, 9:2, 12:2,\n    3:3, 8:3, 11:3,\n    6:4, 7:4, 14:4,\n}\ndf_train['fold'] = df_train['tfrecord'].map(tfrecord2fold)\ndf_train['is_ext'] = 0\ndf_train['filepath'] = df_train['image_name'].apply(lambda x: os.path.join(data_dir, 'train', f'{x}.jpg'))\n\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('seborrheic keratosis', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('lichenoid keratosis', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('solar lentigo', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('lentigo NOS', 'BKL'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('cafe-au-lait macule', 'unknown'))\ndf_train['diagnosis'] = df_train['diagnosis'].apply(lambda x: x.replace('atypical melanocytic proliferation', 'unknown'))\n\ndf_train['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.260639Z","iopub.execute_input":"2021-05-27T13:13:33.260921Z","iopub.status.idle":"2021-05-27T13:13:33.560707Z","shell.execute_reply.started":"2021-05-27T13:13:33.260895Z","shell.execute_reply":"2021-05-27T13:13:33.559878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_external:\n    df_train2 = pd.read_csv(os.path.join(data_dir2, 'train.csv'))\n    df_train2 = df_train2[df_train2['tfrecord'] >= 0].reset_index(drop=True)\n    df_train2['fold'] = df_train2['tfrecord'] % 5\n    df_train2['is_ext'] = 1\n    df_train2['filepath'] = df_train2['image_name'].apply(lambda x: os.path.join(data_dir2, 'train', f'{x}.jpg'))\n\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('NV', 'nevus'))\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('MEL', 'melanoma'))\n    df_train = pd.concat([df_train, df_train2]).reset_index(drop=True)\n\ndiagnosis2idx = {d: idx for idx, d in enumerate(sorted(df_train.diagnosis.unique()))}\ndf_train['target'] = df_train['diagnosis'].map(diagnosis2idx)\nmel_idx = diagnosis2idx['melanoma']\ndiagnosis2idx","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.561976Z","iopub.execute_input":"2021-05-27T13:13:33.56231Z","iopub.status.idle":"2021-05-27T13:13:33.759476Z","shell.execute_reply.started":"2021-05-27T13:13:33.562281Z","shell.execute_reply":"2021-05-27T13:13:33.758778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class SIIMISICDataset(Dataset):\n    def __init__(self, csv, split, mode, transform=None):\n\n        self.csv = csv.reset_index(drop=True)\n        self.split = split\n        self.mode = mode\n        self.transform = transform\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        image = cv2.imread(row.filepath)\n        image = image[:, :, ::-1]\n\n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image'].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n\n        image = image.transpose(2, 0, 1)\n\n        if self.mode == 'test':\n            return torch.tensor(image).float()\n        else:\n            return torch.tensor(image).float(), torch.tensor(self.csv.iloc[index].target).long()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.760788Z","iopub.execute_input":"2021-05-27T13:13:33.761137Z","iopub.status.idle":"2021-05-27T13:13:33.773392Z","shell.execute_reply.started":"2021-05-27T13:13:33.761099Z","shell.execute_reply":"2021-05-27T13:13:33.772661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_val = A.Compose([\n    A.Resize(image_size, image_size),\n    A.Normalize()\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.774765Z","iopub.execute_input":"2021-05-27T13:13:33.775166Z","iopub.status.idle":"2021-05-27T13:13:33.785455Z","shell.execute_reply.started":"2021-05-27T13:13:33.775124Z","shell.execute_reply":"2021-05-27T13:13:33.784685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_show = df_train.sample(1000)\ndataset_show = SIIMISICDataset(df_show, 'train', 'val', transform=transforms_val)\n# dataset_show = CloudDataset(df_train, 'train', 'val', image_size, transform=None)\n# dataset_show = CloudDataset(df_test, 'test', 'test', image_size, transform=None)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        if use_meta:\n            img = img[0]\n        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(str(label))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:33.787029Z","iopub.execute_input":"2021-05-27T13:13:33.78745Z","iopub.status.idle":"2021-05-27T13:13:36.414115Z","shell.execute_reply.started":"2021-05-27T13:13:33.787413Z","shell.execute_reply":"2021-05-27T13:13:36.413085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim, n_meta_features=0, load_pretrained=False):\n\n        super(enetv2, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.enet = geffnet.create_model(enet_type.replace('-', '_'), pretrained=load_pretrained)\n        self.dropout = nn.Dropout(0.5)\n\n        in_ch = self.enet.classifier.in_features\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = self.enet(x)\n        return x\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x).squeeze(-1).squeeze(-1)\n        x = self.myfc(self.dropout(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:36.415781Z","iopub.execute_input":"2021-05-27T13:13:36.416274Z","iopub.status.idle":"2021-05-27T13:13:36.430258Z","shell.execute_reply.started":"2021-05-27T13:13:36.416235Z","shell.execute_reply":"2021-05-27T13:13:36.428829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"def get_trans(img, I):\n    if I >= 4:\n        img = img.transpose(2,3)\n    if I % 4 == 0:\n        return img\n    elif I % 4 == 1:\n        return img.flip(2)\n    elif I % 4 == 2:\n        return img.flip(3)\n    elif I % 4 == 3:\n        return img.flip(2).flip(3)\n\n    \ndef val_epoch(model, loader, is_ext=None, n_test=1, get_output=False):\n    model.eval()\n    LOGITS = []\n    PROBS = []\n    TARGETS = []\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            \n            if use_meta:\n                data, meta = data\n                data, meta, target = data.to(device), meta.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I), meta)\n                    logits += l\n                    probs += l.softmax(1)\n            else:\n                data, target = data.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    logits += l\n                    probs += l.softmax(1)\n            logits /= n_test\n            probs /= n_test\n\n            LOGITS.append(logits.detach().cpu())\n            PROBS.append(probs.detach().cpu())\n            TARGETS.append(target.detach().cpu())\n\n    LOGITS = torch.cat(LOGITS).numpy()\n    PROBS = torch.cat(PROBS).numpy()\n    TARGETS = torch.cat(TARGETS).numpy()\n\n    if get_output:\n        return LOGITS, PROBS\n    else:\n        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n        auc = roc_auc_score((TARGETS==mel_idx).astype(float), LOGITS[:, mel_idx])\n        auc_20 = roc_auc_score((TARGETS[is_ext==0]==mel_idx).astype(float), LOGITS[is_ext==0, mel_idx])\n        return val_loss, acc, auc, auc_20","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:36.432319Z","iopub.execute_input":"2021-05-27T13:13:36.433001Z","iopub.status.idle":"2021-05-27T13:13:36.466975Z","shell.execute_reply.started":"2021-05-27T13:13:36.432959Z","shell.execute_reply":"2021-05-27T13:13:36.465809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PROBS = []\ndfs = []\n\nfor fold in range(5):\n    i_fold = fold\n\n    df_valid = df_train[df_train['fold'] == i_fold]\n    if DEBUG:\n        df_valid = pd.concat([\n            df_valid[df_valid['target'] == mel_idx].sample(10),\n            df_valid[df_valid['target'] != mel_idx].sample(10)\n        ])\n    print(df_valid.shape)\n\n    dataset_valid = SIIMISICDataset(df_valid, 'train', 'val', transform=transforms_val)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, num_workers=num_workers)\n\n    model = enetv2(enet_type, n_meta_features=0, out_dim=out_dim)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{i_fold}.pth')\n    state_dict = torch.load(model_file)\n    state_dict = {k.replace('module.', ''): state_dict[k] for k in state_dict.keys()}\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n\n    this_LOGITS, this_PROBS = val_epoch(model, valid_loader, is_ext=df_valid['is_ext'].values, n_test=8, get_output=True)\n    PROBS.append(this_PROBS)\n    dfs.append(df_valid)\n    \ndfs = pd.concat(dfs).reset_index(drop=True)\ndfs['pred'] = np.concatenate(PROBS).squeeze()[:, mel_idx]","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:13:36.468528Z","iopub.execute_input":"2021-05-27T13:13:36.469546Z","iopub.status.idle":"2021-05-27T13:14:49.534342Z","shell.execute_reply.started":"2021-05-27T13:13:36.469499Z","shell.execute_reply":"2021-05-27T13:14:49.532932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Raw auc_all\nroc_auc_score(dfs['target'] == mel_idx, dfs['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:49.537298Z","iopub.execute_input":"2021-05-27T13:14:49.537559Z","iopub.status.idle":"2021-05-27T13:14:49.550386Z","shell.execute_reply.started":"2021-05-27T13:14:49.53753Z","shell.execute_reply":"2021-05-27T13:14:49.549414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rank per fold auc_all\ndfs2 = dfs.copy()\nfor i in range(5):\n    dfs2.loc[dfs2['fold']==i, 'pred'] = dfs2.loc[dfs2['fold']==i, 'pred'].rank(pct=True)\nroc_auc_score(dfs2['target'] == mel_idx, dfs2['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:49.552296Z","iopub.execute_input":"2021-05-27T13:14:49.552784Z","iopub.status.idle":"2021-05-27T13:14:49.573887Z","shell.execute_reply.started":"2021-05-27T13:14:49.552745Z","shell.execute_reply":"2021-05-27T13:14:49.573038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Raw auc_2020\nroc_auc_score(dfs[dfs['is_ext']==0]['target']==mel_idx, dfs[dfs['is_ext']==0]['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:49.575358Z","iopub.execute_input":"2021-05-27T13:14:49.575733Z","iopub.status.idle":"2021-05-27T13:14:49.588001Z","shell.execute_reply.started":"2021-05-27T13:14:49.575684Z","shell.execute_reply":"2021-05-27T13:14:49.587017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rank per fold auc_2020\ndfs2 = dfs[dfs.is_ext==0].copy()\nfor i in range(5):\n    dfs2.loc[dfs2['fold']==i, 'pred'] = dfs2.loc[dfs2['fold']==i, 'pred'].rank(pct=True)\nroc_auc_score(dfs2['target'] == mel_idx, dfs2['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:49.589332Z","iopub.execute_input":"2021-05-27T13:14:49.589779Z","iopub.status.idle":"2021-05-27T13:14:49.608528Z","shell.execute_reply.started":"2021-05-27T13:14:49.589739Z","shell.execute_reply":"2021-05-27T13:14:49.607766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"n_test = 8\ndf_test = df_test if not DEBUG else df_test.head(batch_size * 2)\ndataset_test = SIIMISICDataset(df_test, 'test', 'test', transform=transforms_val)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:49.610103Z","iopub.execute_input":"2021-05-27T13:14:49.610528Z","iopub.status.idle":"2021-05-27T13:14:49.616838Z","shell.execute_reply.started":"2021-05-27T13:14:49.610491Z","shell.execute_reply":"2021-05-27T13:14:49.615909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i_fold in range(5):\n    model = enetv2(enet_type, n_meta_features=0, out_dim=out_dim)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{i_fold}.pth')\n    state_dict = torch.load(model_file)\n    state_dict = {k.replace('module.', ''): state_dict[k] for k in state_dict.keys()}\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n    models.append(model)\nlen(models)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:49.618276Z","iopub.execute_input":"2021-05-27T13:14:49.618671Z","iopub.status.idle":"2021-05-27T13:14:57.245302Z","shell.execute_reply.started":"2021-05-27T13:14:49.618634Z","shell.execute_reply":"2021-05-27T13:14:57.244592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUTS = []\nPROBS = []\n\nwith torch.no_grad():\n    for (data) in tqdm(test_loader):\n\n        if use_meta:\n            data, meta = data\n            data, meta = data.to(device), meta.to(device)\n            probs = torch.zeros((data.shape[0], out_dim)).to(device)\n            for I in range(n_test):\n                l = model(get_trans(data, I), meta)\n                probs += l.softmax(1)\n        else:\n            data = data.to(device)\n            probs = torch.zeros((data.shape[0], out_dim)).to(device)\n            for model in models:\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    probs += l.softmax(1)\n\n        probs /= n_test * len(models)\n        PROBS.append(probs.detach().cpu())\n\nPROBS = torch.cat(PROBS).numpy()\nOUTPUTS = PROBS[:, mel_idx]","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:14:57.246765Z","iopub.execute_input":"2021-05-27T13:14:57.2471Z","iopub.status.idle":"2021-05-27T13:15:58.965385Z","shell.execute_reply.started":"2021-05-27T13:14:57.247065Z","shell.execute_reply":"2021-05-27T13:15:58.964419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['target'] = OUTPUTS\ndf_test[['image_name', 'target']].to_csv(f'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:15:58.967363Z","iopub.execute_input":"2021-05-27T13:15:58.967748Z","iopub.status.idle":"2021-05-27T13:15:59.260396Z","shell.execute_reply.started":"2021-05-27T13:15:58.967692Z","shell.execute_reply":"2021-05-27T13:15:59.259618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[['image_name', 'target']].head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:15:59.261542Z","iopub.execute_input":"2021-05-27T13:15:59.261902Z","iopub.status.idle":"2021-05-27T13:15:59.280395Z","shell.execute_reply.started":"2021-05-27T13:15:59.261866Z","shell.execute_reply":"2021-05-27T13:15:59.27949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:15:59.283672Z","iopub.execute_input":"2021-05-27T13:15:59.283972Z","iopub.status.idle":"2021-05-27T13:15:59.292665Z","shell.execute_reply.started":"2021-05-27T13:15:59.283945Z","shell.execute_reply":"2021-05-27T13:15:59.291879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Single Image","metadata":{}},{"cell_type":"code","source":"#patient test images processing\n# patient 1 image name\nin1 = 'hello'\n# patient 1 patient_id\npi1 = 'IP23232'\n# patient 1 sex\ns1 = 'male'\n# patient 1 age\na1 = 70.0\n# patient 1 anatom_site_general_challenge. where its located\nasgc1 = 'torso'\n# patient 1 image filepath\nf1 = '../input/jpeg-melanoma-768x768/test/ISIC_0052060.jpg'\nimport csv\nwith open('datasettesting.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"image_name\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"width\", \"height\", \"filepath\"])\n    writer.writerow([in1,pi1, s1, a1, asgc1, 6000, 4000, f1])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:15:59.296244Z","iopub.execute_input":"2021-05-27T13:15:59.296609Z","iopub.status.idle":"2021-05-27T13:15:59.311927Z","shell.execute_reply.started":"2021-05-27T13:15:59.29657Z","shell.execute_reply":"2021-05-27T13:15:59.311006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_single_image = pd.read_csv('datasettesting.csv')\ndf_single_image","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:15:59.31615Z","iopub.execute_input":"2021-05-27T13:15:59.316685Z","iopub.status.idle":"2021-05-27T13:15:59.341456Z","shell.execute_reply.started":"2021-05-27T13:15:59.316649Z","shell.execute_reply":"2021-05-27T13:15:59.340528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as we only read a single image, so we don't need a dataloader\ndataset_test = SIIMISICDataset(df_single_image, 'test', 'test', transform=transforms_val)\nimage = dataset_test[0]  \nimage = image.to(device).unsqueeze(0)  # a single image need to be added a new axis to act like batch_size = 1","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:15:59.348798Z","iopub.execute_input":"2021-05-27T13:15:59.352593Z","iopub.status.idle":"2021-05-27T13:15:59.410208Z","shell.execute_reply.started":"2021-05-27T13:15:59.352525Z","shell.execute_reply":"2021-05-27T13:15:59.407966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    probs = torch.zeros((image.shape[0], out_dim)).to(device)\n    for model in models:\n        for I in range(n_test):\n            l = model(get_trans(image, I))\n            probs += l.softmax(1)\nprobs /= len(models) * n_test","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:21:51.850627Z","iopub.execute_input":"2021-05-27T13:21:51.851034Z","iopub.status.idle":"2021-05-27T13:21:54.839878Z","shell.execute_reply.started":"2021-05-27T13:21:51.85098Z","shell.execute_reply":"2021-05-27T13:21:54.839059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = probs[:, mel_idx].item()\nprediction","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:22:23.191417Z","iopub.execute_input":"2021-05-27T13:22:23.19179Z","iopub.status.idle":"2021-05-27T13:22:23.197553Z","shell.execute_reply.started":"2021-05-27T13:22:23.191758Z","shell.execute_reply":"2021-05-27T13:22:23.196597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}