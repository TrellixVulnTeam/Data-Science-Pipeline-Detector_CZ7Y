{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers, optimizers\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf=pd.read_csv('../input/siim-isic-melanoma-classification/train.csv',dtype=str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_ext(fn):\n    return fn+\".jpg\"\n\ntraindf[\"image_name\"]=traindf[\"image_name\"].apply(append_ext)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(traindf['image_name'], traindf['target'], test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen=ImageDataGenerator(rescale=1./255,validation_split=0.15)\ntrain_generator=datagen.flow_from_dataframe(\ndataframe=traindf,\ndirectory=\"../input/siim128x128-mix/train/\",\nx_col=\"image_name\",\ny_col=\"target\",\nsubset=\"training\",\ncolor_mode='rgb',\nbatch_size=bs,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",\ntarget_size=(128,128))\n\nval_generator=datagen.flow_from_dataframe(\ndataframe=traindf,\ndirectory=\"../input/siim128x128-mix/train/\",\nx_col=\"image_name\",\ny_col=\"target\",\nsubset=\"validation\",\ncolor_mode='rgb',\nbatch_size=bs,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",\ntarget_size=(128,128))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization, UpSampling2D, concatenate\nfrom tensorflow.keras.models import Model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\n## Build the model using the functional API\ni = Input(shape=(128,128,3))\n# x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n# x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n# x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\nx = BatchNormalization()(x)\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n# x = Dropout(0.2)(x)\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n# x = Dropout(0.2)(x)\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n# x = Dropout(0.2)(x)\n#x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n#x = BatchNormalization()(x)\n#x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n#x = BatchNormalization()(x)\n#x = MaxPooling2D((2, 2))(x)\n\n\n# x = GlobalMaxPooling2D()(x)\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(2, activation='softmax')(x)\n\nmodel = Model(inputs=i,outputs=x)\n    \nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef unet(pretrained_weights = None ,input_size = (128,128,3)):\n    i = Input(input_size)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(i)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    #drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)#conv4\n\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    #drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))#conv5\n    merge6 = concatenate([conv4,up6], axis = 3)#drop4\n    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    conv6 = BatchNormalization()(conv6)\n\n    up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    conv7 = BatchNormalization()(conv7)\n\n    up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv8 = BatchNormalization()(conv8)\n\n    up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = BatchNormalization()(conv9)\n    pool9 = MaxPooling2D(pool_size=(2, 2))(conv9)\n\n    conv10 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool9)\n    conv10 = BatchNormalization()(conv10)\n    conv10 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv10)\n    conv10 = BatchNormalization()(conv10)\n    pool10 = MaxPooling2D(pool_size=(2, 2))(conv10)\n\n    merge11 = concatenate([conv3,pool10], axis = 3)\n    conv11 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge11)\n    conv11 = BatchNormalization()(conv11)\n    conv11 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv11)\n    conv11 = BatchNormalization()(conv11)\n    pool11 = MaxPooling2D(pool_size=(2, 2))(conv11)\n\n    conv12 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool11)\n    conv12 = BatchNormalization()(conv12)\n    conv12 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv12)\n    conv12 = BatchNormalization()(conv12)\n    #drop4 = Dropout(0.5)(conv4)\n    pool12 = MaxPooling2D(pool_size=(2, 2))(conv12)#conv4\n\n    conv13 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool12)\n    conv13 = BatchNormalization()(conv13)\n    conv13 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv13)\n    conv13 = BatchNormalization()(conv13)\n    #drop5 = Dropout(0.5)(conv5)\n\n\n\n    up14 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv13))#conv5\n    merge14 = concatenate([conv12,up14], axis = 3)#drop4\n    conv14 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge14)\n    conv14 = BatchNormalization()(conv14)\n    conv14 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv14)\n    conv14 = BatchNormalization()(conv14)\n\n    up15 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv14))\n    merge15 = concatenate([conv11,up15], axis = 3)\n    conv15 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge15)\n    conv15 = BatchNormalization()(conv15)\n    conv15 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv15)\n    conv15 = BatchNormalization()(conv15)\n    conv15 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv15)\n    conv15 = BatchNormalization()(conv15)\n\n    up16 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv15))\n    merge16 = concatenate([conv10,up16], axis = 3)\n    conv16 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge16)\n    conv16 = BatchNormalization()(conv16)\n    conv16 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv16)\n    conv16 = BatchNormalization()(conv16)\n    conv16 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv16)\n    conv16 = BatchNormalization()(conv16)\n\n    up17 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv16))\n    merge17 = concatenate([conv9,up17], axis = 3)\n    conv17 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge17)\n    conv17 = BatchNormalization()(conv17)\n    conv17 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv17)\n    conv17 = BatchNormalization()(conv17)\n\n    merge18= concatenate([conv1,conv17], axis = 3)\n    conv18 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge18)\n    conv18 = BatchNormalization()(conv18)\n    conv18 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge18)\n    #conv18 = BatchNormalization()(conv18)\n    #conv18 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv18)\n    #conv18 = BatchNormalization()(conv18)\n    #conv18 = Conv2D(1, 1, activation = 'sigmoid')(conv18)\n\n    x = Flatten()(conv18) \n    x = Dropout(0.2)(x) \n    x = Dense(1024, activation='relu')(x) \n    x = Dropout(0.2)(x) \n    x = Dense(2, activation='softmax')(x)\n    \n    \n    model = Model(i,x)\n\n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    #model.summary()\n\n    if(pretrained_weights):\n        model.load_weights(pretrained_weights)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=unet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#spe=26501 // 32\nspe=len(train_generator.filenames) // bs\nvs=len(val_generator.filenames) // bs\nmodel.fit_generator(train_generator,steps_per_epoch=spe,epochs=10,validation_data=val_generator, validation_steps=vs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n        directory=\"../input/siim128x128-mix/\",\n        classes=[\"test\"],\n        target_size=(128, 128),\n        batch_size=1,\n        class_mode='categorical',\n        color_mode='rgb',\n        shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict_generator(test_generator,steps = 10982)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames=test_generator.filenames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f=[]\nfor p in filenames:\n    p=p.replace('test/','')\n    p=p.replace('.jpg','')\n    f.append(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(\n    {\n     'image_name': f, \n     'target': (1-predict[:,0])\n    }\n).to_csv('submission.csv', index=False)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('submission.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}