{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#IMPORTS\nimport cv2\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from torchsummary import summary\nimport requests\nfrom PIL import Image\n\n#Using VGG-19 pretrained model for image classification\n\nmodel = torchvision.models.resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def download(url,fname):\n    response = requests.get(url)\n    with open(fname,\"wb\") as f:\n        f.write(response.content)\n    \n# Downloading the image    \n#download(\"https://specials-images.forbesimg.com/imageserve/5db4c7b464b49a0007e9dfac/960x0.jpg?fit=scale\",\"input.jpg\")\n\n# Opening the image\nimg = Image.open('../input/siim-isic-melanoma-classification/jpeg/train/ISIC_0084395.jpg') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess the image\ndef preprocess(image, size=224):\n    transform = T.Compose([\n        T.Resize((size,size)),\n        T.CenterCrop(size),\n        T.ToTensor(),\n        T.Normalize([0.5], [0.225]),\n        T.Lambda(lambda x: x[None]),\n    ])\n    return transform(image)\n\n'''\n    Y = (X - μ)/(σ) => Y ~ Distribution(0,1) if X ~ Distribution(μ,σ)\n    => Y/(1/σ) follows Distribution(0,σ)\n    => (Y/(1/σ) - (-μ))/1 is actually X and hence follows Distribution(μ,σ)\n'''\ndef deprocess(image):\n    transform = T.Compose([\n        T.Lambda(lambda x: x[0]),\n        T.Normalize([0.5], [0.225]),\n        T.ToPILImage(),\n    ])\n    return transform(image)\n\ndef show_img(PIL_IMG):\n    plt.imshow(np.asarray(PIL_IMG))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process(image, size=224):\n    transform = T.Compose([\n        T.Resize((size,size)),\n        T.CenterCrop(size),\n        T.ToTensor(),\n        #T.Normalize([0.5], [0.225]),\n        T.ToPILImage()\n    ])\n    return transform(image)\n\ny = process(img)\nshow_img(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.save(\"skin6.jpeg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modelpreprocess(image, size=224):\n    transform = T.Compose([\n        T.Resize((size,size)),\n        T.CenterCrop(size),\n        T.ToTensor(),\n        T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n        T.ToPILImage()\n    ])\n    return transform(image)\n\ny = modelpreprocess(img)\nshow_img(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process(image, size=224):\n    transform = T.Compose([\n        T.Resize((size,size)),\n        T.CenterCrop(size),\n        T.ToTensor(),\n        T.Normalize([0.5], [0.225]),\n        T.ToPILImage()\n    ])\n    return transform(image)\n\ny = process(img)\nshow_img(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.save(\"norm_skin6.jpeg\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X = preprocess(img)\n\n# we would run the model in evaluation mode\nmodel.eval()\n\n# we need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\nX.requires_grad_()\n\n'''\nforward pass through the model to get the scores, note that VGG-19 model doesn't perform softmax at the end\nand we also don't need softmax, we need scores, so that's perfect for us.\n'''\n\nscores = model(X)\n\n# Get the index corresponding to the maximum score and the maximum score itself.\nscore_max_index = scores.argmax()\n#print(score_max_index.shape)\nscore_max = scores[0,score_max_index]\n\n'''\nbackward function on score_max performs the backward pass in the computation graph and calculates the gradient of \nscore_max with respect to nodes in the computation graph\n'''\nscore_max.backward()\n\n'''\nSaliency would be the gradient with respect to the input image now. But note that the input image has 3 channels,\nR, G and B. To derive a single class saliency value for each pixel (i, j),  we take the maximum magnitude\nacross all colour channels.\n'''\nsaliency, _ = torch.max(X.grad.data.abs(),dim=1)\n\nfig = plt.figure()\n# code to plot the saliency map as a heatmap\nplt.imshow(saliency[0], cmap=plt.cm.hot)\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig.savefig(\"saliency_6.jpeg\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}