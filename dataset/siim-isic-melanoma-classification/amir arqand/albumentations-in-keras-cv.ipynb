{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom tensorflow import keras\nimport os\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.applications import DenseNet201\n#from tensorflow.keras.applications import efficientnet\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications import Xception\nfrom sklearn.utils import class_weight\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n#import cv2\nimport tensorflow as tf\nfrom keras.models import Sequential\n#import efficientnet.keras as efn\n# import tensorflow.keras.applications.ResNet101 as resnet101\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom plotly import express\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n#import lightgbm as lgb\n#import catboost as ctb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv',na_values=['unknown'])\ntest = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR = '../input/resize-jpg-siimisic-melanoma-classification/300x300/train/'\n#DIR = './300x300/train'\nTestDIR = '../input/resize-jpg-siimisic-melanoma-classification/300x300/test/'\nimg = []\ntrain_fk=[]\nlabels = []\nformat = '.jpg'\n\nfor i in train['image_name']:\n    img.append(os.path.join(DIR,i)+format)\n    \nfor i in train['target']:\n    labels.append(str(i))\nfor i in train['image_name']:         #save images name in an array to use later for kfold cross validation\n  train_fk.append(i+format)\n\n#creating a no array for test set as well\ntest_data=[]\nfor i in range(test.shape[0]):\n    test_data.append(TestDIR + test['image_name'].iloc[i]+format)\ndf_test=pd.DataFrame(test_data)\ndf_test.columns=['images']        #this one alsong with above line are creating a dataframe for test data which will be used for the submision task","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = class_weight.compute_class_weight(\n    'balanced',\n    train['target'].unique(),\n    train[['target']].to_numpy().reshape(-1)\n)\nweights = {i : class_weights[i] for i in range(2)}\nprint('benign weight: ',class_weights[0])\nprint('malignant weight: ',class_weights[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this library allow user to use a customized datagenerator with which one can use augmentation implemented in albumentation library \n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n   \nAUGMENTATIONS = albumentations.Compose([\n    albumentations.Transpose(p=0.5),\n    albumentations.RandomContrast(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    #albumentations.RandomCrop(10,10,p=0.5),\n    albumentations.Flip(p=0.5),\n    albumentations.Cutout(p=0.5),\n    albumentations.ShiftScaleRotate(p=0.5),  #default rotations is 45degree + shift height and width with the limit amount of 0.0625\n    albumentations.OneOf([\n    albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=1),\n   # albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    #albumentations.RGBShift(p=0.5),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        preprocess_input=None)\n        \nvalid_datagen = ImageDataAugmentor(rescale=1./255)\n\n#train_generator = train_datagen.flow_from_dataframe(train_data,\n#                                                x_col='image',\n#                                                y_col='target',\n#                                                target_size=(224,224),\n#                                                batch_size=32,\n #                                               shuffle=True,\n  #                                              class_mode='raw')\n        \n#validation_generator = valid_datagen.flow_from_dataframe(val_data,\n #                                               x_col='image',\n  #                                              y_col='target',\n   #                                             target_size=(224,224),\n    #                                            batch_size=32,\n     #                                           shuffle=True,\n      #                                          class_mode='raw')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras import backend as K\n\ndef focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        #compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nn_split = 5\ncv = StratifiedKFold(n_splits=n_split, shuffle=True, random_state=47)\nfold_count = 0\ndf_img = pd.DataFrame(train_fk,columns=['image'])\nprint(type(labels))\ndf_labels = pd.DataFrame(labels,columns=['target'])\ntrain_data = pd.concat([df_img, df_labels], axis = 1) \ntarget = train_data[['target']]\n#print(np.shape(target))\nfor train_idx, val_idx in cv.split(df_img, target ):\n    fold_count += 1\n    print(\"this is the fold number \",fold_count)\n    training_data = train_data.iloc[train_idx]\n    validation_data = train_data.iloc[val_idx]\n    print(\"tr= \",training_data.shape[0])\n    print(\"val= \",validation_data.shape[0])\n  \n\n    train_generator = train_datagen.flow_from_dataframe(training_data,\n                                                        directory=DIR,\n                                                        x_col='image',\n                                                        y_col='target',\n                                                        target_size=(300,300),\n                                                        batch_size=32,\n                                                        shuffle=True,\n                                                        class_mode='binary')\n        \n    validation_generator = valid_datagen.flow_from_dataframe(validation_data,\n                                                             directory=DIR,\n                                                             x_col='image',\n                                                             y_col='target',\n                                                            target_size=(300,300),\n                                                            batch_size=32,\n                                                            shuffle=True,\n                                                            class_mode='binary')\n\n    base_model_alb =  ResNet50V2(include_top=False, weights='imagenet',input_shape=(300,300 , 3))\n  \n    n_layers = len(base_model_alb.layers)\n    for layer in base_model_alb.layers[:n_layers - 15]: #freezing some layers\n      layer.trainable = False\n    for layer in base_model_alb.layers[n_layers - 15:]:\n      layer.trainable = True\n  \n    x = base_model_alb.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    out = Dense(256, activation='relu')(x)\n    predictions = Dense(1, activation='sigmoid')(out)\n\n    model_alb = Model(inputs=base_model_alb.input, outputs=predictions)\n\n\n    from tensorflow.keras.optimizers import Adam\n    def scheduler(epoch, lr):\n        if epoch<4:\n            return lr\n        else:\n            return lr * tf.math.exp(-0.1)\n    callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler),\n                 tf.keras.callbacks.EarlyStopping(patience=4)]\n    model_alb.compile(loss=focal_loss(),\n                  optimizer=Adam(lr=1e-5),\n                  metrics=[tf.keras.metrics.AUC()])\n\n    History = model_alb.fit(train_generator,\n                             steps_per_epoch=training_data.shape[0]//32,\n                             epochs=15,\n                             validation_data=validation_generator,\n                             validation_steps=validation_data.shape[0]//32,\n                             shuffle=False,\n                             callbacks=callbacks,\n                             class_weight=weights\n                             )\n    \n    n_layers = len(base_model_alb.layers)\n    for layer in base_model_alb.layers[:n_layers - 20]:\n        layer.trainable = False\n    for layer in base_model_alb.layers[n_layers - 20:]:\n        layer.trainable = True\n        \n    \n    def scheduler(epoch, lr):\n        if epoch<8:\n            return lr\n        else:\n            return lr * tf.math.exp(-0.1)\n    callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler),\n                 tf.keras.callbacks.EarlyStopping(patience=4)]\n    model_alb.compile(loss=focal_loss(),\n                  optimizer=Adam(lr=1e-6),\n                  metrics=[tf.keras.metrics.AUC()])\n    \n    History = model_alb.fit(train_generator,\n                             steps_per_epoch=training_data.shape[0]//32,\n                             epochs=25,\n                             validation_data=validation_generator,\n                             validation_steps=validation_data.shape[0]//32,\n                             shuffle=False,\n                             callbacks=callbacks,\n                             class_weight=weights\n                             )\n    \n    from tensorflow.keras.preprocessing import image\n    import tensorflow.keras.applications.resnet_v2 as tf_res\n    from tensorflow.keras.applications import xception\n    target=[]\n    for pat in df_test['images']:\n        img_path = str(pat)\n        img = image.load_img(img_path, target_size=(300, 300))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0) \n        y = tf_res.preprocess_input(x)\n # z = xception.preprocess_input(x)\n        prediction=model_alb.predict(y)\n        target.append(prediction[0][0]/n_split)   #give 1/5th share for predicition in each fold\n    submission['target']+=target\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}