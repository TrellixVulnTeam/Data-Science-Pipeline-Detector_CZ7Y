{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n#import tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom shutil import copyfile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONFIGURE GPUs\n#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\ngpus = tf.config.list_physical_devices('GPU'); print(gpus)\nif len(gpus)==1: strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\nelse: strategy = tf.distribute.MirroredStrategy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as display\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\ndata_dir = pathlib.Path('/kaggle/input/siim-isic-melanoma-classification/jpeg/train/')\nimage_count = len(list(data_dir.glob('*.jpg')))\nimage_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted = df.sort_values(by='target', ascending=False)\ndf_sorted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nex = list(data_dir.glob('*.jpg'))\n\n#for image_path in ex[:3]:\n    #display.display(Image.open(str(image_path)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str(ex[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a list of labels (0 - benign, 1 - cancer)\nlabels = []\nfilenames = []\ncounter = 0\nfor item in ex:\n    tmp = df.loc[df['image_name'] == item.stem,'target'].iloc[0]\n    labels.append(tmp)\n    filenames.append(str(item))\n    if tmp == 1:\n        counter+=1\ncounter        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(iter(train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to load and preprocess each image\ndef _parse_fn(filename, label):\n    img = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img)\n    img = (tf.cast(img, tf.float32)/127.5) - 1\n    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 224 # Minimum image size for use with MobileNetV2\nBATCH_SIZE = 32\ntrain_data = train_data.map(_parse_fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, label in train_data.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    #ds = ds.repeat()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds_batched = prepare_for_training(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, label in train_data.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#next(iter(train_ds_batched))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"METRICS = [\n      #tf.keras.metrics.TruePositives(name='tp'),\n      #tf.keras.metrics.FalsePositives(name='fp'),\n      #tf.keras.metrics.TrueNegatives(name='tn'),\n      #tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      #tf.keras.metrics.Precision(name='precision'),\n      #tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = {0: 1.,\n                1: 1.}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss='binary_crossentropy',\n              metrics=[tf.keras.metrics.Accuracy()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_ds_batched,\n          epochs=20,\n          class_weight=class_weight,\n          steps_per_epoch = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alt_model = Sequential()\nalt_model.add(Conv2D(32,3, activation='relu', input_shape=(224, 224 ,3)))\nalt_model.add(Dropout(0.5))\nalt_model.add(MaxPooling2D())\nalt_model.add(BatchNormalization())\nalt_model.add(Conv2D(64,3, activation='relu'))\nalt_model.add(Dropout(0.5))\nalt_model.add(MaxPooling2D())\nalt_model.add(BatchNormalization())\nalt_model.add(Conv2D(128,3,activation='relu'))\nalt_model.add(MaxPooling2D())\nalt_model.add(Flatten())\nalt_model.add(Dropout(0.5))\nalt_model.add(BatchNormalization())\nalt_model.add(Dense(512, activation='relu'))\nalt_model.add(Dense(1,activation='softmax'))\n\nalt_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nalt_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss='binary_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alt_model.fit(train_ds_batched,\n          epochs=10,\n          class_weight=class_weight,\n          steps_per_epoch = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using pretrained ImageNet\nIMAGE_SIZE = 224\nIMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n# Pre-trained model with MobileNetV2\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=IMG_SHAPE,\n    include_top=False,\n    weights='imagenet'\n)\n# Freeze the pre-trained model weights\nbase_model.trainable = True\n# Trainable classification head\nmaxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\nprediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n# Layer classification head with feature detector\nmodel_mobileNet = tf.keras.Sequential([\n    base_model,\n    maxpool_layer,\n    prediction_layer\n])\n\n\nmodel_mobileNet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0005\nmodel_mobileNet.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), \n              loss='binary_crossentropy',\n              metrics=METRICS\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mobileNet.fit(train_ds_batched,\n          epochs=5,\n          steps_per_epoch = 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Models while using GPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    #Using pretrained ImageNet\n    IMAGE_SIZE = 224\n    IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n    # Pre-trained model with MobileNetV2\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=IMG_SHAPE,\n        include_top=False,\n        weights='imagenet'\n    )\n    # Freeze the pre-trained model weights\n    base_model.trainable = True\n    # Trainable classification head\n    maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n    prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n    # Layer classification head with feature detector\n    model_mobileNet = tf.keras.Sequential([\n        base_model,\n        maxpool_layer,\n        prediction_layer\n    ])\n    \n    # Compile the model\n    model_mobileNet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel_mobileNet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mobileNet.fit(train_ds_batched,\n          epochs=5,\n          steps_per_epoch = 50)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}