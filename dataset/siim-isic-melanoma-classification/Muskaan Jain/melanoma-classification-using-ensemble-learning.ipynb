{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport json\nimport math\nimport cv2\nimport PIL\nfrom PIL import Image\nimport seaborn as sns\nsns.set(style='darkgrid')\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras import layers\nfrom keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom keras import backend as K\nimport gc\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json\nimport itertools\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-16T19:16:35.247257Z","iopub.execute_input":"2021-06-16T19:16:35.24771Z","iopub.status.idle":"2021-06-16T19:16:35.272726Z","shell.execute_reply.started":"2021-06-16T19:16:35.247625Z","shell.execute_reply":"2021-06-16T19:16:35.271818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-16T17:42:52.659651Z","iopub.execute_input":"2021-06-16T17:42:52.66009Z","iopub.status.idle":"2021-06-16T17:42:52.670103Z","shell.execute_reply.started":"2021-06-16T17:42:52.660045Z","shell.execute_reply":"2021-06-16T17:42:52.668091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see what files we have in the input directory:","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:16:39.211835Z","iopub.execute_input":"2021-06-16T19:16:39.212202Z","iopub.status.idle":"2021-06-16T19:16:39.234845Z","shell.execute_reply.started":"2021-06-16T19:16:39.212171Z","shell.execute_reply":"2021-06-16T19:16:39.233934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/siim-isic-melanoma-classification\"))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-16T19:16:41.517664Z","iopub.execute_input":"2021-06-16T19:16:41.518078Z","iopub.status.idle":"2021-06-16T19:16:41.524861Z","shell.execute_reply.started":"2021-06-16T19:16:41.518046Z","shell.execute_reply":"2021-06-16T19:16:41.52355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading Train and Test Data\ntrain = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\ntest = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\nprint(\"{} images in train set.\".format(train.shape[0]))\nprint(\"{} images in test set.\".format(test.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:16:44.094058Z","iopub.execute_input":"2021-06-16T19:16:44.094436Z","iopub.status.idle":"2021-06-16T19:16:44.169937Z","shell.execute_reply.started":"2021-06-16T19:16:44.094403Z","shell.execute_reply":"2021-06-16T19:16:44.169022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:16:47.451275Z","iopub.execute_input":"2021-06-16T19:16:47.45167Z","iopub.status.idle":"2021-06-16T19:16:47.471888Z","shell.execute_reply.started":"2021-06-16T19:16:47.451636Z","shell.execute_reply":"2021-06-16T19:16:47.470846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:16:50.967339Z","iopub.execute_input":"2021-06-16T19:16:50.967746Z","iopub.status.idle":"2021-06-16T19:16:50.987707Z","shell.execute_reply.started":"2021-06-16T19:16:50.967712Z","shell.execute_reply":"2021-06-16T19:16:50.986338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n# Plotly for the interactive viewer (see last section)\nimport plotly.graph_objs as go\nimport plotly.graph_objects as go\n\nplt.figure(figsize=(15,15))\n\nlabels=train['anatom_site_general_challenge'].value_counts().index\nvalues=train['anatom_site_general_challenge'].value_counts().values\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent',\n                             insidetextorientation='radial' )])\n#fig = px.sunburst(train, path = [labels,'sex','benign_malignant'], values = values)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:16:53.787515Z","iopub.execute_input":"2021-06-16T19:16:53.78793Z","iopub.status.idle":"2021-06-16T19:16:53.83017Z","shell.execute_reply.started":"2021-06-16T19:16:53.787898Z","shell.execute_reply":"2021-06-16T19:16:53.829265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the distribution of teh target:","metadata":{}},{"cell_type":"code","source":"np.mean(train.target)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:01.165321Z","iopub.execute_input":"2021-06-16T19:17:01.165706Z","iopub.status.idle":"2021-06-16T19:17:01.174271Z","shell.execute_reply.started":"2021-06-16T19:17:01.165674Z","shell.execute_reply":"2021-06-16T19:17:01.172934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So this is a binary classification problem with highly imbalanced data.","metadata":{}},{"cell_type":"markdown","source":"Let's take a look at a few images.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='target', data=train,\n                   order=list(train['target'].value_counts().sort_index().index) ,\n                   color='cyan')","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:04.024223Z","iopub.execute_input":"2021-06-16T19:17:04.024658Z","iopub.status.idle":"2021-06-16T19:17:04.203754Z","shell.execute_reply.started":"2021-06-16T19:17:04.024625Z","shell.execute_reply":"2021-06-16T19:17:04.20261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:07.596559Z","iopub.execute_input":"2021-06-16T19:17:07.596977Z","iopub.status.idle":"2021-06-16T19:17:07.60956Z","shell.execute_reply.started":"2021-06-16T19:17:07.596945Z","shell.execute_reply":"2021-06-16T19:17:07.608041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:10.146852Z","iopub.execute_input":"2021-06-16T19:17:10.147236Z","iopub.status.idle":"2021-06-16T19:17:10.157764Z","shell.execute_reply.started":"2021-06-16T19:17:10.147203Z","shell.execute_reply":"2021-06-16T19:17:10.156055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Target vs Sex Distribution**","metadata":{}},{"cell_type":"code","source":"z=train.groupby(['target','sex'])['benign_malignant'].count().to_frame().reset_index()\nz.style.background_gradient(cmap='Reds')  ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:12.867133Z","iopub.execute_input":"2021-06-16T19:17:12.867505Z","iopub.status.idle":"2021-06-16T19:17:12.903362Z","shell.execute_reply.started":"2021-06-16T19:17:12.867474Z","shell.execute_reply":"2021-06-16T19:17:12.901827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will load some of the resized images (32x32 for now) and try to build some simple models. ","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='target',y='benign_malignant', hue='sex',data=z,kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:16.465081Z","iopub.execute_input":"2021-06-16T19:17:16.466006Z","iopub.status.idle":"2021-06-16T19:17:17.103181Z","shell.execute_reply.started":"2021-06-16T19:17:16.46596Z","shell.execute_reply":"2021-06-16T19:17:17.102093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**VISUALISING IMAGE DATA : JPEG**","metadata":{}},{"cell_type":"code","source":"images= train['image_name'].values\n\n#extract 9 random images\nimport random\nrandom_images = [np.random.choice(images + '.jpg') for i in range(9)]\n\n#location of image dir \nimage_dir = '../input/siim-isic-melanoma-classification/jpeg/train'\n\nprint('Display random images')\n\n#iterate and plot images\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(image_dir, random_images[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()   ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:20.485885Z","iopub.execute_input":"2021-06-16T19:17:20.486442Z","iopub.status.idle":"2021-06-16T19:17:37.125278Z","shell.execute_reply.started":"2021-06-16T19:17:20.486408Z","shell.execute_reply":"2021-06-16T19:17:37.123941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benign = train[train['benign_malignant']=='benign']\nmalignant = train[train['benign_malignant']=='malignant']","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:37.128252Z","iopub.execute_input":"2021-06-16T19:17:37.128687Z","iopub.status.idle":"2021-06-16T19:17:37.151383Z","shell.execute_reply.started":"2021-06-16T19:17:37.128644Z","shell.execute_reply":"2021-06-16T19:17:37.150165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images= benign['image_name'].values\n\n#extract 9 random images\nimport random\nrandom_images = [np.random.choice(images + '.jpg') for i in range(9)]\n\n#location of image dir \nimage_dir = '../input/siim-isic-melanoma-classification/jpeg/train'\n\nprint('Display Benign images')\n\n#iterate and plot images\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(image_dir, random_images[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()   ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:37.153148Z","iopub.execute_input":"2021-06-16T19:17:37.153788Z","iopub.status.idle":"2021-06-16T19:17:49.620914Z","shell.execute_reply.started":"2021-06-16T19:17:37.153739Z","shell.execute_reply":"2021-06-16T19:17:49.619742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images= malignant['image_name'].values\n\n#extract 9 random images\nimport random\nrandom_images = [np.random.choice(images + '.jpg') for i in range(9)]\n\n#location of image dir \nimage_dir = '../input/siim-isic-melanoma-classification/jpeg/train'\n\nprint('Display Malignant images')\n\n#iterate and plot images\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(image_dir, random_images[i]))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout() ","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:17:49.623706Z","iopub.execute_input":"2021-06-16T19:17:49.624196Z","iopub.status.idle":"2021-06-16T19:17:58.772874Z","shell.execute_reply.started":"2021-06-16T19:17:49.624149Z","shell.execute_reply":"2021-06-16T19:17:58.769283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Backgrounf Extraction of Images","metadata":{}},{"cell_type":"code","source":"folder = '../input/siim-isic-melanoma-classification/jpeg/train'\nplt.figure(figsize=(20,20))\n\nfor i in range(5):\n    file = random.choice(os.listdir(folder))\n    image_path= os.path.join(folder, file)\n    main_img = plt.imread(image_path)\n    img = cv2.cvtColor(main_img, cv2.COLOR_BGR2RGB) \n\n    #segmentation using k-means clustering\n    vectorized = img.reshape((-1,3))\n    vectorized = np.float32(vectorized)\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n    K = 8\n    attempts=10\n    ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n    center = np.uint8(center)\n    res = center[label.flatten()]\n    seg_img = res.reshape((img.shape))\n\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(seg_img, cmap=\"Greys_r\")","metadata":{"execution":{"iopub.status.busy":"2021-06-16T19:53:01.786478Z","iopub.execute_input":"2021-06-16T19:53:01.787049Z","iopub.status.idle":"2021-06-16T20:01:26.682457Z","shell.execute_reply.started":"2021-06-16T19:53:01.787005Z","shell.execute_reply":"2021-06-16T20:01:26.681267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Convolution2D,Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import SGD\nfrom keras.callbacks import TensorBoard\nfrom keras import applications","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TRAINING**","metadata":{}},{"cell_type":"code","source":"import time ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start=time.time()\ntrain_images = np.load('../input/siimisic-melanoma-resized-images/x_train_96.npy')\nend=time.time()\nprint(f\"\\nTime to load train images: {round(end-start,5)} seconds.\")\nprint('Train_images shape: ',train_images.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start=time.time()\ntest_images = np.load('../input/siimisic-melanoma-resized-images/x_test_96.npy')\nend=time.time()\nprint(f\"\\nTime to load test images: {round(end-start,5)} seconds.\")\nprint('Test_images shape: ',test_images.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target data\ntrain_labels =np.array(train.drop(['image_name', 'patient_id', 'sex', 'age_approx',\n       'anatom_site_general_challenge', 'diagnosis','benign_malignant'],axis=1))\nprint('Train_labels shape: ',train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#spliting train data\nfrom sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(train_images,train_labels,test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('x_train shape: ',x_train.shape)\nprint('x_val shape: ',x_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA AUGMENTATION**","metadata":{}},{"cell_type":"code","source":"augs = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True)\n\naugs.fit(x_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MODELLING**","metadata":{}},{"cell_type":"code","source":"#annealer = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#strategy = tf.distribute.get_strategy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG-16 MODEL NO. 1\n'''\nfrom keras.applications.vgg16 import VGG16\n\ninput_shape=(96,96,3)\nnum_classes=1\ntmodel_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n    \nmodel = Sequential()\nmodel.add(tmodel_base)\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.50))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='sigmoid', name='output_layer'))\nmodel.summary()\n\nmodel.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XCEPTION MODEL NO. 2\n'''\nfrom keras.layers import Dropout, DepthwiseConv2D, MaxPooling2D, concatenate\nfrom keras.models import Model\n\ninp = Input(shape = (96,96, 3))\nx = inp\nx = Conv2D(32, (3, 3), strides = 2, padding = \"same\", activation = \"relu\")(x)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx = Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\n\nx1 = DepthwiseConv2D((3, 3), (1, 1), padding = \"same\", activation = \"relu\")(x)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx1 = DepthwiseConv2D((3, 3), (1, 1), padding = \"same\", activation = \"relu\")(x1)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx1 = MaxPooling2D((2, 2), strides = 1)(x1)\n\nx = concatenate([x1, Conv2D(64, (2, 2), strides = 1)(x)])\n\nx1 = Activation(\"relu\")(x)\nx1 = Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x1)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx1 = DepthwiseConv2D((3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x1)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx1 = DepthwiseConv2D((3, 3), strides = 1, padding = \"same\")(x1)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx1 = MaxPooling2D((2, 2), strides = 1)(x1)\n\nx = concatenate([x1, Conv2D(256, (2, 2), strides = 1)(x)])\n\n\nx = Activation(\"relu\")(x)\nx = Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx = Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\nx = BatchNormalization(axis = 3)(x)\nx = Dropout(0.4)(x)\nx = Flatten()(x)\n\nx = Dense(1, activation = \"sigmoid\")(x)\n\n\nmodel2 = Model(inp, x)\nmodel2.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nmodel2.summary()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DENSENET MODEL NO. 3\n'''\nfrom tensorflow.keras.applications import DenseNet201\nimport tensorflow.keras.layers as L\n\nwith strategy.scope():\n    dnet201 = DenseNet201(\n        input_shape=(96,96, 3),\n        weights='imagenet',\n        include_top=False\n    )\n    dnet201.trainable = True\n\n    model3 = tf.keras.Sequential([\n        dnet201,\n        L.GlobalAveragePooling2D(),\n        L.Dense(1, activation='sigmoid')\n    ])\n    model3.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        metrics=['accuracy']\n    )\n\nmodel3.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nbatch_size=128\nepochs=30\n\nhistory = model.fit(x_train,\n             y_train,\n             batch_size=batch_size,\n             nb_epoch=epochs,\n             verbose=1,\n             validation_data=(x_val,y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nbatch_size=128\nepochs=15\n\nhistory3 = model2.fit(x_train,\n             y_train,\n             batch_size=batch_size,\n             nb_epoch=epochs,\n             verbose=1,\n             validation_data=(x_val,y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nbatch_size=128\nepochs=30\n\nhistory3 = model3.fit(x_train,\n             y_train, \n             batch_size=batch_size,\n             nb_epoch=epochs,\n             verbose=1,\n             validation_data=(x_val,y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nmodel.save(\"vgg16.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nmodel2.save(\"xception.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nmodel3.save(\"densenet.h5\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"IMPROVING MODEL ","metadata":{}},{"cell_type":"code","source":"model = load(vgg116.h5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EVALUATION**","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(x_val, y_val, verbose=0)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model2.evaluate(x_val, y_val, verbose=0)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model3.evaluate(x_val, y_val, verbose=0)\nprint('Test loss_3:', scores[0])\nprint('Test accuracy_3:', scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PREDICTION**","metadata":{}},{"cell_type":"code","source":"y_test_prob = model.predict(test_images)\npred_df = pd.DataFrame({'image_name': test['image_name'], 'target': np.concatenate(y_test_prob)})\npred_df.to_csv('submission_vgg.csv',header=True, index=False)\npred_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_prob2 = model2.predict(test_images)\npred_df2 = pd.DataFrame({'image_name': test['image_name'], 'target': np.concatenate(y_test_prob2)})\npred_df2.to_csv('submission_xception.csv',header=True, index=False)\npred_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_prob3 = model3.predict(test_images)\npred_df3 = pd.DataFrame({'image_name': test['image_name'], 'target': np.concatenate(y_test_prob3)})\npred_df3.to_csv('submission_dense.csv',header=True, index=False)\npred_df3.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ENSEMBLE**","metadata":{}},{"cell_type":"code","source":"en = pd.DataFrame({'image_name':test['image_name'], 'target':(0.3*pred_df['target'] + 0.3*pred_df2['target'] + 0.3*pred_df3['target'])})\nen.to_csv('ensemble1.csv',header=True, index=False)\nen.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}