{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = '../input/siim-isic-melanoma-classification'\n#list of images with hair\nhair_images =['ISIC_0078712','ISIC_0080817','ISIC_0082348','ISIC_0109869','ISIC_0155012','ISIC_0159568','ISIC_0164145','ISIC_0194550','ISIC_0194914','ISIC_0202023','ISIC_0083035','ISIC_0068279','ISIC_0109703','ISIC_0149527']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# viewing the images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"size=1024\nfor img in hair_images:\n    image = cv2.imread(BASE_PATH + '/jpeg/train/' + img + '.jpg')\n    image_resize = cv2.resize(image,(size,size))\n    image_resize = cv2.cvtColor(image_resize,cv2.COLOR_BGR2RGB)\n    plt.imshow(image_resize)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting hair masks from images","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Experiment with `lower_limit` to get hair with removed noise\n* Note that `lower_limit` is the sensitivity of the threshold of obtaining the mask.. too low value can lead to addition of noise and too high value can lead to loss of info of hair","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_limit = 20# the value that I found helpful\n\n#*********#*********PROCEDURE*********#*********#*********#\n###################################\ngrayScale = cv2.cvtColor(image_resize, cv2.COLOR_RGB2GRAY)\n\n# Kernel for the morphological filtering\nkernel = cv2.getStructuringElement(1,(17,17))\n\n# Perform the blackHat filtering on the grayscale image to find the hair countours\nblackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n\n# intensify the hair countours  \n_ ,threshold = cv2.threshold(blackhat,20,255,cv2.THRESH_BINARY)\n#######################################\nthreshold = cv2.bitwise_not(threshold)\nplt.imshow(threshold,cmap = 'gray')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img(image_name,lower_limit=20):    \n    '''\n    Helper Function to help us iterate with our code!!   \n    \n    \n    '''\n\n    image = cv2.imread(BASE_PATH + '/jpeg/train/' + image_name + '.jpg')\n    image_resize = cv2.resize(image,(size,size))\n   \n    grayScale = cv2.cvtColor(image_resize, cv2.COLOR_RGB2GRAY)\n\n    # Kernel for the morphological filtering\n    kernel = cv2.getStructuringElement(1,(17,17))\n\n    # Perform the blackHat filtering on the grayscale image to find the hair countours\n    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n\n    # intensify the hair countours in preparation for the inpainting \n    _ ,threshold = cv2.threshold(blackhat,lower_limit,255,cv2.THRESH_BINARY)\n    \n    # inpaint the original image depending on the mask\n    final_image = cv2.inpaint(image_resize,threshold,1,cv2.INPAINT_TELEA)\n    \n    threshold = cv2.bitwise_not(threshold)\n    image_resize = cv2.cvtColor(image_resize,cv2.COLOR_BGR2RGB)\n    final_image = cv2.cvtColor(final_image,cv2.COLOR_BGR2RGB)\n    \n    return image_resize,threshold,final_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## STEP 1) getting the first image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_1,_,_ = img(hair_images[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('The second image')\nplt.imshow(image_1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## STEP 2) getting the second image and it's hair mask","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_2,hair_mask_2,_ = img(hair_images[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('The second image')\nplt.imshow(image_2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('The hair mask of the second image')\nplt.imshow(hair_mask_2,cmap = 'binary_r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## STEP 3) applying the hair mask of image 2 one on image 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('image 1 after the hair mask of the secong image on it')\nplt.imshow(cv2.bitwise_and(image_1,image_1,mask = hair_mask_2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### looks good to me!!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Let's look for the best quality hair(s) for later use","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,img_name in enumerate(hair_images) :\n    _,hair_mask,_ = img(img_name)\n    plt.title(f'{i},{img_name}')\n    plt.imshow(cv2.bitwise_and(image_1,image_1,mask = hair_mask))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### selecting the possible candidates for hairs that can be used for our images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"possible_cands = [0,1,3,4,6,9,13]# possible candidates ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_hair_masks = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,img_id in enumerate(possible_cands):\n    _,hair_masks,_ = img(hair_images[img_id])\n    all_hair_masks.append(hair_masks) \n    cv2.imwrite(f'image_{i}.jpg',hair_masks)\n    print(len(all_hair_masks))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_hair_masks = np.array(all_hair_masks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Note: We save the hairs as an array as there is often loss of info with images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('hair_array.npy',all_hair_masks.astype(np.uint8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How to use them??","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1) in your kernel click on '+Add data'\n\n2) Click on 'Kernel Output Files'\n\n3) Search for \"Really Realistic Hair Augmentations\"\n\n4) If you see my kernel, add it\n\n5) then do the following :--","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as albu\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the hairs\nhairs = np.load('../input/really-realistic-hair-augmentations/hair_array.npy')\n#the random transformations we want to apply on the masks\nhair_trans = albu.Compose([\n    albu.ShiftScaleRotate(rotate_limit=[-45,45],scale_limit=[-0.1,0.1],\n                          shift_limit=[-0.1,0.15],border_mode=3,value=0,p=1.)])\n\n#our augmenter\nfrom numpy.random import choice\ndef hair_mask(hairs,IMAGE_SIZE,p = 0.3):\n    chance = np.random.uniform(0,1,1)\n    if chance <= p:\n        mask_to_chose = choice(np.arange(7), 1,p=[0.2,0.2,0.22,0.15,0.14,0.06,0.03])[0]\n        mask = hairs[mask_to_chose]\n        \n        mask = hair_trans(image = mask)['image']\n        mask = cv2.resize(mask/255,(IMAGE_SIZE,IMAGE_SIZE),cv2.INTER_CUBIC)\n        mask[mask == 1.] =  255\n        mask[mask != 255.] = 0\n        \n        \n    else:\n        mask = np.ones((IMAGE_SIZE,IMAGE_SIZE))\n    return mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"changes every time when run if blank then don't worry!!(only when you change the prob!!)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"msk = hair_mask(hairs,IMAGE_SIZE=256,p=1.).astype(np.uint8)\nplt.imshow(msk,cmap = 'binary_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread('../input/siim-isic-melanoma-classification/jpeg/train/ISIC_0015719.jpg')\nimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nimg = cv2.resize(img,(256,256))\n\nplt.imshow(cv2.bitwise_and(img,img,mask= msk))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### and use it in your data loader!!\n## Example\njust find the place where i implemented it!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, filelist_x, targets, batch_size=128, shuffle=False, augment=False, labels=True): \n\n        self.filelist_x = filelist_x\n        self.targets = targets\n        self.augment = augment\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.labels = labels\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.filelist_x) // self.batch_size\n        ct += int((len(self.filelist_x) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self,index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        if self.augment: X = self.__augment_batch(X)\n        if self.labels: return X, y\n        else: return X\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange( len(self.filelist_x) )\n        if self.shuffle: np.random.shuffle(self.indexes)\n\n    def __data_generation(self,indexes):\n        'Generates data containing batch_size samples'   \n\n        X = np.array([lycon.load(self.filelist_x[indexes][i]) for i in range(len(indexes))])\n        y = self.targets[indexes]\n        \n        return X, y\n \n    def __random_transform(self, img):\n        composition = albu.Compose([\n            albu.OneOf([\n                albu.ShiftScaleRotate(rotate_limit=[-90,90],scale_limit=[-0.42,0.35],shift_limit=0,border_mode=0,value=0,p=0.5),\n                albu.CoarseDropout(max_holes=16,max_height=200//10,max_width=200//10,fill_value=0,p=0.5)\n            ], p=0.5),\n            albu.ShiftScaleRotate(rotate_limit=0, scale_limit=0., shift_limit=0.15, border_mode=0, value=0, p=0.5)\n        ])\n        image = composition(image=img)['image']\n        ##############################################################}\n        mask =  hair_mask(hairs,IMAGE_SIZE,p = 0.3).astype(np.uint8)##} This area!!\n        image = cv2.bitwise_and(image,image,mask = mask)##############}\n        ##############################################################}\n        return image\n    \n    def __augment_batch(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i, ] = self.__random_transform(img_batch[i, ])\n        return img_batch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Enjoy!!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}