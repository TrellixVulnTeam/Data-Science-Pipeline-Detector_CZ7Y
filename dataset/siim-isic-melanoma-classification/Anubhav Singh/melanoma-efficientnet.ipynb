{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom efficientnet.tfkeras import *\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.utils import Sequence,to_categorical\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.regularizers import l1\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.metrics import AUC\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import shuffle\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom tensorflow.keras.utils import plot_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Set Path and Read DataFrames**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_images_path='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\ntest_images_path='/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\ntrain_df=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\nsample_sub=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Data Shape: {}'.format(train_df.shape))\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nprint('Running on TPU ', tpu.master())\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcs_path = KaggleDatasets().get_gcs_path()\ndef format_train_path(st):\n    return gcs_path + '/jpeg/train/' + st + '.jpg'\n\ndef format_test_path(st):\n    return gcs_path + '/jpeg/test/' + st + '.jpg'\n\ntrain_data,val_data=train_test_split(train_df,test_size=0.1)\ntrain_paths = train_data.image_name.apply(format_train_path).values\nval_paths = val_data.image_name.apply(format_train_path).values\n\ntrain_labels = train_data['target'].values\nval_labels = val_data['target'].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIMS=(256,256,3)\nEPOCHS=8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename,label=None,image_size=(DIMS[0],DIMS[1])):\n    bits=tf.io.read_file(filename)\n    img=tf.image.decode_jpeg(bits,channels=3)\n    img=tf.cast(img,tf.float32)/255.0\n    img=tf.image.central_crop(img,0.3)\n    img=tf.image.resize(img,image_size)\n    if label is None:\n        return img\n    else:\n        return img, label\n    \ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.rot90(image)\n    if label is None:\n        return image\n    else:\n        return image, label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset=(tf.data.Dataset.from_tensor_slices((train_paths,train_labels)).map(decode_image,num_parallel_calls=AUTO)\n               .map(data_augment,num_parallel_calls=AUTO).repeat()\n              .shuffle(13)\n              .batch(BATCH_SIZE).prefetch(AUTO))\n\nval_dataset=(tf.data.Dataset.from_tensor_slices((val_paths,val_labels))\n             .map(decode_image,num_parallel_calls=AUTO)\n             .shuffle(13)\n             .batch(BATCH_SIZE)\n             .cache()\n             .prefetch(AUTO))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    inp=Input(DIMS)\n    x=EfficientNetB7(include_top=False,input_tensor=inp)\n    gap=SeparableConv2D(2048,2,activation='relu',padding='same')(x.output)\n    \n    x_0=Conv2D(512,(1,1),1,padding='same')(x.output)\n    x_0=BatchNormalization()(x_0)\n    x_0=Activation('relu')(x_0)\n    \n    x_1=Conv2D(512,(2,2),1,padding='same')(x.output)\n    x_1=BatchNormalization()(x_1)\n    x_1=Activation('relu')(x_1)\n    \n    x_2=Conv2D(512,(3,3),1,padding='same')(x.output)\n    x_2=BatchNormalization()(x_2)\n    x_2=Activation('relu')(x_2)\n    \n    x=Concatenate()([x_0,x_1,x_2,gap])\n    x=Conv2D(2000,(2,2),strides=2,padding='same')(x)\n    x=BatchNormalization()(x)\n    x=Activation('relu')(x)\n    x=GlobalAveragePooling2D()(x)\n    \n    out=Dense(1,activation='sigmoid')(x)    \n    model=Model(inp,out) \n        \n    model.compile(\n        optimizer=Adam(0.001),\n        loss = 'binary_crossentropy' ,\n        metrics=[AUC()]\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = len(train_labels) // BATCH_SIZE\nmc=ModelCheckpoint('classifier.h5',monitor='val_loss',save_best_only=True,verbose=1,period=1)\nrop=ReduceLROnPlateau(monitor='val_loss',min_lr=0.0000001,patience=2,mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_dataset,epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,\n                  validation_data=val_dataset,\n                 callbacks=[mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(metrics,name=['loss','AUC']):\n    epochs = range(1, len(metrics[0]) + 1)\n    plt.plot(epochs, metrics[0], 'b',color='red', label='Training '+name[0])\n    plt.plot(epochs, metrics[1], 'b',color='blue', label='Validation '+name[0])\n    plt.title('Metric Plot')\n    plt.legend()\n    plt.figure()\n    plt.plot(epochs, metrics[2], 'b', color='red', label='Training '+name[1])\n    plt.plot(epochs, metrics[3], 'b',color='blue', label='Validation '+name[1])\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics([history.history['loss'],history.history['val_loss'],\n              history.history['auc'],history.history['val_auc']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_paths = sample_sub.image_name.apply(format_test_path).values\ntest_dataset=(tf.data.Dataset.from_tensor_slices(test_paths)\n             .map(decode_image,num_parallel_calls=AUTO)\n             .batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=load_model('classifier.h5')\npreds=model.predict(test_dataset,verbose=1)\nsample_sub['target'] = preds\nsample_sub.to_csv('submission.csv', index=False)\nsample_sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}