{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tqdm import tqdm\n\n# PyTorch libraries and modules\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, BCELoss\nfrom torch.optim import Adam, SGD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\ntest  = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\ntest_path = '../input/siim-isic-melanoma-classification/jpeg/test/'\ntrain_path = '../input/siim-isic-melanoma-classification/jpeg/train/'\nsample_submission = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading training images\n\n#train_img = []\n#for img_name in tqdm(train['image_name']):\n    # defining the image path\n   # image_path = train_path + str(img_name) + '.jpg'\n    # reading the image\n  #  img = imread(image_path, as_gray=True)\n    # normalizing the pixel values\n  #  img /= 255.0\n    # converting the type of pixel to float 32\n  #  img = img.astype('float32')\n    # appending the image into the list\n #   train_img.append(img)\n\n# converting the list to numpy array\n#train_x = np.array(train_img)\n\n# defining the target\ntrain_y = train['target'].values\ntrain_x = np.load((\"../input/x-train/x_train_32.npy\"))\ntrain_x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing images\n\ni = 0\n\nplt.figure(figsize=(10,10))\nplt.subplot(221), plt.imshow(train_x[i])\nplt.subplot(222), plt.imshow(train_x[i+25])\nplt.subplot(223), plt.imshow(train_x[i+50])\nplt.subplot(224), plt.imshow(train_x[i+75])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create validation set\n\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2)\n(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_x.reshape(26500, 3, 32, 32)\ntrain_x  = torch.from_numpy(train_x)\n\n# converting the target into torch format\ntrain_y = train_y.astype(int);\ntrain_y = torch.from_numpy(train_y)\n\n# shape of training data\ntrain_x.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_x = val_x.reshape(6626, 3, 32, 32)\n\nval_x  = torch.from_numpy(val_x)\n\n# converting the target into torch format\nval_y = val_y.astype(int);\nval_y = torch.from_numpy(val_y)\n\n# shape of validation data\nval_x.shape, val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Setting the seed\n\nnp.random.seed(42)\ntorch.manual_seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic CNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n \n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 4)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        self.adapt = nn.AdaptiveMaxPool2d((5,7))\n        self.fc1 = nn.Linear(16*5*7, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Sequential(nn.Linear(84, 2))\n                \n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x.float())), (2, 2))\n        x = self.adapt(F.relu(self.conv2(x.float())))\n        x = x.view(-1, 16*5*7)\n        x = F.relu(self.fc1(x.float()))\n        x = F.relu(self.fc2(x.float()))\n        x = self.fc3(x.float())\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting Optimizer and loss criterion","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net()\n# defining the optimizer\noptimizer = Adam(model.parameters(), lr=0.07)\n# defining the loss function\ncriterion = CrossEntropyLoss() # nn.BCEWithLogitsLoss()\n# checking if GPU is available\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epoch):\n    model.train()\n    tr_loss = 0\n    \n    # getting the training set\n    x_train, y_train = Variable(train_x), Variable(train_y)\n    \n    # getting the validation set\n    x_val, y_val = Variable(val_x), Variable(val_y)\n    \n    # converting the data into GPU format\n    if torch.cuda.is_available():\n        x_train = x_train.cuda()\n        y_train = y_train.cuda()\n        x_val = x_val.cuda()\n        y_val = y_val.cuda()\n\n    # clearing the Gradients of the model parameters\n    optimizer.zero_grad()\n    \n    output_train = model(x_train)\n    output_val = model(x_val)\n\n    # computing the training and validation loss\n    \n    loss_train = criterion(output_train, y_train)\n    loss_val = criterion(output_val, y_val)\n    train_losses.append(loss_train)\n    val_losses.append(loss_val)\n\n    # computing the updated weights of all the model parameters\n    \n    loss_train.backward()\n    optimizer.step()\n    tr_loss = loss_train.item()\n    if epoch%2 == 0:\n        # printing the validation loss\n        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining the number of epochs\n\nn_epochs = 11\n# empty list to store training losses\ntrain_losses = []\n# empty list to store validation losses\nval_losses = []\n# training the model\n#for epoch in range(n_epochs):\n #   train(epoch)\n    \n# plotting the training and validation loss\n\n#plt.plot(train_losses, label='Training loss')\n#plt.plot(val_losses, label='Validation loss')\n#plt.legend()\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#with torch.no_grad():\noutput = model(train_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.detach().numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on training set\nprint(accuracy_score(train_y, predictions))\nprint(roc_auc_score(train_y, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output = model(val_x)\n\nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.detach().numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on validation set\nprint(accuracy_score(val_y, predictions))\nprint(roc_auc_score(val_y, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reshaping test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading test images\n\ntest_img = []\n\n#for img_name in tqdm(test['image_name']):\n    # defining the image path\n #   image_path = test_path + str(img_name) + '.jpg'\n    # reading the image\n  #  img = imread(image_path, as_gray=True)\n    # normalizing the pixel values\n   # img /= 255.0\n    # converting the type of pixel to float 32\n    #img = img.astype('float32')\n    # appending the image into the list\n    #test_img.append(img)\n\n# converting the list to numpy array\n#test_x = np.array(test_img)\n\ntest_x = np.load((\"../input/x-test-32/x_test_32.npy\"))\ntest_x.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Same preprocessing as train set ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting test images into torch format\n\ntest_x = test_x.reshape(10982, 3, 32, 32)\ntest_x  = torch.from_numpy(test_x)\ntest_x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generating predictions for test set\n\noutput = model(test_x)\n\n#softmax = torch.exp(output).cpu()\n#prob = list(softmax.detach().numpy())\n#predictions = np.argmax(prob, axis=1)\n\npreds = F.softmax(output)\npreds = preds[:, 0]\npreds = preds.detach().numpy()\nsample_submission['target'] = preds\nsample_submission.to_csv('sub_05.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}