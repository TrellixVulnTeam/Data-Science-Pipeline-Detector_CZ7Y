{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install efficientnet\nimport efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport gc\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport albumentations\n\n\nfrom random import randint\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tqdm import tqdm\n%matplotlib inline\n\nprint(tf.__version__)\nprint(tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('siic-isic-224x224-images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'gs://kds-e1fe477ff4c67fa3f8291e0d9e4c96250efeec91c8d836b1e932f0cd'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create folds\ndf = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\ndf[\"kfold\"] = -1    \ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n\ndf.to_csv(\"train_folds.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_emodel():\n     with strategy.scope():\n        en =efn.EfficientNetB3(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n        en.trainable = True\n\n        model = tf.keras.Sequential([\n            en,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n        opt = Adam(learning_rate=1e-4)\n        model.compile(optimizer = opt,\n            loss = 'binary_crossentropy',\n            metrics=['accuracy']\n        )\n        return model\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE= 64 * strategy.num_replicas_in_sync\nimg_size = 224\nEPOCHS = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augment(image, label):    \n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_png(bits, channels=3)\n    image = tf.cast(image, tf.float32) /255\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cv2_func(image, label):\n    print(label)\n    image = np.array(image,dtype= np.int64)    \n    image = train_aug(image=image)['image']\n    image = tf.cast(image, tf.float32)\n    return image\n\ndef tf_cv2_func(image, label):\n    print(type(label))\n    [image] = tf.py_function(cv2_func, [image,label], [tf.float32])\n    print(image.shape)\n    return image, label\n\n\n\n# train_dataset = (\n# tf.data.Dataset\n# .from_tensor_slices((train_images, train_targets))\n# .map(decode_image, num_parallel_calls=AUTO) \n# .map(tf_cv2_func, num_parallel_calls=AUTO) \n# .repeat()\n# .cache()\n# .shuffle(512)\n# .batch(BATCH_SIZE)\n# .prefetch(AUTO)\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training_data_path = f\"{GCS_DS_PATH}/train/\"\n# df = pd.read_csv(\"/kaggle/working/train_folds.csv\")\n\n# epochs = 5\n# train_bs = 32* strategy.num_replicas_in_sync\n# valid_bs = 32\n# fold = 0\n\n# df_train = df[df.kfold != fold].reset_index(drop=True)\n\n\n# mean = (0.485, 0.456, 0.406)\n# std = (0.229, 0.224, 0.225)\n# train_aug = albumentations.Compose(\n#     [\n# #         albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n#         albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n#         albumentations.Flip(p=0.5)\n#     ]\n# )\n\n\n\n# train_images = df_train.image_name.values.tolist()\n# train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n# train_targets = df_train.target.values\n\n# train_dataset = (\n# tf.data.Dataset\n# .from_tensor_slices((train_images, train_targets))\n# .map(decode_image, num_parallel_calls=AUTO)    \n# .map(tf_cv2_func , num_parallel_calls =AUTO) \n# .repeat()\n# .cache()\n# .shuffle(512)\n# .batch(BATCH_SIZE)\n# .prefetch(AUTO)\n# )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# test_batch = iter(train_dataset)\n# image , label = next(test_batch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train():\n    training_data_path = f\"{GCS_DS_PATH}/train/\"\n    df = pd.read_csv(\"/kaggle/working/train_folds.csv\")\n    \n    epochs = 5\n    train_bs = 32* strategy.num_replicas_in_sync\n    valid_bs = 32\n    fold = 0\n\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n    model = get_emodel()\n\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n    train_aug = albumentations.Compose(\n        [\n#             albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n            albumentations.Flip(p=0.5)\n        ]\n    )\n\n    valid_aug = albumentations.Compose(\n        [\n#             albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n        ]\n    )\n\n    train_images = df_train.image_name.values.tolist()\n    train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n    train_targets = df_train.target.values\n\n    valid_images = df_valid.image_name.values.tolist()\n    valid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\n    valid_targets = df_valid.target.values\n\n    \n    train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_images, train_targets))\n    .map(decode_image, num_parallel_calls=AUTO)    \n    .map(data_augment, num_parallel_calls=AUTO) \n#     .map(tf_cv2_func, num_parallel_calls=AUTO) \n    .repeat()\n    .cache()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n    )\n\n    valid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_images, valid_targets))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n    )\n\n    Checkpoint=tf.keras.callbacks.ModelCheckpoint(f\"Enet_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True,\n       save_weights_only=True,mode='max')\n    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss', patience=3, verbose=0, mode='auto'\n    )\n    train_history1 = model.fit(\n            train_dataset, \n            validation_data = valid_dataset, \n            steps_per_epoch=train_targets.shape[0] // BATCH_SIZE,            \n            validation_steps=valid_targets.shape[0] // BATCH_SIZE,            \n            callbacks=[lr_callback, Checkpoint],\n            epochs=EPOCHS,\n            verbose=1\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}