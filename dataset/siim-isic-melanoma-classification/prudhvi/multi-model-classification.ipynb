{"cells":[{"metadata":{"id":"nXybux4hCJ0i"},"cell_type":"markdown","source":"**Imports**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"GYTKkHmnCJ0j","outputId":"25d08368-e881-433d-e69a-c962375eba57"},"cell_type":"code","source":"import re\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\nprint(tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\nGCS_PATH=KaggleDatasets().get_gcs_path('512x512-melanoma-tfrecords-70k-images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hardware Detection**","execution_count":null},{"metadata":{"trusted":true,"id":"XxLbBIKUCJ0s","outputId":"04f54748-ad31-4537-b7ef-e3e1a5a7602d"},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set.\n    # On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"id":"8tk5SmMcCJ0z"},"cell_type":"markdown","source":"**Hyper parameters**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nIMAGE_SIZE = [512,512]\n\nLR = 0.00004\n\nEPOCHS = 25\n\nWARMUP = 5\n\nWEIGHT_DECAY = 0\n\nLABEL_SMOOTHING = 0.05\n\nTTA = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Splitting**","execution_count":null},{"metadata":{"trusted":true,"id":"TpIoE0gPCJ06"},"cell_type":"code","source":"def seed_everything(SEED):\n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n\nseed_everything(SEED)\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH+'/train*')\n\nTRAINING_FILENAMES,VALIDATION_FILENAMES=train_test_split(TRAINING_FILENAMES,test_size=0.2,random_state=SEED)\n\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH+'/test*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"EmtvSqFrCJ1A","outputId":"b56779bb-846b-4685-f625-a7f2db630cf6"},"cell_type":"code","source":"print(len(TRAINING_FILENAMES),len(VALIDATION_FILENAMES))","execution_count":null,"outputs":[]},{"metadata":{"id":"tN3x_TQQCJ1Y"},"cell_type":"markdown","source":"# Preparing the dataset","execution_count":null},{"metadata":{"trusted":true,"id":"XUKNW_7cCJ1Z","outputId":"4f11bba5-3ae2-4eff-c4ae-325eada41945"},"cell_type":"code","source":"def decode_augument_image(image_data,seed=SEED):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.bfloat16) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    image = tf.image.rot90(image,k=np.random.randint(4))\n    image = tf.image.random_flip_left_right(image,seed=seed)\n    image = tf.image.random_flip_up_down(image,seed=seed)\n    return image\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.bfloat16) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),  \n        \"sex\": tf.io.FixedLenFeature([], tf.int64), \n        \"anatom_site_general_challenge\" : tf.io.FixedLenFeature([] , tf.int64),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  \n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_augument_image(example['image'])\n    age = tf.cast(example['age_approx'], tf.bfloat16)\n    sex = tf.cast(example['sex'], tf.bfloat16)\n    asg = tf.cast(example['anatom_site_general_challenge'] , tf.bfloat16)\n    target = tf.cast(example['target'], tf.int32)\n    return (image, tf.stack([age,sex,asg])),target\n\ndef read_valid_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),  \n        \"sex\": tf.io.FixedLenFeature([], tf.int64), \n        \"anatom_site_general_challenge\" : tf.io.FixedLenFeature([] , tf.int64),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  \n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    age = tf.cast(example['age_approx'], tf.bfloat16)\n    sex = tf.cast(example['sex'], tf.bfloat16)\n    asg = tf.cast(example['anatom_site_general_challenge'] , tf.bfloat16)\n    target = tf.cast(example['target'], tf.int32)\n    return (image, tf.stack([age,sex,asg])),target\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),  \n        \"sex\": tf.io.FixedLenFeature([], tf.int64), \n        \"anatom_site_general_challenge\" : tf.io.FixedLenFeature([] , tf.int64),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    age = tf.cast(example['age_approx'], tf.bfloat16)\n    sex = tf.cast(example['sex'], tf.bfloat16)\n    asg = tf.cast(example['anatom_site_general_challenge'] , tf.bfloat16)\n    idnum = example['image_name']\n    return (image,tf.stack([age,sex,asg])),idnum# returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False, valid=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    if labeled:\n      dataset = dataset.map(read_labeled_tfrecord,num_parallel_calls=AUTO) \n    elif labeled and valid:\n      dataset = dataset.map(read_valid_labeled_tfrecord,num_parallel_calls=AUTO)\n    else:\n      dataset = dataset.map(read_unlabeled_tfrecord,num_parallel_calls=AUTO)\n\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES ,labeled=True,valid=False)\n    dataset = dataset.shuffle(SEED)\n    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True ,valid=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=True):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, valid=False, ordered=ordered)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALID_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALIDATION_STEPS = NUM_VALID_IMAGES // BATCH_SIZE\nprint('Dataset: {} training images ,{} validation images,{} unlabeled test images'.format(NUM_TRAINING_IMAGES,NUM_VALID_IMAGES,NUM_TEST_IMAGES))\nprint(\"STEPS_PER_EPOCH are {}\".format(STEPS_PER_EPOCH))\nprint(\"validation Steps are {}\".format(VALIDATION_STEPS))","execution_count":null,"outputs":[]},{"metadata":{"id":"LlDgkclzCJ15"},"cell_type":"markdown","source":"# Training ","execution_count":null},{"metadata":{"trusted":true,"id":"94vCRiXzCJ16"},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DuX4Z9U-CJ1-"},"cell_type":"code","source":"from tensorflow.keras import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import *\nfrom efficientnet.tfkeras import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"hbu_hm5ACJ2C"},"cell_type":"code","source":"def create_model():\n    base_model=EfficientNetB7(include_top=False,weights='imagenet',pooling='avg',input_shape=(*IMAGE_SIZE,3))\n    base_model.trainable=False\n    inp1=Input(shape=(*IMAGE_SIZE,3))\n    inp2=Input(shape=(3,))\n    X=base_model(inp1,training=False)\n    #X=GlobalAveragePooling2D()(X)\n    Z=Dense(512,activation='relu')(inp2)\n    Z=BatchNormalization()(Z)\n    Z=Dropout(0.4)(Z)\n    Z=Dense(1024,activation='relu')(Z)\n    Z=BatchNormalization()(Z)\n    Z=Dropout(0.4)(Z)\n    X=Concatenate()([X,Z])\n    X=Dense(1024,activation='relu')(X)\n    X=BatchNormalization()(X)\n    X=Dropout(0.4)(X)\n    Y=Dense(1,activation='sigmoid')(X)\n    return Model(inputs=[inp1,inp2],outputs=Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"X-hTiqJkCJ2H","outputId":"082ada37-fcb2-4b45-bbaa-3214ba582c46"},"cell_type":"code","source":"with strategy.scope():\n    model = create_model()\n    \n    model.compile(optimizer='adam',\n                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing = LABEL_SMOOTHING),\n                  metrics=[tf.keras.metrics.AUC(),'accuracy'])\n    \n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"inhmk0vqCJ2N","outputId":"9c5a0d2c-ec3f-48b5-fc5b-6df38e2f248b"},"cell_type":"code","source":"tf.keras.utils.plot_model(model,show_layer_names=True,show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"7YiNyGhgCJ2S"},"cell_type":"code","source":"def get_cosine_schedule_with_warmup(lr,num_warmup_steps, num_training_steps, num_cycles=0.5):\n    \"\"\"\n    Modified version of the get_cosine_schedule_with_warmup from huggingface.\n    (https://huggingface.co/transformers/_modules/transformers/optimization.html#get_cosine_schedule_with_warmup)\n\n    Create a schedule with a learning rate that decreases following the\n    values of the cosine function between 0 and `pi * cycles` after a warmup\n    period during which it increases linearly between 0 and 1.\n    \"\"\"\n\n    def lrfn(epoch):\n        if epoch < num_warmup_steps:\n            return (float(epoch) / float(max(1, num_warmup_steps))) * lr\n        progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr\n\n    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\nlr_schedule = get_cosine_schedule_with_warmup(lr=LR,num_warmup_steps=WARMUP,num_training_steps=EPOCHS)\n\nes=tf.keras.callbacks.EarlyStopping(monitor='val_auc',mode='max',patience=3,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MSbrp9C_CJ2W","outputId":"e724caae-59ed-42ac-8081-80d17e7a409f"},"cell_type":"code","source":"model.fit(get_training_dataset(),\n          epochs=EPOCHS,\n          steps_per_epoch=STEPS_PER_EPOCH,\n          validation_data=get_validation_dataset(),\n          validation_steps=VALIDATION_STEPS,\n          callbacks=[es,lr_schedule],\n          verbose=2\n         )","execution_count":null,"outputs":[]},{"metadata":{"id":"b1mHmyEbmG2b","outputId":"830ae6a9-6a44-4ae1-dea6-1f566f87ae70","trusted":true},"cell_type":"code","source":"import h5py\n\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\nmodel.save_weights(\"mo.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"UhXjSvA3CJ2f"},"cell_type":"code","source":"def display_training_curves(training, validation, title, subplot):\n    \"\"\"\n    Source: https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n    \"\"\"\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"1nF-k9tHCJ2j","outputId":"7b1f11a5-b6aa-4564-96ac-a153d0bd3315"},"cell_type":"code","source":" display_training_curves(\n        model.history.history['loss'], \n        model.history.history['val_loss'], \n        'loss', 211)\n display_training_curves(\n        model.history.history['accuracy'], \n        model.history.history['val_accuracy'], \n        'accuracy',212)\n display_training_curves(\n     model.history.history['auc'],\n     model.history.history['val_auc'],\n     'auc score ', 311)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8poK3u0jCJ3K","outputId":"517f6b1f-f166-49d9-de0e-e3b7528ed109"},"cell_type":"code","source":"y_pred = model.predict(get_validation_dataset())\n\n\ny_true = np.array([\n    target.numpy() for _, target in iter(get_validation_dataset().unbatch())])\n\nprint(y_true.shape)\nprint(y_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"XhA3rMVfBIgD","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nmetric_score=roc_auc_score(y_true,y_pred)\nprint(metric_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"KXl1O8bICJ3R"},"cell_type":"markdown","source":"#  Generate Predictions","execution_count":null},{"metadata":{"trusted":true,"id":"Dkod6boICJ3S"},"cell_type":"code","source":"def predictions():\n    test_ds=get_test_dataset(ordered=True)\n\n    test_ds_features=test_ds.map(lambda feat,imname:(feat,0)).batch(BATCH_SIZE) #Getting the features of the Test_ds \n\n    preds=model.predict(test_ds_features) #predicting with the model\n\n    test_ids_ds = test_ds.map(lambda img, imname: imname)\n\n    test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n\n    prediction_df=pd.DataFrame({'image_name':test_ids ,'target':np.concatenate(preds)}) #writing to Dataframs\n\n    prediction_df.to_csv(\"submission.csv\",index=False) #Generating CSV file\n    \npredictions()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}