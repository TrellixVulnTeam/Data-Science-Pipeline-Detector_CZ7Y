{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate,Dense,Input,Flatten\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications import DenseNet169\nimport tensorflow\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import DenseNet169 Model without softmax layer\nclass DenseNetEncoder(Model):\n    def __init__(self):\n        super(DenseNetEncoder,self).__init__()\n        self.base_model=DenseNet169(input_shape=(224,224,3),include_top=False,weights='imagenet')\n        self.encoder=Model(inputs=self.base_model.inputs,outputs=self.base_model.outputs)\n        print('Base model loaded {}'.format(DenseNet169.__name__))\n        \n    def call(self,x):\n        print('building basemodel')\n        return self.encoder(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.ops.variables import Variable\n#Concat DenseNet Output and metadata with a fully connected layer and predict an outcome\nclass Predictor(Model):\n    def __init__(self):\n        super(Predictor,self).__init__()\n        self.flatten_layer=Flatten()\n        self.dense_relu=Dense(16,activation='relu')\n        self.dense_sigmoid=Dense(1,activation='sigmoid')\n        \n    def call(self,x):\n        flat = self.flatten_layer(x)\n        fcl0=self.dense_relu(flat)\n        \n\n        #for k, v in locals().items():\n        #    if type(v) is Variable or type(v) is tf.Tensor:\n        #        print(\"{0}: {1}\".format(k, v)) \n        return self.dense_sigmoid(fcl0)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Combine densenet and predictor module together\nclass Classifier(Model):\n    def __init__(self):\n        super(Classifier,self).__init__()\n        self.encoder=DenseNetEncoder()\n        self.predictor=Predictor()\n        print('\\nModel created.')\n    \n    def call(self,x):\n        image_features=self.encoder(x)\n        return self.predictor(image_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load dataframes of images to store context\ntrain = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntrain['path']='../input/siim-isic-melanoma-classification/jpeg/train/'+train['image_name']+'jpg'\n\ntest = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\ntest['path']='../input/siim-isic-melanoma-classification/jpeg/train/'+test['image_name']+'jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\nimport tensorflow\nfrom tensorflow.image import ResizeMethod\n\nclass DataLoader():\n    def __init__(self, csv_file='../input/siim-isic-melanoma-classification/train.csv',\\\n                 img_path='../input/siim-isic-melanoma-classification/jpeg/train/',DEBUG=False):\n        self.csv_file = csv_file\n        self.img_path = img_path\n        \n        self.data_read(DEBUG=DEBUG)\n    \n    def data_read(self,DEBUG=False):\n        train_data = pd.read_csv(self.csv_file)\n        train_data['path'] = self.img_path+train_data['image_name']+'.jpg'\n        \n        meta_data = train_data[['path','sex','age_approx','anatom_site_general_challenge',]]\n        for col in ['sex','age_approx','anatom_site_general_challenge']:\n            meta_data[col].fillna(meta_data[col].mode()[0],inplace=True)\n        meta_data = pd.get_dummies(meta_data,columns=['sex','anatom_site_general_challenge'])\n\n        meta_data.drop(columns=['sex_female','anatom_site_general_challenge_head/neck'],inplace=True)\n\n        meta_data = meta_data[['path', 'age_approx','sex_male',\\\n                               'anatom_site_general_challenge_lower extremity',\\\n                               'anatom_site_general_challenge_oral/genital',\\\n                               'anatom_site_general_challenge_palms/soles',\\\n                               'anatom_site_general_challenge_torso',\\\n                               'anatom_site_general_challenge_upper extremity']]\n\n        train_data=train_data.to_numpy()\n        self.meta_data=meta_data\n        # Dataset shuffling happens here\n        train_data = shuffle(train_data, random_state=0)\n        \n        # Test on a smaller dataset\n        if DEBUG: train_data = train_data[:10]\n            \n        self.filenames = [i[8] for i in train_data]\n        \n        self.features = (meta_data.to_numpy()).flatten()\n        \n        self.labels = [i[7] for i in train_data]\n        \n        # Length of dataset\n        self.length = len(self.filenames)\n    \n    def parser(self,filename,label):\n        image_decoded = tensorflow.image.decode_jpeg(tensorflow.io.read_file(filename))\n        image_decoded = tf.image.resize(image_decoded,size=[224,224])\n        rgb = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n        \n        #features = self.meta_data.loc[self.meta_data['path']==filename]\n        #features.drop(columns='path',inplace=True)\n        #features = features.to_numpy()\n        #features = features.flatten()\n\n        return rgb,label\n    \n    def img_resize(self,img,resolution=224):\n        from skimage.transform import resize\n        return resize(img,(resolution,resolution),preserve_range=True, mode='reflect', anti_aliasing=True)\n    \n    #Tying the parser function in the generator\n    def generator():\n        for i in np.random.permutation(len(self.filenames)):\n            rgb,features,label = self.parser(self.filenames[i],self.label[i])\n            yield {\"input1\":rgb,\"input2\":features},label\n            \n    \n    def get_batch_data(self,batch_size):\n        self.dataset = tf.data.Dataset.from_tensor_slices((self.filenames,self.labels))\n        self.dataset = self.dataset.shuffle(buffer_size=len(self.filenames),reshuffle_each_iteration=True)\n        self.dataset = self.dataset.repeat()\n        self.dataset = self.dataset.map(map_func=self.parser,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        self.dataset = self.dataset.batch(batch_size=batch_size)\n        \n        return self.dataset\n        \n        \n    def get_numpy_data(self,batch_size):\n        images_appended = []\n        meta_data_appended = []\n        labels_appended = []\n        \n        for k in range(batch_size):\n            i = np.random.choice(len(self.filenames))\n            rgb,features,label = self.parser(self.filenames[i],self.labels[i])\n            images_appended.append(rgb)\n            meta_data_appended.append(features)\n            labels_appended.append(label)\n            \n        return np.array(images_appended),np.array(meta_data_appended),np.array(labels_appended)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\ndl = DataLoader()\ntrain_generator = dl.get_batch_data(batch_size)\n\nprint('Data loader ready.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define Model\n\nmodel = Classifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tensorflow.keras.optimizers.Adam(lr=0.001, amsgrad=True)\n\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ncheckpoint_path = \"cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\ncp_callback = tensorflow.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_generator, epochs=15, steps_per_epoch=dl.length//batch_size, callbacks=[cp_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\nfrom skimage.transform import resize\ndef get_prediction(image_name,model=model):\n    filename = '../input/siim-isic-melanoma-classification/jpeg/test/'+image_name+'.jpg'\n    image_decoded = tensorflow.image.decode_jpeg(tensorflow.io.read_file(filename))\n    image_decoded = tf.image.resize(image_decoded,size=[224,224])\n    rgb = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n    rgb = np.expand_dims(rgb, axis=0)\n    return model.predict(rgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submissions = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submissions['target']=Submissions.apply(lambda x: get_prediction(x['image_name']).flatten(), axis=1)\nSubmissions['target']=Submissions['target'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submissions.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}