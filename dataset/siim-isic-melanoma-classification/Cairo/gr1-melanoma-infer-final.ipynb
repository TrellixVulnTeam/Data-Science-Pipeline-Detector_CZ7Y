{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:00:59.263876Z","iopub.execute_input":"2021-07-06T09:00:59.264207Z","iopub.status.idle":"2021-07-06T09:00:59.270986Z","shell.execute_reply.started":"2021-07-06T09:00:59.264174Z","shell.execute_reply":"2021-07-06T09:00:59.269841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip -q install geffnet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-06T09:00:59.283589Z","iopub.execute_input":"2021-07-06T09:00:59.283865Z","iopub.status.idle":"2021-07-06T09:01:08.310205Z","shell.execute_reply.started":"2021-07-06T09:00:59.283839Z","shell.execute_reply":"2021-07-06T09:01:08.309179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport albumentations as A\nimport geffnet\n\ndevice = torch.device('cuda')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-06T09:01:08.312307Z","iopub.execute_input":"2021-07-06T09:01:08.312676Z","iopub.status.idle":"2021-07-06T09:01:11.224027Z","shell.execute_reply.started":"2021-07-06T09:01:08.312643Z","shell.execute_reply":"2021-07-06T09:01:11.223106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_type = '9c_b7ns_1e_640_ext_15ep'\nimage_size = 640\nuse_amp = False\ndata_dir = '../input/jpeg-melanoma-768x768'\ndata_dir2 = '../input/jpeg-isic2019-768x768'\nmodel_dir = '../input/melanoma-winning-models'\nenet_type = 'efficientnet-b7'\nbatch_size = 16\nnum_workers = 4\nout_dim = 9\n\nuse_meta = False\nuse_external = '_ext' in kernel_type","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.225274Z","iopub.execute_input":"2021-07-06T09:01:11.225632Z","iopub.status.idle":"2021-07-06T09:01:11.231125Z","shell.execute_reply.started":"2021-07-06T09:01:11.225596Z","shell.execute_reply":"2021-07-06T09:01:11.230335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read CSV","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_test['filepath'] = df_test['image_name'].apply(lambda x: os.path.join(data_dir, 'test', f'{x}.jpg'))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.232643Z","iopub.execute_input":"2021-07-06T09:01:11.233132Z","iopub.status.idle":"2021-07-06T09:01:11.320125Z","shell.execute_reply.started":"2021-07-06T09:01:11.233094Z","shell.execute_reply":"2021-07-06T09:01:11.319063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_train = df_train[df_train['tfrecord'] != -1].reset_index(drop=True)\ntfrecord2fold = {\n    2:0, 4:0, 5:0, 1:1, 10:1, 13:1, 0:2, 9:2, 12:2, 3:3, 8:3, 11:3, 6:4, 7:4, 14:4\n}\ndf_train['fold'] = df_train['tfrecord'].map(tfrecord2fold)\ndf_train['is_ext'] = 0\ndf_train['filepath'] = df_train['image_name'].apply(lambda x: os.path.join(data_dir, 'train', f'{x}.jpg'))\n\ndef replaceFields (x, replacements):\n    for key in replacements:\n        x= x.replace(key, replacements[key])\n    return x\n\nreplacements = {\n                'seborrheic keratosis':'BKL', \n                'lichenoid keratosis':'BKL', \n                'solar lentigo':'BKL', \n                'lentigo NOS':'BKL', \n                'cafe-au-lait macule':'unknown', \n                'atypical melanocytic proliferation':'unknown'\n               }\n\ndf_train = replaceFields(df_train, replacements)\ndf_train['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.323629Z","iopub.execute_input":"2021-07-06T09:01:11.324012Z","iopub.status.idle":"2021-07-06T09:01:11.615918Z","shell.execute_reply.started":"2021-07-06T09:01:11.323974Z","shell.execute_reply":"2021-07-06T09:01:11.615186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_external:\n    df_train2 = pd.read_csv(os.path.join(data_dir2, 'train.csv'))\n    df_train2 = df_train2[df_train2['tfrecord'] >= 0].reset_index(drop=True)\n    df_train2['fold'] = df_train2['tfrecord'] % 5\n    df_train2['is_ext'] = 1\n    df_train2['filepath'] = df_train2['image_name'].apply(lambda x: os.path.join(data_dir2, 'train', f'{x}.jpg'))\n\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('NV', 'nevus'))\n    df_train2['diagnosis'] = df_train2['diagnosis'].apply(lambda x: x.replace('MEL', 'melanoma'))\n    df_train = pd.concat([df_train, df_train2]).reset_index(drop=True)\n\ndiagnosis2idx = {d: idx for idx, d in enumerate(sorted(df_train.diagnosis.unique()))}\ndf_train['target'] = df_train['diagnosis'].map(diagnosis2idx)\nmel_idx = diagnosis2idx['melanoma']\ndiagnosis2idx","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.61895Z","iopub.execute_input":"2021-07-06T09:01:11.619368Z","iopub.status.idle":"2021-07-06T09:01:11.837423Z","shell.execute_reply.started":"2021-07-06T09:01:11.619329Z","shell.execute_reply":"2021-07-06T09:01:11.836314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class SIIMISICDataset(Dataset):\n    def __init__(self, csv, split, mode, transform=None):\n\n        self.csv = csv.reset_index(drop=True)\n        self.split = split\n        self.mode = mode\n        self.transform = transform\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        image = cv2.imread(row.filepath)\n        image = image[:, :, ::-1]\n\n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image'].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n\n        image = image.transpose(2, 0, 1)\n\n        if self.mode == 'test':\n            return torch.tensor(image).float()\n        else:\n            return torch.tensor(image).float(), torch.tensor(self.csv.iloc[index].target).long()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.83873Z","iopub.execute_input":"2021-07-06T09:01:11.839096Z","iopub.status.idle":"2021-07-06T09:01:11.850502Z","shell.execute_reply.started":"2021-07-06T09:01:11.839065Z","shell.execute_reply":"2021-07-06T09:01:11.849667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_val = A.Compose([\n    A.Resize(image_size, image_size),\n    A.Normalize()\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.851965Z","iopub.execute_input":"2021-07-06T09:01:11.852506Z","iopub.status.idle":"2021-07-06T09:01:11.86024Z","shell.execute_reply.started":"2021-07-06T09:01:11.852465Z","shell.execute_reply":"2021-07-06T09:01:11.859067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_show = df_train.sample(1000)\ndataset_show = SIIMISICDataset(df_show, 'train', 'val', transform=transforms_val)\n# dataset_show = CloudDataset(df_train, 'train', 'val', image_size, transform=None)\n# dataset_show = CloudDataset(df_test, 'test', 'test', image_size, transform=None)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        if use_meta:\n            img = img[0]\n        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(str(label))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:11.861855Z","iopub.execute_input":"2021-07-06T09:01:11.862727Z","iopub.status.idle":"2021-07-06T09:01:14.236297Z","shell.execute_reply.started":"2021-07-06T09:01:11.862682Z","shell.execute_reply":"2021-07-06T09:01:14.235269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim, n_meta_features=0, load_pretrained=False):\n\n        super(enetv2, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.enet = geffnet.create_model(enet_type.replace('-', '_'), pretrained=load_pretrained)\n        self.dropout = nn.Dropout(0.5)\n\n        in_ch = self.enet.classifier.in_features\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = self.enet(x)\n        return x\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x).squeeze(-1).squeeze(-1)\n        x = self.myfc(self.dropout(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:14.237744Z","iopub.execute_input":"2021-07-06T09:01:14.238134Z","iopub.status.idle":"2021-07-06T09:01:14.250215Z","shell.execute_reply.started":"2021-07-06T09:01:14.238091Z","shell.execute_reply":"2021-07-06T09:01:14.24905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"def get_trans(img, I):\n    if I >= 4:\n        img = img.transpose(2,3)\n    if I % 4 == 0:\n        return img\n    elif I % 4 == 1:\n        return img.flip(2)\n    elif I % 4 == 2:\n        return img.flip(3)\n    elif I % 4 == 3:\n        return img.flip(2).flip(3)\n\n    \ndef val_epoch(model, loader, is_ext=None, n_test=1, get_output=False):\n    model.eval()\n    LOGITS = []\n    PROBS = []\n    TARGETS = []\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            \n            if use_meta:\n                data, meta = data\n                data, meta, target = data.to(device), meta.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I), meta)\n                    logits += l\n                    probs += l.softmax(1)\n            else:\n                data, target = data.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    logits += l\n                    probs += l.softmax(1)\n            logits /= n_test\n            probs /= n_test\n\n            LOGITS.append(logits.detach().cpu())\n            PROBS.append(probs.detach().cpu())\n            TARGETS.append(target.detach().cpu())\n\n    LOGITS = torch.cat(LOGITS).numpy()\n    PROBS = torch.cat(PROBS).numpy()\n    TARGETS = torch.cat(TARGETS).numpy()\n\n    if get_output:\n        return LOGITS, PROBS\n    else:\n        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n        auc = roc_auc_score((TARGETS==mel_idx).astype(float), LOGITS[:, mel_idx])\n        auc_20 = roc_auc_score((TARGETS[is_ext==0]==mel_idx).astype(float), LOGITS[is_ext==0, mel_idx])\n        return val_loss, acc, auc, auc_20","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:14.252245Z","iopub.execute_input":"2021-07-06T09:01:14.252884Z","iopub.status.idle":"2021-07-06T09:01:14.27734Z","shell.execute_reply.started":"2021-07-06T09:01:14.252844Z","shell.execute_reply":"2021-07-06T09:01:14.276164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PROBS = []\ndfs = []\n\nfor fold in range(5):\n    i_fold = fold\n\n    df_valid = df_train[df_train['fold'] == i_fold]\n    if DEBUG:\n        df_valid = pd.concat([\n            df_valid[df_valid['target'] == mel_idx].sample(10),\n            df_valid[df_valid['target'] != mel_idx].sample(10)\n        ])\n    print(df_valid.shape)\n\n    dataset_valid = SIIMISICDataset(df_valid, 'train', 'val', transform=transforms_val)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, num_workers=num_workers)\n\n    model = enetv2(enet_type, n_meta_features=0, out_dim=out_dim)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{i_fold}.pth')\n    state_dict = torch.load(model_file)\n    state_dict = {k.replace('module.', ''): state_dict[k] for k in state_dict.keys()}\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n\n    this_LOGITS, this_PROBS = val_epoch(model, valid_loader, is_ext=df_valid['is_ext'].values, n_test=8, get_output=True)\n    PROBS.append(this_PROBS)\n    dfs.append(df_valid)\n    \ndfs = pd.concat(dfs).reset_index(drop=True)\ndfs['pred'] = np.concatenate(PROBS).squeeze()[:, mel_idx]","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:01:14.27886Z","iopub.execute_input":"2021-07-06T09:01:14.279408Z","iopub.status.idle":"2021-07-06T09:02:30.104686Z","shell.execute_reply.started":"2021-07-06T09:01:14.27937Z","shell.execute_reply":"2021-07-06T09:02:30.103781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Raw auc_all\nroc_auc_score(dfs['target'] == mel_idx, dfs['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:30.106272Z","iopub.execute_input":"2021-07-06T09:02:30.106636Z","iopub.status.idle":"2021-07-06T09:02:30.119905Z","shell.execute_reply.started":"2021-07-06T09:02:30.106597Z","shell.execute_reply":"2021-07-06T09:02:30.118912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rank per fold auc_all\ndfs2 = dfs.copy()\nfor i in range(5):\n    dfs2.loc[dfs2['fold']==i, 'pred'] = dfs2.loc[dfs2['fold']==i, 'pred'].rank(pct=True)\nroc_auc_score(dfs2['target'] == mel_idx, dfs2['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:30.121993Z","iopub.execute_input":"2021-07-06T09:02:30.122733Z","iopub.status.idle":"2021-07-06T09:02:30.148132Z","shell.execute_reply.started":"2021-07-06T09:02:30.122689Z","shell.execute_reply":"2021-07-06T09:02:30.147428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Raw auc_2020\nroc_auc_score(dfs[dfs['is_ext']==0]['target']==mel_idx, dfs[dfs['is_ext']==0]['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:30.14934Z","iopub.execute_input":"2021-07-06T09:02:30.149734Z","iopub.status.idle":"2021-07-06T09:02:30.165035Z","shell.execute_reply.started":"2021-07-06T09:02:30.149697Z","shell.execute_reply":"2021-07-06T09:02:30.164203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rank per fold auc_2020\ndfs2 = dfs[dfs.is_ext==0].copy()\nfor i in range(5):\n    dfs2.loc[dfs2['fold']==i, 'pred'] = dfs2.loc[dfs2['fold']==i, 'pred'].rank(pct=True)\nroc_auc_score(dfs2['target'] == mel_idx, dfs2['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:30.166463Z","iopub.execute_input":"2021-07-06T09:02:30.167018Z","iopub.status.idle":"2021-07-06T09:02:30.190538Z","shell.execute_reply.started":"2021-07-06T09:02:30.166975Z","shell.execute_reply":"2021-07-06T09:02:30.189282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"n_test = 8\ndf_test = df_test if not DEBUG else df_test.head(batch_size * 2)\ndataset_test = SIIMISICDataset(df_test, 'test', 'test', transform=transforms_val)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:30.192151Z","iopub.execute_input":"2021-07-06T09:02:30.192564Z","iopub.status.idle":"2021-07-06T09:02:30.200326Z","shell.execute_reply.started":"2021-07-06T09:02:30.192525Z","shell.execute_reply":"2021-07-06T09:02:30.198733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i_fold in range(5):\n    model = enetv2(enet_type, n_meta_features=0, out_dim=out_dim)\n    model = model.to(device)\n    model_file = os.path.join(model_dir, f'{kernel_type}_best_fold{i_fold}.pth')\n    state_dict = torch.load(model_file)\n    state_dict = {k.replace('module.', ''): state_dict[k] for k in state_dict.keys()}\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n    models.append(model)\nlen(models)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:30.202289Z","iopub.execute_input":"2021-07-06T09:02:30.202817Z","iopub.status.idle":"2021-07-06T09:02:37.94417Z","shell.execute_reply.started":"2021-07-06T09:02:30.202773Z","shell.execute_reply":"2021-07-06T09:02:37.943405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUTS = []\nPROBS = []\n\nwith torch.no_grad():\n    for (data) in tqdm(test_loader):\n\n        if use_meta:\n            data, meta = data\n            data, meta = data.to(device), meta.to(device)\n            probs = torch.zeros((data.shape[0], out_dim)).to(device)\n            for I in range(n_test):\n                l = model(get_trans(data, I), meta)\n                probs += l.softmax(1)\n        else:\n            data = data.to(device)\n            probs = torch.zeros((data.shape[0], out_dim)).to(device)\n            for model in models:\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    probs += l.softmax(1)\n\n        probs /= n_test * len(models)\n        PROBS.append(probs.detach().cpu())\n\nPROBS = torch.cat(PROBS).numpy()\nOUTPUTS = PROBS[:, mel_idx]","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:02:37.945616Z","iopub.execute_input":"2021-07-06T09:02:37.946003Z","iopub.status.idle":"2021-07-06T09:03:39.839351Z","shell.execute_reply.started":"2021-07-06T09:02:37.945936Z","shell.execute_reply":"2021-07-06T09:03:39.83819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['target'] = OUTPUTS\ndf_test[['image_name', 'target']].to_csv(f'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:39.840941Z","iopub.execute_input":"2021-07-06T09:03:39.841348Z","iopub.status.idle":"2021-07-06T09:03:40.133805Z","shell.execute_reply.started":"2021-07-06T09:03:39.841307Z","shell.execute_reply":"2021-07-06T09:03:40.132943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[['image_name', 'target']].head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:40.135294Z","iopub.execute_input":"2021-07-06T09:03:40.135686Z","iopub.status.idle":"2021-07-06T09:03:40.154675Z","shell.execute_reply.started":"2021-07-06T09:03:40.135648Z","shell.execute_reply":"2021-07-06T09:03:40.153379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:40.156353Z","iopub.execute_input":"2021-07-06T09:03:40.156989Z","iopub.status.idle":"2021-07-06T09:03:40.164174Z","shell.execute_reply.started":"2021-07-06T09:03:40.156944Z","shell.execute_reply":"2021-07-06T09:03:40.162827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Single Image","metadata":{}},{"cell_type":"markdown","source":"### Non-melanoma image","metadata":{}},{"cell_type":"markdown","source":"Image with a correct metadata attached to it (from DLVN dataset)","metadata":{}},{"cell_type":"code","source":"# patient 1 image filepath\nimport csv\n\nfile_path = '../input/jpegdlvn201720181750x984/DLVN/test/ANH_CHU_THI_LAN_17397544-002.jpg'\n\ndf_test_images = pd.read_csv('../input/jpegdlvn201720181750x984/DLVN/test.csv')\n\nfor _, row in df_test_images.iterrows():\n    if row['image_name']+'.jpg' == file_path.split('/')[-1]:\n        single_image_meta = row\n        break\n\n# df_singe_image = single_image_meta.to_frame()\n# df_single_image\nimage_name = single_image_meta['image_name']\npatient_id = single_image_meta['patient_id']\nsex = single_image_meta['sex']\nage_approx = single_image_meta['age_approx']\nanatom_site_general_challenge = single_image_meta['anatom_site_general_challenge']\nwidth = single_image_meta['width']\nheight = single_image_meta['height']\nwith open('datasettesting.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"image_name\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"width\", \"height\", \"filepath\"])\n    writer.writerow([image_name, patient_id, sex, age_approx, anatom_site_general_challenge, width, height, file_path])\n\ndf_single_image = pd.read_csv('datasettesting.csv')\ndf_single_image","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:40.166206Z","iopub.execute_input":"2021-07-06T09:03:40.166792Z","iopub.status.idle":"2021-07-06T09:03:40.212205Z","shell.execute_reply.started":"2021-07-06T09:03:40.166754Z","shell.execute_reply":"2021-07-06T09:03:40.211302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as we only read a single image, so we don't need a dataloader\ndataset_test = SIIMISICDataset(df_single_image, 'test', 'test', transform=transforms_val)\nimage = dataset_test[0]  \nimage = image.to(device).unsqueeze(0)  # a single image need to be added a new axis to act like batch_size = 1","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:40.213814Z","iopub.execute_input":"2021-07-06T09:03:40.214184Z","iopub.status.idle":"2021-07-06T09:03:40.290652Z","shell.execute_reply.started":"2021-07-06T09:03:40.214146Z","shell.execute_reply":"2021-07-06T09:03:40.289687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    probs = torch.zeros((image.shape[0], out_dim)).to(device)\n    for model in models:\n        for I in range(n_test):\n            l = model(get_trans(image, I))\n            probs += l.softmax(1)\nprobs /= len(models) * n_test","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:40.29201Z","iopub.execute_input":"2021-07-06T09:03:40.292368Z","iopub.status.idle":"2021-07-06T09:03:43.271004Z","shell.execute_reply.started":"2021-07-06T09:03:40.292332Z","shell.execute_reply":"2021-07-06T09:03:43.270273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = probs[:, mel_idx].item()\nprediction","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:43.272266Z","iopub.execute_input":"2021-07-06T09:03:43.2726Z","iopub.status.idle":"2021-07-06T09:03:43.311763Z","shell.execute_reply.started":"2021-07-06T09:03:43.272565Z","shell.execute_reply":"2021-07-06T09:03:43.310639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Melanoma image","metadata":{}},{"cell_type":"markdown","source":"Random melanoma image with made-up metadata","metadata":{}},{"cell_type":"code","source":"#patient test images processing\n# patient 1 image name\nin1 = 'hello'\n# patient 1 patient_id\npi1 = 'IP23232'\n# patient 1 sex\ns1 = 'male'\n# patient 1 age\na1 = 70.0\n# patient 1 anatom_site_general_challenge. where its located\nasgc1 = 'torso'\n# patient 1 image filepath\nf1 = '../input/singletestimage/1200px-Melanoma.jpg'\nimport csv\nwith open('datasettesting.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"image_name\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"width\", \"height\", \"filepath\"])\n    writer.writerow([in1,pi1, s1, a1, asgc1, 1200, 835, f1])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:43.313273Z","iopub.execute_input":"2021-07-06T09:03:43.313656Z","iopub.status.idle":"2021-07-06T09:03:43.321998Z","shell.execute_reply.started":"2021-07-06T09:03:43.313618Z","shell.execute_reply":"2021-07-06T09:03:43.321036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_single_image = pd.read_csv('datasettesting.csv')\ndf_single_image","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:43.323872Z","iopub.execute_input":"2021-07-06T09:03:43.324488Z","iopub.status.idle":"2021-07-06T09:03:43.344976Z","shell.execute_reply.started":"2021-07-06T09:03:43.324447Z","shell.execute_reply":"2021-07-06T09:03:43.343754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = SIIMISICDataset(df_single_image, 'test', 'test', transform=transforms_val)\nimage = dataset_test[0]  \nimage = image.to(device).unsqueeze(0)  # a single image need to be added a new axis to act like batch_size = 1","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:43.346647Z","iopub.execute_input":"2021-07-06T09:03:43.347211Z","iopub.status.idle":"2021-07-06T09:03:43.399911Z","shell.execute_reply.started":"2021-07-06T09:03:43.347171Z","shell.execute_reply":"2021-07-06T09:03:43.399189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    probs = torch.zeros((image.shape[0], out_dim)).to(device)\n    for model in models:\n        for I in range(n_test):\n            l = model(get_trans(image, I))\n            probs += l.softmax(1)\nprobs /= len(models) * n_test","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:43.401275Z","iopub.execute_input":"2021-07-06T09:03:43.401746Z","iopub.status.idle":"2021-07-06T09:03:46.384503Z","shell.execute_reply.started":"2021-07-06T09:03:43.401708Z","shell.execute_reply":"2021-07-06T09:03:46.383545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = probs[:, mel_idx].item()\nprediction","metadata":{"execution":{"iopub.status.busy":"2021-07-06T09:03:46.385764Z","iopub.execute_input":"2021-07-06T09:03:46.386163Z","iopub.status.idle":"2021-07-06T09:03:46.420154Z","shell.execute_reply.started":"2021-07-06T09:03:46.386124Z","shell.execute_reply":"2021-07-06T09:03:46.419033Z"},"trusted":true},"execution_count":null,"outputs":[]}]}