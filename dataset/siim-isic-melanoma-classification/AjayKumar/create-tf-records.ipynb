{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport cv2\nimport tensorflow as tf\nfrom tqdm import tqdm\n%matplotlib inline\nfrom keras.preprocessing import image\nimport glob\nimport math, re, os\nimport sys\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest_csv = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\nsample = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = '../input/siim-isic-melanoma-classification'\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/train*')\n\nTEST_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/tfrecords/test*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [1024, 1024]\nAUTO = tf.data.experimental.AUTOTUNE\n\nBATCH_SIZE = 5\n\nimSize = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_csv\ndf = df.drop(['target'], axis = 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = train_csv['image_name']\n\nX = df\ny = train_csv['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\nX_train = X_train.reset_index(drop=True)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a1 = X_test.loc[X_test['image_name'] == 'ISIC_7020578']['patient_id'].values\na1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test['sex'] = X_test['sex'].fillna((X_test['sex'].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[['sex', 'anatom_site_general_challenge', 'diagnosis']] = X_test[['sex', 'anatom_site_general_challenge', 'diagnosis']].replace(np.nan, '', regex=True)\n\n\nX_train[['sex', 'anatom_site_general_challenge', 'diagnosis']] = X_train[['sex', 'anatom_site_general_challenge', 'diagnosis']].replace(np.nan, '', regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a1[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['image_name'] == 'ISIC_8677254'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['image_name'][0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_paths = []\ntrain_image_labels = []\n\nfor i in range(len(X_train)):\n    \n    name = X_train['image_name'][i]\n    path_temp = f'../input/siim-isic-melanoma-classification/jpeg/train/{name}.jpg'\n    \n    train_image_paths.append(path_temp)\n    train_image_labels.append(y_train[i])\n    \ntrain_image_paths[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following functions can be used to convert a value to a type compatible\n# with tf.Example.\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _floats_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to apply entire process to each element of dataset.\n# process the two images into 'tf.Example' messages.\ndef image_example(image_string, label):\n  \"\"\"\n  Creates a tf.Example message ready to be written to a file.\n  \"\"\"\n  # Create a dictionary mapping the feature name to the tf.Example-compatible\n  # data type.\n  image_feature_description = {\n      \"image\": _bytes_feature(image_string),\n      \"class\": _int64_feature(label),\n      }\n  # Create a Features message using tf.train.Example.\n  return tf.train.Example(features=tf.train.Features(feature=image_feature_description))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Test code\ndef image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis):\n    \"\"\"\n    Creates a tf.Example message ready to be written to a file.\n    \"\"\"\n    # Create a dictionary mapping the feature name to the tf.Example-compatible\n    # data type.\n    image_feature_description = {\n      \"image\": _bytes_feature(image_string),\n      \"class\": _int64_feature(label),\n      #\"patient_id\": _bytes_feature(patient_id),\n      \"patient_id\": _bytes_feature(value = patient_id.encode('utf-8')),\n      \"sex\": _bytes_feature(value = sex.encode('utf-8')),\n      \"age_approx\": _floats_feature(age_approx),\n      \"anatom_site_general_challenge\": _bytes_feature(value = anatom_site_general_challenge.encode('utf-8')),\n      \"diagnosis\": _bytes_feature(value = diagnosis.encode('utf-8')),\n      }\n  # Create a Features message using tf.train.Example.\n\n    #print(image_feature_description)\n    return tf.train.Example(features=tf.train.Features(feature=image_feature_description))\n\n'''\n# define a filename to store preprocessed image data:\nrecord_file = '1.tfrecords'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[0:10]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n        \n        '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%env JOBLIB_TEMP_FOLDER=/tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Final code\n\n\ndef image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis):\n    \"\"\"\n    Creates a tf.Example message ready to be written to a file.\n    \"\"\"\n    # Create a dictionary mapping the feature name to the tf.Example-compatible\n    # data type.\n    image_feature_description = {\n      \"image\": _bytes_feature(image_string),\n      \"class\": _int64_feature(label),\n      #\"patient_id\": _bytes_feature(patient_id),\n      \"patient_id\": _bytes_feature(value = patient_id.encode('utf-8')),\n      \"sex\": _bytes_feature(value = sex.encode('utf-8')),\n      \"age_approx\": _floats_feature(age_approx),\n      \"anatom_site_general_challenge\": _bytes_feature(value = anatom_site_general_challenge.encode('utf-8')),\n      \"diagnosis\": _bytes_feature(value = diagnosis.encode('utf-8')),\n      }\n  # Create a Features message using tf.train.Example.\n\n    #print(image_feature_description)\n    return tf.train.Example(features=tf.train.Features(feature=image_feature_description))\n\n\n# define a filename to store preprocessed image data:\nrecord_file = 'train-1.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[0:5000]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n\n        \n'''        \nrecord_file = 'train-2.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[5000:10000]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n        \nrecord_file = 'train-3.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[10000:15000]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n\nrecord_file = 'train-4.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[15000:20000]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n        \n\nrecord_file = 'train-5.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[20000:25000]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n        \n        \nrecord_file = 'train-6.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[25000:]:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_train.loc[X_train['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_train.loc[X_train['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_train.loc[X_train['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_train.loc[X_train['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_train.loc[X_train['image_name'] == img_name]['diagnosis'].values[0]\n        label = train_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n        \n        \n        '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_image_paths = []\nvalid_image_labels = []\n\nfor i in range(len(X_test)):\n    \n    name = X_test['image_name'][i]\n    path_temp = f'../input/siim-isic-melanoma-classification/jpeg/train/{name}.jpg'\n    \n    valid_image_paths.append(path_temp)\n    valid_image_labels.append(y_test[i])\n    \nvalid_image_paths[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(valid_image_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Validation data creation\n'''\n# define a filename to store preprocessed image data:\nrecord_file = 'valid.tfrec'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in valid_image_paths:\n        image_string = open(filename, 'rb').read()\n        \n        img_name = filename[54:-4]\n        patient_id = X_test.loc[X_test['image_name'] == img_name]['patient_id'].values[0]\n        sex = X_test.loc[X_test['image_name'] == img_name]['sex'].values[0]\n        \n        age_approx = X_test.loc[X_test['image_name'] == img_name]['age_approx'].values[0]\n        anatom_site_general_challenge = X_test.loc[X_test['image_name'] == img_name]['anatom_site_general_challenge'].values[0]\n        diagnosis = X_test.loc[X_test['image_name'] == img_name]['diagnosis'].values[0]\n        label = valid_image_labels[index]\n              \n        index+=1\n        \n        ## storing all the features in the tf.Example message.\n        tf_example = image_example2(image_string, label, patient_id, sex, age_approx, anatom_site_general_challenge, diagnosis)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#anatom_site_general_challenge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test.loc[X_test['image_name'] == img_name]['sex'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#img_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(train_image_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# define a filename to store preprocessed image data:\nrecord_file = 'images.tfrecords'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n    index = 0\n    for filename in train_image_paths[0:10]:\n        image_string = open(filename, 'rb').read()\n        \n        label = train_image_labels[index]\n        index+=1\n    ## storing all the features in the tf.Example message.\n        tf_example = image_example(image_string, label)\n    ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())\n        \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n'''\n# Create a function to apply entire process to each element of dataset.\n# process the two images into 'tf.Example' messages.\ndef image_example(image_string, label):\n    \"\"\"\n    Creates a tf.Example message ready to be written to a file.\n    \"\"\"\n    # Create a dictionary mapping the feature name to the tf.Example-compatible\n    # data type.\n    image_feature_description = {\n        \"image\": _bytes_feature(image_string),\n        \"class\": _int64_feature(label),\n        }\n    # Create a Features message using tf.train.Example.\n    print(image_feature_description)\n    return tf.train.Example(features=tf.train.Features(feature=image_feature_description))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ntrain_image_paths = []\ntrain_image_labels = []\n\nfor i in range(len(X_train)):\n    \n    name = X_train['image_name'][i]\n    path_temp = f'../input/siim-isic-melanoma-classification/jpeg/train/{name}.jpg'\n    \n    train_image_paths.append(path_temp)\n    train_image_labels.append(y_train[i])\n    \ntrain_image_paths[0:10]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''image_string = open(train_image_paths[0], 'rb').read()\nimage_string'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## entire training\n\n'''\n# Write the `tf.Example` observations to the file.\ncnt = 0\nindex = 0\nrecord_file = f'train_{cnt}.tfrec'\nfor filename in train_image_paths[0:10]:\n    \n    image_string = open(filename, 'rb').read()\n    cnt+=1\n    if cnt%4000 == 0:\n        record_file = f'train_{cnt}.tfrec'\n    with tf.io.TFRecordWriter(record_file) as writer:\n    #for filename, label in image_labels.items():\n        \n        \n        label = train_image_labels[index]\n        \n        index+=1\n        cnt+=1\n        ## storing all the features in the tf.Example message.\n        tf_example = image_example(image_string, label)\n        ## write the example messages to a file named images.tfrecords\n        writer.write(tf_example.SerializeToString())'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''!du -sh {record_file}'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to read TFRecord file use TFRecordDataset\nraw_image_dataset = tf.data.TFRecordDataset(record_file)\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n    \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n\n# create a function to apply image feature description to each observation\ndef _parse_image_function(example_proto):\n  # parse the input tf.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\n# use map to apply this operation to each element of dataset\nparsed_image_dataset = raw_image_dataset.map(_parse_image_function)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parsed_image_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the .take method to only pull one example from the dataset.\nfor image_features in parsed_image_dataset.take(1):\n    image = image_features['image'].numpy()\n    #display.display(display.Image(data=image))\n    classes = image_features['class'].numpy()\n    print('The label of image is', classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom PIL import Image\nimport io\nimage2 = Image.open(io.BytesIO(image))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''file = '/kaggle/working/images.tfrecords'\nraw_image_dataset = tf.data.TFRecordDataset(file)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_FILENAMES = ['/kaggle/working/valid.tfrec']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    image = tf.image.resize(image, [imSize,imSize])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['image_name']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data dump\n'''\nprint(\"Training data shapes:\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(\"Training data label examples:\", label.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image_features['class'].numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display.Image(data=image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train_image_paths = []\ntrain_image_labels = []\n\nfor i in range(len(X_train)):\n    \n    name = X_train['image_name'][i]\n    path_temp = f'../input/siim-isic-melanoma-classification/jpeg/train/{name}.jpg'\n    \n    train_image_paths.append(path_temp)\n    train_image_labels.append(y_train[i])\n '''   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndef my_fn(img, label):\n    a = tf.io.read_file(img)\n    b = tf.image.decode_jpeg(a)\n    #c = tf.image.resize_images(b, (192,192))\n    d = tf.dtypes.cast(b, tf.uint8)\n    e = tf.image.encode_jpeg(d)\n    \n    \n    ## labels\n    label = tf.cast(label, tf.int32)\n    \n    return e, label\n    \nds = tf.data.Dataset.from_tensor_slices(train_image_paths[0:10], train_image_labels[0:10])\n\nds2 = ds.map(my_fn)\n\ndds = ds2.map(tf.io.serialize_tensor)\n\ntfrec = tf.data.experimental.TFRecordWriter('images.tfrec')\ntfrec.write(dds)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}