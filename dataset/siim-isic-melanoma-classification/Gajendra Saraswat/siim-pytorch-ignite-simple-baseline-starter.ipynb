{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nflag = 0\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if flag == 5:\n            break\n        print(os.path.join(dirname, filename))\n        flag += 1\n    if flag ==5:\n        break\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing necessary Libraries","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as D\nfrom torch.optim.lr_scheduler import ExponentialLR\n\nfrom torchvision import models as M, transforms as T\n\nfrom tqdm import tqdm_notebook\n\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Loss, Accuracy\nfrom ignite.contrib.handlers.tqdm_logger import ProgressBar\nfrom ignite.handlers import ModelCheckpoint, EarlyStopping ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"os.listdir(\"/kaggle/input/siim-isic-melanoma-classification/jpeg/\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/siim-isic-melanoma-classification\"\ndf_train = pd.read_csv(BASE_PATH + \"/train.csv\")\ndf_test = pd.read_csv(BASE_PATH + \"/test.csv\")\ndf_sub = pd.read_csv(BASE_PATH + \"/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"temp = plt.imread(BASE_PATH + \"/jpeg/train/ISIC_4232172.jpg\")\nplt.xticks([])\nplt.yticks([])\nplt.imshow(temp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Images","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size = 32\ndevice = \"cuda\"\ntorch.manual_seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"temp.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"BINGO_PATH = \"/kaggle/input/siic-isic-224x224-images\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class ImagesDS(D.Dataset):\n    def __init__(self, df, dir, mode = \"train\"):\n        self.records = df.to_records(index = False)\n        self.mode = mode\n        self.dir = dir\n        self.len = df.shape[0]\n        \n    @staticmethod\n    def _load_img_as_tensor(filename):\n        with Image.open(filename) as img:\n            return T.Compose([T.Resize((224, 224)), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])(img)\n        \n    def _get_image_path(self, index):\n        image_id = self.records[index].image_name\n        return \"/\".join([self.dir, self.mode, f\"{image_id}.png\"])\n    \n    def __getitem__(self, index):\n        path = self._get_image_path(index)\n        img = self._load_img_as_tensor(path)\n        if self.mode == \"train\":\n            return img, self.records[index].target\n        else:\n            return img, self.records[index].image_name\n        \n    def __len__(self):\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data, val_data = train_test_split(df_train, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ds = ImagesDS(train_data, BINGO_PATH, mode = \"train\")\nds_val = ImagesDS(val_data, BINGO_PATH, mode = \"train\")\nds_test = ImagesDS(df_test, BINGO_PATH, mode = \"test\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting our pretrained model...","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"classes = 1\nmodel = EfficientNet.from_pretrained(\"efficientnet-b0\")\nmodel.fc = nn.Linear(1280, classes, bias = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loader = D.DataLoader(ds, batch_size = 64, shuffle = True, num_workers = 4)\nval_loader = D.DataLoader(ds_val, batch_size = batch_size, shuffle = True, num_workers = 4)\ntest_loader = D.DataLoader(ds_test, batch_size = batch_size, shuffle = False, num_workers = 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss and Optimizer","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 3e-4, weight_decay = 0.00001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here starts the ignite magic! ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"metrics = {\"loss\" : Loss(criterion), \"accuracy\" : Accuracy()}\n\ntrainer = create_supervised_trainer(model, optimizer, criterion, device = device)\nval_eval = create_supervised_evaluator(model, metrics = metrics, device = device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"@trainer.on(Events.EPOCH_COMPLETED)\ndef compute_and_display(engine):\n    epoch = engine.state.epoch\n    metrics = val_eval.run(val_loader).metrics\n    print(\"Validation Results - Epoch : {} Average loss : {:.4f} Average Accuracy : {:.4f}\".format(engine.state.epoch, metrics[\"loss\"], metrics[\"accuracy\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"handler = EarlyStopping(patience = 4, score_function = lambda engine : engine.state.metrics[\"accuracy\"], trainer = trainer)\n\nval_eval.add_event_handler(Events.COMPLETED, handler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"checkpoints = ModelCheckpoint(\"models\", \"Model\", n_saved = 3, create_dir = True)\n\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoints, {\"Konoha_senpu\" : model})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pbar = ProgressBar(bar_format = \"\")\n\npbar.attach(trainer, output_transform = lambda x : {\"loss\" : x})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"trainer.run(loader, max_epochs = 15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.eval()\ntest_preds = np.zeros((df_test.shape[0], ))\nwith torch.no_grad():\n    for i, data in enumerate(tqdm_notebook(test_loader, position=0, leave=True)):\n        images, _ = data\n        images = images.to(device)\n        output = model(images)\n        output = torch.softmax(output,1).cpu().detach().numpy()[:,1]\n        test_preds[i*batch_size : (i+1)*batch_size] = output","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_sub.target = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_sub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Although this is a basic notebook, I believe if you want to try your ideas on it, it have a lot of possibilities for that. \n\n* Some of the options you might want to try are Augmentation, Fold training, loss, Metrics etc.\n\nThanks for reading this kernel. ^_^","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Have a Great day ahead! :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}