{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset.py\nimport torch\nimport numpy as np\n\nfrom PIL import Image\nfrom PIL import ImageFile\n\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nclass ClassificationDataset:\n    def __init__(self, image_paths, targets, resize=None, augmentations=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        image = image.convert(\"RGB\")\n        targets = self.targets[item]\n        \n        if self.resize is not None:\n            image = image.resize(\n                (self.resize[1], self.resize[0]),\n            resample=Image.BILINEAR\n            )\n        image = np.array(image)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image = image)\n            image = augmented[\"image\"]\n        \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            'image': torch.tensor(image, dtype=torch.float),\n            'targets': torch.tensor(targets, dtype=torch.long),\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# engine.py\n\nimport torch\nimport torch.nn as nn\n\nfrom tqdm import tqdm\n\ndef train(dataset, data_loader, model, optimizer, device):\n    model.train()\n    num_batches = int(len(dataset)/data_loader.batch_size)\n    tk0 = tqdm(data_loader, total=num_batches)\n    for d in tk0:\n        inputs = data['image']\n        targets = data['targets']\n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1,1))\n        loss.backward()\n        optimizer.step()\n    \ndef evaluate(data_loader, model, device):\n    model.eval()\n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        for data in data_loader:\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            output = model(inputs)\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install pretrainedmodels -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.py\nimport torch.nn as nn\nimport pretrainedmodels\n\ndef get_model(pretrained):\n    if pretrained:\n        model = pretrainedmodels.__dict__['alexnet'](\n            pretrained='imagenet'\n        )\n    else:\n        model = pretrained.__dict__['alexnet'](\n            pretrainedmodels=None\n        )\n    model.last_linear = nn.Sequential(\n        nn.BatchNorm1d(4096), \n        nn.Dropout(p=0.25),\n        nn.Linear(in_features=4096,out_features=2048),\n        nn.ReLU(),\n        nn.BatchNorm1d(2048, eps=1e-5, momentum=0.1),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=2048, out_features=1),\n        nn.Sigmoid()\n    )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.py\nimport os\n\nimport pandas as pd\nimport numpy as np\n\nimport albumentations\nimport torch\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\ndata_path = '../input/siim-isic-melanoma-classification/jpeg'\ndevice = 'cuda'\nepochs = 5\ndf = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ndf.head()\nimages = df.image_name.values.tolist()\nimages = [\n    os.path.join(data_path, 'train/', i+'.jpg') for i in images\n]\ntargets = df.target.values\nmodel = get_model(pretrained=True)\nmodel.to(device)\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\naug = albumentations.Compose(\n    [\n        albumentations.Normalize(mean, std, max_pixel_value = 255.0\n                                )\n    ]\n)\ntrain_images, valid_images, train_targets, valid_targets = train_test_split(images, targets, stratify=targets, random_state=42)\ntrain_dataset = ClassificationDataset(\nimage_paths = train_images, \ntargets = train_targets,\nresize = (227, 227), \naugmentations = aug\n)\nvalid_dataset = ClassificationDataset(\nimage_paths = valid_images, \ntargets = train_targets,\nresize = (227, 227), \naugmentations = aug\n)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=16, shuffle=False, num_workers=4\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_dataset, batch_size=16, shuffle=False, num_workers=4\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\nfor epoch in range(1):\n    train(train_dataset,train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(\n        valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    pritn(f\"Epoch={epoch}, Valid ROC AUC = {roc_auc}\"\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}