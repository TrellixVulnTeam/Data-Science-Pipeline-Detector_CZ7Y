{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2 \nfrom matplotlib.image import imread\n# Technically not necessary in newest versions of jupyter\n%matplotlib inline","metadata":{"id":"ieJ8_KHRH97x","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\ntest_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\ntrain=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\ntest=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\nsubmission=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')","metadata":{"id":"Mw6SeKTsH975","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=train['anatom_site_general_challenge'].value_counts().index\nvalues=train['anatom_site_general_challenge'].value_counts().values\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\n\nax.pie(values, labels = labels,autopct='%1.2f%%')\nplt.show()\n \nprint(labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### A \"nevus\" is basically a visible, circumscribed, chronic lesion of the skin.","metadata":{}},{"cell_type":"code","source":"new=train.drop(labels=['image_name','patient_id','sex','age_approx','anatom_site_general_challenge','target'],axis=1)\npd.crosstab(new['diagnosis'].values,new['benign_malignant'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Take a sample from train ","metadata":{}},{"cell_type":"code","source":"df_0=train[train['target']==0].sample(2000)\ndf_1=train[train['target']==1]\ntrain=pd.concat([df_0,df_1])\ntrain=train.reset_index()","metadata":{"id":"hTNHfe7OH980","outputId":"9ddf0be8-b5c5-48a0-e761-01b99ed7a717","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing the Datasets","metadata":{"id":"Am0uvXLuH99C"}},{"cell_type":"code","source":"labels=[]\ndata=[]\nfor i in range(train.shape[0]):\n    data.append(train_dir + train['image_name'].iloc[i]+'.jpg')\n    labels.append(train['target'].iloc[i]/1.0)\ndf=pd.DataFrame(data)\ndf.columns=['images']\ndf['target']=labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data=[]\nfor i in range(test.shape[0]):\n    test_data.append(test_dir + test['image_name'].iloc[i]+'.jpg')\ndf_test=pd.DataFrame(test_data)\ndf_test.columns=['images']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df['images'],df['target'], test_size=0.2, random_state=1234)\n\ntrain=pd.DataFrame(X_train)\ntrain.columns=['images']\ntrain['target']=y_train\n\nvalidation=pd.DataFrame(X_val)\nvalidation.columns=['images']\nvalidation['target']=y_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  Preprocessing ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\nval_datagen=ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train,\n    x_col='images',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=8,\n    shuffle=True,\n    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    validation,\n    x_col='images',\n    y_col='target',\n    target_size=(224, 224),\n    shuffle=False,\n    batch_size=8,\n    class_mode='raw')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16, Xception\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n\ndef vgg16_model( num_classes=None):\n\n #   model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    model = Xception(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(224, 224, 3)\n    )\n    \n    x=Flatten()(model.output)\n    output=Dense(1,activation='sigmoid')(x)\n    model=Model(model.input,output)\n    \n    return model\n\nvgg_conv=vgg16_model(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K \n\ndef focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.metrics  import AUC \nopt = SGD(lr=0.001)\nvgg_conv.compile(loss=focal_loss(), metrics=[AUC()],optimizer=opt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_epochs = 10\nbatch_size=100\nnb_train_steps = train.shape[0]//batch_size\nnb_val_steps=validation.shape[0]//batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_conv.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_val_steps)\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Model","metadata":{}},{"cell_type":"code","source":"vgg_conv.summary()\nvgg_conv.save('Xception_model.h5') \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Load Model ","metadata":{}},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.models import *\n\nloaded_model = tensorflow.keras.models.load_model('Xception_model.h5',\n                                                  custom_objects={'focal_loss': focal_loss, 'focal_crossentropy': focal_loss()})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Improve prediction by using other data ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain_orig=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\ntest_orig=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\n\ntrain_sample =  train_orig.copy()\ntest_sample = test_orig.copy()\n\ntrain_sample.info()\ntest_sample.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##sample \ndf_0=train_sample[train_sample['target']==0].sample(20000)\ndf_1=train_sample[train_sample['target']==1]\ntrain_sample=pd.concat([df_0,df_1])\ntrain_sample=train_sample.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data=[]\nfor i in range(train_sample.shape[0]):\n    image_data.append(train_dir + train_sample['image_name'].iloc[i]+'.jpg')\n\ntrain_sample['images'] = image_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntarget=[]\nfor path in tqdm(train_sample['images']):\n    img=cv2.imread(str(path))\n    img = cv2.resize(img, (224,224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    img=np.reshape(img,(1,224,224,3))\n    prediction=vgg_conv.predict(img)\n    target.append(prediction[0][0])\n    \n\ntrain_sample['predicted']=target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample.to_csv(r'traindata_withpredicted_xception.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### import from  CSV","metadata":{}},{"cell_type":"code","source":"ls\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_sample = pd.read_csv('../input/siimisic-melanoma-saved-model/traindata_withpredicted_xception.csv')\ntrain_sample = pd.read_csv('traindata_withpredicted_xception.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample[train_sample['target']==1].describe().transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='benign_malignant',data=train_sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train_sample.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_sample[['sex','age_approx','anatom_site_general_challenge','predicted']]\ny = train_sample[['target']]/1.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.count()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['age_approx'] = X['age_approx'].fillna(X['age_approx'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[X['age_approx'].isnull()==True]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['sex'] = X['sex'].fillna(value ='male')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[X['sex'].isnull()==True]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='anatom_site_general_challenge',data=train_sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['anatom_site_general_challenge'] = X['anatom_site_general_challenge'].fillna(value ='torso')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[X['anatom_site_general_challenge'].isnull()==True]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X  = X.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking care of missing numerical data\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\nimputer.fit(X[:, 1:2])\nX[:, 1:2] = imputer.transform(X[:, 1:2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding categorical data\n# Encoding the Independent Variable\nfrom sklearn.compose import ColumnTransformer \nfrom  sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers= [('encoder',OneHotEncoder(), [0,2])] , remainder='passthrough')\nX = ct.fit_transform(X)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=101)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n\nmodel.add(Dense(units=1000,activation='relu'))\n\nmodel.add(Dense(units=2000,activation='relu'))\n\nmodel.add(Dense(units=5000,activation='relu'))\n\nmodel.add(Dense(units=10000,activation='relu'))\nmodel.add(Dense(units=20000,activation='relu'))\n\nmodel.add(Dense(units=10000,activation='relu'))\nmodel.add(Dense(units=5000,activation='relu'))\n\nmodel.add(Dense(units=2000,activation='relu'))\nmodel.add(Dense(units=1000,activation='relu'))\n\nmodel.add(Dense(units=400,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=200,activation='relu'))\n\nmodel.add(Dense(units=100,activation='relu'))\n\nmodel.add(Dense(units=50,activation='relu'))\n\nmodel.add(Dense(units=30,activation='relu'))\nmodel.add(Dense(units=10,activation='relu'))\n\nmodel.add(Dense(units=5,activation='relu'))\n\nmodel.add(Dense(units=1,activation='sigmoid'))\n\n# For a binary classification problem\nmodel.compile(loss=focal_loss(), metrics=[AUC()],optimizer=opt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x=X_train, \n          y=y_train, \n          epochs=400, \n          batch_size=128,\n          validation_data=(X_test, y_test), verbose=1\n          )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loss = pd.DataFrame(model.history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loss.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error \nXGBModel = XGBRegressor()\nXGBModel.fit(X_train,y_train , verbose=False)\n\n# Get the mean absolute error on the validation data :\nXGBpredictions = XGBModel.predict(X_test)\nMAE = mean_absolute_error(y_test , XGBpredictions)\nprint('XGBoost validation MAE = ',MAE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"import cv2 \ntarget=[]\nfor path in df_test['images']:\n    img=cv2.imread(str(path))\n    img = cv2.resize(img, (224,224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    img=np.reshape(img,(1,224,224,3))\n    prediction=vgg_conv.predict(img)\n    target.append(prediction[0][0])\n\nsubmission['target']=target\n\nsubmission.to_csv('submission_XGB.csv', index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_sample = pd.read_csv('../input/siimisic-melanoma-saved-model/traindata_withpredicted_xception.csv')\ntest_pred = pd.read_csv('submission_XGB.csv')\ntest_data=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}