{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install -q efficientnet\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os \nimport gc\nfrom kaggle_datasets import KaggleDatasets\nfrom PIL import Image\nfrom keras.metrics import *\nfrom keras.preprocessing import image\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_images_dir = GCS_PATH+'/jpeg/train/'\ntest_images_dir = GCS_PATH+'/jpeg/test/'\ntrain_csv = GCS_PATH+'/train.csv'\ntest_csv  = GCS_PATH+'/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\n\ntrain_df = train_df.replace('male', 0)\ntrain_df = train_df.replace('female', 1)\n\ntest_df = test_df.replace('male', 0)\ntest_df = test_df.replace('female', 1)\n\ntrain_df = train_df.dropna()\n\ntrain_df = train_df.drop(columns = 'patient_id')\ntrain_df = train_df.drop(columns = 'diagnosis')\ntrain_df = train_df.drop(columns = 'benign_malignant')\ntest_df = test_df.drop(columns = 'patient_id')\n\n#anatom_site_general_challenge\ntrain_df = train_df.replace('torso', 0)\ntrain_df = train_df.replace('lower extremity', 1)\ntrain_df = train_df.replace('upper extremity', 2)\ntrain_df = train_df.replace('head/neck', 3)\ntrain_df = train_df.replace('palms/soles', 4)\ntrain_df = train_df.replace('oral/genital', 5)\ntrain_df = train_df.replace(np.nan, 6)\n\ntest_df = test_df.replace('torso', 0)\ntest_df = test_df.replace('lower extremity', 1)\ntest_df = test_df.replace('upper extremity', 2)\ntest_df = test_df.replace('head/neck', 3)\ntest_df = test_df.replace('palms/soles', 4)\ntest_df = test_df.replace('oral/genital', 5)\ntest_df = test_df.replace(np.nan, 6)\n\n# del test_csv\n# del train_csv\n# gc.collect()\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metadata_train = train_df[['sex','age_approx','anatom_site_general_challenge']]\n# target_train = train_df[['target']]\n# img_train = train_df['image_name']+train_images_dir\n\n# metadata_test = test_df[['sex','age_approx','anatom_site_general_challenge']]\n# img_test = test_df[['image_name']]\n\n# data_metadata_train = tf.data.Dataset.from_tensor_slices(metadata_train.values)\n# data_target_train = tf.data.Dataset.from_tensor_slices(target_train.values)\n# data_img_train = tf.data.Dataset.from_tensor_slices(img_train.values)\n\n# img_train = tf.convert_to_tensor(img_train.values)\n#img_train = tf.io.decode_csv(img_train, record_defaults = ['string'])\n\nimage_path = train_images_dir + train_df['image_name'] + '.jpg'\nimage_path = tf.convert_to_tensor(image_path, dtype=tf.string)\nmetadata = train_df[['sex','age_approx','anatom_site_general_challenge']]\nmetadata = np.array(metadata)\nmetadata = tf.convert_to_tensor(metadata)\nlabels = np.array(train_df[['target']])\nprint(labels.sum())\nprint(np.shape(labels))\nlabels = tf.convert_to_tensor(labels)\n\ntimage_path = test_images_dir + test_df['image_name'] + '.jpg'\ntimage_path = tf.convert_to_tensor(timage_path, dtype=tf.string)\ntmetadata = test_df[['sex','age_approx','anatom_site_general_challenge']]\ntmetadata = np.array(tmetadata)\ntmetadata = tf.convert_to_tensor(tmetadata)\n\ndataset = tf.data.Dataset.from_tensor_slices((image_path, metadata, labels))\n\ntdataset = tf.data.Dataset.from_tensor_slices((timage_path, tmetadata))\n\ndef map_fn(path,metadata,label):\n    \n    image = tf.image.decode_jpeg(tf.io.read_file(path))\n\n    image = tf.image.resize(image, [128, 128])\n    \n    image = tf.cast(image, tf.float32) / 255.0\n    \n    return (image, metadata), label\n\ndef tmap_fn(path,metadata):\n    \n    image = tf.image.decode_jpeg(tf.io.read_file(path))\n\n    image = tf.image.resize(image, [128, 128])\n    \n    image = tf.cast(image, tf.float32) / 255.0\n    #test = (image, metadata)\n    return (image, metadata)\n\n\n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# # instantiate a distribution strategy\n# strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nbatch_size = 16 * strategy.num_replicas_in_sync\ndataset = dataset.map(map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ndataset = dataset.repeat()\ndataset = dataset.batch(batch_size)\n#33126\n\ndataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n#images, metadatas, labels = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_imgs = []\n# train_metadatas = []\n# labels = []\n\n# for index, row in train_df.iterrows():\n#     label = row['target']\n#     labels.append(label)\n    \n#     metadata = row[0:-1]\n#     train_metadatas.append(metadata)\n    \n#     train_img = image.load_img(train_images_dir + index + '.jpg', target_size = (128,128,3))\n#     train_img = image.img_to_array(train_img, dtype = np.float16)\n#     train_img = train_img / 225.0\n#     train_imgs.append(train_img)\n    \n    \n    \n# labels = np.array(labels).astype(np.float16)\n# train_metadatas = np.array(train_metadatas).astype(np.float16)\n# train_imgs = np.array(train_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del train_df\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    input_tensor = Input(shape=(128, 128, 3))\n    base_model = efn.EfficientNetB0(include_top=False,\n        input_shape=(128,128, 3),\n        weights='imagenet'\n    )(input_tensor)\n    base_model.trainable = True  \n    \n    #input_tensor = Input(shape=(128, 128, 3))\n    #base_model = efn.EfficientNetB0(include_top=False,input_shape=(128, 128, 3),weights='imagenet')\n\n    #base_model = InceptionV3(include_top=False, input_tensor=input_tensor, weights='imagenet', input_shape=(128,128,3))\n    #x = base_model.output\n    x = GlobalAveragePooling2D()(base_model)\n    x = Dense(512, activation='relu')(x)\n    predictions = Dense(16, activation='relu')(x)\n\n#    img_model = Model(inputs=input_tensor, outputs=predictions)\n\n    input_data = Input(shape=(3))\n    metadata_model = Dense(3, activation=\"relu\")(input_data)\n#    metadata_model = Model(inputs=input_data, outputs = metadata_model)\n\n    combined = tf.keras.layers.concatenate([predictions, metadata_model], axis = 1)\n\n    z = Dense(4, activation=\"relu\")(combined)\n    z = Dense(1, activation=\"sigmoid\")(z)\n\n    model = Model(inputs=[input_tensor, input_data], outputs=z)\n    \n    \n    METRICS = [\n      BinaryAccuracy(name='accuracy'),\n      AUC(name='auc'),\n    ]\n    model.compile(\n        optimizer = 'adam',\n        loss = 'binary_crossentropy',\n        metrics=[METRICS]\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# input_tensor = Input(shape=(128, 128, 3))\n# #base_model = efn.EfficientNetB0(include_top=False,input_shape=(128, 128, 3),weights='imagenet')\n\n# #base_model = InceptionV3(include_top=False, input_tensor=input_tensor, weights='imagenet', input_shape=(128,128,3))\n# x = base_model.output\n# x = GlobalAveragePooling2D()(x)\n# x = Dense(512, activation='relu')(x)\n# predictions = Dense(16, activation='relu')(x)\n\n# img_model = Model(inputs=base_model.input, outputs=predictions)\n\n# input_data = Input(shape=(3))\n# metadata_model = Dense(3, activation=\"relu\")(input_data)\n# metadata_model = Model(inputs=input_data, outputs = metadata_model)\n\n# combined = tf.keras.layers.concatenate([img_model.output, metadata_model.output])\n\n# z = Dense(4, activation=\"relu\")(combined)\n# z = Dense(1, activation=\"sigmoid\")(z)\n\n# model = Model(inputs=[img_model.input, metadata_model.input], outputs=z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# METRICS = [\n#       BinaryAccuracy(name='accuracy'),\n#       AUC(name='auc'),\n# ]\n# model.compile(\n#     optimizer = 'adam',\n#     loss = 'binary_crossentropy',\n#     metrics=[METRICS]\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit([images, metadatas], labels, validation_split=0.30, epochs = 5, batch_size = 1)\nsteps = 33126 // batch_size\nweights = {0:0.018,\n           1:0.982\n          }\nmodel.fit(dataset, epochs = 10, steps_per_epoch=steps, class_weight = weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del images\n# del metadatas\n# del labels\n# gc.collect()\ntdataset = tdataset.map(tmap_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntdataset = tdataset.batch(10982)\n#10982\ntdataset = tdataset.prefetch(tf.data.experimental.AUTOTUNE)\ntimages, tmetadatas = tf.compat.v1.data.make_one_shot_iterator(tdataset).get_next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_imgs = []\n# test_metadatas = []\n\n# for index, row in test_df.head().iterrows():\n#     metadata = row[0:]\n#     test_metadatas.append(metadata)\n    \n#     test_img = image.load_img(test_images_dir + index + '.jpg', target_size = (128,128,3))\n#     test_img = image.img_to_array(test_img, dtype = np.float16)\n#     test_img = test_img / 225.0\n#     test_imgs.append(test_img)\n    \n\n# test_metadatas = np.array(test_metadatas).astype(np.float16)\n# test_imgs = np.array(test_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = model.predict([timages, tmetadatas])\nnp.shape(test_labels)\ntest_df = test_df.reset_index()\ndf_sub = pd.DataFrame()\ndf_sub['image_name'] = test_df['image_name']\ndf_sub['target'] = test_labels.astype(np.float32)\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}