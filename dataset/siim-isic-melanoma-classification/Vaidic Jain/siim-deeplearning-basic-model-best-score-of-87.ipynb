{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install -q efficientnet\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom keras.metrics import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n# train_images_dir = GCS_PATH+'/jpeg/train/'\n# test_images_dir = GCS_PATH+'/jpeg/test/'\n# train_csv = GCS_PATH+'/train.csv'\n# test_csv  = GCS_PATH+'/test.csv'\nPATH = '/kaggle/input/siim-isic-melanoma-classification'\ntrain_images_dir = PATH+'/jpeg/train/'\ntest_images_dir = PATH+'/jpeg/test/'\ntrain_csv = PATH+'/train.csv'\ntest_csv  = PATH+'/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\n\n# print(train_df.isnull().sum(axis=0))\n# print(test_df.isnull().sum(axis=0))\n\ntrain_df['image_name'] = train_df['image_name'] + '.jpg'\ntest_df['image_name'] = test_df['image_name'] + '.jpg'\n\ntrain_df = train_df.sort_values(['patient_id'])\ntrain_df = train_df.reset_index()\n\ntrain_df = train_df.sort_values(['target'])\ntrain_df = train_df.reset_index()\n\ntrain_df = train_df.drop(['index', 'patient_id', 'diagnosis', 'benign_malignant'], axis = 1)\ntest_df = test_df.drop(['patient_id'], axis = 1)\n\ntrain_df['anatom_site_general_challenge'] = train_df['anatom_site_general_challenge'].replace(np.nan, 'torso')\ntest_df['anatom_site_general_challenge'] = test_df['anatom_site_general_challenge'].replace(np.nan, 'torso')\n\ntrain_df = train_df.dropna()\n\ntest_df['age_approx'] = test_df['age_approx'] / train_df['age_approx'].mean()\ntrain_df['age_approx'] = train_df['age_approx'] / train_df['age_approx'].mean()\n\ntrain_df['sex'] = train_df['sex'].replace('female', 0)\ntest_df['sex'] = test_df['sex'].replace('female', 0)\ntrain_df['sex'] = train_df['sex'].replace('male', 1)\ntest_df['sex'] = test_df['sex'].replace('male', 1)\n\ntrain_df['target'] = train_df['target'].replace(0,'0')\ntrain_df['target'] = train_df['target'].replace(1,'1')\n\ntrain_df['anatom_site_general_challenge'] = pd.Categorical(train_df['anatom_site_general_challenge'])\ntrain_df['anatom_site_general_challenge'] = train_df.anatom_site_general_challenge.cat.codes\ntest_df['anatom_site_general_challenge'] = pd.Categorical(test_df['anatom_site_general_challenge'])\ntest_df['anatom_site_general_challenge'] = test_df.anatom_site_general_challenge.cat.codes\n\n#print(train_df.isnull().sum(axis=0))\n# print(test_df.isnull().sum(axis=0))\n\n\nprint(train_df)\ntest_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_split = 0.1\n# batch_size = 16 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val = train_df[0:int(val_split * 33058)]\n# train = train_df[int(val_split * 33058):]\nval = train_df[24000:25000]\nval = pd.concat([val, train_df[33057:]])\ntrain = train_df[25000:33058]\n# train_df['target'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_size=(128, 128)\nbatch_size=32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255.,\n                                   width_shift_range=0.15,\n                                   rotation_range=0.15,\n                                   height_shift_range=0.15,\n                                   zoom_range=0.15,\n                                   horizontal_flip=True,\n                                   brightness_range=[0.5,1.5]\n                                  )\nval_datagen = ImageDataGenerator(rescale=1./255.)\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=train,\n                                                    directory=train_images_dir,\n                                                    x_col='image_name',\n                                                    y_col='target',\n                                                    class_mode='binary',\n#                                                     color_mode='grayscale',\n                                                    target_size=target_size,\n#                                                     shuffle=False,\n                                                    batch_size=batch_size\n                                                   )\nval_generator = val_datagen.flow_from_dataframe(dataframe=val,\n                                                directory=train_images_dir,\n                                                x_col='image_name',\n                                                y_col='target',\n                                                class_mode='binary',\n                                                target_size=target_size,\n#                                                 shuffle=False,\n                                                batch_size=batch_size\n                                               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    base_model = efn.EfficientNetB0(include_top=False,\n        input_shape=(128,128, 3),\n        weights='imagenet'\n    )\n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(1, activation='sigmoid')(x)\n\n\n    model = Model(inputs=base_model.input, outputs=x)\n    \n#     for layer in base_model.layers:\n#           layer.trainable = False\n    \n    \n    METRICS = [\n      BinaryAccuracy(name='accuracy'),\n      AUC(name='auc'),\n    ]\n    model.compile(\n        optimizer = 'adam',\n        loss = 'binary_crossentropy',\n        metrics=[METRICS]\n    )\n\n# model = tf.keras.Sequential([efn.EfficientNetB0(include_top=False, input_shape=(128,128, 3), weights='imagenet'),\n#                             GlobalAveragePooling2D(),\n#                             Dense(1024, activation='relu'),\n#                             Dense(512, activation='relu'),\n#                             Dense(1, activation='sigmoid')]\n#                            )\n# METRICS = [BinaryAccuracy(name='accuracy'),AUC(name='auc'),]\n# model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics=[METRICS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weights = {0:0.018,\n#            1:0.982\n#           }\n# weights = {0:0.072,\n#            1:0.928\n#           }\nmodel.fit(x=train_generator, epochs = 7, validation_data=val_generator)#, class_weight = weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timage_path = test_images_dir + test_df['image_name']\ntimage_path = tf.convert_to_tensor(timage_path, dtype=tf.string)\ntmetadata = test_df[['sex','age_approx','anatom_site_general_challenge']]\ntmetadata = np.array(tmetadata)\ntmetadata = tf.convert_to_tensor(tmetadata)\n\nnp.shape(timage_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tmap_fn(path,metadata):\n    \n    image = tf.image.decode_jpeg(tf.io.read_file(path))\n\n    image = tf.image.resize(image, [128, 128])\n    \n    image = tf.cast(image, tf.float32) / 255.0\n    #test = (image, metadata)\n    return (image, metadata)\n\ntdataset = tf.data.Dataset.from_tensor_slices((timage_path, tmetadata))\ntdataset = tdataset.map(tmap_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntdataset = tdataset.batch(10982)\n#10982\ntdataset = tdataset.prefetch(tf.data.experimental.AUTOTUNE)\ntimages, tmetadatas = tf.compat.v1.data.make_one_shot_iterator(tdataset).get_next()\n\ntest_labels = model.predict([timages])\ntest_df = pd.read_csv(test_csv)\n\nnp.shape(test_labels)\ntest_df = test_df.reset_index()\ndf_sub = pd.DataFrame()\ndf_sub['image_name'] = test_df['image_name']\ndf_sub['target'] = test_labels.astype(np.float32)\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}